Title,Abstract,Keywords
Data mining with big data,"Big Data concern large-volume, complex, growing data sets with multiple, autonomous sources. With the fast development of networking, data storage, and the data collection capacity, Big Data are now rapidly expanding in all science and engineering domains, including physical, biological and biomedical sciences. This paper presents a HACE theorem that characterizes the features of the Big Data revolution, and proposes a Big Data processing model, from the data mining perspective. This data-driven model involves demand-driven aggregation of information sources, mining and analysis, user interest modeling, and security and privacy considerations. We analyze the challenging issues in the data-driven model and also in the Big Data revolution.","Information management,
Data handling,
Data storage systems,
Data privacy,
Data models,
Distributed databases"
An Overview of Massive MIMO: Benefits and Challenges,"Massive multiple-input multiple-output (MIMO) wireless communications refers to the idea equipping cellular base stations (BSs) with a very large number of antennas, and has been shown to potentially allow for orders of magnitude improvement in spectral and energy efficiency using relatively simple (linear) processing. In this paper, we present a comprehensive overview of state-of-the-art research on the topic, which has recently attracted considerable attention. We begin with an information theoretic analysis to illustrate the conjectured advantages of massive MIMO, and then we address implementation issues related to channel estimation, detection and precoding schemes. We particularly focus on the potential impact of pilot contamination caused by the use of non-orthogonal pilot sequences by users in adjacent cells. We also analyze the energy efficiency achieved by massive MIMO systems, and demonstrate how the degrees of freedom provided by massive MIMO systems enable efficient single-carrier transmission. Finally, the challenges and opportunities associated with implementing massive MIMO in future wireless communications systems are discussed.","MIMO,
Vectors,
Antennas,
Uplink,
Channel estimation,
Receivers,
Downlink"
Internet of Things in Industries: A Survey,"Internet of Things (IoT) has provided a promising opportunity to build powerful industrial systems and applications by leveraging the growing ubiquity of radio-frequency identification (RFID), and wireless, mobile, and sensor devices. A wide range of industrial IoT applications have been developed and deployed in recent years. In an effort to understand the development of IoT in industries, this paper reviews the current research of IoT, key enabling technologies, major IoT applications in industries, and identifies research trends and challenges. A main contribution of this review paper is that it summarizes the current state-of-the-art IoT in industries systematically.","Radiofrequency identification,
Big data,
Wireless sensor networks,
Service-oriented architecture,
Wireless communication"
Fast Feature Pyramids for Object Detection,"Multi-resolution image features may be approximated via extrapolation from nearby scales, rather than being computed explicitly. This fundamental insight allows us to design object detection algorithms that are as accurate, and considerably faster, than the state-of-the-art. The computational bottleneck of many modern detectors is the computation of features at every scale of a finely-sampled image pyramid. Our key insight is that one may compute finely sampled feature pyramids at a fraction of the cost, without sacrificing performance: for a broad family of features we find that features computed at octave-spaced scale intervals are sufficient to approximate features on a finely-sampled pyramid. Extrapolation is inexpensive as compared to direct feature computation. As a result, our approximation yields considerable speedups with negligible loss in detection accuracy. We modify three diverse visual recognition systems to use fast feature pyramids and show results on both pedestrian detection (measured on the Caltech, INRIA, TUD-Brussels and ETH data sets) and general object detection (measured on the PASCAL VOC). The approach is general and is widely applicable to vision algorithms requiring fine-grained multi-scale analysis. Our approximation is valid for images with broad spectra (most natural images) and fails for images with narrow band-pass spectra (e.g., periodic textures).",
Channel Estimation and Hybrid Precoding for Millimeter Wave Cellular Systems,"Millimeter wave (mmWave) cellular systems will enable gigabit-per-second data rates thanks to the large bandwidth available at mmWave frequencies. To realize sufficient link margin, mmWave systems will employ directional beamforming with large antenna arrays at both the transmitter and receiver. Due to the high cost and power consumption of gigasample mixed-signal devices, mmWave precoding will likely be divided among the analog and digital domains. The large number of antennas and the presence of analog beamforming requires the development of mmWave-specific channel estimation and precoding algorithms. This paper develops an adaptive algorithm to estimate the mmWave channel parameters that exploits the poor scattering nature of the channel. To enable the efficient operation of this algorithm, a novel hierarchical multi-resolution codebook is designed to construct training beamforming vectors with different beamwidths. For single-path channels, an upper bound on the estimation error probability using the proposed algorithm is derived, and some insights into the efficient allocation of the training power among the adaptive stages of the algorithm are obtained. The adaptive channel estimation algorithm is then extended to the multi-path case relying on the sparse nature of the channel. Using the estimated channel, this paper proposes a new hybrid analog/digital precoding algorithm that overcomes the hardware constraints on the analog-only beamforming, and approaches the performance of digital solutions. Simulation results show that the proposed low-complexity channel estimation algorithm achieves comparable precoding gains compared to exhaustive channel training algorithms. The results illustrate that the proposed channel estimation and precoding algorithms can approach the coverage probability achieved by perfect channel knowledge even in the presence of interference.","Vectors,
Channel estimation,
Algorithm design and analysis,
Array signal processing,
Training,
Radio frequency,
Signal processing algorithms"
XSEDE: Accelerating Scientific Discovery,"Computing in science and engineering is now ubiquitous: digital technologies underpin, accelerate, and enable new, even transformational, research in all domains. Access to an array of integrated and well-supported high-end digital services is critical for the advancement of knowledge. Driven by community needs, the Extreme Science and Engineering Discovery Environment (XSEDE) project substantially enhances the productivity of a growing community of scholars, researchers, and engineers (collectively referred to as ""scientists""' throughout this article) through access to advanced digital services that support open research. XSEDE's integrated, comprehensive suite of advanced digital services federates with other high-end facilities and with campus-based resources, serving as the foundation for a national e-science infrastructure ecosystem. XSEDE's e-science infrastructure has tremendous potential for enabling new advancements in research and education. XSEDE's vision is a world of digitally enabled scholars, researchers, and engineers participating in multidisciplinary collaborations to tackle society's grand challenges.","Knowledge discovery,
Scientific computing,
Digital systems,
Materials engineering,
Supercomputers"
A Review on Multi-Label Learning Algorithms,"Multi-label learning studies the problem where each example is represented by a single instance while associated with a set of labels simultaneously. During the past decade, significant amount of progresses have been made toward this emerging machine learning paradigm. This paper aims to provide a timely review on this area with emphasis on state-of-the-art multi-label learning algorithms. Firstly, fundamentals on multi-label learning including formal definition and evaluation metrics are given. Secondly and primarily, eight representative multi-label learning algorithms are scrutinized under common notations with relevant analyses and discussions. Thirdly, several related learning settings are briefly summarized. As a conclusion, online resources and open research problems on multi-label learning are outlined for reference purposes.","Training,
Correlation,
Supervised learning,
Semantics,
Machine learning algorithms,
Algorithm design and analysis,
Vectors"
Visual Tracking: An Experimental Survey,"There is a large variety of trackers, which have been proposed in the literature during the last two decades with some mixed success. Object tracking in realistic scenarios is a difficult problem, therefore, it remains a most active area of research in computer vision. A good tracker should perform well in a large number of videos involving illumination changes, occlusion, clutter, camera motion, low contrast, specularities, and at least six more aspects. However, the performance of proposed trackers have been evaluated typically on less than ten videos, or on the special purpose datasets. In this paper, we aim to evaluate trackers systematically and experimentally on 315 video fragments covering above aspects. We selected a set of nineteen trackers to include a wide variety of algorithms often cited in literature, supplemented with trackers appearing in 2010 and 2011 for which the code was publicly available. We demonstrate that trackers can be evaluated objectively by survival curves, Kaplan Meier statistics, and Grubs testing. We find that in the evaluation practice the F-score is as effective as the object tracking accuracy (OTA) score. The analysis under a large variety of circumstances provides objective insight into the strengths and weaknesses of trackers.","Target tracking,
Videos,
Radar tracking,
Educational institutions,
Robustness,
Object tracking"
Scalable Nearest Neighbor Algorithms for High Dimensional Data,"For many computer vision and machine learning problems, large training sets are key for good performance. However, the most computationally expensive part of many computer vision and machine learning algorithms consists of finding nearest neighbor matches to high dimensional vectors that represent the training data. We propose new algorithms for approximate nearest neighbor matching and evaluate and compare them with previous algorithms. For matching high dimensional features, we find two algorithms to be the most efficient: the randomized k-d forest and a new algorithm proposed in this paper, the priority search k-means tree. We also propose a new algorithm for matching binary features by searching multiple hierarchical clustering trees and show it outperforms methods typically used in the literature. We show that the optimal nearest neighbor algorithm and its parameters depend on the data set characteristics and describe an automated configuration procedure for finding the best algorithm to search a particular data set. In order to scale to very large data sets that would otherwise not fit in the memory of a single machine, we propose a distributed nearest neighbor matching framework that can be used with any of the algorithms described in the paper. All this research has been released as an open source library called fast library for approximate nearest neighbors (FLANN), which has been incorporated into OpenCV and is now one of the most popular libraries for nearest neighbor matching.","Approximation algorithms,
Clustering algorithms,
Vegetation,
Partitioning algorithms,
Approximation methods,
Machine learning algorithms,
Computer vision"
Toward Scalable Systems for Big Data Analytics: A Technology Tutorial,"Recent technological advancements have led to a deluge of data from distinctive domains (e.g., health care and scientific sensors, user-generated data, Internet and financial companies, and supply chain systems) over the past two decades. The term big data was coined to capture the meaning of this emerging trend. In addition to its sheer volume, big data also exhibits other unique characteristics as compared with traditional data. For instance, big data is commonly unstructured and require more real-time analysis. This development calls for new system architectures for data acquisition, transmission, storage, and large-scale data processing mechanisms. In this paper, we present a literature survey and system tutorial for big data analytics platforms, aiming to provide an overall picture for nonexpert readers and instill a do-it-yourself spirit for advanced audiences to customize their own big-data solutions. First, we present the definition of big data and discuss big data challenges. Next, we present a systematic framework to decompose big data systems into four sequential modules, namely data generation, data acquisition, data storage, and data analytics. These four modules form a big data value chain. Following that, we present a detailed survey of numerous approaches and mechanisms from research and industry communities. In addition, we present the prevalent Hadoop framework for addressing big data challenges. Finally, we outline several evaluation benchmarks and potential research directions for big data systems.",
Fast Compressive Tracking,"It is a challenging task to develop effective and efficient appearance models for robust object tracking due to factors such as pose variation, illumination change, occlusion, and motion blur. Existing online tracking algorithms often update models with samples from observations in recent frames. Despite much success has been demonstrated, numerous issues remain to be addressed. First, while these adaptive appearance models are data-dependent, there does not exist sufficient amount of data for online algorithms to learn at the outset. Second, online tracking algorithms often encounter the drift problems. As a result of self-taught learning, misaligned samples are likely to be added and degrade the appearance models. In this paper, we propose a simple yet effective and efficient tracking algorithm with an appearance model based on features extracted from a multiscale image feature space with dataindependent basis. The proposed appearance model employs non-adaptive random projections that preserve the structure of the image feature space of objects. A very sparse measurement matrix is constructed to efficiently extract the features for the appearance model. We compress sample images of the foreground target and the background using the same sparse measurement matrix. The tracking task is formulated as a binary classification via a naive Bayes classifier with online update in the compressed domain. A coarse-to-fine search strategy is adopted to further reduce the computational complexity in the detection procedure. The proposed compressive tracking algorithm runs in real-time and performs favorably against state-of-the-art methods on challenging sequences in terms of efficiency, accuracy and robustness.",
Adaptive Control of a Flexible Crane System With the Boundary Output Constraint,"In this paper, a flexible cable with a payload attached at the bottom is considered to be the model of a crane system used for positioning the payload. The dynamics of the flexible cable coupled with the tip payload contribute to a hybrid system represented by partial-ordinary differential equations. An integral-barrier Lyapunov function (IBLF)-based control is proposed to suppress the undesirable vibrations of the flexible crane system with the boundary output constraint. Adaption laws are developed for handling parametric uncertainties. A novel IBLF is adopted to guarantee the uniform stability of the closed-loop systems without the violation of the boundary constraint. All closed-loop signals are ensured to be bounded. Extensive simulations are demonstrated to illustrate the performance of the control system.",
5G wireless backhaul networks: challenges and research advances,"5G networks are expected to achieve gigabit-level throughput in future cellular networks. However, it is a great challenge to treat 5G wireless backhaul traffic in an effective way. In this article, we analyze the wireless backhaul traffic in two typical network architectures adopting small cell and millimeter wave communication technologies. Furthermore, the energy efficiency of wireless backhaul networks is compared for different network architectures and frequency bands. Numerical comparison results provide some guidelines for deploying future 5G wireless backhaul networks in economical and highly energy-efficient ways.",
An Information Framework for Creating a Smart City Through Internet of Things,"Increasing population density in urban centers demands adequate provision of services and infrastructure to meet the needs of city inhabitants, encompassing residents, workers, and visitors. The utilization of information and communications technologies to achieve this objective presents an opportunity for the development of smart cities, where city management and citizens are given access to a wealth of real-time information about the urban environment upon which to base decisions, actions, and future planning. This paper presents a framework for the realization of smart cities through the Internet of Things (IoT). The framework encompasses the complete urban information system, from the sensory level and networking support structure through to data management and Cloud-based integration of respective systems and services, and forms a transformational part of the existing cyber-physical system. This IoT vision for a smart city is applied to a noise mapping case study to illustrate a new method for existing operations that can be adapted for the enhancement and delivery of important city services.",
Spectrum Sharing for Device-to-Device Communication in Cellular Networks,"This paper addresses two fundamental and interrelated issues in device-to-device (D2D) enhanced cellular networks. The first issue is how D2D users should access spectrum, and we consider two choices: overlay (orthogonal spectrum between D2D and cellular UEs) and underlay (non-orthogonal). The second issue is how D2D users should choose between communicating directly or via the base station, a choice that depends on distance between the potential D2D transmitter and receiver. We propose a tractable hybrid network model where the positions of mobiles are modeled by random spatial Poisson point process, with which we present a general analytical approach that allows a unified performance evaluation for these questions. Then, we derive analytical rate expressions and apply them to optimize the two D2D spectrum sharing scenarios under a weighted proportional fair utility function. We find that as the proportion of potential D2D mobiles increases, the optimal spectrum partition in the overlay is almost invariant (when D2D mode selection threshold is large) while the optimal spectrum access factor in the underlay decreases. Further, from a coverage perspective, we reveal a tradeoff between the spectrum access factor and the D2D mode selection threshold in the underlay: as more D2D links are allowed (due to a more relaxed mode selection threshold), the network should actually make less spectrum available to them to limit their interference.",
Large-Margin Multi-ViewInformation Bottleneck,"In this paper, we extend the theory of the information bottleneck (IB) to learning from examples represented by multi-view features. We formulate the problem as one of encoding a communication system with multiple senders, each of which represents one view of the data. Based on the precise components filtered out from multiple information sources through a “bottleneck”, a margin maximization approach is then used to strengthen the discrimination of the encoder by improving the code distance within the frame of coding theory. The resulting algorithm therefore inherits all the merits of the IB principle and coding theory. It has two distinct advantages over existing algorithms, namely, that our method finds a tradeoff between the accuracy and complexity of the multi-view model, and that the encoded multi-view data retains sufficient discrimination for classification. We also derive the robustness and generalization error bound of the proposed algorithm, and reveal the specific properties of multi-view learning. First, the complementarity of multi-view features guarantees the robustness of the algorithm. Second, the consensus of multi-view features reduces the empirical Rademacher complexity of the objective function, enhances the accuracy of the solution, and improves the generalization error bound of the algorithm. The resulting objective function is solved efficiently using the alternating direction method. Experimental results on annotation, classification and recognition tasks demonstrate that the proposed algorithm is promising for practical applications.",
Convolutional Neural Networks for Speech Recognition,"Recently, the hybrid deep neural network (DNN)-hidden Markov model (HMM) has been shown to significantly improve speech recognition performance over the conventional Gaussian mixture model (GMM)-HMM. The performance improvement is partially attributed to the ability of the DNN to model complex correlations in speech features. In this paper, we show that further error rate reduction can be obtained by using convolutional neural networks (CNNs). We first present a concise description of the basic CNN and explain how it can be used for speech recognition. We further propose a limited-weight-sharing scheme that can better model speech features. The special structure such as local connectivity, weight sharing, and pooling in CNNs exhibits some degree of invariance to small shifts of speech features along the frequency axis, which is important to deal with speaker and environment variations. Experimental results show that CNNs reduce the error rate by 6%-10% compared with DNNs on the TIMIT phone recognition and the voice search large vocabulary speech recognition tasks.","Convolution,
Hidden Markov models,
Speech,
Speech recognition,
Vectors,
Neural networks,
Training"
Cooperative Co-Evolution With Differential Grouping for Large Scale Optimization,"Cooperative co-evolution has been introduced into evolutionary algorithms with the aim of solving increasingly complex optimization problems through a divide-and-conquer paradigm. In theory, the idea of co-adapted subcomponents is desirable for solving large-scale optimization problems. However, in practice, without prior knowledge about the problem, it is not clear how the problem should be decomposed. In this paper, we propose an automatic decomposition strategy called differential grouping that can uncover the underlying interaction structure of the decision variables and form subcomponents such that the interdependence between them is kept to a minimum. We show mathematically how such a decomposition strategy can be derived from a definition of partial separability. The empirical studies show that such near-optimal decomposition can greatly improve the solution quality on large-scale global optimization problems. Finally, we show how such an automated decomposition allows for a better approximation of the contribution of various subcomponents, leading to a more efficient assignment of the computational budget to various subcomponents.",
The SpiNNaker Project,"The spiking neural network architecture (SpiNNaker) project aims to deliver a massively parallel million-core computer whose interconnect architecture is inspired by the connectivity characteristics of the mammalian brain, and which is suited to the modeling of large-scale spiking neural networks in biological real time. Specifically, the interconnect allows the transmission of a very large number of very small data packets, each conveying explicitly the source, and implicitly the time, of a single neural action potential or “spike.” In this paper, we review the current state of the project, which has already delivered systems with up to 2500 processors, and present the real-time event-driven programming model that supports flexible access to the resources of the machine and has enabled its use by a wide range of collaborators around the world.",
High-Order Distance-Based Multiview Stochastic Learning in Image Classification,"How do we find all images in a larger set of images which have a specific content? Or estimate the position of a specific object relative to the camera? Image classification methods, like support vector machine (supervised) and transductive support vector machine (semi-supervised), are invaluable tools for the applications of content-based image retrieval, pose estimation, and optical character recognition. However, these methods only can handle the images represented by single feature. In many cases, different features (or multiview data) can be obtained, and how to efficiently utilize them is a challenge. It is inappropriate for the traditionally concatenating schema to link features of different views into a long vector. The reason is each view has its specific statistical property and physical interpretation. In this paper, we propose a high-order distance-based multiview stochastic learning (HD-MSL) method for image classification. HD-MSL effectively combines varied features into a unified representation and integrates the labeling information based on a probabilistic framework. In comparison with the existing strategies, our approach adopts the high-order distance obtained from the hypergraph to replace pairwise distance in estimating the probability matrix of data distribution. In addition, the proposed approach can automatically learn a combination coefficient for each view, which plays an important role in utilizing the complementary information of multiview data. An alternative optimization is designed to solve the objective functions of HD-MSL and obtain different views on coefficients and classification scores simultaneously. Experiments on two real world datasets demonstrate the effectiveness of HD-MSL in image classification.","Linear programming,
Optimization,
Probability distribution,
Labeling,
Vectors,
Manifolds,
Stochastic processes"
Composite Neural Dynamic Surface Control of a Class of Uncertain Nonlinear Systems in Strict-Feedback Form,"This paper studies the composite adaptive tracking control for a class of uncertain nonlinear systems in strict-feedback form. Dynamic surface control technique is incorporated into radial-basis-function neural networks (NNs)-based control framework to eliminate the problem of explosion of complexity. To avoid the analytic computation, the command filter is employed to produce the command signals and their derivatives. Different from directly toward the asymptotic tracking, the accuracy of the identified neural models is taken into consideration. The prediction error between system state and serial-parallel estimation model is combined with compensated tracking error to construct the composite laws for NN weights updating. The uniformly ultimate boundedness stability is established using Lyapunov method. Simulation results are presented to demonstrate that the proposed method achieves smoother parameter adaption, better accuracy, and improved performance.","Artificial neural networks,
Estimation,
Approximation methods,
Predictive models,
Vectors,
Nonlinear systems,
Adaptation models"
Adaptive Consensus Control for a Class of Nonlinear Multiagent Time-Delay Systems Using Neural Networks,"Because of the complexity of consensus control of nonlinear multiagent systems in state time-delay, most of previous works focused only on linear systems with input time-delay. An adaptive neural network (NN) consensus control method for a class of nonlinear multiagent systems with state time-delay is proposed in this paper. The approximation property of radial basis function neural networks (RBFNNs) is used to neutralize the uncertain nonlinear dynamics in agents. An appropriate Lyapunov-Krasovskii functional, which is obtained from the derivative of an appropriate Lyapunov function, is used to compensate the uncertainties of unknown time delays. It is proved that our proposed approach guarantees the convergence on the basis of Lyapunov stability theory. The simulation results of a nonlinear multiagent time-delay system and a multiple collaborative manipulators system show the effectiveness of the proposed consensus control algorithm.",
Robust Text Detection in Natural Scene Images,"Text detection in natural scene images is an important prerequisite for many content-based image analysis tasks. In this paper, we propose an accurate and robust method for detecting texts in natural scene images. A fast and effective pruning algorithm is designed to extract Maximally Stable Extremal Regions (MSERs) as character candidates using the strategy of minimizing regularized variations. Character candidates are grouped into text candidates by the single-link clustering algorithm, where distance weights and clustering threshold are learned automatically by a novel self-training distance metric learning algorithm. The posterior probabilities of text candidates corresponding to non-text are estimated with a character classifier; text candidates with high non-text probabilities are eliminated and texts are identified with a text classifier. The proposed system is evaluated on the ICDAR 2011 Robust Reading Competition database; the f-measure is over 76%, much better than the state-of-the-art performance of 71%. Experiments on multilingual, street view, multi-orientation and even born-digital databases also demonstrate the effectiveness of the proposed method.","Clustering algorithms,
Algorithm design and analysis,
Measurement,
Vegetation,
Robustness,
Databases,
Educational institutions"
A Signal Processing Perspective on Hyperspectral Unmixing: Insights from Remote Sensing,"Blind hyperspectral unmixing (HU), also known as unsupervised HU, is one of the most prominent research topics in signal processing (SP) for hyperspectral remote sensing [1], [2]. Blind HU aims at identifying materials present in a captured scene, as well as their compositions, by using high spectral resolution of hyperspectral images. It is a blind source separation (BSS) problem from a SP viewpoint. Research on this topic started in the 1990s in geoscience and remote sensing [3]-[7], enabled by technological advances in hyperspectral sensing at the time. In recent years, blind HU has attracted much interest from other fields such as SP, machine learning, and optimization, and the subsequent cross-disciplinary research activities have made blind HU a vibrant topic. The resulting impact is not just on remote sensing - blind HU has provided a unique problem scenario that inspired researchers from different fields to devise novel blind SP methods. In fact, one may say that blind HU has established a new branch of BSS approaches not seen in classical BSS studies. In particular, the convex geometry concepts - discovered by early remote sensing researchers through empirical observations [3]-[7] and refined by later research - are elegant and very different from statistical independence-based BSS approaches established in the SP field. Moreover, the latest research on blind HU is rapidly adopting advanced techniques, such as those in sparse SP and optimization. The present development of blind HU seems to be converging to a point where the lines between remote sensing-originated ideas and advanced SP and optimization concepts are no longer clear, and insights from both sides would be used to establish better methods.",
Decomposition of a Multiobjective Optimization Problem Into a Number of Simple Multiobjective Subproblems,"This letter suggests an approach for decomposing a multiobjective optimization problem (MOP) into a set of simple multiobjective optimization subproblems. Using this approach, it proposes MOEA/D-M2M, a new version of multiobjective optimization evolutionary algorithm-based decomposition. This proposed algorithm solves these subproblems in a collaborative way. Each subproblem has its own population and receives computational effort at each generation. In such a way, population diversity can be maintained, which is critical for solving some MOPs. Experimental studies have been conducted to compare MOEA/D-M2M with classic MOEA/D and NSGA-II. This letter argues that population diversity is more important than convergence in multiobjective evolutionary algorithms for dealing with some MOPs. It also explains why MOEA/D-M2M performs better.","Optimization,
Sociology,
Statistics,
Vectors,
Approximation methods,
Approximation algorithms,
Linear programming"
Reliable Multicast with Pipelined Network Coding Using Opportunistic Feeding and Routing,"Multicast is an important mechanism in modern wireless networks and has attracted significant efforts to improve its performance with different metrics including throughput, delay, energy efficiency, etc. Traditionally, an ideal loss-free channel model is widely used to facilitate routing protocol design. However, the quality of wireless links is affected or even jeopardized resulting in transmission failures by many factors like collisions, fading or the noise of environment. In this paper, we propose a reliable multicast protocol, called CodePipe, with energy-efficiency, high throughput and fairness in lossy wireless networks. Building upon opportunistic routing and random linear network coding, CodePipe can not only eliminate coordination between nodes, but also improve the multicast throughput significantly by exploiting both intra-batch and inter-batch coding opportunities. In particular, four key techniques, namely, LP-based opportunistic routing structure, opportunistic feeding, fast batch moving and inter-batch coding, are proposed to offer significant improvement in throughput, energy-efficiency and fairness. Moreover, we design an efficient online extension of CodePipe such that it can work in a dynamic network where nodes join and leave the network as time progresses. We evaluate CodePipe on ns2 simulator by comparing with other two state-of-art multicast protocols, MORE and Pacifier. Simulation results show that CodePipe significantly outperforms both of them.",
The Extraction of Neural Information from the Surface EMG for the Control of Upper-Limb Prostheses: Emerging Avenues and Challenges,"Despite not recording directly from neural cells, the surface electromyogram (EMG) signal contains information on the neural drive to muscles, i.e, the spike trains of motor neurons. Using this property, myoelectric control consists of the recording of EMG signals for extracting control signals to command external devices, such as hand prostheses. In commercial control systems, the intensity of muscle activity is extracted from the EMG and used for single degrees of freedom activation (direct control). Over the past 60 years, academic research has progressed to more sophisticated approaches but, surprisingly, none of these academic achievements has been implemented in commercial systems so far. We provide an overview of both commercial and academic myoelectric control systems and we analyze their performance with respect to the characteristics of the ideal myocontroller. Classic and relatively novel academic methods are described, including techniques for simultaneous and proportional control of multiple degrees of freedom and the use of individual motor neuron spike trains for direct control. The conclusion is that the gap between industry and academia is due to the relatively small functional improvement in daily situations that academic systems offer, despite the promising laboratory results, at the expense of a substantial reduction in robustness. None of the systems so far proposed in the literature fulfills all the important criteria needed for widespread acceptance by the patients, i.e. intuitive, closed-loop, adaptive, and robust real-time (<;200 ms delay) control, minimal number of recording electrodes with low sensitivity to repositioning, minimal training, limited complexity and low consumption. Nonetheless, in recent years, important efforts have been invested in matching these criteria, with relevant steps forwards.",
3-D Object Retrieval With Hausdorff Distance Learning,"In view-based 3-D object retrieval, each object is described by a set of views. Group matching thus plays an important role. Previous research efforts have shown the effectiveness of Hausdorff distance in group matching. In this paper, we propose a 3-D object retrieval scheme with Hausdorff distance learning. In our approach, relevance feedback information is employed to select positive and negative view pairs with a probabilistic strategy, and a view-level Mahalanobis distance metric is learned. This Mahalanobis distance metric is adopted in estimating the Hausdorff distances between objects, based on which the objects in the 3-D database are ranked. We conduct experiments on three testing data sets, and the results demonstrate that the proposed Hausdorff learning approach can improve 3-D object retrieval performance.","visual databases,
image matching,
image retrieval,
learning (artificial intelligence),
relevance feedback"
Base-Station Assisted Device-to-Device Communications for High-Throughput Wireless Video Networks,"We propose a new scheme for increasing the throughput of video files in cellular communications systems. This scheme exploits (1) the redundancy of user requests as well as (2) the considerable storage capacity of smartphones and tablets. Users cache popular video files and-after receiving requests from other users-serve these requests via device-to-device localized transmissions. The file placement is optimal when a central control knows a priori the locations of wireless devices when file requests occur. However, even a purely random caching scheme shows only a minor performance loss compared to such a “genie-aided” scheme. We then analyze the optimal collaboration distance, trading off frequency reuse with the probability of finding a requested file within the collaboration distance. We show that an improvement of spectral efficiency of one to two orders of magnitude is possible, even if there is not very high redundancy in video requests.","Wireless communication,
Interference,
Throughput,
Collaboration,
Computer architecture,
Base stations,
Delays"
Group-Based Sparse Representation for Image Restoration,"Traditional patch-based sparse representation modeling of natural images usually suffer from two problems. First, it has to solve a large-scale optimization problem with high computational complexity in dictionary learning. Second, each patch is considered independently in dictionary learning and sparse coding, which ignores the relationship among patches, resulting in inaccurate sparse coding coefficients. In this paper, instead of using patch as the basic unit of sparse representation, we exploit the concept of group as the basic unit of sparse representation, which is composed of nonlocal patches with similar structures, and establish a novel sparse representation modeling of natural images, called group-based sparse representation (GSR). The proposed GSR is able to sparsely represent natural images in the domain of group, which enforces the intrinsic local sparsity and nonlocal self-similarity of images simultaneously in a unified framework. In addition, an effective self-adaptive dictionary learning method for each group with low complexity is designed, rather than dictionary learning from natural images. To make GSR tractable and robust, a split Bregman-based technique is developed to solve the proposed GSR-driven ℓ0 minimization problem for image restoration efficiently. Extensive experiments on image inpainting, image deblurring and image compressive sensing recovery manifest that the proposed GSR modeling outperforms many current state-of-the-art schemes in both peak signal-to-noise ratio and visual perception.","Dictionaries,
Image restoration,
Vectors,
Minimization,
Image coding,
Adaptation models,
Materials"
"LCL
Filter Design and Performance Analysis for Grid-Interconnected Systems","The use of power converters is very important in maximizing the power transfer from renewable energy sources such as wind, solar, or even a hydrogen-based fuel cell to the utility grid. An LCL filter is often used to interconnect an inverter to the utility grid in order to filter the harmonics produced by the inverter. Although there is an extensive amount of literature available describing LCL filters, there has been a gap in providing a systematic design methodology. Furthermore, there has been a lack of a state-space mathematical modeling approach that considers practical cases of delta- and wye-connected capacitors showing their effects on possible grounding alternatives. This paper describes a design methodology of an LCL filter for grid-interconnected inverters along with a comprehensive study of how to mitigate harmonics. The procedures and techniques described in this paper may be used in small-scale renewable energy conversion systems and may be also retrofitted for medium- and large-scale grid-connected systems.","Power harmonic filters,
Inverters,
Capacitors,
Active filters,
Mathematical model,
Inductors,
Harmonic analysis"
Radio propagation path loss models for 5G cellular networks in the 28 GHZ and 38 GHZ millimeter-wave bands,"This article presents empirically-based large-scale propagation path loss models for fifth-generation cellular network planning in the millimeter-wave spectrum, based on real-world measurements at 28 GHz and 38 GHz in New York City and Austin, Texas, respectively. We consider industry-standard path loss models used for today's microwave bands, and modify them to fit the propagation data measured in these millimeter-wave bands for cellular planning. Network simulations with the proposed models using a commercial planning tool show that roughly three times more base stations are required to accommodate 5G networks (cell radii up to 200 m) compared to existing 3G and 4G systems (cell radii of 500 m to 1 km) when performing path loss simulations based on arbitrary pointing angles of directional antennas. However, when directional antennas are pointed in the single best directions at the base station and mobile, coverage range is substantially improved with little increase in interference, thereby reducing the required number of 5G base stations. Capacity gains for random pointing angles are shown to be 20 times greater than today's fourth-generation Long Term Evolution networks, and can be further improved when using directional antennas pointed in the strongest transmit and receive directions with the help of beam combining techniques.","Antenna measurements,
Loss measurement,
Millimeter wave communication,
Propagation losses,
Directive antennas,
Radio propagation"
Deadline Based Resource Provisioningand Scheduling Algorithm for Scientific Workflows on Clouds,"Cloud computing is the latest distributed computing paradigm and it offers tremendous opportunities to solve large-scale scientific problems. However, it presents various challenges that need to be addressed in order to be efficiently utilized for workflow applications. Although the workflow scheduling problem has been widely studied, there are very few initiatives tailored for cloud environments. Furthermore, the existing works fail to either meet the user's quality of service (QoS) requirements or to incorporate some basic principles of cloud computing such as the elasticity and heterogeneity of the computing resources. This paper proposes a resource provisioning and scheduling strategy for scientific workflows on Infrastructure as a Service (IaaS) clouds. We present an algorithm based on the meta-heuristic optimization technique, particle swarm optimization (PSO), which aims to minimize the overall workflow execution cost while meeting deadline constraints. Our heuristic is evaluated using CloudSim and various well-known scientific workflows of different sizes. The results show that our approach performs better than the current state-of-the-art algorithms.","Quality of service,
Cloud computing,
Processor scheduling,
Computational modeling,
Distributed processing,
Computer applications,
Mathematical model"
3-D Mapping With an RGB-D Camera,"In this paper, we present a novel mapping system that robustly generates highly accurate 3-D maps using an RGB-D camera. Our approach requires no further sensors or odometry. With the availability of low-cost and light-weight RGB-D sensors such as the Microsoft Kinect, our approach applies to small domestic robots such as vacuum cleaners, as well as flying robots such as quadrocopters. Furthermore, our system can also be used for free-hand reconstruction of detailed 3-D models. In addition to the system itself, we present a thorough experimental evaluation on a publicly available benchmark dataset. We analyze and discuss the influence of several parameters such as the choice of the feature descriptor, the number of visual features, and validation methods. The results of the experiments demonstrate that our system can robustly deal with challenging scenarios such as fast camera motions and feature-poor environments while being fast enough for online operation. Our system is fully available as open source and has already been widely adopted by the robotics community.","Cameras,
Simultaneous localization and mapping,
Visualization,
Robot vision systems,
Estimation"
A Statistical Prediction Model Based on Sparse Representations for Single Image Super-Resolution,"We address single image super-resolution using a statistical prediction model based on sparse representations of low- and high-resolution image patches. The suggested model allows us to avoid any invariance assumption, which is a common practice in sparsity-based approaches treating this task. Prediction of high resolution patches is obtained via MMSE estimation and the resulting scheme has the useful interpretation of a feedforward neural network. To further enhance performance, we suggest data clustering and cascading several levels of the basic algorithm. We suggest a training scheme for the resulting network and demonstrate the capabilities of our algorithm, showing its advantages over existing methods based on a low- and high-resolution dictionary pair, in terms of computational complexity, numerical criteria, and visual appearance. The suggested approach offers a desirable compromise between low computational complexity and reconstruction quality, when comparing it with state-of-the-art methods for single image super-resolution.","Dictionaries,
Predictive models,
Image reconstruction,
Vectors,
Image resolution,
Feedforward neural networks,
Prediction algorithms"
VSI: A Visual Saliency-Induced Index for Perceptual Image Quality Assessment,"Perceptual image quality assessment (IQA) aims to use computational models to measure the image quality in consistent with subjective evaluations. Visual saliency (VS) has been widely studied by psychologists, neurobiologists, and computer scientists during the last decade to investigate, which areas of an image will attract the most attention of the human visual system. Intuitively, VS is closely related to IQA in that suprathreshold distortions can largely affect VS maps of images. With this consideration, we propose a simple but very effective full reference IQA method using VS. In our proposed IQA model, the role of VS is twofold. First, VS is used as a feature when computing the local quality map of the distorted image. Second, when pooling the quality score, VS is employed as a weighting function to reflect the importance of a local region. The proposed IQA index is called visual saliency-based index (VSI). Several prominent computational VS models have been investigated in the context of IQA and the best one is chosen for VSI. Extensive experiments performed on four largescale benchmark databases demonstrate that the proposed IQA index VSI works better in terms of the prediction accuracy than all state-of-the-art IQA indices we can find while maintaining a moderate computational complexity. The MATLAB source code of VSI and the evaluation results are publicly available online at http://sse.tongji.edu.cn/linzhang/IQA/VSI/VSI.htm.",
3D Object Recognition in Cluttered Scenes with Local Surface Features: A Survey,"3D object recognition in cluttered scenes is a rapidly growing research area. Based on the used types of features, 3D object recognition methods can broadly be divided into two categories-global or local feature based methods. Intensive research has been done on local surface feature based methods as they are more robust to occlusion and clutter which are frequently present in a real-world scene. This paper presents a comprehensive survey of existing local surface feature based 3D object recognition methods. These methods generally comprise three phases: 3D keypoint detection, local surface feature description, and surface matching. This paper covers an extensive literature survey of each phase of the process. It also enlists a number of popular and contemporary databases together with their relevant attributes.","Three-dimensional displays,
Object recognition,
Feature extraction,
Shape,
Databases,
Smoothing methods,
Robustness"
Time Synchronization in WSNs: A Maximum-Value-Based Consensus Approach,"This paper considers time synchronization in wireless sensor networks. When the communication delay is negligible, the maximum time synchronization (MTS) protocol is proposed by which the skew and offset of each node can be synchronized simultaneously. For a more practical case where the intercommunication delays between each connected node are positive random variables, we propose the weighted maximum time synchronization (WMTS), which is able to counteract the impact of random communication delays. Despite the clock offset that cannot be synchronized, WMTS can synchronize the clock skew completely in expectation and achieve acceptable synchronization accuracy. For both protocols, we provide rigorous proofs of global convergence as well as the upper bounds of their convergence time. Compared with existing consensus-based synchronization protocols, the main advantages of our protocols include: 1) a faster convergence speed so that the synchronization can be achieved in a finite time for MTS, and in a finite time in expectation for WMTS, respectively; 2) simultaneous synchronization of both skews and offsets; and 3) random communication delays can be handled effectively. Numerical examples are presented to demonstrate the effectiveness of the proposed protocols.","Synchronization,
Clocks,
Delays,
Protocols,
Hardware,
Wireless sensor networks,
Convergence"
Sparse Beamforming and User-Centric Clustering for Downlink Cloud Radio Access Network,"This paper considers a downlink cloud radio access network (C-RAN) in which all the base-stations (BSs) are connected to a central computing cloud via digital backhaul links with finite capacities. Each user is associated with a user-centric cluster of BSs; the central processor shares the user's data with the BSs in the cluster, which then cooperatively serve the user through joint beamforming. Under this setup, this paper investigates the user scheduling, BS clustering, and beamforming design problem from a network utility maximization perspective. Differing from previous works, this paper explicitly considers the per-BS backhaul capacity constraints. We formulate the network utility maximization problem for the downlink C-RAN under two different models depending on whether the BS clustering for each user is dynamic or static over different user scheduling time slots. In the former case, the user-centric BS cluster is dynamically optimized for each scheduled user along with the beamforming vector in each time-frequency slot, whereas in the latter case, the user-centric BS cluster is fixed for each user and we jointly optimize the user scheduling and the beamforming vector to account for the backhaul constraints. In both cases, the nonconvex per-BS backhaul constraints are approximated using the reweighted ℓ1-norm technique. This approximation allows us to reformulate the per-BS backhaul constraints into weighted per-BS power constraints and solve the weighted sum rate maximization problem through a generalized weighted minimum mean square error approach. This paper shows that the proposed dynamic clustering algorithm can achieve significant performance gain over existing naive clustering schemes. This paper also proposes two heuristic static clustering schemes that can already achieve a substantial portion of the gain.",
Neighborhood Repulsed Metric Learning for Kinship Verification,"Kinship verification from facial images is an interesting and challenging problem in computer vision, and there are very limited attempts on tackle this problem in the literature. In this paper, we propose a new neighborhood repulsed metric learning (NRML) method for kinship verification. Motivated by the fact that interclass samples (without a kinship relation) with higher similarity usually lie in a neighborhood and are more easily misclassified than those with lower similarity, we aim to learn a distance metric under which the intraclass samples (with a kinship relation) are pulled as close as possible and interclass samples lying in a neighborhood are repulsed and pushed away as far as possible, simultaneously, such that more discriminative information can be exploited for verification. To make better use of multiple feature descriptors to extract complementary information, we further propose a multiview NRML (MNRML) method to seek a common distance metric to perform multiple feature fusion to improve the kinship verification performance. Experimental results are presented to demonstrate the efficacy of our proposed methods. Finally, we also test human ability in kinship verification from facial images and our experimental results show that our methods are comparable to that of human observers.","Measurement,
Face,
Feature extraction,
Learning systems,
Databases,
Educational institutions,
Training"
Robust Adaptive Dynamic Programming and Feedback Stabilization of Nonlinear Systems,"This paper studies the robust optimal control design for a class of uncertain nonlinear systems from a perspective of robust adaptive dynamic programming (RADP). The objective is to fill up a gap in the past literature of adaptive dynamic programming (ADP) where dynamic uncertainties or unmodeled dynamics are not addressed. A key strategy is to integrate tools from modern nonlinear control theory, such as the robust redesign and the backstepping techniques as well as the nonlinear small-gain theorem, with the theory of ADP. The proposed RADP methodology can be viewed as an extension of ADP to uncertain nonlinear systems. Practical learning algorithms are developed in this paper, and have been applied to the controller design problems for a jet engine and a one-machine power system.","Optimal control,
Uncertainty,
Approximation methods,
Robustness,
Nonlinear systems,
Closed loop systems,
Dynamic programming"
Real Interference Alignment: Exploiting the Potential of Single Antenna Systems,"In this paper, we develop the machinery of real interference alignment. This machinery is extremely powerful in achieving the sum degrees of freedom (DoF) of single antenna systems. The scheme of real interference alignment is based on designing single-layer and multilayer constellations used for modulating information messages at the transmitters. We show that constellations can be aligned in a similar fashion as that of vectors in multiple antenna systems and space can be broken up into fractional dimensions. The performance analysis of the signaling scheme makes use of a recent result in the field of Diophantine approximation, which states that the convergence part of the Khintchine-Groshev theorem holds for points on nondegenerate manifolds. Using real interference alignment, we obtain the sum DoF of two model channels, namely the Gaussian interference channel (IC) and the X channel. It is proved that the sum DoF of the K-user IC is (K/2) for almost all channel parameters. We also prove that the sum DoF of the X-channel with K transmitters and M receivers is (K M/K + M - 1) for almost all channel parameters.",
Learning Discriminant Face Descriptor,"Local feature descriptor is an important module for face recognition and those like Gabor and local binary patterns (LBP) have proven effective face descriptors. Traditionally, the form of such local descriptors is predefined in a handcrafted way. In this paper, we propose a method to learn a discriminant face descriptor (DFD) in a data-driven way. The idea is to learn the most discriminant local features that minimize the difference of the features between images of the same person and maximize that between images from different people. In particular, we propose to enhance the discriminative ability of face representation in three aspects. First, the discriminant image filters are learned. Second, the optimal neighborhood sampling strategy is soft determined. Third, the dominant patterns are statistically constructed. Discriminative learning is incorporated to extract effective and robust features. We further apply the proposed method to the heterogeneous (cross-modality) face recognition problem and learn DFD in a coupled way (coupled DFD or C-DFD) to reduce the gap between features of heterogeneous face images to improve the performance of this challenging problem. Extensive experiments on FERET, CAS-PEAL-R1, LFW, and HFB face databases validate the effectiveness of the proposed DFD learning on both homogeneous and heterogeneous face recognition problems. The DFD improves POEM and LQP by about 4.5 percent on LFW database and the C-DFD enhances the heterogeneous face recognition performance of LBP by over 25 percent.","Face,
Feature extraction,
Face recognition,
Vectors,
Principal component analysis,
Gabor filters,
Robustness"
From Heuristic Optimization to Dictionary Learning: A Review and Comprehensive Comparison of Image Denoising Algorithms,"Image denoising is a well explored topic in the field of image processing. In the past several decades, the progress made in image denoising has benefited from the improved modeling of natural images. In this paper, we introduce a new taxonomy based on image representations for a better understanding of state-of-the-art image denoising techniques. Within each category, several representative algorithms are selected for evaluation and comparison. The experimental results are discussed and analyzed to determine the overall advantages and disadvantages of each category. In general, the nonlocal methods within each category produce better denoising results than local ones. In addition, methods based on overcomplete representations using learned dictionaries perform better than others. The comprehensive study in this paper would serve as a good reference and stimulate new research ideas in image denoising.",
A New Consensus Model for Group Decision Making Problems With Non-Homogeneous Experts,"In the literature, we find that the consensus models proposed for group decision making problems are guided by consensus degrees and/or similarity measures and/or consistency measures . When we work in heterogeneous group decision making frameworks, we have importance degrees associated with the experts by expressing their different knowledge levels on the problem. Usually, the importance degrees are applied in the weighted aggregation operators developed to solve the decision situations. In this paper, we study another application possibility, i.e., to use heterogeneity existing among experts to guide the consensus model. Thus, the main goal of this paper is to present a new consensus model for heterogeneous group decision making problems guided also by the heterogeneity criterion. It is also based on consensus degrees and similarity measures, but it presents a new feedback mechanism that adjusts the amount of advice required by each expert depending on his/her own relevance or importance level.","decision making,
feedback,
group theory,
mathematical operators"
Power Scaling of Uplink Massive MIMO Systems With Arbitrary-Rank Channel Means,"This paper investigates the uplink achievable rates of massive multiple-input multiple-output (MIMO) antenna systems in Ricean fading channels, using maximal-ratio combining (MRC) and zero-forcing (ZF) receivers, assuming perfect and imperfect channel state information (CSI). In contrast to previous relevant works, the fast fading MIMO channel matrix is assumed to have an arbitrary-rank deterministic component as well as a Rayleigh-distributed random component. We derive tractable expressions for the achievable uplink rate in the large-antenna limit, along with approximating results that hold for any finite number of antennas. Based on these analytical results, we obtain the scaling law that the users' transmit power should satisfy, while maintaining a desirable quality of service. In particular, it is found that regardless of the Ricean K-factor, in the case of perfect CSI, the approximations converge to the same constant value as the exact results, as the number of base station antennas, M, grows large, while the transmit power of each user can be scaled down proportionally to 1/M. If CSI is estimated with uncertainty, the same result holds true but only when the Ricean K-factor is non-zero. Otherwise, if the channel experiences Rayleigh fading, we can only cut the transmit power of each user proportionally to 1/√M. In addition, we show that with an increasing Ricean K-factor, the uplink rates will converge to fixed values for both MRC and ZF receivers.",
Spatio-Temporal Laplacian Pyramid Coding for Action Recognition,"We present a novel descriptor, called spatio-temporal Laplacian pyramid coding (STLPC), for holistic representation of human actions. In contrast to sparse representations based on detected local interest points, STLPC regards a video sequence as a whole with spatio-temporal features directly extracted from it, which prevents the loss of information in sparse representations. Through decomposing each sequence into a set of band-pass-filtered components, the proposed pyramid model localizes features residing at different scales, and therefore is able to effectively encode the motion information of actions. To make features further invariant and resistant to distortions as well as noise, a bank of 3-D Gabor filters is applied to each level of the Laplacian pyramid, followed by max pooling within filter bands and over spatio-temporal neighborhoods. Since the convolving and pooling are performed spatio-temporally, the coding model can capture structural and motion information simultaneously and provide an informative representation of actions. The proposed method achieves superb recognition rates on the KTH, the multiview IXMAS, the challenging UCF Sports, and the newly released HMDB51 datasets. It outperforms state of the art methods showing its great potential on action recognition.",
Feature Learning for Image Classification Via Multiobjective Genetic Programming,"Feature extraction is the first and most critical step in image classification. Most existing image classification methods use hand-crafted features, which are not adaptive for different image domains. In this paper, we develop an evolutionary learning methodology to automatically generate domain-adaptive global feature descriptors for image classification using multiobjective genetic programming (MOGP). In our architecture, a set of primitive 2-D operators are randomly combined to construct feature descriptors through the MOGP evolving and then evaluated by two objective fitness criteria, i.e., the classification error and the tree complexity. After the entire evolution procedure finishes, the best-so-far solution selected by the MOGP is regarded as the (near-)optimal feature descriptor obtained. To evaluate its performance, the proposed approach is systematically tested on the Caltech-101, the MIT urban and nature scene, the CMU PIE, and Jochen Triesch Static Hand Posture II data sets, respectively. Experimental results verify that our method significantly outperforms many state-of-the-art hand-designed features and two feature learning techniques in terms of classification accuracy.","Feature extraction,
Data mining,
Genetic programming,
Sociology,
Statistics,
Learning systems,
Computer architecture"
Labeled Random Finite Sets and the Bayes Multi-Target Tracking Filter,"An analytic solution to the multi-target Bayes recursion known as the δ-Generalized Labeled Multi-Bernoulli ( δ-GLMB) filter has been recently proposed by Vo and Vo in [“Labeled Random Finite Sets and Multi-Object Conjugate Priors,” IEEE Trans. Signal Process., vol. 61, no. 13, pp. 3460-3475, 2014]. As a sequel to that paper, the present paper details efficient implementations of the δ-GLMB multi-target tracking filter. Each iteration of this filter involves an update operation and a prediction operation, both of which result in weighted sums of multi-target exponentials with intractably large number of terms. To truncate these sums, the ranked assignment and K-th shortest path algorithms are used in the update and prediction, respectively, to determine the most significant terms without exhaustively computing all of the terms. In addition, using tools derived from the same framework, such as probability hypothesis density filtering, we present inexpensive (relative to the δ-GLMB filter) look-ahead strategies to reduce the number of computations. Characterization of the L1-error in the multi-target density arising from the truncation is presented.",
A Survey of Clustering Algorithms for Big Data: Taxonomy and Empirical Analysis,"Clustering algorithms have emerged as an alternative powerful meta-learning tool to accurately analyze the massive volume of data generated by modern applications. In particular, their main goal is to categorize data into clusters such that objects are grouped in the same cluster when they are similar according to specific metrics. There is a vast body of knowledge in the area of clustering and there has been attempts to analyze and categorize them for a larger number of applications. However, one of the major issues in using clustering algorithms for big data that causes confusion amongst practitioners is the lack of consensus in the definition of their properties as well as a lack of formal categorization. With the intention of alleviating these problems, this paper introduces concepts and algorithms related to clustering, a concise survey of existing (clustering) algorithms as well as providing a comparison, both from a theoretical and an empirical perspective. From a theoretical perspective, we developed a categorizing framework based on the main properties pointed out in previous studies. Empirically, we conducted extensive experiments where we compared the most representative algorithm from each of the categories using a large number of real (big) data sets. The effectiveness of the candidate clustering algorithms is measured through a number of internal and external validity metrics, stability, runtime, and scalability tests. In addition, we highlighted the set of clustering algorithms that are the best performing for big data.","Clustering algorithms,
Algorithm design and analysis,
Partitioning algorithms,
Big data,
Clustering methods,
Neural networks,
Taxonomies"
Representative Discovery of Structure Cues for Weakly-Supervised Image Segmentation,"Weakly-supervised image segmentation is a challenging problem with multidisciplinary applications in multimedia content analysis and beyond. It aims to segment an image by leveraging its image-level semantics (i.e., tags). This paper presents a weakly-supervised image segmentation algorithm that learns the distribution of spatially structural superpixel sets from image-level labels. More specifically, we first extract graphlets from a given image, which are small-sized graphs consisting of superpixels and encapsulating their spatial structure. Then, an efficient manifold embedding algorithm is proposed to transfer labels from training images into graphlets. It is further observed that there are numerous redundant graphlets that are not discriminative to semantic categories, which are abandoned by a graphlet selection scheme as they make no contribution to the subsequent segmentation. Thereafter, we use a Gaussian mixture model (GMM) to learn the distribution of the selected post-embedding graphlets (i.e., vectors output from the graphlet embedding). Finally, we propose an image segmentation algorithm, termed representative graphlet cut, which leverages the learned GMM prior to measure the structure homogeneity of a test image. Experimental results show that the proposed approach outperforms state-of-the-art weakly-supervised image segmentation methods, on five popular segmentation data sets. Besides, our approach performs competitively to the fully-supervised segmentation models.",
Mobility and Intruder Prior Information Improving the Barrier Coverage of Sparse Sensor Networks,"The barrier coverage problem in emerging mobile sensor networks has been an interesting research issue due to many related real-life applications. Existing solutions are mainly concerned with deciding one-time movement for individual sensors to construct as many barriers as possible, which may not be suitable when there are no sufficient sensors to form a single barrier. In this paper, we aim to achieve barrier coverage in the sensor scarcity scenario by dynamic sensor patrolling. Specifically, we design a periodic monitoring scheduling (PMS) algorithm in which each point along the barrier line is monitored periodically by mobile sensors. Based on the insight from PMS, we then propose a coordinated sensor patrolling (CSP) algorithm to further improve the barrier coverage, where each sensor's current movement strategy is derived from the information of intruder arrivals in the past. By jointly exploiting sensor mobility and intruder arrival information, CSP is able to significantly enhance barrier coverage. We prove that the total distance that sensors move during each time slot in CSP is the minimum. Considering the decentralized nature of mobile sensor networks, we further introduce two distributed versions of CSP: S-DCSP and G-DCSP. We study the scenario where sensors are moving on two barriers and propose two heuristic algorithms to guide the movement of sensors. Finally, we generalize our results to work for different intruder arrival models. Through extensive simulations, we demonstrate that the proposed algorithms have desired barrier coverage performances.","Monitoring,
Robot sensing systems,
Mobile communication,
Mobile computing,
Scheduling,
Algorithm design and analysis,
Heuristic algorithms"
Topological Interference Management Through Index Coding,"This paper studies linear interference networks, both wired and wireless, with no channel state information at the transmitters except a coarse knowledge of the end-to-end one-hop topology of the network that only allows a distinction between weak (zero) and significant (nonzero) channels and no further knowledge of the channel coefficients' realizations. The network capacity (wired) and degrees of freedom (DoF) (wireless) are found to be bounded above by the capacity of an index coding problem for which the antidote graph is the complement of the given interference graph. The problems are shown to be equivalent under linear solutions. An interference alignment perspective is then used to translate the existing index coding solutions into the wired network capacity and wireless network DoF solutions, as well as to find new and unified solutions to different classes of all three problems.","Interference,
Network topology,
Topology,
Wireless networks,
Network coding,
Transmitters"
Secure Deduplication with Efficient and Reliable Convergent Key Management,"Data deduplication is a technique for eliminating duplicate copies of data, and has been widely used in cloud storage to reduce storage space and upload bandwidth. Promising as it is, an arising challenge is to perform secure deduplication in cloud storage. Although convergent encryption has been extensively adopted for secure deduplication, a critical issue of making convergent encryption practical is to efficiently and reliably manage a huge number of convergent keys. This paper makes the first attempt to formally address the problem of achieving efficient and reliable key management in secure deduplication. We first introduce a baseline approach in which each user holds an independent master key for encrypting the convergent keys and outsourcing them to the cloud. However, such a baseline key management scheme generates an enormous number of keys with the increasing number of users and requires users to dedicatedly protect the master keys. To this end, we propose Dekey , a new construction in which users do not need to manage any keys on their own but instead securely distribute the convergent key shares across multiple servers. Security analysis demonstrates that Dekey is secure in terms of the definitions specified in the proposed security model. As a proof of concept, we implement Dekey using the Ramp secret sharing scheme and demonstrate that Dekey incurs limited overhead in realistic environments.","Encryption,
Reliability,
Servers,
Data deduplication"
Semantic Link Network-Based Model for Organizing Multimedia Big Data,"Recent research shows that multimedia resources in the wild are growing at a staggering rate. The rapid increase number of multimedia resources has brought an urgent need to develop intelligent methods to organize and process them. In this paper, the semantic link network model is used for organizing multimedia resources. A whole model for generating the association relation between multimedia resources using semantic link network model is proposed. The definitions, modules, and mechanisms of the semantic link network are used in the proposed method. The integration between the semantic link network and multimedia resources provides a new prospect for organizing them with their semantics. The tags and the surrounding texts of multimedia resources are used to measure their semantic association. The hierarchical semantic of multimedia resources is defined by their annotated tags and surrounding texts. The semantics of tags and surrounding texts are different in the proposed framework. The modules of semantic link network model are implemented to measure association relations. A real data set including 100 thousand images with social tags from Flickr is used in our experiments. Two evaluation methods, including clustering and retrieval, are performed, which shows the proposed method can measure the semantic relatedness between Flickr images accurately and robustly.",
"A benchmark for RGB-D visual odometry, 3D reconstruction and SLAM","We introduce the Imperial College London and National University of Ireland Maynooth (ICL-NUIM) dataset for the evaluation of visual odometry, 3D reconstruction and SLAM algorithms that typically use RGB-D data. We present a collection of handheld RGB-D camera sequences within synthetically generated environments. RGB-D sequences with perfect ground truth poses are provided as well as a ground truth surface model that enables a method of quantitatively evaluating the final map or surface reconstruction accuracy. Care has been taken to simulate typically observed real-world artefacts in the synthetic imagery by modelling sensor noise in both RGB and depth data. While this dataset is useful for the evaluation of visual odometry and SLAM trajectory estimation, our main focus is on providing a method to benchmark the surface reconstruction accuracy which to date has been missing in the RGB-D community despite the plethora of ground truth RGB-D datasets available.","Trajectory,
Noise,
Cameras,
Image reconstruction,
Iterative closest point algorithm,
Three-dimensional displays,
Surface reconstruction"
Modeling of Mutual Coupling Between Planar Inductors in Wireless Power Applications,"This paper presents a compact model of mutual inductance between two planar inductors, which is essential to design and optimize a wireless power transmission system. The tracks of the planar inductors are modeled as constant current carrying filaments, and the mutual inductance between individual filaments is determined by Neumann's integral. The proposed model is derived by solving Neumann's integral using a series expansion technique. This model can predict the mutual inductance at various axial and lateral displacements. Mutual coupling between planar inductors is computed by a 3-D electromagnetic (EM) solver, and the proposed model shows good agreement with these numerical results. Different types of planar inductors were fabricated on a printed circuit board (PCB) or silicon wafer. Using these inductors, wireless power links were constructed for applications like implantable biomedical devices and contactless battery charging systems. Mutual inductance was measured for each of the cases, and the comparison shows that the proposed model can predict mutual coupling suitably.","Coils,
Wireless communication,
Inductors,
Mathematical model,
Inductance,
Predictive models,
Solid modeling"
Coordination for Linear Multiagent Systems With Dynamic Interaction Topology in the Leader-Following Framework,"This paper considers mainly the leader-following consensus for multiple agents with general linear system dynamics under switching topologies. Three different settings are systematically considered. We first consider the setting that the underlying interaction topologies switch arbitrarily among the possible weakly connected digraphs and then extend it to a more general setting that the weak connectivity of the interaction topologies is kept for some disconnected time intervals with short length due to the communication constraints among agents. Exponentially, consensus control is proved to be achieved, and the convergence rate can be specified as well for both settings in spite of the relaxed conditions on the system dynamics of each individual agent which even allow that each agent has exponentially unstable mode, while for the last case where the weak connectivity is only maintained on the joint of the interaction topologies, consensus control is proved to be achieved when the system matrix of each individual agent satisfies certain stability conditions.",
Segmentation of Moving Objects by Long Term Video Analysis,"Motion is a strong cue for unsupervised object-level grouping. In this paper, we demonstrate that motion will be exploited most effectively, if it is regarded over larger time windows. Opposed to classical two-frame optical flow, point trajectories that span hundreds of frames are less susceptible to short-term variations that hinder separating different objects. As a positive side effect, the resulting groupings are temporally consistent over a whole video shot, a property that requires tedious post-processing in the vast majority of existing approaches. We suggest working with a paradigm that starts with semi-dense motion cues first and that fills up textureless areas afterwards based on color. This paper also contributes the Freiburg-Berkeley motion segmentation (FBMS) dataset, a large, heterogeneous benchmark with 59 sequences and pixel-accurate ground truth annotation of moving objects.",
Neural Network-Based Motion Control of an Underactuated Wheeled Inverted Pendulum Model,"In this paper, automatic motion control is investigated for wheeled inverted pendulum (WIP) models, which have been widely applied for modeling of a large range of two wheeled modern vehicles. First, the underactuated WIP model is decomposed into a fully actuated second-order subsystem Σa consisting of planar movement of vehicle forward motion and yaw angular motions, and a passive (nonactuated) first-order subsystem Σb of pendulum tilt motion. Due to the unknown dynamics of subsystem Σa and universal approximation ability of neural network (NN), an adaptive NN scheme has been employed for motion control of subsystem Σa. Model reference approach has been used, whereas the reference model is optimized by finite time linear quadratic regulation technique. Inspired by human control strategy of inverted pendulum, the tilt angular motion in the passive subsystem Σb has been indirectly controlled using the dynamic coupling with planar forward motion of subsystem Σa, such that the satisfactory tracking of set tilt angle can be guaranteed. Rigorous theoretic analysis has been established, and simulation studies have been performed to demonstrate the developed method.",
A Fast HEVC Inter CU Selection Method Based on Pyramid Motion Divergence,"The newly developed HEVC video coding standard can achieve higher compression performance than the previous video coding standards, such as MPEG-4, H.263 and H.264/AVC. However, HEVC's high computational complexity raises concerns about the computational burden on real-time application. In this paper, a fast pyramid motion divergence (PMD) based CU selection algorithm is presented for HEVC inter prediction. The PMD features are calculated with estimated optical flow of the downsampled frames. Theoretical analysis shows that PMD can be used to help selecting CU size. A k nearest neighboring like method is used to determine the CU splittings. Experimental results show that the fast inter prediction method speeds up the inter coding significantly with negligible loss of the peak signal-to-noise ratio.",
The Effect of Dielectric Capping on Few-Layer Phosphorene Transistors: Tuning the Schottky Barrier Heights,"Phosphorene is a unique single elemental semiconductor with two-dimensional layered structures. In this letter, we study the transistor behavior on mechanically exfoliated few-layer phosphorene with the top-gate. We achieve a high ON-current of 144 mA/mm and hole mobility of 95.6 cm2/V·s. We deposit Al2O3 by atomic layer deposition (ALD) and study the effects of dielectric capping. We observe that the polarity of the transistors alternated from p-type to ambipolar with Al2O3 grown on the top. We attribute this transition to the changes for the effective Schottky barrier heights for both electrons and holes at the metal contact edges, which is originated from fixed charges in the ALD dielectric.","Transistors,
Dielectrics,
Logic gates,
Aluminum oxide,
Schottky barriers,
Charge carrier processes"
Joint Embedding Learning and Sparse Regression: A Framework for Unsupervised Feature Selection,"Feature selection has aroused considerable research interests during the last few decades. Traditional learning-based feature selection methods separate embedding learning and feature ranking. In this paper, we propose a novel unsupervised feature selection framework, termed as the joint embedding learning and sparse regression (JELSR), in which the embedding learning and sparse regression are jointly performed. Specifically, the proposed JELSR joins embedding learning with sparse regression to perform feature selection. To show the effectiveness of the proposed framework, we also provide a method using the weight via local linear approximation and adding the ℓ2,1-norm regularization, and design an effective algorithm to solve the corresponding optimization problem. Furthermore, we also conduct some insightful discussion on the proposed feature selection approach, including the convergence analysis, computational complexity, and parameter determination. In all, the proposed framework not only provides a new perspective to view traditional methods but also evokes some other deep researches for feature selection. Compared with traditional unsupervised feature selection methods, our approach could integrate the merits of embedding learning and sparse regression. Promising experimental results on different kinds of data sets, including image, voice data and biological data, have validated the effectiveness of our proposed algorithm.",
Securing the Internet of Things: A Standardization Perspective,"The Internet of Things (IoT) is the next wave of innovation that promises to improve and optimize our daily life based on intelligent sensors and smart objects working together. Through Internet Protocol (IP) connectivity, devices can now be connected to the Internet, thus allowing them to be read, controlled, and managed at any time and at any place. Security is an important aspect for IoT deployments. However, proprietary security solutions do not help in formulating a coherent security vision to enable IoT devices to securely communicate with each other in an interoperable manner. This paper gives an overview of the efforts in the Internet Engineering Task Force (IETF) to standardize security solutions for the IoT ecosystem. We first provide an in-depth review of the communication security solutions for IoT, specifically the standard security protocols to be used in conjunction with the Constrained Application Protocol (CoAP), an application protocol specifically tailored to the needs of adapting to the constraints of IoT devices. Since Datagram Transport Layer Security (DTLS) has been chosen as the channel security underneath CoAP, this paper also discusses the latest standardization efforts to adapt and enhance the DTLS for IoT applications. This includes the use of 1) raw public key in DTLS; 2) extending DTLS record Layer to protect group (multicast) communication; and 3) profiling DTLS for reducing the size and complexity of implementations on embedded devices. We also provide an extensive review of compression schemes that are being proposed in IETF to mitigate message fragmentation issues in DTLS.",
Hardware Trojan Attacks: Threat Analysis and Countermeasures,"Security of a computer system has been traditionally related to the security of the software or the information being processed. The underlying hardware used for information processing has been considered trusted. The emergence of hardware Trojan attacks violates this root of trust. These attacks, in the form of malicious modifications of electronic hardware at different stages of its life cycle, pose major security concerns in the electronics industry. An adversary can mount such an attack with an objective to cause operational failure or to leak secret information from inside a chip-e.g., the key in a cryptographic chip, during field operation. Global economic trend that encourages increased reliance on untrusted entities in the hardware design and fabrication process is rapidly enhancing the vulnerability to such attacks. In this paper, we analyze the threat of hardware Trojan attacks; present attack models, types, and scenarios; discuss different forms of protection approaches, both proactive and reactive; and describe emerging attack modes, defenses, and future research pathways.",
Outage Constrained Robust Transmit Optimization for Multiuser MISO Downlinks: Tractable Approximations by Conic Optimization,"In this paper, we study a probabilistically robust transmit optimization problem under imperfect channel state information (CSI) at the transmitter and under the multiuser multiple-input single-output (MISO) downlink scenario. The main issue is to keep the probability of each user's achievable rate outage as caused by CSI uncertainties below a given threshold. As is well known, such rate outage constraints present a significant analytical and computational challenge. Indeed, they do not admit simple closed-form expressions and are unlikely to be efficiently computable in general. Assuming Gaussian CSI uncertainties, we first review a traditional robust optimization-based method for approximating the rate outage constraints, and then develop two novel approximation methods using probabilistic techniques. Interestingly, these three methods can be viewed as implementing different tractable analytic upper bounds on the tail probability of a complex Gaussian quadratic form, and they provide convex restrictions, or safe tractable approximations, of the original rate outage constraints. In particular, a feasible solution from any one of these methods will automatically satisfy the rate outage constraints, and all three methods involve convex conic programs that can be solved efficiently using off-the-shelf solvers. We then proceed to study the performance-complexity tradeoffs of these methods through computational complexity and comparative approximation performance analyses. Finally, simulation results are provided to benchmark the three convex restriction methods against the state of the art in the literature. The results show that all three methods offer significantly improved solution quality and much lower complexity.","Robustness,
Approximation methods,
Array signal processing,
Optimization,
Vectors,
Downlink,
Silicon"
Age and Gender Estimation of Unfiltered Faces,"This paper concerns the estimation of facial attributes-namely, age and gender-from images of faces acquired in challenging, in the wild conditions. This problem has received far less attention than the related problem of face recognition, and in particular, has not enjoyed the same dramatic improvement in capabilities demonstrated by contemporary face recognition systems. Here, we address this problem by making the following contributions. First, in answer to one of the key problems of age estimation research-absence of data-we offer a unique data set of face images, labeled for age and gender, acquired by smart-phones and other mobile devices, and uploaded without manual filtering to online image repositories. We show the images in our collection to be more challenging than those offered by other face-photo benchmarks. Second, we describe the dropout-support vector machine approach used by our system for face attribute estimation, in order to avoid over-fitting. This method, inspired by the dropout learning techniques now popular with deep belief networks, is applied here for training support vector machines, to the best of our knowledge, for the first time. Finally, we present a robust face alignment technique, which explicitly considers the uncertainties of facial feature detectors. We report extensive tests analyzing both the difficulty levels of contemporary benchmarks as well as the capabilities of our own system. These show our method to outperform state-of-the-art by a wide margin.",
Multitask Linear Discriminant Analysis for View Invariant Action Recognition,"Robust action recognition under viewpoint changes has received considerable attention recently. To this end, self-similarity matrices (SSMs) have been found to be effective view-invariant action descriptors. To enhance the performance of SSM-based methods, we propose multitask linear discriminant analysis (LDA), a novel multitask learning framework for multiview action recognition that allows for the sharing of discriminative SSM features among different views (i.e., tasks). Inspired by the mathematical connection between multivariate linear regression and LDA, we model multitask multiclass LDA as a single optimization problem by choosing an appropriate class indicator matrix. In particular, we propose two variants of graph-guided multitask LDA: 1) where the graph weights specifying view dependencies are fixed a priori and 2) where graph weights are flexibly learnt from the training data. We evaluate the proposed methods extensively on multiview RGB and RGBD video data sets, and experimental results confirm that the proposed approaches compare favorably with the state-of-the-art.","Computer aided manufacturing,
Linear discriminant analysis,
Robustness,
Image recognition,
Vectors,
Three-dimensional displays,
Histograms"
Pilot Beam Pattern Design for Channel Estimation in Massive MIMO Systems,"In this paper, the problem of pilot beam pattern design for channel estimation in massive multiple-input multiple-output systems with a large number of transmit antennas at the base station is considered, and a new algorithm for pilot beam pattern design for optimal channel estimation is proposed under the assumption that the channel is a stationary Gauss-Markov random process. The proposed algorithm designs the pilot beam pattern sequentially by exploiting the properties of Kalman filtering and the associated prediction error covariance matrices and also the channel statistics such as spatial and temporal channel correlation. The resulting design generates a sequentially-optimal sequence of pilot beam patterns with low complexity for a given set of system parameters. Numerical results show the effectiveness of the proposed algorithm.","Channel estimation,
Covariance matrices,
MIMO,
Kalman filters,
Vectors,
Correlation,
Training"
A Survey of Multiobjective Evolutionary Algorithms for Data Mining: Part I,"The aim of any data mining technique is to build an efficient predictive or descriptive model of a large amount of data. Applications of evolutionary algorithms have been found to be particularly useful for automatic processing of large quantities of raw noisy data for optimal parameter setting and to discover significant and meaningful information. Many real-life data mining problems involve multiple conflicting measures of performance, or objectives, which need to be optimized simultaneously. Under this context, multiobjective evolutionary algorithms are gradually finding more and more applications in the domain of data mining since the beginning of the last decade. In this two-part paper, we have made a comprehensive survey on the recent developments of multiobjective evolutionary algorithms for data mining problems. In this paper, Part I, some basic concepts related to multiobjective optimization and data mining are provided. Subsequently, various multiobjective evolutionary approaches for two major data mining tasks, namely feature selection and classification, are surveyed. In Part II of this paper, we have surveyed different multiobjective evolutionary algorithms for clustering, association rule mining, and several other data mining tasks, and provided a general discussion on the scopes for future research in this domain.",
PayLess: A low cost network monitoring framework for Software Defined Networks,"Software Defined Networking promises to simplify network management tasks by separating the control plane (a central controller) from the data plane (switches). OpenFlow has emerged as the de facto standard for communication between the controller and switches. Apart from providing flow control and communication interfaces, OpenFlow provides a flow level statistics collection mechanism from the data plane. It exposes a high level interface for per flow and aggregate statistics collection. Network applications can use this high level interface to monitor network status without being concerned about the low level details. In order to keep the switch design simple, this statistics collection mechanism is implemented as a pull-based service, i.e. network applications and in turn the controller has to periodically query the switches about flow statistics. The frequency of polling the switches determines monitoring accuracy and network overhead. In this paper, we focus on this trade-off between monitoring accuracy, timeliness and network overhead. We propose PayLess - a monitoring framework for SDN. PayLess provides a flexible RESTful API for flow statistics collection at different aggregation levels. It uses an adaptive statistics collection algorithm that delivers highly accurate information in real-time without incurring significant network overhead. We utilize the Floodlight controller's API to implement the proposed monitoring framework. The effectiveness of our solution is demonstrated through emulations in Mininet.",
Shift-Based Density Estimation for Pareto-Based Algorithms in Many-Objective Optimization,"It is commonly accepted that Pareto-based evolutionary multiobjective optimization (EMO) algorithms encounter difficulties in dealing with many-objective problems. In these algorithms, the ineffectiveness of the Pareto dominance relation for a high-dimensional space leads diversity maintenance mechanisms to play the leading role during the evolutionary process, while the preference of diversity maintenance mechanisms for individuals in sparse regions results in the final solutions distributed widely over the objective space but distant from the desired Pareto front. Intuitively, there are two ways to address this problem: 1) modifying the Pareto dominance relation and 2) modifying the diversity maintenance mechanism in the algorithm. In this paper, we focus on the latter and propose a shift-based density estimation (SDE) strategy. The aim of our study is to develop a general modification of density estimation in order to make Pareto-based algorithms suitable for many-objective optimization. In contrast to traditional density estimation that only involves the distribution of individuals in the population, SDE covers both the distribution and convergence information of individuals. The application of SDE in three popular Pareto-based algorithms demonstrates its usefulness in handling many-objective problems. Moreover, an extensive comparison with five state-of-the-art EMO algorithms reveals its competitiveness in balancing convergence and diversity of solutions. These findings not only show that SDE is a good alternative to tackle many-objective problems, but also present a general extension of Pareto-based algorithms in many-objective optimization.",
On Training Targets for Supervised Speech Separation,"Formulation of speech separation as a supervised learning problem has shown considerable promise. In its simplest form, a supervised learning algorithm, typically a deep neural network, is trained to learn a mapping from noisy features to a time-frequency representation of the target of interest. Traditionally, the ideal binary mask (IBM) is used as the target because of its simplicity and large speech intelligibility gains. The supervised learning framework, however, is not restricted to the use of binary targets. In this study, we evaluate and compare separation results by using different training targets, including the IBM, the target binary mask, the ideal ratio mask (IRM), the short-time Fourier transform spectral magnitude and its corresponding mask (FFT-MASK), and the Gammatone frequency power spectrum. Our results in various test conditions reveal that the two ratio mask targets, the IRM and the FFT-MASK, outperform the other targets in terms of objective intelligibility and quality metrics. In addition, we find that masking based targets, in general, are significantly better than spectral envelope based targets. We also present comparisons with recent methods in non-negative matrix factorization and speech enhancement, which show clear performance advantages of supervised speech separation.",
Compressive Sensing via Nonlocal Low-Rank Regularization,"Sparsity has been widely exploited for exact reconstruction of a signal from a small number of random measurements. Recent advances have suggested that structured or group sparsity often leads to more powerful signal reconstruction techniques in various compressed sensing (CS) studies. In this paper, we propose a nonlocal low-rank regularization (NLR) approach toward exploiting structured sparsity and explore its application into CS of both photographic and MRI images. We also propose the use of a nonconvex log det ( X) as a smooth surrogate function for the rank instead of the convex nuclear norm and justify the benefit of such a strategy using extensive experiments. To further improve the computational efficiency of the proposed algorithm, we have developed a fast implementation using the alternative direction multiplier method technique. Experimental results have shown that the proposed NLR-CS algorithm can significantly outperform existing state-of-the-art CS techniques for image recovery.","Minimization,
Optimization,
Magnetic resonance imaging,
Approximation methods,
Image reconstruction,
Educational institutions,
Fourier transforms"
A Survey on Internet of Things From Industrial Market Perspective,"The Internet of Things (IoT) is a dynamic global information network consisting of Internet-connected objects, such as radio frequency identifications, sensors, and actuators, as well as other instruments and smart appliances that are becoming an integral component of the Internet. Over the last few years, we have seen a plethora of IoT solutions making their way into the industry marketplace. Context-aware communications and computing have played a critical role throughout the last few years of ubiquitous computing and are expected to play a significant role in the IoT paradigm as well. In this paper, we examine a variety of popular and innovative IoT solutions in terms of context-aware technology perspectives. More importantly, we evaluate these IoT solutions using a framework that we built around well-known context-aware computing theories. This survey is intended to serve as a guideline and a conceptual framework for context-aware product development and research in the IoT paradigm. It also provides a systematic exploration of existing IoT products in the marketplace and highlights a number of potentially significant research directions and trends.","Context awareness,
Internet of things,
Market research,
Information networks,
Internet,
Globalization,
Interconnections,
Product development,
Futures research"
OSA: An Optical Switching Architecture for Data Center Networks With Unprecedented Flexibility,"A detailed examination of evolving traffic characteristics, operator requirements, and network technology trends suggests a move away from nonblocking interconnects in data center networks (DCNs). As a result, recent efforts have advocated oversubscribed networks with the capability to adapt to traffic requirements on-demand. In this paper, we present the design, implementation, and evaluation of OSA, a novel Optical Switching Architecture for DCNs. Leveraging runtime reconfigurable optical devices, OSA dynamically changes its topology and link capacities, thereby achieving unprecedented flexibility to adapt to dynamic traffic patterns. Extensive analytical simulations using both real and synthetic traffic patterns demonstrate that OSA can deliver high bisection bandwidth (60%-100% of the nonblocking architecture). Implementation and evaluation of a small-scale functional prototype further demonstrate the feasibility of OSA.","telephone traffic,
computer centres,
optical switches"
Envelope Level Crossing Rate and Average Fade Duration of Nonisotropic Vehicle-to-Vehicle Ricean Fading Channels,"This paper proposes a generic geometry-based stochastic model for nonisotropic scattering vehicle-to-vehicle (V2V) Ricean fading channels. With the proposed model, the level crossing rate (LCR) and average fade duration (AFD) are derived. The resultant expressions are sufficiently general and subsume many well-known existing LCRs and AFDs as special cases. The derived LCR and AFD are further investigated in terms of some important parameters, e.g., the shape of the scattering region (two-ring or ellipse), mean angle, angle spread, and directions of movement of the Tx and Rx (same or opposite direction). More importantly, in this paper, the impact of the vehicular traffic density on the LCR and AFD for nonisotropic scattering V2V Ricean fading channels is investigated for the first time. Excellent agreement is observed between the theoretical LCRs/AFDs and corresponding measured data, thus demonstrating the validity and utility of the proposed model.",
Information and Energy Cooperation in Cognitive Radio Networks,"Cooperation between the primary and secondary systems can improve the spectrum efficiency in cognitive radio networks. The key idea is that the secondary system helps to boost the primary system's performance by relaying, and, in return, the primary system provides more opportunities for the secondary system to access the spectrum. In contrast to most of existing works that only consider information cooperation, this paper studies joint information and energy cooperation between the two systems, i.e., the primary transmitter sends information for relaying and feeds the secondary system with energy as well. This is particularly useful when the secondary transmitter has good channel quality to the primary receiver but is energy constrained. We propose and study three schemes that enable this cooperation. First, we assume there exists an ideal backhaul between the two systems for information and energy transfer. We then consider two wireless information and energy transfer schemes from the primary transmitter to the secondary transmitter using power splitting and time splitting energy harvesting techniques, respectively. For each scheme, the optimal and zero-forcing solutions are derived. Simulation results demonstrate promising performance gain for both systems due to the additional energy cooperation. It is also revealed that the power splitting scheme can achieve larger rate region than the time splitting scheme when the efficiency of the energy transfer is sufficiently large.",
Molecular Communication Among Biological Nanomachines: A Layered Architecture and Research Issues,"Molecular communication is an emerging communication paradigm for biological nanomachines. It allows biological nanomachines to communicate through exchanging molecules in an aqueous environment and to perform collaborative tasks through integrating functionalities of individual biological nanomachines. This paper develops the layered architecture of molecular communication and describes research issues that molecular communication faces at each layer of the architecture. Specifically, this paper applies a layered architecture approach, traditionally used in communication networks, to molecular communication, decomposes complex molecular communication functionality into a set of manageable layers, identifies basic functionalities of each layer, and develops a descriptive model consisting of key components of the layer for each layer. This paper also discusses open research issues that need to be addressed at each layer. In addition, this paper provides an example design of targeted drug delivery, a nanomedical application, to illustrate how the layered architecture helps design an application of molecular communication. The primary contribution of this paper is to provide an in-depth architectural view of molecular communication. Establishing a layered architecture of molecular communication helps organize various research issues and design concerns into layers that are relatively independent of each other, and thus accelerates research in each layer and facilitates the design and development of applications of molecular communication.","Molecular communication,
Nanobioscience,
Proteins,
Computer architecture,
Biological cells,
Drugs"
A Nonlinear Mapping Approach to Stain Normalization in Digital Histopathology Images Using Image-Specific Color Deconvolution,"Histopathology diagnosis is based on visual examination of the morphology of histological sections under a microscope. With the increasing popularity of digital slide scanners, decision support systems based on the analysis of digital pathology images are in high demand. However, computerized decision support systems are fraught with problems that stem from color variations in tissue appearance due to variation in tissue preparation, variation in stain reactivity from different manufacturers/batches, user or protocol variation, and the use of scanners from different manufacturers. In this paper, we present a novel approach to stain normalization in histopathology images. The method is based on nonlinear mapping of a source image to a target image using a representation derived from color deconvolution. Color deconvolution is a method to obtain stain concentration values when the stain matrix, describing how the color is affected by the stain concentration, is given. Rather than relying on standard stain matrices, which may be inappropriate for a given image, we propose the use of a color-based classifier that incorporates a novel stain color descriptor to calculate image-specific stain matrix. In order to demonstrate the efficacy of the proposed stain matrix estimation and stain normalization methods, they are applied to the problem of tumor segmentation in breast histopathology images. The experimental results suggest that the paradigm of color normalization, as a preprocessing step, can significantly help histological image analysis algorithms to demonstrate stable performance which is insensitive to imaging conditions in general and scanner variations in particular.","Image color analysis,
Histograms,
Deconvolution,
Estimation,
Image analysis,
Licenses,
Training"
Outlier Detection for Temporal Data: A Survey,"In the statistics community, outlier detection for time series data has been studied for decades. Recently, with advances in hardware and software technology, there has been a large body of work on temporal outlier detection from a computational perspective within the computer science community. In particular, advances in hardware technology have enabled the availability of various forms of temporal data collection mechanisms, and advances in software technology have enabled a variety of data management mechanisms. This has fueled the growth of different kinds of data sets such as data streams, spatio-temporal data, distributed streams, temporal networks, and time series data, generated by a multitude of applications. There arises a need for an organized and detailed study of the work done in the area of outlier detection with respect to such temporal datasets. In this survey, we provide a comprehensive and structured overview of a large set of interesting outlier definitions for various forms of temporal data, novel techniques, and application scenarios in which specific definitions and techniques have been widely used.","Time series analysis,
Computational modeling,
Hidden Markov models,
Predictive models,
Distributed databases,
Pattern matching"
"A Primer on Hardware Security: Models, Methods, and Metrics","The multinational, distributed, and multistep nature of integrated circuit (IC) production supply chain has introduced hardware-based vulnerabilities. Existing literature in hardware security assumes ad hoc threat models, defenses, and metrics for evaluation, making it difficult to analyze and compare alternate solutions. This paper systematizes the current knowledge in this emerging field, including a classification of threat models, state-of-the-art defenses, and evaluation metrics for important hardware-based attacks.","Hardware,
Trojan horses,
Watermarking,
Integrated circuit modeling,
Supply chain management,
Security,
Computer security"
Adaptive Operator Selection With Bandits for a Multiobjective Evolutionary Algorithm Based on Decomposition,"Adaptive operator selection (AOS) is used to determine the application rates of different operators in an online manner based on their recent performances within an optimization process. This paper proposes a bandit-based AOS method, fitness-rate-rank-based multiarmed bandit (FRRMAB). In order to track the dynamics of the search process, it uses a sliding window to record the recent fitness improvement rates achieved by the operators, while employing a decaying mechanism to increase the selection probability of the best operator. Not much work has been done on AOS in multiobjective evolutionary computation since it is very difficult to measure the fitness improvements quantitatively in most Pareto-dominance-based multiobjective evolutionary algorithms. Multiobjective evolutionary algorithm based on decomposition (MOEA/D) decomposes a multiobjective optimization problem into a number of scalar optimization subproblems and optimizes them simultaneously. Thus, it is natural and feasible to use AOS in MOEA/D. We investigate several important issues in using FRRMAB in MOEA/D. Our experimental results demonstrate that FRRMAB is robust and its operator selection is reasonable. Comparison experiments also indicate that FRRMAB can significantly improve the performance of MOEA/D.",
Distributed Control Techniques in Microgrids,"The objective of this paper is to provide a review of distributed control and management strategies for the next generation power system in the context of microgrids. This paper also identifies future research directions. The next generation power system, also referred to as the smart grid, is distinct from the existing power system due to its extensive use of integrated communication, advanced components such as power electronics, sensing, and measurement, and advanced control technologies. At the same time, the need for increased number of small distributed and renewable energy resources can exceed the capabilities of an available computational resource. Therefore, the recent literature has seen a significant research effort on dividing the control task among different units, which gives rise to the development of several distributed techniques. This paper discusses features and characteristics of these techniques, and identifies challenges and opportunities ahead. The paper also discusses the relationship between distributed control and hierarchical control.","Microgrids,
Voltage control,
Decentralized control,
Power system stability,
Multi-agent systems,
Hierarchical systems"
Community-Aware Opportunistic Routing in Mobile Social Networks,"Mobile social networks (MSNs) are a kind of delay tolerant network that consists of lots of mobile nodes with social characteristics. Recently, many social-aware algorithms have been proposed to address routing problems in MSNs. However, these algorithms tend to forward messages to the nodes with locally optimal social characteristics, and thus cannot achieve the optimal performance. In this paper, we propose a distributed optimal Community-Aware Opportunistic Routing (CAOR) algorithm. Our main contributions are that we propose a home-aware community model, whereby we turn an MSN into a network that only includes community homes. We prove that, in the network of community homes, we can still compute the minimum expected delivery delays of nodes through a reverse Dijkstra algorithm and achieve the optimal opportunistic routing performance. Since the number of communities is far less than the number of nodes in magnitude, the computational cost and maintenance cost of contact information are greatly reduced. We demonstrate how our algorithm significantly outperforms the previous ones through extensive simulations, based on a real MSN trace and a synthetic MSN trace.",
"A Vision of IoT: Applications, Challenges, and Opportunities With China Perspective","Internet of Things (IoT), which will create a huge network of billions or trillions of “Things” communicating with one another, are facing many technical and application challenges. This paper introduces the status of IoT development in China, including policies, R&D plans, applications, and standardization. With China's perspective, this paper depicts such challenges on technologies, applications, and standardization, and also proposes an open and general IoT architecture consisting of three platforms to meet the architecture challenge. Finally, this paper discusses the opportunity and prospect of IoT.",
Blind Image Quality Assessment Using Joint Statistics of Gradient Magnitude and Laplacian Features,"Blind image quality assessment (BIQA) aims to evaluate the perceptual quality of a distorted image without information regarding its reference image. Existing BIQA models usually predict the image quality by analyzing the image statistics in some transformed domain, e.g., in the discrete cosine transform domain or wavelet domain. Though great progress has been made in recent years, BIQA is still a very challenging task due to the lack of a reference image. Considering that image local contrast features convey important structural information that is closely related to image perceptual quality, we propose a novel BIQA model that utilizes the joint statistics of two types of commonly used local contrast features: 1) the gradient magnitude (GM) map and 2) the Laplacian of Gaussian (LOG) response. We employ an adaptive procedure to jointly normalize the GM and LOG features, and show that the joint statistics of normalized GM and LOG features have desirable properties for the BIQA task. The proposed model is extensively evaluated on three large-scale benchmark databases, and shown to deliver highly competitive performance with state-of-the-art BIQA models, as well as with some well-known full reference image quality assessment models.","Image quality,
Feature extraction,
Discrete cosine transforms,
Image edge detection,
Predictive models"
Clustering-Guided Sparse Structural Learning for Unsupervised Feature Selection,"Many pattern analysis and data mining problems have witnessed high-dimensional data represented by a large number of features, which are often redundant and noisy. Feature selection is one main technique for dimensionality reduction that involves identifying a subset of the most useful features. In this paper, a novel unsupervised feature selection algorithm, named clustering-guided sparse structural learning (CGSSL), is proposed by integrating cluster analysis and sparse structural analysis into a joint framework and experimentally evaluated. Nonnegative spectral clustering is developed to learn more accurate cluster labels of the input samples, which guide feature selection simultaneously. Meanwhile, the cluster labels are also predicted by exploiting the hidden structure shared by different features, which can uncover feature correlations to make the results more reliable. Row-wise sparse models are leveraged to make the proposed model suitable for feature selection. To optimize the proposed formulation, we propose an efficient iterative algorithm. Finally, extensive experiments are conducted on 12 diverse benchmarks, including face data, handwritten digit data, document data, and biomedical data. The encouraging experimental results in comparison with several representative algorithms and the theoretical analysis demonstrate the efficiency and effectiveness of the proposed algorithm for feature selection.","Clustering algorithms,
Algorithm design and analysis,
Optimization,
Integrated circuits,
Prediction algorithms,
Correlation,
Machine learning algorithms"
A Chain Structure of Switched Capacitor for Improved Cell Balancing Speed of Lithium-Ion Batteries,"Among various active cell balancing circuits, a switched capacitor circuit is promising because it can be implemented with low cost and small size. However, when the switched capacitor is applied in the lithium-ion battery, cell balancing speed is generally slow when the number of batteries is high. Therefore, this paper proposes the chain structure of the switched capacitor to increase balancing speed, particularly among outer cells. In this paper, the cell balancing principle of the conventional switched capacitor is explained, and the reason why slow cell balancing of the switched capacitor is shown in the lithium-ion battery is analyzed. To improve cell balancing speed, two circuits with chain structure are proposed. The balancing performance of the proposed circuits is confirmed by computer simulation, and a comparison between conventional and proposed circuits is presented. The theoretical analysis on the cell balancing speed of conventional structures and the proposed chain structure is also shown in this paper. Experimental tests were carried out to verify the validity of the proposed structures, and the experimental results show an improved balancing performance of the proposed circuit.",
Compact Printed UWB Diversity Slot Antenna With 5.5-GHz Band-Notched Characteristics,"A novel compact printed ultrawideband (UWB) slot antenna for MIMO/diversity applications is presented in this letter. The antenna consists of two modified coplanar waveguides (CPWs) feeding staircase-shaped radiating elements for orthogonal radiation patterns, where a rectangle stub is placed at 45° between the CPW to ensure high isolations. By etching two split-ring resonator (SRR) slots on the radiators respectively, the band-notched property is achieved. Results show that this antenna meets a 10-dB impedance bandwidth and 15 dB isolation from 2.5 to 12 GHz, with a notched band at 5.5 GHz. The measurements of the radiation patterns and envelope correlation coefficient (ECC) denote that the antenna is suitable for multiple-input-multiple-output (MIMO)/diversity systems. Furthermore, it has a compact size of 48 × 48 mm2, which has been significantly reduced, and it is a good candidate for portable devices.",
An Integrated System for Regional Environmental Monitoring and Management Based on Internet of Things,"Climate change and environmental monitoring and management have received much attention recently, and an integrated information system (IIS) is considered highly valuable. This paper introduces a novel IIS that combines Internet of Things (IoT), Cloud Computing, Geoinformatics [remote sensing (RS), geographical information system (GIS), and global positioning system (GPS)], and e-Science for environmental monitoring and management, with a case study on regional climate change and its ecological effects. Multi-sensors and Web services were used to collect data and other information for the perception layer; both public networks and private networks were used to access and transport mass data and other information in the network layer. The key technologies and tools include real-time operational database (RODB); extraction-transformation-loading (ETL); on-line analytical processing (OLAP) and relational OLAP (ROLAP); naming, addressing, and profile server (NAPS); application gateway (AG); application software for different platforms and tasks (APPs); IoT application infrastructure (IoT-AI); GIS and e-Science platforms; and representational state transfer/Java database connectivity (RESTful/JDBC). Application Program Interfaces (APIs) were implemented in the middleware layer of the IIS. The application layer provides the functions of storing, organizing, processing, and sharing of data and other information, as well as the functions of applications in environmental monitoring and management. The results from the case study show that there is a visible increasing trend of the air temperature in Xinjiang over the last 50 years (1962-2011) and an apparent increasing trend of the precipitation since the early 1980s. Furthermore, from the correlation between ecological indicators [gross primary production (GPP), net primary production (NPP), and leaf area index (LAI)] and meteorological elements (air temperature and precipitation), water resource availability is the decisive factor with regard to the terrestrial ecosystem in the area. The study shows that the research work is greatly benefited from such an IIS, not only in data collection supported by IoT, but also in Web services and applications based on cloud computing and e-Science platforms, and the effectiveness of monitoring processes and decision-making can be obviously improved. This paper provides a prototype IIS for environmental monitoring and management, and it also provides a new paradigm for the future research and practice; especially in the era of big data and IoT.",
Breast Cancer Histopathology Image Analysis: A Review,"This paper presents an overview of methods that have been proposed for the analysis of breast cancer histopathology images. This research area has become particularly relevant with the advent of whole slide imaging (WSI) scanners, which can perform cost-effective and high-throughput histopathology slide digitization, and which aim at replacing the optical microscope as the primary tool used by pathologist. Breast cancer is the most prevalent form of cancers among women, and image analysis methods that target this disease have a huge potential to reduce the workload in a typical pathology lab and to improve the quality of the interpretation. This paper is meant as an introduction for nonexperts. It starts with an overview of the tissue preparation, staining and slide digitization processes followed by a discussion of the different image processing techniques and applications, ranging from analysis of tissue staining to computer-aided diagnosis, and prognosis of breast cancer patients.",
A Sparse Embedding and Least Variance Encoding Approach to Hashing,"Hashing is becoming increasingly important in large-scale image retrieval for fast approximate similarity search and efficient data storage. Many popular hashing methods aim to preserve the kNN graph of high dimensional data points in the low dimensional manifold space, which is, however, difficult to achieve when the number of samples is big. In this paper, we propose an effective and efficient hashing approach by sparsely embedding a sample in the training sample space and encoding the sparse embedding vector over a learned dictionary. To this end, we partition the sample space into clusters via a linear spectral clustering method, and then represent each sample as a sparse vector of normalized probabilities that it falls into its several closest clusters. This actually embeds each sample sparsely in the sample space. The sparse embedding vector is employed as the feature of each sample for hashing. We then propose a least variance encoding model, which learns a dictionary to encode the sparse embedding feature, and consequently binarize the coding coefficients as the hash codes. The dictionary and the binarization threshold are jointly optimized in our model. Experimental results on benchmark data sets demonstrated the effectiveness of the proposed approach in comparison with state-of-the-art methods.","Training,
Vectors,
Binary codes,
Dictionaries,
Transforms,
Time complexity,
Image coding"
Neuromorphic Electronic Circuits for Building Autonomous Cognitive Systems,"Several analog and digital brain-inspired electronic systems have been recently proposed as dedicated solutions for fast simulations of spiking neural networks. While these architectures are useful for exploring the computational properties of large-scale models of the nervous system, the challenge of building low-power compact physical artifacts that can behave intelligently in the real world and exhibit cognitive abilities still remains open. In this paper, we propose a set of neuromorphic engineering solutions to address this challenge. In particular, we review neuromorphic circuits for emulating neural and synaptic dynamics in real time and discuss the role of biophysically realistic temporal dynamics in hardware neural processing architectures; we review the challenges of realizing spike-based plasticity mechanisms in real physical systems and present examples of analog electronic circuits that implement them;we describe the computational properties of recurrent neural networks and show how neuromorphic winner-take-all circuits can implement working-memory and decision-making mechanisms. We validate the neuromorphic approach proposed with experimental results obtained from our own circuits and systems, and argue how the circuits and networks presented in this work represent a useful set of components for efficiently and elegantly implementing neuromorphic cognition.",
Pairwise Rotation Invariant Co-Occurrence Local Binary Pattern,"Designing effective features is a fundamental problem in computer vision. However, it is usually difficult to achieve a great tradeoff between discriminative power and robustness. Previous works shown that spatial co-occurrence can boost the discriminative power of features. However the current existing co-occurrence features are taking few considerations to the robustness and hence suffering from sensitivity to geometric and photometric variations. In this work, we study the Transform Invariance (TI) of co-occurrence features. Concretely we formally introduce a Pairwise Transform Invariance (PTI) principle, and then propose a novel Pairwise Rotation Invariant Co-occurrence Local Binary Pattern (PRICoLBP) feature, and further extend it to incorporate multi-scale, multi-orientation, and multi-channel information. Different from other LBP variants, PRICoLBP can not only capture the spatial context co-occurrence information effectively, but also possess rotation invariance. We evaluate PRICoLBP comprehensively on nine benchmark data sets from five different perspectives, e.g., encoding strategy, rotation invariance, the number of templates, speed, and discriminative power compared to other LBP variants. Furthermore we apply PRICoLBP to six different but related applications-texture, material, flower, leaf, food, and scene classification, and demonstrate that PRICoLBP is efficient, effective, and of a well-balanced tradeoff between the discriminative power and robustness.","Transforms,
Image color analysis,
Robustness,
Feature extraction,
Lighting,
Histograms,
Encoding"
A Game-Theoretic Approach to Energy Trading in the Smart Grid,"Electric storage units constitute a key element in the emerging smart grid system. In this paper, the interactions and energy trading decisions of a number of geographically distributed storage units are studied using a novel framework based on game theory. In particular, a noncooperative game is formulated between storage units, such as plug-in hybrid electric vehicles, or an array of batteries that are trading their stored energy. Here, each storage unit's owner can decide on the maximum amount of energy to sell in a local market so as to maximize a utility that reflects the tradeoff between the revenues from energy trading and the accompanying costs. Then in this energy exchange market between the storage units and the smart grid elements, the price at which energy is traded is determined via an auction mechanism. The game is shown to admit at least one Nash equilibrium and a novel algorithm that is guaranteed to reach such an equilibrium point is proposed. Simulation results show that the proposed approach yields significant performance improvements, in terms of the average utility per storage unit, reaching up to 130.2% compared to a conventional greedy approach.","Games,
Smart grids,
Energy storage,
Nash equilibrium,
Vectors,
Energy exchange"
Quality Assessment of Stereoscopic 3D Image Compression by Binocular Integration Behaviors,"The objective approaches of 3D image quality assessment play a key role for the development of compression standards and various 3D multimedia applications. The quality assessment of 3D images faces more new challenges, such as asymmetric stereo compression, depth perception, and virtual view synthesis, than its 2D counterparts. In addition, the widely used 2D image quality metrics (e.g., PSNR and SSIM) cannot be directly applied to deal with these newly introduced challenges. This statement can be verified by the low correlation between the computed objective measures and the subjectively measured mean opinion scores (MOSs), when 3D images are the tested targets. In order to meet these newly introduced challenges, in this paper, besides traditional 2D image metrics, the binocular integration behaviors-the binocular combination and the binocular frequency integration, are utilized as the bases for measuring the quality of stereoscopic 3D images. The effectiveness of the proposed metrics is verified by conducting subjective evaluations on publicly available stereoscopic image databases. Experimental results show that significant consistency could be reached between the measured MOS and the proposed metrics, in which the correlation coefficient between them can go up to 0.88. Furthermore, we found that the proposed metrics can also address the quality assessment of the synthesized color-plus-depth 3D images well. Therefore, it is our belief that the binocular integration behaviors are important factors in the development of objective quality assessment for 3D images.","Three-dimensional displays,
Visualization,
Measurement,
Image coding,
Quality assessment,
Brightness,
Biological system modeling"
Exploiting Web Images for Semantic Video Indexing Via Robust Sample-Specific Loss,"Semantic video indexing, also known as video annotation or video concept detection in literatures, has been attracting significant attention in recent years. Due to deficiency of labeled training videos, most of the existing approaches can hardly achieve satisfactory performance. In this paper, we propose a novel semantic video indexing approach, which exploits the abundant user-tagged Web images to help learn robust semantic video indexing classifiers. The following two major challenges are well studied: 1) noisy Web images with imprecise and/or incomplete tags; and 2) domain difference between images and videos. Specifically, we first apply a non-parametric approach to estimate the probabilities of images being correctly tagged as confidence scores. We then develop a robust transfer video indexing (RTVI) model to learn reliable classifiers from a limited number of training videos together with the abundance of user-tagged images. The RTVI model is equipped with a novel sample-specific robust loss function, which employs the confidence score of a Web image as prior knowledge to suppress the influence and control the contribution of this image in the learning process. Meanwhile, the RTVI model discovers an optimal kernel space, in which the mismatch between images and videos is minimized for tackling the domain difference problem. Besides, we devise an iterative algorithm to effectively optimize the proposed RTVI model and a theoretical analysis on the convergence of the proposed algorithm is provided as well. Extensive experiments on various real-world multimedia collections demonstrate the effectiveness of the proposed robust semantic video indexing approach.","Semantics,
Indexing,
Video signal processing,
Robustness,
Kernel,
Noise,
Noise measurement"
Distributed Neural Network Control for Adaptive Synchronization of Uncertain Dynamical Multiagent Systems,"This paper addresses the leader-follower synchronization problem of uncertain dynamical multiagent systems with nonlinear dynamics. Distributed adaptive synchronization controllers are proposed based on the state information of neighboring agents. The control design is developed for both undirected and directed communication topologies without requiring the accurate model of each agent. This result is further extended to the output feedback case where a neighborhood observer is proposed based on relative output information of neighboring agents. Then, distributed observer-based synchronization controllers are derived and a parameter-dependent Riccati inequality is employed to prove the stability. This design has a favorable decouple property between the observer and the controller designs for nonlinear multiagent systems. For both cases, the developed controllers guarantee that the state of each agent synchronizes to that of the leader with bounded residual errors. Two illustrative examples validate the efficacy of the proposed methods.","Synchronization,
Multi-agent systems,
Nonlinear dynamical systems,
Output feedback,
Artificial neural networks,
Stability analysis"
Dynamic Trust Management for Delay Tolerant Networks and Its Application to Secure Routing,"Delay tolerant networks (DTNs) are characterized by high end-to-end latency, frequent disconnection, and opportunistic communication over unreliable wireless links. In this paper, we design and validate a dynamic trust management protocol for secure routing optimization in DTN environments in the presence of well-behaved, selfish and malicious nodes. We develop a novel model-based methodology for the analysis of our trust protocol and validate it via extensive simulation. Moreover, we address dynamic trust management, i.e., determining and applying the best operational settings at runtime in response to dynamically changing network conditions to minimize trust bias and to maximize the routing application performance. We perform a comparative analysis of our proposed routing protocol against Bayesian trust-based and non-trust based (PROPHET and epidemic) routing protocols. The results demonstrate that our protocol is able to deal with selfish behaviors and is resilient against trust-related attacks. Furthermore, our trust-based routing protocol can effectively trade off message overhead and message delay for a significant gain in delivery ratio. Our trust-based routing protocol operating under identified best settings outperforms Bayesian trust-based routing and PROPHET, and approaches the ideal performance of epidemic routing in delivery ratio and message delay without incurring high message or protocol maintenance overhead.","Routing,
Protocols,
History,
Optimization,
Delays,
Quality of service,
Analytical models"
3D Printed Dielectric Reflectarrays: Low-Cost High-Gain Antennas at Sub-Millimeter Waves,"Dielectric reflectarray antennas are proposed as a promising low-loss and low-cost solution for high gain terahertz (THz) antennas. Variable height dielectric elements are used in the reflectarray designs, which allow for the use of low dielectric-constant materials. Polymer-jetting 3-D printing technology is utilized to fabricate the antenna, which makes it possible to achieve rapid prototyping at a low-cost. Numerical and experimental results are presented for 3 different prototypes operating at 100 GHz, which show a good performance. Moreover the methodology proposed here is readily scalable, and with the current material and fabrication technology, designs up to 1.0 THz can be realized. This study reveals that the proposed design approach is well suited for low-cost high-gain THz antennas.",
Free Market of Crowdsourcing: Incentive Mechanism Design for Mobile Sensing,"Off-the-shelf smartphones have boosted large scale participatory sensing applications as they are equipped with various functional sensors, possess powerful computation and communication capabilities, and proliferate at a breathtaking pace. Yet the low participation level of smartphone users due to various resource consumptions, such as time and power, remains a hurdle that prevents the enjoyment brought by sensing applications. Recently, some researchers have done pioneer works in motivating users to contribute their resources by designing incentive mechanisms, which are able to provide certain rewards for participation. However, none of these works considered smartphone users' nature of opportunistically occurring in the area of interest. Specifically, for a general smartphone sensing application, the platform would distribute tasks to each user on her arrival and has to make an immediate decision according to the user's reply. To accommodate this general setting, we design three online incentive mechanisms, named TBA, TOIM and TOIMAD, based on online reverse auction. TBA is designed to pursue platform utility maximization, while TOIM and TOIM-AD achieve the crucial property of truthfulness. All mechanisms possess the desired properties of computational efficiency, individual rationality, and profitability. Besides, they are highly competitive compared to the optimal offline solution. The extensive simulation results reveal the impact of the key parameters and show good approximation to the state-of-the-art offline mechanism.","Sensors,
Smart phones,
Mechanical factors,
Mobile communication,
Educational institutions,
Electronic mail"
Cognitive Internet of Things: A New Paradigm Beyond Connection,"Current research on Internet of Things (IoT) mainly focuses on how to enable general objects to see, hear, and smell the physical world for themselves, and make them connected to share the observations. In this paper, we argue that only connected is not enough, beyond that, general objects should have the capability to learn, think, and understand both physical and social worlds by themselves. This practical need impels us to develop a new paradigm, named cognitive Internet of Things (CIoT), to empower the current IoT with a “brain” for high-level intelligence. Specifically, we first present a comprehensive definition for CIoT, primarily inspired by the effectiveness of human cognition. Then, we propose an operational framework of CIoT, which mainly characterizes the interactions among five fundamental cognitive tasks: perception-action cycle, massive data analytics, semantic derivation and knowledge discovery, intelligent decision-making, and on-demand service provisioning. Furthermore, we provide a systematic tutorial on key enabling techniques involved in the cognitive tasks. In addition, we also discuss the design of proper performance metrics on evaluating the enabling techniques. Last but not the least, we present the research challenges and open issues ahead. Building on the present work and potentially fruitful future studies, CIoT has the capability to bridge the physical world (with objects, resources, etc.) and the social world (with human demand, social behavior, etc.), and enhance smart resource allocation, automatic network operation, and intelligent service provisioning.",
Feature Correlation Hypergraph: Exploiting High-order Potentials for Multimodal Recognition,"In computer vision and multimedia analysis, it is common to use multiple features (or multimodal features) to represent an object. For example, to well characterize a natural scene image, we typically extract a set of visual features to represent its color, texture, and shape. However, it is challenging to integrate multimodal features optimally. Since they are usually high-order correlated, e.g., the histogram of gradient (HOG), bag of scale invariant feature transform descriptors, and wavelets are closely related because they collaboratively reflect the image texture. Nevertheless, the existing algorithms fail to capture the high-order correlation among multimodal features. To solve this problem, we present a new multimodal feature integration framework. Particularly, we first define a new measure to capture the high-order correlation among the multimodal features, which can be deemed as a direct extension of the previous binary correlation. Therefore, we construct a feature correlation hypergraph (FCH) to model the high-order relations among multimodal features. Finally, a clustering algorithm is performed on FCH to group the original multimodal features into a set of partitions. Moreover, a multiclass boosting strategy is developed to obtain a strong classifier by combining the weak classifiers learned from each partition. The experimental results on seven popular datasets show the effectiveness of our approach.","Entropy,
Correlation,
Kernel,
Boosting,
Joints,
Support vector machines,
Vectors"
A Differential Lyapunov Framework for Contraction Analysis,Lyapunov's second theorem is an essential tool for stability analysis of differential equations. The paper provides an analog theorem for incremental stability analysis by lifting the Lyapunov function to the tangent bundle. The Lyapunov function endows the state-space with a Finsler structure. Incremental stability is inferred from infinitesimal contraction of the Finsler metrics through integration along solutions curves.,"Asymptotic stability,
Manifolds,
Lyapunov methods,
Vectors,
Stability analysis,
Measurement,
Differential equations"
Influence of Delay on System Stability and Delay Optimization of Grid-Connected Inverters With LCL Filter,"Delay is inevitable in digital-controlled system and the delay will change system phase-frequency characteristic, thus affecting system stability. The system stability of inductor-capacitor-inductor (LCL)-type grid-connected inverter with single-loop control based on inverter-side current and single-loop control based on grid-side current is analyzed both in continuous and discrete domains. The influence of delay time on system stability is systematically studied. A delay time control method that is capable of adjusting delay time is further proposed to improve system stability. The proposed delay time control method is applied in the experiment, making an unstable system to be stable, and verifies the analysis result and proposed method.","Delays,
Power system stability,
Damping,
Stability criteria,
Inverters,
Resonant frequency"
Noise Robust Face Hallucination via Locality-Constrained Representation,"Recently, position-patch based approaches have been proposed to replace the probabilistic graph-based or manifold learning-based models for face hallucination. In order to obtain the optimal weights of face hallucination, these approaches represent one image patch through other patches at the same position of training faces by employing least square estimation or sparse coding. However, they cannot provide unbiased approximations or satisfy rational priors, thus the obtained representation is not satisfactory. In this paper, we propose a simpler yet more effective scheme called Locality-constrained Representation (LcR). Compared with Least Square Representation (LSR) and Sparse Representation (SR), our scheme incorporates a locality constraint into the least square inversion problem to maintain locality and sparsity simultaneously. Our scheme is capable of capturing the non-linear manifold structure of image patch samples while exploiting the sparse property of the redundant data representation. Moreover, when the locality constraint is satisfied, face hallucination is robust to noise, a property that is desirable for video surveillance applications. A statistical analysis of the properties of LcR is given together with experimental results on some public face databases and surveillance images to show the superiority of our proposed scheme over state-of-the-art face hallucination approaches.","Face,
Training,
Surveillance,
Image reconstruction,
Noise,
Manifolds,
Robustness"
Stable Matching-Based Selection in Evolutionary Multiobjective Optimization,"Multiobjective evolutionary algorithm based on decomposition (MOEA/D) decomposes a multiobjective optimization problem into a set of scalar optimization subproblems and optimizes them in a collaborative manner. Subproblems and solutions are two sets of agents that naturally exist in MOEA/D. The selection of promising solutions for subproblems can be regarded as a matching between subproblems and solutions. Stable matching, proposed in economics, can effectively resolve conflicts of interests among selfish agents in the market. In this paper, we advocate the use of a simple and effective stable matching (STM) model to coordinate the selection process in MOEA/D. In this model, subproblem agents can express their preferences over the solution agents, and vice versa. The stable outcome produced by the STM model matches each subproblem with one single solution, and it tradeoffs convergence and diversity of the evolutionary search. Comprehensive experiments have shown the effectiveness and competitiveness of our MOEA/D algorithm with the STM model. We have also demonstrated that user-preference information can be readily used in our proposed algorithm to find a region that decision makers are interested in.","Vectors,
Convergence,
Pareto optimization,
Educational institutions,
Linear programming,
Electronic mail"
Artifact Suppressed Dictionary Learning for Low-Dose CT Image Processing,"Low-dose computed tomography (LDCT) images are often severely degraded by amplified mottle noise and streak artifacts. These artifacts are often hard to suppress without introducing tissue blurring effects. In this paper, we propose to process LDCT images using a novel image-domain algorithm called “artifact suppressed dictionary learning (ASDL).” In this ASDL method, orientation and scale information on artifacts is exploited to train artifact atoms, which are then combined with tissue feature atoms to build three discriminative dictionaries. The streak artifacts are cancelled via a discriminative sparse representation operation based on these dictionaries. Then, a general dictionary learning processing is applied to further reduce the noise and residual artifacts. Qualitative and quantitative evaluations on a large set of abdominal and mediastinum CT images are carried out and the results show that the proposed method can be efficiently applied in most current CT systems.",
Half-Quadratic-Based Iterative Minimization for Robust Sparse Representation,"Robust sparse representation has shown significant potential in solving challenging problems in computer vision such as biometrics and visual surveillance. Although several robust sparse models have been proposed and promising results have been obtained, they are either for error correction or for error detection, and learning a general framework that systematically unifies these two aspects and explores their relation is still an open problem. In this paper, we develop a half-quadratic (HQ) framework to solve the robust sparse representation problem. By defining different kinds of half-quadratic functions, the proposed HQ framework is applicable to performing both error correction and error detection. More specifically, by using the additive form of HQ, we propose an ℓ1-regularized error correction method by iteratively recovering corrupted data from errors incurred by noises and outliers; by using the multiplicative form of HQ, we propose an ℓ1-regularized error detection method by learning from uncorrupted data iteratively. We also show that the ℓ1-regularization solved by soft-thresholding function has a dual relationship to Huber M-estimator, which theoretically guarantees the performance of robust sparse representation in terms of M-estimation. Experiments on robust face recognition under severe occlusion and corruption validate our framework and findings.","Robustness,
Minimization,
Additives,
Error correction,
Optimization,
Algorithm design and analysis,
Noise"
Robust Face Recognition via Adaptive Sparse Representation,"Sparse representation (or coding)-based classification (SRC) has gained great success in face recognition in recent years. However, SRC emphasizes the sparsity too much and overlooks the correlation information which has been demonstrated to be critical in real-world face recognition problems. Besides, some paper considers the correlation but overlooks the discriminative ability of sparsity. Different from these existing techniques, in this paper, we propose a framework called adaptive sparse representation-based classification (ASRC) in which sparsity and correlation are jointly considered. Specifically, when the samples are of low correlation, ASRC selects the most discriminative samples for representation, like SRC; when the training samples are highly correlated, ASRC selects most of the correlated and discriminative samples for representation, rather than choosing some related samples randomly. In general, the representation model is adaptive to the correlation structure that benefits from both ℓ1-norm and ℓ2-norm. Extensive experiments conducted on publicly available data sets verify the effectiveness and robustness of the proposed algorithm by comparing it with the state-of-the-art methods.","Face recognition,
Correlation,
Training,
Dictionaries,
Robustness,
Face,
Vectors"
"E
2
LMs
: Ensemble Extreme Learning Machines for Hyperspectral Image Classification","Extreme learning machine (ELM) has attracted attentions in pattern recognition field due to its remarkable advantages such as fast operation, straightforward solution, and strong generalization. However, the performance of ELM for high-dimensional data, such as hyperspectral image, is still an open problem. Therefore, in this paper, we introduce ELM for hyperspectral image classification. Furthermore, in order to overcome the drawbacks of ELM caused by the randomness of input weights and bias, two new algorithms of ensemble extreme learning machines (Bagging-based and AdaBoost-based ELMs) are proposed for the classification task. In order to illustrate the performance of the proposed algorithms, support vector machines (SVMs) are used for evaluation and comparison. Experimental results with real hyperspectral images collected by reflective optics spectrographic image system (ROSIS) and airborne visible/infrared imaging spectrometer (AVIRIS) indicate that the proposed ensemble algorithms produce excellent classification performance in different scenarios with respect to spectral and spectral-spatial feature sets.","Hyperspectral imaging,
Training,
Educational institutions,
Neurons,
Support vector machines"
Extended Dissipative Analysis for Neural Networks With Time-Varying Delays,"In this brief, an extended dissipativity analysis was conducted for a neural network with time-varying delays. The concept of the extended dissipativity can be used to solve for the H∞, L2 - L∞, passive, and dissipative performance by adjusting the weighting matrices in a new performance index. In addition, the activation function dividing method is modified by introducing a tuning parameter. Examples are provided to show the effectiveness and less conservatism of the proposed method.","Symmetric matrices,
Biological neural networks,
Delays,
Stability criteria,
Neurons,
Linear matrix inequalities"
"A 1200-V, 60-A SiC MOSFET Multichip Phase-Leg Module for High-Temperature, High-Frequency Applications","In this paper, a high-temperature, high-frequency, wire-bond-based multichip phase-leg module was designed, fabricated, and fully tested. Using paralleled Silicon Carbide (SiC) MOSFETs, the module was rated at 1200 V and 60 A, and was designed for a 25-kW three-phase inverter operating at a switching frequency of 70 kHz, and in a harsh environment up to 200 °C, for aircraft applications. To this end, the temperature-dependent characteristics of the SiC MOSFET were first evaluated. The results demonstrated the superiority of the SiC MOSFET in both static and switching performances compared to Si devices, but meanwhile did reveal the design tradeoff in terms of the device's gate oxide stability. Various high-temperature packaging materials were then extensively surveyed and carefully selected for the module to sustain the harsh environment. The electrical layout of the module was also optimized using a modeling and simulation approach, in order to minimize the device parasitic ringing during high-speed switching. Finally, the static and switching performances of the fabricated module were tested, and the 200 °C continuous operation of the SiC MOSFETs was verified.","Silicon carbide,
MOSFET,
Temperature,
Temperature measurement,
Switches,
Silicon,
Logic gates"
Data Uncertainty in Face Recognition,"The image of a face varies with the illumination, pose, and facial expression, thus we say that a single face image is of high uncertainty for representing the face. In this sense, a face image is just an observation and it should not be considered as the absolutely accurate representation of the face. As more face images from the same person provide more observations of the face, more face images may be useful for reducing the uncertainty of the representation of the face and improving the accuracy of face recognition. However, in a real world face recognition system, a subject usually has only a limited number of available face images and thus there is high uncertainty. In this paper, we attempt to improve the face recognition accuracy by reducing the uncertainty. First, we reduce the uncertainty of the face representation by synthesizing the virtual training samples. Then, we select useful training samples that are similar to the test sample from the set of all the original and synthesized virtual training samples. Moreover, we state a theorem that determines the upper bound of the number of useful training samples. Finally, we devise a representation approach based on the selected useful training samples to perform face recognition. Experimental results on five widely used face databases demonstrate that our proposed approach can not only obtain a high face recognition accuracy, but also has a lower computational complexity than the other state-of-the-art approaches.",
Fusion of Multichannel Local and Global Structural Cues for Photo Aesthetics Evaluation,"Photo aesthetic quality evaluation is a fundamental yet under addressed task in computer vision and image processing fields. Conventional approaches are frustrated by the following two drawbacks. First, both the local and global spatial arrangements of image regions play an important role in photo aesthetics. However, existing rules, e.g., visual balance, heuristically define which spatial distribution among the salient regions of a photo is aesthetically pleasing. Second, it is difficult to adjust visual cues from multiple channels automatically in photo aesthetics assessment. To solve these problems, we propose a new photo aesthetics evaluation framework, focusing on learning the image descriptors that characterize local and global structural aesthetics from multiple visual channels. In particular, to describe the spatial structure of the image local regions, we construct graphlets small-sized connected graphs by connecting spatially adjacent atomic regions. Since spatially adjacent graphlets distribute closely in their feature space, we project them onto a manifold and subsequently propose an embedding algorithm. The embedding algorithm encodes the photo global spatial layout into graphlets. Simultaneously, the importance of graphlets from multiple visual channels are dynamically adjusted. Finally, these post-embedding graphlets are integrated for photo aesthetics evaluation using a probabilistic model. Experimental results show that: 1) the visualized graphlets explicitly capture the aesthetically arranged atomic regions; 2) the proposed approach generalizes and improves four prominent aesthetic rules; and 3) our approach significantly outperforms state-of-the-art algorithms in photo aesthetics prediction.","Visualization,
Image color analysis,
Probabilistic logic,
Layout,
Training,
Vectors,
Graphical models"
BTM: Topic Modeling over Short Texts,"Short texts are popular on today's web, especially with the emergence of social media. Inferring topics from large scale short texts becomes a critical but challenging task for many content analysis tasks. Conventional topic models such as latent Dirichlet allocation (LDA) and probabilistic latent semantic analysis (PLSA) learn topics from document-level word co-occurrences by modeling each document as a mixture of topics, whose inference suffers from the sparsity of word co-occurrence patterns in short texts. In this paper, we propose a novel way for short text topic modeling, referred as biterm topic model (BTM). BTM learns topics by directly modeling the generation of word co-occurrence patterns (i.e., biterms) in the corpus, making the inference effective with the rich corpus-level information. To cope with large scale short text data, we further introduce two online algorithms for BTM for efficient topic learning. Experiments on real-word short text collections show that BTM can discover more prominent and coherent topics, and significantly outperform the state-of-the-art baselines. We also demonstrate the appealing performance of the two online BTM algorithms on both time efficiency and topic learning.","Semantics,
Analytical models,
Inference algorithms,
Context modeling,
Time complexity,
Algorithm design and analysis,
Data models"
Coupled Binary Embedding for Large-Scale Image Retrieval,"Visual matching is a crucial step in image retrieval based on the bag-of-words (BoW) model. In the baseline method, two keypoints are considered as a matching pair if their SIFT descriptors are quantized to the same visual word. However, the SIFT visual word has two limitations. First, it loses most of its discriminative power during quantization. Second, SIFT only describes the local texture feature. Both drawbacks impair the discriminative power of the BoW model and lead to false positive matches. To tackle this problem, this paper proposes to embed multiple binary features at indexing level. To model correlation between features, a multi-IDF scheme is introduced, through which different binary features are coupled into the inverted file. We show that matching verification methods based on binary features, such as Hamming embedding, can be effectively incorporated in our framework. As an extension, we explore the fusion of binary color feature into image retrieval. The joint integration of the SIFT visual word and binary features greatly enhances the precision of visual matching, reducing the impact of false positive matches. Our method is evaluated through extensive experiments on four benchmark datasets (Ukbench, Holidays, DupImage, and MIR Flickr 1M). We show that our method significantly improves the baseline approach. In addition, large-scale experiments indicate that the proposed method requires acceptable memory usage and query time compared with other approaches. Further, when global color feature is integrated, our method yields competitive performance with the state-of-the-arts.",
Improved and Promising Identification of Human MicroRNAs by Incorporating a High-Quality Negative Set,"MicroRNA (miRNA) plays an important role as a regulator in biological processes. Identification of (pre-) miRNAs helps in understanding regulatory processes. Machine learning methods have been designed for pre-miRNA identification. However, most of them cannot provide reliable predictive performances on independent testing data sets. We assumed this is because the training sets, especially the negative training sets, are not sufficiently representative. To generate a representative negative set, we proposed a novel negative sample selection technique, and successfully collected negative samples with improved quality. Two recent classifiers rebuilt with the proposed negative set achieved an improvement of ~6 percent in their predictive performance, which confirmed this assumption. Based on the proposed negative set, we constructed a training set, and developed an online system called miRNApre specifically for human pre-miRNA identification. We showed that miRNApre achieved accuracies on updated human and non-human data sets that were 34.3 and 7.6 percent higher than those achieved by current methods. The results suggest that miRNApre is an effective tool for pre-miRNA identification. Additionally, by integrating miRNApre, we developed a miRNA mining tool, mirnaDetect, which can be applied to find potential miRNAs in genome-scale data. MirnaDetect achieved a comparable mining performance on human chromosome 19 data as other existing methods.","RNA,
Genetics,
Data mining,
Biological processes,
Machine learning"
Multilinear Sparse Principal Component Analysis,"In this brief, multilinear sparse principal component analysis (MSPCA) is proposed for feature extraction from the tensor data. MSPCA can be viewed as a further extension of the classical principal component analysis (PCA), sparse PCA (SPCA) and the recently proposed multilinear PCA (MPCA). The key operation of MSPCA is to rewrite the MPCA into multilinear regression forms and relax it for sparse regression. Differing from the recently proposed MPCA, MSPCA inherits the sparsity from the SPCA and iteratively learns a series of sparse projections that capture most of the variation of the tensor data. Each nonzero element in the sparse projections is selected from the most important variables/factors using the elastic net. Extensive experiments on Yale, Face Recognition Technology face databases, and COIL-20 object database encoded the object images as second-order tensors, and Weizmann action database as third-order tensors demonstrate that the proposed MSPCA algorithm has the potential to outperform the existing PCA-based subspace learning algorithms.","Tensile stress,
Principal component analysis,
Vectors,
Feature extraction,
Optimization,
Learning systems,
Face recognition"
Blind Deconvolution Using Convex Programming,"We consider the problem of recovering two unknown vectors, w and x, of length L from their circular convolution. We make the structural assumption that the two vectors are members of known subspaces, one with dimension N and the other with dimension K. Although the observed convolution is nonlinear in both w and x, it is linear in the rank-1 matrix formed by their outer product wx*. This observation allows us to recast the deconvolution problem as low-rank matrix recovery problem from linear measurements, whose natural convex relaxation is a nuclear norm minimization program. We prove the effectiveness of this relaxation by showing that, for “generic” signals, the program can deconvolve w and x exactly when the maximum of N and K is almost on the order of L. That is, we show that if x is drawn from a random subspace of dimension N, and w is a vector in a subspace of dimension K whose basis vectors are spread out in the frequency domain, then nuclear norm minimization recovers wx* without error. We discuss this result in the context of blind channel estimation in communications. If we have a message of length N, which we code using a random L x N coding matrix, and the encoded message travels through an unknown linear time-invariant channel of maximum length K, then the receiver can recover both the channel response and the message when L ≳ N + K, to within constant and log factors.",
UpSet: Visualization of Intersecting Sets,"Understanding relationships between sets is an important analysis task that has received widespread attention in the visualization community. The major challenge in this context is the combinatorial explosion of the number of set intersections if the number of sets exceeds a trivial threshold. In this paper we introduce UpSet, a novel visualization technique for the quantitative analysis of sets, their intersections, and aggregates of intersections. UpSet is focused on creating task-driven aggregates, communicating the size and properties of aggregates and intersections, and a duality between the visualization of the elements in a dataset and their set membership. UpSet visualizes set intersections in a matrix layout and introduces aggregates based on groupings and queries. The matrix layout enables the effective representation of associated data, such as the number of elements in the aggregates and intersections, as well as additional summary statistics derived from subset or element attributes. Sorting according to various measures enables a task-driven analysis of relevant intersections and aggregates. The elements represented in the sets and their associated attributes are visualized in a separate view. Queries based on containment in specific intersections, aggregates or driven by attribute filters are propagated between both views. We also introduce several advanced visual encodings and interaction methods to overcome the problems of varying scales and to address scalability. UpSet is web-based and open source. We demonstrate its general utility in multiple use cases from various domains.","Data visualization,
Visualization,
Power generation,
Sorting,
Information analysis"
Learning Local Feature Descriptors Using Convex Optimisation,"The objective of this work is to learn descriptors suitable for the sparse feature detectors used in viewpoint invariant matching. We make a number of novel contributions towards this goal. First, it is shown that learning the pooling regions for the descriptor can be formulated as a convex optimisation problem selecting the regions using sparsity. Second, it is shown that descriptor dimensionality reduction can also be formulated as a convex optimisation problem, using Mahalanobis matrix nuclear norm regularisation. Both formulations are based on discriminative large margin learning constraints. As the third contribution, we evaluate the performance of the compressed descriptors, obtained from the learnt real-valued descriptors by binarisation. Finally, we propose an extension of our learning formulations to a weakly supervised case, which allows us to learn the descriptors from unannotated image collections. It is demonstrated that the new learning methods improve over the state of the art in descriptor learning on the annotated local patches data set of Brown et al. and unannotated photo collections of Philbin et al. .",
Rapidly Exponentially Stabilizing Control Lyapunov Functions and Hybrid Zero Dynamics,"This paper addresses the problem of exponentially stabilizing periodic orbits in a special class of hybrid models-systems with impulse effects-through control Lyapunov functions. The periodic orbit is assumed to lie in a C1 submanifold Z that is contained in the zero set of an output function and is invariant under both the continuous and discrete dynamics; the associated restriction dynamics are termed the hybrid zero dynamics. The orbit is furthermore assumed to be exponentially stable within the hybrid zero dynamics. Prior results on the stabilization of such periodic orbits with respect to the full-order dynamics of the system with impulse effects have relied on input-output linearization of the dynamics transverse to the zero dynamics manifold. The principal result of this paper demonstrates that a variant of control Lyapunov functions that enforce rapid exponential convergence to the zero dynamics surface, Z, can be used to achieve exponential stability of the periodic orbit in the full-order dynamics, thereby significantly extending the class of stabilizing controllers. The main result is illustrated on a hybrid model of a bipedal walking robot through simulations and is utilized to experimentally achieve bipedal locomotion via control Lyapunov functions.",
Mobile Robot Localization Using the Phase of Passive UHF RFID Signals,"This paper presents a global localization system for an indoor autonomous vehicle equipped with odometry sensors and a radio-frequency identification (RFID) reader to interrogate tags located on the ceiling of the environment. The RFID reader can measure the phase of the signals coming from responding tags. This phase has non-univocal dependence on the distance robot tag, but in the considered frequency, it is really sensitive to a change in the position of the robot. For this reason, a multihypothesis Kalman filtering approach provides a really satisfactory performance even in the case that a very small density of tags is used: In the experimental tests, an average position estimation error of about 4 cm is achieved using only two tags for an area of about 5 m2.","Phase measurement,
Antennas,
Radiofrequency identification,
Antenna measurements,
Mobile robots,
Accuracy"
Neural-Network-Based Online HJB Solution for Optimal Robust Guaranteed Cost Control of Continuous-Time Uncertain Nonlinear Systems,"In this paper, the infinite horizon optimal robust guaranteed cost control of continuous-time uncertain nonlinear systems is investigated using neural-network-based online solution of Hamilton-Jacobi-Bellman (HJB) equation. By establishing an appropriate bounded function and defining a modified cost function, the optimal robust guaranteed cost control problem is transformed into an optimal control problem. It can be observed that the optimal cost function of the nominal system is nothing but the optimal guaranteed cost of the original uncertain system. A critic neural network is constructed to facilitate the solution of the modified HJB equation corresponding to the nominal system. More importantly, an additional stabilizing term is introduced for helping to verify the stability, which reinforces the updating process of the weight vector and reduces the requirement of an initial stabilizing control. The uniform ultimate boundedness of the closed-loop system is analyzed by using the Lyapunov approach as well. Two simulation examples are provided to verify the effectiveness of the present control approach.","Robustness,
Cost function,
Optimal control,
Nonlinear systems,
Equations,
Feedback control"
Battery Energy Storage System (BESS) and Battery Management System (BMS) for Grid-Scale Applications,"The current electric grid is an inefficient system that wastes significant amounts of the electricity it produces because there is a disconnect between the amount of energy consumers require and the amount of energy produced from generation sources. Power plants typically produce more power than necessary to ensure adequate power quality. By taking advantage of energy storage within the grid, many of these inefficiencies can be removed. When using battery energy storage systems (BESS) for grid storage, advanced modeling is required to accurately monitor and control the storage system. A battery management system (BMS) controls how the storage system will be used and a BMS that utilizes advanced physics-based models will offer for much more robust operation of the storage system. The paper outlines the current state of the art for modeling in BMS and the advanced models required to fully utilize BMS for both lithium-ion batteries and vanadium redox-flow batteries. In addition, system architecture and how it can be useful in monitoring and control is discussed. A pathway for advancing BMS to better utilize BESS for grid-scale applications is outlined.","Batteries,
System-on-chip,
Computer architecture,
Battery management systems,
Microprocessors,
Energy storage,
Energy conversion,
Microgrids,
Power grids"
Electronic frog eye: Counting crowd using WiFi,"Crowd counting, which count or accurately estimate the number of human beings within a region, is critical in many applications, such as guided tour, crowd control and marketing research and analysis. A crowd counting solution should be scalable and be minimally intrusive (i.e., device-free) to users. Image-based solutions are device-free, but cannot work well in a dim or dark environment. Non-image based solutions usually require every human being carrying device, and are inaccurate and unreliable in practice. In this paper, we present FCC, a device-Free Crowd Counting approach based on Channel State Information (CSI). Our design is motivated by our observation that CSI is highly sensitive to environment variation, like a frog eye. We theoretically discuss the relationship between the number of moving people and the variation of wireless channel state. A major challenge in our design of FCC is to find a stable monotonic function to characterize the relationship between the crowd number and various features of CSI. To this end, we propose a metric, the Percentage of nonzero Elements (PEM), in the dilated CSI Matrix. The monotonic relationship can be explicitly formulated by the Grey Verhulst Model, which is used for crowd counting without a labor-intensive site survey. We implement FCC using off-the-shelf IEEE 802.11n devices and evaluate its performance via extensive experiments in typical real-world scenarios. Our results demonstrate that FCC outperforms the state-of-art approaches with much better accuracy, scalability and reliability.","Computers,
Conferences,
Computer science,
Educational institutions,
FCC,
Performance evaluation,
Cameras"
A Consensus Model to Detect and Manage Noncooperative Behaviors in Large-Scale Group Decision Making,"Consensus reaching processes in group decision making attempt to reach a mutual agreement among a group of decision makers before making a common decision. Different consensus models have been proposed by different authors in the literature to facilitate consensus reaching processes. Classical models focus on solving group decision making problems where few decision makers participate. However, nowadays, societal and technological trends that demand the management of larger scales of decision makers, such as e-democracy and social networks, add a new requirement to the solution of consensus-based group decision making problems. Dealing with such large groups implies the need for mechanisms to detect decision makers' noncooperative behaviors in consensus, which might bias the consensus reaching process. This paper presents a consensus model suitable to manage large scales of decision makers, which incorporates a fuzzy clustering-based scheme to detect and manage individual and subgroup noncooperative behaviors. The model is complemented with a visual analysis tool of the overall consensus reaching process based on self-organizing maps, which facilitates the monitoring of the process performance across the time. The consensus model presented is aimed to the solution of consensus processes involving large groups.","behavioural sciences,
distributed decision making,
fuzzy set theory,
pattern clustering,
self-organising feature maps"
Multiple Mobile Data Offloading Through Disruption Tolerant Networks,"To cope with explosive traffic demands on current cellular networks of limited capacity, Disruption Tolerant Networking (DTN) is used to offload traffic from cellular networks to high capacity and free device-to-device networks. Current DTN-based mobile data offloading models are based on simple and unrealistic network assumptions which do not take into account the heterogeneity of mobile data and mobile users. We establish a mathematical framework to study the problem of multiple-type mobile data offloading under realistic assumptions, where (i) mobile data are heterogeneous in terms of size and lifetime; (ii) mobile users have different data subscribing interests; and (iii) the storages of offloading helpers are limited. We formulate the objective of achieving maximum mobile data offloading as a submodular function maximization problem with multiple linear constraints of limited storage, and propose three algorithms, suitable for the generic and more specific offloading scenarios, respectively, to solve this challenging optimization problem. We show that the designed algorithms effectively offload data to the DTN by using both the theoretical analysis and simulation investigations which employ both real human and vehicular mobility traces.","Telecommunication traffic,
Cellular networks,
Fault tolerance,
Mobile communication"
Information Security in Big Data: Privacy and Data Mining,"The growing popularity and development of data mining technologies bring serious threat to the security of individual,'s sensitive information. An emerging research topic in data mining, known as privacy-preserving data mining (PPDM), has been extensively studied in recent years. The basic idea of PPDM is to modify the data in such a way so as to perform data mining algorithms effectively without compromising the security of sensitive information contained in the data. Current studies of PPDM mainly focus on how to reduce the privacy risk brought by data mining operations, while in fact, unwanted disclosure of sensitive information may also happen in the process of data collecting, data publishing, and information (i.e., the data mining results) delivering. In this paper, we view the privacy issues related to data mining from a wider perspective and investigate various approaches that can help to protect sensitive information. In particular, we identify four different types of users involved in data mining applications, namely, data provider, data collector, data miner, and decision maker. For each type of user, we discuss his privacy concerns and the methods that can be adopted to protect sensitive information. We briefly introduce the basics of related research topics, review state-of-the-art approaches, and present some preliminary thoughts on future research directions. Besides exploring the privacy-preserving approaches for each type of user, we also review the game theoretical approaches, which are proposed for analyzing the interactions among different users in a data mining scenario, each of whom has his own valuation on the sensitive information. By differentiating the responsibilities of different users with respect to security of sensitive information, we would like to provide some useful insights into the study of PPDM.","Privacy,
Data mining,
Game theory,
Tracking,
Computer security,
Data privacy,
Algorithm design and analysis"
Lazy Random Walks for Superpixel Segmentation,"We present a novel image superpixel segmentation approach using the proposed lazy random walk (LRW) algorithm in this paper. Our method begins with initializing the seed positions and runs the LRW algorithm on the input image to obtain the probabilities of each pixel. Then, the boundaries of initial superpixels are obtained according to the probabilities and the commute time. The initial superpixels are iteratively optimized by the new energy function, which is defined on the commute time and the texture measurement. Our LRW algorithm with self-loops has the merits of segmenting the weak boundaries and complicated texture regions very well by the new global probability maps and the commute time strategy. The performance of superpixel is improved by relocating the center positions of superpixels and dividing the large superpixels into small ones with the proposed optimization algorithm. The experimental results have demonstrated that our method achieves better performance than previous superpixel approaches.","Image segmentation,
Optimization,
Symmetric matrices,
Image edge detection,
Computed tomography,
Laplace equations,
Equations"
Color-Guided Depth Recovery From RGB-D Data Using an Adaptive Autoregressive Model,"This paper proposes an adaptive color-guided autoregressive (AR) model for high quality depth recovery from low quality measurements captured by depth cameras. We observe and verify that the AR model tightly fits depth maps of generic scenes. The depth recovery task is formulated into a minimization of AR prediction errors subject to measurement consistency. The AR predictor for each pixel is constructed according to both the local correlation in the initial depth map and the nonlocal similarity in the accompanied high quality color image. We analyze the stability of our method from a linear system point of view, and design a parameter adaptation scheme to achieve stable and accurate depth recovery. Quantitative and qualitative evaluation compared with ten state-of-the-art schemes show the effectiveness and superiority of our method. Being able to handle various types of depth degradations, the proposed method is versatile for mainstream depth sensors, time-of-flight camera, and Kinect, as demonstrated by experiments on real systems.","Cameras,
Color,
Image color analysis,
Adaptation models,
Degradation,
Image resolution,
Data models"
Distributed Energy Consumption Control via Real-Time Pricing Feedback in Smart Grid,"This brief proposes a pricing-based energy control strategy to remove the peak load for smart grid. According to the price, energy consumers control their energy consumption to make a tradeoff between the electricity cost and the load curtailment cost. The consumers are interactive with each other because of pricing based on the total load. We formulate the interactions among the consumers into a noncooperative game and give a sufficient condition to ensure a unique equilibrium in the game. We develop a distributed energy control algorithm and provide a sufficient convergence condition of the algorithm. The energy control algorithm starts at the beginning of each time slot, e.g., 15 min. Finally, the energy control strategy is applied to control the energy consumption of the consumers with heating ventilation air conditioning systems. The numerical results show that the energy control strategy is effective in removing the peak load and matching supply with demand, and the energy control algorithm can converge to the equilibrium.","Pricing,
Energy consumption,
Games,
Nash equilibrium,
Electricity,
Convergence,
Load management"
Energy-Efficient Stochastic Task Scheduling on Heterogeneous Computing Systems,"In the past few years, with the rapid development of heterogeneous computing systems (HCS), the issue of energy consumption has attracted a great deal of attention. How to reduce energy consumption is currently a critical issue in designing HCS. In response to this challenge, many energy-aware scheduling algorithms have been developed primarily using the dynamic voltage-frequency scaling (DVFS) capability which has been incorporated into recent commodity processors. However, these techniques are unsatisfactory in minimizing both schedule length and energy consumption. Furthermore, most algorithms schedule tasks according to their average-case execution times and do not consider task execution times with probability distributions in the real-world. In realizing this, we study the problem of scheduling a bag-of-tasks (BoT) application, made of a collection of independent stochastic tasks with normal distributions of task execution times, on a heterogeneous platform with deadline and energy consumption budget constraints. We build execution time and energy consumption models for stochastic tasks on a single processor. We derive the expected value and variance of schedule length on HCS by Clark's equations. We formulate our stochastic task scheduling problem as a linear programming problem, in which we maximize the weighted probability of combined schedule length and energy consumption metric under deadline and energy consumption budget constraints. We propose a heuristic energy-aware stochastic task scheduling algorithm called ESTS to solve this problem. Our algorithm can achieve high scheduling performance for BoT applications with low time complexity O(n(M + logn)), where n is the number of tasks and M is the total number of processor frequencies. Our extensive simulations for performance evaluation based on randomly generated stochastic applications and real-world applications clearly demonstrate that our proposed heuristic algorithm can improve the weighted probability that both the deadline and the energy consumption budget constraints can be met, and has the capability of balancing between schedule length and energy consumption.","Program processors,
Energy consumption,
Schedules,
Stochastic processes,
Processor scheduling,
Gaussian distribution,
Dynamic scheduling"
Physical Layer Security of Maximal Ratio Combining in Two-Wave With Diffuse Power Fading Channels,"This paper advocates physical layer security of maximal ratio combining (MRC) in wiretap two-wave with diffuse power fading channels. In such a wiretap channel, we consider that confidential messages transmitted from a single antenna transmitter to an M-antenna receiver are overheard by an N-antenna eavesdropper. The receiver adopts MRC to maximize the probability of secure transmission, whereas the eavesdropper adopts MRC to maximize the probability of successful eavesdropping. We derive the secrecy performance for two practical scenarios: 1) the eavesdropper's channel state information (CSI) is available at the transmitter and 2) the eavesdropper's CSI is not available at the transmitter. For the first scenario, we develop a new analytical framework to characterize the average secrecy capacity as the principal security performance metric. Specifically, we derive new closed-form expressions for the exact and asymptotic average secrecy capacity. Based on these, we determine the high signal-to-noise ratio power offset to explicitly quantify the impacts of the main channel and the eavesdropper's channel on the average secrecy capacity. For the second scenario, the secrecy outage probability is the primary security performance metric. Here, we derive new closed-form expressions for the exact and asymptotic secrecy outage probability. We also derive the probability of nonzero secrecy capacity. The asymptotic secrecy outage probability explicitly indicates that the positive impact of M is reflected in the secrecy diversity order and the negative impact of N is reflected in the secrecy array gain. Motivated by this, we examine the performance gap between N and N+1 antennas based on their respective secrecy array gains.","Signal to noise ratio,
Fading,
Transmitters,
Security,
Physical layer,
Receivers,
Antennas"
A 3-D Luneburg Lens Antenna Fabricated by Polymer Jetting Rapid Prototyping,"In this work, we designed, built, and tested a low-gain 20 dBi Luneburg Lens antenna using a rapid prototyping machine as a proof of concept demonstrator. The required continuously varying relative permittivity profile was implemented by changing the size of plastic blocks centered on the junctions of a plastic rod space frame. A 12-cm ( 4λ0 at 10 GHz) diameter lens is designed to work at X-band. The effective permittivity of the unit cell is calculated by effective medium theory and simulated by full-wave finite-element simulations. The fabrication is implemented by a polymer jetting rapid prototyping method. In the measurement, the lens antenna is fed by an X-band waveguide. The measured gain of the antenna at X-band is from 17.3 to 20.3 dB. The measured half-power beam width is from 19° to 12.7° while the side lobes are about 25 dB below the main peak. Good agreement between simulation and experimental results is obtained.","Lenses,
Polymers,
Permittivity,
Antennas,
Gain,
Filling"
A Review of Agent and Service-Oriented Concepts Applied to Intelligent Energy Systems,"The intention of this paper is to provide an overview of using agent and service-oriented technologies in intelligent energy systems. It focuses mainly on ongoing research and development activities related to smart grids. Key challenges as a result of the massive deployment of distributed energy resources are discussed, such as aggregation, supply-demand balancing, electricity markets, as well as fault handling and diagnostics. Concepts and technologies like multiagent systems or service-oriented architectures are able to deal with future requirements supporting a flexible, intelligent, and active power grid management. This work monitors major achievements in the field and provides a brief overview of large-scale smart grid projects using agent and service-oriented principles. In addition, future trends in the digitalization of power grids are discussed covering the deployment of resource constrained devices and appropriate communication protocols. The employment of ontologies ensuring semantic interoperability as well as the improvement of security issues related to smart grids is also discussed.","Smart grids,
Electricity,
Informatics,
Generators,
Real-time systems,
Service-oriented architecture"
Quantitative Comparison of Reconstruction Methods for Intra-Voxel Fiber Recovery From Diffusion MRI,"Validation is arguably the bottleneck in the diffusion magnetic resonance imaging (MRI) community. This paper evaluates and compares 20 algorithms for recovering the local intra-voxel fiber structure from diffusion MRI data and is based on the results of the “HARDI reconstruction challenge” organized in the context of the “ISBI 2012” conference. Evaluated methods encompass a mixture of classical techniques well known in the literature such as diffusion tensor, Q-Ball and diffusion spectrum imaging, algorithms inspired by the recent theory of compressed sensing and also brand new approaches proposed for the first time at this contest. To quantitatively compare the methods under controlled conditions, two datasets with known ground-truth were synthetically generated and two main criteria were used to evaluate the quality of the reconstructions in every voxel: correct assessment of the number of fiber populations and angular accuracy in their orientation. This comparative study investigates the behavior of every algorithm with varying experimental conditions and highlights strengths and weaknesses of each approach. This information can be useful not only for enhancing current algorithms and develop the next generation of reconstruction methods, but also to assist physicians in the choice of the most adequate technique for their studies.","Statistics,
Sociology,
Image reconstruction,
Reconstruction algorithms,
Educational institutions,
Diffusion tensor imaging"
Active Gate Driver for Crosstalk Suppression of SiC Devices in a Phase-Leg Configuration,"In a phase-leg configuration, the high-switching-speed performance of silicon carbide (SiC) devices is limited by the interaction between the upper and lower devices during the switching transient (crosstalk), leading to additional switching losses and overstress of the power devices. To utilize the full potential of fast SiC devices, this paper proposes two gate assist circuits to actively suppress crosstalk on the basis of the intrinsic properties of SiC power devices. One gate assist circuit employs an auxiliary transistor in series with a capacitor to mitigate crosstalk by gate loop impedance reduction. The other gate assist circuit consists of two auxiliary transistors with a diode to actively control the gate voltage for crosstalk elimination. Based on CREE CMF20120D SiC MOSFETs, the experimental results show that both active gate drivers are effective to suppress crosstalk, enabling turn-on switching losses reduction by up to 17%, and negative spurious gate voltage minimization without the penalty of decreasing the switching speed. Furthermore, both gate assist circuits, even without a negative isolated power supply, are more effective in improving the switching behavior of SiC devices in comparison to the conventional gate driver with a -2 V turn-off gate voltage. Accordingly, the proposed active gate assist circuits are simple, efficient, and cost-effective solutions for crosstalk suppression.",
Differential Evolution With Two-Level Parameter Adaptation,"The performance of differential evolution (DE) largely depends on its mutation strategy and control parameters. In this paper, we propose an adaptive DE (ADE) algorithm with a new mutation strategy DE/lbest/1 and a two-level adaptive parameter control scheme. The DE/lbest/1 strategy is a variant of the greedy DE/best/1 strategy. However, the population is mutated under the guide of multiple locally best individuals in DE/lbest/1 instead of one globally best individual in DE/best/1. This strategy is beneficial to the balance between fast convergence and population diversity. The two-level adaptive parameter control scheme is implemented mainly in two steps. In the first step, the population-level parameters Fp and CRp for the whole population are adaptively controlled according to the optimization states, namely, the exploration state and the exploitation state in each generation. These optimization states are estimated by measuring the population distribution. Then, the individual-level parameters Fi and CRi for each individual are generated by adjusting the population-level parameters. The adjustment is based on considering the individual's fitness value and its distance from the globally best individual. This way, the parameters can be adapted to not only the overall state of the population but also the characteristics of different individuals. The performance of the proposed ADE is evaluated on a suite of benchmark functions. Experimental results show that ADE generally outperforms four state-of-the-art DE variants on different kinds of optimization problems. The effects of ADE components, parameter properties of ADE, search behavior of ADE, and parameter sensitivity of ADE are also studied. Finally, we investigate the capability of ADE for solving three real-world optimization problems.",
A Hand Gesture Recognition Framework and Wearable Gesture-Based Interaction Prototype for Mobile Devices,"An algorithmic framework is proposed to process acceleration and surface electromyographic (SEMG) signals for gesture recognition. It includes a novel segmentation scheme, a score-based sensor fusion scheme, and two new features. A Bayes linear classifier and an improved dynamic time-warping algorithm are utilized in the framework. In addition, a prototype system, including a wearable gesture sensing device (embedded with a three-axis accelerometer and four SEMG sensors) and an application program with the proposed algorithmic framework for a mobile phone, is developed to realize gesture-based real-time interaction. With the device worn on the forearm, the user is able to manipulate a mobile phone using 19 predefined gestures or even personalized ones. Results suggest that the developed prototype responded to each gesture instruction within 300 ms on the mobile phone, with the average accuracy of 95.0% in user-dependent testing and 89.6% in user-independent testing. Such performance during the interaction testing, along with positive user experience questionnaire feedback, demonstrates the utility of the framework.",
Adaptive Neural Network Output Feedback Control for Stochastic Nonlinear Systems With Unknown Dead-Zone and Unmodeled Dynamics,"This paper discusses the problem of adaptive neural network output feedback control for a class of stochastic nonlinear strict-feedback systems. The concerned systems have certain characteristics, such as unknown nonlinear uncertainties, unknown dead-zones, unmodeled dynamics and without the direct measurements of state variables. In this paper, the neural networks (NNs) are employed to approximate the unknown nonlinear uncertainties, and then by representing the dead-zone as a time-varying system with a bounded disturbance. An NN state observer is designed to estimate the unmeasured states. Based on both backstepping design technique and a stochastic small-gain theorem, a robust adaptive NN output feedback control scheme is developed. It is proved that all the variables involved in the closed-loop system are input-state-practically stable in probability, and also have robustness to the unmodeled dynamics. Meanwhile, the observer errors and the output of the system can be regulated to a small neighborhood of the origin by selecting appropriate design parameters. Simulation examples are also provided to illustrate the effectiveness of the proposed approach.",
Achieving k-Barrier Coverage in Hybrid Directional Sensor Networks,"Barrier coverage is a critical issue in wireless sensor networks for security applications (e.g., border protection) where directional sensors (e.g., cameras) are becoming more popular than omni-directional scalar sensors (e.g., microphones). However, barrier coverage cannot be guaranteed after initial random deployment of sensors, especially for directional sensors with limited sensing angles. In this paper, we study how to efficiently use mobile sensors to achieve
k
-barrier coverage. In particular, two problems are studied under two scenarios. First, when only the stationary sensors have been deployed, what is the minimum number of mobile sensors required to form
k
-barrier coverage? Second, when both the stationary and mobile sensors have been pre-deployed, what is the maximum number of barriers that could be formed? To solve these problems, we introduce a novel concept of weighted barrier graph (WBG) and prove that determining the minimum number of mobile sensors required to form
k
-barrier coverage is related with finding
k
vertex-disjoint paths with the minimum total length on the WBG. With this observation, we propose an optimal solution and a greedy solution for each of the two problems. Both analytical and experimental studies demonstrate the effectiveness of the proposed algorithms.","Mobile communication,
Sensors,
Mobile computing,
Cameras,
Algorithm design and analysis,
Wireless sensor networks"
Secure Degrees of Freedom of One-Hop Wireless Networks,"We study the secure degrees of freedom (d.o.f.) of one-hop wireless networks by considering four fundamental wireless network structures: 1) Gaussian wiretap channel; 2) Gaussian broadcast channel with confidential messages; 3) Gaussian interference channel with confidential messages; and 4) Gaussian multiple access wiretap channel. The secrecy capacity of the canonical Gaussian wiretap channel does not scale with the transmit power, and hence, the secure d.o.f. of the Gaussian wiretap channel with no helpers is zero. It has been known that a strictly positive secure d.o.f. can be obtained in the Gaussian wiretap channel by using a helper, which sends structured cooperative signals. We show that the exact secure d.o.f. of the Gaussian wiretap channel with a helper is 1/2. Our achievable scheme is based on real interference alignment and cooperative jamming, which renders the message signal and the cooperative jamming signal separable at the legitimate receiver, but aligns them perfectly at the eavesdropper preventing any reliable decoding of the message signal. Our converse is based on two key lemmas. The first lemma quantifies the secrecy penalty by showing that the net effect of an eavesdropper on the system is that it eliminates one of the independent channel inputs. The second lemma quantifies the role of a helper by developing a direct relationship between the cooperative jamming signal of a helper and the message rate. We extend this result to the case of M helpers, and show that the exact secure d.o.f. in this case is M/M+1.We then generalize this approach to more general network structures with multiple messages. We show that the sum secure d.o.f. of the Gaussian broadcast channel with confidential messages and M helpers is 1, the sum secure d.o.f. of the twouser interference channel with confidential messages is 2/3, the sum secure d.o.f. of the two-user interference channel with confidential messages and M helpers is 1, and the sum secure d.o.f. of the K-user multiple access wiretap channel is K(K-1)/K(K-1)+1.","Jamming,
Transmitters,
Receivers,
Interference channels,
Upper bound,
Channel models,
Entropy"
Opportunities and challenges for data center demand response,"This paper surveys the opportunities and challenges in an emerging area of research that has the potential to significantly ease the incorporation of renewable energy into the grid as weil as electric power peak-load shaving: data center demand response. Data center demand response sits at the intersection of two growing fields: energy efficient data centers and demand response in the smart grid. As such, the literature related to data center demand response is sprinkled across multiple areas and worked on by diverse groups. Our goal in this survey is to demonstrate the potential of the field while also summarizing the progress that has been made and the challenges that remain.","Load management,
Electricity,
Energy storage,
Pricing,
Electric potential,
Renewable energy sources,
Data models"
"Improving Fairness, Efficiency, and Stability in HTTP-Based Adaptive Video Streaming With Festive","Modern video players today rely on bit-rate adaptation in order to respond to changing network conditions. Past measurement studies have identified issues with today's commercial players when multiple bit-rate-adaptive players share a bottleneck link with respect to three metrics: fairness, efficiency, and stability. Unfortunately, our current understanding of why these effects occur and how they can be mitigated is quite limited. In this paper, we present a principled understanding of bit-rate adaptation and analyze several commercial players through the lens of an abstract player model consisting of three main components: bandwidth estimation, bit-rate selection, and chunk scheduling. Using framework, we identify the root causes of several undesirable interactions that arise as a consequence of overlaying the video bit-rate adaptation over HTTP. Building on these insights, we develop a suite of techniques that can systematically guide the tradeoffs between stability, fairness, and efficiency and thus lead to a general framework for robust video adaptation. We pick one concrete instance from this design space and show that it significantly outperforms today's commercial players on all three key metrics across a range of experimental scenarios.",
Web Service Recommendation via Exploiting Location and QoS Information,"Web services are integrated software components for the support of interoperable machine-to-machine interaction over a network. Web services have been widely employed for building service-oriented applications in both industry and academia in recent years. The number of publicly available Web services is steadily increasing on the Internet. However, this proliferation makes it hard for a user to select a proper Web service among a large amount of service candidates. An inappropriate service selection may cause many problems (e.g., ill-suited performance) to the resulting applications. In this paper, we propose a novel collaborative filtering-based Web service recommender system to help users select services with optimal Quality-of-Service (QoS) performance. Our recommender system employs the location information and QoS values to cluster users and services, and makes personalized service recommendation for users based on the clustering results. Compared with existing service recommendation methods, our approach achieves considerable improvement on the recommendation accuracy. Comprehensive experiments are conducted involving more than 1.5 million QoS records of real-world Web services to demonstrate the effectiveness of our approach.","Web services,
Quality of service,
Time factors,
Prediction algorithms,
Recommender systems,
Algorithm design and analysis,
Collaboration"
Integer-Forcing Linear Receivers,"Linear receivers are often used to reduce the implementation complexity of multiple-antenna systems. In a traditional linear receiver architecture, the receive antennas are used to separate out the codewords sent by each transmit antenna, which can then be decoded individually. Although easy to implement, this approach can be highly suboptimal when the channel matrix is near singular. This paper develops a new linear receiver architecture that uses the receive antennas to create an effective channel matrix with integer-valued entries. Rather than attempting to recover transmitted codewords directly, the decoder recovers integer combinations of the codewords according to the entries of the effective channel matrix. The codewords are all generated using the same linear code, which guarantees that these integer combinations are themselves codewords. Provided that the effective channel is full rank, these integer combinations can then be digitally solved for the original codewords. This paper focuses on the special case where there is no coding across transmit antennas and no channel state information at the transmitter(s), which corresponds either to a multiuser uplink scenario or to single-user V-BLAST encoding. In this setting, the proposed integer-forcing linear receiver significantly outperforms conventional linear architectures such as the zero forcing and linear minimum mean-squared error receiver. In the high signal-to-noise ratio regime, the proposed receiver attains the optimal diversity-multiplexing tradeoff for the standard multiple-input multiple-output (MIMO) channel with no coding across transmit antennas. It is further shown that in an extended MIMO model with interference, the integer-forcing linear receiver achieves the optimal generalized degrees of freedom.","Decoding,
MIMO,
Signal to noise ratio,
Joints,
Complexity theory,
Receiving antennas"
Quasi-Static Multiple-Antenna Fading Channels at Finite Blocklength,"This paper investigates the maximal achievable rate for a given blocklength and error probability over quasi-static multiple-input multiple-output fading channels, with and without channel state information at the transmitter and/or the receiver. The principal finding is that outage capacity, despite being an asymptotic quantity, is a sharp proxy for the finite-blocklength fundamental limits of slow-fading channels. Specifically, the channel dispersion is shown to be zero regardless of whether the fading realizations are available at both transmitter and receiver, at only one of them, or at neither of them. These results follow from analytically tractable converse and achievability bounds. Numerical evaluation of these bounds verifies that zero dispersion may indeed imply fast convergence to the outage capacity as the blocklength increases. In the example of a particular 1 × 2 single-input multiple-output Rician fading channel, the blocklength required to achieve 90% of capacity is about an order of magnitude smaller compared with the blocklength required for an AWGN channel with the same capacity. For this specific scenario, the coding/decoding schemes adopted in the LTE-Advanced standard are benchmarked against the finite-blocklength achievability and converse bounds.","Receivers,
Transmitters,
Decoding,
Error probability,
MIMO,
Rayleigh channels"
Computer-Aided Detection of Prostate Cancer in MRI,"Prostate cancer is one of the major causes of cancer death for men in the western world. Magnetic resonance imaging (MRI) is being increasingly used as a modality to detect prostate cancer. Therefore, computer-aided detection of prostate cancer in MRI images has become an active area of research. In this paper we investigate a fully automated computer-aided detection system which consists of two stages. In the first stage, we detect initial candidates using multi-atlas-based prostate segmentation, voxel feature extraction, classification and local maxima detection. The second stage segments the candidate regions and using classification we obtain cancer likelihoods for each candidate. Features represent pharmacokinetic behavior, symmetry and appearance, among others. The system is evaluated on a large consecutive cohort of 347 patients with MR-guided biopsy as the reference standard. This set contained 165 patients with cancer and 182 patients without prostate cancer. Performance evaluation is based on lesion-based free-response receiver operating characteristic curve and patient-based receiver operating characteristic analysis. The system is also compared to the prospective clinical performance of radiologists. Results show a sensitivity of 0.42, 0.75, and 0.89 at 0.1, 1, and 10 false positives per normal case. In clinical workflow the system could potentially be used to improve the sensitivity of the radiologist. At the high specificity reading setting, which is typical in screening situations, the system does not perform significantly different from the radiologist and could be used as an independent second reader instead of a second radiologist. Furthermore, the system has potential in a first-reader setting.",
Californium: Scalable cloud services for the Internet of Things with CoAP,"The Internet of Things (IoT) is expected to interconnect a myriad of devices. Emerging networking and backend support technology not only has to anticipate this dramatic increase in connected nodes, but also a change in traffic patterns. Instead of bulk data such as file sharing or multimedia streaming, IoT devices will primarily exchange real-time sensory and control data in small but numerous messages. Often cloud services will handle these data from a huge number of devices, and hence need to be extremely scalable to support conceivable large-scale IoT applications. To this end, we present a system architecture for IoT cloud services based on the Constrained Application Protocol (CoAP), which is primarily designed for systems of tiny, low-cost, resource-constrained IoT devices. Along with our system architecture, we systematically evaluate the performance of the new Web protocol in cloud environments. Our Californium (Cf) CoAP framework shows 33 to 64 times higher throughput than high-performance HTTP Web servers, which are the state of the art for classic cloud services. The results substantiate that the low overhead of CoAP does not only enable Web technology for lowcost IoT devices, but also significantly improves backend service scalability for vast numbers of connected devices.",
A New Selective Loop Bias Mapping Phase Disposition PWM With Dynamic Voltage Balance Capability for Modular Multilevel Converter,"This paper presents an improved phase disposition pulsewidth modulation (PWM) (PDPWM) for the modular multilevel converter (MMC) which is based on the selective loop bias mapping (SLBM) method. Its main idea is to change the bias of the PDPWM carrier wave cycling according to the balance situation of the system. This new modulation method can operate at symmetric condition to generate an output voltage with as many as 2N + 1 levels, and by SLBM, the voltages of the upper/lower arm capacitors can be well balanced. Compared to carrier phase-shifted PWM, this method is more easily to be realized and has much stronger dynamic regulation ability. Specially, this method has no issues of sorting, which makes it suitable for MMC with a large number of submodules in one leg. With simulation and experiments, the validity of the proposed method has been shown.","Capacitors,
Pulse width modulation,
Indexes,
Voltage control,
Sorting,
Phase modulation"
Bag Constrained Structure Pattern Mining for Multi-Graph Classification,"This paper formulates a multi-graph learning task. In our problem setting, a bag contains a number of graphs and a class label. A bag is labeled positive if at least one graph in the bag is positive, and negative otherwise. In addition, the genuine label of each graph in a positive bag is unknown, and all graphs in a negative bag are negative. The aim of multi-graph learning is to build a learning model from a number of labeled training bags to predict previously unseen test bags with maximum accuracy. This problem setting is essentially different from existing multi-instance learning (MIL), where instances in MIL share well-defined feature values, but no features are available to represent graphs in a multi-graph bag. To solve the problem, we propose a Multi-Graph Feature based Learning (gMGFL) algorithm that explores and selects a set of discriminative subgraphs as features to transfer each bag into a single instance, with the bag label being propagated to the transferred instance. As a result, the multi-graph bags form a labeled training instance set, so generic learning algorithms, such as decision trees, can be used to derive learning models for multi-graph classification. Experiments and comparisons on real-world multi-graph tasks demonstrate the algorithm performance.",
Planning Active Distribution Networks Considering Multi-DG Configurations,"Planning distribution systems without considering the operation status of multiple distributed generation (DG) units could result in constraining the network, lowering the utilization of its assets and minimizing the total DG capacity that can be accommodated. In this paper, the impact of multiple DG configurations on the potential of active network management (ANM) schemes is firstly investigated. Secondly, the paper proposes a multi-configuration multi-period optimal power flow (OPF)-based technique (MMOPF) for assessing the maximum DG capacity under ANM schemes considering 1) variability of demand and generation profiles (multi-period scenarios), and 2) different operational status of DG units (multi-configurations). The results show that the availability of DGs at certain locations could critically impact the amount of DG capacity at other locations. If DGs are properly allocated and sized at certain locations up to the optimal limits, even with a “fit-and-forget” approach, the total connected DG capacity can be maximized, with minimum utilization of ANM schemes. However, exceeding these optimal limits may lead to minimizing the total DG penetration in the long term, impacting the system reliability due to the operational status of multiple DG units, and consequently, imposing more investments on ANM schemes to increase the amount of connected DG capacity.",
Sensorless High Order Sliding Mode Control of Induction Motors With Core Loss,"In this paper, a sensorless control scheme is presented for induction motors with core loss. First, a controller is designed using a high order sliding mode twisting algorithm, to track a desired rotor velocity signal and an optimal rotor flux modulus, minimizing the power loss in copper and core. Then, a super-twisting (ST) sliding mode observer for stator current is designed and the rotor flux is calculated, by means of the equivalent control method. Two methods for the rotor velocity estimation are then proposed. The first consists of a further super-twisting sliding mode observer for rotor fluxes, with the purpose of retrieving the back-electromotive force components by means of the equivalent control method. These components are functions of the rotor velocity which, hence, can be easily determined. The second method is based on a generalization of the phase-locked loop methodology. Finally, a simple Luenberger observer is designed, filtering the rotor velocity estimate and giving also an estimate of the load torque. The performance of the motor is verified by means of numeric simulations and experimental tests, where good tracking results are obtained.",
A Recurrent Neural Network for Solving Bilevel Linear Programming Problem,"In this brief, based on the method of penalty functions, a recurrent neural network (NN) modeled by means of a differential inclusion is proposed for solving the bilevel linear programming problem (BLPP). Compared with the existing NNs for BLPP, the model has the least number of state variables and simple structure. Using nonsmooth analysis, the theory of differential inclusions, and Lyapunov-like method, the equilibrium point sequence of the proposed NNs can approximately converge to an optimal solution of BLPP under certain conditions. Finally, the numerical simulations of a supply chain distribution model have shown excellent performance of the proposed recurrent NNs.",
iAware: Making Live Migration of Virtual Machines Interference-Aware in the Cloud,"Large-scale datacenters have been widely used to host cloud services, which are typically allocated to different virtual machines (VMs) through resource multiplexing across shared physical servers. Although recent studies have primarily focused on harnessing live migration of VMs to achieve load balancing and power saving among different servers, there has been little attention on the incurred performance interference and cost on both source and destination servers during and after such VM migration. To avoid potential violations of service-level-agreement (SLA) demanded by cloud applications, this paper proposes iAware, a lightweight interference-aware VM live migration strategy. It empirically captures the essential relationships between VM performance interference and key factors that are practically accessible through realistic experiments of benchmark workloads on a Xen virtualized cluster platform. iAware jointly estimates and minimizes both migration and co-location interference among VMs, by designing a simple multi-resource demand-supply model. Extensive experiments and complementary large-scale simulations are conducted to validate the performance gain and runtime overhead of iAware in terms of I/O and network throughput, CPU consumption, and scalability, compared to the traditional interference-unaware VM migration approaches. Moreover, we demonstrate that iAware is flexible enough to cooperate with existing VM scheduling or consolidation policies in a complementary manner, such that the load balancing or power saving can still be achieved without sacrificing performance.","Virtual machining,
Central Processing Unit,
Bandwidth,
Nonvolatile memory,
Cloud computing,
Degradation"
Capacitively Loaded Circularly Polarized Implantable Patch Antenna for ISM Band Biomedical Applications,"A single-fed miniaturized circularly polarized microstrip patch antenna is designed and experimentally demonstrated for industrial-scientific-medical (2.4-2.48 GHz) biomedical applications. The proposed antenna is designed by utilizing the capacitive loading on the radiator. Compared with the initial topology of the proposed antenna, the so-called square patch antenna with a center-square slot, the proposed method has the advantage of good size reduction and good polarization purity. The footprint of the proposed antenna is 10×10×1.27 mm3. The simulated impedance, axial ratio, and radiation pattern are studied and compared in two simulation models: cubic skin phantom and Gustav voxel human body. The effect of different body phantoms is discussed to evaluate the sensitivity of the proposed antenna. The effect of coaxial cable is also discussed. Two typical approaches to address the biocompatibility issue for practical applications are reported as well. The simulated and measured impedance bandwidths in cubic skin phantom are 7.7% and 10.2%, respectively. The performance of the communication link between the implanted CP antenna and the external antenna is also presented.","Patch antennas,
Microstrip antennas,
Antenna measurements,
Skin,
Dipole antennas,
Impedance"
Compressed Sensing Analog Front-End for Bio-Sensor Applications,"In a conventional bio-sensor, key signal features are acquired using Nyquist-rate analog-to-digital conversion without exploiting the typical bio-signal characteristic of sparsity in some domain (e.g., time, frequency, etc.). Compressed sensing (CS) is a signal processing paradigm that exploits this sparsity for commensurate power savings by enabling alias-free sub-Nyquist acquisition. In a severely energy constrained sensor, CS also eliminates the need for digital signal processing (DSP). A fully-integrated low-power CS analog front-end (CS-AFE) is described for an electrocardiogram (ECG) sensor. Switched-capacitor circuits are used to achieve high accuracy and low power. Implemented in 0.13 μm CMOS in 2×3 mm2, the prototype comprises a 384-bit Fibonacci-Galois hybrid linear feedback shift register and 64 digitally-selectable CS channels with a 6-bit C-2C MDAC/integrator and a 10-bit C-2C SAR ADC in each. Clocked at 2 kHz, the total power dissipation is 28 nW and 1.8 μW for one and 64 active channels, respectively. CS-AFE enables compressive sampling of bio-signals that are sparse in an arbitrary domain.","Electrocardiography,
Compressed sensing,
Accuracy,
Receivers,
Vectors,
Noise,
Sparse matrices"
A Survey on CPG-Inspired Control Models and System Implementation,"This paper surveys the developments of the last 20 years in the field of central pattern generator (CPG) inspired locomotion control, with particular emphasis on the fast emerging robotics-related applications. Functioning as a biological neural network, CPGs can be considered as a group of coupled neurons that generate rhythmic signals without sensory feedback; however, sensory feedback is needed to shape the CPG signals. The basic idea in engineering endeavors is to replicate this intrinsic, computationally efficient, distributed control mechanism for multiple articulated joints, or multi-DOF control cases. In terms of various abstraction levels, existing CPG control models and their extensions are reviewed with a focus on the relative advantages and disadvantages of the models, including ease of design and implementation. The main issues arising from design, optimization, and implementation of the CPG-based control as well as possible alternatives are further discussed, with an attempt to shed more light on locomotion control-oriented theories and applications. The design challenges and trends associated with the further advancement of this area are also summarized.","Neurons,
Biological system modeling,
Oscillators,
Mathematical model,
Adaptation models,
Robot sensing systems"
"The Approximate Sum Capacity of the Symmetric Gaussian
K
-User Interference Channel","Interference alignment has emerged as a powerful tool in the analysis of multiuser networks. Despite considerable recent progress, the capacity region of the Gaussian K-user interference channel is still unknown in general, in part due to the challenges associated with alignment on the signal scale using lattice codes. This paper develops a new framework for lattice interference alignment, based on the compute-and-forward approach. Within this framework, each receiver decodes by first recovering two or more linear combinations of the transmitted codewords with integer-valued coefficients and then solving these linear combinations for its desired codeword. For the special case of symmetric channel gains, this framework is used to derive the approximate sum capacity of the Gaussian interference channel, up to an explicitly defined outage set of the channel gains. The key contributions are the capacity lower bounds for the weak through strong interference regimes, where each receiver should jointly decode its own codeword along with part of the interfering codewords. As part of the analysis, it is shown that decoding K linear combinations of the codewords can approach the sum capacity of the K-user Gaussian multiple-access channel up to a gap of no more than K/2 log K bits.","Receivers,
Lattices,
Interference channels,
Signal to noise ratio,
Transmitters,
Decoding"
An efficiently solvable quadratic program for stabilizing dynamic locomotion,"We describe a whole-body dynamic walking controller implemented as a convex quadratic program. The controller solves an optimal control problem using an approximate value function derived from a simple walking model while respecting the dynamic, input, and contact constraints of the full robot dynamics. By exploiting sparsity and temporal structure in the optimization with a custom active-set algorithm, we surpass the performance of the best available off-the-shelf solvers and achieve 1kHz control rates for a 34-DOF humanoid. We describe applications to balancing and walking tasks using the simulated Atlas robot in the DARPA Virtual Robotics Challenge.",
Efficient Closed-Form Algorithms for AOA Based Self-Localization of Sensor Nodes Using Auxiliary Variables,"Node self-localization is a key research topic for wireless sensor networks (WSNs). There are two main algorithms, the triangulation method and the maximum likelihood (ML) estimator, for angle of arrival (AOA) based self-localization. The ML estimator requires a good initialization close to the true location to avoid divergence, while the triangulation method cannot obtain the closed-form solution with high efficiency. In this paper, we develop a set of efficient closed-form AOA based self-localization algorithms using auxiliary variables based methods. First, we formulate the self-localization problem as a linear least squares problem using auxiliary variables. Based on its closed-form solution, a new auxiliary variables based pseudo-linear estimator (AVPLE) is developed. By analyzing its estimation error, we present a bias compensated AVPLE (BCAVPLE) to reduce the estimation error. Then we develop a novel BCAVPLE based weighted instrumental variable (BCAVPLE-WIV) estimator to achieve asymptotically unbiased estimation of locations and orientations of unknown nodes based on prior knowledge of the AOA noise variance. In the case that the AOA noise variance is unknown, a new AVPLE based WIV (AVPLE-WIV) estimator is developed to localize the unknown nodes. Also, we develop an autonomous coordinate rotation (ACR) method to overcome the tangent instability of the proposed algorithms when the orientation of the unknown node is near π/2. We also derive the Cramér-Rao lower bound (CRLB) of the ML estimator. Extensive simulations demonstrate that the new algorithms achieve much higher localization accuracy than the triangulation method and avoid local minima and divergence in iterative ML estimators.",
Opportunistic Sensing in Wireless Sensor Networks: Theory and Application,"In real world, wireless heterogeneous sensor network (HSN) design and information integration are necessary in different applications. Traditionally, wireless sensor networks information integration is set up to passively fuse all received data. Such an approach is computationally challenging and operationally ineffective because improvements in information accuracy are not guaranteed. Opportunistic Sensing (OS) refers to a paradigm for signal and information processing in which a network of sensing systems can automatically discover and select sensor platforms based on an operational scenario. In this paper, we propose theory and algorithms of OS to simplify the HSN design and promote more efficient information integration. We propose an information theoretical criterion for opportunistic sensing in HSN, and show that HSN with correlated modalities needs less number of codewords than that with independent modalities. Our OS algorithm advances autonomous sensing that not only ensures effective utilization of sensing assets but also provides robust optimal performance. We apply our OS algorithm to radar sensor networks for surveillance and monitoring, and show that our approach works very well and much better than other approaches.",
Ichnaea: A Low-Overhead Robust WLAN Device-Free Passive Localization System,"WLAN Device-free passive (DfP) indoor localization is an emerging technology enabling the localization of entities that do not carry any devices nor participate actively in the localization process using the already installed wireless infrastructure. Current state-of-the-art DfP localization systems require a large overhead to construct an RF profile for the environment, that is then used as a reference for either motion detection or tracking. These profiles are also not robust to changes in the environment, requiring frequent manual maintenance or reconstruction. In this paper, we present the design, implementation and evaluation of Ichnaea, an accurate, robust, and low-overhead DfP localization system. Ichnaea uses a lightweight, typically two minutes, training period to learn the silence profile of the environment. It then applies statistical anomaly detection techniques and particle filtering, while adapting to changes in the environment, to provide its localization capabilities using standard WiFi hardware. Evaluation of Ichnaea in three typical testbeds with a side-by-side comparison to the state-of-the-art WLAN DfP systems shows that it can achieve a worst case median distance error of 2.5 m while requiring significantly lower deployment overhead and being robust to environment changes.","Tracking,
Robustness,
Wireless LAN,
Motion detection,
Monitoring,
Vectors,
Wireless communication"
Optimized Product Quantization,"Product quantization (PQ) is an effective vector quantization method. A product quantizer can generate an exponentially large codebook at very low memory/time cost. The essence of PQ is to decompose the high-dimensional vector space into the Cartesian product of subspaces and then quantize these subspaces separately. The optimal space decomposition is important for the PQ performance, but still remains an unaddressed issue. In this paper, we optimize PQ by minimizing quantization distortions w.r.t the space decomposition and the quantization codebooks. We present two novel solutions to this challenging optimization problem. The first solution iteratively solves two simpler sub-problems. The second solution is based on a Gaussian assumption and provides theoretical analysis of the optimality. We evaluate our optimized product quantizers in three applications: (i) compact encoding for exhaustive ranking [1], (ii) building inverted multi-indexing for non-exhaustive search [2], and (iii) compacting image representations for image retrieval [3]. In all applications our optimized product quantizers outperform existing solutions.","Quantization (signal),
Vectors,
Artificial neural networks,
Optimization,
Encoding,
Indexing,
Linear programming"
Broadcast and Weight: An Integrated Network For Scalable Photonic Spike Processing,"We propose an on-chip optical architecture to support massive parallel communication among high-performance spiking laser neurons. Designs for a network protocol, computational element, and waveguide medium are described, and novel methods are considered in relation to prior research in optical on-chip networking, neural networking, and computing. Broadcast-and-weight is a new approach for combining neuromorphic processing and optoelectronic physics, a pairing that is found to yield a variety of advantageous features. We discuss properties and design considerations for architectures for scalable wavelength reuse and biologically relevant organizational capabilities, in addition to aspects of practical feasibility. Given recent developments commercial photonic systems integration and neuromorphic computing, we suggest that a novel approach to photonic spike processing represents a promising opportunity in unconventional computing.",
Cloud Computing: Opportunities and Challenges,"We live and operate in the world of computing and computers. The Internet has drastically changed the computing world from the concept of parallel computing to distributed computing to grid computing and now to cloud computing. Cloud computing is a new wave in the field of information technology. Some see it as an emerging field in computer science. It consists of a set of resources and services offered through the Internet. Hence, ""cloud computing"" is also called ""Internet computing."" The word ""cloud"" is a metaphor for describing the Web as a space where computing has been preinstalled and exists as a service. Operating systems, applications, storage, data, and processing capacity all exist on the Web, ready to be shared among users. Figure 1 shows a conceptual diagram of cloud computing.","Cloud computing,
Parallel processing,
Technological innovation"
Near-Optimal Sensor Placement for Linear Inverse Problems,"A classic problem is the estimation of a set of parameters from measurements collected by only a few sensors. The number of sensors is often limited by physical or economical constraints and their placement is of fundamental importance to obtain accurate estimates. Unfortunately, the selection of the optimal sensor locations is intrinsically combinatorial and the available approximation algorithms are not guaranteed to generate good solutions in all cases of interest. We propose FrameSense, a greedy algorithm for the selection of optimal sensor locations. The core cost function of the algorithm is the frame potential, a scalar property of matrices that measures the orthogonality of its rows. Notably, FrameSense is the first algorithm that is near-optimal in terms of mean square error, meaning that its solution is always guaranteed to be close to the optimal one. Moreover, we show with an extensive set of numerical experiments that FrameSense achieves state-of-the-art performance while having the lowest computational cost, when compared to other greedy methods.",
Stability Analysis of Polynomial-Fuzzy-Model-Based Control Systems With Mismatched Premise Membership Functions,"This paper investigates the stability of polynomial-fuzzy-model-based (PFMB) control system, which is formed by a polynomial fuzzy model and a polynomial fuzzy controller connected in a closed loop. To enhance the design flexibility, the number of rules and the shape of premise membership functions of the polynomial fuzzy controller are considered to be chosen freely and are different from those of the polynomial fuzzy model, however, which make the stability analysis more difficult and potentially lead to conservative stability analysis result. A sum-of-squares (SOS)-based stability analysis approach using the Lyapunov stability theory is proposed to investigate the stability of the PFMB control systems and synthesize the polynomial fuzzy controller. To facilitate the stability analysis and relax the stability analysis result, the property of the membership functions and the boundary information of the membership grades and premise variables are taken into account in the stability analysis and incorporated into the SOS-based stability conditions. A simulation example is given to illustrate the effectiveness of the proposed approach.","Stability analysis,
Polynomials,
Shape,
Control systems,
Facsimile,
Electronic mail,
Computer science"
A Level-Crossing Based QRS-Detection Algorithm for Wearable ECG Sensors,"In this paper, an asynchronous analog-to-information conversion system is introduced for measuring the RR intervals of the electrocardiogram (ECG) signals. The system contains a modified level-crossing analog-to-digital converter and a novel algorithm for detecting the R-peaks from the level-crossing sampled data in a compressed volume of data. Simulated with MIT-BIH Arrhythmia Database, the proposed system delivers an average detection accuracy of 98.3%, a sensitivity of 98.89%, and a positive prediction of 99.4%. Synthesized in 0.13 μm CMOS technology with a 1.2 V supply voltage, the overall system consumes 622 nW with core area of 0.136 mm2 which make it suitable for wearable wireless ECG sensors in body-sensor networks.",
"Electric Vehicle Charging Station Placement: Formulation, Complexity, and Solutions","To enhance environmental sustainability, many countries will electrify their transportation systems in their future smart city plans, so the number of electric vehicles (EVs) running in a city will grow significantly. There are many ways to recharge EVs' batteries and charging stations will be considered as the main source of energy. The locations of charging stations are critical; they should not only be pervasive enough such that an EV anywhere can easily access a charging station within its driving range, but also widely spread so that EVs can cruise around the whole city upon being recharged. Based on these new perspectives, we formulate the EV charging station placement problem (EVCSPP) in this paper. We prove that the problem is nondeterministic polynomial-time hard. We also propose four solution methods to tackle EVCSPP, and evaluate their performance on various artificial and practical cases. As verified by the simulation results, the methods have their own characteristics and they are suitable for different situations depending on the requirements for solution quality, algorithmic efficiency, problem size, nature of the algorithm, and existence of system prerequisite.","Charging stations,
Urban planning,
Complexity theory,
Mathematical model,
Electric vehicles"
Face Super-Resolution via Multilayer Locality-Constrained Iterative Neighbor Embedding and Intermediate Dictionary Learning,"Based on the assumption that low-resolution (LR) and high-resolution (HR) manifolds are locally isometric, the neighbor embedding super-resolution algorithms try to preserve the geometry (reconstruction weights) of the LR space for the reconstructed HR space, but neglect the geometry of the original HR space. Due to the degradation process of the LR image (e.g., noisy, blurred, and down-sampled), the neighborhood relationship of the LR space cannot reflect the truth. To this end, this paper proposes a coarse-to-fine face super-resolution approach via a multilayer locality-constrained iterative neighbor embedding technique, which intends to represent the input LR patch while preserving the geometry of original HR space. In particular, we iteratively update the LR patch representation and the estimated HR patch, and meanwhile an intermediate dictionary learning scheme is employed to bridge the LR manifold and original HR manifold. The proposed method can faithfully capture the intrinsic image degradation shift and enhance the consistency between the reconstructed HR manifold and the original HR manifold. Experiments with application to face super-resolution on the CAS-PEAL-R1 database and real-world images demonstrate the power of the proposed algorithm.","Face,
Training,
Image resolution,
Manifolds,
Geometry,
Image reconstruction,
Dictionaries"
A Distance-Based Ranking Model Estimation of Distribution Algorithm for the Flowshop Scheduling Problem,"The aim of this paper is two-fold. First, we introduce a novel general estimation of distribution algorithm to deal with permutation-based optimization problems. The algorithm is based on the use of a probabilistic model for permutations called the generalized Mallows model. In order to prove the potential of the proposed algorithm, our second aim is to solve the permutation flowshop scheduling problem. A hybrid approach consisting of the new estimation of distribution algorithm and a variable neighborhood search is proposed. Conducted experiments demonstrate that the proposed algorithm is able to outperform the state-of-the-art approaches. Moreover, from the 220 benchmark instances tested, the proposed hybrid approach obtains new best known results in 152 cases. An in-depth study of the results suggests that the successful performance of the introduced approach is due to the ability of the generalized Mallows estimation of distribution algorithm to discover promising regions in the search space.",
Reversible Data Hiding in Encrypted JPEG Bitstream,"This correspondence proposes a framework of reversible data hiding (RDH) in an encrypted JPEG bitstream. Unlike existing RDH methods for encrypted spatial-domain images, the proposed method aims at encrypting a JPEG bitstream into a properly organized structure, and embedding a secret message into the encrypted bitstream by slightly modifying the JPEG stream. We identify usable bits suitable for data hiding so that the encrypted bitstream carrying secret data can be correctly decoded. The secret message bits are encoded with error correction codes to achieve a perfect data extraction and image recovery. The encryption and embedding are controlled by encryption and embedding keys respectively. If a receiver has both keys, the secret bits can be extracted by analyzing the blocking artifacts of the neighboring blocks, and the original bitstream perfectly recovered. In case the receiver only has the encryption key, he/she can still decode the bitstream to obtain the image with good quality without extracting the hidden data.",
Semi-Global Consensus of Nonlinear Second-Order Multi-Agent Systems With Measurement Output Feedback,"This note addresses a leader-follower consensus control problem for second-order multi-agent systems in a complicated scenario where the agent states are partially measurable and the agent dynamics are intrinsically nonlinear. More specifically, when the states of an agent are not fully measurable, a measurement output is thus defined. As a typical example, the measurement output is defined as the position of an agent while its velocity is unmeasurable. We propose a measurement output feedback controller with a dynamic observer for the unmeasurable states. Moreover, the proposed controller with sufficiently large but explicitly designed gains is able to deal with system nonlinearities when the region of attraction is semi-globally specified.",
Energy Management of Fuel Cell/Battery/Supercapacitor Hybrid Power Sources Using Model Predictive Control,"Well known as an efficient and eco-friendly power source, fuel cell, unfortunately, offers slow dynamics. When attached as primary energy source in a vehicle, fuel cell would not be able to respond to abrupt load variations. Supplementing battery and/or supercapacitor to the system will provide a solution to this shortcoming. On the other hand, a current regulation that is vital for lengthening time span of the energy storage system is needed. This can be accomplished by keeping fuel cell's and batteries' current slope in reference to certain values, as well as attaining a stable dc output voltage. For that purpose, a feedback control system for regulating the hybrid of fuel cell, batteries, and supercapacitor was constructed for this study. Output voltage of the studied hybrid power sources (HPS) was administered by assembling three dc-dc converters comprising two bidirectional converters and one boost converter. Current/voltage output of fuel cell was regulated by boost converter, whereas the bidirectional converters regulated battery and supercapacitor. Reference current for each converter was produced using Model Predictive Control (MPC) and subsequently tracked using hysteresis control. These functions were done on a controller board of a dSPACE DS1104. Subsequently, on a test bench made up from 6 V, 4.5 Ah battery and 7.5 V, 120 F supercapacitor together with a fuel cell of 50 W, 10 A, experiment was conducted. Results show that constructing a control system to restrict fuel cell's and batteries' current slope and maintaining dc bus voltage in accordance with the reference values using MPC was feasible and effectively done.","Fuel cells,
Batteries,
Supercapacitors,
DC-DC power converters,
Hysteresis,
Predictive control,
Time factors,
Energy management"
Defining architecture components of the Big Data Ecosystem,"Big Data are becoming a new technology focus both in science and in industry and motivate technology shift to data centric architecture and operational models. There is a vital need to define the basic information/semantic models, architecture components and operational models that together comprise a so-called Big Data Ecosystem. This paper discusses a nature of Big Data that may originate from different scientific, industry and social activity domains and proposes improved Big Data definition that includes the following parts: Big Data properties (also called Big Data 5V: Volume, Velocity, Variety, Value and Veracity), data models and structures, data analytics, infrastructure and security. The paper discusses paradigm change from traditional host or service based to data centric architecture and operational models in Big Data. The Big Data Architecture Framework (BDAF) is proposed to address all aspects of the Big Data Ecosystem and includes the following components: Big Data Infrastructure, Big Data Analytics, Data structures and models, Big Data Lifecycle Management, Big Data Security. The paper analyses requirements to and provides suggestions how the mentioned above components can address the main Big Data challenges. The presented work intends to provide a consolidated view of the Big Data phenomena and related challenges to modern technologies, and initiate wide discussion.","Big data,
Data models,
Computer architecture,
Security,
Biological system modeling,
Ecosystems,
Industries"
"Polyphase-coded FM (PCFM) radar waveforms, part II: optimization","This paper addresses polyphase code optimization with respect to the nonlinear frequency modulation waveform generated by the continuous phase modulation implementation. A greedy search leveraging the complementary metrics of peak sidelobe level, integrated sidelobe level, and spectral content yield extremely low range sidelobes relative to waveform time-bandwidth product. Transmitter distortion is also incorporated into the optimization via modeling and actual hardware. Thus the physical radar emission can be designed to address spectrum management and enable the physical realization of advanced waveform-diverse schemes.",
Adaptive Neural Network Control of a Fully Actuated Marine Surface Vessel With Multiple Output Constraints,"In this brief, we investigate the control problem of tracking a desired trajectory for a fully actuated marine surface vessel considering multiple outputs constraints. To prevent multiple output constraints violation, a symmetric barrier Lyapunov function (SBLF) is employed. Backstepping, in combination with adaptive feedback approximation techniques, is introduced to design an adaptive neural network control. Experimental simulations are provided to evaluate the feasibility and effectiveness of the proposed controller. Compared to the adaptive neural network control without multiple output constraints, the proposed adaptive neural network using the SBLF can guarantee that all the outputs remain bounded.","Trajectory,
Approximation methods,
Artificial neural networks,
Control design,
Vectors,
Adaptive systems"
Incentive Mechanism for Demand Side Management in Smart Grid Using Auction,"Smart pricing methods using auction mechanism allow more information exchange between users and providers, and they can meet users' energy demand at a low cost of grid operation, which contributes to the economic and environmental benefit in smart grid. However, when asked to report their energy demand, users may have an incentive to cheat in order to consume more while paying less, causing extra costs for grid operation. So it is important to ensure truthfulness among users for demand side management. In this paper, we propose an efficient pricing method that can prevent users' cheating. In the proposed model, the smart meter can record user's consumption information and communicate with the energy provider's terminal. Users' preferences and consumption patterns are modeled in form of a utility function. Based on this, we propose an enhanced AGV (Arrow-d'Aspremont-Gerard-Varet) mechanism to ensure truthfulness. In this incentive method, user's payment is related to its consumption credit. One will be punished to pay extra if there is a cheat record in its consumption history. We prove that the enhanced AGV mechanism can achieve the basic qualifications: incentive compatibility, individual rationality and budget balance. Simulation results confirm that the enhanced AGV mechanism can ensure truth-telling, and benefit both users and energy providers.","Power demand,
Pricing,
Electricity,
Vectors,
Games,
Resource management,
Power distribution"
Adaptive Synchronization for Neutral-Type Neural Networks with Stochastic Perturbation and Markovian Switching Parameters,"In this paper, the problem of adaptive synchronization is investigated for stochastic neural networks of neutral-type with Markovian switching parameters. Using the M-matrix approach and the stochastic analysis method, some sufficient conditions are obtained to ensure three kinds of adaptive synchronization for the stochastic neutral-type neural networks. These three kinds of adaptive synchronization include the almost sure asymptotical synchronization, exponential synchronization in pth moment and almost sure exponential synchronization. Some numerical examples are provided to illustrate the effectiveness and potential of the proposed design techniques.",
Energy-Aware Virtual Network Embedding,"Virtual network embedding, which means mapping virtual networks requested by users to a shared substrate network maintained by an Internet service provider, is a key function that network virtualization needs to provide. Prior work on virtual network embedding has primarily focused on maximizing the revenue of the Internet service provider and did not consider the energy cost in accommodating such requests. As energy cost is more than half of the operating cost of the substrate networks, while trying to accommodate more virtual network requests, minimizing energy cost is critical for infrastructure providers. In this paper, we make the first effort toward energy-aware virtual network embedding. We first propose an energy cost model and formulate the energy-aware virtual network embedding problem as an integer linear programming problem. We then propose two efficient energy-aware virtual network embedding algorithms: a heuristic-based algorithm and a particle-swarm-optimization-technique-based algorithm. We implemented our algorithms in C++ and performed side-by-side comparison with prior algorithms. The simulation results show that our algorithms significantly reduce the energy cost by up to 50% over the existing algorithm for accommodating the same sequence of virtual network requests.","Substrates,
Electricity,
Bandwidth,
Tin,
Power demand,
Algorithm design and analysis,
Heuristic algorithms"
A Novel Joint Data-Hiding and Compression Scheme Based on SMVQ and Image Inpainting,"In this paper, we propose a novel joint data-hiding and compression scheme for digital images using side match vector quantization (SMVQ) and image inpainting. The two functions of data hiding and image compression can be integrated into one single module seamlessly. On the sender side, except for the blocks in the leftmost and topmost of the image, each of the other residual blocks in raster-scanning order can be embedded with secret data and compressed simultaneously by SMVQ or image inpainting adaptively according to the current embedding bit. Vector quantization is also utilized for some complex blocks to control the visual distortion and error diffusion caused by the progressive compression. After segmenting the image compressed codes into a series of sections by the indicator bits, the receiver can achieve the extraction of secret bits and image decompression successfully according to the index values in the segmented sections. Experimental results demonstrate the effectiveness of the proposed scheme.","data encapsulation,
image coding,
image segmentation,
vector quantisation"
Discriminative Object Tracking via Sparse Representation and Online Dictionary Learning,"We propose a robust tracking algorithm based on local sparse coding with discriminative dictionary learning and new keypoint matching schema. This algorithm consists of two parts: the local sparse coding with online updated discriminative dictionary for tracking (SOD part), and the keypoint matching refinement for enhancing the tracking performance (KP part). In the SOD part, the local image patches of the target object and background are represented by their sparse codes using an over-complete discriminative dictionary. Such discriminative dictionary, which encodes the information of both the foreground and the background, may provide more discriminative power. Furthermore, in order to adapt the dictionary to the variation of the foreground and background during the tracking, an online learning method is employed to update the dictionary. The KP part utilizes refined keypoint matching schema to improve the performance of the SOD. With the help of sparse representation and online updated discriminative dictionary, the KP part are more robust than the traditional method to reject the incorrect matches and eliminate the outliers. The proposed method is embedded into a Bayesian inference framework for visual tracking. Experimental results on several challenging video sequences demonstrate the effectiveness and robustness of our approach.","Bayes methods,
dictionaries,
image coding,
image matching,
image representation,
image sequences,
learning (artificial intelligence),
object tracking,
video signal processing"
Risk-Sensitive Mean-Field Games,"In this paper, we study a class of risk-sensitive mean-field stochastic differential games. We show that under appropriate regularity conditions, the mean-field value of the stochastic differential game with exponentiated integral cost functional coincides with the value function satisfying a Hamilton -Jacobi- Bellman (HJB) equation with an additional quadratic term. We provide an explicit solution of the mean-field best response when the instantaneous cost functions are log-quadratic and the state dynamics are affine in the control. An equivalent mean-field risk-neutral problem is formulated and the corresponding mean-field equilibria are characterized in terms of backward-forward macroscopic McKean-Vlasov equations, Fokker-Planck-Kolmogorov equations, and HJB equations. We provide numerical examples on the mean field behavior to illustrate both linear and McKean-Vlasov dynamics.","Equations,
Games,
Stochastic processes,
Mathematical model,
Cost function,
Sociology,
Statistics"
Human Gait Recognition via Sparse Discriminant Projection Learning,"As an important biometric feature, human gait has great potential in video-surveillance-based applications. In this paper, we focus on the matrix representation-based human gait recognition and propose a novel discriminant subspace learning method called sparse bilinear discriminant analysis (SBDA). SBDA extends the recently proposed matrix-representation-based discriminant analysis methods to sparse cases. By introducing the L1 and L2 norms into the objective function of SBDA, two interrelated sparse discriminant subspaces can be obtained for gait feature extraction. Since the optimization problem has no closed-form solutions, an iterative method is designed to compute the optimal sparse subspace using the L1 and L2 norms sparse regression. Theoretical analyses reveal the close relationship between SBDA and previous matrix-representation-based discriminant analysis methods. Since each nonzero element in each subspace is selected from the most important variables/factors, SBDA is potential to perform equivalent to or even better than the state-of-the-art subspace learning methods in gait recognition. Moreover, using the strategy of SBDA plus linear discriminant analysis (LDA), we can further improve the performance. A set of experiments on the standard USF HumanID and CASIA gait databases demonstrate that the proposed SBDA and SBDA + LDA can obtain competitive performance.",
Nonlinearly Activated Neural Network for Solving Time-Varying Complex Sylvester Equation,"The Sylvester equation is often encountered in mathematics and control theory. For the general time-invariant Sylvester equation problem, which is defined in the domain of complex numbers, the Bartels-Stewart algorithm and its extensions are effective and widely used with an O(n3) time complexity. When applied to solving the time-varying Sylvester equation, the computation burden increases intensively with the decrease of sampling period and cannot satisfy continuous realtime calculation requirements. For the special case of the general Sylvester equation problem defined in the domain of real numbers, gradient-based recurrent neural networks are able to solve the time-varying Sylvester equation in real time, but there always exists an estimation error while a recently proposed recurrent neural network by Zhang et al. [this type of neural network is called Zhang neural network (ZNN)] converges to the solution ideally. The advancements in complex-valued neural networks cast light to extend the existing real-valued ZNN for solving the time-varying real-valued Sylvester equation to its counterpart in the domain of complex numbers. In this paper, a complex-valued ZNN for solving the complex-valued Sylvester equation problem is investigated and the global convergence of the neural network is proven with the proposed nonlinear complex-valued activation functions. Moreover, a special type of activation function with a core function, called sign-bi-power function, is proven to enable the ZNN to converge in finite time, which further enhances its advantage in online processing. In this case, the upper bound of the convergence time is also derived analytically. Simulations are performed to evaluate and compare the performance of the neural network with different parameters and activation functions. Both theoretical analysis and numerical simulations validate the effectiveness of the proposed method.","Equations,
Mathematical model,
Convergence,
Recurrent neural networks,
Acceleration,
Signal processing algorithms"
Knowledge Adaptation with PartiallyShared Features for Event DetectionUsing Few Exemplars,"Multimedia event detection (MED) is an emerging area of research. Previous work mainly focuses on simple event detection in sports and news videos, or abnormality detection in surveillance videos. In contrast, we focus on detecting more complicated and generic events that gain more users' interest, and we explore an effective solution for MED. Moreover, our solution only uses few positive examples since precisely labeled multimedia content is scarce in the real world. As the information from these few positive examples is limited, we propose using knowledge adaptation to facilitate event detection. Different from the state of the art, our algorithm is able to adapt knowledge from another source for MED even if the features of the source and the target are partially different, but overlapping. Avoiding the requirement that the two domains are consistent in feature types is desirable as data collection platforms change or augment their capabilities and we should be able to respond to this with little or no effort. We perform extensive experiments on real-world multimedia archives consisting of several challenging events. The results show that our approach outperforms several other state-of-the-art detection algorithms.",
Fast Global Image Smoothing Based on Weighted Least Squares,"This paper presents an efficient technique for performing a spatially inhomogeneous edge-preserving image smoothing, called fast global smoother. Focusing on sparse Laplacian matrices consisting of a data term and a prior term (typically defined using four or eight neighbors for 2D image), our approach efficiently solves such global objective functions. In particular, we approximate the solution of the memory- and computation-intensive large linear system, defined over a d -dimensional spatial domain, by solving a sequence of 1D subsystems. Our separable implementation enables applying a linear-time tridiagonal matrix algorithm to solve d three-point Laplacian matrices iteratively. Our approach combines the best of two paradigms, i.e., efficient edge-preserving filters and optimization-based smoothing. Our method has a comparable runtime to the fast edge-preserving filters, but its global optimization formulation overcomes many limitations of the local filtering approaches. Our method also achieves high-quality results as the state-of-the-art optimization-based techniques, but runs ~10-30 times faster. Besides, considering the flexibility in defining an objective function, we further propose generalized fast algorithms that perform Lγ norm smoothing (0 <; γ <;2) and support an aggregated (robust) data term for handling imprecise data constraints. We demonstrate the effectiveness and efficiency of our techniques in a range of image processing and computer graphics applications.","Smoothing methods,
Linear systems,
Sparse matrices,
Image edge detection,
Laplace equations,
Runtime,
Linear programming"
"Stronger, Smarter, Softer: Next-Generation Wearable Robots","Exosuits show much promise as a method for augmenting the body with lightweight, portable, and compliant wearable systems. We envision that such systems can be further refined so that they can be sufficiently low profile to fit under a wearer's existing clothing. Our focus is on creating an assistive device that provides a fraction of the nominal biological torques and does not provide external load transfer. In early work, we showed that the system can substantially maintain normal biomechanics and positively affect a wearer's metabolic rate. Many basic fundamental research and development challenges remain in actuator development, textile innovation, soft sensor development, human-machine interface (control), biomechanics, and physiology, which provides fertile ground for academic research in many disciplines. While we have focused on gait assistance thus far, numerous other applications are possible, including rehabilitation, upper body support, and assistance for other motions. We look forward to a future where wearable robots provide benefits for people across many areas of our society.","Robot sensing systems,
Wearable computers,
Exoskeletons,
Assistive devices,
Biomedical equipment,
Prosthetics,
Medical control systems,
Sensory aids,
Robot kinematics"
BRINT: Binary Rotation Invariant and Noise Tolerant Texture Classification,"In this paper, we propose a simple, efficient, yet robust multiresolution approach to texture classification-binary rotation invariant and noise tolerant (BRINT). The proposed approach is very fast to build, very compact while remaining robust to illumination variations, rotation changes, and noise. We develop a novel and simple strategy to compute a local binary descriptor based on the conventional local binary pattern (LBP) approach, preserving the advantageous characteristics of uniform LBP. Points are sampled in a circular neighborhood, but keeping the number of bins in a single-scale LBP histogram constant and small, such that arbitrarily large circular neighborhoods can be sampled and compactly encoded over a number of scales. There is no necessity to learn a texton dictionary, as in methods based on clustering, and no tuning of parameters is required to deal with different data sets. Extensive experimental results on representative texture databases show that the proposed BRINT not only demonstrates superior performance to a number of recent state-of-the-art LBP variants under normal conditions, but also performs significantly and consistently better in presence of noise due to its high distinctiveness and robustness. This noise robustness characteristic of the proposed BRINT is evaluated quantitatively with different artificially generated types and levels of noise (including Gaussian, salt and pepper, and speckle noise) in natural texture images.","Noise,
Feature extraction,
Robustness,
Histograms,
Educational institutions,
Vectors,
Lighting"
Intelligent Fusion of Wi-Fi and Inertial Sensor-Based Positioning Systems for Indoor Pedestrian Navigation,"Indoor positioning systems based on wireless local area networks are growing rapidly in importance and gaining commercial interest. Pedestrian dead reckoning (PDR) systems, which rely on inertial sensors, such as accelerometers, gyroscopes, or even magnetometers to estimate users' movement, have also been widely adopted for real-time indoor pedestrian location tracking. Since both kinds of systems have their own advantages and disadvantages, a maximum likelihood-based fusion algorithm that integrates a typical Wi-Fi indoor positioning system with a PDR system is proposed in this paper. The strength of the PDR system should eliminate the weakness of the Wi-Fi positioning system and vice versa. The intelligent fusion algorithm can retrieve the initial user location and moving direction information without requiring any user intervention. Experimental results show that the proposed positioning system has better positioning accuracy than the PDR system or Wi-Fi positioning system alone.",
On the Quality of Service of Cloud Gaming Systems,"Cloud gaming, i.e., real-time game playing via thin clients, relieves users from being forced to upgrade their computers and resolve the incompatibility issues between games and computers. As a result, cloud gaming is generating a great deal of interests among entrepreneurs, venture capitalists, general publics, and researchers. However, given the large design space, it is not yet known which cloud gaming system delivers the best user-perceived Quality of Service (QoS) and what design elements constitute a good cloud gaming system. This study is motivated by the question: How good is the QoS of current cloud gaming systems? Answering the question is challenging because most cloud gaming systems are proprietary and closed, and thus their internal mechanisms are not accessible for the research community. In this paper, we propose a suite of measurement techniques to evaluate the QoS of cloud gaming systems and prove the effectiveness of our schemes using a case study comprising two well-known cloud gaming systems: OnLive and StreamMyGame. Our results show that OnLive performs better, because it provides adaptable frame rates, better graphic quality, and shorter server processing delays, while consuming less network bandwidth. Our measurement techniques are general and can be applied to any cloud gaming systems, so that researchers, users, and service providers may systematically quantify the QoS of these systems. To the best of our knowledge, the proposed suite of measurement techniques have never been presented in the literature.",
Survey of Multiobjective Evolutionary Algorithms for Data Mining: Part II,"This paper is the second part of a two-part paper, which is a survey of multiobjective evolutionary algorithms for data mining problems. In Part I , multiobjective evolutionary algorithms used for feature selection and classification have been reviewed. In this part, different multiobjective evolutionary algorithms used for clustering, association rule mining, and other data mining tasks are surveyed. Moreover, a general discussion is provided along with scopes for future research in the domain of multiobjective evolutionary algorithms for data mining.",
Group Sparse Multiview Patch Alignment Framework With View Consistency for Image Classification,"No single feature can satisfactorily characterize the semantic concepts of an image. Multiview learning aims to unify different kinds of features to produce a consensual and efficient representation. This paper redefines part optimization in the patch alignment framework (PAF) and develops a group sparse multiview patch alignment framework (GSM-PAF). The new part optimization considers not only the complementary properties of different views, but also view consistency. In particular, view consistency models the correlations between all possible combinations of any two kinds of view. In contrast to conventional dimensionality reduction algorithms that perform feature extraction and feature selection independently, GSM-PAF enjoys joint feature extraction and feature selection by exploiting l2-norm on the projection matrix to achieve row sparsity, which leads to the simultaneous selection of relevant features and learning transformation, and thus makes the algorithm more discriminative. Experiments on two real-world image data sets demonstrate the effectiveness of GSM-PAF for image classification.","Feature extraction,
Optimization,
Equations,
Correlation,
Electronic mail,
Kernel,
Image color analysis"
Researcher Bias: The Use of Machine Learning in Software Defect Prediction,"Background. The ability to predict defect-prone software components would be valuable. Consequently, there have been many empirical studies to evaluate the performance of different techniques endeavouring to accomplish this effectively. However no one technique dominates and so designing a reliable defect prediction model remains problematic. Objective. We seek to make sense of the many conflicting experimental results and understand which factors have the largest effect on predictive performance. Method. We conduct a meta-analysis of all relevant, high quality primary studies of defect prediction to determine what factors influence predictive performance. This is based on 42 primary studies that satisfy our inclusion criteria that collectively report 600 sets of empirical prediction results. By reverse engineering a common response variable we build a random effects ANOVA model to examine the relative contribution of four model building factors (classifier, data set, input metrics and researcher group) to model prediction performance. Results. Surprisingly we find that the choice of classifier has little impact upon performance (1.3 percent) and in contrast the major (31 percent) explanatory factor is the researcher group. It matters more who does the work than what is done. Conclusion. To overcome this high level of researcher bias, defect prediction researchers should (i) conduct blind analysis, (ii) improve reporting protocols and (iii) conduct more intergroup studies in order to alleviate expertise issues. Lastly, research is required to determine whether this bias is prevalent in other applications domains.","Software,
Predictive models,
Correlation,
Data models,
Buildings,
Software engineering,
Measurement"
Engineering a Distributed Infrastructure for Large-Scale Cost-Effective Content Dissemination over Urban Vehicular Networks,"This paper proposes a practical and cost-effective approach to construct a fully distributed roadside communication infrastructure to facilitate the localized content dissemination to vehicles in the urban area. The proposed infrastructure is composed of distributed lightweight low-cost devices called roadside buffers (RSBs), where each RSB has the limited buffer storage and is able to transmit wirelessly the cached contents to fast-moving vehicles. To enable the distributed RSBs working toward the global optimal performance (e.g., minimal average file download delays), we propose a fully distributed algorithm to determine optimally the content replication strategy at RSBs. Specifically, we first develop a generic analytical model to evaluate the download delay of files, given the probability density of file distribution at RSBs. Then, we formulate the RSB content replication process as an optimization problem and devise a fully distributed content replication scheme accordingly to enable vehicles to recommend intelligently the desirable content files to RSBs. The proposed infrastructure is designed to optimize the global network utility, which accounts for the integrated download experience of users and the download demands of files. Using extensive simulations, we validate the effectiveness of the proposed infrastructure and show that the proposed distributed protocol can approach to the optimal performance and can significantly outperform the traditional heuristics.",
Local Synchronization of Chaotic Neural Networks With Sampled-Data and Saturating Actuators,"This paper investigates the problem of local synchronization of chaotic neural networks with sampled-data and actuator saturation. A new time-dependent Lyapunov functional is proposed for the synchronization error systems. The advantage of the constructed Lyapunov functional lies in the fact that it is positive definite at sampling times but not necessarily between sampling times, and makes full use of the available information about the actual sampling pattern. A local stability condition of the synchronization error systems is derived, based on which a sampled-data controller with respect to the actuator saturation is designed to ensure that the master neural networks and slave neural networks are locally asymptotically synchronous. Two optimization problems are provided to compute the desired sampled-data controller with the aim of enlarging the set of admissible initial conditions or the admissible sampling upper bound ensuring the local synchronization of the considered chaotic neural networks. A numerical example is used to demonstrate the effectiveness of the proposed design technique.",
Adaptive Resource Provisioning for the Cloud Using Online Bin Packing,"Data center applications present significant opportunities for multiplexing server resources. Virtualization technology makes it easy to move running application across physical machines. In this paper, we present an approach that uses virtualization technology to allocate data center resources dynamically based on application demands and support green computing by optimizing the number of servers actively used. We abstract this as a variant of the relaxed on-line bin packing problem and develop a practical, efficient algorithm that works well in a real system. We adjust the resources available to each VM both within and across physical servers. Extensive simulation and experiment results demonstrate that our system achieves good performance compared to the existing work.","Green computing,
Approximation algorithms,
Approximation methods,
Heuristic algorithms,
Resource management,
Cloud computing,
Scheduling algorithms,
Virtualization"
Prediction of Human Activity by Discovering Temporal Sequence Patterns,"Early prediction of ongoing human activity has become more valuable in a large variety of time-critical applications. To build an effective representation for prediction, human activities can be characterized by a complex temporal composition of constituent simple actions and interacting objects. Different from early detection on short-duration simple actions, we propose a novel framework for long -duration complex activity prediction by discovering three key aspects of activity: Causality, Context-cue, and Predictability. The major contributions of our work include: (1) a general framework is proposed to systematically address the problem of complex activity prediction by mining temporal sequence patterns; (2) probabilistic suffix tree (PST) is introduced to model causal relationships between constituent actions, where both large and small order Markov dependencies between action units are captured; (3) the context-cue, especially interactive objects information, is modeled through sequential pattern mining (SPM), where a series of action and object co-occurrence are encoded as a complex symbolic sequence; (4) we also present a predictive accumulative function (PAF) to depict the predictability of each kind of activity. The effectiveness of our approach is evaluated on two experimental scenarios with two data sets for each: action-only prediction and context-aware prediction. Our method achieves superior performance for predicting global activity classes and local action units.",
Enabling Smart Cloud Services Through Remote Sensing: An Internet of Everything Enabler,"The recent emergence and success of cloud-based services has empowered remote sensing and made it very possible. Cloud-assisted remote sensing (CARS) enables distributed sensory data collection, global resource and data sharing, remote and real-time data access, elastic resource provisioning and scaling, and pay-as-you-go pricing models. CARS has great potentials for enabling the so-called Internet of Everything (IoE), thereby promoting smart cloud services. In this paper, we survey CARS. First, we describe its benefits and capabilities through real-world applications. Second, we present a multilayer architecture of CARS by describing each layer's functionalities and responsibilities, as well as its interactions and interfaces with its upper and lower layers. Third, we discuss the sensing services models offered by CARS. Fourth, we discuss some popular commercial cloud platforms that have already been developed and deployed in recent years. Finally, we present and discuss major design requirements and challenges of CARS.","Clouds,
Monitoring,
Real-time systems,
Intelligent sensors,
Cloud computing"
Online Signature Verification on Mobile Devices,"This paper studies online signature verification on touch interface-based mobile devices. A simple and effective method for signature verification is developed. An online signature is represented with a discriminative feature vector derived from attributes of several histograms that can be computed in linear time. The resulting signature template is compact and requires constant space. The algorithm was first tested on the well-known MCYT-100 and SUSIG data sets. The results show that the performance of the proposed technique is comparable and often superior to state-of-the-art algorithms despite its simplicity and efficiency. In order to test the proposed method on finger drawn signatures on touch devices, a data set was collected from an uncontrolled environment and over multiple sessions. Experimental results on this data set confirm the effectiveness of the proposed algorithm in mobile settings. The results demonstrate the problem of within-user variation of signatures across multiple sessions and the effectiveness of cross session training strategies to alleviate these problems.","Vectors,
Histograms,
Feature extraction,
Mobile handsets,
Hidden Markov models,
Quantization (signal),
Performance evaluation"
Contrast Enhancement-Based Forensics in Digital Images,"As a retouching manipulation, contrast enhancement is typically used to adjust the global brightness and contrast of digital images. Malicious users may also perform contrast enhancement locally for creating a realistic composite image. As such it is significant to detect contrast enhancement blindly for verifying the originality and authenticity of the digital images. In this paper, we propose two novel algorithms to detect the contrast enhancement involved manipulations in digital images. First, we focus on the detection of global contrast enhancement applied to the previously JPEG-compressed images, which are widespread in real applications. The histogram peak/gap artifacts incurred by the JPEG compression and pixel value mappings are analyzed theoretically, and distinguished by identifying the zero-height gap fingerprints. Second, we propose to identify the composite image created by enforcing contrast adjustment on either one or both source regions. The positions of detected blockwise peak/gap bins are clustered for recognizing the contrast enhancement mappings applied to different source regions. The consistency between regional artifacts is checked for discovering the image forgeries and locating the composition boundary. Extensive experiments have verified the effectiveness and efficacy of the proposed techniques.","Histograms,
Transform coding,
Image coding,
Digital images,
Fingerprint recognition,
Information science,
Filtering"
Cooperative Coevolution With Route Distance Grouping for Large-Scale Capacitated Arc Routing Problems,"In this paper, a divide-and-conquer approach is proposed to solve the large-scale capacitated arc routing problem (LSCARP) more effectively. Instead of considering the problem as a whole, the proposed approach adopts the cooperative coevolution (CC) framework to decompose it into smaller ones and solve them separately. An effective decomposition scheme called the route distance grouping (RDG) is developed to decompose the problem. Its merit is twofold. First, it employs the route information of the best-so-far solution, so that the quality of the decomposition is upper bounded by that of the best-so-far solution. Thus, it can keep improving the decomposition by updating the best-so-far solution during the search. Second, it defines a distance between routes, based on which the potentially better decompositions can be identified. Therefore, RDG is able to obtain promising decompositions and focus the search on the promising regions of the vast solution space. Experimental studies verified the efficacy of RDG on the instances with a large number of tasks and tight capacity constraints, where it managed to obtain significantly better results than its counterpart without decomposition in a much shorter time. Furthermore, the best-known solutions of the EGL-G LSCARP instances are much improved.",
A Novel Low-Cost Circularly Polarized Rotated Stacked Dielectric Resonator Antenna,"A novel low-cost method for generating circular polarization in a dielectric resonator antenna is proposed. The antenna comprises four rectangular dielectric layers, each one being rotated by an angle of 30 ° relative to its adjacent layers. Utilizing such an approach has provided a circular polarization over a bandwidth of 6% from 9.55 to 10.15 GHz. This has been achieved in conjunction with a 21% impedance-matching bandwidth over the same frequency range. Also, the radiation efficiency of the proposed circularly polarized dielectric resonator antenna is 93% in this frequency band of operation",
Measuring Crowd Collectiveness,"Collective motions of crowds are common in nature and have attracted a great deal of attention in a variety of multidisciplinary fields. Collectiveness, which indicates the degree of individuals acting as a union, is a fundamental and universal measurement for various crowd systems. By quantifying the topological structures of collective manifolds of crowd, this paper proposes a descriptor of collectiveness and its efficient computation for the crowd and its constituent individuals. The Collective Merging algorithm is then proposed to detect collective motions from random motions. We validate the effectiveness and robustness of the proposed collectiveness on the system of self-driven particles as well as other real crowd systems such as pedestrian crowds and bacteria colony. We compare the collectiveness descriptor with human perception for collective motion and show their high consistency. As a universal descriptor, the proposed crowd collectiveness can be used to compare different crowd systems. It has a wide range of applications, such as detecting collective motions from crowd clutters, monitoring crowd dynamics, and generating maps of collectiveness for crowded scenes. A new Collective Motion Database, which consists of 413 video clips from 62 crowded scenes, is released to the public.","Manifolds,
Dynamics,
Microorganisms,
Computational modeling,
Correlation,
Hidden Markov models,
Monitoring"
Multimodal Similarity-Preserving Hashing,"We introduce an efficient computational framework for hashing data belonging to multiple modalities into a single representation space where they become mutually comparable. The proposed approach is based on a novel coupled siamese neural network architecture and allows unified treatment of intra- and inter-modality similarity learning. Unlike existing cross-modality similarity learning approaches, our hashing functions are not limited to binarized linear projections and can assume arbitrarily complex forms. We show experimentally that our method significantly outperforms state-of-the-art hashing approaches on multimedia retrieval tasks.","Training,
Measurement,
Vectors,
Neural networks,
Standards,
Optimization,
Databases"
Sensor Selection Based on Generalized Information Gain for Target Tracking in Large Sensor Networks,"In this paper, sensor selection problems for target tracking in large sensor networks with linear equality or inequality constraints are considered. First, we derive an equivalent Kalman filter for sensor selection, i.e., generalized information filter. Then, under a regularity condition, we prove that the multistage look-ahead policy that minimizes either the final or the average estimation error covariances of next multiple time steps is equivalent to a myopic sensor selection policy that maximizes the trace of the generalized information gain at each time step. Moreover, when the measurement noises are uncorrelated between sensors, the optimal solution can be obtained analytically for sensor selection when constraints are temporally separable. When constraints are temporally inseparable, sensor selections can be obtained by approximately solving a linear programming problem so that the sensor selection problem for a large sensor network can be dealt with quickly. Although there is no guarantee that the gap between the performance of the chosen subset and the performance bound is always small, numerical examples suggest that the algorithm is near-optimal in many cases. Finally, when the measurement noises are correlated between sensors, the sensor selection problem with temporally inseparable constraints can be relaxed to a Boolean quadratic programming problem which can be efficiently solved by a Gaussian randomization procedure along with solving a semi-definite programming problem. Numerical examples show that the proposed method is much better than the method that ignores dependence of noises.",
Footstep planning on uneven terrain with mixed-integer convex optimization,"We present a new method for planning footstep placements for a robot walking on uneven terrain with obstacles, using a mixed-integer quadratically-constrained quadratic program (MIQCQP). Our approach is unique in that it handles obstacle avoidance, kinematic reachability, and rotation of footstep placements, which typically have required non-convex constraints, in a single mixed-integer optimization that can be efficiently solved to its global optimum. Reachability is enforced through a convex inner approximation of the reachable space for the robot's feet. Rotation of the footsteps is handled by a piecewise linear approximation of sine and cosine, designed to ensure that the approximation never overestimates the robot's reachability. Obstacle avoidance is ensured by decomposing the environment into convex regions of obstacle-free configuration space and assigning each footstep to one such safe region. We demonstrate this technique in simple 2D and 3D environments and with real environments sensed by a humanoid robot. We also discuss computational performance of the algorithm, which is currently capable of planning short sequences of a few steps in under one second or longer sequences of 10-30 footsteps in tens of seconds to minutes on common laptop computer hardware. Our implementation is available within the Drake MATLAB toolbox [1].",
Novel Neural Networks-Based Fault Tolerant Control Scheme With Fault Alarm,"In this paper, the problem of adaptive active fault-tolerant control for a class of nonlinear systems with unknown actuator fault is investigated. The actuator fault is assumed to have no traditional affine appearance of the system state variables and control input. The useful property of the basis function of the radial basis function neural network (NN), which will be used in the design of the fault tolerant controller, is explored. Based on the analysis of the design of normal and passive fault tolerant controllers, by using the implicit function theorem, a novel NN-based active fault-tolerant control scheme with fault alarm is proposed. Comparing with results in the literature, the fault-tolerant control scheme can minimize the time delay between fault occurrence and accommodation that is called the time delay due to fault diagnosis, and reduce the adverse effect on system performance. In addition, the FTC scheme has the advantages of a passive fault-tolerant control scheme as well as the traditional active fault-tolerant control scheme's properties. Furthermore, the fault-tolerant control scheme requires no additional fault detection and isolation model which is necessary in the traditional active fault-tolerant control scheme. Finally, simulation results are presented to demonstrate the efficiency of the developed techniques.","Fault tolerance,
Fault tolerant systems,
Actuators,
Nonlinear systems,
Noise measurement,
Delay effects"
Fast Exact Search in Hamming Space With Multi-Index Hashing,"There is growing interest in representing image data and feature descriptors using compact binary codes for fast near neighbor search. Although binary codes are motivated by their use as direct indices (addresses) into a hash table, codes longer than 32 bits are not being used as such, as it was thought to be ineffective. We introduce a rigorous way to build multiple hash tables on binary code substrings that enables exact k-nearest neighbor search in Hamming space. The approach is storage efficient and straight-forward to implement. Theoretical analysis shows that the algorithm exhibits sub-linear run-time behavior for uniformly distributed codes. Empirical results show dramatic speedups over a linear scan baseline for datasets of up to one billion codes of 64, 128, or 256 bits.",
A Decentralized Controller Architecture for a Cascaded H-Bridge Multilevel Converter,"Despite its inherently modular hardware structure, the control system of most cascaded H-bridge converters is usually highly centralized and relies on a high-bandwidth intraconverter communication system to transmit time critical control signals to the module controllers. In contrast, this paper presents a decentralized control strategy for a modular cascaded converter, where each module controller determines its own switching actions based on local sensors, a local current regulator, and a local modulator. The system achieves the same performance as an optimized centralized control system while only requiring a low intraconverter communication bandwidth.","power convertors,
centralised control,
decentralised control"
Learning Salient Features for Speech Emotion Recognition Using Convolutional Neural Networks,"As an essential way of human emotional behavior understanding, speech emotion recognition (SER) has attracted a great deal of attention in human-centered signal processing. Accuracy in SER heavily depends on finding good affect- related , discriminative features. In this paper, we propose to learn affect-salient features for SER using convolutional neural networks (CNN). The training of CNN involves two stages. In the first stage, unlabeled samples are used to learn local invariant features (LIF) using a variant of sparse auto-encoder (SAE) with reconstruction penalization. In the second step, LIF is used as the input to a feature extractor, salient discriminative feature analysis (SDFA), to learn affect-salient, discriminative features using a novel objective function that encourages feature saliency, orthogonality, and discrimination for SER. Our experimental results on benchmark datasets show that our approach leads to stable and robust recognition performance in complex scenes (e.g., with speaker and language variation, and environment distortion) and outperforms several well-established SER features.","Feature extraction,
Speech,
Speech recognition,
Spectrogram,
Acoustics,
Emotion recognition,
Convolution"
Sparse Packetized Predictive Control for Networked Control Over Erasure Channels,"We study feedback control over erasure channels with packet-dropouts. To achieve robustness with respect to packet-dropouts, the controller transmits data packets containing plant input predictions, which minimize a finite horizon cost function. To reduce the data size of packets, we propose to adopt sparsity-promoting optimizations, namely, l1 - l2 and l2-constrained l0 optimizations, for which efficient algorithms exist. We show how to design the tuning parameters to ensure (practical) stability of the resulting feedback control systems when the number of consecutive packet-dropouts is bounded.","Stability analysis,
Vectors,
Asymptotic stability,
Networked control systems,
Predictive control,
Cost function"
A Contract-Based Methodology for Aircraft Electric Power System Design,"In an aircraft electric power system, one or more supervisory control units actuate a set of electromechanical switches to dynamically distribute power from generators to loads, while satisfying safety, reliability, and real-time performance requirements. To reduce expensive redesign steps, this control problem is generally addressed by minor incremental changes on top of consolidated solutions. A more systematic approach is hindered by a lack of rigorous design methodologies that allow estimating the impact of earlier design decisions on the final implementation. To achieve an optimal implementation that satisfies a set of requirements, we propose a platform-based methodology for electric power system design, which enables independent implementation of system topology (i.e., interconnection among elements) and control protocol by using a compositional approach. In our flow, design space exploration is carried out as a sequence of refinement steps from the initial specification toward a final implementation by mapping higher level behavioral and performance models into a set of either existing or virtual library components at the lower level of abstraction. Specifications are first expressed using the formalisms of linear temporal logic, signal temporal logic, and arithmetic constraints on Boolean variables. To reason about different requirements, we use specialized analysis and synthesis frameworks and formulate assume guarantee contracts at the articulation points in the design flow. We show the effectiveness of our approach on a proof-of-concept electric power system design.","Aircraft manufacture,
Design automation,
Power system stabilty,
Design methodology,
Cyberphysical systems"
Segmentation of the Blood Vessels and Optic Disk in Retinal Images,"Retinal image analysis is increasingly prominent as a nonintrusive diagnosis method in modern ophthalmology. In this paper, we present a novel method to segment blood vessels and optic disk in the fundus retinal images. The method could be used to support nonintrusive diagnosis in modern ophthalmology since the morphology of the blood vessel and the optic disk is an important indicator for diseases like diabetic retinopathy, glaucoma, and hypertension. Our method takes as first step the extraction of the retina vascular tree using the graph cut technique. The blood vessel information is then used to estimate the location of the optic disk. The optic disk segmentation is performed using two alternative methods. The Markov random field (MRF) image reconstruction method segments the optic disk by removing vessels from the optic disk region, and the compensation factor method segments the optic disk using the prior local intensity knowledge of the vessels. The proposed method is tested on three public datasets, DIARETDB1, DRIVE, and STARE. The results and comparison with alternative methods show that our method achieved exceptional performance in segmenting the blood vessel and optic disk.",
User Grouping for Massive MIMO in FDD Systems: New Design Methods and Analysis,"The massive multiple-input multiple-output (MIMO) system has drawn increasing attention recently as it is expected to boost the system throughput and result in lower costs. Previous studies mainly focus on time division duplexing (TDD) systems, which are more amenable to practical implementations due to channel reciprocity. However, there are many frequency division duplexing (FDD) systems deployed worldwide. Consequently, it is of great importance to investigate the design and performance of FDD massive MIMO systems. To reduce the overhead of channel estimation in FDD systems, a two-stage precoding scheme was recently proposed to decompose the precoding procedure into intergroup precoding and intragroup precoding. The problem of user grouping and scheduling thus arises. In this paper, we first propose three novel similarity measures for user grouping based on weighted likelihood, subspace projection, and Fubini-Study, respectively, as well as two novel clustering methods, including hierarchical and K-medoids clustering. We then propose a dynamic user scheduling scheme to further enhance the system throughput once the user groups are formed. The load balancing problem is considered when few users are active and solved with an effective algorithm. The efficacy of the proposed schemes are validated with theoretical analysis and simulations.",
Design and Performance Study of a Dual-Element Multiband Printed Monopole Antenna Array for MIMO Terminals,"This letter presents a study on linearly polarized compact multiband multiple-input-multiple-output (MIMO) antenna system for small mobile terminals. The MIMO antenna system consists of two symmetric printed monopole antennas with edge-to-edge separation of 0.097 λ0 at 900 MHz. Each antenna element has a capacitive feed and is composed of two twisted lines, a parasitic loop, and a shorting trip that generate five resonant modes around 900, 1800, 2100, 3500, and 5400 MHz, covering GSM850/900, DCS, PCS, UMTS, WLAN, and WiMAX frequency bands. Two inverted-L shaped branches and a rectangular slot with one circular end, etched on the ground plane, were introduced to improve the isolation between antenna elements. The isolation achieved is higher than 15 dB in the lower band and 20 dB in the upper bands, leading to an envelope correlation coefficient of less than 0.025. The simulated performance of the designed antenna system has been verified in the experiment.","MIMO,
Antenna measurements,
Antenna radiation patterns,
Wireless communication,
Wireless LAN,
Mobile communication"
Associative Hierarchical Random Fields,"This paper makes two contributions: the first is the proposal of a new model-The associative hierarchical random field (AHRF), and a novel algorithm for its optimization; the second is the application of this model to the problem of semantic segmentation. Most methods for semantic segmentation are formulated as a labeling problem for variables that might correspond to either pixels or segments such as super-pixels. It is well known that the generation of super pixel segmentations is not unique. This has motivated many researchers to use multiple super pixel segmentations for problems such as semantic segmentation or single view reconstruction. These super-pixels have not yet been combined in a principled manner, this is a difficult problem, as they may overlap, or be nested in such a way that the segmentations form a segmentation tree. Our new hierarchical random field model allows information from all of the multiple segmentations to contribute to a global energy. MAP inference in this model can be performed efficiently using powerful graph cut based move making algorithms. Our framework generalizes much of the previous work based on pixels or segments, and the resulting labelings can be viewed both as a detailed segmentation at the pixel level, or at the other extreme, as a segment selector that pieces together a solution like a jigsaw, selecting the best segments from different segmentations as pieces. We evaluate its performance on some of the most challenging data sets for object class segmentation, and show that this ability to perform inference using multiple overlapping segmentations leads to state-of-the-art results.",
Silicon Photonic Transceiver Circuits With Microring Resonator Bias-Based Wavelength Stabilization in 65 nm CMOS,"Photonic interconnects are a promising technology to meet the bandwidth demands of next-generation high-performance computing systems. This paper presents silicon photonic transceiver circuits for a microring resonator-based optical interconnect architecture in a 1 V standard 65 nm CMOS technology. The transmitter circuits incorporate high-swing ( 2Vpp and 4Vpp) drivers with nonlinear pre-emphasis and automatic bias-based tuning for resonance wavelength stabilization. An optical forwarded-clock adaptive inverter-based transimpedance amplifier (TIA) receiver trades off power for varying link budgets by employing an on-die eye monitor and scaling the TIA supply for the required sensitivity. At 5 Gb/s operation, the 4Vpp transmitter achieves 12.7 dB extinction ratio with 4.04 mW power consumption, excluding laser power, when driving wire-bonded modulators designed in a 130 nm SOI process, while a 0.28 nm tuning range is obtained at 6.8 μW/GHz efficiency with the bias-based tuning scheme implemented with the 2Vpp transmitter. When tested with a wire-bonded 150 fF p-i-n photodetector, the receiver achieves -9 dBm sensitivity at a BER=10-9 and consumes 2.2 mW at 8 Gb/s. Testing with an on-die test structure emulating a low-capacitance waveguide photodetector yields 17 μApp sensitivity at 10 Gb/s and more than 40% power reduction with higher input current levels.",
Optimal Integration of Plug-In Hybrid Electric Vehicles in Microgrids,"Plug-in hybrid electric vehicles' (PHEVs) integration can result in additional electricity consumers and electricity suppliers in microgrids (MGs). This paper presents a new method for optimal integration of PHEVs in MGs, which considers the optimal number of parking numbers under optimal scheduling of PHEVs. Due to the uncertainty of solar energy, the radial basis function network (RBFN) techniques are used for forecasting photovoltaic (PV) power output. Monte Carlo simulation is used to deal with the uncertainties associated with the daily distance driven of the PHEVs, load values, and electricity market price. The objective is the minimization of total cost (TC) and optimal set of the optimization problem is found using genetic algorithm (GA) method. In order to verify the effectiveness of the proposed method, two market policies are used as case studies. The computation results can be used to evaluate the impact of PHEVs' integration on economical performance of MGs.","Batteries,
Microgrids,
Forecasting,
Energy storage,
Plug-in hybrid electric vehicles"
A Smart Multicoil Inductively Coupled Array for Wireless Power Transmission,"This paper presents a novel resonance-based multicoil array structure to wirelessly charge or power up apparatus, like smart phones, computer mouses, smart animal research systems, or implanted medical devices. The proposed array consists of a novel multicoil inductive link, whose primary resonator is made of several identical coil elements connected in parallel and arranged in an array. Such a structure presents several key features compared to previous inductive coil arrays. The proposed approach can do the following: 1) deliver power with superior efficiency over longer separation distances; 2) naturally track the receiver position and localize transmitted power through nearby coil array elements without the need for complex control and detection circuitry; and 3) accommodate either short- or long-range power transmission applications simply by slightly modifying the receiver topology. The performance of the proposed structure is verified by measurement results. In a three-coil configuration, the prototype provides a power transfer efficiency (PTE) of 83.3% and a power delivered to the load (PDL) of 3.87 W for a separation distance below 1 cm, while in a four-coil configuration, it provides a PTE of 76% and a PDL of 115 mW for a separation distance of 4 cm.","Coils,
Arrays,
Receivers,
Couplings,
Prototypes,
Topology,
Power transmission"
Active Learning by Querying Informative and Representative Examples,"Active learning reduces the labeling cost by iteratively selecting the most valuable data to query their labels. It has attracted a lot of interests given the abundance of unlabeled data and the high cost of labeling. Most active learning approaches select either informative or representative unlabeled instances to query their labels, which could significantly limit their performance. Although several active learning algorithms were proposed to combine the two query selection criteria, they are usually ad hoc in finding unlabeled instances that are both informative and representative. We address this limitation by developing a principled approach, termed QUIRE, based on the min-max view of active learning. The proposed approach provides a systematic way for measuring and combining the informativeness and representativeness of an unlabeled instance. Further, by incorporating the correlation among labels, we extend the QUIRE approach to multi-label learning by actively querying instance-label pairs. Extensive experimental results show that the proposed QUIRE approach outperforms several state-of-the-art active learning approaches in both single-label and multi-label learning.","Measurement uncertainty,
Uncertainty,
Algorithm design and analysis,
Correlation,
Labeling,
Clustering algorithms,
Kernel"
A Gaussian Process Surrogate Model Assisted Evolutionary Algorithm for Medium Scale Expensive Optimization Problems,"Surrogate model assisted evolutionary algorithms (SAEAs) have recently attracted much attention due to the growing need for computationally expensive optimization in many real-world applications. Most current SAEAs, however, focus on small-scale problems. SAEAs for medium-scale problems (i.e., 20-50 decision variables) have not yet been well studied. In this paper, a Gaussian process surrogate model assisted evolutionary algorithm for medium-scale computationally expensive optimization problems (GPEME) is proposed and investigated. Its major components are a surrogate model-aware search mechanism for expensive optimization problems when a high-quality surrogate model is difficult to build and dimension reduction techniques for tackling the “curse of dimensionality.” A new framework is developed and used in GPEME, which carefully coordinates the surrogate modeling and the evolutionary search, so that the search can focus on a small promising area and is supported by the constructed surrogate model. Sammon mapping is introduced to transform the decision variables from tens of dimensions to a few dimensions, in order to take advantage of Gaussian process surrogate modeling in a low-dimensional space. Empirical studies on benchmark problems with 20, 30, and 50 variables and a real-world power amplifier design automation problem with 17 variables show the high efficiency and effectiveness of GPEME. Compared to three state-of-the-art SAEAs, better or similar solutions can be obtained with 12% to 50% exact function evaluations.","Computational modeling,
Training data,
Data models,
Mathematical model,
Optimization,
Databases,
Benchmark testing"
Energy-Storage-Based Low-Frequency Oscillation Damping Control Using Particle Swarm Optimization and Heuristic Dynamic Programming,"Low-frequency oscillation is one of the main barriers limiting power transmission between two connected power systems. Although power system stabilizers (PSSs) have been proved to be effective in damping inner-area oscillation, inter-area oscillation still remains a critical challenge in today's power systems. Since the low-frequency oscillation between two connected power systems is active power oscillation, power modulation through energy storage devices (ESDs) can be an efficient and effective way to maintain such power system stability. In this paper, we investigate the integration of a new goal representation heuristic dynamic programming (GrHDP) algorithm to adaptively control ESD to damp inter-area oscillation. A particle swarm optimization (PSO)-based power oscillation damper (POD) has also been proposed for comparison. Various simulation studies with residue-based POD controller design, the proposed PSO optimized controller design, and the GrHDP-based controller design over a four-machine-two-area benchmark power system with energy storage device have been conducted. Simulation results have demonstrated the efficiency and effectiveness of the GrHDP-based approach for inter-area oscillation damping in a wide range of system operating conditions.",
Depth-Based Human Fall Detection via Shape Features and Improved Extreme Learning Machine,"Falls are one of the major causes leading to injury of elderly people. Using wearable devices for fall detection has a high cost and may cause inconvenience to the daily lives of the elderly. In this paper, we present an automated fall detection approach that requires only a low-cost depth camera. Our approach combines two computer vision techniques-shape-based fall characterization and a learning-based classifier to distinguish falls from other daily actions. Given a fall video clip, we extract curvature scale space (CSS) features of human silhouettes at each frame and represent the action by a bag of CSS words (BoCSS). Then, we utilize the extreme learning machine (ELM) classifier to identify the BoCSS representation of a fall from those of other actions. In order to eliminate the sensitivity of ELM to its hyperparameters, we present a variable-length particle swarm optimization algorithm to optimize the number of hidden neurons, corresponding input weights, and biases of ELM. Using a low-cost Kinect depth camera, we build an action dataset that consists of six types of actions (falling, bending, sitting, squatting, walking, and lying) from ten subjects. Experimenting with the dataset shows that our approach can achieve up to 91.15% sensitivity, 77.14% specificity, and 86.83% accuracy. On a public dataset, our approach performs comparably to state-of-the-art fall detection methods that need multiple cameras.","Feature extraction,
Cameras,
Particle swarm optimization,
Accuracy,
Computer vision,
Algorithm design and analysis"
Development of Advanced All-SiC Power Modules,"A thermally integrated packaging structure for an all silicon carbide (SiC) power module was used to realize highly efficient cooling of power semiconductor devices through direct bonding of the power stage and a cold baseplate. The prototype power modules composed of SiC metal-oxide-semiconductor field-effect transistors and Schottky barrier diodes demonstrate significant improvements such as low-power losses and low-thermal resistance. Direct comparisons to their silicon counterparts, which are composed of insulated gate bipolar transistors and PiN diodes, as well as conventional thermal packaging, were experimentally performed. The advantages of this SiC module in efficiency and power density for power electronics systems have also been identified, with clarification of the SiC attributes and packaging advancements.",
Population Classification in Fire Evacuation: A Multiobjective Particle Swarm Optimization Approach,"In an emergency evacuation operation, accurate classification of the evacuee population can provide important information to support the responders in decision making; and therefore, makes a great contribution in protecting the population from potential harm. However, real-world data of fire evacuation is often noisy, incomplete, and inconsistent, and the response time of population classification is very limited. In this paper, we propose an effective multiobjective particle swarm optimization method for population classification in fire evacuation operations, which simultaneously optimizes the precision and recall measures of the classification rules. We design an effective approach for encoding classification rules, and use a comprehensive learning strategy for evolving particles and maintaining diversity of the swarm. Comparative experiments show that the proposed method performs better than some state-of-the-art methods for classification rule mining, especially on the real-world fire evacuation dataset. This paper also reports a successful application of our method in a real-world fire evacuation operation that recently occurred in China. The method can be easily extended to many other multiobjective rule mining problems.","Sociology,
Statistics,
Data mining,
Optimization,
Particle swarm optimization,
Decision trees,
Vectors"
Distributed Object Detection With Linear SVMs,"In vision and learning, low computational complexity and high generalization are two important goals for video object detection. Low computational complexity here means not only fast speed but also less energy consumption. The sliding window object detection method with linear support vector machines (SVMs) is a general object detection framework. The computational cost is herein mainly paid in complex feature extraction and innerproduct-based classification. This paper first develops a distributed object detection framework (DOD) by making the best use of spatial-temporal correlation, where the process of feature extraction and classification is distributed in the current frame and several previous frames. In each framework, only subfeature vectors are extracted and the response of partial linear classifier (i.e., subdecision value) is computed. To reduce the dimension of traditional block-based histograms of oriented gradients (BHOG) feature vector, this paper proposes a cell-based HOG (CHOG) algorithm, where the features in one cell are not shared with overlapping blocks. Using CHOG as feature descriptor, we develop CHOG-DOD as an instance of DOD framework. Experimental results on detection of hand, face, and pedestrian in video show the superiority of the proposed method.","Feature extraction,
Vectors,
US Department of Defense,
Object detection,
Histograms,
Computational efficiency,
Support vector machines"
Control barrier function based quadratic programs with application to adaptive cruise control,"This paper develops a control methodology that unifies control barrier functions and control Lyapunov functions through quadratic programs. The result is demonstrated on adaptive cruise control, which presents both safety and performance considerations, as well as actuator bounds. We begin by presenting a novel notion of a barrier function associated with a set, formulated in the context of Lyapunov-like conditions; the existence of a barrier function satisfying these conditions implies forward invariance of the set. This formulation naturally yields a notion of control barrier function (CBF), yielding inequality constraints in the control input that, when satisfied, again imply forward invariance of the set. Through these constructions, CBFs can naturally be unified with control Lyapunov functions (CLFs) in the context of a quadratic program (QP); this allows for the simultaneous achievement of control objectives (represented by CLFs) subject to conditions on the admissible states of the system (represented by CBFs). These formulations are illustrated in the context of adaptive cruise control, where the control objective of achieving a desired speed is balanced by the minimum following conditions on a lead car and force-based constraints on acceleration and braking.","Lyapunov methods,
Vehicles,
Context,
Force,
Acceleration,
Safety,
Control systems"
Visual Tracking via Online Nonnegative Matrix Factorization,"In visual tracking, holistic and part-based representations are both popular choices to model target appearance. The former is known for great efficiency and convenience, while the latter for robustness against local appearance or shape variations. Based on nonnegative matrix factorization (NMF), we propose a novel visual tracker that takes advantage of both groups. The idea is to model the target appearance by a nonnegative combination of nonnegative components learned from examples observed in previous frames. To adjust NMF to the tracking context, we include sparsity and smoothness constraints in addition to the nonnegativity one. Furthermore, an online iterative learning algorithm, together with a proof of convergence, is proposed for efficient model updating. Putting these ingredients together with a particle filter framework, the proposed tracker, constrained online nonnegative matrix factorization (CONMF), achieves robustness to challenging appearance variations and nontrivial deformations while running in real time. We evaluate the proposed tracker on various benchmark sequences containing targets undergoing large variations in scale, pose, or illumination. The robustness and efficiency of CONMF is validated in comparison with several state-of-the-art trackers.",
Single Image Interpolation Via Adaptive Nonlocal Sparsity-Based Modeling,"Single image interpolation is a central and extensively studied problem in image processing. A common approach toward the treatment of this problem in recent years is to divide the given image into overlapping patches and process each of them based on a model for natural image patches. Adaptive sparse representation modeling is one such promising image prior, which has been shown to be powerful in filling-in missing pixels in an image. Another force that such algorithms may use is the self-similarity that exists within natural images. Processing groups of related patches together exploits their correspondence, leading often times to improved results. In this paper, we propose a novel image interpolation method, which combines these two forces-nonlocal self-similarities and sparse representation modeling. The proposed method is contrasted with competitive and related algorithms, and demonstrated to achieve state-of-the-art results.",
Visual Parameter Space Analysis: A Conceptual Framework,"Various case studies in different application domains have shown the great potential of visual parameter space analysis to support validating and using simulation models. In order to guide and systematize research endeavors in this area, we provide a conceptual framework for visual parameter space analysis problems. The framework is based on our own experience and a structured analysis of the visualization literature. It contains three major components: (1) a data flow model that helps to abstractly describe visual parameter space analysis problems independent of their application domain; (2) a set of four navigation strategies of how parameter space analysis can be supported by visualization tools; and (3) a characterization of six analysis tasks. Based on our framework, we analyze and classify the current body of literature, and identify three open research gaps in visual parameter space analysis. The framework and its discussion are meant to support visualization designers and researchers in characterizing parameter space analysis problems and to guide their design and evaluation processes.",
NETWRAP: An NDN Based Real-TimeWireless Recharging Framework for Wireless Sensor Networks,"Using vehicles equipped with wireless energy transmission technology to recharge sensor nodes over the air is a game-changer for traditional wireless sensor networks. The recharging policy regarding when to recharge which sensor nodes critically impacts the network performance. So far only a few works have studied such recharging policy for the case of using a single vehicle. In this paper, we propose NETWRAP, an NDN based Real Time Wireless Recharging Protocol for dynamic wireless recharging in sensor networks. The real-time recharging framework supports single or multiple mobile vehicles. Employing multiple mobile vehicles provides more scalability and robustness. To efficiently deliver sensor energy status information to vehicles in real-time, we leverage concepts and mechanisms from named data networking (NDN) and design energy monitoring and reporting protocols. We derive theoretical results on the energy neutral condition and the minimum number of mobile vehicles required for perpetual network operations. Then we study how to minimize the total traveling cost of vehicles while guaranteeing all the sensor nodes can be recharged before their batteries deplete. We formulate the recharge optimization problem into a Multiple Traveling Salesman Problem with Deadlines (m-TSP with Deadlines), which is NP-hard. To accommodate the dynamic nature of node energy conditions with low overhead, we present an algorithm that selects the node with the minimum weighted sum of traveling time and residual lifetime. Our scheme not only improves network scalability but also ensures the perpetual operation of networks. Extensive simulation results demonstrate the effectiveness and efficiency of the proposed design. The results also validate the correctness of the theoretical analysis and show significant improvements that cut the number of nonfunctional nodes by half compared to the static scheme while maintaining the network overhead at the same level.",
Online Verification of Automated Road Vehicles Using Reachability Analysis,"An approach for formally verifying the safety of automated vehicles is proposed. Due to the uniqueness of each traffic situation, we verify safety online, i.e., during the operation of the vehicle. The verification is performed by predicting the set of all possible occupancies of the automated vehicle and other traffic participants on the road. In order to capture all possible future scenarios, we apply reachability analysis to consider all possible behaviors of mathematical models considering uncertain inputs (e.g., sensor noise, disturbances) and partially unknown initial states. Safety is guaranteed with respect to the modeled uncertainties and behaviors if the occupancy of the automated vehicle does not intersect that of other traffic participants for all times. The applicability of the approach is demonstrated by test drives with an automated vehicle at the Robotics Institute at Carnegie Mellon University.",
Medium-Voltage 12-Pulse Converter: Output Voltage Harmonic Compensation Using a Series APF,"In this paper, compensation of the dc-side voltage harmonics of a medium-voltage (MV) 12-pulse ac/dc converter is achieved using a series active power filter (APF). The output voltage harmonics are dependent on the converter firing delay angles and, consequently, on the specific power locus followed by the ac/dc converter. This power locus ensures minimum fifth and seventh harmonics (total rms) in the input current which provides minimum input current total harmonic distortion when the reactive power is less than 0.5 p.u. The series APF is connected between the load and the converter output via a magnetic amplifier to eliminate the dc current from the APF inverter, thus reducing inverter losses. Voltage harmonic compensation using a series APF, with and without a magnetic amplifier, is examined with both resistive and inductive loads. The simulation results for compensating a 3.3-kV MV 12-pulse converter system are experimentally verified using a scaled prototype 12-pulse converter with a series APF.",
HeteSim: A General Framework for Relevance Measure in Heterogeneous Networks,"Similarity search is an important function in many applications, which usually focuses on measuring the similarity between objects with the same type. However, in many scenarios, we need to measure the relatedness between objects with different types. With the surge of study on heterogeneous networks, the relevance measure on objects with different types becomes increasingly important. In this paper, we study the relevance search problem in heterogeneous networks, where the task is to measure the relatedness of heterogeneous objects (including objects with the same type or different types). A novel measure HeteSim is proposed, which has the following attributes: (1) a uniform measure: it can measure the relatedness of objects with the same or different types in a uniform framework; (2) a path-constrained measure: the relatedness of object pairs are defined based on the search path that connects two objects through following a sequence of node types; (3) a semi-metric measure: HeteSim has some good properties (e.g., selfmaximum and symmetric), which are crucial to many data mining tasks. Moreover, we analyze the computation characteristics of HeteSim and propose the corresponding quick computation strategies. Empirical studies show that HeteSim can effectively and efficiently evaluate the relatedness of heterogeneous objects.",
Early MERGE Mode Decision Based on Motion Estimation and Hierarchical Depth Correlation for HEVC,"The high efficiency video coding (HEVC) is the latest video coding standard, which adopts the quadtree structure based coding tree unit (CTU) to improve the coding efficiency. In the HEVC encoding process, the CTU is recursively split into the 8×8 size coding units (CUs) from the 64×64 size CU. Along with the increased number of the sizes of the CUs, the number of coding modes has been greatly increased, which results in high computational complexity in the HEVC encoder. In this paper, we propose an early MERGE mode decision algorithm to reduce the computational complexity of the HEVC encoder. Firstly, based on the all-zero block (AZB) and the motion estimation (ME) information of the INTER 2N×2N mode, an early MERGE mode decision is proposed for the root CUs (i.e., 64×64 size CUs). Then, an early MERGE mode decision is proposed for the children CUs (i.e., 32×32, 16×16, and 8×8 size CUs) by considering the mode selection correlation between the root CU and the children CUs. To maximize the computational complexity reduction, when the root CUs are encoded in the non-MERGE modes, the AZB and the ME information are also used for early termination of the children CUs. Experimental results demonstrate that compared to the state-of-the-art published method, the proposed algorithm can achieve about 35% encoding time on average saving while the rate distortion performance degradation is negligible.","Encoding,
Video coding,
Correlation,
Computational complexity,
Educational institutions,
Video sequences,
Motion estimation"
Passivity and Passification of Memristor-Based Recurrent Neural Networks With Time-Varying Delays,"This paper presents new theoretical results on the passivity and passification of a class of memristor-based recurrent neural networks (MRNNs) with time-varying delays. The casual assumptions on the boundedness and Lipschitz continuity of neuronal activation functions are relaxed. By constructing appropriate Lyapunov-Krasovskii functionals and using the characteristic function technique, passivity conditions are cast in the form of linear matrix inequalities (LMIs), which can be checked numerically using an LMI toolbox. Based on these conditions, two procedures for designing passification controllers are proposed, which guarantee that MRNNs with time-varying delays are passive. Finally, two illustrative examples are presented to show the characteristics of the main results in detail.","Memristors,
Delays,
Biological neural networks,
Linear matrix inequalities,
Biological system modeling"
Dynamics of Discrete-Time Sliding-Mode-Control Uncertain Systems With a Disturbance Compensator,"In this paper, dynamical behaviors of the discrete-time sliding-mode-control (DSMC) uncertain systems are studied. First, a discrete reaching law with a disturbance compensator is presented, and a sliding-mode controller is designed by using the proposed reaching law. Second, the time steps for the system trajectories to converge to the switching manifold are found. Then, a quasi-sliding-mode domain (QSMD) of the DSMC uncertain systems is obtained, and the system dynamics of the DSMC systems in QSMD are described. Finally, numerical simulations are given to demonstrate the effectiveness of the proposed strategies.",
GaN-on-Si Vertical Schottky and p-n Diodes,"This letter demonstrates GaN vertical Schottky and p-n diodes on Si substrates for the first time. With a total GaN drift layer of only 1.5-μm thick, a breakdown voltage (BV) of 205 V was achieved for GaN-on-Si Schottky diodes, and a soft BV higher than 300 V was achieved for GaN-on-Si p-n diodes with a peak electric field of 2.9 MV/cm in GaN. A trap-assisted space-charge-limited conduction mechanism determined the reverse leakage and breakdown mechanism for GaN-on-Si vertical p-n diodes. The ON-resistance was 6 and 10 mQ · cm2 for the vertical Schottky and p-n diode, respectively. These results show the promising performance of GaN-on-Si vertical devices for future power applications.","Gallium nitride,
Schottky diodes,
Substrates,
Silicon,
Leakage currents,
Aluminum gallium nitride"
A new cost function for spatial image steganography,"A well defined cost function is crucial to steganography under the scenario of minimizing embedding distortion. In this paper, we present a new cost function for spatial image steganography. The proposed cost function is designed by using a high-pass filter to locate the less predictable parts in an image, and then using two low-pass filters to make the low cost values more clustered. Experiments show that the steganographic method with the proposed cost function makes the embedding changes more concentrated in texture regions, and thus achieves a better performance on resisting the state-of-the-art steganalysis over prior works, including HUGO, WOW, and S-UNIWARD.","Cost function,
Security,
Payloads,
Additives,
Testing,
Forensics,
Conferences"
A Universal Islanding Detection Technique for Distributed Generation Using Pattern Recognition,"Anti-islanding protection methods, proposed in the literature, are distributed generation (DG) type dependent or in other words work efficiently for a specific DG type (synchronous or inverter based). In this paper, we investigate the possibility of developing an efficient universal islanding detection method that can be applied to both inverter and synchronous-based DG. The proposed method relies on extracting a group of features, from measured data simulated for both types of DGs, from which the best features are selected for islanding detection. A random forest (RF) classification technique is used to detect islanding and non-islanding situations with an objective of minimizing the non-detection zone as well as avoiding nuisance DG tripping during non-islanding conditions. Islanding and non-islanding cases were generated for the IEEE 34-bus system and used to train and test the proposed technique. In the paper, k-fold cross-validation was used in order to test the accuracy of the proposed algorithm for detecting islanding. The results show that the proposed methodology has zero non-detection zone, high accuracy, and fast response when applied to both types of DGs independently of the size of the island. Among the various classification approaches investigated, the RF technique proved to be the most efficient approach for the proposed islanding detection method.","Feature extraction,
Islanding,
Reactive power,
Inverters,
Accuracy,
Radio frequency,
Vegetation"
Access Strategy for Hybrid Underlay-Overlay Cognitive Radios With Energy Harvesting,"In this paper, we consider a hybrid underlay-overlay cognitive radio with energy harvesting. In the considered system, secondary user can harvest energy from the primary user's signal as well as from the other ambient sources, such as solar, wind, vibration and so on. Energy is harvested from the primary user's signal when the primary channel is found in busy state. The secondary user either operates in one of the two transmission modes; overlay and underlay in order to maximize the throughput, remains in the sleep mode in order to conserve energy, or harvests energy from the primary channel in order to maximize the remaining energy. To maximize long-term throughput of the system, we propose an access strategy in which the partially observable Markov decision process framework is used to determine action of the secondary user, and energy threshold is used to determine the transmission mode (overlay or underlay) of secondary user. Simulations show that for certain values of the system parameters, the considered system provides 60% improved throughput than overlay-only cognitive radio and 43% enhanced throughput than a hybrid cognitive radio system harvesting energy only from the ambient sources. However, increasing the throughput also increases computational burden on the secondary user, which may increase latency and energy requirements of the system.","Sensors,
Throughput,
Interference,
Receivers,
Cognitive radio,
Energy harvesting,
Transmitters"
IK-SVD: Dictionary Learning for Spatial Big Data via Incremental Atom Update,"A large group of dictionary learning algorithms focus on adaptive sparse representation of data. Almost all of them fix the number of atoms in iterations and use unfeasible schemes to update atoms in the dictionary learning process. It's difficult, therefore, for them to train a dictionary from Big Data. A new dictionary learning algorithm is proposed here by extending the classical K-SVD method. In the proposed method, when each new batch of data samples is added to the training process, a number of new atoms are selectively introduced into the dictionary. Furthermore, only a small group of new atoms as subspace controls the current orthogonal matching pursuit, construction of error matrix, and SVD decomposition process in every training cycle. The information, from both old and new samples, is explored in the proposed incremental K-SVD (IK-SVD) algorithm, but only the current atoms are adaptively updated. This makes the dictionary better represent all the samples without the influence of redundant information from old samples.","Dictionaries,
Remote sensing,
Information management,
Data handling,
Data storage systems,
Big data ,
Mathematical model,
Learning systems,
Spatial analysis"
Base Station Activation and Linear Transceiver Design for Optimal Resource Management in Heterogeneous Networks,"In a densely deployed heterogeneous network (HetNet), the number of pico/micro base stations (BS) can be comparable with the number of the users. To reduce the operational overhead of the HetNet, proper identification of the set of serving BSs becomes an important design issue. In this work, we show that by jointly optimizing the transceivers and determining the active set of BSs, high system resource utilization can be achieved with only a small number of BSs. In particular, we provide formulations and efficient algorithms for such joint optimization problem, under the following two common design criteria: i) minimization of the total power consumption at the BSs, and ii) maximization of the system spectrum efficiency. In both cases, we introduce a nonsmooth regularizer to facilitate the activation of the most appropriate BSs. We illustrate the efficiency and the efficacy of the proposed algorithms via extensive numerical simulations.","Signal processing algorithms,
Quality of service,
Vectors,
Array signal processing,
Base stations,
Joints,
Interference"
A Survey on Geographic Load Balancing Based Data Center Power Management in the Smart Grid Environment,"Power management is becoming an increasingly important issue for Internet services supported by multiple geo-distributed data centers. These data center's energy consumptions and costs are becoming unacceptably high, and placing a heavy burden on both energy resources and the environment. Emerging smart grid provides a feasible way for dynamic and efficient power management of data centers. Various power management methodologies based on geographic load balancing (GLB) have recently been proposed to effectively utilize several features of smart grid. In this paper, we summarize the motivations, current state of the art, approaches and techniques proposed in the recent research works in this discipline. In all of these works, many perspectives of power management have been addressed using various computer science principles. We specifically elaborate on how researchers are exploiting mathematical tools to address these perspectives. Finally, we point out subject matters that need more attentions from the research community and provide our vision on possible future works along this direction.","Smart grids,
Electricity,
Load management,
Servers,
Power demand,
Renewable energy sources,
Optimization"
A Micro Inertial Energy Harvesting Platform With Self-Supplied Power Management Circuit for Autonomous Wireless Sensor Nodes,"A 0.25 cm3 autonomous energy harvesting micro-platform is realized to efficiently scavenge, rectify and store ambient vibration energy with batteryless cold start-up and zero sleep-mode power consumption. The fabricated compact system integrates a high-performance vacuum-packaged piezoelectric MEMS energy harvester with a power management IC and surface-mount components including an ultra-capacitor. The power management circuit incorporates a rectification stage with ~30 mV voltage drop, a bias-Ωip stage with a novel control system for increased harvesting efficiency, a trickle charger for permanent storage of harvested energy, and a low power supply-independent bias circuitry. The overall system weighs less than 0.6 grams, does not require a precharged battery, and has power consumption of 0.5 μW in active-mode and 10 pW in sleep-mode operation. While excited with 1 g vibration, the platform is tested to charge an initially depleted 70 mF ultra-capacitor to 1.85 V in 50 minutes (at 155 Hz vibration), and a 20 mF ultra-capacitor to 1.35 V in 7.5 min (at 419 Hz). The end-to-end rectification efficiency from the harvester to the ultra-capacitor is measured as 58-86%. The system can harvest from a minimum vibration level of 0.1 g.",
sEMG-Based Joint Force Control for an Upper-Limb Power-Assist Exoskeleton Robot,"This paper investigates two surface electromyogram (sEMG)-based control strategies developed for a power-assist exoskeleton arm. Different from most of the existing position control approaches, this paper develops force control methods to make the exoskeleton robot behave like humans in order to provide better assistance. The exoskeleton robot is directly attached to a user's body and activated by the sEMG signals of the user's muscles, which reflect the user's motion intention. In the first proposed control method, the forces of agonist and antagonist muscles pair are estimated, and their difference is used to produce the torque of the corresponding joints. In the second method, linear discriminant analysis-based classifiers are introduced as the indicator of the motion type of the joints. Then, the classifier's outputs together with the estimated force of corresponding active muscle determine the torque control signals. Different from the conventional approaches, one classifier is assigned to each joint, which decreases the training time and largely simplifies the recognition process. Finally, the extensive experiments are conducted to illustrate the effectiveness of the proposed approaches.",
The k-Q Analysis for an LLC Series Resonant Converter,"The k-Q analysis of the resonant tank for an LLC series-resonant converter (SRC) is presented in this letter. In order to guarantee the LLC-SRC operating region, the k-Q design guideline of the resonant tank is proposed.",
Using humans as sensors: An estimation-theoretic perspective,"The explosive growth in social network content suggests that the largest “sensor network” yet might be human. Extending the participatory sensing model, this paper explores the prospect of utilizing social networks as sensor networks, which gives rise to an interesting reliable sensing problem. In this problem, individuals are represented by sensors (data sources) who occasionally make observations about the physical world. These observations may be true or false, and hence are viewed as binary claims. The reliable sensing problem is to determine the correctness of reported observations. From a networked sensing standpoint, what makes this sensing problem formulation different is that, in the case of human participants, not only is the reliability of sources usually unknown but also the original data provenance may be uncertain. Individuals may report observations made by others as their own. The contribution of this paper lies in developing a model that considers the impact of such information sharing on the analytical foundations of reliable sensing, and embed it into a tool called Apollo that uses Twitter as a “sensor network” for observing events in the physical world. Evaluation, using Twitter-based case-studies, shows good correspondence between observations deemed correct by Apollo and ground truth.",
Improved Conditions for Passivity of Neural Networks With a Time-Varying Delay,"The passivity of neural networks with a time-varying delay and norm-bounded parameter uncertainties is investigated in this paper. A complete delay-decomposing approach is employed to construct a Lyapunov-Krasovskii functional. Then, by utilizing a segmentation technique to consider the time-varying delay and its derivative and introducing some free-weighting matrices to express the relationship between the time-varying delay and its varying interval, some improved passivity criteria are derived. Finally, two numerical examples are given to show the effectiveness and the merits of the proposed method.",
Design of Optimal Sparse Interconnection Graphs for Synchronization of Oscillator Networks,"We study the optimal design of a conductance network as a means for synchronizing a given set of oscillators. Synchronization is achieved when all oscillator voltages reach consensus, and performance is quantified by the mean-square deviation from the consensus value. We formulate optimization problems that address the tradeoff between synchronization performance and the number and strength of oscillator couplings. We promote the sparsity of the coupling network by penalizing the number of interconnection links. For identical oscillators, we establish convexity of the optimization problem and demonstrate that the design problem can be formulated as a semidefinite program. Finally, for special classes of oscillator networks we derive explicit analytical expressions for the optimal conductance values.","Oscillators,
Synchronization,
Optimization,
Equations,
Couplings,
Sparse matrices,
Linear matrix inequalities"
Symmetrical SURF and Its Applications to Vehicle Detection and Vehicle Make and Model Recognition,"Speeded-Up Robust Features (SURF) is a robust and useful feature detector for various vision-based applications but it is unable to detect symmetrical objects. This paper proposes a new symmetrical SURF descriptor to enrich the power of SURF to detect all possible symmetrical matching pairs through a mirroring transformation. A vehicle make and model recognition (MMR) application is then adopted to prove the practicability and feasibility of the method. To detect vehicles from the road, the proposed symmetrical descriptor is first applied to determine the region of interest of each vehicle from the road without using any motion features. This scheme provides two advantages: there is no need for background subtraction and it is extremely efficient for real-time applications. Two MMR challenges, namely multiplicity and ambiguity problems, are then addressed. The multiplicity problem stems from one vehicle model often having different model shapes on the road. The ambiguity problem results from vehicles from different companies often sharing similar shapes. To address these two problems, a grid division scheme is proposed to separate a vehicle into several grids; different weak classifiers that are trained on these grids are then integrated to build a strong ensemble classifier. The histogram of gradient and SURF descriptors are adopted to train the weak classifiers through a support vector machine learning algorithm. Because of the rich representation power of the grid-based method and the high accuracy of vehicle detection, the ensemble classifier can accurately recognize each vehicle.",
Ubiquitous WSN for Healthcare: Recent Advances and Future Prospects,"Wireless sensor networks (WSNs) have witnessed rapid advancement in medical applications from real-time telemonitoring and computer-assisted rehabilitation to emergency response systems. In this paper, we present the state-of-the-art research from the ubiquity perspective, and discuss the insights as well as vision of future directions in WSN-based healthcare systems. First, we propose a novel tiered architecture that can be generally applied to WSN-based healthcare systems. Then, we analyze the IEEE 802 series standards in the access layer on their capabilities in setting up WSNs for healthcare. We also explore some of the up-to-date work in the application layer, mostly on the smartphone platforms. Furthermore, in order to develop and integrate effective ubiquitous sensing for healthcare (USH), we highlight four important design goals (i.e., proactiveness, transparency, awareness, and trustworthiness) that should be taken into account in future systems.","Wireless sensor networks,
Medical services,
Wireless communication,
Standards,
Monitoring,
Biomedical monitoring,
Computer architecture"
Ship Detection From Optical Satellite Images Based on Sea Surface Analysis,"Automatic ship detection in high-resolution optical satellite images with various sea surfaces is a challenging task. In this letter, we propose a novel detection method based on sea surface analysis to solve this problem. The proposed method first analyzes whether the sea surface is homogeneous or not by using two new features. Then, a novel linear function combining pixel and region characteristics is employed to select ship candidates. Finally, Compactness and Length-width ratio are adopted to remove false alarms. Specifically, based on the sea surface analysis, the proposed method cannot only efficiently block out no-candidate regions to reduce computational time, but also automatically assign weights for candidate selection function to optimize the detection performance. Experimental results on real panchromatic satellite images demonstrate the detection accuracy and computational efficiency of the proposed method.","Marine vehicles,
Sea surface,
Optical imaging,
Satellites,
Optical sensors,
Optical surface waves,
Remote sensing"
Transmission Phase Limit of Multilayer Frequency-Selective Surfaces for Transmitarray Designs,"Many transmitarray antennas are designed with multilayer frequency-selective surface (M-FSS) type elements. The goal of this paper is to reveal the transmission phase limit of M-FSS for transmitarray antenna designs. An analytical study of the transmission coefficient of multiple conductor layers separated by dielectric materials has been carried out, and the maximum transmission phase range has been determined according to the number of layers, substrate permittivity, and separation between conductor layers. It is revealed that the -1-dB transmission phase limits are 54°, 170°, 308°, and full 360 °for single-, double-, triple-, and quad-layer FSS consisting of identical layers, respectively. Furthermore, it is shown that if -3-dB criteria is used, a triple-layer FSS is sufficient to achieve the full 360 ° phase range. The effectiveness of the analytical study has been validated through numerical simulations of several representative FSS examples.","Frequency selective surfaces,
Transmitting antennas,
Substrates,
Permittivity,
Conductors,
Arrays,
Equations"
"Improvement of
V
th
Instability in Normally-Off GaN MIS-HEMTs Employing
PEALD-
SiN
x
as an Interfacial Layer","In this letter, reduction of threshold voltage instability in gate recessed normally-off GaN metal insulator semiconductor high electron mobility transistors with SiNx gate insulator was investigated. A plasma enhanced atomic layer deposition technique was successfully employed for very thin SiNx (5 nm) as an interfacial layer. The hysteresis and drift of threshold voltage in transfer curve and the forward biased gate leakage current were effectively reduced.",
Online Social Networks: Threats and Solutions,"Many online social network (OSN) users are unaware of the numerous security risks that exist in these networks, including privacy violations, identity theft, and sexual harassment, just to name a few. According to recent studies, OSN users readily expose personal and private details about themselves, such as relationship status, date of birth, school name, email address, phone number, and even home address. This information, if put into the wrong hands, can be used to harm users both in the virtual world and in the real world. These risks become even more severe when the users are children. In this paper, we present a thorough review of the different security and privacy risks, which threaten the well-being of OSN users in general, and children in particular. In addition, we present an overview of existing solutions that can provide better protection, security, and privacy for OSN users. We also offer simple-to-implement recommendations for OSN users, which can improve their security and privacy when using these platforms. Furthermore, we suggest future research directions.","Social network services,
Computer security,
Privacy,
Twitter,
Facebook,
Online services"
4W1H in mobile crowd sensing,"With the rapid proliferation of sensor-rich smartphones, mobile crowd sensing has become a popular research field. In this article, we propose a four-stage life cycle (i.e., task creation, task assignment, individual task execution, and crowd data integration) to characterize the mobile crowd sensing process, and use 4W1H (i.e., what, when, where, who, and how) to sort out the research problems in the mobile crowd sensing domain. Furthermore, we attempt to foresee some new research directions in future mobile crowd sensing research.",
Survivable Virtual Network Design and Embedding to Survive a Facility Node Failure,"As virtualization is becoming a promising way to support various emerging application, provisioning survivability to requested virtual networks (VN) in a resource efficient way is important. In this paper, we investigate the survivable VN embedding (SVNE) problem from a new perspective. First, we consider the failure dependent protection (FDP) in which each primary facility node would have a different backup facility node, as opposed to the Failure Independent Protection (FIP) which has been studied before, in order to provide the same degree of protection against a single node failure with less substrate resources. Secondly, we enhance the VN with additional computing and communication resources and design the Enhanced VN (or EVN) before embedding it to the substrate in order to further reduce the amount of substrate resources needed to survive a single facility node failure. The work is the first that combines the FDP with EVN design (FD-EVN) to explore a resource efficient solution to the SVNE problem. After presenting a binary quadratic programming (BQP) formulation of the FD-EVN design problem and a Mixed Integer Linear Programming (MILP) formulation of the EVN embedding (EVNE) problem, we propose two heuristic algorithms for FD-EVN design, as well as an EVNE algorithm that explores primary and backup substrate resources sharing. Simulations are conducted to evaluate the performance of the solutions to the BQP/MILP formulation when possible, and the heuristics. The proposed FD-EVN approach has shown to be resource efficient and in particular, outperform other approaches in terms of request acceptance ratio and embedding cost, although as a tradeoff, requiring more service migration after failures.","Substrates,
Bandwidth,
Heuristic algorithms,
Tin,
Vectors,
Algorithm design and analysis,
Educational institutions"
Exploring Permission-Induced Risk in Android Applications for Malicious Application Detection,"Android has been a major target of malicious applications (malapps). How to detect and keep the malapps out of the app markets is an ongoing challenge. One of the central design points of Android security mechanism is permission control that restricts the access of apps to core facilities of devices. However, it imparts a significant responsibility to the app developers with regard to accurately specifying the requested permissions and to the users with regard to fully understanding the risk of granting certain combinations of permissions. Android permissions requested by an app depict the app's behavioral patterns. In order to help understanding Android permissions, in this paper, we explore the permission-induced risk in Android apps on three levels in a systematic manner. First, we thoroughly analyze the risk of an individual permission and the risk of a group of collaborative permissions. We employ three feature ranking methods, namely, mutual information, correlation coefficient, and T-test to rank Android individual permissions with respect to their risk. We then use sequential forward selection as well as principal component analysis to identify risky permission subsets. Second, we evaluate the usefulness of risky permissions for malapp detection with support vector machine, decision trees, as well as random forest. Third, we in depth analyze the detection results and discuss the feasibility as well as the limitations of malapp detection based on permission requests. We evaluate our methods on a very large official app set consisting of 310 926 benign apps and 4868 real-world malapps and on a third-party app sets. The empirical results show that our malapp detectors built on risky permissions give satisfied performance (a detection rate as 94.62% with a false positive rate as 0.6%), catch the malapps' essential patterns on violating permission access regulations, and are universally applicable to unknown malapps (detection rate as 74.03%).",
Distributed Wireless Video Scheduling With Delayed Control Information,"Traditional distributed wireless video scheduling is based on perfect control channels in which instantaneous control information from the neighbors is available. However, it is difficult, sometimes even impossible, to obtain this information in practice, especially for dynamic wireless networks. Thus, neither the distortion-minimum scheduling approaches aiming to meet the longterm video quality demands nor the solutions that focus on minimum delay can be applied directly. This motivates us to investigate the distributed wireless video scheduling with delayed control information (DCI). First, to exploit in a tractable framework, we translate this scheduling problem into a stochastic optimization rather than a convex optimization problem. Next, we consider two classes of DCI distributions: 1) the class with finite mean and variance and 2) a general class that does not employ any parametric representation. In each case, we study the relationship between the DCI and scheduling performance, and provide a general performance property bound for any distributed scheduling. Subsequently, a class of distributed scheduling scheme is proposed to achieve the performance bound by making use of the correlation among the time-scale control information. Finally, we provide simulation results to demonstrate the correctness of the theoretical analysis and the efficiency of the proposed scheme.","Correlation,
Wireless networks,
Delays,
Convergence,
Streaming media,
Dynamic scheduling"
Approximate Physical World Reconstruction Algorithms in Sensor Networks,"To observe the complicated physical world, the sensors in a network sense and sample the data from the physical world. Currently, most existing works use the Equi-Frequency Sampling (EFS) methods or EFS based methods for data acquisition. However, the accuracy of EFS and EFS based methods cannot be guaranteed in practice since the physical world keeps changing continuously, and these methods do not effectively support reconstruction of the monitored physical world. To overcome the shortages of EFS and EFS based methods, this paper focuses on designing physical-world-aware data acquisition algorithms to support O(ε)-approximation to the physical world for any ε ≥ 0. Two physical-world-aware data acquisition algorithms are proposed. Both algorithms can adjust the sensing frequency automatically based on the changing trend of the physical world and the given ε. The thorough analysis on the performances of the algorithms are also provided. It is proven that the error bounds of the algorithms are O(ε) and the complexities of the algorithms are O(1/(ε1/4)). Based on the new data acquisition algorithms, an algorithm for reconstructing the physical world is proposed and analyzed. The theoretical analysis and experimental results show that the proposed algorithms have high performances on the aspects of accuracy and energy consumption.","Interpolation,
Algorithm design and analysis,
Data acquisition,
Monitoring,
Splines (mathematics),
Accuracy"
An Energy-Efficient Smart Comfort Sensing System Based on the IEEE 1451 Standard for Green Buildings,"In building automation, comfort is an important aspect, and the real-time measurement of comfort is notoriously complicated. In this paper, we have developed a wireless, smart comfort sensing system. The important parameters in designing the prevalent measurement of comfort systems, such as portability, power consumption, reliability, and system cost, were considered. To achieve the target design goals, the communication module, sensor node, and sink node were developed based on the IEEE1451 standard. Electrochemical and semiconductor sensors were considered for the development of the sensor array, and the results of both technologies were compared. The sensor and sink nodes were implemented using the ATMega88 microcontroller. Microsoft Visual Studio 2013 preview was used to create the graphical user interface in C#. The sensors were calibrated after the signal processing circuit to ensure that the standard accuracy of the sensor was achieved. This paper presents detailed design solutions to problems that existed in the literature.","Temperature sensors,
Intelligent sensors,
Temperature measurement,
Buildings,
Microcontrollers,
Humidity"
OpinionFlow: Visual Analysis of Opinion Diffusion on Social Media,"It is important for many different applications such as government and business intelligence to analyze and explore the diffusion of public opinions on social media. However, the rapid propagation and great diversity of public opinions on social media pose great challenges to effective analysis of opinion diffusion. In this paper, we introduce a visual analysis system called OpinionFlow to empower analysts to detect opinion propagation patterns and glean insights. Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model to approximate opinion propagation among Twitter users. Accordingly, we design an opinion flow visualization that combines a Sankey graph with a tailored density map in one view to visually convey diffusion of opinions among many users. A stacked tree is used to allow analysts to select topics of interest at different levels. The stacked tree is synchronized with the opinion flow visualization to help users examine and compare diffusion patterns across topics. Experiments and case studies on Twitter data demonstrate the effectiveness and usability of OpinionFlow.","Visual analytics,
Social network services,
Media,
Data visualization,
Twitter,
Information analysis"
Unsupervised Adaptation Across Domain Shifts by Generating Intermediate Data Representations,"With unconstrained data acquisition scenarios widely prevalent, the ability to handle changes in data distribution across training and testing data sets becomes important. One way to approach this problem is through domain adaptation, and in this paper we primarily focus on the unsupervised scenario where the labeled source domain training data is accompanied by unlabeled target domain test data. We present a two-stage data-driven approach by generating intermediate data representations that could provide relevant information on the domain shift. Starting with a linear representation of domains in the form of generative subspaces of same dimensions for the source and target domains, we first utilize the underlying geometry of the space of these subspaces, the Grassmann manifold, to obtain a `shortest' geodesic path between the two domains. We then sample points along the geodesic to obtain intermediate cross-domain data representations, using which a discriminative classifier is learnt to estimate the labels of the target data. We subsequently incorporate non-linear representation of domains by considering a Reproducing Kernel Hilbert Space representation, and a low-dimensional manifold representation using Laplacian Eigenmaps, and also examine other domain adaptation settings such as (i) semi-supervised adaptation where the target domain is partially labeled, and (ii) multi-domain adaptation where there could be more than one domain in source and/or target data sets. Finally, we supplement our adaptation technique with (i) fine-grained reference domains that are created by blending samples from source and target data sets to provide some evidence on the actual domain shift, and (ii) a multi-class boosting analysis to obtain robustness to the choice of algorithm parameters. We evaluate our approach for object recognition problems and report competitive results on two widely used Office and Bing adaptation data sets.",
H.264/AVC to HEVC Video Transcoder Based on Dynamic Thresholding and Content Modeling,"The new video coding standard, High Efficiency Video Coding (HEVC), was developed to succeed the current standard, H.264/AVC, as the state of the art in video compression. However, there is a lot of legacy content encoded with H.264/AVC. This paper proposes and evaluates several transcoding algorithms from the H.264/AVC to the HEVC format. In particular, a novel transcoding architecture, in which the first frames of the sequence are used to compute the parameters so that the transcoder can learn the mapping for that particular sequence, is proposed. Then, two types of mode mapping algorithms are proposed. In the first solution, a single H.264/AVC coding parameter is used to determine the outgoing HEVC partitions using dynamic thresholding. The second solution uses linear discriminant functions to map the incoming H.264/AVC coding parameters to the outgoing HEVC partitions. This paper contains experiments designed to study the impact of the number of frames used for training in the transcoder. Comparisons with existing transcoding solutions reveal that the proposed work results in lower rate-distortion loss at a competitive complexity performance.","Video coding,
Transcoding,
Vectors,
Training,
Discrete cosine transforms,
Measurement,
Transform coding"
Flexible Indoor Localization and Tracking Based on a Wearable Platform and Sensor Data Fusion,"Indoor localization and tracking of moving human targets is a task of recognized importance and difficulty. In this paper, we describe a position measurement technique based on the fusion of various sensor data collected using a wearable embedded platform. Since the accumulated measurement uncertainty affecting inertial data (especially due to the on-board accelerometer) usually makes the measured position values drift away quickly, a heuristic approach is used to keep velocity estimation uncertainty in the order of a few percent. As a result, unlike other solutions proposed in the literature, localization accuracy is good when the wearable platform is worn at the waist. Unbounded uncertainty growth is prevented by injecting the position values collected at a very low rate from the nodes of an external fixed infrastructure (e.g., based on cameras) into an extended Kalman filter. If the adjustment rate is in the order of several seconds and if such corrections are performed only when the user is detected to be in movement, the infrastructure remains idle most of time with evident benefits in terms of scalability. In fact, multiple platforms could work simultaneously in the same environment without saturating the communication channels.","Accuracy,
Acceleration,
Uncertainty,
Estimation,
Vectors,
Covariance matrices,
Velocity measurement"
Sybil Attacks and Their Defenses in the Internet of Things,"The emerging Internet-of-Things (IoT) are vulnerable to Sybil attacks where attackers can manipulate fake identities or abuse pseudoidentities to compromise the effectiveness of the IoT and even disseminate spam. In this paper, we survey Sybil attacks and defense schemes in IoT. Specifically, we first define three types Sybil attacks: SA-1, SA-2, and SA-3 according to the Sybil attacker's capabilities. We then present some Sybil defense schemes, including social graph-based Sybil detection (SGSD), behavior classification-based Sybil detection (BCSD), and mobile Sybil detection with the comprehensive comparisons. Finally, we discuss the challenging research issues and future directions for Sybil defense in IoT.","Mobile communication,
Ubiquitous computing,
Social network services,
Network security,
Computer security,
Mobile computing"
Last-Position Elimination-Based Learning Automata,"An update scheme of the state probability vector of actions is critical for learning automata (LA). The most popular is the pursuit scheme that pursues the estimated optimal action and penalizes others. This paper proposes a reverse philosophy that leads to last-position elimination-based learning automata (LELA). The action graded last in terms of the estimated performance is penalized by decreasing its state probability and is eliminated when its state probability becomes zero. All active actions, that is, actions with nonzero state probability, equally share the penalized state probability from the last-position action at each iteration. The proposed LELA is characterized by the relaxed convergence condition for the optimal action, the accelerated step size of the state probability update scheme for the estimated optimal action, and the enriched sampling for the estimated nonoptimal actions. The proof of the E-optimal property for the proposed algorithm is presented. Last-position elimination is a widespread philosophy in the real world and has proved to be also helpful for the update scheme of the learning automaton via the simulations of well-known benchmark environments. In the simulations, two versions of the LELA, using different selection strategies of the last action, are compared with the classical pursuit algorithms Discretized Pursuit RewardInaction (DPRI) and Discretized Generalized Pursuit Algorithm (DGPA). Simulation results show that the proposed schemes achieve significantly faster convergence and higher accuracy than the classical ones. Specifically, the proposed schemes reduce the interval to find the best parameter for a specific environment in the classical pursuit algorithms. Thus, they can have their parameter tuning easier to perform and can save much more time when applied to a practical case. Furthermore, the convergence curves and the corresponding variance coefficient curves of the contenders are illustrated to characterize their essential differences and verify the analysis results of the proposed algorithms.",
A Privacy-Preserving Attribute-Based Authentication System for Mobile Health Networks,"Electronic healthcare (eHealth) systems have replaced paper-based medical systems due to the attractive features such as universal accessibility, high accuracy, and low cost. As a major component of eHealth systems, mobile healthcare (mHealth) applies mobile devices, such as smartphones and tablets, to enable patient-to-physician and patient-to-patient communications for better healthcare and quality of life (QoL). Unfortunately, patients' concerns on potential leakage of personal health records (PHRs) is the biggest stumbling block. In current eHealth/mHealth networks, patients' medical records are usually associated with a set of attributes like existing symptoms and undergoing treatments based on the information collected from portable devices. To guarantee the authenticity of those attributes, PHRs should be verifiable. However, due to the linkability between identities and PHRs, existing mHealth systems fail to preserve patient identity privacy while providing medical services. To solve this problem, we propose a decentralized system that leverages users' verifiable attributes to authenticate each other while preserving attribute and identity privacy. Moreover, we design authentication strategies with progressive privacy requirements in different interactions among participating entities. Finally, we have thoroughly evaluated the security and computational overheads for our proposed schemes via extensive simulations and experiments.","Privacy,
Medical services,
Authentication,
Medical diagnostic imaging,
Mobile computing,
Cryptography"
Adaptive PI Control of STATCOM for Voltage Regulation,"STATCOM can provide fast and efficient reactive power support to maintain power system voltage stability. In the literature, various STATCOM control methods have been discussed including many applications of proportional-integral (PI) controllers. However, these previous works obtain the PI gains via a trial-and-error approach or extensive studies with a tradeoff of performance and applicability. Hence, control parameters for the optimal performance at a given operating point may not be effective at a different operating point. This paper proposes a new control model based on adaptive PI control, which can self-adjust the control gains during a disturbance such that the performance always matches a desired response, regardless of the change of operating condition. Since the adjustment is autonomous, this gives the plug-and-play capability for STATCOM operation. In the simulation test, the adaptive PI control shows consistent excellence under various operating conditions, such as different initial control gains, different load levels, change of transmission network, consecutive disturbances, and a severe disturbance. In contrast, the conventional STATCOM control with tuned, fixed PI gains usually perform fine in the original system, but may not perform as efficient as the proposed control method when there is a change of system conditions.",
ML-Reconstruction for TOF-PET With Simultaneous Estimation of the Attenuation Factors,"In positron emission tomography (PET), attenuation correction is typically done based on information obtained from transmission tomography. Recent studies show that time-of-flight (TOF) PET emission data allow joint estimation of activity and attenuation images. Mathematical analysis revealed that the joint estimation problem is determined up to a scale factor. In this work, we propose a maximum likelihood reconstruction algorithm that jointly estimates the activity image together with the sinogram of the attenuation factors. The algorithm is evaluated with 2-D and 3-D simulations as well as clinical TOF-PET measurements of a patient scan and compared to reference reconstructions. The robustness of the algorithm to possible imperfect scanner calibration is demonstrated with reconstructions of the patient scan ignoring the varying detector sensitivities.","Attenuation,
Image reconstruction,
Noise,
Sensitivity,
Positron emission tomography,
Three-dimensional displays,
Detectors"
Loose-Ordering Consistency for persistent memory,"Emerging non-volatile memory (NVM) technologies enable data persistence at the main memory level at access speeds close to DRAM. In such persistent memories, memory writes need to be performed in strict order to satisfy storage consistency requirements and enable correct recovery from system crashes. Unfortunately, adhering to a strict order for writes to persistent memory significantly degrades system performance as it requires flushing dirty data blocks from CPU caches and waiting for their completion at the main memory in the order specified by the program. This paper introduces a new mechanism, called Loose-Ordering Consistency (LOC), that satisfies the ordering requirements of persistent memory writes at significantly lower performance degradation than state-of-the-art mechanisms. LOC consists of two key techniques. First, Eager Commit reduces the commit overhead for writes within a transaction by eliminating the need to perform a persistent commit record write at the end of a transaction. We do so by ensuring that we can determine the status of all committed transactions during recovery by storing necessary metadata information statically with blocks of data written to memory. Second, Speculative Persistence relaxes the ordering of writes between transactions by allowing writes to be speculatively written to persistent memory. A speculative write is made visible to software only after its associated transaction commits. To enable this, our mechanism requires the tracking of committed transaction ID and support for multi-versioning in the CPU cache. Our evaluations show that LOC reduces the average performance overhead of strict write ordering from 66.9% to 34.9% on a variety of workloads.","Protocols,
Memory management,
Computer crashes,
Software,
Hardware,
Random access memory,
Nonvolatile memory"
Inkjet-Printed Microstrip Patch Antennas Realized on Textile for Wearable Applications,This letter introduces a new technique of inkjet printing antennas on textiles. A screen-printed interface layer was used to reduce the surface roughness of the polyester/cotton material that facilitated the printing of a continuous conducting surface. Conducting ink was used to create three inkjet-printed microstrip patch antennas. An efficiency of 53% was achieved for a fully flexible antenna with two layers of ink. Measurements of the antennas bent around a polystyrene cylinder indicated that a second layer of ink improved the robustness to bending.,
Modeling and Rendering Realistic Textures from Unconstrained Tool-Surface Interactions,"Texture gives real objects an important perceptual dimension that is largely missing from virtual haptic interactions due to limitations of standard modeling and rendering approaches. This paper presents a set of methods for creating a haptic texture model from tool-surface interaction data recorded by a human in a natural and unconstrained manner. The recorded high-frequency tool acceleration signal, which varies as a function of normal force and scanning speed, is segmented and modeled as a piecewise autoregressive (AR) model. Each AR model is labeled with the source segment's median force and speed values and stored in a Delaunay triangulation to create a model set for a given texture. We use these texture model sets to render synthetic vibration signals in real time as a user interacts with our TexturePad system, which includes a Wacom tablet and a stylus augmented with a Haptuator. We ran a human-subject study with two sets of ten participants to evaluate the realism of our virtual textures and the strengths and weaknesses of this approach. The results indicated that our virtual textures accurately capture and recreate the roughness of real textures, but other modeling and rendering approaches are required to completely match surface hardness and slipperiness.","Force,
Haptic interfaces,
Acceleration,
Vibrations,
Materials,
Rendering (computer graphics),
Data models"
"Linear Degrees of Freedom of the
X
-Channel With Delayed CSIT","We establish the degrees of freedom (DoF) of the two-user X-channel with delayed channel knowledge at transmitters [i.e., delayed channel state information at the transmitters (CSIT)], assuming linear coding strategies at the transmitters. We derive a new upper bound and characterize the linear DoF of this network to be 6/5. The converse builds upon our development of a general lemma that shows that, if two distributed transmitters employ linear strategies, the ratio of the dimensions of received linear subspaces at the two receivers cannot exceed 3/2, due to delayed CSIT. As a byproduct, we also apply this general lemma to the three-user interference channel with delayed CSIT, thereby deriving a new upper bound of 9/7 on its linear DoF. This is the first bound that captures the impact of delayed CSIT on the DoF of this network, under the assumption of linear encoding strategies.","Transmitters,
Receivers,
Interference,
Vectors,
Encoding,
Equations,
Entropy"
"Low-Rank Modeling of Local
k
-Space Neighborhoods (LORAKS) for Constrained MRI","Recent theoretical results on low-rank matrix reconstruction have inspired significant interest in low-rank modeling of MRI images. Existing approaches have focused on higher-dimensional scenarios with data available from multiple channels, timepoints, or image contrasts. The present work demonstrates that single-channel, single-contrast, single-timepoint k-space data can also be mapped to low-rank matrices when the image has limited spatial support or slowly varying phase. Based on this, we develop a novel and flexible framework for constrained image reconstruction that uses low-rank matrix modeling of local k-space neighborhoods (LORAKS). A new regularization penalty and corresponding algorithm for promoting low-rank are also introduced. The potential of LORAKS is demonstrated with simulated and experimental data for a range of denoising and sparse-sampling applications. LORAKS is also compared against state-of-the-art methods like homodyne reconstruction, l1-norm minimization, and total variation minimization, and is demonstrated to have distinct features and advantages. In addition, while calibration-based support and phase constraints are commonly used in existing methods, the LORAKS framework enables calibrationless use of these constraints.","Approximation methods,
Fourier transforms,
Image reconstruction,
Magnetic resonance imaging,
Matrix decomposition"
The Fog computing paradigm: Scenarios and security issues,"Fog Computing is a paradigm that extends Cloud computing and services to the edge of the network. Similar to Cloud, Fog provides data, compute, storage, and application services to end-users. In this article, we elaborate the motivation and advantages of Fog computing, and analyse its applications in a series of real scenarios, such as Smart Grid, smart traffic lights in vehicular networks and software defined networks. We discuss the state-of-the-art of Fog computing and similar work under the same umbrella. Security and privacy issues are further disclosed according to current Fog computing paradigm. As an example, we study a typical attack, man-in-the-middle attack, for the discussion of security in Fog computing. We investigate the stealthy features of this attack by examining its CPU and memory consumption on Fog device.","Cloud computing,
Security,
Companies,
Intelligent sensors,
Logic gates,
Wireless sensor networks"
Diversity Comparison of Pareto Front Approximations in Many-Objective Optimization,"Diversity assessment of Pareto front approximations is an important issue in the stochastic multiobjective optimization community. Most of the diversity indicators in the literature were designed to work for any number of objectives of Pareto front approximations in principle, but in practice many of these indicators are infeasible or not workable when the number of objectives is large. In this paper, we propose a diversity comparison indicator (DCI) to assess the diversity of Pareto front approximations in many-objective optimization. DCI evaluates relative quality of different Pareto front approximations rather than provides an absolute measure of distribution for a single approximation. In DCI, all the concerned approximations are put into a grid environment so that there are some hyperboxes containing one or more solutions. The proposed indicator only considers the contribution of different approximations to nonempty hyperboxes. Therefore, the computational cost does not increase exponentially with the number of objectives. In fact, the implementation of DCI is of quadratic time complexity, which is fully independent of the number of divisions used in grid. Systematic experiments are conducted using three groups of artificial Pareto front approximations and seven groups of real Pareto front approximations with different numbers of objectives to verify the effectiveness of DCI. Moreover, a comparison with two diversity indicators used widely in many-objective optimization is made analytically and empirically. Finally, a parametric investigation reveals interesting insights of the division number in grid and also offers some suggested settings to the users with different preferences.",
A Novel Approach to Mapped Correlation of ID for RFID Anti-Collision,"One of the key problems that should be solved is the collision between tags which lowers the efficiency of the RFID system. The existed popular anti-collision algorithms are ALOHA-type algorithms and QT. But these methods show good performance when the number of tags to read is small and not dynamic. However, when the number of tags to read is large and dynamic, the efficiency of recognition is very low. A novel approach to mapped correlation of ID for RFID anti-collision has been proposed to solve the problem in this paper. This method can increase the association between tags so that tags can send their own ID under certain trigger conditions, by mapped correlation of ID, querying on multi-tree becomes more efficient. In the case of not too big number of tags, by replacing the actual ID with the temporary ID, the method can greatly reduce the number of times that the reader reads and writes to tag's ID. In the case of dynamic ALOHA-type applications, the reader can determine the locations of the empty slots according to the position of the binary pulse, so it can avoid the decrease in efficiency which is caused by reading empty slots when reading slots. Experiments have shown this method can greatly improve the recognition efficiency of the system.","Radiofrequency identification,
Heuristic algorithms,
Algorithm design and analysis,
Encoding,
RFID tags,
Multiaccess communication"
"Noncontact Monitoring Breathing Pattern, Exhalation Flow Rate and Pulse Transit Time","We present optical imaging-based methods to measure vital physiological signals, including breathing frequency (BF), exhalation flow rate, heart rate (HR), and pulse transit time (PTT). The breathing pattern tracking was based on the detection of body movement associated with breathing using a differential signal processing approach. A motion-tracking algorithm was implemented to correct random body movements that were unrelated to breathing. The heartbeat pattern was obtained from the color change in selected region of interest (ROI) near the subject's mouth, and the PTT was determined by analyzing pulse patterns at different body parts of the subject. The measured BF, exhaled volume flow rate and HR are consistent with those measured simultaneously with reference technologies (r = 0.98, p <; 0.001 for HR; r = 0.93, p <; 0.001 for breathing rate), and the measured PTT difference (30-40 ms between mouth and palm) is comparable to the results obtained with other techniques in the literature. The imaging-based methods are suitable for tracking vital physiological parameters under free-living condition and this is the first demonstration of using noncontact method to obtain PTT difference and exhalation flow rate.","Heart beat,
Biomedical monitoring,
Noise,
Frequency measurement,
Cameras"
Gate Recessed Quasi-Normally OFF Al2O3/AlGaN/GaN MIS-HEMT With Low Threshold Voltage Hysteresis Using PEALD AlN Interfacial Passivation Layer,"In this letter, a gate recessed normally OFF AlGaN/GaN MIS-HEMT with low threshold voltage hysteresis using Al2O3/AlN stack gate insulator is presented. The trapping effect of Al2O3/GaN interface was effectively reduced with the insertion of 2-nm AlN thin interfacial passivation layer grown by plasma enhanced atomic layer deposition. The device exhibits a threshold voltage of +1.5 V, with current density of 420 mA/mm, an OFF-state breakdown voltage of 600 V, and high ON/OFF drain current ratio of ~109.","Gallium nitride,
III-V semiconductor materials,
Aluminum oxide,
Logic gates,
Aluminum gallium nitride,
Hysteresis,
Insulators"
"Generalized Hidden-Mapping Ridge Regression, Knowledge-Leveraged Inductive Transfer Learning for Neural Networks, Fuzzy Systems and Kernel Methods","Inductive transfer learning has attracted increasing attention for the training of effective model in the target domain by leveraging the information in the source domain. However, most transfer learning methods are developed for a specific model, such as the commonly used support vector machine, which makes the methods applicable only to the adopted models. In this regard, the generalized hidden-mapping ridge regression (GHRR) method is introduced in order to train various types of classical intelligence models, including neural networks, fuzzy logical systems and kernel methods. Furthermore, the knowledge-leverage based transfer learning mechanism is integrated with GHRR to realize the inductive transfer learning method called transfer GHRR (TGHRR). Since the information from the induced knowledge is much clearer and more concise than that from the data in the source domain, it is more convenient to control and balance the similarity and difference of data distributions between the source and target domains. The proposed GHRR and TGHRR algorithms have been evaluated experimentally by performing regression and classification on synthetic and real world datasets. The results demonstrate that the performance of TGHRR is competitive with or even superior to existing state-of-the-art inductive transfer learning algorithms.","Neural networks,
Kernel,
Learning systems,
Data models,
Fuzzy systems,
Support vector machines,
Linear regression"
An Evolutionary Multiobjective Approach to Sparse Reconstruction,"This paper addresses the problem of finding sparse solutions to linear systems. Although this problem involves two competing cost function terms (measurement error and a sparsity-inducing term), previous approaches combine these into a single cost term and solve the problem using conventional numerical optimization methods. In contrast, the main contribution of this paper is to use a multiobjective approach. The paper begins by investigating the sparse reconstruction problem, and presents data to show that knee regions do exist on the Pareto front (PF) for this problem and that optimal solutions can be found in these knee regions. Another contribution of the paper, a new soft-thresholding evolutionary multiobjective algorithm (StEMO), is then presented, which uses a soft-thresholding technique to incorporate two additional heuristics: one with greater chance to increase speed of convergence toward the PF, and another with higher probability to improve the spread of solutions along the PF, enabling an optimal solution to be found in the knee region. Experiments are presented, which show that StEMO significantly outperforms five other well known techniques that are commonly used for sparse reconstruction. Practical applications are also demonstrated to fundamental problems of recovering signals and images from noisy data.","Equations,
Sociology,
Statistics,
Evolutionary computation,
Optimization,
Search problems,
Measurement errors"
Comparative Validation of Single-Shot Optical Techniques for Laparoscopic 3-D Surface Reconstruction,"Intra-operative imaging techniques for obtaining the shape and morphology of soft-tissue surfaces in vivo are a key enabling technology for advanced surgical systems. Different optical techniques for 3-D surface reconstruction in laparoscopy have been proposed, however, so far no quantitative and comparative validation has been performed. Furthermore, robustness of the methods to clinically important factors like smoke or bleeding has not yet been assessed. To address these issues, we have formed a joint international initiative with the aim of validating different state-of-the-art passive and active reconstruction methods in a comparative manner. In this comprehensive in vitro study, we investigated reconstruction accuracy using different organs with various shape and texture and also tested reconstruction robustness with respect to a number of factors like the pose of the endoscope as well as the amount of blood or smoke present in the scene. The study suggests complementary advantages of the different techniques with respect to accuracy, robustness, point density, hardware complexity and computation time. While reconstruction accuracy under ideal conditions was generally high, robustness is a remaining issue to be addressed. Future work should include sensor fusion and in vivo validation studies in a specific clinical context. To trigger further research in surface reconstruction, stereoscopic data of the study will be made publically available at www.open-CAS.com upon publication of the paper.","Endoscopes,
Image reconstruction,
Surface reconstruction,
Three-dimensional displays,
Surgery,
Robustness,
Reconstruction algorithms"
Lagrange Stability of Memristive Neural Networks With Discrete and Distributed Delays,"Memristive neuromorphic system is a good candidate for creating artificial brain. In this paper, a general class of memristive neural networks with discrete and distributed delays is introduced and studied. Some Lagrange stability criteria dependent on the network parameters are derived via nonsmooth analysis and control theory. In particular, several succinct criteria are provided to ascertain the Lagrange stability of memristive neural networks with and without delays. The proposed Lagrange stability criteria are the improvement and extension of the existing results in the literature. Three numerical examples are given to show the superiority of theoretical results.","Stability criteria,
Delays,
Trajectory,
Biological neural networks,
Memristors"
Non-Naive Bayesian Classifiers for Classification Problems With Continuous Attributes,"An important way to improve the performance of naive Bayesian classifiers (NBCs) is to remove or relax the fundamental assumption of independence among the attributes, which usually results in an estimation of joint probability density function (p.d.f.) instead of the estimation of marginal p.d.f. in the NBC design. This paper proposes a non-naive Bayesian classifier (NNBC) in which the independence assumption is removed and the marginal p.d.f. estimation is replaced by the joint p.d.f. estimation. A new technique of estimating the class-conditional p.d.f. based on the optimal bandwidth selection, which is the crucial part of the joint p.d.f. estimation, is applied in our NNBC. Three well-known indexes for measuring the performance of Bayesian classifiers, which are classification accuracy, area under receiver operating characteristic curve, and probability mean square error, are adopted to conduct a comparison among the four Bayesian models, i.e., normal naive Bayesian, flexible naive Bayesian (FNB), the homologous model of FNB (FNBROT), and our proposed NNBC. The comparative results show that NNBC is statistically superior to the other three models regarding the three indexes. And, in the comparison with support vector machine and four boosting-based classification methods, NNBC achieves a relatively favorable classification accuracy while significantly reducing the training time.","Estimation,
Bandwidth,
Bayes methods,
Joints,
Equations,
Kernel,
Reactive power"
Hybridization of Decomposition and Local Search for Multiobjective Optimization,"Combining ideas from evolutionary algorithms, decomposition approaches, and Pareto local search, this paper suggests a simple yet efficient memetic algorithm for combinatorial multiobjective optimization problems: memetic algorithm based on decomposition (MOMAD). It decomposes a combinatorial multiobjective problem into a number of single objective optimization problems using an aggregation method. MOMAD evolves three populations: 1) population PL for recording the current solution to each subproblem; 2) population PP for storing starting solutions for Pareto local search; and 3) an external population PE for maintaining all the nondominated solutions found so far during the search. A problem-specific single objective heuristic can be applied to these subproblems to initialize the three populations. At each generation, a Pareto local search method is first applied to search a neighborhood of each solution in PP to update PL and PE. Then a single objective local search is applied to each perturbed solution in PL for improving PL and PE, and reinitializing PP. The procedure is repeated until a stopping condition is met. MOMAD provides a generic hybrid multiobjective algorithmic framework in which problem specific knowledge, well developed single objective local search and heuristics and Pareto local search methods can be hybridized. It is a population based iterative method and thus an anytime algorithm. Extensive experiments have been conducted in this paper to study MOMAD and compare it with some other state-of-the-art algorithms on the multiobjective traveling salesman problem and the multiobjective knapsack problem. The experimental results show that our proposed algorithm outperforms or performs similarly to the best so far heuristics on these two problems.","Search problems,
Sociology,
Vectors,
Pareto optimization,
Approximation methods"
Comparative Analysis Between Two-Level and Three-Level DC/AC Electric Vehicle Traction Inverters Using a Novel DC-Link Voltage Balancing Algorithm,"This paper presents an extensive comparative study between a two- and three-level inverter for electric vehicle traction applications. An advanced control strategy for balancing the two dc-link capacitors is also proposed. In this paper, the main focus is on the total voltage harmonic distortion (%THDv), the analytical derivation of the three-level capacitor currents, and the voltage balancing of two capacitor voltages. For generating the gate signals, space vector pulse width modulation (SV-PWM) is used. The developed voltage-balancing scheme helps to reduce the number of converter switching sequences, compared with the conventional SV-PWM strategy, and keeps the voltage difference between the two dc-link capacitors at the desired voltage level. The developed test-bench is used for a permanent magnet synchronous machine drive for electric vehicle (EV) applications. Detailed simulation studies are performed using MATLAB/Simulink block set and experimental verification is achieved using dSpace based real-time simulator. Both the simulation and experimental results show a significant improvement in reduction of total harmonic distortion (%THDv) for the three-level inverter.","Vectors,
Inverters,
Capacitors,
Switches,
Switching frequency,
Switching loss,
Topology"
Fast Transient Boundary Control and Steady-State Operation of the Dual Active Bridge Converter Using the Natural Switching Surface,"This paper presents a boundary control scheme for dual active bridge (DAB) converters using the natural switching surface (NSS). The implementation of a curved switching surface for DAB converters is a new area of research undertaken in this paper. The proposed technique brings the benefit of unprecedented dynamic performance, already developed for nonisolated topologies (e.g., buck and boost), to this more complex isolated topology. The analysis provides insight into the natural trajectories of the DAB converters and creates an accurate framework in the normalized geometrical domain. As a result, the physical limits of the converter under study become evident. Those physical limits are exploited by employing the NSS to obtain fast transient response under start-up, sudden load transients, and reference change. In addition, fixed-frequency operation is one of the key features of the proposed control scheme, which allows optimizing the design of the high-frequency transformer. Experimental results are presented to validate the NSS for DAB converters and illustrate the benefits of the normalization technique.","Trajectory,
Switches,
Steady-state,
Bridge circuits,
Inductors,
Transient analysis"
Dynamic search in fireworks algorithm,"We propose an improved version of the recently developed Enhanced Fireworks Algorithm (EFWA) based on an adaptive dynamic local search mechanism. In EFWA, the explosion amplitude (i.e., search area around the current location) of each firework is computed based on the quality of the firework's current location. This explosion amplitude is limited by a lower bound which decreases with the number of iterations in order to avoid the explosion amplitude to be [close to] zero, and in order to enhance global search abilities at the beginning and local search abilities towards the later phase of the algorithm. As the explosion amplitude in EFWA depends solely on the fireworks' fitness and the current number of iterations, this procedure does not allow for an adaptive optimization process. To deal with these limitations, we propose the Dynamic Search Fireworks Algorithm (dynFWA) which uses a dynamic explosion amplitude for the firework at the currently best position. If the fitness of the best firework could be improved, the explosion amplitude will increase in order to speed up convergence. On the contrary, if the current position of the best firework could not be improved, the explosion amplitude will decrease in order to narrow the search area. In addition, we show that one of the EFWA operators can be removed in dynFWA without a loss in accuracy - this makes dynFWA computationally more efficient than EFWA. Experiments on 28 benchmark functions indicate that dynFWA is able to significantly outperform EFWA, and achieves better performance than the latest SPSO version SPSO2011.",
Contextual Hashing for Large-Scale Image Search,"With the explosive growth of the multimedia data on the Web, content-based image search has attracted considerable attentions in the multimedia and the computer vision community. The most popular approach is based on the bag-of-visual-words model with invariant local features. Since the spatial context information among local features is critical for visual content identification, many methods exploit the geometric clues of local features, including the location, the scale, and the orientation, for explicitly post-geometric verification. However, usually only a few initially top-ranked results are geometrically verified, considering the high computational cost in full geometric verification. In this paper, we propose to represent the spatial context of local features into binary codes, and implicitly achieve geometric verification by efficient comparison of the binary codes. Besides, we explore the multimode property of local features to further boost the retrieval performance. Experiments on holidays, Paris, and Oxford building benchmark data sets demonstrate the effectiveness of the proposed algorithm.","Binary codes,
Visualization,
Context,
Feature extraction,
Vectors,
Indexing,
Hamming distance"
Feature Selection Inspired Classifier Ensemble Reduction,"Classifier ensembles constitute one of the main research directions in machine learning and data mining. The use of multiple classifiers generally allows better predictive performance than that achievable with a single model. Several approaches exist in the literature that provide means to construct and aggregate such ensembles. However, these ensemble systems contain redundant members that, if removed, may further increase group diversity and produce better results. Smaller ensembles also relax the memory and storage requirements, reducing system's run-time overhead while improving overall efficiency. This paper extends the ideas developed for feature selection problems to support classifier ensemble reduction, by transforming ensemble predictions into training samples, and treating classifiers as features. Also, the global heuristic harmony search is used to select a reduced subset of such artificial features, while attempting to maximize the feature subset evaluation. The resulting technique is systematically evaluated using high dimensional and large sized benchmark datasets, showing a superior classification performance against both original, unreduced ensembles, and randomly formed subsets.","Training,
Accuracy,
Educational institutions,
Complexity theory,
Diversity reception,
Nickel,
Cybernetics"
Investigation of Conducted EMI in SiC JFET Inverters Using Separated Heat Sinks,"This paper systematically investigates the conducted electromagnetic interference (EMI) using separated heat sinks for a silicon carbide (SiC) JFET inverter for motor drives. The inverter circuit layout is implemented with discrete SiC JFETs attached on top of the heat sink, which creates extensive capacitive couplings and moreover increases parasitic oscillations. To minimize the influence, the solution of using separated heat sinks is proposed. For better common mode performance, the high-side heat sink is grounded to avoid fast dv/dts that occur between the drain of the lower switch and the low-side heat sink. For better differential mode performance, the RC snubber circuit and ferrite beads are used to damp parasitic oscillations. Two 2.2 kW inverter prototypes, with six discrete SiC JFETs on one common heat sink and separated heat sinks, respectively, are built using the same circuit layout. Their EMI spectra are compared under unfiltered and filtered conditions. The experiments show that the separate heat sinks inverter system exhibits significantly reduced EMI. Last, three improved solutions are proposed, which effectively suppresses the emitted EMI to the target level.","Heat sinks,
Silicon carbide,
Switches,
Inverters,
Capacitors,
JFETs,
Oscillators"
Evolutionary Dynamics of Information Diffusion Over Social Networks,"Current social networks are of extremely large-scale generating tremendous information flows at every moment. How information diffuses over social networks has attracted much attention from both industry and academics. Most of the existing works on information diffusion analysis are based on machine learning methods focusing on social network structure analysis and empirical data mining. However, the network users' decisions, actions, and socio-economic interactions are generally ignored by most of existing works. In this paper, we propose an evolutionary game theoretic framework to model the dynamic information diffusion process in social networks. Specifically, we derive the information diffusion dynamics in complete networks, uniform degree, and nonuniform degree networks, with the highlight of two special networks, the Erdös-Rényi random network and the Barabási-Albert scale-free network. We find that the dynamics of information diffusion over these three kinds of networks are scale-free and all the three dynamics are same with each other when the network scale is sufficiently large. To verify our theoretical analysis, we perform simulations for the information diffusion over synthetic networks and real-world Facebook networks. Moreover, we also conduct an experiment on a Twitter hashtags dataset, which shows that the proposed game theoretic model can well fit and predict the information diffusion over real social networks.","Games,
Twitter,
Diffusion processes,
Sociology,
Statistics,
Analytical models"
Image Set-Based Collaborative Representation for Face Recognition,"With the rapid development of digital imaging and communication technologies, image set-based face recognition (ISFR) is becoming increasingly important. One key issue of ISFR is how to effectively and efficiently represent the query face image set using the gallery face image sets. The set-to-set distance-based methods ignore the relationship between gallery sets, whereas representing the query set images individually over the gallery sets ignores the correlation between query set images. In this paper, we propose a novel image set-based collaborative representation and classification method for ISFR. By modeling the query set as a convex or regularized hull, we represent this hull collaboratively over all the gallery sets. With the resolved representation coefficients, the distance between the query set and each gallery set can then be calculated for classification. The proposed model naturally and effectively extends the image-based collaborative representation to an image set based one, and our extensive experiments on benchmark ISFR databases show the superiority of the proposed method to state-of-the-art ISFR methods under different set sizes in terms of both recognition rate and efficiency.","Collaboration,
Face recognition,
Computational modeling,
Kernel,
Correlation,
Support vector machines,
Face"
Maximizing Sum Rates in Cognitive Radio Networks: Convex Relaxation and Global Optimization Algorithms,"A key challenge in wireless cognitive radio networks is to maximize the total throughput also known as the sum rates of all the users while avoiding the interference of unlicensed band secondary users from overwhelming the licensed band primary users. We study the weighted sum rate maximization problem with both power budget and interference temperature constraints in a cognitive radio network. This problem is nonconvex and generally hard to solve. We propose a reformulation-relaxation technique that leverages nonnegative matrix theory to first obtain a relaxed problem with nonnegative matrix spectral radius constraints. A useful upper bound on the sum rates is then obtained by solving a convex optimization problem over a closed bounded convex set. It also enables the sum-rate optimality to be quantified analytically through the spectrum of specially-crafted nonnegative matrices. Furthermore, we obtain polynomial-time verifiable sufficient conditions that can identify polynomial-time solvable problem instances, which can be solved by a fixed-point algorithm. As a by-product, an interesting optimality equivalence between the nonconvex sum rate problem and the convex max-min rate problem is established. In the general case, we propose a global optimization algorithm by utilizing our convex relaxation and branch-and-bound to compute an ε-optimal solution. Our technique exploits the nonnegativity of the physical quantities, e.g., channel parameters, powers and rates, that enables key tools in nonnegative matrix theory such as the (linear and nonlinear) Perron-Frobenius theorem, quasi-invertibility, Friedland-Karlin inequalities to be employed naturally. Numerical results are presented to show that our proposed algorithms are theoretically sound and have relatively fast convergence time even for large-scale problems","Interference,
Optimization,
Cognitive radio,
Algorithm design and analysis,
Upper bound"
Sparse Multi-Modal Hashing,"Learning hash functions across heterogenous high-dimensional features is very desirable for many applications involving multi-modal data objects. In this paper, we propose an approach to obtain the sparse codesets for the data objects across different modalities via joint multi-modal dictionary learning, which we call sparse multi-modal hashing (abbreviated as SM2H). In SM2H, both intra-modality similarity and inter-modality similarity are first modeled by a hypergraph, then multi-modal dictionaries are jointly learned by Hypergraph Laplacian sparse coding. Based on the learned dictionaries, the sparse codeset of each data object is acquired and conducted for multi-modal approximate nearest neighbor retrieval using a sensitive Jaccard metric. The experimental results show that SM2H outperforms other methods in terms of mAP and Percentage on two real-world data sets.","Dictionaries,
Dinosaurs,
Correlation,
Search problems,
Artificial neural networks,
Data models,
Feature extraction"
Influence of Leading Design Parameters on the Force Performance of a Complementary and Modular Linear Flux-Switching Permanent-Magnet Motor,"This paper investigates the influence of some leading design parameters on the force performance of a new complementary and modular linear flux-switching permanent-magnet (LFSPM) motor. The originality of the proposed structure is that each phase consists of two “E”-shaped modules, whose positions are mutually 180 ° electrical degrees apart. Also, there is a flux barrier between the two modules. First, the structure and influence of some leading design parameters on the force performance of the complementary and modular LFSPM motor are analyzed. Then, a conventional LFSPM motor obtained directly from a rotary FSPM motor is optimized and compared with the complementary and modular LFSPM motor based on finite-element method. The results reveal that the proposed motor has sinusoidal and symmetrical three-phase back electromotive force waveforms and smaller cogging force and force ripple than the existing motors. Moreover, a prototype of the proposed motor is built to validate the study.","permanent magnet motors,
finite element analysis,
linear motors"
Objective Automatic Assessment of Rehabilitative Speech Treatment in Parkinson's Disease,"Vocal performance degradation is a common symptom for the vast majority of Parkinson's disease (PD) subjects, who typically follow personalized one-to-one periodic rehabilitation meetings with speech experts over a long-term period. Recently, a novel computer program called Lee Silverman voice treatment (LSVT) Companion was developed to allow PD subjects to independently progress through a rehabilitative treatment session. This study is part of the assessment of the LSVT Companion, aiming to investigate the potential of using sustained vowel phonations towards objectively and automatically replicating the speech experts' assessments of PD subjects' voices as “acceptable” (a clinician would allow persisting during in-person rehabilitation treatment) or “unacceptable” (a clinician would not allow persisting during in-person rehabilitation treatment). We characterize each of the 156 sustained vowel /a/ phonations with 309 dysphonia measures, select a parsimonious subset using a robust feature selection algorithm, and automatically distinguish the two cohorts (acceptable versus unacceptable) with about 90% overall accuracy. Moreover, we illustrate the potential of the proposed methodology as a probabilistic decision support tool to speech experts to assess a phonation as “acceptable” or “unacceptable.” We envisage the findings of this study being a first step towards improving the effectiveness of an automated rehabilitative speech assessment tool.",
LARS*: An Efficient and Scalable Location-Aware Recommender System,"This paper proposes LARS*, a location-aware recommender system that uses location-based ratings to produce recommendations. Traditional recommender systems do not consider spatial properties of users nor items; LARS*, on the other hand, supports a taxonomy of three novel classes of location-based ratings, namely, spatial ratings for non-spatial items, non-spatial ratings for spatial items, and spatial ratings for spatial items. LARS* exploits user rating locations through user partitioning, a technique that influences recommendations with ratings spatially close to querying users in a manner that maximizes system scalability while not sacrificing recommendation quality. LARS* exploits item locations using travel penalty, a technique that favors recommendation candidates closer in travel distance to querying users in a way that avoids exhaustive access to all spatial items. LARS* can apply these techniques separately, or together, depending on the type of location-based rating available. Experimental evidence using large-scale real-world data from both the Foursquare location-based social network and the MovieLens movie recommendation system reveals that LARS* is efficient, scalable, and capable of producing recommendations twice as accurate compared to existing recommendation approaches.","Scalability,
Collaboration,
Maintenance engineering,
Data structures,
Recommender systems,
Motion pictures,
Database systems"
Flat Luneburg Lens via Transformation Optics for Directive Antenna Applications,"The great flexibility offered by transformation optics for controlling electromagnetic radiation by virtually re-shaping the electromagnetic space has inspired a myriad of dream-tailored electromagnetic devices. Here we show a 3D-transformed microwave Luneburg lens antenna which demonstrates high directivity, low side-lobe level, broadband response and steerable capabilities. A conventional Luneburg lens is redesigned accounting for dielectric materials that implement a coordinate transformation, modifying the lens geometry to accommodate its size and shape for easy integration with planar microwave antenna applications. An all dielectric lens is manufactured following a thorough holistic analysis of ceramic materials with different volume fractions of bi-modal distributed titanate fillers. Fabrication and measurements of a 3-D flat Luneburg lens antenna validate the design and confirm a high-directivity performance. A directivity of 17.96 dBi, low side-lobe levels for both main planes ~ -26 dB, excellent directivity performance within the X-band and beam-steering up to 34 ° were achieved.","Lenses,
Materials,
Permittivity,
Broadband antennas,
Directive antennas,
Microwave antennas,
Fabrication"
"Transform-Invariant PCA: A Unified Approach to Fully Automatic FaceAlignment, Representation, and Recognition","We develop a transform-invariant PCA (TIPCA) technique which aims to accurately characterize the intrinsic structures of the human face that are invariant to the in-plane transformations of the training images. Specially, TIPCA alternately aligns the image ensemble and creates the optimal eigenspace, with the objective to minimize the mean square error between the aligned images and their reconstructions. The learning from the FERET facial image ensemble of 1,196 subjects validates the mutual promotion between image alignment and eigenspace representation, which eventually leads to the optimized coding and recognition performance that surpasses the handcrafted alignment based on facial landmarks. Experimental results also suggest that state-of-the-art invariant descriptors, such as local binary pattern (LBP), histogram of oriented gradient (HOG), and Gabor energy filter (GEF), and classification methods, such as sparse representation based classification (SRC) and support vector machine (SVM), can benefit from using the TIPCA-aligned faces, instead of the manually eye-aligned faces that are widely regarded as the ground-truth alignment. Favorable accuracies against the state-of-the-art results on face coding and face recognition are reported.","Face,
Face recognition,
Image recognition,
Training,
Image reconstruction,
Principal component analysis,
Probes"
Structure-Constrained Low-Rank Representation,"Benefiting from its effectiveness in subspace segmentation, low-rank representation (LRR) and its variations have many applications in computer vision and pattern recognition, such as motion segmentation, image segmentation, saliency detection, and semisupervised learning. It is known that the standard LRR can only work well under the assumption that all the subspaces are independent. However, this assumption cannot be guaranteed in real-world problems. This paper addresses this problem and provides an extension of LRR, named structure-constrained LRR (SC-LRR), to analyze the structure of multiple disjoint subspaces, which is more general for real vision data. We prove that the relationship of multiple linear disjoint subspaces can be exactly revealed by SC-LRR, with a predefined weight matrix. As a nontrivial byproduct, we also illustrate that SC-LRR can be applied for semisupervised learning. The experimental results on different types of vision problems demonstrate the effectiveness of our proposed method.",
Fast Single Image Super-Resolution via Self-Example Learning and Sparse Representation,"In this paper, we propose a novel algorithm for fast single image super-resolution based on self-example learning and sparse representation. We propose an efficient implementation based on the K-singular value decomposition (SVD) algorithm, where we replace the exact SVD computation with a much faster approximation, and we employ the straightforward orthogonal matching pursuit algorithm, which is more suitable for our proposed self-example-learning-based sparse reconstruction with far fewer signals. The patches used for dictionary learning are efficiently sampled from the low-resolution input image itself using our proposed sample mean square error strategy, without an external training set containing a large collection of high- resolution images. Moreover, the l0-optimization-based criterion, which is much faster than l1-optimization-based relaxation, is applied to both the dictionary learning and reconstruction phases. Compared with other super-resolution reconstruction methods, our low- dimensional dictionary is a more compact representation of patch pairs and it is capable of learning global and local information jointly, thereby reducing the computational cost substantially. Our algorithm can generate high-resolution images that have similar quality to other methods but with an increase in the computational efficiency greater than hundredfold.","Dictionaries,
Image reconstruction,
Training,
Image resolution,
Approximation algorithms,
Interpolation,
Reconstruction algorithms"
"A General Framework for Regularized, Similarity-Based Image Restoration","Any image can be represented as a function defined on a weighted graph, in which the underlying structure of the image is encoded in kernel similarity and associated Laplacian matrices. In this paper, we develop an iterative graph-based framework for image restoration based on a new definition of the normalized graph Laplacian. We propose a cost function, which consists of a new data fidelity term and regularization term derived from the specific definition of the normalized graph Laplacian. The normalizing coefficients used in the definition of the Laplacian and associated regularization term are obtained using fast symmetry preserving matrix balancing. This results in some desired spectral properties for the normalized Laplacian such as being symmetric, positive semidefinite, and returning zero vector when applied to a constant image. Our algorithm comprises of outer and inner iterations, where in each outer iteration, the similarity weights are recomputed using the previous estimate and the updated objective function is minimized using inner conjugate gradient iterations. This procedure improves the performance of the algorithm for image deblurring, where we do not have access to a good initial estimate of the underlying image. In addition, the specific form of the cost function allows us to render the spectral analysis for the solutions of the corresponding linear equations. In addition, the proposed approach is general in the sense that we have shown its effectiveness for different restoration problems, including deblurring, denoising, and sharpening. Experimental results verify the effectiveness of the proposed algorithm on both synthetic and real examples.","Laplace equations,
Symmetric matrices,
Kernel,
Vectors,
Cost function,
Image restoration,
Linear programming"
Computer-Aided Bleeding Detection in WCE Video,"Wireless capsule endoscopy (WCE) can directly take digital images in the gastrointestinal tract of a patient. It has opened a new chapter in small intestine examination. However, a major problem associated with this technology is that too many images need to be manually examined by clinicians. Currently, there is no standard for capsule endoscopy image interpretation and classification. Most state-of-the-art CAD methods often suffer from poor performance, high computational cost, or multiple empirical thresholds. In this paper, a new method for rapid bleeding detection in the WCE video is proposed. We group pixels through superpixel segmentation to reduce the computational complexity while maintaining high diagnostic accuracy. Feature of each superpixel is extracted using the red ratio in RGB space and fed into support vector machine for classification. Also, the influence of edge pixels has been removed in this paper. Comparative experiments show that our algorithm is superior to the existing methods in terms of sensitivity, specificity, and accuracy.","biomedical optical imaging,
computational complexity,
endoscopes,
feature extraction,
image classification,
image segmentation,
medical image processing,
support vector machines,
video signal processing"
An overview of research trends in CogInfoCom,"Cognitive infocommunications (CogInfoCom) is an interdisciplinary field that targets engineering applications based on emergent synergies between ICT and the cognitive sciences. The unique perspective of CogInfoCom enables researchers to focus on both the qualitative and quantitative analysis of cognitive capabilities in application areas where humans are becoming increasingly entangled with and dependent on intelligent networked services. An international conference on the field has been held every year since 2010, and the two most recent events have been supported by the IEEE. In this paper, we provide an overview of the various research directions which have been represented at the conference series, and which have as a result gained strong relevance to CogInfoCom during the past few years.","Conferences,
Speech,
Social network services,
Sensors,
Internet,
User interfaces,
Semantics"
Visual Exploration of Sparse Traffic Trajectory Data,"In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system.","Trajectory,
Visual analytics,
Data visualization,
Aircraft navigation"
A Multiple-Valued Decision Diagram Based Method for Efficient Reliability Analysis of Non-Repairable Phased-Mission Systems,"Many practical systems are phased-mission systems (PMSs), where the mission consists of multiple, consecutive, and non-overlapping phases of operation. An accurate reliability analysis of a PMS must consider statistical dependence of component states across phases, as well as dynamics in system configurations, success criteria, and component behavior. This paper proposes a new method based on multiple-valued decision diagrams (MDDs) for the reliability analysis of a non-repairable binary-state PMS. Due to its multi-valued logic nature, the MDD model has recently been applied to the reliability analysis of multistate systems. In this work, we present a novel way to adapt MDDs for the reliability analysis of systems with multiple phases. Examples show how the MDD models are generated and evaluated to obtain the mission reliability measures. Performance of the MDD-based method is compared with an existing binary decision diagram (BDD)-based method for PMS analysis. Empirical results show that the MDD-based method can offer lower computational complexity as well as a simpler model construction and improved evaluation algorithms over those used in the BDD-based method.","Data structures,
Boolean functions,
Reliability,
Fault trees,
Analytical models,
Adaptation models,
Computational modeling"
Novel Example-Based Method for Super-Resolution and Denoising of Medical Images,"In this paper, we propose a novel example-based method for denoising and super-resolution of medical images. The objective is to estimate a high-resolution image from a single noisy low-resolution image, with the help of a given database of high and low-resolution image patch pairs. Denoising and super-resolution in this paper is performed on each image patch. For each given input low-resolution patch, its high-resolution version is estimated based on finding a nonnegative sparse linear representation of the input patch over the low-resolution patches from the database, where the coefficients of the representation strongly depend on the similarity between the input patch and the sample patches in the database. The problem of finding the nonnegative sparse linear representation is modeled as a nonnegative quadratic programming problem. The proposed method is especially useful for the case of noise-corrupted and low-resolution image. Experimental results show that the proposed method outperforms other state-of-the-art super-resolution methods while effectively removing noise.","Databases,
Noise,
Vectors,
Biomedical imaging,
Spatial resolution,
Noise measurement"
Toward Energy Efficient Big Data Gathering in Densely Distributed Sensor Networks,"Recently, the big data emerged as a hot topic because of the tremendous growth of the information and communication technology. One of the highly anticipated key contributors of the big data in the future networks is the distributed wireless sensor networks (WSNs). Although the data generated by an individual sensor may not appear to be significant, the overall data generated across numerous sensors in the densely distributed WSNs can produce a significant portion of the big data. Energy-efficient big data gathering in the densely distributed sensor networks is, therefore, a challenging research area. One of the most effective solutions to address this challenge is to utilize the sink node's mobility to facilitate the data gathering. While this technique can reduce energy consumption of the sensor nodes, the use of mobile sink presents additional challenges such as determining the sink node's trajectory and cluster formation prior to data collection. In this paper, we propose a new mobile sink routing and data gathering method through network clustering based on modified expectation-maximization technique. In addition, we derive an optimal number of clusters to minimize the energy consumption. The effectiveness of our proposal is verified through numerical results.",
Bayesian Nonparametric Dictionary Learning for Compressed Sensing MRI,"We develop a Bayesian nonparametric model for reconstructing magnetic resonance images (MRIs) from highly undersampled
k
-space data. We perform dictionary learning as part of the image reconstruction process. To this end, we use the beta process as a nonparametric dictionary learning prior for representing an image patch as a sparse combination of dictionary elements. The size of the dictionary and patch-specific sparsity pattern are inferred from the data, in addition to other dictionary learning variables. Dictionary learning is performed directly on the compressed image, and so is tailored to the MRI being considered. In addition, we investigate a total variation penalty term in combination with the dictionary learning model, and show how the denoising property of dictionary learning removes dependence on regularization parameters in the noisy setting. We derive a stochastic optimization algorithm based on Markov chain Monte Carlo for the Bayesian model, and use the alternating direction method of multipliers for efficiently performing total variation minimization. We present empirical results on several MRI, which show that the proposed regularization framework can improve reconstruction accuracy over other methods.","Dictionaries,
Image reconstruction,
Magnetic resonance imaging,
Noise reduction,
Vectors,
TV,
Bayes methods"
"Reusing Building Blocks of Extracted Knowledge to Solve Complex, Large-Scale Boolean Problems","Evolutionary computation techniques have had limited capabilities in solving large-scale problems due to the large search space demanding large memory and much longer training times. In the work presented here, a genetic programming like rich encoding scheme has been constructed to identify building blocks of knowledge in a learning classifier system. The fitter building blocks from the learning system trained against smaller problems have been utilized in a higher complexity problem in the domain to achieve scalable learning. The proposed system has been examined and evaluated on four different Boolean problem domains: 1) multiplexer, 2) majority-on, 3) carry, and 4) even-parity problems. The major contribution of this paper is to successfully extract useful building blocks from smaller problems and reuse them to learn more complex large-scale problems in the domain, e.g., 135-bit multiplexer problem, where the number of possible instances is 2135 ≈ 4 × 1040, is solved by reusing the extracted knowledge from the learned lower level solutions in the domain. Autonomous scaling is, for the first time, shown to be possible in learning classifier systems. It improves effectiveness and reduces the number of training instances required in large problems, but requires more time due to its sequential build-up of knowledge.","Sociology,
Statistics,
Standards,
Genetic programming,
Encoding,
Training,
Multiplexing"
Energy Harvesting Cooperative Communication Systems,"This paper addresses the problem of throughput maximization in an energy-harvesting two-hop amplify-and-forward relay network. We obtain optimal policies for transmission power for two cases. First, we assume non-causal knowledge of the harvested energy and that of the fading channel states. Then, we assume that this information is known only causally. We propose an effective algorithm to solve the power-use problem in the non-causal (offline) case. For the causal (online) case, we cast the problem as a Markov decision process (MDP) and solve the resulting optimization problem using only causal knowledge of the fading and the harvested energy. This MDP approach yields good performance, but at the cost of computational complexity. To address this issue, we consider the case where the power control at the transmitting nodes is limited to on-off switching. We derive interesting properties for the optimal solutions to the MDP formulation for this special case. Furthermore, using these properties, we propose a computationally simple power allocation scheme. The performances of the proposed schemes are evaluated using computer simulations and are compared to existing methods which address the same problem.","Relays,
Energy harvesting,
Throughput,
Batteries,
Wireless communication,
Fading"
Tunnel FET RF Rectifier Design for Energy Harvesting Applications,"Radio-frequency (RF)-powered energy harvesting systems have offered new perspectives in various scientific and clinical applications such as health monitoring, bio-signal acquisition, and battery-less data-transceivers. In such applications, an RF rectifier with high sensitivity, high power conversion efficiency (PCE) is critical to enable the utilization of the ambient RF signal power. In this paper, we explore the high PCE advantage of the steep-slope III-V heterojunction tunnel field-effect transistor (HTFET) RF rectifiers over the Si FinFET baseline design for RF-powered battery-less systems. We investigate the device characteristics of HTFETs to improve the sensitivity and PCE of the RF rectifiers. Different topologies including the two-transistor (2-T) and four-transistor (4-T) complementary-HTFET designs, and the n-type HTFET-only designs are evaluated with design parameter optimizations to achieve high PCE and high sensitivity. The performance evaluation of the optimized 4-T cross-coupled HTFET rectifier has shown an over 50% PCE with an RF input power ranging from -40 dBm to -25 dBm, which significantly extends the RF input power range compared to the baseline Si FinFET design. A maximum PCE of 84% and 85% has been achieved in the proposed 4-T N-HTFET-only rectifier at -33.7 dBm input power and the 4-T cross-coupled HTFET rectifier at -34.5 dBm input power, respectively. The capability of obtaining a high PCE at a low RF input power range reveals the superiority of the HTFET RF rectifiers for battery-less energy harvesting applications.",
Integration of SDR and SDN for 5G,"Wireless networks have evolved from 1G to 4G networks, allowing smart devices to become important tools in daily life. The 5G network is a revolutionary technology that can change consumers' Internet use habits, as it creates a truly wireless environment. It is faster, with better quality, and is more secure. Most importantly, users can truly use network services anytime, anywhere. With increasing demand, the use of bandwidth and frequency spectrum resources is beyond expectations. This paper found that the frequency spectrum and network information have considerable relevance; thus, spectrum utilization and channel flow interactions should be simultaneously considered. We considered that software defined radio (SDR) and software defined networks (SDNs) are the best solution. We propose a cross-layer architecture combining SDR and SDN characteristics. As the simulation evaluation results suggest, the proposed architecture can effectively use the frequency spectrum and considerably enhance network performance. Based on the results, suggestions are proposed for follow-up studies on the proposed architecture.","Bandwidth,
Hardware,
Protocols,
Control systems,
Monitoring,
Software radio,
Computer architecture"
Video Saliency Incorporating Spatiotemporal Cues and Uncertainty Weighting,"We propose a novel algorithm to detect visual saliency from video signals by combining both spatial and temporal information and statistical uncertainty measures. The main novelty of the proposed method is twofold. First, separate spatial and temporal saliency maps are generated, where the computation of temporal saliency incorporates a recent psychological study of human visual speed perception. Second, the spatial and temporal saliency maps are merged into one using a spatiotemporally adaptive entropy-based uncertainty weighting approach. The spatial uncertainty weighing incorporates the characteristics of proximity and continuity of spatial saliency, while the temporal uncertainty weighting takes into account the variations of background motion and local contrast. Experimental results show that the proposed spatiotemporal uncertainty weighting algorithm significantly outperforms state-of-the-art video saliency detection models.","Uncertainty,
Visualization,
Spatiotemporal phenomena,
Feature extraction,
Computational modeling,
Image color analysis,
Biological system modeling"
Scalable Recommendation with Social Contextual Information,"Exponential growth of information generated by online social networks demands effective and scalable recommender systems to give useful results. Traditional techniques become unqualified because they ignore social relation data; existing social recommendation approaches consider social network structure, but social contextual information has not been fully considered. It is significant and challenging to fuse social contextual factors which are derived from users' motivation of social behaviors into social recommendation. In this paper, we investigate the social recommendation problem on the basis of psychology and sociology studies, which exhibit two important factors: individual preference and interpersonal influence. We first present the particular importance of these two factors in online behavior prediction. Then we propose a novel probabilistic matrix factorization method to fuse them in latent space. We further provide a scalable algorithm which can incrementally process the large scale data. We conduct experiments on both Facebook style bidirectional and Twitter style unidirectional social network data sets. The empirical results and analysis on these two large data sets demonstrate that our method significantly outperforms the existing approaches.approaches.","Context modeling,
Recommender systems,
Twitter,
Correlation,
Probabilistic logic,
Facebook"
Dynamic Simulation of Large-Scale Power Systems Using a Parallel Schur-Complement-Based Decomposition Method,"Power system dynamic simulations are crucial for the operation of electric power systems as they provide important information on the dynamic evolution of the system after an occurring disturbance. This paper proposes a robust, accurate and efficient parallel algorithm based on the Schur complement domain decomposition method. The algorithm provides numerical and computational acceleration of the procedure. Based on the shared-memory parallel programming model, a parallel implementation of the proposed algorithm is presented. The implementation is general, portable and scalable on inexpensive, shared-memory, multi-core machines. Two realistic test systems, a medium-scale and a large-scale, are used for performance evaluation of the proposed method.",
A data-driven approach to cleaning large face datasets,"Large face datasets are important for advancing face recognition research, but they are tedious to build, because a lot of work has to go into cleaning the huge amount of raw data. To facilitate this task, we describe an approach to building face datasets that starts with detecting faces in images returned from searches for public figures on the Internet, followed by discarding those not belonging to each queried person. We formulate the problem of identifying the faces to be removed as a quadratic programming problem, which exploits the observations that faces of the same person should look similar, have the same gender, and normally appear at most once per image. Our results show that this method can reliably clean a large dataset, leading to a considerable reduction in the work needed to build it. Finally, we are releasing the FaceScrub dataset that was created using this approach. It consists of 141,130 faces of 695 public figures and can be obtained from http://vintage.winklerbros.net/facescrub.html.",
Spatial Entropy-Based Global and Local Image Contrast Enhancement,"This paper proposes a novel algorithm, which enhances the contrast of an input image using spatial information of pixels. The algorithm introduces a new method to compute the spatial entropy of pixels using spatial distribution of pixel gray levels. Different than the conventional methods, this algorithm considers the distribution of spatial locations of gray levels of an image instead of gray-level distribution or joint statistics computed from the gray levels of an image. For each gray level, the corresponding spatial distribution is computed using a histogram of spatial locations of all pixels with the same gray level. Entropy measures are calculated from the spatial distributions of gray levels of an image to create a distribution function, which is further mapped to a uniform distribution function to achieve the final contrast enhancement. The method achieves contrast improvement in the case of low-contrast images; however, it does not alter the image if the image's contrast is high enough. Thus, it always produces visually pleasing results without distortions. Furthermore, this method is combined with transform domain coefficient weighting to achieve both local and global contrast enhancement at the same time. The level of the local contrast enhancement can be controlled. Several experiments on effects of contrast enhancement are performed. Experimental results show that the proposed algorithms produce better or comparable enhanced images than several state-of-the-art algorithms.",
Whole-body motion planning with centroidal dynamics and full kinematics,"To plan dynamic, whole-body motions for robots, one conventionally faces the choice between a complex, full-body dynamic model containing every link and actuator of the robot, or a highly simplified model of the robot as a point mass. In this paper we explore a powerful middle ground between these extremes. We exploit the fact that while the full dynamics of humanoid robots are complicated, their centroidal dynamics (the evolution of the angular momentum and the center of mass (COM) position) are much simpler. By treating the dynamics of the robot in centroidal form and directly optimizing the joint trajectories for the actuated degrees of freedom, we arrive at a method that enjoys simpler dynamics, while still having the expressiveness required to handle kinematic constraints such as collision avoidance or reaching to a target. We further require that the robot's COM and angular momentum as computed from the joint trajectories match those given by the centroidal dynamics. This ensures that the dynamics considered by our optimization are equivalent to the full dynamics of the robot, provided that the robot's actuators can supply sufficient torque. We demonstrate that this algorithm is capable of generating highly-dynamic motion plans with examples of a humanoid robot negotiating obstacle course elements and gait optimization for a quadrupedal robot. Additionally, we show that we can plan without pre-specifying the contact sequence by exploiting the complementarity conditions between contact forces and contact distance.","Robots,
Kinematics,
Dynamics,
Optimization,
Trajectory,
Collision avoidance,
Joints"
Exemplar-Based Color Constancy and Multiple Illumination,"Exemplar-based learning or, equally, nearest neighbor methods have recently gained interest from researchers in a variety of computer science domains because of the prevalence of large amounts of accessible data and storage capacity. In computer vision, these types of technique have been successful in several problems such as scene recognition, shape matching, image parsing, character recognition, and object detection. Applying the concept of exemplar-based learning to the problem of color constancy seems odd at first glance since, in the first place, similar nearest neighbor images are not usually affected by precisely similar illuminants and, in the second place, gathering a dataset consisting of all possible real-world images, including indoor and outdoor scenes and for all possible illuminant colors and intensities, is indeed impossible. In this paper, we instead focus on surfaces in the image and address the color constancy problem by unsupervised learning of an appropriate model for each training surface in training images. We find nearest neighbor models for each surface in a test image and estimate its illumination based on comparing the statistics of pixels belonging to nearest neighbor surfaces and the target surface. The final illumination estimation results from combining these estimated illuminants over surfaces to generate a unique estimate. We show that it performs very well, for standard datasets, compared to current color constancy algorithms, including when learning based on one image dataset is applied to tests from a different dataset. The proposed method has the advantage of overcoming multi-illuminant situations, which is not possible for most current methods since they assume the color of the illuminant is constant all over the image. We show a technique to overcome the multiple illuminant situation using the proposed method and test our technique on images with two distinct sources of illumination using a multiple-illuminant color constancy dataset. The concept proposed here is a completely new approach to the color constancy problem and provides a simple learning-based framework.","Image color analysis,
Lighting,
Training,
Estimation,
Feature extraction,
Surface treatment,
Light sources"
Adaptive Fireworks Algorithm,"In this paper, firstly, the amplitude used in the Enhanced Fireworks Algorithm (EFWA) is analyzed and its lack of adaptability is revealed, and then the adaptive amplitude method is proposed where amplitude is calculated according to the already evaluated fitness of the individuals adaptively. Finally, the Adaptive Fireworks Algorithm (AFWA) is proposed, replacing the amplitude operator in EFWA with the new adaptive amplitude. Some theoretical analyses are made to prove the adaptive explosion amplitude a promising method. Experiments on CEC13's 28 benchmark functions are also conducted in order to illustrate the performance and it turns out that the AFWA where adaptive amplitude is adopted outperforms significantly the EFWA and meanwhile the time consumed is not longer. Moreover, according to experimental results, AFWA performs better than the Standard Particle Swarm Optimization (SPSO).","Sparks,
Explosions,
Nickel,
Next generation networking,
Evolutionary computation,
Algorithm design and analysis,
Upper bound"
Robust and Reverse-Engineering Resilient PUF Authentication and Key-Exchange by Substring Matching,"This paper proposes novel robust and low-overhead physical unclonable function (PUF) authentication and key exchange protocols that are resilient against reverse-engineering attacks. The protocols are executed between a party with access to a physical PUF (prover) and a trusted party who has access to the PUF compact model (verifier). The proposed protocols do not follow the classic paradigm of exposing the full PUF responses or a transformation of them. Instead, random subsets of the PUF response strings are sent to the verifier so the exact position of the subset is obfuscated for the third-party channel observers. Authentication of the responses at the verifier side is done by matching the substring to the available full response string; the index of the matching point is the actual obfuscated secret (or key) and not the response substring itself. We perform a thorough analysis of resiliency of the protocols against various adversarial acts, including machine learning and statistical attacks. The attack analysis guides us in tuning the parameters of the protocol for an efficient and secure implementation. The low overhead and practicality of the protocols are evaluated and confirmed by hardware implementation.","Protocols,
Authentication,
Error correction,
Licenses,
Reverse engineering,
Network security"
Temporal and Thermal Stability of Al2O3-Passivated Phosphorene MOSFETs,"This letter evaluates temporal and thermal stability of a state-of-the-art few-layer phosphorene MOSFET with Al2O3 surface passivation and Ti/Au top gate. As fabricated, the phosphorene MOSFET was stable in atmosphere for at least 100 h. With annealing at 200 °C in dry nitrogen for 1 h, its drain current increased by an order of magnitude to ~100 mA/mm, which could be attributed to the reduction of trapped charge in Al2O3 and/or Schottky barrier at the source and drain contacts. Thereafter, the drain current was stable between -50°C and 150°C up to at least 2000 h. These promising results suggest that environmental protection of phosphorene should not be a major concern, and passivation of phosphorene should focus on its effect on electronic control and transport as in conventional silicon MOSFETs. With cutoff frequencies approaching the gigahertz range, the present phosphorene MOSFET, although far from being optimized, can meet the speed and stability requirements of most flexible electronics for which phosphorene is intrinsically advantageous due to its corrugated lattice structure.",
On Controllability of Neuronal Networks With Constraints on the Average of Control Gains,"Control gains play an important role in the control of a natural or a technical system since they reflect how much resource is required to optimize a certain control objective. This paper is concerned with the controllability of neuronal networks with constraints on the average value of the control gains injected in driver nodes, which are in accordance with engineering and biological backgrounds. In order to deal with the constraints on control gains, the controllability problem is transformed into a constrained optimization problem (COP). The introduction of the constraints on the control gains unavoidably leads to substantial difficulty in finding feasible as well as refining solutions. As such, a modified dynamic hybrid framework (MDyHF) is developed to solve this COP, based on an adaptive differential evolution and the concept of Pareto dominance. By comparing with statistical methods and several recently reported constrained optimization evolutionary algorithms (COEAs), we show that our proposed MDyHF is competitive and promising in studying the controllability of neuronal networks. Based on the MDyHF, we proceed to show the controlling regions under different levels of constraints. It is revealed that we should allocate the control gains economically when strong constraints are considered. In addition, it is found that as the constraints become more restrictive, the driver nodes are more likely to be selected from the nodes with a large degree. The results and methods presented in this paper will provide useful insights into developing new techniques to control a realistic complex network efficiently.","Controllability,
Biological neural networks,
Complex networks,
Optimization,
Educational institutions"
Secure Data Aggregation in Wireless Sensor Networks: Filtering out the Attacker's Impact,"Wireless sensor networks (WSNs) are increasingly used in many applications, such as volcano and fire monitoring, urban sensing, and perimeter surveillance. In a large WSN, in-network data aggregation (i.e., combining partial results at intermediate nodes during message routing) significantly reduces the amount of communication overhead and energy consumption. The research community proposed a loss-resilient aggregation framework called synopsis diffusion, which uses duplicate-insensitive algorithms on top of multipath routing schemes to accurately compute aggregates (e.g., predicate count or sum). However, this aggregation framework does not address the problem of false subaggregate values contributed by compromised nodes. This attack may cause large errors in the aggregate computed at the base station, which is the root node in the aggregation hierarchy. In this paper, we make the synopsis diffusion approach secure against the above attack launched by compromised nodes. In particular, we present an algorithm to enable the base station to securely compute predicate count or sum even in the presence of such an attack. Our attack-resilient computation algorithm computes the true aggregate by filtering out the contributions of compromised nodes in the aggregation hierarchy. Extensive analysis and simulation study show that our algorithm outperforms other existing approaches.","Aggregates,
Algorithm design and analysis,
Wireless sensor networks,
Approximation algorithms,
Security,
Routing,
Base stations"
Fine-Grained Localization for Multiple Transceiver-Free Objects by using RF-Based Technologies,"In traditional radio-based localization methods, the target object has to carry a transmitter (e.g., active RFID), a receiver (e.g., 802.11 × detector), or a transceiver (e.g., sensor node). However, in some applications, such as safe guard systems, it is not possible to meet this precondition. In this paper, we propose a model of signal dynamics to allow the tracking of a transceiver-free object. Based on radio signal strength indicator (RSSI), which is readily available in wireless communication, three centralized tracking algorithms, and one distributed tracking algorithm are proposed to eliminate noise behaviors and improve accuracy. The midpoint and intersection algorithms can be applied to track a single object without calibration, while the best-cover algorithm has higher tracking accuracy but requires calibration. The probabilistic cover algorithm is based on distributed dynamic clustering. It can dramatically improve the localization accuracy when multiple objects are present. Our experimental test-bed is a grid sensor array based on MICA2 sensor nodes. The experimental results show that the localization accuracy for single object can reach about 0.8 m and for multiple objects is about 1 m.","Heuristic algorithms,
Wireless sensor networks,
Receivers,
Accuracy,
Wireless communication,
Clustering algorithms,
Calibration"
Detecting Protein Complexes Basedon Uncertain Graph Model,"Advanced biological technologies are producing large-scale protein–protein interaction (PPI) data at an ever increasing pace, which enable us to identify protein complexes from PPI networks. Pair-wise protein interactions can be modeled as a graph, where vertices represent proteins and edges represent PPIs. However most of current algorithms detect protein complexes based on deterministic graphs, whose edges are either present or absent. Neighboring information is neglected in these methods. Based on the uncertain graph model, we propose the concept of expected density to assess the density degree of a subgraph, the concept of relative degree to describe the relationship between a protein and a subgraph in a PPI network. We develop an algorithm called DCU (detecting complex based on uncertain graph model) to detect complexes from PPI networks. In our method, the expected density combined with the relative degree is used to determine whether a subgraph represents a complex with high cohesion and low coupling. We apply our method and the existing competing algorithms to two yeast PPI networks. Experimental results indicate that our method performs significantly better than the state-of-the-art methods and the proposed model can provide more insights for future study in PPI networks.","Proteins,
Clustering algorithms,
Protein engineering,
Prediction algorithms,
Sensitivity,
Bioinformatics"
Use of SSK Modulation in Two-Way Amplify-and-Forward Relaying,"Space-shift keying (SSK) modulation is a novel multiple-input-multiple-output (MIMO) technique, which activates only a single antenna for transmission at any time instant and uses the index of this active antenna to implicitly convey information. In this paper, a pragmatic communication strategy for the use of SSK modulation in two-way amplify-and-forward (AF) relaying is proposed. Specifically, the transceiver sends the signal by employing SSK modulation and detects the signal based on the maximal-ratio combining principle. By considering a Nakagami- m fading environment, upper bounded and asymptotic bit error probabilities (BEPs) are both derived in closed form. The optimal power allocation problem in the minimization of the average BEP is also addressed. Finally, Monte Carlo simulations are conducted to verify the accuracy of the analysis.",
A Nonlinear Adaptive Level Set for Image Segmentation,"In this paper, we present a novel level set method (LSM) for image segmentation. By utilizing the Bayesian rule, we design a nonlinear adaptive velocity and a probability-weighted stopping force to implement a robust segmentation for objects with weak boundaries. The proposed method is featured by the following three properties: 1) it automatically determines the curve to shrink or expand by utilizing the Bayesian rule to involve the regional features of images; 2) it drives the curve evolve with an appropriate speed to avoid the leakage at weak boundaries; and 3) it reduces the influence of false boundaries, i.e., edges far away from objects of interest. We applied the proposed segmentation method to artificial images, medical images and the BSD-300 image dataset for qualitative and quantitative evaluations. The comparison results show the proposed method performs competitively, compared with the LSM and its representative variants.","Bayes methods,
image segmentation"
Increasing TLB reach by exploiting clustering in page translations,"The steadily increasing sizes of main memory capacities require corresponding increases in the processor's translation lookaside buffer (TLB) resources to avoid performance bottlenecks. Large operating system page sizes can mitigate the bottleneck with a smaller TLB, but most OSs and applications do not fully utilize the large-page support in current hardware. Recent work has shown that, while not guaranteed, some virtual-to-physical page mappings exhibit “contiguous” spatial locality in which consecutive virtual pages map to consecutive physical pages. Such locality provides opportunities to coalesce “adjacent” TLB entries for increased reach. We observe that beyond simple adjacent-entry coalescing, many more translations exhibit “clustered” spatial locality in which a group or cluster of nearby virtual pages map to a similarly clustered set of physical pages. In this work, we provide a detailed characterization of the spatial locality among the virtual-to-physical translations. Based on this characterization, we present a multi-granular TLB organization that significantly increases its effective reach and reduces miss rates substantially while requiring no additional OS support. Our evaluation shows that the multi-granular design outperforms conventional TLBs and the recently proposed coalesced TLBs technique.","Virtual private networks,
Hardware,
Organizations,
Benchmark testing,
Prefetching,
Operating systems"
"LIDA: A Systems-level Architecture for Cognition, Emotion, and Learning","We describe a cognitive architecture learning intelligent distribution agent (LIDA) that affords attention, action selection and human-like learning intended for use in controlling cognitive agents that replicate human experiments as well as performing real-world tasks. LIDA combines sophisticated action selection, motivation via emotions, a centrally important attention mechanism, and multimodal instructionalist and selectionist learning. Empirically grounded in cognitive science and cognitive neuroscience, the LIDA architecture employs a variety of modules and processes, each with its own effective representations and algorithms. LIDA has much to say about motivation, emotion, attention, and autonomous learning in cognitive agents. In this paper, we summarize the LIDA model together with its resulting agent architecture, describe its computational implementation, and discuss results of simulations that replicate known experimental data. We also discuss some of LIDA's conceptual modules, propose nonlinear dynamics as a bridge between LIDA's modules and processes and the underlying neuroscience, and point out some of the differences between LIDA and other cognitive architectures. Finally, we discuss how LIDA addresses some of the open issues in cognitive architecture research.","Computational modeling,
Computer architecture,
Cognition,
Neuroscience,
Brain modeling,
Cognitive science,
Psychology"
Recharging schedules for wireless sensor networks with vehicle movement costs and capacity constraints,"Several recent works have studied the schedule for mobile vehicles to recharge sensor nodes via wireless energy transfer technologies. Unfortunately, most of them overlooked the important factors of the vehicles' moving energy consumption and limited recharging capacity. These oversights may lead to problematic schedules or even stranded vehicles. In this paper, we study the recharging schedule that maximizes the recharging profit - the amount of replenished energy less the cost of vehicle movements - under these important constraints. We first derive the minimum number of vehicles needed for energy neutral condition and discover a set of desired network properties. Then we formulate the recharge schedule optimization into a Profitable Traveling Salesmen Problem with capacity and battery deadline constraints, which we prove to be NP-hard. We propose two algorithms to solve the problem. The first one is a greedy algorithm that maximizes the recharge profit at each step; the second one first adaptively partitions the network based on recharge requests, then forms Capacitated Minimum Spanning Tree in each partition followed by route improvements. Finally, we evaluate and compare the performance of proposed algorithms and validate the correctness of theoretical results through extensive simulations. Given a sufficient number of vehicles, the adaptive algorithm can keep the number of nonfunctional nodes at zero. Compared to the greedy algorithm, it reduces the percentage of transient energy depletion by 30-50% with 10-20% energy saving on vehicles.",
Rank Preserving Discriminant Analysis for Human Behavior Recognition on Wireless Sensor Networks,"With the rapid development of the intelligent sensing and the prompt growing industrial safety demands, human behavior recognition has received a great deal of attentions in industrial informatics. To deploy an utmost scalable, flexible, and robust human behavior recognition system, we need both innovative sensing electronics and suitable intelligence algorithms. Wireless sensor networks (WSNs) open a novel way for human behavior recognition, because the heavy computation can be immediately transferred to a network server. In this paper, a new scheme for human behavior recognition on WSNs is proposed, which transmits activities' signals compressed by Hamming compressed sensing to the network server and conducts behavior recognition through a collaboration between a new dimension reduction algorithm termed rank preserving discriminant analysis (RPDA) and a nearest neighbor classifier. RPDA encodes local rank information of within-class samples and discriminative information of the between-class under the framework of Patch Alignment Framework. Experiments are conducted on the SCUT Naturalistic 3D Acceleration-based Activity (SCUT NAA) dataset and demonstrate the effectiveness of RPDA for human behavior recognition.","wireless sensor networks,
behavioural sciences computing,
compressed sensing,
data reduction,
intelligent sensors,
network servers,
occupational safety,
statistical analysis"
Characterization of Oxygen Accumulation in Indium-Tin-Oxide for Resistance Random Access Memory,"In this letter, we report the oxygen accumulation effect and its influence on resistive switching for gadolinium-doped silicon dioxide (Gd:SiO2) resistance random access memory (RRAM). We find that oxygen absorbance by indium-tin-oxide electrode affects the conduction current mechanism, and remarkably modifies the device performance of RRAM devices. By current fitting, Schottky emission can be observed in both low and high resistance states, from which conduction model is proposed to clarify the oxygen accumulation phenomenon. Reliability tests, including endurance and high temperature retention are further carried out, evaluating the significance of oxygen accumulation effect in redox reaction for RRAM devices.","Indium tin oxide,
Switches,
Electrodes,
Silicon,
Resistance,
Educational institutions,
Tin"
Fashion Parsing With Weak Color-Category Labels,"In this paper we address the problem of automatically parsing the fashion images with weak supervision from the user-generated color-category tags such as “red jeans” and “white T-shirt”. This problem is very challenging due to the large diversity of fashion items and the absence of pixel-level tags, which make the traditional fully supervised algorithms inapplicable. To solve the problem, we propose to combine the human pose estimation module, the MRF-based color and category inference module and the (super)pixel-level category classifier learning module to generate multiple well-performing category classifiers, which can be directly applied to parse the fashion items in the images. Besides, all the training images are parsed with color-category labels and the human poses of the images are estimated during the model learning phase in this work. We also construct a new fashion image dataset called Colorful-Fashion, in which all 2,682 images are labeled with pixel-level color-category labels. Extensive experiments on this dataset clearly show the effectiveness of the proposed method for the weakly supervised fashion parsing task.","Image color analysis,
Training,
Estimation,
Materials,
Face,
Skin,
Support vector machines"
Gradient Histogram Estimation and Preservation for Texture Enhanced Image Denoising,"Natural image statistics plays an important role in image denoising, and various natural image priors, including gradient-based, sparse representation-based, and nonlocal self-similarity-based ones, have been widely studied and exploited for noise removal. In spite of the great success of many denoising algorithms, they tend to smooth the fine scale image textures when removing noise, degrading the image visual quality. To address this problem, in this paper, we propose a texture enhanced image denoising method by enforcing the gradient histogram of the denoised image to be close to a reference gradient histogram of the original image. Given the reference gradient histogram, a novel gradient histogram preservation (GHP) algorithm is developed to enhance the texture structures while removing noise. Two region-based variants of GHP are proposed for the denoising of images consisting of regions with different textures. An algorithm is also developed to effectively estimate the reference gradient histogram from the noisy observation of the unknown image. Our experimental results demonstrate that the proposed GHP algorithm can well preserve the texture appearance in the denoised images, making them look more natural.",
Opportunistic Flooding in Low-Duty-Cycle Wireless Sensor Networks with Unreliable Links,"Flooding service has been investigated extensively in wireless networks to efficiently disseminate network-wide commands, configurations, and code binaries. However, little work has been done on low-duty-cycle wireless sensor networks in which nodes stay asleep most of the time and wake up asynchronously. In this type of network, a broadcasting packet is rarely received by multiple nodes simultaneously, a unique constraining feature that makes existing solutions unsuitable. In this paper, we introduce Opportunistic Flooding, a novel design tailored for low-duty-cycle networks with unreliable wireless links and predetermined working schedules. Starting with an energy-optimal tree structure, probabilistic forwarding decisions are made at each sender based on the delay distribution of next-hop receivers. Only opportunistically early packets are forwarded via links outside the tree to reduce the flooding delay and redundancy in transmission. We further propose a forwarder selection method to alleviate the hidden terminal problem and a link-quality-based backoff method to resolve simultaneous forwarding operations. We show by extensive simulations and test-bed implementations that Opportunistic Flooding is close to the optimal performance achievable by oracle flooding designs. Compared with Improved Traditional Flooding, our design achieves significantly shorter flooding delay while consuming only 20-60% of the transmission energy.",
A Demand Response Energy Management Scheme for Industrial Facilities in Smart Grid,"Demand response (DR) smart grid technology provides an opportunity for electricity consumers to actively participate in the management of power systems. Industry is one of the major consumers of electric power. In this study, we propose a DR energy management scheme for industrial facilities based on the state task network (STN) and mixed integer linear programming (MILP). The scheme divides the processing tasks in industrial facilities into nonschedulable tasks (NSTs) and schedulable tasks (STs), and takes advantage of distributed energy resources (DERs) to implement DR. Based on day-ahead hourly electricity prices, the scheme determines the scheduling of STs and DERs in order to shift the demand from peak periods (with high electricity prices) to off-peak periods (with low electricity prices), which not only improves the reliability of the electric power system, but also reduces energy costs for industrial facilities.","Industrial plants,
Energy management,
Smart grids,
Energy storage,
Mixed integer linear programming,
Power system management"
Novel Adaptive Strategies for Synchronization of Linearly Coupled Neural Networks With Reaction-Diffusion Terms,"In this paper, two types of linearly coupled neural networks with reaction-diffusion terms are proposed. We respectively investigate the adaptive synchronization of these two types of complex network models. With local information of node dynamics, some novel adaptive strategies to tune the coupling strengths among network nodes are designed. By constructing appropriate Lyapunov functionals and using inequality techniques, several sufficient conditions are given for reaching synchronization by using the designed adaptive laws. Finally, two examples with numerical simulations are provided to demonstrate the effectiveness of the theoretical results.","Synchronization,
Adaptive systems,
Complex networks,
Couplings,
Neural networks,
Neurons,
Adaptation models"
Mixed Noise Removal by Weighted Encoding With Sparse Nonlocal Regularization,"Mixed noise removal from natural images is a challenging task since the noise distribution usually does not have a parametric model and has a heavy tail. One typical kind of mixed noise is additive white Gaussian noise (AWGN) coupled with impulse noise (IN). Many mixed noise removal methods are detection based methods. They first detect the locations of IN pixels and then remove the mixed noise. However, such methods tend to generate many artifacts when the mixed noise is strong. In this paper, we propose a simple yet effective method, namely weighted encoding with sparse nonlocal regularization (WESNR), for mixed noise removal. In WESNR, there is not an explicit step of impulse pixel detection; instead, soft impulse pixel detection via weighted encoding is used to deal with IN and AWGN simultaneously. Meanwhile, the image sparsity prior and nonlocal self-similarity prior are integrated into a regularization term and introduced into the variational encoding framework. Experimental results show that the proposed WESNR method achieves leading mixed noise removal performance in terms of both quantitative measures and visual quality.",
Fin Shape Impact on FinFET Leakage With Application to Multithreshold and Ultralow-Leakage FinFET Design,"FinFETs have emerged as the solution to short channel effects at the 22-nm technology node and beyond. Previously, there have been few studies on the impact of fin cross section shape on transistor leakage. We show for the first time that fin shape significantly impacts transistor leakage in bulk tri-gate nFinFETs with thin fins when the fin body doping profile is optimized to minimize leakage. We show that a triangular fin reduces leakage current by 70% over a rectangular fin with the same base fin width. We describe how fin shape can be used to implement multithreshold nFinFETs without increasing chip area consumption. We also describe how by combining triangular fins with existing gate-source/drain underlap multithreshold techniques, it is possible to design ultralow-power nFinFETs with less than 1 pA/μm leakage current while maintaining high performing ION/IOFF, threshold voltage, and subthreshold swing.","Doping,
Shape,
FinFETs,
Logic gates,
Current density,
Leakage currents"
Crossbar RRAM Arrays: Selector Device Requirements During Write Operation,"A comprehensive analysis of write operations (SET and RESET) in a resistance-change memory (resistive random access memory) crossbar array is carried out. Three types of resistive switching memory cells-nonlinear, rectifying-SET, and rectifying-RESET-are compared with each other in terms of voltage delivery, current delivery, and power consumption. Two different write schemes, V/2 and V/3, were considered, and the V/2 write scheme is preferred due to much lower power consumption. A simple numerical method was developed that simulates entire current flows and node voltages within a crossbar array and provides a quantitative tool for the accurate analysis of crossbar arrays and guidelines for developing reliable write operation.","Power demand,
Resistance,
Arrays,
Switches,
Leakage currents,
Reliability,
Junctions"
A Review of Multitaper Spectral Analysis,"Nonparametric spectral estimation is a widely used technique in many applications ranging from radar and seismic data analysis to electroencephalography (EEG) and speech processing. Among the techniques that are used to estimate the spectral representation of a system based on finite observations, multitaper spectral estimation has many important optimality properties, but is not as widely used as it possibly could be. We give a brief overview of the standard nonparametric spectral estimation theory and the multitaper spectral estimation, and give two examples from EEG analyses of anesthesia and sleep.",
Hyperspectral Image Classification Through Bilayer Graph-Based Learning,"Hyperspectral image classification with limited number of labeled pixels is a challenging task. In this paper, we propose a bilayer graph-based learning framework to address this problem. For graph-based classification, how to establish the neighboring relationship among the pixels from the high dimensional features is the key toward a successful classification. Our graph learning algorithm contains two layers. The first-layer constructs a simple graph, where each vertex denotes one pixel and the edge weight encodes the similarity between two pixels. Unsupervised learning is then conducted to estimate the grouping relations among different pixels. These relations are subsequently fed into the second layer to form a hypergraph structure, on top of which, semisupervised transductive learning is conducted to obtain the final classification results. Our experiments on three data sets demonstrate the merits of our proposed approach, which compares favorably with state of the art.","Hyperspectral imaging,
Educational institutions,
Training,
Semisupervised learning,
Random variables,
Linear programming"
Predicting Essential Proteins Based on Weighted Degree Centrality,"Essential proteins are vital for an organism's viability under a variety of conditions. There are many experimental and computational methods developed to identify essential proteins. Computational prediction of essential proteins based on the global protein-protein interaction (PPI) network is severely restricted because of the insufficiency of the PPI data, but fortunately the gene expression profiles help to make up the deficiency. In this work, Pearson correlation coefficient (PCC) is used to bridge the gap between PPI and gene expression data. Based on PCC and edge clustering coefficient (ECC), a new centrality measure, i.e., the weighted degree centrality (WDC), is developed to achieve the reliable prediction of essential proteins. WDC is employed to identify essential proteins in the yeast PPI and e-Coli networks in order to estimate its performance. For comparison, other prediction technologies are also performed to identify essential proteins. Some evaluation methods are used to analyze the results from various prediction approaches. The prediction results and comparative analyses are shown in the paper. Furthermore, the parameter λ in the method WDC will be analyzed in detail and an optimal λ value will be found. Based on the optimal λ value, the differentiation of WDC and another prediction method PeC is discussed. The analyses prove that WDC outperforms other methods including DC, BC, CC, SC, EC, IC, NC, and PeC. At the same time, the analyses also mean that it is an effective way to predict essential proteins by means of integrating different data sources.","Proteins,
Gene expression,
Correlation,
Bioinformatics,
Organisms"
Prioritizing Consumers in Smart Grid: A Game Theoretic Approach,"This paper proposes an energy management technique for a consumer-to-grid system in smart grid. The benefit to consumers is made the primary concern to encourage consumers to participate voluntarily in energy trading with the central power station (CPS) in situations of energy deficiency. A novel system model motivating energy trading under the goal of social optimality is proposed. A single-leader multiple-follower Stackelberg game is then studied to model the interactions between the CPS and a number of energy consumers (ECs), and to find optimal distributed solutions for the optimization problem based on the system model. The CPS is considered as a leader seeking to minimize its total cost of buying energy from the ECs, and the ECs are the followers who decide on how much energy they will sell to the CPS for maximizing their utilities. It is shown that the game, which can be implemented distributedly, possesses a socially optimal solution, in which the sum of the benefits to all consumers is maximized, as the total cost to the CPS is minimized. Numerical analysis confirms the effectiveness of the game.","Games,
Energy management,
Smart grids,
Vectors,
Optimization,
Decision making,
Pricing"
Management of an academic HPC cluster: The UL experience,"The intensive growth of processing power, data storage and transmission capabilities has revolutionized many aspects of science. These resources are essential to achieve high-quality results in many application areas. In this context, the University of Luxembourg (UL) operates since 2007 an High Performance Computing (HPC) facility and the related storage by a very small team. The aspect of bridging computing and storage is a requirement of UL service - the reasons are both legal (certain data may not move) and performance related. Nowadays, people from the three faculties and/or the two Interdisciplinary centers within the UL, are users of this facility. More specifically, key research priorities such as Systems Bio-medicine (by LCSB) and Security, Reliability & Trust (by SnT) require access to such HPC facilities in order to function in an adequate environment. The management of HPC solutions is a complex enterprise and a constant area for discussion and improvement. The UL HPC facility and the derived deployed services is a complex computing system to manage by its scale: at the moment of writing, it consists of 150 servers, 368 nodes (3880 computing cores) and 1996 TB of shared storage which are all configured, monitored and operated by only three persons using advanced IT automation solutions based on Puppet [1], FAI [2] and Capistrano [3]. This paper covers all the aspects in relation to the management of such a complex infrastructure, whether technical or administrative. Most design choices or implemented approaches have been motivated by several years of experience in addressing research needs, mainly in the HPC area but also in complementary services (typically Web-based). In this context, we tried to answer in a flexible and convenient way many technological issues. This experience report may be of interest for other research centers and universities belonging either to the public or the private sector looking for good if not best practices in cluster architecture and management.","Servers,
Educational institutions,
Surface acoustic waves,
Context,
IP networks,
Security,
Automation"
Differential Evolution Enhanced With Multiobjective Sorting-Based Mutation Operators,"Differential evolution (DE) is a simple and powerful population-based evolutionary algorithm. The salient feature of DE lies in its mutation mechanism. Generally, the parents in the mutation operator of DE are randomly selected from the population. Hence, all vectors are equally likely to be selected as parents without selective pressure at all. Additionally, the diversity information is always ignored. In order to fully exploit the fitness and diversity information of the population, this paper presents a DE framework with multiobjective sorting-based mutation operator. In the proposed mutation operator, individuals in the current population are firstly sorted according to their fitness and diversity contribution by nondominated sorting. Then parents in the mutation operators are proportionally selected according to their rankings based on fitness and diversity, thus, the promising individuals with better fitness and diversity have more opportunity to be selected as parents. Since fitness and diversity information is simultaneously considered for parent selection, a good balance between exploration and exploitation can be achieved. The proposed operator is applied to original DE algorithms, as well as several advanced DE variants. Experimental results on 48 benchmark functions and 12 real-world application problems show that the proposed operator is an effective approach to enhance the performance of most DE algorithms studied.","Sociology,
Statistics,
Vectors,
Sorting,
Optimization,
Convergence,
Complexity theory"
Scalability of Quasi-Hysteretic FSM-Based Digitally Controlled Single-Inductor Dual-String Buck LED Driver to Multiple Strings,"There has been growing interest in single-inductor multiple-output (SIMO) dc-dc converters due to its reduced cost and smaller form factor in comparison with using multiple single-output converters. An application for such a SIMO-based switching converter is to drive multiple LED strings in a multichannel LED display. This paper proposes a quasi-hysteretic finite-state-machine-based digitally controlled single-inductor dual-output buck switching LED driver operating in discontinuous conduction mode (DCM) and extends it to drive multiple outputs. Based on the time-multiplexing control scheme in DCM, a theoretical upper limit of the total number of outputs in a SIMO buck switching LED driver for various backlight LED current values can be derived analytically. The advantages of the proposed SIMO LED driver include reducing the controller design complexity by eliminating loop compensation, driving more LED strings without limited by the maximum LED current rating, performing digital dimming with no additional switches required, and optimization of local bus voltage to compensate for variability of LED forward voltage VF in each individual LED string with smaller power loss. Loosely binned LEDs with larger VF variation can, therefore, be used for reduced LED costs.","Light emitting diodes,
Inductors,
Switches,
Voltage control,
Capacitors,
Clocks"
Volumetric 3D mapping in real-time on a CPU,"In this paper we propose a novel volumetric multi-resolution mapping system for RGB-D images that runs on a standard CPU in real-time. Our approach generates a textured triangle mesh from a signed distance function that it continuously updates as new RGB-D images arrive. We propose to use an octree as the primary data structure which allows us to represent the scene at multiple scales. Furthermore, it allows us to grow the reconstruction volume dynamically. As most space is either free or unknown, we allocate and update only those voxels that are located in a narrow band around the observed surface. In contrast to a regular grid, this approach saves enormous amounts of memory and computation time. The major challenge is to generate and maintain a consistent triangle mesh, as neighboring cells in the octree are more difficult to find and may have different resolutions. To remedy this, we present in this paper a novel algorithm that keeps track of these dependencies, and efficiently updates corresponding parts of the triangle mesh. In our experiments, we demonstrate the real-time capability on a large set of RGB-D sequences. As our approach does not require a GPU, it is well suited for applications on mobile or flying robots with limited computational resources.","Real-time systems,
Geometry,
Face,
Three-dimensional displays,
Cameras,
Octrees"
MOEA/D with Adaptive Weight Adjustment,"Recently, MOEA/D (multi-objective evolutionary algorithm based on decomposition) has achieved great success in the field of evolutionary multi-objective optimization and has attracted a lot of attention. It decomposes a multi-objective optimization problem (MOP) into a set of scalar subproblems using uniformly distributed aggregation weight vectors and provides an excellent general algorithmic framework of evolutionary multi-objective optimization. Generally, the uniformity of weight vectors in MOEA/D can ensure the diversity of the Pareto optimal solutions, however, it cannot work as well when the target MOP has a complex Pareto front (PF; i.e., discontinuous PF or PF with sharp peak or low tail). To remedy this, we propose an improved MOEA/D with adaptive weight vector adjustment (MOEA/D-AWA). According to the analysis of the geometric relationship between the weight vectors and the optimal solutions under the Chebyshev decomposition scheme, a new weight vector initialization method and an adaptive weight vector adjustment strategy are introduced in MOEA/D-AWA. The weights are adjusted periodically so that the weights of subproblems can be redistributed adaptively to obtain better uniformity of solutions. Meanwhile, computing efforts devoted to subproblems with duplicate optimal solution can be saved. Moreover, an external elite population is introduced to help adding new subproblems into real sparse regions rather than pseudo sparse regions of the complex PF, that is, discontinuous regions of the PF. MOEA/D-AWA has been compared with four state of the art MOEAs, namely the original MOEA/D, Adaptive-MOEA/D, -MOEA/D, and NSGA-II on 10 widely used test problems, two newly constructed complex problems, and two many-objective problems. Experimental results indicate that MOEA/D-AWA outperforms the benchmark algorithms in terms of the IGD metric, particularly when the PF of the MOP is complex.",
Efficient Privacy-Preserving Authentication for Vehicular Ad Hoc Networks,"In this paper, we present an efficient privacy-preserving authentication scheme based on group signature for vehicular ad hoc networks (VANETs). Although group signature is widely used in VANETs to realize anonymous authentication, the existing schemes based on group signatures suffer from long computation delay in the certificate revocation list (CRL) checking and in the signature verification process, leading to high message loss. As a result, they cannot meet the requirement of verifying hundreds of messages per second in VANETs. In our scheme, we first divide the precinct into several domains, in which roadside units (RSUs) are responsible for distributing group private keys and managing vehicles in a localized manner. Then, we use a hash message authentication code (HMAC) to avoid time-consuming CRL checking and to ensure the integrity of messages before batch group authentication. Finally, we adopt cooperative message authentication among entities, in which each vehicle only needs to verify a small number of messages, thus greatly alleviating the authentication burden. The security and performance analysis show that our scheme is more efficient in terms of authentication speed, while keeping conditional privacy in VANETs.","Vehicles,
Authentication,
Public key,
Materials,
Privacy,
Educational institutions"
Gamification for Engaging Computer Science Students in Learning Activities: A Case Study,"Gamification is the use of game design elements in non-game settings to engage participants and encourage desired behaviors. It has been identified as a promising technique to improve students' engagement which could have a positive impact on learning. This study evaluated the learning effectiveness and engagement appeal of a gamified learning activity targeted at the learning of C-programming language. Furthermore, the study inquired into which gamified learning activities were more appealing to students. The study was conducted using the mixed-method sequential explanatory protocol. The data collected and analysed included logs, questionnaires, and pre- and post-tests. The results of the evaluation show positive effects on the engagement of students toward the gamified learning activities and a moderate improvement in learning outcomes. Students reported different motivations for continuing and stopping activities once they completed the mandatory assignment. The preferences for different gamified activities were also conditioned by academic milestones.","Games,
Education,
Computer languages,
Planning,
Electronic mail,
Communities"
Approximation-Based Adaptive Neural Control Design for a Class of Nonlinear Systems,"This paper focuses on approximation-based adaptive neural control of a class of nonlinear non-strict-feedback systems. Based on the structural characteristic and the monotonously increasing property of the system bounding functions, a variable separation method is first developed. By this method, an approximation-based adaptive backstepping approach is proposed for a class of nonlinear non-strict-feedback systems. It is shown that the proposed controller guarantees semi-global boundedness of all the signals in the closed-loop systems. Three examples are used to illustrate the effectiveness of the proposed approach.","Approximation methods,
Nonlinear systems,
Backstepping,
Adaptive control,
Closed loop systems,
Artificial neural networks"
Single Image Defogging by Multiscale Depth Fusion,"Restoration of fog images is important for the deweathering issue in computer vision. The problem is ill-posed and can be regularized within a Bayesian context using a probabilistic fusion model. This paper presents a multiscale depth fusion (MDF) method for defog from a single image. A linear model representing the stochastic residual of nonlinear filtering is first proposed. Multiscale filtering results are probabilistically blended into a fused depth map based on the model. The fusion is formulated as an energy minimization problem that incorporates spatial Markov dependence. An inhomogeneous Laplacian–Markov random field for the multiscale fusion regularized with smoothing and edge-preserving constraints is developed. A nonconvex potential, adaptive truncated Laplacian, is devised to account for spatially variant characteristics such as edge and depth discontinuity. Defog is solved by an alternate optimization algorithm searching for solutions of depth map by minimizing the nonconvex potential in the random field. The MDF method is experimentally verified by real-world fog images including cluttered-depth scene that is challenging for defogging at finer details. The fog-free images are restored with improving contrast and vivid colors but without over-saturation. Quantitative assessment of image quality is applied to compare various defog methods. Experimental results demonstrate that the accurate estimation of depth map by the proposed edge-preserved multiscale fusion should recover high-quality images with sharp details.","Atmospheric modeling,
Markov random fields,
Smoothing methods,
Filtering,
Image restoration,
Adaptation models,
Image edge detection"
Survey: Functional Module Detection from Protein-Protein Interaction Networks,"A protein-protein interaction (PPI) network is a biomolecule relationship network that plays an important role in biological activities. Studies of functional modules in a PPI network contribute greatly to the understanding of biological mechanism. With the development of life science and computing science, a great amount of PPI data has been acquired by various experimental and computational approaches, which presents a significant challenge of detecting functional modules in a PPI network. To address this challenge, many functional module detecting methods have been developed. In this survey, we first analyze the existing problems in detecting functional modules and discuss the countermeasures in the data preprocess and postprocess. Second, we introduce some special metrics for distance or graph developed in clustering process of proteins. Third, we give a classification system of functional module detecting methods and describe some existing detection methods in each category. Fourth, we list databases in common use and conduct performance comparisons of several typical algorithms by popular measurements. Finally, we present the prospects and references for researchers engaged in analyzing PPI networks.","Proteins,
Clustering algorithms,
Measurement,
IEEE Computer Society,
Bioinformatics,
Educational institutions"
iCloudAccess: Cost-Effective Streaming of Video Games From the Cloud With Low Latency,"As a new paradigm, cloud gaming allows users to play high-end video games instantly without downloading or installing the original game software. In this paper, we first conduct a series of well-designed active and passive measurements on a large-scale cloud gaming platform and identify the significant diversity in the queueing delay and response delay among users. We note that the latency problem largely results from user-specified request routing and inelastic server provisioning. To address latency problem of the cloud gaming platform, we further propose an online control algorithm called iCloudAccess to perform intelligent request dispatching and server provisioning. Our main objective is to cut down the provisioning cost of cloud gaming service providers while still ensuring the user quality-of-experience requirements. We formulate the problem as a constrained stochastic optimization problem and apply the Lyapunov optimization theory to derive the online control algorithm with provable upper bounds. We also conduct extensive trace-driven simulations to evaluate the effectiveness of our algorithm, and our results show that our proposed algorithm achieves significant gain over other alternative approaches.","Delays,
Games,
Servers,
Dispatching,
Cloud computing,
Streaming media,
Optimization"
A Submillimetric 3-DOF Force Sensing Instrument With Integrated Fiber Bragg Grating for Retinal Microsurgery,"Vitreoretinal surgery requires very fine motor control to perform precise manipulation of the delicate tissue in the interior of the eye. Besides physiological hand tremor, fatigue, poor kinesthetic feedback, and patient movement, the absence of force sensing is one of the main technical challenges. Previous two degrees of freedom (DOF) force sensing instruments have demonstrated robust force measuring performance. The main design challenge is to incorporate high sensitivity axial force sensing. This paper reports the development of a submillimetric 3-DOF force sensing pick instrument based on fiber Bragg grating (FBG) sensors. The configuration of the four FBG sensors is arranged to maximize the decoupling between axial and transverse force sensing. A superelastic nitinol flexure is designed to achieve high axial force sensitivity. An automated calibration system was developed for repeatability testing, calibration, and validation. Experimental results demonstrate a FBG sensor repeatability of 1.3 pm. The linear model for calculating the transverse forces provides an accurate global estimate. While the linear model for axial force is only locally accurate within a conical region with a 30° vertex angle, a second-order polynomial model can provide a useful global estimate for axial force. Combining the linear model for transverse forces and nonlinear model for axial force, the 3-DOF force sensing instrument can provide sub-millinewton resolution for axial force and a quarter millinewton for transverse forces. Validation with random samples show the force sensor can provide consistent and accurate measurement of 3-D forces.","Force,
Instruments,
Robot sensing systems,
Fiber gratings,
Strain"
Capacity Results for Binary Fading Interference Channels With Delayed CSIT,"To study the effect of lack of up-to-date channel state information at the transmitters (CSITs), we consider two-user binary fading interference channels with Delayed-CSIT. We characterize the capacity region for such channels under homogeneous assumption, where channel gains have identical and independent distributions across time and space, eliminating the possibility of exploiting time/space correlation. We introduce and discuss several novel coding opportunities created by outdated CSIT that can enlarge the achievable rate region. The capacity-achieving scheme relies on accurate combination, concatenation, and merging of these opportunities, depending on the channel statistics. The outer-bounds are based on an extremal inequality we develop for a binary broadcast channel with delayed-CSIT. We further extend the results and characterize the capacity region when output feedback links are available from the receivers to the transmitters in addition to the delayed knowledge of the channel state information. We also discuss the extension of our results to the nonhomogeneous setting.",
EvoRiver: Visual Analysis of Topic Coopetition on Social Media,"Cooperation and competition (jointly called “coopetition”) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., “topic leaders”) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).",
A Cluster-Based Differential Evolution With Self-Adaptive Strategy for Multimodal Optimization,"Multimodal optimization is one of the most challenging tasks for optimization. It requires an algorithm to effectively locate multiple global and local optima, not just single optimum as in a single objective global optimization problem. To address this objective, this paper first investigates a cluster-based differential evolution (DE) for multimodal optimization problems. The clustering partition is used to divide the whole population into subpopulations so that different subpopulations can locate different optima. Furthermore, the self-adaptive parameter control is employed to enhance the search ability of DE. In this paper, the proposed multipopulation strategy and the self-adaptive parameter control technique are applied to two versions of DE, crowding DE (CDE) and species-based DE (SDE), which yield self-CCDE and self-CSDE, respectively. The new algorithms are tested on two different sets of benchmark functions and are compared with several state-of-the-art designs. The experiment results demonstrate the effectiveness and efficiency of the proposed multipopulation strategy and the self-adaptive parameter control technique. The proposed algorithms consistently rank top among all the competing state-of-the-art algorithms.","Optimization,
Sociology,
Statistics,
Vectors,
Clustering algorithms,
Algorithm design and analysis,
Partitioning algorithms"
Role-Dependent Privacy Preservation for Secure V2G Networks in the Smart Grid,"Vehicle-to-grid (V2G), involving both charging and discharging of battery vehicles (BVs), enhances the smart grid substantially to alleviate peaks in power consumption. In a V2G scenario, the communications between BVs and power grid may confront severe cyber security vulnerabilities. Traditionally, authentication mechanisms are solely designed for the BVs when they charge electricity as energy customers. In this paper, we first show that, when a BV interacts with the power grid, it may act in one of three roles: 1) energy demand (i.e., a customer); 2) energy storage; and 3) energy supply (i.e., a generator). In each role, we further demonstrate that the BV has dissimilar security and privacy concerns. Hence, the traditional approach that only considers BVs as energy customers is not universally applicable for the interactions in the smart grid. To address this new security challenge, we propose a role-dependent privacy preservation scheme (ROPS) to achieve secure interactions between a BV and power grid. In the ROPS, a set of interlinked subprotocols is proposed to incorporate different privacy considerations when a BV acts as a customer, storage, or a generator. We also outline both centralized and distributed discharging operations when a BV feeds energy back into the grid. Finally, security analysis is performed to indicate that the proposed ROPS owns required security and privacy properties and can be a highly potential security solution for V2G networks in the smart grid. The identified security challenge as well as the proposed ROPS scheme indicates that role-awareness is crucial for secure V2G networks.","Privacy,
Authentication,
Smart grids,
Electricity,
Protocols"
Analytic Expressions and Bounds for Special Functions and Applications in Communication Theory,"This paper is devoted to the derivation of novel analytic expressions and bounds for a family of special functions that are useful in wireless communication theory. These functions are the well-known Nuttall Q-function, incomplete Toronto function, Rice Ie-function, and incomplete Lipschitz-Hankel integrals. Capitalizing on the offered results, useful identities are additionally derived between the above functions and Humbert, Φ1, function as well as for specific cases of the Kampé de Fériet function. These functions can be considered as useful mathematical tools that can be employed in applications relating to the analytic performance evaluation of modern wireless communication systems, such as cognitive radio, cooperative, and free-space optical communications as well as radar, diversity, and multiantenna systems. As an example, new closed-form expressions are derived for the outage probability over nonlinear generalized fading channels, namely, α-η-μ, α-λ-μ, and α-κ-μ as well as for specific cases of the η-μ and λ-μ fading channels. Furthermore, simple expressions are presented for the channel capacity for the truncated channel inversion with fixed rate and corresponding optimum cutoff signal-to-noise ratio for single-antenna and multiantenna communication systems over Rician fading channels. The accuracy and validity of the derived expressions is justified through extensive comparisons with respective numerical results.","Wireless communication,
Upper bound,
Closed-form solutions,
Fading,
Educational institutions,
Approximation methods,
Finite wordlength effects"
A Generic Approach to Pathological Lung Segmentation,"In this study, we propose a novel pathological lung segmentation method that takes into account neighbor prior constraints and a novel pathology recognition system. Our proposed framework has two stages; during stage one, we adapted the fuzzy connectedness (FC) image segmentation algorithm to perform initial lung parenchyma extraction. In parallel, we estimate the lung volume using rib-cage information without explicitly delineating lungs. This rudimentary, but intelligent lung volume estimation system allows comparison of volume differences between rib cage and FC based lung volume measurements. Significant volume difference indicates the presence of pathology, which invokes the second stage of the proposed framework for the refinement of segmented lung. In stage two, texture-based features are utilized to detect abnormal imaging patterns (consolidations, ground glass, interstitial thickening, tree-inbud, honeycombing, nodules, and micro-nodules) that might have been missed during the first stage of the algorithm. This refinement stage is further completed by a novel neighboring anatomy-guided segmentation approach to include abnormalities with weak textures, and pleura regions. We evaluated the accuracy and efficiency of the proposed method on more than 400 CT scans with the presence of a wide spectrum of abnormalities. To our best of knowledge, this is the first study to evaluate all abnormal imaging patterns in a single segmentation framework. The quantitative results show that our pathological lung segmentation method improves on current standards because of its high sensitivity and specificity and may have considerable potential to enhance the performance of routine clinical tasks.","Lungs,
Pathology,
Image segmentation,
Computed tomography,
Diseases,
Shape"
Resilient Distributed Control in the Presence of Misbehaving Agents in Networked Control Systems,"In this paper, we study the problem of reaching a consensus among all the agents in the networked control systems (NCS) in the presence of misbehaving agents. A reputation-based resilient distributed control algorithm is first proposed for the leader-follower consensus network. The proposed algorithm embeds a resilience mechanism that includes four phases (detection, mitigation, identification, and update), into the control process in a distributed manner. At each phase, every agent only uses local and one-hop neighbors' information to identify and isolate the misbehaving agents, and even compensate their effect on the system. We then extend the proposed algorithm to the leaderless consensus network by introducing and adding two recovery schemes (rollback and excitation recovery) into the current framework to guarantee the accurate convergence of the well-behaving agents in NCS. The effectiveness of the proposed method is demonstrated through case studies in multirobot formation control and wireless sensor networks.","Decentralized control,
Lead,
Monitoring,
Resilience,
Convergence,
Network topology"
"(ACH
)
2
: Routing Scheme to Maximize Lifetime and Throughput of Wireless Sensor Networks","Regarding energy efficiency in wireless sensor networks (WSNs), routing protocols are engaged in a playful manner suggesting a consciousness of high value. In this paper, we present away cluster heads (CHs) with adaptive clustering habit ((ACH)2) scheme for WSNs. Our proposed scheme increases the stability period, network lifetime, and throughput of the WSN. The beauty of our proposed scheme is its away CHs formation, and free association mechanisms. The (ACH)2 controls the CHs' election and selection in such a way that uniform load on CHs is ensured. On the other hand, free association mechanism removes back transmissions. Thus, the scheme operations minimize the over all energy consumption of the network. In subject to throughput maximization, a linear programming-based mathematical formulation is carried out in which the induced subproblem of bandwidth allocation is solved by mixed-bias resource allocation scheme. We implement (ACH)2 scheme, by varying node density and initial energy of nodes in homogeneous, heterogeneous, reactive, and proactive simulation environments. Results justify its applicability.","Wireless sensor networks,
Sensors,
Routing protocols,
Energy consumption,
Routing,
Throughput"
Different Complex ZFs Leading to Different Complex ZNN Models for Time-Varying Complex Generalized Inverse Matrices,"As a special class of recurrent neural network, Zhang neural network (ZNN) has been recently proposed since 2001 for solving various time-varying problems, and has shown high efficiency and excellent performance for solving the problems in the real domain. In this paper, to solve online the time-varying complex generalized inverse (in most cases, the pseudoinverse) problem in the complex domain, a new type of complex-valued ZNN is further proposed and investigated. The design of such a complex ZNN is based on a complex Zhang function (ZF) which is indefinite and quite different from the usual error function (specially, the scalar-valued energy function) in the studies of conventional algorithms. By introducing five different complex ZFs, five different complex ZNN models (termed complex ZNN-I, ZNN-II, ZNN-III, ZNN-IV, and ZNN-V models) are proposed, developed, and investigated for the online solution of the time-varying complex generalized inverse matrices. Theoretical results of convergence analysis are presented to show the desirable properties of complex ZNN models. In addition, we discover the link between the proposed complex ZNN models and the Getz-Marsden dynamic system in the complex domain. Computer-simulation results further demonstrate the effectiveness of complex ZNN models based on different complex ZFs for the time-varying complex generalized inverse matrices.","Mathematical model,
Convergence,
Computational modeling,
Equations,
Problem-solving,
Time-varying systems,
Recurrent neural networks"
3-D Simulation of Interdigitated-Back-Contact Silicon Solar Cells With Quokka Including Perimeter Losses,"An interdigitated-back-contact (IBC) version of Quokka, a recently developed free and fast solar cell simulation program, is presented. It is capable of simulating IBC unit cells with a variety of interdigitated contact and diffusion patterns in both 2-D and 3-D. The program is evaluated by comparing simulated and experimental current-voltage (I-V) curves of high-efficiency IBC solar cells. The simulations include the perimeter effects of edges and busbars by simulating the inner unit cell in 3-D, and accounting for the edges and busbars by 2-D unit cell approximations. The simulation agrees well with the experiment under 1-sun conditions with different aperture areas. Furthermore, simulations of the inner unit cell are successfully validated against Sentaurus Device, for both the I-V curve and detailed free energy losses at maximum power point. The results evidence the validity of the quasi-neutral and conductive-boundary approximations employed by Quokka for fast simulation of IBC solar cells.",
HEp-2 Cell Classification Using Shape Index Histograms With Donut-Shaped Spatial Pooling,"We present a new method for automatic classification of indirect immunoflourescence images of HEp-2 cells into different staining pattern classes. Our method is based on a new texture measure called shape index histograms that captures second-order image structure at multiple scales. Moreover, we introduce a spatial decomposition scheme which is radially symmetric and suitable for cell images. The spatial decomposition is performed using donut-shaped pooling regions of varying sizes when gathering histogram contributions. We evaluate our method using both the ICIP 2013 and the ICPR 2012 competition datasets. Our results show that shape index histograms are superior to other popular texture descriptors for HEp-2 cell classification. Moreover, when comparing to other automated systems for HEp-2 cell classification we show that shape index histograms are very competitive; especially considering the relatively low complexity of the method.","Shape,
Indexes,
Histograms,
Accuracy,
Vectors,
Shape measurement,
Feature extraction"
Motivating Smartphone Collaboration in Data Acquisition and Distributed Computing,"This paper analyzes and compares different incentive mechanisms for a master to motivate the collaboration of smartphone users on both data acquisition and distributed computing applications. To collect massive sensitive data from users, we propose a reward-based collaboration mechanism, where the master announces a total reward to be shared among collaborators, and the collaboration is successful if there are enough users wanting to collaborate. We show that if the master knows the users' collaboration costs, then he can choose to involve only users with the lowest costs. However, without knowing users' private information, then he needs to offer a larger total reward to attract enough collaborators. Users will benefit from knowing their costs before the data acquisition. Perhaps surprisingly, the master may benefit as the variance of users' cost distribution increases. To utilize smartphones' computation resources to solve complex computing problems, we study how the master can design an optimal contract by specifying different task-reward combinations for different user types. Under complete information, we show that the master involves a user type as long as the master's preference characteristic outweighs that type's unit cost. All collaborators achieve a zero payoff in this case. If the master does not know users' private cost information, however, he will conservatively target at a smaller group of users with small costs, and has to give most benefits to the collaborators.","Collaboration,
Data acquisition,
Games,
Computational modeling,
Databases,
Distributed computing,
Google"
Cost-Effective Scalable and Anonymous Certificateless Remote Authentication Protocol,"Existing anonymous remote authentication protocols to secure wireless body area networks (WBANs) raise challenges such as eliminating the need for distributing clients' account information to the application providers and achieving forward security. This paper efficiently addresses these challenges by devising a scalable certificateless remote authentication protocol with anonymity and forward security for WBANs. Different from the previous protocols in this field, our protocol not only provides mutual authentication, session key establishment, anonymity, unlinkability, and nonrepudiation, but also achieves forward security, key escrow resilience, and scalability. Performance evaluation demonstrates that compared with the most efficient ID-based remote anonymous authentication protocol, our protocol reduces at least 52.6% and 17.6% of the overall running time and communication overhead, respectively, and the reduction in the computation cost and communication overhead achieves at least 73.8% and 55.8%, respectively, compared with up-to-date certificateless remote authentication protocol with anonymity.",
Index modulated OFDM with interleaved grouping for V2X communications,"The rapid penetration of intelligent transportation systems (ITS) into the conventional transportation infrastructure urgently calls for high spectral efficiency high reliability communication technology for vehicle-to-vehicle and vehicle-to-infrastructure (V2X) applications. Since orthogonal frequency division multiplexing (OFDM) is widely considered as a promising candidate for such applications, in this paper we propose a novel variation of OFDM for improved spectral efficiency as well as enhanced reliability in V2X channels with correlated frequency-selective fading and inevitable Doppler effects. Our proposed scheme is built upon a recently emerging technique termed as index modulated (IM-)OFDM. However, different from the existing localized subcarrier grouping, we propose interleaved subcarrier grouping. We then carry out analytical and simulated comparisons to demonstrate the merits of this new scheme in terms of both the bit error rate (BER) performance and the maximum achievable rate (MAR) of the overall system, in V2X channels.",
Challenges and Opportunities of Underwater Cognitive Acoustic Networks,"In oceans, both the natural acoustic systems (such as marine mammals) and artificial acoustic systems [like underwater acoustic networks (UANs) and sonar users] use acoustic signal for communication, echolocation, sensing, and detection. This makes the channel spectrum heavily shared by various underwater acoustic systems. Nevertheless, the precious spectrum resource is still underutilized temporally and spatially in underwater environments. To efficiently utilize the spectrum while avoiding harmful interference with other acoustic systems, a smart UAN should be aware of the surrounding environment and reconfigure their operation parameters. Unfortunately, existing UAN designs have mainly focused on the single network scenario, and very few studies have considered the presence of nearby acoustic activities. In this paper, we advocate cognitive acoustic as a promising technique to develop an environment-friendly UAN with high spectrum utilization. However, underwater cognitive acoustic networks (UCANs) also pose grand challenges due to the unique features of underwater channel and acoustic systems. In this paper, we comprehensively investigate these unique characteristics and their impact on the UCAN design. Finally, possible solutions to tackle such challenges are advocated.","Green's function methods,
Impedance,
Integral equations,
Sonar navigation,
Interference,
Underwater acoustics,
Acoustic devices"
An Overview of Information Hiding in H.264/AVC Compressed Video,"Information hiding refers to the process of inserting information into a host to serve specific purpose(s). In this paper, information hiding methods in the H.264/AVC compressed video domain are surveyed. First, the general framework of information hiding is conceptualized by relating the state of an entity to a meaning (i.e., sequences of bits). This concept is illustrated by using various data representation schemes such as bit plane replacement, spread spectrum, histogram manipulation, divisibility, mapping rules, and matrix encoding. Venues at which information hiding takes place are then identified, including prediction process, transformation, quantization, and entropy coding. Related information hiding methods at each venue are briefly reviewed, along with the presentation of the targeted applications, appropriate diagrams, and references. A timeline diagram is constructed to chronologically summarize the invention of information hiding methods in the compressed still image and video domains since 1992. A comparison among the considered information hiding methods is also conducted in terms of venue, payload, bitstream size overhead, video quality, computational complexity, and video criteria. Further perspectives and recommendations are presented to provide a better understanding of the current trend of information hiding and to identify new opportunities for information hiding in compressed video.",
Optimal Periodic Sensor Scheduling in Networks of Dynamical Systems,"We consider the problem of finding optimal time-periodic sensor schedules for estimating the state of discrete-time dynamical systems. We assume that multiple sensors have been deployed and that the sensors are subject to resource constraints, which limits the number of times each can be activated over one period of the periodic schedule. We seek an algorithm that strikes a balance between estimation accuracy and total sensor activations over one period. We make a correspondence between active sensors and the nonzero columns of the estimator gain. We formulate an optimization problem in which we minimize the trace of the error covariance with respect to the estimator gain while simultaneously penalizing the number of nonzero columns of the estimator gain. This optimization problem is combinatorial in nature, and we employ the alternating direction method of multipliers (ADMM) to find its locally optimal solutions. Numerical results and comparisons with other sensor scheduling algorithms in the literature are provided to illustrate the effectiveness of our proposed method.","Schedules,
Frequency measurement,
Time measurement,
Scheduling,
Optimal scheduling,
Kalman filters"
A Frame-Level Rate Control Scheme Based on Texture and Nontexture Rate Models for High Efficiency Video Coding,"In this paper, a frame-level rate control scheme is proposed based on texture and nontexture rate models for High Efficiency Video Coding (HEVC). Due to more complicated coding structures and the adoption of new coding tools, the statistical characteristics of transform residues are significantly different depending on the depth levels of coding units (CUs) from which the residues are obtained. A new texture rate model is constructed for the transform residues, which are categorized into three types of CUs: low-, medium- and high-textured CUs. One single Laplacian probability PDF model is used for each residue category to derive a rate-quantization model. Based on the Laplacian PDF, a simplified rate model for texture bits is derived using entropy. In addition, an analytic rate model for nontexture bits is proposed, which also takes into account the different characteristics of nontexture bits occurring in various depths of CUs in HEVC. The nontexture bitrates are modeled based on the linear relation between the total nontexture data and the dominant nontexture data in each CU category. Based on the proposed rate models for the texture and nontexture bits, accurate rate control can be achieved owing to more precise rate estimation. The experimental results show that the proposed rate control scheme achieves the average PSNR with 0.44 dB higher and the average PSNR standard deviation of 0.32 point lower with the buffer status levels maintained very close to target buffer levels, compared to the conventional methods. Finally, the proposed rate control scheme remarkably outperforms the conventional schemes especially for the sequences of complex texture and large motion.","Encoding,
Transforms,
Video coding,
Laplace equations,
Materials,
Predictive models,
Complexity theory"
Spectral Embedded Hashing for Scalable Image Retrieval,"We propose a new graph based hashing method called spectral embedded hashing (SEH) for large-scale image retrieval. We first introduce a new regularizer into the objective function of the recent work spectral hashing to control the mismatch between the resultant hamming embedding and the low-dimensional data representation, which is obtained by using a linear regression function. This linear regression function can be employed to effectively handle the out-of-sample data, and the introduction of the new regularizer makes SEH better cope with the data sampled from a nonlinear manifold. Considering that SEH cannot efficiently cope with the high dimensional data, we further extend SEH to kernel SEH (KSEH) to improve the efficiency and effectiveness, in which a nonlinear regression function can also be employed to obtain the low dimensional data representation. We also develop a new method to efficiently solve the approximate solution for the eigenvalue decomposition problem in SEH and KSEH. Moreover, we show that some existing hashing methods are special cases of our KSEH. Our comprehensive experiments on CIFAR, Tiny-580K, NUS-WIDE, and Caltech-256 datasets clearly demonstrate the effectiveness of our methods.","Kernel,
Eigenvalues and eigenfunctions,
Linear programming,
Image retrieval,
Binary codes,
Optimization,
Manifolds"
High Efficiency Resonant DC/DC Converter Utilizing a Resistance Compression Network,"This paper presents a new topology for a high-efficiency dc/dc resonant power converter that utilizes a resistance compression network (RCN) to provide simultaneous zero-voltage switching and near-zero-current switching across a wide range of input voltage, output voltage, and power levels. The RCN maintains desired current waveforms over a wide range of voltage operating conditions. The use of ON/OFF control in conjunction with narrowband frequency control enables high efficiency to be maintained across a wide range of power levels. The converter implementation provides galvanic isolation and enables large (greater than 1:10) voltage conversion ratios, making the system suitable for large step-up conversion in applications such as distributed photovoltaic converters. Experimental results from a 200-W prototype operating at 500 kHz show that over 95% efficiency is maintained across an input voltage range of 25-40 V with an output voltage of 400 V. It is also shown that the converter operates very efficiently over a wide output voltage range of 250-400 V, and a wide output power range of 20-200 W. These experimental results demonstrate the effectiveness of the proposed design.","Resistance,
DC-DC power converters,
Power generation,
Impedance,
Zero voltage switching,
Prototypes,
Capacitors"
Contour Model-Based Hand-Gesture Recognition Using the Kinect Sensor,"In RGB-D sensor-based pose estimation, training data collection is often a challenging task. In this paper, we propose a new hand motion capture procedure for establishing the real gesture data set. A 14-patch hand partition scheme is designed for color-based semiautomatic labeling. This method is integrated into a vision-based hand gesture recognition framework for developing desktop applications. We use the Kinect sensor to achieve more reliable and accurate tracking under unconstrained conditions. Moreover, a hand contour model is proposed to simplify the gesture matching process, which can reduce the computational complexity of gesture matching. This framework allows tracking hand gestures in 3-D space and matching gestures with simple contour model, and thus supports complex real-time interactions. The experimental evaluations and a real-world demo of hand gesture interaction demonstrate the effectiveness of this framework.","Image color analysis,
Estimation,
Image segmentation,
Feature extraction,
Labeling,
Three-dimensional displays,
Shape"
Performance Study of Multilayer Perceptrons in a Low-Cost Electronic Nose,"Nonselective gas sensor array has different sensitivities to different chemicals in which each gas sensor will also produce different voltage signals when exposed to an analyte with different concentrations. Therefore, the characteristics of cross sensitivities and broad spectrum of nonselective chemical sensors promote the fast development of portable and low-cost electronic nose (E-nose). Simultaneous concentration estimation of multiple kinds of chemicals is always a challengeable task in E-nose. Multilayer perceptron (MLP) neural network, as one of the most popular pattern recognition algorithms in E-nose, has been studied further in this paper. Two structures of single multiple inputs multiple outputs (SMIMO) and multiple multiple inputs single output (MMISO)-based MLP with parameters optimization in neural network learning processing using eight computational intelligence optimization algorithms are presented in this paper for detection of six kinds of indoor air contaminants. Experiments prove that the performance in accuracy and convergence of MMISO structure-based MLP are much better than SMIMO structure in concentration estimation for more general use of E-nose.","Chemicals,
Estimation,
Arrays,
Optimization,
Neural networks,
Humidity,
Gas detectors"
Mining Compact Bag-of-Patterns for Low Bit Rate Mobile Visual Search,"Visual patterns, i.e., high-order combinations of visual words, contributes to a discriminative abstraction of the high-dimensional bag-of-words image representation. However, the existing visual patterns are built upon the 2D photographic concurrences of visual words, which is ill-posed comparing with their real-world 3D concurrences, since the words from different objects or different depth might be incorrectly bound into an identical pattern. On the other hand, designing compact descriptors from the mined patterns is left open. To address both issues, in this paper, we propose a novel compact bag-of-patterns (CBoPs) descriptor with an application to low bit rate mobile landmark search. First, to overcome the ill-posed 2D photographic configuration, we build up a 3D point cloud from the reference images of each landmark, therefore more accurate pattern candidates can be extracted from the 3D concurrences of visual words. A novel gravity distance metric is then proposed to mine discriminative visual patterns. Second, we come up with compact image description by introducing a CBoPs descriptor. CBoP is figured out by sparse coding over the mined visual patterns, which maximally reconstructs the original bag-of-words histogram with a minimum coding length. We developed a low bit rate mobile landmark search prototype, in which CBoP descriptor is directly extracted and sent from the mobile end to reduce the query delivery latency. The CBoP performance is quantized in several large-scale benchmarks with comparisons to the state-of-the-art compact descriptors, topic features, and hashing descriptors. We have reported comparable accuracy to the million-scale bag-of-words histogram over the million scale visual words, with high descriptor compression rate (approximately 100-bits) than the state-of-the-art bag-of-words compression scheme.","Visualization,
Three-dimensional displays,
Vocabulary,
Image coding,
Histograms,
Mobile communication,
Itemsets"
A Dynamic Appearance Descriptor Approach to Facial Actions Temporal Modeling,"Both the configuration and the dynamics of facial expressions are crucial for the interpretation of human facial behavior. Yet to date, the vast majority of reported efforts in the field either do not take the dynamics of facial expressions into account, or focus only on prototypic facial expressions of six basic emotions. Facial dynamics can be explicitly analyzed by detecting the constituent temporal segments in Facial Action Coding System (FACS) Action Units (AUs)-onset, apex, and offset. In this paper, we present a novel approach to explicit analysis of temporal dynamics of facial actions using the dynamic appearance descriptor Local Phase Quantization from Three Orthogonal Planes (LPQ-TOP). Temporal segments are detected by combining a discriminative classifier for detecting the temporal segments on a frame-by-frame basis with Markov Models that enforce temporal consistency over the whole episode. The system is evaluated in detail over the MMI facial expression database, the UNBC-McMaster pain database, the SAL database, the GEMEP-FERA dataset in database-dependent experiments, in cross-database experiments using the Cohn-Kanade, and the SEMAINE databases. The comparison with other state-of-the-art methods shows that the proposed LPQ-TOP method outperforms the other approaches for the problem of AU temporal segment detection, and that overall AU activation detection benefits from dynamic appearance information.","visual databases,
face recognition,
Markov processes"
Security of IoT systems: Design challenges and opportunities,"Computer-aided design (CAD), in its quest to facilitate new design revolutions, is again on the brink of changing its scope. Following both historical and recent technological and application trends, one can identify several emerging research and development directions in which CAD approaches and techniques may have major impacts. Among them, due to the potential to fundamentally alter everyday life as well as how science and engineering systems are designed and operated, the Internet of Things (IoT) stands out. IoT also poses an extraordinary system replete with conceptual and technical challenges. For instance, greatly reduced quantitative bounds on acceptable area and energy metrics require qualitative breakthroughs in design and optimization techniques. Most likely the most demanding of requirements for the widespread realization of many IoT visions is security. IoT security has an exceptionally wide scope in at least four dimensions. In terms of security scope it includes rarely addressed tasks such as trusted sensing, computation, communication, privacy, and digital forgetting. It also asks for new and better techniques for the protection of hardware, software, and data that considers the possibility of physical access to IoT devices. Sensors and actuators are common components of IoT devices and pose several unique security challenges including the integrity of physical signals and actuating events. Finally, during processing of collected data, one can envision many semantic attacks. Our strategic objective is to provide an impetus for the development of IoT CAD security techniques. We start by presenting a brief survey of IoT challenges and opportunities with an emphasis on security issues. Next, we discuss the potential of hardware-based IoT security approaches. Finally, we conclude with several case studies that advocate the use of stable PUFs and digital PPUFs for several IoT security protocols.","Security,
Hardware,
Logic gates,
Computer architecture,
Delays,
Protocols,
Microprocessors"
Security as a Service Model for Cloud Environment,Cloud computing is becoming increasingly important for provision of services and storage of data in the Internet. However there are several significant challenges in securing cloud infrastructures from different types of attacks. The focus of this paper is on the security services that a cloud provider can offer as part of its infrastructure to its customers (tenants) to counteract these attacks. Our main contribution is a security architecture that provides a flexible security as a service model that a cloud provider can offer to its tenants and customers of its tenants. Our security as a service model while offering a baseline security to the provider to protect its own cloud infrastructure also provides flexibility to tenants to have additional security functionalities that suit their security requirements. The paper describes the design of the security architecture and discusses how different types of attacks are counteracted by the proposed architecture. We have implemented the security architecture and the paper discusses analysis and performance evaluation results.,"Security,
Virtual machining,
Computer architecture,
Cloud computing,
Operating systems,
Privacy,
Software as a service"
Interactive Phrases: Semantic Descriptionsfor Human Interaction Recognition,"This paper addresses the problem of recognizing human interactions from videos. We propose a novel approach that recognizes human interactions by the learned high-level descriptions, interactive phrases. Interactive phrases describe motion relationships between interacting people. These phrases naturally exploit human knowledge and allow us to construct a more descriptive model for recognizing human interactions. We propose a discriminative model to encode interactive phrases based on the latent SVM formulation. Interactive phrases are treated as latent variables and are used as mid-level features. To complement manually specified interactive phrases, we also discover data-driven phrases from data in order to find potentially useful and discriminative phrases for differentiating human interactions. An information-theoretic approach is employed to learn the data-driven phrases. The interdependencies between interactive phrases are explicitly captured in the model to deal with motion ambiguity and partial occlusion in the interactions. We evaluate our method on the BIT-Interaction data set, UT-Interaction data set, and Collective Activity data set. Experimental results show that our approach achieves superior performance over previous approaches.","Videos,
Vectors,
Torso,
Semantics,
Training,
Hidden Markov models,
Feature extraction"
Automatic Tuberculosis Screening Using Chest Radiographs,"Tuberculosis is a major health threat in many regions of the world. Opportunistic infections in immunocompromised HIV/AIDS patients and multi-drug-resistant bacterial strains have exacerbated the problem, while diagnosing tuberculosis still remains a challenge. When left undiagnosed and thus untreated, mortality rates of patients with tuberculosis are high. Standard diagnostics still rely on methods developed in the last century. They are slow and often unreliable. In an effort to reduce the burden of the disease, this paper presents our automated approach for detecting tuberculosis in conventional posteroanterior chest radiographs. We first extract the lung region using a graph cut segmentation method. For this lung region, we compute a set of texture and shape features, which enable the X-rays to be classified as normal or abnormal using a binary classifier. We measure the performance of our system on two datasets: a set collected by the tuberculosis control program of our local county's health department in the United States, and a set collected by Shenzhen Hospital, China. The proposed computer-aided diagnostic system for TB screening, which is ready for field deployment, achieves a performance that approaches the performance of human experts. We achieve an area under the ROC curve (AUC) of 87% (78.3% accuracy) for the first set, and an AUC of 90% (84% accuracy) for the second set. For the first set, we compare our system performance with the performance of radiologists. When trying not to miss any positive cases, radiologists achieve an accuracy of about 82% on this set, and their false positive rate is about half of our system's rate.","Lungs,
Shape,
Hospitals,
X-rays,
Computational modeling,
Medical diagnostic imaging,
Diseases"
Information Flow Control for Secure Cloud Computing,"Security concerns are widely seen as an obstacle to the adoption of cloud computing solutions. Information Flow Control (IFC) is a well understood Mandatory Access Control methodology. The earliest IFC models targeted security in a centralised environment, but decentralised forms of IFC have been designed and implemented, often within academic research projects. As a result, there is potential for decentralised IFC to achieve better cloud security than is available today. In this paper we describe the properties of cloud computing-Platform-as-a-Service clouds in particular-and review a range of IFC models and implementations to identify opportunities for using IFC within a cloud computing context. Since IFC security is linked to the data that it protects, both tenants and providers of cloud services can agree on security policy, in a manner that does not require them to understand and rely on the particulars of the cloud software stack in order to effect enforcement.","Cloud computing,
Software as a service,
Access control,
Runtime,
Data models"
Multivariate Network Exploration and Presentation: From Detail to Overview via Selections and Aggregations,"Network data is ubiquitous; e-mail traffic between persons, telecommunication, transport and financial networks are some examples. Often these networks are large and multivariate, besides the topological structure of the network, multivariate data on the nodes and links is available. Currently, exploration and analysis methods are focused on a single aspect; the network topology or the multivariate data. In addition, tools and techniques are highly domain specific and require expert knowledge. We focus on the non-expert user and propose a novel solution for multivariate network exploration and analysis that tightly couples structural and multivariate analysis. In short, we go from Detail to Overview via Selections and Aggregations (DOSA): users are enabled to gain insights through the creation of selections of interest (manually or automatically), and producing high-level, infographic-style overviews simultaneously. Finally, we present example explorations on real-world datasets that demonstrate the effectiveness of our method for the exploration and understanding of multivariate networks where presentation of findings comes for free.","Data visualization,
Clutter,
Network topology,
Context awareness,
Image color analysis"
As-Projective-As-Possible Image Stitching with Moving DLT,"The success of commercial image stitching tools often leads to the impression that image stitching is a “solved problem”. The reality, however, is that many tools give unconvincing results when the input photos violate fairly restrictive imaging assumptions; the main two being that the photos correspond to views that differ purely by rotation, or that the imaged scene is effectively planar. Such assumptions underpin the usage of 2D projective transforms or homographies to align photos. In the hands of the casual user, such conditions are often violated, yielding misalignment artifacts or “ghosting” in the results. Accordingly, many existing image stitching tools depend critically on post-processing routines to conceal ghosting. In this paper, we propose a novel estimation technique called Moving Direct Linear Transformation (Moving DLT) that is able to tweak or fine-tune the projective warp to accommodate the deviations of the input data from the idealized conditions. This produces as-projective-as-possible image alignment that significantly reduces ghosting without compromising the geometric realism of perspective image stitching. Our technique thus lessens the dependency on potentially expensive postprocessing algorithms. In addition, we describe how multiple as-projective-as-possible warps can be simultaneously refined via bundle adjustment to accurately align multiple images for large panorama creation.","Cameras,
Three-dimensional displays,
Estimation,
Yarn,
Extrapolation,
Educational institutions"
A Semisupervised Multiagent System Model to Support Consensus-Reaching Processes,"Consensus reaching processes as part of solving group decision-making problems attempt to reach a mutual agreement in the group before making a decision. Most consensus models and consensus support systems that are proposed in the literature present some noticeable drawbacks: the need for constant human supervision by experts to guarantee an effective process and the difficulty to manage large groups of experts, which are increasingly common in current decisions and may imply a higher cost and complexity to carry out such processes. In order to overcome these problems, this paper presents a novel consensus support system based on the multiagent system paradigm, which automates and supports consensus reaching processes by providing agents with the necessary degree of autonomy to conduct discussion processes by themselves, with a semisupervised methodology. The main novelty of such a system is the agent semisupervised autonomy approach it incorporates, which lets agents conduct most of the discussion process by themselves and allows them to interact with their corresponding human experts under certain circumstances in which human supervision might be convenient and necessary.","Cascading style sheets,
Multi-agent systems,
Computational modeling,
Computer architecture,
Proposals,
Decision making,
Uncertainty"
Control-limited differential dynamic programming,"Trajectory optimizers are a powerful class of methods for generating goal-directed robot motion. Differential Dynamic Programming (DDP) is an indirect method which optimizes only over the unconstrained control-space and is therefore fast enough to allow real-time control of a full humanoid robot on modern computers. Although indirect methods automatically take into account state constraints, control limits pose a difficulty. This is particularly problematic when an expensive robot is strong enough to break itself. In this paper, we demonstrate that simple heuristics used to enforce limits (clamping and penalizing) are not efficient in general. We then propose a generalization of DDP which accommodates box inequality constraints on the controls, without significantly sacrificing convergence quality or computational effort. We apply our algorithm to three simulated problems, including the 36-DoF HRP-2 robot. A movie of our results can be found here goo.gl/eeiMnn.","Convergence,
Trajectory,
Clamps,
Robots,
Optimization,
Dynamic programming,
Heuristic algorithms"
An Accurate and Robust Range Image Registration Algorithm for 3D Object Modeling,"Range image registration is a fundamental research topic for 3D object modeling and recognition. In this paper, we propose an accurate and robust algorithm for pairwise and multi-view range image registration. We first extract a set of Rotational Projection Statistics (RoPS) features from a pair of range images, and perform feature matching between them. The two range images are then registered using a transformation estimation method and a variant of the Iterative Closest Point (ICP) algorithm. Based on the pairwise registration algorithm, we propose a shape growing based multi-view registration algorithm. The seed shape is initialized with a selected range image and then sequentially updated by performing pairwise registration between itself and the input range images. All input range images are iteratively registered during the shape growing process. Extensive experiments were conducted to test the performance of our algorithm. The proposed pairwise registration algorithm is accurate, and robust to small overlaps, noise and varying mesh resolutions. The proposed multi-view registration algorithm is also very accurate. Rigorous comparisons with the state-of-the-art show the superiority of our algorithm.",
Learning in the Model Space for Cognitive Fault Diagnosis,"The emergence of large sensor networks has facilitated the collection of large amounts of real-time data to monitor and control complex engineering systems. However, in many cases the collected data may be incomplete or inconsistent, while the underlying environment may be time-varying or unformulated. In this paper, we develop an innovative cognitive fault diagnosis framework that tackles the above challenges. This framework investigates fault diagnosis in the model space instead of the signal space. Learning in the model space is implemented by fitting a series of models using a series of signal segments selected with a sliding window. By investigating the learning techniques in the fitted model space, faulty models can be discriminated from healthy models using a one-class learning algorithm. The framework enables us to construct a fault library when unknown faults occur, which can be regarded as cognitive fault isolation. This paper also theoretically investigates how to measure the pairwise distance between two models in the model space and incorporates the model distance into the learning algorithm in the model space. The results on three benchmark applications and one simulated model for the Barcelona water distribution network confirm the effectiveness of the proposed framework.","water supply,
cognitive systems,
fault diagnosis,
learning (artificial intelligence)"
Circularly Polarized Helical Antenna for ISM-Band Ingestible Capsule Endoscope Systems,"A multilayer miniaturized circularly polarized (CP) helical antenna is designed and experimentally demonstrated for industrial, scientific, and medical (ISM) (2.4-2.48 GHz) ingestible capsule endoscope systems. The proposed antenna is composed of three open loops at various layers connected by via holes to form an axial-mode helical structure to generate traveling wave radiation. A one-layer muscle phantom model is used for initial design and optimization. The footprint of the proposed antenna is π×(5.5)2×3.81 mm 3. The simulated and measured impedance bandwidth is over 40% and 26% in the one-layer muscle phantom, respectively. The simulated axial ratio (AR) bandwidth is around 33.3%. The CP purity of the proposed antenna is calculated by comparing the communication link levels for two orthogonal polarizations. Additionally, electrical components are modeled inside the capsule to evaluate the effects on the antenna performance. CST voxel Gustav human body is utilized to study the design in a realistic environment. Finally, an omnidirectional CP exterior antenna is designed and the communication link is evaluated.","Helical antennas,
Dipole antennas,
Muscles,
Phantoms,
Reflection coefficient,
Resonant frequency"
Soft Biometrics; Human Identification Using Comparative Descriptions,"Soft biometrics are a new form of biometric identification which use physical or behavioral traits that can be naturally described by humans. Unlike other biometric approaches, this allows identification based solely on verbal descriptions, bridging the semantic gap between biometrics and human description. To permit soft biometric identification the description must be accurate, yet conventional human descriptions comprising of absolute labels and estimations are often unreliable. A novel method of obtaining human descriptions will be introduced which utilizes comparative categorical labels to describe differences between subjects. This innovative approach has been shown to address many problems associated with absolute categorical labels-most critically, the descriptions contain more objective information and have increased discriminatory capabilities. Relative measurements of the subjects' traits can be inferred from comparative human descriptions using the Elo rating system. The resulting soft biometric signatures have been demonstrated to be robust and allow accurate recognition of subjects. Relative measurements can also be obtained from other forms of human representation. This is demonstrated using a support vector machine to determine relative measurements from gait biometric signatures-allowing retrieval of subjects from video footage by using human comparisons, bridging the semantic gap.","Databases,
Reliability,
Iris recognition,
Surveillance,
Face,
Color"
Optimized Electric Vehicle Charging With Intermittent Renewable Energy Sources,"Renewable energy and Electric Vehicles (EVs) are promising solutions for energy cost savings and emission reduction. However, integration of renewable energy sources into the electric grid could be a difficult task, because of the generation source intermittency and inconsistency with energy usage. In this paper, we present results of our study on the problem of allocating energy from renewable sources to EVs in a cost efficient manner. We have assumed that the renewable energy supply is time variant and in many ways unpredictable. EVs' charging requests should be satisfied within a specified time frame, which may incur a cost of drawing additional energy (possibly non-renewable energy) from the power grid if the renewable energy supply is not sufficient to meet the deadlines and may also reduce energy efficiency. We have formulated a stochastic optimization problem based on queuing model to minimize the time average cost of using non-renewable energy sources. The proposed approach fully considers the individual charging rate limit and deadline of each EV. The Lyapunov optimization technique is used to solve the problem. The developed dynamic control algorithm does not require knowledge of the statistical distribution of the time-varying renewable energy generation, EV charging demand, or extra energy pricing. Simulation results using different wind power generation profiles were performed and analyzed in the study. The results show that our EV charging scheduling method based on Lyapunov optimization can reduce both charging cost and mean delay time of fulfilling EV charging requests.","Renewable energy sources,
Energy efficiency,
Electric vehicles,
Lyapunov methods,
Stochastic processes,
Optimization,
Smart grids"
MPC-Based Voltage/Var Optimization for Distribution Circuits With Distributed Generators and Exponential Load Models,"This paper proposes a model predictive control (MPC)-based voltage/var optimization (VVO) technique considering the integration of distributed generators and load-to-voltage sensitivities. The paper schedules optimal tap positions of on-load tap changer and switch statuses of capacitor banks based on predictive outputs of wind turbines and photovoltaic generators. Compared with previous efforts on VVO which used constant-power load model, the exponential load model is used to capture the various load behaviors in this paper. Different customer types such as industrial, residential, and commercial loads are also considered. The uncertainties of model prediction errors are taken into account in the proposed model. A scenario reduction technique is applied to enhance a tradeoff between the accuracy of the solution and the computational burden. The MPC-based VVO problem is formulated as a mixed-integer nonlinear program with reduced scenarios. Case studies show the effectiveness of the proposed method.","Load modeling,
Capacitors,
Reactive power,
Voltage control,
Mathematical model,
Predictive control"
Application-based review of GaN HFETs,"Normally-off GaN-on-Si heterojunction field-effect transistors (HFETs) have been developed with up to 650 V blocking capability, fast switching, and low conduction losses in commercial devices. The natively depletion-mode device can be modified to be normally-off using a variety of techniques. For a power electronics engineer accustomed to Si-based converter design, there is inherent benefit to understanding the unique characteristics and challenges that distinguish GaN HFETs from Si MOSFETs. Dynamic Rds-on self-commutated reverse conduction, gate voltage and current requirements, and the effects of very fast switching are explained from an applications perspective. This paper reviews available literature on commercial and near-commercial GaN HFETs, to prepare engineers with Si-based power electronics experience to effectively design GaN-based converters.","Logic gates,
Gallium nitride,
HEMTs,
MODFETs,
Aluminum gallium nitride,
Silicon,
Threshold voltage"
Equivalence of SVM and Carrier-Based PWM in Three-Phase/Wire/Level Vienna Rectifier and Capability of Unbalanced-Load Control,"In this paper, the analysis of space vector modulation of a three-phase/wire/level Vienna rectifier is conducted, according to which the implementation of the equivalent carrier-based pulsewidth modulation is deduced theoretically within each separated sector in the diagram of vectors. The voltage balancing ability of dc-link neutral point, which depends on the uneven distribution of short vectors, is analyzed as well. An adaptive and robust controller to balance the output voltage under the unbalanced load limit for different modulation indices is proposed. The proposed controller can work at wide range of unbalanced load condition as well. Furthermore, the maximum unbalanced load is deduced versus the modulation index m when the converter works in unity power factor. An experimental prototype of 2.5 kW was built to verify the effectiveness of the theoretical analysis. Finally, the tested unbalanced limit of outputs for the experimental platform was given under different modulation indices. The output voltages for dual bus are balanced, and the theoretical analysis is verified.","Vectors,
Support vector machines,
Rectifiers,
Pulse width modulation,
Switches,
Topology"
An Efficient Approach for Optimizing Frequency Reconfigurable Pixel Antennas Using Genetic Algorithms,In this paper we describe a method for optimizing frequency reconfigurable pixel antennas. The method utilizes a multi-objective function that is efficiently computed by using only one full electromagnetic simulation in the entire genetic algorithm optimization process. Minimization of the number of switches in the design is also attempted. The method is demonstrated using an antenna structure consisting of a rectangular grid of pixels adjacent to a ground plane and using RF MEMS switches for achieving the reconfigurability. The effects of the RF MEMS switches on the antenna performance as well as the control feed lines for them are also addressed. We provide both simulation and experimental results for a reconfigurable dual-band antenna that reconfigures the bands 820-1140 and 1720-1900 MHz to the bands 860-1160 and 1890-2300 MHz with dimensions of 39 mm × 24 mm on a ground plane of 40 mm × 65 mm with one switch only. The results demonstrate that reconfigurable antennas can be designed effectively with a minimum number of switches using an efficient optimization method.,
Designing a Robust Activity Recognition Framework for Health and Exergaming Using Wearable Sensors,"Detecting human activity independent of intensity is essential in many applications, primarily in calculating metabolic equivalent rates and extracting human context awareness. Many classifiers that train on an activity at a subset of intensity levels fail to recognize the same activity at other intensity levels. This demonstrates weakness in the underlying classification method. Training a classifier for an activity at every intensity level is also not practical. In this paper, we tackle a novel intensity-independent activity recognition problem where the class labels exhibit large variability, the data are of high dimensionality, and clustering algorithms are necessary. We propose a new robust stochastic approximation framework for enhanced classification of such data. Experiments are reported using two clustering techniques, K-Means and Gaussian Mixture Models. The stochastic approximation algorithm consistently outperforms other well-known classification schemes which validate the use of our proposed clustered data representation. We verify the motivation of our framework in two applications that benefit from intensity-independent activity recognition. The first application shows how our framework can be used to enhance energy expenditure calculations. The second application is a novel exergaming environment aimed at using games to reward physical activity performed throughout the day, to encourage a healthy lifestyle.","Stochastic processes,
Approximation methods,
Feature extraction,
Accelerometers,
Clustering algorithms,
Legged locomotion,
Approximation algorithms"
Robust Multi-Factor Authentication for Fragile Communications,"In large-scale systems, user authentication usually needs the assistance from a remote central authentication server via networks. The authentication service however could be slow or unavailable due to natural disasters or various cyber attacks on communication channels. This has raised serious concerns in systems which need robust authentication in emergency situations. The contribution of this paper is two-fold. In a slow connection situation, we present a secure generic multi-factor authentication protocol to speed up the whole authentication process. Compared with another generic protocol in the literature, the new proposal provides the same function with significant improvements in computation and communication. Another authentication mechanism, which we name stand-alone authentication, can authenticate users when the connection to the central server is down. We investigate several issues in stand-alone authentication and show how to add it on multi-factor authentication protocols in an efficient and generic way.","Authentication,
Protocols,
Biometrics (access control),
Servers,
Telecommunication services,
Digital signatures"
Origin-Destination Flow Data Smoothing and Mapping,"This paper presents a new approach to flow mapping that extracts inherent patterns from massive geographic mobility data and constructs effective visual representations of the data for the understanding of complex flow trends. This approach involves a new method for origin-destination flow density estimation and a new method for flow map generalization, which together can remove spurious data variance, normalize flows with control population, and detect high-level patterns that are not discernable with existing approaches. The approach achieves three main objectives in addressing the challenges for analyzing and mapping massive flow data. First, it removes the effect of size differences among spatial units via kernel-based density estimation, which produces a measurement of flow volume between each pair of origin and destination. Second, it extracts major flow patterns in massive flow data through a new flow sampling method, which filters out duplicate information in the smoothed flows. Third, it enables effective flow mapping and allows intuitive perception of flow patterns among origins and destinations without bundling or altering flow paths. The approach can work with both point-based flow data (such as taxi trips with GPS locations) and area-based flow data (such as county-to-county migration). Moreover, the approach can be used to detect and compare flow patterns at different scales or in relatively sparse flow datasets, such as migration for each age group. We evaluate and demonstrate the new approach with case studies of U.S. migration data and experiments with synthetic data.","Flow graphs,
Statistics,
Smoothing methods,
Bandwidth allocation,
Feature extraction,
Data visualization"
Transmitarray Antenna Design Using Cross-Slot Elements With No Dielectric Substrate,"The transmitarray antenna has received considerable attention in recent years as it combines the favorable features of the lens antenna and the array techniques. The goal of this letter is to present detailed design analysis of a multiple-conductor-layers transmitarray antenna using slot-type element with no dielectric substrate. A transmitarray antenna using quad-layer cross-slot elements has been designed, fabricated, and tested for 11.3 GHz operating frequency. The measured gain of the prototype transmitarray is 23.76 dB at 11.3 GHz. It is observed that the oblique incidence and the wave polarization have strong effect on the transmission coefficient of the slot-type element. Thus, a detailed analysis of the transmitarray considering the oblique incidence angles and the feed polarization conditions is performed with good agreement between the simulation and measured results.","Transmitting antennas,
Antenna measurements,
Gain,
Arrays,
Feeds,
Gain measurement"
Designing an Efficient Image Encryption-Then-Compression System via Prediction Error Clustering and Random Permutation,"In many practical scenarios, image encryption has to be conducted prior to image compression. This has led to the problem of how to design a pair of image encryption and compression algorithms such that compressing the encrypted images can still be efficiently performed. In this paper, we design a highly efficient image encryption-then-compression (ETC) system, where both lossless and lossy compression are considered. The proposed image encryption scheme operated in the prediction error domain is shown to be able to provide a reasonably high level of security. We also demonstrate that an arithmetic coding-based approach can be exploited to efficiently compress the encrypted images. More notably, the proposed compression approach applied to encrypted images is only slightly worse, in terms of compression efficiency, than the state-of-the-art lossless/lossy image coders, which take original, unencrypted images as inputs. In contrast, most of the existing ETC solutions induce significant penalty on the compression efficiency.","Image coding,
Encryption,
Bit rate,
Decoding,
Image reconstruction"
Learning High-Level Feature by Deep Belief Networks for 3-D Model Retrieval and Recognition,"3-D shape analysis has attracted extensive research efforts in recent years, where the major challenge lies in designing an effective high-level 3-D shape feature. In this paper, we propose a multi-level 3-D shape feature extraction framework by using deep learning. The low-level 3-D shape descriptors are first encoded into geometric bag-of-words, from which middle-level patterns are discovered to explore geometric relationships among words. After that, high-level shape features are learned via deep belief networks, which are more discriminative for the tasks of shape classification and retrieval. Experiments on 3-D shape recognition and retrieval demonstrate the superior performance of the proposed method in comparison to the state-of-the-art methods.","Shape,
Three-dimensional displays,
Solid modeling,
Feature extraction,
Kernel,
Heating,
Educational institutions"
Real-time and low latency embedded computer vision hardware based on a combination of FPGA and mobile CPU,"Recent developments in smartphones create an ideal platform for robotics and computer vision applications: they are small, powerful, embedded devices with low-power mobile CPUs. However, though the computational power of smartphones has increased substantially in recent years, they are still not capable of performing intense computer vision tasks in real time, at high frame rates and low latency. We present a combination of FPGA and mobile CPU to overcome the computational and latency limitations of mobile CPUs alone. With the FPGA as an additional layer between the image sensor and CPU, the system is capable of accelerating computer vision algorithms to real-time performance. Low latency calculation allows for direct usage within control loops of mobile robots. A stereo camera setup with disparity estimation based on the semi global matching algorithm is implemented as an accelerated example application. The system calculates dense disparity images with 752×480 pixels resolution at 60 frames per second. The overall latency of the disparity estimation is less than 2 milliseconds. The system is suitable for any mobile robot application due to its light weight and low power consumption.","Field programmable gate arrays,
Mobile communication,
Image sensors,
Cameras,
Streaming media,
Real-time systems,
Estimation"
Distributed Sampled-Data {H_\infty } Filtering for Sensor Networks With Nonuniform Sampling Periods,"This paper presents a switched system approach to solving the distributed sampled-data \mbiH∞ filtering problem for sensor networks with nonuniform sampling periods. The sensor network is considered to be a peer-to-peer network without an estimation center. The measurements are sampled with nonuniform sampling periods, and each sensor in the network collects the sampled measurements only from its neighbors and runs a distributed \mbiH∞ filtering algorithm to generate estimates. A stochastic switched system model is proposed to describe the aperiodic sampled-data filtering system with random packet losses. A sufficient existence condition for the distributed \mbiH∞ filters is derived by using the average dwell time method, and it is shown that the obtained condition critically depends on the sampling periods and the packet loss probabilities. The design of the filters is accomplished by solving a convex optimization problem, and the designed filters guarantee that the filtering system is mean-square exponentially stable and all the filtering errors satisfy an average H∞ noise attenuation level. An illustrative example is finally given to show the effectiveness of the proposed results.","Estimation,
Switched systems,
Nonuniform sampling,
Packet loss,
Noise,
Switches"
Task-Tree Based Large-Scale Mosaicking for Massive Remote Sensed Imageries with Dynamic DAG Scheduling,"Remote sensed imagery mosaicking at large scale has been receiving increasing attentions in regional to global research. However, when scaling to large areas, image mosaicking becomes extremely challenging for the dependency relationships among a large collection of tasks which give rise to ordering constraint, the demand of significant processing capabilities and also the difficulties inherent in organizing these enormous tasks and RS image data. We propose a task-tree based mosaicking for remote sensed imageries at large scale with dynamic DAG scheduling. It expresses large scale mosaicking as a data-driven task tree with minimal height. And also a critical path based dynamical DAG scheduling solution with status queue named CPDS-SQ is provided to offer an optimized schedule on multi-core cluster with minimal completion time. All the individual dependent tasks are run by a core parallel mosaicking program implemented with MPI to perform mosaicking on different pairs of images. Eventually, an effective but easier approach is offered to improve the large-scale processing capability by decoupling the dependence relationships among tasks from the complex parallel processing procedure. Through experiments on large-scale mosaicking, we confirmed that our approach were efficient and scalable.","Dynamic scheduling,
Remote sensing,
Radiometry,
Processor scheduling,
Schedules"
Batched Sparse Codes,"Network coding can significantly improve the transmission rate of communication networks with packet loss compared with routing. However, using network coding usually incurs high computational and storage costs in the network devices and terminals. For example, some network coding schemes require the computational and/or storage capacities of an intermediate network node to increase linearly with the number of packets for transmission, making such schemes difficult to be implemented in a router-like device that has only constant computational and storage capacities. In this paper, we introduce batched sparse code (BATS code), which enables a digital fountain approach to resolve the above issue. BATS code is a coding scheme that consists of an outer code and inner code. The outer code is a matrix generation of a fountain code. It works with the inner code that comprises random linear coding at the intermediate network nodes. BATS codes preserve such desirable properties of fountain codes as ratelessness and low encoding/decoding complexity. The computational and storage capacities of the intermediate network nodes required for applying BATS codes are independent of the number of packets for transmission. Almost capacity-achieving BATS code schemes are devised for unicast networks and certain multicast networks. For general multicast networks, under different optimization criteria, guaranteed decoding rates for the destination nodes can be obtained.","Decoding,
Network coding,
Encoding,
Complexity theory,
Vectors,
Generators,
Packet loss"
A Social Compute Cloud: Allocating and Sharing Infrastructure Resources via Social Networks,"Social network platforms have rapidly changed the way that people communicate and interact. They have enabled the establishment of, and participation in, digital communities as well as the representation, documentation and exploration of social relationships. We believe that as `apps' become more sophisticated, it will become easier for users to share their own services, resources and data via social networks. To substantiate this, we present a social compute cloud where the provisioning of cloud infrastructure occurs through “friend” relationships. In a social compute cloud, resource owners offer virtualized containers on their personal computer(s) or smart device(s) to their social network. However, as users may have complex preference structures concerning with whom they do or do not wish to share their resources, we investigate, via simulation, how resources can be effectively allocated within a social community offering resources on a best effort basis. In the assessment of social resource allocation, we consider welfare, allocation fairness, and algorithmic runtime. The key findings of this work illustrate how social networks can be leveraged in the construction of cloud computing infrastructures and how resources can be allocated in the presence of user sharing preferences.","Resource management,
Computational modeling,
Cloud computing,
Facebook,
Educational institutions,
Supply and demand"
PaCC: A Parallel Compare and Compress Codec for Area Reduction in Nonvolatile Processors,"Nonvolatile (NV) processors have attracted much attention in recent years due to their zero standby power, resilience to power failures, and instant-on feature. One design challenge of NV processors is the excess area needed by NV registers. This paper introduces a parallel compare and compress (PaCC) architecture to reduce such excess area. A key component of the PaCC architecture is a new codec which effectively balances area and performance. In addition, the PaCC architecture includes a configurable state table to support reference vector selection for different applications. With the proposed vector selection algorithm, the PaCC architecture can outperform other vector selection approaches by over 59% in terms of reduction in the number of NV registers. The proposed architecture has been fully realized at the circuit level and synthesized for the Rohm's 0.13-μm ferroelectric-CMOS hybrid process. Results demonstrate that the design can reduce the number of NV registers by 70%-80% with less than 1% overflow possibility, which leads to up to 30% processor area saving. The overall approach is applicable to any NV processor design regardless of the NV material used.",
An Improved RIP-Based Performance Guarantee for Sparse Signal Recovery via Orthogonal Matching Pursuit,"A sufficient condition reported very recently for perfect recovery of a K-sparse vector via orthogonal matching pursuit (OMP) in K iterations (when there is no noise) is that the restricted isometry constant (RIC) of the sensing matrix satisfies δK+1 <; (1/√(K) + 1). In the noisy case, this RIC upper bound along with a requirement on the minimal signal entry magnitude is known to guarantee exact support identification. In this paper, we show that, in the presence of noise, a relaxed RIC upper bound δK+1 <; (√(4K + 1) - 1/2K) together with a relaxed requirement on the minimal signal entry magnitude suffices to achieve perfect support identification using OMP. In the noiseless case, our result asserts that such a relaxed RIC upper bound can ensure exact support recovery in K iterations: this narrows the gap between the so far best known bound δK+1 <; (1/√(K( + 1)) and the ultimate performance guarantee δK+1 = (1/(K)). Our approach relies on a newly established near orthogonality condition, characterized via the achievable angles between two orthogonal sparse vectors upon compression, and, thus, better exploits the knowledge about the geometry of the compressed space. The proposed near orthogonality condition can be also exploited to derive less restricted sufficient conditions for signal reconstruction in two other compressive sensing problems, namely, compressive domain interference cancellation and support identification via the subspace pursuit algorithm.","Sensors,
Noise,
Vectors,
Matching pursuit algorithms,
Sparse matrices,
Upper bound,
Signal reconstruction"
Towards Adaptively Tuned Silicon Microring Resonators for Optical Networks-on-Chip Applications,"We propose to monitor the spectral alignment of silicon microring resonators with an optical carrier in the 1300 / 1550 nm wavelengths by photodetecting the microring internal power using a defect-state-absorption-based silicon photodetector integrated along the microring. We can thereby adaptively tune the resonance wavelength based on the photocurrent to compensate the spectral misalignment using either an integrated electro-optical or thermo-optical tuner. Our analysis suggests that the spectral alignment can be preserved within ~±0.01 nm upon an on-chip temperature variation of 10°C or a carrier wavelength drift of ±60 pm, assuming a closed-loop operation time shorter than 900 μs and a total power consumption of ~0.65 mW for 1550 nm and ~1.1 mW for 1300 nm. As a proof-of-concept, we experimentally demonstrate monitoring the spectral alignment using the photocurrents from a silicon microring carrier-injection switch upon a 10 Gb/s data transmission in 1550 nm, while subjecting the switch to a temperature variation between 20 - 33 °C. We further analyze the feasibility of integrating such an adaptively tuned silicon microring resonator into a single-channel M-input N-output (M × N) optical switch-matrix. Our worst-case analysis suggests that a 16 × 16 switch-matrix in an estimated total footprint of ~640 μm × 480 μm imposes an estimated total power consumption of ~167 mW for 1550 nm, and a 13 × 13 switch-matrix in an estimated total footprint of ~520 μm × 390 μm imposes an estimated power consumption of ~185 mW for 1300 nm.","Optical switches,
Silicon,
Optical waveguides,
Tuning,
Optical resonators,
Monitoring,
Photoconductivity"
Low-Power High-Throughput LDPC Decoder Using Non-Refresh Embedded DRAM,"The majority of the power consumption of a high-throughput LDPC decoder is spent on memory. Unlike in a general-purpose processor, the memory access in an LDPC decoder is deterministic and the access window is short. We take advantage of the unique memory access characteristic to design a non-refresh eDRAM that holds data for the necessary access window, and further improve its access time by trading off the excess retention time. The resulting 3T eDRAM cell is designed to balance wordline coupling to reliably retain data for a fast access. We integrate 32 5x210 non-refresh eDRAM arrays in a row-parallel LDPC decoder suitable for the IEEE 802.11ad standard. Memory refresh is eliminated and random access is replaced with a simple sequential addressing. With row merging and dual-frame processing, the 1.6 mm 2 65 nm LDPC decoder chip achieves a peak throughput of 9 Gb/s at 89.5 pJ/b, of which only 21% is spent on eDRAMs. With voltage and frequency scaling, the power consumption of the LDPC decoder is reduced to 37.7 mW for a 1.5 Gb/s throughput at 35.6 pJ/b.","Parity check codes,
Decoding,
Throughput,
Clocks,
Merging,
Memory management"
Background-Modeling-Based Adaptive Prediction for Surveillance Video Coding,"The exponential growth of surveillance videos presents an unprecedented challenge for high-efficiency surveillance video coding technology. Compared with the existing coding standards that were basically developed for generic videos, surveillance video coding should be designed to make the best use of the special characteristics of surveillance videos (e.g., relative static background). To do so, this paper first conducts two analyses on how to improve the background and foreground prediction efficiencies in surveillance video coding. Following the analysis results, we propose a background-modeling-based adaptive prediction (BMAP) method. In this method, all blocks to be encoded are firstly classified into three categories. Then, according to the category of each block, two novel inter predictions are selectively utilized, namely, the background reference prediction (BRP) that uses the background modeled from the original input frames as the long-term reference and the background difference prediction (BDP) that predicts the current data in the background difference domain. For background blocks, the BRP can effectively improve the prediction efficiency using the higher quality background as the reference; whereas for foreground-background-hybrid blocks, the BDP can provide a better reference after subtracting its background pixels. Experimental results show that the BMAP can achieve at least twice the compression ratio on surveillance videos as AVC (MPEG-4 Advanced Video Coding) high profile, yet with a slightly additional encoding complexity. Moreover, for the foreground coding performance, which is crucial to the subjective quality of moving objects in surveillance videos, BMAP also obtains remarkable gains over several state-of-the-art methods.","Surveillance,
Encoding,
Video coding,
Image coding,
Object oriented modeling,
Complexity theory,
Decoding"
Supporting Heterogeneity in Cyber-Physical Systems Architectures,"Cyber-physical systems (CPS) are heterogeneous, because they tightly couple computation, communication, and control along with physical dynamics, which are traditionally considered separately. Without a comprehensive modeling formalism, model-based development of CPS involves using a multitude of models in a variety of formalisms that capture various aspects of the system design, such as software design, networking design, physical models, and protocol design. Without a rigorous unifying framework, system integration and integration of the analysis results for various models remains ad hoc. In this paper, we propose a multi-view architecture framework that treats models as views of the underlying system structure and uses structural and semantic mappings to ensure consistency and enable system-level verification in a hierarchical and compositional manner. Throughout the paper, the theoretical concepts are illustrated using two examples: a quadrotor and an automotive intersection collision avoidance system.","Analytical models,
Semantics,
Computational modeling,
Unified modeling language,
Computer architecture,
Connectors,
Vehicles"
Understanding Collective Activitiesof People from Videos,"This paper presents a principled framework for analyzing collective activities at different levels of semantic granularity from videos. Our framework is capable of jointly tracking multiple individuals, recognizing activities performed by individuals in isolation (i.e., atomic activities such as walking or standing), recognizing the interactions between pairs of individuals (i.e., interaction activities) as well as understanding the activities of group of individuals (i.e., collective activities). A key property of our work is that it can coherently combine bottom-up information stemming from detections or fragments of tracks (or tracklets) with top-down evidence. Top-down evidence is provided by a newly proposed descriptor that captures the coherent behavior of groups of individuals in a spatial-temporal neighborhood of the sequence. Top-down evidence provides contextual information for establishing accurate associations between detections or tracklets across frames and, thus, for obtaining more robust tracking results. Bottom-up evidence percolates upwards so as to automatically infer collective activity labels. Experimental results on two challenging data sets demonstrate our theoretical claims and indicate that our model achieves enhances tracking results and the best collective classification results to date.","Target tracking,
Trajectory,
Videos,
Hidden Markov models,
Histograms,
Vectors,
Context"
A Barycentric Coordinate Based Distributed Localization Algorithm for Sensor Networks,"This paper studies the problem of determining the sensor locations in a large sensor network using only relative distance (range) measurements. Based on a generalized barycentric coordinate representation, our work generalizes the DILOC algorithm to the localization problem under arbitrary deployments of sensor nodes and anchor nodes. First, a criterion and algorithm are developed to determine a generalized barycentric coordinate of a node with respect to its neighboring nodes, which do not require the node to be inside the convex hull of its neighbors. Next, for the localization problem based on the generalized barycentric coordinate representation, a necessary and sufficient condition for the localizability of a sensor network with a generic configuration is obtained. Finally, a new linear iterative algorithm is proposed to ensure distributed implementation as well as global convergence to the true coordinates.","Signal processing algorithms,
Convergence,
Distance measurement,
Iterative methods,
Linear systems,
Coordinate measuring machines,
Educational institutions"
Robust Deformable and Occluded Object Tracking With Dynamic Graph,"While some efforts have been paid to handle deformation and occlusion in visual tracking, they are still great challenges. In this paper, a dynamic graph-based tracker (DGT) is proposed to address these two challenges in a unified framework. In the dynamic target graph, nodes are the target local parts encoding appearance information, and edges are the interactions between nodes encoding inner geometric structure information. This graph representation provides much more information for tracking in the presence of deformation and occlusion. The target tracking is then formulated as tracking this dynamic undirected graph, which is also a matching problem between the target graph and the candidate graph. The local parts within the candidate graph are separated from the background with Markov random field, and spectral clustering is used to solve the graph matching. The final target state is determined through a weighted voting procedure according to the reliability of part correspondence, and refined with recourse to a foreground/background segmentation. An effective online updating mechanism is proposed to update the model, allowing DGT to robustly adapt to variations of target structure. Experimental results show improved performance over several state-of-the-art trackers, in various challenging scenarios.","Target tracking,
Robustness,
Visualization,
Color,
Support vector machines"
Social learning and distributed hypothesis testing,"This paper considers a problem of distributed hypothesis testing and social learning. Individual nodes in a network receive noisy (private) observations whose distribution is parameterized by a discrete parameter (hypotheses). The distributions are known locally at the nodes, but the true parameter/hypothesis is not known. An update rule is analyzed in which agents first perform a Bayesian update of their belief (distribution estimate) of the parameter based on their local observation, communicate these updates to their neighbors, and then perform a “non-Bayesian” linear consensus using the log-beliefs of their neighbors. The main result of this paper is that under mild assumptions, the belief of any agent in any incorrect parameter converges to zero exponentially fast, and the exponential rate of learning is a characterized by the network structure and the divergences between the observations' distributions.","Convergence,
Bayes methods,
Information theory,
Testing,
Probability distribution,
Vectors,
Computers"
Saliency-Based Defect Detection in Industrial Images by Using Phase Spectrum,"For computer vision-based inspection of electronic chips or dies in semiconductor production lines, we propose a new method to effectively and efficiently detect defects in images. Different from the traditional methods that compare the image of each test chip or die with the template image one by one, which are sensitive to misalignment between the test and template images, a collection of multiple test images are used as the input image for processing simultaneously in our method with two steps. The first step is to obtain salient regions of the whole collection of test images, and the second step is to evaluate local discrepancy between salient regions in test images and the corresponding regions in the defect-free template image. To be more specific, in the first step of our method, phase-only Fourier transform (POFT), which is computationally efficient for online applications in industry, is used for saliency detection. We provide the theoretical justification for POFT to be effective to attenuate the normal regions and amplify the defects in multiple test images, which are usually arranged in a matrix format in industrial practice. By comparing with four other popular methods, the proposed algorithm can efficiently accommodate small variations (inevitable in practice) in test chips or dies, such as the spatial misalignments and product variations. Experimental results on a large-scale database including 1073 images, 94 of which are defective, show that our method performs much better than the other methods in terms of precision, recall, and F-measure.","Inspection,
Algorithm design and analysis,
Feature extraction,
Fourier transforms,
Computer vision"
Intelligent Channel Bonding in 802.11n WLANs,"The IEEE 802.11n standard defines channel bonding that allows wireless devices to operate on 40 MHz channels by doubling their bandwidth from standard 20 MHz channels. Increasing channel width increases capacity, but it comes at the cost of decreased transmission range and greater susceptibility to interference. However, with the incorporation of Multiple-Input Multiple-Output (MIMO) technology in 802.11n, devices can now exploit the increased transmission rates from wider channels with minimal sacrifice to signal quality and range. The goal of our work is to identify the network factors that influence the performance of channel bonding in 802.11n networks and make intelligent channel bonding decisions. We discover that channel width selection should consider not only a link's signal quality, but also the strength of neighboring links, their physical rates, and interferer load. We use our findings to design and implement a network detector that successfully identifies interference conditions that affect channel bonding decisions in 100% of our test cases. Our detector can form the foundation for more robust and accurate algorithms that can adapt bandwidth to variations in channel conditions. Our findings allows us to predict the impact of network conditions on performance and make channel bonding decisions that maximize throughput.","IEEE 802.11n Standard,
Channel estimation,
Wireless networks,
Wireless LAN"
Segmentation and Enhancement of Latent Fingerprints: A Coarse to Fine RidgeStructure Dictionary,"Latent fingerprint matching has played a critical role in identifying suspects and criminals. However, compared to rolled and plain fingerprint matching, latent identification accuracy is significantly lower due to complex background noise, poor ridge quality and overlapping structured noise in latent images. Accordingly, manual markup of various features (e.g., region of interest, singular points and minutiae) is typically necessary to extract reliable features from latents. To reduce this markup cost and to improve the consistency in feature markup, fully automatic and highly accurate (“lights-out” capability) latent matching algorithms are needed. In this paper, a dictionary-based approach is proposed for automatic latent segmentation and enhancement towards the goal of achieving “lights-out” latent identification systems. Given a latent fingerprint image, a total variation (TV) decomposition model with L1 fidelity regularization is used to remove piecewise-smooth background noise. The texture component image obtained from the decomposition of latent image is divided into overlapping patches. Ridge structure dictionary, which is learnt from a set of high quality ridge patches, is then used to restore ridge structure in these latent patches. The ridge quality of a patch, which is used for latent segmentation, is defined as the structural similarity between the patch and its reconstruction. Orientation and frequency fields, which are used for latent enhancement, are then extracted from the reconstructed patch. To balance robustness and accuracy, a coarse to fine strategy is proposed. Experimental results on two latent fingerprint databases (i.e., NIST SD27 and WVU DB) show that the proposed algorithm outperforms the state-of-the-art segmentation and enhancement algorithms and boosts the performance of a state-of-the-art commercial latent matcher.","Dictionaries,
Image segmentation,
NIST,
Feature extraction,
Frequency estimation,
Estimation,
Noise"
Detecting Movements of a Target Using Face Tracking in Wireless Sensor Networks,"Target tracking is one of the key applications of wireless sensor networks (WSNs). Existing work mostly requires organizing groups of sensor nodes with measurements of a target's movements or accurate distance measurements from the nodes to the target, and predicting those movements. These are, however, often difficult to accurately achieve in practice, especially in the case of unpredictable environments, sensor faults, etc. In this paper, we propose a new tracking framework, called FaceTrack, which employs the nodes of a spatial region surrounding a target, called a face. Instead of predicting the target location separately in a face, we estimate the target's moving toward another face. We introduce an edge detection algorithm to generate each face further in such a way that the nodes can prepare ahead of the target's moving, which greatly helps tracking the target in a timely fashion and recovering from special cases, e.g., sensor fault, loss of tracking. Also, we develop an optimal selection algorithm to select which sensors of faces to query and to forward the tracking data. Simulation results, compared with existing work, show that FaceTrack achieves better tracking accuracy and energy efficiency. We also validate its effectiveness via a proof-of-concept system of the Imote2 sensor platform.","Target tracking,
Wireless sensor networks,
Face,
Image edge detection,
Vehicles,
Accuracy"
VMThunder: Fast Provisioning of Large-Scale Virtual Machine Clusters,"Infrastructure as a service (IaaS) allows users to rent resources from the Cloud to meet their various computing requirements. The pay-as-you-use model, however, poses a nontrivial technical challenge to the IaaS cloud service providers: how to fast provision a large number of virtual machines (VMs) to meet users' dynamic computing requests? We address this challenge with VMThunder, a new VM provisioning tool, which downloads data blockson demandduring the VM booting process and speeds up VM image streaming by strategically integrating peer-to-peer (P2P) streaming techniques with enhanced optimization schemes such as transfer on demand, cache on read, snapshot on local, and relay on cache. In particular, VMThunder stores the original images in a share storage and in the meantime it adopts a tree-based P2P streaming scheme so that common image blocks are cached and reused across the nodes in the cluster. We implement VMThunder in CentOS Linux and thoroughly test its performance. Comprehensive experimental results show that VMThunder outperforms the state-of-the-art VM provisioning methods, with respect to scalability, latency, and VM runtime I/O performance.","Streaming media,
Peer-to-peer computing,
Servers,
Virtual machining,
Image storage,
Relays,
Clouds"
Finite-Time Consensus in Networks of Integrator-Like Dynamic Agents With Directional Link Failure,"This technical note proposes a general class of nonlinear protocols in the form of continuous state feedbacks for finite-time consensus in networks of integrator-like dynamic agents with directional link failure. These protocols, with adjustable terms, are applicable in a wide range of situations, such as with input saturation restrictions and with convergence rate constraints. Based on the assumption of a common positive dwell time for all active information links, it is shown that if the union of the interaction topology over some fixed length of time always contains a spanning tree, then the system will solve an asymptotical consensus problem; in addition, if the length sum of time intervals, over which the interaction topology contains a spanning tree, is larger than a threshold, determined by the state differences between agents, then the system will solve a finite-time consensus problem. The validity of the protocols is proven in the case with external reference inputs. Finally, simulations are presented to demonstrate the effectiveness of the theoretical results.","Protocols,
Topology,
Switches,
Network topology,
Nickel,
Convergence,
Vectors"
Voltage Stability and Control of Offshore Wind Farms With AC Collection and HVDC Transmission,"This paper investigates the stability and control of offshore wind farms employing medium-voltage ac collection and high-voltage dc (HVDC) transmission to the onshore power grids. Type-IV (full power conversion) turbines and HVDC rectifier based on voltage-source converters are assumed. Output impedance models of the wind turbines and input impedance models of the HVDC rectifier in the positive- and negative-sequence are developed using the harmonic linearization method. An impedance-based stability criterion is then applied to determine the stability of the offshore ac collection bus. Possible instability of the ac bus voltage and resonance between the wind farm and the HVDC rectifier are examined through analysis of the system impedance model. The analytical impedance models are used to identify the root causes of such instability and resonance problems, and to develop possible solutions. Detailed circuit simulation is used to validate the analysis. Individual converter impedance models are also validated by experimental measurements of scaled-down prototypes.","HVDC transmission,
Impedance,
Inverters,
Rectifiers,
Wind turbines,
Wind farms,
Voltage control"
Iris Image Classification Based on Hierarchical Visual Codebook,"Iris recognition as a reliable method for personal identification has been well-studied with the objective to assign the class label of each iris image to a unique subject. In contrast, iris image classification aims to classify an iris image to an application specific category, e.g., iris liveness detection (classification of genuine and fake iris images), race classification (e.g., classification of iris images of Asian and non-Asian subjects), coarse-to-fine iris identification (classification of all iris images in the central database into multiple categories). This paper proposes a general framework for iris image classification based on texture analysis. A novel texture pattern representation method called Hierarchical Visual Codebook (HVC) is proposed to encode the texture primitives of iris images. The proposed HVC method is an integration of two existing Bag-of-Words models, namely Vocabulary Tree (VT), and Locality-constrained Linear Coding (LLC). The HVC adopts a coarse-to-fine visual coding strategy and takes advantages of both VT and LLC for accurate and sparse representation of iris texture. Extensive experimental results demonstrate that the proposed iris image classification method achieves state-of-the-art performance for iris liveness detection, race classification, and coarse-to-fine iris identification. A comprehensive fake iris image database simulating four types of iris spoof attacks is developed as the benchmark for research of iris liveness detection.","Iris recognition,
Visualization,
Encoding,
Vocabulary,
Feature extraction,
Biomedical imaging,
Iris"
Preliminary walking experiments with underactuated 3D bipedal robot MARLO,"This paper reports on an underactuated 3D bipedal robot with passive feet that can start from a quiet standing position, initiate a walking gait, and traverse the length of the laboratory (approximately 10 m) at a speed of roughly 1 m/s. The controller was developed using the method of virtual constraints, a control design method first used on the planar point-feet robots Rabbit and MABEL. For the preliminary experiments reported here, virtual constraints were experimentally tuned to achieve robust planar walking and then 3D walking. A key feature of the controller leading to successful 3D walking is the particular choice of virtual constraints in the lateral plane, which implement a lateral balance control strategy similar to SIMBICON. To our knowledge, MARLO is the most highly underactuated bipedal robot to walk unassisted in 3D.","Legged locomotion,
Three-dimensional displays,
Hip,
Torso,
Knee,
Robot kinematics"
Bandwidth Enhancement of a Planar Printed Quasi-Yagi Antenna With Size Reduction,"A compact planar printed quasi-Yagi antenna is presented. The proposed antenna consists of a microstrip line to slotline transition structure, a driver dipole and two parasitic strips. The driver dipole is connected to the slotline through coplanar stripline (CPS). The ground plane is modified by symmetrically adding two extended stubs to reduce the lateral size. Experimental and simulated results show that the proposed quasi-Yagi antenna has a wide bandwidth and good unidirectional radiation characteristics. Compared with conventional printed quasi-Yagi antennas, the width of the proposed quasi-Yagi antenna is reduced by approximately 16.7%. The proposed antenna presents an excellent end-fire radiation with a front-to-back ratio greater than 10 dB. Its measured bandwidth is from 3.6-11.6 GHz with a ratio of about 3.22: 1. A moderate gain, which is better than 4 dBi, is obtained.","Antenna measurements,
Dipole antennas,
Bandwidth,
Microstrip antennas,
Broadband antennas,
Microstrip"
Predictive Monitoring of Mobile Patients by Combining Clinical Observations With Data From Wearable Sensors,"The majority of patients in the hospital are ambulatory and would benefit significantly from predictive and personalized monitoring systems. Such patients are well suited to having their physiological condition monitored using low-power, minimally intrusive wearable sensors. Despite data-collection systems now being manufactured commercially, allowing physiological data to be acquired from mobile patients, little work has been undertaken on the use of the resultant data in a principled manner for robust patient care, including predictive monitoring. Most current devices generate so many false-positive alerts that devices cannot be used for routine clinical practice. This paper explores principled machine learning approaches to interpreting large quantities of continuously acquired, multivariate physiological data, using wearable patient monitors, where the goal is to provide early warning of serious physiological determination, such that a degree of predictive care may be provided. We adopt a one-class support vector machine formulation, proposing a formulation for determining the free parameters of the model using partial area under the ROC curve, a method arising from the unique requirements of performing online analysis with data from patient-worn sensors. There are few clinical evaluations of machine learning techniques in the literature, so we present results from a study at the Oxford University Hospitals NHS Trust devised to investigate the large-scale clinical use of patient-worn sensors for predictive monitoring in a ward with a high incidence of patient mortality. We show that our system can combine routine manual observations made by clinical staff with the continuous data acquired from wearable sensors. Practical considerations and recommendations based on our experiences of this clinical study are discussed, in the context of a framework for personalized monitoring.","Biomedical monitoring,
Monitoring,
Support vector machines,
Manuals,
Kernel,
Wearable sensors,
Hospitals"
H-Infinity Stabilization for Singular Networked Cascade Control Systems With State Delay and Disturbance,"This paper is concerned with the stabilization and H∞ control problems for a class of singular networked cascade control systems with state delay and disturbance. Via the fact that single loop feedback control shows a shortcoming in that the plant output as nonzero disturbance acts on the systems, a new model of singular networked cascade control system is proposed. In this system, both the network-induced delay and data packed dropout phenomena are considered. Based on the model, sufficient conditions are derived in terms of linear matrix inequalities and the corresponding H∞ stabilizing controller design technique is also developed based on the above conditions. The proposed method emphasizes the implementation issue and employs the cascade control to singular networked control systems. A simulation example is given to illustrate the proposed design procedures and its applications.","Delays,
Delay effects,
Linear matrix inequalities,
Symmetric matrices,
Informatics,
Networked control systems"
Model-Based Iterative Reconstruction for Dual-Energy X-Ray CT Using a Joint Quadratic Likelihood Model,"Dual-energy X-ray CT (DECT) has the potential to improve contrast and reduce artifacts as compared to traditional CT. Moreover, by applying model-based iterative reconstruction (MBIR) to dual-energy data, one might also expect to reduce noise and improve resolution. However, the direct implementation of dual-energy MBIR requires the use of a nonlinear forward model, which increases both complexity and computation. Alternatively, simplified forward models have been used which treat the material-decomposed channels separately, but these approaches do not fully account for the statistical dependencies in the channels. In this paper, we present a method for joint dual-energy MBIR (JDE-MBIR), which simplifies the forward model while still accounting for the complete statistical dependency in the material-decomposed sinogram components. The JDE-MBIR approach works by using a quadratic approximation to the polychromatic log-likelihood and a simple but exact nonnegativity constraint in the image domain. We demonstrate that our method is particularly effective when the DECT system uses fast kVp switching, since in this case the model accounts for the inaccuracy of interpolated sinogram entries. Both phantom and clinical results show that the proposed model produces images that compare favorably in quality to previous decomposition-based methods, including FBP and other statistical iterative approaches.","Materials,
Image reconstruction,
Approximation methods,
Computational modeling,
Attenuation,
Noise,
Switches"
Combining LBP Difference and Feature Correlation for Texture Description,"Effective characterization of texture images requires exploiting multiple visual cues from the image appearance. The local binary pattern (LBP) and its variants achieve great success in texture description. However, because the LBP(-like) feature is an index of discrete patterns rather than a numerical feature, it is difficult to combine the LBP(-like) feature with other discriminative ones by a compact descriptor. To overcome the problem derived from the nonnumerical constraint of the LBP, this paper proposes a numerical variant accordingly, named the LBP difference (LBPD). The LBPD characterizes the extent to which one LBP varies from the average local structure of an image region of interest. It is simple, rotation invariant, and computationally efficient. To achieve enhanced performance, we combine the LBPD with other discriminative cues by a covariance matrix. The proposed descriptor, termed the covariance and LBPD descriptor (COV-LBPD), is able to capture the intrinsic correlation between the LBPD and other features in a compact manner. Experimental results show that the COV-LBPD achieves promising results on publicly available data sets.","Vectors,
Covariance matrices,
Correlation,
Hamming distance,
Feature extraction,
Histograms,
Euclidean distance"
Thermography-Based Virtual MPPT Scheme for Improving PV Energy Efficiency Under Partial Shading Conditions,"This paper proposes a new thermography-based maximum power point tracking (MPPT) scheme to address photovoltaic (PV) partial shading faults. Solar power generation utilizes a large number of PV cells connected in series and in parallel in an array, and that are physically distributed across a large field. When a PV module is faulted or partial shading occurs, the PV system sees a nonuniform distribution of generated electrical power and thermal profile, and the generation of multiple maximum power points (MPPs). If left untreated, this reduces the overall power generation and severe faults may propagate, resulting in damage to the system. In this paper, a thermal camera is employed for fault detection and a new MPPT scheme is developed to alter the operating point to match an optimized MPP. Extensive data mining is conducted on the images from the thermal camera in order to locate global MPPs. Based on this, a virtual MPPT is set out to find the global MPP. This can reduce MPPT time and be used to calculate the MPP reference voltage. Finally, the proposed methodology is experimentally implemented and validated by tests on a 600-W PV array.","Arrays,
Maximum power point trackers,
Photovoltaic systems,
Circuit faults,
Cameras"
Performance characteristics of virtual switching,"Virtual switches, like Open vSwitch, have emerged as an important part of cloud networking architectures. They connect interfaces of virtual machines and establish the connection to the outer network via physical network interface cards. Today, all important cloud frameworks support Open vSwitch as the default virtual switch. However, general understanding about the performance implications of Open vSwitch in different usage scenarios is missing. In this work we provide insights into the performance properties by systematically conducting measurements in virtual switching setups. We present quantitative and qualitative performance results of Open vSwitch in scenarios involving physical and virtual network interfaces.","Throughput,
Kernel,
Switches,
Linux,
Hardware,
Virtual machining"
The role of mobility for D2D communications in LTE-advanced networks: energy vs. bandwidth efficiency,"Energy efficiency and bandwidth efficiency are two paramount important performance metrics for device-to-device communications. In this work, we investigate how mobility impacts EE and BE in a general framework of an LTEAdvanced network. First, we deploy a simple but practical mobility model to capture the track of the mobile devices. In particular, unlike previous works focusing on mobility velocity, which is difficult to obtain in practical mobile D2D systems, we deploy the parameter of device density to describe the device mobility. Next, we investigate the relationship between EE and BE in a mobile environment, and propose an EE-BE-aware scheduling scheme with a dynamic relay selection strategy that is flexible enough for making the transmission decision, including relay selection, rate allocation, and routing. Subsequently, through rigorous theoretical analysis, we derive a precise EE-BE trade-off curve for any device density and achieve the condition to attain the optimal EE and BE simultaneously. Finally, numerical simulation results are provided to validate the efficiency of the proposed scheduling scheme and the correctness of our analysis.","Mobile communication,
Long Term Evolution,
Wireless communication,
Bandwidth,
Dynamic scheduling,
Routing,
Energy efficiency"
Finite-Length Scaling for Polar Codes,"Consider a binary-input memoryless output-symmetric channel W. Such a channel has a capacity, call it I(W), and for any R <; I(W) and strictly positive constant Pe we know that we can construct a coding scheme that allows transmission at rate R with an error probability not exceeding Pe. Assume now that we let the rate R tend to I(W) and we ask how we have to scale the blocklength N in order to keep the error probability fixed to Pe. We refer to this as the finite-length scaling behavior. This question was addressed by Strassen as well as Polyanskiy, Poor, and Verdu, and the result is that N must grow at least as the square of the reciprocal of I(W) - R. Polar codes are optimal in the sense that they achieve capacity. In this paper, we are asking to what degree they are also optimal in terms of their finite-length behavior. Since the exact scaling behavior depends on the choice of the channel, our objective is to provide scaling laws that hold universally for all binary-input memoryless output-symmetric channels. Our approach is based on analyzing the dynamics of the un-polarized channels. More precisely, we provide bounds on (the exponent of) the number of subchannels whose Bhattacharyya constant falls in a fixed interval [a, b]. Mathematically, this can be stated as bounding the sequence {1/n logPr(Zn ∈ [a, b])}n∈N, where Zn is the Bhattacharyya process. We then use these bounds to derive tradeoffs between the rate and the block-length. The main results of this paper can be summarized as follows. Consider the sum of Bhattacharyya parameters of subchannels chosen (by the polar coding scheme) to transmit information. If we require this sum to be smaller than a given value Pe > 0, then the required block-length N scales in terms of the rate R <; I(W) as N ≥ α/(I(W) - R)μ, where α is a positive constant that depends on Pe and I(W). We show that μ = 3.579 is a valid choice, and we conjecture that indeed the value of μ can be improved to μ = 3.627, the parameter for the binary erasure channel. Also, we show that with the same requirement on the sum of Bhattacharyya parameters, the blocklength scales in terms of the rate like N ≤ β/(I(W) - R)μ̅, where β is a constant that depends on Pe and I(W), and μ̅ = 6.",
Mining Building Energy Management System Data Using Fuzzy Anomaly Detection and Linguistic Descriptions,"Building Energy Management Systems (BEMSs) are essential components of modern buildings that are responsible for minimizing energy consumption while maintaining occupant comfort. However, since indoor environment is dependent on many uncertain criteria, performance of BEMS can be suboptimal at times. Unfortunately, complexity of BEMSs, large amount of data, and interrelations between data can make identifying these suboptimal behaviors difficult. This paper proposes a novel Fuzzy Anomaly Detection and Linguistic Description (Fuzzy-ADLD)-based method for improving the understandability of BEMS behavior for improved state-awareness. The presented method is composed of two main parts: 1) detection of anomalous BEMS behavior; and 2) linguistic representation of BEMS behavior. The first part utilizes modified nearest neighbor clustering algorithm and fuzzy logic rule extraction technique to build a model of normal BEMS behavior. The second part of the presented method computes the most relevant linguistic description of the identified anomalies. The presented Fuzzy-ADLD method was applied to real-world BEMS system and compared against a traditional alarm-based BEMS. Six different scenarios were tested, and the presented Fuzzy-ADLD method identified anomalous behavior either as fast as or faster (an hour or more) than the alarm based BEMS. Furthermore, the Fuzzy-ADLD method identified cases that were missed by the alarm-based system, thus demonstrating potential for increased state-awareness of abnormal building behavior.","Pragmatics,
Clustering algorithms,
Temperature sensors,
Temperature measurement,
Floors"
Distributed Frequency Control in Smart Grids via Randomized Demand Response,"Frequency control is essential to maintain the stability and reliability of power grids. For decades, generation side controllers, e.g., governors and automatic generation controllers, have been used to stabilize the frequency of power systems, which incur high operational costs. In smart grids, utilizing demand response is an appealing alternative to control the system frequency at the demand side, which can reduce the dependency of grids on expensive generation side controllers. Despite of economic advantages, the frequency oscillation problem, which occurs when smart appliances simultaneously respond to the system frequency by varying their power consumptions, is the main barrier to realize demand response enabled frequency control in practice. In this paper, we investigate a new distributed control algorithm by randomizing smart appliances' responses to solve this problem. We provide a comprehensive analysis to characterize various impacts of the randomized demand response on the system frequency in terms of its mean and variance over time. Furthermore, based on the frequency dynamics analysis, we determine the average frequency recovery time, the average number of responded smart appliances, and the probability of frequency overshoot, which provide important guidelines for designing our control algorithm. Finally, we validate our analysis via simulations under practical setups.","Home appliances,
Frequency control,
Time-frequency analysis,
Power demand,
Load management"
SPICE Modeling of Double-Gate Tunnel-FETs Including Channel Transports,"SPICE modeling of double-gate (DG) tunnel FETs (TFETs) including channel transports is reported. An ideal drain current model neglecting the channel transport is developed first. It captures the interband tunneling characteristics, describes their geometry dependences, and is suitable for DG TFETs with limited drivability. The ideal current model and previously proposed charge model are then extended to include the channel transports. One way to model the transport is appending a DG MOSFET in series with the ideal TFET model. The dependences of TFETs current and terminal charges on channel transports are reproduced. Another way by inserting a resistance at the TFET source side is also proposed with reduced simulation time.",
Curve Boxplot: Generalization of Boxplot for Ensembles of Curves,"In simulation science, computational scientists often study the behavior of their simulations by repeated solutions with variations in parameters and/or boundary values or initial conditions. Through such simulation ensembles, one can try to understand or quantify the variability or uncertainty in a solution as a function of the various inputs or model assumptions. In response to a growing interest in simulation ensembles, the visualization community has developed a suite of methods for allowing users to observe and understand the properties of these ensembles in an efficient and effective manner. An important aspect of visualizing simulations is the analysis of derived features, often represented as points, surfaces, or curves. In this paper, we present a novel, nonparametric method for summarizing ensembles of 2D and 3D curves. We propose an extension of a method from descriptive statistics, data depth, to curves. We also demonstrate a set of rendering and visualization strategies for showing rank statistics of an ensemble of curves, which is a generalization of traditional whisker plots or boxplots to multidimensional curves. Results are presented for applications in neuroimaging, hurricane forecasting and fluid dynamics.","Data visualization,
Curve fitting,
Statistical analysis,
Robustness,
Shape analysis,
Computational modeling"
A DFA-Based Functional Proxy Re-Encryption Scheme for Secure Public Cloud Data Sharing,"In this paper, for the first time, we define a general notion for proxy re-encryption (PRE), which we call deterministic finite automata-based functional PRE (DFA-based FPRE). Meanwhile, we propose the first and concrete DFA-based FPRE system, which adapts to our new notion. In our scheme, a message is encrypted in a ciphertext associated with an arbitrary length index string, and a decryptor is legitimate if and only if a DFA associated with his/her secret key accepts the string. Furthermore, the above encryption is allowed to be transformed to another ciphertext associated with a new string by a semitrusted proxy to whom a re-encryption key is given. Nevertheless, the proxy cannot gain access to the underlying plaintext. This new primitive can increase the flexibility of users to delegate their decryption rights to others. We also prove it as fully chosen-ciphertext secure in the standard model.","Encryption,
Standards,
Electronic mail,
Adaptation models,
Indexes"
Optimal Control of Markov Decision Processes With Linear Temporal Logic Constraints,"In this paper, we develop a method to automatically generate a control policy for a dynamical system modeled as a Markov Decision Process (MDP). The control specification is given as a Linear Temporal Logic (LTL) formula over a set of propositions defined on the states of the MDP. Motivated by robotic applications requiring persistent tasks, such as environmental monitoring and data gathering, we synthesize a control policy that minimizes the expected cost between satisfying instances of a particular proposition over all policies that maximize the probability of satisfying the given LTL specification. Our approach is based on the definition of a novel optimization problem that extends the existing average cost per stage problem. We propose a sufficient condition for a policy to be optimal, and develop a dynamic programming algorithm that synthesizes a policy that is optimal for a set of LTL specifications.","Markov processes,
Vectors,
Probabilistic logic,
Equations,
Transient analysis,
Optimal control,
Process control"
Compact Hyper-Band Printed Slot Antenna With Stable Radiation Properties,"A compact hyper-band ( >10:1 impedance bandwidth) printed antenna design is investigated numerically and experimentally. It is based on an elliptical-slot antenna augmented with a parasitic oval patch and driven with a specially engineered microstrip-line-fed elliptical tuning fork element. The parasitic and driven elements are adjusted along with the elliptical slot to create additional resonance modes; adjust the coupling strengths among all of the design components; facilitate the overlap of adjacent resonance modes; and fine tune the input impedance. The total size of the final optimized antenna is only 30 ×40 mm2. It exhibits a -10-dB impedance bandwidth from 2.26 to 22.18 GHz. Desirable radiation performance characteristics, including relatively stable and omni-directional radiation patterns, are obtained over this range. A prototype was fabricated and tested. The experimental results confirm the predicted input impedance bandwidth and radiation characteristics. While the hyper-band performance could be used for high fidelity short pulse applications, the antenna could also be used for multi-band operations from 3.1-10.6 GHz since it covers that entire ultra-wideband (UWB) spectral range.","Bandwidth,
Antenna measurements,
Slot antennas,
Impedance,
Resonant frequency,
Ultra wideband antennas"
Learning about Social Learning in MOOCs: From Statistical Analysis to Generative Model,"We study user behavior in the courses offered by a major massive online open course (MOOC) provider during the summer of 2013. Since social learning is a key element of scalable education on MOOC and is done via online discussion forums, our main focus is on understanding forum activities. Two salient features of these activities drive our research: (1) high decline rate: for each course studied, the volume of discussion declined continuously throughout the duration of the course; (2) high-volume, noisy discussions: at least 30 percent of the courses produced new threads at rates that are infeasible for students or teaching staff to read through. Further, a substantial portion of these discussions are not directly course-related. In our analysis, we investigate factors that are associated with the decline of activity on MOOC forums, and we find effective strategies to classify threads and rank their relevance. Specifically, we first use linear regression models to analyze the forum activity count data over time, and make a number of observations; for instance, the teaching staff's active participation in the discussions is correlated with an increase in the discussion volume but does not slow down the decline rate. We then propose a unified generative model for the discussion threads, which allows us both to choose efficient thread classifiers and to design an effective algorithm for ranking thread relevance. Further, our algorithm is compared against two baselines using human evaluation from Amazon Mechanical Turk.","Message systems,
Algorithm design and analysis,
Statistical analysis,
Analytical models"
Predicting Vulnerable Software Components via Text Mining,"This paper presents an approach based on machine learning to predict which components of a software application contain security vulnerabilities. The approach is based on text mining the source code of the components. Namely, each component is characterized as a series of terms contained in its source code, with the associated frequencies. These features are used to forecast whether each component is likely to contain vulnerabilities. In an exploratory validation with 20 Android applications, we discovered that a dependable prediction model can be built. Such model could be useful to prioritize the validation activities, e.g., to identify the components needing special scrutiny.","Software,
Predictive models,
Measurement,
Security,
Androids,
Humanoid robots,
Text mining"
High-Gain and Broadband Transmitarray Antenna Using Triple-Layer Spiral Dipole Elements,"A triple-layer transmitarray antenna has been designed, fabricated, and tested at X-band. Using a spiral-dipole element, a full transmission phase range of 360 ° is achieved for a transmission magnitude equal to or better than -4.2 dB. The transmission phase distribution of the transmitarray elements has been optimized to reduce the effects of the lossy elements with low transmission magnitudes on the antenna gain, leading to an average element loss as low as 0.49 dB. The measured gain of the transmitarray prototype is 28.9 dB at 11.3 GHz, resulting in a 30% aperture efficiency. Antenna bandwidths of 9% for 1-dB gain and 19.4% for 3-dB gain are achieved in this design.","Transmitting antennas,
Gain,
Apertures,
Antenna measurements,
Feeds,
Broadband antennas,
Dipole antennas"
Improving the Performance of a Line Regulating Converter in a Converter-Dominated DC Microgrid System,"This paper describes the controller design procedure for a line-regulating converter in a converter-dominated dc microgrid system. The purpose of the controller is to mitigate the effects of the constant power loads on the stability and performance of the dc microgrid system. In this work, first, the overall structure, operation, and building blocks of the dc microgrid under analysis are introduced. Next, the dynamic model of the dc microgrid and the required transfer functions for the controller design are derived. Then, two proposed controller design methods are introduced and implemented on an virtual line-regulating converter in a dc microgrid system. Finally, the controller design methods are verified experimentally using the results from a built prototype dc microgrid system.","Microgrids,
Stability analysis,
Voltage control,
Impedance,
Power system stability,
Load modeling,
Transfer functions"
Stray Inductance Reduction of Commutation Loop in the P-cell and N-cell-Based IGBT Phase Leg Module,"This paper proposes a novel packaging method for insulated-gate bipolar transistor (IGBT) modules based on the concepts of P-cell and N-cell. The novel packaging reduces the stray inductance in the current commutation path in a phase-leg module and hence improves the switching behavior. A P-cell- and N-cell-based module and a conventional module are designed. Using finite-element-analysis-based Ansys Q3D Extractor, electromagnetic simulations are conducted to extract the stray inductance from the two modules. Two prototype phase-leg modules based on the two different designs are fabricated. The parasitics are measured using a precision impedance analyzer. Finally, a double pulse tester based-switching characterization is performed to illustrate the effect of stray inductance reduction in the proposed packaging design. The experimental results show the reduction in overshoot voltage with the proposed layout.","Inductance,
Insulated gate bipolar transistors,
Wires,
Multichip modules,
Switches,
Layout,
Inductance measurement"
A Feedback Controlled MEMS Nanopositioner for On-Chip High-Speed AFM,"We report the design of a two-degree-of-freedom microelectromechanical systems nanopositioner for on-chip atomic force microscopy (AFM). The device is fabricated using a silicon-on-insulator-based process to function as the scanning stage of a miniaturized AFM. It is a highly resonant system with its lateral resonance frequency at ~850 Hz. The incorporated electrostatic actuators achieve a travel range of 16 μm in each direction. Lateral displacements of the scan table are measured using a pair of electrothermal position sensors. These sensors are used, together with a positive position feedback controller, in a feedback loop, to damp the highly resonant dynamics of the stage. The feedback controlled nanopositioner is used, successfully, to generate high-quality AFM images at scan rates as fast as 100 Hz.","Nanopositioning,
Micromechanical devices,
Sensor phenomena and characterization,
Sensitivity,
Displacement measurement,
Bridge circuits"
Compact Dual-Band WLAN Diversity Antennas on USB Dongle Platform,"An antenna system comprising two closely spaced chip antennas is proposed for dual-band wireless LAN uses. The distance between two chips is 12 mm and the spacing between antenna feeds is 1 mm only. Yet, superior isolation performance is achieved in both operation bands. A novel isolation enhancing measure is implemented for the higher 5 GHz band, which is done by adding a pair of open-ended stubs next to antenna feeds. The stub pair functions as an all-stop filter and elevates the port isolation. Rigorous simulation works were conducted to associate antenna geometry with performance features. Results such as impedance matching, isolation, and radiation patterns were examined jointly to identify mechanisms of its decoupling and diversity features. Antenna diversity assessment measures including the envelope correlation coefficient and the effective diversity gain were derived. Results demonstrate that the proposed compact two-antenna configuration suits well to the diversity antenna need on portable devices.","Antenna radiation patterns,
Dual band,
Wireless LAN,
Antenna feeds,
Antenna measurements"
Reduced DC voltage source flying capacitor multicell multilevel inverter: analysis and implementation,"Voltage source multicell multilevel converters (VSMMCs) have been extensively exploited in medium-voltage highpower fed industrial applications. One of the typical breeds of the VSMMCs is flying-capacitor multicell converter (FCMC). This study presents an improved configuration for FCMCs, accompanied by its analysis, modelling and implementation. The main advantage of the proposed converter, in comparison with the conventional one, is that the number and voltage rating of the required dc voltage sources are halved in the improved topology which results in reducing the cost, size, installation area and weight of the FCMCs effectively. This amelioration is attained by adding four power switches to the conventional topology of an FCMC without making any amendments to the number and voltage rating of high-frequency power-switches and flying capacitors (FCs). The proposed switching and control methodology for the adopted FCMC is based on the phase-shifted carrier pulse width modulation technique with applying some amendments; therefore the natural balancing phenomenon of the FC voltages, one of the critical advantages of the FCMCs, is preserved in the proposed VSMMC. Experimental measurements taken from the 3-cell-four-level and 4-cell-five-level laboratory prototype systems of the proposed converter are presented in order to validate and corroborate the effectiveness and advantages of the proposed topology, its switching and suggested control strategy. Furthermore, experimental studies are accomplished on an 8-cell-nine-level prototype system of the proposed FCMC to peruse its feasibility and viability for higher number of cells and voltage levels. In addition, comparison of the proposed converter with the other types of multilevel converters is carried out to underline the advantages of the proposed structure profoundly.",
Dynamic Multiservice Load Balancing in Cloud-Based Multimedia System,"Consider a centralized hierarchical cloud-based multimedia system (CMS) consisting of a resource manager, cluster heads, and server clusters, in which the resource manager assigns clients' requests for multimedia service tasks to server clusters according to the task characteristics, and then each cluster head distributes the assigned task to the servers within its server cluster. For such a complicated CMS, however, it is a research challenge to design an effective load balancing algorithm that spreads the multimedia service task load on servers with the minimal cost for transmitting multimedia data between server clusters and clients, while the maximal load limit of each server cluster is not violated. Unlike previous work, this paper takes into account a more practical dynamic multiservice scenario in which each server cluster only handles a specific type of multimedia task, and each client requests a different type of multimedia service at a different time. Such a scenario can be modelled as an integer linear programming problem, which is computationally intractable in general. As a consequence, this paper further solves the problem by an efficient genetic algorithm with an immigrant scheme, which has been shown to be suitable for dynamic problems. Simulation results demonstrate that the proposed genetic algorithm can efficiently cope with dynamic multiservice load balancing in CMS.",
A Planar Magnetically Coupled Resonant Wireless Power Transfer System Using Printed Spiral Coils,"A fully planar wireless power transfer (WPT) system via strongly coupled magnetic resonances is presented. In it, both the transmitter and the receiver are planarized with the use of coplanar printed spiral coils (PSCs) and a printed loop. An equivalent circuit model of the proposed planar WPT system is derived to facilitate the design, and a flowchart is provided for the optimization of the system with given size constraints. To realize high peak power transfer efficiency, the quality factor of individual loop or resonator, the mutual coupling between resonators, and the frequency splitting phenomenon of the system are analyzed in addition to the effect of the input impedance of the system on the transmission efficiency. Furthermore, parallel current paths are created by applying auxiliary strips to the backside of the substrates and connecting to the prime resonators using vias to decrease the resistance and to increase the quality factor of the PSC resonators, and this in turn further improves the transfer efficiency of the proposed planar WPT system. The measured results show that the proposed WPT system is able to provide a stable wireless power transfer with up to 81.68% efficiency at a distance of 10 cm. The planar structure and the high transfer efficiency make the proposed design a suitable candidate for wireless power transfer of small portable electronic devices.","Coils,
Wireless communication,
Spirals,
Q-factor,
Magnetic resonance,
Strips,
Substrates"
Offline Text-Independent Writer Identification Based on Scale Invariant Feature Transform,"This paper proposes a novel offline text-independent writer identification method based on scale invariant feature transform (SIFT), composed of training, enrollment, and identification stages. In all stages, an isotropic LoG filter is first used to segment the handwriting image into word regions (WRs). Then, the SIFT descriptors (SDs) of WRs and the corresponding scales and orientations (SOs) are extracted. In the training stage, an SD codebook is constructed by clustering the SDs of training samples. In the enrollment stage, the SDs of the input handwriting are adopted to form an SD signature (SDS) by looking up the SD codebook and the SOs are utilized to generate a scale and orientation histogram (SOH). In the identification stage, the SDS and SOH of the input handwriting are extracted and matched with the enrolled ones for identification. Experimental results on six public data sets (including three English data sets, one Chinese data set, and two hybrid-language data sets) demonstrate that the proposed method outperforms the state-of-the-art algorithms.","Feature extraction,
Image segmentation,
Indexes,
Training,
Vectors,
Histograms,
Transforms"
Multifrequency Electrical Impedance Tomography Using Spectral Constraints,"Multifrequency electrical impedance tomography (MFEIT) exploits the dependence of tissue impedance on frequency to recover an image of conductivity. MFEIT could provide emergency diagnosis of pathologies such as acute stroke, brain injury and breast cancer. We present a method for performing MFEIT using spectral constraints. Boundary voltage data is employed directly to reconstruct the volume fraction distribution of component tissues using a nonlinear method. Given that the reconstructed parameter is frequency independent, this approach allows for the simultaneous use of all multifrequency data, thus reducing the degrees of freedom of the reconstruction problem. Furthermore, this method allows for the use of frequency difference data in a nonlinear reconstruction algorithm. Results from empirical phantom measurements suggest that our fraction reconstruction method points to a new direction for the development of multifrequency EIT algorithms in the case that the spectral constraints are known, and may provide a unifying framework for static EIT imaging.","Conductivity,
Image reconstruction,
Frequency measurement,
Tomography,
Impedance,
Voltage measurement"
Multitouch Gesture-Based Authentication,"This paper investigates multitouch gestures for user authentication on touch sensitive devices. A canonical set of 22 multitouch gestures was defined using characteristics of hand and finger movement. Then, a multitouch gesture matching algorithm robust to orientation and translation was developed. Two different studies were performed to evaluate the concept. First, a single session experiment was performed in order to explore feasibility of multitouch gestures for user authentication. Testing on the canonical set showed that the system could achieve good performance in terms of distinguishing between gestures performed by different users. In addition, the tests demonstrated a desirable alignment of usability and security as gestures that were more secure from a biometric point of view were rated as more desirable in terms of ease, pleasure, and excitement. Second, a study involving a three-session experiment was performed. Results indicate that biometric information gleaned from a short user-device interaction remains consistent across gaps of several days, though there is noticeable degradation of performance when the authentication is performed over multiple sessions. In addition, the study showed that user-defined gestures yield the highest recognition rate among all other gestures, whereas the use of multiple gestures in a sequence aids in boosting verification accuracy. In terms of memorability, the study showed that it is feasible for a user to recall user-defined gestural passwords and it is observed that the recall rate increases over time. It is also noticed that performing a user-defined gesture over a customized background image does result in higher verification performance. In terms of usability, the study shows that users did not have difficulty in performing multitouch gestures as they all rated each gesture as easy to perform.","Authentication,
Thumb,
Usability,
Performance evaluation,
Accuracy,
Taxonomy"
Robust Trajectory Estimation for Crowdsourcing-Based Mobile Applications,"Crowdsourcing-based mobile applications are becoming more and more prevalent in recent years, as smartphones equipped with various built-in sensors are proliferating rapidly. The large quantity of crowdsourced sensing data stimulates researchers to accomplish some tasks that used to be costly or impossible, yet the quality of the crowdsourced data, which is of great importance, has not received sufficient attention. In reality, the low-quality crowdsourced data are prone to containing outliers that may severely impair the crowdsourcing applications. Thus in this work, we conduct pioneer investigation considering crowdsourced data quality. Specifically, we focus on estimating user motion trajectory information, which plays an essential role in multiple crowdsourcing applications, such as indoor localization, context recognition, indoor navigation, etc. We resort to the family of robust statistics and design a robust trajectory estimation scheme, name TrMCD, which is capable of alleviating the negative influence of abnormal crowdsourced user trajectories, differentiating normal users from abnormal users, and overcoming the challenge brought by spatial unbalance of crowdsourced trajectories. Two real field experiments are conducted and the results show that TrMCD is robust and effective in estimating user motion trajectories and mapping fingerprints to physical locations.","Trajectory,
Robustness,
Estimation,
Sensors,
Mobile communication,
Calibration,
Context"
A Hyper-Heuristic Scheduling Algorithm for Cloud,"Rule-based scheduling algorithms have been widely used on many cloud computing systems because they are simple and easy to implement. However, there is plenty of room to improve the performance of these algorithms, especially by using heuristic scheduling. As such, this paper presents a novel heuristic scheduling algorithm, called hyper-heuristic scheduling algorithm (HHSA), to find better scheduling solutions for cloud computing systems. The diversity detection and improvement detection operators are employed by the proposed algorithm to dynamically determine which low-level heuristic is to be used in finding better candidate solutions. To evaluate the performance of the proposed method, this study compares the proposed method with several state-of-the-art scheduling algorithms, by having all of them implemented on CloudSim (a simulator) and Hadoop (a real system). The results show that HHSA can significantly reduce the makespan of task scheduling compared with the other scheduling algorithms evaluated in this paper, on both CloudSim and Hadoop.","Heuristic algorithms,
Pricing,
Scheduling algorithms,
Cloud computing,
Time complexity"
Scalable Dynamic Routing Protocol for Cognitive Radio Sensor Networks,"Wireless sensor networks (WSNs) have been increasingly considered an attractive solution for a plethora of applications. The low cost of sensor nodes provides a mean to deploy large sensor arrays in a variety of applications, such as civilian and environmental monitoring. Most of the WSNs operate in unlicensed spectrum bands, which have become overcrowded. As the number of the nodes that join the network increases, the need for energy-efficient, resource-constrained, and spectrum-efficient protocol also increases. Incorporating cognitive radio capability in sensor networks yields a promising networking paradigm, also known as cognitive radio sensor networks. In this paper, a cognitive networking with opportunistic routing protocol for WSNs is introduced. The objective of the proposed protocol is to improve the network performance after increasing network scalability. The performance of the proposed protocol is evaluated through simulations. An accurate channel model is built to evaluate the signal strength in different areas of a complex indoor environment. Then, a discrete event simulator is applied to examine the performance of the proposed protocol in comparison with two other routing protocols. Simulation results show that when comparing with other common routing protocols, the proposed protocol performs better with respect to throughput, packet delay, and total energy consumption.","Sensors,
Wireless sensor networks,
Routing,
Transmitters,
Routing protocols,
Channel models"
Cooperative Tracking Control of Nonlinear Multiagent Systems Using Self-Structuring Neural Networks,"This paper considers a cooperative tracking problem for a group of nonlinear multiagent systems under a directed graph that characterizes the interaction between the leader and the followers. All the networked systems can have different dynamics and all the dynamics are unknown. A neural network (NN) with flexible structure is used to approximate the unknown dynamics at each node. Considering that the leader is a neighbor of only a subset of the followers and the followers have only local interactions, we introduce a cooperative dynamic observer at each node to overcome the deficiency of the traditional tracking control strategies. An observer-based cooperative controller design framework is proposed with the aid of graph tools, Lyapunov-based design method, self-structuring NN, and separation principle. It is proved that each agent can follow the active leader only if the communication graph contains a spanning tree. Simulation results on networked robots are provided to show the effectiveness of the proposed control algorithms.","Artificial neural networks,
Multi-agent systems,
Neurons,
Observers,
Topology,
Synchronization,
Network topology"
Power-Aware Activity Monitoring Using Distributed Wearable Sensors,"Monitoring human movements using wireless wearable sensors finds applications in a variety of domains including healthcare and wellness. In these systems, sensory devices are tightly integrated with the human body and infer status of the user through signal and information processing. Typically, highly accurate observations can be made at the cost of deploying a sufficiently large number of sensors, which in turn results in increased energy consumption of the system and reduced adherence to using the system. Therefore, optimizing power consumption of the system while maintaining acceptable accuracy plays a crucial role in realizing these stringent resource constraint systems. In this paper, we present an activity monitoring approach that minimizes power consumption of the system subject to a lower bound on the classification accuracy. The system utilizes computationally simple template-matching blocks that perform classifications on individual sensor nodes. The system further employs a boosting approach to enhance accuracy of the distributed classifier by selecting a subset of sensors optimized in terms of power consumption and capable of achieving a given lower bound accuracy criterion. A proof-of-concept evaluation with three participants performing 14 transitional actions was conducted, where collected signals were segmented and labeled manually for each action. The results indicated that the proposed approach provides more than a 65% reduction in the power consumption of the signal processing, while maintaining 80% sensitivity in classifying human movements.",
FPGA-RPI: A Novel FPGA Architecture With RRAM-Based Programmable Interconnects,"In this paper we introduce a novel field programmable gate array (FPGA) architecture with resistive random access memory (RRAM)-based programmable interconnects (FPGA-RPI). Programmable interconnects are the dominant part of FPGA. We use RRAMs to build programmable interconnects, and optimize their structures by exploiting opportunities that emerge in RRAM-based circuits. FPGA-RPI can be fabricated by the existing CMOS-compatible RRAM process. Using an advanced placement and routing tool named VPR-RPI which was developed to deal with the novel architecture, a customized CAD flow is provided for FPGA-RPI. Results show that the programmable interconnects of FPGA-RR have a 96% smaller footprint, 55% higher performance, and 79% lower power consumptions compared to other FPGA counterparts.","CMOS memory circuits,
field programmable gate arrays,
integrated circuit interconnections,
network routing,
random-access storage"
A Performance Modeling and Optimization Analysis Tool for Sparse Matrix-Vector Multiplication on GPUs,"This paper presents a performance modeling and optimization analysis tool to predict and optimize the performance of sparse matrix-vector multiplication (SpMV) on GPUs. We make the following contributions: 1) We present an integrated analytical and profile-based performance modeling to accurately predict the kernel execution times of CSR, ELL, COO, and HYB SpMV kernels. Our proposed approach is general, and neither limited by GPU programming languages nor restricted to specific GPU architectures. In this paper, we use CUDA-based SpMV kernels and NVIDIA Tesla C2050 for our performance modeling and experiments. According to our experiments, for 77 out of 82 test cases, the performance differences between the predicted and measured execution times are less than 9 percent; for the rest five test cases, the differences are between 9 and 10 percent. For CSR, ELL, COO, and HYB SpMV CUDA kernels, the average differences are 6.3, 4.4, 2.2, and 4.7 percent, respectively. 2) Based on the performance modeling, we design a dynamic-programming based SpMV optimal solution auto-selection algorithm to automatically report an optimal solution (i.e., optimal storage strategy, storage format(s), and execution time) for a target sparse matrix. In our experiments, the average performance improvements of the optimal solutions are 41.1, 49.8, and 37.9 percent, compared to NVIDIA's CSR, COO, and HYB CUDA kernels, respectively.","Benchmark testing,
Kernel,
Strips,
Graphics processing units,
Computational modeling,
Sparse matrices,
Analytical models"
Multi-Material Decomposition Using Statistical Image Reconstruction for Spectral CT,"Spectral computed tomography (CT) provides information on material characterization and quantification because of its ability to separate different basis materials. Dual-energy (DE) CT provides two sets of measurements at two different source energies. In principle, two materials can be accurately decomposed from DECT measurements. However, many clinical and industrial applications require three or more material images. For triple-material decomposition, a third constraint, such as volume conservation, mass conservation or both, is required to solve three sets of unknowns from two sets of measurements. The recently proposed flexible image-domain (ID) multi-material decomposition) method assumes each pixel contains at most three materials out of several possible materials and decomposes a mixture pixel by pixel. We propose a penalized-likelihood (PL) method with edge-preserving regularizers for each material to reconstruct multi-material images using a similar constraint from sinogram data. We develop an optimization transfer method with a series of pixel-wise separable quadratic surrogate (PWSQS) functions to monotonically decrease the complicated PL cost function. The PWSQS algorithm separates pixels to allow simultaneous update of all pixels, but keeps the basis materials coupled to allow faster convergence rate than our previous proposed material- and pixel-wise SQS algorithms. Comparing with the ID method using 2-D fan-beam simulations, the PL method greatly reduced noise, streak and cross-talk artifacts in the reconstructed basis component images, and achieved much smaller root mean square errors.","Materials,
Computed tomography,
Image reconstruction,
Cost function,
Attenuation,
Vectors"
Monitoring of GMAW Weld Pool From the Reflected Laser Lines for Real-Time Control,"Controlling the welding process by monitoring the weld pool surface becomes more and more popular in robotic arc welding. In this paper, we propose a monitoring system to infer the P-gas metal arc welding (GMAW) weld pool geometry from the reflected laser lines, which are projected onto the specular weld pool and reflected onto a diffusive plane. The parallel straight lines are distorted according to the shape of the weld pool and thus contain the weld pool's shape information. Accurately computing the equations of the imaged laser lines in the world coordinate system is critical for the subsequent weld pool shape estimation. This paper focuses on accurately segmenting and identifying the reflected laser lines and novel image processing algorithms are proposed to fulfill this specific task. Experimental results verified the effectiveness of the proposed algorithms.",
Integrating Electrical Energy Storage Into Coordinated Voltage Control Schemes for Distribution Networks,"In this paper, a coordinated voltage control scheme utilizing electrical energy storage (EES) is presented, for future distribution networks with large, clustered distributions of low carbon technologies (LCTs) in terms of both feeder and phase location. The benefits of the EES integrated scheme over conventional voltage control schemes are demonstrated by realizing a set of network scenarios on a case study network both in simulation and in network in the loop (NIL) emulation at a smart grid laboratory facility. The case study uses a rigorously validated model of an actual GB distribution network with multiple EES installations. It was found that the EES integrated voltage control scheme is able to provide increased capability over conventional voltage control schemes and increase the value of EES to network operation.",
Real and Complex Monotone Communication Games,"Noncooperative game-theoretic tools have been increasingly used to study many important resource allocation problems in communications, networking, smart grids, and portfolio optimization. In this paper, we consider a general class of convex Nash equilibrium problems (NEPs), where each player aims at solving an arbitrary smooth convex optimization problem. Differently from most of current works, we do not assume any specific structure for the players' problems, and we allow the optimization variables of the players to be matrices in the complex domain. Our main contribution is the design of a novel class of distributed (asynchronous) best-response-algorithms suitable for solving the proposed NEPs, even in the presence of multiple solutions. The new methods, whose convergence analysis is based on variational inequality (VI) techniques, can select, among all the equilibria of a game, those that optimize a given performance criterion, at the cost of limited signaling among the players. This is a major departure from existing best-response algorithms, whose convergence conditions imply the uniqueness of the NE. Some of our results hinge on the use of VI problems directly in the complex domain; the study of these new kind of VIs also represents a noteworthy innovative contribution. We then apply the developed methods to solve some new generalizations of Single Input Single Output (SISO) and Multiple Input Multiple Output (MIMO) games in cognitive radio systems, showing a considerable performance improvement over classical pure noncooperative schemes.","Games,
Convergence,
Algorithm design and analysis,
Resource management,
Optimization,
Vectors,
MIMO"
Evaluation and Comparison of Current Fetal Ultrasound Image Segmentation Methods for Biometric Measurements: A Grand Challenge,"This paper presents the evaluation results of the methods submitted to Challenge US: Biometric Measurements from Fetal Ultrasound Images, a segmentation challenge held at the IEEE International Symposium on Biomedical Imaging 2012. The challenge was set to compare and evaluate current fetal ultrasound image segmentation methods. It consisted of automatically segmenting fetal anatomical structures to measure standard obstetric biometric parameters, from 2D fetal ultrasound images taken on fetuses at different gestational ages (21 weeks, 28 weeks, and 33 weeks) and with varying image quality to reflect data encountered in real clinical environments. Four independent sub-challenges were proposed, according to the objects of interest measured in clinical practice: abdomen, head, femur, and whole fetus. Five teams participated in the head sub-challenge and two teams in the femur sub-challenge, including one team who tackled both. Nobody attempted the abdomen and whole fetus sub-challenges. The challenge goals were two-fold and the participants were asked to submit the segmentation results as well as the measurements derived from the segmented objects. Extensive quantitative (region-based, distance-based, and Bland-Altman measurements) and qualitative evaluation was performed to compare the results from a representative selection of current methods submitted to the challenge. Several experts (three for the head sub-challenge and two for the femur sub-challenge), with different degrees of expertise, manually delineated the objects of interest to define the ground truth used within the evaluation framework. For the head sub-challenge, several groups produced results that could be potentially used in clinical settings, with comparable performance to manual delineations. The femur sub-challenge had inferior performance to the head sub-challenge due to the fact that it is a harder segmentation problem and that the techniques presented relied more on the femur's appearance.","Image segmentation,
Head,
Ultrasonic imaging,
Biomedical imaging,
Ultrasonic variables measurement,
Magnetic heads"
All-environment visual place recognition with SMART,"This paper presents Sequence Matching Across Route Traversals (SMART); a generally applicable sequence-based place recognition algorithm. SMART provides invariance to changes in illumination and vehicle speed while also providing moderate pose invariance and robustness to environmental aliasing. We evaluate SMART on vehicles travelling at highly variable speeds in two challenging environments; firstly, on an all-terrain vehicle in an off-road, forest track and secondly, using a passenger car traversing an urban environment across day and night. We provide comparative results to the current state-of-the-art SeqSLAM algorithm and investigate the effects of altering SMART's image matching parameters. Additionally, we conduct an extensive study of the relationship between image sequence length and SMART's matching performance. Our results show viable place recognition performance in both environments with short 10-metre sequences, and up to 96% recall at 100% precision across extreme day-night cycles when longer image sequences are used.","Roads,
Visualization,
Cameras,
Trajectory,
Vehicles,
Image sequences,
Sensors"
Adaptive Neural PD Control With Semiglobal Asymptotic Stabilization Guarantee,"This paper proves that adaptive neural plus proportional-derivative (PD) control can lead to semiglobal asymptotic stabilization rather than uniform ultimate boundedness for a class of uncertain affine nonlinear systems. An integral Lyapunov function-based ideal control law is introduced to avoid the control singularity problem. A variable-gain PD control term without the knowledge of plant bounds is presented to semiglobally stabilize the closed-loop system. Based on a linearly parameterized raised-cosine radial basis function neural network, a key property of optimal approximation is exploited to facilitate stability analysis. It is proved that the closed-loop system achieves semiglobal asymptotic stability by the appropriate choice of control parameters. Compared with previous adaptive approximation-based semiglobal or asymptotic stabilization approaches, our approach not only significantly simplifies control design, but also relaxes constraint conditions on the plant. Two illustrative examples have been provided to verify the theoretical results.","Artificial neural networks,
Approximation methods,
PD control,
Nonlinear systems,
Adaptive systems,
Vectors"
Sparsity-Based Poisson Denoising With Dictionary Learning,"The problem of Poisson denoising appears in various imaging applications, such as low-light photography, medical imaging, and microscopy. In cases of high SNR, several transformations exist so as to convert the Poisson noise into an additive-independent identically distributed. Gaussian noise, for which many effective algorithms are available. However, in a low-SNR regime, these transformations are significantly less accurate, and a strategy that relies directly on the true noise statistics is required. Salmon et al. took this route, proposing a patch-based exponential image representation model based on Gaussian mixture model, leading to state-of-the-art results. In this paper, we propose to harness sparse-representation modeling to the image patches, adopting the same exponential idea. Our scheme uses a greedy pursuit with boot-strapping-based stopping condition and dictionary learning within the denoising process. The reconstruction performance of the proposed scheme is competitive with leading methods in high SNR and achieving state-of-the-art results in cases of low SNR.","Dictionaries,
Noise reduction,
Noise measurement,
Signal to noise ratio,
Minimization,
Vectors"
Impact of Water-Assisted Electrochemical Reactions on the OFF-State Degradation of AlGaN/GaN HEMTs,"The origin of structural and electrical degradation in AlGaN/GaN high-electron mobility transistors (HEMTs) under OFF-state stress was systematically studied. Hydroxyl groups (OH-) from the environment and/or adsorbed water on the III-N surface, were found to play an important role in the formation of surface pits during OFF-state electrical stress. The mechanism of this water-related structural degradation is explained by an electrochemical cell formed at the gate edge where gate metal, the III-N surface, and the passivation layer meet. The relationship between structural and electrical degradation in AlGaN/GaN HEMTs under OFF-state stress is discussed. Specifically, the permanent decrease in the drain current is directly linked with the formation of the surface pits, while the permanent increase in the gate current is found to be uncorrelated with the structural degradation.","Logic gates,
HEMTs,
MODFETs,
Aluminum gallium nitride,
Gallium nitride,
Degradation,
Surface treatment"
Adaptive Dynamic Sliding-Mode Fuzzy CMAC for Voice Coil Motor Using Asymmetric Gaussian Membership Function,"When the precise model of a controlled system is difficult to obtain, a model-free control method is suitable for control system design. The design goal of this paper is to propose a more efficient control method to deal with control systems with unknown system dynamic models and to achieve favorable chattering-free trajectory tracking performance. The cerebellar model articulation controller (CMAC) is an efficient neural network that can be applied for model-free control systems. This study proposes an adaptive dynamic sliding-mode fuzzy CMAC (ADSFC) system, which is comprised of a fuzzy CMAC and a fuzzy compensator. A fuzzy CMAC using an asymmetric Gaussian membership function is the main controller and the fuzzy compensator can compensate the approximation error introduced by a fuzzy CMAC. Moreover, a proportional-integral-type adaptation learning algorithm is developed to speed up the parameter learning. Finally, the proposed ADSFC system is applied to control a voice coil motor (VCM). Finally, the experimental results demonstrate the effectiveness of the proposed ADSFC scheme.","Frequency control,
Coils,
Switches,
Adaptation models,
Fuzzy systems,
Approximation error"
A Collaborative Fuzzy Clustering Algorithm in Distributed Network Environments,"Due to privacy and security requirements or technical constraints, traditional centralized approaches to data clustering in a large dynamic distributed peer-to-peer network are difficult to perform. In this paper, a novel collaborative fuzzy clustering algorithm is proposed, in which the centralized clustering solution is approximated by performing distributed clustering at each peer with the collaboration of other peers. The required communication links are established at the level of cluster prototype and attribute weight. The information exchange only exists between topological neighboring peers. The attribute-weight-entropy regularization technique is applied in the distributed clustering method to achieve an ideal distribution of attribute weights, which ensures good clustering results. And the important features are successfully extracted for the high-dimensional data clustering. The kernelization of the proposed algorithm is also realized as a practical tool for clustering the data with “nonspherical”-shaped clusters. Experiments on synthetic and real-world datasets have demonstrated the efficiency and superiority of the proposed algorithms.","Clustering algorithms,
Prototypes,
Collaboration,
Peer-to-peer computing,
Niobium,
Clustering methods,
Distributed databases"
Total Variation-Stokes Strategy for Sparse-View X-ray CT Image Reconstruction,"Previous studies have shown that by minimizing the total variation (TV) of the to-be-estimated image with some data and/or other constraints, a piecewise-smooth X-ray computed tomography image can be reconstructed from sparse-view projection data. However, due to the piecewise constant assumption for the TV model, the reconstructed images are frequently reported to suffer from the blocky or patchy artifacts. To eliminate this drawback, we present a total variation-stokes-projection onto convex sets (TVS-POCS) reconstruction method in this paper. The TVS model is derived by introducing isophote directions for the purpose of recovering possible missing information in the sparse-view data situation. Thus the desired consistencies along both the normal and the tangent directions are preserved in the resulting images. Compared to the previous TV-based image reconstruction algorithms, the preserved consistencies by the TVS-POCS method are expected to generate noticeable gains in terms of eliminating the patchy artifacts and preserving subtle structures. To evaluate the presented TVS-POCS method, both qualitative and quantitative studies were performed using digital phantom, physical phantom and clinical data experiments. The results reveal that the presented method can yield images with several noticeable gains, measured by the universal quality index and the full-width-at-half-maximum merit, as compared to its corresponding TV-based algorithms. In addition, the results further indicate that the TVS-POCS method approaches to the gold standard result of the filtered back-projection reconstruction in the full-view data case as theoretically expected, while most previous iterative methods may fail in the full-view case because of their artificial textures in the results.","Image reconstruction,
Vectors,
Computed tomography,
Mathematical model,
X-ray imaging,
Equations,
TV"
Using the Humanoid Robot KASPAR to Autonomously Play Triadic Games and Facilitate Collaborative Play Among Children With Autism,"This paper presents a novel design, implementation, and first evaluation of a triadic, collaborative game involving the humanoid robot, kinesics and synchronization in personal assistant robotics (KASPAR), playing games with pairs of children with autism. Children with autism have impaired social communication and social interaction skills which make it difficult for them to participate in many different forms of social and collaborative play. Our proof-of-concept 10-week, long term study demonstrates how a humanoid robot can be used to foster and support collaborative play among children with autism. In this work, KASPAR operates fully autonomously, and uses information on the state of the game and behavior of the children to engage, motivate, encourage, and advise pairs of children playing an imitation game. Results are presented from a first evaluation study which examined whether having pairs of children with autism play an imitative, collaborative game with a humanoid robot affected the way these children would play the same game without the robot. Our initial evaluation involved six children with autism who each participated in 23 controlled play sessions both with and without the robot, using a specially designed imitation-based collaborative game. In total 78 play sessions were run. Detailed observational analyses of the children's behaviors indicated that different pairs of children with autism showed improved social behaviors in playing with each other after they played as pairs with the robot KASPAR compared to before they did so. These results are encouraging and provide a proof-of-concept of using an autonomously operating robot to encourage collaborative skills among children with autism.","Autism,
Games,
Collaboration,
Shape,
Humanoid robots,
Educational institutions"
The Effects of Interactive Latency on Exploratory Visual Analysis,"To support effective exploration, it is often stated that interactive visualizations should provide rapid response times. However, the effects of interactive latency on the process and outcomes of exploratory visual analysis have not been systematically studied. We present an experiment measuring user behavior and knowledge discovery with interactive visualizations under varying latency conditions. We observe that an additional delay of 500ms incurs significant costs, decreasing user activity and data set coverage. Analyzing verbal data from think-aloud protocols, we find that increased latency reduces the rate at which users make observations, draw generalizations and generate hypotheses. Moreover, we note interaction effects in which initial exposure to higher latencies leads to subsequently reduced performance in a low-latency setting. Overall, increased latency causes users to shift exploration strategy, in turn affecting performance. We discuss how these results can inform the design of interactive analysis tools.","Visual analytics,
Data visualization,
Visualization,
Interactive services,
Image color analysis"
An Innovative Nonintrusive Driver Assistance System for Vital Signal Monitoring,"This paper describes an in-vehicle nonintrusive biopotential measurement system for driver health monitoring and fatigue detection. Previous research has found that the physiological signals including eye features, electrocardiography (ECG), electroencephalography (EEG) and their secondary parameters such as heart rate and HR variability are good indicators of health state as well as driver fatigue. A conventional biopotential measurement system requires the electrodes to be in contact with human body. This not only interferes with the driver operation, but also is not feasible for long-term monitoring purpose. The driver assistance system in this paper can remotely detect the biopotential signals with no physical contact with human skin. With delicate sensor and electronic design, ECG, EEG, and eye blinking can be measured. Experiments were conducted on a high fidelity driving simulator to validate the system performance. The system was found to be able to detect the ECG/EEG signals through cloth or hair with no contact with skin. Eye blinking activities can also be detected at a distance of 10 cm. Digital signal processing algorithms were developed to decimate the signal noise and extract the physiological features. The extracted features from the vital signals were further analyzed to assess the potential criterion for alertness and drowsiness determination.","Intelligent vehicles,
Road safety,
Electrocardiography,
Electroencephalography,
Fatigue,
Monitoring,
Bioelectric phenomena"
Phase-Separated DCSK: A Simple Delay-Component-Free Solution for Chaotic Communications,"In this brief, a phase-separated differential chaos shift keying (PS-DCSK) modulation scheme is proposed as a simple delay-component-free version of DCSK modulation. Separated by orthogonal sinusoidal carriers rather than time delay, the reference and information-bearing signals in DCSK are transmitted simultaneously and parallel in the proposed system. As a result, PS-DCSK not only can avoid the difficult-to-implement radio-frequency delay line problem but also can achieve a doubled attainable data rate, enhanced communication security, and equivalent bit-error-rate (BER) performance with respect to DCSK. Finally, analytical expressions for the BER performance of the proposed system are derived and verified by computer simulation results over additive Gaussian white noise and Rayleigh fading channels.","Bit error rate,
Synchronization,
Chaotic communication,
Fading,
AWGN channels"
An Energy-Aware Trust Derivation Scheme With Game Theoretic Approach in Wireless Sensor Networks for IoT Applications,"Trust evaluation plays an important role in securing wireless sensor networks (WSNs), which is one of the most popular network technologies for the Internet of Things (IoT). The efficiency of the trust evaluation process is largely governed by the trust derivation, as it dominates the overhead in the process, and performance of WSNs is particularly sensitive to overhead due to the limited bandwidth and power. This paper proposes an energy-aware trust derivation scheme using game theoretic approach, which manages overhead while maintaining adequate security of WSNs. A risk strategy model is first presented to stimulate WSN nodes' cooperation. Then, a game theoretic approach is applied to the trust derivation process to reduce the overhead of the process. We show with the help of simulations that our trust derivation scheme can achieve both intended security and high efficiency suitable for WSN-based IoT networks.","Wireless sensor networks,
Security,
Energy efficiency,
Games,
Computational modeling,
Energy consumption,
Electronic mail"
CC-KF: Enhanced TOA Performance in Multipath and NLOS Indoor Extreme Environment,"Time-of-arrival (TOA)-based indoor geolocation suffer from huge distance measurement error caused by multipath and nonline-of-sight (NLOS) conditions. In this paper, we presented a new distance mitigation algorithm based on channel classification and Kalman filter to enhanced TOA performance in multipath and NLOS indoor extreme environment. This algorithm could significantly reduce the ranging error caused by the extreme channel condition in indoor area. We compared the performance of our algorithm with the traditional TOA distance mitigation algorithms, such as Kalman filter, biased Kalman filter, binary hypothesis testing, and ANN, using a commercially available TOA-based geolocation system in typical indoor and underground environments. Results show the performance of our algorithm is much superior to the others.","Distance measurement,
Kalman filters,
Measurement uncertainty,
Accuracy,
Receivers,
Mathematical model,
Noise measurement"
Integration of Plug-in Hybrid Electric Vehicles into Residential Distribution Grid Based on Two-Layer Intelligent Optimization,"This paper presents a methodology for modeling the load demand of plug-in hybrid electric vehicles (PHEVs). Due to the stochastic nature of vehicle arrival time, departure time and daily mileage, probabilistic methods are chosen to model the driving pattern. However, these three elements of driving pattern are correlated with each other, which makes the probability density functions (pdfs)-based probabilistic methods inaccurate. Here a fuzzy logic based stochastic model is built to study the relationship between the three elements of driving pattern. Moreover, a load profile modeling framework (LPMF) for PHEVs is proposed to synthesize both the characteristics of driving pattern and vehicle parameters into a load profile prediction system. Based on this stochastic model of PHEV, a two-layer evolution strategy particle swarm optimization (ESPSO) algorithm is proposed to integrate PHEVs into a residential distribution grid. A novel business model is developed for PHEVs to provide ancillary service and participate in peak load shaving. A virtual time-of-use rate is used to reflect the load deviation of the system. Then, an objective function is developed to aggregate the peak load shaving, power quality improvement, charging cost, battery degradation cost and frequency regulation earnings into one cost function. The ESPSO approach can benefit the system in four major aspects by: 1) improving the power quality; 2) reducing the peak load; 3) providing frequency regulation service; and 4) minimizing the total virtual cost. Finally, simulations are carried out based on different control strategies and the results have demonstrated the effectiveness of the proposed algorithm.","Load modeling,
Stochastic processes,
Vehicles,
Batteries,
Frequency control,
System-on-chip,
Power grids"
A New Iterative Triclass Thresholding Technique in Image Segmentation,"We present a new method in image segmentation that is based on Otsu's method but iteratively searches for subregions of the image for segmentation, instead of treating the full image as a whole region for processing. The iterative method starts with Otsu's threshold and computes the mean values of the two classes as separated by the threshold. Based on the Otsu's threshold and the two mean values, the method separates the image into three classes instead of two as the standard Otsu's method does. The first two classes are determined as the foreground and background and they will not be processed further. The third class is denoted as a to-be-determined (TBD) region that is processed at next iteration. At the succeeding iteration, Otsu's method is applied on the TBD region to calculate a new threshold and two class means and the TBD region is again separated into three classes, namely, foreground, background, and a new TBD region, which by definition is smaller than the previous TBD regions. Then, the new TBD region is processed in the similar manner. The process stops when the Otsu's thresholds calculated between two iterations is less than a preset threshold. Then, all the intermediate foreground and background regions are, respectively, combined to create the final segmentation result. Tests on synthetic and real images showed that the new iterative method can achieve better performance than the standard Otsu's method in many challenging cases, such as identifying weak objects and revealing fine structures of complex objects while the added computational cost is minimal.","Image segmentation,
Histograms,
Iterative methods,
Standards,
Educational institutions,
Biomedical imaging,
Hospitals"
Insurance Telematics: Opportunities and Challenges with the Smartphone Solution,"Smartphone-based insurance telematics or usage based insurance is a disruptive technology which relies on insurance premiums that reflect the risk profile of the driver; measured via smartphones with appropriate installed software. A survey of smartphone-based insurance telematics is presented, including definitions; Figure-of-Merits (FoMs), describing the behavior of the driver and the characteristics of the trip; and risk profiling of the driver based on different sets of FoMs. The data quality provided by the smartphone is characterized in terms of Accuracy, Integrity, Availability, and Continuity of Service. The quality of the smartphone data is further compared with the quality of data from traditional in-car mounted devices for insurance telematics, revealing the obstacles that have to be combated for a successful smartphone-based installation, which are the poor integrity and low availability. Simply speaking, the reliability is lacking considering the smartphone measurements. Integrity enhancement of smartphone data is illustrated by both second-by-second lowlevel signal processing to combat outliers and perform integrity monitoring, and by trip-based map-matching for robustification of the recorded trip data. A plurality of FoMs are described, analyzed and categorized, including events and properties like harsh braking, speeding, and location. The categorization of the FoMs in terms of Observability, Stationarity, Driver influence, and Actuarial relevance are tools for robust risk profiling of the driver and the trip. Proper driver feedback is briefly discussed, and rule-of-thumbs for feedback design are included. The work is supported by experimental validation, statistical analysis, and experiences from a recent insurance telematics pilot run in Sweden.","Smart phones,
Electrical vehicles,
Telematics,
Availability,
Time measurement,
Global Positioning System,
Software measurement,
Feedback"
Joint Approximately Sparse Channel Estimation and Data Detection in OFDM Systems Using Sparse Bayesian Learning,"It is well known that the impulse response of a wideband wireless channel is approximately sparse, in the sense that it has a small number of significant components relative to the channel delay spread. In this paper, we consider the estimation of the unknown channel coefficients and its support in OFDM systems using a sparse Bayesian learning (SBL) framework for exact inference. In a quasi-static, block-fading scenario, we employ the SBL algorithm for channel estimation and propose a joint SBL (J-SBL) and a low-complexity recursive J-SBL algorithm for joint channel estimation and data detection. In a time-varying scenario, we use a first-order autoregressive model for the wireless channel and propose a novel, recursive, low-complexity Kalman filtering-based SBL (KSBL) algorithm for channel estimation. We generalize the KSBL algorithm to obtain the recursive joint KSBL algorithm that performs joint channel estimation and data detection. Our algorithms can efficiently recover a group of approximately sparse vectors even when the measurement matrix is partially unknown due to the presence of unknown data symbols. Moreover, the algorithms can fully exploit the correlation structure in the multiple measurements. Monte Carlo simulations illustrate the efficacy of the proposed techniques in terms of the mean-square error and bit error rate performance.","Channel estimation,
OFDM,
Joints,
Signal processing algorithms,
Estimation,
Vectors,
Inference algorithms"
Rf-powered systems using steep-slope devices,Steep-slope tunnel devices promise new opportunities in ultra-low-power computing. This paper focuses on how steep-slope devices can enhance efficiencies of harvesting ambient RF energy and improve power efficiency of analog and digital computational blocks.,"Sensors,
Radio frequency,
Wireless sensor networks,
CMOS integrated circuits,
Silicon,
FinFETs,
Wireless communication"
Randomized Algorithms for Optimal Solutions of Double-Sided QCQP With Applications in Signal Processing,"Quadratically constrained quadratic programming (QCQP) with double-sided constraints has plenty of applications in signal processing as have been addressed in recent years. QCQP problems are hard to solve, in general, and they are typically approached by solving a semidefinite programming (SDP) relaxation followed by a postprocessing procedure. Existing postprocessing schemes include Gaussian randomization to generate an approximate solution, rank reduction procedure (the so-called purification), and some specific rank-one matrix decomposition techniques to yield a globally optimal solution. In this paper, we propose several randomized postprocessing methods to output not an approximate solution but a globally optimal solution for some solvable instances of the double-sided QCQP (i.e., instances with a small number of constraints). We illustrate their applicability in robust receive beamforming, radar optimal code design, and broadcast beamforming for multiuser communications. As a byproduct, we derive an alternative (shorter) proof for the Sturm-Zhang rank-one matrix decomposition theorem.","Array signal processing,
Vectors,
Robustness,
Signal processing algorithms,
Interference,
Radar"
Design and Evaluation of Multiple Valued Logic Gates Using Pseudo N-Type Carbon Nanotube FETs,"Multiple valued logic (MVL) circuits are particularly attractive for nanoscale implementation as advantages in information density and operating speed can be harvested using emerging technologies. In this paper, a new family of MVL gates is proposed for implementation using carbon nanotube field-effect transistors (CNTFETs). The proposed designs use pseudo N-type CNTFETs and no resistor is utilized for their operation. This approach exploits threshold voltage control of the P-type and N-type transistors, while ensuring correct MVL operation for both ternary and quaternary logic gates. This paper provides a detailed assessment of several figures of merit, such as static power consumption, switching power consumption, propagation delay and the power-delay product (PDP). Compared with resistor-loaded designs, the proposed pseudo-NCNTFET MVL gates show advantages in circuit area, power consumption and energy efficiency, while still incurring a comparable propagation delay. Compared to a complementary logic family, the pseudo-NCNTFET MVL logic family requires a smaller circuit area with a similar propagation delay on average, albeit with a larger PDP and static power consumption. A design methodology and a discussion of issues related to leakage and yield are also provided for the proposed MVL logic family.","CNTFETs,
Inverters,
Logic gates,
Power demand,
Standards,
Resistors,
Threshold voltage"
Adaptive Real Power Capping Method for Fair Overvoltage Regulation of Distribution Networks With High Penetration of PV Systems,"For distribution networks with a high penetration of photovoltaic (PV) systems, overvoltage is a common and major issue that needs be addressed to not only assure reliable and secure system operation, but also to fully utilize PV generation capacity. A new real power capping method is proposed in this paper to prevent overvoltages by adaptively setting the power caps for PV inverters in real time. The proposed method can maintain voltage profiles below a preset upper limit while maximizing the PV generation and fairly distributing the real power curtailments among all the PV systems in the network. As a result, each of the PV systems in the network has equal opportunity to generate electricity and shares the responsibility of voltage regulation. The method does not require global information and can be implemented either under a centralized supervisory control scheme or in a distributed way via consensus control. Both steady state and dynamic simulation studies under various scenarios have been carried out on a 33-bus distribution system and the IEEE 13-bus test feeder to verify the effectiveness of the method.","Voltage control,
Distributed power generation,
Reactive power,
Photovoltaic systems"
Realizing Unified Microgrid Voltage Profile and Loss Minimization: A Cooperative Distributed Optimization and Control Approach,"Cooperative distributed optimization is proposed in this paper to optimally dispatch the reactive power of the distributed generators (DGs). The overall objective is to minimize the cost function that is the sum of all quadratic voltage errors of the DG nodes and other critical nodes in the system. It is assumed that each DG is only aware of its own cost function defined as the quadratic voltage error of its respective node. In the proposed method, every DG performs optimization with respect to its own objective function while considering the information received locally from the neighboring nodes in the microgrid, and the critical nodes without DG also contribute to optimization. The proposed distributed optimization and control scheme enables the microgrid to have a unified voltage profile, and incorporating the subgradient method facilitates its application even when the microgrid information is unknown. Microgrid active power loss is also investigated, and it is shown that the unified voltage profile naturally leads to the overall active power loss minimization as well. Stability analysis and criteria are provided. Simulation results of a typical microgrid illustrate superior performance of the proposed technique.",
A Disturbance-Adaptive Design for VANET-Enabled Vehicle Platoon,"In highway systems, grouping vehicles into platoons can improve road capacity and energy efficiency. With the advance of technologies, the performance of platoons can be further enhanced by vehicular ad hoc networks (VANETs). In the past few years, many studies have been conducted on the dynamics of a VANET-enabled platoon under traffic disturbance, which is a common scenario on a highway. However, most of them do not consider the impact of platoon dynamics on the behaviors of VANETs. Moreover, most existing studies focus on how to maintain the stability of a platoon and do not address how to mitigate negative effects of traffic disturbance, such as uncomfortable passenger experience, increased fuel consumption, and increased exhaust emission. In this paper, we will investigate the dynamics of the VANET-enabled platoon from an integrated perspective. In particular, we first propose a novel disturbance-adaptive platoon (DA-Platoon) architecture, in which a platoon controller shall adapt to the disturbance scenario and shall consider both VANET and platoon dynamics requirements. Based on a specific realization of the DA-Platoon architecture, we then analyze the traffic dynamics inside a platoon and derive desired parameters, including intraplatoon spacing and platoon size, so as to satisfy VANET constraints under traffic disturbance. To mitigate the adverse effects of traffic disturbance, we also design a novel driving strategy for the leading vehicle of a platoon, with which we can determine the desired interplatoon spacing. Finally, we conduct extensive simulation experiments, which not only validate our analysis but also demonstrate the effectiveness of the proposed driving strategy.","Vehicles,
Vehicle dynamics,
Vehicular ad hoc networks,
Acceleration,
Protocols,
Relays,
Merging"
Secure Time Synchronization in WirelessSensor Networks: A MaximumConsensus-Based Approach,"Time synchronization is a fundamental requirement for the wide spectrum of applications with wireless sensor networks (WSNs). However, most existing time synchronization protocols are likely to deteriorate or even to be destroyed when the WSNs are attacked by malicious intruders. This paper is concerned with secure time synchronization for WSNs under message manipulation attacks. Specifically, the theoretical analysis and simulation results are first provided to demonstrate that the maximum consensus based time synchronization (MTS) protocol would be invalid under message manipulation attacks. Then, a novel secured maximum consensus based time synchronization (SMTS) protocol is proposed to detect and invalidate message manipulation attacks. Furthermore, we prove that SMTS is guaranteed to converge with simultaneous compensation of both clock skew and offset. Extensive numerical results show the effectiveness of our proposed protocol.","Synchronization,
Clocks,
Hardware,
Protocols,
Wireless sensor networks,
Delays,
Noise"
"Metrics for Describing Soft-Tissue Artefact and Its Effect on Pose, Size, and Shape of Marker Clusters","In human movement analysis based on stereophotogrammetry, bone pose is reconstructed by observing a cluster of skin markers. Each marker undergoes a displacement relative to the underlying bone that is regarded as an artefact (soft-tissue artefact, STA) since it affects accuracy in bone pose estimation. This paper proposes a set of metrics for the statistical description of the STA and its effects on cluster pose, size, and shape, with the intent of contributing to a clearer knowledge of its characteristics, and consequently of setting the bases for the development of more accurate bone pose estimators than presently available. Skin marker clusters behave as deformable bodies in motion relative to the underlying bone. Their motion can be described, based on Procrustes analysis, as the composition of four independent transformations: translation and rotation (rigid motion, RM), and change in size and shape (nonrigid motion, NRM). Statistical parameters describing the time histories of both the individual marker STA and the cluster transformations listed earlier were defined. For demonstration purposes, data collected ex vivo were used. The lower limbs of three cadavers were made to undergo movements with prevailing flexion-extension components. Femur pose was accurately measured using pin markers and the movement of twelve thigh skin markers observed relative to it. The STAs of all possible clusters of four skin markers were analysed. RM and NRM exhibited similar magnitudes and therefore impact on bone pose estimation. Thus bone pose estimators should not account for NRM only, as is normally the case, but also for RM.","Shape,
Bones,
Skin,
Thigh,
Biological tissues,
Read only memory,
Joints"
Threshold Saturation for Spatially Coupled LDPC and LDGM Codes on BMS Channels,"Spatially-coupled low-density parity-check (LDPC) codes, which were first introduced as LDPC convolutional codes, have been shown to exhibit excellent performance under low-complexity belief-propagation decoding. This phenomenon is now termed threshold saturation via spatial coupling. Spatially-coupled codes have been successfully applied in numerous areas. In particular, it was proven that spatially-coupled regular LDPC codes universally achieve capacity over the class of binary memoryless symmetric (BMS) channels under belief-propagation decoding. Recently, potential functions have been used to simplify threshold saturation proofs for scalar and vector recursions. In this paper, potential functions are used to prove threshold saturation for irregular LDPC and low-density generator-matrix codes on BMS channels, extending the simplified proof technique to BMS channels. The corresponding potential functions are closely related to the average Bethe free entropy of the ensembles in the large-system limit. These functions also appear in statistical physics when the replica method is used to analyze optimal decoding.","Entropy,
Decoding,
Couplings,
Degradation,
Measurement,
Iterative decoding"
Multi-Dimensional Fourier Ringdown Analysis for Power Systems Using Synchrophasors,"Wide-area implementations of synchrophasors enable real-time monitoring of power system dynamic responses during disturbances. These disturbances generally excite oscillatory modes of the system which can become problematic if the modes are either poorly damped or negatively damped. This paper describes a Fourier based automatic ringdown analysis algorithm proposed for extracting dominant oscillatory modal content of power system responses from multiple synchrophasor measurements. This approach is well suited for detecting electromechanical oscillatory modes in real-time. The proposed method is shown to be robust under noisy conditions by testing with simulation data as well as real system data, and is able to extract multiple problematic oscillatory modes computationally fast.","Damping,
Fourier transforms,
Algorithm design and analysis,
Oscillators,
Phasor measurement units,
Vectors,
Real-time systems"
Handover Scheme for 5G C/U Plane Split Heterogeneous Network in High-Speed Railway,"Being a promising technology for fifth-generation (5G) communication systems, a novel railway communication system based on control/user (C/U) plane split heterogeneous networks can provide a high-quality broadband wireless service for passengers in high-speed railways with higher system capacity, better transmission reliability, and less cochannel interference. However, due to its special architecture where the C-plane and the U-plane must be split and supported by a macro Evolved Node B (eNB) and a phantom eNB, respectively, it would suffer more serious handover problem, particularly in intermacrocell handover, which directly degrades its applicability and availability in high-speed railways. Moreover, no technical specification has been released about this network architecture. Therefore, this paper focuses on redesigning and analyzing technical details and handover procedures based on Long-Term Evolution (LTE) specifications to guarantee the proposed system's practicability and generality and its analytical tractability. To resolve the handover problem, this paper proposes a handover trigger decision scheme based on GM(1, n) model of the grey system theory. By this scheme, the received signal quality from the (N + 1)th measurement report can be predicted from the Nth measurement period, and the predicted values can be then utilized to make the handover trigger decision. The simulation results show that our proposed scheme is capable of triggering handover in advance effectively and of enhancing handover success probability remarkably.","Computer architecture,
Handover,
Microprocessors,
Phantoms,
Rail transportation,
Current measurement"
DOTS: A Propagation Delay-Aware Opportunistic MAC Protocol for Mobile Underwater Networks,"Mobile underwater networks with acoustic communications are confronted with several unique challenges such as long propagation delays, high transmission power consumption, and node mobility. In particular, slow signal propagation permits multiple packets to concurrently travel in the underwater channel, which must be exploited to improve the overall throughput. To this end, we propose the delay-aware opportunistic transmission scheduling (DOTS) protocol that uses passively obtained local information (i.e., neighboring nodes' propagation delay map and their expected transmission schedules) to increase the chances of concurrent transmissions while reducing the likelihood of collisions. Our extensive simulation results document that DOTS outperforms existing solutions and provides fair medium access even with node mobility.","Protocols,
Mobile communication,
Mobile computing,
US Department of Transportation,
Propagation delay,
Sensors,
Synchronization"
SlashBurn: Graph Compression and Mining beyond Caveman Communities,"Given a real world graph, how should we lay-out its edges? How can we compress it? These questions are closely related, and the typical approach so far is to find clique-like communities, like the cavemen graph', and compress them. We show that the block-diagonal mental image of the cavemen graph' is the wrong paradigm, in full agreement with earlier results that real world graphs have no good cuts. Instead, we propose to envision graphs as a collection of hubs connecting spokes, with super-hubs connecting the hubs, and so on, recursively. Based on the idea, we propose the SLASHBURN method to recursively split a graph into hubs and spokes connected only by the hubs. We also propose techniques to select the hubs and give an ordering to the spokes, in addition to the basic SLASHBURN. We give theoretical analysis of the proposed hub selection methods. Our view point has several advantages: (a) it avoids the no good cuts' problem, (b) it gives better compression, and (c) it leads to faster execution times for matrix-vector operations, which are the back-bone of most graph processing tools. Through experiments, we show that SLASHBURN consistently outperforms other methods for all data sets, resulting in better compression and faster running time. Moreover, we show that SLASHBURN with the appropriate spokes ordering can further improve compression while hardly sacrificing the running time.","Graph theory,
Cost function,
Matrix decomposition,
Data mining,
Encoding"
Toward QoI and Energy-Efficiency in Internet-of-Things Sensory Environments,"Considering physical sensors with certain sensing capabilities in an Internet-of-Things (IoTs) sensory environment, in this paper, we propose an efficient energy management framework to control the duty cycles of these sensors under quality-of-information (QoI) expectations in a multitask-oriented environment. Contrary to past research efforts, our proposal is transparent and compatible both with the underlying low-layer protocols and diverse applications, and preserving energy-efficiency in the long run without sacrificing the QoI levels attained. In particular, we first introduce the novel concept of QoI-aware sensor-to-task relevancy to explicitly consider the sensing capabilities offered by a sensor to the IoT sensory environments, and QoI requirements required by a task. Second, we propose a novel concept of the critical covering set of any given task in selecting the sensors to service a task over time. Third, energy management decision is made dynamically at runtime, to reach the optimum for long-term application arrivals and departures under the constraint of their service delay. We show a case study to utilize sensors to perform environmental monitoring with a complete set of performance analysis. We further consider the signal propagation and processing latency into the proposal, and provide a thorough analysis on its impact on average measured delay probability.",
Learning Deep Hierarchical Visual Feature Coding,"In this paper, we propose a hybrid architecture that combines the image modeling strengths of the bag of words framework with the representational power and adaptability of learning deep architectures. Local gradient-based descriptors, such as SIFT, are encoded via a hierarchical coding scheme composed of spatial aggregating restricted Boltzmann machines (RBM). For each coding layer, we regularize the RBM by encouraging representations to fit both sparse and selective distributions. Supervised fine-tuning is used to enhance the quality of the visual representation for the categorization task. We performed a thorough experimental evaluation using three image categorization data sets. The hierarchical coding scheme achieved competitive categorization accuracies of 79.7% and 86.4% on the Caltech-101 and 15-Scenes data sets, respectively. The visual representations learned are compact and the model's inference is fast, as compared with sparse coding methods. The low-level representations of descriptors that were learned using this method result in generic features that we empirically found to be transferrable between different image data sets. Further analysis reveal the significance of supervised fine-tuning when the architecture has two layers of representations as opposed to a single layer.","Encoding,
Computer architecture,
Visualization,
Dictionaries,
Learning systems,
Neural networks,
Adaptation models"
Generalized Hermite Polynomial Chaos for Variability Analysis of Macromodels Embeddedin Nonlinear Circuits,"This paper describes a new approach to extend the variability analysis based on the polynomial chaos (PC) technique to nonlinear circuits. The proposed approach enables interconnects and package modules whose macromodels have their variability characterized using the PC, to be used in general nonlinear circuits. This allows the PC variability analysis to be performed directly in the time domain. The numerical examples are presented to demonstrate the validity and accuracy of the proposed method.","Polynomials,
Vectors,
Nonlinear circuits,
Accuracy,
Integrated circuit interconnections,
Stochastic processes"
Multiattribute SCADA-Specific Intrusion Detection System for Power Networks,"The increased interconnectivity and complexity of supervisory control and data acquisition (SCADA) systems in power system networks has exposed the systems to a multitude of potential vulnerabilities. In this paper, we present a novel approach for a next-generation SCADA-specific intrusion detection system (IDS). The proposed system analyzes multiple attributes in order to provide a comprehensive solution that is able to mitigate varied cyber-attack threats. The multiattribute IDS comprises a heterogeneous white list and behavior-based concept in order to make SCADA cybersystems more secure. This paper also proposes a multilayer cyber-security framework based on IDS for protecting SCADA cybersecurity in smart grids without compromising the availability of normal data. In addition, this paper presents a SCADA-specific cybersecurity testbed to investigate simulated attacks, which has been used in this paper to validate the proposed approach.","Protocols,
Computer security,
Detectors,
SCADA systems,
Intrusion detection,
Current measurement"
A Unified Learning Framework for Single Image Super-Resolution,"It has been widely acknowledged that learning- and reconstruction-based super-resolution (SR) methods are effective to generate a high-resolution (HR) image from a single low-resolution (LR) input. However, learning-based methods are prone to introduce unexpected details into resultant HR images. Although reconstruction-based methods do not generate obvious artifacts, they tend to blur fine details and end up with unnatural results. In this paper, we propose a new SR framework that seamlessly integrates learning- and reconstruction-based methods for single image SR to: 1) avoid unexpected artifacts introduced by learning-based SR and 2) restore the missing high-frequency details smoothed by reconstruction-based SR. This integrated framework learns a single dictionary from the LR input instead of from external images to hallucinate details, embeds nonlocal means filter in the reconstruction-based SR to enhance edges and suppress artifacts, and gradually magnifies the LR input to the desired high-quality SR result. We demonstrate both visually and quantitatively that the proposed framework produces better results than previous methods from the literature.","Image reconstruction,
Dictionaries,
Image resolution,
Matching pursuit algorithms,
Image edge detection,
Estimation,
Learning systems"
Investigation on Cost Assignment in Spatial Image Steganography,"Relating the embedding cost in a distortion function to statistical detectability is an open vital problem in modern steganography. In this paper, we take one step forward by formulating the process of cost assignment into two phases: 1) determining a priority profile and 2) specifying a cost-value distribution. We analytically show that the cost-value distribution determines the change rate of cover elements. Furthermore, when the cost-values are specified to follow a uniform distribution, the change rate has a linear relation with the payload, which is a rare property for content-adaptive steganography. In addition, we propose some rules for ranking the priority profile for spatial images. Following such rules, we propose a five-step cost assignment scheme. Previous steganographic schemes, such as HUGO, WOW, S-UNIWARD, and MG, can be integrated into our scheme. Experimental results demonstrate that the proposed scheme is capable of better resisting steganalysis equipped with high-dimensional rich model features.","Payloads,
Additives,
Security,
Vectors,
Feature extraction,
Encoding,
Educational institutions"
Radio resource allocation for physical-layer security in D2D underlay communications,"Device-to-Device (D2D) communications have been proposed recently to improve the spectral efficiency. In this paper, we consider physical-layer security in D2D communication as an underlay to cellular networks with an eavesdropper. Benefiting from the underlaid spectrum reuse, D2D users can contribute to the system secrecy capacity, while D2D users may interfere the cellular users and decrease their secrecy capacity. We formulate this problem as a matching problem in the weighted bipartite graph and introduce the Kuhn-Munkres (KM) algorithm to provide the optimal solution. Simulation results show that the system secrecy capacity can be greatly improved by introducing D2D communications underlaying cellular networks.","Labeling,
Bipartite graph,
Resource management,
Wireless communication,
Receivers,
Mobile communication,
Mobile computing"
"Optimal, Nonlinear, and Distributed Designs of Droop Controls for DC Microgrids","In this paper, the problem of optimal voltage and power regulation is formulated for distributed generators (DGs) in DC microgrids. It is shown that the resulting control is optimal but would require the full information of the microgrid. Relaxation of information requirement reduces the optimal control into several controls including the conventional droop control. The general setting of a DC microgrid equipped with local sensing/communication network calls for the design and implementation of a cooperative droop control that uses the available local information and coordinates voltage control in a distributed manner. The proposed cooperative droop control is shown to include other controls as special cases, its performance is superior to the conventional droop control, and it is robust with respect to uncertain changes in both distribution network and sensing/communication network. These features make the proposed control an effective scheme for operating a DC microgrid with intermittent and distributed generation.","Microgrids,
Voltage control,
Sensors,
Stability analysis,
Symmetric matrices,
Optimal control,
Adaptive control"
A Hybrid Time-Domain Discontinuous Galerkin-Boundary Integral Method for Electromagnetic Scattering Analysis,A scheme hybridizing discontinuous Galerkin time-domain (DGTD) and time-domain boundary integral (TDBI) methods for accurately analyzing transient electromagnetic scattering is proposed. Radiation condition is enforced using the numerical flux on the truncation boundary. The fields required by the flux are computed using the TDBI from equivalent currents introduced on a Huygens' surface enclosing the scatterer. The hybrid DGTDBI ensures that the radiation condition is mathematically exact and the resulting computation domain is as small as possible since the truncation boundary conforms to scatterer's shape and is located very close to its surface. Locally truncated domains can also be defined around each disconnected scatterer additionally reducing the size of the overall computation domain. Numerical examples demonstrating the accuracy and versatility of the proposed method are presented.,"Time-domain analysis,
Plasmas,
Method of moments,
Electromagnetic scattering,
Magnetic domains,
Computational modeling,
Integral equations"
Learning Automata-Based QoS Framework for Cloud IaaS,"This paper presents a Learning Automata (LA)-based QoS (LAQ) framework capable of addressing some of the challenges and demands of various cloud applications. The proposed LAQ framework ensures that the computing resources are used in an efficient manner and are not over- or under-utilized by the consumer applications. Service provisioning can only be guaranteed by continuously monitoring the resource and quantifying various QoS metrics, so that services can be delivered in an on-demand basis with certain levels of guarantee. The proposed framework helps in ensuring guarantees with these metrics in order to provide QoS-enabled cloud services. The performance of the proposed system is evaluated with and without LA, and it is shown that the LA-based solution improves the performance of the system in terms of response time and speed up.","Quality of service,
Learning automata,
Virtual machining,
Time factors,
Monitoring,
Cloud computing,
Automata"
Instant Mobile Video Search With Layered Audio-Video Indexing and Progressive Transmission,"The proliferation of mobile devices is producing a new wave of applications that enable users to sense their surroundings with smart phones. People are preferring mobile devices to search and browse video content on the move. In this paper, we have developed an innovative mobile video search system through which users can discover videos by simply pointing their phones at a screen to capture a very few seconds of what they are watching. Different than most existing mobile video search applications, the proposed system is aiming at instant and progressive video search by leveraging the light-weight computing capacity of mobile devices. In particular, the system is able to index large-scale video data using a new layered audio-video indexing approach in the cloud, as well as generate lightweight joint audio-video signatures with progressive transmission and perform progressive search on mobile devices. Furthermore, we showcase that the system can be applied to two novel applications-video entity search and video clip localization. The evaluations on the real-world mobile video query dataset show that our system significantly improves user's search experience due to search accuracy, low retrieval latency, and very short recording duration.","Mobile communication,
Visualization,
Mobile handsets,
Feature extraction,
Streaming media,
Indexing,
Servers"
Multiresolution Imaging,"Imaging resolution has been standing as a core parameter in various applications of vision. Mostly, high resolutions are desirable or essential for many applications, e.g., in most remote sensing systems, and therefore much has been done to achieve a higher resolution of an image based on one or a series of images of relatively lower resolutions. On the other hand, lower resolutions are also preferred in some cases, e.g., for displaying images in a very small screen or interface. Accordingly, algorithms for image upsampling or downsampling have also been proposed. In the above algorithms, the downsampled or upsampled (super-resolution) versions of the original image are often taken as test images to evaluate the performance of the algorithms. However, there is one important question left unanswered: whether the downsampled or upsampled versions of the original image can represent the low-resolution or high-resolution real images from a camera? To tackle this point, the following works are carried out: 1) a multiresolution camera is designed to simultaneously capture images in three different resolutions; 2) at a given resolution (i.e., image size), the relationship between a pair of images is studied, one gained via either downsampling or super-resolution, and the other is directly captured at this given resolution by an imaging device; and 3) the performance of the algorithms of super-resolution and image downsampling is evaluated by using the given image pairs. The key reason why we can effectively tackle the aforementioned issues is that the designed multiresolution imaging camera can provide us with real images of different resolutions, which builds a solid foundation for evaluating various algorithms and analyzing the images with different resolutions, which is very important for vision.",
On Zero-Delay Source-Channel Coding,"This paper studies the zero-delay source-channel coding problem, and specifically the problem of obtaining the vector transformations that optimally map between the m-dimensional source space and k-dimensional channel space, under a given transmission power constraint and for the mean square error distortion. The functional properties of the cost are studied and the necessary conditions for the optimality of the encoder and decoder mappings are derived. An optimization algorithm that imposes these conditions iteratively, in conjunction with the noisy channel relaxation method to mitigate poor local minima, is proposed. The numerical results show strict improvement over prior methods. The numerical approach is extended to the scenario of source-channel coding with decoder side information. The resulting encoding mappings are shown to be continuous relatives of, and in fact subsume as special case, the Wyner-Ziv mappings encountered in digital distributed source coding systems. A well-known result in information theory pertains to the linearity of optimal encoding and decoding mappings in the scalar Gaussian source and channel setting, at all channel signal-to-noise ratios (CSNRs). In this paper, the linearity of optimal coding, beyond the Gaussian source and channel, is considered and the necessary and sufficient condition for linearity of optimal mappings, given a noise (or source) distribution, and a specified a total power constraint are derived. It is shown that the Gaussian source-channel pair is unique in the sense that it is the only source-channel pair for which the optimal mappings are linear at more than one CSNR values. Moreover, the asymptotic linearity of optimal mappings is shown for low CSNR if the channel is Gaussian regardless of the source and, at the other extreme, for high CSNR if the source is Gaussian, regardless of the channel. The extension to the vector settings is also considered where besides the conditions inherited from the scalar case, additional constraints must be satisfied to ensure linearity of the optimal mappings.","Decoding,
Channel coding,
Delays,
Vectors,
Linearity,
Noise"
Identification and Evolution of Structurally Dominant Nodes in Protein-Protein Interaction Networks,"It is well known that protein-protein interaction (PPI) networks are typical evolving complex networks. Identification of important nodes has been an emerging popular topic in complex networks. Many indexes have been proposed to measure the importance of nodes in complex networks, such as degree, closeness, betweenness, k-shell, clustering coefficient, semi-local centrality, eigenvector centrality. Based on multivariate statistical analysis, through integrating the above indexes and further considering the appearances of nodes in network motifs, this paper aims at developing a new measure to characterize the structurally dominant proteins (SDP) in PPI networks. Moreover, we will further investigate the evolution of the defined dominant nodes in temporal evolving real-world and artificial PPI networks. Our results indicate that the constructed artificial networks have some similar statistical properties as those of the real-world evolving networks. In this case, the artificial PPI networks can be used to further investigate the above evolution characteristics of the real-world evolving networks. Simulation results reveal that SDP in the yeast PPI networks are evolutionary conserved, however, the undominant nodes evolve rapidly. Furthermore, PPI networks are very robust against random mutations, while fragile yet with certain robustness to targeted mutations on SDP. Our investigations shed some light on the future applications of the evolving characteristics of bio-molecular networks, such as reengineering of particular networks for technological, synthetic or pharmacological purposes.","Proteins,
Indexes,
Vectors,
Complex networks,
Biomedical measurement,
Evolution (biology)"
Resilience Analysis of Power Grids Under the Sequential Attack,"The modern society increasingly relies on electrical service, which also brings risks of catastrophic consequences, e.g., large-scale blackouts. In the current literature, researchers reveal the vulnerability of power grids under the assumption that substations/transmission lines are removed or attacked synchronously. In reality, however, it is highly possible that such removals can be conducted sequentially. Motivated by this idea, we discover a new attack scenario, called the sequential attack, which assumes that substations/transmission lines can be removed sequentially, not synchronously. In particular, we find that the sequential attack can discover many combinations of substation whose failures can cause large blackout size. Previously, these combinations are ignored by the synchronous attack. In addition, we propose a new metric, called the sequential attack graph (SAG), and a practical attack strategy based on SAG. In simulations, we adopt three test benchmarks and five comparison schemes. Referring to simulation results and complexity analysis, we find that the proposed scheme has strong performance and low complexity.","Power grids,
Power system security,
Power system protection,
Substations,
Power transmission lines,
Complexity theory"
Visualizing Mobility of Public Transportation System,"Public transportation systems (PTSs) play an important role in modern cities, providing shared/massive transportation services that are essential for the general public. However, due to their increasing complexity, designing effective methods to visualize and explore PTS is highly challenging. Most existing techniques employ network visualization methods and focus on showing the network topology across stops while ignoring various mobility-related factors such as riding time, transfer time, waiting time, and round-the-clock patterns. This work aims to visualize and explore passenger mobility in a PTS with a family of analytical tasks based on inputs from transportation researchers. After exploring different design alternatives, we come up with an integrated solution with three visualization modules: isochrone map view for geographical information, isotime flow map view for effective temporal information comparison and manipulation, and OD-pair journey view for detailed visual analysis of mobility factors along routes between specific origin-destination pairs. The isotime flow map linearizes a flow map into a parallel isoline representation, maximizing the visualization of mobility information along the horizontal time axis while presenting clear and smooth pathways from origin to destinations. Moreover, we devise several interactive visual query methods for users to easily explore the dynamics of PTS mobility over space and time. Lastly, we also construct a PTS mobility model from millions of real passenger trajectories, and evaluate our visualization techniques with assorted case studies with the transportation researchers.","Transportation,
Data visualization,
Urban areas,
Visual analytics,
Schedules,
Radiofrequency identification,
Urban areas"
Lung Nodule Classification With Multilevel Patch-Based Context Analysis,"In this paper, we propose a novel classification method for the four types of lung nodules, i.e., well-circumscribed, vascularized, juxta-pleural, and pleural-tail, in low dose computed tomography scans. The proposed method is based on contextual analysis by combining the lung nodule and surrounding anatomical structures, and has three main stages: an adaptive patch-based division is used to construct concentric multilevel partition; then, a new feature set is designed to incorporate intensity, texture, and gradient information for image patch feature description, and then a contextual latent semantic analysis-based classifier is designed to calculate the probabilistic estimations for the relevant images. Our proposed method was evaluated on a publicly available dataset and clearly demonstrated promising classification performance.","Lungs,
Feature extraction,
Educational institutions,
Context,
Anatomical structure,
Histograms,
Shape"
The Faces of Engagement: Automatic Recognition of Student Engagementfrom Facial Expressions,"Student engagement is a key concept in contemporary education, where it is valued as a goal in its own right. In this paper we explore approaches for automatic recognition of engagement from students' facial expressions. We studied whether human observers can reliably judge engagement from the face; analyzed the signals observers use to make these judgments; and automated the process using machine learning. We found that human observers reliably agree when discriminating low versus high degrees of engagement (Cohen's κ = 0.96). When fine discrimination is required (four distinct levels) the reliability decreases, but is still quite high ( κ = 0.56). Furthermore, we found that engagement labels of 10-second video clips can be reliably predicted from the average labels of their constituent frames (Pearson r=0.85), suggesting that static expressions contain the bulk of the information used by observers. We used machine learning to develop automatic engagement detectors and found that for binary classification (e.g., high engagement versus low engagement), automated engagement detectors perform with comparable accuracy to humans. Finally, we show that both human and automatic engagement judgments correlate with task performance. In our experiment, student post-test performance was predicted with comparable accuracy from engagement labels ( r=0.47) as from pre-test scores ( r=0.44).","Training,
Labeling,
Games,
Software,
Tablet computers,
Observers,
Reliability"
Face-to-Face Proximity EstimationUsing Bluetooth On Smartphones,"The availability of “always-on” communications has tremendous implications for how people interact socially. In particular, sociologists are interested in the question if such pervasive access increases or decreases face-to-face interactions. Unlike triangulation which seeks to precisely define position, the question of face-to-face interaction reduces to one of proximity, i.e., are the individuals within a certain distance? Moreover, the problem of proximity estimation is complicated by the fact that the measurement must be quite precise (1-1.5 m) and can cover a wide variety of environments. Existing approaches such as GPS and Wi-Fi triangulation are insufficient to meet the requirements of accuracy and flexibility. In contrast, Bluetooth, which is commonly available on most smartphones, provides a compelling alternative for proximity estimation. In this paper, we demonstrate through experimental studies the efficacy of Bluetooth for this exact purpose. We propose a proximity estimation model to determine the distance based on the RSSI values of Bluetooth and light sensor data in different environments. We present several real world scenarios and explore Bluetooth proximity estimation on Android with respect to accuracy and power consumption.","Bluetooth,
Estimation,
Smart phones,
Accuracy,
IEEE 802.11 Standards,
Global Positioning System,
Batteries"
Patlak Image Estimation From Dual Time-Point List-Mode PET Data,"We investigate using dual time-point PET data to perform Patlak modeling. This approach can be used for whole body dynamic PET studies in which we compute voxel-wise estimates of Patlak parameters using two frames of data for each bed position. Our approach directly uses list-mode arrival times for each event to estimate the Patlak parametric image. We use a penalized likelihood method in which the penalty function uses spatially variant weighting to ensure a count independent local impulse response. We evaluate performance of the method in comparison to fractional changes in SUV values (%DSUV) between the two frames using Cramer Rao analysis and Monte Carlo simulation. Receiver operating characteristic (ROC) curves are used to compare performance in differentiating tumors relative to background based on the dynamic data sets. Using area under the ROC curve as a performance metric, we show superior performance of Patlak relative to %DSUV over a range of dynamic data sets and parameters. These results suggest that Patlak analysis may be appropriate for analysis of dual time-point whole body PET data and could lead to superior detection of tumors relative to %DSUV metrics.","Approximation methods,
Positron emission tomography,
Image reconstruction,
Image resolution,
Estimation,
Computational modeling,
Data models"
Symbol Interval Optimization for Molecular Communication With Drift,"In this paper, we propose a symbol interval optimization algorithm in molecular communication with drift. Proper symbol intervals are important in practical communication systems since information needs to be sent as fast as possible with low error rates. There is a trade-off, however, between symbol intervals and inter-symbol interference (ISI) from Brownian motion. Thus, we find proper symbol interval values considering the ISI inside two kinds of blood vessels, and also suggest no ISI system for strong drift models. Finally, an isomer-based molecule shift keying (IMoSK) is applied to calculate achievable data transmission rates (achievable rates, hereafter). Normalized achievable rates are also obtained and compared in one-symbol ISI and no ISI systems.","Receivers,
Transmitters,
Molecular communication,
Gaussian distribution,
Modulation,
Biological system modeling,
Nanobioscience"
Generic Node Removal for Factor-Graph SLAM,"This paper reports on a generic factor-based method for node removal in factor-graph simultaneous localization and mapping (SLAM), which we call generic linear constraints (GLCs). The need for a generic node removal tool is motivated by long-term SLAM applications, whereby nodes are removed in order to control the computational cost of graph optimization. GLC is able to produce a new set of linearized factors over the elimination clique that can represent either the true marginalization (i.e., dense GLC) or a sparse approximation of the true marginalization using a ChowLiu tree (i.e., sparse GLC). The proposed algorithm improves upon commonly used methods in two key ways: First, it is not limited to graphs with strictly full-state relative-pose factors and works equally well with other low-rank factors, such as those produced by monocular vision. Second, the new factors are produced in such a way that accounts for measurement correlation, which is a problem encountered in other methods that rely strictly upon pairwise measurement composition. We evaluate the proposed method over multiple real-world SLAM graphs and show that it outperforms other recently proposed methods in terms of Kullback-Leibler divergence. Additionally, we experimentally demonstrate that the proposed GLC method provides a principled and flexible tool to control the computational complexity of long-term graph SLAM, with results shown for 34.9 h of real-world indoor-outdoor data covering 147.4 km collected over 27 mapping sessions spanning a period of 15 months.","Simultaneous localization and mapping,
Optimization,
Approximation methods,
Correlation,
Mobile robots"
Rate-0.96 LDPC Decoding VLSI for Soft-Decision Error Correction of NAND Flash Memory,"The reliability of data stored in high-density Flash memory devices tends to decrease rapidly because of the reduced cell size and multilevel cell technology. Soft-decision error correction algorithms that use multiple-precision sensing for reading memory can solve this problem; however, they require very complex hardware for high-throughput decoding. In this paper, we present a rate-0.96 (68254, 65536) shortened Euclidean geometry low-density parity-check code and its VLSI implementation for high-throughput NAND Flash memory systems. The design employs the normalized a posteriori probability (APP)-based algorithm, serial schedule, and conditional update, which lead to simple functional units, halved decoding iterations, and low-power consumption, respectively. A pipelined-parallel architecture is adopted for high-throughput decoding, and memory-reduction techniques are employed to minimize the chip size. The proposed decoder is implemented in 0.13-μm CMOS technology, and the chip size and energy consumption of the decoder are compared with those of a BCH (Bose-Chaudhuri-Hocquenghem) decoding circuit showing comparable error-correcting performance and throughput.","CMOS memory circuits,
decoding,
error correction,
flash memories,
NAND circuits,
parity check codes,
probability,
VLSI"
Analysis of Human Grasping Behavior: Object Characteristics and Grasp Type,"This paper is the first of a two-part series analyzing human grasping behavior during a wide range of unstructured tasks. The results help clarify overall characteristics of human hand to inform many domains, such as the design of robotic manipulators, targeting rehabilitation toward important hand functionality, and designing haptic devices for use by the hand. It investigates the properties of objects grasped by two housekeepers and two machinists during the course of almost 10,000 grasp instances and correlates the grasp types used to the properties of the object. We establish an object classification that assigns each object properties from a set of seven classes, including mass, shape and size of the grasp location, grasped dimension, rigidity, and roundness. The results showed that 55 percent of grasped objects had at least one dimension larger than 15 cm, suggesting that more than half of objects cannot physically be grasped using their largest axis. Ninety-two percent of objects had a mass of 500 g or less, implying that a high payload capacity may be unnecessary to accomplish a large subset of human grasping behavior. In terms of grasps, 96 percent of grasp locations were 7 cm or less in width, which can help to define requirements for hand rehabilitation and defines a reasonable grasp aperture size for a robotic hand. Subjects grasped the smallest overall major dimension of the object in 94 percent of the instances. This suggests that grasping the smallest axis of an object could be a reliable default behavior to implement in grasp planners.","Grasping,
Shape,
Robots,
Force,
Thumb,
Joints"
The Random Cluster Model for Robust Geometric Fitting,"Random hypothesis generation is central to robust geometric model fitting in computer vision. The predominant technique is to randomly sample minimal subsets of the data, and hypothesize the geometric models from the selected subsets. While taking minimal subsets increases the chance of successively “hitting” inliers in a sample, hypotheses fitted on minimal subsets may be severely biased due to the influence of measurement noise, even if the minimal subsets contain purely inliers. In this paper we propose Random Cluster Models, a technique used to simulate coupled spin systems, to conduct hypothesis generation using subsets larger than minimal. We show how large clusters of data from genuine instances of the model can be efficiently harvested to produce accurate hypotheses that are less affected by the vagaries of fitting on minimal subsets. A second aspect of the problem is the optimization of the set of structures that best fit the data. We show how our novel hypothesis sampler can be integrated seamlessly with graph cuts under a simple annealing framework to optimize the fitting efficiently. Unlike previous methods that conduct hypothesis sampling and fitting optimization in two disjoint stages, our algorithm performs the two subtasks alternatingly and in a mutually reinforcing manner. Experimental results show clear improvements in overall efficiency.","Data models,
Optimization,
Computational modeling,
Labeling,
Robustness,
Generators,
Accuracy"
"Group Secret Key Generation via Received Signal Strength: Protocols, Achievable Rates, and Implementation","Secret key generation among wireless devices using physical layer information of radio channel has been an attractive alternative for ensuring security in mobile environments. Received signal strength (RSS) based secret key extraction gains much attention due to its easy accessibility in wireless infrastructure. However, the problem of using RSS to generate keys among multiple devices to ensure secure group communication in practice remains open. In this work, we propose a framework for collaborative key generation among multiple wireless devices leveraging RSS. To deal with mobile devices not within each other's communication range, we employ relay nodes to achieve reliable key extraction. To enable secure group communication, two protocols are developed to perform collaborative group key generation via star and chain topologies respectively. We further provide the theoretic analysis on the achievable secrecy rate for both star and chain topologies in the presence of an eavesdropper. Our prototype development using MICAz motes and extensive experiments using fading trend based key extraction demonstrate the feasibility of using RSS for group key generation in both indoor and outdoor environments, and concurrently achieving a lower bit mismatch rate compared to existing studies.","Wireless communication,
Communication system security,
Radio communication,
Relays,
Protocols,
Collaboration,
Fading channels"
Privacy Preserving Delegated Access Control in Public Clouds,"Current approaches to enforce fine-grained access control on confidential data hosted in the cloud are based on fine-grained encryption of the data. Under such approaches, data owners are in charge of encrypting the data before uploading them on the cloud and re-encrypting the data whenever user credentials change. Data owners thus incur high communication and computation costs. A better approach should delegate the enforcement of fine-grained access control to the cloud, so to minimize the overhead at the data owners, while assuring data confidentiality from the cloud. We propose an approach, based on two layers of encryption, that addresses such requirement. Under our approach, the data owner performs a coarse-grained encryption, whereas the cloud performs a fine-grained encryption on top of the owner encrypted data. A challenging issue is how to decompose access control policies (ACPs) such that the two layer encryption can be performed. We show that this problem is NP-complete and propose novel optimization algorithms. We utilize an efficient group key management scheme that supports expressive ACPs. Our system assures the confidentiality of the data and preserves the privacy of users from the cloud while delegating most of the access control enforcement to the cloud.","Encryption,
Access control,
Cloud computing,
Protocols,
Privacy"
Stackelberg Game for Bandwidth Allocation in Cloud-Based Wireless Live-Streaming Social Networks,"Multimedia social networks have been introduced as a new technology to enrich people's lives through enhanced multimedia distribution. On the other hand, a media cloud system can perform multimedia processing and storage, and provide heterogeneous multimedia services. However, the challenges still remain for end users (e.g., mobile devices and PCs) to receive multimedia streaming from the cloud system with satisfied quality-of-service (QoS). To address these challenges, an efficient multimedia distribution approach taking advantage of live-streaming social networks is innovated in this paper to deliver the media services from the cloud to both desktop and wireless end users. Our approach allows bandwidth limited mobile users to acquire live multimedia streaming from desktop users, directly based on their social relationships rather than from the cloud. When a number of mobile users compete for limited bandwidth access with the desktop users, a bandwidth allocation problem must be solved to meet all users' QoS requirements in the live-streaming social network. We formulate the problem as a two-stage Stackelberg game, in which both desktop users and mobile users target at maximizing their utilities. In our study, a noncooperative game is used to model the competition among the desktop users in terms of shared bandwidth and price in the first stage of the game. The second stage of the game models the behavior of a mobile user selecting the desktop users by an evolutionary game. In addition, a case study is conducted following the general Stackelberg game formulation, where the existence of a unique Nash equilibrium is proved. Based on our game modeling, we design protocols for both desktop and mobile users and evaluate them with numerical examples.","cloud computing,
evolutionary computation,
game theory,
multimedia computing,
quality of service,
social networking (online)"
Quantitative Gait Measurement With Pulse-Doppler Radar for Passive In-Home Gait Assessment,"In this paper, we propose a pulse-Doppler radar system for in-home gait assessment of older adults. A methodology has been developed to extract gait parameters including walking speed and step time using Doppler radar. The gait parameters have been validated with a Vicon motion capture system in the lab with 13 participants and 158 test runs. The study revealed that for an optimal step recognition and walking speed estimation, a dual radar set up with one radar placed at foot level and the other at torso level is necessary. An excellent absolute agreement with intraclass correlation coefficients of 0.97 was found for step time estimation with the foot level radar. For walking speed, although both radars show excellent consistency they all have a system offset compared to the ground truth due to walking direction with respect to the radar beam. The torso level radar has a better performance (9% offset on average) in the speed estimation compared to the foot level radar (13%-18% offset). Quantitative analysis has been performed to compute the angles causing the systematic error. These lab results demonstrate the capability of the system to be used as a daily gait assessment tool in home environments, useful for fall risk assessment and other health care applications. The system is currently being tested in an unstructured home environment.","Legged locomotion,
Doppler radar,
Torso,
Spectrogram,
Time-frequency analysis,
Monitoring"
Wireless Tissue Palpation for Intraoperative Detection of Lumps in the Soft Tissue,"In an open surgery, identification of precise margins for curative tissue resection is performed by manual palpation. This is not the case for minimally invasive and robotic procedures, where tactile feedback is either distorted or not available. In this paper, we introduce the concept of intraoperative wireless tissue palpation. The wireless palpation probe (WPP) is a cylindrical device (15 mm in diameter, 60 mm in length) that can be deployed through a trocar incision and directly controlled by the surgeon to create a volumetric stiffness distribution map of the region of interest. This map can then be used to guide the tissue resection to minimize healthy tissue loss. The wireless operation prevents the need for a dedicated port and reduces the chance of instrument clashing in the operating field. The WPP is able to measure in real time the indentation pressure with a sensitivity of 34 Pa, the indentation depth with an accuracy of 0.68 mm, and the probe position with a maximum error of 11.3 mm in a tridimensional workspace. The WPP was assessed on the benchtop in detecting the local stiffness of two different silicone tissue simulators (elastic modulus ranging from 45 to 220 kPa), showing a maximum relative error below 5%. Then, in vivo trials were aimed to identify an agar-gel lump injected into a porcine liver and to assess the device usability within the frame of a laparoscopic procedure. The stiffness map created intraoperatively by the WPP was compared with a map generated ex vivo by a standard uniaxial material tester, showing less than 8% local stiffness error at the site of the lump.","Wireless communication,
Wireless sensor networks,
Surgery,
Probes,
Robots,
Transceivers,
Real-time systems"
A Tensor-Based Approach for Big Data Representation and Dimensionality Reduction,"Variety and veracity are two distinct characteristics of large-scale and heterogeneous data. It has been a great challenge to efficiently represent and process big data with a unified scheme. In this paper, a unified tensor model is proposed to represent the unstructured, semistructured, and structured data. With tensor extension operator, various types of data are represented as subtensors and then are merged to a unified tensor. In order to extract the core tensor which is small but contains valuable information, an incremental high order singular value decomposition (IHOSVD) method is presented. By recursively applying the incremental matrix decomposition algorithm, IHOSVD is able to update the orthogonal bases and compute the new core tensor. Analyzes in terms of time complexity, memory usage, and approximation accuracy of the proposed method are provided in this paper. A case study illustrates that approximate data reconstructed from the core set containing 18% elements can guarantee 93% accuracy in general. Theoretical analyzes and experimental results demonstrate that the proposed unified tensor model and IHOSVD method are efficient for big data representation and dimensionality reduction.",
A Thickness-Mode AlGaN/GaN Resonant Body High Electron Mobility Transistor,"A multigigahertz AlGaN/GaN resonant body transistor (RBT) is reported, wherein the mechanical resonance and electrical signal modulation are achieved simultaneously. A 175-Å-thick AlGaN layer is used as the piezoelectric transduction layer, and the 2-D electron gas present at the AlGaN/GaN interface is employed as the bottom electrode as well as the transistor conducting channel. The carrier concentration of the channel is modulated when the device undergoes acoustic strain. A quality factor of 250 and acoustic transconductance of 25 μS is achieved at resonance frequency of 4.23 GHz, marking the highest frequency and highest transconductance reported to date for GaN-based RBTs. The frequency×Q of this device is among the best reported for GaN-based resonators.","Logic gates,
Gallium nitride,
Aluminum gallium nitride,
Acoustics,
Transconductance,
HEMTs,
Electrodes"
MOSDEN: An Internet of Things Middleware for Resource Constrained Mobile Devices,"The Internet of Things (IoT) is part of Future Internet and will comprise many billions of Internet Connected Objects (ICO) or `things' where things can sense, communicate, compute and potentially actuate as well as have intelligence, multi-modal interfaces, physical/ virtual identities and attributes. Collecting data from these objects is an important task as it allows software systems to understand the environment better. Many different hardware devices may involve in the process of collecting and uploading sensor data to the cloud where complex processing can occur. Further, we cannot expect all these objects to be connected to the computers due to technical and economical reasons. Therefore, we should be able to utilize resource constrained devices to collect data from these ICOs. On the other hand, it is critical to process the collected sensor data before sending them to the cloud to make sure the sustainability of the infrastructure due to energy constraints. This requires to move the sensor data processing tasks towards the resource constrained computational devices (e.g. mobile phones). In this paper, we propose Mobile Sensor Data Processing Engine (MOSDEN), an plug-in-based IoT middleware for mobile devices, that allows to collect and process sensor data without programming efforts. Our architecture also supports sensing as a service model. We present the results of the evaluations that demonstrate its suitability towards real world deployments. Our proposed middleware is built on Android platform.","Middleware,
Computer architecture,
Internet,
Sensors,
Data processing,
Smart phones"
Toward safe close-proximity human-robot interaction with standard industrial robots,"Allowing humans and robots to interact in close proximity to each other has great potential for increasing the effectiveness of human-robot teams across a large variety of domains. However, as we move toward enabling humans and robots to interact at ever-decreasing distances of separation, effective safety technologies must also be developed. While new, inherently human-safe robot designs have been established, millions of industrial robots are already deployed worldwide, which makes it attractive to develop technologies that can turn these standard industrial robots into human-safe platforms. In this work, we present a real-time safety system capable of allowing safe human-robot interaction at very low distances of separation, without the need for robot hardware modification or replacement. By leveraging known robot joint angle values and accurate measurements of human positioning in the workspace, we can achieve precise robot speed adjustment by utilizing real-time measurements of separation distance. This, in turn, allows for collision prevention in a manner comfortable for the human user.We demonstrate our system achieves latencies below 9.64 ms with 95% probability, 11.10 ms with 99% probability, and 14.08 ms with 99.99% probability, resulting in robust real-time performance.","Safety,
Service robots,
Robot sensing systems,
Robot kinematics,
Standards,
Collision avoidance"
Tree Filtering: Efficient Structure-Preserving Smoothing With a Minimum Spanning Tree,"We present a new efficient edge-preserving filter-“tree filter”-to achieve strong image smoothing. The proposed filter can smooth out high-contrast details while preserving major edges, which is not achievable for bilateral-filter-like techniques. Tree filter is a weighted-average filter, whose kernel is derived by viewing pixel affinity in a probabilistic framework simultaneously considering pixel spatial distance, color/intensity difference, as well as connectedness. Pixel connectedness is acquired by treating pixels as nodes in a minimum spanning tree (MST) extracted from the image. The fact that an MST makes all image pixels connected through the tree endues the filter with the power to smooth out high-contrast, fine-scale details while preserving major image structures, since pixels in small isolated region will be closely connected to surrounding majority pixels through the tree, while pixels inside large homogeneous region will be automatically dragged away from pixels outside the region. The tree filter can be separated into two other filters, both of which turn out to have fast algorithms. We also propose an efficient linear time MST extraction algorithm to further improve the whole filtering speed. The algorithms give tree filter a great advantage in low computational complexity (linear to number of image pixels) and fast speed: it can process a 1-megapixel 8-bit image at ~ 0.25 s on an Intel 3.4 GHz Core i7 CPU (including the construction of MST). The proposed tree filter is demonstrated on a variety of applications.",
Density Sensitive Hashing,"Nearest neighbor search is a fundamental problem in various research fields like machine learning, data mining and pattern recognition. Recently, hashing-based approaches, for example, locality sensitive hashing (LSH), are proved to be effective for scalable high dimensional nearest neighbor search. Many hashing algorithms found their theoretic root in random projection. Since these algorithms generate the hash tables (projections) randomly, a large number of hash tables (i.e., long codewords) are required in order to achieve both high precision and recall. To address this limitation, we propose a novel hashing algorithm called density sensitive hashing (DSH) in this paper. DSH can be regarded as an extension of LSH. By exploring the geometric structure of the data, DSH avoids the purely random projections selection and uses those projective functions which best agree with the distribution of the data. Extensive experimental results on real-world data sets have shown that the proposed method achieves better performance compared to the state-of-the-art hashing approaches.",
Modeling and Validating E-Commerce Business Process Based on Petri Nets,"E-commerce and online shopping with a third-party payment platform have rapidly developed recently, and encountered many fault tolerance and security problems concerned by users. The causes of these problems include malicious behavior and imperfect business processes. The latter lead to the emergence of security vulnerabilities and loss of user funds which become more and more serious these years. We focus on the business process of e-commerce, and propose a formal model for constructing an e-commerce business process called an E-commerce Business Process Net. It integrates both data and control flows based on Petri nets. Rationality and transaction consistency are defined and validated to guarantee the transaction properties of an e-commerce business process. This paper offers a complete methodology for modeling and validating an e-commerce system with a third-party payment platform from the view point of a business process. Its use enables a designer to identify errors early in the design process and correct them before the deployment phase. In order to demonstrate the applicability and feasibility of the methodology, we have modeled and validated a real-world e-commerce business process and discovered the problems that cause the violation of transaction properties.",
Knowledge-based fast evolutionary MCTS for general video game playing,"General Video Game Playing is a game AI domain in which the usage of game-dependent domain knowledge is very limited or even non existent. This imposes obvious difficulties when seeking to create agents able to play sets of different games. Taken more broadly, this issue can be used as an introduction to the field of General Artificial Intelligence. This paper explores the performance of a vanilla Monte Carlo Tree Search algorithm, and analyzes the main difficulties encountered when tackling this kind of scenarios. Modifications are proposed to overcome these issues, strengthening the algorithm's ability to gather and discover knowledge, and taking advantage of past experiences. Results show that the performance of the algorithm is significantly improved, although there remain unresolved problems that require further research. The framework employed in this research is publicly available and will be used in the General Video Game Playing competition at the IEEE Conference on Computational Intelligence and Games in 2014.","Games,
Missiles,
Cities and towns,
Portals,
Navigation"
QoS-Guaranteed Bandwidth Shifting and Redistribution in Mobile Cloud Environment,"Mobile cloud computing (MCC) improves the computational capabilities of resource-constrained mobile devices. On the other hand, the mobile users demand a certain level of quality-of-service (QoS) provisioning while they use services from the cloud, even if the interfacing gateway changes due to the mobility of the users. In this paper, we identify, formulate, and address the problem of QoS-guaranteed bandwidth shifting and redistribution among the interfacing gateways for maximizing their utility. Due to node mobility, bandwidth shifting is required for providing QoS-guarantee to the mobile nodes. However, shifting alone is not always sufficient for maintaining QoS-guarantee because of varying spectral efficiency across the associated channels, coupled with the corresponding protocol overhead involved with the computation of utility. We formulate bandwidth redistribution as a utility maximization problem, and solve it using a modified descending bid auction. In the proposed scheme, named as AQUM, each gateway aggregates the demands of all the connecting mobile nodes and makes a bid for the required amount of bandwidth. We investigate the existence of Nash equilibrium (NE) in the proposed solution. Theoretically, we deduce the maximum and minimum selling prices of bandwidth, and prove the convergence of AQUM. Simulation results establish the correctness of the proposed algorithm.",
Incremental Fuzzy Clustering With Multiple Medoids for Large Data,"As an important technique of data analysis, clustering plays an important role in finding the underlying pattern structure embedded in unlabeled data. Clustering algorithms that need to store all the data into the memory for analysis become infeasible when the dataset is too large to be stored. To handle such large data, incremental clustering approaches are proposed. The key idea behind these approaches is to find representatives (centroids or medoids) to represent each cluster in each data chunk, which is a packet of the data, and final data analysis is carried out based on those identified representatives from all the chunks. In this paper, we propose a new incremental clustering approach called incremental multiple medoids-based fuzzy clustering (IMMFC) to handle complex patterns that are not compact and well separated. We would like to investigate whether IMMFC is a good alternative to capturing the underlying data structure more accurately. IMMFC not only facilitates the selection of multiple medoids for each cluster in a data chunk, but also has the mechanism to make use of relationships among those identified medoids as side information to help the final data clustering process. The detailed problem formulation, updating rules derivation, and the in-depth analysis of the proposed IMMFC are provided. Experimental studies on several large datasets that include real world malware datasets have been conducted. IMMFC outperforms existing incremental fuzzy clustering approaches in terms of clustering accuracy and robustness to the order of data. These results demonstrate the great potential of IMMFC for large-data analysis.","Clustering algorithms,
Linear programming,
TV,
Algorithm design and analysis,
Data analysis,
Vectors,
Time complexity"
Uncertainty Management in Differential Evolution Induced Multiobjective Optimization in Presence of Measurement Noise,"This paper aims to design new strategies to extend traditional multiobjective optimization algorithms to efficiently obtain Pareto-optimal solutions in presence of noise on the objective surfaces. The first strategy, referred to as adaptive selection of sample size, is employed to balance the tradeoff between quality measure of fitness and run-time complexity. The second strategy is concerned with determining statistical expectation, instead of conventional averaging, of fitness samples as the measure of fitness of the trial solutions. The third strategy attempts to extend Goldberg's method to compare slightly worse trial solutions with its competitor by a more statistically viable comparator to examine possible placement of the former solution in the Pareto optimal front. The traditional differential evolution for multiobjective optimization algorithm has been modified by extending its selection step with the proposed strategies. Experiments undertaken to study the performance of the extended algorithm reveal that the extended algorithm outperforms its competitors with respect to three performance metrics, when examined on a test suite of 23 standard benchmarks with additive noise of three statistical distributions. The extended algorithm has been applied on the well known box-pushing problem, where the forces and torques required to shift the box by two robots are evaluated to jointly satisfy the conflicting objectives on task-execution time and energy consumption in presence of noise on range estimates from the sidewalls of the workspace. The application justifies the importance of the proposed noise-handling strategies in practical systems.","Noise measurement,
Noise,
Linear programming,
Pollution measurement,
Sociology,
Statistics,
Optimization"
Algorithms and Experiments on Flocking of Multiagents in a Bounded Space,"In most scenarios encountered in both natural systems and engineering applications, collective motions are always confined in a bounded space. The conventional flocking formulation with velocity consensus does not apply in these scenarios as agents with a constant velocity that unavoidably move out of any bounded space. In this brief, the conventional flocking formulation and algorithms are generalized to address the issues caused by bouncing boundaries of a bounded space. In addition, the theoretical design was successfully implemented in a group of real robots such that it experimentally achieved a desired flock in a bounded space.","Aerospace electronics,
Synchronization,
Joints,
Robot kinematics,
Trajectory,
Algorithm design and analysis"
Integration of Network Topological and Connectivity Properties for Neuroimaging Classification,"Rapid advances in neuroimaging techniques have provided an efficient and noninvasive way for exploring the structural and functional connectivity of the human brain. Quantitative measurement of abnormality of brain connectivity in patients with neurodegenerative diseases, such as mild cognitive impairment (MCI) and Alzheimer's disease (AD), have also been widely reported, especially at a group level. Recently, machine learning techniques have been applied to the study of AD and MCI, i.e., to identify the individuals with AD/MCI from the healthy controls (HCs). However, most existing methods focus on using only a single property of a connectivity network, although multiple network properties, such as local connectivity and global topological properties, can potentially be used. In this paper, by employing multikernel based approach, we propose a novel connectivity based framework to integrate multiple properties of connectivity network for improving the classification performance. Specifically, two different types of kernels (i.e., vector-based kernel and graph kernel) are used to quantify two different yet complementary properties of the network, i.e., local connectivity and global topological properties. Then, multikernel learning (MKL) technique is adopted to fuse these heterogeneous kernels for neuroimaging classification. We test the performance of our proposed method on two different data sets. First, we test it on the functional connectivity networks of 12 MCI and 25 HC subjects. The results show that our method achieves significant performance improvement over those using only one type of network property. Specifically, our method achieves a classification accuracy of 91.9%, which is 10.8% better than those by single network-property-based methods. Then, we test our method for gender classification on a large set of functional connectivity networks with 133 infants scanned at birth, 1 year, and 2 years, also demonstrating very promising results.","Kernel,
Feature extraction,
Support vector machines,
Diseases,
Neuroimaging,
Educational institutions,
Time series analysis"
"Design of a low-latency, high-reliability wireless communication system for control applications","High-performance industrial control systems with tens to hundreds of sensors and actuators use wired connections between all of their components because they require low-latency, high-reliability links to maintain stability; however, the wires cause many mechanical problems that moving to wireless links would solve. No existing or proposed wireless system can achieve the latency and reliability required by the control algorithms because they are designed for either high-throughput or low-power communication between a pair or a small number of terminals. A preliminary wireless system architecture is proposed that focuses on low-latency operation through the use of reliable broadcasting, semi-fixed resource allocation, and low-rate coding. For an industrial printer application with 30 nodes in the control loop and a moderate information throughput of 4.8Mb/s, the system can achieve latencies under 2ms for SNRs above 7dB.","Wireless communication,
Wireless sensor networks,
Sensors,
Actuators,
Reliability,
Standards"
Design and Assessment of a Depth-Fused Multi-Focal-Plane Display Prototype,"Depth-fused multi-focal-plane display was proposed to create a fixed-viewpoint volumetric display capable of rendering correct or nearly-correct focus cues in a stereoscopic display through a small number of discretely placed focal planes. It may effectively address the negative effects of conventional stereoscopic displays on depth perception accuracy and visual fatigue due to the lack of focus cues. In this paper, we presented the design and assessment of a novel depth-fused six-focal plane display prototype, capable of rendering nearly-accurate focus cues for a depth range of 3 diopters with high image quality at flicker-free speed. The optical system design, prototype implementation and demonstration, and experimental assessment of the prototype were discussed in detail.","Three-dimensional displays,
Lenses,
Prototypes,
Retina,
Optical imaging,
Mirrors,
Stereo image processing"
A Floating Memristor Emulator Based Relaxation Oscillator,"In this paper, a flux-controlled memristor emulator with floating terminals by making use of four current conveyors is newly proposed. By replacing the three resistors in the positive and negative feedback loops of a typical relaxation oscillator respectively, three cases of memristor emulator based oscillating circuits are theoretically constructed and mathematically analyzed. To further probe the practicability and inherent features of the new memristor emulator and oscillator, experimental tests are carried out and the measured experimental results show differences from typical relaxation oscillators, this new memristor emulator based oscillator can provide novel and steady oscillating behaviors. The comparison of measured data with theoretical analysis is in good agreement, which further confirms the practicability of this new memristor emulator and oscillator.",
"Electrical Characteristics of n, p-In0.53Ga0.47As MOSCAPs With In Situ PEALD-AlN Interfacial Passivation Layer","The effects of plasma enhanced atomic layer deposition (PEALD)-AlN interfacial passivation layer (IPL) on the Al2O3/In0.53Ga0.47As interfaces qualities are studied with different plasma powers. The improvement in electrical properties, including capacitance-voltage (C-V) hysteresis, frequency dispersion, and interface state densities (Dit) are demonstrated on the Al2O3/n, p-In0.53Ga0.47As MOS capacitors. The excellent C-V behaviors are observed on both type of In0.53Ga0.47As-based MOS devices by performing a thin AlN-IPL at the plasma power of 150 W. To explore the interaction between PEALD-AlN layer and In0.53Ga0.47As surface, X-ray photoelectron spectroscopy and high-resolution transmission electron microscopy analyses have also been characterized.","Passivation,
Plasmas,
III-V semiconductor materials,
Aluminum oxide,
Educational institutions,
High K dielectric materials"
How to achieve the capacity of asymmetric channels,"We describe coding techniques that achieve the capacity of a discrete memoryless asymmetric channel. To do so, we discuss how recent advances in coding for symmetric channels yield more efficient solutions also for the asymmetric case. In more detail, we consider three basic approaches. The first one is Gallager's scheme that concatenates a linear code with a non-linear mapper, in order to bias the input distribution. We explicitly show that both polar codes and spatially coupled codes can be employed in this scenario. Further, we derive a scaling law between the gap to capacity, the cardinality of channel input and output alphabets, and the required size of the mapper. The second one is an integrated approach in which the coding scheme is used both for source coding, in order to create codewords with the capacity-achieving distribution, and for channel coding, in order to provide error protection. Such a technique has been recently introduced by Honda and Yamamoto in the context of polar codes, and we show how to apply it also to the design of sparse graph codes. The third approach is based on an idea due to Böcherer and Mathar and separates completely the two tasks of source coding and channel coding by “chaining” together several codewords. We prove that we can combine any suitable source code with any suitable channel code in order to provide optimal schemes for asymmetric channels. In particular, polar codes and spatially coupled codes fulfill the required conditions.","Parity check codes,
Source coding,
Channel coding,
Receivers,
Channel capacity,
Transmitters"
Gabor-Based Nonuniform Scale-Frequency Map for Environmental Sound Classification in Home Automation,"This work presents a novel feature extraction approach called nonuniform scale-frequency map for environmental sound classification in home automation. For each audio frame, important atoms from the Gabor dictionary are selected by using the Matching Pursuit algorithm. After the system disregards phase and position information, the scale and frequency of the atoms are extracted to construct a scale-frequency map. Principal Component Analysis (PCA) and Linear Discriminate Analysis (LDA) are then applied to the scale-frequency map, subsequently generating the proposed feature. During the classification phase, a segment-level multiclass Support Vector Machine (SVM) is operated. Experiments on a 17-class sound database indicate that the proposed approach can achieve an accuracy rate of 86.21%. Furthermore, a comparison reveals that the proposed approach is superior to the other time-frequency methods.","Atomic clocks,
Accuracy,
Matching pursuit algorithms,
Feature extraction,
Dictionaries,
Support vector machines,
Principal component analysis"
"Workload Analysis, Implications, and Optimization on a Production Hadoop Cluster: A Case Study on Taobao","Understanding the characteristics of MapReduce workloads in a Hadoop cluster is the key to making optimal configuration decisions and improving the system efficiency and throughput. However, workload analysis on a Hadoop cluster, particularly in a large-scale e-commerce production environment, has not been well studied yet. In this paper, we performed a comprehensive workload analysis using the trace collected from a 2000-node Hadoop cluster at Taobao, which is the biggest online e-commerce enterprise in Asia, ranked 10th in the world as reported by Alexa. The results of the workload analysis are representative and generally consistent with the data warehouses for e-commerce web sites, which can help researchers and engineers understand the workload characteristics of Hadoop in their production environments. Based on the observations and implications derived from the trace, we designed a workload generator Ankus, to expedite the performance evaluation and debugging of new mechanisms. Ankus supports synthesizing an e-commerce style MapReduce workload at a low cost. Furthermore, we proposed and implemented a job scheduling algorithm, Fair4S , which is designed to be biased towards small jobs. Small jobs account for the majority of the workload, and most of them require instant and interactive responses, which is an important phenomenon at production Hadoop systems. The inefficiency of Hadoop fair scheduler for handling small jobs motivates us to design the Fair4S, which introduces pool weights and extends job priorities to guarantee the rapid responses for small jobs. Experimental evaluation verified that the Fair4S accelerates the average waiting times of small jobs by a factor of 7 compared with the fair scheduler.","Production,
Log-normal distribution,
Generators,
Resource management,
Standards,
Distribution functions"
Investigations of SIW Leaky-Wave Antenna for Endfire-Radiation With Narrow Beam and Sidelobe Suppression,"A new substrate integrated waveguide (SIW) leaky-wave antenna is investigated for endfire-radiation with a narrow beam and sidelobe suppression. Maximum directivity conditions for endfire-radiation from line sources with different amplitude distributions are theoretically discussed as a design aid. Interestingly, for endfire beams it is seen that designs that have a lower sidelobe level can also have a higher directivity, contrary to what is normally encountered for broadside beams. An SIW leaky-wave antenna with tapered transverse slots on only the top and bottom planes is presented. Compared with a previous leaky-wave antenna having uniform transverse slots on the top plane, the presented leaky-wave antenna has a main beam that can radiate exactly at endfire and also has a lower sidelobe level. The design of the low sidelobe antenna is based on the leaky mode, which loses physical significance as the beam is scanned to the endfire direction. Nevertheless, the antenna retains a good beam shape and a low sidelobe level when it radiates at endfire. A prototype is made, and measured results are consistent with theoretical and simulated results.","Surface waves,
Leaky wave antennas,
Substrates,
Slot antennas,
Attenuation,
Helical antennas"
Flexible Image Similarity Computation Using Hyper-Spatial Matching,"Spatial pyramid matching (SPM) has been widely used to compute the similarity of two images in computer vision and image processing. While comparing images, SPM implicitly assumes that: in two images from the same category, similar objects will appear in similar locations. However, this is not always the case. In this paper, we propose hyper-spatial matching (HSM), a more flexible image similarity computing method, to alleviate the mis-matching problem in SPM. The match between corresponding regions, HSM considers the relationship of all spatial pairs in two images, which includes more meaningful match than SPM. We propose two learning strategies to learn SVM models with the proposed HSM kernel in image classification, which are hundreds of times faster than a general purpose SVM solver applied to the HSM kernel (in both training and testing). We compare HSM and SPM on several challenging benchmarks, and show that HSM is better than SPM in describing image similarity.","Kernel,
Support vector machines,
Additives,
Training,
Approximation methods,
Vectors,
Face"
USB: Ultrashort Binary Descriptor for Fast Visual Matching and Retrieval,"Currently, many local descriptors have been proposed to tackle a basic issue in computer vision: duplicate visual content matching. These descriptors either are represented as high-dimensional vectors relatively expensive to extract and compare or are binary codes limited in robustness. Bag-of-visual words (BoWs) model compresses local features into a compact representation that allows for fast matching and scalable indexing. However, the codebook training, high-dimensional feature extraction, and quantization significantly degrade the flexibility and efficiency of BoWs model. In this paper, we study an alternative to current local descriptors and BoWs model by extracting the ultrashort binary descriptor (USB) and a compact auxiliary spatial feature from each keypoint detected in images. A typical USB is a 24-bit binary descriptor, hence it directly quantizes visual clues of image keypoints to about 16 million unique IDs. USB allows fast image matching and indexing and avoids the expensive codebook training and feature quantization in BoWs model. The spatial feature complementarily captures the spatial configuration in neighbor region of each keypoint, hence is used to filter mismatched USBs in a cascade verification. In image matching task, USB shows promising accuracy and nearly one-order faster speed than SIFT. We also test USB in retrieval tasks on UKbench, Oxford5K, and 1.2 million distractor images. Comparisons with recent retrieval methods manifest the competitive accuracy, memory consumption, and significantly better efficiency of our approach.","Visualization,
Universal Serial Bus,
Feature extraction,
Quantization (signal),
Computational modeling,
Correlation,
Robustness"
SMOS Retrieval Results Over Forests: Comparisons With Independent Measurements,"This paper shows results obtained by using SMOS Level 2 retrieval algorithm, run at prototype stage, over forests. For each SMOS pixel, the algorithm estimates the soil moisture (SM) and the vegetation optical depth (τ). Average τ values retrieved in 4 days of July 2011 over forest pixels are shown and compared against forest height estimated by GLAS Lidar on board ICEsat satellite. Results of the comparison show a significantly increasing trend of τ with respect to forest height. For each 1-m interval of forest height estimated by Lidar, the standard deviation of optical depth is slightly higher than 0.1. The analysis is made again considering forest τ retrieved in 4 days of February, May, and November 2011, and it is observed that seasonal effects over optical depth are low. As an insight, it is shown that the increasing trend is still observed after subdividing world forests into Coniferous, Deciduous Broadleaf, and Evergreen Broadleaf. Comparisons with independent information about biomass are also shown at regional level for the U.S. The increasing trend is still observed, but with a reduced range of values. For SM, 14 nodes of the SCAN/SNOTEL network in the U.S. are considered. Over 2 years of data, retrieved values of SM are compared against ground measurements. Obtained values of correlation coefficient, rms error, and bias are reported.","Integrated optics,
Adaptive optics,
Optical sensors,
Biomedical optical imaging,
Laser radar,
Vegetation mapping,
Biomass"
Distributed Compressed Sensing for Static and Time-Varying Networks,"We consider the problem of in-network compressed sensing from distributed measurements. Every agent has a set of measurements of a signal x, and the objective is for the agents to recover x from their collective measurements using only communication with neighbors in the network. Our distributed approach to this problem is based on the centralized Iterative Hard Thresholding algorithm (IHT). We first present a distributed IHT algorithm for static networks that leverages standard tools from distributed computing to execute in-network computations with minimized bandwidth consumption. Next, we address distributed signal recovery in networks with time-varying topologies. The network dynamics necessarily introduce inaccuracies to our in-network computations. To accommodate these inaccuracies, we show how centralized IHT can be extended to include inexact computations while still providing the same recovery guarantees as the original IHT algorithm. We then leverage these new theoretical results to develop a distributed version of IHT for time-varying networks. Evaluations show that our distributed algorithms for both static and time-varying networks outperform previously proposed solutions in time and bandwidth by several orders of magnitude.","Distributed processing,
Iterative methods"
A Tri-Gram Based Feature Extraction Technique Using Linear Probabilities of Position Specific Scoring Matrix for Protein Fold Recognition,"In biological sciences, the deciphering of a three dimensional structure of a protein sequence is considered to be an important and challenging task. The identification of protein folds from primary protein sequences is an intermediate step in discovering the three dimensional structure of a protein. This can be done by utilizing feature extraction technique to accurately extract all the relevant information followed by employing a suitable classifier to label an unknown protein. In the past, several feature extraction techniques have been developed but with limited recognition accuracy only. In this study, we have developed a feature extraction technique based on tri-grams computed directly from Position Specific Scoring Matrices. The effectiveness of the feature extraction technique has been shown on two benchmark datasets. The proposed technique exhibits up to 4.4% improvement in protein fold recognition accuracy compared to the state-of-the-art feature extraction techniques.",
Simultaneous Sparsity Model for Histopathological Image Representation and Classification,"The multi-channel nature of digital histopathological images presents an opportunity to exploit the correlated color channel information for better image modeling. Inspired by recent work in sparsity for single channel image classification, we propose a new simultaneous sparsity model for multi-channel histopathological image representation and classification (SHIRC). Essentially, we represent a histopathological image as a sparse linear combination of training examples under suitable channel-wise constraints. Classification is performed by solving a newly formulated simultaneous sparsity-based optimization problem. A practical challenge is the correspondence of image objects (cellular and nuclear structures) at different spatial locations in the image. We propose a robust locally adaptive variant of SHIRC (LA-SHIRC) to tackle this issue. Experiments on two challenging real-world image data sets: 1) mammalian tissue images acquired by pathologists of the animal diagnostics lab (ADL) at Pennsylvania State University, and 2) human intraductal breast lesions, reveal the merits of our proposal over state-of-the-art alternatives. Further, we demonstrate that LA-SHIRC exhibits a more graceful decay in classification accuracy against the number of training images which is highly desirable in practice where generous training per class is often not available.","Sparse representation,
Image color analysis,
Classification,
Biomedical image processing,
Biomedical imaging,
Image reconstruction,
Image analysis"
On the MIMO capacity with residual transceiver hardware impairments,"Radio-frequency (RF) impairments in the transceiver hardware of communication systems (e.g., phase noise (PN), high power amplifier (HPA) nonlinearities, or in-phase/quadrature-phase (I/Q) imbalance) can severely degrade the performance of traditional multiple-input multiple-output (MIMO) systems. Although calibration algorithms can partially compensate these impairments, the remaining distortion still has substantial impact. Despite this, most prior works have not analyzed this type of distortion. In this paper, we investigate the impact of residual transceiver hardware impairments on the MIMO system performance. In particular, we consider a transceiver impairment model, which has been experimentally validated, and derive analytical ergodic capacity expressions for both exact and high signal-to-noise ratios (SNRs). We demonstrate that the capacity saturates in the high-SNR regime, thereby creating a finite capacity ceiling. We also present a linear approximation for the ergodic capacity in the low-SNR regime, and show that impairments have only a second-order impact on the capacity. Furthermore, we analyze the effect of transceiver impairments on large-scale MIMO systems; interestingly, we prove that if one increases the number of antennas at one side only, the capacity behaves similar to the finite-dimensional case. On the contrary, if the number of antennas on both sides increases with a fixed ratio, the capacity ceiling vanishes; thus, impairments cause only a bounded offset in the capacity compared to the ideal transceiver hardware case.","MIMO,
Hardware,
Signal to noise ratio,
Transceivers,
Transmitters,
Receiving antennas"
"Real-Time, Simultaneous Myoelectric Control Using Force and Position-Based Training Paradigms","In this paper, the simultaneous real-time control of multiple degrees of freedom (DOF) for myoelectric systems is investigated. The goal of this study, in which ten able-bodied subjects participated, was to directly compare three control paradigms of constrained (force targeted), unconstrained (position targeted) and resisted unconstrained (position targeted) limb contractions. Artificial neural networks (ANNs) were trained for simultaneous myoelectric control of the three degrees of freedom (DOFs) (wrist flexion-extension, abduction-adduction, and pronation-supination) using mirrored bilateral contractions. In the resisted unconstrained experiment, some resistance to movement was provided using flexible wrist braces in order to increase the required level of muscle activation. The force, in constrained experiments, and position, in unconstrained and resisted unconstrained experiments, were measured. The three protocols were compared off-line using estimation accuracies (R2) and online using a real-time computer-based target acquisition test. The constrained control paradigm outperformed the unconstrained method in the abduction-adduction DOF (Rconstrained2 = 90.8 ± 0.6, Runconstrained2 = 85.6 ± 1.6) and pronation-supination DOF ( Rconstrained2 = 88.5 ± 0.9, Runconstrained2 = 82.3 ± 1.6), but no significant difference was found in the flexion-extension DOF. The constrained control method outperformed unconstrained control in two real-time testing metrics including completion time and path efficiency. The constrained method results, however, were not significantly different than those of the resisted unconstrained method (with braces) in both off-line and real-time tests. This suggests that the quality of control using constrained and unconstrained contraction-based myoelectric schemes is not appreciably different when using comparable levels of muscle activation.","Force,
Electromyography,
Wrist,
Protocols,
Training,
Joints,
Real-time systems"
Iterative Reconstruction for X-Ray Computed Tomography Using Prior-Image Induced Nonlocal Regularization,"Repeated X-ray computed tomography (CT) scans are often required in several specific applications such as perfusion imaging, image-guided biopsy needle, image-guided intervention, and radiotherapy with noticeable benefits. However, the associated cumulative radiation dose significantly increases as comparison with that used in the conventional CT scan, which has raised major concerns in patients. In this study, to realize radiation dose reduction by reducing the X-ray tube current and exposure time (mAs) in repeated CT scans, we propose a prior-image induced nonlocal (PINL) regularization for statistical iterative reconstruction via the penalized weighted least-squares (PWLS) criteria, which we refer to as “PWLS-PINL”. Specifically, the PINL regularization utilizes the redundant information in the prior image and the weighted least-squares term considers a data-dependent variance estimation, aiming to improve current low-dose image quality. Subsequently, a modified iterative successive overrelaxation algorithm is adopted to optimize the associative objective function. Experimental results on both phantom and patient data show that the present PWLS-PINL method can achieve promising gains over the other existing methods in terms of the noise reduction, low-contrast object detection, and edge detail preservation.","Computed tomography,
Image reconstruction,
Image edge detection,
X-ray imaging,
Educational institutions,
Noise,
Phantoms"
An Embedded System-on-Chip Architecture for Real-time Visual Detection and Matching,"Detecting and matching image features is a fundamental task in video analytics and computer vision systems. It establishes the correspondences between two images taken at different time instants or from different viewpoints. However, its large computational complexity has been a challenge to most embedded systems. This paper proposes a new FPGA-based embedded system architecture for feature detection and matching. It consists of scale-invariant feature transform (SIFT) feature detection, as well as binary robust independent elementary features (BRIEF) feature description and matching. It is able to establish accurate correspondences between consecutive frames for 720-p (1280x720) video. It optimizes the FPGA architecture for the SIFT feature detection to reduce the utilization of FPGA resources. Moreover, it implements the BRIEF feature description and matching on FPGA. Due to these contributions, the proposed system achieves feature detection and matching at 60 frame/s for 720-p video. Its processing speed can meet and even exceed the demand of most real-life real-time video analytics applications. Extensive experiments have demonstrated its efficiency and effectiveness.",
Modeling Transmission Line Constraints in Two-Stage Robust Unit Commitment Problem,"Integration of renewable energy sources and demand response poses new challenges to system operators as they increase the uncertainty of the power supply and demand. Recently, robust optimization techniques are applied to the unit commitment problem with uncertainty as an alternative to the stochastic programming approaches. However, it remains challenging to solve the robust unit commitment model with full transmission line constraints. In this paper, we propose novel acceleration techniques for solving two-stage robust unit commitment problem with consideration of full transmission line constraints. We use 1) the cutting-plane algorithm for the master problem, which dynamically includes critical transmission line constraints, and 2) column-generation methods, including the branch-and-price-and-cut algorithm and heuristic approaches, for the subproblems, which add only necessary transmission line dual variables on the fly. Computational results for the modified IEEE 118-bus system show that the combination of the cutting-plane algorithm and the heuristic column-generation approach greatly reduces the total solution time of the two-stage robust unit commitment problem.","Robustness,
Uncertainty,
Power transmission lines,
Wind power generation,
Load modeling,
Optimization,
Heuristic algorithms"
Online Grid Impedance Measurement Using Discrete-Interval Binary Sequence Injection,"Grid impedance affects the stability and control performance of grid-connected power electronic devices, such as inverters used to integrate wind and solar energy. Adaptive control of such inverters, to guarantee stability under different grid conditions, requires online measurement of the grid impedance performed in real time. Such online measurement can be performed by injecting a current perturbation from the inverter into the grid and by reading the grid voltage responses. To minimize the impact on the inverter operation, the injection must be kept as small as possible while producing enough voltage perturbation that can be reliably measured and processed to extract its various frequency components. This paper proposes the use of a discrete-interval binary sequence (DIBS) for this application to minimize the injection. The DIBS is a computer-optimized binary sequence, where the energy is maximized at specified harmonic frequencies based on the expected grid-impedance characteristics. Experimental results based on a three-phase grid-connected inverter are presented to demonstrate the effectiveness of the proposed methods.",
Risk-Aware Day-Ahead Scheduling and Real-time Dispatch for Electric Vehicle Charging,"This paper studies risk-aware day-ahead scheduling and real-time dispatch for electric vehicle (EV) charging, aiming to jointly optimize the EV charging cost and the risk of the load mismatch between the forecast and the actual EV loads, due to the random driving activities of EVs. It turns out that the consideration of the load mismatch risk in the objective function significantly complicates the risk-aware day-ahead scheduling problem (indeed it involves nonconvex optimization). A key step taken here is to utilize a hidden convexity structure to recast this problem as a two-stage stochastic linear program, and then solve it by using the L-shaped method. Since the computational complexity grows exponentially in the number of EVs, an estimation algorithm is developed based on importance sampling to mitigate the computational complexity. Further, a distributed risk-aware real-time dispatch algorithm is developed, in which the aggregator needs to compute only the shadow prices for each EV to optimize its own charging strategy in a distributed manner. It is shown, based on real data, that the proposed risk-aware day-ahead scheduling algorithm using importance sampling can significantly reduce the overall charging cost with a small number of samples.","Real-time systems,
Monte Carlo methods,
Scheduling,
Electric vehicles,
Vectors,
Processor scheduling,
Schedules"
On the impact of hardware impairments on massive MIMO,"Massive multi-user (MU) multiple-input multiple-output (MIMO) systems are one possible key technology for next generation wireless communication systems. Claims have been made that massive MU-MIMO will increase both the radiated energy efficiency as well as the sum-rate capacity by orders of magnitude, because of the high transmit directivity. However, due to the very large number of transceivers needed at each base-station (BS), a successful implementation of massive MU-MIMO will be contingent on of the availability of very cheap, compact and power-efficient radio and digital-processing hardware. This may in turn impair the quality of the modulated radio frequency (RF) signal due to an increased amount of power-amplifier distortion, phase-noise, and quantization noise. In this paper, we examine the effects of hardware impairments on a massive MU-MIMO single-cell system by means of theory and simulation. The simulations are performed using simplified, well-established statistical hardware impairment models as well as more sophisticated and realistic models based upon measurements and electromagnetic antenna array simulations.","Arrays,
Hardware,
MIMO,
Quantization (signal),
Antenna arrays,
Noise,
Vectors"
Symbiotic Tracker Ensemble Toward A Unified Tracking Framework,"Tracking people and objects is a fundamental stage toward many video surveillance systems, for which various trackers have been specifically designed in the past decade. However, it comes to a consensus that there is not any specific tracker that works sufficiently well under all circumstances. Therefore, one potential solution is to deploy multiple trackers, with a tracker output fusion step to boost the overall performance. Subsequently, an intelligent fusion design, yet general and orthogonal to any specific tracker, plays a key role in successful tracking. In this paper, we propose a symbiotic tracker ensemble toward a unified tracking framework, which is based on only the output of each individual tracker, without knowing its specific mechanism. In our approach, all trackers run in parallel, without requiring any details for tracker running, which means that all trackers are treated as black boxes. The proposed symbiotic tracker ensemble framework aims at learning an optimal combination of these tracking results. Our method captures the relation among individual trackers robustly from two aspects. First, the consistency between two successive frames is calculated for each tracker. Then, the pair-wise correlation among different trackers is estimated in the new coming frame by a graph-propagation process. Experimental results on the Caremedia dataset and the Caviar dataset demonstrate the effectiveness of the proposed method, with comparisons to several state-of-the-art methods.",
Discovering and Profiling Overlapping Communities in Location-Based Social Networks,"With the recent surge of location-based social networks (LBSNs), such as Foursquare and Facebook Places, huge digital footprints of people's locations, profiles, and online social connections become accessible to service providers. Unlike social networks (e.g., Flickr, Facebook) that have explicit groups for users to subscribe to or join, LBSNs usually have no explicit community structure. In order to capitalize on the large number of potential users, quality community detection and profiling approaches are needed. In the meantime, the diversity of people's interests and behaviors when using LBSNs suggests that their community structures overlap. In this paper, based on the user check-in traces at venues and user/venue attributes, we come out with a novel multimode multi-attribute edge-centric coclustering framework to discover the overlapping and hierarchical communities of LBSNs users. By employing both intermode and intramode features, the proposed framework is not only able to group like-minded users from different social perspectives but also discover communities with explicit profiles indicating the interests of community members. The efficacy of our approach is validated by intensive empirical evaluations using the collected Foursquare dataset.","mobile computing,
pattern clustering,
social networking (online)"
Postreconstruction Nonlocal Means Filtering of Whole-Body PET With an Anatomical Prior,"Positron emission tomography (PET) images usually suffer from poor signal-to-noise ratio (SNR) due to the high level of noise and low spatial resolution, which adversely affect its performance for lesion detection and quantification. The complementary information present in high-resolution anatomical images from multi-modality imaging systems could potentially be used to improve the ability to detect and/or quantify lesions. However, previous methods that use anatomical priors usually require matched organ/lesion boundaries. In this study, we investigated the use of anatomical information to suppress noise in PET images while preserving both quantitative accuracy and the amplitude of prominent signals that do not have corresponding boundaries on computerized tomography (CT). The proposed approach was realized through a postreconstruction filter based on the nonlocal means (NLM) filter, which reduces noise by computing the weighted average of voxels based on the similarity measurement between patches of voxels within the image. Anatomical knowledge obtained from CT was incorporated to constrain the similarity measurement within a subset of voxels. In contrast to other methods that use anatomical priors, the actual number of neighboring voxels and weights used for smoothing were determined from a robust measurement on PET images within the subset. Thus, the proposed approach can be robust to signal mismatches between PET and CT. A 3-D search scheme was also investigated for the volumetric PET/CT data. The proposed anatomically guided median nonlocal means filter (AMNLM) was first evaluated using a computer phantom and a physical phantom to simulate realistic but challenging situations where small lesions are located in homogeneous regions, which can be detected on PET but not on CT. The proposed method was further assessed with a clinical study of a patient with lung lesions. The performance of the proposed method was compared to Gaussian, edge-preserving bilateral and NLM filters, as well as median nonlocal means (MNLM) filtering without an anatomical prior. The proposed AMNLM method yielded improved lesion contrast and SNR compared with other methods even with imperfect anatomical knowledge, such as missing lesion boundaries and mismatched organ boundaries.","Positron emission tomography,
Computed tomography,
Noise,
Lesions,
Smoothing methods,
Phantoms,
Noise measurement"
A New Multiobjective Evolutionary Algorithm for Mining a Reduced Set of Interesting Positive and Negative Quantitative Association Rules,"Most of the algorithms for mining quantitative association rules focus on positive dependencies without paying particular attention to negative dependencies. The latter may be worth taking into account, however, as they relate the presence of certain items to the absence of others. The algorithms used to extract such rules usually consider only one evaluation criterion in measuring the quality of generated rules. Recently, some researchers have framed the process of extracting association rules as a multiobjective problem, allowing us to jointly optimize several measures that can present different degrees of trade-off depending on the dataset used. In this paper, we propose MOPNAR, a new multiobjective evolutionary algorithm, in order to mine a reduced set of positive and negative quantitative association rules with low computational cost. To accomplish this, our proposal extends a recent multiobjective evolutionary algorithm based on decomposition to perform an evolutionary learning of the intervals of the attributes and a condition selection for each rule, while introducing an external population and a restarting process to store all the nondominated rules found and to improve the diversity of the rule set obtained. Moreover, this proposal maximizes three objectives-comprehensibility, interestingness, and performance-in order to obtain rules that are interesting, easy to understand, and provide good coverage of the dataset. The effectiveness of the proposed approach is validated over several real-world datasets.","Association rules,
Sociology,
Statistics,
Itemsets,
Vectors,
Proposals"
Affect and Engagement in Game-BasedLearning Environments,"The link between affect and student learning has been the subject of increasing attention in recent years. Affective states such as flow and curiosity tend to have positive correlations with learning while negative states such as boredom and frustration have the opposite effect. Student engagement and motivation have also been shown to be critical in improving learning gains with computer-based learning environments. Consequently, it is a design goal of many computer-based learning environments to encourage positive affect and engagement while students are learning. Game-based learning environments offer significant potential for increasing student engagement and motivation. However, it is unclear how affect and engagement interact with learning in game-based learning environments. This work presents an in-depth analysis of how these phenomena occur in the game-based learning environment, Crystal Island. The findings demonstrate that game-based learning environments can simultaneously support learning and promote positive affect and engagement.","Crystals,
Games,
Educational institutions,
Correlation,
Artificial intelligence,
Communities,
Diseases"
MIMO Radar Transmit Beampattern Design Without Synthesising the Covariance Matrix,"Compared to phased-array, multiple-input multiple- output (MIMO) radars provide more degrees-of-freedom (DOF) that can be exploited for improved spatial resolution, better parametric identifiability, lower sidelobe levels at the transmitter/receiver, and design variety of transmit beampatterns. The design of the transmit beampattern generally requires the waveforms to have arbitrary auto- and cross-correlation properties. The generation of such waveforms is a two-step complicated process. In the first step, a waveform covariance matrix is synthesized, which is a constrained optimization problem. In the second step, to realize this covariance matrix actual waveforms are designed, which is also a constrained optimization problem. Our proposed scheme converts this two-step constrained optimization problem into a one-step unconstrained optimization problem. In the proposed scheme, in contrast to synthesizing the covariance matrix for the desired beampattern, nT-independent finite-alphabet constant-envelope waveforms are generated and preprocessed, with weight matrix W, before transmitting from the antennas. In this work, two weight matrices are proposed that can be easily optimized for the desired symmetric and nonsymmetric beampatterns and guarantee equal average power transmission from each antenna. Simulation results validate our claims.",
Recent Advances on Singlemodal and Multimodal Face Recognition: A Survey,"High performance for face recognition systems occurs in controlled environments and degrades with variations in illumination, facial expression, and pose. Efforts have been made to explore alternate face modalities such as infrared (IR) and 3-D for face recognition. Studies also demonstrate that fusion of multiple face modalities improve performance as compared with singlemodal face recognition. This paper categorizes these algorithms into singlemodal and multimodal face recognition and evaluates methods within each category via detailed descriptions of representative work and summarizations in tables. Advantages and disadvantages of each modality for face recognition are analyzed. In addition, face databases and system evaluations are also covered.","Face recognition,
Databases,
Deformable models,
Lighting,
Infrared imaging"
Distributed Adaptive Voltage Control of Inverter-Based Microgrids,"This paper proposes an adaptive and distributed secondary voltage control for microgrids with inverter-based distributed generators (DG). The proposed control is fully adaptive and does not require the information of DG parameters. Neural networks are used to compensate for the uncertainties caused by the unknown dynamics of DGs. The controller structure is fully distributed such that each DG only requires its own information and the information of its neighbors on the communication network. Therefore, this secondary control is associated with a sparse communication network. The effectiveness of the proposed methodology is verified for different loading, outage, and islanding scenarios, as well as variable communication structures in a microgrid setup.","Voltage control,
Microgrids,
Synchronization,
Nonlinear dynamical systems,
Communication networks,
Multi-agent systems,
Vectors"
Design of a Nonvolatile 7T1R SRAM Cell for Instant-on Operation,"Energy consumption is a major concern in nanoscale CMOS ICs; the power-Off operational mode and low-voltage circuits have been proposed to alleviate energy dissipation. Static random access memories (SRAMs) are widely used in today's chips; nonvolatile SRAMs (NVSRAMs) have been proposed to preserve data, while providing fast power- On/Off speeds. Nonvolatile operation is usually accomplished by the use of a resistive RAM circuit (hence referred to as RRAM); the utilization of a RRAM with an SRAMs not only enables chips to achieve low energy consumption for nonvolatile operation, but it also permits to restore data when a restore on power-up is performed (this operation is also commonly referred to as “Instant-on”). This paper presents a novel NVSRAM circuit for “Instant-on” operation and evaluates its performance at nanometric feature sizes. The proposed memory cell consists of a SRAM core (in this case, a 6T cell) and an oxide resistive RRAM circuit (1T1R), thus making a 7T1R scheme. The proposed cell offers better nonvolatile performance (in terms of operations such as “Store,” “Power-down,” and “Restore”) when compared with existing nonvolatile cells. The scenario of multiple-context configuration is also analyzed. Figures of merit such as energy, operational delay, and area are also substantially improved, making the proposed design a better scheme for “Instant-on” operation.",
A Markov Decision Process-based service migration procedure for follow me cloud,"The Follow-Me Cloud (FMC) concept enables service mobility across federated data centers (DCs). Following the mobility of a mobile user, the service located in a given DC is migrated each time an optimal DC is detected. The detailed criterion for optimality is defined by operator policy, but it may be typically derived from geographical proximity or load. Service migration may be an expensive operation given the incurred cost in terms of signaling messages and data transferred between DCs. Decision on service migration defines therefore a tradeoff between cost and user perceived quality. In this paper, we address this tradeoff by modeling the service migration procedure using a Markov Decision Process (MDP). The aim is to formulate a decision policy that determines whether to migrate a service or not when the concerned User Equipment (UE) is at a certain distance from the source DC. We numerically formulate the decision policies and compare the proposed approach against the baseline counterpart.","Mobile communication,
Mobile computing,
Quality of service,
Markov processes,
Distributed databases,
Reliability,
Motion pictures"
A Field Validated Model of a Vanadium Redox Flow Battery for Microgrids,The vanadium redox flow battery (VRB) is well-suited for applications with renewable energy devices. This paper presents a practical analysis of the VRB for use in a microgrid system. The first part of the paper develops a reduced order circuit model of the VRB and analyzes its experimental performance efficiency during deployment. The model parameters of the various VRB system components were estimated from experimental field data. The parasitic losses of the circulation pumps power consumption were predicted during different operating situations. The second part of the paper addresses the implementation issues of the VRB application in a photovoltaic-based microgrid system. Commercially available chargers designed for lead-acid battery systems were shown to be non-optimal for VRB systems and a new dc-dc converter control was proposed to provide improved charging performance. The system model was validated with field-obtained experimental data.,"Batteries,
Microgrids,
System-on-chip,
Load modeling,
Integrated circuit modeling,
Atmospheric modeling"
Near-Real-Time Parameter Estimation of an Electrical Battery Model With Multiple Time Constants and SOC-Dependent Capacitance,"A modified particle swarm optimization algorithm for conducting near-real-time parameter estimation of an electrical model for lithium batteries is presented. The model comprises a dynamic capacitance for characterizing the nonlinear relationship between the battery electromotive force and the state-of-charge, and a resistor-capacitor network for characterizing the static and transient responses. The algorithm is confirmed by successfully determining all parameters in a predefined simulation model. It is also evaluated on a hardware test bed with two samples of 3.3-V, 40-Ah, Lithium Iron Phosphate (LiFePO4) battery driven under six different loading patterns. The intrinsic parameters are estimated by first processing 15-min samples of the battery terminal voltage and current. The whole process takes 2 min. Then, the voltage-current characteristics in the following 15 min are predicted. Results show that the extracted parameters can fit the first 15-min voltage samples with a maximum error of 16 mV and an average error of 3.8 mV. With the extracted parameters, the electrical model can predict voltage-current characteristics in the following 15 min with a maximum error of 31 mV and an average error of 15 mV. The algorithm is further verified by successfully determining the emulated variation of the output resistance.","Batteries,
Integrated circuit modeling,
Mathematical model,
Computational modeling,
Parameter estimation,
System-on-chip,
Estimation"
Mobile App Classification with Enriched Contextual Information,"The study of the use of mobile Apps plays an important role in understanding the user preferences, and thus provides the opportunities for intelligent personalized context-based services. A key step for the mobile App usage analysis is to classify Apps into some predefined categories. However, it is a nontrivial task to effectively classify mobile Apps due to the limited contextual information available for the analysis. For instance, there is limited contextual information about mobile Apps in their names. However, this contextual information is usually incomplete and ambiguous. To this end, in this paper, we propose an approach for first enriching the contextual information of mobile Apps by exploiting the additional Web knowledge from the Web search engine. Then, inspired by the observation that different types of mobile Apps may be relevant to different real-world contexts, we also extract some contextual features for mobile Apps from the context-rich device logs of mobile users. Finally, we combine all the enriched contextual information into the Maximum Entropy model for training a mobile App classifier. To validate the proposed method, we conduct extensive experiments on 443 mobile users' device logs to show both the effectiveness and efficiency of the proposed approach. The experimental results clearly show that our approach outperforms two state-of-the-art benchmark methods with a significant margin.","Mobile communication,
Context,
Feature extraction,
Semantics,
Knowledge engineering,
Web search,
Engines"
A Native Stochastic Computing Architecture Enabled by Memristors,"A two-terminal memristor device is a promising digital memory for its high integration density, substantially lower energy consumption compared to CMOS, and scalability below 10 nm. However, a nanoscale memristor is an inherently stochastic device, and extra energy and latency are required to make a deterministic memory based on memristors. Instead of enforcing deterministic storage, we take advantage of the nondeterministic memory for native stochastic computing, where the randomness required by stochastic computing is intrinsic to the devices without resorting to expensive stochastic number generation. This native stochastic computing system can be implemented as a hybrid integration of memristor memory and simple CMOS stochastic computing circuits. We use an approach called group write to program memristor memory cells in arrays to generate random bit streams for stochastic computing. Three methods are proposed to program memristors using stochastic bit streams and compensate for the nonlinear memristor write function: voltage predistortion, parallel single-pulse write, and downscaled write and upscaled read. To evaluate these technical approaches, we show by simulation a memristor-based stochastic processor for gradient descent optimization, and k-means clustering. The native stochastic computing based on memristors demonstrates key advantages in energy and speed in compute-intensive, data-intensive, and probabilistic applications.","Memristors,
Switches,
Resistance,
Programming,
CMOS integrated circuits,
Materials,
Probabilistic logic"
Property Analysis of XOR-Based Visual Cryptography,"A (k,n) visual cryptographic scheme (VCS) encodes a secret image into n shadow images (printed on transparencies) distributed among n participants. When any k participants superimpose their transparencies on an overhead projector (OR operation), the secret image can be visually revealed by a human visual system without computation. However, the monotone property of OR operation degrades the visual quality of reconstructed image for OR-based VCS (OVCS). Accordingly, XOR-based VCS (XVCS), which uses XOR operation for decoding, was proposed to enhance the contrast. In this paper, we investigate the relation between OVCS and XVCS. Our main contribution is to theoretically prove that the basis matrices of (k,n)-OVCS can be used in (k,n)-XVCS. Meantime, the contrast is enhanced 2(k-1) times.","Visualization,
Image reconstruction,
Stacking,
Cryptography,
Decoding,
Vectors"
Popular Conjectures Imply Strong Lower Bounds for Dynamic Problems,"We consider several well-studied problems in dynamic algorithms and prove that sufficient progress on any of them would imply a breakthrough on one of five major open problems in the theory of algorithms: 1) Is the 3SUM problem on n numbers in O(n2-ε) time for some ε > 0? 2) Can one determine the satisfiability of a CNF formula on n variables and poly n clauses in O((2 - ε)npoly n) time for some ε > 0? 3) Is the All Pairs Shortest Paths problem for graphs on n vertices in O(n3-ε) time for some ε > 0? 4) Is there a linear time algorithm that detects whether a given graph contains a triangle? 5) Is there an O(n3-ε) time combinatorial algorithm for n×n Boolean matrix multiplication? The problems we consider include dynamic versions of bipartite perfect matching, bipartite maximum weight matching, single source reachability, single source shortest paths, strong connectivity, subgraph connectivity, diameter approximation and some nongraph problems such as Pagh's problem defined in a recent paper by Patrascu[STOC 2010].","Heuristic algorithms,
Approximation algorithms,
Polynomials,
Image edge detection,
Computer science,
Upper bound,
Runtime"
"Software-Defined Mobile Cloud: Architecture, services and use cases","Software-Defined Networking (SDN) is an emerging technology which brings flexibility and programmability to networks and introduces new services and features. However, most SDN architectures have been designed for wired infrastructures, especially in the data center space, and primary trends for wireless and mobile SDN are on the access network and the wireless backhaul. In this paper, we propose several designs for SDN-based Mobile Cloud architectures, focusing on Ad hoc networks. We present the required core components to build SDN-based Mobile Cloud, including variations that are required to accommodate different wireless environments, such as mobility and unreliable wireless link conditions. We also introduce several instances of the proposed architectures based on frequency selection of wireless transmission that are designed around different use cases of SDN-based Mobile Cloud. We demonstrate the feasibility of our architecture by implementing SDN-based routing in the mobile cloud and comparing it with traditional Mobile Ad Hoc Network (MANET) routing. The feasibility of our architecture is shown by achieving high packet delivery ratio with acceptable overhead.","Ad hoc networks,
Mobile computing,
Wireless communication,
Frequency control,
Jamming"
Photonic Generation of Microwave Waveforms Based on a Polarization Modulator in a Sagnac Loop,"An optical microwave waveform generator using a polarization modulator (PolM) in a Sagnac loop is proposed and experimentally demonstrated. Microwave waveforms including a triangular waveform, a sawtooth waveform, and a square waveform, can be generated using a sinusoidal signal to modulate a light wave at a PolM in a Sagnac loop. In the proposed microwave waveform generator, a sinusoidal microwave signal is applied to the PolM in the Sagnac loop. Due to the velocity mismatch, only the clockwise light wave in the Sagnac loop is effectively modulated by the sinusoidal microwave signal at the PolM, and the counter-clockwise light wave is not modulated. Along the clockwise direction, the powers of the odd- and even-order sidebands can be controlled separately by tuning a polarization controller after the PolM. In addition, the output power of the optical carrier can be independently controlled by combining the counter-clockwise and clockwise optical carriers at the output of a polarization beam splitter. As a result, a modulated signal with controllable odd- and even-order sidebands is generated. By applying the modulated signal to a photodetector, a microwave signal with fully controllable odd- and even-order harmonics is generated, which corresponds to a desired microwave waveform. A theoretical analysis is developed, which is validated by an experiment. A triangular, sawtooth, and square waveform with a repetition rate tunable from 2 to 4 GHz is experimentally generated.","Harmonic analysis,
Microwave photonics,
Optical polarization,
Power system harmonics,
Microwave filters,
Fourier series"
Full-Duplex Cloud Radio Access Networks: An Information-Theoretic Viewpoint,"The conventional design of cellular systems prescribes the separation of uplink and downlink transmissions via time-division or frequency-division duplex. Recent advances in analog and digital domain self-interference interference cancellation challenge the need for this arrangement and open up the possibility to operate base stations, particularly low-power ones, in a full-duplex mode. As a means to cope with the resulting downlink-to-uplink interference among base stations, this letter investigates the impact of the Cloud Radio Access Network (C-RAN) architecture. The analysis follows an information theoretic approach based on the classical Wyner model. The analytical results herein confirm the significant potential advantages of the C-RAN architecture in the presence of full-duplex base stations, as long as sufficient fronthaul capacity is available and appropriate mobile station scheduling, or successive interference cancellation at the mobile stations, is implemented.","Downlink,
Uplink,
Interference,
Base stations,
Computer architecture,
Noise,
Baseband"
Undersampled phase shift ON-OFF keying for camera communication,"In this paper, an optical camera communication system utilizing the under-sampled phase shift ON-OFF keying modulation is proposed to support non-flickering visible light communication. This system sends three types of light symbols through light emitting diode (LED) lamps, which are recorded by a camera. By employing a dual LED lamp with a designated mapping and framing method, the data rate can reach up to 3 times of the camera's frame rate. The experiment results show that the proposed camera communication system can achieve 150 bps error-free communications for a range up to 12 m.","Cameras,
Videos,
Receivers,
LED lamps,
Modulation,
Uncertainty"
Generation of Linearly Chirped Microwave Waveform With an Increased Time-Bandwidth Product Based on a Tunable Optoelectronic Oscillator and a Recirculating Phase Modulation Loop,"Photonic generation of a linearly chirped microwave waveform with an increased time-bandwidth product (TBWP) based on a frequency-tunable optoelectronic oscillator (OEO) and a recirculating phase modulation loop (RPML) is proposed and experimentally demonstrated, for the first time to the best of our knowledge. In the proposed system, a continuous-wave (CW) light wave is divided into two parts: one is sent to the tunable OEO to generate a frequency-tunable microwave signal and the other is intensity-modulated by a switching signal at an intensity modulator to form a chirp-free optical pulse, which are then sent to the RPML, in which the chirp-free pulse is phase modulated by a parabolic waveform to generate a linearly chirped optical waveform. The recirculation of the linearly chirped optical waveform inside the loop would lead to the waveform to experience multiple phase modulations, thus multiplying its chirp rate. By beating the chirped waveform and an optical sideband from the OEO at a high-speed photodetector (PD), a linearly chirped microwave waveform is obtained. The key significance of the approach is that the chirp rate is significantly increased, leading to a significantly increased TBWP. In addition, the approach allows the generation of a linearly chirped frequency-tunable microwave waveform without using a separate microwave source. The technique is experimentally verified. The generation of a linearly chirped microwave waveform with an increased TBWP by 16 times is demonstrated.","Optical pulses,
Chirp,
Optical switches,
Phase modulation,
Microwave oscillators,
Microwave photonics"
Design of a Metamaterial-Based Backward-Wave Oscillator,"In this paper, we present the design of a microwave generator using metamaterials (MTMs) in a negative index waveguide interacting with a high-power electron beam. The microwave structure is formed by inserting two MTM plates loaded with complementary split-ring-resonators (CSRRs) into a rectangular waveguide. Electromagnetic simulations using the high-frequency structure simulator code confirm the presence of a negative index TM-like mode suitable for use in a backward-wave oscillator (BWO). Particle-in-cell (PIC) simulations using the computer simulation technology (CST) Particle Studio code are performed to evaluate the efficiency of an S-Band MTM-based BWO (MTMBWO) excited by a 500 keV, 80-A electron beam. After about 250 ns, the MTMBWO reaches a saturated output power of 5.75 MW with an efficiency of 14% at a frequency near 2.6 GHz. The MTMBWO is also modeled by representing the MTM plates, which consist of CSRRs, as dielectric slabs whose effective permittivity is given by a Lorentzian model. The dielectric slab model is also simulated with the CST PIC code and shows good qualitative agreement with the simulations including the CSRR loaded plates. A cold test structure was fabricated from brass to test the theoretical predictions of the microwave transmission versus frequency of the negative index waveguide. Test results using a vector network analyzer showed very good agreement with the simulations for the excitation of the negative index TM-like mode near 2.6 GHz. The proposed structure appears to be promising for use in a MTMBWO high-power microwave generator.","Electron beams,
Indexes,
Electromagnetic waveguides,
Slabs,
Microwave oscillators,
Load modeling,
Power generation"
Weakly Supervised Visual Dictionary Learning by Harnessing Image Attributes,"Bag-of-features (BoFs) representation has been extensively applied to deal with various computer vision applications. To extract discriminative and descriptive BoF, one important step is to learn a good dictionary to minimize the quantization loss between local features and codewords. While most existing visual dictionary learning approaches are engaged with unsupervised feature quantization, the latest trend has turned to supervised learning by harnessing the semantic labels of images or regions. However, such labels are typically too expensive to acquire, which restricts the scalability of supervised dictionary learning approaches. In this paper, we propose to leverage image attributes to weakly supervise the dictionary learning procedure without requiring any actual labels. As a key contribution, our approach establishes a generative hidden Markov random field (HMRF), which models the quantized codewords as the observed states and the image attributes as the hidden states, respectively. Dictionary learning is then performed by supervised grouping the observed states, where the supervised information is stemmed from the hidden states of the HMRF. In such a way, the proposed dictionary learning approach incorporates the image attributes to learn a semantic-preserving BoF representation without any genuine supervision. Experiments in large-scale image retrieval and classification tasks corroborate that our approach significantly outperforms the state-of-the-art unsupervised dictionary learning approaches.",
A Monte Carlo Simulation Platform for Studying Low Voltage Residential Networks,"The smart grid vision has resulted in many demand side innovations such as nonintrusive load monitoring techniques, residential micro-grids, and demand response programs. Many of these techniques need a detailed residential network model for their research, evaluation, and validation. In response to such a need, this paper presents a sequential Monte Carlo (SMC) simulation platform for modeling and simulating low voltage residential networks. This platform targets the simulation of the quasi-steady-state network condition over an extended period such as 24 h. It consists of two main components. The first is a multiphase network model with power flow, harmonic, and motor starting study capabilities. The second is a load/generation behavior model that establishes the operating characteristics of various loads and generators based on time-of-use probability curves. These two components are combined together through an SMC simulation scheme. Four case studies are presented to demonstrate the applications of the proposed platform.",
Monte Carlo Non-Local Means: Random Sampling for Large-Scale Image Filtering,"We propose a randomized version of the nonlocal means (NLM) algorithm for large-scale image filtering. The new algorithm, called Monte Carlo nonlocal means (MCNLM), speeds up the classical NLM by computing a small subset of image patch distances, which are randomly selected according to a designed sampling pattern. We make two contributions. First, we analyze the performance of the MCNLM algorithm and show that, for large images or large external image databases, the random outcomes of MCNLM are tightly concentrated around the deterministic full NLM result. In particular, our error probability bounds show that, at any given sampling ratio, the probability for MCNLM to have a large deviation from the original NLM solution decays exponentially as the size of the image or database grows. Second, we derive explicit formulas for optimal sampling patterns that minimize the error probability bound by exploiting partial knowledge of the pairwise similarity weights. Numerical experiments show that MCNLM is competitive with other state-of-the-art fast NLM algorithms for single-image denoising. When applied to denoising images using an external database containing ten billion patches, MCNLM returns a randomized solution that is within 0.2 dB of the full NLM solution while reducing the runtime by three orders of magnitude.","Noise reduction,
Noise measurement,
Signal processing algorithms,
Monte Carlo methods,
Random variables,
Algorithm design and analysis,
Computational complexity"
A Novel UWB Monopole Antenna With Tunable Notched Behavior Using Varactor Diode,"This letter presents a novel ultrawideband (UWB) antenna with tunable notched band. The antenna is assembled on an FR4 substrate with thickness of 0.8 mm and εr = 4.4. By inserting a π-shaped slot on the radiating patch, band-notch function is achieved. By loading the slot with lumped varactor, tunability of the created notch would be possible. Based on this technique, an electronically controlled notched-band antenna is designed and fabricated including a single varactor diode with a varying capacitance value of 0.63-2.67 pF. Using the cited varactor, notched band tunability of 2.7-7.2 GHz is obtained.","Varactors,
Antenna measurements,
Ultra wideband antennas,
Slot antennas"
A 3.4-\mu W Object-Adaptive CMOS Image Sensor With Embedded Feature Extraction Algorithm for Motion-Triggered Object-of-Interest Imaging,"We report a low-power object-adaptive CMOS imager, which suppresses spatial temporal bandwidth. The object-adaptive imager has embedded a feature extraction algorithm for identifying objects of interest. The sensor wakes up triggered by motion sensing and extracts features from the captured image for the detection of object-of-interest (OOI). Full-image capturing operation and image signal transmission are performed only when the interested objects are found, which significantly reduces power consumption at the sensor node. This motion-triggered OOI imaging significantly saves a spatial bandwidth more than 96.5% from the feature output and saves a temporal bandwidth from the motion-triggered wakeup and object adaptive imaging. The sensor consumes low power by employing a reconfigurable differential-pixel architecture with reduced power supply voltage and by implementing the feature extraction algorithm with mixed-signal circuitry in a small area. The chip operates at 0.22 μW/frame in motion-sensing mode and at 3.4 μW/frame for feature extraction, respectively. The object detection from on-chip feature extraction circuits has demonstrated a 94.5% detection rate for human from a set of 200 sample images.","Feature extraction,
Imaging,
Bandwidth,
Power demand,
Wireless sensor networks,
Capacitors"
Model-Based Classification Methods of Global Patterns in Dermoscopic Images,"In this paper different model-based methods of classification of global patterns in dermoscopic images are proposed. Global patterns identification is included in the pattern analysis framework, the melanoma diagnosis method most used among dermatologists. The modeling is performed in two senses: first a dermoscopic image is modeled by a finite symmetric conditional Markov model applied to L*a*b* color space and the estimated parameters of this model are treated as features. In turn, the distribution of these features are supposed that follow different models along a lesion: a Gaussian model, a Gaussian mixture model, and a bag-of-features histogram model. For each case, the classification is carried out by an image retrieval approach with different distance metrics. The main objective is to classify a whole pigmented lesion into three possible patterns: globular, homogeneous, and reticular. An extensive evaluation of the performance of each method has been carried out on an image database extracted from a public Atlas of Dermoscopy. The best classification success rate is achieved by the Gaussian mixture model-based method with a 78.44% success rate in average. In a further evaluation the multicomponent pattern is analyzed obtaining a 72.91% success rate.","Classification,
Image color analysis,
Gaussian processes,
Markov processes,
Feature extraction,
Level set,
Image segmentation"
Design of Transformer-Based Boost Converter for High Internal Resistance Energy Harvesting Sources With 21 mV Self-Startup Voltage and 74% Power Efficiency,"Thin-film thermoelectric generators (TEG) or graphene-based microbial fuel cells (MFC) are emerging energy harvesting sources with promising power density and sustainability. Nevertheless, conventional transformer-based boost converters commonly used to achieve autonomous low voltage startup encounter low efficiency and potential startup problems with these novel power sources due to their high internal resistance. In this paper, an improved design of transformer-based boost converter addressing these issues is demonstrated with prototype chip fabricated using a standard 0.13 μm CMOS process. The self-start oscillation does not rely on the conventional LC resonant principle, but instead is dependent on the MOS transistor's active-over-leakage current ratio and the mutual coupling between the two identical transformer coils. Circuit design techniques to regulate output voltage and to track system's maximum power point (MPP) of this boost converter are presented. Measurement results confirmed that the proposed circuit works with either low threshold voltage or native MOS transistors. It needs minimum self-startup voltage of 21 mV (at 5.8 μW input power) and minimum startup power of 1.3 μW (at 35 mV input voltage) respectively. The maximum output power is 2 mW and peak power conversion efficiency is 74% at a regulated output voltage of 1 V.",
Double Selection Based Semi-Supervised Clustering Ensemble for Tumor Clustering from Gene Expression Profiles,"Tumor clustering is one of the important techniques for tumor discovery from cancer gene expression profiles, which is useful for the diagnosis and treatment of cancer. While different algorithms have been proposed for tumor clustering, few make use of the expert's knowledge to better the performance of tumor discovery. In this paper, we first view the expert's knowledge as constraints in the process of clustering, and propose a feature selection based semi-supervised cluster ensemble framework (FS-SSCE) for tumor clustering from bio-molecular data. Compared with traditional tumor clustering approaches, the proposed framework FS-SSCE is featured by two properties: (1) The adoption of feature selection techniques to dispel the effect of noisy genes. (2) The employment of the binate constraint based K-means algorithm to take into account the effect of experts' knowledge. Then, a double selection based semi-supervised cluster ensemble framework (DS-SSCE) which not only applies the feature selection technique to perform gene selection on the gene dimension, but also selects an optimal subset of representative clustering solutions in the ensemble and improve the performance of tumor clustering using the normalized cut algorithm. DS-SSCE also introduces a confidence factor into the process of constructing the consensus matrix by considering the prior knowledge of the data set. Finally, we design a modified double selection based semi-supervised cluster ensemble framework (MDS-SSCE) which adopts multiple clustering solution selection strategies and an aggregated solution selection function to choose an optimal subset of clustering solutions. The results in the experiments on cancer gene expression profiles show that (i) FS-SSCE, DS-SSCE and MDS-SSCE are suitable for performing tumor clustering from bio-molecular data. (ii) MDS-SSCE outperforms a number of state-of-the-art tumor clustering approaches on most of the data sets.","Cancer,
Tumors,
Gene expression,
Bioinformatics,
Clustering algorithms,
Algorithm design and analysis,
Mutual information"
Exponential Stabilization for Sampled-Data Neural-Network-Based Control Systems,"This paper investigates the problem of sampled-data stabilization for neural-network-based control systems with an optimal guaranteed cost. Using time-dependent Lyapunov functional approach, some novel conditions are proposed to guarantee the closed-loop systems exponentially stable, which fully use the available information about the actual sampling pattern. Based on the derived conditions, the design methods of the desired sampled-data three-layer fully connected feedforward neural-network-based controller are established to obtain the largest sampling interval and the smallest upper bound of the cost function. A practical example is provided to demonstrate the effectiveness and feasibility of the proposed techniques.","Cost function,
Delays,
Symmetric matrices,
Upper bound,
Closed loop systems,
Neural networks"
Event-Based Stabilization of Periodic Orbits for Underactuated 3-D Bipedal Robots With Left-Right Symmetry,"Models of robotic bipedal walking are hybrid, with a differential equation that describes the stance phase and a discrete map describing the impact event, that is, the nonstance leg contacting the walking surface. The feedback controllers for these systems can be hybrid as well, including both continuous and discrete (event-based) actions. This paper concentrates on the event-based portion of the feedback design problem for 3-D bipedal walking. The results are developed in the context of robustly stabilizing periodic orbits for a simulation model of ATRIAS 2.1, which is a highly underactuated 3-D bipedal robot with series-compliant actuators and point feet, against external disturbances as well as parametric and nonparametric uncertainty. It is shown that left-right symmetry of the model can be used to both simplify and improve the design of event-based controllers. Here, the event-based control is developed on the basis of the Poincaré map, linear matrix inequalities and robust optimal control. The results are illustrated by designing a controller that enhances the lateral stability of ATRIAS 2.1.","Legged locomotion,
Orbits,
Robustness,
Torso,
Friction,
Solid modeling"
TSP: Thermal Safe Power - Efficient power budgeting for many-core systems in dark silicon,"Chip manufacturers provide the Thermal Design Power (TDP) for a specific chip. The cooling solution is designed to dissipate this power level. But because TDP is not necessarily the maximum power that can be applied, chips are operated with Dynamic Thermal Management (DTM) techniques. To avoid excessive triggers of DTM, usually, system designers also use TDP as power constraint. However, using a single and constant value as power constraint, e.g., TDP, can result in big performance losses in many-core systems. Having better power budgeting techniques is a major step towards dealing with the dark silicon problem. This paper presents a new power budget concept, called Thermal Safe Power (TSP), which is an abstraction that provides safe power constraint values as a function of the number of simultaneously operating cores. Executing cores at any power consumption below TSP ensures that DTM is not triggered. TSP can be computed offline for the worst cases, or online for a particular mapping of cores. Our simulations show that using TSP as power constraint results in 50.5% and 14.2% higher average performance, compared to using constant power budgets (both per-chip and per-core) and a boosting technique, respectively. Moreover, TSP results in dark silicon estimations which are more optimistic than estimations using constant power budgets.","Power demand,
Steady-state,
Thermal conductivity,
Vectors,
Boosting,
Temperature measurement,
Multicore processing"
A Sensitivity Approach to Model Local Voltage Controllers in Distribution Networks,"Local controllers are essential in distribution networks; they are employed in classical devices such as load tap-changing (LTC) transformers and switchable shunt capacitors, and more recently in distributed generation (DG). The effective use of distribution management system (DMS) applications requires an accurate model of the interaction between the local controllers through the distribution system. This paper presents a new sensitivity matrix approach for modeling such interactions, and demonstrates its application in the implicit ZBus Gauss method for power flow computation. The sensitivity method models both PV buses (for the connection of DG) and tap position adjustments through current source injections, and consequently avoids re-factorization of the network bus admittance matrix. Numerical results on distribution networks with up to 3145 buses show that the sensitivity-based power flow method for simulating the operation of local controllers is superior to a sequential control action adjustment approach previously proposed in the literature, and that its computing time is commensurate with the performance requirements in real-time DMS applications.","Sensitivity,
Voltage control,
Mathematical model,
Reactive power,
Equations,
Load modeling,
Computational modeling"
"Design of Wideband, FSS-Based MultiBeam Antennas Using the Effective Medium Approach","We present the design, simulation, and measurement results of a broadband, low-profile, multibeam antenna. The antenna uses multiple feed elements placed on the focal plane of a planar microwave lens to achieve high-gain, multibeam operation with a wide field of view. The lens is based on a recently reported design employing the constituting unit cells of appropriately designed miniaturized-element frequency selective surfaces (MEFSSs) as its spatial time-delay units. A new technique for modeling such lenses is also presented that greatly simplifies the full-wave electromagnetic simulation of MEFSS-based lenses. This technique is based on treating the pixels of the lens as effective media with the same effective permittivity and permeability and significantly reduces the difficulty of modeling and optimizing the proposed multibeam antenna with its relatively large aperture size in a full-wave electromagnetic simulation tool. Using this procedure, a prototype multibeam antenna operating in the 8-10 GHz range is designed. The prototype is fabricated and characterized using a multiprobe, spherical near field system. The measurement results are in good agreement with the simulation results obtained using the proposed simplified modeling technique. Measurements demonstrate consistent radiation characteristics over the antenna's entire operational band with multiple beams in a field of view of ±45°.","Lenses,
Apertures,
Antenna feeds,
Microwave antenna arrays,
Microwave theory and techniques"
Fuzzy Modelling and Consensus of Nonlinear Multiagent Systems With Variable Structure,"The consensus problem of multiagent nonlinear systems (MANNs) with variable structure is discussed in this paper. T-S fuzzy models are first presented to describe MANNs with variable structure. The nodes of each T-S fuzzy model are rearranged so that the global fuzzy model is decomposed into independent and small-scale fuzzy models. It is shown that the consensus of the global fuzzy model is equivalent to that of its corresponding small-scale fuzzy models in which the continuous and sampled controllers are applied. Sufficient conditions are derived to ensure the consensus of the controlled fuzzy models. Finally, simulation results are given to illustrate the effectiveness of the proposed criteria.","Fuzzy systems,
Multi-agent systems,
Asymptotic stability,
Stability analysis,
Laplace equations,
Symmetric matrices,
Educational institutions"
Analysis of Architecturally Significant Requirements for Enterprise Systems,"In designing and developing enterprise systems, systems engineers must consider the requirements that drive the important architecture decisions. Architecturally significant requirements tend to have a global impact on the underlying software infrastructure, and therefore need to be thoroughly examined. Despite the increasing effort in engineering enterprise systems' requirements, little is known about the analysis of architecture interactions and tradeoffs. In this paper, we propose a framework consisting of an integrated set of activities to help tackle requirements analysis in practice. Specifically, we leverage the quality attribute scenarios to elicit implicit yet significant requirements, to model requirements interplays, to manage terminological interferences, and to determine change impacts. We apply the proposed framework to a customer relationship management software system. The results show that the framework offers concrete insights and can be incorporated into an organization's systems practice with a moderate cost.","business data processing,
customer relationship management,
formal specification,
software architecture,
systems analysis"
Single-Trial Classification of Event-Related Potentials in Rapid Serial Visual Presentation Tasks Using Supervised Spatial Filtering,"Accurate detection of single-trial event-related potentials (ERPs) in the electroencephalogram (EEG) is a difficult problem that requires efficient signal processing and machine learning techniques. Supervised spatial filtering methods that enhance the discriminative information in EEG data are commonly used to improve single-trial ERP detection. We propose a convolutional neural network (CNN) with a layer dedicated to spatial filtering for the detection of ERPs and with training based on the maximization of the area under the receiver operating characteristic curve (AUC). The CNN is compared with three common classifiers: 1) Bayesian linear discriminant analysis; 2) multilayer perceptron (MLP); and 3) support vector machines. Prior to classification, the data were spatially filtered with xDAWN (for the maximization of the signal-to-signal-plus-noise ratio), common spatial pattern, or not spatially filtered. The 12 analytical techniques were tested on EEG data recorded in three rapid serial visual presentation experiments that required the observer to discriminate rare target stimuli from frequent nontarget stimuli. Classification performance discriminating targets from nontargets depended on both the spatial filtering method and the classifier. In addition, the nonlinear classifier MLP outperformed the linear methods. Finally, training based AUC maximization provided better performance than training based on the minimization of the mean square error. The results support the conclusion that the choice of the systems architecture is critical and both spatial filtering and classification must be considered together.","Electroencephalography,
Neurons,
Visualization,
Training,
Sensors,
Convolution,
Biological neural networks"
Semi-Supervised Multiple Feature Analysis for Action Recognition,"This paper presents a semi-supervised method for categorizing human actions using multiple visual features. The proposed algorithm simultaneously learns multiple features from a small number of labeled videos, and automatically utilizes data distributions between labeled and unlabeled data to boost the recognition performance. Shared structural analysis is applied in our approach to discover a common subspace shared by each type of feature. In the subspace, the proposed algorithm is able to characterize more discriminative information of each feature type. Additionally, data distribution information of each type of feature has been preserved. The aforementioned attributes make our algorithm robust for action recognition, especially when only limited labeled training samples are provided. Extensive experiments have been conducted on both the choreographed and the realistic video datasets, including KTH, Youtube action and UCF50. Experimental results show that our method outperforms several state-of-the-art algorithms. Most notably, much better performances have been achieved when there are only a few labeled training samples.","Videos,
Correlation,
Semisupervised learning,
Linear programming,
Training,
Manifolds,
Optimization"
Hire me: Computational Inference of Hirability in Employment Interviews Based on Nonverbal Behavior,"Understanding the basis on which recruiters form hirability impressions for a job applicant is a key issue in organizational psychology and can be addressed as a social computing problem. We approach the problem from a face-to-face, nonverbal perspective where behavioral feature extraction and inference are automated. This paper presents a computational framework for the automatic prediction of hirability. To this end, we collected an audio-visual dataset of real job interviews where candidates were applying for a marketing job. We automatically extracted audio and visual behavioral cues related to both the applicant and the interviewer. We then evaluated several regression methods for the prediction of hirability scores and showed the feasibility of conducting such a task, with ridge regression explaining 36.2% of the variance. Feature groups were analyzed, and two main groups of behavioral cues were predictive of hirability: applicant audio features and interviewer visual cues, showing the predictive validity of cues related not only to the applicant, but also to the interviewer. As a last step, we analyzed the predictive validity of psychometric questionnaires often used in the personnel selection process, and found that these questionnaires were unable to predict hirability, suggesting that hirability impressions were formed based on the interaction during the interview rather than on questionnaire data.","Interviews,
Feature extraction,
Employment,
Psychology,
Visualization,
Social network services,
Sensors"
Direct Electricity Trading in Smart Grid: A Coalitional Game Analysis,"Integration of distributed generation based on renewable energy sources into the power system has gained popularity in recent years. Many small-scale electricity suppliers (SESs) have recently entered the electricity market, which has been traditionally dominated by a few large-scale electricity suppliers. The emergence of SESs enables direct trading (DT) of electricity between SESs and end-users (EUs), without going through retailers, and promotes the possibility of improving the benefits to both parties. In this paper, the cooperation between SESs and EUs in DT is analyzed based on coalitional game theory. In particular, an electricity pricing scheme that achieves a fair division of revenue between SESs and EUs is analytically derived by using the asymptotic Shapley value. The asymptotic Shapley value is shown to be in the core of the coalitional game such that no group of SESs and EUs has an incentive to abandon the coalition, which implies the stable operation of DT for the proposed pricing scheme. Unlike the existing pricing schemes that typically require multiple stages of calculations and real time information about each participant, the electricity price for the proposed scheme can be determined instantaneously based on the number of participants in DT and statistical information about electricity supply and demand. Therefore, the proposed pricing scheme is suitable for practical implementation. Using computer simulations, the price of electricity for the proposed DT scheme is examined in various environments, and the numerical results validate the asymptotic analysis. Moreover, the revenues of the SESs and EUs are evaluated for various types of SESs and different numbers of participants in DT. The optimal ratio of different types of SESs is also investigated.","Electricity,
Games,
Pricing,
Silicon,
Electricity supply industry,
Smart grids,
Niobium"
Bandwidth Enhancement of 2-D Leaky-Wave Antennas With Double-Layer Periodic Surfaces,Broadband high-gain 2-D Fabry-Perot (FP) leaky-wave antennas (LWAs) consisting of two periodic metallodielectric arrays over a ground plane are presented. Full-wave method of moments (MoM) is employed for the estimation of the near fields upon plane wave illumination and the extraction of the far field directivity and radiation patterns of the LWA. This yields a fast and rigorous tool for the characterization of this type of antennas. Qualitative design guidelines to tailor the antenna directivity bandwidth are provided for the first time based on a detailed analysis of the excited modes. Numerical examples are given to demonstrate the technique and prove the improvement in the antenna bandwidth. The proposed antenna exhibits a six-fold bandwidth improvement compared with the single array LWA with the same directivity. Simulated and experimental results from a finite size antenna prototype are presented.,
An Optimal-Dimensionality Sampling Scheme on the Sphere With Fast Spherical Harmonic Transforms,"We develop a sampling scheme on the sphere that permits accurate computation of the spherical harmonic transform and its inverse for signals band-limited at L using only L2 samples. We obtain the optimal number of samples given by the degrees of freedom of the signal in harmonic space. The number of samples required in our scheme is a factor of two or four fewer than existing techniques, which require either 2L2 or 4L2 samples. We note, however, that we do not recover a sampling theorem on the sphere, where spherical harmonic transforms are theoretically exact. Nevertheless, we achieve high accuracy even for very large band-limits. For our optimal-dimensionality sampling scheme, we develop a fast and accurate algorithm to compute the spherical harmonic transform (and inverse), with computational complexity comparable with existing schemes in practice. We conduct numerical experiments to study in detail the stability, accuracy and computational complexity of the proposed transforms. We also highlight the advantages of the proposed sampling scheme and associated transforms in the context of potential applications.","Harmonic analysis,
Transforms,
Vectors,
Frequency modulation,
Accuracy,
Computational complexity"
Parallel Real-Time Scheduling of DAGs,"Recently, multi-core processors have become mainstream in processor design. To take full advantage of multi-core processing, computation-intensive real-time systems must exploit intra-task parallelism. In this paper, we address the problem of realtime scheduling for a general model of deterministic parallel tasks, where each task is represented as a directed acyclic graph (DAG) with nodes having arbitrary execution requirements. We prove processor-speed augmentation bounds for both preemptive and nonpreemptive real-time scheduling for general DAG tasks on multi-core processors. We first decompose each DAG into sequential tasks with their own release times and deadlines. Then we prove that these decomposed tasks can be scheduled using preemptive global EDF with a resource augmentation bound of 4. This bound is as good as the best known bound for more restrictive models, and is the first for a general DAG model. We also prove that the decomposition has a resource augmentation bound of 4 plus a constant non-preemption overhead for non-preemptive global EDF scheduling. To our knowledge, this is the first resource augmentation bound for non-preemptive scheduling of parallel tasks. Finally, we evaluate our analytical results through simulations that demonstrate that the derived resource augmentation bounds are safe in practice.","Real-time systems,
Processor scheduling,
Schedules,
Job shop scheduling,
Multicore processing,
Timing"
A Si-Micromachined 162-Stage Two-Part Knudsen Pump for On-Chip Vacuum,"This paper investigates a two-part architecture for a Knudsen vacuum pump with no moving parts. This type of pump exploits the thermal transpiration that results from the free-molecular flow in nonisothermal channels. For a high compression ratio, 162 stages are serially cascaded. The two-part architecture uses 54 stages designed for the pressure range from 760 to ≈ 50 Torr, and 108 stages designed for lower pressures. This approach provides greater compression ratio and speed than using a uniform design for each stage. Finite element simulations and analytical design analysis are presented. A five-mask single-wafer fabrication process is used for monolithic integration of the Knudsen pump that has a footprint of 12 × 15 mm2. The pressure levels of each stage are measured by integrated Pirani gauges. Experimental evaluation shows that, using an input power of ≈ 0.39 W, the evacuated chamber is reduced from 760 to ≈ 0.9 Torr, resulting in a compression ratio of ≈ 844. The vacuum levels are sustained during 37 days of continuous operation.","Standards,
Creep,
Hydraulic diameter,
Fabrication,
Cavity resonators,
Heating,
System-on-chip"
Measuring Time-Varying Information Flow in Scalp EEG Signals: Orthogonalized Partial Directed Coherence,"This study aimed to develop a time-frequency method for measuring directional interactions over time and frequency from scalp-recorded electroencephalographic (EEG) signals in a way that is less affected by volume conduction and amplitude scaling. We modified the time-varying generalized partial directed coherence (tv-gPDC) method, by orthogonalization of the strictly causal multivariate autoregressive model coefficients, to minimize the effect of mutual sources. The novel measure, generalized orthogonalized PDC (gOPDC), was tested first using two simulated models with feature dimensions relevant to EEG activities. We then used the method for assessing event-related directional information flow from flash-evoked responses in neonatal EEG. For testing statistical significance of the findings, we followed a thresholding procedure driven by baseline periods in the same EEG activity. The results suggest that the gOPDC method 1) is able to remove common components akin to volume conduction effect in the scalp EEG, 2) handles the potential challenge with different amplitude scaling within multichannel signals, and 3) can detect directed information flow within a subsecond time scale in nonstationary multichannel EEG datasets. This method holds promise for estimating directed interactions between scalp EEG channels that are commonly affected by the confounding impact of mutual cortical sources.","Electroencephalography,
Brain modeling,
Coherence,
Scalp,
Pediatrics,
Educational institutions"
On Continuous User Authentication via Typing Behavior,"We hypothesize that an individual computer user has a unique and consistent habitual pattern of hand movements, independent of the text, while typing on a keyboard. As a result, this paper proposes a novel biometric modality named typing behavior (TB) for continuous user authentication. Given a webcam pointing toward a keyboard, we develop real-time computer vision algorithms to automatically extract hand movement patterns from the video stream. Unlike the typical continuous biometrics, such as keystroke dynamics (KD), TB provides a reliable authentication with a short delay, while avoiding explicit key-logging. We collect a video database where 63 unique subjects type static text and free text for multiple sessions. For one typing video, the hands are segmented in each frame and a unique descriptor is extracted based on the shape and position of hands, as well as their temporal dynamics in the video sequence. We propose a novel approach, named bag of multi-dimensional phrases, to match the cross-feature and cross-temporal pattern between a gallery sequence and probe sequence. The experimental results demonstrate a superior performance of TB when compared with KD, which, together with our ultrareal-time demo system, warrant further investigation of this novel vision application and biometric modality.","Authentication,
Shape,
Feature extraction,
Histograms,
Keyboards,
Mice,
Computers"
Internet Traffic Classification Using Constrained Clustering,"Statistics-based Internet traffic classification using machine learning techniques has attracted extensive research interest lately, because of the increasing ineffectiveness of traditional port-based and payload-based approaches. In particular, unsupervised learning, that is, traffic clustering, is very important in real-life applications, where labeled training data are difficult to obtain and new patterns keep emerging. Although previous studies have applied some classic clustering algorithms such as K-Means and EM for the task, the quality of resultant traffic clusters was far from satisfactory. In order to improve the accuracy of traffic clustering, we propose a constrained clustering scheme that makes decisions with consideration of some background information in addition to the observed traffic statistics. Specifically, we make use of equivalence set constraints indicating that particular sets of flows are using the same application layer protocols, which can be efficiently inferred from packet headers according to the background knowledge of TCP/IP networking. We model the observed data and constraints using Gaussian mixture density and adapt an approximate algorithm for the maximum likelihood estimation of model parameters. Moreover, we study the effects of unsupervised feature discretization on traffic clustering by using a fundamental binning method. A number of real-world Internet traffic traces have been used in our evaluation, and the results show that the proposed approach not only improves the quality of traffic clusters in terms of overall accuracy and per-class metrics, but also speeds up the convergence.","Internet,
Clustering algorithms,
Unsupervised learning,
Accuracy,
Adaptation models,
Data models,
Maximum likelihood estimation"
Two-Stage Cost-Sensitive Learning for Software Defect Prediction,"Software defect prediction (SDP), which classifies software modules into defect-prone and not-defect-prone categories, provides an effective way to maintain high quality software systems. Most existing SDP models attempt to attain lower classification error rates other than lower misclassification costs. However, in many real-world applications, misclassifying defect-prone modules as not-defect-prone ones usually leads to higher costs than misclassifying not-defect-prone modules as defect-prone ones. In this paper, we first propose a new two-stage cost-sensitive learning (TSCS) method for SDP, by utilizing cost information not only in the classification stage but also in the feature selection stage. Then, specifically for the feature selection stage, we develop three novel cost-sensitive feature selection algorithms, namely, Cost-Sensitive Variance Score (CSVS), Cost-Sensitive Laplacian Score (CSLS), and Cost-Sensitive Constraint Score (CSCS), by incorporating cost information into traditional feature selection algorithms. The proposed methods are evaluated on seven real data sets from NASA projects. Experimental results suggest that our TSCS method achieves better performance in software defect prediction compared to existing single-stage cost-sensitive classifiers. Also, our experiments show that the proposed cost-sensitive feature selection methods outperform traditional cost-blind feature selection methods, validating the efficacy of using cost information in the feature selection stage.","Software algorithms,
Prediction algorithms,
Neural networks,
Software metrics,
Software systems"
Reachability Analysis of Nonlinear Differential-Algebraic Systems,"This paper presents a numerical procedure for the reachability analysis of systems with nonlinear, semi-explicit, index-1 differential-algebraic equations. The procedure computes reachable sets for uncertain initial states and inputs in an overapproximative way, i.e. it is guaranteed that all possible trajectories of the system are enclosed. Thus, the result can be used for formal verification of system properties that can be specified in the state space as unsafe or goal regions. Due to the representation of reachable sets by zonotopes and the use of highly scalable operations on them, the presented approach scales favorably with the number of state variables. This makes it possible to solve problems of industry-relevant size, as demonstrated by a transient stability analysis of the IEEE 14-bus benchmark problem for power systems.","Reachability analysis,
Mathematical model,
Vectors,
Equations,
Linear systems,
Differential equations,
Indexes"
Automated Removal of EKG Artifact From EEG Data Using Independent Component Analysis and Continuous Wavelet Transformation,"The electrical potential produced by the cardiac activity sometimes contaminates electroencephalogram (EEG) recordings, resulting in spiky activities that are referred to as electrocardiographic (EKG) artifact. For a variety of reasons it is often desirable to automatically detect and remove these artifacts. Especially, for accurate source localization of epileptic spikes in an EEG recording from a patient with epilepsy, it is of great importance to remove any concurrent artifact. Due to similarities in morphology between the EKG artifacts and epileptic spikes, any automated artifact removal algorithm must have an extremely low false-positive rate in addition to a high detection rate. In this paper, an automated algorithm for removal of EKG artifact is proposed that satisfies such criteria. The proposed method, which uses combines independent component analysis and continuous wavelet transformation, uses both temporal and spatial characteristics of EKG related potentials to identify and remove the artifacts. The method outperforms algorithms that use general statistical features such as entropy and kurtosis for artifact rejection.","Electrocardiography,
Electroencephalography,
Integrated circuits,
Continuous wavelet transforms,
Scalp,
Algorithm design and analysis,
Entropy"
Visual SLAM for Handheld Monocular Endoscope,"Simultaneous localization and mapping (SLAM) methods provide real-time estimation of 3-D models from the sole input of a handheld camera, routinely in mobile robotics scenarios. Medical endoscopic sequences mimic a robotic scenario in which a handheld camera (monocular endoscope) moves along an unknown trajectory while observing an unknown cavity. However, the feasibility and accuracy of SLAM methods have not been extensively validated with human in vivo image sequences. In this work, we propose a monocular visual SLAM algorithm tailored to deal with medical image sequences in order to provide an up-to-scale 3-D map of the observed cavity and the endoscope trajectory at frame rate. The algorithm is validated over synthetic data and human in vivo sequences corresponding to 15 laparoscopic hernioplasties where accurate ground-truth distances are available. It can be concluded that the proposed procedure is: 1) noninvasive, because only a standard monocular endoscope and a surgical tool are used; 2) convenient, because only a hand-controlled exploratory motion is needed; 3) fast, because the algorithm provides the 3-D map and the trajectory in real time; 4) accurate, because it has been validated with respect to ground-truth; and 5) robust to inter-patient variability, because it has performed successfully over the validation sequences.","Three-dimensional displays,
Simultaneous localization and mapping,
Cameras,
Cavity resonators,
Endoscopes,
Real-time systems,
Biomedical imaging"
On the Landscape of Combinatorial Optimization Problems,"This paper carries out a comparison of the fitness landscape for four classic optimization problems: Max-Sat, graph-coloring, traveling salesman, and quadratic assignment. We have focused on two types of properties, local average properties of the landscape, and properties of the local optima. For the local optima we give a fairly comprehensive description of the properties, including the expected time to reach a local optimum, the number of local optima at different cost levels, the distance between optima, and the expected probability of reaching the optima. Principle component analysis is used to understand the correlations between the local optima. Most of the properties that we examine have not been studied previously, particularly those concerned with properties of the local optima. We compare and contrast the behavior of the four different problems. Although the problems are very different at the low level, many of the long-range properties exhibit a remarkable degree of similarity.","Optimization,
Color,
Correlation,
Hamming distance,
Search problems,
Algorithm design and analysis"
Au-Free Normally-Off AlGaN/GaN-on-Si MIS-HEMTs Using Combined Partially Recessed and Fluorinated Trap-Charge Gate Structures,"In this letter, partially recessed gate structures in conjunction with negative trap charges by F- plasma treatments both at AlGaN barrier and on gate dielectric surface are employed to realize the normally-OFF operation for AlGaN/GaN Metal-Insulator-Semiconductor High Electron Mobility Transistors in Au-free scheme. A partial gate recessed trench is designed to effectively reduce the 2-D electron gas (2DEG) density and achieve positive threshold voltage (Vth) without severe degradation in 2-DEG channel mobility. Furthermore, the fixed trap charges are innovatively placed at the gate AlGaN and Si3N4 layers by a two-stage F- plasma treatment to further increase the Vth, without mobility degradation. A high Vth of 1.9 V and a drain current ~200 mA/mm are achieved in the fabricated device, which also has a lower leakage current and the higher breakdown voltage of 580 V.","Logic gates,
Aluminum gallium nitride,
HEMTs,
MODFETs,
Gallium nitride,
Plasmas,
Dielectrics"
Error Bars Considered Harmful: Exploring Alternate Encodings for Mean and Error,"When making an inference or comparison with uncertain, noisy, or incomplete data, measurement error and confidence intervals can be as important for judgment as the actual mean values of different groups. These often misunderstood statistical quantities are frequently represented by bar charts with error bars. This paper investigates drawbacks with this standard encoding, and considers a set of alternatives designed to more effectively communicate the implications of mean and error data to a general audience, drawing from lessons learned from the use of visual statistics in the information visualization community. We present a series of crowd-sourced experiments that confirm that the encoding of mean and error significantly changes how viewers make decisions about uncertain data. Careful consideration of design tradeoffs in the visual presentation of data results in human reasoning that is more consistently aligned with statistical inferences. We suggest the use of gradient plots (which use transparency to encode uncertainty) and violin plots (which use width) as better alternatives for inferential tasks than bar charts with error bars.","Encoding,
Information analysis,
Data visualization,
Standards,
Error analysis"
The Manumeter: A Wearable Device for Monitoring Daily Use of the Wrist and Fingers,"Nonobtrusive options for monitoring the wrist and hand movement are needed for stroke rehabilitation and other applications. This paper describes the “manumeter,” a device that logs total angular distance travelled by wrist and finger joints using a magnetic ring worn on the index finger and two triaxial magnetometers mounted in a watch-like unit. We describe an approach to estimate the wrist and finger joint angles using a radial basis function network that maps differential magnetometer readings to joint angles. We tested this approach by comparing manumeter estimates of total angular excursion with those from a passive goniometric exoskeleton worn simultaneously as seven participants completed a set of 12 manual tasks at low-, medium-, and high-intensity conditions on a first testing day, 1-2 days later, and 6-8 days later, using only the original calibration from the first testing day. Manumeter estimates scaled proportionally to the intensity of hand activity. Estimates of angular excursion made with the manumeter were 92.5% ± 28.4 (SD), 98.3% ± 23.3, and 94.7% ± 19.3 of the goniometric exoskeleton across the three testing days, respectively. Magnetic sensing of wrist and finger movement is nonobtrusive and can quantify the amount of use of the hand across days.",
Gait and Balance Analysis for Patients With Alzheimer's Disease Using an Inertial-Sensor-Based Wearable Instrument,"Despite patients with Alzheimer's disease (AD) were reported of revealing gait disorders and balance problems, there is still lack of objective quantitative measurement of gait patterns and balance capability of AD patients. Based on an inertial-sensor-based wearable device, this paper develops gait and balance analyzing algorithms to obtain quantitative measurements and explores the essential indicators from the measurements for AD diagnosis. The gait analyzing algorithm is composed of stride detection followed by gait cycle decomposition so that gait parameters are developed from the decomposed gait details. On the other hand, the balance is measured by the sway speed in anterior-posterior (AP) and medial-lateral (ML) directions of the projection path of body's center of mass (COM). These devised gait and balance parameters were explored on twenty-one AD patients and fifty healthy controls (HCs). Special evaluation procedure including single-task and dual-task walking experiments for observing the cognitive function and attention is also devised for the comparison of AD and HC groups. Experimental results show that the wearable instrument with the designed gait and balance analyzing system is a promising tool for automatically analyzing gait information and balance ability, serving as assistant indicators for early diagnosis of AD.",
Antenna Shape Synthesis Without Prior Specification of the Feedpoint Locations,An antenna shape synthesis method is proposed that allows shaping of the antenna geometry prior to specification of the feed location and type. This reduces the constraints placed on the optimization process and can lead to potentially new designs due to the increased degree of freedom afforded. An appropriate feedpoint is easily chosen after shape optimization by selecting a location on the resulting structure for best impedance matching. The procedure is made possible through the use of characteristic mode concepts. Examples show that the antenna-Q values of the resulting shaped radiators closely approach the fundamental bounds.,"Shape,
Eigenvalues and eigenfunctions,
Optimization,
Antenna feeds,
Surface impedance,
Resonant frequency"
Noninvasive Diabetes Mellitus Detection Using Facial Block Color With a Sparse Representation Classifier,"Diabetes mellitus (DM) is gradually becoming an epidemic, affecting almost every single country. This has placed a tremendous amount of burden on governments and healthcare officials. In this paper, we propose a new noninvasive method to detect DM based on facial block color features with a sparse representation classifier (SRC). A noninvasive capture device with image correction is initially used to capture a facial image consisting of four facial blocks strategically placed around the face. Six centroids from a facial color gamut are applied to calculate the facial color features of each block. This means that a given facial block can be represented by its facial color features. For SRC, two subdictionaries, a Healthy facial color features subdictionary and DM facial color features subdictionary, are employed in the SRC process. Experimental results are shown for a dataset consisting of 142 Healthy and 284 DM samples. Using a combination of the facial blocks, the SRC can distinguish Healthy and DM classes with an average accuracy of 97.54%.","Image color analysis,
Color,
Feature extraction,
Training,
Accuracy,
Diabetes,
Face"
Real-Time Implementation of Intelligent Reconfiguration Algorithm for Microgrid,"Microgrids with renewable distributed generation and energy storage offer sustainable energy solutions. To maintain the availability of energy to the connected loads, considering priority and to interrupt the smallest portion of the microgrid under any abnormal conditions, reconfiguration is critical to restore service to a section or to meet some operational requirements of dropping minimum loads. Reconfiguration is the process of modifying the microgrid's topological structure by changing the status (open/close) of the circuit breakers or switches. In this work, constraints are the power balance equation and power generation limits, and we assumed that the system is designed with the entire planning and operational control criterion to meet the voltage violation and line overloading constraints. This paper offers novel real-time implementation of intelligent algorithm for microgrid reconfiguration. Intelligent algorithm is based on the genetic algorithms and has been tested on two test systems including shipboard power system and modified Consortium for Electric Reliability Technology Solutions (CERTS) microgrid. Real-time test bed utilizes real-time digital simulator and commercial real-time controllers from Schweitzer Engineering Lab. Reconfiguration algorithm has been implemented in the real time using real-time test bed, e.g., microgrid system, and satisfactory results were obtained.",
Big data: transforming the design philosophy of future internet,"Big data opens the era of the fourth paradigm for science discovery through datadriven computing. This new paradigm applies to the design of the future Internet, which currently faces issues in supporting new applications, efficient resource utilization, and continuous evolvement. We observe several technological transformations in network architecture, services, and applications, and point out the grand opportunities for designing future Internet architecture, communication models, and resource management mechanisms enabled by the availability of massive network data. In particular, we envision in the future Internet: 1) computational complexity replaces state complexity in the control plane; 2) data intelligence enables user choices and rewards innovations; and 3) correlations from data analytics help solve inherently hard optimization problems. Finally, we identify the key challenges in data-driven Internet design and outline future research directions.","Internet,
Computer architecture,
Network architecture,
Resource management,
Big data,
Computational modeling"
Real-time pose estimation of deformable objects using a volumetric approach,"Pose estimation of deformable objects is a fundamental and challenging problem in robotics. We present a novel solution to this problem by first reconstructing a 3D model of the object from a low-cost depth sensor such as Kinect, and then searching a database of simulated models in different poses to predict the pose. Given noisy depth images from 360-degree views of the target object acquired from the Kinect sensor, we reconstruct a smooth 3D model of the object using depth image segmentation and volumetric fusion. Then with an efficient feature extraction and matching scheme, we search the database, which contains a large number of deformable objects in different poses, to obtain the most similar model, whose pose is then adopted as the prediction. Extensive experiments demonstrate better accuracy and orders of magnitude speed-up compared to our previous work. An additional benefit of our method is that it produces a high-quality mesh model and camera pose, which is necessary for other tasks such as regrasping and object manipulation.","Clothing,
Three-dimensional displays,
Solid modeling,
Grasping,
Robot sensing systems,
Feature extraction"
Topic-Sensitive Influencer Mining in Interest-Based Social Media Networks via Hypergraph Learning,"Social media is emerging as a new mainstream means of interacting around online media. Social influence mining in social networks is therefore of critical importance in real-world applications such as friend suggestion and photo recommendation. Social media is inherently multimodal, including rich types of user contributed content and social link information. Most of the existing research suffers from two limitations: 1) only utilizing the textual information, and/or 2) only analyzing the generic influence but ignoring the more important topic-level influence. To address these limitations, in this paper we develop a novel Topic-Sensitive Influencer Mining (TSIM) framework in interest-based social media networks. Specifically, we take Flickr as the study platform. People in Flickr interact with each other through images. TSIM aims to find topical influential users and images. The influence estimation is determined with a hypergraph learning approach. In the hypergraph, the vertices represent users and images, and the hyperedges are utilized to capture multi-type relations including visual-textual content relations among images, and social links between users and images. Algorithmwise, TSIM first learns the topic distribution by leveraging user-contributed images, and then infers the influence strength under different topics for each node in the hypergraph. Extensive experiments on a real-world dataset of more than 50 K images and 70 K comment/favorite links from Flickr have demonstrated the effectiveness of our proposed framework. In addition, we also report promising results of friend suggestion and photo recommendation via TSIM on the same dataset.","Media,
Videos,
YouTube,
Electronic mail,
Nominations and elections"
Patchwork-Based Audio Watermarking Method Robust to De-synchronization Attacks,"This paper presents a patchwork-based audio watermarking method to resist de-synchronization attacks such as pitch-scaling, time-scaling, and jitter attacks. At the embedding stage, the watermarks are embedded into the host audio signal in the discrete cosine transform (DCT) domain. Then, a set of synchronization bits are implanted into the watermarked signal in the logarithmic DCT (LDCT) domain. At the decoding stage, we analyze the received audio signal in the LDCT domain to find the scaling factor imposed by an attack. Then, we modify the received signal to remove the scaling effect, together with the embedded synchronization bits. After that, watermarks are extracted from the modified signal. Simulation results show that at the embedding rate of 10 bps, the proposed method achieves 98.9% detection rate on average under the considered de-synchronization attacks. At the embedding rate of 16 bps, it can still obtain 94.7% detection rate on average. So, the proposed method is much more robust to de-synchronization attacks than other patchwork watermarking methods. Compared with the audio watermarking methods designed for tackling de-synchronization attacks, our method has much higher embedding capacity.","Watermarking,
Synchronization,
Discrete cosine transforms,
Decoding,
Robustness,
Indexes,
Cepstral analysis"
Optimal Camera Placement for Providing Angular Coverage in Wireless Video Sensor Networks,"Wireless Video Sensor Networks (WVSNs) provide opportunities to use large number of low-cost low-resolution wireless camera sensors for large-scale outdoor remote surveillance missions. Camera sensor deployment is crucial in achieving good coverage, accuracy and fault tolerance. In particular, with the decreased costs of wireless cameras, redundant camera deployment is attractive in order to get multiple disparate views of events for improved event identification. If the capturing of an event spans 360°, this is referred to as angular coverage. In this paper, we consider the problem of determining optimal camera placement to achieve angular coverage continuously over a given region. We develop a bi-level algorithm to find the minimum-cost camera placement. In the first level, we run a master problem that identifies the camera placement points to achieve angular coverage of a discrete set of points selected from the region of interest. Next, we use a sub-problem to identify points in the continuous region that are not covered by the cameras placed in the previous run of the master problem. We then add these uncovered points to discrete point set of the master problem and re-run the master problem. We continue running the master and sub-problems iteratively until the sub-problem becomes infeasible indicating that the entire region is covered. In the numerical experiments, we consider two cases 1) placement of homogeneous cameras with fixed resolutions; and 2) placement of heterogeneous cameras with different characteristics and resolutions. We also introduce varying resolution requirements for different parts of the region and place the cameras such that the required resolution is satisfied. The numerical results show the superiority of the bi-level approach respect to existing approaches.","Cameras,
Wireless communication,
Wireless sensor networks,
Surveillance,
Measurement,
Shape"
Downlink Spectral Efficiency of Distributed Antenna Systems Under a Stochastic Model,"This paper studies the downlink spectral efficiency of distributed antenna system (DAS) where antenna ports are distributed as a Poisson point process (PPP), while assuming channel state information is not available at the transmitter and each antenna has an individual power constraint. We first consider the case with a single user per cell and analyze regular DAS with fixed cell boundaries, and study both blanket transmission where the user is served by all the antenna ports within each cell, and selective transmission where only the closest antenna port to the user within each cell is selected. We derive efficiently computable spectral efficiency expressions as a function of the user location, and show the limitation of blanket transmission by establishing that the cell-edge spectral efficiency under blanket transmission is upper bounded by a constant. Further, from a network perspective, we also model users as a PPP and assume a time-division multiple-access (TDMA) scheme, and give analytical expressions for and compare the average spectral efficiencies of regular DAS and user-centric DAS where no fixed cell boundaries exist. We validate our models with simulation, and show that selective transmission outperforms blanket transmission for regular DAS, and user-centric DAS with selective transmission achieves a higher spectral efficiency averaged over the network than regular DAS.",
Towards a unified behavior trees framework for robot control,"This paper presents a unified framework for Behavior Trees (BTs), a plan representation and execution tool. The available literature lacks the consistency and mathematical rigor required for robotic and control applications. Therefore, we approach this problem in two steps: first, reviewing the most popular BT literature exposing the aforementioned issues; second, describing our unified BT framework along with equivalence notions between BTs and Controlled Hybrid Dynamical Systems (CHDSs). This paper improves on the existing state of the art as it describes BTs in a more accurate and compact way, while providing insight about their actual representation capabilities. Lastly, we demonstrate the applicability of our framework to real systems scheduling open-loop actions in a grasping mission that involves a NAO robot and our BT library.","Vehicles,
Tin,
Robots,
Trajectory,
Heuristic algorithms,
Synchronization"
"Single- and Multiple-Event Induced Upsets in
HfO
2
/Hf
1T1R RRAM","Single-event upsets in 1T1R Resistive Random Access Memory (RRAM) structures are experimentally demonstrated by generating current transients in the access transistors of the memory cells. The relationship between the single-event upset threshold of the RRAM and the applied voltage is exponential, which is verified using TPA laser analysis and heavy-ion irradiation. Multiple-Event Upsets (MEUs) also occur, where individual ions incrementally change the RRAM's resistance until their cumulative effect causes an upset. Single-event models are presented that allow direct correlation of the voltage across the RRAM, caused by the ion-generated current transient, and the change in RRAM resistance. The RRAM is vulnerable only in the high resistance state, when a voltage capable of writing to the cell is applied to the bit line. This is approximately 0.5% of the memory element's operation time, leading to relatively low projected upset rates.","Transient analysis,
Resistance,
Transistors,
Testing,
Measurement by laser beam,
Electrical resistance measurement,
Lasers"
Design of a Breath Analysis System for Diabetes Screening and Blood Glucose Level Prediction,"It has been reported that concentrations of several biomarkers in diabetics' breath show significant difference from those in healthy people's breath. Concentrations of some biomarkers are also correlated with the blood glucose levels (BGLs) of diabetics. Therefore, it is possible to screen for diabetes and predict BGLs by analyzing one's breath. In this paper, we describe the design of a novel breath analysis system for this purpose. The system uses carefully selected chemical sensors to detect biomarkers in breath. Common interferential factors, including humidity and the ratio of alveolar air in breath, are compensated or handled in the algorithm. Considering the intersubject variance of the components in breath, we build subject-specific prediction models to improve the accuracy of BGL prediction. A total of 295 breath samples from healthy subjects and 279 samples from diabetic subjects were collected to evaluate the performance of the system. The sensitivity and specificity of diabetes screening are 91.51% and 90.77%, respectively. The mean relative absolute error for BGL prediction is 21.7%. Experiments show that the system is effective and that the strategies adopted in the system can improve its accuracy. The system potentially provides a noninvasive and convenient method for diabetes screening and BGL monitoring as an adjunct to the standard criteria.",
Surface Wave Transformation Lens Antennas,"A new class of dielectric sheet antennas is presented based on transformation optics. Specifically, we successfully implement the transformation with a consideration of surface wave eigenmode properties, and carry out a practical perforated design by drilling holes to synthesize the required dielectric constants for their potential realization. The full wave simulation shows that our surface wave transformation lens antenna is capable of obtaining a greatly improved directivity, while maintaining the original low profile.","Lenses,
Surface waves,
Antennas,
Permittivity,
Optical surface waves,
Surface impedance,
Substrates"
Gain Scheduled Control of Linear Systems Subject to Actuator Saturation With Application to Spacecraft Rendezvous,"This brief is concerned with gain scheduled approaches to the stabilization of linear systems with actuator saturation. For linear systems that are polynomially unstable, using the parametric Lyapunov equation-based and Riccati equation-based design, we propose gain scheduling approaches to increase the design parameter online so as to increase the convergence rates of the closed-loop systems. To apply the proposed gain scheduling approaches, only a scalar differential equation whose right-hand side is a function of the state vector is required to be integrated online. The closed-loop system is proven to be exponentially stable provided some parameters in the scheduling law are properly chosen. The established gain scheduling approaches are also extended to exponentially unstable linear systems with actuator saturation. As applications of the proposed dynamic gain scheduling approaches, the controller design of spacecraft rendezvous systems is revisited. Numerical simulation with the nonlinear model of a spacecraft rendezvous system shows the effectiveness of the proposed gain scheduling approaches.","Closed loop systems,
Space vehicles,
Linear systems,
Convergence,
Eigenvalues and eigenfunctions,
Dynamic scheduling"
DataClouds: Enabling Community-Based Data-Centric Services Over the Internet of Things,"The Internet of Things (IoT) is emerging as one of the major trends for the next evolution of the Internet, where billions of physical objects or things (including but not limited to humans) will be connected over the Internet, and a vast amount of information data will be shared among them. However, the current Internet was built on a host-centric communication model, which was primarily designed for meeting the demand of pair-wise peer-to-peer communications and cannot well accommodate various advanced data-centric services boosted by the IoT in which users care about content and are oblivious to locations where the content is stored. In this paper, we propose a novel architecture for the future Internet based on information-centric networking (ICN), which is called DataClouds, to better accommodate data-centric services. Different from existing ICN-based architectures, we take the sharing nature of data-centric services under the IoT into consideration and introduce logically and physically formed communities as the basic building blocks to construct the network so that data could be more efficiently shared and disseminated among interested users. We also elaborate on several fundamental design challenges for the Internet under this new architecture and show that DataClouds could offer more efficient and flexible solutions than traditional ICN-based architectures.","Cloud computing,
Wireless sensor networks,
Internet of Things,
Mobile radio mobility management,
Computer architecture"
Cloud-Based Mobile Multimedia Recommendation System With User Behavior Information,"Facing massive multimedia services and contents in the Internet, mobile users usually waste a lot of time to obtain their interests. Therefore, various context-aware recommendation systems have been proposed. Most of those proposed systems deploy a large number of context collectors at terminals and access networks. However, the context collecting and exchanging result in heavy network overhead, and the context processing consumes huge computation. In this paper, a cloud-based mobile multimedia recommendation system which can reduce network overhead and speed up the recommendation process is proposed. The users are classified into several groups according to their context types and values. With the accurate classification rules, the context details are not necessary to compute, and the huge network overhead is reduced. Moreover, user contexts, user relationships, and user profiles are collected from video-sharing websites to generate multimedia recommendation rules based on the Hadoop platform. When a new user request arrives, the rules will be extended and optimized to make real-time recommendation. The results show that the proposed approach can recommend desired services with high precision, high recall, and low response delay.","Context,
Mobile communication,
Multimedia communication,
Recommender systems,
Streaming media,
Real-time systems"
Learning Race from Face: A Survey,"Faces convey a wealth of social signals, including race, expression, identity, age and gender, all of which have attracted increasing attention from multi-disciplinary research, such as psychology, neuroscience, computer science, to name a few. Gleaned from recent advances in computer vision, computer graphics, and machine learning, computational intelligence based racial face analysis has been particularly popular due to its significant potential and broader impacts in extensive real-world applications, such as security and defense, surveillance, human computer interface (HCI), biometric-based identification, among others. These studies raise an important question: How implicit, non-declarative racial category can be conceptually modeled and quantitatively inferred from the face? Nevertheless, race classification is challenging due to its ambiguity and complexity depending on context and criteria. To address this challenge, recently, significant efforts have been reported toward race detection and categorization in the community. This survey provides a comprehensive and critical review of the state-of-the-art advances in face-race perception, principles, algorithms, and applications. We first discuss race perception problem formulation and motivation, while highlighting the conceptual potentials of racial face processing. Next, taxonomy of feature representational models, algorithms, performance and racial databases are presented with systematic discussions within the unified learning scenario. Finally, in order to stimulate future research in this field, we also highlight the major opportunities and challenges, as well as potentially important cross-cutting themes and research directions for the issue of learning race from face.","Cultural differences,
Face recognition,
Computer vision,
Computational modeling,
Feature extraction,
Psychology,
Image classification,
Image color analysis"
Smith Predictor-Based Robot Control for Ultrasound-Guided Teleoperated Beating-Heart Surgery,"Performing surgery on fast-moving heart structures while the heart is freely beating is next to impossible. Nevertheless, the ability to do this would greatly benefit patients. By controlling a teleoperated robot to continuously follow the heart's motion, the heart can be made to appear stationary. The surgeon will then be able to operate on a seemingly stationary heart when in reality it is freely beating. The heart's motion is measured from ultrasound images and thus involves a non-negligible delay due to image acquisition and processing, estimated to be 150 ms that, if not compensated for, can cause the teleoperated robot's end-effector (i.e., the surgical tool) to collide with and puncture the heart. This research proposes the use of a Smith predictor to compensate for this time delay in calculating the reference position for the teleoperated robot. The results suggest that heart motion tracking is improved as the introduction of the Smith predictor significantly decreases the mean absolute error, which is the error in making the distance between the robot's end-effector and the heart follow the surgeon's motion, and the mean integrated square error.",
Distributed and Asynchronous Data Collection in Cognitive Radio Networks with Fairness Consideration,"As a promising communication paradigm, Cognitive Radio Networks (CRNs) have paved a road for Secondary Users (SUs) to opportunistically exploit unused licensed spectrum without causing unacceptable interference to Primary Users (PUs). In this paper, we study the distributed data collection problem for asynchronous CRNs, which has not been addressed before. We study the Proper Carrier-sensing Range (PCR) for SUs. By working with this PCR, an SU can successfully conduct data transmission without disturbing the activities of PUs and other SUs. Subsequently, based on the PCR, we propose an Asynchronous Distributed Data Collection (ADDC) algorithm with fairness consideration for CRNs. ADDC collects a snapshot of data to the base station in a distributed manner without the time synchronization requirement. The algorithm is scalable and more practical compared with centralized and synchronized algorithms. Through comprehensive theoretical analysis, we show that ADDC is order-optimal in terms of delay and capacity, as long as an SU has a positive probability to access the spectrum. Furthermore, we extend ADDC to deal with the continuous data collection issue, and analyze the delay and capacity performances of ADDC for continuous data collection, which are also proven to be order-optimal. Finally, extensive simulation results indicate that ADDC can effectively accomplish a data collection task and significantly reduce data collection delay.","Data collection,
Data communication,
Interference,
Delays,
Base stations,
Synchronization,
Wireless networks"
Secure Outsourced Attribute-Based Signatures,"Attribute-based signature (ABS) enables users to sign messages over attributes without revealing any information other than the fact that they have attested to the messages. However, heavy computational cost is required during signing in existing work of ABS, which grows linearly with the size of the predicate formula. As a result, this presents a significant challenge for resource-constrained devices (such as mobile devices or RFID tags) to perform such heavy computations independently. Aiming at tackling the challenge above, we first propose and formalize a new paradigm called Outsourced ABS, i.e., OABS, in which the computational overhead at user side is greatly reduced through outsourcing intensive computations to an untrusted signing-cloud service provider (S-CSP). Furthermore, we apply this novel paradigm to existing ABS schemes to reduce the complexity. As a result, we present two concrete OABS schemes: i) in the first OABS scheme, the number of exponentiations involving in signing is reduced from O(d) to O(1) (nearly three), where d is the upper bound of threshold value defined in the predicate; ii) our second scheme is built on Herranz et al.'s construction with constant-size signatures. The number of exponentiations in signing is reduced from O(d2) to O(d) and the communication overhead is O(1). Security analysis demonstrates that both OABS schemes are secure in terms of the unforgeability and attribute-signer privacy definitions specified in the proposed security model. Finally, to allow for high efficiency and flexibility, we discuss extensions of OABS and show how to achieve accountability as well.","Outsourcing,
Security,
Educational institutions,
Games,
Privacy,
Electronic mail,
Polynomials"
Miniaturized Dual-Band Antenna for Implantable Wireless Communications,"A miniaturized dual-band antenna is presented for implantable wireless communications. By introducing an offset at the feedpoint, dual-band performance of a dipole antenna is realized, operating at both Medical Implant Communications Service (MICS) 402-405 MHz and Industrial, Scientific, and Medical (ISM) 2.40-2.48 GHz bands. Parylene-C of thickness 20 μm is taken as a biocompatible insulating layer, and a rather compact size of 67.8 mm3 (10.02 mm × 10.02 mm × 0.675 mm) is obtained. In order to achieve good impedance matching at the feedpoint, an inductive loop is loaded at one of the dipole arms. The measured |S11 | in skin-mimicking gel shows that a bandwidth of 47.5% and 31.6% can be achieved at the MICS and ISM bands, respectively.","Dipole antennas,
Microwave integrated circuits,
Dual band,
Skin,
Impedance matching"
Denoise-and-Forward Network Coding for Two-Way Relay MIMO Systems,"In this paper, we propose a denoise-and-forward network coding (DNF-NC) transmission scheme for its applications in two-way relay multiple-input and multiple-output (MIMO) systems. We first consider a scenario with a single pair of source nodes, and minimum mean square error (MMSE) receiver is applied at each node. The global optimal precoding design based on the mean square error (MSE) criterion can be achieved by solving two independent convex optimization problems. To achieve a better tradeoff between performance and complexity, an alternative power optimization approach is proposed using a channel diagonalization technique. Then, we proceed to considering a more challenging bidirectional communication scenario with multiple pairs of source nodes. With intrapair coordination at the sources, we modify DNF-NC by employing a signal alignment technique to combat interpair interference. The numerical results demonstrate that the proposed DNF-NC schemes can significantly improve bit error rate (BER) performance in both two scenarios, and such performance gains can be achieved with relatively low computational complexity.","Relays,
Network coding,
MIMO,
Optimization,
Vectors,
Antennas,
Receivers"
Probability Models for Open Set Recognition,"Real-world tasks in computer vision often touch upon open set recognition: multi-class recognition with incomplete knowledge of the world and many unknown inputs. Recent work on this problem has proposed a model incorporating an open space risk term to account for the space beyond the reasonable support of known classes. This paper extends the general idea of open space risk limiting classification to accommodate non-linear classifiers in a multiclass setting. We introduce a new open set recognition model called compact abating probability (CAP), where the probability of class membership decreases in value (abates) as points move from known data toward open space. We show that CAP models improve open set recognition for multiple algorithms. Leveraging the CAP formulation, we go on to describe the novel Weibull-calibrated SVM (W-SVM) algorithm, which combines the useful properties of statistical extreme value theory for score calibration with one-class and binary support vector machines. Our experiments show that the W-SVM is significantly better for open set object detection and OCR problems when compared to the state-of-the-art for the same tasks.",
A Multi-Resolution FPGA-Based Architecture for Real-Time Edge and Corner Detection,"This work presents a new flexible parameterizable architecture for image and video processing with reduced latency and memory requirements, supporting a variable input resolution. The proposed architecture is optimized for feature detection, more specifically, the Canny edge detector and the Harris corner detector. The architecture contains neighborhood extractors and threshold operators that can be parameterized at runtime. Also, algorithm simplifications are employed to reduce mathematical complexity, memory requirements, and latency without losing reliability. Furthermore, we present the proposed architecture implementation on an FPGA-based platform and its analogous optimized implementation on a GPU-based architecture for comparison. A performance analysis of the FPGA and the GPU implementations, and an extra CPU reference implementation, shows the competitive throughput of the proposed architecture even at a much lower clock frequency than those of the GPU and the CPU. Also, the results show a clear advantage of the proposed architecture in terms of power consumption and maintain a reliable performance with noisy images, low latency and memory requirements.","Graphics processing units,
Image edge detection,
Computer architecture,
Detectors,
Instruction sets,
Feature extraction,
Field programmable gate arrays"
Downlink Radio Resource Partitioning with Fractional Frequency Reuse in Femtocell Networks,"Femtocell and fractional frequency reuse (FFR) techniques have received wide attention as the solutions to the data surge problem in mobile networks. With FFR, the frequency band of a macrocell is divided into several frequency partitions (FPs), and the transmission power levels assigned to FPs differ from each other. In this paper, we propose a downlink resource partitioning scheme for two-tier networks, where macrocells adopting FFR are overlaid with the femtocells. With the proposed scheme, every FP is divided into the macro-dedicated, the shared, and the femto-dedicated portions. The ratio of these three portions is different for each FP. We suggest a method to determine a proper ratio of portions in each FP by using an optimization approach. Simulation results show that the proposed scheme maximizes the whole system capacity while satisfying the constraints on the minimum capacity requirement for both macrocell and femtocell.","femtocellular radio,
optimisation"
Monolithic Integration of AlGaN/GaN HEMT on LED by MOCVD,"Monolithic integration of high-performance AlGaN/GaN high-electron mobility transistors (HEMTs) and blue light emitting diodes (LEDs) on sapphire substrates has been demonstrated by metal organic chemical vapor deposition selective growth technique. The integrated HEMT-LED exhibits a peak transconductance (Gm) of 244 mS/mm, a maximum drain current (Id) of 920 mA/mm, and an ON-resistance (Ron) of 2.6 Ω·mm. The forward voltage (VF) of the LED is 3.1 V under an injection current of 10 mA. The integrated LED emits modulated light power efficiently at a wavelength of 470 nm by a serially connected GaN HEMT, showing potential applications such as solid-state lighting, displays, and visible light communications.","HEMTs,
Light emitting diodes,
Gallium nitride,
Aluminum gallium nitride,
Logic gates,
Substrates,
MOCVD"
Building a Scalable System for Stealthy P2P-Botnet Detection,"Peer-to-peer (P2P) botnets have recently been adopted by botmasters for their resiliency against take-down efforts. Besides being harder to take down, modern botnets tend to be stealthier in the way they perform malicious activities, making current detection approaches ineffective. In addition, the rapidly growing volume of network traffic calls for high scalability of detection systems. In this paper, we propose a novel scalable botnet detection system capable of detecting stealthy P2P botnets. Our system first identifies all hosts that are likely engaged in P2P communications. It then derives statistical fingerprints to profile P2P traffic and further distinguish between P2P botnet traffic and legitimate P2P traffic. The parallelized computation with bounded complexity makes scalability a built-in feature of our system. Extensive evaluation has demonstrated both high detection accuracy and great scalability of the proposed system.","Peer-to-peer computing,
Scalability,
Electronic mail,
Educational institutions,
Overlay networks,
Monitoring,
Feature extraction"
Fourier-Based Transmit Beampattern Design Using MIMO Radar,"In multiple-input multiple-output (MIMO) radar settings, it is often desirable to transmit power only to a given location or set of locations defined by a beampattern. Transmit waveform design is a topic that has received much attention recently, involving synthesis of both the signal covariance matrix, R, as well as the actual waveforms. Current methods involve a two-step process of designing R via iterative solutions and then using R to generate waveforms that fulfill practical constraints such as having a constant-envelope or drawing from a finite alphabet. In this paper, a closed-form method to design R for a uniform linear array is proposed that utilizes the discrete Fourier transform (DFT) coefficients and Toeplitz matrices. The resulting covariance matrix fulfills the practical constraints such as positive semidefiniteness and the uniform elemental power constraint and provides performance similar to that of iterative methods, which require a much greater computation time. Next, a transmit architecture is presented that exploits the orthogonality of frequencies at discrete DFT values to transmit a sum of orthogonal signals from each antenna. The resulting waveforms provide a lower mean-square error than current methods at a much lower computational cost, and a simulated detection scenario demonstrates the performance advantages achieved.","Covariance matrices,
MIMO,
Iterative methods,
Transmitting antennas,
Discrete Fourier transforms,
Cost function,
MIMO radar"
Compressive Sensing of Sparse Tensors,"Compressive sensing (CS) has triggered an enormous research activity since its first appearance. CS exploits the signal's sparsity or compressibility in a particular domain and integrates data compression and acquisition, thus allowing exact reconstruction through relatively few nonadaptive linear measurements. While conventional CS theory relies on data representation in the form of vectors, many data types in various applications, such as color imaging, video sequences, and multisensor networks, are intrinsically represented by higher order tensors. Application of CS to higher order data representation is typically performed by conversion of the data to very long vectors that must be measured using very large sampling matrices, thus imposing a huge computational and memory burden. In this paper, we propose generalized tensor compressive sensing (GTCS)-a unified framework for CS of higher order tensors, which preserves the intrinsic structure of tensor data with reduced computational complexity at reconstruction. GTCS offers an efficient means for representation of multidimensional data by providing simultaneous acquisition and compression from all tensor modes. In addition, we propound two reconstruction procedures, a serial method and a parallelizable method. We then compare the performance of the proposed method with Kronecker compressive sensing (KCS) and multiway compressive sensing (MWCS). We demonstrate experimentally that GTCS outperforms KCS and MWCS in terms of both reconstruction accuracy (within a range of compression ratios) and processing speed. The major disadvantage of our methods (and of MWCS as well) is that the compression ratios may be worse than that offered by KCS.","Tensile stress,
Vectors,
Compressed sensing,
Image coding,
Image reconstruction,
Minimization,
Approximation methods"
Controlling the Relative Agent Motion in Multi-Agent Formation Stabilization,"In this technical note, we propose a novel technique to control the relative motion of multiple mobile agents as they stabilize to a desired configuration. In particular, we focus on the agents' relative velocities and the rate of change of their pairwise distances, and employ constructs from classic navigation functions (NFs) to control these quantities. Controlling agent velocities requires nontrivial extensions of the NF methodology to second-order models. Although in this work we propose a centralized framework to control the relative agent velocities, it adds a new dimension to the control of multi-agent systems with several advantages. In particular, we provide a novel approach to control the transient dynamics of a network that may facilitate the integration of continuous motion planing with discrete topology control. The result is verified theoretically and via computer simulations.","Navigation,
Topology,
Multi-agent systems,
Lyapunov methods,
Convergence,
Control systems,
Dynamics"
Bare Bones Particle Swarm Optimization With Scale Matrix Adaptation,"Bare bones particle swarm optimization (BBPSO) is a swarm algorithm that has shown potential for solving single-objective unconstrained optimization problems over continuous search spaces. However, it suffers of the premature convergence problem that means it may get trapped into a local optimum when solving multimodal problems. In order to address this drawback and improve the performance of the BBPSO, we propose a variant of this algorithm, named by us as BBPSO with scale matrix adaptation (SMA), SMA-BBPSO for short reference. In the SMA-BBPSO, the position of a particle is selected from a multivariate t -distribution with a rule for adaptation of its scale matrix. We use the multivariate t -distribution in its hierarchical form, as a scale mixtures of normal distributions. The t -distribution has heavier tails than those of the normal distribution, which increases the ability of the particles to escape from a local optimum. In addition, our approach includes the normal distribution as a particular case. As a consequence, the t -distribution can be applied during the optimization process by maintaining the proper balance between exploration and exploitation. We also propose a simple update rule to adapt the scale matrix associated with a particle. Our strategy consists of adapting the scale matrix of a particle such that the best position found by any particle in its neighborhood is sampled with maximum likelihood in the next iteration. A theoretical analysis was developed to explain how the SMA-BBPSO works, and an empirical study was carried out to evaluate the performance of the proposed algorithm. The experimental results show the suitability of the proposed approach in terms of effectiveness to find good solutions for all benchmark problems investigated. Nonparametric statistical tests indicate that SMA-BBPSO shows a statistically significant improvement compared with other swarm algorithms.","Gaussian distribution,
Optimization,
Covariance matrices,
Particle swarm optimization,
Search problems,
Standards,
Vectors"
A Printed UWB Vivaldi Antenna Using Stepped Connection Structure Between Slotline and Tapered Patches,"In this letter, a new stepped connection structure between slotline and tapered patches is adopted in a planar printed Vivaldi antenna. By using the stepped connection structure, the impedance matching is significantly improved and a wide bandwidth is achieved. In order to illustrate the effectiveness of this design, a prototype of the modified Vivaldi antenna is fabricated and tested. Experimental results show that the impedance matching is significantly improved in the band from 3 to 15.1 GHz. In addition, a measured gain, which is better than 5 dBi, is obtained with a compact size. Compared to other techniques, the presented technique effectively improves the impedance matching and enlarges the bandwidth without changing the overall dimensions. Moreover, a relatively flat group time delay response is achieved within the band of 3-15.1 GHz.","Vivaldi antennas,
Antenna measurements,
Impedance,
Impedance matching,
Slot antennas,
Bandwidth"
Layered costmaps for context-sensitive navigation,"Many navigation systems, including the ubiquitous ROS navigation stack, perform path-planning on a single costmap, in which the majority of information is stored in a single grid. This approach is quite successful at generating collision-free paths of minimal length, but it can struggle in dynamic, people-filled environments when the values in the costmap expand beyond occupied or free space. We have created and implemented a new method called layered costmaps, which work by separating the processing of costmap data into semantically-separated layers. Each layer tracks one type of obstacle or constraint, and then modifies a master costmap which is used for the path planning. We show how the algorithm can be integrated with the open-source ROS navigation stack, and how our approach is easier to fine-tune to specific environmental contexts than the existing monolithic one. Our design also results in faster path planning in practical use, and exhibits a cleaner separation of concerns that the original architecture. The new algorithm also makes it possible to represent complex cost values in order to create navigation behavior for a wide range of contexts.","Navigation,
Robot sensing systems,
Semantics,
Collision avoidance,
Context,
Path planning"
I/Q Imbalance in AF Dual-Hop Relaying: Performance Analysis in Nakagami-m Fading,"We analyze the performance of amplify-and-forward dual-hop relaying systems in the presence of in-phase and quadrature-phase imbalance (IQI) at the relay node. In particular, an exact analytical expression for and tight lower bounds on the outage probability are derived over independent, non-identically distributed Nakagami-m fading channels. Moreover, tractable upper and lower bounds on the ergodic capacity are presented at arbitrary signal-to-noise ratios (SNRs). Some special cases of practical interest (e.g., Rayleigh and Nakagami-0.5 fading) are also studied. An asymptotic analysis is performed in the high SNR regime, where we observe that IQI results in a ceiling effect on the signal-to-interference-plus-noise ratio (SINR), which depends only on the level of I/Q impairments, i.e., the joint image rejection ratio. Finally, the optimal I/Q amplitude and phase mismatch parameters are provided for maximizing the SINR ceiling, thus improving the system performance. An interesting observation is that, under a fixed total phase mismatch constraint, it is optimal to have the same level of transmitter (TX) and receiver (RX) phase mismatch at the relay node, while the optimal values for the TX and RX amplitude mismatch should be inversely proportional to each other.","Relays,
Signal to noise ratio,
Interference,
Rayleigh channels,
Joints,
Baseband"
A 60 GHz Drain-Source Neutralized Wideband Linear Power Amplifier in 28 nm CMOS,"CMOS technology scaling has enabled the design of high speed and efficient digital circuits. However, the continued scaling is detrimental to the design of RF and mm-wave systems. Higher sensitivity to process variations and inaccuracies in modeling of active and passive devices pose another challenge to the design of these systems at deep submicron technology nodes. This paper describes the design of a 60 GHz power amplifier in 28 nm CMOS technology. A drain-source neutralization technique maintains the stability of the PA and the wideband nature is achieved by the application of low-k transformer networks. The PA comprises of three stages and achieves an overall bandwidth of 11 GHz with a peak gain of 24.4 dB. Using a two-way transmission line based power combiner, the PA delivers a saturated output power of 16.5 dBm with a peak power added efficiency (PAE) of 12.6%.","Logic gates,
Metals,
Impedance,
Capacitance,
Power generation,
Layout,
Power amplifiers"
Reliability-Oriented Single-Path Routing Protocols in Wireless Sensor Networks,"Wireless sensor networks (WSNs) bring significant advantages over traditional communications in today's applications, such as environmental monitoring, homeland security, and health care. However, harsh and complex environments pose great challenges in the reliability of WSN communications. To achieve reliable wireless communications within WSNs, it is essential to have a reliable routing protocol and to have a means to evaluate the reliability performance of different routing protocols. In this paper, we first model the reliability of two different types of sensor nodes: 1) energy harvesting sensor nodes and 2) battery-powered sensor nodes. We then present wireless link reliability models for each type of sensor nodes, where effects of different parameters, such as battery life-time, shadowing, noise, and location uncertainty, are considered for analyzing the wireless link reliability. Based on the sensor node and wireless link reliability models, we compare the performance of different routing algorithms in terms of end-to-end path reliability and number of hops. A dynamic routing approach is then proposed to achieve the most reliable end-to-end path in WSNs. Furthermore, to facilitate a fair and comprehensive comparison among different routing algorithms, a cost function approach that integrates the end-to-end path reliability and number of hops is proposed, providing an indicator of quality of service of applications running on WSNs.",
Recognition of deformable object category and pose,"We present a novel method for classifying and estimating the categories and poses of deformable objects, such as clothing, from a set of depth images. The framework presented here represents the recognition part of the entire pipeline of dexterous manipulation of deformable objects, which contains grasping, recognition, regrasping, placing flat, and folding. We first create an off-line simulation of the deformable objects and capture depth images from different view points as training data. Then by extracting features and applying sparse coding and dictionary learning, we build up a codebook for a set of different poses of a particular deformable object category. The whole framework contains two layers which yield a robust system that first classifies deformable objects on category level and then estimates the current pose from a group of predefined poses of a single deformable object. The system is tested on a variety of similar deformable objects and achieves a high output accuracy. By knowing the current pose of the garment, we can continue with further tasks such as regrasping and folding.","Clothing,
Grasping,
Training,
Encoding,
Vectors,
Robots,
Data models"
Self-Adaptation of Playing Strategies in General Game Playing,"The term general game playing (GGP) refers to a subfield of AI which aims at developing agents able to effectively play many games from a particular class (finite, deterministic). It is also the name of the annual competition proposed by Stanford Logic Group at Stanford University (Stanford, CA, USA), which provides a framework for testing and evaluating GGP agents. In this paper, we present our GGP player which managed to win four out of seven games in the 2012 preliminary round and advanced to the final phase. Our system (named MINI-Player) relies on a pool of playing strategies and autonomously picks the ones which seem to be best suited to a given game. The chosen strategies are combined with one another and incorporated into the upper confidence bounds applied to trees (UCT) algorithm. The effectiveness of our player is evaluated on a set of games from the 2012 GGP Competition as well as a few other, single-player games. The paper discusses the efficacy of proposed playing strategies and evaluates the mechanism of their switching. The proposed idea of dynamically assigning search strategies during play is both novel and promising.",
Empirical Studies of Bio-Inspired Self-Organized Secure Autonomous Routing Protocol,"A wireless sensor network (WSN) depends on miniaturized wireless sensor nodes that are deployed to monitor physical phenomena by communicating with each other with limited resources. The major factor to be tackled in the WSN is the network lifetime. A recent WSN routing protocol defined as secure real-time load distribution (SRTLD) uses broadcast packets to perform neighbor discovery and calculation at every hop while transferring data packets. Thus, it has high energy consumption. The proposed novel biological inspired self-organized secure autonomous routing protocol (BIOSARP) enhances SRTLD with an autonomous routing mechanism. In the BIOSARP mechanism, an optimal forwarding decision is obtained using improved ant colony optimization (IACO). In IACO, the pheromone value/probability is computed based on the end-to-end delay, remaining battery power, and link quality metrics. The proposed BIOSARP has been designed to reduce the broadcast and packet overhead in order to minimize the delay, packet loss, and power consumption in the WSN. In this paper, we present the architecture, implementation, and detailed outdoor experimental testbed results of the proposed BIOSARP. These results show that BIOSARP outperforms energy and delay ants algorithm, improved energy-efficient ant-based routing, and SRTLD in simulations and as well as in real testbed experimentation. The empirical study confirmed that BIOSARP offers better performance and can be practically implemented in the WSN applications for structural and environmental monitoring or battlefield surveillance.","Wireless sensor networks,
Routing,
Routing protocols,
Sensors,
Delays,
Batteries,
Algorithm design and analysis"
Power Control and Coding Formulation for State Estimation With Wireless Sensors,"Technological advances made wireless sensors cheap and reliable enough to be brought into industrial use. A major challenge arises from the fact that wireless channels introduce random packet dropouts. Power control and coding are key enabling technologies in wireless communications to ensure efficient communication. In this paper, we examine the role of power control and coding for Kalman filtering over wireless correlated channels. Two estimation architectures are considered; initially, the sensors send their measurements directly to a single gateway (GW). Next, wireless relay nodes provide additional links. The GW decides on the coding scheme and the transmitter power levels of the wireless nodes. The decision process is carried out online and adapts to varying channel conditions to improve the tradeoff between state estimation accuracy and energy expenditure. In combination with predictive power control, we investigate the use of multiple-description coding (MDC), zero-error coding (ZEC), and network coding and provide sufficient conditions for the expectation of the estimation error covariance matrix to be bounded. Numerical results suggest that the proposed method may lead to energy savings of around 50%, when compared with an alternative scheme, wherein transmission power levels and bit-rates are governed by simple logic. In particular, ZEC is preferable at time instances with high channel gains, whereas MDC is superior for time instances with low gains. When channels between the sensors and the GW are in deep fades, network coding improves estimation accuracy significantly without sacrificing energy efficiency.","Kalman filters,
network coding,
power system control,
wireless sensor networks"
Tri-Resistive Switching Behavior of Hydrogen Induced Resistance Random Access Memory,"In this letter, the special role of hydrogen ions in hafnium doped silicon oxide resistive random access memory (RRAM) is presented. In addition to the more typical oxygen ion-dominated resistive switching, hydrogen ions were also observed to trigger a resistance transformation phenomenon, producing a tri-resistive device. Unlike a normal RRAM device, a hydrogen plasma-treated device is operated with a reversed voltage polarity, and the direction of hydrogen ion migration results in the chemical bonds breaking and repairing. By changing the voltage polarity and stop voltage, this tri-resistive behavior can be achieved. This particular hydrogen-induced switching behavior suggests a different RRAM switching mechanism and is finally explained by our model.","Switches,
Hydrogen,
Plasmas,
Silicon,
Resistance,
Educational institutions,
Ions"
Scheduling Jobs With Unknown Duration in Clouds,"We consider a stochastic model of jobs arriving at a cloud data center. Each job requests a certain amount of CPU, memory, disk space, etc. Job sizes (durations) are also modeled as random variables, with possibly unbounded support. These jobs need to be scheduled nonpreemptively on servers. The jobs are first routed to one of the servers when they arrive and are queued at the servers. Each server then chooses a set of jobs from its queues so that it has enough resources to serve all of them simultaneously. This problem has been studied previously under the assumption that job sizes are known and upper-bounded, and an algorithm was proposed that stabilizes traffic load in a diminished capacity region. Here, we present a load balancing and scheduling algorithm that is throughput-optimal, without assuming that job sizes are known or are upper-bounded.","Servers,
Schedules,
Scheduling,
Routing,
Markov processes,
Throughput,
Vectors"
The Impact of Aging on a Physical Unclonable Function,"On-chip physical unclonable functions (PUFs) have shown promises to solve several security problems. A PUF's behavior needs to be robust against reversible as well as irreversible temporal variabilities in circuits so that noise in the PUF output is minimized. While the effect of the reversible temporal variabilities on PUFs is well studied, sufficient attention has not been given so far to analyze the effect of the irreversible temporal variabilities i.e., aging on PUFs. In this paper, we perform an accelerated aging test on a ring oscillator (RO) PUF and analyze how it affects the functionality of the PUF. With our experiment using a set of 90-nm field-programmable gate arrays, we observe that aging makes PUF responses unreliable. Additionally, simulations show that the randomness of PUF responses remains unaffected despite aging. We also show that a passive countermeasure technique using a configurable RO can mitigate aging effect on the PUF significantly.","Stress,
Field programmable gate arrays,
High definition video,
Accelerated aging,
Authentication,
Logic gates"
Reverse Engineering Digital Circuits Using Structural and Functional Analyses,"Integrated circuits (ICs) are now designed and fabricated in a globalized multivendor environment making them vulnerable to malicious design changes, the insertion of hardware Trojans/malware, and intellectual property (IP) theft. Algorithmic reverse engineering of digital circuits can mitigate these concerns by enabling analysts to detect malicious hardware, verify the integrity of ICs, and detect IP violations. In this paper, we present a set of algorithms for the reverse engineering of digital circuits starting from an unstructured netlist and resulting in a high-level netlist with components such as register files, counters, adders, and subtractors. Our techniques require no manual intervention and experiments show that they determine the functionality of >45% and up to 93% of the gates in each of the test circuits that we examine. We also demonstrate that our algorithms are scalable to real designs by experimenting with a very large, highly-optimized system-on-chip (SOC) design with over 375000 combinational elements. Our inference algorithms cover 68% of the gates in this SOC. We also demonstrate that our algorithms are effective in aiding a human analyst to detect hardware Trojans in an unstructured netlist.","Algorithm design and analysis,
Logic gates,
Reverse engineering,
Trojan horses,
Inference algorithms,
Hardware,
Globalization,
Integrated circuits"
Two-phase authentication protocol for wireless sensor networks in distributed IoT applications,"In the centralized Wireless Sensor Network (WSN) architecture there exists a central entity, which acquires, processes and provides information from sensor nodes. Conversely, in the WSN applications in distributed Internet of Things (IoT) architecture, sensor nodes sense data, process, exchange information and perform collaboratively with other sensor nodes and endusers. In order to maintain the trustworthy connectivity and the accessibility of distributed IoT, it is important to establish secure links for end-to-end communication with proper authentication. The authors propose an implicit certificate-based authentication mechanism for WSNs in distributed IoT applications. The developed two-phase authentication protocol allows the sensor nodes and the end-users to authenticate each other and initiate secure connections. The proposed protocol supports the resource scarcity of the sensor nodes, heterogeneity and scalability of the network. The performance and security analysis justify that the proposed scheme is viable to deploy in resource constrained WSNs.","Authentication,
Wireless sensor networks,
Protocols,
Servers,
Ciphers,
Public key"
Hierarchical traffic control for partially decentralized coordination of multi AGV systems in industrial environments,"This paper deals with decentralized coordination of Automated Guided Vehicles (AGVs). We propose a hierarchical traffic control algorithm, that implements path planning on a two layer architecture. The high-level layer describes the topological relationships among different areas of the environment. In the low-level layer, each area includes a set of fixed routes, along which the AGVs have to move. An algorithm is also introduced for the automatic definition of the route map itself. The coordination among the AGVs is obtained exploiting shared resources (i.e. centralized information) and local negotiation (i.e. decentralized coordination). The proposed strategy is validated by means of simulations using real plant.","Splines (mathematics),
Path planning,
Optimization,
Vectors,
Computer architecture,
Materials,
Prediction algorithms"
Studies on Resilient Control Through Multiagent Consensus Networks Subject to Disturbances,"Resiliency is one of the most critical objectives found in complex industrial applications today and designing control systems to provide resiliency is an open problem. This paper proposes resilient control design guidelines for industrial systems that can be modeled as networked multiagent consensus systems subject to disturbances or noise. We give a general analysis of multiagent consensus networks in the presence of different disturbances from the input-to-output stability point of view. Using a nonsingular linear transformation, some necessary and sufficient results are established for disturbed multiagent consensus networks by taking advantage of the input-to-state stability theory, based on which the disturbance rejection performance is analyzed in three cases separated by the spaces of disturbances and state disagreements between agents. It is shown that the linear matrix inequality technique can be adopted to determine the optimal disturbance rejection indexes for all the three cases. In addition, two illustrative numerical examples are given to demonstrate the derived consensus results for different types of directed graphs and subject to different classes of disturbances.","Multi-agent systems,
Noise,
Stability analysis,
Face,
Control systems,
Vectors,
Resilience"
Recursive Waterfilling for Wireless Links With Energy Harvesting Transmitters,"Energy harvesting is often used for green communications. The problem of power allocation is then to maximize the throughput, taking into account the fact that channel conditions and energy sources are time varying. In particular, for the constraints of the target problem, besides the allocated power values being nonnegative, the successively harvested energy sum leads to the triangle coefficient matrix of the power sum constraints. In this paper, we propose a geometric waterfilling (GWF) algorithm in place of the conventional waterfilling (CWF) algorithm for power allocation with a sum power constraint. We then recursively apply the GWF as a functional block to sequentially solve the power allocation problem for energy harvesting transmission in a fading channel. This algorithm is referred to as RGWF. The proposed RGWF is further extended to solving the minimization of the transmission completion time (referred to as RGWFn) by inserting a condition to check if the preset information transmission data bits are achieved. Since RGWF is defined by recursion and along natural progress of time, we can compute a family of solutions for subprocesses from epoch 1 to epoch k, for k = 1, ..., K, where K is the index of the final epoch for the entire process. Thus, RGWF can be utilized for efficiently carrying out the computation of RGWFn. RGWF and RGWFn belong to dynamical recursive algorithms. Compared with the existing results in the open literature, the proposed algorithms have distinguished features: 1) They provide the exact optimal solutions via efficient finite computation under the recursive category, and 2) the optimality of the proposed algorithms is strictly proven. Numerical examples are provided to illustrate the procedures to obtain the optimal power allocation by using the proposed algorithms.","Resource management,
Energy harvesting,
Fading,
Indexes,
Throughput,
Batteries,
Complexity theory"
Self-Adaptively Weighted Co-Saliency Detection via Rank Constraint,"Co-saliency detection aims at discovering the common salient objects existing in multiple images. Most existing methods combine multiple saliency cues based on fixed weights, and ignore the intrinsic relationship of these cues. In this paper, we provide a general saliency map fusion framework, which exploits the relationship of multiple saliency cues and obtains the self-adaptive weight to generate the final saliency/co-saliency map. Given a group of images with similar objects, our method first utilizes several saliency detection algorithms to generate a group of saliency maps for all the images. The feature representation of the co-salient regions should be both similar and consistent. Therefore, the matrix jointing these feature histograms appears low rank. We formalize this general consistency criterion as the rank constraint, and propose two consistency energy to describe it, which are based on low rank matrix approximation and low rank matrix recovery, respectively. By calculating the self-adaptive weight based on the consistency energy, we highlight the common salient regions. Our method is valid for more than two input images and also works well for single image saliency detection. Experimental results on a variety of benchmark data sets demonstrate that the proposed method outperforms the state-of-the-art methods.","Silicon,
Histograms,
Approximation methods,
Image color analysis,
Matrix decomposition,
Educational institutions,
Visualization"
Micro-Doppler Parameter Estimation via Parametric Sparse Representation and Pruned Orthogonal Matching Pursuit,"The rotation, vibration, or coning motion of a target may produce periodic Doppler modulation, which is called the micro-Doppler phenomenon and is widely used for target classification and recognition. In this paper, the signal of interest is decomposed into a family of parametric basis-signals that are generated by discretizing the micro-Doppler parameter domain and synthesizing the micro-Doppler components with over-complete time-frequency characteristics. In this manner, micro-Doppler parameter estimation is converted into the problem of sparse signal recovery with a parametric dictionary. This problem can be considered as a specific case of dictionary learning, i.e., we need to solve for both the sparse solution and the parameter inside the dictionary matrix. To solve this problem, a novel pruned orthogonal matching pursuit (POMP) algorithm is proposed, in which the pruning operation is embedded into the iterative process of the orthogonal matching pursuit (OMP) algorithm. The effectiveness of the proposed approach is validated by simulations.","Doppler effect,
Matching pursuit algorithms,
Transforms,
Sparse matrices,
Algorithm design and analysis,
Parameter estimation"
MultiComm: Finding Community Structure in Multi-Dimensional Networks,"The main aim of this paper is to develop a community discovery scheme in a multi-dimensional network for data mining applications. In online social media, networked data consists of multiple dimensions/entities such as users, tags, photos, comments, and stories. We are interested in finding a group of users who interact significantly on these media entities. In a co-citation network, we are interested in finding a group of authors who relate to other authors significantly on publication information in titles, abstracts, and keywords as multiple dimensions/entities in the network. The main contribution of this paper is to propose a framework (MultiComm)to identify a seed-based community in a multi-dimensional network by evaluating the affinity between two items in the same type of entity (same dimension)or different types of entities (different dimensions)from the network. Our idea is to calculate the probabilities of visiting each item in each dimension, and compare their values to generate communities from a set of seed items. In order to evaluate a high quality of generated communities by the proposed algorithm, we develop and study a local modularity measure of a community in a multi-dimensional network. Experiments based on synthetic and real-world data sets suggest that the proposed framework is able to find a community effectively. Experimental results have also shown that the performance of the proposed algorithm is better in accuracy than the other testing algorithms in finding communities in multi-dimensional networks.","Communities,
Tensile stress,
Vectors,
Probability,
Algorithm design and analysis,
Media,
Data mining"
Using Topological Analysis to Support Event-Guided Exploration in Urban Data,"The explosion in the volume of data about urban environments has opened up opportunities to inform both policy and administration and thereby help governments improve the lives of their citizens, increase the efficiency of public services, and reduce the environmental harms of development. However, cities are complex systems and exploring the data they generate is challenging. The interaction between the various components in a city creates complex dynamics where interesting facts occur at multiple scales, requiring users to inspect a large number of data slices over time and space. Manual exploration of these slices is ineffective, time consuming, and in many cases impractical. In this paper, we propose a technique that supports event-guided exploration of large, spatio-temporal urban data. We model the data as time-varying scalar functions and use computational topology to automatically identify events in different data slices. To handle a potentially large number of events, we develop an algorithm to group and index them, thus allowing users to interactively explore and query event patterns on the fly. A visual exploration interface helps guide users towards data slices that display interesting events and trends. We demonstrate the effectiveness of our technique on two different data sets from New York City (NYC): data about taxi trips and subway service. We also report on the feedback we received from analysts at different NYC agencies.","Topology,
Terrain mapping,
Event detection,
Data visualization,
Urban areas"
Model-Based MR Parameter Mapping With Sparsity Constraints: Parameter Estimation and Performance Bounds,"Magnetic resonance parameter mapping (e.g., T1 mapping, T2 mapping, T2* mapping) is a valuable tool for tissue characterization. However, its practical utility has been limited due to long data acquisition time. This paper addresses this problem with a new model-based parameter mapping method. The proposed method utilizes a formulation that integrates the explicit signal model with sparsity constraints on the model parameters, enabling direct estimation of the parameters of interest from highly undersampled, noisy k-space data. An efficient greedy-pursuit algorithm is described to solve the resulting constrained parameter estimation problem. Estimation-theoretic bounds are also derived to analyze the benefits of incorporating sparsity constraints and benchmark the performance of the proposed method. The theoretical properties and empirical performance of the proposed method are illustrated in a T2 mapping application example using computer simulations.","Data models,
Maximum likelihood estimation,
Optimization,
Brain modeling,
Parameter estimation,
Frequency modulation,
Matrices"
A 1.2-pJ/bit 16-Gb/s 60-GHz OOK Transmitter in 65-nm CMOS for Wireless Network-On-Chip,"This paper presents a high-efficiency 60-GHz on-off keying (OOK) transmitter (TX) designed for wireless network-on-chip applications. Aiming at an intra-chip communication distance of 20 mm, the TX consists of a drive amplifier (DA), a high-speed OOK modulator, and a transformer-coupled voltage-controlled oscillator. For high efficiency, a common-source topology with a drain-to-gate neutralization technique is chosen for the DA. A detailed mathematical design methodology is derived for the neutralization technique. The bulk-driven OOK modulator employs a novel dual feedthrough cancellation technique, resulting in a 30-dB on-off ratio. Fabricated in a 65-nm bulk CMOS process, the TX consumes only 19 mW from a 1-V supply, and occupies an active area of 0.077 mm2. A maximum modulation data rate of 16 Gb/s with 0.75-dBm output power is demonstrated through measurements, which translates to a bit-energy efficiency of 1.2 pJ/bit.","Modulation,
Wireless communication,
Transceivers,
Bandwidth,
Power generation,
Couplings,
CMOS integrated circuits"
Sequential Bayesian Estimation With Censored Data for Multi-Sensor Systems,"In this paper, a new framework for sequential Bayesian estimation in sensor networks is proposed, which consists of two processes: censoring of measurements at local sensors and fusion of both received measurements and missing ones at the fusion center (FC). In our scheme, each local sensor maintains a Kalman filter (KF) for a linear Gaussian system or an extended Kalman filter (EKF) for a nonlinear system and the FC runs a particle filter (PF) to track the system state. Informative measurements are selected for transmission by an innovation based per-sensor censoring process executed at the sensors at each time. Though the less informative measurements are not sent to the FC, their absence still conveys some information, and the proposed scheme exploits such information from the missing messages. Numerical results show that, under the same bandwidth constraint, the proposed scheme outperforms the one that ignores missing data information and the one that selects sensors randomly for information transmission.","Bayes methods,
Distributed databases,
Atmospheric measurements,
Particle measurements,
Kalman filters,
Estimation,
Bandwidth"
Multi-Label Image Categorization With Sparse Factor Representation,"The goal of multilabel classification is to reveal the underlying label correlations to boost the accuracy of classification tasks. Most of the existing multilabel classifiers attempt to exhaustively explore dependency between correlated labels. It increases the risk of involving unnecessary label dependencies, which are detrimental to classification performance. Actually, not all the label correlations are indispensable to multilabel model. Negligible or fragile label correlations cannot be generalized well to the testing data, especially if there exists label correlation discrepancy between training and testing sets. To minimize such negative effect in the multilabel model, we propose to learn a sparse structure of label dependency. The underlying philosophy is that as long as the multilabel dependency cannot be well explained, the principle of parsimony should be applied to the modeling process of the label correlations. The obtained sparse label dependency structure discards the outlying correlations between labels, which makes the learned model more generalizable to future samples. Experiments on real world data sets show the competitive results compared with existing algorithms.",
Infrared Absorption Properties of Carbon Nanotube/Nanodiamond Based Thin Film Coatings,"We report on the characterization of thin-film near and short wavelength infrared absorbers comprised of carbon nanotubes dispersed in a polymer. Charged nanodiamond particles are used to effectively and uniformly disperse the carbon nanotubes in the polymer matrix, leading to a very homogenous film. Using this new technique, we demonstrate an infrared absorption of up to 95% in films with thicknesses . This remarkably high absorption is the result of low reflection off the surface and high absorption across the film thickness. The complex refractive index of the films is extracted using an effective media approximation. Calculations show the film has a wide angle for high absorption and is polarization independent. These films are easy to fabricate, robust and damage-resistant, and are compatible with post-processing techniques. These films can be used as the coating layer to boost the efficiency of uncooled infrared sensors and solar-thermal energy harvesters.","Absorption,
Polymers,
Detectors,
Coatings,
Wavelength measurement,
Temperature measurement"
Constrained Optimization Via Artificial Immune System,"An artificial immune system inspired by the fundamental principle of the vertebrate immune system, for solving constrained optimization problems, is proposed. The analogy between the mechanism of biological immune response and constrained optimization formulation is drawn. Individuals in population are classified into feasible and infeasible groups according to their constraint violations that closely match with the two states, inactivated and activated, of B-cells in the immune response. Feasible group focuses on exploitation in the feasible areas through clonal selection, recombination, and hypermutation, while infeasible group facilitates exploration along the feasibility boundary via location update. Direction information is extracted to promote the interactions between these two groups. This approach is validated by the benchmark functions proposed most recently and compared with those of the state of the art from various branches of evolutionary computation paradigms. The performance achieved is considered fairly competitive and promising.","evolutionary computation,
artificial immune systems,
constraint theory"
Plexe: A platooning extension for Veins,"Cooperative driving in general and Cooperative Adaptive Cruise Control (CACC) or platooning in particular require blending control theory, communications and networking, as well as mechanics and physics. Given the lack of an integrated modeling framework and theory as well as the prohibitively high costs of using prototypes for what-if studies, simulation remains the fundamental instrument to evaluate entire cooperative driving systems. This work presents Plexe, an Open Source extension to Veins that offers researchers a simulation environment able to run experiments in realistic scenarios, taking into account physics and mechanics of the vehicles, communications and networking impairments, and Inter-Vehicle Communication (IVC) protocol stacks. Plexe is easily extensible and already implements protocols to support platooning and cooperative driving applications and several state of the art cruise control models. We describe the structure of the simulator and the control algorithms that Plexe implements and provide two use cases which show the potential of our framework as a powerful research tool for cooperative driving systems.","Vehicles,
Acceleration,
Veins,
Protocols,
Roads,
Vehicle dynamics,
Safety"
Dense Dielectric Patch Array Antenna With Improved Radiation Characteristics Using EBG Ground Structure and Dielectric Superstrate for Future 5G Cellular Networks,"In this paper, a new dense dielectric (DD) patch array antenna prototype operating at 28 GHz for future fifth generation (5G) cellular networks is presented. This array antenna is proposed and designed with a standard printed circuit board process to be suitable for integration with radio frequency/microwave circuitry. The proposed structure employs four circular-shaped DD patch radiator antenna elements fed by a 1-to-4 Wilkinson power divider. To improve the array radiation characteristics, a ground structure based on a compact uniplanar electromagnetic bandgap unit cell has been used. The DD patch shows better radiation and total efficiencies compared with the metallic patch radiator. For further gain improvement, a dielectric layer of a superstrate is applied above the array antenna. The measured impedance bandwidth of the proposed array antenna ranges from 27 to beyond 32 GHz for a reflection coefficient (S11) of less than -10 dB. The proposed design exhibits stable radiation patterns over the whole frequency band of interest, with a total realized gain more than 16 dBi. Due to the remarkable performance of the proposed array, it can be considered as a good candidate for 5G communication applications.","Dielectrics,
Microwave antenna arrays,
Antenna arrays,
Antenna measurements,
Prototypes,
Radiators,
Mobile communication,
Electromagnetic band gap,
Cellular networks,
Patch antennas"
Compiler-Assisted STT-RAM-Based Hybrid Cache for Energy Efficient Embedded Systems,"Hybrid caches consisting of static RAM (SRAM) and spin-torque transfer (STT)-RAM have been proposed recently for energy efficiency. To explore the advantages of hybrid cache, most of the management strategies for hybrid caches employ migration-based techniques to dynamically move write-intensive data from STT-RAM to SRAM. These techniques involve additional access operations, and thus lead to extra overheads. In this paper, we propose two compilation-based approaches to improve the energy efficiency and performance of STT-RAM-based hybrid cache by reducing the migration overheads. The first approach, migration-aware data layout, is proposed to reduce the migrations by rearranging the data layout. The second approach, migration-aware cache locking, is proposed to reduce the migrations by locking migration-intensive memory blocks into SRAM part of hybrid cache. Furthermore, experiments show that these two methods can be combined to reduce more migrations. The reduction of migration overheads can improve the energy efficiency and performance of STT-RAM-based hybrid cache. Experimental results show that, combining these two methods, on average, the number of write operations on STT-RAM is reduced by 17.6%, the number of migrations is reduced by 38.9%, the total dynamic energy is reduced by 15.6%, and the total access latency is reduced by 13.8%.","Layout,
Random access memory,
Embedded systems,
Computer science,
Educational institutions,
Heuristic algorithms,
Benchmark testing"
Image Segmentation UsingHigher-Order Correlation Clustering,"In this paper, a hypergraph-based image segmentation framework is formulated in a supervised manner for many high-level computer vision tasks. To consider short- and long-range dependency among various regions of an image and also to incorporate wider selection of features, a higher-order correlation clustering (HO-CC) is incorporated in the framework. Correlation clustering (CC), which is a graph-partitioning algorithm, was recently shown to be effective in a number of applications such as natural language processing, document clustering, and image segmentation. It derives its partitioning result from a pairwise graph by optimizing a global objective function such that it simultaneously maximizes both intra-cluster similarity and inter-cluster dissimilarity. In the HO-CC, the pairwise graph which is used in the CC is generalized to a hypergraph which can alleviate local boundary ambiguities that can occur in the CC. Fast inference is possible by linear programming relaxation, and effective parameter learning by structured support vector machine is also possible by incorporating a decomposable structured loss function. Experimental results on various data sets show that the proposed HO-CC outperforms other state-of-the-art image segmentation algorithms. The HO-CC framework is therefore an efficient and flexible image segmentation framework.",
On Optimally Reducing Power Loss in Micro-grids With Power Storage Devices,"Smart micro-grids can produce “renewable” energy and store them in power storage devices. Power loss, however, is a significant problem in power exchange among the micro-grids and between the macro-station and individual micro-grids. To optimally reduce the total power losses in such a power grid system, in this paper, a greedy coalition formation algorithm is proposed, which allows the macro-station to coordinate mutual power exchange among the micro-grids and between each micro-grid and the macro-station. Our algorithm optimizes the total power losses across the entire power grid, including the cost of charging and discharging power storage devices and power losses due to power transfers. The algorithm creates exchange pairs among the micro-grids, giving priority to pairs with higher power loss reduction per exchanged power unit. Through computer-based simulations, we demonstrate that the proposed approach significantly reduces the average power loss compared with the conventional noncooperative method. The simulations also demonstrate that the communications overhead of our proposal (due to negotiations aimed at forming coalitions) does not significantly affect the available communication resource.","Propagation losses,
Power markets,
Educational institutions,
Batteries,
Smart grids,
Power generation"
From Series Production of Gyrotrons for W7-X Toward EU-1 MW Gyrotrons for ITER,"Europe is devoting significant joint efforts to develop and to manufacture MW-level gyrotrons for electron cyclotron heating and current drive of future plasma experiments. The two most important ones are the stellarator Wendelstein W7-X at Greifswald and the Tokamak ITER at Cadarache. While the series production of the 140 GHz, 1 MW, CW gyrotrons for the 10-MW electron cyclotron resonance heating system of stellarator W7-X is proceeding, the European GYrotron Consortium is presently developing the EU-1 MW, 170 GHz, CW gyrotron for ITER. The initial design had already been initiated in 2007, as a risk mitigation measure during the development of the advanced ITER EU-2-MW coaxial-cavity gyrotron. The target of the ITER EU-1-MW conventional-cavity design is to benefit as much as possible from the experiences made during the development and series production of the W7-X gyrotron and of the experiences gained from the earlier EU-2-MW coaxial-cavity gyrotron design. Hence, the similarity of the construction will be made visible in this paper. During 2012, the scientific design of the ITER EU-1-MW gyrotron components has been finalized. In collaboration with the industrial partner Thales electron devices, Vélizy, France, the industrial design of the technological parts of the gyrotron is being completed. A short-pulse prototype is under development to support the design of the CW prototype tube. The technological path toward the EU ITER-1 MW gyrotron and the final design will be presented.","Gyrotrons,
Prototypes,
Radio frequency,
Europe,
Cavity resonators,
Structural beams,
Power generation"
MODLoc: Localizing Multiple Objects in Dynamic Indoor Environment,"Radio frequency (RF) based technologies play an important role in indoor localization, since Radio Signal Strength (RSS) can be easily measured by various wireless devices without additional cost. Among these, radio map based technologies (also referred as fingerprinting technologies) are attractive due to high accuracy and easy deployment. However, these technologies have not been extensively applied on real environment for two fatal limitations. First, it is hard to localize multiple objects. When the number of target objects is unknown, constructing a radio map of multiple objects is almost impossible. Second, environment changes will generate different multipath signals and severely disturb the RSS measurement, making laborious retraining inevitable. Motivated by these, in this paper, we propose a novel approach, called Line-of-sight radio map matching, which only reserves the LOS signal among nodes. It leverages frequency diversity to eliminate the multipath behavior, making RSS more reliable than before. We implement our system MODLoc based on TelosB sensor nodes and commercial 802.11 NICs with Channel State Information (CSI) as well. Through extensive experiments, it shows that the accuracy does not decrease when localizing multiple targets in a dynamic environment. Our work outperforms the traditional methods by about 60 percent. More importantly, no calibration is required in such environment. Furthermore, our approach presents attractive flexibility, making it more appropriate for general RF-based localization studies than just the radio map based localization.",
\hbox{QB}^{2}\hbox{IC}: A QoS-Based Broadcast Protocol Under Blind Information for Multihop Cognitive Radio Ad Hoc Networks,"Broadcasting is an important operation in wireless networks where control information is usually propagated as broadcasts for the realization of most networking protocols. In traditional ad hoc networks, broadcasts are conducted on a common channel, which is shared by all nodes in the network. However, in cognitive radio (CR) ad hoc networks, unlicensed users may observe heterogeneous spectrum availability, which is unknown to other unlicensed users before the control information was broadcast. Thus, it is extremely challenging that broadcasts can be successfully conducted without knowing the spectrum availability information in advance. In addition, since broadcast collisions (i.e., simultaneous reception of broadcast messages at the same node) often lead to the waste of network resources, they should be efficiently mitigated in multihop scenarios. In this paper, a quality-of-service (QoS)-based broadcast protocol under Blind Information for multihop CR ad hoc networks, i.e., QB2IC, is proposed with the aim of having a high success rate and short broadcast delay. In our design, we do not assume that unlicensed users are aware of the network topology, the spectrum availability information, and time synchronization information. To the best of our knowledge, this is the first paper that investigates the broadcast issue in multihop CR ad hoc networks under blind information. Simulation results show that our proposed QB2IC protocol outperforms other broadcast schemes in terms of a higher success rate and shorter average broadcast delay.","Ad hoc networks,
Delays,
Receivers,
Protocols,
Spread spectrum communication,
Quality of service,
Network topology"
Structural Properties and Conditional Diagnosability of Star Graphs by Using the PMC Model,"Processor fault diagnosis has played an important role in measuring the reliability of a multiprocessor system; the diagnosability of many well-known multiprocessor systems has been widely investigated. Conditional diagnosability is a novel measure of diagnosability. It includes a condition whereby any fault set cannot contain all the neighbors of any node in a system. In this paper, the conditional diagnosability of star graphs by using the PMC model is evaluated. Several new structural properties of star graphs are derived. Based on these properties, the conditional diagnosability of an n-dimensional star graph is determined to be 8n - 21 for n ≥ 5.",
Lightweight map matching for indoor localisation using conditional random fields,"Indoor tracking and navigation is a fundamental need for pervasive and context-aware smartphone applications. Although indoor maps are becoming increasingly available, there is no practical and reliable indoor map matching solution available at present. We present MapCraft, a novel, robust and responsive technique that is extremely computationally efficient (running in under 10 ms on an Android smartphone), does not require training in different sites, and tracks well even when presented with very noisy sensor data. Key to our approach is expressing the tracking problem as a conditional random field (CRF), a technique which has had great success in areas such as natural language processing, but has yet to be considered for indoor tracking. Unlike directed graphical models like Hidden Markov Models, CRFs capture arbitrary constraints that express how well observations support state transitions, given map constraints. Extensive experiments in multiple sites show how MapCraft outperforms state-of-the art approaches, demonstrating excellent tracking error and accurate reconstruction of tortuous trajectories with zero training effort. As proof of its robustness, we also demonstrate how it is able to accurately track the position of a user from accelerometer and magnetometer measurements only (i.e. gyro- and WiFi-free). We believe that such an energy-efficient approach will enable always-on background localisation, enabling a new era of location-aware applications to be developed.","Hidden Markov models,
Buildings,
Training,
Graphical models,
Trajectory,
Magnetometers,
Sensors"
A Coding Scheme for Visible Light Communication With Wide Dimming Range,"For visible light communications (VLCs), dimming support is desirable to provide variable levels of lighting brightness. When error correction coding schemes are used for VLC systems, different code rates should be employed according to target dimming levels. In this letter, we propose a coding scheme, which can provide a wide range of brightness and a simple encoding/decoding structure for all different rates by using a rate-compatible punctured code. Puncturing patterns having the minimum bit error rate are provided by computer search. The results show that the VLC system with the proposed coding scheme can achieve optimum performances as well as a precise dimming support.","Encoding,
Bit error rate,
Convolutional codes,
Lighting,
Upper bound,
Brightness,
Light emitting diodes"
"Joint mode selection, channel allocation and power assignment for green device-to-device communications","Device-to-Device (D2D) communication has emerged as a promising technique for improving capacity and reducing power consumption in wireless networks. Most existing works on D2D communications either targeted CDMA-based single-channel networks or aimed to maximize network throughput. In this paper, we, however, aim at enabling green D2D communications in OFDMA-based wireless networks. We formally define an optimization problem based on a practical link data rate model, whose objective is to minimize power consumption while meeting user data rate requirements. We then present an effective algorithm to solve it in polynomial time, which jointly determines mode selection, channel allocation and power assignment. It has been shown by extensive simulation results that the proposed algorithm can achieve over 57% power savings, compared to several baseline methods.","Power demand,
Signal to noise ratio,
Interference,
Channel allocation,
Wireless networks,
Resource management,
Receivers"
Color-Image Quality Assessment: From Prediction to Optimization,"While image-difference metrics show good prediction performance on visual data, they often yield artifact-contaminated results if used as objective functions for optimizing complex image-processing tasks. We investigate in this regard the recently proposed color-image-difference (CID) metric particularly developed for predicting gamut-mapping distortions. We present an algorithm for optimizing gamut mapping employing the CID metric as the objective function. Resulting images contain various visual artifacts, which are addressed by multiple modifications yielding the improved color-image-difference (iCID) metric. The iCID-based optimizations are free from artifacts and retain contrast, structure, and color of the original image to a great extent. Furthermore, the prediction performance on visual data is improved by the modifications.",
Context-Aware Hypergraph Construction for Robust Spectral Clustering,"Spectral clustering is a powerful tool for unsupervised data analysis. In this paper, we propose a context-aware hypergraph similarity measure (CAHSM), which leads to robust spectral clustering in the case of noisy data. We construct three types of hypergraphs-the pairwise hypergraph, the k-nearest-neighbor (kNN) hypergraph, and the high-order over-clustering hypergraph. The pairwise hypergraph captures the pairwise similarity of data points; the kNNhypergraph captures the neighborhood of each point; and the clustering hypergraph encodes high-order contexts within the dataset. By combining the affinity information from these three hypergraphs, the CAHSM algorithm is able to explore the intrinsic topological information of the dataset. Therefore, data clustering using CAHSM tends to be more robust. Considering the intra-cluster compactness and the inter-cluster separability of vertices, we further design a discriminative hypergraph partitioning criterion (DHPC). Using both CAHSM and DHPC, a robust spectral clustering algorithm is developed. Theoretical analysis and experimental evaluation demonstrate the effectiveness and robustness of the proposed algorithm.","Clustering algorithms,
Context,
Optimization,
Communities,
Robustness,
Vectors,
Partitioning algorithms"
Community-Aware Task Allocation for Social Networked Multiagent Systems,"In this paper, we propose a novel community-aware task allocation model for social networked multiagent systems (SN-MASs), where the agent' cooperation domain is constrained in community and each agent can negotiate only with its intracommunity member agents. Under such community-aware scenarios, we prove that it remains NP-hard to maximize system overall profit. To solve this problem effectively, we present a heuristic algorithm that is composed of three phases: 1) task selection: select the desirable task to be allocated preferentially; 2) allocation to community: allocate the selected task to communities based on a significant task-first heuristics; and 3) allocation to agent: negotiate resources for the selected task based on a nonoverlap agent-first and breadth-first resource negotiation mechanism. Through the theoretical analyses and experiments, the advantages of our presented heuristic algorithm and community-aware task allocation model are validated. 1) Our presented heuristic algorithm performs very closely to the benchmark exponential brute-force optimal algorithm and the network flow-based greedy algorithm in terms of system overall profit in small-scale applications. Moreover, in the large-scale applications, the presented heuristic algorithm achieves approximately the same overall system profit, but significantly reduces the computational load compared with the greedy algorithm. 2) Our presented community-aware task allocation model reduces the system communication cost compared with the previous global-aware task allocation model and improves the system overall profit greatly compared with the previous local neighbor-aware task allocation model.",
An Automatically Generated Evaluation Function in General Game Playing,"General game-playing (GGP) competitions provide a framework for building multigame-playing agents. In this paper, we describe an attempt at the implementation of such an agent. It relies heavily on our knowledge-free method of automatic construction of an approximate state evaluation function, based on game rules only. This function is then employed by one of the two game tree search methods: MTD (f) or guided upper confidence bounds applied to trees (GUCT), the latter being our proposal of an algorithm combining UCT with the usage of an evaluation function. The performance of our agent is very satisfactory when compared to a baseline UCT implementation.","Games,
Algorithm design and analysis,
Stability analysis,
Buildings,
Correlation,
Approximation algorithms,
Law"
A Scientometric Analysis of Cloud Computing Literature,"The popularity and rapid development of cloud computing in recent years has led to a huge amount of publications containing the achieved knowledge of this area of research. Due to the interdisciplinary nature and high relevance of cloud computing research, it becomes increasingly difficult or even impossible to understand the overall structure and development of this field without analytical approaches. While evaluating science has a long tradition in many fields, we identify a lack of a comprehensive scientometric study in the area of cloud computing. Based on a large bibliographic data base, this study applies scientometric means to empirically study the evolution and state of cloud computing research with a view from above the clouds. By this, we provide extensive insights into publication patterns, research impact and research productivity. Furthermore, we explore the interplay of related subtopics by analyzing keyword clusters. The results of this study provide a better understanding of patterns, trends and other important factors as a basis for directing research activities, sharing knowledge and collaborating in the area of cloud computing research.","Cloud computing,
Bibliometrics,
Productivity,
Market research,
Indexes"
Provenance-Assisted Classification in Social Networks,"Signal feature extraction and classification are two common tasks in the signal processing literature. This paper investigates the use of source identities as a common mechanism for enhancing the classification accuracy of social signals. We define social signals as outputs, such as microblog entries, geotags, or uploaded images, contributed by users in a social network. Many classification tasks can be defined on such outputs. For example, one may want to identify the dialect of a microblog contributed by an author, or classify information referred to in a user's tweet as true or false. While the design of such classifiers is application-specific, social signals share in common one key property: they are augmented by the explicit identity of the source. This motivates investigating whether or not knowing the source of each signal (in addition to exploiting signal features) allows the classification accuracy to be improved. We call it provenance-assisted classification. This paper answers the above question affirmatively, demonstrating how source identities can improve classification accuracy, and derives confidence bounds to quantify the accuracy of results. Evaluation is performed in two real-world contexts: (i) fact-finding that classifies microblog entries into true and false, and (ii) language classification of tweets issued by a set of possibly multi-lingual speakers. We also carry out extensive simulation experiments to further evaluate the performance of the proposed classification scheme over different problem dimensions. The results show that provenance features significantly improve classification accuracy of social signals, even when no information is known about the sources (besides their ID). This observation offers a general mechanism for enhancing classification results in social networks.",
Brain Tumor Segmentation Based on Local Independent Projection-Based Classification,"Brain tumor segmentation is an important procedure for early tumor diagnosis and radiotherapy planning. Although numerous brain tumor segmentation methods have been presented, enhancing tumor segmentation methods is still challenging because brain tumor MRI images exhibit complex characteristics, such as high diversity in tumor appearance and ambiguous tumor boundaries. To address this problem, we propose a novel automatic tumor segmentation method for MRI images. This method treats tumor segmentation as a classification problem. Additionally, the local independent projection-based classification (LIPC) method is used to classify each voxel into different classes. A novel classification framework is derived by introducing the local independent projection into the classical classification model. Locality is important in the calculation of local independent projections for LIPC. Locality is also considered in determining whether local anchor embedding is more applicable in solving linear projection weights compared with other coding methods. Moreover, LIPC considers the data distribution of different classes by learning a softmax regression model, which can further improve classification performance. In this study, 80 brain tumor MRI images with ground truth data are used as training data and 40 images without ground truth data are used as testing data. The segmentation results of testing data are evaluated by an online evaluation tool. The average dice similarities of the proposed method for segmenting complete tumor, tumor core, and contrast-enhancing tumor on real patient data are 0.84, 0.685, and 0.585, respectively. These results are comparable to other state-of-the-art methods.","Tumors,
Image segmentation,
Magnetic resonance imaging,
Testing,
Training,
Dictionaries,
Brain"
Visualization beyond the Desktop--the Next Big Thing,"Visualization is coming of age. With visual depictions being seamlessly integrated into documents, and data visualization techniques being used to understand increasingly large and complex datasets, the term ""visualization""' is becoming used in everyday conversations. But we are on a cusp; visualization researchers need to develop and adapt to today's new devices and tomorrow's technology. Today, people interact with visual depictions through a mouse. Tomorrow, they'll be touching, swiping, grasping, feeling, hearing, smelling, and even tasting data. The next big thing is multisensory visualization that goes beyond the desktop.","Data visualization,
Visualization,
Human computer interaction,
Computer vision,
Context modeling,
Haptic interfaces,
Market research"
Bayesian Coalition Game as-a-Service for Content Distribution in Internet of Vehicles,"With the latest developments in cloud computing and Internet of Vehicles (IoV), now it is possible to construct an efficient next generation infrastructure, which may act as an interface for the connection of a number of objects such as vehicles, intelligent sensors, actuators, home appliances, high-computing servers, and computers to the Internet. In such an environment, vehicles on the road may act as source provider or consumer to facilitate various users connected to the Internet. Content distribution to all these objects especially to the vehicles in this environment is a challenging task due to the tight constraints of maintaining connectivity, coverage, and topology of the vehicles. To address these issues, in this paper, we proposed a new Bayesian coalition game (BCG) as-a-service for content distribution among these objects using support from cloud. We have addressed the problem of content distribution to vehicles from the perspective of BCG and learning automata (LA). Content are assumed to be located at the cloud, which is accessed by the vehicles through Internet even on-the-fly. Vehicles are assumed to be the players in the game and form a coalition among themselves using Markov decision process (MDP). For each action taken by an automaton, it may get a reward or a penalty from the environment according to which it updates its action probability vector. The performance of the proposed scheme is evaluated be selecting various parameters. The results obtained show that proposed scheme is effective in building next generation IoV environment.","Vehiclular ad hoc networks,
Road traffic,
Bayes methods,
Learning automata,
Cloud computing,
Automata"
An Unsupervised Feature Selection Framework for Social Media Data,"The explosive usage of social media produces massive amount of unlabeled and high-dimensional data. Feature selection has been proven to be effective in dealing with high-dimensional data for efficient learning and data mining. Unsupervised feature selection remains a challenging task due to the absence of label information based on which feature relevance is often assessed. The unique characteristics of social media data further complicate the already challenging problem of unsupervised feature selection, e.g., social media data is inherently linked, which makes invalid the independent and identically distributed assumption, bringing about new challenges to unsupervised feature selection algorithms. In this paper, we investigate a novel problem of feature selection for social media data in an unsupervised scenario. In particular, we analyze the differences between social media data and traditional attribute-value data, investigate how the relations extracted from linked data can be exploited to help select relevant features, and propose a novel unsupervised feature selection framework, LUFS, for linked social media data. We systematically design and conduct systemic experiments to evaluate the proposed framework on data sets from real-world social media Web sites. The empirical study demonstrates the effectiveness and potential of our proposed framework.",
All Polarization Receiving Rectenna With Harmonic Rejection Property for Wireless Power Transmission,"In this paper, a high conversion efficiency rectenna for wireless power transmission at 2.45 GHz is proposed. The rectenna is fabricated on a low-cost FR-4 substrate. The proposed design contains a dual circularly polarized patch antenna in which a high-order harmonic rejection property is embedded, and a pair of rectifying circuits without harmonic rejection filters. The dimension for the proposed rectenna design is 100×100×3.8 mm3. The proposed rectenna collects waves in all polarization senses simultaneously with a suitable air gap width, chosen to maximize antenna gain, and provide high isolation between the rectifying circuits. The rectifying circuits are fed by the wave power of orthogonally polarized waves. The conversion efficiency is improved by blocking the second and the third harmonic noise from reemission without suffering loss from filters: the second harmonic noise is rejected with a T-shape slot, while the third is rejected by a U-shape resonator. The measured conversion efficiency of the proposed rectenna reaches 82.3% when the inputs of the rectifying circuits are fed at 22 dBm, surpassing the majority of existing rectenna designs in the current literature. The functionality of reception at all polarizations is also verified, distinguishing our design from other proposals.","Harmonic analysis,
Antenna measurements,
Rectennas,
Rectifying circuits,
Gain,
Receiving antennas,
Resonant frequency"
A Simple Proof of Maxwell Saturation for Coupled Scalar Recursions,"Low-density parity-check (LDPC) convolutional codes (or spatially coupled codes) were recently shown to approach capacity on the binary erasure channel (BEC) and binary-input memoryless symmetric channels. The mechanism behind this spectacular performance is now called threshold saturation via spatial coupling. This new phenomenon is characterized by the belief-propagation threshold of the spatially coupled ensemble increasing to an intrinsic noise threshold defined by the uncoupled system. In this paper, we present a simple proof of threshold saturation that applies to a wide class of coupled scalar recursions. Our approach is based on constructing potential functions for both the coupled and uncoupled recursions. Our results actually show that the fixed point of the coupled recursion is essentially determined by the minimum of the uncoupled potential function and we refer to this phenomenon as Maxwell saturation. A variety of examples are considered including the density-evolution equations for: irregular LDPC codes on the BEC, irregular low-density generator-matrix codes on the BEC, a class of generalized LDPC codes with BCH component codes, the joint iterative decoding of LDPC codes on intersymbol-interference channels with erasure noise, and the compressed sensing of random vectors with independent identically distributed components.","Vectors,
Couplings,
Noise,
Iterative decoding,
Standards,
Convolutional codes"
Performance Analysis of Free-Space Optical Communication Systems With Multiuser Diversity Over Atmospheric Turbulence Channels,"Free-space optical (FSO) communication has become a cost-effective method to provide high data rates. However, the turbulence-induced fading limits its application to short-range applications. To address this, we propose a multiuser diversity (MD) FSO scheme in which the Nth best user is selected and the channel fluctuations can be effectively exploited to produce a selection diversity gain. More specifically, we first present the statistics analysis for the considered system over both weak and strong atmospheric turbulence channels. Based on these statistics, the outage probability, bit-error rate performance, average capacity, diversity order, and coverage are analyzed. Results show that the diversity order for the gamma-gamma fading is N min{α, β}/2, where N is the number of users, and α and β are the channel fading parameters related to the effective atmospheric conditions of the link.","Fading,
Apertures,
Atmospheric modeling,
Optical fiber communication,
Adaptive optics,
MIMO,
Log-normal distribution"
EEG-based emotion classification using deep belief networks,"In recent years, there are many great successes in using deep architectures for unsupervised feature learning from data, especially for images and speech. In this paper, we introduce recent advanced deep learning models to classify two emotional categories (positive and negative) from EEG data. We train a deep belief network (DBN) with differential entropy features extracted from multichannel EEG as input. A hidden markov model (HMM) is integrated to accurately capture a more reliable emotional stage switching. We also compare the performance of the deep models to KNN, SVM and Graph regularized Extreme Learning Machine (GELM). The average accuracies of DBN-HMM, DBN, GELM, SVM, and KNN in our experiments are 87.62%, 86.91%, 85.67%, 84.08%, and 69.66%, respectively. Our experimental results show that the DBN and DBN-HMM models improve the accuracy of EEG-based emotion classification in comparison with the state-of-the-art methods.",
SIFT Hardware Implementation for Real-Time Image Feature Extraction,"This paper introduces a high-speed all-hardware scale-invariant feature transform (SIFT) architecture with parallel and pipeline technology for real-time extraction of image features. The task-level parallel and pipeline structure are exploited between the hardware blocks, and the data-level parallel and pipeline architecture are exploited inside each block. Two identical random access memories are adopted with ping-pong operation to execute the key point detection module and the descriptor generation module in task-level parallelism. With speeding up the key point detection module of SIFT, the descriptor generation module has become the bottleneck of the system's performance; therefore, this paper proposes an optimized descriptor generation algorithm. A novel window-dividing method is proposed with square subregions arranged in 16 directions, and the descriptors are generated by reordering the histogram instead of window rotation. Therefore, the main orientation detection block and descriptor generation block run in parallel instead of interactively. With the optimized algorithm cooperating with pipeline structure inside each block, we not only improve the parallelism of the algorithm, but also avoid floating data calculation to save hardware consumption. Thus, the descriptor generation module leads the speed almost 15 times faster than a recent solution. The proposed system was implemented on field programmable gate array and the overall time to extract SIFT features for an image having 512×512 pixels is only 6.55 ms (sufficient for real-time applications), and the number of feature points can reach up to 2900.",
Constraint-Aware Approach to Web Service Composition,"The creation of value-added services by automatic composition of existing ones is gaining significant momentum as the potential silver bullet in service-oriented computing. A large number of composition methods have been proposed, and most of them are based on the matching of input and output parameters of services only. However, most services in the real world are not universally applicable, and some applicable conditions or restrictions are imposed on them by their providers. Such constraints have a great impact on service composition, but have been largely ignored by the existing methods. In this paper, they are discussed and defined, and a simple formal expression is adopted to describe them. Two novel concepts, called service intension and service extension, are presented, which allow one to divide the basic elements of a web service definition into two parts. Consequently, their use allows us to propose a constraint-aware service composition method in which service constraints are well taken care. The proposed solution includes a graph search-based algorithm and two novel preprocessing methods. A publicly available test set from ICEBE05 is used to evaluate and analyze the proposed methodology.",
A Flocking-Based Paradigm for Hierarchical Cyber-Physical Smart Grid Modeling and Control,"It is well known that information will play an important role in enhancing emerging smart grid system operation. Therefore, questions naturally arise as to when the increased data-dependence may be considered excessive. Two practical considerations emerge: 1) communications and computational overhead, in which redundant and irrelevant information acquisition and use results in heavy computational burden with limited performance return; and 2) increasing risks of power system disruption due to information delay from communication congestion or cyber attack. One strategy to improve smart grid resilience is to determine the appropriate degree of dependence on cyber information to balance performance with overhead and risk. In this paper, we present a hierarchical cyber-physical multiagent model of smart grid system operation based on flocking theory in the context of the transient stability problem. Through this model, we study strategies that harness a selective degree of cyber technology by leveraging physical couplings. Our formulation enables the identification of large-scale distributed control strategies for robust and resilient power grid operation. We demonstrate the potential performance improvements of our findings on the New England 39-bus power system for case studies involving a variety of system faults and communication delays.",
Holistic Scheduling of Real-Time Applications in Time-Triggered In-Vehicle Networks,"As time-triggered communication protocols [e.g., time-triggered controller area network (TTCAN), time-triggered protocol (TTP), and FlexRay] are widely used on vehicles, the scheduling of tasks and messages on in-vehicle networks becomes a critical issue for offering quality-of-service (QoS) guarantees to time-critical applications on vehicles. This paper studies a holistic scheduling problem for handling real-time applications in time-triggered in-vehicle networks where practical aspects in system design and integration are captured. The contributions of this paper are multifold. First, it designs a novel scheduling algorithm, referred to as Unfixed Start Time (UST) algorithm, which schedules tasks and messages in a flexible way to enhance schedulability. In addition, to tolerate assignment conflicts and further improve schedulability, it proposes two rescheduling and backtracking methods, namely, Rescheduling with Offset Modification (ROM) and Backtracking and Priority Promotion (BPP) procedures. Extensive performance evaluation studies are conducted to quantify the performance of the proposed algorithm under a variety of scenarios.","Job shop scheduling,
Schedules,
Heuristic algorithms,
Real-time systems,
Informatics,
Protocols"
On the Mixed {{\rm H}_2}/{{\rm H}_\infty } Loop-Shaping Tradeoffs in Fractional-Order Control of the AVR System,"This paper looks at frequency domain design of a fractional-order (FO) proportional-integral differential (PID) controller for an automatic voltage regulator (AVR) system. Various performance criteria of the AVR system are formulated as system norms and are then coupled with an evolutionary multiobjective optimization (MOO) algorithm to yield Pareto optimal design tradeoffs. The performance measures consist of mixed H2/H∞ design objectives, such as the set-point tracking, load disturbance, and noise rejection controller effort, which are an exhaustive set of conflicting control objectives. A fuzzy logic-based mechanism is used to identify the best compromise solution on the Pareto fronts. The advantages and disadvantages of using an FOPID controller over the conventional PID controller, which are popular for industrial use, are enunciated from the presented simulations. The relevance and impact of FO controller design from the perspective of the dynamics of AVR control loop is also discussed.","Transfer functions,
Sensitivity,
PD control,
Voltage control,
Fractional calculus,
Frequency-domain analysis,
Optimization"
GreenDroid: Automated Diagnosis of Energy Inefficiency for Smartphone Applications,"Smartphone applications' energy efficiency is vital, but many Android applications suffer from serious energy inefficiency problems. Locating these problems is labor-intensive and automated diagnosis is highly desirable. However, a key challenge is the lack of a decidable criterion that facilitates automated judgment of such energy problems. Our work aims to address this challenge. We conducted an in-depth study of 173 open-source and 229 commercial Android applications, and observed two common causes of energy problems: missing deactivation of sensors or wake locks, and cost-ineffective use of sensory data. With these findings, wepropose an automated approach to diagnosing energy problems in Android applications. Our approach explores an application's state space by systematically executing the application using Java PathFinder (JPF). It monitors sensor and wake lock operations to detect missing deactivation of sensors and wake locks. It also tracks the transformation and usage of sensory data and judges whether they are effectively utilized by the application using our state-sensitive data utilization metric. In this way, our approach can generate detailed reports with actionable information to assist developers in validating detected energy problems. We built our approach as a tool, GreenDroid, on top of JPF. Technically, we addressed the challenges of generating user interaction events and scheduling event handlers in extending JPF for analyzing Android applications. We evaluated GreenDroid using 13 real-world popular Android applications. GreenDroid completed energy efficiency diagnosis for these applications in a few minutes. It successfully located real energy problems in these applications, and additionally found new unreported energy problems that were later confirmed by developers.","Androids,
Humanoid robots,
Computer bugs,
Sensors,
Open source software,
Green products,
Google"
A Feature Study for Classification-Based Speech Separation at Low Signal-to-Noise Ratios,"Speech separation can be formulated as a classification problem. In classification-based speech separation, supervised learning is employed to classify time-frequency units as either speech-dominant or noise-dominant. In very low signal-to-noise ratio (SNR) conditions, acoustic features extracted from a mixture are crucial for correct classification. In this study, we systematically evaluate a range of promising features for classification-based separation using six nonstationary noises at the low SNR level of -5 dB, which is chosen with the goal of improving human speech intelligibility in mind. In addition, we propose a new feature called multi-resolution cochleagram (MRCG). The new feature is constructed by combining four cochleagrams at different spectrotemporal resolutions in order to capture both the local and contextual information. Experimental results show that MRCG gives the best classification results among all evaluated features. In addition, our results indicate that auto-regressive moving average (ARMA) filtering, a post-processing technique for improving automatic speech recognition features, also improves many acoustic features for speech separation.","Speech,
Speech processing,
Signal to noise ratio,
Feature extraction,
Mel frequency cepstral coefficient,
IEEE transactions"
Automatic and Accurate Shadow Detection Using Near-Infrared Information,"We present a method to automatically detect shadows in a fast and accurate manner by taking advantage of the inherent sensitivity of digital camera sensors to the near-infrared (NIR) part of the spectrum. Dark objects, which confound many shadow detection algorithms, often have much higher reflectance in the NIR. We can thus build an accurate shadow candidate map based on image pixels that are dark both in the visible and NIR representations. We further refine the shadow map by incorporating ratios of the visible to the NIR image, based on the observation that commonly encountered light sources have very distinct spectra in the NIR band. The results are validated on a new database, which contains visible/NIR images for a large variety of real-world shadow creating illuminant conditions, as well as manually labeled shadow ground truth. Both quantitative and qualitative evaluations show that our method outperforms current state-of-the-art shadow detection algorithms in terms of accuracy and computational efficiency.",
An Efficient Hardware Implementation of HOG Feature Extraction for Human Detection,"In intelligent transportation systems, human detection is an important issue and has been widely used in many applications. Histograms of oriented gradients (HOG) are proven to be able to significantly outperform existing feature sets for human detection. In this paper, we present a low-cost high-speed hardware implementation for HOG feature extraction. The simulation shows that the proposed circuit can achieve 167 MHz with 153-K gate counts by using Taiwan Semiconductor Manufacturing Company 0.13-μm technology. Compared with the previous hardware architectures for HOG feature extraction, our circuit requires fewer hardware costs and achieves faster working speed.",
A Multisize Superpixel Approach for Salient Object Detection Based on Multivariate Normal Distribution Estimation,"This paper presents a new method for salient object detection based on a sophisticated appearance comparison of multisize superpixels. Those superpixels are modeled by multivariate normal distributions in CIE-Lab color space, which are estimated from the pixels they comprise. This fitting facilitates an efficient application of the Wasserstein distance on the Euclidean norm (W2) to measure perceptual similarity between elements. Saliency is computed in two ways. On the one hand, we compute global saliency by probabilistically grouping visually similar superpixels into clusters and rate their compactness. On the other hand, we use the same distance measure to determine local center-surround contrasts between superpixels. Then, an innovative locally constrained random walk technique that considers local similarity between elements balances the saliency ratings inside probable objects and background. The results of our experiments show the robustness and efficiency of our approach against 11 recently published state-of-the-art saliency detection methods on five widely used benchmark data sets.",
Drift Compensation for Electronic Nose by Semi-Supervised Domain Adaption,"Drift compensation is an important issue for electronic nose systems. Traditional methods are costly and laborious because they need to frequently recalibrate referred gases or continually provide data labeling. In this paper, a new drift compensation method is proposed. The inspiration of our method is originated from semi-supervised domain adaption that can effectively tackle the mismatches between source domain and target domain. In our approach, a weighted geodesic flow kernel is initially constructed, then the combination of such kind of kernels is proposed considering that there are intermediate unlabeled data between the source and target domains. We will discuss how unlabeled data is selected from the target domain. The selected unlabeled data is used to provide incremental knowledge in order to dynamically adapt classifier to the target domain. Based on the kernel combination and selected unlabeled data, manifold regularization is used to train the classifier. To the best of our knowledge, we are the first to apply domain adaption to deal with the sensor drift problem. The advantages of our method include degrading recalibration rate, requiring few labeled data, and the robustness in handling the drift. Our experiments show that the proposed method significantly outperforms the baseline methods.","Kernel,
Manifolds,
Equations,
Gas detectors,
Educational institutions,
Silicon"
"Notice of Violation of IEEE Publication Principles
Critical Density for Coverage and Connectivity in Two-Dimensional Aligned-Orientation Directional Sensor Networks Using Continuum Percolation","Notice of Violation of IEEE Publication Principles

""Critical Density for Coverage and Connectivity in Two-Dimensional Aligned-Orientation Directional Sensor Networks Using Continuum Percolation,""
by Mohammad Khanjary, Masoud Sabaei, and Mohammad Reza Meybodi
in IEEE Sensors Journal, vol. 14, no. 8, pp. 2856-2863, Aug. 2014

After careful and considered review of the content and authorship of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.

This paper contains significant portions of original text from the paper cited below. The original text was copied without attribution (including appropriate references to the original author(s) and/or paper title) and without permission.

""Integrated Coverage and Connectivity in Wireless Sensor Networks: A Two-Dimensional Percolation Problem,""
by H. M. Ammari and S. K. Das,
in IEEE Transactions on Computers, vol. 57, no. 10, pp. 1423-1434, Oct. 2008


Sensing coverage is one of the fundamental design issues in wireless sensor networks, which reflects the surveillance quality provided by them. Moreover, network connectivity enables the gathered data by sensors to reach to the sink node. Given an initially uncovered field, and as more and more directional sensors are continuously added to the sensor network, the size of partial covered areas increases. At some point, the situation abruptly changes from small fragmented covered areas to a single large covered area. We call this abrupt change the sensing-coverage phase transition (SCPT). Likewise, given an originally disconnected sensor network, as more and more sensors are added, the number of connected components changes such that the sensor network suddenly becomes connected at some point. We call this sudden change the network connectivity phase transition (NCPT). The nature of such phase transitions is a central topic in the percolation theory. In this paper, we introduce aligned-orientation directional sensor networks in which nodes are deployed based on Poisson point process and the orientation of all sensor nodes is the same. Then, we propose an approach to compute density of nodes at critical percolation for both of the SCPT and NCPT problems in such networks, for all angles of field-of-view between 0 and π by using continuum percolation. Due to percolation theory, the critical density is infimum density that for densities above it SCPT and NCPT almost surely occur. In addition, we propose a model for percolation in directional sensor networks, which provides a basis for solving the SCPT and NCPT problems together.","Sensors,
Mathematical model,
Equations,
Approximation methods,
Vectors,
Euclidean distance,
Lattices"
Feature Selection in Life Science Classification: Metaheuristic Swarm Search,"The purpose of classification in medical informatics is to predict the presence or absence of a particular disease as well as disease types from historical data. Medical data often contain irrelevant features and noise, and an appropriate subset of the significant features can improve classification accuracy. Therefore, researchers apply feature selection to identify and remove irrelevant and redundant features. The authors propose a versatile feature selection approach called Swarm Search Feature Selection (SS-FS), based on stochastic swarm intelligence. It is designed to overcome NP-hard combinatorial search problems such as the selection of an optimal feature subset from an extremely large array of features--which is not uncommon in biomedical data. SS-FS is demonstrated to be a feasible computing tool in achieving high accuracy in classification via testing with two empirical biomedical datasets. This article is part of a special issue on life sciences computing.","Science - general,
Classification algorithms,
Computational modeling,
Computational biophysics,
Search problems,
Microorganisms,
Diseases,
Particle swarm optimization,
Biomedical monitoring,
Classification"
"GPU-Aware MPI on RDMA-Enabled Clusters: Design, Implementation and Evaluation","Designing high-performance and scalable applications on GPU clusters requires tackling several challenges. The key challenge is the separate host memory and device memory, which requires programmers to use multiple programming models, such as CUDA and MPI, to operate on data in different memory spaces. This challenge becomes more difficult to tackle when non-contiguous data in multidimensional structures is used by real-world applications. These challenges limit the programming productivity and the application performance. We propose the GPU-Aware MPI to support data communication from GPU to GPU using standard MPI. It unifies the separate memory spaces, and avoids explicit CPU-GPU data movement and CPU/GPU buffer management. It supports all MPI datatypes on device memory with two algorithms: a GPU datatype vectorization algorithm and a vector based GPU kernel data pack and unpack algorithm. A pipeline is designed to overlap the non-contiguous data packing and unpacking on GPUs, the data movement on the PCIe, and the RDMA data transfer on the network. We incorporate our design with the open-source MPI library MVAPICH2 and optimize a production application: the multiphase 3D LBM. Besides the increase of programming productivity, we observe up to 19.9 percent improvement in application-level performance on 64 GPUs of the Oakley supercomputer.",
Discovering Emerging Topics in Social Streams via Link-Anomaly Detection,"Detection of emerging topics is now receiving renewed interest motivated by the rapid growth of social networks. Conventional-term-frequency-based approaches may not be appropriate in this context, because the information exchanged in social-network posts include not only text but also images, URLs, and videos. We focus on emergence of topics signaled by social aspects of theses networks. Specifically, we focus on mentions of users--links between users that are generated dynamically (intentionally or unintentionally) through replies, mentions, and retweets. We propose a probability model of the mentioning behavior of a social network user, and propose to detect the emergence of a new topic from the anomalies measured through the model. Aggregating anomaly scores from hundreds of users, we show that we can detect emerging topics only based on the reply/mention relationships in social-network posts. We demonstrate our technique in several real data sets we gathered from Twitter. The experiments show that the proposed mention-anomaly-based approaches can detect new topics at least as early as text-anomaly-based approaches, and in some cases much earlier when the topic is poorly identified by the textual contents in posts.","Social network services,
Maximum likelihood estimation,
Encoding,
Hidden Markov models,
Density functional theory,
Training"
Coding or Not: Optimal Mobile Data Offloading in Opportunistic Vehicular Networks,"To cope with explosive vehicular traffic and ever-increasing application demands in the vehicular cellular network, opportunistic vehicular networks are used to disseminate mobile data by high-capacity device-to-device communication, which offloads significant traffic from the cellular network. In the current opportunistic vehicular data transmission, coding-based schemes are proposed to address the challenge of opportunistic contact. However, whether coding techniques can be beneficial in the context of vehicular mobile data offloading is still an open question. In this paper, we establish a mathematical framework to study the problem of coding-based mobile data offloading under realistic network assumptions, where 1) mobile data items are heterogeneous in terms of size; 2) mobile users have different interests to different data; and 3) the storage of offloading participants is limited. We formulate the problem as a users' interest satisfaction maximization problem with multiple linear constraints of limited storage. Then, we propose an efficient scheme to solve the problem, by providing a solution that decides when the coding should be used and how to allocate the network resources in terms of contact rate and offloading helpers' storage. Finally, we show the effectiveness of our algorithm through extensive simulations using two real vehicular traces.","Mobile communication,
Encoding,
Mobile computing,
Vehicles,
Buffer storage,
Resource management,
Data models"
Model predictive control with signal temporal logic specifications,"We present a mathematical programming-based method for model predictive control of discrete-time cyber-physical systems subject to signal temporal logic (STL) specifications. We describe the use of STL to specify a wide range of properties of these systems, including safety, response and bounded liveness. For synthesis, we encode STL specifications as mixed integer-linear constraints on the system variables in the optimization problem at each step of a model predictive control framework. We present experimental results for controller synthesis for building energy and climate control.","Encoding,
Robustness,
Trajectory,
Predictive control,
Semantics,
Optimal control,
Cost function"
Information Fusion to Defend Intentional Attack in Internet of Things,"Robust network design against attacks is one of the most fundamental issues in Internet of Things (IoT) architecture as IoT operations highly rely on the support of the underlaying communication infrastructures. In this paper, the vulnerability of IoT infrastructure under intentional attacks is investigated by relating the network resilience to the percolation-based connectivity. Intentional attacks impose severe threats on the network operations as it can effectively disrupt a network by paralyzing a small fraction of nodes, and therefore deteriorating IoT operations. A fusion-based defense mechanism is proposed to mitigate the damage caused by such attacks, where each node feedbacks minimum (one-bit) local decision to the fusion center for attack inference. By formulating the attack and defense strategy as a zero-sum game, the outcome of the game equilibrium is used to evaluate the effectiveness of the proposed mechanism. The robustness of the Internet-oriented and the cyber-physical system (CPS)-oriented networks are specifically analyzed to illustrate the foundation of future IoT infrastructure. Both analytical and empirical results show that the proposed mechanism greatly enhances the robustness of IoT, even in the weak local detection capability and fragile network structure regime.",
SIP Flooding Attack Detection with a Multi-Dimensional Sketch Design,"The session initiation protocol (SIP) is widely used for controlling multimedia communication sessions over the Internet Protocol (IP). Effectively detecting a flooding attack to the SIP proxy server is critical to ensure robust multimedia communications over the Internet. The existing flooding detection schemes are inefficient in detecting low-rate flooding from dynamic background traffic, or may even totally fail when flooding is launched in a multi-attribute manner by simultaneously manipulating different types of SIP messages. In this paper, we develop an online detection scheme for SIP flooding attacks, by integrating a novel three-dimensional sketch design with the Hellinger distance (HD) detection technique. In our sketch design, each SIP attribute is associated with a two-dimensional sketch hash table, which summarizes the incoming SIP messages into a probability distribution over the sketch table. The evolution of the probability distribution can then be monitored through HD analysis for flooding attack detection. Our three-dimensional design offers the benefit of high detection accuracy even for low-rate flooding, robust performance under multi-attribute flooding, and the capability of selectively discarding the offending SIP messages to prevent the attacks from bringing damages to the network. Furthermore, we design a scheme to control the distribution of the normal traffic over the sketch. Such a design ensures our detection scheme's effectiveness even under the severe distributed denial of service (DDoS) scenario, where attackers can flood over all the sketch table entries. In this paper, we not only theoretically analyze the performance of the proposed detection techniques, but also resort to extensive computer simulations to thoroughly examine the performance.",
Improvement of Long-Term Durability and Bias Stress Stability in p-Type SnO Thin-Film Transistors Using a SU-8 Passivation Layer,"We investigate the effects of ambient atmosphere on the electrical performance of p-type tin monoxide (SnO) thin-film transistors (TFTs), and present the effective method for the passivation of SnO TFTs using a SU-8 organic layer. The experimental data shows that the SnO TFTs without a passivation layer suffer from the electrical performance degradation under humid environments, which implies that the formation of the passivation layer is necessary in p-type SnO TFTs for the stable operation of the devices. The SU-8 organic layer was successfully incorporated as a passivation layer of SnO TFTs. The SnO TFTs with a SU-8 passivation layer exhibit very similar transfer characteristics with those without a passivation layer, and show much improved long-term durability and bias stress stability compared with the SnO TFTs without a passivation layer under air environments.",
Reverse and forward engineering of frequency control in power networks,"We reverse-engineer the frequency dynamics with general primary frequency control and show that it is a distributed algorithm to solve a well-defined optimization problem. We further investigate the role of deadband in control, and show that if the aggregated uncontrolled load deviation is nonzero the frequencies will be synchronized, and if however it is zero the frequencies may oscillate but within the deadband. The optimization model does not only provide a way to characterize the equilibrium and establish the convergence of the frequency dynamics, but also suggests a principled way to engineer frequency control. By leveraging the optimization problem and insights from reverse engineering, we propose a distributed realtime frequency control scheme that does not only maintain the frequency to the nominal value but also achieves economic efficiency. This is drastically different from the current hierarchical control approach that addresses frequency regulation and economic efficiency at different timescales and with centralized control, and is what is needed for future power system to cope with rapid and large fluctuations in supply/demand and manage a huge number of control points. This work presents a step towards developing a new foundation - network dynamics as optimization algorithms - for distributed realtime control and optimization of future power networks.","Frequency control,
Optimization,
Heuristic algorithms,
Economics,
Frequency synchronization,
Equations,
Mathematical model"
Dynamic Models of Behavior for Just-in-Time Adaptive Interventions,"Improvements in health behavior theory will be central to creating successful interventions that encourage and support behavior change and maintenance. The authors discuss dynamic, multimethod, conceptually driven, and data-rich approaches for the development of testable computational models of health-related behaviors in real time.","Computational modeling,
Adaptation models,
Data models,
Context awareness,
Real-time systems,
Context modeling,
Maintenance engineering,
Deformable models"
Graph-Embedding-Based Learning for Robust Object Tracking,"Object tracking is viewed as a two-class “one-versus-rest” classification problem, in which the sample distribution of the target over a short period of time is approximately Gaussian while the background samples are often multimodal. Based on these special properties, we propose a graph-embedding-based learning method, in which the topology structures of graphs are carefully designed to reflect the properties of the sample distributions. This method can simultaneously learn the subspace of the target and its local discriminative structure against the background. Moreover, a heuristic negative sample selection scheme is adopted to make the classification more effective. In applications to tracking, the graph-embedding-based learning is incorporated into a Bayesian inference framework cascaded with hierarchical motion estimation, which significantly improves the accuracy and efficiency of the localization. Furthermore, an incremental updating technique for the graphs is developed to capture the changes in both appearance and illumination. Experimental results demonstrate that, compared with the two state-of-the-art methods, the proposed tracking algorithm is more efficient and effective, particularly in dynamically changing and cluttered scenes.",
A W-Band Low-Noise PLL With a Fundamental VCO in SiGe for Millimeter-Wave Applications,"A W-band fundamental phase-locked loop (PLL) is designed and fully integrated to achieve high output power and low noise in a 0.13-μm SiGe BiCMOS process. A PLL with a fundamental voltage-controlled oscillator (VCO) is chosen after comparing several frequency-synthesizer architectures. Local oscillator (LO) generation and LO distribution are also considered. The employed free-running VCO achieves a tuning range from 92.5 to 102.5 GHz (8.3%), an output power of 6 dBm, and a phase noise of -124.5 dBc/Hz at 10-MHz offset. The locking range of the PLL is from 92.7 to 100.2 GHz, and the phase noise is -102 dBc/Hz at 1-MHz offset. The root mean square jitter integrated from 1 MHz to 1 GHz is 71 fs. Finally, the figure-of-merit for VCOs is discussed.","Voltage-controlled oscillators,
Phase locked loops,
Power generation,
Phase noise,
Varactors,
Frequency synthesizers"
A Dynamic Model of Switched-Capacitor Power Converters,"Switched-capacitor (SC) converters are frequently used for low-power applications that require little or no output regulation. Previous work has established static SC converter models, essentially composed of an ideal transformer (with turns ratio determined by the topology) and an output resistance that varies with component choices, switching frequency, and duty ratio. In this paper, the static model is expanded to include the dynamic response to the input voltage and output current changes. The dynamic model is particularly important in systems that experience large output power transients, such as low-power systems that enter and exit sleep modes. For applications that are only concerned with input-output behavior, a reduced-order model that neglects internal dynamics is derived. The dynamic model is validated with both simulations and experimental results.","transformers,
dynamic response,
low-power electronics,
power convertors,
reduced order systems,
switched capacitor networks"
A New Payment System for Enhancing Location Privacy of Electric Vehicles,"An electric vehicle (EV) is a promising and futuristic automobile propelled by electric motors, using electrical energy stored in batteries or another energy storage device. Due to the need for the battery to be recharged, the cars will be required to visit a recharging infrastructure very frequently. This may disclose the users' private information, such as their location and, thus, compromise users' privacy. In this paper, we propose a new payment system that is suitable for EVs. Our system not only supports privacy protection (location privacy) but supports traceability in the case where the cars are stolen as well. Our system can further support the future vehicle-to-grid (V2G) paradigm. In addition, we prove the security and produce a proof-of-concept prototype to enumerate our system.",
Binaural Classification for Reverberant Speech Segregation Using Deep Neural Networks,"Speech signal degradation in real environments mainly results from room reverberation and concurrent noise. While human listening is robust in complex auditory scenes, current speech segregation algorithms do not perform well in noisy and reverberant environments. We treat the binaural segregation problem as binary classification, and employ deep neural networks (DNNs) for the classification task. The binaural features of the interaural time difference and interaural level difference are used as the main auditory features for classification. The monaural feature of gammatone frequency cepstral coefficients is also used to improve classification performance, especially when interference and target speech are collocated or very close to one another. We systematically examine DNN generalization to untrained spatial configurations. Evaluations and comparisons show that DNN-based binaural classification produces superior segregation performance in a variety of multisource and reverberant conditions.","Speech,
Training,
Azimuth,
Feature extraction,
Interference,
Signal to noise ratio"
PHEV Charging and Discharging Cooperation in V2G Networks: A Coalition Game Approach,"Recently, plug-in hybrid electric vehicles (PHEVs) have attracted considerable attention as a sustainable transport system and also an essential component of the smart grid. With the rapid growth of PHEVs penetration, the charging and discharging of PHEVs will pose a significant impact on the residential electricity distribution network. For this reason, the management of PHEV charging and discharging has become one of the key issues in the research of PHEVs. In most existing work, PHEVs are supposed to operate individually for charging and discharging in the grid. However, we argue that, by leveraging the cooperation among PHEVs, the grid will efficiently stimulate PHEV users to charge in load valley and discharge in load peak. As a consequence, the electricity load is well balanced. Meanwhile, the PHEV users also achieve higher profit. The PHEV charging and discharging cooperation is a win-win strategy for both the grid and the PHEV users. We formulate and resolve the PHEV charging and discharging cooperation in the framework of coalition game. The simulation results indicate that the peak-valley difference in electricity load of the grid is significantly reduced. Besides, the PHEV users have better satisfaction in the vehicle battery status and the economic profit.","Vehiclular ad hoc networks,
Sustainable development,
Electric vehicles,
Discharges (electric),
Battery chargers,
Hybrid electric vehicles,
Load modeling"
Mitigating cascading failures in interdependent power grids and communication networks,"We study the interdependency between the power grid and the communication network used to control the grid. A communication node depends on the power grid in order to receive power for operation, and a power node depends on the communication network in order to receive control signals. We demonstrate that these dependencies can lead to cascading failures, and it is essential to consider the power flow equations for studying the behavior of such interdependent networks. We propose a two-phase control policy to mitigate the cascade of failures. In the first phase, our control policy finds the unavoidable failures that occur due to physical disconnection. In the second phase, our algorithm redistributes the power so that all the connected communication nodes have enough power for operation and no power lines overload. We perform a sensitivity analysis to evaluate the performance of our control policy, and show that our control policy achieves close to optimal yield for many scenarios. This analysis can help design robust interdependent grids and associated control policies.",
Maximizing charging throughput in rechargeable sensor networks,"Energy is one of the most critical optimization objectives in wireless sensor networks. Compared with renewable energy harvesting technology, wireless energy transfer based on magnetic resonant coupling is able to provide more reliable energy supplies for sensors in wireless rechargeable sensor networks. The adoption of wireless mobile chargers (mobile vehicles) to replenish sensors' energy has attracted much attention recently by the research community. Most existing studies assume that the energy consumption rates of sensors in the entire network lifetime are fixed or given in advance, and no constraint is imposed on the mobile charger (e.g., its travel distance per tour). In this paper, we consider the dynamic sensing and transmission behaviors of sensors, by providing a novel charging paradigm and proposing efficient sensor charging algorithms. Specifically, we first formulate a charging throughput maximization problem. Since the problem is NP-hard, we then devise an offline approximation algorithm and online heuristics for it. We finally conduct extensive experimental simulations to evaluate the performance of the proposed algorithms. Experimental results demonstrate that the proposed algorithms are efficient.","Mobile communication,
Throughput,
Base stations,
Wireless sensor networks,
Clustering algorithms,
Wireless communication,
Approximation algorithms"
A Novel Unified Analytical Model for Broadcast Protocols in Multi-Hop Cognitive Radio Ad Hoc Networks,"Broadcast is an important operation in wireless ad hoc networks where control information is usually propagated as broadcasts for the realization of most networking protocols. In traditional ad hoc networks, since the spectrum availability is uniform, broadcasts are delivered via a common channel which can be heard by all users in a network. However, in cognitive radio (CR) ad hoc networks, different unlicensed users may acquire different available channels depending on the locations and traffic of licensed users. This non-uniform channel availability leads to several significant differences and causes unique challenges when analyzing the performance of broadcast protocols in CR ad hoc networks. In this paper, a novel unified analytical model is proposed to address these challenges. Our proposed analytical model can be applied to any broadcast protocol with any CR network topology. We propose to decompose an intricate network into several simple networks which are tractable for analysis. We also propose systematic methodologies for such decomposition. Results from both the hardware implementation and software simulation validate the analysis well. To the best of our knowledge, this is the first analytical work on the performance analysis of broadcast protocols for multi-hop CR ad hoc networks.","Broadcasting,
Wireless networks,
Ad hoc networks,
Channel estimation,
Cognitive radio"
Dynamic Scheduling and Pricing in Wireless Cloud Computing,"In this paper, we consider a wireless cloud computing system in which the service provider operates a data center and provides cloud services to its subscribers at dynamic prices. We propose a joint optimization of scheduling and pricing decisions for delay-tolerant batch services to maximize the service provider's long-term profit. Unlike the existing research on jointly scheduling and pricing that focuses on static or asymptotic analysis, we focus on a dynamic setting and develop a provably-efficient Dynamic Scheduling and Pricing (Dyn-SP) algorithm which, without the necessity of predicting the future information, can be applied to an arbitrarily random environment that may follow an arbitrary trajectory overtime. We prove that, compared to the optimal offline algorithm with future information, Dyn-SP produces a close-to-optimal average profit while bounding the job queue length in the data center. We perform a trace-based simulation study to validate Dyn-SP. In particular, we show both analytically and numerically that a desired tradeoff between the profit and queueing delay can be obtained by appropriately tuning the control parameter. Our results also indicate that, compared to the existing algorithms which neglect demand-side management, cooling system energy consumption, and/or the queue length information, Dyn-SP achieves a higher average profit while incurring (almost) the same average queueing delay.","Wireless networks,
Pricing,
Cloud computing"
"Securing smart home: Technologies, security challenges, and security requirements","Smart homes are gaining vast popularity as the most promising application of the emerging Internet of Things (IoT) technology. Exploiting the high level of connectivity present in current electronic devices (such as smartphones, tablets, and multimedia systems), smart homes provide innovative, automated and interactive services for residential customers through distributed and collaborative operations. As these types of networks become enormously popular, it is fundamental to provide the adequate level of protection against cyber-attacks for the residential customers. However, the resource-constrained nature of many of the devices present in a smart home environment, does not permit to implement the standard security solutions and therefore smart homes currently present security vulnerabilities. In this paper the security challenges and threats to the existing solutions suited for smart homes are examined in detail with the objective of fostering the development of practical solutions to secure the smart homes.","Smart homes,
Security,
Protocols,
IEEE 802.11 Standards,
IEEE 802.15 Standards,
Software,
Batteries"
TCP Congestion Avoidance Algorithm Identification,"The Internet has recently been evolving from homogeneous congestion control to heterogeneous congestion control. Several years ago, Internet traffic was mainly controlled by the traditional RENO, whereas it is now controlled by multiple different TCP algorithms, such as RENO, CUBIC, and Compound TCP (CTCP). However, there is very little work on the performance and stability study of the Internet with heterogeneous congestion control. One fundamental reason is the lack of the deployment information of different TCP algorithms. In this paper, we first propose a tool called TCP Congestion Avoidance Algorithm Identification (CAAI) for actively identifying the TCP algorithm of a remote Web server. CAAI can identify all default TCP algorithms (e.g., RENO, CUBIC, and CTCP) and most non-default TCP algorithms of major operating system families. We then present the CAAI measurement result of about 30 000 Web servers. We found that only 3.31 % ~ 14.47 % of the Web servers still use RENO, 46.92% of the Web servers use BIC or CUBIC, and 14.5 % ~ 25.66 % of the Web servers use CTCP. Our measurement results show a strong sign that the majority of TCP flows are not controlled by RENO anymore, and a strong sign that the Internet congestion control has changed from homogeneous to heterogeneous.","Web servers,
Algorithm design and analysis,
Feature extraction,
Operating systems,
Linux"
A Truthful QoS-Aware Spectrum Auction with Spatial Reuse for Large-Scale Networks,"In cognitive radio networks (CRNs), a wireless user with primary access right on a channel (called primary user) has prioritized access to the channel and the user with secondary access right (called secondary user) can use the channel when the primary user is idle. Spectrum auction has emerged as a promising approach to address the access allocation problem in CRNs. A significant challenge in designing such auction is providing truthfulness to avoid market manipulation. In most previous work, the primary access rights on channels are pre-determined before the auction and bidders can only compete for the secondary access rights. However, a user's requirement on spectrum access rights relies on their QoS demands. Therefore, it is much desirable to allocate spectrum access rights on the basis of QoS demands as well as to exploit the resulting spatial spectrum reuse opportunities. To solve this problem, we propose TRUMP, a truthful spectrum auction mechanism, by taking into consideration both QoS demands and spectrum spatial reuse, which can drastically improve spectrum utilization. The theoretical analysis proves that TRUMP achieves truthfulness and individual rationality with polynomial-time complexity. Our extensive simulation results show that our proposals outperform previous work in terms of both social welfare and spectrum utilization.",
"Top-
k
Automatic Service Composition: A Parallel Method for Large-Scale Service Sets","Quality-of-Service (QoS)-aware web service composition is of great importance to assemble individual services into a composite one meeting functional and nonfunctional requirements. Given a large number of candidate services, automatic composition is essential so as to derive a composite service efficiently. Most existing methods return one solution that is optimal in some given criteria. This is somewhat rigid in terms of flexibility. In case some component service in the optimal composition becomes unavailable, the composition algorithm has to run again to find another optimal solution. Also, in a lot of circumstances users prefer multiple alternatives over a single one. Therefore, providing top- k service compositions according to their QoS is becoming more desirable. On another aspect, from the perspective of computation efficiency, due to the explosion of the searching space, single-threaded methods are usually not capable of handling a large number of candidate services. This paper tackles these two issues together, i.e., large-scale, QoS-based services composition yielding top- k solutions. The composition algorithm is based on the combination of backtrack search and depth-first search, which can be executed in a parallel way. Experiments are carried out based on the datasets provided by the WS-Challenge competition 2009 and China Web Service 2011. The results show that our approach can not only find the same optimal solution as the winning systems from these competitions, but also provide alternative solutions together with the optimal QoS.",
On the Carrier Injection Efficiency and Thermal Property of InGaN/GaN Axial Nanowire Light Emitting Diodes,"We have investigated the impact of surface recombination on the effective carrier injection efficiency and the Joule heating of axial InGaN/GaN nanowire light-emitting diodes (LEDs). The results reveal that the carrier injection efficiency of such devices is extremely low (<;10%), due to the severe carrier loss through nonradiative surface recombination. It is further observed that the thermal resistance of typical nanowire LEDs is comparable with, or lower than that of their planar counterparts, in spite of the reduced thermal conductivity of nanowires. The poor carrier injection efficiency, however, leads to significantly elevated junction temperatures for nanowire LEDs. We have further demonstrated, both theoretically and experimentally, that the carrier injection efficiency can be significantly improved in p-doped nanowires, due to the downward surface band bending, and in InGaN/GaN/AlGaN dot-in-a-wire core-shell nanoscale heterostructures, due to the superior carrier confinement offered by the large bandgap AlGaN shell. This paper offers important insight for the design and epitaxial growth of high-performance nanowire LEDs.",
Robust and flexible FPGA-based digital PUF,"We have developed the first FPGA-based digital physical unclonable function (PUF) by leveraging the reconfigurability of an FPGA and introducing a new way of using the standard analog delay PUF. The key observation is that for any analog delay PUF, there is a subset of challenge inputs for which the PUF output is stable regardless of operation and environmental conditions. We use only such stable inputs to initialize the look-up tables (LUTs) that are configured in such a way that the digital PUF is formed. We demonstrate the effectiveness of the new security primitive using extensive simulation and experimental results. For example, we show that the new PUF is resistant against a wide spectrum of security attacks and its output stream passes all the NIST randomness tests.","Delays,
Table lookup,
Security,
Field programmable gate arrays,
Thermal stability,
Temperature distribution,
Hardware"
A Wireless Accelerometer-Based Automatic Vehicle Classification Prototype System,"Automatic vehicle classification (AVC) systems provide data about vehicle classes that are used for many purposes. This paper describes a prototype axle count and spacing AVC system using wireless accelerometers and magnetometers. The accelerometers detect vehicle axles, and the magnetometers report vehicle arrivals and departures and estimate speed. The prototype system is installed on Interstate 80 at Pinole, CA, USA, and tested under various traffic conditions. Video images and reports from a nearby commercial weigh-in-motion station provide ground truth to evaluate the performance of the system, including classification, axle spacing, and vehicle counts. The results show that the prototype AVC system is reliable in classifying vehicles even under congested traffic with accuracy of 99%.","Vehicles,
Axles,
Magnetometers,
Accelerometers,
Prototypes,
Wireless sensor networks,
Wireless communication"
Predicting Visual Semantic Descriptive Terms From Radiological Image Data: Preliminary Results With Liver Lesions in CT,"We describe a framework to model visual semantics of liver lesions in CT images in order to predict the visual semantic terms (VST) reported by radiologists in describing these lesions. Computational models of VST are learned from image data using linear combinations of high-order steerable Riesz wavelets and support vector machines (SVM). In a first step, these models are used to predict the presence of each semantic term that describes liver lesions. In a second step, the distances between all VST models are calculated to establish a nonhierarchical computationally-derived ontology of VST containing inter-term synonymy and complementarity. A preliminary evaluation of the proposed framework was carried out using 74 liver lesions annotated with a set of 18 VSTs from the RadLex ontology. A leave-one-patient-out cross-validation resulted in an average area under the ROC curve of 0.853 for predicting the presence of each VST. The proposed framework is expected to foster human-computer synergies for the interpretation of radiological images while using rotation-covariant computational models of VSTs to 1) quantify their local likelihood and 2) explicitly link them with pixel-based image content in the context of a given imaging domain.","Lesions,
Computational modeling,
Semantics,
Visualization,
Ontologies,
Liver,
Computed tomography"
A Learning-Based QoE-Driven Spectrum Handoff Scheme for Multimedia Transmissions over Cognitive Radio Networks,"Enabling the spectrum handoff for multimedia applications in cognitive radio networks (CRNs) is challenging, due to multiple interruptions from primary users (PUs), contentions among secondary users (SUs), and heterogenous Quality-of-Experience (QoE) requirements. In this paper, we propose a learning-based and QoE-driven spectrum handoff scheme to maximize the multimedia users' satisfaction. We develop a mixed preemptive and non-preemptive resume priority (PRP/NPRP) M/G/1 queueing model for modeling the spectrum usage behavior for prioritized multimedia applications. Then, a mathematical framework is formulated to analyze the performance of SUs. We apply the reinforcement learning to our QoE-driven spectrum handoff scheme to maximize the quality of video transmissions in the long term. The proposed learning scheme is asymptotically optimal, model-free, and can adaptively perform spectrum handoff for the changing channel conditions and traffic load. Experimental results demonstrate the effectiveness of the proposed queueing model for prioritized traffic in CRNs, and show that the proposed learning-based QoE-driven spectrum handoff scheme improves quality of video transmissions.",
A 3.4-pJ FeRAM-Enabled D Flip-Flop in 0.13-\mu \hbox{m} CMOS for Nonvolatile Processing in Digital Systems,"In order to realize a digital system with no distinction between “on” and “off,” the computational state must be stored in nonvolatile memory elements. If the energy cost and time cost of managing the computational state in nonvolatile memory can be lowered to the microsecond and picojoule-per-bit level, such a system could operate from unreliable harvested energy, never requiring a reboot. This work presents a nonvolatile D-flip-flop (NVDFF) designed in 0.13- μm CMOS that retains state in ferroelectric capacitors during sporadic power loss. The NVDFF is integrated into an ASIC design flow, and a test-case nonvolatile FIR filter with an accompanying power management unit automatically saves and restores the state based on the status of a one-bit indicator of energy availability. Correct operation has been verified over power-cycle intervals from 4.8 μs to 1 day. The round-trip save-restore energy is 3.4 pJ per NVDFF. Also presented are statistical measurements across 21 \thinspace000 NVDFFs to validate the capability of the circuit to achieve the requisite 10-ppm failure rate for embedded system applications.","Nonvolatile memory,
Latches,
Capacitors,
CMOS integrated circuits,
Sensors,
Finite impulse response filters,
Field effect transistors"
Designing Hardware-Efficient Fixed-Point FIR Filters in an Expanding Subexpression Space,"This paper presents a practical method for designing fixed-point FIR filters. The proposed method takes both the filter's magnitude response and its hardware cost into consideration in the design process. The method constructs a basis set based on the fixed-point coefficients that have been synthesized already. The elements in the basis set are used to synthesize the undetermined fixed-point coefficients later. Thus, this basis set expands gradually along with the progress of the coefficient design. The method employs some strategies to speed up the design process. For example, a complexity estimation strategy helps us stop digging deeper in some branches of the search tree, and a solution prediction strategy for high-order FIR filters helps us design fixed-point FIR filters of length equal to a few hundreds. Applying the proposed method to design twenty benchmark cases, we can obtain hardware-efficient results in a reasonable design time. In two long filter design cases, our design results are better than those designed by the other methods.","Finite impulse response filters,
Adders,
Passband,
Hardware,
Complexity theory,
Design methodology,
Computers"
Data-Driven MFAC for a Class of Discrete-Time Nonlinear Systems With RBFNN,"A novel model-free adaptive control method is proposed for a class of discrete-time single input single output (SISO) nonlinear systems, where the equivalent dynamic linearization technique is used on the ideal nonlinear controller. With radial basis function neural network, the controller parameters are tuned on-line directly using the measured input and output data of the plant, when the plant model is unavailable. The stability of the proposed method is guaranteed by rigorous theoretical analysis, and the effectiveness and applicability are verified by numerical simulation and further demonstrated by the experiment on three tanks water level control process.","Data models,
Tuning,
Control systems,
Vectors,
Adaptation models,
Neurons,
Learning systems"
Maximal Entropy Random Walk for Region-Based Visual Saliency,"Visual saliency is attracting more and more research attention since it is beneficial to many computer vision applications. In this paper, we propose a novel bottom-up saliency model for detecting salient objects in natural images. First, inspired by the recent advance in the realm of statistical thermodynamics, we adopt a novel mathematical model, namely, the maximal entropy random walk (MERW) to measure saliency. We analyze the rationality and superiority of MERW for modeling visual saliency. Then, based on the MERW model, we establish a generic framework for saliency detection. Different from the vast majority of existing saliency models, our method is built on a purely region-based strategy, which is able to yield high-resolution saliency maps with well preserved object shapes and uniformly highlighted salient regions. In the proposed framework, the input image is first over-segmented into superpixels, which are taken as the primary units for subsequent procedures, and regional features are extracted. Then, saliency is measured according to two principles, i.e., uniqueness and visual organization, both implemented in a unified approach, i.e., the MERW model based on graph representation. Intensive experimental results on publicly available datasets demonstrate that our method outperforms the state-of-the-art saliency models.","Visualization,
Computational modeling,
Mathematical model,
Image segmentation,
Entropy,
Image color analysis,
Thermodynamics"
Interactive Artificial Bee Colony Supported Passive Continuous Authentication System,"In this paper, an initiative passive continuous authentication (CA) system based on both hard and soft biometrics is presented. Human facial features are used as hard biometric information for the authentication process, and the clothes' color of a user is employed as the soft biometric information. The passive CA system keeps verifying, without interrupting the user from concentrating on his work. It also provides the capacity for the machine to recognize who is in front of the terminal, reduces the potential security leaks, and denies access to the invader with the stolen account and password. In this system, the face recognition core is implemented not only by the Eigenface method, but also assisted by the interactive artificial bee colony optimization algorithm. The proposed method is evaluated by the ORL face database and tested on the prototype CA system for computer security. The experimental results indicate that the accuracy of recognition is raised up to 3.13%, i.e., from 83.75% to 86.88%, with data from the ORL database, and it is improved by 34.53% on average in the real-time continuous authentication environment.",
Nonmyopic View Planning for Active Object Classification and Pose Estimation,"One of the central problems in computer vision is the detection of semantically important objects and the estimation of their pose. Most of the work in object detection has been based on single image processing, and its performance is limited by occlusions and ambiguity in appearance and geometry. This paper proposes an active approach to object detection in which the point of view of a mobile depth camera is controlled. When an initial static detection phase identifies an object of interest, several hypotheses are made about its class and orientation. Then, a sequence of views, which balances the amount of energy used to move the sensor with the chance of identifying the correct hypothesis, is planned. We formulate an active hypothesis testing problem, which includes sensor mobility, and solve it using a point-based approximate partially observable Markov decision process algorithm. The validity of our approach is verified through simulation and realworld experiments with the PR2 robot. The results suggest that the approach outperforms the widely used greedy viewpoint selection and provides a significant improvement over static object detection.","Robot sensing systems,
Planning,
Detectors,
Estimation,
Mobile communication,
Cameras"
Morphological Profiles Based on Differently Shaped Structuring Elements for Classification of Images With Very High Spatial Resolution,"Morphological profiles (MPs) have been proposed for the segmentation and classification of high spatial resolution (HSR) images. A shortcoming of the originally proposed MPs is that the profiles were only based on structuring elements (SEs) of one particular shape, suggesting that such MPs may not be suitable for detecting different shapes in images. To better fit several shapes in a given image, a new approach based on mathematical morphology is proposed to extract structural information from HSR images and consequently yield new versions of MPs. The classification results for the new MPs are compared with the classification of spatial features extracted with the use of pixel shape index, gray level co-occurrence matrix, and previously proposed MPs. The experimental results suggest the following: 1) structural and spectral features can complement each other and their integration can improve classification accuracy and 2) MPs constructed by differently shaped SEs are less sensitive to salt-and-pepper noise than those constructed by fixed-shaped SEs.",
Optimal Demand-Side Management and Power Generation Scheduling in an All-Electric Ship,"The worldwide effort for the development of more efficient and environmentally friendly ships has led to the development of new concepts. Extensive electrification is a very promising technology for this purpose. Together with optimal power management can lead to a substantial improvement in ship efficiency ensuring, at the same time, compliance with the environmental constraints and enhancing ship sustainability. In this paper, a method for optimal demand-side management and power generation scheduling is proposed. Demand-side management is based on the adjustment of the power consumed by ship electric propulsion motors, and no energy storage facility is exploited. Dynamic programming algorithm subjected to ship operation and environmental and travel constraints is used to solve the problem for all-electric ships (AESs). Simulation results prove that the proposed method ensures cost minimization of ship power system operation, greenhouse gas (GHG) emissions limitation, and compliance with all technical and operational constraints.","Marine vehicles,
Generators,
Propulsion,
Energy efficiency,
Power generation,
Optimization,
Dynamic programming"
Hardware obfuscation using PUF-based logic,"There is a great need to develop universal and robust techniques for intellectual property protection of integrated circuits. In this paper, we introduce techniques for the obfuscation of an arbitrary circuit by using physical unclonable functions (PUFs) and programmable logic. Specifically, we introduce the notion of PUF-based logic which can be configured to be functionally equivalent to any arbitrary design, as well as a new architecture for wire merging that obfuscates signal paths exponentially. We systematically apply our techniques in such a way so as to maximize obfuscation while minimizing area and delay overhead. We analyze our techniques on popular benchmark circuits and show them to be resilient against very powerful reverse engineering attacks in which the adversary has knowledge of the complete netlist along with the ability to read and write to any flip-flop in the circuit.","Wires,
Reverse engineering,
Logic gates,
Field programmable gate arrays,
Security,
Standards,
Hardware"
Modeling and Analysis on the Propagation Dynamics of Modern Email Malware,"Due to the critical security threats imposed by email-based malware in recent years, modeling the propagation dynamics of email malware becomes a fundamental technique for predicting its potential damages and developing effective countermeasures. Compared to earlier versions of email malware, modern email malware exhibits two new features, reinfection and self-start. Reinfection refers to the malware behavior that modern email malware sends out malware copies whenever any healthy or infected recipients open the malicious attachment. Self-start refers to the behavior that malware starts to spread whenever compromised computers restart or certain files are visited. In the literature, several models are proposed for email malware propagation, but they did not take into account the above two features and cannot accurately model the propagation dynamics of modern email malware. To address this problem, we derive a novel difference equation based analytical model by introducing a new concept of virtual infected user. The proposed model can precisely present the repetitious spreading process caused by reinfection and self-start and effectively overcome the associated computational challenges. We perform comprehensive empirical and theoretical study to validate the proposed analytical model. The results show our model greatly outperforms previous models in terms of estimation accuracy.","Electronic mail,
Malware,
Mathematical model,
Computational modeling,
Analytical models,
Computers,
Topology"
"Artificial Neural Networks for Control of a Grid-Connected Rectifier/Inverter Under Disturbance, Dynamic and Power Converter Switching Conditions","Three-phase grid-connected converters are widely used in renewable and electric power system applications. Traditionally, grid-connected converters are controlled with standard decoupled d-q vector control mechanisms. However, recent studies indicate that such mechanisms show limitations in their applicability to dynamic systems. This paper investigates how to mitigate such restrictions using a neural network to control a grid-connected rectifier/inverter. The neural network implements a dynamic programming algorithm and is trained by using backpropagation through time. To enhance performance and stability under disturbance, additional strategies are adopted, including the use of integrals of error signals to the network inputs and the introduction of grid disturbance voltage to the outputs of a well-trained network. The performance of the neural-network controller is studied under typical vector control conditions and compared against conventional vector control methods, which demonstrates that the neural vector control strategy proposed in this paper is effective. Even in dynamic and power converter switching environments, the neural vector controller shows strong ability to trace rapidly changing reference commands, tolerate system disturbances, and satisfy control requirements for a faulted power system.","Voltage control,
Vectors,
Neural networks,
Control systems,
Standards,
Tuning,
Inverters"
Robust Control for Urban Road Traffic Networks,"The aim of the presented research is to elaborate a traffic-responsive optimal signal split algorithm taking uncertainty into account. The traffic control objective is to minimize the weighted link queue lengths within an urban network area. The control problem is formulated in a centralized rolling-horizon fashion in which unknown but bounded demand and queue uncertainty influences the prediction. An efficient constrained minimax optimization is suggested to obtain the green time combination, which minimizes the objective function when worst case uncertainty appears. As an illustrative example, a simulation study is carried out to demonstrate the effectiveness and computational feasibility of the robust predictive approach. By using real-world traffic data and microscopic traffic simulator, the proposed robust signal split algorithm is analyzed and compared with well-tuned fixed-time signal timing and to nominal predictive solutions under different traffic conditions.","Uncertainty,
Mathematical model,
Predictive models,
Optimization,
Computational modeling,
Robustness,
Vehicles"
Reusing Genetic Programming for Ensemble Selection in Classification of Unbalanced Data,"Classification algorithms can suffer from performance degradation when the class distribution is unbalanced. This paper develops a two-step approach to evolving ensembles using genetic programming (GP) for unbalanced data. The first step uses multiobjective (MO) GP to evolve a Pareto-approximated front of GP classifiers to form the ensemble by trading-off the minority and the majority class against each other during learning. The MO component alleviates the reliance on sampling to artificially rebalance the data. The second step, which is the focus this paper, proposes a novel ensemble selection approach using GP to automatically find/choose the best individuals for the ensemble. This new GP approach combines multiple Pareto-approximated front members into a single composite genetic program solution to represent the (optimized) ensemble. This ensemble representation has two main advantages/novelties over traditional genetic algorithm (GA) approaches. First, by limiting the depth of the composite solution trees, we use selection pressure during evolution to find small highly-cooperative groups of individuals for the ensemble. This means that ensemble sizes are not fixed a priori (as in GA), but vary depending on the strength of the base learners. Second, we compare different function set operators in the composite solution trees to explore new ways to aggregate the member outputs and thus, control how the ensemble computes its output. We show that the proposed GP approach evolves smaller more diverse ensembles compared to an established ensemble selection algorithm, while still performing as well as, or better than the established approach. The evolved GP ensembles also perform well compared to other bagging and boosting approaches, particularly on tasks with high levels of class imbalance.",
Fast and Flexible Hardware Support for ECC Over Multiple Standard Prime Fields,"Elliptic curve cryptography (ECC) is widely used as an efficient mechanism to secure private data using public-key protocols. We focus on ECC over five standard prime fields recommended by the National Institute of Standard and Technology (with the corresponding prime sizes of 192, 224, 256, 384, and 521 bits) and propose a novel hardware processor that enables flexible security-performance tradeoffs. To enhance performance, our processor exploits parallelism by pipelining modular arithmetic computations and associated input/output data transfers. To enhance security, modular arithmetic computations and associated data transfers are grouped into atomically executed computational blocks. The flexibility of our processor is achieved through the software-controlled hardware programmability, which allows for different scenarios of computing atomic block sequences. A Xilinx Virtex-6 FPGA implementation of the proposed hardware architecture takes between 0.30 ms (192-bit ECC) and 3.91 ms (521-bit ECC) to perform a typical scalar multiplication, which demonstrates both flexibility and efficiency of our processor.",
Comparison of Reaction-Diffusion and Atomistic Trap-Based BTI Models for Logic Gates,"In deeply scaled CMOS technology, time-dependent degradation mechanisms (TDDMs), such as Bias Temperature Instability (BTI), have threatened the transistor performance, hence the overall circuit/system reliability. Two well-known attempts to model BTI mechanism are the reaction-diffusion (R-D) model and the Atomistic trap-based model. This paper presents a thorough comparative analysis of the two models at the gate-level in order to explore when their predictions are the same and when not. The comparison is done by evaluating degradation trends in a set of CMOS logic gates (e.g., INV, NAND, NOR, etc.) while considering seven attributes: 1) gate type, 2) gate drive strength, 3) input frequency, 4) duty factor, 5) non-periodicity, 6) instant degradation versus long-term aging, and 7) simulation CPU time and memory usage. The simulation results show that two models are in consistency in terms of the gate degradation trends w.r.t. the first four attributes (gate type, input frequency, etc.). For the rest of the attributes, the workload-dependent solution of the Atomistic trap-based model is superior from the point of non-periodicity and instant degradation, while the R-D model gets advantageous in case of long-term aging, and simulation CPU time and memory usage due to its lite AC periodic and duty factor dependent solution.","Atomistic trapping,
Degradation,
Reaction-diffusion models"
Hyperspectral Image Classification Using Functional Data Analysis,"The large number of spectral bands acquired by hyperspectral imaging sensors allows us to better distinguish many subtle objects and materials. Unlike other classical hyperspectral image classification methods in the multivariate analysis framework, in this paper, a novel method using functional data analysis (FDA) for accurate classification of hyperspectral images has been proposed. The central idea of FDA is to treat multivariate data as continuous functions. From this perspective, the spectral curve of each pixel in the hyperspectral images is naturally viewed as a function. This can be beneficial for making full use of the abundant spectral information. The relevance between adjacent pixel elements in the hyperspectral images can also be utilized reasonably. Functional principal component analysis is applied to solve the classification problem of these functions. Experimental results on three hyperspectral images show that the proposed method can achieve higher classification accuracies in comparison to some state-of-the-art hyperspectral image classification methods.","Hyperspectral imaging,
Support vector machines,
Splines (mathematics),
Feature extraction,
Kernel,
Principal component analysis"
Efficient algorithm and architecture for elliptic curve cryptography for extremely constrained secure applications,"Recently, considerable research has been performed in cryptography and security to optimize the area, power, timing, and energy needed for the point multiplication operations over binary elliptic curves. In this paper, we propose an efficient implementation of point multiplication on Koblitz curves targeting extremely-constrained, secure applications. We utilize the Gaussian normal basis (GNB) representation of field elements over GF(2m) and employ an efficient bit-level GNB multiplier. One advantage of this GNB multiplier is that we are able to reduce the hardware complexity through sharing the addition/accumulation with other field additions. We utilized the special property of normal basis representation and squarings are implemented very efficiently by only rewiring in hardware. We introduce a new technique for point addition in affine coordinate which requires fewer registers. Based on this technique, we propose an extremely small processor architecture for point multiplication. Through application-specific integrated circuit (ASIC) implementations, we evaluate the area, performance, and energy consumption of the proposed crypto-processor. Utilizing two different working frequencies, it is shown that the proposed architecture reaches better results compared to the previous works, making it suitable for extremely-constrained, secure environments.","Gaussian processes,
Registers,
Computer architecture,
Elliptic curve cryptography,
Hardware,
Complexity theory"
Design of a Wideband Planar Printed Quasi-Yagi Antenna Using Stepped Connection Structure,"Although conventional Yagi antenna has the advantage of unidirectional radiation patterns, it is not suitable for wideband applications due to its drawback of narrow bandwidth. In this communication, a compact wideband planar printed quasi-Yagi antenna is presented. The proposed quasi-Yagi antenna consists of a microstrip line to slotline transition structure, a driver dipole, and a parasitic strip element. The driver dipole is connected to the slotline through a coplanar stripline (CPS). The proposed antenna uses a stepped connection structure between the CPS and the slotline to improve the impedance matching. Two apertures are symmetrically etched in the ground plane to improve the unidirectional radiation characteristics. Simulation and experimental results show that the unidirectional radiation patterns of the proposed antenna are good. A 92.2% measured bandwidth with from 3.8 to 10.3 GHz is achieved. A moderate gain, which is better than 4 dBi, is also obtained.",
A 10/30 MHz Fast Reference-Tracking Buck Converter With DDA-Based Type-III Compensator,"A 10/30 MHz voltage-mode controlled buck converter with a wide duty-cycle range is presented. A high-accuracy delay-compensated ramp generator using only low-speed comparators but can work up to 70 MHz is proposed. By using a differential difference amplifier (DDA), a new Type-III compensator is proposed to reduce the chip area of the compensator by 60%. Moreover, based on the unique structure of the proposed compensator, an end-point prediction (EPP) scheme is also implemented to achieve fast reference-tracking responses. The converter was fabricated in a 0.13 μm standard CMOS process. It achieves wide duty-cycle ranges of 0.75 and 0.59 when switching at 10 MHz and 30 MHz with peak efficiencies of 91.8% and 86.6%, respectively. The measured maximum output power is 3.6 W with 2.4 V output voltage and 1.5 A load current. With a constant load current of 500 mA, the up-tracking speeds for switching frequencies of 10 MHz and 30 MHz are 1.67 μs/V and 0.67 μs/V, respectively. The down-tracking speeds for 10 MHz and 30 MHz are 4.44 μs/V and 1.56 μs/V, respectively.","Delays,
Generators,
Voltage control,
Switching frequency,
DC-DC power converters,
Capacitors,
System-on-chip"
Depth Map Coding for View Synthesis Based on Distortion Analyses,"In 3-D video, view synthesis with depth-image-based rendering is employed to generate any virtual view between available camera views. Distortions in depth map induce geometry changes in the virtual views, and thus degrade the performance of view synthesis. This paper proposes a depth map coding method to improve the performance of view synthesis based on distortion analyses. The major technical innovation of this paper is to formulate maximum tolerable depth distortion (MTDD) and depth disocclusion mask (DDM), since such depth sensitivity for view synthesis and inter-view redundancy can be well utilized in coding. To be more specific, we define two different encoders (e.g., base encoder and side encoder) for depth maps in left and right views, respectively. For base encoding, different types of coding units are extracted based on the distribution of MTDD and assigned with different quantitative parameters for coding. For side encoding, a warped-SKIP mode is designed to remove inter-view redundancy based on the distribution of DDM. The experimental results show that the proposed scheme not only achieves high view synthesis performance, but also reduce the computational complexity of encoding.","Encoding,
Image color analysis,
Image coding,
Cameras,
Video coding,
Correlation,
Image analysis"
IVC in Cities: Signal Attenuation by Buildings and How Parked Cars Can Improve the Situation,"We study the effectiveness of Inter-Vehicle Communication (IVC) in urban and suburban environments at low node densities, with a particular focus on cooperative awareness and traffic safety. The recently standardized DSRC/WAVE protocol suite defines a platform for such applications, which mainly focus on beaconing, i.e., periodic 1-hop-broadcast. In general, such safety relevant transmissions are defined by time criticality. One of the major problems to be solved is how to tackle the very difficult and complex radio signal attenuation due to buildings and other obstacles, especially in cities. Typical concepts address this problem by requiring all vehicles to also act as relays or by using dedicated Roadside Units (RSUs). We show how such systems may be operated more efficiently and how the situation can be further improved by relying on parked vehicles in addition to, or as a replacement for, RSUs. Given the fact that the U.S. DOT is already evaluating whether to make DSRC mandatory for new cars, wide availability of radio equipped cars can be predicted; also the impact in terms of energy consumption is negligible. We performed an extensive set of simulations to evaluate the negative impact of buildings at low node densities and the benefit of our proposal. Our results clearly indicate that situation awareness can be significantly improved. When disseminating safety critical events in a realistic scenario, reasonable numbers of parked cars can increase cooperative awareness by up to 25%, a factor which requires an unreasonably costly number of RSUs. To the best of our knowledge, we are the first to propose the utilization of parked vehicles as relay nodes for safety applications in vehicular networks.",
"Drift-free humanoid state estimation fusing kinematic, inertial and LIDAR sensing","This paper describes an algorithm for the probabilistic fusion of sensor data from a variety of modalities (inertial, kinematic and LIDAR) to produce a single consistent position estimate for a walking humanoid. Of specific interest is our approach for continuous LIDAR-based localization which maintains reliable drift-free alignment to a prior map using a Gaussian Particle Filter. This module can be bootstrapped by constructing the map on-the-fly and performs robustly in a variety of challenging field situations. We also discuss a two-tier estimation hierarchy which preserves registration to this map and other objects in the robot's vicinity while also contributing to direct low-level control of a Boston Dynamics Atlas robot. Extensive experimental demonstrations illustrate how the approach can enable the humanoid to walk over uneven terrain without stopping (for tens of minutes), which would otherwise not be possible. We characterize the performance of the estimator for each sensor modality and discuss the computational requirements.","Robot sensing systems,
Legged locomotion,
Laser radar,
Foot,
Joints,
Pelvis"
MVCWalker: Random Walk-Based Most Valuable Collaborators Recommendation Exploiting Academic Factors,"In academia, scientific research achievements would be inconceivable without academic collaboration and cooperation among researchers. Previous studies have discovered that productive scholars tend to be more collaborative. However, it is often difficult and time-consuming for researchers to find the most valuable collaborators (MVCs) from a large volume of big scholarly data. In this paper, we present MVCWalker, an innovative method that stands on the shoulders of random walk with restart (RWR) for recommending collaborators to scholars. Three academic factors, i.e., coauthor order, latest collaboration time, and times of collaboration, are exploited to define link importance in academic social networks for the sake of recommendation quality. We conducted extensive experiments on DBLP data set in order to compare MVCWalker to the basic model of RWR and the common neighbor-based model friend of friends in various aspects, including, e.g., the impact of critical parameters and academic factors. Our experimental results show that incorporating the above factors into random walk model can improve the precision, recall rate, and coverage rate of academic collaboration recommendations.","Collaboration,
Social network services,
Vectors,
Educational institutions,
Recommender systems,
Context,
Data models"
Resource Allocation for Personalized Video Summarization,"We propose a hybrid personalized summarization framework that combines adaptive fast-forwarding and content truncation to generate comfortable and compact video summaries. We formulate video summarization as a discrete optimization problem, where the optimal summary is determined by adopting Lagrangian relaxation and convex-hull approximation to solve a resource allocation problem. To trade-off playback speed and perceptual comfort we consider information associated to the still content of the scene, which is essential to evaluate the relevance of a video, and information associated to the scene activity, which is more relevant for visual comfort. We perform clip-level fast-forwarding by selecting the playback speeds from discrete options, which naturally include content truncation as special case with infinite playback speed. We demonstrate the proposed summarization framework in two use cases, namely summarization of broadcasted soccer videos and surveillance videos. Objective and subjective experiments are performed to demonstrate the relevance and efficiency of the proposed method.","Visualization,
Resource management,
Optimization,
Surveillance,
Organizations,
Semantics,
Approximation methods"
Germanium Gate PhotoMOSFET Integrated to Silicon Photonics,"This paper presents a novel germanium gated NMOS phototransistor integrated on a silicon photonics platform on silicon-on-insulator (SOI) substrate. The phototransistor is fabricated with a modified NMOS process flow, with germanium which is recrystallized using rapid melt growth during the source/drain activation anneal step. The resulting device, with 1-μm channel length, and 8-μm channel width, demonstrates a responsivity of over 18 A/W at 1550 nm with 583 nW of incident light. By increasing the incident power to 912 μW, the device operates at 2.5 GHz. Miniaturization is expected to improve both responsivity and speed in future devices.","Logic gates,
Germanium,
Silicon,
Transistors,
Optical waveguides,
Photodiodes,
Capacitance"
Body Surface Context: A New Robust Feature for Action Recognition From Depth Videos,"Human action recognition in videos is useful for many applications. However, there still exist huge challenges in real applications due to the variations in the appearance, lighting condition and viewing angle, of the subjects. In this consideration, depth data have advantages over red, green, blue (RGB) data because of their spatial information about the distance between object and viewpoint. Unlike existing works, we utilize the 3-D point cloud, which contains points in the 3-D real-world coordinate system to represent the external surface of human body. Specifically, we propose a new robust feature, the body surface context (BSC), by describing the distribution of relative locations of the neighbors for a reference point in the point cloud in a compact and descriptive way. The BSC encodes the cylindrical angular of the difference vector based on the characteristics of human body, which increases the descriptiveness and discriminability of the feature. As the BSC is an approximate object-centered feature, it is robust to transformations including translations and rotations, which are very common in real applications. Furthermore, we propose three schemes to represent human actions based on the new feature, including the skeleton-based scheme, the random-reference-point scheme, and the spatial-temporal scheme. In addition, to evaluate the proposed feature, we construct a human action dataset by a depth camera. Experiments on three datasets demonstrate that the proposed feature outperforms RGB-based features and other existing depth-based features, which validates that the BSC feature is promising in the field of human action recognition.","Three-dimensional displays,
Vectors,
Feature extraction,
Joints,
Shape,
Context"
OMP Based Joint Sparsity Pattern Recovery Under Communication Constraints,"We address the problem of joint sparsity pattern recovery based on multiple measurement vectors (MMVs) in resource constrained distributed networks. We assume that distributed nodes observe sparse signals that share a common (but unknown) sparsity pattern. Each node is assumed to sample the sparse signals via different sensing matrices in general. In many distributed communication networks, it is often required that joint sparse recovery be performed under inherent resource constraints such as communication bandwidth and transmit/processing power. We propose two approaches to take the communication constraints into account while performing joint sparsity pattern recovery. First, we explore the use of a shared multiple access channel (MAC) in forwarding observation vectors from each node to a fusion center. With MAC, while the bandwidth requirement does not depend on the number of nodes, the fusion center has access to only linear combinations of the observations. We discuss the conditions under which the common sparsity pattern can be recovered reliably. Second, we develop two efficient collaborative algorithms based on orthogonal matching pursuit (OMP), to jointly estimate the common sparsity pattern in a decentralized manner with a low communication overhead. In the proposed algorithms, each node collaborates with neighboring nodes by sharing a small amount of information at different stages while estimating the indices of the true sparsity pattern in a greedy manner. The tradeoff between the performance gain and the communication overhead of the proposed algorithms is demonstrated via simulations.","Vectors,
Matching pursuit algorithms,
Joints,
Sensors,
Sparse matrices,
Signal processing algorithms,
Bandwidth"
How to Estimate the Regularization Parameter for Spectral Regression Discriminant Analysis and its Kernel Version?,"Spectral regression discriminant analysis (SRDA) has recently been proposed as an efficient solution to large-scale subspace learning problems. There is a tunable regularization parameter in SRDA, which is critical to algorithm performance. However, how to automatically set this parameter has not been well solved until now. So this regularization parameter was only set to be a constant in SRDA, which is obviously suboptimal. This paper proposes to automatically estimate the optimal regularization parameter of SRDA based on the perturbation linear discriminant analysis (PLDA). In addition, two parameter estimation methods for the kernel version of SRDA are also developed. One is derived from the method of optimal regularization parameter estimation for SRDA. The other is to utilize the kernel version of PLDA. Experiments on a number of publicly available databases demonstrate the effectiveness of the proposed methods for face recognition, spoken letter recognition, handwritten digit recognition, and text categorization.",
Interaction primitives for human-robot cooperation tasks,"To engage in cooperative activities with human partners, robots have to possess basic interactive abilities and skills. However, programming such interactive skills is a challenging task, as each interaction partner can have different timing or an alternative way of executing movements. In this paper, we propose to learn interaction skills by observing how two humans engage in a similar task. To this end, we introduce a new representation called Interaction Primitives. Interaction primitives build on the framework of dynamic motor primitives (DMPs) by maintaining a distribution over the parameters of the DMP. With this distribution, we can learn the inherent correlations of cooperative activities which allow us to infer the behavior of the partner and to participate in the cooperation. We will provide algorithms for synchronizing and adapting the behavior of humans and robots during joint physical activities.","Robots,
Trajectory,
Joints,
Vectors,
Hidden Markov models,
IP networks,
Human-robot interaction"
A Circularly Polarized Multiple Radiating Mode Microstrip Antenna for Satellite Receive Applications,"A beam peak and null steering multiple radiating mode based microstrip patch antenna is presented for satellite receive applications operating at L1 Global Positioning System (GPS) band. Two collocated microstrip patch antennas were designed to produce TM11 and TM21 radiating modes. These orthogonal and circularly polarized radiation patterns were combined enabling full hemispherical steering of a single beam peak and null. Using theoretical analysis and full-wave simulation, the multimode aperture was designed to operate over a 25 MHz bandwidth centered at 1.575 GHz, which covers the L1 GPS band. Impedance and radiation pattern measurements of the passive antenna aperture were in close agreement with the simulated data. Next, this antenna was integrated with an active feed network allowing full hemispherical control over the beam null position and limited beam peak scan in ≈ 5° increments. Using a simple calibration scheme, the measured beam peak and null elevation angles were programmed to within <; 10° of the intended value based on simulation. Azimuthal positions were consistently offset by ≈ 20° from the simulated value, which could be resolved in the board layout by phase matching the transmission lines and test point locations. The antenna maintained high total efficiency >68% and low axial ratio 3 dB over all steering angles.",
A Broadcast Approach for Fading Wiretap Channels,"A (layered) broadcast approach is studied for the fading wiretap channel without the channel state information (CSI) at the transmitter. Two broadcast schemes, based on superposition coding and embedded coding, respectively, are developed to encode information into a number of layers and use stochastic encoding to keep the corresponding information secret from an eavesdropper. The layers that can be successfully and securely transmitted are determined by the channel states to the legitimate receiver and the eavesdropper. The advantage of these broadcast approaches is that the transmitter does not need to know the CSI to the legitimate receiver and the eavesdropper, but the scheme still adapts to the channel states of the legitimate receiver and the eavesdropper. Three scenarios of block fading wiretap channels with stringent delay constraints are studied, in which either the legitimate receiver's channel, the eavesdropper's channel, or both channels are fading. For each scenario, the secrecy rate that can be achieved via the broadcast approach developed in this paper is derived, and the optimal power allocation over the layers (or the conditions on the optimal power allocation) is also characterized. A notion of probabilistic secrecy, which characterizes the probability that a certain secrecy rate of decoded messages is achieved during one block, is also introduced and studied for scenarios when the eavesdropper's channel is fading. Numerical examples are provided to demonstrate the impact of the CSI at the transmitter and the channel fluctuations of the eavesdropper on the average secrecy rate. These examples also demonstrate the advantage of the proposed broadcast approach over the compound channel approach.","Receivers,
Fading,
Transmitters,
Encoding,
Indexes,
Resource management,
Security"
"Augmented Lagrangian with Variable Splitting for Faster Non-Cartesian {\rm L}_{1}
-SPIRiT MR Image Reconstruction","SPIRiT (iterative self-consistent parallel imaging reconstruction), and its sparsity-regularized variant L1-SPIRiT, are compatible with both Cartesian and non-Cartesian magnetic resonance imaging sampling trajectories. However, the non-Cartesian framework is more expensive computationally, involving a nonuniform Fourier transform with a nontrivial Gram matrix. We propose a novel implementation of the regularized reconstruction problem using variable splitting, alternating minimization of the augmented Lagrangian, and careful preconditioning. Our new method based on the alternating direction method of multipliers converges much faster than existing methods because of the preconditioners' heightened effectiveness. We demonstrate such rapid convergence substantially improves image quality for a fixed computation time. Our framework is a step forward towards rapid non-Cartesian L1-SPIRiT reconstructions.","Image reconstruction,
Coils,
Imaging,
Convergence,
Transforms,
Tuning,
Mathematical model"
"Similarity Measure Between Patient Traces for Clinical Pathway Analysis: Problem, Method, and Applications","Clinical pathways leave traces, described as event sequences with regard to a mixture of various latent treatment behaviors. Measuring similarities between patient traces can profitably be exploited further as a basis for providing insights into the pathways, and complementing existing techniques of clinical pathway analysis (CPA), which mainly focus on looking at aggregated data seen from an external perspective. Most existing methods measure similarities between patient traces via computing the relative distance between their event sequences. However, clinical pathways, as typical human-centered processes, always take place in an unstructured fashion, i.e., clinical events occur arbitrarily without a particular order. Bringing order in the chaos of clinical pathways may decline the accuracy of similarity measure between patient traces, and may distort the efficiency of further analysis tasks. In this paper, we present a behavioral topic analysis approach to measure similarities between patient traces. More specifically, a probabilistic graphical model, i.e., latent Dirichlet allocation (LDA), is employed to discover latent treatment behaviors of patient traces for clinical pathways such that similarities of pairwise patient traces can be measured based on their underlying behavioral topical features. The presented method provides a basis for further applications in CPA. In particular, three possible applications are introduced in this paper, i.e., patient trace retrieval, clustering, and anomaly detection. The proposed approach and the presented applications are evaluated via a real-world dataset of several specific clinical pathways collected from a Chinese hospital.","Hospitals,
Mathematical model,
Blood,
Sugar,
Kidney,
Vectors,
Resource management"
Solving the Physical Traveling Salesman Problem: Tree Search and Macro Actions,"This paper presents a number of approaches for solving a real-time game consisting of a ship that must visit a number of waypoints scattered around a 2-D maze full of obstacles. The game, the Physical Traveling Salesman Problem (PTSP), which featured in two IEEE conference competitions during 2012, provides a good balance between long-term planning (finding the optimal sequence of waypoints to visit), and short-term planning (driving the ship in the maze). This paper focuses on the algorithm that won both PTSP competitions: it takes advantage of the physics of the game to calculate the optimal order of waypoints, and it employs Monte Carlo tree search (MCTS) to drive the ship. The algorithm uses repetitions of actions (macro actions) to reduce the search space for navigation. Variations of this algorithm are presented and analyzed, in order to understand the strength of each one of its constituents and to comprehend what makes such an approach the best controller found so far for the PTSP.",
An Online Learned Elementary Grouping Model for Multi-target Tracking,"We introduce an online approach to learn possible elementary groups (groups that contain only two targets) for inferring high level context that can be used to improve multi-target tracking in a data-association based framework. Unlike most existing association-based tracking approaches that use only low level information (e.g., time, appearance, and motion) to build the affinity model and consider each target as an independent agent, we online learn social grouping behavior to provide additional information for producing more robust tracklets affinities. Social grouping behavior of pairwise targets is first learned from confident tracklets and encoded in a disjoint grouping graph. The grouping graph is further completed with the help of group tracking. The proposed method is efficient, handles group merge and split, and can be easily integrated into any basic affinity model. We evaluate our approach on two public datasets, and show significant improvements compared with state-of-the-art methods.","Conferences,
Computer vision,
Pattern recognition"
On a Mathematical Model for Low-Rate Shrew DDoS,"The shrew distributed denial of service (DDoS) attack is very detrimental for many applications, since it can throttle TCP flows to a small fraction of their ideal rate at very low attack cost. Earlier works mainly focused on empirical studies of defending against the shrew DDoS, and very few of them provided analytic results about the attack itself. In this paper, we propose a mathematical model for estimating attack effect of this stealthy type of DDoS. By originally capturing the adjustment behaviors of victim TCPs congestion window, our model can comprehensively evaluate the combined impact of attack pattern (i.e., how the attack is configured) and network environment on attack effect (the existing models failed to consider the impact of network environment). Henceforth, our model has higher accuracy over a wider range of network environments. The relative error of our model remains around 10% for most attack patterns and network environments, whereas the relative error of the benchmark model in previous works has a mean value of 69.57%, and it could be more than 180% in some cases. More importantly, our model reveals some novel properties of the shrew attack from the interaction between attack pattern and network environment, such as the minimum cost formula to launch a successful attack, and the maximum effect formula of a shrew attack. With them, we are able to find out how to adaptively tune the attack parameters (e.g., the DoS burst length) to improve its attack effect in a given network environment, and how to reconfigure the network resource (e.g., the bottleneck buffer size) to mitigate the shrew DDoS with a given attack pattern. Finally, based on our theoretical results, we put forward a simple strategy to defend the shrew attack. The simulation results indicate that this strategy can remarkably increase TCP throughput by nearly half of the bottleneck bandwidth (and can be higher) for general attack patterns.","Throughput,
Mathematical model,
Computer crime,
Adaptation models,
Bandwidth,
Delays,
Packet loss"
Cloud Detection of RGB Color Aerial Photographs by Progressive Refinement Scheme,"In this paper, we propose an automatic and effective cloud detection algorithm for color aerial photographs. Based on the properties derived from observations and statistical results on a large number of color aerial photographs with cloud layers, we present a novel progressive refinement scheme for detecting clouds in the color aerial photographs. We first construct a significance map which highlights the difference between cloud regions and noncloud regions. Based on the significance map and the proposed optimal threshold setting, we obtain a coarse cloud detection result which classifies the input aerial photograph into the candidate cloud regions and noncloud regions. In order to accurately detect the cloud regions from the candidate cloud regions, we then construct a robust detail map derived from a multiscale bilateral decomposition to guide us in removing noncloud regions from the candidate cloud regions. Finally, we further perform a guided feathering to achieve our final cloud detection result, which detects semitransparent cloud pixels around the boundaries of cloud regions. The proposed method is evaluated in terms of both visual and quantitative comparisons, and the evaluation results show that our proposed method works well for the cloud detection of color aerial photographs.","Clouds,
Image color analysis,
Image segmentation,
Histograms,
Color,
Accuracy,
Satellites"
Cloudified IP Multimedia Subsystem (IMS) for Network Function Virtualization (NFV)-based architectures,"The maturity reached by virtualisation technology enabled great innovation for efficient applications and services development and delivery, independent of the underlying hardware equipment, especially with the large deployment of off-the-shelf hardware based cloud infrastructures. In order to take advantage of this technology, the existing network functions have to be developed and adapted to the new paradigm. However, traditional telecom services are still implemented on dedicated hardware resulting in high deployment and maintenance costs compared to the other already cloudified services. ETSI Network Functions Virtualisation (NFV) aims to fill this gap by applying to telecom the virtualisation technologies. This paper introduces a set of three software architectures for efficient virtualisation of IP Multimedia Subsystem (IMS) in different operator environments responding to the high level requirements of the ETSI NFV use case for virtualizing operator core network functions. Additionally, a management architecture for simplifying the deployment and runtime orchestration of such a virtual service on top of a cloud infrastructure is presented. Furthermore, one of the IMS software architectures was implemented based on the Fraunhofer FOKUS Open IMS Core, measured and evaluated on top of an OpenStack cloud.","Computer architecture,
Hardware,
Software,
Servers,
Multimedia communication,
Virtualization,
Virtual machining"
Multi-Dimensional Tumor Detection in Automated Whole Breast Ultrasound Using Topographic Watershed,"Automated whole breast ultrasound (ABUS) is becoming a popular screening modality for whole breast examination. Compared to conventional handheld ultrasound, ABUS achieves operator-independent and is feasible for mass screening. However, reviewing hundreds of slices in an ABUS image volume is time-consuming. A computer-aided detection (CADe) system based on watershed transform was proposed in this study to accelerate the reviewing. The watershed transform was applied to gather similar tissues around local minima to be homogeneous regions. The likelihoods of being tumors of the regions were estimated using the quantitative morphology, intensity, and texture features in the 2-D/3-D false positive reduction (FPR). The collected database comprised 68 benign and 65 malignant tumors. As a result, the proposed system achieved sensitivities of 100% (133/133), 90% (121/133), and 80% (107/133) with FPs/pass of 9.44, 5.42, and 3.33, respectively. The figure of merit of the combination of three feature sets is 0.46 which is significantly better than that of other feature sets (p-value <; 0.05). In summary, the proposed CADe system based on the multi-dimensional FPR using the integrated feature set is promising in detecting tumors in ABUS images.","Tumors,
Feature extraction,
Breast,
Educational institutions,
Materials,
Transforms,
Morphology"
The Effects of Spatial Dispersion on Power Flow Along a Printed-Circuit Tensor Impedance Surface,"In this communication, expressions for the group velocity and the direction of power flow along an idealized tensor impedance boundary condition (TIBC) and a printed-circuit tensor impedance surface (PCTIS), are found. A PCTIS consists of a patterned metallic cladding over a grounded dielectric substrate. The patterned metallic cladding is modeled by a tensor impedance sheet. Expressions for the surface impedance of a TIBC and a PCTIS are reviewed. From these expressions, the group velocity and direction of power flow are derived as a function of transverse wave vector. A PCTIS exhibits spatial dispersion due to the electrical thickness of its substrate while a TIBC does not. As a result of this spatial dispersion, a PCTIS can have the same surface impedance as a TIBC for a given transverse wave vector, but a different direction of power flow. The expressions for direction of power flow along a TIBC and a PCTIS are verified with a full-wave electromagnetic solver.",
Semi-Automatic Segmentation and Classification of Pap Smear Cells,"Cytologic screening has been widely used for detecting the cervical cancers. In this study, a semiautomatic PC-based cellular image analysis system was developed for segmenting nuclear and cytoplasmic contours and for computing morphometric and textual features to train support vector machine (SVM) classifiers to classify four different types of cells and to discriminate dysplastic from normal cells. A software program incorporating function, including image reviewing and standardized denomination of file names, was also designed to facilitate and standardize the workflow of cell analyses. Two experiments were conducted to verify the classification performance. The cross-validation results of the first experiment showed that average accuracies of 97.16% and 98.83%, respectively, for differentiating four different types of cells and in discriminating dysplastic from normal cells have been achieved using salient features (8 for four-cluster and 7 for two-cluster classifiers) selected with SVM recursive feature addition. In the second experiment, 70% (837) of the cell images were used for training and 30% (361) for testing, achieving an accuracy of 96.12% and 98.61% for four-cluster and two-cluster classifiers, respectively. The proposed system provides a feasible and effective tool in evaluating cytologic specimens.",
Multiple Morphological Profiles From Multicomponent-Base Images for Hyperspectral Image Classification,"Morphological profiles (MPs) are a useful tool for remotely sensed image classification. These profiles are constructed on a base image that can be a single band of a multicomponent remote sensing image. Principal component analysis (PCA) has been used to provide other base images to construct MPs in high-dimensional remote sensing scenes such as hyperspectral images [e.g., by deriving the first principal components (PCs) and building the MPs on the first few components]. In this paper, we discuss several strategies for producing the base images for MPs, and further categorize the considered methods into four classes: linear, nonlinear, manifold learning-based, and multilinear transformation-based. It is found that the multilinear PCA (MPCA) is a powerful approach for base image extraction. That is because it is a tensor-based feature representation approach, which is able to simultaneously exploit the spectral-spatial correlation between neighboring pixels. We also show that independent component analysis (ICA) is more effective for constructing base images than PCA. Another important contribution of this paper is a new concept of multiple MPs (MMPs), aimed at synthesizing the spectral-spatial information extracted from the multicomponent base images, and further enhancing the classification accuracy of MPs. Moreover, we propose two different strategies to interpret the newly proposed MMPs by considering their hyperdimensional feature space: decision fusion and sparse classifier based on multinomial logistic regression (MLR). Experiments conducted on three well-known hyperspectral datasets are used to quantitatively assess the accuracy of different algorithms.","Hyperspectral imaging,
Principal component analysis,
Feature extraction,
Manifolds,
Spatial analysis"
Power Consumption During Neuronal Computation,"Maintaining the ability of the nervous system to perceive, remember, process, and react to the outside world requires a continuous energy supply. Yet the overall power consumption is remarkably low, which has inspired engineers to mimic nervous systems in designing artificial cochlea, retinal implants, and brain-computer interfaces (BCIs) to improve the quality of life in patients. Such neuromorphic devices are both energy efficient and increasingly able to emulate many functions of the human nervous system. We examine the energy constraints of neuronal signaling within biology, review the quantitative tradeoff between energy use and information processing, and ask whether the biophysics and design of nerve cells minimizes energy consumption.","Neurons,
Noise measurement,
Electric potential,
Neuroscience,
Power demand,
Energy efficiency,
Power consumption,
Biological system modeling,
Biophysics"
Cost Analysis of Movement-Based Location Management in PCS Networks: An Embedded Markov Chain Approach,"In this paper, we develop an approach of embedded Markov chain to analyze the signaling cost of a movement-based location management (MBLM) scheme. This approach distinguishes itself from those developed in the literature in the following aspects. 1) It considers the location area (LA) architecture used by personal communication service (PCS) networks for location management. 2) It considers two different call handling models that determine after a call whether a location update should be performed. 3) It considers the effect of the call holding time on the call handling models. 4) It proposes to use a fluid flow model to describe the dependence between the cell and the LA residence time. We derive closed-form analytical formulas for the signaling cost, whose accuracy is manifested by a simulation. Based on the analytical formulas, we conduct a numerical study to evaluate the influence of various parameters on the signaling cost. The formulas can contribute to the implementation of the MBLM scheme in PCS networks including Fourth-Generation (4G) Long-Term Evolution. The modeling approach developed in this paper can be exploited to model other location management schemes.","Computer architecture,
Microprocessors,
Mathematical model,
Analytical models,
Markov processes,
Numerical models,
GSM"
"GOM-Face: GKP, EOG, and EMG-Based Multimodal Interface With Application to Humanoid Robot Control","We present a novel human-machine interface, called GOM-Face , and its application to humanoid robot control. The GOM-Face bases its interfacing on three electric potentials measured on the face: 1) glossokinetic potential (GKP), which involves the tongue movement; 2) electrooculogram (EOG), which involves the eye movement; 3) electromyogram, which involves the teeth clenching. Each potential has been individually used for assistive interfacing to provide persons with limb motor disabilities or even complete quadriplegia an alternative communication channel. However, to the best of our knowledge, GOM-Face is the first interface that exploits all these potentials together. We resolved the interference between GKP and EOG by extracting discriminative features from two covariance matrices: a tongue-movement-only data matrix and eye-movement-only data matrix. With the feature extraction method, GOM-Face can detect four kinds of horizontal tongue or eye movements with an accuracy of 86.7% within 2.77 s. We demonstrated the applicability of the GOM-Face to humanoid robot control: users were able to communicate with the robot by selecting from a predefined menu using the eye and tongue movements.","Tongue,
Electrooculography,
Electric potential,
Feature extraction,
Electromyography,
Vectors,
Visualization"
iVisDesigner: Expressive Interactive Design of Information Visualizations,"We present the design, implementation and evaluation of iVisDesigner, a web-based system that enables users to design information visualizations for complex datasets interactively, without the need for textual programming. Our system achieves high interactive expressiveness through conceptual modularity, covering a broad information visualization design space. iVisDesigner supports the interactive design of interactive visualizations, such as provisioning for responsive graph layouts and different types of brushing and linking interactions. We present the system design and implementation, exemplify it through a variety of illustrative visualization designs and discuss its limitations. A performance analysis and an informal user study are presented to evaluate the system.","Data visualization,
Information analysis,
Data visualization,
Web and internet services,
Programming profession"
A Reliability Enhanced Address Mapping Strategy for Three-Dimensional (3-D) NAND Flash Memory,"The linear scaling down of NAND flash memory is approaching its physical, electrical, and reliability limitations. To maintain the current trend of increasing bit density and reducing bit per cost, 3-D flash memory is emerging as a viable solution to fulfill the ever-increasing demands of storage capacity. In 3-D NAND flash memory, multiple layers are stacked to provide ultrahigh density storage devices. However, the physical architecture of 3-D flash memory leads to a higher probability of disturbance to adjacent physical pages and greatly increases bit error rates. This paper presents a novel physical-location-aware address mapping strategy for 3-D NAND flash memory. It permutes the physical mapping of pages and maximizes the distance between the consecutively logical pages, which can significantly reduce the disturbance to adjacent physical pages and effectively enhance the reliability. The proposed mapping strategy is applied to a representative flash storage system. Experimental results show that the proposed scheme can reduce uncorrectable page errors by 70.16% with less than 10.01% space overhead in comparison with the baseline scheme.","Ash,
Reliability,
Physical layer,
Drives,
Resource management,
Educational institutions,
Logic gates"
L1-Norm Kernel Discriminant Analysis Via Bayes Error Bound Optimization for Robust Feature Extraction,"A novel discriminant analysis criterion is derived in this paper under the theoretical framework of Bayes optimality. In contrast to the conventional Fisher's discriminant criterion, the major novelty of the proposed one is the use of L1 norm rather than L2 norm, which makes it less sensitive to the outliers. With the L1-norm discriminant criterion, we propose a new linear discriminant analysis (L1-LDA) method for linear feature extraction problem. To solve the L1-LDA optimization problem, we propose an efficient iterative algorithm, in which a novel surrogate convex function is introduced such that the optimization problem in each iteration is to simply solve a convex programming problem and a close-form solution is guaranteed to this problem. Moreover, we also generalize the L1-LDA method to deal with the nonlinear robust feature extraction problems via the use of kernel trick, and hereafter proposed the L1-norm kernel discriminant analysis (L1-KDA) method. Extensive experiments on simulated and real data sets are conducted to evaluate the effectiveness of the proposed method in comparing with the state-of-the-art methods.","Vectors,
Feature extraction,
Kernel,
Robustness,
Optimization,
Principal component analysis,
Upper bound"
Enabling Reputation and Trust in Privacy-Preserving Mobile Sensing,"Mobile sensing is becoming a popular paradigm to collect information from and outsource tasks to mobile users. These applications deal with lot of personal information, e.g., identity and location. Therefore, we need to pay a deeper attention to privacy and anonymity. However, the knowledge of the data source is desired to evaluate the trustworthiness of the sensing data. Anonymity and trust become two conflicting objectives in mobile sensing. In this paper, we propose ARTSense, a framework to solve the problem of “trust without identity” in mobile sensing. Our solution consists of a privacy-preserving provenance model, a data trust assessment scheme and an anonymous reputation management protocol. In contrast to other recent solutions, our scheme does not require a trusted third party and both positive and negative reputation updates can be enforced. In the trust assessment, we consider contextual factors that dynamically affects the trustworthiness of the sensing data as well as the mutual support and conflict among data from difference sources. Security analysis shows that ARTSense achieves our desired anonymity and security goals. Our prototype implementation on Android demonstrates that ARTSense incurs minimal computation overhead on mobile devices, and simulation results justify that ARTSense captures the trust of information and reputation of participants accurately.",
On the Use of Genetic Programming for Mining Comprehensible Rules in Subgroup Discovery,"This paper proposes a novel grammar-guided genetic programming algorithm for subgroup discovery. This algorithm, called comprehensible grammar-based algorithm for subgroup discovery (CGBA-SD), combines the requirements of discovering comprehensible rules with the ability to mine expressive and flexible solutions owing to the use of a context-free grammar. Each rule is represented as a derivation tree that shows a solution described using the language denoted by the grammar. The algorithm includes mechanisms to adapt the diversity of the population by self-adapting the probabilities of recombination and mutation. We compare the approach with existing evolutionary and classic subgroup discovery algorithms. CGBA-SD appears to be a very promising algorithm that discovers comprehensible subgroups and behaves better than other algorithms as measures by complexity, interest, and precision indicate. The results obtained were validated by means of a series of nonparametric tests.",
Constrained Concept Factorization for Image Representation,"Matrix factorization based techniques, such as nonnegative matrix factorization and concept factorization, have attracted great attention in dimensionality reduction and data clustering. Previous studies show that both of them yield impressive results on image processing and document clustering. However, both of them are essentially unsupervised methods and cannot incorporate label information. In this paper, we propose a novel semi-supervised matrix decomposition method for extracting the image concepts that are consistent with the known label information. With this constraint, we call the new approach constrained concept factorization. By requiring that the data points sharing the same label have the same coordinate in the new representation space, this approach has more discriminating power. The experimental results on several corpora show good performance of our novel algorithm in terms of clustering accuracy and mutual information.","Matrix decomposition,
Linear programming,
Vectors,
Algorithm design and analysis,
Approximation algorithms,
Clustering algorithms,
Data models"
A Novel Video Dataset for Change Detection Benchmarking,"Change detection is one of the most commonly encountered low-level tasks in computer vision and video processing. A plethora of algorithms have been developed to date, yet no widely accepted, realistic, large-scale video data set exists for benchmarking different methods. Presented here is a unique change detection video data set consisting of nearly 90000 frames in 31 video sequences representing six categories selected to cover a wide range of challenges in two modalities (color and thermal infrared). A distinguishing characteristic of this benchmark video data set is that each frame is meticulously annotated by hand for ground-truth foreground, background, and shadow area boundaries-an effort that goes much beyond a simple binary label denoting the presence of change. This enables objective and precise quantitative comparison and ranking of video-based change detection algorithms. This paper discusses various aspects of the new data set, quantitative performance metrics used, and comparative results for over two dozen change detection algorithms. It draws important conclusions on solved and remaining issues in change detection, and describes future challenges for the scientific community. The data set, evaluation tools, and algorithm rankings are available to the public on a website1 and will be updated with feedback from academia and industry in the future.","Robustness,
Lighting,
Optical imaging,
Hidden Markov models,
Adaptive optics,
Optical sensors,
Motion segmentation"
A Sub-nW 2.4 GHz Transmitter for Low Data-Rate Sensing Applications,"This paper presents the design of a narrowband transmitter and antenna system that achieves an average power consumption of 78 pW when operating at a duty-cycled data rate of 1 bps. Fabricated in a 0.18 μm CMOS process, the transmitter employs a direct-RF power oscillator topology where a loop antenna acts as a both a radiative and resonant element. The low-complexity single-stage architecture, in combination with aggressive power gating techniques and sizing optimizations, limited the standby power of the transmitter to only 39.7 pW at 0.8 V. Supporting both OOK and FSK modulations at 2.4 GHz, the transmitter consumed as low as 38 pJ/bit at an active-mode data rate of 5 Mbps. The loop antenna and integrated diodes were also used as part of a wireless power transfer receiver in order to kick-start the system power supply prior to energy harvesting operation.","Antennas,
Radio transmitters,
Sensors,
Frequency shift keying,
Oscillators,
Radio frequency,
Wireless communication"
Frontal Gait Recognition From Incomplete Sequences Using RGB-D Camera,"Frontal gait recognition using partial cycle information has not received significant attention to date in spite of its many potential applications. In this paper, we propose a hierarchical classification strategy that combines front and back view features captured by RGB-D (Red Green Blue - Depth) cameras. Airport security check points are considered as a typical application scenario, where two depth cameras mounted on top of a metal detector gate positioned beyond a yellow line, respectively, record front and back views of a subject as he goes through the check-in process. Due to the short distance of the surveillance zone between the yellow line and point of exit, it is often not possible to capture a full gait cycle independently from the front view or back view. An initial stage of anthropometric feature-based classification followed by motion feature extraction from the front view is used to restrict the potential set of matched subjects. A final classification is then applied on this reduced set of subjects using depth features extracted from the back view. The method is computationally efficient with a much higher rate of accuracy compared with existing gait recognition approaches.","Feature extraction,
Gait recognition,
Cameras,
Joints,
Videos,
Legged locomotion"
"A Reconfigurable 40-to-67 dB SNR, 50-to-6400 Hz Frame-Rate, Column-Parallel Readout IC for Capacitive Touch-Screen Panels","This paper describes a capacitive touch-screen panel (TSP) readout IC that provides a reconfigurable SNR and frame rate with high noise immunity and touch sensitivity. The readout IC mitigates severe noise interference with a lock-in sensing architecture. In addition, a band-pass filtering effect by the TSP and charge amplifier further improves the noise immunity. A differential sensing scheme is employed to enhance the touch sensitivity and to reject a common-mode noise. A column-parallel incremental ΣΔ ADC is adopted to provide a high resolution and frame rate. Furthermore, a multiple sampling and averaging effect of the ADC enhances the noise immunity. The readout IC reconfigures its SNR and frame rate by adjusting the configurable resolution of the employed ADC. The test chip is fabricated in a 0.18 μm CMOS process and occupies a 2.2 mm 2 active area. The test chip achieves a 60 dB SNR and 200 Hz frame rate with a 12×8 TSP. The SNR can be adjusted from 40 dB to 67 dB, while the frame rate is then inversely scaled from 50 Hz to 6.4 kHz. The test chip supports a supply voltage range from 2.1 V to 3.3 V and consumes 6.26 mW from a 3.3 V supply.",
Robust Control for Steer-by-Wire Systems With Partially Known Dynamics,"In this paper, a robust control scheme (RCS) for Steer-by-Wire (SbW) systems with partially known dynamics is proposed. It is shown that an SbW system can be represented by a nominal model and an unknown portion. A nominal feedback controller can then be used to stabilize the nominal model and a sliding mode compensator (SMC) is designed to remove the effects of both the unknown system dynamics and uncertain road conditions on the steering performance. For practical consideration, robust exact differentiator (RED) technique is utilized to estimate the derivatives of the position signals for controller design. It is further shown that the designed RCS is able to guarantee a robust steering performance against system and road uncertainties. The comparative experimental studies are given to verify the excellent performance of the proposed RCS for SbW systems.","Uncertainty,
Steering systems,
Vehicle dynamics,
Robust control,
Sliding mode control"
SDN-based solutions for Moving Target Defense network protection,"Software-Defined Networking (SDN) allows network capabilities and services to be managed through a central control point. Moving Target Defense (MTD) on the other hand, introduces a constantly adapting environment in order to delay or prevent attacks on a system. MTD is a use case where SDN can be leveraged in order to provide attack surface obfuscation. In this paper, we investigate how SDN can be used in some network-based MTD techniques. We first describe the advantages and disadvantages of these techniques, the potential countermeasures attackers could take to circumvent them, and the overhead of implementing MTD using SDN. Subsequently, we study the performance of the SDN-based MTD methods using Cisco's One Platform Kit and we show that they significantly increase the attacker's overheads.","Ports (Computers),
Reconnaissance,
Payloads,
Algorithm design and analysis,
Servers,
Delays"
Measurement and Analysis on the Packet Delivery Performance in a Large-Scale Sensor Network,"Understanding the packet delivery performance of a wireless sensor network (WSN) is critical for improving system performance and exploring future developments and applications of WSN techniques. In spite of many empirical measurements in the literature, we still lack in-depth understanding on how and to what extent different factors contribute to the overall packet losses for a complete stack of protocols at large scale. Specifically, very little is known about: 1) when, where, and under what kind of circumstances packet losses occur; 2) why packets are lost. As a step toward addressing those issues, we deploy a large-scale WSN and design a measurement system for retrieving important system metrics. We propose MAP, a step-by-step methodology to identify the losses, extract system events, and perform spatial-temporal correlation analysis by employing a carefully examined causal graph. MAP enables us to get a closer look at the root causes of packet losses in a low-power ad hoc network. This study validates some earlier conjectures on WSNs and reveals some new findings. The quantitative results also shed lights for future large-scale WSN deployments .","Wireless sensor networks,
Packet loss,
Protocols,
Routing,
Monitoring,
Radiation detectors"
Robust Online Learned Spatio-Temporal Context Model for Visual Tracking,"Visual tracking is an important but challenging problem in the computer vision field. In the real world, the appearances of the target and its surroundings change continuously over space and time, which provides effective information to track the target robustly. However, enough attention has not been paid to the spatio-temporal appearance information in previous works. In this paper, a robust spatio-temporal context model based tracker is presented to complete the tracking task in unconstrained environments. The tracker is constructed with temporal and spatial appearance context models. The temporal appearance context model captures the historical appearance of the target to prevent the tracker from drifting to the background in a long-term tracking. The spatial appearance context model integrates contributors to build a supporting field. The contributors are the patches with the same size of the target at the key-points automatically discovered around the target. The constructed supporting field provides much more information than the appearance of the target itself, and thus, ensures the robustness of the tracker in complex environments. Extensive experiments on various challenging databases validate the superiority of our tracker over other state-of-the-art trackers.",
A Compact Frequency-Reconfigurable Multiband LTE MIMO Antenna for Laptop Applications,"A compact frequency-reconfigurable multipleinput-multiple-output (MIMO) antenna on a laptop is proposed for multiband LTE services. Each MIMO antenna consists of two planar inverted-F antenna (PIFA) elements, using a T-shaped dc line and two p-i-n diodes (D1 and D2), in conjunction with the proximity-coupled feed structure. By effectively minimizing its dimension and its interference with antenna performance, the proposed T-shaped dc line is designed to fit within the proximity-coupled feed structure. The proposed MIMO antenna covers the LTE 17/13 bands (704-787 MHz, VSWR <; 3) at State 1 (D1 and D2: ON state), and the LTE 20/7 bands (791-862 MHz, 2500-2690 MHz, VSWR <; 3) at State 2 (D1 and D2: OFF state). The proposed antenna obtains high isolation (> 20 dB), low envelope correlation coefficient (ECC <; 0.0161), and total efficiency of greater than 51%, for all operating frequency bands.",
Effective Risk Communication for Android Apps,"The popularity and advanced functionality of mobile devices has made them attractive targets for malicious and intrusive applications (apps). Although strong security measures are in place for most mobile systems, the area where these systems often fail is the reliance on the user to make decisions that impact the security of a device. As our prime example, Android relies on users to understand the permissions that an app is requesting and to base the installation decision on the list of permissions. Previous research has shown that this reliance on users is ineffective, as most users do not understand or consider the permission information. We propose a solution that leverages a method to assign a risk score to each app and display a summary of that information to users. Results from four experiments are reported in which we examine the effects of introducing summary risk information and how best to convey such information to a user. Our results show that the inclusion of risk-score information has significant positive effects in the selection process and can also lead to more curiosity about security-related information.",
Towards indoor localization using Visible Light Communication for consumer electronic devices,"Indoor localization is the fundamental capability for indoor service robots and indoor applications on mobile devices. To realize that, the cost of sensors is of great concern. In order to decode the signal carried out by the LED beacons, we propose two reliable solutions using common sensors available on consumer electronic devices. Firstly, we introduce a dedicated analog sensor, which can be directly connected to the microphone input of a computer or a smart phone. It decodes both the signal pattern and signal strength of a beacon. Secondly, we utilize rolling-shutter cameras to decode the signal pattern, providing potential solutions to the localization of hand-held devices with cameras. In contrast to existing widely-applied indoor localization approaches, like vision-based and laser-based methods, our approach reveals its advantages as low-cost, globally consistent and it retains the potential applications using Visible Light Communication(VLC). We also study the characteristics of the proposed solutions under typical indoor conditions by experiments.","Decoding,
Cameras,
Sensors,
Light emitting diodes,
Light sources,
Smart phones,
Modulation"
Outsourcing Private RAM Computation,"We construct the first schemes that allow a client to privately outsource arbitrary program executions to a remote server while ensuring that: (I) the client's work is small and essentially independent of the complexity of the computation being outsourced, and (II) the server's work is only proportional to the run-time of the computation on a random access machine (RAM), rather than its potentially much larger circuit size. Furthermore, our solutions are non-interactive and have the structure of reusable garbled RAM programs, addressing an open question of Lu and Ostrovsky (Eurocrypt 2013). We also construct schemes for an augmented variant of the above scenario, where the client can initially outsource a large private and persistent database to the server, and later outsource arbitrary program executions with read/write access to this database. Our solutions are built from non-reusable garbled RAM in conjunction with new types of reusable garbled circuits that are more efficient than prior solutions but only satisfy weaker security. For the basic setting without a persistent database, we can instantiate the required type of reusable garbled circuits from indistinguishability obfuscation or from functional encryption for circuits as a black-box. For the more complex setting with a persistent database, we can instantiate the required type of reusable garbled circuits using stronger notions of obfuscation. Our basic solution also requires the client to perform a one-time pre-processing step to garble a program at the cost of its RAM run-time, and we can avoid this cost using stronger notions of obfuscation. It remains an open problem to instantiate these new types of reusable garbled circuits under weaker assumptions, possibly avoiding obfuscation altogether. We show several simple extensions of our results and techniques to achieve: efficiency proportional to the input-specific RAM run-time, verifiability of outsourced RAM computation, functional encryption for RAMs, and a candidate obfuscation for RAMs.",
Motor Learning Perspectives on HapticTraining for the Upper Extremities,"Recent developments in neurorehabilitation have spawned numerous new robotic rehabilitation therapies. However, many of the concepts upon which these therapies are based are not fully understood and it may be necessary to explore some of the motor learning principles that apply to the use of haptics for motor learning in non-clinical scenarios/populations. We conducted a review of studies that utilized a haptic training paradigm teaching healthy participants to perform a motor skill involving the upper extremities. We discuss studies in the context of four important motor learning concepts: performance versus learning, feedback, observational learning, and functional task difficulty. Additionally, we note that the proliferation of research in haptic training has led to an extensive vocabulary of terms, some of which may be misnomers or redundant. We propose a classification of terms describing haptic training in an effort to provide clarity and further contextualize the studies. We believe that making connections to motor learning principles and clarifying meanings will facilitate a fuller understanding of the outcomes of studies in basic science research and allow for more directed applications of these training techniques to clinical populations.","Haptic interfaces,
Training,
Robots,
Trajectory,
Context,
Extremities,
Medical treatment"
Secondary Peak Detection of PPG Signal for Continuous Cuffless Arterial Blood Pressure Measurement,"The arterial blood pressure (ABP) is one of the most important physiological parameters for health monitoring. Most of the blood measurement devices in the market determine the ABP through the inflation and the deflation of a cuff controlled by a bladder. This method is very uncomfortable for most of the users and may even cause anxiety, which in turn can affect the blood pressure (BP) (white coat syndrome). This paper investigates a cuffless nonintrusive approach to estimate the BP. The main idea is to measure the pulse transit time (PTT), i.e., the delay between the R-peak of the electrocardiogram (ECG) signal and the following peak of the finger photoplethysmograph (PPG) signal. The main problem of this approach is that when the dicrotic notch of the PPG signal is unobservable, the position and the amplitude of the main peak of the PPG signal will be changed. As a result, the correlation between the BP and the PTT can be affected. To overcome this problem, three types of secondary peak detection methods are designed to reveal the secondary peak from the original PPG signal. Actual ECG, PPG, and the BP measurements extracted from the Multiparameter Intelligent Monitoring in Intensive Care II database that contains clinical signal data reflecting real measurements are used. The results verify that the proposed detection methods improve the correlation relationship between the BP and the PTT, and demonstrate that the adjusted PTT can be used as an indicator of the ABP by removing the dicrotic notch impact on the PPG signal.","Correlation,
Electrocardiography,
Databases,
Estimation,
MIMICs,
Biomedical measurement,
Standards"
Novel Configuration and Transient Management Control Strategy for VSC-HVDC,"This paper presents a novel system configuration for voltage source converter (VSC)-based high-voltage direct current (HVDC) transmission connected to a large-scale offshore wind power plant (WPP). The proposed scheme is reconfigured at the onshore end to achieve shunt and series compensation, which is named as `Unified-VSC-HVDC' (U-VSC-HVDC). A mathematical model of the proposed configuration is derived to determine the rating of the employed series and shunt converters. To achieve a flexible control strategy for balanced and unbalanced fault conditions, the proposed transient management scheme employs positive and negative sequence controllers for the series compensation. The negative sequence voltage components are determined in such a way as to minimize power oscillations caused by asymmetrical faults, and hence to reduce DC link voltage overshoots. A test system comprised of a detailed representation of the proposed configuration is simulated and evaluated using PSCAD/EMTDC. A comprehensive study validates the capability of the proposed configuration and transient management scheme for achieving smooth power transfer and superior transient performance of the electrical grid. Also, it minimizes the possibilities of electrical network propagations in response to symmetrical and asymmetrical grid faults.",
Mobile User Authentication Using Statistical Touch Dynamics Images,"Behavioral biometrics have recently begun to gain attention for mobile user authentication. The feasibility of touch gestures as a novel modality for behavioral biometrics has been investigated. In this paper, we propose applying a statistical touch dynamics image (aka statistical feature model) trained from graphic touch gesture features to retain discriminative power for user authentication while significantly reducing computational time during online authentication. Systematic evaluation and comparisons with state-of-the-art methods have been performed on touch gesture data sets. Implemented as an Android App, the usability and effectiveness of the proposed method have also been evaluated.","Authentication,
Probes,
Feature extraction,
Training,
Mobile communication,
Biometrics (access control),
Vectors"
SybilBelief: A Semi-Supervised Learning Approach for Structure-Based Sybil Detection,"Sybil attacks are a fundamental threat to the security of distributed systems. Recently, there has been a growing interest in leveraging social networks to mitigate Sybil attacks. However, the existing approaches suffer from one or more drawbacks, including bootstrapping from either only known benign or known Sybil nodes, failing to tolerate noise in their prior knowledge about known benign or Sybil nodes, and not being scalable. In this paper, we aim to overcome these drawbacks. Toward this goal, we introduce SybilBelief, a semi-supervised learning framework, to detect Sybil nodes. SybilBelief takes a social network of the nodes in the system, a small set of known benign nodes, and, optionally, a small set of known Sybils as input. Then, SybilBelief propagates the label information from the known benign and/or Sybil nodes to the remaining nodes in the system. We evaluate SybilBelief using both synthetic and real-world social network topologies. We show that SybilBelief is able to accurately identify Sybil nodes with low false positive rates and low false negative rates. SybilBelief is resilient to noise in our prior knowledge about known benign and Sybil nodes. Moreover, SybilBelief performs orders of magnitudes better than existing Sybil classification mechanisms and significantly better than existing Sybil ranking mechanisms.","Social network services,
Peer-to-peer computing,
Noise,
Image edge detection,
Random variables,
Generators,
Couplings"
Serendip: Topic model-driven visual exploration of text corpora,"Exploration and discovery in a large text corpus requires investigation at multiple levels of abstraction, from a zoomed-out view of the entire corpus down to close-ups of individual passages and words. At each of these levels, there is a wealth of information that can inform inquiry - from statistical models, to metadata, to the researcher's own knowledge and expertise. Joining all this information together can be a challenge, and there are issues of scale to be combatted along the way. In this paper, we describe an approach to text analysis that addresses these challenges of scale and multiple information sources, using probabilistic topic models to structure exploration through multiple levels of inquiry in a way that fosters serendipitous discovery. In implementing this approach into a tool called Serendip, we incorporate topic model data and metadata into a highly reorderable matrix to expose corpus level trends; extend encodings of tagged text to illustrate probabilistic information at a passage level; and introduce a technique for visualizing individual word rankings, along with interaction techniques and new statistical methods to create links between different levels and information types. We describe example uses from both the humanities and visualization research that illustrate the benefits of our approach.","Measurement,
Market research,
Data models,
Data visualization,
Probabilistic logic,
Adaptation models,
Vectors"
Maximum a Posteriori Probability Estimation for Online Surveillance Video Synopsis,"To reduce human efforts in browsing long surveillance videos, synopsis videos are proposed. Traditional synopsis video generation applying optimization on video tubes is very time consuming and infeasible for real-time online generation. This dilemma significantly reduces the feasibility of synopsis video generation in practical situations. To solve this problem, the synopsis video generation problem is formulated as a maximum a posteriori probability (MAP) estimation problem in this paper, where the positions and appearing frames of video objects are chronologically rearranged in real time without the need to know their complete trajectories. Moreover, a synopsis table is employed with MAP estimation to decide the temporal locations of the incoming foreground objects in the synopsis video without needing an optimization procedure. As a result, the computational complexity of the proposed video synopsis generation method can be significantly reduced. Furthermore, as it does not require prescreening the entire video, this approach can be applied on online streaming videos.","Streaming media,
Surveillance,
Predictive models,
Real-time systems,
Estimation,
Indexes,
Optimization"
Online Coordinated Charging Decision Algorithm for Electric Vehicles Without Future Information,"The large-scale integration of plug-in electric vehicles (PEVs) to the power grid spurs the need for efficient charging coordination mechanisms. It can be shown that the optimal charging schedule smooths out the energy consumption over time so as to minimize the total energy cost. In practice, however, it is hard to smooth out the energy consumption perfectly, because the future PEV charging demand is unknown at the moment when the charging rate of an existing PEV needs to be determined. In this paper, we propose an online coordinated charging decision (ORCHARD) algorithm, which minimizes the energy cost without knowing the future information. Through rigorous proof, we show that ORCHARD is strictly feasible in the sense that it guarantees to fulfill all charging demands before due time. Meanwhile, it achieves the best known competitive ratio of 2.39. By exploiting the problem structure, we propose a novel reduced-complexity algorithm to replace the standard convex optimization techniques used in ORCHARD. Through extensive simulations, we show that the average performance gap between ORCHARD and the offline optimal solution, which utilizes the complete future information, is as small as 6.5%. By setting a proper speeding factor, the average performance gap can be further reduced to 5%.","Charging stations,
Schedules,
Algorithm design and analysis,
Plug-in hybrid electric vehicles,
Computational complexity"
Real-Time 10.4-Gb/s Single-Band Optical 256/64/16QAM Receiver for OFDM-PON,"In this letter, a 10.4-Gb/s real-time baseband orthogonal frequency division multiplexing (OFDM) receiver utilizing 256/64/16-quadrature amplitude modulation (QAM) adaptive modulation format, incorporating several key functionalities, including symbol synchronization, channel equalization, as well as sampling clock frequency synchronization is successfully implemented using a commercial field programmable gate array chip and a sample rate of 5-GS/s analog-to-digital converter. The performance of the real-time baseband OFDM receiver is experimentally investigated in an intensity-modulation and direct-detection optical communication system. The offline generated 10.4-Gb/s adaptively modulated 256/64/16QAM encoded optical OFDM signal with a high spectral efficiency of 4.84 bit/s/Hz can be successful transmitted over 20-km standard single mode fiber with a bit error rate <;3.8 × 10-3. In addition, the frame miss probability is real-time measured in the receiver to obtain an optimal threshold value for the symbol synchronization.","OFDM,
Real-time systems,
Optical receivers,
Passive optical networks,
Synchronization,
Adaptive optics"
Tracking by Sampling and IntegratingMultiple Trackers,"We propose the visual tracker sampler, a novel tracking algorithm that can work robustly in challenging scenarios, where several kinds of appearance and motion changes of an object can occur simultaneously. The proposed tracking algorithm accurately tracks a target by searching for appropriate trackers in each frame. Since the real-world tracking environment varies severely over time, the trackers should be adapted or newly constructed depending on the current situation, so that each specific tracker takes charge of a certain change in the object. To do this, our method obtains several samples of not only the states of the target but also the trackers themselves during the sampling process. The trackers are efficiently sampled using the Markov Chain Monte Carlo (MCMC) method from the predefined tracker space by proposing new appearance models, motion models, state representation types, and observation types, which are the important ingredients of visual trackers. All trackers are then integrated into one compound tracker through an Interacting MCMC (IMCMC) method, in which the trackers interactively communicate with one another while running in parallel. By exchanging information with others, each tracker further improves its performance, thus increasing overall tracking performance. Experimental results show that our method tracks the object accurately and reliably in realistic videos, where appearance and motion drastically change over time, and outperforms even state-of-the-art tracking methods.","Target tracking,
Visualization,
Robustness,
Videos,
Bayes methods,
Lighting"
Hybrid CMOS/BEOL-NEMS technology for ultra-low-power IC applications,Three-dimensional (3-D) nano-electro-mechanical (NEM) switches (relays) are proposed to reduce the die area and power consumption of digital logic and memory circuits.,"Relays,
Electrodes,
CMOS integrated circuits,
Switches,
Nanoelectromechanical systems,
Contacts,
Metals"
Identifying and classifying ambiguity for regulatory requirements,"Software engineers build software systems in increasingly regulated environments, and must therefore ensure that software requirements accurately represent obligations described in laws and regulations. Prior research has shown that graduate-level software engineering students are not able to reliably determine whether software requirements meet or exceed their legal obligations and that professional software engineers are unable to accurately classify cross-references in legal texts. However, no research has determined whether software engineers are able to identify and classify important ambiguities in laws and regulations. Ambiguities in legal texts can make the difference between requirements compliance and non-compliance. Herein, we develop a ambiguity taxonomy based on software engineering, legal, and linguistic understandings of ambiguity. We examine how 17 technologists and policy analysts in a graduate-level course use this taxonomy to identify ambiguity in a legal text. We also examine the types of ambiguities they found and whether they believe those ambiguities should prevent software engineers from implementing software that complies with the legal text. Our research suggests that ambiguity is prevalent in legal texts. In 50 minutes of examination, participants in our case study identified on average 33.47 ambiguities in 104 lines of legal text using our ambiguity taxonomy as a guideline. Our analysis suggests (a) that participants used the taxonomy as intended: as a guide and (b) that the taxonomy provides adequate coverage (97.5%) of the ambiguities found in the legal text.","Law,
Software,
Taxonomy,
Context,
Tutorials,
Pragmatics"
Recursive Robust PCA or Recursive Sparse Recovery in Large but Structured Noise,"This paper studies the recursive robust principal components analysis problem. If the outlier is the signal-of-interest, this problem can be interpreted as one of recursively recovering a time sequence of sparse vectors, St, in the presence of large but structured noise, Lt. The structure that we assume on Lt is that Lt is dense and lies in a low-dimensional subspace that is either fixed or changes slowly enough. A key application where this problem occurs is in video surveillance where the goal is to separate a slowly changing background (Lt) from moving foreground objects (St) on-the-fly. To solve the above problem, in recent work, we introduced a novel solution called recursive projected CS (ReProCS). In this paper, we develop a simple modification of the original ReProCS idea and analyze it. This modification assumes knowledge of a subspace change model on the Lt's. Under mild assumptions and a denseness assumption on the unestimated part of the subspace of Lt at various times, we show that, with high probability, the proposed approach can exactly recover the support set of St at all times, and the reconstruction errors of both St and Lt are upper bounded by a time-invariant and small value. In simulation experiments, we observe that the last assumption holds as long as there is some support change of St every few frames.","Vectors,
Principal component analysis,
Robustness,
Linear matrix inequalities,
Noise,
Sparse matrices,
Eigenvalues and eigenfunctions"
A Robotic Crack Inspection and Mapping System for Bridge Deck Maintenance,"One of the important tasks for bridge maintenance is bridge deck crack inspection. Traditionally, a human inspector detects cracks using his/her eyes and marks the location of cracks manually. However, the accuracy of the inspection result is low due to the subjective nature of human judgement. We propose a crack inspection system that uses a camera-equipped mobile robot to collect images on the bridge deck. In this method, the Laplacian of Gaussian (LoG) algorithm is used to detect cracks and a global crack map is obtained through camera calibration and robot localization. To ensure that the robot collects all the images on the bridge deck, a path planning algorithm based on the genetic algorithm is developed. The path planning algorithm finds a solution which minimizes the number of turns and the traveling distance. We validate our proposed system through both simulations and experiments.","Robot kinematics,
Bridges,
Cameras,
Robot vision systems,
Inspection,
Mobile robots"
Design Space Exploration for Wireless NoCs Incorporating Irregular Network Routing,"The millimeter-wave small-world wireless network-on-chip (mSWNoC) is an enabling interconnect architecture to design high-performance and low-power multicore chips. As the mSWNoC has an overall irregular topology, it is essential to design and optimize suitable deadlock-free routing mechanisms for it. In this paper, we quantify the latency, energy dissipation, and thermal profiles of mSWNoC architectures by incorporating irregular network routing strategies. We demonstrate that the latency, energy dissipation, and thermal profile are affected by the adopted routing methodologies. The overall system performance and thermal profile are governed by the traffic-dependent optimization of the routing methods. Our aim is to establish the energy-thermal-performance trade-offs for the mSWNoC depending on the exact routing strategy and the characteristics of the benchmarks considered.","Routing,
Wireless communication,
Switches,
System recovery,
Benchmark testing,
Computer architecture,
Topology"
The Weight Distributions of Several Classes of Cyclic Codes From APN Monomials,"Let m ≥ 3 be an odd integer and p be an odd prime. In this paper, a number of classes of three-weight cyclic codes C(1,e) over Fp, which have parity-check polynomial m1(x)me(x), are presented by examining general conditions on the parameters p, m, and e, where mi(x) is the minimal polynomial of π-i over Fp for a primitive element π of Fpm. Furthermore, for p ≡ 3 (mod 4) and a positive integer e satisfying (pk + 1) · e ≡ 2 (mod pm - 1) for some positive integer k with gcd(m, k) = 1, the value distributions of the exponential sums T(a, b) = Σx∈Fpm ωTr(ax+bxe) and S(a, b, c) = Σx∈Fpm ωTr(ax+bxe+cxs), where s = (pm - 1)/2, are determined. As an application, the value distribution of S(a, b, c) is utilized to derive the weight distribution of the cyclic codes C(1,e,s) with parity-check polynomial m1(x)me(x)ms(x). In the case of p = 3 and even e satisfying the above condition, the dual of the cyclic code C(1,e,s) has optimal minimum distance.","Polynomials,
Hamming weight,
Educational institutions,
Electronic mail,
Materials,
Cryptography"
Unconstrained Video Monitoring of Breathing Behavior and Application to Diagnosis of Sleep Apnea,"This paper presents a new real-time automated infrared video monitoring technique for detection of breathing anomalies, and its application in the diagnosis of obstructive sleep apnea. We introduce a novel motion model to detect subtle, cyclical breathing signals from video, a new 3-D unsupervised self-adaptive breathing template to learn individuals' normal breathing patterns online, and a robust action classification method to recognize abnormal breathing activities and limb movements. This technique avoids imposing positional constraints on the patient, allowing patients to sleep on their back or side, with or without facing the camera, fully or partially occluded by the bed clothes. Moreover, shallow and abdominal breathing patterns do not adversely affect the performance of the method, and it is insensitive to environmental settings such as infrared lighting levels and camera view angles. The experimental results show that the technique achieves high accuracy (94% for the clinical data) in recognizing apnea episodes and body movements and is robust to various occlusion levels, body poses, body movements (i.e., minor head movement, limb movement, body rotation, and slight torso movement), and breathing behavior (e.g., shallow versus heavy breathing, mouth breathing, chest breathing, and abdominal breathing).","Sleep apnea,
Monitoring,
Cameras,
Noise,
Sensors,
Motion detection,
Adaptation models"
Superiorization of the ML-EM Algorithm,"A reconstructed image in positron emission tomography (PET) should be such that its likelihood, assuming a Poisson model, is high given the observed detector readings. The expectation maximization (EM) methodology leads to an iterative algorithm, called ML-EM, that converges in the limit to an image that maximizes this likelihood. An undesirable property of the algorithm is that it produces images with irregular high amplitude patterns as the number of iterations increases. One approach to alleviate these high amplitude patterns is to use a stopping rule that terminates the process before the appearance of the undesirable high amplitude patterns; one recently-proposed stopping rule results in the method called MLEM-STOP. This paper takes a different approach by applying the recently developed superiorization methodology to ML-EM. Superiorization is an automated procedure for turning an iterative algorithm for producing images that satisfy a primary criterion (in our case that of having a high likelihood given the observed detector readings) into its superiorized version that will be as good as the original algorithm according to the primary criterion, but will in addition produce images that are also good according to a secondary criterion. The approach is demonstrated for two secondary criteria, one provided by an assumed Gaussian prior distribution and the other based on total variation minimization. It is demonstrated that the superiorization methodology achieves its aim for both these criteria. It is further shown by a study, using statistical hypothesis testing on simulated collection of PET data from the human head, that for either secondary criterion the superiorized version of ML-EM outperforms MLEM-STOP for the task of estimating activity within neuroanatomical structures.","Positron emission tomography,
Image reconstruction,
Vectors,
Detectors,
Phantoms,
Iterative methods,
Gaussian distribution"
Jointly Learning Visually Correlated Dictionaries for Large-Scale Visual Recognition Applications,"Learning discriminative dictionaries for image content representation plays a critical role in visual recognition. In this paper, we present a joint dictionary learning (JDL) algorithm which exploits the inter-category visual correlations to learn more discriminative dictionaries. Given a group of visually correlated categories, JDL simultaneously learns one common dictionary and multiple category-specific dictionaries to explicitly separate the shared visual atoms from the category-specific ones. The problem of JDL is formulated as a joint optimization with a discrimination promotion term according to the Fisher discrimination criterion. A visual tree method is developed to cluster a large number of categories into a set of disjoint groups, so that each of them contains a reasonable number of visually correlated categories. The process of image category clustering helps JDL to learn better dictionaries for classification by ensuring that the categories in the same group are of strong visual correlations. Also, it makes JDL to be computationally affordable in large-scale applications. Three classification schemes are adopted to make full use of the dictionaries learned by JDL for visual content representation in the task of image categorization. The effectiveness of the proposed algorithms has been evaluated using two image databases containing 17 and 1,000 categories, respectively.","Dictionaries,
Visualization,
Clustering algorithms,
Correlation,
Training,
Joints,
Vegetation"
Learning to predict trajectories of cooperatively navigating agents,"The problem of modeling the navigation behavior of multiple interacting agents arises in different areas including robotics, computer graphics, and behavioral science. In this paper, we present an approach to learn the composite navigation behavior of interacting agents from demonstrations. The decision process that ultimately leads to the observed continuous trajectories of the agents often also comprises discrete decisions, which partition the space of composite trajectories into homotopy classes. Therefore, our method uses a mixture probability distribution that consists of a discrete distribution over the homotopy classes and continuous distributions over the composite trajectories for each homotopy class. Our approach learns the model parameters of this distribution that match, in expectation, the observed behavior in terms of user-defined features. To compute the feature expectations over the high-dimensional continuous distributions, we use Hamiltonian Markov chain Monte Carlo sampling. We exploit that the distributions are highly structured due to physical constraints and guide the sampling process to regions of high probability. We apply our approach to learning the behavior of pedestrians and demonstrate that it outperforms state-of-the-art methods.",
Variability Mining: Consistent Semi-automatic Detection of Product-Line Features,"Software product line engineering is an efficient means to generate a set of tailored software products from a common implementation. However, adopting a product-line approach poses a major challenge and significant risks, since typically legacy code must be migrated toward a product line. Our aim is to lower the adoption barrier by providing semi-automatic tool support-called variability mining -to support developers in locating, documenting, and extracting implementations of product-line features from legacy code. Variability mining combines prior work on concern location, reverse engineering, and variability-aware type systems, but is tailored specifically for the use in product lines. Our work pursues three technical goals: (1) we provide a consistency indicator based on a variability-aware type system, (2) we mine features at a fine level of granularity, and (3) we exploit domain knowledge about the relationship between features when available. With a quantitative study, we demonstrate that variability mining can efficiently support developers in locating features.","Feature extraction,
Software,
Context,
Data mining,
Java,
Companies,
Educational institutions"
Large-scale logistic regression and linear support vector machines using spark,"Logistic regression and linear SVM are useful methods for large-scale classification. However, their distributed implementations have not been well studied. Recently, because of the inefficiency of the MapReduce framework on iterative algorithms, Spark, an in-memory cluster-computing platform, has been proposed. It has emerged as a popular framework for large-scale data processing and analytics. In this work, we consider a distributed Newton method for solving logistic regression as well linear SVM and implement it on Spark. We carefully examine many implementation issues significantly affecting the running time and propose our solutions. After conducting thorough empirical investigations, we release an efficient and easy-to-use tool for the Spark community.",
Achieving Accountability in Smart Grid,"Smart grid is a promising power infrastructure that is integrated with communication and information technologies. Nevertheless, privacy and security concerns arise simultaneously. Failure to address these issues will hinder the modernization of the existing power system. After critically reviewing the current status of smart grid deployment and its key cyber security concerns, the authors argue that accountability mechanisms should be involved in smart grid designs. We design two separate accountable communication protocols using the proposed architecture with certain reasonable assumptions under both home area network and neighborhood area network. Analysis and simulation results indicate that the design works well, and it may cause all power loads to become accountable.","Smart grids,
Home appliances,
Smart meters,
Reliability,
Security,
Real-time systems,
Monitoring"
A Compressive Sensing Based Secure Watermark Detection and Privacy Preserving Storage Framework,"Privacy is a critical issue when the data owners outsource data storage or processing to a third party computing service, such as the cloud. In this paper, we identify a cloud computing application scenario that requires simultaneously performing secure watermark detection and privacy preserving multimedia data storage. We then propose a compressive sensing (CS)-based framework using secure multiparty computation (MPC) protocols to address such a requirement. In our framework, the multimedia data and secret watermark pattern are presented to the cloud for secure watermark detection in a CS domain to protect the privacy. During CS transformation, the privacy of the CS matrix and the watermark pattern is protected by the MPC protocols under the semi-honest security model. We derive the expected watermark detection performance in the CS domain, given the target image, watermark pattern, and the size of the CS matrix (but without the CS matrix itself). The correctness of the derived performance has been validated by our experiments. Our theoretical analysis and experimental results show that secure watermark detection in the CS domain is feasible. Our framework can also be extended to other collaborative secure signal processing and data-mining applications in the cloud.","Watermarking,
Compressed sensing,
Protocols,
DH-HEMTs,
Multimedia communication,
Discrete cosine transforms,
Cryptography"
Control and verification of high-dimensional systems with DSOS and SDSOS programming,"In this paper, we consider linear programming (LP) and second order cone programming (SOCP) based alternatives to sum of squares (SOS) programming and apply this framework to high-dimensional problems arising in control applications. Despite the wide acceptance of SOS programming in the control and optimization communities, scalability has been a key challenge due to its reliance on semidefinite programming (SDP) as its main computational engine. While SDPs have many appealing features, current SDP solvers do not approach the scalability or numerical maturity of LP and SOCP solvers. Our approach is based on the recent work of Ahmadi and Majumdar [1], which replaces the positive semidefiniteness constraint inherent in the SOS approach with stronger conditions based on diagonal dominance and scaled diagonal dominance. This leads to the DSOS and SDSOS cones of polynomials, which can be optimized over using LP and SOCP respectively. We demonstrate this approach on four high dimensional control problems that are currently well beyond the reach of SOS programming: computing a region of attraction for a 22 dimensional system, analysis of a 50 node network of oscillators, searching for degree 3 controllers and degree 8 Lyapunov functions for an Acrobot system (with the resulting controller validated on a hardware platform), and a balancing controller for a 30 state and 14 control input model of the ATLAS humanoid robot. While there is additional conservatism introduced by our approach, extensive numerical experiments on smaller instances of our problems demonstrate that this conservatism can be small compared to SOS programming.","Polynomials,
Programming,
Symmetric matrices,
Optimization,
Approximation methods,
Scalability,
Lyapunov methods"
Optimal Cooperative Beamforming Design for MIMO Decode-and-Forward Relay Channels,"In this paper, we consider a transmit beamforming design for multiple-input-multiple-output (MIMO) decode-and-forward (DF) half-duplex two-hop relay channels with a direct source-destination link. For the scenario where source and relay nodes are equipped with multiple antennas and the destination node is deployed with single antenna, we formulate and solve the optimal beamforming vectors for source and relay nodes jointly. Specifically, we identify several unique properties of the optimal solutions through mathematical derivation, based on which we develop a systematic approach to arrive at the optimal beamforming vectors for the source and relay nodes for different system configurations. We derive a low-complexity explicit expression for the optimal beamforming vectors for some specific scenarios. Numerical results show that our proposed beamforming design scheme can achieve the ε-optimal solution with low computational complexity for MIMO DF relay networks.",
Uncooled Infrared Detectors Using Gallium Nitride on Silicon Micromechanical Resonators,"This paper presents the analysis, design, fabrication, and the first measured results demonstrating the use of gallium nitride (GaN)-based micromechanical resonator arrays as high-sensitivity, low-noise infrared (IR) detectors. The IR sensing mechanism is based on monitoring the change in the resonance frequency of the resonators upon near IR radiation. The resonators are characterized for their RF and thermal performance and exhibit a radiant responsivity of 1.68%/W, thermal time constant on the order of 556 μs, and an average IR responsivity of -1.5% when compared with a reference resonator, for a 100 mK radiation-induced temperature rise. An analysis of the design of the devices is presented as a path toward better design, specifically, for low thermal noise equivalent temperature difference in the long wavelength IR spectrum.",
Accelerometry-Based Home Monitoring for Detection of Nocturnal Hypermotor Seizures Based on Novelty Detection,"Nocturnal home monitoring of epileptic children is often not feasible due to the cumbersome manner of seizure monitoring with the standard method of video/EEG-monitoring. We propose a method for hypermotor seizure detection based on accelerometers attached to the extremities. From the acceleration signals, multiple temporal, frequency, and wavelet-based features are extracted. After determining the features with the highest discriminative power, we classify movement events in epileptic and nonepileptic movements. This classification is only based on a nonparametric estimate of the probability density function of normal movements. Such approach allows us to build patient-specific models to classify movement data without the need for seizure data that are rarely available. If, in the test phase, the probability of a data point (event) is lower than a threshold, this event is considered to be an epileptic seizure; otherwise, it is considered as a normal nocturnal movement event. The mean performance over seven patients gives a sensitivity of 95.24% and a positive predictive value of 60.04%. However, there is a noticeable interpatient difference.",
A Fast Adaptive Parameter Estimation for Total Variation Image Restoration,"Estimation of the regularization parameter, which strikes a balance between the data fidelity and regularity, is essential for successfully solving ill-posed image restoration problems. Based on the classical total variation (TV) model and prevalent alternating direction method of multipliers, we hammer out a fast algorithm being able to simultaneously estimate the regularization parameter and restore the degraded image. By applying variable splitting technique to both the regularization term and data fidelity term, we overcome the nondifferentiability of TV and achieve a closed form to update the regularization parameter in each iteration. The solution is guaranteed to satisfy Morozov's discrepancy principle. Furthermore, we present a convergence proof for the proposed algorithm on the premise of a variable regularization parameter. Experimental results demonstrate that the proposed algorithm is superior in speed and competitive in accuracy compared with several state-of-the-art methods. Besides, the proposed method can be smoothly extended to the multichannel image restoration.","Image restoration,
TV,
Convergence,
Vectors,
Manganese,
Equations,
Noise"
On the Security of an Efficient Dynamic Auditing Protocol in Cloud Storage,"Using cloud storage, data owners can remotely store their data and enjoy the on-demand high quality cloud services without the burden of local data storage and maintenance. However, this new paradigm does trigger many security concerns. A major concern is how to ensure the integrity of the outsourced data. To address this issue, recently, a highly efficient dynamic auditing protocol (IEEE Transactions on Parallel and Distributed Systems, doi:10.1109/TPDS.2013.199) for cloud storage was proposed which enjoys many desirable features. Unfortunately, in this letter, we demonstrate that the protocol is insecure when an active adversary is involved in the cloud environment. We show that the adversary is able to arbitrarily modify the cloud data without being detected by the auditor in the auditing process. We also suggest a solution to fix the problem while preserving all the properties of the original protocol.","Protocols,
Cloud computing,
Educational institutions,
Servers,
Cryptography,
Computer science"
Analysis and Design of Output-Capacitor-Free Low-Dropout Regulators With Low Quiescent Current and High Power Supply Rejection,"This paper summarizes and extends our discussions on the recently developed output-capacitor-free low-dropout regulators (LDRs) with low quiescent current and high power supply rejection (LQC-HPSR LDRs) for SoC power management applications. By modifying the biasing scheme in a cascoding-based high-PSR topology, quiescent current consumption is significantly reduced while high PSR over a wide frequency range is maintained. The operation principle of the LQC-HPSR LDRs is elaborated and comprehensive analysis of PSR at different frequency ranges is presented. Furthermore, a novel implementation with enhanced robustness is proposed to limit the internal voltage range and accelerate the start-up speed as well. Two 12 mA LQC-HPSR LDRs-the first has one and the second has two NMOS transistors cascoded to the core regulator-have been designed in a 0.35- μm CMOS process with active areas of 0.055 mm2 and 0.084 mm2, respectively. Experimental results showed that they had dropout voltages of 0.4 V and 0.6 V, and achieved PSRs better than -23.0 dB and -38.0 dB up to 50 MHz at full load while consuming quiescent currents of only 28.6 μA and 43.9 μA, respectively.","Logic gates,
MOS devices,
System-on-chip,
Noise,
Power supplies,
Capacitors,
Regulators"
"High Performance InAs/{\rm In}_{0.53}{\rm Ga}_{0.23}{\rm Al}_{0.24}{\rm As}
/InP Quantum Dot 1.55 \mu{\rm m}
Tunnel Injection Laser","The characteristics of 1.55 μm InAs self-organized quantum-dot lasers, grown on (001) InP substrates by molecular beam epitaxy, have been investigated. Modulation doping of the dots with holes and tunnel injection of electrons have been incorporated in the design of the active (gain) region of the laser heterostructure. Large values of To=227 K (5°C ≤ T ≤ 45°C) and 100 K were derived from temperature dependent measurements of the light-current characteristics. The modal gain per dot layer is 14.5 cm-1 and the differential gain derived from both light-current and small-signal modulation measurements is ~ 0.8×10-15 cm2. The maximum measured -3 dB small-signal modulation bandwidth is 14.4 GHz and the gain compression factor is 5.4×10-17 cm2. The lasers are characterized by a chirp of 0.6 Å for a modulation frequency of 10 GHz and a near zero α-parameter at the peak of the laser emission. These characteristics are amongst the best from any 1.55 μm edge-emitting semiconductor laser.","Quantum dot lasers,
Measurement by laser beam,
Temperature measurement,
Modulation,
Waveguide lasers,
Quantum dots"
Fuzzy Multiple Attributes Group Decision-Making Based on Ranking Interval Type-2 Fuzzy Sets and the TOPSIS Method,"In this paper, we present a new method for fuzzy multiple attributes group decision-making based on the proposed ranking method of trapezoidal interval type-2 fuzzy sets and the TOPSIS method. Firstly, we present a new method for ranking trapezoidal interval type-2 fuzzy sets. Secondly, we construct the decision matrix and the average decision matrix, respectively. Thirdly, we construct the weighting decision matrix and average weighting decision matrix, respectively. Fourthly, we construct the ranking decision matrix by calculating the ranking values of trapezoidal interval type-2 fuzzy sets in the average decision matrix. Then, we get the absolute positive ideal solution and the absolute negative ideal solution with respect to the attributes based on the ranking decision matrix. Then, we calculate the distance between each alternative and the absolute positive ideal solution and calculate the distance between each alternative and the negative ideal solution, respectively. Finally, we calculate the relative degree of closeness of each alternative. The larger the value of the relative degree of closeness of an alternative, the better the preference order of the alternative. The proposed fuzzy multiple attributes group decision-making method can overcome the drawbacks of the existing method.","Fuzzy sets,
Decision making"
Subjective Quality Assessment of Longer Duration Video Sequences Delivered Over HTTP Adaptive Streaming to Tablet Devices,"HTTP adaptive streaming facilitates video streaming to mobile devices connected through heterogeneous networks without the need for a dedicated streaming infrastructure. By splitting different encoded versions of the same video into small segments, clients can continuously decide which segments to download based on available network resources and device characteristics. These encoded versions can, for example, differ in terms of bitrate and spatial or temporal resolution. However, as a result of dynamically selecting video segments, perceived video quality can fluctuate during playback which will impact end-users' quality of experience. Subjective studies have already been conducted to assess the influence of video delivery using HTTP Adaptive Streaming to mobile devices. Nevertheless, existing studies are limited to the evaluation of short video sequences in controlled environments. Research has already shown that video duration and assessment environment influence quality perception. Therefore, in this article, we go beyond the traditional ways for subjective quality evaluation by conducting novel experiments on tablet devices in more ecologically valid testing environments using longer duration video sequences. As such, we want to mimic realistic viewing behavior as much as possible. Our results show that both video content and the range of quality switches significantly influence end-users' rating behavior. In general, quality level switches are only perceived in high motion sequences or in case switching occurs between high and low quality video segments. Moreover, we also found that video stallings should be avoided during playback at all times.","Streaming media,
Video sequences,
Quality assessment,
Bit rate,
Video recording,
Tablet computers,
Mobile handsets"
"Rethinking the Data Center Networking: Architecture, Network Protocols, and Resource Sharing","Large-scale data centers enable the new era of cloud computing and provide the core infrastructure to meet the computing and storage requirements for both enterprise information technology needs and cloud-based services. To support the ever-growing cloud computing needs, the number of servers in today's data centers are increasing exponentially, which in turn leads to enormous challenges in designing an efficient and cost-effective data center network. With data availability and security at stake, the issues with data center networks are more critical than ever. Motivated by these challenges and critical issues, many novel and creative research works have been proposed in recent years. In this paper, we investigate in data center networks and provide a general overview and analysis of the literature covering various research areas, including data center network interconnection architectures, network protocols for data center networks, and network resource sharing in multitenant cloud data centers. We start with an overview on data center networks and together with its requirements navigate the data center network designs. We then present the research literature related to the aforementioned research topics in the subsequent sections. Finally, we draw the conclusions.","Computer security,
Resource management,
Large-scale systems,
Data centers,
Cloud computing,
Information technology,
Servers,
Computer architecture,
Design methodology"
A Geometric Particle Filter for Template-Based Visual Tracking,"Existing approaches to template-based visual tracking, in which the objective is to continuously estimate the spatial transformation parameters of an object template over video frames, have primarily been based on deterministic optimization, which as is well-known can result in convergence to local optima. To overcome this limitation of the deterministic optimization approach, in this paper we present a novel particle filtering approach to template-based visual tracking. We formulate the problem as a particle filtering problem on matrix Lie groups, specifically the three-dimensional Special Linear group SL(3) and the two-dimensional affine group Aff(2). Computational performance and robustness are enhanced through a number of features: (i) Gaussian importance functions on the groups are iteratively constructed via local linearization; (ii) the inverse formulation of the Jacobian calculation is used; (iii) template resizing is performed; and (iv) parent-child particles are developed and used. Extensive experimental results using challenging video sequences demonstrate the enhanced performance and robustness of our particle filtering-based approach to template-based visual tracking. We also show that our approach outperforms several state-of-the-art template-based visual tracking methods via experiments using the publicly available benchmark data set.","Tracking,
Visualization,
Equations,
Mathematical model,
Approximation methods,
Algebra,
Approximation algorithms"
Discussion of the Epsilon-Near-Zero Effect of Graphene in a Horizontal Slot Waveguide,"Horizontal slot waveguides based on graphene have been considered an attractive structure for optical waveguide modulators for transverse magnetic (TM) modes. Graphene is embedded in the slot region of a horizontal slot waveguide. If graphene were treated as an isotropic material and its dielectric constant were made close to zero by adjusting its Fermi level, the surface-normal electric field component of the fundamental TM mode of a horizontal slot waveguide might be highly enhanced in graphene. This could cause a large increase in the attenuation coefficient of the mode. This is called the epsilon-near-zero (ENZ) effect. This paper discusses that graphene needs to be treated as an anisotropic material that has an almost real surface-normal dielectric constant component. Then, the ENZ effect does not exist. Approximate analytic expressions and numerical simulation are used for the discussion, and they demonstrate that horizontal slot waveguides are not appropriate for graphene-based modulators for TM modes.","Graphene,
Optical waveguides,
Mathematical model,
Electric fields,
Modulation,
Dielectrics,
Optical attenuators"
Dynamic Power Allocation for Maximizing Throughput in Energy-Harvesting Communication System,"The design of online algorithms for maximizing the achievable rate in a wireless communication channel between a source and a destination over a fixed number of slots is considered. The source is assumed to be powered by a natural renewable source, and the most general case of arbitrarily varying energy arrivals is considered, where neither the future energy arrival instants or amount nor their distribution is known. The fading coefficients are also assumed to be arbitrarily varying over time, with only causal information available at the source. For a maximization problem, the utility of an online algorithm is tested by finding its competitive ratio or competitiveness that is defined to be the maximum of the ratio of the gain of the optimal offline algorithm and the gain of the online algorithm over all input sequences. We show that the lower bound on the optimal competitive ratio for maximizing the achievable rate is arbitrarily close to the number of slots. Conversely, we propose a simple strategy that invests available energy uniformly over all remaining slots until the next energy arrival, and show that its competitive ratio is equal to the number of slots, to conclude that it is an optimal online algorithm.","Fading,
Heuristic algorithms,
Algorithm design and analysis,
Wireless communication,
Resource management,
Upper bound,
IEEE transactions"
200 MeV Proton Radiography Studies With a Hand Phantom Using a Prototype Proton CT Scanner,"Proton radiography has applications in patient alignment and verification procedures for proton beam radiation therapy. In this paper, we report an experiment which used 200 MeV protons to generate proton energy-loss and scattering radiographs of a hand phantom. The experiment used the first-generation proton computed tomography (CT) scanner prototype, which was installed on the research beam line of the clinical proton synchrotron at Loma Linda University Medical Center. It was found that while both radiographs displayed anatomical details of the hand phantom, the energy-loss radiograph had a noticeably higher resolution. Nonetheless, scattering radiography may yield more contrast between soft and bone tissue than energy-loss radiography, however, this requires further study. This study contributes to the optimization of the performance of the next-generation of clinical proton CT scanners. Furthermore, it demonstrates the potential of proton imaging (proton radiography and CT), which is now within reach of becoming available as a new, potentially low-dose medical imaging modality.","Protons,
Scattering,
Phantoms,
Computed tomography,
Image reconstruction,
Diagnostic radiography"
Modeling Sources of Nonlinearity in a Simple p-i-n Photodetector,"Nonlinearity in p-i-n photodetectors leads to power generation at harmonics of the input frequency, limiting the performance of RF-photonic systems. We use one-dimensional and two-dimensional simulations of the drift-diffusion equations to determine the physical origin of the saturation in a simple heterojunction p-i-n photodetector at room temperature. Incomplete ionization, external loading, impact ionization, and the Franz-Keldysh effect are all included in the model. Impact ionization is the main source of nonlinearity at large reverse bias (>10 V in the device that we simulated). The electron and hole current contributions to the second harmonic power were calculated. We find that impact ionization has a greater effect on the electrons than it does on the holes. We also find that the hole velocity saturates slowly with increasing reverse bias, and the hole current makes a large contribution to the harmonic power at 10 V. This result implies that decreasing the hole injection will decrease the harmonic power.",
A Circuit for Energy Harvesting Using On-Chip Solar Cells,This paper addresses on-chip solar energy harvesting and proposes a circuit that can be employed to generate high voltages from integrated photodiodes. The proposed circuit uses a switched-inductor approach to avoid stacking photodiodes to generate high voltages. The effect of parasitic photodiodes present in integrated circuits (ICs) is addressed and a solution to minimize their impact is presented. The proposed circuit employs two switch transistors and two off-chip components: an inductor and a capacitor. A theoretical analysis of a switched-inductor dc-dc converter is carried out and a mathematical model of the energy harvester is developed. Measurements taken from a fabricated IC are presented and shown to be in good agreement with hardware measurements. Measurement results show that voltages of up to 2.81 V (depending on illumination and loading conditions) can be generated from a single integrated photodiode. The energy harvester circuit achieves a maximum conversion efficiency of 59%.,"Photodiodes,
Integrated circuit modeling,
Energy harvesting,
System-on-chip,
Capacitors,
Standards,
Photovoltaic cells"
Average Consensus on Arbitrary Strongly Connected Digraphs With Time-Varying Topologies,"We have recently proposed a “surplus-based” algorithm which solves the multi-agent average consensus problem on general strongly connected and static digraphs. The essence of that algorithm is to employ an additional variable to keep track of the state changes of each agent, thereby achieving averaging even though the state sum is not preserved. In this note, we extend this approach to the more interesting and challenging case of time-varying topologies: An extended surplus-based averaging algorithm is designed, under which a necessary and sufficient graphical condition is derived that guarantees state averaging. The derived condition requires only that the digraphs be arbitrary strongly connected in a joint sense, and does not impose “balanced” or “symmetric” properties on the network topology, which is therefore more general than those previously reported in the literature.","Heuristic algorithms,
Topology,
Network topology,
Algorithm design and analysis,
Convergence,
Joints,
Switches"
"Noninvasive, Accurate Assessment of the Behavior of Representative Populations of Motor Units in Targeted Reinnervated Muscles","Targeted muscle reinnervation (TMR) redirects nerves that have lost their target, due to amputation, to remaining muscles in the region of the stump with the intent of establishing intuitive myosignals to control a complex prosthetic device. In order to directly recover the neural code underlying an attempted limb movement, in this paper, we present the decomposition of high-density surface electromyographic (EMG) signals detected from three TMR patients into the individual motor unit spike trains. The aim was to prove, for the first time, the feasibility of decoding the neural drive that would reach muscles of the missing limb in TMR patients, to show the accuracy of the decoding, and to demonstrate the representativeness of the pool of extracted motor units. Six to seven flexible EMG electrode grids of 64 electrodes each were mounted over the reinnervated muscles of each patient, resulting in up to 448 EMG signals. The subjects were asked to attempt elbow extension and flexion, hand open and close, wrist extension and flexion, wrist pronation and supination, of their missing limb. The EMG signals were decomposed using the Convolution Kernel Compensation technique and the decomposition accuracy was evaluated with a signal-based index of accuracy, called pulse-to-noise ratio (PNR). The results showed that the spike trains of 3 to 27 motor units could be identified for each task, with a sensitivity of the decomposition >90%, as revealed by PNR. The motor unit discharge rates were within physiological values of normally innervated muscles. Moreover, the detected motor units showed a high degree of common drive so that the set of extracted units per task was representative of the behavior of the population of active units. The results open a path for a new generation of human-machine interfaces in which the control signals are extracted from noninvasive recordings and the obtained neural information is based directly on the spike trains of motor neurons.","Muscles,
Electromyography,
Tunneling magnetoresistance,
Discharges (electric),
Electrodes,
Indexes,
Accuracy"
The Technologically Integrated Oncosimulator: Combining Multiscale Cancer Modeling With Information Technology in the In Silico Oncology Context,"This paper outlines the major components and function of the technologically integrated oncosimulator developed primarily within the Advancing Clinico Genomic Trials on Cancer (ACGT) project. The Oncosimulator is defined as an information technology system simulating in vivo tumor response to therapeutic modalities within the clinical trial context. Chemotherapy in the neoadjuvant setting, according to two real clinical trials concerning nephroblastoma and breast cancer, has been considered. The spatiotemporal simulation module embedded in the Oncosimulator is based on the multiscale, predominantly top-down, discrete entity-discrete event cancer simulation technique developed by the In Silico Oncology Group, National Technical University of Athens. The technology modules include multiscale data handling, image processing, invocation of code execution via a spreadsheet-inspired environment portal, execution of the code on the grid, and the visualization of the predictions. A refining scenario for the eventual coupling of the oncosimulator with immunological models is also presented. Parameter values have been adapted to multiscale clinical trial data in a consistent way, thus supporting the predictive potential of the oncosimulator. Indicative results demonstrating various aspects of the clinical adaptation and validation process are presented. Completion of these processes is expected to pave the way for the clinical translation of the system.","Tumors,
Chemotherapy,
Computational modeling,
Breast cancer,
Oncology,
Adaptation models"
Micromachined Thick Mesh Filters for Millimeter-Wave and Terahertz Applications,"This paper presents several freestanding bandpass mesh filters fabricated using an SU-8-based micromachining technique. The important geometric feature of the filters, which SU8 is able to increase, is the thickness of the cross-shaped micromachined slots. This is five times its width. This thickness offers an extra degree of control over the resonance characteristics. The large thickness not only strengthens the structures, but also enhances the resonance quality factor ( Q-factor). A 0.3-mm-thick, single-layer, mesh filter resonant at 300 GHz has been designed and fabricated and its performance verified. The measured Q-factor is 16.3 and the insertion loss is 0.98 dB. Two multi-layer filter structures have also been demonstrated. The first one is a stacked structure of two single mesh filters producing a double thickness, which achieved a further increased Q-factor of 27. This is over six times higher than a thin mesh filter. The second multilayer filter is an electromagnetically coupled structure forming a two-pole filter. The coupling characteristics are discussed based on experimental and simulation results. These thick mesh filters can potentially be used for sensing and material characterization at millimeter-wave and terahertz frequencies.","Resonant frequency,
Couplings,
Materials,
Educational institutions,
Millimeter wave technology,
Sensitivity,
Bandwidth"
Proximal ADMM for Multi-Channel Image Reconstruction in Spectral X-ray CT,"The development of spectral X-ray computed tomography (CT) using binned photon-counting detectors has received great attention in recent years and has enabled selective imaging of contrast agents loaded with K-edge materials. A practical issue in implementing this technique is the mitigation of the high-noise levels often present in material-decomposed sinogram data. In this work, the spectral X-ray CT reconstruction problem is formulated within a multi-channel (MC) framework in which statistical correlations between the decomposed material sinograms can be exploited to improve image quality. Specifically, a MC penalized weighted least squares (PWLS) estimator is formulated in which the data fidelity term is weighted by the MC covariance matrix and sparsity-promoting penalties are employed. This allows the use of any number of basis materials and is therefore applicable to photon-counting systems and K-edge imaging. To overcome numerical challenges associated with use of the full covariance matrix as a data fidelity weight, a proximal variant of the alternating direction method of multipliers is employed to minimize the MC PWLS objective function. Computer-simulation and experimental phantom studies are conducted to quantitatively evaluate the proposed reconstruction method.",
Image-Based Quantitative Analysis of Gold Immunochromatographic Strip via Cellular Neural Network Approach,"Gold immunochromatographic strip assay provides a rapid, simple, single-copy and on-site way to detect the presence or absence of the target analyte. This paper aims to develop a method for accurately segmenting the test line and control line of the gold immunochromatographic strip (GICS) image for quantitatively determining the trace concentrations in the specimen, which can lead to more functional information than the traditional qualitative or semi-quantitative strip assay. The canny operator as well as the mathematical morphology method is used to detect and extract the GICS reading-window. Then, the test line and control line of the GICS reading-window are segmented by the cellular neural network (CNN) algorithm, where the template parameters of the CNN are designed by the switching particle swarm optimization (SPSO) algorithm for improving the performance of the CNN. It is shown that the SPSO-based CNN offers a robust method for accurately segmenting the test and control lines, and therefore serves as a novel image methodology for the interpretation of GICS. Furthermore, quantitative comparison is carried out among four algorithms in terms of the peak signal-to-noise ratio. It is concluded that the proposed CNN algorithm gives higher accuracy and the CNN is capable of parallelism and analog very-large-scale integration implementation within a remarkably efficient time.","Cellular neural networks,
Neural networks,
Immune system,
Algorithm design and analysis,
Image segmentation,
Chromatography"
A Z-Source Half-Bridge Converter,"Applying an LC network into a half-bridge converter, a novel Z-source half-bridge converter is presented, in which less LC components are needed compared to the conventional one. This Z-source half-bridge converter can solve not only the problems of the shoot-through and limited voltage but also the problem of imbalance at the midpoint voltage of input capacitors. Furthermore, it can generate a broader range of output voltage values and much more kinds of waveforms, such as the varied positive or negative output voltages and the varied time ratio between positive and negative voltages, which are particularly desirable for some special power supplies, like the electrochemical power supply. Finally, the proposed converter is implemented in a prototype, and the experimental results can verify the effectiveness of the proposed converter.",
"{\ssr{PriWhisper}}
: Enabling Keyless Secure Acoustic Communication for Smartphones","Short-range wireless communication technologies have been used in many security-sensitive smartphone applications and services such as contactless micro payment and device pairing. Typically, the data confidentiality of the existing short-range communication systems relies on so-called “key-exchange then encryption” mechanism, which is inefficient, especially for short communication sessions. In this work, we present {\ssb{PriWhisper}}
—a keyless secure acoustic short-range communication system for smartphones. It is designed to provide a software-based solution to secure smartphone communication without the key agreement phase. {\ssb{PriWhisper}}
adopts the emerging friendly jamming technique from radio communication for data confidentiality. The system prototype is implemented and evaluated on several Android smartphone platforms for efficiency and usability. We theoretically and experimentally analyze the security of our proposed acoustic communication system against eavesdropping. In particular, we study the (in)separability of the data signal and jamming signal against blind signal segmentation (BSS) attacks such as independent component analysis (ICA). The result shows that {\ssb{PriWhisper}}
provides sufficient security guarantees for commercial smartphone applications and yet strong compatibilities with most legacy smartphone platforms. As an application, we also develop {\ssb{AcousAuth}}
—a novel smartphone-empowered system for personal authentication.",
The Nature and the Kinetics of Light-Induced Defect Creation in Hydrogenated Amorphous Silicon Films and Solar Cells,"The nature and the kinetics of light-induced defect creation in hydrogenated amorphous silicon (a-Si:H) films and solar cells are investigated by means of Doppler broadening positron annihilation spectroscopy, Fourier transform photocurrent spectroscopy, and J-V characterization. There is a strong correlation between the open volume deficiencies in a-Si:H and the Staebler-Wronski effect (SWE). The carrier generation and recombination profiles in the absorber layer are spatially correlated, and the recombination due to defects in the top and bottom parts of the absorber layer is different. Furthermore, the various defect distributions in the bandgap have different defect creation kinetics. It is demonstrated that the SWE defect formation kinetics in a solar cell are very complex and can impossibly be described by one time scaling ~ tβ as is often claimed.","Photovoltaic cells,
Kinetic theory,
Degradation,
Light emitting diodes,
Amorphous silicon"
MobiFuzzyTrust: An Efficient Fuzzy Trust Inference Mechanism in Mobile Social Networks,"Mobile social networks (MSNs) facilitate connections between mobile users and allow them to find other potential users who have similar interests through mobile devices, communicate with them, and benefit from their information. As MSNs are distributed public virtual social spaces, the available information may not be trustworthy to all. Therefore, mobile users are often at risk since they may not have any prior knowledge about others who are socially connected. To address this problem, trust inference plays a critical role for establishing social links between mobile users in MSNs. Taking into account the nonsemantical representation of trust between users of the existing trust models in social networks, this paper proposes a new fuzzy inference mechanism, namely MobiFuzzyTrust, for inferring trust semantically from one mobile user to another that may not be directly connected in the trust graph of MSNs. First, a mobile context including an intersection of prestige of users, location, time, and social context is constructed. Second, a mobile context aware trust model is devised to evaluate the trust value between two mobile users efficiently. Finally, the fuzzy linguistic technique is used to express the trust between two mobile users and enhance the human's understanding of trust. Real-world mobile dataset is adopted to evaluate the performance of the MobiFuzzyTrust inference mechanism. The experimental results demonstrate that MobiFuzzyTrust can efficiently infer trust with a high precision.",
A Study on Quality Assessment for Medical Ultrasound Video Compressed via HEVC,"The quality of experience and quality of service provided in the healthcare sector are critical in evaluating the reliable delivery of the healthcare services provided. Medical images and videos play a major role in modern e-health services and have become an integral part of medical data communication systems. The quality evaluation of medical images and videos is an essential process, and one of the ways of addressing it is via the use of quality metrics. In this paper, we evaluate the performance of seven state-of-the-art video quality metrics with respect to compressed medical ultrasound video sequences. We study the performance of each video quality metric in representing the diagnostic quality of the video, by evaluating the correlation of each metric with the subjective opinions of medical experts. The results indicate that the visual information fidelity, structural similarity index, and universal quality index metrics show good correlation with the subjective scores provided by medical experts. The tests also investigate the performance of the emerging video compression standard, high-efficiency video coding-HEVC, for medical ultrasound video compression. The results show that, using HEVC with the considered ultrasound video sequences, a diagnostically reliable compressed ultrasound video can be obtained for compression with values of the quantization parameter up to 35.",
Anomaly Detection of Light-Emitting Diodes Using the Similarity-Based Metric Test,"Today's decreasing product development cycle time requires rapid and cost-effective reliability analysis and testing. Qualification is the process of demonstrating that a product is capable of meeting or exceeding specified requirements. Light-emitting diode (LED) qualification tests are often as long as 6000 h, but this length of time does not guarantee the typically required lifetime of 10 years or more. This paper presents a prognostics-based technique that reduces the LED qualification time. An anomaly detection technique called the similarity-based metric test is developed to identify anomalies without utilizing historical libraries of healthy and unhealthy data. The similarity-based metric test extracts features from the spectral power distributions (SPDs) using peak analysis, reduces the dimensionality of the features using principal component analysis, and partitions the data set of principal components into groups using a k-nearest neighbor (KNN)-kernel density-based clustering technique. A detection algorithm then evaluates the distances from the centroid of each cluster to each test point and detects anomalies when the distance is greater than the threshold. From this, the dominant degradation processes associated with the LED die and phosphors in the LED package can be identified. In our case study, anomalies were detected at less than 1200 h using the similarity-based metric test. Thus, our method could decrease the amount of LED qualification testing time by providing users with an earlier time to begin remaining useful life prediction without waiting 6000 h as required by industrial standards.","Phosphors,
Image color analysis,
Feature extraction,
Training data,
Qualifications,
Degradation,
Light emitting diodes"
Displacement Sensing With Silicon Flexures in MEMS Nanopositioners,"We report a novel piezoresistive microelectromechanical system (MEMS) differential displacement sensing technique with a minimal footprint realized through a standard MEMS fabrication process, whereby no additional doping is required to build the piezoresistors. The design is based on configuring a pair of suspension beams attached to a movable stage so that they experience opposite axial forces when the stage moves. The resulting difference between the beam resistances is transduced into a sensor output voltage using a halfbridge readout circuit and differential amplifier. Compared with a single piezoresistive flexure sensor, the design approximately achieves 2, 22, and 200 times improvement in sensitivity, linearity, and resolution, respectively, with 1.5-nm resolution over a large travel range exceeding 12 μm.","Piezoresistance,
Piezoresistive devices,
Sensors,
Micromechanical devices,
Suspensions,
Nanopositioning,
Bridge circuits"
Tunable Dual-Wavelength Thulium-Doped Fiber Laser by Employing a HB-FBG,"A novel tunable dual-wavelength thulium-doped fiber laser is demonstrated experimentally. The wavelength-tuning by employing a high birefringence fiber Bragg grating is proposed in 2-μm band lasing for the first time. By adjusting the polarization controller, stable dual-wavelength operation at the wavelengths of 1941.40 and 1942.21 nm is obtained. The optical signal-to-noise ratio is better than 48 dB. A 15.5% slope efficiency is achieved using a 90% output coupling ratio for laser extracting. The wavelength-tuning range in dual-wavelength operation is as wide as 6.93 nm.",
Radar Target Profiling and Recognition Based on TSI-Optimized Compressive Sensing Kernel,"The design of wideband radar systems is often limited by existing analog-to-digital (A/D) converter technology. State-of-the-art A/D rates and high effective number of bits result in rapidly increasing cost and power consumption for the radar system. Therefore, it is useful to consider compressive sensing methods that enable reduced sampling rate, and in many applications, prior knowledge of signals of interest can be learned from training data and used to design better compressive measurement kernels. In this paper, we use a task-specific information-based approach to optimizing sensing kernels for high-resolution radar range profiling of man-made targets. We employ a Gaussian mixture (GM) model for the targets and use a Taylor series expansion of the logarithm of the GM probability distribution to enable a closed-form gradient of information with respect to the sensing kernel. The GM model admits nuisance parameters such as target pose angle and range translation. The gradient is then used in a gradient-based approach to search for the optimal sensing kernel. In numerical simulations, we compare the performance of the proposed sensing kernel design to random projections and to lower-bandwidth waveforms that can be sampled at the Nyquist rate. Simulation results demonstrate that the proposed technique for sensing kernel design can significantly improve performance.",
Novel Method for Predicting Dexterous Individual Finger Movements by Imaging Muscle Activity Using a Wearable Ultrasonic System,"Recently there have been major advances in the electro-mechanical design of upper extremity prosthetics. However, the development of control strategies for such prosthetics has lagged significantly behind. Conventional noninvasive myoelectric control strategies rely on the amplitude of electromyography (EMG) signals from flexor and extensor muscles in the forearm. Surface EMG has limited specificity for deep contiguous muscles because of cross talk and cannot reliably differentiate between individual digit and joint motions. We present a novel ultrasound imaging based control strategy for upper arm prosthetics that can overcome many of the limitations of myoelectric control. Real time ultrasound images of the forearm muscles were obtained using a wearable mechanically scanned single element ultrasound system, and analyzed to create maps of muscle activity based on changes in the ultrasound echogenicity of the muscle during contraction. Individual digit movements were associated with unique maps of activity. These maps were correlated with previously acquired training data to classify individual digit movements. Preliminary results using ten healthy volunteers demonstrated this approach could provide robust classification of individual finger movements with 98% accuracy (precision 96%-100% and recall 97%-100% for individual finger flexions). The change in ultrasound echogenicity was found to be proportional to the digit flexion speed (R2=0.9), and thus our proposed strategy provided a proportional signal that can be used for fine control. We anticipate that ultrasound imaging based control strategies could be a significant improvement over conventional myoelectric control of prosthetics.","Thumb,
Ultrasonic imaging,
Muscles,
Electromyography,
Training,
Prosthetics"
Design of Radiation-Hardened RF Low-Noise Amplifiers Using Inverse-Mode SiGe HBTs,"A SiGe RF low-noise amplifier (LNA) with built-in tolerance to single-event transients is proposed. The LNA utilizes an inverse-mode SiGe HBT for the common-base transistor in a cascode core. This new cascode configuration exhibits reduced transient peaks and shorter transient durations compared to the conventional cascode one. The improved SET response was verified with through-wafer two-photon absorption pulsed-laser experiments and supported via mixed-mode TCAD simulations. In addition, analysis of the RF performance and the reliability issues associated with the inverse-mode operation further suggests this new cascode structure can be a strong contender for space-based applications. The LNA with the inverse-mode-based cascode core was fabricated in a 130 nm SiGe BiCMOS platform and has similar RF performance to the conventional schematic-based LNA, further validating the proposed approach.","Silicon germanium,
Radio frequency,
Transient analysis,
Heterojunction bipolar transistors,
Radiation hardening (electronics),
Low-noise amplifiers"
6-D Magnetic Localization and Orientation Method for an Annular Magnet Based on a Closed-Form Analytical Model,"Magnetic tracking technology is emerging to provide an occlusion-free tracking scheme for the estimation of full pose (position and orientation) of various instruments. This brings substantial benefits for intracorporeal applications, such as for tracking of flexible or wireless endoscopic devices, and thus is significant for further computer-assisted diagnosis, interventions, and surgeries. Toward efficient magnetic tracking, a 6-D magnetic localization and orientation method is proposed in this paper. An annular permanent magnet is mounted on the exterior surface of a capsule. With a magnetic sensor array, the magnetic field can be measured and the capsule's 3-D location and 3-D orientation information can be estimated based on proposed closed-form analytical model of annular magnet and particle swarm optimization algorithm. Magnetic dipole model and Levenberg-Marquardt algorithm are used to improve the speed and accuracy of estimation. Extensive simulation experiments show that the localization and orientation method works well with good position and orientation accuracy.","Magnetic resonance imaging,
Magnetic analysis,
Magnetic noise,
Magnetic shielding,
Superconducting magnets,
Analytical models,
Magnetic sensors"
Heterogeneity Image Patch Index and Its Application to Consumer Video Summarization,"Automatic video summarization is indispensable for fast browsing and efficient management of large video libraries. In this paper, we introduce an image feature that we refer to as heterogeneity image patch (HIP) index. The proposed HIP index provides a new entropy-based measure of the heterogeneity of patches within any picture. By evaluating this index for every frame in a video sequence, we generate a HIP curve for that sequence. We exploit the HIP curve in solving two categories of video summarization applications: key frame extraction and dynamic video skimming. Under the key frame extraction framework, a set of candidate key frames is selected from abundant video frames based on the HIP curve. Then, a proposed patch-based image dissimilarity measure is used to create affinity matrix of these candidates. Finally, a set of key frames is extracted from the affinity matrix using a min-max based algorithm. Under video skimming, we propose a method to measure the distance between a video and its skimmed representation. The video skimming problem is then mapped into an optimization framework and solved by minimizing a HIP-based distance for a set of extracted excerpts. The HIP framework is pixel-based and does not require semantic information or complex camera motion estimation. Our simulation results are based on experiments performed on consumer videos and are compared with state-of-the-art methods. It is shown that the HIP approach outperforms other leading methods, while maintaining low complexity.",
Reliable Cooperative Communications Based on Random Network Coding in Multi-Hop Relay WSNs,"Reliability is an important issue when designing wireless sensor networks (WSNs), since the WSNs need to work for a long time without manual interventions. Many techniques, such as multiple input multiple output systems and low density parity check codes, have been devised to improve the reliability of computer networks and wireless networks. However, these techniques are too complicated to apply in the WSNs due to the extremely limited resources of the wireless sensor nodes. Hence, it is a hot research topic to design a reliable scheme with low complexity in the WSNs. In recent years, there are a few schemes proposed to improve transmission reliability in the WSNs, such as multipath routing and cooperative transmission. In this paper, a network coding-based cooperative communications scheme (NCCC) is proposed. Combining the advantages of both cooperative communications and network coding, the NCCC can improve the packet loss-resistant capability through network coding and the communications fail-resistant capability through cooperative communications. In the NCCC, coding vectors in network coding procedure are chosen from a finite field randomly, which makes the NCCC easy to be implemented in the resource-limited sensor nodes. Theoretical analyses and experimental results show that the NCCC can achieve a good reliability performance at the cost of neglectable delay.","Wireless sensor networks,
Network coding,
Reliability,
Sensors,
Encoding,
Vectors,
Wireless communication"
One-Way Functions and (Im)Perfect Obfuscation,"A program obfuscator takes a program and outputs a ""scrambled"" version of it, where the goal is that the obfuscated program will not reveal much about its structure beyond what is apparent from executing it. There are several ways of formalizing this goal. Specifically, in indistinguishability obfuscation, first defined by Barak et al. (CRYPTO 2001), the requirement is that the results of obfuscating any two functionally equivalent programs (circuits) will be computationally indistinguishable. Recently, a fascinating candidate construction for indistinguishability obfuscation was proposed by Garg et al. (FOCS 2013). This has led to a flurry of discovery of intriguing constructions of primitives and protocols whose existence was not previously known (for instance, fully deniable encryption by Sahai and Waters, STOC 2014). Most of them explicitly rely on additional hardness assumptions, such as one-way functions. Our goal is to get rid of this extra assumption. We cannot argue that indistinguishability obfuscation of all polynomial-time circuits implies the existence of one-way functions, since if P ≠ NP, then program obfuscation (under the indistinguishability notion) is possible. Instead, the ultimate goal is to argue that if P &ne; NP and program obfuscation is possible, then one-way functions exist. Our main result is that if NP ⊈; io-BPP and there is an efficient (even imperfect) indistinguishability obfuscator, then there are one-way functions. In addition, we show that the existence of an indistinguishability obfuscator implies (unconditionally) the existence of SZK-arguments for NP. This, in turn, provides an alternative version of our main result, based on the assumption of hard-on-the average NP problems. To get some of our results we need obfuscators for simple programs such as 3CNF formulas","Probabilistic logic,
Inverters,
Polynomials,
Encryption,
Awards activities,
Electronic mail"
Characterizing and subsetting big data workloads,"Big data benchmark suites must include a diversity of data and workloads to be useful in fairly evaluating big data systems and architectures. However, using truly comprehensive benchmarks poses great challenges for the architecture community. First, we need to thoroughly understand the behaviors of a variety of workloads. Second, our usual simulation-based research methods become prohibitively expensive for big data. As big data is an emerging field, more and more software stacks are being proposed to facilitate the development of big data applications, which aggravates these challenges. In this paper, we first use Principle Component Analysis (PCA) to identify the most important characteristics from 45 metrics to characterize big data workloads from BigDataBench, a comprehensive big data benchmark suite. Second, we apply a clustering technique to the principle components obtained from the PCA to investigate the similarity among big data workloads, and we verify the importance of including different software stacks for big data benchmarking. Third, we select seven representative big data workloads by removing redundant ones and release the BigDataBench simulation version, which is publicly available from http://prof.ict.ac.cn/BigDataBench/simulatorversion/.","Big data,
Software,
Measurement,
Benchmark testing,
Microarchitecture,
Sparks,
Couplings"
"l
q
Sparsity Penalized Linear Regression With Cyclic Descent","Recently, there has been a lot of focus on penalized least squares problems for noisy sparse signal estimation. The penalty induces sparsity and a very common choice has been the convex l1 norm. However, to improve sparsity and reduce the biases associated with the l1 norm, one must move to non-convex penalties such as the lq norm . In this paper we present a novel cyclic descent algorithm for optimizing the resulting lq penalized least squares problem. Optimality conditions for this problem are derived and competing ones clarified. Coordinate-wise convergence as well as convergence to a local minimizer of the algorithm, which is highly non-trivial, is proved and we illustrate with simulations comparing the signal reconstruction quality with three penalty functions: l0, l1 and lq with 0 <; q <; 1.","Convex optimization,
Inverse problems"
Localization and manipulation of small parts using GelSight tactile sensing,"Robust manipulation and insertion of small parts can be challenging because of the small tolerances typically involved. The key to robust control of these kinds of manipulation interactions is accurate tracking and control of the parts involved. Typically, this is accomplished using visual servoing or force-based control. However, these approaches have drawbacks. Instead, we propose a new approach that uses tactile sensing to accurately localize the pose of a part grasped in the robot hand. Using a feature-based matching technique in conjunction with a newly developed tactile sensing technology known as GelSight that has much higher resolution than competing methods, we synthesize high-resolution height maps of object surfaces. As a result of these high-resolution tactile maps, we are able to localize small parts held in a robot hand very accurately. We quantify localization accuracy in benchtop experiments and experimentally demonstrate the practicality of the approach in the context of a small parts insertion problem.",
A Direct Method With Structural Priors for Imaging Pharmacokinetic Parameters in Dynamic Fluorescence Molecular Tomography,"Images of pharmacokinetic parameters in dynamic fluorescence molecular tomography (FMT) have the potential to provide quantitative physiological information for biological studies and drug development. However, images obtained with conventional indirect methods suffer from low signal-to-noise ratio because of failure in efficiently modeling the measurement noise. Besides, FMT suffers from low spatial resolution due to its ill-posed nature, which further reduces the image quality. In this letter, we present a direct method with structural priors for imaging pharmacokinetic parameters, which uses a nonlinear objective function to efficiently model the measurement noise and utilizes the structural priors to mitigate the ill-posedness of FMT. The results of numerical simulations and in vivo mouse experiments demonstrate that the proposed method leads to significant improvements in the image quality.","Liver,
Mice,
Image reconstruction,
Noise measurement,
Numerical simulation,
Biomedical measurement,
Numerical models"
Effective decomposition of large-scale separable continuous functions for cooperative co-evolutionary algorithms,"In this paper we investigate the performance of cooperative co-evolutionary (CC) algorithms on large-scale fully-separable continuous optimization problems. We have shown that decomposition can have significant impact on the performance of CC algorithms. The empirical results show that the subcomponent size should be chosen small enough so that the subcomponent size is within the capacity of the subcomponent optimizer. In practice, determining the optimal size is difficult. Therefore, adaptive techniques are desired by practitioners. Here we propose an adaptive method, MLSoft, that uses widely-used techniques in reinforcement learning such as the value function method and softmax selection rule to adapt the subcomponent size during the optimization process. The experimental results show that MLSoft is significantly better than an existing adaptive algorithm called MLCC on a set of large-scale fully-separable problems.","Optimization,
Benchmark testing,
Equations,
Educational institutions,
Learning (artificial intelligence),
Vectors,
Convergence"
"Compact, Low Profile, Common Aperture Polarization, and Pattern Diversity Antennas","This paper presents compact and low profile two-port antennas that can provide polarization or pattern diversity schemes from a common aperture. The proposed antennas make use of a novel small microstrip antenna topology with an open area at its waist. The two sections of the small-size microstrip antenna are connected through a magnetic coupling mechanism facilitated by two vertical metallic strips connecting the top plates to the ground plane. This allows for placement of another small antenna element within the same aperture having either polarization or pattern that is orthogonal to the microstrip antenna with low envelope correlation. Topologies of polarization and pattern-diversity antennas are optimized for size reduction and minimum envelope correlation. Although the proposed diversity antenna consists of two antenna elements with different polarizations or radiation patterns, they just occupy about 30% of the area of a conventional microstrip antenna over the same substrate. It is shown that the envelope correlation between radiation patterns of the two antenna elements is lower than -30 dB over the 10-dB return loss bandwidth of the proposed antenna.","Microstrip antennas,
Microstrip,
Antenna radiation patterns,
Resonant frequency,
Aperture antennas,
Diversity reception"
Probabilistically Weighted OWA Aggregation,"In decision-making under uncertainty we have a collection of alternatives from which we must choose one. Associated with each alternative is an uncertainty profile consisting of the set of possible outcomes that can occur if we choose this alternative along with some indication of the uncertainty associated with the outcomes. Since it is difficult to compare these uncertainty profiles one commonly used approach is to obtain a representative value, an aggregation of the information in the uncertainty profile, and use these to compare the alternatives. The method that we use to aggregate the information in the uncertainty profile must reflect aspects of the decision attitude of the decision maker. Here we look at the role that the ordered weighted averaging (OWA) can play in the aggregation process used to obtain these representative values. Since an uncertainty profile can involve a discrete set of possible outcomes or an interval of possible outcomes we provide the OWA operator with the capability to perform aggregations in either of these environments. In addition we provide the OWA operator with the ability to perform aggregations in situations where the arguments being aggregated, the potential outcomes, have an associated uncertainty, probability of occurrence. Particularly notable is the extension the OWA operator to perform aggregation with arguments consisting of a continuum of values with an associated probability density function. We also look at the cases where the uncertainty is modeled with a belief structure as well a possibility distribution.",
An efficient energy hole alleviating algorithm for wireless sensor networks,"Many consumer products in the home environment are managed by the Wireless Sensor Networks (WSNs). However, the energy hole problem in the WSNs which with logical ring topology and uniformly distributed sensors is usually caused by the energy exhaustion of the sensors which distributed in the first radius range of the sink. This paper firstly analyzed the energy consumption model of the sensor, the data transmission model of the sensor, and the energy consumption distribution model of the WSNs. Then, a WSN Energy Hole Alleviating (WSNEHA) algorithm, which is based on the data forwarding and router selection strategy, is proposed. The WSNEHPA adopts the data forwarding and routing selection strategy to balance the energy consumption of the sensors in the first radius range of the sink. Experimental results demonstrate that WSNEHPA can efficiently balance the energy consumption of the sensors in the first radius range of the sink, and that the lifetime of the WSNs can be extended efficiently.","Sensors,
Wireless sensor networks,
Energy consumption,
Algorithm design and analysis,
Data communication,
Educational institutions,
Topology"
Markerless Motion Tracking of Awake Animals in Positron Emission Tomography,"Noninvasive functional imaging of awake, unrestrained small animals using motion-compensation removes the need for anesthetics and enables an animal's behavioral response to stimuli or administered drugs to be studied concurrently with imaging. While the feasibility of motion-compensated radiotracer imaging of awake rodents using marker-based optical motion tracking has been shown, markerless motion tracking would avoid the risk of marker detachment, streamline the experimental workflow, and potentially provide more accurate pose estimates over a greater range of motion. We have developed a stereoscopic tracking system which relies on native features on the head to estimate motion. Features are detected and matched across multiple camera views to accumulate a database of head landmarks and pose is estimated based on 3D-2D registration of the landmarks to features in each image. Pose estimates of a taxidermal rat head phantom undergoing realistic rat head motion via robot control had a root mean square error of 0.15 and 1.8 mm using markerless and marker-based motion tracking, respectively. Markerless motion tracking also led to an appreciable reduction in motion artifacts in motion-compensated positron emission tomography imaging of a live, unanesthetized rat. The results suggest that further improvements in live subjects are likely if nonrigid features are discriminated robustly and excluded from the pose estimation process.","Cameras,
Head,
Animals,
Tracking,
Feature extraction,
Calibration,
Positron emission tomography"
Receptive Fields Selection for Binary Feature Description,"Feature description for local image patch is widely used in computer vision. While the conventional way to design local descriptor is based on expert experience and knowledge, learning-based methods for designing local descriptor become more and more popular because of their good performance and data-driven property. This paper proposes a novel data-driven method for designing binary feature descriptor, which we call receptive fields descriptor (RFD). Technically, RFD is constructed by thresholding responses of a set of receptive fields, which are selected from a large number of candidates according to their distinctiveness and correlations in a greedy way. Using two different kinds of receptive fields (namely rectangular pooling area and Gaussian pooling area) for selection, we obtain two binary descriptors RFDR and RFDG accordingly. Image matching experiments on the well-known patch data set and Oxford data set demonstrate that RFD significantly outperforms the state-of-the-art binary descriptors, and is comparable with the best float-valued descriptors at a fraction of processing time. Finally, experiments on object recognition tasks confirm that both RFDR and RFDG successfully bridge the performance gap between binary descriptors and their floating-point competitors.","Training,
Image matching,
Boosting,
Robustness,
Object recognition,
Accuracy,
Correlation"
A Multiple-Valued Decision-Diagram-Based Approach to Solve Dynamic Fault Trees,"Dynamic fault trees (DFTs) have been used for many years because they can easily provide a concise representation of the dynamic failure behaviors of general non-repairable fault tolerant systems. However, when repeated failure events appear in real-life DFT models, the traditional modularization-based DFT analysis process can still generate large dynamic subtrees, the modeling of which can lead to a state explosion problem. Examples of these kinds of large dynamic subtrees abound in models of real-world dynamic software and embedded computing systems integrating with various multi-function components. This paper proposes an efficient, multiple-valued decision-diagram (MDD)-based DFT analysis approach for computing the reliability of large dynamic subtrees. Unlike the traditional modularization methods where the whole dynamic subtree must be solved using state-space methods, the proposed approach restricts the state-space method only to components associated with dynamic failure behaviors within the dynamic subtree. By using multiple-valued variables to encode the dynamic gates, a single compact MDD can be generated to model the failure behavior of the overall system. The combination of MDD and state-space methods applied at the component or gate level helps relieve the state explosion problem of the traditional modularization method, for the problems we explore. Applications and advantages of the proposed approach are illustrated through detailed analyses of an example DFT, and through two case studies.",
A New Approach Based on Wavelet Design and Machine Learning for Islanding Detection of Distributed Generation,"This paper presents a new approach based on wavelet design and machine learning applied to passive islanding detection of distributed generation. Procrustes analysis is used to determine the filter coefficients of a newly designed wavelet. To automate the classification process, machine learning algorithms are used to develop appropriate models. The IEEE 13-bus standard test distribution system simulated in PSCAD/EMTDC is used as a test bed to assess the performance of the proposed approach. The numerical results demonstrating the effectiveness of the proposed approach are discussed and conclusions are drawn.","Indexes,
Wavelet transforms,
Shape,
Voltage measurement,
Support vector machines,
Switches,
Training"
BurstMem: A high-performance burst buffer system for scientific applications,"The growth of computing power on large-scale systems requires commensurate high-bandwidth I/O systems. Many parallel file systems are designed to provide fast sustainable I/O in response to applications' soaring requirements. To meet this need, a novel system is imperative to temporarily buffer the bursty I/O and gradually flush datasets to long-term parallel file systems. In this paper, we introduce the design of BurstMem, a high-performance burst buffer system. BurstMem provides a storage framework with efficient storage and communication management strategies. Our experiments demonstrate that BurstMem is able to speed up the I/O performance of scientific applications by up to 8.5× on leadership computer systems.","Servers,
Checkpointing,
Bandwidth,
Storage management,
Indexing,
Message systems,
Random access memory"
An Efficient Generic Framework for Three-Factor Authentication With Provably Secure Instantiation,"Remote authentication has been widely studied and adapted in distributed systems. The security of remote authentication mechanisms mostly relies on one of or the combination of three factors: 1) something users know-password; 2) something users have-smart card; and 3) something users are-biometric characteristics. This paper introduces an efficient generic framework for three-factor authentication. The proposed generic framework enhances the security of existing two-factor authentication schemes by upgrading them to three-factor authentication schemes, without exposing user privacy. In addition, we present a case study by upgrading a secure two-factor authentication scheme to a secure three-factor authentication scheme. Furthermore, implementation analysis, formal proof, and privacy discussion are provided to show that the derived scheme is practical, secure, and privacy preserving.","Authentication,
Smart cards,
Security,
Feature extraction,
Privacy,
Biometrics (access control)"
Spatial Filtering Based on Canonical Correlation Analysis for Classification of Evoked or Event-Related Potentials in EEG Data,"Classification of evoked or event-related potentials is an important prerequisite for many types of brain-computer interfaces (BCIs). To increase classification accuracy, spatial filters are used to improve the signal-to-noise ratio of the brain signals and thereby facilitate the detection and classification of evoked or event-related potentials. While canonical correlation analysis (CCA) has previously been used to construct spatial filters that increase classification accuracy for BCIs based on visual evoked potentials, we show in this paper, how CCA can also be used for spatial filtering of event-related potentials like P300. We also evaluate the use of CCA for spatial filtering on other data with evoked and event-related potentials and show that CCA performs consistently better than other standard spatial filtering methods.",
An Investigation into Back-end Advancements for Speaker Recognition in Multi-Session and Noisy Enrollment Scenarios,"This study aims to explore the case of robust speaker recognition with multi-session enrollments and noise, with an emphasis on optimal organization and utilization of speaker information presented in the enrollment and development data. This study has two core objectives. First, we investigate more robust back-ends to address noisy multi-session enrollment data for speaker recognition. This task is achieved by proposing novel back-end algorithms. Second, we construct a highly discriminative speaker verification framework. This task is achieved through intrinsic and extrinsic back-end algorithm modification, resulting in complementary sub-systems. Evaluation of the proposed framework is performed on the NIST SRE2012 corpus. Results not only confirm individual sub-system advancements over an established baseline, the final grand fusion solution also represents a comprehensive overall advancement for the NIST SRE2012 core tasks. Compared with state-of-the-art SID systems on the NIST SRE2012, the novel parts of this study are: 1) exploring a more diverse set of solutions for low-dimensional i-Vector based modeling; and 2) diversifying the information configuration before modeling. All these two parts work together, resulting in very competitive performance with reasonable computational cost.",
Behavioral Analysis of Insider Threat: A Survey and Bootstrapped Prediction in Imbalanced Data,"The problem of insider threat is receiving increasing attention both within the computer science community as well as government and industry. This paper starts by presenting a broad, multidisciplinary survey of insider threat capturing contributions from computer scientists, psychologists, criminologists, and security practitioners. Subsequently, we present the behavioral analysis of insider threat (BAIT) framework, in which we conduct a detailed experiment involving 795 subjects on Amazon Mechanical Turk (AMT) in order to gauge the behaviors that real human subjects follow when attempting to exfiltrate data from within an organization. In the real world, the number of actual insiders found is very small, so supervised machine-learning methods encounter a challenge. Unlike past works, we develop bootstrapping algorithms that learn from highly imbalanced data, mostly unlabeled, and almost no history of user behavior from an insider threat perspective. We develop and evaluate seven algorithms using BAIT and show that they can produce a realistic (and acceptable) balance of precision and recall.","Sociology,
Psychology,
Computer security,
Bayes methods,
Algorithm design and analysis,
Human factors,
Predictive models"
Rule based realtime motion assessment for rehabilitation exercises,"In this paper, we describe a rule based approach to realtime motion assessment of rehabilitation exercises. We use three types of rules to define each exercise: (1) dynamic rules, with each rule specifying a sequence of monotonic segments of the moving joint or body segment, (2) static rules for stationary joints or body segments, and (3) invariance rules that dictate the requirements of moving joints or body segments. A finite state machine based approach is used in dynamic rule specification and realtime assessment. In addition to the typical advantages of the rule based approach, such as realtime motion assessment with specific feedback, our approach has the following advantages: (1) increased reusability of the defined rules as well as the rule assessment engine facilitated by a set of generic rule elements; (2) increased customizability of the rules for each exercise enabled by the use of a set of generic rule elements and the use of extensible rule encoding method; and (3) increased robustness without relying on expensive statistical algorithms to tolerate motion sensing errors and subtle patient errors.","Joints,
Hidden Markov models,
Hip,
Monitoring,
Motion segmentation,
Robustness,
Gesture recognition"
Energy Efficient Task Assignment with Guaranteed Probability Satisfying Timing Constraints for Embedded Systems,"The trade-off between system performance and energy efficiency (service time) is critical for battery-based embedded systems. Most of the previous work focuses on saving energy in a deterministic way by taking the average or worst scenario into account. However, such deterministic approaches usually are inappropriate in modeling energy consumption because of uncertainties in conditional instructions on processors and time-varying external environments (e.g., fluctuant network bandwidth and different user inputs). By adopting a probabilistic approach, this paper proposes a model and a set of algorithms to address the Processor and Voltage Assignment with Probability (PVAP) problem of data-dependent aperiodic tasks in real-time embedded systems, ensuring that all the tasks can be done under the time constraint with a guaranteed probability. We adopt a task DAG (Directed Acyclic Graph) to model the PVAP problem. We first use a processor scheduling algorithm to map the task DAG onto a set of voltage-variable processors, and then use our dynamic programming algorithm to assign a proper voltage to each task. Finally, to escape from local optima, a local search with restarts searches the optimal solution from candidate solutions by updating the objective function, until the stop criteria are reached or a time bound is elapsed. The experimental results demonstrate that for probability 1.0, our approach yields slightly better results than the well-known algorithms like ASAP/ALAP (As Soon As Possible/As Late As Possible) and ILP (Integer Linear Programming) with/without DVS (Dynamic Voltage Scaling). However, for probabilities 0.8 and 0.9, our approach significantly outperforms those algorithms (maximum improvement of 50.3 percent).","Program processors,
Silicon,
Probabilistic logic,
Embedded systems,
Timing,
Energy consumption"
SimRPU: A Simulation Environment for Reconfigurable Architecture Exploration,"To assist the system architects with fast exploration and performance evaluation of the reconfigurable software/hardware architectures, this paper presents a system-level simulator, named after SimRPU, for the reconfigurable processing unit (RPU), which is the major computing engine in reconfigurable processor. The proposed simulator consists of a simulation kernel, a software compiler, a system profiler providing performance, area and power information for the desired architectures, and a system debugger supporting inspecting and modification of the internal state of the RPU. Object-oriented hierarchical and parameterized architecture modeling techniques are proposed to satisfy the requirements for a fast and comprehensive evaluation. Cycle-accurate simulation mechanisms are developed to improve the accuracy of the profiled performance data. Compared with the traditional register transfer level (RTL) based simulation scheme, the proposed simulator could achieve an average speedup of 18.5× with only 3.5% reduction on performance estimation accuracy. One reconfigurable processor targeted at high-definition multimedia decoding applications (such as H.264, MPEG2, AVS, etc.) is implemented with Taiwan Semiconductor Manufacturing Company 65-nm process using the proposed exploration and design flow. The measured results show that the implemented architecture has obvious advantages in terms of both performance and power consumption than the reference designs in multimedia decoding applications.","Computer architecture,
Context,
Computational modeling,
Hardware,
Object oriented modeling,
Registers,
Software"
Online Anomaly Detection in Wireless Body Area Networks for Reliable Healthcare Monitoring,"In this paper, we propose a lightweight approach for online detection of faulty measurements by analyzing the data collected from medical wireless body area networks. The proposed framework performs sequential data analysis using a smart phone as a base station, and takes into account the constrained resources of the smart phone, such as processing power and storage capacity. The main objective is to raise alarms only when patients enter in an emergency situation, and to discard false alarms triggered by faulty measurements or ill-behaved sensors. The proposed approach is based on the Haar wavelet decomposition, nonseasonal Holt-Winters forecasting, and the Hampel filter for spatial analysis, and on for temporal analysis. Our objective is to reduce false alarms resulting from unreliable measurements and to reduce unnecessary healthcare intervention. We apply our proposed approach on real physiological dataset. Our experimental results prove the effectiveness of our approach in achieving good detection accuracy with a low false alarm rate. The simplicity and the processing speed of our proposed framework make it useful and efficient for real time diagnosis.","Monitoring,
Biomedical monitoring,
Wireless sensor networks,
Sensor phenomena and characterization,
Discrete wavelet transforms"
Global Synchronization Measurement of Multivariate Neural Signals with Massively Parallel Nonlinear Interdependence Analysis,"The estimation of synchronization amongst multiple brain regions is a critical issue in understanding brain functions. There is a lack of an appropriate approach which is capable of 1) measuring the direction and strength of synchronization of activities of multiple brain regions, and 2) adapting to the quickly increasing sizes and scales of neural signals. Nonlinear Interdependence (NLI) analysis is an effective method for measuring synchronization direction and strength of bivariate neural signal. However, the method currently does not directly apply in handling multivariate signal. Its application in practice has also long been largely hampered by the ultra-high complexity of NLI algorithms. Aiming at these problems, this study 1) extends the conventional NLI to quantify the global synchronization of multivariate neural signals, and 2) develops a parallelized NLI method with general-purpose computing on the graphics processing unit (GPGPU), namely, G-NLI. The approach performs synchronization measurement in a massively parallel manner. The G-NLI has improved the runtime performance by more than 1000 times comparing to the original sequential NLI. Meanwhile, the G-NLI was employed to analyze 10-channel local field potential (LFP) recordings from a patient suffering from temporal lobe epilepsy. The results demonstrate that the proposed G-NLI method can support real-time global synchronization measurement and it could be successful in localization of epileptic focus.","synchronisation,
bioelectric potentials,
diseases,
electroencephalography,
general purpose computers,
graphics processing units,
medical disorders,
medical signal processing,
neurophysiology"
Segmentation of PET Images for Computer-Aided Functional Quantification of Tuberculosis in Small Animal Models,"Pulmonary infections often cause spatially diffuse and multi-focal radiotracer uptake in positron emission tomography (PET) images, which makes accurate quantification of the disease extent challenging. Image segmentation plays a vital role in quantifying uptake due to the distributed nature of immuno-pathology and associated metabolic activities in pulmonary infection, specifically tuberculosis (TB). For this task, thresholding-based segmentation methods may be better suited over other methods; however, performance of the thresholding-based methods depend on the selection of thresholding parameters, which are often suboptimal. Several optimal thresholding techniques have been proposed in the literature, but there is currently no consensus on how to determine the optimal threshold for precise identification of spatially diffuse and multi-focal radiotracer uptake. In this study, we propose a method to select optimal thresholding levels by utilizing a novel intensity affinity metric within the affinity propagation clustering framework. We tested the proposed method against 70 longitudinal PET images of rabbits infected with TB. The overall dice similarity coefficient between the segmentation from the proposed method and two expert segmentations was found to be 91.25 ±8.01% with a sensitivity of 88.80 ±12.59% and a specificity of 96.01 ±9.20%. High accuracy and heightened efficiency of our proposed method, as compared to other PET image segmentation methods, were reported with various quantification metrics.","Positron emission tomography,
Histograms,
Lesions,
Image segmentation,
Lungs,
Rabbits,
Diseases"
Breast Nodules Computer-Aided Diagnostic System Design Using Fuzzy Cerebellar Model Neural Networks,"Since the mortality rate of breast cancer in women is gradually increasing, a well-designed computer-aided diagnosis (CAD) system can assist doctors in early diagnosis of the breast cancer. In this paper, a breast nodule CAD system is developed, and this system aims for a high-performance classifier for characterizing breast nodules as either benign or malignant on an ultrasonic image. A fuzzy cerebellar model neural network (FCMNN) CAD system is developed. Since the FCMNN contains the layers with overlapped membership functions, it possesses more generalization ability than a conventional fuzzy neural network. Moreover, a FCMNN can be viewed as a generation of a fuzzy neural network; if each layer of FCMNN is reduced to contain only one different neuron, then the FCMNN can be reduced to a fuzzy neural network. Thus, it is used to develop a CAD system; this is a novel research on a breast nodule ultrasound image CAD system using an FCMNN. The testing of 65 practical ultrasound images demonstrates that the proposed FCMNN CAD system can distinguish benign or malignant breast nodules with relatively high accuracy (more than 90%), and the intensive experimental results where the resulting classifier outperforms other classifiers, such as a support vector machine and a neural network by using the N -folds cross-validation method are shown. The experimental results are even higher than doctor's diagnosis; therefore, the proposed diagnostic system can serve as an assistant system to help doctors correctly diagnose breast nodules.","biomedical ultrasonics,
CAD,
fuzzy neural nets,
medical image processing,
support vector machines"
Toward Accurate Human Tracking: Modeling Time-of-Arrival for Wireless Wearable Sensors in Multipath Environment,"For time-of-arrival-(TOA)-based indoor human tracking system, the wireless channel between human body surface and external reference node can be regarded as the source of inaccuracy. Since only the arrival time of direct path provides accurate range estimate, the nonline of sight caused by human body leads to undetectable direct path condition and thus results in a significant distance measurement error. In this paper, we measured TOA ranging error for indoor human tracking applications inside a typical office environment. A large number of TOA ranging samples was obtained and statistically analyzed. The TOA ranging error was modeled as a Gaussian random variable with the parameters, including position of target sensor, angle between human facing direction, and direction of transmitter-receiver, signal-to-noise ratio, and bandwidth of the system. As a validation of proposed model, excellent agreement has been found between empirical measurement and model-based software simulation.","Distance measurement,
Sensors,
Bandwidth,
Antenna measurements,
Signal to noise ratio,
Wireless sensor networks,
Wireless communication"
Robust Recovery of Corrupted Low-RankMatrix by Implicit Regularizers,"Low-rank matrix recovery algorithms aim to recover a corrupted low-rank matrix with sparse errors. However, corrupted errors may not be sparse in real-world problems and the relationship between ℓ1 regularizer on noise and robust M-estimators is still unknown. This paper proposes a general robust framework for low-rank matrix recovery via implicit regularizers of robust M-estimators, which are derived from convex conjugacy and can be used to model arbitrarily corrupted errors. Based on the additive form of half-quadratic optimization, proximity operators of implicit regularizers are developed such that both low-rank structure and corrupted errors can be alternately recovered. In particular, the dual relationship between the absolute function in ℓ1 regularizer and Huber M-estimator is studied, which establishes a connection between robust low-rank matrix recovery methods and M-estimators based robust principal component analysis methods. Extensive experiments on synthetic and real-world data sets corroborate our claims and verify the robustness of the proposed framework.",
Controllability of switched infinite-dimensional linear dynamical systems,"During last few years switched both linear and nonlinear control systems have been considered in many papers and monographs. However, most of the results are given for finite-dimensional switched system. In this paper we shall present results concerning controllability of infinite-dimensional linear discrete-time switched systems. For controllability analysis of switched linear control systems there is much more difficult situation because we have to determined the control input and the switching rule. Thus, the interaction between them is very important from controllability point of view. In this paper using results taken directly from linear operators in Hilbert spaces we shall present a survey (without proofs) of the new results on controllability for linear discrete-time switched dynamical systems with unconstrained admissible controls.",
Visual Words Assignment Via Information-Theoretic Manifold Embedding,"Codebook-based learning provides a flexible way to extract the contents of an image in a data-driven manner for visual recognition. One central task in such frameworks is codeword assignment, which allocates local image descriptors to the most similar codewords in the dictionary to generate histogram for categorization. Nevertheless, existing assignment approaches, e.g., nearest neighbors strategy (hard assignment) and Gaussian similarity (soft assignment), suffer from two problems: 1) too strong Euclidean assumption and 2) neglecting the label information of the local descriptors. To address the aforementioned two challenges, we propose a graph assignment method with maximal mutual information (GAMI) regularization. GAMI takes the power of manifold structure to better reveal the relationship of massive number of local features by nonlinear graph metric. Meanwhile, the mutual information of descriptor-label pairs is ultimately optimized in the embedding space for the sake of enhancing the discriminant property of the selected codewords. According to such objective, two optimization models, i.e., inexact-GAMI and exact-GAMI, are respectively proposed in this paper. The inexact model can be efficiently solved with a closed-from solution. The stricter exact-GAMI nonparametrically estimates the entropy of descriptor-label pairs in the embedding space and thus leads to a relatively complicated but still trackable optimization. The effectiveness of GAMI models are verified on both the public and our own datasets.","Manifolds,
Mutual information,
Optimization,
Histograms,
Measurement,
Visualization,
Entropy"
HIV Haplotype Inference Using a Propagating Dirichlet Process Mixture Model,"This paper presents a new computational technique for the identification of HIV haplotypes. HIV tends to generate many potentially drug-resistant mutants within the HIV-infected patient and being able to identify these different mutants is important for efficient drug administration. With the view of identifying the mutants, we aim at analyzing short deep sequencing data called reads. From a statistical perspective, the analysis of such data can be regarded as a nonstandard clustering problem due to missing pairwise similarity measures between non-overlapping reads. To overcome this problem we propagate a Dirichlet Process Mixture Model by sequentially updating the prior information from successive local analyses. The model is verified using both simulated and real sequencing data.","Sequential analysis,
Human immunodeficiency virus,
Drugs,
Analytical models,
Data models"
Evaluation of On-Board Photovoltaic Modules Options for Electric Vehicles,"This paper presents an overview of different commercial photovoltaic (PV) module options to power on-board electric vehicles (EVs). We propose the evaluation factors, constraints, and the decision-making criteria necessary to assess the suitability of this PV module for this application. The incorporation of quality function deployment (QFD) and the analytical hierarchy process (AHP) is the decision-making methodology used in this study. Our approach is innovative and robust in that the evaluation depends upon data collected from PV manufactures datasheets. Unlike traditional research, a hybrid AHP and QFD innovative decision-making methodology has been created, and current commercial PV market data for all pairwise comparisons are used to show that methodology. Using both cooled and uncooled PV modules, best, intermediate, and worst-case scenarios were used to estimate the driving ranges of lightweight EVs powered exclusively by bulk silicon PV modules. Results showed that the available daily driving ranges were between 25 and 60 km and that the CO2 emissions were reduced between 3 and 6.5 kg, compared with internal combustion vehicles of a similar type. We found that mono-Si PV modules were most suited to power low-speed, lightweight, and aerodynamically efficient EVs.","Quality function deployment,
Decision making,
Solar energy,
Photovoltaic cells,
Electric vehicles"
A Construction of New Quantum MDS Codes,"It has been a great challenge to construct new quantum maximum-distance-separable (MDS) codes. In particular, it is very hard to construct the quantum MDS codes with relatively large minimum distance. So far, except for some sparse lengths, all known q-ary quantum MDS codes have minimum distance ≤q/2 + 1. In this paper, we provide a construction of the quantum MDS codes with minimum distance >q/2 + 1. In particular, we show the existence of the q-ary quantum MDS codes with length n = q2 + 1 and minimum distance d for any d q + 1 (this result extends those given in the works of Guardia (2011), Jin et al. (2010), and Kai an Zhu (2012)); and with length (q2 + 2)/3 and minimum distance d for any d (2q+2)/3 if 3|(q + 1). Our method is through Hermitian selforthogonal codes. The main idea of constructing the Hermitian self-orthogonal codes is based on the solvability in Fq of a system of homogenous equations over Fq2.","Equations,
Quantum mechanics,
Educational institutions,
Reed-Solomon codes,
Vectors,
Linear codes"
MDD-Based Method for Efficient Analysis on Phased-Mission Systems With Multimode Failures,"Many practical systems are phased-mission systems with multimode failures (MFPMSs) where the mission consists of multiple nonoverlapping phases of operation, and the system components may assume more than one failure mode. In MFPMSs, dependence arises among different phases and among different failure modes of the same component, which makes the reliability analysis of MFPMSs difficult. This paper proposes a new analytical method based on multivalued decision diagrams (MDDs) for the reliability analysis of nonrepairable MFPMSs. MDDs have recently been applied to the reliability analysis of single-phase systems with multiple component states. In this paper, we make the new contribution by proposing a novel way to adapt MDDs for the reliability analysis of systems with multiple phases and multimode failures. Examples show how the MDD models are generated and evaluated to obtain the mission reliability measures. Performance of the MDD-based method is compared with an existing binary decision diagram (BDD)-based method for MFPMS analysis through several examples and a comprehensive benchmark study. Empirical results show that the proposed MDD-based method can offer lower computational complexity and simpler model construction and evaluation algorithms than the BDD-based method, and it can be effectively applied to large practical cases.",
HOG active appearance models,"We propose the combination of dense Histogram of Oriented Gradients (HOG) features with Active Appearance Models (AAMs). We employ the efficient Inverse Compositional optimization technique and show results for the task of face fitting. By taking advantage of the descriptive characteristics of HOG features, we build robust and accurate AAMs that generalize well to unseen faces with illumination, identity, pose and occlusion variations. Our experiments on challenging in-the-wild databases show that HOG AAMs significantly outperfrom current state-of-the-art results of discriminative methods trained on larger databases.","Shape,
Active appearance model,
Face,
Databases,
Integrated circuits,
Pattern recognition"
Performance Analysis of Relay-Assisted All-Optical FSO Networks Over Strong Atmospheric Turbulence Channels With Pointing Errors,"In this study, we consider a relay-assisted free-space optical communication scheme over strong atmospheric turbulence channels with misalignment-induced pointing errors. The links from the source to the destination are assumed to be all-optical links. Assuming a variable gain relay with amplify-and-forward protocol, the electrical signal at the source is forwarded to the destination with the help of this relay through all-optical links. More specifically, we first present a cumulative density function (CDF) analysis for the end-to-end signal-to-noise ratio. Based on this CDF, the outage probability, bit-error rate, and average capacity of our proposed system are derived. Results show that the system diversity order is related to the minimum value of the channel parameters.","Relays,
Bit error rate,
Adaptive optics,
System performance,
High-speed optical techniques,
Signal to noise ratio,
Wireless communication"
A Random Decision Tree Framework for Privacy-Preserving Data Mining,"Distributed data is ubiquitous in modern information driven applications. With multiple sources of data, the natural challenge is to determine how to collaborate effectively across proprietary organizational boundaries while maximizing the utility of collected information. Since using only local data gives suboptimal utility, techniques for privacy-preserving collaborative knowledge discovery must be developed. Existing cryptography-based work for privacy-preserving data mining is still too slow to be effective for large scale data sets to face today's big data challenge. Previous work on random decision trees (RDT) shows that it is possible to generate equivalent and accurate models with much smaller cost. We exploit the fact that RDTs can naturally fit into a parallel and fully distributed architecture, and develop protocols to implement privacy-preserving RDTs that enable general and efficient distributed privacy-preserving knowledge discovery.","Decision trees,
Vectors,
Protocols,
Vegetation,
Data mining,
Encryption"
Mitigation of Inverter-Grid Harmonic Resonance by Narrow-Band Damping,This paper deals with damping of resonance between grid-connected inverters and the power grid. This paper proposes a narrow-band digital filtering technique to resolve the resonance problem by shaping the inverter output impedance at selected frequencies without affecting the characteristics of the inverter outside the selected frequency range. A frequency-sampling method is used to implement the narrow-band digital filter which allows direct control of the filter's amplitude and phase response in accordance with damping requirements. The experimental results are presented to demonstrate the performance of the proposed method.,"Impedance,
Inverters,
Resonant frequency,
Power harmonic filters,
Damping,
Discrete Fourier transforms,
Narrowband"
A Comprehensive Study of Sampling-Based Optimum Signal Detection in Concentration-Encoded Molecular Communication,"In this paper, a comprehensive analysis of the sampling-based optimum signal detection in ideal (i.e., free) diffusion-based concentration-encoded molecular communication (CEMC) system has been presented. A generalized amplitude-shift keying (ASK)-based CEMC system has been considered in diffusion-based noise and intersymbol interference (ISI) conditions. Information is encoded by modulating the amplitude of the transmission rate of information molecules at the TN. The critical issues involved in the sampling-based receiver thus developed are addressed in detail, and its performance in terms of the number of samples per symbol, communication range, and transmission data rate is evaluated. ISI produced by the residual molecules deteriorates the performance of the CEMC system significantly, which further deteriorates when the communication range and/or the transmission data rate increase(s). In addition, the performance of the optimum receiver depends on the receiver's ability to compute the ISI accurately, thus providing a trade-off between receiver complexity and achievable bit error rate (BER). Exact and approximate detection performances have been derived. Finally, it is found that the sampling-based signal detection scheme thus developed can be applied to both binary and multilevel (M-ary) ASK-based CEMC systems, although M-ary systems suffer more from higher BER.","Nanobioscience,
Receivers,
Signal detection,
Sensors,
Stochastic processes,
Molecular communication,
Noise"
Hardware Implementation of an Automatic Adaptive Centralized Underfrequency Load Shedding Scheme,"The underfrequency load shedding (UFLS) mostly used in industry is a decentralized deterministic scheme designed to shed a prespecified amount of load after a predetermined time delay. It sheds the same amount of load from the same location irrespective of how fast the frequency drops and without consideration of the disturbance location or dip in bus voltage. Recent studies focused on adaptive UFLS, but these studies are still based on software simulation. This study presents an implementation of a real-time centralized adaptive UFLS scheme using industry-grade hardware. It estimates the amount of load to be shed based on the rate of frequency decline and distributes the load to be shed among the load buses based on the voltage dip at these buses. The UFLS in this study is implemented using a real-time digital simulator, phasor measurement units embedded in the relays, a global positioning system clock, and a synchrophasor vector processor. The load is modelled as a mixture of dynamic and static load. The implemented scheme restored the system frequency and voltage. The results emphasize its adaptability and suitability for implementation in industry.","Phasor measurement units,
Real-time systems,
Load modeling,
Power system stability,
Generators,
Relays,
Mathematical model"
Multi-Observation Blind Deconvolution with an Adaptive Sparse Prior,"This paper describes a robust algorithm for estimating a single latent sharp image given multiple blurry and/or noisy observations. The underlying multi-image blind deconvolution problem is solved by linking all of the observations together via a Bayesian-inspired penalty function, which couples the unknown latent image along with a separate blur kernel and noise variance associated with each observation, all of which are estimated jointly from the data. This coupled penalty function enjoys a number of desirable properties, including a mechanism whereby the relative-concavity or sparsity is adapted as a function of the intrinsic quality of each corrupted observation. In this way, higher quality observations may automatically contribute more to the final estimate than heavily degraded ones, while troublesome local minima can largely be avoided. The resulting algorithm, which requires no essential tuning parameters, can recover a sharp image from a set of observations containing potentially both blurry and noisy examples, without knowing a priori the degradation type of each observation. Experimental results on both synthetic and real-world test images clearly demonstrate the efficacy of the proposed method.",
Impact of Technology Scaling on SRAM Soft Error Rates,"Soft error rates for triple-well and dual-well SRAM circuits over the past few technology generations have shown an apparently inconsistent behavior. This work compares the heavy-ion induced upset cross-section in 28, 40, and 65 nm dual- and triple-well SRAMs over a wide range of particle LETs. Similar experiments on identical layouts for all these technologies along with 3-D TCAD simulations are used to identify the dominant mechanisms for single-event upsets. Results demonstrate that the well-engineering strongly influence the single-event response of SRAMs. Layout also plays an important role and the combined effects of well-engineering and layout determine the soft-error sensitivity of SRAMs fabricated in advanced technology nodes.",
Correlated Orienteering Problem and its application to informative path planning for persistent monitoring tasks,"We propose a novel non-linear extension to the Orienteering Problem (OP), called the Correlated Orienteering Problem (COP). We use COP to plan informative tours (cyclic paths) for persistent monitoring of an environment with spatial correlations, where the tours are constrained to a fixed length or time budget. The main feature of COP is a quadratic utility function that captures spatial correlations among points of interest that are close to each other. COP may be solved using mixed integer quadratic programming (MIQP) that can plan multiple disjoint tours that maximize the quadratic utility function. We perform extensive characterization of our method to verify its correctness, as well as its applicability to the estimation of a realistic, time-varying, and spatially correlated scalar field.","Mathematical model,
Correlation,
Equations,
Computational modeling,
Robot sensing systems,
Monitoring"
TSV-Aware Interconnect Distribution Models for Prediction of Delay and Power Consumption of 3-D Stacked ICs,"3-D integrated circuits (3-D ICs) are expected to have shorter wirelength, better performance, and less power consumption than 2-D ICs. These benefits come from die stacking and use of through-silicon vias (TSVs) fabricated for interconnections across dies. However, the use of TSVs has several negative impacts such as area and capacitance overhead. To predict the quality of 3-D ICs more accurately, TSV-aware 3-D wirelength distribution models considering the negative impacts were developed. In this paper, we apply an optimal buffer insertion algorithm to the TSV-aware 3-D wirelength distribution models and present various prediction results on wirelength, delay, and power consumption of 3-D ICs. We also apply the framework to 2-D and 3-D ICs built with various combinations of process and TSV technologies and predict the quality of today and future 3-D ICs.","Through-silicon vias,
Integrated circuit modeling,
Solid modeling,
Logic gates,
Predictive models,
Computational modeling,
Delays"
Characterization and Reliability of Sintered Nanosilver Joints by a Rapid Current-Assisted Method for Power Electronics Packaging,"A rapid current-assisted sintering technology (CAST) was used to bond electronic devices with nanosilver paste, which is a promising alternative compared with traditional solders. Instead of using an external heating source, the specimen and bonding material of nanosilver paste were heated by the alternating current whose current direction is not constant. Die-shear testing and hardness measurement were used to evaluate the bonding strength. The bonding strength and hardness increase with increasing the current and/or current-on time. CAST was able to sinter nanosilver in a very short time, i.e., less than 1 s. Scanning electron microscopy was used to characterize the microstructures of sintered silver joints. The reliability of the sintered joints by CAST was also evaluated by cyclic shearing tests. The joint by CAST could survive much longer time than that by the conventional hot pressing way. The CAST was recommended to bond two pieces of bare copper with nanosilver paste in power electronic applications without any protective gas atmosphere, e.g., bus bar connection.","Joints,
Silver,
Materials,
Educational institutions,
Copper,
Bonding,
Heating"
Bundled Visualization of DynamicGraph and Trail Data,"Depicting change captured by dynamic graphs and temporal paths, or trails, is hard. We present two techniques for simplified visualization of such data sets using edge bundles. The first technique uses an efficient image-based bundling method to create smoothly changing bundles from streaming graphs. The second technique adds edge-correspondence data atop of any static bundling algorithm, and is best suited for graph sequences. We show how these techniques can produce simplified visualizations of streaming and sequence graphs. Next, we show how several temporal attributes can be added atop of our dynamic graphs. We illustrate our techniques with data sets from aircraft monitoring, software engineering, and eye-tracking of static and dynamic scenes.",
Stochastic Analysis of the LMS and NLMS Algorithms for Cyclostationary White Gaussian Inputs,"This paper studies the stochastic behavior of the LMS and NLMS algorithms for a system identification framework when the input signal is a cyclostationary white Gaussian process. The input cyclostationary signal is modeled by a white Gaussian random process with periodically time-varying power. Mathematical models are derived for the mean and mean-square-deviation (MSD) behavior of the adaptive weights with the input cyclostationarity. These models are also applied to the non-stationary system with a random walk variation of the optimal weights. Monte Carlo simulations of the two algorithms provide strong support for the theory. Finally, the performance of the two algorithms is compared for a variety of scenarios.","Signal processing algorithms,
Adaptation models,
Algorithm design and analysis,
Least squares approximations,
Mathematical model,
Vectors,
Analytical models"
Coded-Aperture Imaging Using Photo-Induced Reconfigurable Aperture Arrays for Mapping Terahertz Beams,"We report terahertz coded-aperture imaging using photo-induced reconfigurable aperture arrays on a silicon wafer. The coded aperture was implemented using programmable illumination from a commercially available digital light processing projector. At 590 GHz, each of the array element apertures can be optically turned on and off with a modulation depth of 20 dB and a modulation rate of ~ 1.3 kHz. Prototype demonstrations of 4 ×4 coded-aperture imaging using Hadamard coding have been performed. Continuous THz imaging with 8 ×8 pixels has also been demonstrated, using a slowly moving metal strip as the target. In addition, this technique has been successfully applied to mapping THz beams by using a 6 ×6 aperture array at 590 GHz. The imaging results agree closely with theoretical calculations based on Gaussian beam propagation, demonstrating that this technique is promising for realizing real-time and low-cost terahertz cameras for many applications. The reported approach provides a simple but powerful means to visualize THz beams, which is highly desired in quasi-optical system alignment, quantum-cascade laser design and characterization, and THz antenna characterization.",
A feasibility study of using a single Kinect sensor for rehabilitation exercises monitoring: A rule based approach,"In this paper, we present a feasibility study for using a single Microsoft Kinect sensor to assess the quality of rehabilitation exercises. Unlike competing studies that have focused on the validation of the accuracy of Kinect motion sensing data at the level of joint positions, joint angles, and displacement of joints, we take a rule based approach. The advantage of our approach is that it provides a concrete context for judging the feasibility of using a single Kinect sensor for rehabilitation exercise monitoring. Our study aims to answer the following question: if it is found that Kinect's measurement on a metric deviates from the ground truth by some amount, is this an acceptable error? By defining a set of correctness rules for each exercise, the question will be answered definitively with no ambiguity. Defining appropriate context in a validation study is especially important because (1) the deviation of Kinect measurement from the ground truth varies significantly for different exercises, even for the same joint, and (2) different exercises have different tolerance levels for the movement restrictions of body segments. In this study, we also show that large but systematic deviations of the Kinect measurement from the ground truth are not as harmful as it seems because the problem can be overcome by adjusting parameters in the correctness rules.","Joints,
Hip,
Shoulder,
Vectors,
Accuracy,
Sensors,
Context"
Phase Current Reconstructions from DC-Link Currents in Three-Phase Three-Level PWM Inverters,"This paper describes phase current reconstruction methods from dc-link currents in three-phase three-level PWM inverters. Since the three-level inverters have three paths between dc-link and power switches, the reconstructions differ from that in two-level inverters which have two paths there. Considering these paths in three-level inverter, this paper proposes the methods for phase current reconstruction. While the reconstruction method is executed by the currents sampled on the dc-links, the system encounters current-unmeasurable areas where the dc currents cannot be sampled due to the lack of measurement time according to the PWM status. This paper analyzes the areas and proposes a minimum voltage injection method for minimizing them to guarantee accurate current reconstruction. The method provides the expanded operating areas especially in low-output voltage operation and the minimized distortions in output voltages. The feasibility of the proposed method has been assessed in experiments.","Inverters,
Vectors,
Sensors,
Current measurement,
Switches,
Voltage measurement,
Pulse width modulation"
CBM: Online Strategies on Cost-Aware Buffer Management for Mobile Video Streaming,"Mobile video traffic, owing to the rapid adoption of smartphones and tablets, has been growing exponentially in recent years and started to dominate the mobile Internet. In reality, mobile video applications commonly adopt buffering techniques to handle bandwidth fluctuation and minimize the impact of stochastic wireless channels on user experiences. However, recent measurement work reveals that mobile users tend to abort more frequently than PC users during viewing videos. Such a high abortion rate results in a significant wastage of buffered video data, which is directly translated into monetary and energy cost for mobile users. In this paper, we propose an intelligent buffer management strategy called CBM (Cost-aware Buffer Management), for mobile video streaming applications. Our purpose is to minimize cost induced by un-consumed video data while respecting certain user experience requirements. To this objective, we formulate the problem into a constrained stochastic optimization problem, and apply the Lyapunov optimization theory to derive the corresponding online strategy for cost minimization. Different from conventional heuristic-based strategies, our proposed CBM strategy can provide provably performance guarantee with explicit bounds. We also conduct extensive simulations to validate the effectiveness of our proposed strategy and our experimental results show that CBM achieves significant gains over existing schemes.","Streaming media,
Mobile communication,
Mobile handsets,
Energy consumption,
Optimization,
Wireless communication,
Educational institutions"
Neural Network Based Pitch Tracking in Very Noisy Speech,"Pitch determination is a fundamental problem in speech processing, which has been studied for decades. However, it is challenging to determinate pitch in strong noise because the harmonic structure is corrupted. In this paper, we estimate pitch using supervised learning, where the probabilistic pitch states are directly learned from noisy speech data. We investigate two alternative neural networks modeling pitch state distribution given observations. The first one is a feedforward deep neural network (DNN), which is trained on static frame-level acoustic features. The second one is a recurrent deep neural network (RNN) which is trained on sequential frame-level features and capable of learning temporal dynamics. Both DNNs and RNNs produce accurate probabilistic outputs of pitch states, which are then connected into pitch contours by Viterbi decoding. Our systematic evaluation shows that the proposed pitch tracking algorithms are robust to different noise conditions and can even be applied to reverberant speech. The proposed approach also significantly outperforms other state-of-the-art pitch tracking algorithms.",
Permission-combination-based scheme for Android mobile malware detection,"With the increase use of Android mobile phones, more Android malwares are being developed. Android malware detection becomes a crucial task. In this paper, we present a permission-combination-based scheme for Android malware detection. The Android malware detection scheme is based on permission combinations declared in the application manifest file. We obtain the permission combinations that are requested frequently by malwares but rarely by benign applications. We generate rule sets based on the permission combinations. Our experimental results show that the malware detection rate is up to 96%, and the benign application recognition rate is up to 88%. Our experimental results with real malwares show that the Android malware detection scheme is very efficient and effective.","Malware,
Smart phones,
Internet,
Mobile communication,
Androids,
Humanoid robots,
Mobile computing"
"Analysis of Human Grasping Behavior: Correlating Tasks, Objects and Grasps","This paper is the second in a two-part series analyzing human grasping behavior during a wide range of unstructured tasks. It investigates the tasks performed during the daily work of two housekeepers and two machinists and correlates grasp type and object properties with the attributes of the tasks being performed. The task or activity is classified according to the force required, the degrees of freedom, and the functional task type. We found that 46 percent of tasks are constrained, where the manipulated object is not allowed to move in a full six degrees of freedom. Analyzing the interrelationships between the grasp, object, and task data show that the best predictors of the grasp type are object size, task constraints, and object mass. Using these attributes, the grasp type can be predicted with 47 percent accuracy. Those parameters likely make useful heuristics for grasp planning systems. The results further suggest the common sub-categorization of grasps into power, intermediate, and precision categories may not be appropriate, indicating that grasps are generally more multi-functional than previously thought. We find large and heavy objects are grasped with a power grasp, but small and lightweight objects are not necessarily grasped with precision grasps-even with grasped object size less than 2 cm and mass less than 20 g, precision grasps are only used 61 percent of the time. These results have important implications for robotic hand design and grasp planners, since it appears while power grasps are frequently used for heavy objects, they can still be quite practical for small, lightweight objects.","Grasping,
Shape analysis,
Robots,
Thumb"
Efficient resource allocation for mobile social networks in D2D communication underlaying cellular networks,"With the fast development of mobile terminals and wireless communication networks, mobile social networks (MSNs) play an important role in everyday lives to access social activities. However, most research on MSNs typically focuses on the relations of the users' physical location, but not make sufficient use of social ties. Consequently, in this paper, we consider a scenario of MSNs with online social networks and offline Device-to-Device (D2D) communication underlaying cellular networks, and study the problem of data dissemination to the mobile users under the constraint of limited spectrum resources. We first present a novel approach to formulate the social relationships for the offline mobiles by comparing the similarity of mobile users' social activities with the Bayesian model. And then we realize efficient data propagation using coalitional graph game. Finally, we provide simulation results to verify effectiveness of our studies.",
Formation movements in minimally rigid formation control with mismatched mutual distances,"When a gradient descent control law is employed for stabilizing undirected minimally rigid formations, mismatched desired distances between neighboring agent pairs will cause additional motions of the whole formation. By reviewing and extending the results in [1], [2], we show that in general rotational motions and helical motions will occur for 2-D formations and 3-D formations, respectively. We then consider the problem of how to compute the formulas for the motions caused by constant mismatches. A novel idea based on the angular-momentum concept in rigid body dynamics is proposed for deriving the formation formulas, e.g., angular velocity, rotational radius, etc. in terms of the distance mismatch terms. This has implications on steering and controlling rigid formation motions.","Vectors,
Equations,
Shape,
Mathematical model,
Angular velocity,
Symmetric matrices,
Sun"
Multivariable Dynamic Ankle Mechanical Impedance With Relaxed Muscles,"Neurological or biomechanical disorders may distort ankle mechanical impedance and thereby impair locomotor function. This paper presents a quantitative characterization of multivariable ankle mechanical impedance of young healthy subjects when their muscles were relaxed, to serve as a baseline to compare with pathophysiological ankle properties of biomechanically and/or neurologically impaired patients. Measurements using a highly backdrivable wearable ankle robot combined with multi-input multi-output stochastic system identification methods enabled reliable characterization of ankle mechanical impedance in two degrees-of-freedom (DOFs) simultaneously, the sagittal and frontal planes. The characterization included important ankle properties unavailable from single DOF studies: coupling between DOFs and anisotropy as a function of frequency. Ankle impedance in joint coordinates showed responses largely consistent with a second-order system consisting of inertia, viscosity, and stiffness in both seated (knee flexed) and standing (knee straightened) postures. Stiffness in the sagittal plane was greater than in the frontal plane and furthermore, was greater when standing than when seated, most likely due to the stretch of bi-articular muscles (medial and lateral gastrocnemius). Very low off-diagonal partial coherences implied negligible coupling between dorsiflexion-plantarflexion and inversion-eversion. The directions of principal axes were tilted slightly counterclockwise from the original joint coordinates. The directional variation (anisotropy) of ankle impedance in the 2-D space formed by rotations in the sagittal and frontal planes exhibited a characteristic “peanut” shape, weak in inversion-eversion over a wide range of frequencies from the stiffness dominated region up to the inertia dominated region. Implications for the assessment of neurological and biomechanical impairments are discussed.","Bioimpedance,
Joints,
Actuators,
Biomedical engineering,
Muscles,
Biomechanics,
Patient rehabilitation"
Robust Face Recognition With Structurally Incoherent Low-Rank Matrix Decomposition,"For the task of robust face recognition, we particularly focus on the scenario in which training and test image data are corrupted due to occlusion or disguise. Prior standard face recognition methods like Eigenfaces or state-of-the-art approaches such as sparse representation-based classification did not consider possible contamination of data during training, and thus their recognition performance on corrupted test data would be degraded. In this paper, we propose a novel face recognition algorithm based on low-rank matrix decomposition to address the aforementioned problem. Besides the capability of decomposing raw training data into a set of representative bases for better modeling the face images, we introduce a constraint of structural incoherence into the proposed algorithm, which enforces the bases learned for different classes to be as independent as possible. As a result, additional discriminating ability is added to the derived base matrices for improved recognition performance. Experimental results on different face databases with a variety of variations verify the effectiveness and robustness of our proposed method.",
Channel Estimation in CP-OQAM-OFDM Systems,"Due to the insertion of cyclic prefix (CP), orthogonal-frequency-division multiplexing (OFDM) systems with offset quadrature amplitude modulation (OQAM) (OQAM-OFDM) and CP, denoted as CP-OQAM-OFDM, systems have more robustness to combat a multi-path fading channel and simpler and better receivers than the conventional OQAM-OFDM systems. In this paper, two channel estimators, i.e., weighted least square (WLS) and pairs of pilots (POP) are presented in CP-OQAM-OFDM systems. To evaluate the proposed WLS and POP estimators, the corresponding Cramér-Rao bounds are given for comparison. In addition, the computational complexities of the proposed estimators are analyzed as well. Simulation results demonstrate that both of the proposed channel estimators can achieve good bit error rate (BER) performance.","Channel estimation,
OFDM,
Equalizers,
Delays,
Quadrature amplitude modulation,
Receivers,
Wireless communication"
Islanding Detection for Inverter-Based Distributed Generation Using Support Vector Machine Method,"In this paper, a new islanding detection method for single phase inverter-based distributed generation is presented. In the first stage of the proposed method, a parametric technique called autoregressive signal modeling is utilized to extract signal features from voltage and current signals at the point of common coupling with the grid. In the second stage, advanced machine learning technique based on support vector machine, which takes calculated features as inputs is utilized to predict islanding state. The extensive study is performed on the IEEE 13 bus system and feature vectors corresponding to various islanding and nonislanding conditions are used for support vector machine classifier training and testing. Simulation results show that the proposed method can accurately detect system islanding operation mode 50 ms after the event starts. Further, the robustness of the proposed method is analyzed by examining its performances in the systems with multiple distributed generations, and when system loading condition, grid disturbance types, and characteristics are altered.","Support vector machines,
Feature extraction,
Reactive power,
Islanding,
Autoregressive processes,
Robustness"
From Fuzzy Cognitive Maps to Granular Cognitive Maps,"Fuzzy cognitive maps (FCMs) form a class of graph-oriented fuzzy models describing causal relationships among concepts. In this study, we augment these models by introducing their generalization coming in the form of granular FCMs. In contrast with FCMs, in the granular FCMs, the connections between the nodes (states) are described in the form of information granules, especially intervals and fuzzy sets. Key scenarios in which granular models (and granular FCMs) arise are presented in order to offer a compelling rationale behind the formation of such models. In the context of system modeling, we show that information granularity emerges as an important design asset. We discuss detailed schemes of allocation of information granularity and quantify a performance of the resulting granular FCM in terms of a coverage criterion. For illustrative purposes, the detailed studies are completed for granular FCMs with interval-valued connections.","Numerical models,
Fuzzy cognitive maps,
Data models,
Fuzzy sets,
Resource management,
Computational modeling,
Optimization"
mPASS: Integrating people sensing and crowdsourcing to map urban accessibility,"This paper presents mPASS (mobile Pervasive Accessibility Social Sensing), a system designed to collect data about urban and architectural accessibility and to provide users with personalized paths, computed on the basis of their preferences and needs. The system combines data obtained by sensing, crowdsourcing and mashing-up with main geo-referenced social systems, with the aim of offering services based on a detailed and valid data set.","Sensors,
Routing,
Conferences,
Crowdsourcing,
Mobile communication,
Wheelchairs,
Organizations"
Assessing effect sizes of influence factors towards a QoE model for HTTP adaptive streaming,"HTTP Adaptive Streaming (HAS) is employed by more and more video streaming services in the Internet. It allows to adapt the downloaded video quality to the current network conditions, and thus, avoids stalling (i.e., playback interruptions) to the greatest possible extend. The adaptation of video streams is done by switching between different quality representation levels, which influences the user perceived quality of the video stream. In this work, the influence of several adaptation parameters, namely, switch amplitude (i.e., quality level difference), switching frequency, and recency effects, on Quality of Experience (QoE) is investigated. Therefore, crowdsourcing experiments were conducted in order to collect subjective ratings for different adaptation-related test conditions. The results of these subjective studies indicate the influence of the adaptation parameters, and based on these findings a simplified QoE model for HAS is presented, which only relies on the switch amplitude and the playback time of each layer.","Switches,
Streaming media,
Crowdsourcing,
Video recording,
Quality assessment,
Time-frequency analysis,
Bars"
A Cascaded Microsecond-Pulse Generator for Discharge Applications,"Gas discharges using pulsed power are a promising and efficient approach for producing low-temperature plasmas at atmospheric pressure. Pulsed power generators vary widely in performance and should be chosen according to the load and application requirements. In this paper, a microsecond-pulselength high voltage (HV) generator is developed for atmospheric-pressure plasma jets that use a cascade-type voltage circuit. The electrical parameters including voltage amplitude, pulse repetition frequency, and pulsewidth, are determined by the trigger system. The voltage amplitude can be up to 10 kV and the pulse repetition frequency varies from 1 Hz to 5 kHz. The unipolar output pulse can be either positive or negative, with either square or triangular wave profile that can also be controlled by the optical trigger system. When the output pulse is a square wave, the rising edge is about 100 ns, the falling edge is approximately 2~μs, and the pulsewidth at the top varies from 0.5 to 30 μs. When the output pulse is a triangular wave, the base of the pulse is from 7 to 62 μs, and the stepped rising edge is from 5 to 30 μs. The HV pulse generator is used for producing helium plasma jets into open air. Preliminary experimental data show the effects of the pulse voltage amplitude, pulse repetition frequency, and pulsewidth on plasma jets, and confirm that the generator can provide a good performance for driving cold plasma jets.",
Automated composition of motion primitives for multi-robot systems from safe LTL specifications,"We present a compositional motion planning framework for multi-robot systems based on an encoding to satisfiability modulo theories (SMT). In our framework, the desired behavior of a group of robots is specified using a set of safe linear temporal logic (LTL) properties. Our method relies on a library of motion primitives, each of which corresponds to a controller that ensures a particular trajectory in a given configuration. Using the closed-loop behavior of the robots under the action of different controllers, we formulate the motion planning problem as an SMT solving problem and use an off-the-shelf SMT solver to generate trajectories for the robots. Our approach can also be extended to synthesize optimal cost trajectories where optimality is defined with respect to the available motion primitives. Experimental results show that our framework can efficiently solve complex motion planning problems in the context of multi-robot systems.",
A Novel Layout Decomposition Algorithm for Triple Patterning Lithography,"While double patterning lithography (DPL) has been widely recognized as one of the most promising solutions for the sub-22 nm technology node to enhance pattern printability, triple patterning lithography (TPL) will be required for gate, contact, and metal-1 layers which are too complex and dense to be split into only two masks, for the 15 nm technology node and beyond. Nevertheless, there is very little research focusing on the layout decomposition for TPL. Recent work proposed the first systematic study on the layout decomposition for TPL. However, the proposed algorithm extending a stitch-finding method used in DPL may miss legal stitch locations and generate conflicts that can be resolved by inserting stitches for TPL. In this paper, we point out two main differences between DPL and TPL layout decompositions. Based on the two differences, we propose a novel TPL layout decomposition algorithm. We first present two new graph reduction techniques to reduce the problem size without degrading overall solution quality. We then propose a stitch-aware mask assignment algorithm, based on a heuristic that finds a mask assignment such that the conflicts among the features in the same mask are more likely to be resolved by inserting stitches. Finally, stitches are inserted to resolve as many conflicts as possible. Experimental results show that the proposed layout decomposition algorithm can achieve around 56% reduction of conflicts and more than 40X speed-up, as compared to the previous work.",
Identification of Nonlinear Dynamic System Using a Novel Recurrent Wavelet Neural Network Based on the Pipelined Architecture,"This paper presents a novel modular recurrent neural network based on the pipelined architecture (PRWNN) to reduce the computational complexity and improve the performance of the recurrent wavelet neural network (RWNN). The PRWNN inherits the modular architectures of the pipelined recurrent neural network proposed by Haykin and Li and is made up of a number of RWNN modules that are interconnected in a chained form. Since those modules of the PRWNN can be simultaneously performed in a pipelined parallelism fashion, this would lead to a crucial improvement of computational efficiency. Furthermore, owing to the cascade interconnection of dynamic modules, the performance of the PRWNN can be further enhanced. An adaptive gradient algorithm based on the real-time recurrent learning is derived to suit for the modular PRWNN. Simulation examples are given to evaluate the effectiveness of the PRWNN model on the identification of nonlinear dynamic systems and analysis of sunspot number time series. According to simulation results, it is clearly shown that the PRWNN provides impressive better performance in comparison with the single RWNN model.",
An Adaptive Approach to Real-Time Aggregate Monitoring With Differential Privacy,"Sharing real-time aggregate statistics of private data is of great value to the public to perform data mining for understanding important phenomena, such as Influenza outbreaks and traffic congestion. However, releasing time-series data with standard differential privacy mechanism has limited utility due to high correlation between data values. We propose FAST, a novel framework to release real-time aggregate statistics under differential privacy based on filtering and adaptive sampling. To minimize the overall privacy cost, FAST adaptively samples long time-series according to the detected data dynamics. To improve the accuracy of data release per time stamp, FAST predicts data values at non-sampling points and corrects noisy observations at sampling points. Our experiments with real-world as well as synthetic data sets confirm that FAST improves the accuracy of released aggregates even under small privacy cost and can be used to enable a wide range of monitoring applications.",
Semantic Pyramids for Gender and Action Recognition,"Person description is a challenging problem in computer vision. We investigated two major aspects of person description: 1) gender and 2) action recognition in still images. Most state-of-the-art approaches for gender and action recognition rely on the description of a single body part, such as face or full-body. However, relying on a single body part is suboptimal due to significant variations in scale, viewpoint, and pose in real-world images. This paper proposes a semantic pyramid approach for pose normalization. Our approach is fully automatic and based on combining information from full-body, upper-body, and face regions for gender and action recognition in still images. The proposed approach does not require any annotations for upper-body and face of a person. Instead, we rely on pretrained state-of-the-art upper-body and face detectors to automatically extract semantic information of a person. Given multiple bounding boxes from each body part detector, we then propose a simple method to select the best candidate bounding box, which is used for feature extraction. Finally, the extracted features from the full-body, upper-body, and face regions are combined into a single representation for classification. To validate the proposed approach for gender recognition, experiments are performed on three large data sets namely: 1) human attribute; 2) head-shoulder; and 3) proxemics. For action recognition, we perform experiments on four data sets most used for benchmarking action recognition in still images: 1) Sports; 2) Willow; 3) PASCAL VOC 2010; and 4) Stanford-40. Our experiments clearly demonstrate that the proposed approach, despite its simplicity, outperforms state-of-the-art methods for gender and action recognition.","Detectors,
Face,
Semantics,
Image recognition,
Feature extraction,
Computer vision,
Face recognition"
Design of GaN Doherty Power Amplifiers for Broadband Applications,"This letter presents a modified Doherty power amplifier (DPA) architecture to release bandwidth limitation of the conventional DPA. The proposed DPA structure eliminates two quarter wavelength impedance inverters used in the conventional DPAs. Instead, both the carrier and peak amplifiers in the proposed DPA are matched to 70 Ω at the output ports, which enables an easier implementation of broadband matching networks. Broadband input matching network (IMN) and output matching network (OMN) are then designed to achieve wideband DPA with enhanced performance. To verify the design concept, a broadband DPA is designed, fabricated, and measured on a RT/Duroid 5880 substrate with 2.2 dielectric constant and 0.787 mm substrate thickness. In the working frequency bands (0.8 to 1.2 GHz), the designed DPA provides 50.8% to 78.5% power-added efficiency (PAE) at full output power, 30.3% to 40.1% PAE at 6 dB of output power back-off (OBO), 10.8 to 14.8 dB gain (the gain variation is within 2.6 dB over different input power levels at each specific frequency), and maximum output power between 40.2 and 42.9 dBm.","Impedance,
Bandwidth,
Broadband amplifiers,
Gallium nitride,
Gain,
Inverters"
Learning Locality Preserving Graph from Data,"Machine learning based on graph representation, or manifold learning, has attracted great interest in recent years. As the discrete approximation of data manifold, the graph plays a crucial role in these kinds of learning approaches. In this paper, we propose a novel learning method for graph construction, which is distinct from previous methods in that it solves an optimization problem with the aim of directly preserving the local information of the original data set. We show that the proposed objective has close connections with the popular Laplacian Eigenmap problem, and is hence well justified. The optimization turns out to be a quadratic programming problem with n(n - 1)/2 variables (n is the number of data points). Exploiting the sparsity of the graph, we further propose a more efficient cutting plane algorithm to solve the problem, making the method better scalable in practice. In the context of clustering and semi-supervised learning, we demonstrated the advantages of our proposed method by experiments.",
Sliding HDCA: Single-Trial EEG Classification to Overcome and Quantify Temporal Variability,"Patterns of neural data obtained from electroencephalography (EEG) can be classified by machine learning techniques to increase human-system performance. In controlled laboratory settings this classification approach works well; however, transitioning these approaches into more dynamic, unconstrained environments will present several significant challenges. One such challenge is an increase in temporal variability in measured behavioral and neural responses, which often results in suboptimal classification performance. Previously, we reported a novel classification method designed to account for temporal variability in the neural response in order to improve classification performance by using sliding windows in hierarchical discriminant component analysis (HDCA), and demonstrated a decrease in classification error by over 50% when compared to the standard HDCA method (Marathe et al., 2013). Here, we expand upon this approach and show that embedded within this new method is a novel signal transformation that, when applied to EEG signals, significantly improves the signal-to-noise ratio and thereby enables more accurate single-trial analysis. The results presented here have significant implications for both brain-computer interaction technologies and basic science research into neural processes.",
Part-Based Multiderivative Edge Cross-Sectional Profiles for Polyp Detection in Colonoscopy,"This paper presents a novel technique for automated detection of protruding polyps in colonoscopy images using edge cross-section profiles (ECSP). We propose a part-based multi-derivative ECSP that computes derivative functions of an edge cross-section profile and segments each of these profiles into parts. Therefore, we can model or extract features suitable for each part. Our features obtained from the parts can effectively describe complex properties of protruding polyps including the shape of the parts, texture, and protrusion and smoothness of the polyp surface. We evaluated our method against two existing polyp image detection techniques on 42 different polyps, including those with little protrusion. Each polyp has a large variation of appearance in viewing angles, light conditions, and scales in different images. The evaluation showed that our technique outperformed the existing techniques in both accuracy and analysis time. Our method has a higher area under the free-response receiver operating characteristic curve. For instance, when both techniques have a true positive rate for polyp image detection of 81.4%, the average number of false regions per image of our technique is 0.32 compared to 1.8 of the best existing technique under study. Additionally, our technique can precisely mark edges of candidate polyp regions as visual feedback. These results altogether indicate that our technique is promising to provide visual feedback of polyp regions in clinical practice.","Image edge detection,
Feature extraction,
Shape,
Colonoscopy,
Image segmentation,
Vectors,
Endoscopes"
Radial Basis Functions for Combining Shape and Speckle Tracking in 4D Echocardiography,"Quantitative analysis of left ventricular deformation can provide valuable information about the extent of disease as well as the efficacy of treatment. In this work, we develop an adaptive multi-level compactly supported radial basis approach for deformation analysis in 3D+time echocardiography. Our method combines displacement information from shape tracking of myocardial boundaries (derived from B-mode data) with mid-wall displacements from radio-frequency-based ultrasound speckle tracking. We evaluate our methods on open-chest canines (N=8) and show that our combined approach is better correlated to magnetic resonance tagging-derived strains than either individual method. We also are able to identify regions of myocardial infarction (confirmed by postmortem analysis) using radial strain values obtained with our approach.","Shape,
Myocardium,
Speckle,
Tracking,
Correlation,
Computed tomography,
Strain"
Energy-Aware Data Allocation and Task Scheduling on Heterogeneous Multiprocessor Systems With Time Constraints,"In this paper, we address the problem of energy-aware heterogeneous data allocation and task scheduling on heterogeneous multiprocessor systems for real-time applications. In a heterogeneous distributed shared-memory multiprocessor system, an important problem is how to assign processors to real-time application tasks, allocate data to local memories, and generate an efficient schedule in such a way that a time constraint can be met and the total system energy consumption can be minimized. We propose an optimal approach, i.e., an integer linear programming method, to solve this problem. As the problem has been conclusively shown to be computationally very complicated, we also present two heuristic algorithms, i.e., task assignment considering data allocation (TAC-DA) and task ratio greedy scheduling (TRGS), to generate near-optimal solutions for real-time applications in polynomial time. We evaluate the performance of our algorithms by comparing them with a greedy algorithm that is commonly used to solve heterogeneous task scheduling problems. Based on our extensive simulation study, we observe that our algorithms exhibit excellent performance. We conducted experimental performance evaluation on two heterogeneous multiprocessor systems. The average reduction rates of the total energy consumption of the TAC-DA and TRGS algorithms to that of the greedy algorithm are 13.72% and 15.76%, respectively, on the first system, and 19.76% and 24.67%, respectively, on the second system. To the best of our knowledge, this is the first study to solve the problem of task scheduling incorporated with data allocation and energy consumption on heterogeneous distributed shared-memory multiprocessor systems.","Program processors,
Energy consumption,
Resource management,
Processor scheduling,
Memory management,
Scheduling"
A Principled Way of Assessing Visualization Literacy,"We describe a method for assessing the visualization literacy (VL) of a user. Assessing how well people understand visualizations has great value for research (e. g., to avoid confounds), for design (e. g., to best determine the capabilities of an audience), for teaching (e. g., to assess the level of new students), and for recruiting (e. g., to assess the level of interviewees). This paper proposes a method for assessing VL based on Item Response Theory. It describes the design and evaluation of two VL tests for line graphs, and presents the extension of the method to bar charts and scatterplots. Finally, it discusses the reimplementation of these tests for fast, effective, and scalable web-based use.",
Sensor-Driven Area Coverage for an Autonomous Fixed-Wing Unmanned Aerial Vehicle,"Area coverage with an onboard sensor is an important task for an unmanned aerial vehicle (UAV) with many applications. Autonomous fixed-wing UAVs are more appropriate for larger scale area surveying since they can cover ground more quickly. However, their non-holonomic dynamics and susceptibility to disturbances make sensor coverage a challenging task. Most previous approaches to area coverage planning are offline and assume that the UAV can follow the planned trajectory exactly. In this paper, this restriction is removed as the aircraft maintains a coverage map based on its actual pose trajectory and makes control decisions based on that map. The aircraft is able to plan paths in situ based on sensor data and an accurate model of the on-board camera used for coverage. An information theoretic approach is used that selects desired headings that maximize the expected information gain over the coverage map. In addition, the branch entropy concept previously developed for autonomous underwater vehicles is extended to UAVs and ensures that the vehicle is able to achieve its global coverage mission. The coverage map over the workspace uses the projective camera model and compares the expected area of the target on the ground and the actual area covered on the ground by each pixel in the image. The camera is mounted on a two-axis gimbal and can either be stabilized or optimized for maximal coverage. Hardware-in-the-loop simulation results and real hardware implementation on a fixed-wing UAV show the effectiveness of the approach. By including the already developed automatic takeoff and landing capabilities, we now have a fully automated and robust platform for performing aerial imagery surveys.","Cameras,
Robot sensing systems,
Vehicles,
Trajectory,
Planning,
Object detection"
An Online Sleep Apnea Detection Method Based on Recurrence Quantification Analysis,"This paper introduces an online sleep apnea detection method based on heart rate complexity as measured by recurrence quantification analysis (RQA) statistics of heart rate variability (HRV) data. RQA statistics can capture nonlinear dynamics of a complex cardiorespiratory system during obstructive sleep apnea. In order to obtain a more robust measurement of the nonstationarity of the cardiorespiratory system, we use different fixed amount of neighbor thresholdings for recurrence plot calculation. We integrate a feature selection algorithm based on conditional mutual information to select the most informative RQA features for classification, and hence, to speed up the real-time classification process without degrading the performance of the system. Two types of binary classifiers, i.e., support vector machine and neural network, are used to differentiate apnea from normal sleep. A soft decision fusion rule is developed to combine the results of these classifiers in order to improve the classification performance of the whole system. Experimental results show that our proposed method achieves better classification results compared with the previous recurrence analysis-based approach. We also show that our method is flexible and a strong candidate for a real efficient sleep apnea detection system.",
Face recognition on smartphones via optimised Sparse Representation Classification,"Face recognition is an element of many smartphone apps, e.g. face unlocking, people tagging and games. Sparse Representation Classification (SRC) is a state-of-the-art face recognition algorithm, which has been shown to outperform many classical face recognition algorithms in OpenCV. The success of SRC is due to its use of ℓ1 optimisation, which makes SRC robust to noise and occlusions. Since ℓ1 optimisation is computationally intensive, SRC uses random projection matrices to reduce the dimension of the ℓ1 problem. However, random projection matrices do not give consistent classification accuracy. In this paper, we propose a method to optimise the projection matrix for ℓ1-based classification1. Our evaluations, based on publicly available databases and real experiment, show that face recognition based on the optimised projection matrix can be 5-17% more accurate than its random counterpart and OpenCV algorithms. Furthermore, the optimised projection matrix does not have to be re-calculated even if new faces are added to the training set. We implement the SRC with optimised projection matrix on Android smartphones and find that the computation of residuals in SRC is a severe bottleneck, taking up 85-90% of the computation time. To address this problem, we propose a method to compute the residuals approximately, which is 50 times faster but without sacrificing recognition accuracy. Lastly, we demonstrate the feasibility of our new algorithm by the implementation and evaluation of a new face unlocking app and show its robustness to variation to poses, facial expressions, lighting changes and occlusions.","Coherence,
Face recognition,
Accuracy,
Optimization,
Vectors,
Smart phones,
Sensors"
Proposal for Supercontinuum Generation by Optofluidic Infiltrated Photonic Crystal Fibers,"We propose a technique based on optofluidic infiltration to design a photonic crystal fiber (PCF) to control chromatic dispersion for supercontinuum generation. Selectively infiltrating the PCF air-holes with an optical fluid having an appropriate refractive index, we have achieved a PCF with low confinement loss and ultra-flattened near zero dispersion centered about λZD ~ 1325 nm, without a need for nano-scale geometrical tuning. Numerical simulations show that femto-second pulses, with center wavelengths within the range of 1250 nm ≤ λ0 ≤ 1625 nm, can generate relatively flat supercontinuum spectra as wide as 640 to 1180 nm, passing through a 250-mm long PCF whose dispersion profile is engineered via selective optofluidic infiltration. Simulations also show that optical fluid with refractive index of nF = 1.32 for input signals having the aforementioned range of wavelengths result in the widest flat supercontinua. This is attributed to the smallest corresponding effective mode area as well as the smallest and flat corresponding dispersion both of which enhance the PCF nonlinearities.",
Extension of the Pierce Model to Multiple Transmission Lines Interacting With an Electron Beam,"A possible route toward achieving high-power microwave (HPM) devices is through the use of novel slow-wave structures, represented by multiple coupled transmission lines (MTLs), and whose behavior when coupled to electron beams has not been sufficiently explored. We present the extension of the 1-D linearized Pierce theory to MTLs coupled to a single electron beam. We develop multiple formalisms to calculate the k-ω dispersion relation of the system and find that the existence of a growing wave solution is always guaranteed if the electron propagation constant is larger than or equal to the largest propagation constant of the MTL system. We verify our findings with illustrative examples that bring to light unique properties of the system in which growing waves were found to exist within finite bands of the electron propagation constant and also present possible means to improve the gain. By treating the beam-MTL interaction as distributed dependent current generators in the MTL, we derive relations characterizing the power flux and energy exchange between the beam and the MTLs. For the growing wave, we show that the beam always behaves as an energy source causing power flux along the transmission lines. The theory developed in this paper is the basis for the possible use of degenerate band edges in periodic MTL systems for HPM amplifiers.",
Context-oriented opportunistic cloud offload processing for energy conservation in wireless devices,"This paper elaborates on the design and the comparative evaluation with other similar approaches, of a Cloud executable process-offloading scheme. The mobile devices gather through their communication and social context (""friend's"" available resources and bandwidth etc.), the related data, towards elaborating further and enabling the process of the execution offloading. The proposed scheme aims at prolonging the lifetime of the mobile devices, while at the same time, it aims at saving resources on the user's device to maximize the efficiency in running context applications. The proposed social-aware scheme opportunistically exploits the resources of other socially-connected peers, in order to extend the capabilities of the mobile devices, by providing extra computing, storage resources, as well as the execution guarantee within a specified time frame. Comparative performance evaluations, in the presence of ""critical-process executions"", as well as in the sense of meeting the required deadlines, were performed for the comparison with other similar schemes to prove the validity and the efficiency of the proposed framework, in contrast to the nodes' lifetime extensibility.","Mobile handsets,
Peer-to-peer computing,
Mobile communication,
Context,
Energy consumption,
Performance evaluation,
Cloud computing"
A Novel and Lightweight System to Secure Wireless Medical Sensor Networks,"Wireless medical sensor networks (MSNs) are a key enabling technology in e-healthcare that allows the data of a patient's vital body parameters to be collected by the wearable or implantable biosensors. However, the security and privacy protection of the collected data is a major unsolved issue, with challenges coming from the stringent resource constraints of MSN devices, and the high demand for both security/privacy and practicality. In this paper, we propose a lightweight and secure system for MSNs. The system employs hash-chain based key updating mechanism and proxy-protected signature technique to achieve efficient secure transmission and fine-grained data access control. Furthermore, we extend the system to provide backward secrecy and privacy preservation. Our system only requires symmetric-key encryption/decryption and hash operations and is thus suitable for the low-power sensor nodes. This paper also reports the experimental results of the proposed system in a network of resource-limited motes and laptop PCs, which show its efficiency in practice. To the best of our knowledge, this is the first secure data transmission and access control system for MSNs until now.","access control,
biomedical communication,
biomedical electronics,
biomedical measurement,
biosensors,
data privacy,
health care,
low-power electronics,
medical computing,
private key cryptography,
prosthetics,
wireless sensor networks"
Quantum-Assisted Routing Optimization for Self-Organizing Networks,"Self-organizing networks act autonomously for the sake of achieving the best possible performance. The attainable routing depends on a delicate balance of diverse and often conflicting quality-of-service requirements. Finding the optimal solution typically becomes an nonolynomial-hard problem, as the network size increases in terms of the number of nodes. Moreover, the employment of user-defined utility functions for the aggregation of the different objective functions often leads to suboptimal solutions. On the other hand, Pareto optimality is capable of amalgamating the different design objectives by providing an element of elitism. Although there is a plethora of bioinspired algorithms that attempt to address this optimization problem, they often fail to generate all the points constituting the optimal Pareto front. As a remedy, we propose an optimal multiobjective quantum-assisted algorithm, namely the nondominated quantum optimization algorithm (NDQO), which evaluates the legitimate routes using the concept of Pareto optimality at a reduced complexity. We then compare the performance of the NDQO algorithm to the state-of-the-art evolutionary algorithms, demonstrating that the NDQO algorithm achieves a near-optimal performance. Furthermore, we analytically derive the upper and lower bounds of the NDQO algorithmic complexity, which is of the order of O(N) and O(N√(N)) in the best and worst case scenario, respectively. This corresponds to a substantial complexity reduction of the NDQO from the order of O(N2) imposed by the brute-force method.","Self-organizing networks,
Routing,
Complexity theory,
Wireless sensor networks,
Optimization,
Quantum computing,
Quality of service,
Biological system modeling"
Online Visual Tracking via Two View Sparse Representation,"In this letter, we present a novel online tracking method based on sparse representation. In contrast to existing “sparse representation”-based tracking algorithms, this work adopts the sparse representation method to construct both object and state models. The tracked object can be sparsely represented by a series of object templates, and also can be sparsely represented by candidate samples in the current frame. Furthermore, we propose a unified objective function to integrate object and state models, and cast the tracking problem as an optimization problem that can be solved in an iteration manner. Finally, we compare the proposed tracker with nine state-of-the-art tracking methods by using some challenging image sequences. Both qualitative and quantitative evaluations demonstrate that our tracker achieves favorable performance in terms of both accuracy and speed.","Vectors,
Signal processing algorithms,
Optimization,
Educational institutions,
Linear programming,
Tracking,
Visualization"
EasySMS: A Protocol for End-to-End Secure Transmission of SMS,"Nowadays, short message service (SMS) is being used in many daily life applications, including healthcare monitoring, mobile banking, mobile commerce, and so on. But when we send an SMS from one mobile phone to another, the information contained in the SMS transmit as plain text. Sometimes this information may be confidential like account numbers, passwords, license numbers, and so on, and it is a major drawback to send such information through SMS while the traditional SMS service does not provide encryption to the information before its transmission. In this paper, we propose an efficient and secure protocol called EasySMS, which provides end-to-end secure communication through SMS between end users. The working of the protocol is presented by considering two different scenarios. The analysis of the proposed protocol shows that this protocol is able to prevent various attacks, including SMS disclosure, over the air modification, replay attack, man-in-the-middle attack, and impersonation attack. The EasySMS protocol generates minimum communication and computation overheads as compared with existing SMSSec and PK-SIM protocols. On an average, the EasySMS protocol reduces 51% and 31% of the bandwidth consumption and reduces 62% and 45% of message exchanged during the authentication process in comparison to SMSSec and PK-SIM protocols respectively. Authors claim that EasySMS is the first protocol completely based on the symmetric key cryptography and retain original architecture of cellular network.","Protocols,
Mobile communication,
Cryptography,
Authentication,
Materials,
Servers"
Smart cloud search services: verifiable keyword-based semantic search over encrypted cloud data,"With the increasing popularity of the pay-as-you- consume cloud computing paradigm, a large number of cloud services are pushed to consumers. One hand, it brings great convenience to consumers who use intelligent terminals; on the other hand, consumers are also facing serious difficulties that how to search the most suitable services or products from cloud. So how to enable a smart cloud search scheme is a critical problem in the consumer-centric cloud computing paradigm. For protecting data privacy, sensitive data are always encrypted before being outsourced. Although the existing searchable encryption schemes enable users to search over encrypted data, these schemes support only exact keyword search, which greatly affects data usability. Moreover, these schemes do not support verifiability of search result. In order to save computation cost or download bandwidth, cloud server only conducts a fraction of search operation or return a part of result, which is viewed as selfish and semi-honest-but-curious. So, how to enhance flexibility of encrypted cloud data while supporting verifiability of search result is a big challenge. To tackle the challenge, a smart semantic search scheme is proposed in this paper, which returns not only the result of keyword-based exact match, but also the result of keyword-based semantic match. At the same time, the proposed scheme supports the verifiability of search result. The rigorous security analysis and performance analysis show that the proposed scheme is secure under the proposed model and effectively achieves the goal of keyword-based semantic search.",
Iron Loss Calculation in Steel Laminations at High Frequencies,"This paper proposes a model for the computation of iron losses in steel laminations accounting simultaneously for magnetic hysteresis and eddy currents. The proposed model is well suited for finite element implementation and relies on a consistent thermodynamic background. The focus of this paper is particularly set on a systematic and accurate identification of material parameters from standard dc measurements (Epstein frame, single-sheet tester). Once identified, those material parameters can be used to obtain quantitative predictions of iron losses at higher frequencies and in the presence of higher harmonics. The model and the identification process are validated against measurements for a M235-35 A electrical steel over a wide range of field intensity and frequencies.","Magnetic hysteresis,
Materials,
Steel,
Iron,
Vectors,
Computational modeling,
Lamination"
"Intrinsically switchable, high-Q ferroelectric-on-silicon composite film bulk acoustic resonators","This paper presents a voltage-controlled, high-quality factor (Q) composite thin-film bulk acoustic resonator (FBAR) at 1.28 GHz. The composite FBAR consists of a thin layer of barium strontium titanate (BST) that is sandwiched between two electrodes deposited on a silicon-on-insulator (SOI) wafer. The BST layer, which has a strong electrostrictive effect, is used for electromechanical transduction by means of its voltage-induced piezoelectricity. The silicon layer, with its low mechanical loss, increases the Q of the resonator. The composite FBAR presented here exhibits Qs exceeding 800 with a resonance frequency and Q product (f × Q) of 1026 GHz.","Film bulk acoustic resonators,
Transmission line measurements,
Power transmission lines,
Resonant frequency,
Impedance,
Electrodes"
Towards Green Optical/Wireless In-Building Networks: Radio-Over-Fiber,"Energy efficiency has become a major paradigm in the design and operation of future telecommunication networks. Recent studies show that the aggregate power consumption of in-building IT networks (residential and office) is massive and comparable with that of data centers due to the large number of buildings. In this paper, we analyze the energy efficiency of next-generation in-building IT networks to deliver high-speed mobile access to end users via integrated optical/wireless networks using Radio-over-Fiber (RoF) technology. Based on a validated energy efficiency model, our results show that although individual point-to-point RoF links are not as energy efficient as legacy Baseband-over-Fiber links, RoF networks may actually be more energy-efficient when designed keenly with small cells sizes and when the static energy consumption of the remote units is above a particular threshold. Under the assumptions used in this paper, we show that the DRoF-based architectures can be designed to more energy efficient for cell sizes <;17 m.",
Asymmetric Doherty Power Amplifier Designed Using Model-Based Nonlinear Embedding,"A novel procedure is introduced for designing Doherty amplifiers using the model-based nonlinear-embedding technique. First, the Doherty intrinsic load-matching network is designed at the transistor current-source reference plane with the main and auxiliary devices interconnected. Identical devices with different biasing are used for realizing an asymmetric Doherty implementation with 9-dB back-off. The required multiharmonic impedances at the package planes are then obtained using the embedding device model for both devices, and the complex load impedance at the fundamental is projected back to resistive loads using an offset line. An even-number multisection impedance transformer and a reduced drain voltage of the main amplifier are used to design the asymmetric Doherty load network while providing the necessary loads to the main and auxiliary devices. The optimization of the drain efficiency and gain curves of the asymmetric Doherty operation for the proposed design is further investigated by adjusting the auxiliary gate-bias. An efficiency above 50% over an 11-dB power range is experimentally observed with 41.8-dBm peak output power using continuous wave (CW) at 2 GHz. Using a dual-input implementation of the designed Doherty power amplifier (PA), a systematic dual-input CW characterization of the Doherty operation is performed to establish the relative auxiliary-to-main phase offsets and power offsets yielding a maximum efficiency under constant gain. From this dual-input characterization, it is found that the optimal gate bias for single-input Doherty operation is the one for which the constant-gain maximum efficiency is achieved for a quasi-constant auxiliary-to-main input power ratio corresponding to the one implemented in the input divider in the single-input Doherty PA.","Load modeling,
Harmonic analysis,
Impedance,
Logic gates,
Peak to average power ratio,
Mathematical model,
Equations"
An Efficient Multi Queue Job Scheduling for Cloud Computing,"Cloud computing is one of the well developing field in Computer Science and Information Technology. The efficient job scheduling increases the client satisfaction and utilize the system energy in terms of time. A Multi Queue Scheduling (MQS) algorithm proposed to reduces the cost of both reservation and on-demand plans using the global scheduler. Scheduling is the most important complex part in cloud computing. The ultimate aim of global scheduler is to share the resources at most the maximum level. Researcher gives more importance to build a job scheduling algorithms that are well-suited and appropriate in Cloud computing situation. Job scheduling is one of the critical event in cloud computing because the user have to pay for services based on usage time. The proposed methodology depicts the concept of clustering the jobs based on burst time. During the time of scheduling the traditional methods such as First Come First Serve, Shortest Job First, EASY, Combinational Backfill and Improved backfill using balance spiral method are creates fragmentation. The proposed method overcome this problem and reduces the starvation with in the process. This paper also focus some existing scheduling algorithm and issues related to them in cloud computing. The proposed MQS method gives more importance to select job dynamically in order to achieve the optimum cloud scheduling problem and hence it utilize the unused free space in an economic way.","Cloud computing,
Scheduling algorithms,
Resource management,
Computational modeling,
Dynamic scheduling"
Evolutionary Algorithms With Segment-Based Search for Multiobjective Optimization Problems,"This paper proposes a variation operator, called segment-based search (SBS), to improve the performance of evolutionary algorithms on continuous multiobjective optimization problems. SBS divides the search space into many small segments according to the evolutionary information feedback from the set of current optimal solutions. Two operations, micro-jumping and macro-jumping, are implemented upon these segments in order to guide an efficient information exchange among “good” individuals. Moreover, the running of SBS is adaptive according to the current evolutionary status. SBS is activated only when the population evolves slowly, depending on general genetic operators (e.g., mutation and crossover). A comprehensive set of 36 test problems is employed for experimental verification. The influence of two algorithm settings (i.e., the dimensionality and boundary relaxation strategy) and two probability parameters in SBS (i.e., the SBS rate and micro-jumping proportion) are investigated in detail. Moreover, an empirical comparative study with three representative variation operators is carried out. Experimental results show that the incorporation of SBS into the optimization process can improve the performance of evolutionary algorithms for multiobjective optimization problems.",
BDD based synthesis of Boolean functions using memristors,"Very recently a new passive circuit element called memristor has been extensively investigated by researchers, which can be used for a variety of applications. This two-terminal device having few nanometer dimensions has been experimentally shown to possess both memory and resistor properties. This has also received great attention due to the fact that these devices can very easily be integrated on CMOS subsystems. Most of the logic design works in this context are based on material implication operation which can be very efficiently implemented using memristors. In this paper we propose an efficient realization of 2-to-1 multiplexer using memristors, and hence present a synthesis methodology that represents a given Boolean function as a Reduced Ordered Binary Decision Diagram (ROBDD) and then maps the same to memristor implementation.","Memristors,
Boolean functions,
Data structures,
Multiplexing,
Loading,
Logic design,
Logic gates"
The research and implementation of cloud computing platform based on docker,"Cloud computing is now leading-edge Internet technology and virtualization technology is one of the important part of cloud computing system. Virtualization, in computing, refers to the act of creating a virtual (rather than actual) version of something, including but not limited to a virtual computer hardware platform, operating system (OS), storage device, or computer network resources. Docker is a new type of virtualization technology. In this paper, through an application instance, we will describe docker's applications and advantages in the cloud Computing.",
Understanding Alternating Minimization for Matrix Completion,"Alternating minimization is a widely used and empirically successful heuristic for matrix completion and related low-rank optimization problems. Theoretical guarantees for alternating minimization have been hard to come by and are still poorly understood. This is in part because the heuristic is iterative and non-convex in nature. We give a new algorithm based on alternating minimization that provably recovers an unknown low-rank matrix from a random subsample of its entries under a standard incoherence assumption. Our results reduce the sample size requirements of the alternating minimization approach by at least a quartic factor in the rank and the condition number of the unknown matrix. These improvements apply even if the matrix is only close to low-rank in the Frobenius norm. Our algorithm runs in nearly linear time in the dimension of the matrix and, in a broad range of parameters, gives the strongest sample bounds among all subquadratic time algorithms that we are aware of. Underlying our work is a new robust convergence analysis of the well-known Power Method for computing the dominant singular vectors of a matrix. This viewpoint leads to a conceptually simple understanding of alternating minimization. In addition, we contribute a new technique for controlling the coherence of intermediate solutions arising in iterative algorithms based on a smoothed analysis of the QR factorization. These techniques may be of interest beyond their application here.",
SIPS: Solar Irradiance Prediction System,"There is high interest in up-scaling capacities of renewable energy sources such as wind and solar. However, variability and uncertainty in power output is a major concern and forecasting is, therefore, a top priority. Advancements in forecasting can potentially limit the impact of fluctuations in solar power generation, specifically in cloudy days when the variability and dynamics are the largest. We propose SIPS, Solar Irradiance Prediction System, a novel sensing infrastructure using wireless sensor networks (WSNs) to enable sensing of solar irradiance for solar power generation forecasting. In this paper, we report the findings of a deployment of a hierarchical WSN system consisting of 19 TelosB nodes equipped with solar irradiance sensors, and 5 MicaZ nodes equipped with GPS boards, deployed in the vicinity of a 1 MW solar array. We evaluate different irradiance sensor types and the performance of different novel prediction methods using SIPS' data and show that the spatial-temporal cross-correlations between sensor node readings and solar array output power exists and can be exploited to improve prediction accuracy. Using this data for short-term solar forecasting for cloudy days with very high dynamics in solar output power generation - the worst case scenario for prediction-, we get an average of 97.24% accuracy in our prediction for short time horizon forecasting and 240% reduction of predicted normalized root mean square error (NRMSE) compared to state-of-the-art methods that do not use SIPS data.","Clouds,
Forecasting,
Power generation,
Predictive models,
Wireless sensor networks,
Sensor systems"
Toward online 3-D object segmentation and mapping,"We build on recent fast and accurate 3-D reconstruction techniques to segment objects during scene reconstruction. We take object outline information from change detection to build 3-D models of rigid objects and represent the scene as static and dynamic components. Object models are updated online during mapping, and can integrate segmentation information from sources other than change detection.",
A Survey and Comparative Study of Statistical Tests for Identifying Differential Expression from Microarray Data,"DNA microarray is a powerful technology that can simultaneously determine the levels of thousands of transcripts (generated, for example, from genes/miRNAs) across different experimental conditions or tissue samples. The motto of differential expression analysis is to identify the transcripts whose expressions change significantly across different types of samples or experimental conditions. A number of statistical testing methods are available for this purpose. In this paper, we provide a comprehensive survey on different parametric and non-parametric testing methodologies for identifying differential expression from microarray data sets. The performances of the different testing methods have been compared based on some real-life miRNA and mRNA expression data sets. For validating the resulting differentially expressed miRNAs, the outcomes of each test are checked with the information available for miRNA in the standard miRNA database PhenomiR 2.0. Subsequently, we have prepared different simulated data sets of different sample sizes (from 10 to 100 per group/population) and thereafter the power of each test have been calculated individually. The comparative simulated study might lead to formulate robust and comprehensive judgements about the performance of each test in the basis of assumption of data distribution. Finally, a list of advantages and limitations of the different statistical tests has been provided, along with indications of some areas where further studies are required.","Standards,
Sociology,
Correlation,
Testing,
Analysis of variance,
Computational biology"
Blind Image Deblurring Using Spectral Properties of Convolution Operators,"Blind deconvolution is to recover a sharp version of a given blurry image or signal when the blur kernel is unknown. Because this problem is ill-conditioned in nature, effectual criteria pertaining to both the sharp image and blur kernel are required to constrain the space of candidate solutions. While the problem has been extensively studied for long, it is still unclear how to regularize the blur kernel in an elegant, effective fashion. In this paper, we show that the blurry image itself actually encodes rich information about the blur kernel, and such information can indeed be found by exploring and utilizing a well-known phenomenon, that is, sharp images are often high pass, whereas blurry images are usually low pass. More precisely, we shall show that the blur kernel can be retrieved through analyzing and comparing how the spectrum of an image as a convolution operator changes before and after blurring. Subsequently, we establish a convex kernel regularizer, which depends only on the given blurry image. Interestingly, the minimizer of this regularizer guarantees to give a good estimate to the desired blur kernel if the original image is sharp enough. By combining this powerful regularizer with the prevalent nonblind devonvolution techniques, we show how we could significantly improve the deblurring results through simulations on synthetic images and experiments on realistic images.","Kernel,
Convolution,
Deconvolution,
Eigenvalues and eigenfunctions,
Image edge detection,
Image restoration,
Cameras"
A Novel Polar Space Random Field Model for the Detection of Glandular Structures,"In this paper, we propose a novel method to detect glandular structures in microscopic images of human tissue. We first convert the image from Cartesian space to polar space and then introduce a novel random field model to locate the possible boundary of a gland. Next, we develop a visual feature-based support vector regressor to verify if the detected contour corresponds to a true gland. And finally, we combine the outputs of the random field and the regressor to form the GlandVision algorithm for the detection of glandular structures. Our approach can not only detect the existence of the gland, but also can accurately locate it with pixel accuracy. In the experiments, we treat the task of detecting glandular structures as object (gland) detection and segmentation problems respectively. The results indicate that our new technique outperforms state-of-the-art computer vision algorithms in respective fields.","Glands,
Image color analysis,
Inference algorithms,
Educational institutions,
Image edge detection,
Approximation algorithms,
Image segmentation"
An efficient task scheduling algorithm for heterogeneous multi-cloud environment,"Cloud Computing has been adopted as one of the growing technologies in the business and research community. However, due to significant client demands, there is a need to overflow some workloads to other data centers as no data center has unlimited resources. The workload sharing provides even more flexible and cheaper resources to complete the applications submitted to the data centers. However, scheduling workloads in multi-cloud environment is challenging as the data centers have resources which are heterogeneous in nature. In this paper, we propose a task scheduling algorithm in a heterogeneous multi-cloud environment. The algorithm is based on two popular algorithms namely, Min-Min and Max-Min. We perform extensive experiments on some benchmark and synthetic data sets and compare the results with two existing multi-cloud scheduling algorithms. The results show that the proposed algorithm outperforms both the algorithms in terms of makespan and average cloud utilization.",
Energy-Aware Sensor Selection in Field Reconstruction,"In this letter, a new sparsity-promoting penalty function is introduced for sensor selection problems in field reconstruction, which has the property of avoiding scenarios where the same sensors are successively selected. Using a reweighted ℓ1 relaxation of the ℓ0 norm, the sensor selection problem is reformulated as a convex quadratic program. In order to handle large-scale problems, we also present two fast algorithms: accelerated proximal gradient method and alternating direction method of multipliers. Numerical results are provided to demonstrate the effectiveness of our approaches.","Signal processing algorithms,
Vectors,
Estimation,
Gradient methods,
Acceleration,
Schedules"
A Novel Vehicular Information Network Architecture Based on Named Data Networking (NDN),"Vehicular information network and Internet of Things (IoT) technologies have been receiving a lot of attention in recent years. As one of the most important and promising IoT areas, a vehicular information network aims to implement a myriad of applications related to vehicles, traffic information, drivers, passengers, and pedestrians. However, intervehicular communication (IVC) in a vehicular information network is still based on the TCP/IP protocol stack which is not efficient and scalable. To address the efficiency and scalability issues of the IVC, we leverage the named data networking (NDN) paradigm where the end user only cares about the needed content and pays no attention to the actual location of the content. The NDN model is highly suitable for the IVC scenario with its hierarchical content naming scheme and flexible content retrieval and caching support. We design a novel vehicular information network architecture based on the basic communication principle of NDN. Our proposed architecture aims to improve content naming, addressing, data aggregation, and mobility for IVC in the vehicular information network. In addition, the key parameter settings of the proposed schemes are analyzed in order to help guide their actual deployment.",
Study and analysis of various task scheduling algorithms in the cloud computing environment,Cloud computing is a novel perspective for large scale distributed computing and parallel processing. It provides computing as a utility service on a pay per use basis. The performance and efficiency of cloud computing services always depends upon the performance of the user tasks submitted to the cloud system. Scheduling of the user tasks plays significant role in improving performance of the cloud services. Task scheduling is one of the main types of scheduling performed. This paper presents a detailed study of various task scheduling methods existing for the cloud environment. A brief analysis of various scheduling parameters considered in these methods is also discussed in this paper.,"Load management,
Dynamic scheduling,
Scheduling algorithms,
Heuristic algorithms,
Servers"
Survey of Multiscale and Multiphysics Applications and Communities,"Multiscale and multiphysics applications are now commonplace, and many researchers focus on combining existing models to construct new multiscale models. This concise review of multiscale applications and their source communities in the EU and US outlines differences and commonalities among approaches and identifies areas in which collaboration between disciplines could be particularly beneficial. Because different communities adopt very different approaches to constructing multiscale simulations, and simulations on a length scale of a few meters and a time scale of a few hours can be found in many multiscale research domains, communities might receive additional benefit from sharing methods that are geared towards these scales. The Web extra is the full literature list mentioned in the article.",
Access Points Planning in Urban Area for Data Dissemination to Drivers,"Roadside infrastructure can greatly help disseminate data to drivers. In this paper, we study a fundamental problem, i.e., roadside infrastructure planning. We propose a class of algorithms named Tailor to select a minimum number of intersections to install the infrastructure. In the case when the traffic information is not available, we formulate the intersection selection problem, which formally proves its np-completeness, and provide novel heuristics, i.e., the adapted-bipartite-based heuristics (ABS), to solve it, whose worst-case approximation ratio is 4/3. ABS bridges the planar graph and the bipartite graph through topology transformation. With ABS, the approximate solution to all the problems that are NP-hard in a general planar graph but polynomially solvable in a bipartite graph can be efficiently obtained in the planar graph. We also prove that, even with traffic information, the intersection selection problem remains NP-hard. Greedy heuristics is employed to balance the tradeoff between the number of selected intersections and the percentage of reached vehicles.","Face,
Vehicles,
Bipartite graph,
Polynomials,
Topology,
Approximation methods,
Redundancy"
Scaling Reverse Time Migration Performance through Reconfigurable Dataflow Engines,"Seismic migrations dominate about 90 percent of the computation cycles in the oil and gas industry. With the demand to handle high-density data and more complicated physics models, migration applications always call for more computing power, and they adopt new architectures quickly. Current multicore and many-core architectures have significantly improved the density of computational resources within a chip, but they also have made memory bandwidth a bottleneck that stops the scaling of performance over the increased number of cores. In this article, the authors present their reverse time migration design based on reconfigurable data-flow engines. Combining both algorithmic and architectural optimizations, they manage to achieve a balanced utilization of various resources (computational logic, local buffers, memory bandwidth, and so on) in the system, with none of them becoming the performance bottleneck. Their data-flow design provides performance equivalent to 72 Intel CPU cores, and achieves 10 times higher power efficiency than the multicore CPU architecture.",
Gate Bias Dependence of Defect-Mediated Hot-Carrier Degradation in GaN HEMTs,"Monte Carlo analysis of hot-electron degradation in AlGaN/GaN high-electron mobility transistors shows that, for gate voltages corresponding to semi-ON bias conditions, the average electron energy has a spatial peak with (EAVE) ~ 1.5 eV. The peak is located at the edge of the gate. At this location, the carrier versus energy distribution has a large tail extending over 3 eV. When transferred to the lattice, this energy can cause defect dehydrogenation and device degradation. These results are consistent with the experimental data indicating maximum degradation in the semi-ON bias condition.","Logic gates,
Gallium nitride,
Degradation,
HEMTs,
MODFETs,
Aluminum gallium nitride,
Scattering"
Learning Perceptual Kernels for Visualization Design,"Visualization design can benefit from careful consideration of perception, as different assignments of visual encoding variables such as color, shape and size affect how viewers interpret data. In this work, we introduce perceptual kernels: distance matrices derived from aggregate perceptual judgments. Perceptual kernels represent perceptual differences between and within visual variables in a reusable form that is directly applicable to visualization evaluation and automated design. We report results from crowd-sourced experiments to estimate kernels for color, shape, size and combinations thereof. We analyze kernels estimated using five different judgment types-including Likert ratings among pairs, ordinal triplet comparisons, and manual spatial arrangement-and compare them to existing perceptual models. We derive recommendations for collecting perceptual similarities, and then demonstrate how the resulting kernels can be applied to automate visualization design decisions.","Kernel,
Visualization,
Shape analysis,
Data visualization,
Encoding,
Image color analysis,
Color analysis"
Universal Outlier Hypothesis Testing,"Outlier hypothesis testing is studied in a universal setting. Multiple sequences of observations are collected, a small subset of which are outliers. A sequence is considered an outlier if the observations in that sequence are distributed according to an outlier distribution, distinct from the typical distribution governing the observations in all the other sequences. Nothing is known about the outlier and typical distributions except that they are distinct and have full supports. The goal is to design a universal test to best discern the outlier sequence(s). For models with exactly one outlier sequence, the generalized likelihood test is shown to be universally exponentially consistent. A single-letter characterization of the error exponent achievable by the test is derived, and it is shown that the test achieves the optimal error exponent asymptotically as the number of sequences approaches infinity. When the null hypothesis with no outlier is included, a modification of the generalized likelihood test is shown to achieve the same error exponent under each non-null hypothesis, and also consistency under the null hypothesis. Then, models with more than one outlier are studied in the following settings. For the setting with a known number of distinctly distributed outliers, the achievable error exponent of the generalized likelihood test is characterized. The limiting error exponent achieved by such a test is characterized, and the test is shown to be asymptotically exponentially consistent. For the setting with an unknown number of identically distributed outliers, a modification of the generalized likelihood test is shown to achieve a positive error exponent under each non-null hypothesis, and also consistency under the null hypothesis. When the outlier sequences can be distinctly distributed (with their total number being unknown), it is shown that a universally exponentially consistent test cannot exist, even when the typical distribution is known and the null hypothesis is excluded.","Testing,
Error probability,
Encoding,
Training data,
Manganese,
Measurement,
Decoding"
Demonstrations of Efficient Online Spectrum Defragmentation in Software-Defined Elastic Optical Networks,"Elastic optical networks (EONs) facilitate agile spectrum management in the optical layer. When coupling with software-defined networking, they function as software-defined EONs (SD-EONs) and provide service providers more freedom to customize their infrastructure dynamically. In this paper, we investigate how to overcome spectrum fragmentation in SD-EONs with OpenFlow-controlled online spectrum defragmentation (DF), and conduct system implementations to facilitate highly-efficient online DF. We first consider sequential DF, i.e., the scenario that involves a sequence of lightpath reconfigurations to progressively consolidate the spectrum utilization. We modify our previous DF algorithm to make sure that the reconfigurations can be performed in batches and the “make-before-break” scheme can be applied to all of them. The modified algorithm is implemented in an OpenFlow (OF) controller, and we design OF extensions to facilitate synchronous batch reconfiguration. Then, we further simplify the DF operations by designing and implementing parallel DF that can accomplish all the DF-related lightpath reconfigurations simultaneously. All these DF implementations are experimentally demonstrated in an SD-EON control plane testbed that consists of 14 stand-alone OF agents and one OF controller, which are all implemented based on high-performance Linux servers. The experimental results indicate that our OF-controlled online DF implementations perform well and can improve network performance in an efficient way.","Optical switches,
Bandwidth,
Optical fiber networks,
Algorithm design and analysis,
Frequency modulation,
Erbium,
Ports (Computers)"
Carbon-Aware Energy Cost Minimization for Distributed Internet Data Centers in Smart Microgrids,"In this paper, we investigate the problem of minimizing carbon-aware energy cost for distributed Internet data centers (IDCs) in smart microgrids. Specifically, a socially responsible IDC operator intends to jointly minimize the long-term energy cost and carbon emission in IDC operations. Since the future system parameters (e.g., electricity price, workload, renewable energy generation, and carbon emission rate) are random, we formulate the above-mentioned problem as a stochastic program to minimize the time-averaged expectation of the weighted summation of energy cost and carbon emission with guaranteed quality of service for service requests. Then, we design an operation algorithm to solve the formulated problem based on Lyapunov optimization technique without requiring any knowledge about system statistics. Finally, evaluations based on real-life data show that the proposed operation algorithm can achieve lower energy cost and carbon emission simultaneously compared with the carbon-oblivious algorithm.","Carbon dioxide,
Generators,
Batteries,
Energy management,
Internet of Things,
Electricity,
Power demand,
Data centers,
Distributed processing"
Joint User Grouping and Transceiver Design in a MIMO Interfering Broadcast Channel,"Consider a MIMO multi-cellular network (also known as an interfering broadcast channel) where each base station transmits signals to the users in its own cell. The basic problem is to design linear transmit/receive beamformers and schedule users across a fixed set of time slots so as to maximize the system throughput in the presence of both inter and intra cell interference. In this paper, we propose a joint linear transceiver design and user grouping scheme for sum utility maximization that is based on iterative minimization of weighted mean squared error (MSE). The proposed algorithm only needs local channel knowledge and its convergence to a stationary point is guaranteed for some well-known utility functions, while ensuring user fairness. The simulation results show that the proposed formulation/algorithm can offer significantly higher system throughput than the standard multi-user MIMO techniques such as the SVD-MMSE strategy, while maintaining user fairness. Furthermore, the proposed algorithm exhibits fast convergence and is amenable to distributed implementation with limited information exchange.","Algorithm design and analysis,
Joints,
Transceivers,
Convergence,
MIMO,
Interference,
Receivers"
Incentive-Compatible Online Mechanisms for Resource Provisioning and Allocation in Clouds,"Cloud providers provision their various resources such as CPUs, memory, and storage in the form of Virtual Machine (VM) instances which are then allocated to the users. We design online mechanisms for VM provisioning and allocation in clouds that consider several types of available resources. Our proposed online mechanisms make no assumptions about future demand of VMs, which is the case in real cloud settings. The proposed mechanisms are invoked as soon as a user places a request or some of the allocated resources are released and become available. The mechanisms allocate VM instances to selected users for the period they are requested for, and ensure that the users will continue using their VM instances for the entire requested period. In addition, the mechanisms determine the payment the users have to pay for using the allocated resources. We prove that the mechanisms are incentive-compatible, that is, they give incentives to the users to reveal their true valuations for their requested bundles of VM instances. We investigate the performance of our proposed mechanisms through extensive experiments.","Resource management,
Silicon,
Cost accounting,
Vectors,
Mechanical factors,
Cloud computing,
Computer science"
Sub-1-volt Piezoelectric Nanoelectromechanical Relays With Millivolt Switching Capability,"The design, fabrication, and characterization of the first piezoelectric nanoelectromechanical relays with sub-1-volt actuation (520 mV) are presented. The low actuation voltage is enabled by employing ultrathin piezoelectric aluminum nitride films (10 nm) with high c-axis orientation and controlled residual stress in a stress-compensating geometry. Two different actuation methods based on optimized four-layer unimorph actuators are used to synthesize normally closed relays with high mechanical restoring forces. The first experimental demonstration of few millivolts switching (10 mV) using the realized relays is also presented. The relays exhibit a very low energy dissipation per switching cycle (23 aJ), an extremely small subthreshold slope (0.013 mV/decade), and a low ON-state resistance (2.3 kQ).","Relays,
Switches,
III-V semiconductor materials,
Actuators,
Nanoelectromechanical systems,
Stress,
Logic gates"
Spatial-Spectral Information Based Abundance-Constrained Endmember Extraction Methods,"Endmember extraction, which is an important technique for hyperspectral data interpretation, selects a collection of pure signature spectra of the different materials, called endmembers, which are present in a remotely sensed hyperspectral image scene. These pure signatures are then used in spectral unmixing algorithms to decompose the scene into abundance fractions, which indicate the proportion of each endmember's presence in a mixed pixel. In other words, abundances can be obtained by the given endmembers. Correspondingly, endmembers can be extracted based on an abundance constraint. In this paper, we first propose an endmember extraction framework based on an abundance constraint whose efficiency is related to the abundance calculation. The mainstream existing spatial-spectral algorithms can have a very high complexity and are sensitive to outliers, or the spatial information is considered followed by the spectral information. We therefore propose a strategy to consider the spectral information followed by the spatial information, using an abundance-constrained framework. The spatial strategy is also assumed to be immune to outliers. Experiments on both synthetic and real hyperspectral data sets indicate that: 1) the abundance constraint is effective for endmember extraction; and 2) the proposed spatial processing method used in the abundance-constrained endmember extraction framework can effectively avoid outliers.","Hyperspectral imaging,
Data mining,
Materials,
Noise,
Algorithm design and analysis"
Hybrid Dataflow/von-Neumann Architectures,"General purpose hybrid dataflow/von-Neumann architectures are gaining attraction as effective parallel platforms. Although different implementations differ in the way they merge the conceptually different computational models, they all follow similar principles: they harness the parallelism and data synchronization inherent to the dataflow model, yet maintain the programmability of the von-Neumann model. In this paper, we classify hybrid dataflow/von-Neumann models according to two different taxonomies: one based on the execution model used for inter- and intrablock execution, and the other based on the integration level of both control and dataflow execution models. The paper reviews the basic concepts of von-Neumann and dataflow computing models, highlights their inherent advantages and limitations, and motivates the exploration of a synergistic hybrid computing model. Finally, we compare a representative set of recent general purpose hybrid dataflow/von-Neumann architectures, discuss their different approaches, and explore the evolution of these hybrid processors.","Computational modeling,
Computer architecture,
Parallel processing,
Instruction sets,
Data models,
Synchronization"
Salient Region Detection by Fusing Bottom-Up and Top-Down Features Extracted From a Single Image,"Recently, some global contrast-based salient region detection models have been proposed based on only the low-level feature of color. It is necessary to consider both color and orientation features to overcome their limitations, and thus improve the performance of salient region detection for images with low-contrast in color and high-contrast in orientation. In addition, the existing fusion methods for different feature maps, like the simple averaging method and the selective method, are not effective sufficiently. To overcome these limitations of existing salient region detection models, we propose a novel salient region model based on the bottom-up and top-down mechanisms: the color contrast and orientation contrast are adopted to calculate the bottom-up feature maps, while the top-down cue of depth-from-focus from the same single image is used to guide the generation of final salient regions, since depth-from-focus reflects the photographer's preference and knowledge of the task. A more general and effective fusion method is designed to combine the bottom-up feature maps. According to the degree-of-scattering and eccentricities of feature maps, the proposed fusion method can assign adaptive weights to different feature maps to reflect the confidence level of each feature map. The depth-from-focus of the image as a significant top-down feature for visual attention in the image is used to guide the salient regions during the fusion process; with its aid, the proposed fusion method can filter out the background and highlight salient regions for the image. Experimental results show that the proposed model outperforms the state-of-the-art models on three public available data sets.","Image color analysis,
Feature extraction,
Image edge detection,
Visualization,
Color,
Educational institutions,
Computational modeling"
Band Codes for Energy-Efficient Network Coding With Application to P2P Mobile Streaming,"A key problem in network coding (NC) lies in the complexity and energy consumption associated with the packet decoding processes, which hinder its application in mobile environments. Controlling and hence limiting such factors has always been an important but elusive research goal, since the packet degree distribution, which is the main factor driving the complexity, is altered in a non-deterministic way by the random recombinations at the network nodes. In this paper we tackle this problem with a new approach and propose Band Codes (BC), a novel class of network codes specifically designed to preserve the packet degree distribution during packet encoding, recombination and decoding. BC are random codes over GF(2) that exhibit low decoding complexity, feature limited and controlled degree distribution by construction, and hence allow to effectively apply NC even in energy-constrained scenarios. In particular, in this paper we motivate and describe our new design and provide a thorough analysis of its performance. We provide numerical simulations of the BC performance in order to validate the analysis and assess the overhead of BC with respect to a conventional random NC scheme. Moreover, experiment in a real-world application, namely peer-to-peer mobile media streaming using a random-push protocol, show that BC reduce the decoding complexity by a factor of two with negligible increase of the encoding overhead, paving the way for the application of NC to power-constrained devices.","Encoding,
Decoding,
Complexity theory,
Peer-to-peer computing,
Streaming media,
Throughput,
Mobile handsets"
Adaptive Neural Control of MIMO Nonlinear Systems With a Block-Triangular Pure-Feedback Control Structure,"This paper presents adaptive neural tracking control for a class of uncertain multiinput-multioutput (MIMO) nonlinear systems in block-triangular form. All subsystems within these MIMO nonlinear systems are of completely nonaffine pure-feedback form and allowed to have different orders. To deal with the nonaffine appearance of the control variables, the mean value theorem is employed to transform the systems into a block-triangular strict-feedback form with control coefficients being couplings among various inputs and outputs. A systematic procedure is proposed for the design of a new singularity-free adaptive neural tracking control strategy. Such a design procedure can remove the couplings among subsystems and hence avoids the possible circular control construction problem. As a consequence, all the signals in the closed-loop system are guaranteed to be semiglobally uniformly ultimately bounded. Moreover, the outputs of the systems are ensured to converge to a small neighborhood of the desired trajectories. Simulation studies verify the theoretical findings revealed in this paper.","MIMO,
Artificial neural networks,
Nonlinear systems,
Couplings,
Adaptive systems,
Approximation methods,
Lyapunov methods"
Evidence of the Robustness of a COTS Soft-Error Free SRAM to Neutron Radiation,"Radiation tests with 15-MeV neutrons were performed in a COTS SRAM including a new memory cell design combining SRAM cells and DRAM capacitors to determine if, as claimed, it is soft-error free and to estimate upper bounds for the cross-section. These tests led to cross-section values two orders of magnitude below those of typical CMOS SRAMs in the same technology node. MUSCA SEP3 simulations complement these results predicting that only high-energy neutrons ( > 30 MeV) can provoke bit flips in the studied SRAMs. MUSCA SEP3 is also used to investigate the sensitivity of the studied SRAM to radioactive contamination and to compare it with the one of standard CMOS SRAMs. Results are useful to make predictions about the operation of this memory in environments such as avionics.","Neutrons,
SRAM cells,
CMOS integrated circuits,
Reliability,
Error analysis,
Single event upsets"
PAPR Reduction in Coded SC-FDMA Systems via Introducing Few Bit Errors,"We propose a simple and flexible peak-to-average power ratio (PAPR) reduction scheme for coded single carrier frequency division multiple access (SC-FDMA) signals in the uplink of the Long Term Evolution (LTE). The proposed scheme is based on the introduction of few bit errors to modify the few complex modulated symbols of each data SC-FDMA symbol in a sub-frame, which cause peaks of the output signal samples to be larger than a predetermined threshold value. In addition, the effect on the bit error rate (BER) performance of the few deliberately corrupted bits can be greatly mitigated by using the channel decoding at the receiver. Computer simulations show that the proposed scheme can reduce the PAPR of SC-FDMA signals effectively with almost the same BER as the conventional SC-FDMA signals when the signal-to-noise ratio (SNR) is below 35 dB.",
Developing Trends in Aptamer-Based Biosensor Devices and Their Applications,"Aptamers are, in general, easier to produce, easier to store and are able to bind to a wider variety of targets than antibodies. For these reasons, aptamers are gaining increasing popularity in environmental monitoring as well as disease detection and disease management applications. This review article examines the research and design of RNA and DNA aptamer based biosensor systems and applications as well as their potential for integration in effective biosensor devices. As single stranded DNA or RNA molecules that can bind to specific targets, aptamers are well suited for biomolecular recognition and sensing applications. Beyond being able to be designed for a near endless number of specific targets, aptamers can also be made which change their conformation in a predictable and consistent way upon binding. This can lead to many unique and effective detection methods using a variety of optical and electrochemical means.","Gold,
Biosensors,
Nanoparticles,
Biomedical optical imaging,
Optical sensors,
DNA"
An Analysis of Failure-Related Energy Waste in a Large-Scale Cloud Environment,"Cloud computing providers are under great pressure to reduce operational costs through improved energy utilization while provisioning dependable service to customers; it is therefore extremely important to understand and quantify the explicit impact of failures within a system in terms of energy costs. This paper presents the first comprehensive analysis of the impact of failures on energy consumption in a real-world large-scale cloud system (comprising over 12 500 servers), including the study of failure and energy trends of the spatial and temporal environmental characteristics. Our results show that 88% of task failure events occur in lower priority tasks producing 13% of total energy waste, and 1% of failure events occur in higher priority tasks due to server failures producing 8% of total energy waste. These results highlight an unintuitive but significant impact on energy consumption due to failures, providing a strong foundation for research into dependable energy-aware cloud computing.","Waste management,
Cloud computing,
Computer crashes,
Hardware,
Energy consumption,
Failure analysis"
Multifeature-Based Surround Inhibition Improves Contour Detection in Natural Images,"To effectively perform visual tasks like detecting contours, the visual system normally needs to integrate multiple visual features. Sufficient physiological studies have revealed that for a large number of neurons in the primary visual cortex (V1) of monkeys and cats, neuronal responses elicited by the stimuli placed within the classical receptive field (CRF) are substantially modulated, normally inhibited, when difference exists between the CRF and its surround, namely, non-CRF, for various local features. The exquisite sensitivity of V1 neurons to the center-surround stimulus configuration is thought to serve important perceptual functions, including contour detection. In this paper, we propose a biologically motivated model to improve the performance of perceptually salient contour detection. The main contribution is the multifeature-based center-surround framework, in which the surround inhibition weights of individual features, including orientation, luminance, and luminance contrast, are combined according to a scale-guided strategy, and the combined weights are then used to modulate the final surround inhibition of the neurons. The performance was compared with that of single-cue-based models and other existing methods (especially other biologically motivated ones). The results show that combining multiple cues can substantially improve the performance of contour detection compared with the models using single cue. In general, luminance and luminance contrast contribute much more than orientation to the specific task of contour extraction, at least in gray-scale natural images.","Neurons,
Visualization,
Visual systems,
Feature extraction,
Computational modeling,
Vectors"
Indexing Graphs for Path Queries with Applications in Genome Research,"We propose a generic approach to replace the canonical sequence representation of genomes with graph representations, and study several applications of such extensions. We extend the Burrows-Wheeler transform (BWT) of strings to acyclic directed labeled graphs, to support path queries as an extension to substring searching. We develop, apply, and tailor this technique to a) read alignment on an extended BWT index of a graph representing pan-genome, i.e., reference genome and known variants of it; and b) split-read alignment on an extended BWT index of a splicing graph. Other possible applications include probe/primer design, alignments to assembly graphs, and alignments to phylogenetic tree of partial-order graphs. We report several experiments on the feasibility and applicability of the approach. Especially on highly-polymorphic genome regions our pan-genome index is making a significant improvement in alignment accuracy.","Automata,
Indexes,
Bioinformatics,
Vectors,
Arrays,
Transforms,
Genomics"
Two-Stage Framework for Efficient Gaussian Process Modeling of Antenna Input Characteristics,"A two-stage approach based on Gaussian process regression that achieves significantly reduced requirements for computationally expensive high-fidelity training data is presented for the modeling of planar antenna input characteristics. Our method involves variable-fidelity electromagnetic simulations. In the first stage, a mapping between electromagnetic models (simulations) of low and high fidelity is learned, which allows us to substantially reduce (by 80% or more) the computational effort necessary to set up the high-fidelity training data sets for the actual surrogate models (second stage), with negligible loss in predictive power. We illustrate our method by modeling the input characteristics of three antenna structures with up to seven design variables. The accuracy of the two-stage method is confirmed by the successful use of the surrogates within a space-mapping-based optimization/design framework.",
Novel Techniques for High-Sensitivity Hardware Trojan Detection Using Thermal and Power Maps,"Hardware Trojans are malicious alterations or injections of unwanted circuitry to integrated circuits (ICs) by untrustworthy factories. They render great threat to the security of modern ICs by various unwanted activities such as bypassing or disabling the security fence of a system, leaking confidential information, deranging, or destroying the entire chip. Traditional testing strategies are becoming ineffective since these techniques suffer from decreased sensitivity toward small Trojans because of oversized chip and large amount of process variation present in nanometer technologies. The production volume along with decreased controllability and observability to complex ICs internals make it difficult to efficiently perform Trojan detection using typical structural tests like path latency and leakage power. In this paper, we propose a completely new post-silicon multimodal approach using runtime thermal and power maps for Trojan detection and localization. Utilizing the novel framework, we propose two different Trojan detection methods involving 2-D principal component analysis. First, supervised thresholding in case training data set is available and second, unsupervised clustering which require no prior characterization data of the chip. We introduce 11 regularization in the thermal to power inversion procedure which improves Trojan detection accuracy. To characterize ICs accurately, we perform our experiments in presence of realistic CMOS process variation. Our experimental evaluations reveal that our proposed methodology can detect very small Trojans with 3-4 orders of magnitude smaller power consumptions than the total power usage of the chip, while it scales very well because of the spatial view to ICs internals by the thermal mapping.","Trojan horses,
Intrusion detection,
Principal component analysis,
CMOS process,
Clustering methods"
TEAM: Trust-Extended Authentication Mechanism for Vehicular Ad Hoc Networks,"The security of vehicular ad hoc networks (VANETs) has been receiving a significant amount of attention in the field of wireless mobile networking because VANETs are vulnerable to malicious attacks. A number of secure authentication schemes based on asymmetric cryptography have been proposed to prevent such attacks. However, these schemes are not suitable for highly dynamic environments such as VANETs, because they cannot efficiently cope with the authentication procedure. Hence, this still calls for an efficient authentication scheme for VANETs. In this paper, we propose a decentralized lightweight authentication scheme called trust-extended authentication mechanism (TEAM) for vehicle-to-vehicle communication networks. TEAM adopts the concept of transitive trust relationships to improve the performance of the authentication procedure and only needs a few storage spaces. Moreover, TEAM satisfies the following security requirements: anonymity, location privacy, mutual authentication, forgery attack resistance, modification attack resistance, replay attack resistance, no clock synchronization problem, no verification table, fast error detection, perfect forward secrecy, man-in-the-middle attack resistance, and session key agreement.","Authentication,
Vehicular ad hoc networks,
Phase shift keying,
Resistance"
Synergistic circuit and system design for energy-efficient and robust domain wall caches,"Non-volatile memories are gaining significant attention for embedded cache application due to their low standby power and excellent retention. Domain wall memory (DWM) is one possible candidate due to its ability to store multiple bits per cell in order to break the density barrier. Additionally, it provides low standby power, fast access time, good endurance and retention. However, it suffers from poor write latency, shift latency, shift power and write power. DWM is sequential in nature and latency of read/write operations depends on the offset of the bit from the read/write head. This paper investigates the circuit design challenges such as bitcell layout, head positioning, utilization factor of the nanowire, shift power, shift latency and provides solutions to deal with these issues. A synergistic system is proposed by combining circuit techniques such as merged read/write heads (for compact layout), flipped-bitcell and shift gating (for shift power optimization), wordline (WL) strapping (for access latency), shift circuit design with micro-architectural techniques such as segmented cache to realize energy-efficient and robust DWM cache. Simulations show 3-33% better performance and 1.25X-14.4X better power over a wide range of PARSEC benchmarks.",
Confucius: A Tool Supporting Collaborative Scientific Workflow Composition,"Modern scientific data management and analysis usually rely on multiple scientists with diverse expertise. In recent years, such a collaborative effort is often structured and automated by a data flow-oriented process called scientific workflow. However, such workflows may have to be designed and revised among multiple scientists over a long time period. Existing workbenches are single user-oriented and do not support scientific workflow application development in a ""collaborative fashion"". In this paper, we report our research on the enabling techniques in the aspects of collaboration provenance management and reproduciability. Based on a scientific collaboration ontology, we propose a service-oriented collaboration model supported by a set of composable collaboration primitives and patterns. The collaboration protocols are then applied to support effective concurrency control in the process of collaborative workflow composition. We also report the design and development of Confucius, a service-oriented collaborative scientific workflow composition tool that extends an open-source, single-user development environment.",
3D human action segmentation and recognition using pose kinetic energy,"Human action recognition is challenging, due to large temporal and spatial variations in actions performed by humans. These variations include significant nonlinear temporal stretching. In this paper, we propose an intuitively simple method to extract action templates from 3D human joint data that is insensitive to nonlinear stretching. The extracted action templates are used as the training instances of the actions to train multiple classifiers including a multi-class SVM classifier. Given an unknown action, we first extract and classify all its constituent atomic actions and then assign the action label via an equal voting scheme. We have tested the method on two public datasets that contain 3D human skeleton data. The experimental results show the proposed method can obtain a comparable or better performance than published state-of-the-art methods. Additional experiments also demonstrate the method works robustly on randomly stretched actions.","Three-dimensional displays,
Hidden Markov models,
Joints,
Feature extraction,
Kinetic energy,
Training"
Physics-Based Device-Level Power Electronic Circuit Hardware Emulation on FPGA,"Accurate models of power electronic devices are necessary for hardware-in-the-loop (HIL) simulators. This paper proposes a digital hardware emulation of device-level models for the insulated gate bipolar transistor (IGBT) and the power diode on the field programmable gate array (FPGA). The hardware emulation utilizes detailed physics-based nonlinear models for these devices, and features a fully paralleled implementation using an accurate floating-point data representation in VHSIC hardware description language (VHDL) language. A dc-dc buck converter circuit is emulated to validate the hardware IGBT and diode models, and the nonlinear circuit simulation process. The captured oscilloscope results demonstrate high accuracy of the emulator in comparison to the offline simulation of the original system using Saber software.","Integrated circuit modeling,
Circuit simulation,
Parallel processing,
Field programmable gate arrays,
Insulated gate bipolar transistors,
Parallel algorithms,
Semiconductor diodes"
Development of a Mechatronics-Based Citizen Science Platform for Aquatic Environmental Monitoring,"In this paper, we present the design and proof of concept of a low-cost, self-sustained mobile surface vehicle for environmental monitoring. The vehicle is equipped with water quality sensors and cameras for image acquisition and two thrusters allowing it to maneuver. The device is part of a citizen science system wherein volunteers help in the environmental recovery of polluted bodies of water by performing online research and classification tasks. While aiding in environmental recovery, the users become more proficient in wildlife classification and water quality assessment. Telemetry collected by the vehicle is wirelessly uploaded to a web-based interface allowing volunteers to access images, positioning information, and water quality sensor data. The citizen science system allows for the study of social networking and human-computer interaction based on user activity. Specifically, the platform can be utilized to experiment with different interfaces and social interactions in hypothesis-driven research on human-computer interactions.",
In-network caching and content placement in cooperative small cell networks,"Anticipating multimedia file requests via caching at the small cell base stations (SBSs) has emerged as a promising technique for enhancing the quality-of-service (QoS) of cellular user equipments (UEs). Nevertheless, in traditional caching approaches, files are retrieved from evolved packet core (EPC) of the network, and without coordination among SBSs, which introduces new challenges of content duplication and unbalanced traffic load on the backhaul. In this paper, we propose a collaborative framework in which the SBSs can access files from the caches of other SBSs within the same network domain (i.e., connected to the same service gateway). We design a cost model for the content retrieval of contents across SBSs and from the EPC, and we propose a cost-aware decentralized algorithm, based on which the SBSs devise individual caching strategies (i.e., which files to cache, and from where). Simulation results show that the proposed cooperative caching scheme yields significant gains in terms of in-network content availability, reaching up to 21% improvement compared to a traditional approaches based on geographical distribution of the UEs.",
Fully Automatic Control of Paraplegic FES Pedaling Using Higher-Order Sliding Mode and Fuzzy Logic Control,"In this paper, a fully automatic robust control strategy is proposed for control of paraplegic pedaling using functional electrical stimulation (FES). The method is based on higher-order sliding mode (HOSM) control and fuzzy logic control. In FES, the strength of muscle contraction can be altered either by varying the pulse width (PW) or by the pulse amplitude (PA) of the stimulation signal. The proposed control strategy regulates simultaneously both PA and PW (i.e., PA/PW modulation). A HOSM controller is designed for regulating the PW and a fuzzy logic controller for the PA. The proposed control scheme is free-model and does not require any offline training phase and subject-specific information. Simulation studies on a virtual patient and experiments on three paraplegic subjects demonstrate good tracking performance and robustness of the proposed control strategy against muscle fatigue and external disturbances during FES-induced pedaling. The results of simulation studies show that the power and cadence tracking errors are 5.4% and 4.8%, respectively. The experimental results indicate that the proposed controller can improve pedaling system efficacy and increase the endurance of FES pedaling. The average of power tracking error over three paraplegic subjects is 7.4±1.4% using PA/PW modulation, while the tracking error is 10.2±1.2% when PW modulation is used. The subjects could pedal for 15 min with about 4.1% power loss at the end of experiment using proposed control strategy, while the power loss is 14.3% using PW modulation. The controller could adjust the stimulation intensity to compensate the muscle fatigue during long period of FES pedaling.","Muscles,
Fuzzy logic,
Modulation,
Fatigue,
Joints,
Hip,
Torque"
JPEG Anti-Forensics With Improved Tradeoff Between Forensic Undetectability and Image Quality,"This paper proposes a JPEG anti-forensic method, which aims at removing from a given image the footprints left by JPEG compression, in both the spatial domain and DCT domain. With reasonable loss of image quality, the proposed method can defeat existing forensic detectors that attempt to identify traces of the image JPEG compression history or JPEG anti-forensic processing. In our framework, first because of a total variation-based deblocking operation, the partly recovered DCT information is thereafter used to build an adaptive local dithering signal model, which is able to bring the DCT histogram of the processed image close to that of the original one. Then, a perceptual DCT histogram smoothing is carried out by solving a simplified assignment problem, where the cost function is established as the total perceptual quality loss due to the DCT coefficient modification. The second-round deblocking and de-calibration operations successfully bring the image statistics that are used by the JPEG forensic detectors to the normal status. Experimental results show that the proposed method outperforms the state-of-the-art methods in a better tradeoff between the JPEG forensic undetectability and the visual quality of processed images. Moreover, the application of the proposed anti-forensic method in disguising double JPEG compression artifacts is proven to be feasible by experiments.","Transform coding,
Discrete cosine transforms,
Image coding,
Forensics,
Detectors,
Histograms,
Quantization (signal)"
Application-Adaptive Guardbanding to Mitigate Static and Dynamic Variability,"Traditional application execution assumes an error-free execution hardware and environment. Such guarantees in execution are achieved by providing guardbands in the design of microelectronic processors. In reality, applications exhibit varying degrees of tolerance to error in computations. This paper proposes an adaptive guardbanding technique to combat CMOS variability for error-tolerant (probabilistic) applications as well as traditional error-intolerant applications. The proposed technique leverages a combination of accurate design time analysis and a minimally intrusive runtime technique to mitigate Process, Voltage, and Temperature (PVT) variations for a near-zero area overhead. We demonstrate our approach on a 32-bit in-order RISC processor with full post Placement and Routing (P&R) layout results in TSMC 45 nm technology. The adaptive guardbanding technique eliminates traditional guardbands on operating frequency using information from PVT variations and application-specific requirements on computational accuracy. For error-intolerant applications, we introduce the notion of Sequence-Level Vulnerability (SLV) that utilizes circuit-level vulnerability for constructing high-level software knowledge as metadata. In effect, the SLV metadata partitions sequences of integer SPARC instructions into two equivalence classes to enable the adaptive guardbanding technique to adapt the frequency simultaneously for dynamic voltage and temperature variations, as well as adapt to the different classes of the instruction sequences. The proposed technique achieves on an average 1.6 × speedup for error-intolerant applications compared to recent work . For probabilistic applications, the adaptive technique guarantees the error-free operation of a set of paths of the processor that always require correct timing (Vulnerable Paths) while reducing the cost of guardbanding for the rest of the paths (Invulnerable Paths). This increases the throughput of probabilistic applications upto 1.9 × over the traditional worst-case design. The proposed technique has 0.022% area overhead, and imposes only 0.034% and 0.031% total power overhead for intolerant and probabilistic applications respectively.","reduced instruction set computing,
CMOS integrated circuits,
integrated circuit layout,
microprocessor chips,
probability"
A Dynamic Path Planning Approach for Multirobot Sensor-Based Coverage Considering Energy Constraints,"Multirobot sensor-based coverage path planning determines a tour for each robot in a team such that every point in a given workspace is covered by at least one robot using its sensors. In sensor-based coverage of narrow spaces, i.e., obstacles lie within the sensor range, a generalized Voronoi diagram (GVD)-based graph can be used to model the environment. A complete sensor-based coverage path plan for the robot team can be obtained by using the capacitated arc routing problem solution methods on the GVD-based graph. Unlike capacitated arc routing problem, sensor-based coverage problem requires to consider two types of edge demands. Therefore, modified Ulusoy algorithm is used to obtain mobile robot tours by taking into account two different energy consumption cases during sensor-based coverage. However, due to the partially unknown nature of the environment, the robots may encounter obstacles on their tours. This requires a replanning process that considers the remaining energy capacities and the current positions of the robots. In this paper, the modified Ulusoy algorithm is extended to incorporate this dynamic planning problem. A dynamic path-planning approach is proposed for multirobot sensor-based coverage of narrow environments by considering the energy capacities of the mobile robots. The approach is tested in a laboratory environment using Pioneer 3-DX mobile robots. Simulations are also conducted for a larger test environment.","computational geometry,
energy conservation,
energy consumption,
graph theory,
mobile robots,
multi-robot systems,
path planning,
sensors"
A Compact Transregional Model for Digital CMOS Circuits Operating Near Threshold,"Power dissipation is currently one of the most important design constraints in digital systems. In order to reduce power and energy demands in the foremost technology, namely CMOS, it is necessary to reduce the supply voltage to near the device threshold voltage. Existing analytical models for MOS devices are either too complex, thus obscuring the basic physical relations between voltages and currents, or they are inaccurate and discontinuous around the region of interest, i.e., near threshold. This paper presents a simple transregional compact model for analyzing digital circuits around the threshold voltage. The model is continuous, physically derived (by way of a simplified inversion-charge approximation), and accurate over a wide operational range: from a few times the thermal voltage to approximately twice the threshold voltage in modern technologies.","Integrated circuit modeling,
Approximation methods,
Semiconductor device modeling,
Threshold voltage,
Mathematical model,
Mobile communication,
Equations"
CMOS Startup Charge Pump With Body Bias and Backward Control for Energy Harvesting Step-Up Converters,"A new low voltage charge pump is developed to help start up a step-up converter in energy harvesting applications. The proposed charge pump is the first to utilize both backward control scheme and two branches of charge transfer switches (CTSs) to direct charge flow. The backward control scheme uses the internal boosted voltage to dynamically control the CTSs' gate, and the two branches utilize both NMOS and PMOS to implement their switching structure. The combination of backward control scheme and two-branch operation allows the CTSs to be completely turned on and off. Thus, the reverse charge sharing phenomenon and switching loss are significantly reduced, which effectively improves pumping efficiency. The last stage is specially designed to improve the charge pump's charge and capacitance drivability. Using subthreshold operation and body-bias technique, the charge pump and its clock generator can operate under a low voltage supply. The proposed charge pump circuit is designed in a standard 0.18 μm CMOS process. It consists of 6 stages, each with a 24 pF pumping capacitor (total 288 pF pumping capacitance area). Under a 320 mV supply, the measured output voltage of the proposed charge pump can rise from 0 to 2.04 V within 0.1 milliseconds.",
To Shut Them Up or to Clarify: Restraining the Spread of Rumors in Online Social Networks,"Restraining the spread of rumors in online social networks (OSNs) has long been an important but difficult problem to be addressed. Currently, there are mainly two types of methods 1) blocking rumors at the most influential users or community bridges, or 2) spreading truths to clarify the rumors. Each method claims the better performance among all the others according to their own considerations and environments. However, there must be one standing out of the rest. In this paper, we focus on this part of work. The difficulty is that there does not exist a universal standard to evaluate them. In order to address this problem, we carry out a series of empirical and theoretical analysis on the basis of the introduced mathematical model. Based on this mathematical platform, each method will be evaluated by using real OSN data. We have done three types of analysis in this work. First, we compare all the measures of locating important users. The results suggest that the degree and betweenness measures outperform all the others in the Facebook network. Second, we analyze the method of the truth clarification method, and find that this method has a long-term performance while the degree measure performs well only in the early stage. Third, in order to leverage these two methods, we further explore the strategy of different methods working together and their equivalence. Given a fixed budget in the real world, our analysis provides a potential solution to find out a better strategy by integrating both types of methods together. From both the academic and technical perspective, the work in this paper is an important step towards the most practical and optimal strategies of restraining rumors in OSNs.",
Compute-and-Forward: Finding the best equation,"Compute-and-Forward is an emerging technique to deal with interference. It allows the receiver to decode a suitably chosen integer linear combination of the transmitted messages. The integer coefficients should be adapted to the channel fading state. Optimizing these coefficients is a Shortest Lattice Vector (SLV) problem. In general, the SLV problem is known to be prohibitively complex. In this paper, we show that the particular SLV instance resulting from the Compute-and-Forward problem can be solved in low polynomial complexity and give an explicit deterministic algorithm that is guaranteed to find the optimal solution.","Vectors,
Matrix decomposition,
Complexity theory,
Equations,
Lattices,
Relays,
Mathematical model"
Information Equals Amortized Communication,"We show how to efficiently simulate the sending of a single message M to a receiver who has partial information about the message, so that the expected number of bits communicated in the simulation is close to the amount of additional information that the message reveals to the receiver. This is a generalization and strengthening of the Slepian-Wolf theorem, which shows how to carry out such a simulation with low amortized communication in the case that M is a deterministic function of X. A caveat is that our simulation is interactive. As a consequence, we prove that the internal information cost (namely the information revealed to the parties) involved in computing any relation or function using a two party interactive protocol is exactly equal to the amortized communication complexity of computing independent copies of the same relation or function. We also show that the only way to prove a strong direct sum theorem for randomized communication complexity is by solving a particular variant of the pointer jumping problem that we define. This paper implies that a strong direct sum theorem for communication complexity holds if and only if efficient compression of communication protocols is possible. In particular, together with our result, a recent result of Ganor, Kol, and Raz implies that the strongest version of direct sum for randomized communication complexity is false.","Protocols,
Complexity theory,
Receivers,
Entropy,
Random variables,
Mutual information"
Low-Complexity Soft-Output Quantum-Assisted Multiuser Detection for Direct-Sequence Spreading and Slow Subcarrier-Hopping Aided SDMA-OFDM Systems,"Low-complexity suboptimal multiuser detectors (MUDs) are widely used in multiple access communication systems for separating users, since the computational complexity of the maximum likelihood (ML) detector is potentially excessive for practical implementation. Quantum computing may be invoked in the detection procedure, by exploiting its inherent parallelism for approaching the ML MUDs performance at a substantially reduced number of cost function evaluations. In this contribution, we propose a soft-output (SO) quantum-assisted MUD achieving a near-ML performance and compare it to the corresponding SO ant colony optimization MUD. We investigate rank deficient direct-sequence spreading (DSS) and slow subcarrier-hopping aided (SSCH) spatial division multiple access orthogonal frequency division multiplexing systems, where the number of users to be detected is higher than the number of receive antenna elements used. We show that for a given complexity budget, the proposed SO-Dürr-Høyer algorithm (DHA) QMUD achieves a better performance. We also propose an adaptive hybrid SO-ML/SO-DHA MUD, which adapts itself to the number of users equipped with the same spreading sequence and transmitting on the same subcarrier. Finally, we propose a DSS-based uniform SSCH scheme, which improves the system's performance by 0.5 dB at a BER of 10-5, despite reducing the complexity required by the MUDs employed.","OFDM,
Multiuser detection,
Detectors,
Decision support systems,
Communication systems,
Computational complexity"
Generalized Higher Degree Total Variation (HDTV) Regularization,"We introduce a family of novel image regularization penalties called generalized higher degree total variation (HDTV). These penalties further extend our previously introduced HDTV penalties, which generalize the popular total variation (TV) penalty to incorporate higher degree image derivatives. We show that many of the proposed second degree extensions of TV are special cases or are closely approximated by a generalized HDTV penalty. Additionally, we propose a novel fast alternating minimization algorithm for solving image recovery problems with HDTV and generalized HDTV regularization. The new algorithm enjoys a tenfold speed up compared with the iteratively reweighted majorize minimize algorithm proposed in a previous paper. Numerical experiments on 3D magnetic resonance images and 3D microscopy images show that HDTV and generalized HDTV improve the image quality significantly compared with TV.","HDTV,
Three-dimensional displays,
Laplace equations,
Image reconstruction,
Vectors,
Approximation algorithms"
Probabilistic Reconstruction of Ancestral Gene Orders with Insertions and Deletions,"Changes of gene orderings have been extensively used as a signal to reconstruct phylogenies and ancestral genomes. Inferring the gene order of an extinct species has a wide range of applications, including the potential to reveal more detailed evolutionary histories, to determine gene content and ordering, and to understand the consequences of structural changes for organismal function and species divergence. In this study, we propose a new adjacency-based method, PMAG + , to infer ancestral genomes under a more general model of gene evolution involving gene insertions and deletions (indels), in addition to gene rearrangements. PMAG + improves on our previous method PMAG by developing a new approach to infer ancestral gene contents and reducing the adjacency assembly problem to an instance of TSP. We designed a series of experiments to extensively validate PMAG + and compared the results with the most recent and comparable method GapAdj. According to the results, ancestral gene contents predicted by PMAG + coincides highly with the actual contents with error rates less than 1 percent. Under various degrees of indels, PMAG + consistently achieves more accurate prediction of ancestral gene orders and at the same time, produces contigs very close to the actual chromosomes.","Genomics,
Biological cells,
Phylogeny,
Error analysis,
Probability,
Bioinformatics,
Computational biology"
Fast name lookup for Named Data Networking,"Complex name constitution plus huge-sized name routing table makes wire speed name lookup a challenging task in Named Data Networking. To overcome this challenge, we propose two techniques to significantly speed up the lookup process. First, we look up name prefixes in an order based on the distribution of prefix length in the forwarding table, which can find the longest match much faster than the linear search of current prototype CCNx. The search order can be dynamically adjusted as the forwarding table changes. Second, we propose a new near-perfect hash table data structure that combines many small sparse perfect hash tables into a larger dense one while keeping the worst-case access time of O(1) and supporting fast update. Also the hash table stores the signature of a key instead of the key itself, which further improves lookup speed and reduces memory use.",Bismuth
Polynomial-Time T-Depth Optimization of Clifford+T Circuits Via Matroid Partitioning,"Most work in quantum circuit optimization has been performed in isolation from the results of quantum fault-tolerance. Here we present a polynomial-time algorithm for optimizing quantum circuits that takes the actual implementation of fault-tolerant logical gates into consideration. Our algorithm resynthesizes quantum circuits composed of Clifford group and T gates, the latter being typically the most costly gate in fault-tolerant models, e.g., those based on the Steane or surface codes, with the purpose of minimizing both T-count and T-depth. A major feature of the algorithm is the ability to resynthesize circuits with ancillae at effectively no additional cost, allowing space-time trade-offs to be easily explored. The tested benchmarks show up to 65.7% reduction in T-count and up to 87.6% reduction in T-depth without ancillae, or 99.7% reduction in T-depth using ancillae.",
Hierarchical Lung Field Segmentation With Joint Shape and Appearance Sparse Learning,"Lung field segmentation in the posterior-anterior (PA) chest radiograph is important for pulmonary disease diagnosis and hemodialysis treatment. Due to high shape variation and boundary ambiguity, accurate lung field segmentation from chest radiograph is still a challenging task. To tackle these challenges, we propose a joint shape and appearance sparse learning method for robust and accurate lung field segmentation. The main contributions of this paper are: 1) a robust shape initialization method is designed to achieve an initial shape that is close to the lung boundary under segmentation; 2) a set of local sparse shape composition models are built based on local lung shape segments to overcome the high shape variations; 3) a set of local appearance models are similarly adopted by using sparse representation to capture the appearance characteristics in local lung boundary segments, thus effectively dealing with the lung boundary ambiguity; 4) a hierarchical deformable segmentation framework is proposed to integrate the scale-dependent shape and appearance information together for robust and accurate segmentation. Our method is evaluated on 247 PA chest radiographs in a public dataset. The experimental results show that the proposed local shape and appearance models outperform the conventional shape and appearance models. Compared with most of the state-of-the-art lung field segmentation methods under comparison, our method also shows a higher accuracy, which is comparable to the inter-observer annotation variation.",
Poster: A simulator for heterogeneous vehicular networks,"We are aiming to better investigate heterogeneous vehicular networking technologies to overcome the shortcomings of using just a single wireless technology. Performance evaluation is usually done using simulation, for which we need integrated tools supporting WiFi, IEEE 802.11p, cellular technology, and mobility feedback. The established vehicular networking simulators such as Veins, iTETRIS, or VSimRTI, however, currently have no support for such heterogeneous networking, in particular for Long Term Evolution (LTE). We present a new integrated simulation framework based on the popular and mature Veins framework named VeinsLTE. We present early results that clearly demonstrate the potential of this integrated approach.","Vehicles,
Veins,
Conferences,
Long Term Evolution,
Delays,
Computational modeling,
Wireless LAN"
A 3-D Semi-Implicit Method for Computing the Current Density in Bulk Superconductors,A semi-implicit approach is proposed for computing the current density in superconductors characterized by nonlinear vectorial power law. A nodal discontinuous Galerkin method is adopted for the spatial discretization of the nonlinear system satisfied by the components of the electric field. Explicit developments are used to construct boundary conditions to avoid the modeling of a volume around the superconducting sample. A modified Newton iterative method is introduced for solving the discrete system. Numerical examples on a 2-D superconducting plate and a 3-D superconducting cube are computed. Distributions of a component of the current density are presented and differences in the diffusive process are highlighted. The penetration time and losses are compared with those obtained with an A-V formulation solved by a finite-volume method.,"High-temperature superconductors,
Boundary conditions,
Demagnetization,
Current density,
Method of moments,
Equations"
Design and Evaluation of Interactive Proofreading Tools for Connectomics,"Proofreading refers to the manual correction of automatic segmentations of image data. In connectomics, electron microscopy data is acquired at nanometer-scale resolution and results in very large image volumes of brain tissue that require fully automatic segmentation algorithms to identify cell boundaries. However, these algorithms require hundreds of corrections per cubic micron of tissue. Even though this task is time consuming, it is fairly easy for humans to perform corrections through splitting, merging, and adjusting segments during proofreading. In this paper we present the design and implementation of Mojo, a fully-featured single-user desktop application for proofreading, and Dojo, a multi-user web-based application for collaborative proofreading. We evaluate the accuracy and speed of Mojo, Dojo, and Raveler, a proofreading tool from Janelia Farm, through a quantitative user study. We designed a between-subjects experiment and asked non-experts to proofread neurons in a publicly available connectomics dataset. Our results show a significant improvement of corrections using web-based Dojo, when given the same amount of time. In addition, all participants using Dojo reported better usability. We discuss our findings and provide an analysis of requirements for designing visual proofreading software.","Image segmentation,
Three-dimensional displays,
Interactive systems,
Rendering (computer graphics),
Data visualization"
Ordinal Feature Selection for Iris and Palmprint Recognition,"Ordinal measures have been demonstrated as an effective feature representation model for iris and palmprint recognition. However, ordinal measures are a general concept of image analysis and numerous variants with different parameter settings, such as location, scale, orientation, and so on, can be derived to construct a huge feature space. This paper proposes a novel optimization formulation for ordinal feature selection with successful applications to both iris and palmprint recognition. The objective function of the proposed feature selection method has two parts, i.e., misclassification error of intra and interclass matching samples and weighted sparsity of ordinal feature descriptors. Therefore, the feature selection aims to achieve an accurate and sparse representation of ordinal measures. And, the optimization subjects to a number of linear inequality constraints, which require that all intra and interclass matching pairs are well separated with a large margin. Ordinal feature selection is formulated as a linear programming (LP) problem so that a solution can be efficiently obtained even on a large-scale feature pool and training database. Extensive experimental results demonstrate that the proposed LP formulation is advantageous over existing feature selection methods, such as mRMR, ReliefF, Boosting, and Lasso for biometric recognition, reporting state-of-the-art accuracy on CASIA and PolyU databases.","Linear programming,
Training,
Iris recognition,
Optimization,
Biomedical imaging,
Databases,
Boosting"
UnetStack: An agent-based software stack and simulator for underwater networks,"To deploy successful underwater networks in the face of challenges such as low bandwidth, long propagation delay, half-duplex nature of links, high packet loss and time variability, we require highly optimized network protocols with low overhead and significant cross-layer information sharing. UnetStack is a network stack designed to provide a good balance between separation of concern, and information sharing. By replacing a traditional layered stack architecture by an agent-based architecture, we provide additional flexibility that allows novel protocols to be easily implemented, deployed and tested. In discrete-event simulation mode, UnetStack can be used on desktop/laptop computers or computing clusters to simulate underwater networks and test protocol performance. In real-time simulation mode, it can be used to interactively debug protocol implementations, and test deployment scenarios prior to an experiment. Once tested, the protocols can simply be copied to an underwater modem with UnetStack support, and deployed in the field. The stack implementation has been extensively tested, not only through carefully calibrated simulations, but also in several field experiments. We provide an overview of UnetStack and briefly discuss a few deployments to illustrate some of its key features.","Protocols,
Modems,
Reliability,
Peer-to-peer computing,
Waste materials,
Distance measurement,
Computer architecture"
Single image 3D object detection and pose estimation for grasping,We present a novel approach for detecting objects and estimating their 3D pose in single images of cluttered scenes. Objects are given in terms of 3D models without accompanying texture cues. A deformable parts-based model is trained on clusters of silhouettes of similar poses and produces hypotheses about possible object locations at test time. Objects are simultaneously segmented and verified inside each hypothesis bounding region by selecting the set of superpixels whose collective shape matches the model silhouette. A final iteration on the 6-DOF object pose minimizes the distance between the selected image contours and the actual projection of the 3D model. We demonstrate successful grasps using our detection and pose estimate with a PR2 robot. Extensive evaluation with a novel ground truth dataset shows the considerable benefit of using shape-driven cues for detecting objects in heavily cluttered scenes.,
Strained Growth of Aluminum-Doped Zinc Oxide on Flexible Glass Substrate and Degradation Studies Under Cyclic Bending Conditions,"Aluminum-doped zinc oxide (AZO) thin films have been used in low cost transparent conductive oxide (TCO) applications. For flexible electronics, the devices are subjected to cyclic bending during manufacturing and usage, which may lead to both electrical and optical degradation of TCO thin films. This paper was designed to investigate the effect of the strained growth and normal growth methods on the electrical and optical degradation under diverse cyclic bending conditions. The AZO thin films were deposited on a 100 μm thick Corning Willow Glass flexible substrate by using an RF-magnetron sputtering technique. The design of experiments technique was applied to analyze the significant factors that can affect the electrical and optical performance of AZO thin films. The experimental factors include growth methods, bending radius, and tension. From the analysis of the X-ray diffraction technique, the AZO thin films grown by the normal method have dominant (0 0 2) orientation, but the AZO thin films prepared by the strained growth method show other orientations, including (0 0 2) orientation. Although the strained growth method does change the AZO thin film properties, the strained growth method does not significantly improve the reliability of the AZO thin film after a 2000 cycle bending fatigue test.","Substrates,
Glass,
Degradation,
Analysis of variance,
Optical films,
Resistance"
Autonomous robotic system for bridge deck data collection and analysis,"Bridge deck inspection is conducted to identify bridge condition deterioration and, thus, to facilitate implementation of appropriate maintenance or rehabilitation procedures. In this paper, we report the development of a robotic system for bridge deck data collection and analysis. The robotic system accurately localizes itself and autonomously maneuvers on the bridge deck to collect visual images and conduct nondestructive evaluation (NDE) measurements. The developed robotic system can reduce the cost and time of the bridge deck data collection. Crack detection and mapping algorithm to build the deck crack maps is presented in detail. The electrical resistivity (ER), impact-echo (IE) and ultrasonic surface waves (USW) data collected by the robot are analyzed to generate the corrosion, delamination and concrete elastic modulus maps of the deck. The presented robotic system has been successfully deployed to inspect numerous bridges.",
"Low-Latency Digit-Serial Systolic Double Basis Multiplier over \mbi GF{(2^m})
Using Subquadratic Toeplitz Matrix-Vector Product Approach","Recently in cryptography and security, the multipliers with subquadratic space complexity for trinomials and some specific pentanomials have been proposed. For such kind of multipliers, alternatively, we use double basis multiplication which combines the polynomial basis and the modified polynomial basis to develop a new efficient digit-serial systolic multiplier. The proposed multiplier depends on trinomials and almost equally space pentanomials (AESPs), and utilizes the subquadratic Toeplitz matrix-vector product scheme to derive a low-latency digit-serial systolic architecture. If the selected digit-size is d bits, the proposed digit-serial multiplier for both polynomials, i.e., trinomials and AESPs, requires the latency of 2⌈√{m/d⌉, while traditional ones take at least O(⌈m/d⌉) clock cycles. Analytical and application-specific integrated circuit (ASIC) synthesis results indicate that both the area and the time × area complexities of our proposed architecture are significantly lower than the existing digit-serial systolic multipliers.","Polynomials,
Complexity theory,
Computer architecture,
Vectors,
Educational institutions,
Electronic mail,
Clocks"
ERNN: A Biologically Inspired Feedforward Neural Network to Discriminate Emotion From EEG Signal,"Emotions play an important role in human cognition, perception, decision making, and interaction. This paper presents a six-layer biologically inspired feedforward neural network to discriminate human emotions from EEG. The neural network comprises a shift register memory after spectral filtering for the input layer, and the estimation of coherence between each pair of input signals for the hidden layer. EEG data are collected from 57 healthy participants from eight locations while subjected to audio-visual stimuli. Discrimination of emotions from EEG is investigated based on valence and arousal levels. The accuracy of the proposed neural network is compared with various feature extraction methods and feedforward learning algorithms. The results showed that the highest accuracy is achieved when using the proposed neural network with a type of radial basis function.","Electroencephalography,
Biological neural networks,
Feedforward neural networks,
Feature extraction,
Computer architecture,
Brain models"
NEIWalk: Community Discovery in Dynamic Content-Based Networks,"Recently, discovering dynamic communities has become an increasingly important task. Many algorithms have been proposed, most of which only use linkage structure. However, rich information is encoded in the content of social networks such as node content and edge content, which is essential to discover topically meaningful communities. Therefore, to detect both structurally and topically meaningful communities, linkage structure, node content and edge content should be integrated. The main challenge lies in how to integrate them dynamically in a seamless way. This paper proposes a novel transformation of content-based network into a Node-Edge Interaction (NEI) network where linkage structure, node content and edge content are embedded seamlessly. A differential activity based approach is proposed to incrementally maintain the NEI network as the content-based network evolves. To capture the semantic effect of different edge types, a transition probability matrix is devised for the NEI network. Based on this, heterogeneous random walk is applied to discover dynamic communities, leading to a new dynamic community detection method termed NEIWalk (NEI network based random Walk). Theoretical analysis shows that the proposed NEIWalk method gets a bounded accuracy loss due to the random walk sampling. Experimental results demonstrate the effectiveness and efficiency of NEIWalk.","Communities,
Couplings,
Image edge detection,
Social network services,
Semantics,
Heuristic algorithms,
Educational institutions"
A Wideband High-Isolated Dual-Polarized Patch Antenna Using Two Different Balun Feedings,"In this letter, a dual-polarized patch antenna with low profile and wide bandwidth is presented. The square patch, where a bow-tie slot is etched on, is excited by two different balance-to-unbalance feedings for dual polarization. One of the polarizations is excited by the central-placed transition, which transfers the unbalanced microstripline feed to the balanced slot feed. The other polarization is excited by a differential feed network, which contains two capacitively coupled probe feeds. By adopting the two balanced feedings, high isolation and low cross polarization are achieved. A prototype of the proposed antenna is built and tested. Measured results show that the -10-dB reflection coefficient bandwidth of the two polarizations is about 18.8%, with port isolation less than -28.5 dB.",
Byzantine-Resilient Secure Software-Defined Networks with Multiple Controllers in Cloud,"Software-defined network (SDN) is the next generation of networking architecture that is dynamic, manageable, cost-effective, and adaptable, making it ideal for the high-bandwidth, dynamic nature of today's applications. In SDN, network management is facilitated through software rather than low-level device configurations. However, the centralized control plane introduced by SDN imposes a great challenge for the network security. In this paper, we present a secure SDN structure, in which each device is managed by multiple controllers, not just a single as in a traditional manner, with the dynamic and isolated instance provided by the cloud. It can resist Byzantine attacks on controllers and the communication links between controllers and SDN switches. Furthermore, we study a controller minimization problem with security requirement and propose a cost-efficient controller assignment algorithm with a constant approximation ratio. From the experiment result, the secure SDN structure has little impact on the network latency, provide better security than general distributed controller, and the proposed algorithm performs higher efficiency than random assignment.","Control systems,
Computer security,
IP networks,
Ports (Computers),
Software,
Cloud computing,
Fault tolerant systems"
Mode Switching Feedback Compensation Considering Rolling Friction Characteristics for Fast and Precise Positioning,"This paper presents a mode switching feedback (FB) compensation methodology based on rolling friction models for the fast and precise positioning of table drive systems. Rolling friction in the table drive mechanisms behaves as a nonlinear elastic component in the micro displacement region and deteriorates the position settling performance with slow responses. Effects of the rolling friction on the positioning, therefore, should be compensated to provide the desired control performance. The authors have already proposed a rolling friction model-based friction compensation scheme to improve the slow settling responses. The conventional approach, however, could not suppress vibratory settling responses due to unknown model errors and/or plant perturbations, and there still remains the performance deterioration in the positioning accuracy to be solved. In this research, therefore, a novel mode switching FB compensation considering the rolling friction properties is applied to provide the desired settling performance with well-suppression of both vibratory response and slow response. The feature of the proposed approach is that the vibratory and slow responses at the settling are handled as an initial value response of the FB control system in the micro displacement region and can be suppressed in a mode switching control manner on the basis of initial value compensation frameworks utilizing the elastic characteristic of the rolling friction. The proposed approach has been verified by numerical simulations and experiments using a prototype of industrial table positioning devices.","Friction,
Gain,
Rheology"
Adhesive Force Characterization for MEM Logic Relays With Sub-Micron Contacting Regions,"Contact adhesive force (Fa) scaling is critical for relay miniaturization, since the actuation area and/or actuation voltage must be sufficiently large to overcome the spring restoring force (Fk) in order to turn on the relay and Fk must be larger than Fa in order to turn off the relay. In this work, contact adhesive force is investigated in MEM logic relays with contact dimple regions as small as 100 nm in lateral dimension. The results indicate that van der Waals force is predominant. An adhesive force of 0.02 nN/nm2 is extracted for tungsten-to-tungsten contact. Fa reduction should be possible with contact dimple size reduction and contact surface coating.",
Common Feature Discriminant Analysis for Matching Infrared Face Images to Optical Face Images,"In biometrics research and industry, it is critical yet a challenge to match infrared face images to optical face images. The major difficulty lies in the fact that a great discrepancy exists between the infrared face image and corresponding optical face image because they are captured by different devices (optical imaging device and infrared imaging device). This paper presents a new approach called common feature discriminant analysis to reduce this great discrepancy and improve optical-infrared face recognition performance. In this approach, a new learning-based face descriptor is first proposed to extract the common features from heterogeneous face images (infrared face images and optical face images), and an effective matching method is then applied to the resulting features to obtain the final decision. Extensive experiments are conducted on two large and challenging optical-infrared face data sets to show the superiority of our approach over the state-of-the-art.","Face,
Vectors,
Optical imaging,
Face recognition,
Feature extraction,
Biomedical optical imaging,
Correlation"
A Kinect-based rehabilitation exercise monitoring and guidance system,"In this paper, we describe the design and implementation of a Kinect-based system for rehabilitation exercises monitoring and guidance. We choose to use the Unity framework to implement our system because it enables us to use virtual reality techniques to demonstrate detailed movements to the patient, and to facilitate examination of the quality and quantity of the patient sessions by the clinician. The avatar-based rendering of motion also preserves the privacy of the patients, which is essential for healthcare systems. The key contribution of our research is a rule-based approach to realtime exercise quality assessment and feedback. We developed a set of basic rule elements that can be used to express the correctness rules for common rehabilitation exercises.","Visualization,
Three-dimensional displays,
Joints,
Hip,
Monitoring,
Avatars,
Games"
Resonant Body Transistors in IBM's 32 nm SOI CMOS Technology,"This paper presents unreleased CMOS-integrated MEMS resonators fabricated at the transistor level of IBM's 32SOI technology and realized without the need for any postprocessing or packaging. In this technology, resonant body transistors (RBTs) are driven capacitively and sensed piezoresistively using an n-channel field effect transistor (FET). Acoustic Bragg Reflectors (ABRs) are used to localize acoustic vibrations in the unreleased resonators completely buried under the CMOS metal stack and surrounded by low-κ dielectric. FET sensing is analytically compared with alternative active and passive sensing mechanisms to benchmark CMOS-MEMS resonator performance with frequency scaling. Experimental results from the first generation hybrid CMOS-MEMS RBTs show RBTs operating above 11 GHz with Qs of 24-30 and footprints of 5 × 3 μm. Comparative behavior of devices with design variations is used to demonstrate the effect of ABRs on spurious mode suppression. In addition, the performance of the RBTs is compared with passive electrostatic resonators, which show no discernible peak. Finally, temperature stability of <;3 ppm/K due to complimentary materials in the CMOS stack is analytically and experimentally verified.","Sensors,
Field effect transistors,
Acoustics,
CMOS integrated circuits,
Noise,
Resonant frequency,
Materials"
A Novel Built-In Self-Authentication Technique to Prevent Inserting Hardware Trojans,"With the rapid globalization of the semiconductor industry, hardware Trojans have become a significant threat to government agencies and enterprises that require secure and reliable systems for their critical applications. Because of the diversity of hardware Trojans and the randomness associated with process variations, hardware Trojan detection is a challenging problem. In this paper, we propose a novel technique, called built-in self-authentication (BISA), which can be used to make hardware Trojan insertion by untrusted Graphic Data System (GDSII) developer and untrusted foundry considerably more difficult and easier to detect. The unused spaces in the circuit layout represent the best opportunity to insert Trojans by these entities. BISA works by eliminating this spare space and filling it with functional filler cells, instead of nonfunctional filler cells. A self-testing procedure generates a digital signature that will be different if any BISA cells are changed because of hardware Trojan insertion. We demonstrate that BISA can be applied to any flat or bottom-up hierarchical design with negligible overhead in terms of area, power, and timing.",
A Reliability-Aware Address Mapping Strategy for NAND Flash Memory Storage Systems,"The increasing density of NAND flash memory leads to a dramatic increase in the bit error rate of flash, which greatly reduces the ability of error correcting codes (ECC) to handle multibit errors. NAND flash memory is normally used to store the file system metadata and page mapping information. Thus, a broken physical page containing metadata may cause an unintended and severe change in functionality of the entire flash. This paper presents Meta-Cure, a novel hardware and file system interface that transparently protects metadata in the presence of multibit faults. Meta-Cure exploits built-in ECC and replication in order to protect pages containing critical data, such as file system metadata. Redundant pairs are formed at run time and distributed to different physical pages to protect against failures. Meta-Cure requires no changes to the file system, on-chip hierarchy, or hardware implementation of flash memory chip. We evaluate Meta-Cure under a real-embedded platform using a variety of I/O traces. The evaluation platform adopts dual ARM Cortex A9 processor cores with 64 Gb NAND flash memory. We have evaluated the effectiveness of Meta-Cure on the new technology file system file system. Experimental results show that the proposed technique can reduce uncorrectable page errors by 70.38% with less than 7.86% time overhead in comparison with conventional error correction techniques.","Ash,
Reliability,
Error correction codes,
Hardware,
Bit error rate,
Error correction"
Asynchronous-Channels Within Petri Net-Based GALS Distributed Embedded Systems Modeling,"Model-based development approaches can provide a major contribution in the development of globally asynchronous locally synchronous distributed embedded systems (GALS-DES) if supported by suited modeling formalisms and design automation tools. The use of Petri nets (either low-level or high-level classes) extended with asynchronous-channels (ACs), time domains, priorities, inputs, and outputs is proposed in this paper to model GALS-DES (composed by deterministic components), ensuring that the created GALS model is locally deterministic, distributable, network-independent, and platform-independent. The proposed ACs, with high level of abstraction, specify the components interaction through Petri net objects with specific attributes that unambiguously identify this interaction within the GALS model. Two algorithms are proposed to translate and decompose the GALS model into Petri net models without ACs, which can be used as inputs in model-checking tools and automatic code generators supporting GALS-DES verification and implementation. The specification of a small goods lift distributed controller illustrates the use of the proposed ACs.","Petri nets,
Synchronization,
Time-domain analysis,
Embedded systems,
Algorithm design and analysis,
Communication channels"
Kernelized Bayesian Matrix Factorization,"We extend kernelized matrix factorization with a full-Bayesian treatment and with an ability to work with multiple side information sources expressed as different kernels. Kernels have been introduced to integrate side information about the rows and columns, which is necessary for making out-of-matrix predictions. We discuss specifically binary output matrices but extensions to realvalued matrices are straightforward. We extend the state of the art in two key aspects: (i) A full-conjugate probabilistic formulation of the kernelized matrix factorization enables an efficient variational approximation, whereas full-Bayesian treatments are not computationally feasible in the earlier approaches. (ii) Multiple side information sources are included, treated as different kernels in multiple kernel learning which additionally reveals which side sources are informative. We then show that the framework can also be used for supervised and semi-supervised multilabel classification and multi-output regression, by considering samples and outputs as the domains where matrix factorization operates. Our method outperforms alternatives in predicting drug-protein interactions on two data sets. On multilabel classification, our algorithm obtains the lowest Hamming losses on 10 out of 14 data sets compared to five state-of-the-art multilabel classification algorithms. We finally show that the proposed approach outperforms alternatives in multi-output regression experiments on a yeast cell cycle data set.","Kernel,
Bayes methods,
Approximation methods,
Probabilistic logic,
Computational modeling,
Covariance matrices,
Prediction algorithms"
Image Classification Using Multiscale Information Fusion Based on Saliency Driven Nonlinear Diffusion Filtering,"In this paper, we propose saliency driven image multiscale nonlinear diffusion filtering. The resulting scale space in general preserves or even enhances semantically important structures such as edges, lines, or flow-like structures in the foreground, and inhibits and smoothes clutter in the background. The image is classified using multiscale information fusion based on the original image, the image at the final scale at which the diffusion process converges, and the image at a midscale. Our algorithm emphasizes the foreground features, which are important for image classification. The background image regions, whether considered as contexts of the foreground or noise to the foreground, can be globally handled by fusing information from different scales. Experimental tests of the effectiveness of the multiscale space for the image classification are conducted on the following publicly available datasets: 1) the PASCAL 2005 dataset; 2) the Oxford 102 flowers dataset; and 3) the Oxford 17 flowers dataset, with high classification rates.","Image classification,
Filtering,
Image edge detection,
Context,
Clutter,
Equations,
Classification algorithms"
Hierarchical Heuristic Search Using a Gaussian Mixture Model for UAV Coverage Planning,"During unmanned aerial vehicle (UAV) search missions, efficient use of UAV flight time requires flight paths that maximize the probability of finding the desired subject. The probability of detecting the desired subject based on UAV sensor information can vary in different search areas due to environment elements like varying vegetation density or lighting conditions, making it likely that the UAV can only partially detect the subject. This adds another dimension of complexity to the already difficult (NP-Hard) problem of finding an optimal search path. We present a new class of algorithms that account for partial detection in the form of a task difficulty map and produce paths that approximate the payoff of optimal solutions. The algorithms use the mode goodness ratio heuristic that uses a Gaussian mixture model to prioritize search subregions. The algorithms search for effective paths through the parameter space at different levels of resolution. We compare the performance of the new algorithms against two published algorithms (Bourgault's algorithm and LHC-GW-CONV algorithm) in simulated searches with three real search and rescue scenarios, and show that the new algorithms outperform existing algorithms significantly and can yield efficient paths that yield payoffs near the optimal.","Path planning,
Unmanned aerial vehicles,
Heuristic algorithms,
Hierarchical systems,
Navigation,
Gaussian mixture model"
Analyzing Cognitive Network Access Efficiency Under Limited Spectrum Handoff Agility,"Most existing studies on cognitive-radio networks assume that cognitive users (CUs) can switch to any available channel, regardless of the frequency gap between a target channel and the current channel. However, due to hardware limitations, CUs can actually jump only so far from where the operating frequency of their current channel is. This paper studies the performance of cognitive-radio networks while considering realistic channel handoff agility, where CUs can only switch to their neighboring channels. We use a continuous-time Markov process to derive and analyze the forced termination and blocking probabilities of CUs. Using these derived probabilities, we then study and analyze the impact of limited spectrum handoff agility on cognitive spectrum access efficiency. We show that accounting for realistic spectrum handoff agility reduces performance of cognitive-radio networks in terms of spectrum access capability and efficiency.","Cognitive radio,
Switches,
Markov processes,
Analytical models,
Delays,
Adaptation models,
Educational institutions"
A Hierarchical System for a Distributed Representation of the Peripersonal Space of a Humanoid Robot,"Reaching a target object in an unknown and unstructured environment is easily performed by human beings. However, designing a humanoid robot that executes the same task requires the implementation of complex abilities, such as identifying the target in the visual field, estimating its spatial location, and precisely driving the motors of the arm to reach it. While research usually tackles the development of such abilities singularly, in this work we integrate a number of computational models into a unified framework, and demonstrate in a humanoid torso the feasibility of an integrated working representation of its peripersonal space. To achieve this goal, we propose a cognitive architecture that connects several models inspired by neural circuits of the visual, frontal and posterior parietal cortices of the brain. The outcome of the integration process is a system that allows the robot to create its internal model and its representation of the surrounding space by interacting with the environment directly, through a mutual adaptation of perception and action. The robot is eventually capable of executing a set of tasks, such as recognizing, gazing and reaching target objects, which can work separately or cooperate for supporting more structured and effective behaviors.","Visualization,
Robot sensing systems,
Brain models,
Humanoid robots,
Object recognition"
Performance Modeling and Evaluation of Peer-to-Peer Live Streaming Systems Under Flash Crowds,"A peer-to-peer (P2P) live streaming system faces a big challenge under flash crowds. When a flash crowd occurs, the sudden arrival of numerous peers may starve the upload capacity of the system, hurt its quality of service, and even cause system collapse. This paper provides a comprehensive study on the performance of P2P live streaming systems under flash crowds. By modeling the systems using a fluid model, we study the system capacity, peer startup latency, and system recovery time of systems with and without admission control for flash crowds, respectively. Our study demonstrates that, without admission control, a P2P live streaming system has limited capacity to handle flash crowds. We quantify this capacity by the largest flash crowd (measured in shock level) that the system can handle, and further find this capacity is independent of system initial state while decreasing as departure rate of stable peer increases, in a power-law relationship. We also establish the mathematical relationship of flash crowd size to the worst-case peer startup latency and system recovery time. For a system with admission control, we prove that it can recover stability under flash crowds of any sizes. Moreover, its worst-case peer startup latency and system recovery time increase logarithmically with the flash crowd size. Based on the analytical results, we present detailed flash crowd handling strategies, which can be used to achieve satisfying peer startup performance while keeping system stability in the presence of flash crowds under different circumstances .","Ash,
Admission control,
Bandwidth,
Peer-to-peer computing,
Electric shock,
Mathematical model,
Media"
Density-aware detailed placement with instant legalization,"Placement consists of three stages: global placement, legalization, and detailed placement (DP). Recently, most research works have concentrated on improving global placement and legalization, but innovations in DP have been rarely seen. ICCAD13 held a DP contest that formulates the emerging placement issues into a bin-utilization metric and maximum cell displacement constraint. This paper presents a detailed placer that can effectively reduce both half-perimeter wirelength and the peak bin-utilization under the displacement constraint. The proposed lazy-update based incremental density profit function supports efficient cell swapping. Combination of lazy-update density profit function and Density-Driven Swap lets our placer achieve AOFP of 0 for the majority of the ICCAD13 test cases. The placer presented produces the best placement results among the top3 teams in the ICCAD13 contest.","Portable document format,
IEEE Xplore"
Variational Bayesian Method for Retinex,"In this paper, we propose a variational Bayesian method for Retinex to simulate and interpret how the human visual system perceives color. To construct a hierarchical Bayesian model, we use the Gibbs distributions as prior distributions for the reflectance and the illumination, and the gamma distributions for the model parameters. By assuming that the reflection function is piecewise continuous and illumination function is spatially smooth, we define the energy functions in the Gibbs distributions as a total variation function and a smooth function for the reflectance and the illumination, respectively. We then apply the variational Bayes approximation to obtain the approximation of the posterior distribution of unknowns so that the unknown images and hyperparameters are estimated simultaneously. Experimental results demonstrate the efficiency of the proposed method for providing competitive performance without additional information about the unknown parameters, and when prior information is added the proposed method outperforms the non-Bayesian-based Retinex methods we compared.","Lighting,
Approximation methods,
Bayes methods,
Reflectivity,
Approximation algorithms,
Image color analysis,
Computational modeling"
Ionizing Radiation Effects on Nonvolatile Memory Properties of Programmable Metallization Cells,"The impact of ionizing radiation on the retention and endurance of programmable metallization cells (PMC) ReRAM cells is investigated and presented for the first time, with additional work on resistance switching. This study shows that 60Co gamma-ray exposure has a minimal effect on the retention of PMC devices, up to a total ionizing dose (TID) of 2.8 Mrad (Ge30Se70), the maximum TID level tested. The retention of both high resistance states (HRS) and low resistance states (LRS) during exposure was tested. Endurance appears to be slightly reduced with gamma-ray exposure. The endurance was tested to maximum TID of 4.62 Mrad (Ge30Se70). DC response characterizations were also performed on PMC devices after cumulative dose exposures with 50 MeV protons and 100 keV electrons. The data show that PMCs are most sensitive to proton irradiation incident from the backside of the device. For the electron exposures, it is shown that the LRS is mostly unaffected, but the HRS drifts to lower resistance values with an increase in radiation exposure.","Resistance,
Silver,
Protons,
Metallization,
Read only memory,
Nonvolatile memory"
"Analytical Modeling of Capacitances for GaN HEMTs, Including Parasitic Components","In this paper, a surface potential-based terminal charge and capacitance model, including parasitic components for AlGaN/GaN HEMTs is developed. First, by solving the charge control equations, the sheet charge density in the channel is modeled with a close-form expression. Then, using this result, based on the surface potential definition, the intrinsic terminal charges and capacitances are derived consistently with current model. Finally, by introducing parasitic components, the capacitances for the full structure of the HEMT devices are given. The model is evaluated step-by-step with good agreements compared with the TCAD simulations and the experimental data. Meanwhile, the effects of bulk traps and surface traps in the capacitances are analyzed. The complete model, including currents and capacitances has been implemented in i-MOS platform for evaluations and circuit simulations.",
Microarchitectural performance characterization of irregular GPU kernels,"GPUs are increasingly being used to accelerate general-purpose applications, including applications with data-dependent, irregular memory access patterns and control flow. However, relatively little is known about the behavior of irregular GPU codes, and there has been minimal effort to quantify the ways in which they differ from regular GPGPU applications. We examine the behavior of a suite of optimized irregular CUDA applications on a cycle-accurate GPU simulator. We characterize the performance bottlenecks in each program and connect source code with microarchitectural characteristics. We also assess the impact of improvements in cache and DRAM bandwidth and latency and discuss the implications for GPU architecture design. We find that, while irregular graph codes exhibit significantly more underutilized execution cycles due to branch divergence, load imbalance, and synchronization overhead than regular programs, these factors contribute less to performance degradation than we expected. It appears that code optimizations are often able to effectively address these performance hurdles. Insufficient bandwidth and long memory latency are the biggest limiters of performance. Surprisingly, we find that applications with irregular memory access patterns are more sensitive to changes in L2 latency and bandwidth than DRAM latency and bandwidth.","Graphics processing units,
Benchmark testing,
Random access memory,
Hardware,
Kernel,
Bandwidth,
Pipelines"
Automated Biosignal Quality Analysis for Electromyography Using a One-Class Support Vector Machine,"This paper introduces the importance of biosignal quality assessment and presents a pattern classification approach to differentiate clean from contaminated electromyography (EMG) signals. Alternatively to traditional bottom-up approaches, which examine specific contaminants only, we present a top-down approach using a one-class support vector machine (SVM) trained on clean EMG and tested on artificially contaminated EMG. Both simulated and real EMG are used. Results are evaluated for each contaminant: 1) power line interference; 2) motion artifact; 3) ECG interference; 4) quantization noise; 5) analog-to-digital converter clipping; and 6) amplifier saturation, as a function of the level of signal contamination. Results show that different ranges of contamination can be detected in the EMG depending on the type of contaminant. At high levels of contamination, the SVM classifies all EMG signals as contaminated, whereas at low levels of contamination, it classifies the majority of EMG signals as contaminant free. A transition point for each contaminant is identified, where the classification accuracy drops and variance in classification increases. In some cases, contamination can be detected with the SVM when it is not visually discernible. This method is shown to be successful in detecting problems due to single contaminants but is generic to all forms of contamination in EMG.",
Design and Optimization of an Ultra Wideband and Compact Microwave Antenna for Radiometric Monitoring of Brain Temperature,"We present the modeling efforts on antenna design and frequency selection to monitor brain temperature during prolonged surgery using noninvasive microwave radiometry. A tapered log-spiral antenna design is chosen for its wideband characteristics that allow higher power collection from deep brain. Parametric analysis with the software HFSS is used to optimize antenna performance for deep brain temperature sensing. Radiometric antenna efficiency (η) is evaluated in terms of the ratio of power collected from brain to total power received by the antenna. Anatomical information extracted from several adult computed tomography scans is used to establish design parameters for constructing an accurate layered 3-D tissue phantom. This head phantom includes separate brain and scalp regions, with tissue equivalent liquids circulating at independent temperatures on either side of an intact skull. The optimized frequency band is 1.1-1.6 GHz producing an average antenna efficiency of 50.3% from a two turn log-spiral antenna. The entire sensor package is contained in a lightweight and low-profile 2.8 cm diameter by 1.5 cm high assembly that can be held in place over the skin with an electromagnetic interference shielding adhesive patch. The calculated radiometric equivalent brain temperature tracks within 0.4 °C of the measured brain phantom temperature when the brain phantom is lowered 10 °C and then returned to the original temperature (37 °C) over a 4.6-h experiment. The numerical and experimental results demonstrate that the optimized 2.5-cm log-spiral antenna is well suited for the noninvasive radiometric sensing of deep brain temperature.","Antennas,
Temperature measurement,
Phantoms,
Temperature sensors,
Microwave radiometry,
Scalp"
Hardness Assurance for Proton Direct Ionization-Induced SEEs Using a High-Energy Proton Beam,"The low-energy proton energy spectra of all shielded space environments have the same shape. This shape is easily reproduced in the laboratory by degrading a high-energy proton beam, producing a high-fidelity test environment. We use this test environment to dramatically simplify rate prediction for proton direct ionization effects, allowing the work to be done at high-energy proton facilities, on encapsulated parts, without knowledge of the IC design, and with little or no computer simulations required. Proton direct ionization (PDI) is predicted to significantly contribute to the total error rate under the conditions investigated. Scaling effects are discussed using data from 65-nm, 45-nm, and 32-nm SOI SRAMs. These data also show that grazing-angle protons will dominate the PDI-induced error rate due to their higher effective LET, so PDI hardness assurance methods must account for angular effects to be conservative. We show that this angular dependence can be exploited to quickly assess whether an IC is susceptible to PDI.","Protons,
Integrated circuits,
Error analysis,
Single event upsets,
Substrates,
Radiation effects"
MobiFish: A lightweight anti-phishing scheme for mobile phones,"Recent years have witnessed the increasing threat of phishing attacks on mobile platforms. In fact, mobile phishing is more dangerous due to the limitations of mobile phones and mobile user habits. Existing schemes designed for phishing attacks on computers/laptops cannot effectively address phishing attacks on mobile devices. This paper presents MobiFish, a novel automated lightweight anti-phishing scheme for mobile platforms. MobiFish verifies the validity of web pages and applications (Apps) by comparing the actual identity to the identity claimed by the web pages and Apps. MobiFish has been implemented on the Nexus 4 smartphone running the Android 4.2 operating system. We experimentally evaluate the performance of MobiFish with 100 phishing URLs and corresponding legitimate URLs, as well as fake Facebook Apps. The result shows that MobiFish is very effective in detecting phishing attacks on mobile phones.","Mobile communication,
Web pages,
Mobile handsets,
Optical character recognition software,
Browsers,
HTML,
Superluminescent diodes"
Dark silicon as a challenge for hardware/software co-design,"Dark Silicon refers to the observation that in future technology nodes, it may only be possible to power-on a fraction of on-chip resources (processing cores, hardware accelerators, cache blocks and so on) in order to stay within the power budget and safe thermal limits, while the other resources will have to be kept powered-off or “dark”. In other words, chips will have an abundance of transistors, i.e., more than the number that can be simultaneously powered-on. Heterogeneous computing has been proposed as one way to effectively leverage this abundance of transistors in order to increase performance, energy efficiency and even reliability within power and thermal constraints. However, several critical challenges remain to be addressed including design, automated synthesis, design space exploration and run-time management of heterogeneous dark silicon processors. The hardware/software co-design and synthesis community has potentially much to contribute in solving these new challenges introduced by dark silicon and, in particular, heterogeneous computing. In this paper, we identify and highlight some of these critical challenges, and outline some of our early research efforts in addressing them.","Silicon,
Program processors,
Reliability,
Computer architecture,
Switches,
Hardware"
Multiscale Saliency Detection Using Random Walk With Restart,"In this paper, we propose a graph-based multiscale saliency-detection algorithm by modeling eye movements as a random walk on a graph. The proposed algorithm first extracts intensity, color, and compactness features from an input image. It then constructs a fully connected graph by employing image blocks as the nodes. It assigns a high edge weight if the two connected nodes have dissimilar intensity and color features and if the ending node is more compact than the starting node. Then, the proposed algorithm computes the stationary distribution of the Markov chain on the graph as the saliency map. However, the performance of the saliency detection depends on the relative block size in an image. To provide a more reliable saliency map, we develop a coarse-to-fine refinement technique for multiscale saliency maps based on the random walk with restart (RWR). Specifically, we use the saliency map at a coarse scale as the restarting distribution of RWR at a fine scale. Experimental results demonstrate that the proposed algorithm detects visual saliency precisely and reliably. Moreover, the proposed algorithm can be efficiently used in the applications of proto-object extraction and image retargeting.","Feature extraction,
Markov processes,
Eye movements"
Modeling of Single Photon Avalanche Diode Array Detectors for PET Applications,"We developed a configurable model of single photon avalanche diodes (SPAD) array photodetectors with intelligent control and active quenching. In this model individual components can be simulated independently and subsequently linked to provide the overall detector response. The model enables the simulation of the entire detector and analysis of performance, including photon detection efficiency, timing and energy resolution. It can be used to optimize detector performance for specific applications, such as positron emission tomography (PET). The simulator consists of multiple configurable and interchangeable modules to model the array geometry as well as physical and optical characteristics based on physical models and statistical equations. Readout electronics are also simulated in an algorithmic form. Monte Carlo simulations are used to model the 511 keV annihilation photon interactions and the optical photon transport in the scintillator, as well as carrier random walk in the silicon. Different methods to extract information from the digital output signal can be investigated. The simulator paves the way to the developement of new algorithms to extract relevant information in PET, but also for other applications such as Cerenkov radiation and fluorescence microscopy. Simulation results for photon detection efficiency, energy resolution and timing resolution are reported, showing the functionality of the simulator.","Photonics,
Arrays,
Crystals,
Detectors,
Crosstalk,
Positron emission tomography,
Noise"
Thermally induced threshold voltage instability of III-Nitride MIS-HEMTs and MOSC-HEMTs: Underlying mechanisms and optimization schemes,"The mechanisms of divergent VTH-thermal-stabilities of III-nitride (III-N) MIS-HEMT and MOS-Channel-HEMT are revealed in this work. The more significant VTH-thermal-instability of MIS-HEMT is attributed to the polarized III-N barrier layer that spatially separates the critical gate-dielectric/III-N interface from the channel and allows “deeper” interface trap levels emerging above the Fermi level at pinch-off. We also reveal the influences of the barrier layer's thickness and the fixed charges (e.g. F-) in the barrier layer on VTH-thermal-stability and attempt to provide guidelines for the optimization of insulated-gate III-N power switching devices. A tailor-made normally-off MIS-HEMT with optimal tradeoff between performance and stability is thereby demonstrated, by conjunctively utilizing partially recessed gate and fluorine plasma implantation techniques.","Gallium nitride,
Logic gates,
Dielectrics,
Electron traps,
HEMTs,
Aluminum gallium nitride,
Capacitance-voltage characteristics"
Human Movement Modeling and Activity Perception Based on Fiber-Optic Sensing System,"This paper presents a flexible fiber-optic sensor-based pressure sensing system for human activity analysis and situation perception in indoor environments. In this system, a binary sensing technology is applied to reduce the data workload, and a bipedal movement-based space encoding scheme is designed to capture people's geometric information. We also develop a nonrepetitive encoding scheme to eliminate the ambiguity caused by the two-foot structure of bipedal movements. Furthermore, we propose an invariant activity representation model based on trajectory segments and their statistical distributions. In addition, a mixture model is applied to represent scenarios. The number of subjects is finally determined by Bayesian information criterion. The Bayesian network and region of interests are employed to facilitate the perception of interactions and situations. The results are obtained using distribution divergence estimation, expectation-maximization, and Bayesian network inference methods. In the experiments, we simulated an office environment and tested walk, work, rest, and talk activities for both one and two person cases. The experiment results have demonstrated that the average individual activity recognition is higher than 90%, and the situation perception rate can achieve 80%.",
Internal Model-Based Current Control of the RL Filter-Based Voltage-Sourced Converter,"Power system operates close to its operational limit to achieve a higher level of utilization of the grid infrastructure. As a result, its transient behavior is of great importance to prevent violation of the operation limits. This paper proposes an internal model control (IMC)-based approach for voltage-sourced converters (VSC) to improve their dynamic behavior. This IMC controller is designed based on a detailed model of the VSC. The proposed control approach has superior performance, i.e., faster step response and less overshoot, and higher axes decoupling than the conventional dq-current control method. The proposed IMC-based controller has a straightforward design procedure, and can be implemented using simple PI and PID controllers. Several case studies are presented to evaluate and compare the transient performance of the IMC-based controller with conventional dq current control subsequent to step changes in the set points of direct and quadrature axes current, single-phase fault, and three-phase fault.","Current control,
Power conversion,
Transfer functions,
Mathematical model,
Couplings,
Transient analysis"
Normalized Correlation-Based Quantization Modulation for Robust Watermarking,"A novel quantization watermarking method is presented in this paper, which is developed following the established feature modulation watermarking model. In this method, a feature signal is obtained by computing the normalized correlation (NC) between the host signal and a random signal. Information modulation is carried out on the generated NC by selecting a codeword from the codebook associated with the embedded information. In a simple case, the structured codebooks are designed using uniform quantizers for modulation. The watermarked signal is produced to provide the modulated NC in the sense of minimizing the embedding distortion. The performance of the NC-based quantization modulation (NCQM) is analytically investigated, in terms of the embedding distortion and the decoding error probability in the presence of valumetric scaling and additive noise attacks. Numerical simulations on artificial signals confirm the validity of our analyses and exhibit the performance advantage of NCQM over other modulation techniques. The proposed method is also simulated on real images by using the wavelet-based implementations, where the host signal is constructed by the detail coefficients of wavelet decomposition at the third level and transformed into the NC feature signal for the information modulation. Experimental results show that the proposed NCQM not only achieves the improved watermark imperceptibility and a higher embedding capacity in high-noise regimes, but also is more robust to a wide range of attacks, e.g., valumetric scaling, Gaussian filtering, additive noise, Gamma correction, and Gray-level transformations, as compared with the state-of-the-art watermarking methods.","Watermarking,
Vectors,
Modulation,
Quantization (signal),
Feature extraction,
Decoding,
Robustness"
Performance Analysis of RFID Protocols: CDMA Versus the Standard EPC Gen-2,"Radio frequency identification (RFID) is a ubiquitous wireless technology which allows objects to be identified automatically. An RFID tag is a small electronic device with an antenna and has a unique identification (ID) number. RFID tags can be categorized into passive and active tags. For passive tags, a standard communication protocol known as EPC-global Generation-2, or briefly EPC Gen-2, is currently in use. RFID systems are prone to transmission collisions due to the shared nature of the wireless channel used by tags. The EPC Gen-2 standard recommends using dynamic framed slotted ALOHA technique to solve the collision issue and to read the tag IDs successfully. Recently, some researchers have suggested to replace the dynamic framed slotted ALOHA technique used in the standard EPC Gen-2 protocol with the code division multiple access (CDMA) technique to reduce the number of collisions and to improve the tag identification procedure. In this paper, the standard EPC Gen-2 protocol and the CDMA-based tag identification schemes are modeled as absorbing Markov chain systems. Using the proposed Markov chain systems, the analytical formulae for the average number of queries and the total number of transmitted bits needed to identify all tags in an RFID system are derived for both the EPC Gen-2 protocol and the CDMA-based tag identification schemes. In the next step, the performance of the EPC Gen-2 protocol is compared with the CDMA-based tag identification schemes and it is shown that the standard EPC Gen-2 protocol outperforms the CDMA-based tag identification schemes in terms of the number of transmitted bits and the average time required to identify all tags in the system.","Protocols,
Radiofrequency identification,
Markov processes,
Standards,
Multiaccess communication,
Performance analysis"
Collaborative 20 Questions for Target Localization,"We consider the problem of 20 questions with noise for multiple players under the minimum entropy criterion in the setting of stochastic search, with application to target localization. Each player yields a noisy response to a binary query governed by a certain error probability. First, we propose a sequential policy for constructing questions that queries each player in sequence and refines the posterior of the target location. Second, we consider a joint policy that asks all players questions in parallel at each time instant and characterize the structure of the optimal policy for constructing the sequence of questions. This generalizes the single player probabilistic bisection method for stochastic search problems. Third, we prove an equivalence between the two schemes showing that, despite the fact that the sequential scheme has access to a more refined filtration, the joint scheme performs just as well on average. Fourth, we establish convergence rates of the mean-square error and derive error exponents. Finally, we obtain an extension to the case of unknown error probabilities. This framework provides a mathematical model for incorporating a human in the loop for active machine learning systems.",
Improving Performance of Networked Control Systems by Using Adaptive Buffering,"The performance of networked control systems is strongly affected by time-varying transmission delays. A traditional solution to this problem consists of storing arriving packets in a buffer which smooths delay jitter at the cost of an increased constant delay. The size of the buffer is based on either a long-term or worst case analysis of network behavior leading to poor performance when the instantaneous network behavior is different. To overcome this problem, this paper proposes the following: 1) to adapt the buffer size according to the actual delay variation; 2) to resize buffer content by using cubic spline smoothing which also reduces the signal noise; and 3) to use a Smith predictor at the controller side. Simulation results show that the adaptive buffering strategy reduces delay and packet loss probability while the spline smoothing process improves control performance even in case of constant-size buffers.","Delays,
Standards,
Splines (mathematics),
Smoothing methods,
Packet loss,
Noise"
Frame Rate Up Conversion Based on Variational Image Fusion,"This paper presents a new framework for motion compensated frame rate up conversion (FRUC) based on variational image fusion. The proposed algorithm consists of two steps: 1) generation of multiple intermediate interpolated frames and 2) fusion of those intermediate frames. In the first step, we determine four different sets of the motion vector field using four neighboring frames. We then generate intermediate interpolated frames corresponding to the determined four sets of the motion vector field, respectively. Multiple sets of the motion vector field are used to solve the occlusion problem in motion estimation. In the second step, the four intermediate interpolated frames are fused into a single frame via a variational image fusion process. For effective fusion, we determine fusion weights for each intermediate interpolated frame by minimizing the energy, which consists of a weighted- L1-norm based data energy and gradient-driven smoothness energy. Experimental results demonstrate that the proposed algorithm improves the performance of FRUC compared with the existing algorithms.","Interpolation,
Image motion analysis,
Computer vision,
Adaptive optics,
Optical imaging,
Optical filters,
Reliability"
A hybrid biogeography-based optimization and fireworks algorithm,"The paper presents a hybrid biogeography-based optimization (BBO) and fireworks algorithm (FWA) for global optimization. The key idea is to introduce the migration operator of BBO to FWA, in order to enhance information sharing among the population, and thus improve solution diversity and avoid premature convergence. A migration probability is designed to integrate the migration of BBO and the normal explosion operator of FWA, which can not only reduce the computational burden, but also achieve a better balance between solution diversification and intensification. The Gaussian explosion of the enhanced FWA (EFWA) is reserved to keep the high exploration ability of the algorithm. Experimental results on selected benchmark functions show that the hybrid BBO FWA has a significantly performance improvement in comparison with both BBO and EFWA.","Explosions,
Sparks,
Optimization,
Sociology,
Statistics,
Benchmark testing,
Convergence"
Fast T2 Mapping With Improved Accuracy Using Undersampled Spin-Echo MRI and Model-Based Reconstructions With a Generating Function,"A model-based reconstruction technique for accelerated T2 mapping with improved accuracy is proposed using undersampled Cartesian spin-echo magnetic resonance imaging (MRI) data. The technique employs an advanced signal model for T2 relaxation that accounts for contributions from indirect echoes in a train of multiple spin echoes. An iterative solution of the nonlinear inverse reconstruction problem directly estimates spin-density and T2 maps from undersampled raw data. The algorithm is validated for simulated data as well as phantom and human brain MRI at 3T. The performance of the advanced model is compared to conventional pixel-based fitting of echo-time images from fully sampled data. The proposed method yields more accurate T2 values than the mono-exponential model and allows for retrospective undersampling factors of at least 6. Although limitations are observed for very long T2 relaxation times, respective reconstruction problems may be overcome by a gradient dampening approach. The analytical gradient of the utilized cost function is included as Appendix . The source code is made available to the community.","Image reconstruction,
Magnetic resonance imaging,
Frequency-domain analysis,
Data models,
Discrete Fourier transforms,
Phantoms,
Accuracy"
Task Polar Coordinate Frame-Based Contouring Control of Biaxial Systems,"Contouring control is crucial in high-speed and high-precision manufacturing. In this paper, a novel task polar coordinate frame (TPCF), moving along the desired contour, is proposed to naturally calculate and control the estimated contouring error by the circular approximation, a second-order approximation. The dynamics in the world Cartesian coordinate frame is transformed into radial and angular dynamics in the local polar coordinate frame. By the feedback linearization technique and an input feedforward compensation, the closed-loop dynamics are decoupled in terms of the estimated contouring error and the angular error, respectively. Proportional-plus-derivative controllers can be assigned to stabilize the individual axis dynamics in the TPCF. By tuning the control parameters, different strengthening on estimated contouring error and angular error can be imposed explicitly and directly. Various experiments on an XY-stage biaxial system with typical contours, a circle and a figure-“8,” were conducted. Comparative studies are carried out for the TPCF- and traditional Frenet frame-based controls. The contouring errors were drastically reduced by the proposed approach, particularly in high-speed and large-curvature contouring cases.",
Meta-Heuristic Combining Prior Online and Offline Information for the Quadratic Assignment Problem,"The construction of promising solutions for NP-hard combinatorial optimization problems (COPs) in meta-heuristics is usually based on three types of information, namely a priori information, a posteriori information learned from visited solutions during the search procedure, and online information collected in the solution construction process. Prior information reflects our domain knowledge about the COPs. Extensive domain knowledge can surely make the search effective, yet it is not always available. Posterior information could guide the meta-heuristics to globally explore promising search areas, but it lacks local guidance capability. On the contrary, online information can capture local structures, and its application can help exploit the search space. In this paper, we studied the effects of using this information on metaheuristic's algorithmic performances for the COPs. The study was illustrated by a set of heuristic algorithms developed for the quadratic assignment problem. We first proposed an improved scheme to extract online local information, then developed a unified framework under which all types of information can be combined readily. Finally, we studied the benefits of the three types of information to meta-heuristics. Conclusions were drawn from the comprehensive study, which can be used as principles to guide the design of effective meta-heuristic in the future.",
Dictionary Learning for Analysis-Synthesis Thresholding,"Thresholding is a classical technique for signal denoising. In this process, a noisy signal is decomposed over an orthogonal or overcomplete dictionary, the smallest coefficients are nullified, and the transform pseudo-inverse is applied to produce an estimate of the noiseless signal. The dictionaries used is this process are typically fixed dictionaries such as the DCT or Wavelet dictionaries. In this work, we propose a method for incorporating adaptive, trained dictionaries in the thresholding process. We present a generalization of the basic process which utilizes a pair of overcomplete dictionaries, and can be applied to a wider range of recovery tasks. The two dictionaries are associated with the analysis and synthesis stages of the algorithm, and we thus name the process analysis-synthesis thresholding. The proposed training method trains both the dictionaries and threshold values simultaneously given examples of original and degraded signals, and does not require an explicit model of the degradation. Experiments with small-kernel image deblurring demonstrate the ability of our method to favorably compete with dedicated deconvolution processes, using a simple, fast, and parameterless recovery process.","Dictionaries,
Analytical models,
Mathematical model,
Algorithm design and analysis,
Signal processing algorithms,
Noise reduction,
Equations"
Improving Heterogeneous SOA-Based IoT Message Stability by Shortest Processing Time Scheduling,"An Internet of Things (IoT) system features integration information from heterogeneous sensor devices, allowing them to deliver a variety of sensed information through networks. An IoT broker in the system acts as an information exchange center, relaying periodic messages from heterogeneous sensor devices to IoT clients. As more devices participate in the IoT system, the service scale of entire system increases. To overcome the limitation of the number of direct links to an single working element, the whole IoT system should be divided into many subsystems, called IoT units, to form the system hierarchy. Furthermore, applying the service-oriented architecture (SOA) concept to realize the IoT service can facilitate to adapt the future-proof devices to the IoT system. Normally, a web-based message visualization can unify the client interface in a SOA-based system. However, a large volume of web-based messages with various sizes are not easy to be stably displayed at the client side. This paper proposes an IoT system skeleton and a shortest processing time (SPT) algorithm for scheduling web-based IoT messages. The implemented scheduling scheme supported by a priority queue model can effectively stablize the response messages from the scattered IoT sensors per each client request.",
A Passivity Framework for Modeling and Mitigating Wormhole Attacks on Networked Control Systems,"Networked control systems consist of distributed sensors and actuators that communicate via a wireless network. The use of an open wireless medium and unattended deployment leaves these systems vulnerable to intelligent adversaries whose goal is to disrupt the system performance. In this paper, we study the wormhole attack on a networked control system, in which an adversary establishes a link between two geographically distant regions of the network by using either high-gain antennas, as in the out-of-band wormhole, or colluding network nodes as in the in-band wormhole. Wormholes allow the adversary to violate the timing constraints of real-time control systems by first creating low-latency links, which attract network traffic, and then delaying or dropping packets. Since the wormhole attack reroutes and replays valid messages, it cannot be detected using cryptographic mechanisms alone. We study the impact of the wormhole attack on the network flows and delays and introduce a passivity-based control-theoretic framework for modeling and mitigating the wormhole attack. We develop this framework for both the in-band and out-of-band wormhole attacks as well as complex, hereto-unreported wormhole attacks consisting of arbitrary combinations of in-and out-of band wormholes. By integrating existing mitigation strategies into our framework, we analyze the throughput, delay, and stability properties of the overall system. Through simulation study, we show that, by selectively dropping control packets, the wormhole attack can cause disturbances in the physical plant of a networked control system, and demonstrate that appropriate selection of detection parameters mitigates the disturbances due to the wormhole while satisfying the delay constraints of the physical system.","Delays,
Resource management,
Routing,
Silicon,
Networked control systems,
Cryptography"
An Enhanced Group Mobility Protocol for 6LoWPAN-Based Wireless Body Area Networks,"The IPv6 over low power wireless personal area network (6LoWPAN) has attracted lots of attention recently because it can be used for the communications of Internet of things. In this paper, the concept of group-based network roaming in proxy mobile IPv6 (PMIPv6) domain is considered in the 6LoWPAN-based wireless body area networks. PMIPv6 is a standard to manage the network-based mobility in all-IP wireless network. However, it does not perform well in group-based body area networks. To further reduce the handoff delay and signaling cost, an enhanced group mobility scheme is proposed in this paper to reduce the number of control messages, including router solicitation and router advertisement messages as opposed to the group-based PMIPv6 protocol. Simulation results illustrate that the proposed handoff scheme can reduce the handoff delay and signaling cost. The packet loss ratio and the overhead can also be reduced.","Sensors,
Protocols,
Delays,
Mobile communication,
Manganese,
Wireless sensor networks,
IP networks"
Smart grid-oriented algorithm of data retrieval and processing based on cRIO,"The purpose of this project is to build a platform consisting of hardware and software bits in the CompactRIO smart grid monitoring system. “Smart Grid” refers to technologies that are using computer-based remote control systems to operate electric power distribution systems. The first phase of the project identifies the CompactRIO hardware specification details. Extensive research was conducted at different combinations of the I/O module. The second phase identifies the software implementation of the system. LabVIEW Electrical Power, FPGA and Real-Time modules were used to produce the required data package. The final phase involves different data management approaches such as sending to Datasocket server and file storage. After successful completion of the platform, the network transmits the information over a two-way communication channel. The local engineers can use the data package to monitor the service condition and identify unexpected system problems. This project is particularly useful in demonstrating ways to improve and develop the smart grid by using LabVIEW modules.","Nickel,
Smart grids,
Hardware,
Software,
Servers,
Field programmable gate arrays,
Voltage measurement"
Fast Direct Solver for Essentially Convex Scatterers Using Multilevel Non-Uniform Grids,"A fast algorithm for the direct solution of the method of moments (MoM) systems of equations describing scattering from essentially convex bodies is presented. The algorithm reveals the ranks of interactions between subdomains and compresses the system to that of interacting unknowns only. The procedure is facilitated by representing the interactions via non-uniform sampling grids (NGs). In a multilevel procedure, the interactions' “skeletons,” revealed at each level of the subdomain hierarchy, are aggregated and recompressed. The algorithm is demonstrated here for the generalized equivalence integral equation (GEIE). This recently introduced integral representation, relying on a generalized equivalence theorem, is highly compressible for convex scatterers. The algorithm is detailed, including the treatment of computational bottlenecks by using NG-approach schemes that are tailored to the GEIE formulation. For the essentially circular case, compression to O(1) unknowns at an O(NlogN) computational complexity with O(N) storage is demonstrated.","Testing,
Impedance,
Matrix decomposition,
Algorithm design and analysis,
Method of moments,
Integral equations,
Interpolation"
Scanned Image Descreening With Image Redundancy and Adaptive Filtering,"Currently, most electrophotographic printers use halftoning technique to print continuous tone images, so scanned images obtained from such hard copies are usually corrupted by screen like artifacts. In this paper, a new model of scanned halftone image is proposed to consider both printing distortions and halftone patterns. Based on this model, an adaptive filtering based descreening method is proposed to recover high quality contone images from the scanned images. Image redundancy based denoising algorithm is first adopted to reduce printing noise and attenuate distortions. Then, screen frequency of the scanned image and local gradient features are used for adaptive filtering. Basic contone estimate is obtained by filtering the denoised scanned image with an anisotropic Gaussian kernel, whose parameters are automatically adjusted with the screen frequency and local gradient information. Finally, an edge-preserving filter is used to further enhance the sharpness of edges to recover a high quality contone image. Experiments on real scanned images demonstrate that the proposed method can recover high quality contone images from the scanned images. Compared with the state-of-the-art methods, the proposed method produces very sharp edges and much cleaner smooth regions.","Image edge detection,
Kernel,
Printing,
Noise,
Printers,
Redundancy,
Noise reduction"
"Improved Exact Enumerative Algorithms for the Planted (l, d)-Motif Search Problem","In this paper efficient exact algorithms are proposed for the planted ( l, d)-motif search problem. This problem is to find all motifs of length l that are planted in each input string with at most d mismatches. The “quorum” version of this problem is also treated in this paper to find motifs planted not in all input strings but in at least q input strings. The proposed algorithms are based on the previous algorithms called qPMSPruneI and qPMS7 that traverse a search tree starting from a l-length substring of an input string. To improve these previous algorithms, several techniques are introduced, which contribute to reducing the computation time for the traversal. In computational experiments, it will be shown that the proposed algorithms outperform the previous algorithms.",
Video Saliency Map Detection by Dominant Camera Motion Removal,"We present a trajectory-based approach to detect salient regions in videos by dominant camera motion removal. Our approach is designed in a general way so that it can be applied to videos taken by either stationary or moving cameras without any prior information. Moreover, multiple salient regions of different temporal lengths can also be detected. To this end, we extract a set of spatially and temporally coherent trajectories of keypoints in a video. Then, velocity and acceleration entropies are proposed to represent the trajectories. In this way, long-term object motions are exploited to filter out short-term noises, and object motions of various temporal lengths can be represented in the same way. On the other hand, we are inspired by the observation that the trajectories in backgrounds, i.e., the nonsalient trajectories, are usually consistent with the dominant camera motion no matter whether the camera is stationary or not. We make use of this property to develop a unified approach to saliency generation for both stationary and moving cameras. Specifically, one-class SVM is employed to remove the consistent trajectories in motion. It follows that the salient regions could be highlighted by applying a diffusion process to the remaining trajectories. In addition, we create a set of manually annotated ground truth on the collected videos. The annotated videos are then used for performance evaluation and comparison. The promising results on various types of videos demonstrate the effectiveness and great applicability of our approach.",
Stochastic Bandwidth Estimation in Networks With Random Service,"Numerous methods for available bandwidth estimation have been developed for wireline networks, and their effectiveness is well-documented. However, most methods fail to predict bandwidth availability reliably in a wireless setting. It is accepted that the increased variability of wireless channel conditions makes bandwidth estimation more difficult. However, a (satisfactory) explanation why these methods are failing is missing. This paper seeks to provide insights into the problem of bandwidth estimation in wireless networks or, more broadly, in networks with random service. We express bandwidth availability in terms of bounding functions with a defined violation probability. Exploiting properties of a stochastic min-plus linear system theory, the task of bandwidth estimation is formulated as inferring an unknown bounding function from measurements of probing traffic. We present derivations showing that simply using the expected value of the available bandwidth in networks with random service leads to a systematic overestimation of the traffic departures. Furthermore, we show that in a multihop setting with random service at each node, available bandwidth estimates requires observations over (in principle infinitely) long time periods. We propose a new estimation method for random service that is based on iterative constant-rate probes that take advantage of statistical methods. We show how our estimation method can be realized to achieve both good accuracy and confidence levels. We evaluate our method for wired single-and multihop networks, as well as for wireless networks.","iterative methods,
probability,
radio networks,
statistical analysis,
stochastic processes,
telecommunication traffic,
wireless channels"
Semantic segmentation with heterogeneous sensor coverages,"We propose a new approach to semantic parsing, which can seamlessly integrate evidence from multiple sensors with overlapping but possibly different fields of view (FOV), account for missing data and predict semantic labels over the spatial union of sensors coverages. The existing approaches typically carry out semantic segmentation using only one modality, incorrectly interpolate measurements of other modalities or at best assign semantic labels only to the spatial intersection of coverages of different sensors. In this work we remedy these problems by proposing an effective and efficient strategy for inducing the graph structure of Conditional Random Field used for inference and a novel method for computing the sensor domain dependent potentials. We focus on RGB cameras and 3D data from lasers or depth sensors. The proposed approach achieves superior performance, compared to state of the art and obtains labels for the union of spatial coverages of both sensors, while effectively using appearance or 3D cues when they are available. The efficiency of the approach is amenable to realtime implementation. We quantitatively validate our proposal in two publicly available datasets from indoors and outdoors real environments. The obtained semantic understanding of the acquired sensory information can enable higher level tasks for autonomous mobile robots and facilitate semantic mapping of the environments.","Three-dimensional displays,
Semantics,
Robot sensing systems,
Image segmentation,
Cameras,
Vectors,
Visualization"
Cost Optimization of Elasticity Cloud Resource Subscription Policy,"In cloud computing, resource subscription is an important procedure which enables customers to elastically subscribe to IT resources based on their service requirements. Resource subscription can be divided into two categories, namely long-term reservation and on-demand subscription. Although customers need to pay the upfront fee for a long-term reservation contract, the usage charge of reserved resources is generally much cheaper than that of the on-demand subscription. To provide a better Internet service by using cloud resource, service operators will expect to make a trade-off between the amount of long-term reserved resources and that of on-demand subscribed resources. Therefore, how to properly make resource provision plans is a challenging issue. In this paper, we present a two-phase algorithm for service operators to minimize their service provision cost. In the first phase, we propose a mathematical formulae to compute the optimal amount of long-term reserved resources. In the second phase, we use the Kalman filter to predict resource demand and adaptively change the subscribed on-demand resources such that provision cost could be minimized. We evaluated our solution by using real-world data. Our numerical results indicated that the proposed mechanisms are able to significantly reduce the provision cost.","Subscriptions,
Resource management,
Contracts,
Computational modeling,
Cloud computing"
Acquisition and management of biomedical data using Internet of Things concepts,"Internet of Things (IoT) is a concept that considers the pervasive presence of things or objects/equipment that communicate through wireless, cable connections and can interact with each other and can collaborate with other things or objects, to create new services and medical applications in order to achieve common objectives (diagnosis, treatment, patient rehabilitation). Considering that the Android operating system allows data storage, connectivity, Web browser, media support, development environment, we propose to develop an application that will come in support to any patient who is suffering from hypotension/hypertension, diabetes, obesity, or other metabolic diseases associated, and even more for patients with vision impairments who are unable to be independent. With the help of such application the patients and physicians can monitor measured values of blood pressure, values of blood glucose, weight, body mass index, cholesterol, etc., having the possibility of creating a database and a medical history, in which the values specified by the medical devices are stored on the smartphone using Bluetooth™ technique. In this paper we developed an application on the Android platform which aims at recording data measured (SBP - Systolic Blood Pressure, DBP - Diastolic Blood Pressure and Heart Rate) by the electronic sphygmomanometer which communicates using Bluetooth™ technique. The application offers the possibility of transmitting medical data via mobile Internet or wireless. Data will be compared with standard values and if these values are not in the normal range, the patient is alerted, including family doctor, or in the worst case the emergency service.","Blood pressure,
Pressure measurement,
Biomedical monitoring,
Diabetes,
Hypertension,
Medical diagnostic imaging"
Privacy-Preserving Clinical Decision Support System Using Gaussian Kernel-Based Classification,"A clinical decision support system forms a critical capability to link health observations with health knowledge to influence choices by clinicians for improved healthcare. Recent trends toward remote outsourcing can be exploited to provide efficient and accurate clinical decision support in healthcare. In this scenario, clinicians can use the health knowledge located in remote servers via the Internet to diagnose their patients. However, the fact that these servers are third party and therefore potentially not fully trusted raises possible privacy concerns. In this paper, we propose a novel privacy-preserving protocol for a clinical decision support system where the patients' data always remain in an encrypted form during the diagnosis process. Hence, the server involved in the diagnosis process is not able to learn any extra knowledge about the patient's data and results. Our experimental results on popular medical datasets from UCI-database demonstrate that the accuracy of the proposed protocol is up to 97.21% and the privacy of patient data is not compromised.","Servers,
Kernel,
Decision support systems,
Encryption,
Support vector machines,
Medical services"
Modal Analysis With Compressive Measurements,"Structural Health Monitoring (SHM) systems are critical for monitoring aging infrastructure (such as buildings or bridges) in a cost-effective manner. Such systems typically involve collections of battery-operated wireless sensors that sample vibration data over time. After the data is transmitted to a central node, modal analysis can be used to detect damage in the structure. In this paper, we propose and study three frameworks for Compressive Sensing (CS) in SHM systems; these methods are intended to minimize power consumption by allowing the data to be sampled and/or transmitted more efficiently. At the central node, all of these frameworks involve a very simple technique for estimating the structure's mode shapes without requiring a traditional CS reconstruction of the vibration signals; all that is needed is to compute a simple Singular Value Decomposition. We provide theoretical justification (including measurement bounds) for each of these techniques based on the equations of motion describing a simplified Multiple-Degree-Of-Freedom (MDOF) system, and we support our proposed techniques using simulations based on synthetic and real data.",
Fast Regular Expression Matching Using Small TCAM,"Regular expression (RE) matching is a core component of deep packet inspection in modern networking and security devices. In this paper, we propose the first hardware-based RE matching approach that uses ternary content addressable memory (TCAM), which is available as off-the-shelf chips and has been widely deployed in modern networking devices for tasks such as packet classification. We propose three novel techniques to reduce TCAM space and improve RE matching speed: transition sharing, table consolidation, and variable striding. We tested our techniques on eight real-world RE sets, and our results show that small TCAMs can be used to store large deterministic finite automata (DFAs) and achieve potentially high RE matching throughput. For space, we can store each of the corresponding eight DFAs with 25 000 states in a 0.59-Mb TCAM chip. Using a different TCAM encoding scheme that facilitates processing multiple characters per transition, we can achieve potential RE matching throughput of 10-19 Gb/s for each of the eight DFAs using only a single 2.36-Mb TCAM chip.","Encoding,
Doped fiber amplifiers,
Vegetation,
Random access memory,
Redundancy,
Inspection,
Automata"
Crowdsourcing 2.0: Enhancing execution speed and reliability of web-based QoE testing,"Since its introduction a few years ago, the concept of `Crowdsourcing' has been heralded as highly attractive alternative approach towards evaluating the Quality of Experience (QoE) of networked multimedia services. The main reason is that, in comparison to traditional laboratory-based subjective quality testing, crowd-based QoE assessment over the Internet promises to be not only much more cost-effective (no lab facilities required, less cost per subject) but also much faster in terms of shorter campaign setup and turnaround times. However, the reliability of remote test subjects and consequently, the trustworthiness of study results is still an issue that prevents the widespread adoption of crowd-based QoE testing. Various ideas for improving user rating reliability and test efficiency have been proposed, with the majority of them relying on a posteriori analysis of results. However, such methods introduce a major lag that significantly affects efficiency of campaign execution. In this paper we address these shortcomings by introducing in momento methods for crowdsourced video QoE assessment which yield improvements of results reliability by factor two and campaign execution efficiency by factor ten. The proposed in momento methods are applicable to existing crowd-based QoE testing approaches and suitable for a variety of service scenarios.","Crowdsourcing,
Testing,
Quality of service,
Quality assessment,
Video recording,
Reliability engineering"
Active Diagnosability of Discrete Event Systems and its Application to Battery Fault Diagnosis,"A battery system may consist of many batteries; each battery can have a normal operating mode and several faulty modes. This makes the fault status of a battery system very complex. To diagnose such a complex system, passive diagnosis is often insufficient. We may need to actively control the system to complete the diagnosis task. In this brief, we investigate the active diagnosis in the framework of discrete event systems. We model the system to be diagnosed by an automaton (finite state machine) with state outputs in which some events are controllable in the sense that they can be enforced, and some events are not. We say that the system is actively diagnosable if we can find a control under which the faults can be diagnosed. We derive a necessary and sufficient condition for a system to be actively diagnosable. Algorithms are devised for checking active diagnosability and finding controls that achieve it. The theoretical results are then applied to fault diagnosis of battery systems. We illustrate the approach using a simplified battery system consisting of four batteries. We find a control that diagnoses the faults based on the measurements of two temperature sensors.","Batteries,
Automata,
Aging,
Battery charge measurement,
Resistance,
Fault diagnosis,
Control systems"
Continuous-time controllers for stabilizing periodic orbits of hybrid systems: Application to an underactuated 3D bipedal robot,"This paper presents a systematic approach to exponentially stabilize periodic orbits in nonlinear systems with impulse effects, a special class of hybrid systems. Stabilization is achieved with a time invariant continuous-time controller. The presented method assumes a parametrized family of continuous-time controllers has been designed so that (1) a periodic orbit is induced, and (2) the orbit itself is invariant under the choice of parameters in the controllers. By investigating the properties of the Poincaré return map, a sensitivity analysis is presented that translates the stabilization problem into a set of Bilinear Matrix Inequalities (BMIs). A BMI optimization problem is set up to select the parameters of the continuous-time controller to achieve exponential stability. We illustrate the power of the approach by finding new stabilizing solutions for periodic orbits of an underactuated 3D bipedal robot.",
Coordinated caching model for minimizing energy consumption in radio access network,"To reduce network access latency, network traffic volume, and server load, caching capacity was proposed as a component of eNodeBs in the radio access network (RAN). These eNodeB caches require less transport energy but bring additional caching energy through providing each eNodeB with caching capacity. It is thus challenging for eNodeBs to make content placement and request routing decisions so as to minimize the total energy consumption, especially when considering different caching hardware technologies, arrival rate of requests and content popularity. To address this problem, we first build an energy model to formulate the problem of minimizing energy consumption at eNodeB caches. Then a Lagrangian relaxation technique is adopted to find a near-optimal solution to the proposed model. Based on the proposed model and the obtained solution, we design a practical scheme for coordinating the content placement and request routing, and thus ensure the minimum-energy eNodeB caches. Compared with the existing works, our proposal significantly reduces the energy consumption by approximately 28% while keeps a good network performance. Our results also indicate that caching hardware technologies and content popularity greatly affect the content placement, therefore are crucial to the energy efficiency of eNodeB caches.","Energy consumption,
Servers,
Radio access networks,
Nickel,
Routing,
Random access memory,
Wireless communication"
Spatially-Constrained Similarity Measurefor Large-Scale Object Retrieval,"One fundamental problem in object retrieval with the bag-of-words model is its lack of spatial information. Although various approaches are proposed to incorporate spatial constraints into the model, most of them are either too strict or too loose so that they are only effective in limited cases. In this paper, a new spatially-constrained similarity measure (SCSM) is proposed to handle object rotation, scaling, view point change and appearance deformation. The similarity measure can be efficiently calculated by a voting-based method using inverted files. During the retrieval process, object localization in the database images can also be simultaneously achieved using SCSM without post-processing. Furthermore, based on the retrieval and localization results of SCSM, we introduce a novel and robust re-ranking method with the k-nearest neighbors of the query for automatically refining the initial search results. Extensive performance evaluations on six public data sets show that SCSM significantly outperforms other spatial models including RANSAC-based spatial verification, while k-NN re-ranking outperforms most state-of-the-art approaches using query expansion. We also adapted SCSM for mobile product image search with an iterative algorithm to simultaneously extract the product instance from the mobile query image, identify the instance, and retrieve visually similar product images. Experiments on two product image search data sets show that our approach can robustly localize and extract the product in the query image, and hence drastically improve the retrieval accuracy over baseline methods.","Visualization,
Search problems,
Mobile communication,
Spatial databases,
Feature extraction,
Image segmentation"
Automated support for combinational creativity in requirements engineering,"Requirements engineering (RE), framed as a creative problem solving process, plays a key role in innovating more useful and novel requirements and improving a software system's sustainability. Existing approaches, such as creativity workshops and feature mining from web services, facilitate creativity by exploring a search space of partial and complete possibilities of requirements. To further advance the literature, we support creativity from a combinational perspective, i.e., making unfamiliar connections between familiar possibilities of requirements. In particular, we propose a novel framework that extracts familiar ideas from the requirements and stakeholders' comments using topic modeling and applies part-of-speech tagging to obtain unfamiliar idea combinations. We apply our framework on two large open source software systems and further report a human subject evaluation. The results show that our framework complements existing approaches by generating original and relevant requirements in an automated manner.","Social network services,
Space exploration,
Software engineering,
Software systems,
Conferences,
Tagging"
A Novel Strategy for Solving the Stochastic Point Location Problem Using a Hierarchical Searching Scheme,"Stochastic point location (SPL) deals with the problem of a learning mechanism (LM) determining the optimal point on the line when the only input it receives are stochastic signals about the direction in which it should move. One can differentiate the SPL from the traditional class of optimization problems by the fact that the former considers the case where the directional information, for example, as inferred from an Oracle (which possibly computes the derivatives), suffices to achieve the optimization-without actually explicitly computing any derivatives. The SPL can be described in terms of a LM (algorithm) attempting to locate a point on a line. The LM interacts with a random environment which essentially informs it, possibly erroneously, if the unknown parameter is on the left or the right of a given point. Given a current estimate of the optimal solution, all the reported solutions to this problem effectively move along the line to yield updated estimates which are in the neighborhood of the current solution.1 This paper proposes a dramatically distinct strategy, namely, that of partitioning the line in a hierarchical tree-like manner, and of moving to relatively distant points, as characterized by those along the path of the tree. We are thus attempting to merge the rich fields of stochastic optimization and data structures. Indeed, as in the original discretized solution to the SPL, in one sense, our solution utilizes the concept of discretization and operates a uni-dimensional controlled random walk (RW) in the discretized space, to locate the unknown parameter. However, by moving to nonneighbor points in the space, our newly proposed hierarchical stochastic searching on the line (HSSL) solution performs such a controlled RW on the discretized space structured on a superimposed binary tree. We demonstrate that the HSSL solution is orders of magnitude faster than the original SPL solution proposed by Oommen. By a rigorous analysis, the HSSL is shown to be optimal if the effectiveness (or credibility) of the environment, given by p, is greater than the golden ratio conjugate. The solution has been both analytically solved and simulated, and the results obtained are extremely fascinating, as this is the first reported use of time reversibility in the analysis of stochastic learning. The learning automata extensions of the scheme are currently being investigated.",
A Carpooling Recommendation System for Taxicab Services,"Carpooling taxicab services hold the promise of providing additional transportation supply, especially in the extreme weather or rush hour when regular taxicab services are insufficient. Although many recommendation systems about regular taxicab services have been proposed recently, little research, if any, has been done to assist passengers to find a successful taxicab ride with carpooling. In this paper, we present the first systematic work to design a unified recommendation system for both the regular and carpooling services, called CallCab, based on a data-driven approach. In response to a passenger's real-time request, CallCab aims to recommend either: 1) a vacant taxicab for a regular service with no detour or 2) an occupied taxicab heading to the similar direction for a carpooling service with the minimum detour, yet without assuming any knowledge of destinations of passengers already in taxicabs. To analyze these unknown destinations of occupied taxicabs, CallCab generates and refines taxicab trip distributions based on GPS data sets and context information collected in the existing taxicab infrastructure. To improve CallCab's efficiency to process such a big data set, we augment the efficient MapReduce model with a Measure phase tailored for our CallCab. Finally, we design a reciprocal price mechanism to facilitate the taxicab carpooling implementation in the real world. We evaluate CallCab with a real-world data set of 14000 taxicabs, and results show that compared with the ground truth, CallCab reduces 60% of the total mileage to deliver all passengers and 41% of passenger's waiting time. Our price mechanism reduces 23% of passengers' fares and increases 28% of drivers' profits simultaneously.","Global Positioning System,
Urban areas,
Public transportation,
Transportation,
Real-time systems,
Dispatching"
Development of a tele-operative testing cell as a remote lab for material characterization,"Laboratory experiments play a significant role in engineering education. The experience gathered during the labs is one of the most important experiences during studying engineering because there is a strong connection between theory and practical relevance. A tele-operative testing cell for material characterization for forming processes is presented. This testing cell is used as a remote lab so that students can gain their experiences location and time-independent via the internet. In addition, the tele-operative testing cell is also used within the scope of lectures to combine the theory with live experiments in interaction with the students. The main aspects are, on the one hand, the developments in the field of engineering and the implementation of the IT components like iLab and, on the other hand, the integration of the tele-operative testing cell into engineering education.","Collaborative work,
Decision support systems,
Conferences,
Abstracts,
Engineering education,
Manufacturing,
Laboratories"
The Power Delay Profile of the Single-Antenna Full-Duplex Self-Interference Channel in Indoor Environments at 2.6 GHz,"In this letter, the power delay profile (PDP) of the single-antenna full-duplex self-interference channel (SIC) is investigated in the indoor environments. The measurements are performed at the center frequency of 2.6 GHz with 200 MHz bandwidth. We find that the PDP can be decomposed into three components: leakage path, antenna reflection path, and space multipath. The major effects in determining the leakage path and the antenna reflection path are analyzed. Furthermore, the model of the profiles of the leakage path and the antenna reflection path is derived. The space multipath can be modeled as a power-law decay plus a random variable with lognormal statistics.","Circulators,
Ports (Computers),
Antenna measurements,
Antenna feeds,
Delays"
PBS: A Portable Billing Scheme with Fine-Grained Access Control for Service-Oriented Vehicular Networks,"Vehicular ad hoc networks (VANETs) are an emerging wireless network technology used to improve road safety. Commercial services will play an important role in drawing customers to VANETs. Therefore, service-oriented vehicular networks offer an effective and promising approach. To meet the diverse requirements of different users, fine-grained access control is essential. This paper aims to address security, privacy and billing issues in service-oriented vehicular networks. Taking advantage of a portable electronic currency, the proposed scheme mitigates the long authentication delay of the centralized AAA architecture. Variant attribute-based encryption ensures fine-grained access control and secure billing. Only vehicles possessing the proper service attributes and valid electronic currency are authorized to access the requested service file. The security properties of entity authentication, session key agreement, privacy, fraud electronic currency prevention, double-spending prevention, and nonrepudiated billing are achieved. Extensive analysis and simulations demonstrate that our scheme is a viable candidate to replace a centralized AAA architecture with a decentralized method for better scalability in service-oriented vehicular networks.","Intelligent vehicle networks,
Ad hoc networks,
Wireless networks,
Road transportation,
Vehicular ad hoc networks"
Analysis of network address shuffling as a moving target defense,"Address shuffling is a type of moving target defense that prevents an attacker from reliably contacting a system by periodically remapping network addresses. Although limited testing has demonstrated it to be effective, little research has been conducted to examine the theoretical limits of address shuffling. As a result, it is difficult to understand how effective shuffling is and under what circumstances it is a viable moving target defense. This paper introduces probabilistic models that can provide insight into the performance of address shuffling. These models quantify the probability of attacker success in terms of network size, quantity of addresses scanned, quantity of vulnerable systems, and the frequency of shuffling. Theoretical analysis shows that shuffling is an acceptable defense if there is a small population of vulnerable systems within a large network address space, however shuffling has a cost for legitimate users. These results will also be shown empirically using simulation and actual traffic traces.","Probes,
Computers,
Computational modeling,
Reconnaissance,
IP networks,
Information systems"
2D Affine and Projective Shape Analysis,"Current techniques for shape analysis tend to seek invariance to similarity transformations (rotation, translation, and scale), but certain imaging situations require invariance to larger groups, such as affine or projective groups. Here we present a general Riemannian framework for shape analysis of planar objects where metrics and related quantities are invariant to affine and projective groups. Highlighting two possibilities for representing object boundaries-ordered points (or landmarks) and parameterized curves-we study different combinations of these representations (points and curves) and transformations (affine and projective). Specifically, we provide solutions to three out of four situations and develop algorithms for computing geodesics and intrinsic sample statistics, leading up to Gaussian-type statistical models, and classifying test shapes using such models learned from training data. In the case of parameterized curves, we also achieve the desired goal of invariance to re-parameterizations. The geodesics are constructed by particularizing the path-straightening algorithm to geometries of current manifolds and are used, in turn, to compute shape statistics and Gaussian-type shape models. We demonstrate these ideas using a number of examples from shape and activity recognition.",
The Resistivity of Zinc Oxide Under Different Annealing Configurations and Its Impact on the Leakage Characteristics of Zinc Oxide Thin-Film Transistors,"Sputtered zinc oxide (ZnO) without intentional doping was thermally annealed and the dependence of its resistivity on different sample configurations and heat-treatment conditions was studied. The ZnO was either exposed to the ambience or sealed with an impermeable cover during the annealing. The resistivity resulting from the sealed configuration was found to be lower. The possible origins of the charge carriers responsible for the conductivity were investigated, with the most plausible one studied in greater detail using photoluminescence. The leakage current in the OFF-state of a field-effect thin-film transistor is largely controlled by the residual conductivity of the channel region of the transistor. For a ZnO transistor, this region is typically undoped and subjected to a series of thermal processes under a variety of coverage configurations during the course of the fabrication of the transistor. The implied correlation between the aggregate thermal treatment and the characteristics of a transistor in its OFF-state was investigated and demonstrated.","Annealing,
Zinc oxide,
Conductivity,
Heating,
Thin film transistors,
Silicon"
QoS-Compliant Sequential Channel Sensing for Cognitive Radios,"In this paper, we study the quality-of-service (QoS) support for realtime traffic in cognitive radio (CR) networks when spectrum availability and quality is not known a priori. A resource-constrained CR relies on sequential channel sensing and probing to resolve spectrum uncertainty and search for good transmission opportunities in real time. We are interested in maximizing the effective throughput the CR can achieve with a desired confidence (success probability) under a spectrum access delay constraint. This quantity can be interpreted as the QoS-compliant (e.g., min-rate and delay) capacity of the CR link under the uncertain spectrum environment. The optimization is formulated as a finite-horizon optimal stopping problem under the objective of maximizing a given percentile of the rate of return at the stopping time. This formulation cannot be directly solved by classical optimal stopping theory, because the latter only supports a mean-reward objective function. A novel transformation is developed to convert the problem into solving a series of sub problems, each of which optimizes a transformed mean-reward of the original problem and therefore can be solved using classical optimal stopping method. We prove the monotonicity of the sub problems, based on which we develop a fast algorithm to efficiently find the unique solution to the original problem. To account for different MAC mechanisms used in practice, our analysis considers both non-recall and recall channel decision strategies. Extensive simulations are performed to verify the effectiveness and significance of the optimization. We show that significant gains (e.g., over 30%) on the QoS-compliant capacity can be achieved by the proposed algorithm when compared with the counterparts.","Sensors,
Quality of service,
Spread spectrum management,
Optimization,
Linear programming,
Transmitters"
Joint Video Frame Set Division and Low-Rank Decomposition for Background Subtraction,"The recently proposed robust principle component analysis (RPCA) has been successfully applied in background subtraction. However, low-rank decomposition makes sense on the condition that the foreground pixels (sparsity patterns) are uniformly located at the scene, which is not realistic in real-world applications. To overcome this limitation, we reconstruct the input video frames and aim to make the foreground pixels not only sparse in space but also sparse in time. Therefore, we propose a joint video frame set division and RPCA-based method for background subtraction. In addition, we use the motion as a priori knowledge which has not been considered in the current subspace-based methods. The proposed method consists of two phases. In the first phase, we propose a lower bound-based within-class maximum division method to divide the video frame set into several subsets. In this way, the successive frames are assigned to different subsets in which the foregrounds are located at the scene randomly. In the second phase, we augment each subset using the frames with a small quantity of motion. To evaluate the proposed method, the experiments are conducted on real-world and public datasets. The comparisons with the state-of-the-art background subtraction methods validate the superiority of our method.","Sparse matrices,
Noise,
Matrix decomposition,
Mathematical model,
Principal component analysis,
Statistical distributions,
Surveillance"
Fixed-Complexity Quantum-Assisted Multi-User Detection for CDMA and SDMA,"In a system supporting numerous users the complexity of the optimal Maximum Likelihood Multi-User Detector (ML MUD) becomes excessive. Based on the superimposed constellations of K users, the ML MUD outputs the specific multi-level K-user symbol that minimizes the Euclidean distance with respect to the faded and noise-contaminated received multi-level symbol. Explicitly, the Euclidean distance is considered as the Cost Function (CF). In a system supporting K users employing M-ary modulation, the ML MUD uses M^K CF evaluations (CFE) per time slot. In this contribution we propose an Early Stopping-aided Durr-H\o yer algorithm-based Quantum-assisted MUD (ES-DHA QMUD) based on two techniques for achieving optimal ML detection at a low complexity. Our solution is also capable of flexibly adjusting the QMUD's performance and complexity trade-off, depending on the computing power available at the base station. We conclude by proposing a general design methodology for the ES-DHA QMUD in the context of both CDMA and SDMA systems.","Multiaccess communication,
Multiuser detection,
Detectors,
Complexity theory,
Quantum computing,
Modulation,
Databases"
Device Modeling for Understanding AlGaN/GaN HEMT Gate-Lag,"Using a simple simulation framework, it is shown that a passivation dielectric that minimizes surface leakage and creates a high density of shallow traps at the surface is vital to minimize the formation of the virtual gate and eliminate AlGaN/GaN HEMT gate-lag. Under large negative gate voltage, this is also expected to create higher fields and current crowding at the gate edge, promoting an increase in total gate leakage. While the AlGaN barrier properties are also found to impact gate-lag, the use of a passivation dielectric that minimizes surface leakage can overpower it's influence and suppress current collapse. Access region shrinking and the use of a longer gate are also found to improve gate-lag.","Logic gates,
Aluminum gallium nitride,
Dielectrics,
Passivation,
Electron traps,
HEMTs,
Gallium nitride"
"Adaptive GSA-Based Optimal Tuning of PI Controlled Servo Systems With Reduced Process Parametric Sensitivity, Robust Stability and Controller Robustness",This paper suggests a new generation of optimal PI controllers for a class of servo systems characterized by saturation and dead zone static nonlinearities and second-order models with an integral component. The objective functions are expressed as the integral of time multiplied by absolute error plus the weighted sum of the integrals of output sensitivity functions of the state sensitivity models with respect to two process parametric variations. The PI controller tuning conditions applied to a simplified linear process model involve a single design parameter specific to the extended symmetrical optimum (ESO) method which offers the desired tradeoff to several control system performance indices. An original back-calculation and tracking anti-windup scheme is proposed in order to prevent the integrator wind-up and to compensate for the dead zone nonlinearity of the process. The minimization of the objective functions is carried out in the framework of optimization problems with inequality constraints which guarantee the robust stability with respect to the process parametric variations and the controller robustness. An adaptive gravitational search algorithm (GSA) solves the optimization problems focused on the optimal tuning of the design parameter specific to the ESO method and of the anti-windup tracking gain. A tuning method for PI controllers is proposed as an efficient approach to the design of resilient control systems. The tuning method and the PI controllers are experimentally validated by the adaptive GSA-based tuning of PI controllers for the angular position control of a laboratory servo system.,"Sensitivity,
Process control,
Tuning,
Robust stability,
Robustness,
Servomotors,
Linear programming"
A Heterogeneous Fleet of Vehicles for Automated Humanitarian Missions,"An automated emergency response system and an experimental framework for its design and validation are presented here. The system consists of a high-level mission optimization and a fleet of heterogeneous autonomous vehicles. The fleet includes ground vehicles for setting up local stations, fixed-wing aircraft for assessing infrastructure damage and performing surveillance, and rotorcraft for delivering emergency supplies. Internet technology provides a unifying environment for the vehicles, optimization module, operators, and emergency responders with support for computational integration in cyberspace.",
Iterative Method for Predistortion of MRI Gradient Waveforms,"The purpose of this work is to correct for transient gradient waveform errors in magnetic resonance imaging (MRI), whether from eddy currents, group delay, or gradient amplifier nonlinearities, which are known to affect image quality. An iterative method is proposed to minimize error between desired and measured gradient waveforms, whose success does not depend on accurate knowledge of the gradient system impulse response. The method was applied to half-pulse excitation for 2-D ultra-short echo time (UTE) imaging on a small animal MRI system and to spiral 2-D excitation on a human 7T MRI system. Predistorted gradient waveforms reduced temporal signal variation caused by excitation gradient trajectory errors in 2-D UTE, and improved the quality of excitation patterns produced by spiral excitation pulses. Iterative gradient predistortion is useful for minimizing transient gradient errors without requiring accurate characterization of the gradient system impulse response.","Predistortion,
Radio frequency,
Measurement uncertainty,
Trajectory,
Magnetic resonance imaging,
Spirals"
Analysis of EDF scheduling for Wireless Sensor-Actuator Networks,"Industry is adopting Wireless Sensor-Actuator Networks (WSANs) as the communication infrastructure for process control applications. To meet the stringent real-time performance requirements of control systems, there is a critical need for fast end-to-end delay analysis for real-time flows that can be used for online admission control. This paper presents a new end-to-end delay analysis for periodic flows whose transmissions are scheduled based on the Earliest Deadline First (EDF) policy. Our analysis comprises novel techniques to bound the communication delays caused by channel contention and transmission conflicts in a WSAN. Furthermore, we propose a technique to reduce the pessimism in admission control by iteratively tightening the delay bounds for flows with short deadlines. Experiments on a WSAN testbed and simulations demonstrate the effectiveness of our analysis for online admission control of real-time flows.",
How to Display Group Information on Node-Link Diagrams: An Evaluation,"We present the results of evaluating four techniques for displaying group or cluster information overlaid on node-link diagrams: node coloring, GMap, BubbleSets, and LineSets. The contributions of the paper are three fold. First, we present quantitative results and statistical analyses of data from an online study in which approximately 800 subjects performed 10 types of group and network tasks in the four evaluated visualizations. Specifically, we show that BubbleSets is the best alternative for tasks involving group membership assessment; that visually encoding group information over basic node-link diagrams incurs an accuracy penalty of about 25 percent in solving network tasks; and that GMap's use of prominent group labels improves memorability. We also show that GMap's visual metaphor can be slightly altered to outperform BubbleSets in group membership assessment. Second, we discuss visual characteristics that can explain the observed quantitative differences in the four visualizations and suggest design recommendations. This discussion is supported by a small scale eye-tracking study and previous results from the visualization literature. Third, we present an easily extensible user study methodology.","Data visualization,
Cluster approximation,
Image color analysis,
Approximation algorithms,
Encoding,
Algorithm design and analysis"
"Ultra-Stable RF-Over-Fiber Transport in NASA Antennas, Phased Arrays and Radars","Research and development in ultra-stable RF transport in optical fibers in the late-1970s/early-1980s at the NASA Jet Propulsion Laboratory led to successful field deployments in the three global sites of the NASA Deep Space Network which have been in continuous operation for the past three decades. This RF-over-fiber system underpinned critical tracking, navigation and communications functions for every deep space mission during this period and into the future. Successful operation of this system led to adoption of RF photonics as a fundamental infrastructure technology incorporated today in every deep space tracking antenna network and radio telescope worldwide. This RF-over-fiber system is also deployed in NASA's ground-based and space-borne planetary imaging and mapping radars. These systems were a predecessor to commercial RF-over-fiber networks which are key infrastructure components of today's cable and wireless industries. This paper provides an exposition of a number of NASA antennas, arrays and radar systems in which RF-over-fiber transport has played an enabling role.",
A Secure Data Self-Destructing Scheme in Cloud Computing,"With the rapid development of versatile cloud services, it becomes increasingly susceptible to use cloud services to share data in a friend circle in the cloud computing environment. Since it is not feasible to implement full lifecycle privacy security, access control becomes a challenging task, especially when we share sensitive data on cloud servers. In order to tackle this problem, we propose a key-policy attribute-based encryption with time-specified attributes (KP-TSABE), a novel secure data self-destructing scheme in cloud computing. In the KP-TSABE scheme, every ciphertext is labeled with a time interval while private key is associated with a time instant. The ciphertext can only be decrypted if both the time instant is in the allowed time interval and the attributes associated with the ciphertext satisfy the key's access structure. The KP-TSABE is able to solve some important security problems by supporting user-defined authorization period and by providing fine-grained access control during the period. The sensitive data will be securely self-destructed after a user-specified expiration time. The KP-TSABE scheme is proved to be secure under the decision l-bilinear Diffie-Hellman inversion (l-Expanded BDHI) assumption. Comprehensive comparisons of the security properties indicate that the KP-TSABE scheme proposed by us satisfies the security requirements and is superior to other existing schemes.","Cloud computing,
Encryption,
Authorization,
Data privacy,
Computer security"
Classemes and Other Classifier-Based Features for Efficient Object Categorization,"This paper describes compact image descriptors enabling accurate object categorization with linear classification models, which offer the advantage of being efficient to both train and test. The shared property of our descriptors is the use of classifiers to produce the features of each image. Intuitively, these classifiers evaluate the presence of a set of basis classes inside the image. We first propose to train the basis classifiers as recognizers of a hand-selected set of object classes. We then demonstrate that better accuracy can be achieved by learning the basis classes as “abstract categories” collectively optimized as features for linear classification. Finally, we describe several strategies to aggregate the outputs of basis classifiers evaluated on multiple subwindows of the image in order to handle cases when the photo contains multiple objects and large amounts of clutter. We test our descriptors on challenging benchmarks of object categorization and detection, using a simple linear SVM as classifier. Our results are on par with those achieved by the best systems in these fields but are produced at orders of magnitude lower computational costs and using an image representation that is general and not specifically tuned for a predefined set of test classes.",
Learning Structural Regularity for Evaluating Blocking Artifacts in JPEG Images,"Image degradation damages genuine visual structures and causes pseudo structures. Pseudo structures are usually present with regularities. This letter proposes a machine learning based blocking artifacts metric for JPEG images by measuring the regularities of pseudo structures. Image corner, block boundary and color change properties are used to differentiate the blocking artifacts. A support vector regression (SVR) model is adopted to learn the underlying relations between these features and perceived blocking artifacts. The blocking artifacts score of a test image is predicted using the trained model. Extensive experiments demonstrate the effectiveness of the method.","Measurement,
Databases,
Transform coding,
Image quality,
Image color analysis,
Predictive models,
Image edge detection"
Wireless Power Delivery to Low-Power Mobile Devices Based on Retro-Reflective Beamforming,"This letter presents an experimental study on wireless power delivery to low-power mobile devices based on retro-reflective beamforming. In our scheme, a pilot signal composed of an impulse train is broadcast from a mobile device. The pilot signal is received and analyzed by a wireless charger that includes four antenna elements. Then, according to the analysis outcome, the wireless charger constructs a focused power beam onto the mobile device. In our experiments, the total power transmitted from the wireless charger is approximately 1 Watt; 14 mW of power is harvested by the mobile device 50-cm distance away. Our experimental results successfully demonstrate that the power beam in reaction to the pilot signal is capable of tracking the mobile device's location dynamically. In addition, since the pilot signal's spectrum covers a certain frequency range, the carrier of wireless power in our scheme can be configured among multiple frequencies.","Wireless communication,
Wireless sensor networks,
Receivers,
Mobile handsets,
Array signal processing,
Radio frequency,
Transmitting antennas"
Analysis of Carrier Transport in Short-Channel MOSFETs,"A method for extracting transport parameters in short-channel FETs is presented in the context of the Lundstrom model for quasi-ballistic short-channel FETs. The parameters extracted from measured data are unidirectional thermal velocity, critical length, and mean free path at low and high drain biases. The method is based on an analysis of the channel length dependence of apparent mobility and virtual-source (VS) velocity, which are obtained by fitting the VS model to measured data. Data from (100)-oriented undoped-body extremely thin silicon-on-insulator FETs with neutral stress liners are used to validate the method. Since this method does not assume any theoretical knowledge of band structure parameters, it can be applied to short-channel FETs with any geometry, any channel material, and with unknown levels of channel stress.",
Design of a Wearable Device for Reading Positive Expressions from Facial EMG Signals,"In this paper we present the design of a wearable device that reads positive facial expressions using physiological signals. We first analyze facial morphology in 3 dimensions and facial electromyographic signals on different facial locations and show that we can detect electromyographic signals with high amplitude on areas of low facial mobility on the side of the face, which are correlated to ones obtained from electrodes on traditional surface electromyographic capturing positions on top of facial muscles on the front of the face. We use a multi-attribute decision-making method to find adequate electrode positions on the side of face to capture these signals. Based on this analysis, we design and implement an ergonomic wearable device with high reliability. Because the signals are recorded distally, the proposed device uses independent component analysis and an artificial neural network to analyze them and achieve a high facial expression recognition rate on the side of the face. The recognized emotional facial expressions through the wearable interface device can be recorded during therapeutic interventions and for long-term facial expression recognition to quantify and infer the user's affective state in order to support medical professionals.","Electrodes,
Electromyography,
Face recognition,
Emotion recognition,
Facial muscles,
Muscles"
Effect of water absorption on dielectric properties of nano-silica/polyethylene composites,"The effect of moisture content on the dielectric properties of polymer/nano-silica blends was investigated. It was found that the DC breakdown strength, electrical conductivity and complex permittivity were all strongly influenced by absorbed water. However, a control sample without nano-silica was largely unaffected by changes in moisture content. This has important implications for researchers and cable designers.","Dielectrics,
Conductivity,
Electric breakdown,
Polymers,
Moisture,
Testing,
Permittivity"
Operation Characteristics of 12-Cavity Relativistic Magnetron With Single-Stepped Cavities,"The possibility of using single-stepped cavities to replace the common tapered cavities was studied using particle-in-cell simulations in an A6 magnetron with diffraction output (MDO). The replacing of the tapered cavities by the single-stepped cavities in a 12-cavity MDO increases the interaction space where the charged particles interact with the induced RF waves. The electronic efficiency of the 12-cavity MDO with single-stepped cavities driven by the transparent cathode [2] of GW output power level can be as high as 73% for α = 18.2°, 74% for α = 17.5°, and 72% for α = 12.5° at β = 32°, where α is the angle between the outer wall and z-axis, and β is the angle between the inner wall and z-axis. The depth of single-stepped cavities is changed when α is changed, which results in different frequency range of magnetron operating modes. When a 400-kV voltage pulse of 10-ns duration is applied to a transparent cathode or a solid cathode, the output power can be as high as 1 GW. Without loss of generality, for α = 12.5° at β = 32°, the peak efficiency around 70% of 12-cavity MDO with single-stepped cavities design occurs at the voltage (V ~ 400 ± 50 kV). The results presented in this paper provide references for relativistic magnetron mode selection or mode switching experiments when choosing the input parameters (magnetic field and accelerating voltage) allowing the magnetron to operate in the desired operation mode.","Cathodes,
Cavity resonators,
Power generation,
Educational institutions,
Solids,
Magnetic liquids,
Magnetic switching"
A comparative study of measurement-based Thevenin equivalents identification methods,"With the development of phasor measurement units (PMU), real-time voltage stability monitoring techniques using phasor measurements have been widely discussed in the past decade. For various measurement-based techniques, the fundamental idea behind them is to identify the Thevenin equivalents (TE) of the outer system seen from the nodes/areas of interests, and then assess the voltage stability margin based on the equivalent circuits. Therefore, fast and accurate identification of the TE is crucial for such online monitoring applications. Though several identification methods have been proposed claiming to achieve good performance, they have not been explicitly compared with each other. This work presents an analogous comparative study of four different methods. After a brief introduction, the four methods are compared in the aspects of time complexity and measurement needed by using an algorithm analysis. Then they are tested on the measurements generated from time domain simulations of the Northeast Power Coordinating Council (NPCC) 140-bus system. Following the case study, a detailed performance analysis is given, and the results can serve as a general guidance on choosing the TE identification methods and the corresponding parameters.","Impedance,
Voltage measurement,
Phasor measurement units,
Load modeling,
Power system stability,
Stability analysis,
Circuit stability"
Unobtrusive In-Home Detection of Time Spent Out-of-Home With Applications to Loneliness and Physical Activity,"Loneliness is a common condition in elderly associated with severe health consequences including increased mortality, decreased cognitive function, and poor quality of life. Identifying and assisting lonely individuals is therefore increasingly important-especially in the home setting-as the very nature of loneliness often makes it difficult to detect by traditional methods. One critical component in assessing loneliness unobtrusively is to measure time spent out-of-home, as loneliness often presents with decreased physical activity, decreased motor functioning, and a decline in activities of daily living, all of which may cause decrease in the amount of time spent outside the home. Using passive and unobtrusive in-home sensing technologies, we have developed a methodology for detecting time spent out-of-home based on logistic regression. Our approach was both sensitive (0.939) and specific (0.975) in detecting time out-of-home across over 41 000 epochs of data collected from four subjects monitored for at least 30 days each in their own homes. In addition to linking time spent out-of-home to loneliness, (r = -0.44, p = 0.011) as measured by the UCLA Loneliness Index, we demonstrate its usefulness in other applications such as uncovering general behavioral patterns of elderly and exploring the link between time spent out-of-home and physical activity ( r = 0.415, p = 0.031), as measured by the Berkman Social Disengagement Index.",
Improvement of SOI Trench LDMOS Performance With Double Vertical Metal Field Plate,"In this paper, a novel high-voltage trench lateral double-diffused metal-oxide-semiconductor field effect transistor (TLDMOS) based on silicon-on-insulator technology is proposed. The new structure is characterized by a double vertical metal field plate (DVFP) in the oxide trench, which is surrounded by heavily doped N/P pillars [superjuction (SJ)]. The DVFP introduces five new electric field peaks in the bulk of drift region compared with the conventional TLDMOS, leading to the breakdown voltage (BV) increase. Furthermore, the DVFP and SJ provide an electrons accumulation layer at the interface of the N pillar and oxide trench under the ON-state, reducing the specific ON-resistance (RON). With the 2-D device simulation, a BV of 840 V and a RON of 60.2 mQ · cm2 are realized on a 25-μm-thick SOI layer and 0.5 μm buried oxide layer, and the Baliga's figure of merit [(FOM), FOM = BV2/RON] of 11.4 MW/cm2 is achieved, breaking through the silicon limit.","Doping,
Performance evaluation,
Silicon-on-insulator,
Silicon,
Electric breakdown,
Electron devices,
Metals"
Security and Privacy in Molecular Communication and Networking: Opportunities and Challenges,"Molecular Communication (MC) is an emerging and promising communication paradigm for several multi-disciplinary domains like bio-medical, industry and military. Differently to the traditional communication paradigm, the information is encoded on the molecules, that are then used as carriers of information. Novel approaches related to this new communication paradigm have been proposed, mainly focusing on architectural aspects and categorization of potential applications. So far, security and privacy aspects related to the molecular communication systems have not been investigated at all and represent an open question that need to be addressed. The main motivation of this paper lies on providing some first insights about security and privacy aspects of MC systems, by highlighting the open issues and challenges and above all by outlining some specific directions of potential solutions. Existing cryptographic methods and security approaches are not suitable for MC systems since do not consider the pecific issues and challenges, that need ad-hoc solutions. We will discuss directions in terms of potential solutions by trying to highlight the main advantages and potential drawbacks for each direction considered. We will try to answer to the main questions: 1) why this solution can be exploited in the MC field to safeguard the system and its reliability? 2) which are the main issues related to the specific approach? .","Security,
Molecular communication,
Privacy,
Nanobioscience,
IEEE Potentials,
Immune system"
Dynamic Network Visualization withExtended Massive Sequence Views,"Networks are present in many fields such as finance, sociology, and transportation. Often these networks are dynamic: they have a structural as well as a temporal aspect. In addition to relations occurring over time, node information is frequently present such as hierarchical structure or time-series data. We present a technique that extends the Massive Sequence View ( msv) for the analysis of temporal and structural aspects of dynamic networks. Using features in the data as well as Gestalt principles in the visualization such as closure, proximity, and similarity, we developed node reordering strategies for the msv to make these features stand out that optionally take the hierarchical node structure into account. This enables users to find temporal properties such as trends, counter trends, periodicity, temporal shifts, and anomalies in the network as well as structural properties such as communities and stars. We introduce the circular msv that further reduces visual clutter. In addition, the (circular) msv is extended to also convey time-series data associated with the nodes. This enables users to analyze complex correlations between edge occurrence and node attribute changes. We show the effectiveness of the reordering methods on both synthetic and a rich real-world dynamic network data set.",
The Steganographer is the Outlier: Realistic Large-Scale Steganalysis,"We present a method for a completely new kind of steganalysis to determine who, out of a large number of actors each transmitting a large number of objects, is hiding payload inside some of them. It has significant challenges, including unknown embedding parameters and natural deviation between innocent cover sources, which are usually avoided in steganalysis tested under laboratory conditions. Our method uses standard steganalysis features, the maximum mean discrepancy measure of distance, and ranks the actors by their degree of deviation from the rest: we show that it works reliably, completely unsupervised, when tested against some of the standard steganography methods available to nonexperts. We also determine good parameters for the detector and show that it creates a two-player game between the guilty actor and the steganalyst.","Detectors,
Payloads,
Feature extraction,
Kernel,
Robustness,
Monitoring,
Art"
Exponential Separation of Information and Communication,"We show an exponential gap between communication complexity and information complexity, by giving an explicit example for a communication task (relation), with information complexity ≤ O(k), and distributional communication complexity ≥2k. This shows that a communication protocol cannot always be compressed to its internal information. By a result of Braverman [1], our gap is the largest possible. By a result of Braverman and Rao [2], our example shows a gap between communication complexity and amortized communication complexity, implying that a tight direct sum result for distributional communication complexity cannot hold.","Complexity theory,
Protocols,
Games,
Random variables,
Noise,
Noise measurement,
Entropy"
Oriented Image Foresting Transform Segmentation by Seed Competition,"Seed-based methods for region-based image segmentation are known to provide satisfactory results for several applications, being usually easy to extend to multidimensional images. However, while boundary-based methods like live wire can easily incorporate a preferred boundary orientation, region-based methods are usually conceived for undirected graphs, and do not resolve well between boundaries with opposite orientations. This motivated researchers to investigate extensions for some region-based frameworks, seeking to better solve oriented transitions. In this same spirit, we discuss how to incorporate this orientation information in a region-based approach called “IFT segmentation by seed competition” by exploring digraphs. We give direct proof for the optimality of the proposed extensions in terms of energy functions associated with the cuts. To stress these theoretical results, we also present an experimental evaluation that shows the obtained gains in accuracy for some 2D and 3D data sets of medical images.","Image segmentation,
Transforms,
Equations,
Accuracy,
Biomedical imaging,
Wires,
Three-dimensional displays"
Theory and Experiment of a W-Band Tunable Gyrotron Oscillator,"A gyrotron capable of both frequency and power tuning is a promising coherent millimeter-THz wave source. A self-consistent nonlinear theory is applied to investigate the electron cyclotron interaction between electron beam and wave modes of axial nonfixed profiles in an extended W-band TE01 mode cylindrical cavity. It is revealed that tuning the magnetic field strength can excite electron cyclotron resonances on forward wave, backward wave, and even simultaneous on both waves, which makes the system operate under distinctive states, namely the gyrotron backward wave oscillation state and the gyromonotron state. In this paper, a W-band prototype gyrotron oscillator based on an extended cylindrical waveguide cavity is built, and the experiment test indicates that the system starts oscillation in a relative wide range of the operation parameters. The measured frequency spectrum reveals the system iteratively switches between the lower order instability axial modes, and it operates under nonstationary oscillation states. The experimental measurement of highest output power ~8 kW is consistent with the theoretical predictions. An optimized gyrotron circuit with efficiency exceeding 20% and tunable bandwidth over 10 GHz is also presented. The free oscillation behaviors revealed in this paper provide interesting guidance for developing tunable gyrotrons in millimeter-THz wave range.","Gyrotrons,
Cavity resonators,
Tuning,
Electron beams,
Magnetic resonance,
Oscillators,
Magnetic domains"
Automatic Scaling of Internet Applications for Cloud Computing Services,Many Internet applications can benefit from an automatic scaling property where their resource usage can be scaled up and down automatically by the cloud service provider. We present a system that provides automatic scaling for Internet applications in the cloud environment. We encapsulate each application instance inside a virtual machine (VM) and use virtualization technology to provide fault isolation. We model it as the Class Constrained Bin Packing (CCBP) problem where each server is a bin and each class represents an application. The class constraint reflects the practical limit on the number of applications a server can run simultaneously. We develop an efficient semi-online color set algorithm that achieves good demand satisfaction ratio and saves energy by reducing the number of servers used when the load is low. Experiment results demonstrate that our system can improve the throughput by 180% over an open source implementation of Amazon EC2 and restore the normal QoS five times as fast during flash crowds. Large scale simulations demonstrate that our algorithm is extremely scalable: the decision time remains under 4 s for a system with 10 000 servers and 10 000 applications. This is an order of magnitude improvement over traditional application placement algorithms in enterprise environments.,"Servers,
Color,
Cloud computing,
Switches,
Computer architecture,
Central Processing Unit"
Secure kNN Query Processing in Untrusted Cloud Environments,"Mobile devices with geo-positioning capabilities (e.g., GPS) enable users to access information that is relevant to their present location. Users are interested in querying about points of interest (POI) in their physical proximity, such as restaurants, cafes, ongoing events, etc. Entities specialized in various areas of interest (e.g., certain niche directions in arts, entertainment, travel) gather large amounts of geo-tagged data that appeal to subscribed users. Such data may be sensitive due to their contents. Furthermore, keeping such information up-to-date and relevant to the users is not an easy task, so the owners of such data sets will make the data accessible only to paying customers. Users send their current location as the query parameter, and wish to receive as result the nearest POIs, i.e., nearest-neighbors (NNs). But typical data owners do not have the technical means to support processing queries on a large scale, so they outsource data storage and querying to a cloud service provider. Many such cloud providers exist who offer powerful storage and computational infrastructures at low cost. However, cloud providers are not fully trusted, and typically behave in an honest-but-curious fashion. Specifically, they follow the protocol to answer queries correctly, but they also collect the locations of the POIs and the subscribers for other purposes. Leakage of POI locations can lead to privacy breaches as well as financial losses to the data owners, for whom the POI data set is an important source of revenue. Disclosure of user locations leads to privacy violations and may deter subscribers from using the service altogether. In this paper, we propose a family of techniques that allow processing of NN queries in an untrusted outsourced environment, while at the same time protecting both the POI and querying users' positions. Our techniques rely on mutable order preserving encoding (mOPE), the only secure order-preserving encryption method known to-date. We also provide performance optimizations to decrease the computational cost inherent to processing on encrypted data, and we consider the case of incrementally updating data sets. We present an extensive performance evaluation of our techniques to illustrate their viability in practice.","Servers,
Encoding,
Query processing,
Data models,
Protocols,
Encryption"
Voxel Selection Framework in Multi-Voxel Pattern Analysis of fMRI Data for Prediction of Neural Response to Visual Stimuli,"Multi-voxel pattern analysis (MVPA) of functional magnetic resonance imaging (fMRI) data is an emerging approach for probing the neural correlates of cognition. MVPA allows cognitive states to be modeled as distributed patterns of neural activity and classified according to stimulus conditions. In practice, building a robust, generalizable classification model can be challenging because the number of voxels (features) far exceeds the number of stimulus instances/data observations. To avoid model overfitting, there is a need to select informative voxels before building a classification model. In this paper, we propose a robust feature (voxel) selection framework using mutual information (MI) and partial least square regression (PLS) to establish an informativeness index for prioritizing selection of voxels based on the degree of their association to the experimental conditions. We evaluated the robustness of our proposed framework by assessing performance of standard classification algorithms, when combined with our feature selection approach, in a publicly-available fMRI dataset of object-level representation widely used to benchmark MVPA performance (Haxby, 2001). The computational results suggest that our feature selection framework based on MI and PLS drastically improves the classification accuracy relative to those previously reported in the literature. Our results also suggest that highly informative voxels may provide meaningful insight into the functional-anatomic relationship of brain activity and stimulus conditions.","Feature extraction,
Accuracy,
Brain,
Support vector machines,
Educational institutions,
Indexes,
Pattern analysis"
Safe and Practical Energy-Efficient Detour Routing in IP Networks,"The Internet is generally not energy-efficient since all network devices are running all the time and only a small fraction of consumed power is actually related to traffic forwarding. Existing studies try to detour around links and nodes during traffic forwarding to save powers for energy-efficient routing. However, energy-efficient routing in traditional IP networks is not well addressed. The most challenges within an energy-efficient routing scheme in IP networks lie in safety and practicality. The scheme should ensure routing stability and loop- and congestion-free packet forwarding, while not requiring modifications in the traditional IP forwarding diagram and shortest-path routing protocols. In this paper, we propose a novel energy-efficient routing approach called safe and practical energy-efficient detour routing (SPEED) for power savings in IP networks. We provide theoretical insight into energy-efficient routing and prove that determining if energy-efficient routing exists is NP-complete. We develop a heuristic in SPEED to maximize pruned links in computing energy-efficient routings. Extensive experimental results show that SPEED significantly saves power consumptions without incurring network congestions using real network topologies and traffic matrices.","Routing,
IP networks,
Routing protocols,
Internet,
IEEE transactions,
Safety,
Energy consumption"
FN-DFE: Fuzzy-Neural Data Fusion Engine for Enhanced Resilient State-Awareness of Hybrid Energy Systems,"Resiliency and improved state-awareness of modern critical infrastructures, such as energy production and industrial systems, is becoming increasingly important. As control systems become increasingly complex, the number of inputs and outputs increase. Therefore, in order to maintain sufficient levels of state-awareness, a robust system state monitoring must be implemented that correctly identifies system behavior even when one or more sensors are faulty. Furthermore, as intelligent cyber adversaries become more capable, incorrect values may be fed to the operators. To address these needs, this paper proposes a fuzzyneural data fusion engine (FN-DFE) for resilient state-awareness of control systems. The designed FN-DFE is composed of a three-layered system consisting of: 1) traditional threshold based alarms; 2) anomalous behavior detector using self-organizing fuzzy logic system; and 3) artificial neural network-based system modeling and prediction. The improved control system stateawareness is achieved via fusing input data from multiple sources and combining them into robust anomaly indicators. In addition, the neural network-based signal predictions are used to augment the resiliency of the system and provide coherent state-awareness despite temporary unavailability of sensory data. The proposed system was integrated and tested with a model of the Idaho National Laboratory's hybrid energy system facility known as HYTEST. Experiment results demonstrate that the proposed FNDFE provides timely plant performance monitoring and anomaly detection capabilities. It was shown that the system is capable of identifying intrusive behavior significantly earlier than conventional threshold-based alarm systems.","Vectors,
Artificial neural networks,
Control systems,
Robustness,
Monitoring,
Sensor systems"
Performance and Reliability Evaluation of BSM Broadcasting in DSRC with Multi-Channel Schemes,"IEEE 1609.4 protocol defines a channel switching mechanism to enable a single radio operating efficiently on multiple channels to support both safety and non-safety services. Basic safety message (BSM) is transmitted only through the control channel at regular intervals. In this paper, we propose an analytic model based on interacting semi-Markov process (SMP) to evaluate both Medium Access Control (MAC) and application level performance and reliability of safety message broadcasting incorporating the impact of multi-channel operations. Message service time distribution is derived using Laplace-Stieltjes transform based on the proposed model. Due to the cyclic interactions between the SMP models for vehicles contending the same channel, fixed-point iteration is used to obtain converged solutions. Subsequently, MAC and application-level performance and reliability metrics are derived based on the converged solutions. Channel fading with path loss is taken into consideration in this derivation. The analytic models are validated through extensive simulations in NS2 to verify the effectiveness and accuracy of our proposed fixed-point iteration based model decomposition. The effects of channel switching mechanism and channel fading are also evaluated by comparing with other analytic models.","Fading channels,
Analytical models,
Reliability,
Safety,
Broadcasting"
Obstacle avoidance for industrial AGVs,"The paper deals with the obstacle avoidance problem for Automated Guided Vehicles (AGVs). We propose an automatic algorithm to build new obstacle-free trajectories that leave the original roadmap. The new path has to also comply with the dynamic and kinematic constraints of the AGV. The new paths are generated by means of polar spline curves, lane-change maneuver curves and line segments. The proposed method is validated by means of simulations.","Collision avoidance,
Sensors,
Splines (mathematics),
Vehicles,
Robots,
Safety,
Kinematics"
Exploring Feasibilities of Symmetry Islands and Monotonic Current Paths in Slicing Trees for Analog Placement,"Although modern analog placement algorithms aimed to minimize area and wirelength while satisfying symmetry, proximity, and other placement constraints, the generated layout does not reflect the circuit performance very well because of the routing-induced parasitics on the critical current/signal paths. To simultaneously consider symmetry, wirelength, area utilization, and current/signal paths during analog placement, this paper explores the feasibilities of symmetry islands and monotonic current paths in slicing trees for analog placement optimization. Experimental results show that the proposed formulation and algorithms can generate much more compact layouts resulting in similar or even better circuit performance compared with the previous work.","MOSFET,
Layout,
Vegetation,
Capacitance,
Circuit optimization,
Educational institutions"
Improvements to speaker adaptive training of deep neural networks,"Speaker adaptive training (SAT) is a well studied technique for Gaussian mixture acoustic models (GMMs). Recently we proposed to perform SAT for deep neural networks (DNNs), with speaker i-vectors applied in feature learning. The resulting SAT-DNN models significantly outperform DNNs on word error rates (WERs). In this paper, we present different methods to further improve and extend SAT-DNN. First, we conduct detailed analysis to investigate i-vector extractor training and flexible feature fusion. Second, the SAT-DNN approach is extended to improve tasks including bottleneck feature (BNF) generation, convolutional neural network (CNN) acoustic modeling and multilingual DNN-based feature extraction. Third, for transcribing multimedia data, we enrich the i-vector representation with global speaker attributes (age, gender, etc.) obtained automatically from video signals. On a collection of instructional videos, incorporation of the additional visual features is observed to boost the recognition accuracy of SAT-DNN.","Feature extraction,
Training,
Speech,
Acoustics,
Filter banks,
Convolution,
Visualization"
Cumulative-Sum-Based Localization of Sound Events in Low-Cost Wireless Acoustic Sensor Networks,"Wireless acoustic sensor networks (WASNs) are known for their potential applications in multiple areas, such as audio-based surveillance, binaural hearing aids or advanced acoustic monitoring. The knowledge of the spatial position of a source of interest is usually a requirement for many of these applications. Therefore, source localization is an important problem to be addressed in WASNs. Unfortunately, most localization algorithms need costly signal processing stages that prevent them from being implemented in low-cost sensor networks, requiring additional modules for signal acquisition and processing. This paper presents a low-complexity method for acoustic event detection and localization considering a change detection statistical framework. Two possible implementation approaches based on the efficient cumulative sum (CUSUM) algorithm are presented and discussed. Results from simulations and a real deployment show that the proposed techniques can be easily implemented in low-cost sensor networks, providing good localization accuracy and making good use of the available node resources.","Acoustics,
Microphones,
Maximum likelihood estimation,
Signal to noise ratio,
Speech,
Signal processing algorithms"
Dynamic Probabilistic CCA for Analysis of Affective Behavior and Fusion of Continuous Annotations,"Fusing multiple continuous expert annotations is a crucial problem in machine learning and computer vision, particularly when dealing with uncertain and subjective tasks related to affective behavior. Inspired by the concept of inferring shared and individual latent spaces in Probabilistic Canonical Correlation Analysis (PCCA), we propose a novel, generative model that discovers temporal dependencies on the shared/individual spaces (Dynamic Probabilistic CCA, DPCCA). In order to accommodate for temporal lags, which are prominent amongst continuous annotations, we further introduce a latent warping process, leading to the DPCCA with Time Warpings (DPCTW) model. Finally, we propose two supervised variants of DPCCA/DPCTW which incorporate inputs (i.e., visual or audio features), both in a generative (SG-DPCCA) and discriminative manner (SD-DPCCA). We show that the resulting family of models (i) can be used as a unifying framework for solving the problems of temporal alignment and fusion of multiple annotations in time, (ii) can automatically rank and filter annotations based on latent posteriors or other model statistics, and (iii) that by incorporating dynamics, modeling annotation-specific biases, noise estimation, time warping and supervision, DPCTW outperforms state-of-the-art methods for both the aggregation of multiple, yet imperfect expert annotations as well as the alignment of affective behavior.","Probabilistic logic,
Noise measurement,
Heuristic algorithms,
Estimation,
Computational modeling"
A Forward Approach to Establish Parametric Scattering Center Models for Known Complex Radar Targets Applied to SAR ATR,"This paper presents a forward approach to establish parametric scattering center models for known complex radar targets. In this approach, an automatic technique based on ray tracing and clustering is first developed to extract scattering centers directly from the computer-aided design (CAD) model of the targets. Following this, a set of forward methods is developed to determine the physically relevant parameters of two-dimension (2-D) attributed scatterers, such as type, amplitude, position and length. Finally, this approach is validated through the parametric model establishment of two complex targets and good agreement has been demonstrated between the reconstructed and actual radar characteristics. Different from the familiar inverse extraction approaches, the proposed approach provides a new forward way of constructing radar targets' feature database based on 2-D parametric scattering center model, which will ultimately facilitate the feature matching in the synthetic aperture radar (SAR) automatic target recognition (ATR) system.","Scattering,
Solid modeling,
Feature extraction,
Ray tracing,
Synthetic aperture radar,
Computational modeling"
Toward Long-Term and Accurate Augmented-Reality for Monocular Endoscopic Videos,"By overlaying preoperative radiological 3-D models onto the intraoperative laparoscopic video, augmented-reality (AR) displays promise to increase surgeons' visual awareness of high-risk surgical targets (e.g., the location of a tumor). Existing AR surgical systems lack in robustness and accuracy because of the many challenges in endoscopic imagery, such as frequent changes in illumination, rapid camera motions, prolonged organ occlusions, and tissue deformations. The frequent occurrence of these events can cause the loss of image (anchor) points, and thus, the loss of the AR display after a few frames. In this paper, we present the design of a new AR system that represents a first step toward long term and accurate augmented surgical display for monocular (calibrated and uncalibrated) endoscopic videos. Our system uses correspondence-search methods, and a new weighted sliding-window registration approach, to automatically and accurately recover the overlay by predicting the image locations of a high number of anchor points that were lost after a sudden image change. The effectiveness of the proposed system in maintaining a long term (over 2 min) and accurate (less than 1 mm) augmentation has been documented over a set of real partial-nephrectomy laparascopic videos.","Cameras,
Surgery,
Videos,
Solid modeling,
Tracking,
Feature extraction,
Biological systems"
Mobile Landmark Search with 3D Models,"Landmark search is crucial to improve the quality of travel experience. Smart phones make it possible to search landmarks anytime and anywhere. Most of the existing work computes image features on smart phones locally after taking a landmark image. Compared with sending original image to the remote server, sending computed features saves network bandwidth and consequently makes sending process fast. However, this scheme would be restricted by the limitations of phone battery power and computational ability. In this paper, we propose to send compressed (low resolution) images to remote server instead of computing image features locally for landmark recognition and search. To this end, a robust 3D model based method is proposed to recognize query images with corresponding landmarks. Using the proposed method, images with low resolution can be recognized accurately, even though images only contain a small part of the landmark or are taken under various conditions of lighting, zoom, occlusions and different viewpoints. In order to provide an attractive landmark search result, a 3D texture model is generated to respond to a landmark query. The proposed search approach, which opens up a new direction, starts from a 2D compressed image query input and ends with a 3D model search result.",
"Waveform Equations, Output Power, and Power Conversion Efficiency for Class-E Inverter Outside Nominal Operation","This paper presents analytical expressions for steady-state waveforms, output power, and power conversion efficiency for the class-E inverter outside the class-E zero-voltage switching and zero-derivative switching conditions. The analytical expressions in this paper include the MOSFET-body-diode effect. By carrying out PSpice simulations and circuit experiments, it is shown that the analytical predictions agree with the simulated and experimental results quantitatively, which indicates the validity of the analytical expressions. Additionally, the switching-pattern distribution maps are also given by using the analytical waveform equations.","waveform analysis,
invertors,
power MOSFET,
SPICE"
Wet Adhesion Inspired Bionic Climbing Robot,"Arthropods like stick insects have remarkable locomotion performance to climb vertical surfaces with their wet adhesion pads. This paper focuses on the development of a novel wet adhesion pad for wall-climbing robots that can scale walls. According to the morphology of insects' pads, mechanism of wet adhesive is analyzed. A novel wet adhesive pad with microstructure based on combining electroforming process with soft lithography is explored. Characteristic test results show that microstructures on the surface of pads fabricated by the proposed technique can improve the wet adhesive ability effectively. The design, manufacture, and test of a hexapod climbing robot prototype are also discussed. Experimental results show that the climbing ability of the robot with the pads is exceptional; the robot can climb up to more than 80 ° sloped surface and stick to the vertical surface statically.","Force,
Adhesives,
Surface morphology,
Robots,
Surface treatment,
Insects,
Microstructure"
Comparison Study of Swarm Intelligence Techniques for the Annual Crop Planning Problem,"Annual crop planning (ACP) is an NP-hard type optimization problem in agricultural planning. It involves finding the optimal solution for the seasonal hectare allocations of a limited amount of agricultural land, among various competing crops that are required to be grown on it. This study investigates the effectiveness of employing three relatively new swarm intelligence (SI) metaheuristic techniques in determining the solutions to the ACP problem with case study from an existing irrigation scheme. The SI metaheuristics studied are cuckoo search (CS), firefly algorithm (FA), and glowworm swarm optimization (GSO). Solutions obtained from these techniques are compared with that of a similar population-based technique, namely, genetic algorithm (GA). Results obtained show that each of the three SI algorithms provides superior solutions for the case studied.","agriculture,
genetic algorithms,
production planning,
resource allocation,
swarm intelligence"
Barriers to Near-Optimal Equilibria,"This paper explains when and how communication and computational lower bounds for algorithms for an optimization problem translate to lower bounds on the worst-case quality of equilibria in games derived from the problem. We give three families of lower bounds on the quality of equilibria, each motivated by a different set of problems: congestion, scheduling, and distributed welfare games, welfare-maximization in combinatorial auctions with ""black-box"" bidder valuations, and welfare-maximization in combinatorial auctions with succinctly described valuations. The most straightforward use of our lower bound framework is to harness an existing computational or communication lower bound to derive a lower bound on the worst-case price of anarchy (POA) in a class of games. This is a new approach to POA lower bounds, which relies on reductions in lieu of explicit constructions. More generally, the POA lower bounds implied by our framework apply to all classes of games that share the same underlying optimization problem, independent of the details of players' utility functions. For this reason, our lower bounds are particularly significant for problems of game design -- ranging from the design of simple combinatorial auctions to the computation of tolls for routing networks -- where the goal is to design a game that has only near-optimal equilibria. For example, our results imply that the simultaneous first-price auction format is optimal among all ""simple combinatorial auctions"" in several settings.",
Congestion-aware network selection and data offloading,"Wi-Fi offloading is a cost-effective approach to provide an immediate capacity relief to the congested areas in a cellular network. However, previously proposed schemes mainly focus on alleviating the cellular congestion by offloading the data traffic to Wi-Fi as much as possible, but without systematic considerations of the network congestion, switching penalty, and pricing in the networks. In this paper, we consider the network selection and data offloading problem in an integrated cellular Wi-Fi system by incorporating the practical considerations of (i) user mobility, (ii) location, user, and time dependent WiFi availabilities, (iii) network dependent switching time and switching cost for changing network connections, and (iv) usage-based pricing into our modeling. We formulate the interactions of the users' congestion-aware network selection decisions across multiple time slots as a non-cooperative network selection game (NSG), where the strategy of each user corresponds to a route on a graph. We prove that the NSG is equivalent to a congestion game, which implies that the game has the finite improvement property. As a result, when the players repeatedly perform better response updates, the system is guaranteed to converge to a pure Nash equilibrium. Simulation results show that our proposed NSG scheme achieves a better load balancing than two static heuristic schemes.","Switches,
IEEE 802.11 Standards,
Games,
Availability,
Pricing,
Convergence,
Mobile communication"
OER Approach for Specific Student Groups in Hardware-Based Courses,"Hardware-based courses in computer science studies require much effort from both students and teachers. The most important part of students' learning is attending in person and actively working on laboratory exercises on hardware equipment. This paper deals with a specific group of students, those who are marginalized by not being able to regularly attend lessons and perform the laboratory exercises. This group of “busy students” includes older students, and those who travel, are employed or are parents. In particular it describes how such students achieved impressive results in a hardware-based course by using Open Educational Resources (OER). These facilitated students' learning process and gave busy students the opportunity to organize their learning time so as to work on the hardware courses remotely from home when they had time and opportunity. The results of the evaluation show significant improvements, both in grade distribution and course throughput, after implementing the new Open Educational Resources approach.","Hardware,
Laboratories,
Education,
Computer science,
Software,
Microcontrollers,
Materials"
On resilient control of nonlinear systems under Denial-of-Service,"We investigate the analysis and design of a control strategy for nonlinear systems under Denial-of-Service attacks. Based on an ISS-Lyapunov function analysis, we provide a characterization of the maximal percentage of time that feedback information can be lost without resulting in instability of the system. Motivated by the presence of a digital channel we consider event-based controllers for which the existence of a minimal inter-sampling time is ensured.","Computer crime,
Stability analysis,
Actuators,
Delays,
Nonlinear systems,
Communication channels"
Order of Magnitude Sensitivity Increase in X-ray Fluorescence Computed Tomography (XFCT) Imaging With an Optimized Spectro-Spatial Detector Configuration: Theory and Simulation,"The purpose of this study was to increase the sensitivity of XFCT imaging by optimizing the data acquisition geometry for reduced scatter X-rays. The placement of detectors and detector energy window were chosen to minimize scatter X-rays. We performed both theoretical calculations and Monte Carlo simulations of this optimized detector configuration on a mouse-sized phantom containing various gold concentrations. The sensitivity limits were determined for three different X-ray spectra: a monoenergetic source, a Gaussian source, and a conventional X-ray tube source. Scatter X-rays were minimized using a backscatter detector orientation (scatter direction > 110° to the primary X-ray beam). The optimized configuration simultaneously reduced the number of detectors and improved the image signal-to-noise ratio. The sensitivity of the optimized configuration was 10 μg/mL (10 pM) at 2 mGy dose with the mono-energetic source, which is an order of magnitude improvement over the unoptimized configuration (102 pM without the optimization). Similar improvements were seen with the Gaussian spectrum source and conventional X-ray tube source. The optimization improvements were predicted in the theoretical model and also demonstrated in simulations. The sensitivity of XFCT imaging can be enhanced by an order of magnitude with the data acquisition optimization, greatly enhancing the potential of this modality for future use in clinical molecular imaging.",
The LEAP FPGA operating system,"FPGAs offer attractive power and performance for many applications, especially relative to traditional sequential architectures. In spite of these advantages, FPGAs have been deployed in only a few, niche domains.We argue that the difficulty of programming FPGAs all but precludes their use in more general systems: FPGA programmers are currently exposed to all the gory system details that software operating systems long ago abstracted away. In this work, we present the Latency-insensitive Environment for Application Programming (LEAP), an FPGA operating system built around latency-insensitive communications channels. LEAP alleviates the FPGA programming problem by providing a rich set of portable latency-insensitive abstraction layers for program development. Unlike software operating systems services, which are generally dynamic, the nature of FPGAs requires that many configuration decisions be made at compile time. We present an extensible interface for compile-time management of resources. We demonstrate that LEAP provides design portability, while consuming as little as 3% of FPGA area, by mapping several designs on to various FPGA platforms.","Field programmable gate arrays,
Operating systems,
Libraries,
Program processors,
Hardware,
Abstracts"
A General Framework of Wiretap Channel With Helping Interference and State Information,"This paper considers a general framework of the wiretap channel with helping interference and state information (WT-HI-SI), where a transmitter-receiver pair wishes to keep the message secret from a passive eavesdropper in the presence of an interferer and a random state. The interferer is to help the legitimate transceivers to enhance their security level, and the state information is available at the transmitter, but not at the eavesdropper. For the discrete memoryless WT-HI-SI, an achievable scheme is proposed by combining the noise forward scheme and the double binning coding scheme. Some previously proposed schemes can be viewed as special cases of the proposed scheme. Then, the achievable scheme is applied to two special channels, the Gaussian WT-HI-SI and the Gaussian WT-HI, respectively. For the Gaussian WT-HI-SI, there exists an external random state noncausally available to the transmitter in advance. But for the Gaussian WT-HI, there does not exist any external random state. In this case, we propose a novel achievable scheme that requires the transmitter to artificially generate the random state whose power can be adjusted adaptively according to dynamic channel conditions. Both the analytic and numerical results are provided to demonstrate that the use of the state information can generally improve the secrecy performance. A more important contribution of this paper is that even for the scenario where no external state information is available to the transmitter, the proposed scheme with the artificial state can still achieve a strictly larger secrecy rate in comparison with existing interference assisted schemes.","Interference,
Transmitters,
Receivers,
Encoding,
Signal to noise ratio,
Context"
An Ultracapacitor Integrated Power Conditioner for Intermittency Smoothing and Improving Power Quality of Distribution Grid,"Penetration of various types of distributed energy resources (DERs) like solar, wind, and plug-in hybrid electric vehicles (PHEVs) onto the distribution grid is on the rise. There is a corresponding increase in power quality problems and intermittencies on the distribution grid. In order to reduce the intermittencies and improve the power quality of the distribution grid, an ultracapacitor (UCAP) integrated power conditioner is proposed in this paper. UCAP integration gives the power conditioner active power capability, which is useful in tackling the grid intermittencies and in improving the voltage sag and swell compensation. UCAPs have low energy density, high-power density, and fast charge/discharge rates, which are all ideal characteristics for meeting high-power low-energy events like grid intermittencies, sags/swells. In this paper, UCAP is integrated into dc-link of the power conditioner through a bidirectional dc-dc converter that helps in providing a stiff dc-link voltage. The integration helps in providing active/reactive power support, intermittency smoothing, and sag/swell compensation. Design and control of both the dc-ac inverters and the dc-dc converter are discussed. The simulation model of the overall system is developed and compared with the experimental hardware setup.",
Generating Summary Risk Scores for Mobile Applications,"One of Android's main defense mechanisms against malicious apps is a risk communication mechanism which, before a user installs an app, warns the user about the permissions the app requires, trusting that the user will make the right decision. This approach has been shown to be ineffective as it presents the risk information of each app in a “stand-alone” fashion and in a way that requires too much technical knowledge and time to distill useful information. We discuss the desired properties of risk signals and relative risk scores for Android apps in order to generate another metric that users can utilize when choosing apps. We present a wide range of techniques to generate both risk signals and risk scores that are based on heuristics as well as principled machine learning techniques. Experimental results conducted using real-world data sets show that these methods can effectively identify malware as very risky, are simple to understand, and easy to use.",
Incremental synthesis of switching protocols via abstraction refinement,"We consider the problem of synthesizing switching protocols that regulate the modes of a switched system in order to guarantee that the trajectories of the system satisfy certain high-level specifications. In particular, we develop a computational framework for incremental synthesis of switching protocols. Augmented finite transition systems are used as abstract representations of continuous dynamics. Inspired by counter-example guided abstraction refinement procedures for hybrid system verification, we start with a coarse abstraction and gradually refine it according to preorder relations on augmented finite transition systems. At each iteration, the proposed procedure can produce either a switching protocol that ensures the satisfaction of the specification, a certificate for nonexistence of such a protocol, or a refinement suggestion together with a partial solution to be used in the next iteration. Although the procedure is not guaranteed to terminate in general, we illustrate its practical applicability with two simple examples.","Games,
Switches,
Protocols,
Switched systems,
Trajectory,
Abstracts,
Heuristic algorithms"
Improving Smart Conference Participation Through Socially Aware Recommendation,"This paper addresses recommending presentation sessions at smart conferences to participants. We propose a venue recommendation algorithm: socially aware recommendation of venues and environments (SARVE). SARVE computes correlation and social characteristic information of conference participants. In order to model a recommendation process using distributed community detection, SARVE further integrates the current context of both the smart conference community and participants. SARVE recommends presentation sessions that may be of high interest to each participant. We evaluate SARVE using a real-world dataset. In our experiments, we compare SARVE with two related state-of-the-art methods, namely context-aware mobile recommendation services and conference navigator (recommender) model. Our experimental results show that in terms of the utilized evaluation metrics, i.e., precision, recall, and f-measure, SARVE achieves more reliable and favorable social (relations and context) recommendation results.","Context,
Communities,
Recommender systems,
Correlation,
Social network services,
Schedules,
Mobile communication"
Efficient Multiview Depth Coding Optimization Based on Allowable Depth Distortion in View Synthesis,"Depth video is used as the geometrical information of 3D world scenes in 3D view synthesis. Due to the mismatch between the number of depth levels and disparity levels in the view synthesis, the relationship between depth distortion and rendering position error can be modeled as a many-to-one mapping function, in which different depth distortion values might be projected to the same geometrical distortion in the synthesized virtual view image. Based on this property, we present an allowable depth distortion (ADD) model for 3D depth map coding. Then, an ADD-based rate-distortion model is proposed for mode decision and motion/disparity estimation modules aiming at minimizing view synthesis distortion at a given bit rate constraint. In addition, an ADD-based depth bit reduction algorithm is proposed to further reduce the depth bit rate while maintaining the qualities of the synthesized images. Experimental results in intra depth coding show that the proposed overall algorithm achieves Bjontegaard delta peak signal-to-noise ratio gains of 1.58 and 2.68 dB on average for half and integer-pixel rendering precisions, respectively. In addition, the proposed algorithms are also highly efficient for inter depth coding when evaluated with different metrics.","Image coding,
Rendering (computer graphics),
Image color analysis,
Rate-distortion,
Three-dimensional displays,
Three-dimensional television"
An Improved Ensemble Learning Method for Classifying High-Dimensional and Imbalanced Biomedicine Data,"Training classifiers on skewed data can be technically challenging tasks, especially if the data is high-dimensional simultaneously, the tasks can become more difficult. In biomedicine field, skewed data type often appears. In this study, we try to deal with this problem by combining asymmetric bagging ensemble classifier (asBagging) that has been presented in previous work and an improved random subspace (RS) generation strategy that is called feature subspace (FSS). Specifically, FSS is a novel method to promote the balance level between accuracy and diversity of base classifiers in asBagging. In view of the strong generalization capability of support vector machine (SVM), we adopt it to be base classifier. Extensive experiments on four benchmark biomedicine data sets indicate that the proposed ensemble learning method outperforms many baseline approaches in terms of Accuracy, F-measure, G-mean and AUC evaluation criterions, thus it can be regarded as an effective and efficient tool to deal with high-dimensional and imbalanced biomedical data.","Feature extraction,
Bioinformatics,
Frequency selective surfaces,
Training,
Support vector machines,
Cancer"
Secure communication in cellular networks: The benefits of millimeter wave mobile broadband,"This paper proposes millimeter wave (mmWave) mobile broadband for achieving secure communication in downlink cellular network. Analog beamforming with phase shifters is adopted for the mmWave transmission. The secrecy throughput is analyzed based on two different transmission modes, namely delay-tolerant transmission and delay-limited transmission. The impact of large antenna arrays at the mmWave frequencies on the secrecy throughput is examined. Numerical results corroborate our analysis and show that mmWave systems can enable significant secrecy improvement. Moreover, it is indicated that with large antenna arrays, multi-gigabit per second secure link at the mmWave frequencies can be reached in the delay-tolerant transmission mode and the adverse effect of secrecy outage vanishes in the delay-limited transmission mode.","Throughput,
Base stations,
Antenna arrays,
Wireless communication,
Receivers,
Fading,
Transmitting antennas"
Robust Path Diversity for Network Quality of Service in Cyber-Physical Systems,"The reliability of control in cyber-physical systems (CPSs) heavily depends on the network-induced delay. The problem of obtaining a maximum allowable delay bound has been widely studied in the networked control systems (NCS) area. Once the delay bound is derived, the remaining question is how to make a network satisfy the bound. In this paper, we propose a robust path selection algorithm, which exploits multipath diversity for providing robust network performance against intrinsic randomness in delay. Our path selection algorithm gives the required paths for any given robustness level parameterized by the reliability violation probability. Based on extensive experimental results with our testbed, we empirically show that the proposed scheme can provide the required network quality of service (QoS) for system robustness.","Robustness,
Delays,
Optimization,
Uncertainty,
Quality of service,
Algorithm design and analysis"
Exploiting Trajectory-Based Coverage for Geocast in Vehicular Networks,"Geocast in vehicular networks aims to deliver a message to a target geographical region, which is useful for many applications such as geographic advertising. This is a highly challenging task in vehicular network environments due to the rare encounter opportunities and uncertainty caused by vehicular mobility. As more vehicles are equipped with on-board navigation systems, vehicle trajectories are ready for exploitation. We observe that a vehicle has a higher capability of delivering a message to the target region if its own future trajectory or trajectories of those vehicles to be encountered overlap the target region. Motivated by this observation, we develop a message forwarding metric, called coverage capability, to characterize the capability of a vehicle to successfully geocast the message. When calculating the coverage capability, we are facing the major challenge raised by the absence of accurate vehicle arrival time. Through an empirical study using real vehicular GPS traces of 2,600 taxis, we verify that the travel time of a vehicle, which is modeled as a random variable, follows the Gamma distribution. The travel time modeling helps us to make accurate predictions for inter-vehicle encounters. We perform extensive trace-driven simulations and the results show that our approach achieves 37.4 percent higher delivery ratio and 43.1 percent lower transmission overhead comparing with GPSR which is a representative geographic routing protocol.",
Genetic algorithm-aided dynamic fuzzy rule interpolation,"Fuzzy rule interpolation (FRI) is a well established area for reducing the complexity of fuzzy models and for making inference possible in sparse rule-based systems. Regardless of the actual FRI approach employed, the interpolative reasoning process generally produces a large number of interpolated rules, which are then discarded as soon as the required outcomes have been obtained. However, these interpolated rules may contain potentially useful information, e.g., covering regions that were uncovered by the original sparse rule base. Thus, such rules should be exploited in order to develop a dynamic rule base for improving the overall system coverage and efficacy. This paper presents a genetic algorithm based dynamic fuzzy rule interpolation framework, for the purpose of selecting, combining, and promoting informative, frequently used intermediate rules into the existing rule base. Simulations are employed to demonstrate the proposed method, showing better accuracy and robustness than that achievable through conventional FRI that uses just the original sparse rule base.","Biological cells,
Sociology,
Statistics,
Genetic algorithms,
Interpolation,
Heuristic algorithms,
Clustering algorithms"
Solving an Extended Double Row Layout Problem Using Multiobjective Tabu Search and Linear Programming,"Facility layout problems have drawn much attention over the years, as evidenced by many different versions and formulations in the manufacturing context. This paper is motivated by semiconductor manufacturing, where the floor space is highly expensive (such as in a cleanroom environment) but there is also considerable material handling amongst machines. This is an integrated optimization task that considers both material movement and manufacturing area. Specifically, a new approach combining multiobjective tabu search with linear programming is proposed for an extended double row layout problem, in which the objective is to determine exact locations of machines in both rows to minimize material handling cost and layout area where material flows are asymmetric. First, a formulation of this layout problem is established. Second, an optimization framework is proposed that utilizes multiobjective tabu search and linear programming to determine a set of non-dominated solutions, which includes both sequences and positions of machines. This framework is applied to various manufacturing situations, and compared with an exact approach and a popular multiobjective genetic algorithm optimization algorithm. Experimental results show that the proposed approach is able to obtain sets of Pareto solutions that are far better than those obtained by the alternative approaches.","Layout,
Linear programming,
Materials handling,
Search problems,
Manufacturing,
Optimization"
Highly Scalable Raised Source/Drain InAs Quantum Well MOSFETs Exhibiting I_{{\scriptstyle {\rm ON}}}=482~\mu{\rm A}/\mu{\rm m} at I_{{\scriptstyle {\rm OFF}}}=100~{\rm nA}/\mu{\rm m} and V_{\rm DD}=0.5~{\rm V},"We report raised source/drain (S/D) InAs quantum well MOSFETs incorporating a vertical spacer formed by metal-organic chemical vapor deposition epitaxial regrowth. By adopting a 12-nm-thick vertical spacer between the channel and the N+ S/D, OFF-state characteristics are significantly improved. A device with a 40-nm-Lg and 12-nm-thick spacer shows 2.5-mS/μm peak transconductance (gm), 86-mV/decade subthreshold swing at VDS = 0.5 V, 83-mV/V drain-induced barrier lowering, and 482-μA/μm ON-current at 100-nA/μm OFF-current and VDD = 0.5 V. In addition, a 3.0-mS/μm peak gm at VDS = 0.5 V is achieved in an 18-nm-Lg device with a 2-nm-thick spacer, the highest reported peak gm of any field-effect transistor.","Logic gates,
MOSFET,
Indium compounds,
Performance evaluation,
Leakage currents,
Electrostatics,
Resistance"
"Routing, spectrum and core assignment for space division multiplexing elastic optical networks","Elastic Optical Network (EON) is expected as one of future networks in terms of spectrum flexibility. While Routing and Wavelength Assignment (RWA) problem is one of the key issues in traditional Wavelength Division Multiplexing (WDM) networks, Routing and Spectrum Assignment (RSA) problem has much impact on network performance in EONs. On the other hand, Data-Center (DC) traffic and/or mobile back-haul traffic keep on increasing. To deal with such forthcoming huge capacity of applications, Space Division Multiplexing (SDM) technologies, such as Multi-Core Fiber (MCF) and few-mode fiber, are intensively researched. From network perspective, this paper focuses on Routing, Spectrum and Core Assignment (RSCA) problem for future SDM-EON. Introducing multi-core fibers makes RSA problem more complex because fiber-core dimension is newly expanded. In addition, physical impairment caused by MCF must be taken into account. In this paper, first, the target RSCA problem is divided into the routing and SCA problems, and K-shortest path based pre-computation method is introduced as the routing solution. Next, according to whether MCF has inter-core crosstalk or not, we propose SCA methods with crosstalk awareness and with prioritized area concept, respectively. Finally, the paper evaluates the effectiveness of the proposed algorithms compared with representative ones.","Crosstalk,
Optical fiber networks,
Routing,
Optical crosstalk,
Optical modulation,
Optical fibers"
Synchronization of Boolean Networks with Different Update Schemes,"In this paper, the synchronizations of Boolean networks with different update schemes (synchronized Boolean networks and asynchronous Boolean networks) are investigated. All nodes in Boolean network are represented in terms of semi-tensor product. First, we give the concept of inner synchronization and observe that all nodes in a Boolean network are synchronized with each other. Second, we investigate the outer synchronization between a driving Boolean network and a corresponding response Boolean network. We provide not only the concept of traditional complete synchronization, but also the anti-synchronization and get the anti-synchronization in simulation. Third, we extend the outer synchronization to asynchronous Boolean network and get the complete synchronization between an asynchronous Boolean network and a response Boolean network. Consequently, theorems for synchronization of Boolean networks and asynchronous Boolean networks are derived. Examples are provided to show the correctness of our theorems.","Synchronization,
Neural networks,
Manganese,
Computational biology,
Bioinformatics,
Biological system modeling"
Vision-based autonomous landing system for unmanned aerial vehicle: A survey,"Recently, there has been growing interest in developing unmanned aircraft system (UAS) based on visual sensors. During the whole autonomous assignment, the landing procedure is one of the most dangerous and challenging process. For most of unmanned aircraft vehicle, visual sensors are the basic equipment, which are also widely used during the landing maneuver. This paper first presents the main research groups involved in the development of vision-based autonomous landing systems. Then it discusses the detail of each algorithms and systems in different categories. The goal of this paper is to review the state-of-the-art vision-based autonomous landing methods that captures all milestones and seminal works. These algorithms and systems are classified into different categories. Finally, the paper highlights challenges in this research field.","Unmanned aerial vehicles,
Robots,
Cameras,
Sensors,
Automation,
Helicopters,
Visualization"
Representing Business Processes Through a Temporal Data-Centric Workflow Modeling Language: An Application to the Management of Clinical Pathways,"Workflow technology has emerged as one of the leading technologies in modeling, redesigning, and executing business processes in several different application domains. Among them, the representation and management of health and clinical processes have been attracting a growing interest. Such processes are in general related to the way each health organization provides the required healthcare services. Health and clinical processes underlie the specification and application of clinical protocols, clinical guidelines, clinical pathways, and the most common clinical/administrative procedures. Current workflow systems are lacking in effective management of three general key aspects that are common (not only) in the clinical/health context: data dependencies, exception handling, and temporal constraints. For example, a laparoscopic intervention may need the results of the concurrent bioptic analysis to be properly concluded while exceptional recovery activities have to be performed in case of emergency evidence during standard treatment; however, the successful application of a fibrinolytic therapy requires a maximum delay of 30 min after the admission into the emergency department. In this paper, we propose TNest, a new advanced, structured, and highly modular workflow modeling language that allows one to easily express data dependencies and time constraints during process design, in addition to exception handling and compensation activities. As for temporal constraints, we focus here on temporal controllability which is the capability of executing a workflow for all possible durations of all tasks satisfying all temporal constraints. Moreover, we analyze the computational complexity of the temporal controllability problem in TNest, and we propose a general algorithm to check the controllability. All the features of TNest that have been considered to model clinical pathways from classical clinical guidelines, i.e., those features for the management of STEMI patients, published by the American College of Cardiology/American Heart Association, will be used throughout the paper as a motivating scenario.","Guidelines,
Controllability,
Medical treatment,
Computational modeling,
Business,
Data models"
Detection of Respiratory Arousals Using Photoplethysmography (PPG) Signal in Sleep Apnea Patients,"Respiratory events during sleep induce cortical arousals and manifest changes in autonomic markers in sleep disorder breathing (SDB). Finger photoplethysmography (PPG) has been shown to be a reliable method of determining sympathetic activation. We hypothesize that changes in PPG signals are sufficient to predict the occurrence of respiratory-event-related cortical arousal. In this study, we develop a respiratory arousal detection model in SDB subjects by using PPG features. PPG signals from 10 SDB subjects (9 male, 1 female) with age range 43-75 years were used in this study. Time domain features of PPG signals, such as 1) PWA-pulse wave amplitude, 2) PPI-peak-to-peak interval, and 3) Area-area under peak, were used to detect arousal events. In this study, PWA and Area have shown better performance (higher accuracy and lower false rate) compared to PPI features. After investigating possible groupings of these features, combination of PWA and Area (PWA + Area) was shown to provide better accuracy with a lower false detection rate in arousal detection. PPG-based arousal indexes agreed well across a wide range of decision thresholds, resulting in a receiver operating characteristic with an area under the curve of 0.91. For the decision threshold (PCthresh = 25%) chosen for the final analyses, a sensitivity of 68.1% and a specificity of 95.2% were obtained. The results showed an accuracy of 84.68%, 85.15%, 86.93%, and 50.79% with a false rate of 21.80%, 55.41%, 64.78%, and 50.79% at PCthresh = 25% or PPI, PWA, Area , and PWA + Area features, respectively. This indicates that combining PWA and Area features reduced the false positive rate without much affecting the sensitivity of the arousal detection system. In conclusion, the PPG-based respiratory arousal detection model is a simple and promising alternative to the conventional electroencephalogram (EEG)-based respiratory arousal detection system.","Feature extraction,
Accuracy,
Electroencephalography,
Sleep apnea,
Brain modeling,
Heart rate variability"
Towards Online Shortest Path Computation,"The online shortest path problem aims at computing the shortest path based on live traffic circumstances. This is very important in modern car navigation systems as it helps drivers to make sensible decisions. To our best knowledge, there is no efficient system/solution that can offer affordable costs at both client and server sides for online shortest path computation. Unfortunately, the conventional client-server architecture scales poorly with the number of clients. A promising approach is to let the server collect live traffic information and then broadcast them over radio or wireless network. This approach has excellent scalability with the number of clients. Thus, we develop a new framework called live traffic index (LTI)which enables drivers to quickly and effectively collect the live traffic information on the broadcasting channel. An impressive result is that the driver can compute/update their shortest path result by receiving only a small fraction of the index. Our experimental study shows that LTI is robust to various parameters and it offers relatively short tune-in cost (at client side), fast query response time (at client side), small broadcast size (at server side), and light maintenance time (at server side)for online shortest path problem.","Indexes,
Roads,
Servers,
Maintenance engineering,
Computational modeling,
Time factors,
Navigation"
Evolving Classifiers to Recognize the Movement Characteristics of Parkinson's Disease Patients,"Parkinson's disease is a debilitating neurological condition that affects approximately 1 in 500 people and often leads to severe disability. To improve clinical care, better assessment tools are needed that increase the accuracy of differential diagnosis and disease monitoring. In this paper, we report how we have used evolutionary algorithms to induce classifiers capable of recognizing the movement characteristics of Parkinson's disease patients. These diagnostically relevant patterns of movement are known to occur over multiple time scales. To capture this, we used two different classifier architectures: sliding-window genetic programming classifiers, which model over-represented local patterns that occur within time series data, and artificial biochemical networks, computational dynamical systems that respond to dynamical patterns occurring over longer time scales. Classifiers were trained and validated using movement recordings of 49 patients and 41 age-matched controls collected during a recent clinical study. By combining classifiers with diverse behaviors, we were able to construct classifier ensembles with diagnostic accuracies in the region of 95%, comparable to the accuracies achieved by expert clinicians. Further analysis indicated a number of features of diagnostic relevance, including the differential effect of handedness and the over-representation of certain patterns of acceleration.","Diseases,
Medical diagnostic imaging,
Context,
Time series analysis,
Standards,
Evolutionary computation,
Biological system modeling"
Toward Amp-Level Field Emission With Large-Area Arrays of Pt-Coated Self-Aligned Gated Nanoscale Tips,"Design, fabrication, and characterization of Pt-coated, self-aligned, and gated Si field emission arrays are reported. Arrays of 320000 tips with 10 μm pitch are employed to emit currents as high as 0.35 A (current density of 1.1 A/cm2) at gate-emitter biases of 300 V. For reliability, the devices have a gate dielectric thicker than 2.5 μm maintaining the field inside gate insulator below 150 V/μm and a 5-nm-thick Pt-coating protecting the tips against sputtering by back-streaming ions. The Pt-coating also increases the capture cross section of electrons from the emitter cone, resulting in higher emission currents compared with uncoated Si tips when the supply of electrons is limited to the surface. The device failure at high currents is associated with plasma ignition due to local pressure rise caused by outgassing of the anode. At lower emission currents, the devices are capable of long-term emission (>3 h) at pressures as high as 10-5 Torr. Furthermore, a high-yield fabrication process is presented for large-area fabrication of highly-uniform gated tip arrays that could be expanded to active areas larger than 10 cm2 to increase the emission current.","Logic gates,
Silicon,
Dielectrics,
Fabrication,
Anodes,
Etching"
Lazy Cohomology Generators: A Breakthrough in (Co)homology Computations for CEM,"Computing the first cohomology group generators received great attention in computational electromagnetics as a theoretically sound and safe method to produce cuts required when eddy-current problems are solved with the magnetic scalar potential formulations. This paper exploits the novel concept of lazy cohomology generators and a fast and general algorithm to compute them. This graph-theoretic algorithm is much faster than all competing ones being the typical computational time in the order of seconds even with meshes formed by millions of elements. Moreover, this paper introduces the use of minimal boundary generators to ease human-based basis selection and to obtain representatives of generators with compact support. We are persuaded that this is the definitive solution to this long-standing problem.","Generators,
Conductors,
Electric potential,
Standards,
Vectors,
Complexity theory,
Equations"
"A 0.13-\mu{\rm m}
CMOS Low-Power Capacitor-Less LDO Regulator Using Bulk-Modulation Technique","In this paper, a bulk-modulation technique is introduced for improving the performance of low-drop-out (LDO) voltage regulators. Compared to conventional LDO voltage regulators, the proposed circuit achieves improved accuracy, stability, and output load current capability. The technique is particularly suited for low-power applications such as biomedical implants and portable devices. A proof-of-concept prototype is designed and fabricated in 0.13-μm CMOS, to illustrate the enhancement that can be achieved by applying this technique. The proposed enhanced LDO regulator which is based on conventional LDO regulators is able to delivers up to 5 mA of load current while providing a 1 V (~ 1.5% load regulation) drawing 99.0 μA from a 1.2 V supply. Measurement results confirm that as compared to conventional LDOs, the proposed circuit offers better stability as well as %75 improvement in the load current delivery and ~10× faster recovery time for no-load to and from full-load transitions.","Regulators,
Transistors,
Voltage control,
Threshold voltage,
Modulation,
Bandwidth,
Logic gates"
Toward a modular soft sensor-embedded glove for human hand motion and tactile pressure measurement,"The ability to measure human hand motions and interaction forces is critical to improving our understanding of manual gesturing and grasp mechanics. This knowledge serves as a basis for developing better tools for human skill training and rehabilitation, exploring more effective methods of designing and controlling robotic hands, and creating more sophisticated human-computer interaction devices which use complex hand motions as control inputs. This paper presents work on the design, fabrication, and experimental validation of a soft sensor-embedded glove which measures both hand motion and contact pressures during human gesturing and manipulation tasks. We design an array of liquid-metal embedded elastomer sensors to measure up to hundreds of Newtons of interaction forces across the human palm during manipulation tasks and to measure skin strains across phalangeal and carpal joints for joint motion tracking. The elastomeric sensors provide the mechanical compliance necessary to accommodate anatomical variations and permit a normal range of hand motion. We explore methods of assembling this soft sensor glove from modular, individually fabricated pressure and strain sensors and develop design guidelines for their mechanical integration. Experimental validation of a soft finger glove prototype demonstrates the sensitivity range of the designed sensors and the mechanical robustness of the proposed assembly method, and provides a basis for the production of a complete soft sensor glove from inexpensive modular sensor components.","Thumb,
Strain,
Joints,
Mechanical sensors,
Fabrication"
A K-Main Routes Approach to Spatial Network Activity Summarization,"Data summarization is an important concept in data mining for finding a compact representation of a dataset. In spatial network activity summarization (SNAS), we are given a spatial network and a collection of activities (e.g., pedestrian fatality reports, crime reports) and the goal is to find k shortest paths that summarize the activities. SNAS is important for applications where observations occur along linear paths such as roadways, train tracks, etc. SNAS is computationally challenging because of the large number of k subsets of shortest paths in a spatial network. Previous work has focused on either geometry or subgraph-based approaches (e.g., only one path), and cannot summarize activities using multiple paths. This paper proposes a K-Main Routes (KMR) approach that discovers k shortest paths to summarize activities. KMR generalizes K-means for network space but uses shortest paths instead of ellipses to summarize activities. To improve performance, KMR uses network Voronoi, divide and conquer, and pruning strategies. We present a case study comparing KMR's network-based output (i.e., shortest paths) to geometry-based outputs (e.g., ellipses) on pedestrian fatality data. Experimental results on synthetic and real data show that KMR with our performance-tuning decisions yields substantial computational savings without reducing summary path coverage.","Roads,
Water resources,
Rivers,
Generators,
Electronic mail"
Solving Technical Problems on the Full-Bridge Single-Stage PFCs,"AC-DC conversion with power factor correction using full-bridge single-stage (FBSS) converters may introduce various complex operating limits and control problems that are not usually described in literature. This is mainly due to the fact that they devaluate and restrict the number of applications of those topologies. These problems are identified as primary transformer saturation and output voltage perturbations. The operation at light loads and with wide load variation is also a complex issue that leads to uncontrollable input current and dc bus voltage. This paper clarifies such technical problems referring their impact in the FBSS topologies operation, and presents design criteria and control solutions to minimize their effects. A low cost free wheeling circuit (FWC) that allows null input current to solve the light load operation problem is also presented.",
Reachability-based safe learning with Gaussian processes,"Reinforcement learning for robotic applications faces the challenge of constraint satisfaction, which currently impedes its application to safety critical systems. Recent approaches successfully introduce safety based on reachability analysis, determining a safe region of the state space where the system can operate. However, overly constraining the freedom of the system can negatively affect performance, while attempting to learn less conservative safety constraints might fail to preserve safety if the learned constraints are inaccurate. We propose a novel method that uses a principled approach to learn the system's unknown dynamics based on a Gaussian process model and iteratively approximates the maximal safe set. A modified control strategy based on real-time model validation preserves safety under weaker conditions than current approaches. Our framework further incorporates safety into the reinforcement learning performance metric, allowing a better integration of safety and learning. We demonstrate our algorithm on simulations of a cart-pole system and on an experimental quadrotor application and show how our proposed scheme succeeds in preserving safety where current approaches fail to avoid an unsafe condition.","Safety,
Level set,
Reachability analysis,
Measurement,
Algorithm design and analysis,
Control systems,
Kernel"
Codes Between MBR and MSR Points With Exact Repair Property,"In this paper, distributed storage systems with exact repair are studied. Constructions for exact-regenerating codes between the minimum storage regenerating (MSR) and the minimum bandwidth regenerating (MBR) points are given. To the best of our knowledge, no previous construction of exact-regenerating codes between MBR and MSR points is done except in the works by Tian et al. and Sasidharan et al. In contrast to their works, the methods used here are elementary. In this paper, it is shown that in the case that the parameters
n
,
k
, and
d
are close to each other, the given construction is close to optimal when comparing with the known functional repair capacity. This is done by showing that when the distances of the parameters
n
,
k
, and
d
are fixed but the actual values approach to infinity, the fraction of the performance of constructed codes with exact repair and the known capacity of codes with functional repair, approaches to one. Also, a simple variation of the constructed codes with almost the same performance is given. Also some bounds for the capacity of exact-repairing codes are given. These bounds illustrate the relationships between storage codes with different parameters.",
High-Order Statistics of Microtexton for HEp-2 Staining Pattern Classification,"This study addresses the classification problem of the HEp-2 cell using indirect immunofluorescent (IIF) image analysis, which can indicate the presence of autoimmune diseases by finding antibodies in the patient serum. Generally, the method used for IIF analysis remains subjective, and depends too heavily on the experience and expertise of the physician. Recently, studies have shown that it is possible to identify the cell patterns using IIF image analysis and machine learning techniques. However, it still has large gap in recognition rates to the physical experts' one. This paper explores an approach in which the discriminative features of HEp-2 cell images in IIF are extracted and then, the patterns of the HEp-2 cell are identified using machine learning techniques. Motivated by the progress in the research field of computer vision, as a result of which small local pixel pattern distributions can now be highly discriminative, the proposed strategy employs a parametric probability process to model local image patches (textons: microstructures in the cell image) and extract the higher-order statistics of the model parameters for the image description. The proposed strategy can adaptively characterize the microtexton space of HEp-2 cell images as a generative probability model, and discover the parameters that yield a better fitting of the training space, which would lead to a more discriminant representation for the cell image. The simple linear support vector machine is used for cell pattern identification because of its low computational cost, in particular for large-scale datasets. Experiments using the open HEp-2 cell dataset used in the ICIP2013 contest validate that the proposed strategy can achieve a much better performance than the widely used local binary pattern (LBP) histogram and its extensions, rotation invariant co-occurrence LBP, and pairwise rotation invariant co-occurrence LBP, and that the achieved recognition error rate is even very significantly below the observed intralaboratory variability.","Feature extraction,
Adaptation models,
Image representation,
Vectors,
Histograms,
Pattern recognition,
Image analysis"
Pairwise Costs in Semisupervised Discriminant Analysis for Face Recognition,"In recent years, face recognition is being recognized as a cost-sensitive learning problem. Many cost-sensitive classifiers have been proposed. However, no sufficient attention is paid to the research on cost-sensitive dimensionality reduction, especially on the cost-sensitive semisupervised dimensionality reduction. To the best of our knowledge, cost sensitive semisupervised discriminant analysis (CS3DA) may be the first work. CS3DA first uses the sparse representation to infer a soft label for unlabeled sample and then learns the projection direction by incorporating misclassification costs into both labeled and unlabeled data. Although CS3DA reduces the loss of misclassification, it has two major drawbacks: 1) the sparsity is not a feature of face recognition, and therefore sparse approximations may not deliver the robustness or performance desired and 2) CS3DA is not proven to satisfy the minimal misclassification loss criterion. In this paper, we embed pairwise costs in semisupervised discriminant analysis (PCSDA) for face recognition. PCSDA first uses a simple l2 approach to predict the label of unlabeled data, and then learns the projection direction by embedding pairwise costs in both labeled and unlabeled data. Compared with CS3DA, PCSDA has three major advantages: 1) l2 approach is more accurate and robust than sparse representation for face recognition; 2) we prove that CS3DA approximates the pairwise Bayesian risk only when the classes are balanced and without outliers in face data sets; and 3) PCSDA approximates the pairwise Bayesian risk considering the class imbalance problem and outliers in face recognition. Hence, the projection direction obtained by using PCSDA can be more discriminative, immunes to outliers and class imbalance problem. The experimental results on AR, PIE, ORL, and extended Yale B data sets demonstrate the effectiveness of PCSDA.",
Real-time life logging via a depth silhouette-based human activity recognition system for smart home services,"A real-time life logging system that provide monitoring, recording and recognition of daily human activities using video cameras offers life-care or health-care services at smart homes. Such a vision-based life logging system can provide continuous monitoring and recording of a resident's daily activities from which one can obtain behavior patterns of daily life events and improve the quality of life especially for the elderly. This paper presents a real-time life logging system via depth imaging-based human activity recognition. A depth imaging device is utilized to obtain depth silhouettes of human activities. Then from the silhouettes, human body points information gets extracted and used in activity recognition, producing life logs. The system is composed of two key processes; one is training of the life logging system, and the other is running the trained life-logging system to record life logs. In the training process, the system includes the data collection from a depth camera, extraction of body points features from each depth silhouette and finally training of the activity recognizer (i.e., Hidden Markov Models). Then, after training, one can run the trained system which recognizes learned activities and store life logs in real-time. The proposed approach is evaluated against the life logging system that uses the conventional principal components (PC) and Radon transform features of depth silhouettes and achieves superior recognition rate. Real-time experimental results show the feasibility and functionality of the implemented system which could be used to generate life logs of human activities at smart homes.",
Visual Methods for Analyzing Probabilistic Classification Data,"Multi-class classifiers often compute scores for the classification samples describing probabilities to belong to different classes. In order to improve the performance of such classifiers, machine learning experts need to analyze classification results for a large number of labeled samples to find possible reasons for incorrect classification. Confusion matrices are widely used for this purpose. However, they provide no information about classification scores and features computed for the samples. We propose a set of integrated visual methods for analyzing the performance of probabilistic classifiers. Our methods provide insight into different aspects of the classification results for a large number of samples. One visualization emphasizes at which probabilities these samples were classified and how these probabilities correlate with classification error in terms of false positives and false negatives. Another view emphasizes the features of these samples and ranks them by their separation power between selected true and false classifications. We demonstrate the insight gained using our technique in a benchmarking classification dataset, and show how it enables improving classification performance by interactively defining and evaluating post-classification rules.","Histograms,
Probability,
Probabilistic logic,
Data visualization,
Image color analysis,
Electric breakdown"
Optimization Algorithms for Kinematically Optimal Design of Parallel Manipulators,"Optimal design is an inevitable step for parallel manipulators. The formulated optimal design problems are generally constrained, nonlinear, multimodal, and even without closed-form analytical expressions. Numerical optimization algorithms are thus applied to solve the problems. However, the optimization algorithms are usually chosen ad arbitrium. This paper aims to provide a guideline to choose algorithms for optimal design problems. Typical algorithms, the sequential quadratic programming (SQP) with multiple initial points, the controlled random search (CRS), the genetic algorithm (GA), the differential evolution (DE), and the particle swarm optimization (PSO), are investigated in detail for their convergence performances by using two canonical design examples, the Delta robot and the Gough-Stewart platform. It is shown that SQP with multiple initial points can be efficient for simple design problems, while DE and PSO perform effectively and steadily for all design problems. CRS can be used to generate good initial points since it exhibits excellent convergence evolution in the starting period.",
Determining Process Model Precision and Generalization with Weighted Artificial Negative Events,"Process mining encompasses the research area which is concerned with knowledge discovery from event logs. One common process mining task focuses on conformance checking, comparing discovered or designed process models with actual real-life behavior as captured in event logs in order to assess the “goodness” of the process model. This paper introduces a novel conformance checking method to measure how well a process model performs in terms of precision and generalization with respect to the actual executions of a process as recorded in an event log. Our approach differs from related work in the sense that we apply the concept of so-called weighted artificial negative events toward conformance checking, leading to more robust results, especially when dealing with less complete event logs that only contain a subset of all possible process execution behavior. In addition, our technique offers a novel way to estimate a process model's ability to generalize. Existing literature has focused mainly on the fitness (recall) and precision (appropriateness) of process models, whereas generalization has been much more difficult to estimate. The described algorithms are implemented in a number of ProM plugins, and a Petri net conformance checking tool was developed to inspect process model conformance in a visual manner.","Data mining,
Complexity theory,
Robustness,
Measurement,
Context modeling,
Petri nets,
Educational institutions"
Efficient compressive spectrum sensing algorithm for M2M devices,"Spectrum used for Machine-to-Machine (M2M) communications should be as cheap as possible or even free in order to connect billions of devices. Recently, both UK and US regulators have conducted trails and pilots to release the UHF TV spectrum for secondary licence-exempt applications. However, it is a very challenging task to implement wideband spectrum sensing in compact and low power M2M devices as high sampling rates are very expensive and difficult to achieve. In recent years, compressive sensing (CS) technique makes fast wideband spectrum sensing possible by taking samples at sub-Nyquist sampling rates. In this paper, we propose a two-step CS based spectrum sensing algorithm. In the first step, the CS is implemented in an SU and only part of the spectrum of interest is supposed to be sensed by an SU in each sensing period to reduce the complexity in the signal recovery process. In the second step, a denoising algorithm is proposed to improve the detection performance of spectrum sensing. The proposed two-step CS based spectrum sensing is compared with the traditional scheme and the theoretical curves.","Sensors,
Signal processing algorithms,
Noise reduction,
Wideband,
Signal to noise ratio,
Cognitive radio,
Matching pursuit algorithms"
The impact of bandwidth constraints on the energy consumption of Wireless Sensor Networks,"Optimization of flows to maximize Wireless Sensor Network (WSN) lifetime is a problem already investigated in various aspects. However, most studies ignored the effects of finite bandwidth. As source data rate of sensor nodes increases, flow patterns that balance energy dissipation optimally might need more bandwidth than available. As a result, ignoring bandwidth limitations may lead to infeasible solutions. In this study, we make a comprehensive evaluation of the impacts of finite bandwidth by building a linear programming framework. The objective is the minimization of the energy expenditure in the maximum energy-dissipating node to achieve the maximum lifetime under bandwidth constraints. Our analysis reveals that energy consumption values may stay constant until a threshold data rate is reached. But, after the threshold the energy values increase because suboptimal paths are used due to bandwidth constraints. The bandwidth for optimal energy dissipation is limited approximately by twice the minimum bandwidth requirement.","Bandwidth,
Energy consumption,
Wireless sensor networks,
Energy dissipation,
Interference,
Mathematical model,
Equations"
Simultaneous Segmentation and Multiresolution Nonrigid Atlas Registration,"In this paper, a novel Markov random field (MRF)-based approach is presented for segmenting medical images while simultaneously registering an atlas nonrigidly. In the literature, both segmentation and registration have been studied extensively. For applications that involve both, such as segmentation via atlas-based registration, earlier studies proposed addressing these problems iteratively by feeding the output of each to initialize the other. This scheme, however, cannot guarantee an optimal solution for the combined task at hand, since these two individual problems are then treated separately. In this paper, we formulate simultaneous registration and segmentation (SRS) as a maximum a-posteriori (MAP) problem. We decompose the resulting probabilities such that the MAP inference can be done using MRFs. An efficient hierarchical implementation is employed, allowing coarse-to-fine registration while estimating segmentation at pixel level. The method is evaluated on two clinical data sets: 1) mandibular bone segmentation in 3D CT and 2) corpus callosum segmentation in 2D midsaggital slices of brain MRI. A video tracking example is also given. Our implementation allows us to directly compare the proposed method with the individual segmentation/registration and the iterative approach using the exact same potential functions. In a leave-one-out evaluation, SRS demonstrated more accurate results in terms of dice overlap and surface distance metrics for both data sets. We also show quantitatively that the SRS method is less sensitive to the errors in the registration as opposed to the iterative approach.","Image segmentation,
Coherence,
Markov processes,
Biomedical imaging,
Optimization,
Computational modeling,
Bayes methods"
Integration and Virtualization of Relational SQL and NoSQL Systems Including MySQL and MongoDB,"NoSQL databases are growing in popularity for Big Data applications in web analytics and supporting large web sites due to their high availability and scalability. Since each NoSQL system has its own API and does not typically support standards such as SQL and JDBC, integrating these systems with other enterprise and reporting software requires extra effort. In this work, we present a generic standards-based architecture that allows NoSQL systems, with specific focus on MongoDB, to be queried using SQL and seamlessly interact with any software supporting JDBC. A virtualization system is built on top of the NoSQL sources that translates SQL queries into the source-specific APIs. The virtualization architecture allows users to query and join data from both NoSQL and relational SQL systems in a single SQL query. Experimental results demonstrate that the virtualization layer adds minimal overhead in translating SQL to NoSQL APIs, and the virtualization system can efficiently perform joins across sources.",
Multi-GPU Implementation of the Minimum Volume Simplex Analysis Algorithm for Hyperspectral Unmixing,"Spectral unmixing is an important task in remotely sensed hyperspectral data exploitation. The linear mixture model has been widely used to unmix hyperspectral images by identifying a set of pure spectral signatures, called endmembers, and estimating their respective abundances in each pixel of the scene. Several algorithms have been proposed in the recent literature to automatically identify endmembers, even if the original hyperspectral scene does not contain any pure signatures. A popular strategy for endmember identification in highly mixed hyperspectral scenes has been the minimum volume simplex analysis (MVSA), known to be a computationally very expensive algorithm. This algorithm calculates the minimum volume enclosing simplex, as opposed to other algorithms that perform maximum simplex volume analysis (MSVA). The high computational complexity of MVSA, together with its very high memory requirements, has limited its adoption in the hyperspectral imaging community. In this paper, we develop several optimizations to the MVSA algorithm. The main computational task of MVSA is the solution of a quadratic optimization problem with equality and inequality constraints, with the inequality constraints being in the order of the number of pixels multiplied by the number of endmembers. As a result, storing and computing the inequality constraint matrix is highly inefficient. The first optimization presented in this paper uses algebra operations in order to reduce the memory requirements of the algorithm. In the second optimization, we use graphics processing units (GPUs) to effectively solve (in parallel) the quadratic optimization problem involved in the computation of MVSA. In the third optimization, we extend the single GPU implementation to a multi-GPU one, developing a hybrid strategy that distributes the computation while taking advantage of GPU accelerators at each node. The presented optimizations are tested in different analysis scenarios (using both synthetic and real hyperspectral data) and shown to provide state-of-the-art results from the viewpoint of unmixing accuracy and computational performance. The speedup achieved using the full GPU cluster compared to the CPU implementation in tenfold in a real hyperspectral image.",
A geometry-based channel model for shallow underwater acoustic channels under rough surface and bottom scattering conditions,"This paper develops a stochastic geometry-based channel model for wideband single-input single-output (SISO) shallow underwater acoustic (UWA) channels under the assumption that the ocean surface and bottom are rough. Starting from a geometrical model, we derive a reference model assuming that the scatterers are randomly distributed on the surface and the bottom of the water. The probability density functions (PDFs) of the angle-of-departure (AOD) and the angle-of-arrival (AOA) of the reference model are analyzed. Furthermore, the two-dimensional (2D) time-frequency correlation function (T-FCF) of the reference model is studied. From the reference model, we then derive the corresponding simulation model by applying the generalized concept of deterministic channel modelling. For the parametrization of the UWA channel simulator, we propose a new method which is further on called the method of equally spaced scatterers (MESS). The performance of the MESS is compared with that of the Lp-norm method (LPNM). It is shown that our design concept results in an excellent match between the T-FCF of the reference model and that of the simulation model. It is also shown that both the MESS and the LPNM have a similar performance, whereby the MESS provides a closed-form solution, while the LPNM does not.",
Prostate Cancer Grading: Use of Graph Cut and Spatial Arrangement of Nuclei,"Tissue image grading is one of the most important steps in prostate cancer diagnosis, where the pathologist relies on the gland structure to assign a Gleason grade to the tissue image. In this grading scheme, the discrimination between grade 3 and grade 4 is the most difficult, and receives the most attention from researchers. In this study, we propose a novel method (called nuclei-based method) that 1) utilizes graph theory techniques to segment glands and 2) computes a gland-score (based on the spatial arrangement of nuclei) to estimate how similar a segmented region is to a gland. Next, we create a fusion method by combining this nuclei-based method with the lumen-based method presented in our previous work to improve the performance of grade 3 versus grade 4 classification problem (the accuracy is now improved to 87.3% compared to 81.1% of the lumen-based method alone). To segment glands, we build a graph of nuclei and lumina in the image, and use the normalized cut method to partition the graph into different components, each corresponding to a gland. Unlike most state-of-the-art lumen-based gland segmentation method, the nuclei-based method is able to segment glands without lumen or glands with multiple lumina. Moreover, another important contribution in this research is the development of a set of measures to exploit the difference in nuclei spatial arrangement between grade 3 images (where nuclei form closed chain structure on the gland boundary) and grade 4 image (where nuclei distribute more randomly in the gland). These measures are combined to generate a single gland-score value, which estimates how similar a segmented region (which is a set of nuclei and lumina) is to a gland.","Glands,
Image segmentation,
Feature extraction,
Accuracy,
Cancer,
Databases,
Shape"
Balancing Exploration and Exploitation in Sampling-Based Motion Planning,"We present the exploring/exploiting tree (EET) algorithm for motion planning. The EET planner deliberately trades probabilistic completeness for computational efficiency. This tradeoff enables the EET planner to outperform state-of-the-art sampling-based planners by up to three orders of magnitude. We show that these considerable speedups apply for a variety of challenging real-world motion planning problems. The performance improvements are achieved by leveraging work space information to continuously adjust the sampling behavior of the planner. When the available information captures the planning problem's inherent structure, the planner's sampler becomes increasingly exploitative. When the available information is less accurate, the planner automatically compensates by increasing local configuration space exploration. We show that active balancing of exploration and exploitation based on workspace information can be a key ingredient to enabling highly efficient motion planning in practical scenarios.",
Kernel sparse subspace clustering,"Subspace clustering refers to the problem of grouping data points that lie in a union of low-dimensional subspaces. One successful approach for solving this problem is sparse subspace clustering, which is based on a sparse representation of the data. In this paper, we extend SSC to non-linear manifolds by using the kernel trick. We show that the alternating direction method of multipliers can be used to efficiently find kernel sparse representations. Various experiments on synthetic as well real datasets show that non-linear mappings lead to sparse representation that give better clustering results than state-of-the-art methods.","Kernel,
Computer vision,
Clustering algorithms,
Conferences,
Manifolds,
Pattern recognition,
Signal processing algorithms"
A Study on the Effectiveness of Different Independent Component Analysis Algorithms for Hyperspectral Image Classification,"This paper presents a thorough study on the performances of different independent component analysis (ICA) algorithms for the extraction of class-discriminant information in remote sensing hyperspectral image classification. The study considers the three implementations of ICA that are most widely used in signal processing, namely Infomax, FastICA, and JADE. The analysis aims to address a number of important issues regarding the use of ICA in the RS domain. Three scenarios are considered and the performances of the ICA algorithms are evaluated and compared against each other, in order to reach the final goal of identifying the most suitable approach to the analysis of hyperspectral images in supervised classification. Different feature extraction and selection techniques are used for dimensionality reduction with ICA and are then compared to the commonly used strategy, which is based on preprocessing data with principal components analysis (PCA) prior to classification. Experimental results obtained on three real hyperspectral data sets from each of the considered algorithms are presented and analyzed in terms of both classification accuracies and computational time.","Feature extraction,
Algorithm design and analysis,
Principal component analysis,
Signal processing algorithms,
Hyperspectral imaging,
Vectors"
Multi-machine power system control based on dual heuristic dynamic programming,"In this paper, we integrate a goal network into the existing dual heuristic dynamic programming (DHP) architecture, and study its damping performance on the multi-machine power system. There are four types of neural network in our proposed design: a goal network, a critic network, an action network and a model network. The motivation of this design is to build a general mapping between the system variables and the partial derivatives of the utility function, so that these required derivatives can be directly obtained and adaptively tuned over time. However, the existing DHP design can only obtain a predefined (fixed) external utility function (or its derivatives). We apply both the proposed approach and the existing DHP approach on the multi-machine power system, and compare the damping performance on a four-machine two-area power system. The simulation results demonstrate the improved control performance with the proposed design.",
Low Profile Vertically Polarized Omnidirectional Wideband Antenna With Capacitively Coupled Parasitic Elements,"This communication presents a low profile and electrically small wideband antenna with omnidirectional radiation pattern and vertical polarization. A novel design approach manipulating the topology of a low profile folded monopole antenna with capacitively coupled parasitic elements in the same plane is presented to achieve omnidirectional radiation pattern. The 10-dB return loss fractional bandwidth of 43% is achieved with the dimension of 0.2λLF ×0.2λLF ×0.06λLF where λLF is the wavelength at the lowest frequency of the operation. Unlike the convention wideband λ/4 monopole antennas utilizing inductively coupled parasitic elements, the λ/2 folded monopole antenna allows for positioning the capacitively coupled parasitic elements in the middle of the antenna where maximum electric stored energy is formed. This, together with reducing the lateral dimension of the folded monopole antenna, enables the cancellation of radiated fields from electric currents in the horizontal plane of the proposed antenna, which is essential to achieve vertically polarized omnidirectional radiation. The compact parasitic elements introduce additional resonances that significantly increase the antenna bandwidth. Effects of design parameters on two resonant frequencies and impedance matching to a 50 Ω feed are investigated using the equivalent circuit model of the parasitic element and full-wave electromagnetic (EM) simulations. Based on this analysis, a design procedure to optimize the antenna topology is established.",
Difficulties in specifying reference points to calculate the inverted generational distance for many-objective optimization problems,"Recently the inverted generational distance (IGD) measure has been frequently used for performance evaluation of evolutionary multi-objective optimization (EMO) algorithms on many-objective problems. When the IGD measure is used to evaluate an obtained solution set of a many-objective problem, we have to specify a set of reference points as an approximation of the Pareto front. The IGD measure is calculated as the average distance from each reference point to the nearest solution in the solution set, which can be viewed as an approximate distance from the Pareto front to the solution set in the objective space. Thus the IGD-based performance evaluation totally depends on the specification of reference points. In this paper, we illustrate difficulties in specifying reference points. First we discuss the number of reference points required to approximate the entire Pareto front of a many-objective problem. Next we show some simple examples where the uniform sampling of reference points on the known Pareto front leads to counter-intuitive results. Then we discuss how to specify reference points when the Pareto front is unknown. In this case, a set of reference points is usually constructed from obtained solutions by EMO algorithms to be evaluated. We show that the selection of EMO algorithms used to construct reference points has a large effect on the evaluated performance of each algorithm.","Performance evaluation,
Approximation algorithms,
Approximation methods,
Standards,
Optimization,
Vectors,
Visualization"
The Applicability of Spatiotemporal Oriented Energy Features to Region Tracking,"This paper proposes the novel application of an uncommonly rich feature representation to the domain of visual tracking. The proposed representation for tracking models both the spatial structure and dynamics of a target in a unified fashion, while simultaneously offering robustness to illumination variations. Specifically, the proposed feature is derived from spatiotemporal energy measurements that are computed by filtering in 3D, (x, y, t), image spacetime. These spatiotemporal energy measurements capture the underlying local spacetime orientation structure of the target across multiple scales. The breadth of applicability of these features within the field of visual tracking is demonstrated by their instantiation within three disparate tracking paradigms that are representative of the various basic types of region trackers in the field. Instantiation within these three tracking paradigms requires that the raw oriented energy measurements be post-processed using different methodologies that range from histogram accumulation to the identity transform. Qualitative and quantitative empirical evaluation on a challenging suite of videos demonstrates the strength and applicability of the proposed representation to tracking, as it outperforms other commonly-used features across all tracking paradigms. Moreover, it is shown that overall high tracking accuracy can be obtained with this proposed representation, as spatiotemporal oriented energy instantiations are shown to outperform several recent, state-of-the-art trackers.",
DDDAS-Based Parallel Simulation of Threat Management for Urban Water Distribution Systems,"Contaminant source characterization (CSC) in a water distribution system (WDS) exhibits a computationally intensive problem. Traditional solutions to the CSC problem can't fulfill the CSC's quality-of-service (QoS) requirements. We present a parallel solution using the MapReduce paradigm in the cloud that can deliver a high-performance, fault-tolerant, and flexible solution.",
DoA estimation and achievable rate analysis for 3D millimeter wave massive MIMO systems,"Mobile data traffic is predicted to grow exponentially in the future. To address the challenge and consider the form factor limitation at the base station, 3D millimeter wave massive MIMO has been introduced as an enabling technology for 5G systems. In 3D millimeter wave massive MIMO systems, due to the large number of antennas and limited number of clusters, a base station will mainly rely on the uplink sounding signals instead of the feedback to figure out the channel knowledge to perform 3D MIMO operation. Accordingly, multi-dimensional channel estimation becomes critical for such systems to realize the predicted rate gains. In this paper, the performance of direction of arrival (DoA) estimation at the base station using ESPRIT method is characterized. The DoA estimation is further related to the underlying 3D MIMO achievable rate and the optimal transmission strategy is characterized. Finally, the impact of channel estimation error on the underlying achievable rate is analyzed. Our results suggest that DoA estimation is crucial for the transmit beam-forming of 3D millimeter wave massive MIMO systems. Furthermore, the optimal transmission strategy depends heavily on the performance of the underlying DoA estimation.","Direction-of-arrival estimation,
MIMO,
Estimation,
Base stations,
Three-dimensional displays,
Millimeter wave technology,
Wireless communication"
Social Network Services for Rail Traffic Applications,"With the rapid development of high-speed railway, subway, city railway, and intercity rail, how to ensure the reliability, safety, and comfort of such rail traffic transportation systems becomes the focus. Meanwhile, the social network service (SNS) is advancing so fast all over the world. How to combine the characteristics of rail traffic transportation systems with that of the social networks, which enable them to play an important role in the rail traffic operations, will become one of the core problems in the future development of intelligent rail traffic transportation systems. Based on the business requirements, the reliable transmission of information, and the characteristics of the rail traffic transportation systems, this article proposes a new concept of ""dedicated social network"" whose information are exchanged within the internal intranet. A novel social network architecture for rail traffic transportation system is proposed, including the SNS Management Center, a dedicated social network for internal information exchanges among the drivers, the dispatchers, and the train control center, the SNS for the information exchanges among the train marshals, crews, and passengers. The proposed framework attempts to exploit social networks in an active manner in the field of rail traffic transportation systems to make the system safer, more secure, reliable, comfortable, and humane.","Social network services,
Safety,
Rail transportation,
Intelligent vehicles,
Internet,
Monitoring"
A Fuzzy-Rule-Based Approach for Single Frame Super Resolution,"In this paper, a novel fuzzy rule-based prediction framework is developed for high-quality image zooming. In classical interpolation-based image zooming, resolution is increased by inserting pixels using certain interpolation techniques. Here, we propose a patch-based image zooming technique, where each low-resolution (LR) image patch is replaced by an estimated high-resolution (HR) patch. Since an LR patch can be generated from any of the many possible HR patches, it would be natural to develop rules to find different possible HR patches and then to combine them according to rule strength to get the estimated HR patch. Here, we generate a large number of LR-HR patch pairs from a collection of natural images, group them into different clusters, and then generate a fuzzy rule for each of these clusters. The rule parameters are also learned from these LR-HR patch pairs. As a result, an efficient mapping from LR patch space to HR patch space can be formulated. The performance of the proposed method is tested on different images, and is also compared with other representative as well as state-of-the-art image zooming techniques. Experimental results show that the proposed method is better than the competing methods and is capable of reconstructing thin lines, edges, fine details, and textures in the image efficiently.","Vectors,
Interpolation,
Image edge detection,
Dictionaries,
Image resolution,
Image reconstruction,
Training"
Learning accurate kinematic control of cable-driven surgical robots using data cleaning and Gaussian Process Regression,"Precise control of industrial automation systems with non-linear kinematics due to joint elasticity, variation in cable tensioning, or backlash is challenging; especially in systems that can only be controlled through an interface with an imprecise internal kinematic model. Cable-driven Robotic Surgical Assistants (RSAs) are one example of such an automation system, as they are designed for master-slave teleoperation. We consider the problem of learning a function to modify commands to the inaccurate control interface such that executing the modified command on the system results in a desired state. To achieve this, we must learn a mapping that accounts for the non-linearities in the kinematic chain that are not accounted for by the system's internal model. Gaussian Process Regression (GPR) is a data-driven technique that can estimate this non-linear correction in a task-specific region of state space, but it is sensitive to corruption of training examples due to partial occlusion or lighting changes. In this paper, we extend the use of GPR to learn a non-linear correction for cable-driven surgical robots by using (i) velocity as a feature in the regression and (ii) removing corrupted training observations based on rotation limits and the magnitude of velocity. We evaluate this approach on the Raven II Surgical Robot on the task of grasping foam “damaged tissue” fragments, using the PhaseSpace LED-based motion capture system to track the Raven end-effector. Our main result is a reduction in the norm of the mean position error from 2.6 cm to 0.2 cm and the norm of the mean angular error from 20.6 degrees to 2.8 degrees when correcting commands for a set of held-out trajectories. We also use the learned mapping to achieve a 3.8× speedup over past results on the task of autonomous surgical debridement.","Training,
Robots,
Cleaning,
Ground penetrating radar,
Kinematics,
Gaussian processes,
Testing"
Pseudo-Marginal Bayesian Inference for Gaussian Processes,"The main challenges that arise when adopting Gaussian process priors in probabilistic modeling are how to carry out exact Bayesian inference and how to account for uncertainty on model parameters when making model-based predictions on out-of-sample data. Using probit regression as an illustrative working example, this paper presents a general and effective methodology based on the pseudo-marginal approach to Markov chain Monte Carlo that efficiently addresses both of these issues. The results presented in this paper show improvements over existing sampling methods to simulate from the posterior distribution over the parameters defining the covariance function of the Gaussian Process prior. This is particularly important as it offers a powerful tool to carry out full Bayesian inference of Gaussian Process based hierarchic statistical models in general. The results also demonstrate that Monte Carlo based integration of all model parameters is actually feasible in this class of models providing a superior quantification of uncertainty in predictions. Extensive comparisons with respect to state-of-the-art probabilistic classifiers confirm this assertion.",
On Bilateral Teleoperation of Aerial Robots,"This paper presents a generic hierarchical passive teleoperation control architecture that effectively addresses the issues of workspace incompatibility and precision, as well as other classical and peculiar challenges. More specifically, the control scheme consists of a user-defined variable scale mapping, a variable impedance master controller, and a virtual slave system. The port-based modeling framework has been extensively used in our formulation, providing more insight about energetic flows in the system that are particularly useful for the design of a passive controlled system. Moreover, various practical considerations that are required for the effective usage of the control architecture are discussed. The achieved better precision and overall task performance have been validated and verified by elaborate simulations and experiments.","Vehicles,
Haptic interfaces,
Couplings,
Robots,
Ports (Computers),
Vehicle dynamics,
Impedance"
Analytical QoE Models for Bit-Rate Switching in Dynamic Adaptive Streaming Systems,"Video streaming service in wireless networks is increasingly using dynamic selection of video bit-rates to provide a high quality of user experience (QoE). The bit-rate switching mechanism, performed at client side, plays a key role in determining QoE metrics. In this paper, we present the first analytical framework to compute starvation probability of playout buffer, continuous playback time and mean video quality, given the bit-rate switching logics. Wireless channel is modeled as a continuous time Markov process, and playout buffer is modeled as a fluid queue with Markov modulated fluid arrival. We construct a set of ordinary differential equations (ODEs) to characterize the dynamics of starvation probability and expected continuous playback time with regard to buffer length, and simple models to analyze mean bit-rate for different bit-rate switching algorithms. Our framework is very general in that by adding appropriate parameters, it can be utilized to predict the QoE metrics of dynamic adaptive streaming with a variety of features: i) buffer-aware bit-rate switching ii) (im)patience of the user, and iii) receiver-side flow control.",
Speaker adaptation of hybrid NN/HMM model for speech recognition based on singular value decomposition,"Recently several speaker adaptation methods have been proposed for deep neural network (DNN) in many large vocabulary continuous speech recognition (LVCSR) tasks. However, only a few methods rely on tuning the weight matrices in trained DNNs to optimize system performance since it is very prone to over-fitting especially when some class labels are missing in the adaptation data. In this paper, we propose a new speaker adaptation method for the hybrid NN/HMM speech recognition model based on singular value decomposition (SVD). We apply SVD on the weight matrices in trained DNNs, and then tune diagonal matrices with the adaptation data. This solves the over-fitting problem since we can change the weight matrices slightly by only modifying the singular values. We evaluate the proposed adaptation method in two standard speech recognition tasks, namely TIMIT phone recognition and large vocabulary speech recognition in the Switchboard task. Experimental results have shown that it is effective to adapt large DNN models using only a small amount of adaptation data. For example, the Switchboard results have shown that the proposed SVD-based adaptation method may achieve up to 3-6% relative error reduction using only a few dozens of adaptation utterances per speaker.",
Fuzzy Preference Based Feature Selection and Semisupervised SVM for Cancer Classification,"DNA microarray data now permit scientists to screen thousand of genes simultaneously and determine whether those genes are active or silent in normal and cancerous tissues. With the advancement of microarray technology, new analytical methods must be developed to find out whether microarray data have discriminative signatures of gene expression over normal or cancerous tissues. In this paper, we attempt a prediction scheme that combines fuzzy preference based rough set (FPRS) method for feature (gene) selection with semisupervised SVMs. To show the effectiveness of the proposed approach, we compare the performance of this technique with the signal-to-noise ratio (SNR) and consistency based feature selection (CBFS) methods. Using six benchmark gene microarray datasets (including both binary and multi-class classification problems), we demonstrate experimentally that our proposed scheme can achieve significant empirical success and is biologically relevant for cancer diagnosis and drug discovery.",
The Capacity Region of Two-Receiver Multiple-Input Broadcast Packet Erasure Channels With Channel Output Feedback,"This paper studies the capacity of the two-receiver multiple-input broadcast packet erasure channels (PECs) with channel output feedback, which is in contrast with the single-input setting of the existing works. Motivated by the immense success of linear network coding (LNC) in theory and in practice, this paper first focuses on LNC schemes and characterizes the LNC feedback capacity region of two-receiver multiple-input broadcast PECs. A new linear-space-based approach is proposed, which unifies the problems of finding a capacity outer bound and devising the achievability scheme into a single linear programming problem. In particular, an LP solver is used to exhaustively search for the LNC scheme(s) with the best possible throughput, the result of which is thus guaranteed to attain the LNC feedback capacity. It is then proven by pure algebraic arguments that the LNC capacity region matches a simple capacity region outer bound, which proves that the derived LNC capacity region is indeed the true capacity. A byproduct of the above results is a complete LNC capacity region characterization for two-receiver partially Markovian and partially controllable broadcast PECs.",
Minimal Volume Simplex (MVS) approach for convex hull generation in TP Model Transformation,"To a large degree, systems and control applications of TP Model Transformation rely on convex hull manipulation of polytopic LPV/qLPV system models. In this respect, the creation of tight convex hulls is an especially challenging problem, as it requires complex nonlinear optimisation. By defining the Minimal Volume Simplex (MVS) type hull, the paper presents a novel approach for tight convex hull generation. The approach, which involves the so-called MVSA algorithm, leads to a radical reduction in computational time while showing improved numerical properties in terms of repeatability and reliability as compared to other hull generation methods. Furthermore, the proposed method allows for the taking into account of special design considerations regarding the alignment of the convex hull.","Numerical models,
Vectors,
Computational modeling,
Solid modeling,
Tin,
Cost function"
Group-Invariant Colour Morphology Based on Frames,"Mathematical morphology is a very popular framework for processing binary or grayscale images. One of the key problems in applying this framework to color images is the notorious false color problem. We discuss the nature of this problem and its origins. In doing so, it becomes apparent that the lack of invariance of operators to certain transformations (forming a group) plays an important role. The main culprits are the basic join and meet operations, and the associated lattice structure that forms the theoretical basis for mathematical morphology. We show how a lattice that is not group invariant can be related to another lattice that is. When all transformations in a group are linear, these lattices can be related to one another via the theory of frames. This provides all the machinery to let us transform any (grayscale or color) morphological filter into a group-invariant filter on grayscale or color images. We then demonstrate the potential for both subjective and objective improvement in selected tasks.","Lattices,
Image color analysis,
Morphology,
Vectors,
Green products,
Transforms,
Noise reduction"
Distributed Control and Generation Estimation Method for Integrating High-Density Photovoltaic Systems,"The presence of distributed generators (DGs) such as photovoltaic systems (PVs) is increasing significantly in distribution networks, and in order to accommodate a higher penetration of DGs, technical issues arising from fluctuation and unpredictability of their power output must be addressed. It is beneficial if DGs of high penetration can be dispatched when necessary. To this end, a distributed control and generation estimation approach is developed to dispatch multiple DGs, each of which consists of a PV and a controllable load. A strongly connected digraph with a row stochastic adjacency matrix is a sufficient requirement for the communication topology. A distributed weights adjustment algorithm adaptively makes the adjacency matrix doubly stochastic so that the aggregated power generation capacity can be estimated. Then, the expected consensus operational point of the DGs is calculated by those DGs that can obtain power dispatch command from the supervisory control and data acquisition system and is propagated to the rest of the DGs with a consensus algorithm. With this method, all the DGs operate at the same ratio of available power, while their aggregated power meets the power dispatch command. Simulations in the IEEE standard 34-bus distribution network verify the effectiveness of the proposed approach.","Decentralized control,
Estimation,
Communication networks,
Photovoltaic systems,
Electrical engineering,
Educational institutions"
From Ego to Nos-Vision: Detecting Social Relationships in First-Person Views,"In this paper we present a novel approach to detect groups in ego-vision scenarios. People in the scene are tracked through the video sequence and their head pose and 3D location are estimated. Based on the concept of f-formation, we define with the orientation and distance an inherently social pairwise feature that describes the affinity of a pair of people in the scene. We apply a correlation clustering algorithm that merges pairs of people into socially related groups. Due to the very shifting nature of social interactions and the different meanings that orientations and distances can assume in different contexts, we learn the weight vector of the correlation clustering using Structural SVMs. We extensively test our approach on two publicly available datasets showing encouraging results when detecting groups from first-person camera views.","Head,
Estimation,
Training,
Three-dimensional displays,
Cameras,
Correlation,
Vectors"
"Super Hydrophobic Parylene-C Produced by Consecutive
O
2
and
SF
6
Plasma Treatment","The wetting behavior of polymeric biomaterials is of great importance for biomedical research and pharmaceutical applications. Tailoring of polymer surface wettability is particularly effective to address biomedical issues such as biofouling control and biocompatibility improvement. In this paper, we conducted comprehensive experiments and analytical modeling to understand the effects of a consecutive-O2-SF6 plasma treatment on the super hydrophobicity of parylene-C. Experimentally, super hydrophobic parylene-C surfaces with a maximum water contact angle of ~169° have been successfully achieved. Atomic force microscopy and X-ray photoelectron spectroscopy results strongly suggest that the modification of surface wettability can be attributed to the variation in surface roughness and the plasma-induced surface chemistry. Analytically, a transition of droplet status from the Wenzel state to the Cassie state on hydrophobic parylene-C surfaces has been demonstrated after sufficient roughening by O2 plasma pre-treatment. The surface morphology of plasma-treated parylene-C films has also been analyzed and the hexagonal-close-packed model of downward crowns shows the best agreement with experimental results. Our simple and time-efficient treatment eliminates the need for creating well-defined patterns, is completely compatible with conventional microfabrication techniques, and can also be applied to curved parylene surfaces.","Surface treatment,
Surface morphology,
Rough surfaces,
Surface roughness,
Plasmas,
Sulfur hexafluoride,
Surface topography"
Workload-Aware Credit Scheduler for Improving Network I/O Performance in Virtualization Environment,"Single-root I/O virtualization (SR-IOV) has become the de facto standard of network virtualization in cloud infrastructure. Owing to the high interrupt frequency and heavy cost per interrupt in high-speed network virtualization, the performance of network virtualization is closely correlated to the computing resource allocation policy in Virtual Machine Manager (VMM). Therefore, more sophisticated methods are needed to process irregularity and the high frequency of network interrupts in high-speed network virtualization environment. However, the I/O-intensive and CPU-intensive applications in virtual machines are treated in the same manner since application attributes are transparent to the scheduler in hypervisor, and this unawareness of workload makes virtual systems unable to take full advantage of high performance networks. In this paper, we discuss the SR-IOV networking solution and show by experiment that the current credit scheduler in Xen does not utilize high performance networks efficiently. Hence we propose a novel workload-aware scheduling model with two optimizations to eliminate the bottleneck caused by scheduler. In this model, guest domains are divided into I/O-intensive domains and CPU-intensive domains according to their monitored behaviour. I/O-intensive domains can obtain extra credits that CPU-intensive domains are willing to share. In addition, the total number of credits available is adjusted to accelerate the I/O responsiveness. Our experimental evaluations show that the new scheduling models improve bandwidth and reduce response time, by keeping the fairness between I/O-intensive and CPU-intensive domains. This enables virtualization infrastructure to provide cloud computing services more efficiently and predictably.",
Real-time 6-DOF monocular visual SLAM in a large-scale environment,"Real-time approach for monocular visual simultaneous localization and mapping (SLAM) within a large-scale environment is proposed. From a monocular video sequence, the proposed method continuously computes the current 6-DOF camera pose and 3D landmarks position. The proposed method successfully builds consistent maps from challenging outdoor sequences using a monocular camera as the only sensor, while existing approaches have utilized additional structural information such as camera height from the ground. By using a binary descriptor and metric-topological mapping, the system demonstrates real-time performance on a large-scale outdoor environment without utilizing GPUs or reducing input image size. The effectiveness of the proposed method is demonstrated on various challenging video sequences including the KITTI dataset and indoor video captured on a micro aerial vehicle.","Visualization,
Simultaneous localization and mapping,
Cameras,
Measurement,
Feature extraction,
Optimization,
Three-dimensional displays"
An Online Sensor Power Schedule for Remote State Estimation With Communication Energy Constraint,"We consider sensor transmission power scheduling for remote state estimation with limited communication energy. A sensor needs to decide when to switch between different transmission energy levels in order to minimize the average expected estimation error covariance subject to the available energy budget. In the existing work the sensor only exploits the prior knowledge of the system parameters, the noise covariance and the channel characteristics but neglects the realtime information the estimator can provide. Thanks to the power asymmetry between the sensor and the estimator, we propose an online scheduling scheme which makes a choice based on the acknowledgement sequence at the remote estimator side and show that the scheme outperforms the optimal offline schedule under the same energy constraint.",
Full Security of Quantum Key Distribution From No-Signaling Constraints,"We analyze a cryptographic protocol for generating a distributed secret key from correlations that violate a Bell inequality by a sufficient amount, and prove its security against eavesdroppers, constrained only by the assumption that any information accessible to them must be compatible with the non-signaling principle. The claim holds with respect to the state-of-the-art security definition used in cryptography, known as universally-composable security. The non-signaling assumption only refers to the statistics of measurement outcomes depending on the choices of measurements; hence security is independent of the internal workings of the devices - they do not even need to follow the laws of quantum theory. This is relevant for practice as a correct and complete modeling of realistic devices is generally impossible. The techniques developed are general and can be applied to other Bell inequality-based protocols. In particular, we provide a scheme for estimating Bell-inequality violations when the samples are not independent and identically distributed.",
Preliminary results on correct-by-construction control software synthesis for adaptive cruise control,"A plethora of driver convenience and safety automation systems are being introduced into production vehicles, such as electronic stability control, adaptive cruise control, lane keeping, and obstacle avoidance. Assuring the seamless and safe integration of each new automation function with existing control functions is a major challenge for vehicle manufacturers. This challenge is compounded by having different suppliers providing software modules for different control functionalities. In this paper, we report on our preliminary steps to address this problem through a fresh perspective combining formal methods, control theory, and correct-by-construction software synthesis. In particular, we begin the process of synthesizing the control software module for adaptive cruise control from formal specifications given in Linear Temporal Logic. In the longer run, we will endow each interacting software module with an assume-guarantee specification stating under which environment assumptions the module is guaranteed to meet its specifications. These assume-guarantee specifications will then be used to formally prove correctness of the cyber-physical system obtained when the integrated modules interact with the physical dynamics.","Vehicles,
Lead,
Software,
Safety,
Automation,
Control systems,
Computational modeling"
The effects of latency on player performance in cloud-based games,"Cloud-based games are an increasingly popular method to distribute and play computer games on the Internet. While there has been some work studying network aspects of cloud-based games and examining the effects of latency on traditional games, there has not been sufficient research on the impact of latency on cloud-based games nor a comparison of the impact of latency on cloud-based games versus traditional games. This paper presents the results of two user studies that measure the objective and subjective effects of latency on cloud-based games, one study using the commercial cloud game system OnLive and the other study using the academic cloud game system GamingAnywhere. Analysis of the results shows both quality of experience and user performance degrade linearly with an increase in latency. More significantly, latency affects cloud-based games in a manner most similar to that of traditional first-person avatar games, the most sensitive class of games, despite the fact that the cloud-based games may have a different user perspective. These results have implications for cloud-based game designers and cloud system developers.",
UREAL: Underwater Reflection-Enabled Acoustic-Based Localization,"The underwater medium is an extreme environment for achieving accurate localization due to its many challenges, some of which includes propagation delay, multipath, rough surfaces, and more. Localization relies on accurate ranging information such as time of arrival, time difference of arrival, and angle of arrival (AOA). In the underwater environment, these ranging measurements will be prone to errors especially when the algorithm relies on the stability of the line-of-sight (LOS) link. This error is mainly attributed to the multipath nature of the underwater medium, most notably in shallow water setups. To circumvent these issues, we propose a novel underwater signal reflection-enabled acoustic-based localization scheme (UREAL) that employs both LOS and surface-reflected nonline-of-sight (NLOS) ranging information to locate a node that has drifted away. We classify both the LOS and surface-reflected NLOS links by leveraging our previous work, which uses homomorphic deconvolution to recover the channel IR containing the link information. Our UREAL scheme uses both azimuthal and elevation AOA measurements to provide the 3-D ranging required for the position estimation process. We then present a closed-form least squares method that is used to locate the lost node with either LOS AOA measurements and/or with surface-reflected AOA ranging information. The approach is validated using a 3-D underwater setup and is shown to outperform competing schemes.","Sensors,
Surface treatment,
Propagation losses,
Distance measurement,
Reflection,
Surface waves,
Acoustics"
7T Transmit/Receive Arrays Using ICE Decoupling for Human Head MR Imaging,"In designing large-sized volume type phased array coils for human head imaging at ultrahigh fields, e.g., 7T, minimizing electromagnetic coupling among array elements is technically challenging. A new decoupling method based on induced current compensation or elimination (ICE) for a microstrip line planar array has recently been proposed. In this study, an eight-channel transmit/receive volume array with ICE-decoupled loop elements was built and investigated to demonstrate its feasibility and robustness for human head imaging at 7T. Isolation between adjacent loop elements was better than - 25 dB with a human head load. The worst-case of the isolation between all of the elements was about - 17.5 dB. All of the MRI experiments were performed on a 7T whole-body human MR scanner. Images of the phantom and human head were acquired and g-factor maps were measured and calculated to evaluate the performance of the coil array. Compared with the conventional capacitively decoupled array, the ICE-decoupled array demonstrated improved parallel imaging ability and had a higher SNR. The experimental results indicate that the transceiver array design with ICE decoupling technique might be a promising solution to designing high performance transmit/receive coil arrays for human head imaging at ultrahigh fields.",
Transforming morning to afternoon using linear regression techniques,"Visual localization in outdoor environments is often hampered by the natural variation in appearance caused by such things as weather phenomena, diurnal fluctuations in lighting, and seasonal changes. Such changes are global across an environment and, in the case of global light changes and seasonal variation, the change in appearance occurs in a regular, cyclic manner. Visual localization could be greatly improved if it were possible to predict the appearance of a particular location at a particular time, based on the appearance of the location in the past and knowledge of the nature of appearance change over time. In this paper, we investigate whether global appearance changes in an environment can be learned sufficiently to improve visual localization performance. We use time of day as a test case, and generate transformations between morning and afternoon using sample images from a training set. We demonstrate the learned transformation can be generalized from training data and show the resulting visual localization on a test set is improved relative to raw image comparison. The improvement in localization remains when the area is revisited several weeks later.","Visualization,
Lighting,
Linear regression,
Training,
Robots,
Training data,
Meteorology"
Bounded Asymmetrical Student's-t Mixture Model,"The finite mixture model based on the Student's-t distribution, which is heavily tailed and more robust than the Gaussian mixture model (GMM), is a flexible and powerful tool to address many computer vision and pattern recognition problems. However, the Student's-t distribution is unbounded and symmetrical around its mean. In many applications, the observed data are digitalized and have bounded support. The distribution of the observed data usually has an asymmetric form. A new finite bounded asymmetrical Student's-t mixture model (BASMM), which includes the GMM and the Student's-t mixture model (SMM) as special cases, is presented in this paper. We propose an extension of the Student's-t distribution in this paper. This new distribution is sufficiently flexible to fit different shapes of observed data, such as non-Gaussian, nonsymmetric, and bounded support data. Another advantage of the proposed model is that each of its components can model the observed data with different bounded support regions. In order to estimate the model parameters, previous models represent the Student's-t distributions as an infinite mixture of scaled Gaussians. We propose an alternate approach in order to minimize the higher bound on the data negative log-likelihood function, and directly deal with the Student's-t distribution. As an application, our method has been applied to image segmentation with promising results.","Gaussian distribution,
Data models,
Computational modeling,
Image segmentation,
Robustness,
Shape,
Bayes methods"
Millimeter-Wave Silicon-on-Glass Integrated Tapered Antenna,"This letter presents a millimeter-wave (mmW) high-efficiency tapered dielectric antenna, which is designed and fabricated on a new integrated technology platform called silicon-on-glass (SOG). The antenna is fabricated using photolithography and dry etching of the Si layer of the SOG wafer. The proposed antenna advantages include high efficiency, low-cost fabrication with high precision, and small size. Experimental results are presented to validate the new design concept, which is optimized for low sidelobe, high gain, and short length.","Antenna measurements,
Silicon,
Dielectrics,
Electromagnetic waveguides,
Antenna radiation patterns,
Loss measurement"
Scalable Implicit Flow Solver for Realistic Wing Simulations with Flow Control,"Massively parallel computation provides an enormous capacity to perform simulations on a timescale that can change the paradigm of how scientists, engineers, and other practitioners use simulations to address discovery and design. This work considers an active flow control application on a realistic and complex wing design that could be leveraged by a scalable, fully implicit, unstructured flow solver and access to high-performance computing resources. The article describes the active flow control application; then summarizes the main features in the implementation of a massively parallel turbulent flow solver, PHASTA; and finally demonstrates the methods strong scalability at extreme scale. Scaling studies performed with unstructured meshes of 11 and 92 billion elements on the Argonne Leadership Computing Facility's Blue Gene/Q Mira machine with up to 786,432 cores and 3,145,728 MPI processes.","Parallel processing,
Simulation,
Finite element analysis,
Scalability,
Mathematical model,
High performance computing,
Computer performance,
Numerical analysis,
Differential equations,
Scientific computing"
Temporal Video Quality Model Accounting for Variable Frame Delay Distortions,"We announce a new video quality model (VQM) that accounts for the perceptual impact of variable frame delays (VFD) in videos with demonstrated top performance on the laboratory for image and video engineering (LIVE) mobile video quality assessment (VQA) database. This model, called VQM_VFD, uses perceptual features extracted from spatialtemporal blocks spanning fixed angular extents and a long edge detection filter. VQM_VFD predicts video quality by measuring multiple frame delays using perception based parameters to track subjective quality over time. In the performance analysis of VQM_VFD, we evaluated its efficacy at predicting human opinions of visual quality. A detailed correlation analysis and statistical hypothesis testing show that VQM_VFD accurately predicts human subjective judgments and substantially outperforms top-performing image quality assessment and VQA models previously tested on the LIVE mobile VQA database. VQM_VFD achieved the best performance on the mobile and tablet studies of the LIVE mobile VQA database for simulated compression, wireless packet-loss, and rate adaptation, but not for temporal dynamics. These results validate the new model and warrant a hard release of the VQM_VFD algorithm.",
Compact Polarization Beam Splitter for Silicon-Based Slot Waveguides Using an Asymmetrical Multimode Waveguide,"A compact polarization beam splitter (PBS) for silicon-based slot waveguides is proposed, where an asymmetrical multimode waveguide (AMW), cut by a right angle at one corner, is employed to efficiently separate the TE and TM modes. With the unique modal properties of the slot waveguides, the input TE mode almost passes through the AMW and enters into the bar port, while the input TM mode forms a mirror image at the cross port due to the self-imaging effect. Tapered waveguide structures and S-bend are incorporated into the PBS for enhancing the performance. Results show that a PBS with an AMW of 2.3 μm in length is achieved, where the extinction ratios are 16.6 and 20.9 dB, respectively, for TE and TM modes, and the insertion losses are 1.37 and 0.81 dB, respectively, at the wavelength of 1.55 μm, and the bandwidths can cover the entire C-band for both polarizations. In addition, fabrication tolerances to the structural parameters are investigated and field evolution along the propagation distance through the designed PBS is also demonstrated.","Optical waveguides,
Ports (Computers),
Erbium,
Silicon,
Fabrication,
Indexes,
Wires"
Impact of Current Flow Shape in Tapered (Versus Rectangular) FinFET on Threshold Voltage Variation Induced by Work-Function Variation,"Depending on the real fin shape in a FinFET (i.e., rectangular versus tapered fin), the impact of the current flow shape in both rectangular and tapered FinFETs on threshold voltage variation induced by work-function variation is investigated by performing extensive 3-D TCAD simulations. It is found that if a FinFET has two independent (versus single and bulky) current flow in the channel, the extended gate area should be (should not be) included in calculating the ratio of average grain size to gate area (RGG) to agree with a previously validated FinFET RGG plot. Depending on the current flow shape in a FinFET, the RGG calculation should be refined.",
A 3-D Miniaturized High Selectivity Bandpass Filter in LTCC Technology,"Transmission zeros are used to improve the roll-off factors of filters but as a consequence, the out-of-band rejection decreases. In this work, an LTCC filter design is presented which employs a series inductor (implemented as a via hole) to improve the out-of-band rejection by introducing a third transmission zero. The filter, designed for GPS band (1.57 GHz), has one of the smallest reported foot prints ( (0.063×0.048×0.005)λg) and demonstrates the highest roll off factor (16.7 dB/100 MHz) for this band. With only four LTCC layers, the design is cost effective and thus highly suitable for miniaturized, ultra-thin system-on-package applications.",
An evasion and counter-evasion study in malicious websites detection,"Malicious websites are a major cyber attack vector, and effective detection of them is an important cyber defense task. The main defense paradigm in this regard is that the defender uses some kind of machine learning algorithms to train a detection model, which is then used to classify websites in question. Unlike other settings, the following issue is inherent to the problem of malicious websites detection: the attacker essentially has access to the same data that the defender uses to train his/her detection models. This `symmetry' can be exploited by the attacker, at least in principle, to evade the defender's detection models. In this paper, we present a framework for characterizing the evasion and counter-evasion interactions between the attacker and the defender, where the attacker attempts to evade the defender's detection models by taking advantage of this symmetry. Within this framework, we show that an adaptive attacker can make malicious websites evade powerful detection models, but proactive training can be an effective counter-evasion defense mechanism. The framework is geared toward the popular detection model of decision tree, but can be adapted to accommodate other classifiers.",
Smart adaptation of beacons transmission rate and power for enhanced vehicular awareness in VANETs,"In this work, we are interested in periodic beacons transmission, the main cause of the Control Channel (CCH) congestion and the major obstacle delaying the progress of safety messages dissemination in VANETs. In order to offload the network, solutions that range from transmit rate to transmit power adaptations including hybrid solutions have been proposed. Although some of these solutions have managed to successfully reduce the load on the wireless channel, none, to the best of our knowledge, have considered the impact of the applied adaptation scheme on the overall level of awareness among vehicles and its quality. ETSI TS released a technical specification stating a limit for the minimum beacons transmit rate in order to maintain a good level of awareness among vehicles and ensure a certain accuracy in VANET applications. In this paper, we propose to jointly adapt both transmit rate and power in a new smart way that guarantees a strict beaconing frequency as well as a good level of awareness in closer ranges, while maintaining a marginal beacons collision rate and a good level of channel utilisation. First, the transmit rate is adapted to meet the channel requirements in terms of collision rate and channel load; then, once the minimum beacon transmit rate, set by ETSI, has been reached, transmit power is adapted in a way that guarantees a good level of awareness for closer neighbours. The simulation results show a significant enhancement in terms of the quality as well as the level of awareness.","Vehicles,
Safety,
Roads,
Educational institutions,
Telecommunication standards,
Vehicular ad hoc networks"
Clock Synchronization in Wireless Sensor Network With Selective Convergence Rate for Event Driven Measurement Applications,"In this paper, a novel wireless sensor network synchronization protocol for event-driven measurement applications is proposed. The objective is twofold: 1) to provide high accuracy in the area where an event is detected and 2) to ensure a long network lifetime. The complexity of the problem arises from the fact that these two properties are usually in conflict. To increase the synchronization accuracy, nodes are required to exchange synchronization packets at higher rate, thus impacting the network lifetime. Vice versa to ensure a long network life time, the number of packets to be exchanged should be minimized thus impacting the synchronization accuracy. A tradeoff can be achieved by observing that the packet rate should be increased only for the portion of the network surrounding the detected events as only these nodes require a higher accuracy to collect data. The proposed algorithm represents a formalization of this idea. Numerical and experimental results are provided to fvalidate the effectiveness of the proposed algorithm.",
An Automatic Framework for Textured 3D Video-Based Facial Expression Recognition,"Most of the existing research on 3D facial expression recognition has been done using static 3D meshes. 3D videos of a face are believed to contain more information in terms of the facial dynamics which are very critical for expression recognition. This paper presents a fully automatic framework which exploits the dynamics of textured 3D videos for recognition of six discrete facial expressions. Local video-patches of variable lengths are extracted from numerous locations of the training videos and represented as points on the Grassmannian manifold. An efficient graph-based spectral clustering algorithm is used to separately cluster these points for every expression class. Using a valid Grassmannian kernel function, the resulting cluster centers are embedded into a Reproducing Kernel Hilbert Space (RKHS) where six binary SVM models are learnt. Given a query video, we extract video-patches from it, represent them as points on the manifold and match these points with the learnt SVM models followed by a voting based strategy to decide about the class of the query video. The proposed framework is also implemented in parallel on 2D videos and a score level fusion of 2D & 3D videos is performed for performance improvement of the system. The experimental results on BU4DFE data set show that the system achieves a very high classification accuracy for facial expression recognition from 3D videos.","Videos,
Three-dimensional displays,
Feature extraction,
Face recognition,
Hidden Markov models,
Face,
Manifolds"
Autonomous quadrotor flight using onboard RGB-D visual odometry,"In this paper we present a navigation system for Micro Aerial Vehicles (MAV) based on information provided by a visual odometry algorithm processing data from an RGB-D camera. The visual odometry algorithm uses an uncertainty analysis of the depth information to align newly observed features against a global sparse model of previously detected 3D features. The visual odometry provides updates at roughly 30 Hz that is fused at 1 KHz with the inertial sensor data through a Kalman Filter. The high-rate pose estimation is used as feedback for the controller, enabling autonomous flight. We developed a 4DOF path planner and implemented a real-time 3D SLAM where all the system runs on-board. The experimental results and live video demonstrates the autonomous flight and 3D SLAM capabilities of the quadrotor with our system.","Visualization,
Cameras,
Three-dimensional displays,
Computers,
Simultaneous localization and mapping,
Feature extraction"
MRI Meets MPI: A Bimodal MPI-MRI Tomograph,"While magnetic particle imaging (MPI) constitutes a novel biomedical imaging technique for tracking superpara magnetic nanoparticles in vivo, unlike magnetic resonance imaging (MRI), it cannot provide anatomical background information. Until now these two modalities have been performed in separate scanners and image co-registration has been hampered by the need to reposition the sample in both systems as similarly as possible. This paper presents a bimodal MPI-MRI-tomograph that combines both modalities in a single system. MPI and MRI images can thus be acquired without moving the sample or replacing any parts in the setup. The images acquired with the presented setup show excellent agreement between the localization of the nano particles in MPI and the MRI background data. A combination of two highly complementary imaging modalities has been achieved.","Coils,
Magnetic resonance imaging,
Magnetic fields,
Harmonic analysis,
Switches,
Educational institutions"
Ecologically valid long-term mood monitoring of individuals with bipolar disorder using speech,"Speech patterns are modulated by the emotional and neurophysiological state of the speaker. There exists a growing body of work that computationally examines this modulation in patients suffering from depression, autism, and post-traumatic stress disorder. However, the majority of the work in this area focuses on the analysis of structured speech collected in controlled environments. Here we expand on the existing literature by examining bipolar disorder (BP). BP is characterized by mood transitions, varying from a healthy euthymic state to states characterized by mania or depression. The speech patterns associated with these mood states provide a unique opportunity to study the modulations characteristic of mood variation. We describe methodology to collect unstructured speech continuously and unobtrusively via the recording of day-to-day cellular phone conversations. Our pilot investigation suggests that manic and depressive mood states can be recognized from this speech data, providing new insight into the feasibility of unobtrusive, unstructured, and continuous speech-based wellness monitoring for individuals with BP.",
Unifying multi-goal path planning for autonomous data collection,"In this paper, we propose a framework for solving variants of the multi-goal path planning problem with applications to autonomous data collection. Autonomous data collection requires optimizing the trajectory of a mobile vehicle to collect data from a number of stationary sensors in a known configuration. The proposed approach utilizes the self-organizing map (SOM) architecture to provide a unified solution to multi-goal path planning problems. Our approach applies to cases where the vehicle must move within a radius of a sensor to collect data and also where some sensors can be ignored due to a lower priority. We compare our proposed approach to state-of-the-art approximate solutions to variants of the Traveling Salesman Problem (TSP) for random deployments and in an underwater monitoring application domain. Our results demonstrate that the SOM approach outperforms combinatorial heuristic algorithms and also provides a unified approach for solving variants of the multi-goal path planning problem.",
Using Ultrasound Backscattering Signals and Nakagami Statistical Distribution to Assess Regional Cataract Hardness,"This study aims to analyze the protein aggregates spatial distribution for different cataract degrees, and correlate this information with the lens acoustical parameters and by this way, assess the cataract regional hardness. Different cataract degrees were induced ex vivo in porcine lenses. A 25 MHz ultrasonic transducer was used to obtain the acoustical parameters (velocity, attenuation, and backscattering signals). B-scan and Nakagami images were constructed. Also, lenses with different cataract degrees were sliced in two regions (nucleus and cortex), for fibers and collagen detection. A significant increase with cataract formation was found for the velocity, attenuation, and brightness intensity of the B-scan images and Nakagami m parameter (p <; 0.01). The acoustical parameters showed a good to moderate correlation with the m parameter for the different stages of cataract formation. A strong correlation was found between the protein aggregates in the cortex and the m parameter. Lenses without cataract are characterized using a classification and regression tree, by a mean brightness intensity ≤0.351, a variance of the B-scan brightness intensity ≤0.070, a velocity ≤1625 m/s, and an attenuation ≤0.415 dB/mm·MHz (sensitivity: 100% and specificity: 72.6%). To characterize different cataract degrees, the m parameter should be considered. Initial stages of cataract are characterized by a mean brightness intensity >0.351 and a variance of the m parameter >0.110. Advanced stages of cataract are characterized by a mean brightness intensity >0.351, a variance of the m parameter ≤0.110, and a mean m parameter >0.374. For initial and advanced stages of cataract, a sensitivity of 78.4% and a specificity of 86.5% are obtained.","Lenses,
Nakagami distribution,
Attenuation,
Ultrasonic imaging,
Brightness,
Backscatter,
Eyes,
Noninvasive treatment"
"Solving the Secondary Structure Matching Problem in Cryo-EM De Novo Modeling Using a Constrained
K
-Shortest Path Graph Algorithm","Electron cryomicroscopy is becoming a major experimental technique in solving the structures of large molecular assemblies. More and more three-dimensional images have been obtained at the medium resolutions between 5 and 10 Å. At this resolution range, major α-helices can be detected as cylindrical sticks and β-sheets can be detected as plain-like regions. A critical question in de novo modeling from cryo-EM images is to determine the match between the detected secondary structures from the image and those on the protein sequence. We formulate this matching problem into a constrained graph problem and present an O(Δ2N22N) algorithm to this NP-Hard problem. The algorithm incorporates the dynamic programming approach into a constrained K-shortest path algorithm. Our method, DP-TOSS, has been tested using α-proteins with maximum 33 helices and α-β proteins up to five helices and 12 β-strands. The correct match was ranked within the top 35 for 19 of the 20 α-proteins and all nine α-β proteins tested. The results demonstrate that DP-TOSS improves accuracy, time and memory space in deriving the topologies of the secondary structure elements for proteins with a large number of secondary structures and a complex skeleton.","Topology,
Skeleton,
Heuristic algorithms,
Image resolution,
Protein sequence,
Amino acids"
A New Learning Algorithm for a Fully Connected Neuro-Fuzzy Inference System,"A traditional neuro-fuzzy system is transformed into an equivalent fully connected three layer neural network (NN), namely, the fully connected neuro-fuzzy inference systems (F-CONFIS). The F-CONFIS differs from traditional NNs by its dependent and repeated weights between input and hidden layers and can be considered as the variation of a kind of multilayer NN. Therefore, an efficient learning algorithm for the F-CONFIS to cope these repeated weights is derived. Furthermore, a dynamic learning rate is proposed for neuro-fuzzy systems via F-CONFIS where both premise (hidden) and consequent portions are considered. Several simulation results indicate that the proposed approach achieves much better accuracy and fast convergence.",
Activity Sculptures: Exploring the Impact of Physical Visualizations on Running Activity,"Data sculptures are a promising type of visualizations in which data is given a physical form. In the past, they have mostly been used for artistic, communicative or educational purposes, and designers of data sculptures argue that in such situations, physical visualizations can be more enriching than pixel-based visualizations. We present the design of Activity Sculptures: data sculptures of running activity. In a three-week field study we investigated the impact of the sculptures on 14 participants' running activity, the personal and social behaviors generated by the sculptures, as well as participants' experiences when receiving these individual physical tokens generated from the specific data of their runs. The physical rewards generated curiosity and personal experimentation but also social dynamics such as discussion on runs or envy/competition. We argue that such passive (or calm) visualizations can complement nudging and other mechanisms of persuasion with a more playful and reflective look at ones' activity.","Data visualization,
Three-dimensional displays,
Solid modeling,
Printing,
Mobile communication"
Millimeter-Wave Generation in an Optoelectronic Oscillator Using an Ultrahigh Finesse Etalon as a Photonic Filter,A Fabry-Perot etalon with a finesse of 100 000 is used as a photonic filter in a single loop optoelectronic oscillator. The etalon provides narrow bandwidth microwave filtering at harmonics of its 1.5 GHz free spectral range for oscillation in the range of 6 to 60 GHz. Fiber delays as long as 2 km are added to the loop with no spurious modes visible above the noise floor. The environmental stability of the etalon makes it suitable as a secondary reference for feedback to the optical frequency which contributes to the reduction of phase noise and long term frequency drift.,"Optical fiber amplifiers,
Microwave filters,
Phase noise,
Optical fiber filters"
QoF: Towards Comprehensive Path Quality Measurement in Wireless Sensor Networks,"Due to its large scale and constrained communication radius, a wireless sensor network mostly relies on multi-hop transmissions to deliver a data packet along a sequence of nodes. It is of essential importance to measure the forwarding quality of multi-hop paths and such information shall be utilized in designing efficient routing strategies. Existing metrics like ETX, ETF mainly focus on quantifying the link performance in between the nodes while overlooking the forwarding capabilities inside the sensor nodes. The experience on manipulating GreenOrbs, a large-scale sensor network with 330 nodes, reveals that the quality of forwarding inside each sensor node is at the least an equally important factor that contributes to the path quality in data delivery. In this paper we propose QoF, Quality of Forwarding, a new metric which explores the performance in the gray zone inside a node left unattended in previous studies. By combining the QoF measurements within a node and over a link, we are able to comprehensively measure the intact path quality in designing efficient multi-hop routing protocols. We implement QoF and build a modified Collection Tree Protocol (CTP). We evaluate the data collection performance in a testbed consisting of 50 TelosB nodes, and compare it with the original CTP protocol. The experimental results show that our approach takes both transmission cost and forwarding reliability into consideration, thus achieving a high throughput for data collection.","Packet loss,
Routing,
Reliability,
Wireless sensor networks,
Data collection"
Multi-Label Learning With Fused Multimodal Bi-Relational Graph,"The problem of multi-label image classification using multiple feature modalities is considered in this work. Given a collection of images with partial labels, we first model the association between different feature modalities and the images labels. These associations are then propagated with a graph diffusion kernel to classify the unlabeled images. Towards this objective, a novel Fused Multimodal Bi-relational Graph representation is proposed, with multiple graphs corresponding to different feature modalities, and one graph corresponding to the image labels. Such a representation allows for effective exploitation of both feature complementariness and label correlation. This contrasts with previous work where these two factors are considered in isolation. Furthermore, we provide a solution to learn the weight for each image graph by estimating the discriminative power of the corresponding feature modality. Experimental results with our proposed method on two standard multi-label image datasets are very promising.",
Operation Characteristics of A6 Relativistic Magnetron Using Single-Stepped Cavities With Axial Extraction,"We report the performance of an A6 relativistic magnetron with single-stepped cavities output. Particle-in-cell simulation shows the electronic efficiency of an A6 relativistic magnetron with an anode block made of six single-stepped cavities can be up to 78% with an output power of one gigawatt for an applied voltage of 400 kV. When the A6 relativistic magnetron with axial extraction using six single-stepped cavities is applied with a voltage of V ~ 400 kV ± 50 kV the electronic efficiency can be as high as 60%, while the output power can be as high as 1 GW. And, when a 10-ns voltage pulse of 400 kV is applied on this magnetrons with diffraction output using single-stepped cavities, the output power pulse can be as high 1.2 GW. The results in this paper will provide a reference for choosing a cavity that is easily manufactured, so that a physical experiment is more feasible.","Cathodes,
Cavity resonators,
Power generation,
Educational institutions,
Plasmas,
Magnetic liquids,
Anodes"
A survey on resource allocation strategies in cloud computing,"Cloud computing provides user-requested services that are reliable, dynamic, flexible and efficient. In order to offer such guaranteed services to cloud users, effective resource allocation strategies must be implemented. The methodology used should also confirm to the Service Level Agreement (SLA) drawn between the customer and the service provider. This work presents a study of such resource allocation strategies in cloud computing. The strategies include resource requirements prediction algorithms and resource allocation algorithms. This works studies the various resource allocation techniques utilized in cloud computing and makes a comparative study of the merits and demerits of each technique. This study aims to identify an efficient resource allocation strategy that utilizes resources effectively in the resource constrained environment of cloud computing.","Resource management,
Cloud computing,
Prediction algorithms,
Computer architecture,
Algorithm design and analysis,
Dynamic scheduling,
Heuristic algorithms"
A Component Model for Model Transformations,"Model-driven engineering promotes an active use of models to conduct the software development process. In this way, models are used to specify, simulate, verify, test and generate code for the final systems. Model transformations are key enablers for this approach, being used to manipulate instance models of a certain modelling language. However, while other development paradigms make available techniques to increase productivity through reutilization, there are few proposals for the reuse of model transformations across different modelling languages. As a result, transformations have to be developed from scratch even if other similar ones exist. In this paper, we propose a technique for the flexible reutilization of model transformations. Our proposal is based on generic programming for the definition and instantiation of transformation templates, and on component-based development for the encapsulation and composition of transformations. We have designed a component model for model transformations, supported by an implementation currently targeting the Atlas Transformation Language (ATL). To evaluate its reusability potential, we report on a generic transformation component to analyse workflow models through their transformation into Petri nets, which we have reused for eight workflow languages, including UML Activity Diagrams, YAWL and two versions of BPMN.","Unified modeling language,
Adaptation models,
Petri nets,
Analytical models,
Logic gates,
Software,
Proposals"
Combinatorial Reliability Analysis of Imperfect Coverage Systems Subject to Functional Dependence,"Functional dependence occurs when the failure of one component causes other components within the same system to become inaccessible or unusable. It is one of the dynamic behaviors that have been recognized in the dynamic fault tree analysis, where a dynamic gate called FDEP was designed to model such behavior. Traditional approaches to handling functional dependence in the reliability analysis of fault-tolerant systems with imperfect fault coverage are mainly based on Markov models, which are often computationally intensive, and even intractable due to the well-known state space explosion problem. In addition, the Markov-based approaches are typically restricted to exponential time-to-failure distributions for system components. In this paper, a combinatorial, separable method based on the divide-and-conquer paradigm and total probability theorem is proposed for addressing the above problems. The proposed method obviates the use of inefficient Markov models, offering exact, computationally-efficient solutions to the reliability analysis of imperfect coverage systems subject to functional dependencies. The proposed method is applicable to the analysis of large systems with any arbitrary time-to-failure distributions. Several case studies are given to illustrate the application and advantages of the proposed method.","Reliability,
Logic gates,
Fault trees,
Discrete Fourier transforms,
Computational modeling,
Markov processes,
Analytical models"
Multisensor data fusion for obstacle detection in automated factory logistics,"This paper describes data fusion methodologies for obstacle detection in an automation system based on advanced Automatic Guided Vehicles (AGV), used for automated logistics in modern factories. We present the background of the problem, introducing generic aspects of the system architecture designed to cope with the obstacle detection in automated factory logistics; then, we focus on the system specification for the module responsible of integrating data from different sources and providing a global representation of the environment. Finally, we present a comparative analysis among different strategies of multisensor data fusion compliant with the requirements of the described system, highlighting their advantages and drawbacks.","Data integration,
Robot sensing systems,
Target tracking,
Logistics,
Laser fusion,
Production facilities,
Vehicles"
Advanced Pattern based Memory Controller for FPGA based HPC applications,"The ever-increasing complexity of high-performance computing applications limits performance due to memory constraints in FPGAs. To address this issue, we propose the Advanced Pattern based Memory Controller (APMC), which supports both regular and irregular memory patterns. The proposed memory controller systematically reduces the latency faced by processors/accelerators due to irregular memory access patterns and low memory bandwidth by using a smart mechanism that collects and stores the different patterns and reuses them when it is needed. In order to prove the effectiveness of the proposed controller, we implemented and tested it on a Xilinx ML505 FPGA board. In order to prove that our controller is efficient in a variety of scenarios, we used several benchmarks with different memory access patterns. The benchmarking results show that our controller consumes 20% less hardware resources, 32% less on chip power and achieves a maximum speedup of 52× and 2.9× for regular and irregular applications respectively.","Random access memory,
Data structures,
Three-dimensional displays,
Memory management,
Prefetching,
Hardware,
Field programmable gate arrays"
Alternating Direction Method of Multiplier for Tomography With Nonlocal Regularizers,"The ordered subset expectation maximization (OSEM) algorithm approximates the gradient of a likelihood function using a subset of projections instead of using all projections so that fast image reconstruction is possible for emission and transmission tomography such as SPECT, PET, and CT. However, OSEM does not significantly accelerate reconstruction with computationally expensive regularizers such as patch-based nonlocal (NL) regularizers, because the regularizer gradient is evaluated for every subset. We propose to use variable splitting to separate the likelihood term and the regularizer term for penalized emission tomographic image reconstruction problem and to optimize it using the alternating direction method of multiplier (ADMM). We also propose a fast algorithm to optimize the ADMM parameter based on convergence rate analysis. This new scheme enables more sub-iterations related to the likelihood term. We evaluated our ADMM for 3-D SPECT image reconstruction with a patch-based NL regularizer that uses the Fair potential function. Our proposed ADMM improved the speed of convergence substantially compared to other existing methods such as gradient descent, EM, and OSEM using De Pierro's approach, and the limited-memory Broyden-Fletcher-Goldfarb-Shanno algorithm.","Image reconstruction,
Approximation methods,
Convergence,
Approximation algorithms,
Vectors,
Single photon emission computed tomography"
Facial Skin Beautification Using Adaptive Region-Aware Masks,"In this paper, we propose a unified facial beautification framework with respect to skin homogeneity, lighting, and color. A novel region-aware mask is constructed for skin manipulation, which can automatically select the edited regions with great precision. Inspired by the state-of-the-art edit propagation techniques, we present an adaptive edge-preserving energy minimization model with a spatially variant parameter and a high-dimensional guided feature space for mask generation. Using region-aware masks, our method facilitates more flexible and accurate facial skin enhancement while the complex manipulations are simplified considerably. In our beautification framework, a portrait is decomposed into smoothness, lighting, and color layers by an edge-preserving operator. Next, facial landmarks and significant features are extracted as input constraints for mask generation. After three region-aware masks have been obtained, a user can perform facial beautification simply by adjusting the skin parameters. Furthermore, the combinations of parameters can be optimized automatically, depending on the data priors and psychological knowledge. We performed both qualitative and quantitative evaluation for our method using faces with different genders, races, ages, poses, and backgrounds from various databases. The experimental results demonstrate that our technique is superior to previous methods and comparable to commercial systems, for example, PicTreat, Portrait+, and Portraiture.",
Towards Accurate Dielectric Property Retrieval of Biological Tissues for Blood Glucose Monitoring,"An analytical formulation for relative dielectric constant retrieval is reconstructed to establish a relationship between the response of a spiral microstrip resonator and effective relative dielectric constant of a lossy superstrate, such as biological tissue. To do so, an analytical equation is modified by constructing functions for the two unknowns, the filling factor A and effective length leff of the resonator. This is done by simulating the resonator with digital phantoms of varying permittivity. The values of A and leff are determined for each phantom from the resulting S-parameter response, using particle swarm optimization. Multiple nonlinear regression is applied to produce equations for A and leff, expressed as a function of frequency and the phantom's relative dielectric constant. These equations are combined to form a new nonlinear analytical equation, which is then solved using the Newton-Raphson iterative method, for both simulations and measurements of physical phantoms. To verify the reconstructed dielectric constant, the dielectric properties of the physical phantoms are determined with commercial high temperature open-ended coaxial probe. The dielectric properties are reconstructed by the described method, with less than 3.67% error with respect to the measurements.","Phantoms,
Sugar,
Dielectrics,
Permittivity,
Dielectric measurement,
Spirals,
Microstrip"
Towards Mobile Document Image Retrieval for Digital Library,"With the proliferation of mobile devices, recent years have witnessed an emerging potential to integrate mobile visual search techniques into digital library. Such a mobile application scenario in digital library has posed significant and unique challenges in document image search. The mobile photograph makes it tough to extract discriminative features from the landmark regions of documents, like line drawings, as well as text layouts. In addition, both search scalability and query delivery latency remain challenging issues in mobile document search. The former relies on an effective yet memory-light indexing structure to accomplish fast online search, while the latter puts a bit budget constraint of query images over the wireless link. In this paper, we propose a novel mobile document image retrieval framework, consisting of a robust Local Inner-distance Shape Context (LISC) descriptor of line drawings, a Hamming distance KD-Tree for scalable and memory-light document indexing, as well as a JBIG2 based query compression scheme, together with a Retinex based enhancement and an OTSU based binarization, to reduce the latency of delivering query while maintaining query quality in terms of search performance. We have extensively validated the key techniques in this framework by quantitative comparison to alternative approaches.",
Investigation of Surface- and Buffer-Induced Current Collapse in GaN High-Electron Mobility Transistors Using a Soft Switched Pulsed I-V Measurement,"In this letter, we investigated the behaviors of surface- and buffer-induced current collapse in AlGaN/GaN high-electron mobility transistors (HEMTs) using a soft-switched pulsed I-V measurement with different quiescent bias points. It is found that the surface- and buffer-related current collapse have different relationship with the gate and drain biases (VGS0,VDS0) during quiescent bias stress. The surface-induced current collapse in devices without passivation monotonically increases with the negative VGS0, suggesting that an electron injection to the surface from gate leakage is the dominant mechanism and the Si3N4 passivation could effectively eliminate such current collapse. The buffer-induced current collapse in devices with intentionally carbon-doped buffer layer exhibits a different relationship with VGS0 after surface passivation. The buffer-related current collapse shows a bell-shaped behavior with VGS0, suggesting that a hot electron trapping in the buffer is the dominant mechanism. The soft-switched pulsed I-V measurement provides an effective method to distinguish between the surface- and buffer-related current collapse in group III-nitride HEMTs.",
A Flexible Framework for Asynchronous in Situ and in Transit Analytics for Scientific Simulations,"High performance computing systems are today composed of tens of thousands of processors and deep memory hierarchies. The next generation of machines will further increase the unbalance between I/O capabilities and processing power. To reduce the pressure on I/Os, the in situ analytics paradigm proposes to process the data as closely as possible to where and when the data are produced. Processing can be embedded in the simulation code, executed asynchronously on helper cores on the same nodes, or performed in transit on staging nodes dedicated to analytics. Today, software environnements as well as usage scenarios still need to be investigated before in situ analytics become a standard practice. In this paper we introduce a framework for designing, deploying and executing in situ scenarios. Based on a component model, the scientist designs analytics workflows by first developing processing components that are next assembled in a dataflow graph through a Python script. At runtime the graph is instantiated according to the execution context, the framework taking care of deploying the application on the target architecture and coordinating the analytics workflows with the simulation execution. Component coordination, zero-copy intra-node communications or inter-nodes data transfers rely on per-node distributed daemons. We evaluate various scenarios performing in situ and in transit analytics on large molecular dynamics systems simulated with Gromacs using up to 2048 cores. We show in particular that analytics processing can be performed on the fraction of resources the simulation does not use well, resulting in a limited impact on the simulation performance (less than 9%). Our more advanced scenario combines in situ and in transit processing to compute a molecular surface based on the Quick surf algorithm.","Analytical models,
Computational modeling,
Data models,
Ports (Computers),
Numerical models,
Standards,
Data visualization"
Towards on-path caching alternatives in Information-Centric Networks,"Information-Centric Networking (ICN), an alternative to the current Internet architecture, focuses on the distribution and retrieval of content instead of the transfer of information between specific endpoints. Approaches to ICN employ caches in the network to eliminate the transfer of information over lengthy communication paths from a source to consumers. The contribution of this paper lies in the placement of copies in on-path in-network caching. Our goal is to investigate the suitability of a probabilistic algorithm, Prob-PD, based on two variables, the content's popularity rates and the distance ratio of each node from the source, with regard to caching performance, i.e. cache hit rates, cache replacement rates and content delivery times. Towards this goal, we present an initial comparison of simulation results of the proposed caching mechanism and published alternatives showing significant gains of the algorithm.","Conferences,
Measurement,
Probabilistic logic,
Computer architecture,
Topology,
Educational institutions,
Internet"
Assessing Executive Function Using a Computer Game: Computational Modeling of Cognitive Processes,"Early and reliable detection of cognitive decline is one of the most important challenges of current healthcare. In this project, we developed an approach whereby a frequently played computer game can be used to assess a variety of cognitive processes and estimate the results of the pen-and-paper trail making test (TMT)--known to measure executive function, as well as visual pattern recognition, speed of processing, working memory, and set-switching ability. We developed a computational model of the TMT based on a decomposition of the test into several independent processes, each characterized by a set of parameters that can be estimated from play of a computer game designed to resemble the TMT. An empirical evaluation of the model suggests that it is possible to use the game data to estimate the parameters of the underlying cognitive processes and using the values of the parameters to estimate the TMT performance. Cognitive measures and trends in these measures can be used to identify individuals for further assessment, to provide a mechanism for improving the early detection of neurological problems, and to provide feedback and monitoring for cognitive interventions in the home.","Games,
Computers,
Biomedical measurement,
Mice,
Computational modeling,
Informatics,
Standards"
Visual Persuasion: Inferring Communicative Intents of Images,"In this paper we introduce the novel problem of understanding visual persuasion. Modern mass media make extensive use of images to persuade people to make commercial and political decisions. These effects and techniques are widely studied in the social sciences, but behavioral studies do not scale to massive datasets. Computer vision has made great strides in building syntactical representations of images, such as detection and identification of objects. However, the pervasive use of images for communicative purposes has been largely ignored. We extend the significant advances in syntactic analysis in computer vision to the higher-level challenge of understanding the underlying communicative intent implied in images. We begin by identifying nine dimensions of persuasive intent latent in images of politicians, such as ""socially dominant, "" ""energetic, "" and ""trustworthy, "" and propose a hierarchical model that builds on the layer of syntactical attributes, such as ""smile"" and ""waving hand, "" to predict the intents presented in the images. To facilitate progress, we introduce a new dataset of 1, 124 images of politicians labeled with ground-truth intents in the form of rankings. This study demonstrates that a systematic focus on visual persuasion opens up the field of computer vision to a new class of investigations around mediated images, intersecting with media analysis, psychology, and political communication.",
Robust pedestrian dead reckoning (R-PDR) for arbitrary mobile device placement,"Pedestrian dead reckoning, especially on smart-phones, is likely to play an increasingly important role in indoor tracking and navigation, due to its low cost and ability to work without any additional infrastructure. A challenge however, is that positioning, both in terms of step detection and heading estimation, must be accurate and reliable, even when the use of the device is so varied in terms of placement (e.g. handheld or in a pocket) or orientation (e.g holding the device in either portrait or landscape mode). Furthermore, the placement can vary over time as a user performs different tasks, such as making a call or carrying the device in a bag. A second challenge is to be able to distinguish between a true step and other periodic motion such as swinging an arm or tapping when the placement and orientation of the device is unknown. If this is not done correctly, then the PDR system typically overestimates the number of steps taken, leading to a significant long term error. We present a fresh approach, robust PDR (R-PDR), based on exploiting how bipedal motion impacts acquired sensor waveforms. Rather than attempting to recognize different placements through sensor data, we instead simply determine whether the motion of one or both legs impact the measurements. In addition, we formulate a set of techniques to accurately estimate the device orientation, which allows us to very accurately (typically over 99%) reject false positives. We demonstrate that regardless of device placement, we are able to detect the number of steps taken with >99.4% accuracy. R-PDR thus addresses the two main limitations facing existing PDR techniques.",
Near-Realistic Mobile Exergames With Wireless Wearable Sensors,"Exergaming is expanding as an option for sedentary behavior in childhood/adult obesity and for extra exercise for gamers. This paper presents the development process for a mobile active sports exergame with near-realistic motions through the usage of body-wearable sensors. The process begins by collecting a dataset specifically targeted to mapping real-world activities directly to the games, then, developing the recognition system in a fashion to produce an enjoyable game. The classification algorithm in this paper has precision and recall of 77% and 77% respectively, compared with 40% and 19% precision and recall on current activity monitoring algorithms intended for general daily living activities. Aside from classification, the user experience must be strong enough to be a successful system for adoption. Indeed, fast and intense activities as well as competitive, multiplayer environments make for a successful, enjoyable exergame. This enjoyment is evaluated through a 30 person user study. Multiple aspects of the exergaming user experience trials have been merged into a comprehensive survey, called ExerSurvey. All but one user thought the motions in the game were realistic and difficult to cheat. Ultimately, a game with near-realistic motions was shown to be an enjoyable, active video exergame for any environment.","Games,
Mobile communication,
Training,
Foot,
Vectors,
Wearable sensors"
Optimal Correlative Coding for Discrete-Time OFDM Systems,"Frequency-domain correlative coding (CC) has been widely considered to be effective in intercarrier interference (ICI) mitigation in orthogonal frequency-division multiplexing (OFDM) systems due to its potential in the considerable enhancement of the carrier-to-interference power ratio (CIR). Existing work has focused on searching for the optimal coding coefficients in minimizing the ICI power. However, the fundamental analysis is largely based on the continuous-time signal model (CTSM) and the assumption of an infinite number of subcarriers. In practice, the OFDM signal always involves a finite bandwidth and is sampled for digital processing purposes. Attentive to the given needs of practical systems, we derive the optimal coding coefficients in the maximization of the CIR or the minimization of the ICI power based on the discrete-time signal model (DTSM) with a finite number of subcarriers. Results show that the optimal coding coefficients for the DTSM differ from the existing coefficients developed for the CTSM and that our performance analysis leads to a much improved coding gain prediction for practical systems.","Encoding,
OFDM,
Gain,
Analytical models,
Fading,
Doppler shift"
An Adaptable Robot Vision System Performing Manipulation Actions With Flexible Objects,"This paper describes an adaptable system which is able to perform manipulation operations (such as Peg-in-Hole or Laying-Down actions) with flexible objects. As such objects easily change their shape significantly during the execution of an action, traditional strategies, e.g, for solve path-planning problems, are often not applicable. It is therefore required to integrate visual tracking and shape reconstruction with a physical modeling of the materials and their deformations as well as action learning techniques. All these different submodules have been integrated into a demonstration platform, operating in real-time. Simulations have been used to bootstrap the learning of optimal actions, which are subsequently improved through real-world executions. To achieve reproducible results, we demonstrate this for casted silicone test objects of regular shape. Note to Practitioners - The aim of this work was to facilitate the setup of robot-based automation of delicate handling of flexible objects consisting of a uniform material. As examples, we have considered how to optimally maneuver flexible objects through a hole without colliding and how to place flexible objects on a flat surface with minimal introduction of internal stresses in the object. Given the material properties of the object, we have demonstrated in these two applications how the system can be programmed with minimal requirements of human intervention. Rather than being an integrated system with the drawbacks in terms of lacking flexibility, our system should be viewed as a library of new technologies that have been proven to work in close to industrial conditions. As a rather basic, but necessary part, we provide a technology for determining the shape of the object when passing on, e.g., a conveyor belt prior to being handled. The main technologies applicable for the manipulated objects are: A method for real-time tracking of the flexible objects during manipulation, a method for model-based offline prediction of the static deformation of grasped, flexible objects and, finally, a method for optimizing specific tasks based on both simulated and real-world executions.",
Convex and analytically-invertible dynamics with contacts and constraints: Theory and implementation in MuJoCo,"We describe a full-featured simulation pipeline implemented in the MuJoCo physics engine. It includes multi-joint dynamics in generalized coordinates, holonomic constraints, dry joint friction, joint and tendon limits, frictionless and frictional contacts that can have sliding, torsional and rolling friction. The forward dynamics of a 27-dof humanoid with 10 contacts are evaluated in 0.1 msec. Since the simulation is stable at 10 msec timesteps, it can run 100 times faster than real-time on a single core of a desktop processor. Furthermore the entire simulation pipeline can be inverted analytically, an order-of-magnitude faster than the corresponding forward dynamics. We soften all constraints, in a way that avoids instabilities and unrealistic penetrations associated with earlier spring-damper methods and yet is sufficient to allow inversion. Constraints are imposed via impulses, using an extended version of the velocity-stepping approach. For holomonic constraints the extension involves a soft version of the Gauss principle. For all other constraints we extend our earlier work on complementarity-free contact dynamics - which were already known to be invertible via an iterative solver - and develop a new formulation allowing analytical inversion.","Friction,
Dynamics,
Vectors,
Joints,
Force,
Convex functions,
Heuristic algorithms"
Adaptive Shape Prior Constrained Level Sets for Bladder MR Image Segmentation,"Three-dimensional bladder wall segmentation for thickness measuring can be very useful for bladder magnetic resonance (MR) image analysis, since thickening of the bladder wall can indicate abnormality. However, it is a challenging task due to the artifacts inside bladder lumen, weak boundaries in the apex and base areas, and complicated outside intensity distributions. To deal with these difficulties, in this paper, an adaptive shape prior constrained directional level set model is proposed to segment the inner and outer boundaries of the bladder wall. In addition, a coupled directional level set model is presented to refine the segmentation by exploiting the prior knowledge of region information and minimum thickness. With our proposed method, the influence of the artifacts in the bladder lumen and the complicated outside tissues surrounding the bladder can be appreciably reduced. Furthermore, the leakage on the weak boundaries can be avoided. Compared with other related methods, better results were obtained on 11 patients' 3-D bladder MR images by using the proposed method.","Level set,
Bladder,
Shape,
Image segmentation,
Adaptation models,
Image edge detection,
Mathematical model"
An end-to-end system for designing mechanical structures for print-and-fold robots,"This work presents a script-based development environment aimed at allowing users to easily design and create mechanical bodies for folded plastic robots. The origami-inspired fabrication process is inexpensive and widely accessible, and the tools developed in this work allow for open source design sharing and modular reuse. Designs are generated by recursively combining mechanical components - from primitive building blocks, through mechanisms and assemblies, to full robots - in a flexible yet well-defined manner. This process was used to design robotic elements of increasing complexity up to a multi-degree-of-freedom compliant manipulator arm, demonstrating the power of this system. The developed system is extensible, opening avenues for further research ultimately leading to the development of a complete robot compiler.","Robots,
Three-dimensional displays,
Geometry,
Fabrication,
Libraries,
Solids,
Joints"
Performance Analysis and Power Allocation for Two-Way Amplify-and-Forward Relaying With Generalized Differential Modulation,"Differential modulation has been proposed to mitigate the difficulties involved in estimating the channel state information (CSI) in a two-way relay network (TWRN). However, it suffers at least 3-dB performance loss compared with the coherent detection. This work proposes a new differential modulation and detection scheme to close the performance gap for TWRN using amplify-and-forward (AF) protocol. At two source nodes T1 and T2, a block-by-block differential encoder is employed, where each block consists of one reference symbol (RS) and several normal symbols (NSs). After two-way AF (TWAF) relaying, the information bits can be recovered without any knowledge of CSI. The bit-error-rate (BER) performance of the proposed scheme is analyzed, and closed-form expressions for the lower bound of BER and its high signal-to-noise ratio (SNR) approximation are derived. To minimize the lower bound of BER, we also investigate power allocation among the RS and the NSs in each block. Simulation results show that the performance gap between the proposed differential transmission scheme with a block length of 256 and the coherent receiver with perfect CSI is within 0.5 dB in quasi-static fading channels.","Relays,
Signal to noise ratio,
Resource management,
Bit error rate,
Modulation,
Receivers,
Protocols"
Efficient Power Conservation Mechanism in Spline Function Defined WSN Terrain,"Coverage is a vital issue that ensures that basic functions are available in wireless sensor networks (WSNs). These functions provide communications during emergency rescue or in war environments. Sensor nodes must be dispersed and survive in place for a long time in order to accurately monitor all events. However, sensor nodes rely on limited battery energy restricted to the lifetime of the entire network. When few sensor nodes are awake during an epoch, the entire network lifetime becomes longer. This implies that the coverage problem must be solved based on the energy efficiency issue. In order to strengthen the coverage ratio with a limited number of sensor nodes, practical coverage algorithms were proposed in the existing researches but investigated in a 2-D plane, which is not suitable for a realistic environment. Few researchers have investigated the WSN coverage problem for a 3-D space. The actual terrain is rugged and bumpy that prevents deploying sensor nodes in three-dimension space. In this paper, we consider the field of interest as a complex surface but also use the spline function to obtain factual information about a complex surface. Furthermore, dynamic programming is utilized to optimize the sensing radius for reducing the power consumption.","Sensors,
Splines (mathematics),
Three-dimensional displays,
Surface topography,
Surface reconstruction,
Wireless sensor networks,
Equations"
Strong Impossibility Results for Sparse Signal Processing,"This letter derives strong impossibility results for several sparse signal processing problems. It is shown that regardless of the allowed error probability in identifying the salient support set (as long as this probability is below one), the required number of measurements is almost the same as that required for the error probability to be arbitrarily small. Our proof technique involves the use of the blowing-up lemma and can be applied to diverse problems from noisy group testing to graphical model selection as long as the observations are discrete.","Testing,
Noise measurement,
Error probability,
Sparse matrices"
In-Network Quality Optimization for Adaptive Video Streaming Services,"HTTP adaptive streaming (HAS) services allow the quality of streaming video to be automatically adapted by the client application in face of network and device dynamics. Due to their advantages compared to traditional techniques, HAS-based protocols are widely used for over-the-top (OTT) video streaming. However, they are yet to be adopted in managed environments, such as ISP networks. A major obstacle is the purely client-driven design of current HAS approaches, which leads to excessive quality oscillations, suboptimal behavior, and the inability to enforce management policies. Moreover, the provider has no control over the quality that is provided, which is essential when offering a managed service. This article tackles these challenges and facilitates the adoption of HAS in managed networks. Specifically, several centralized and distributed algorithms and heuristics are proposed that allow nodes inside the network to steer the HAS client's quality selection process. The algorithms are able to enforce management policies by limiting the set of available qualities for specific clients. Additionally, simulation results show that by coordinating the quality selection process across multiple clients, the proposed algorithms significantly reduce quality oscillations by a factor of five and increase the average delivered video quality by at least 14%.","Streaming media,
Servers,
Bit rate,
Optimization,
Throughput,
Bandwidth,
Switches"
Multimodal Registration and Data Fusion for Cardiac Resynchronization Therapy Optimization,"Cardiac resynchronization therapy (CRT) has been shown to improve cardiovascular function in specific patients suffering from heart failure. This procedure still needs to be optimized to overcome the high rate of implanted patients that do not respond to this therapy. We propose in this work a better characterization of the electro-mechanical (EM) coupling of each region of the left ventricle (LV) that could be useful to precise the best implantation site. A new descriptor is proposed with the extraction of local electro-mechanical delays. Their measurement is based on the fusion of anatomical, functional and electrical data acquired using computed tomography (CT), speckle tracking echocardiography (STE), and electro-anatomical mappings (EAM). We propose a workflow to place multimodal data in the same geometrical referential system and to extract local electro-mechanical descriptors. It implies the fusion of electrical and mechanical data on a 3D+ t anatomical model of the LV. It mainly consists in four steps: 1) the modeling of the endocardium using a dynamic surface estimated from CT images; 2) the semi-interactive registration of EAM data and CT images; 3) the automatic registration of STE data on the dynamic model, using a metric based on Fourier descriptors and dynamic time warping; 4) the temporal alignment between EAM and STE and the estimation of local electro-mechanical delays. The proposed process has been applied to real data corresponding to five patients undergoing CRT. Results show that local electro-mechanical delays provide meaningful information on the local characterization of the LV and may be useful for the optimal pacing site selection in CRT.",
Improved Block Truncation Coding Using Optimized Dot Diffusion,"Block truncation coding (BTC) has been considered a highly efficient compression technique for decades. However, its inherent artifacts, blocking effect and false contour, caused by low bit rate configuration are the key problems. To deal with these, an improved BTC, namely dot-diffused BTC (DDBTC), is proposed in this paper. Moreover, this method can provide excellent processing efficiency by exploiting the nature parallelism advantage of the dot diffusion, and excellent image quality can also be offered through co-optimizing the class matrix and diffused matrix of the dot diffusion. According to the experimental results, the proposed DDBTC is superior to the former error-diffused BTC in terms of various objective image quality assessment methods as well as processing efficiency. In addition, the DDBTC also shows a significant image quality improvement comparing with that of the former ordered-dither BTC.","block codes,
image coding,
matrix algebra,
optimisation"
A complete KALDI recipe for building Arabic speech recognition systems,In this paper we present a recipe and language resources for training and testing Arabic speech recognition systems using the KALDI toolkit. We built a prototype broadcast news system using 200 hours GALE data that is publicly available through LDC. We describe in detail the decisions made in building the system: using the MADA toolkit for text normalization and vowelization; why we use 36 phonemes; how we generate pronunciations; how we build the language model. We report results using state-of-the-art modeling and decoding techniques. The scripts are released through KALDI and resources are made available on QCRI's language resources web portal. This is the first effort to share reproducible sizable training and testing results on MSA system.,
"Sensing, Understanding, and Shaping Social Behavior","The ability to understand social systems through the aid of computational tools is central to the emerging field of computational social systems. Such understanding can answer epistemological questions on human behavior in a data-driven manner, and provide prescriptive guidelines for persuading humans to undertake certain actions in real-world social scenarios. The growing number of works in this subfield has the potential to impact multiple walks of human life including health, wellness, productivity, mobility, transportation, education, shopping, and sustenance. The contribution of this paper is twofold. First, we provide a functional survey of recent advances in sensing, understanding, and shaping human behavior, focusing on real-world behavior of users as measured using passive sensors. Second, we present a case study on how trust, which is an important building block of computational social systems, can be quantified, sensed, and applied to shape human behavior. Our findings suggest that:1) trust can be operationalized and predicted via computational methods (passive sensing and network analysis) and 2) trust has a significant impact on social persuasion; in fact, it was found to be significantly more effective than the closeness of ties in determining the amount of behavior change.",
Decision Fusion for Multimodal Biometrics Using Social Network Analysis,"This paper presents for the first time decision fusion for multimodal biometric system using social network analysis (SNA). The main challenge in the design of biometric systems, at present, lies in unavailability of high-quality data to ensure consistently high recognition results. Resorting to multimodal biometric partially solves the problem, however, issues with dimensionality reduction, classifier selection, and aggregated decision making remain. The presented methodology successfully overcomes the problem through employing novel decision fusion using SNA. While several types of feature extractors can be used to reduce the dimension and identify significant features, we chose the Fisher Linear Discriminant Analysis as one of the most efficient methods. Social networks are constructed based on similarity and correlation of features among the classes. The final classification result is generated based on the two levels of decision fusion methods. At the first level, individual biometrics (face or ear or signature) are classified using matching score methodology. SNA is used to reinforce the confidence level of the classifier to reduce the error rate. In the second level, outcomes of classification based on individual biometrics are fused together to obtain the final decision.",
Automated Characterization of Breast Lesions Imaged With an Ultrafast DCE-MR Protocol,"Dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) of the breast has become an invaluable tool in the clinical work-up of patients suspected of having breast carcinoma. The purpose of this study is to introduce novel features extracted from the kinetics of contrast agent uptake imaged by a short (100 s) view-sharing MRI protocol, and to investigate how these features measure up to commonly used features for regular DCE-MRI of the breast. Performance is measured with a computer aided diagnosis (CADx) system aimed at distinguishing benign from malignant lesions. A bi-temporal breast MRI protocol was used. This protocol produces five regular, high spatial-resolution T1-weighted acquisitions interleaved with a series of 20 ultrafast view-sharing acquisitions during contrast agent uptake. We measure and compare the performances of morphological and kinetic features derived from both the regular DCE-MRI sequence and the ultrafast view-sharing sequence with four different classifiers. The classification performance of kinetics derived from the short (100 s) ultrafast acquisition starting with contrast agent administration, is significantly higher than the performance of kinetics derived from a much lengthier (510 s), commonly used 3-D gradient echo acquisition. When combined with morphology information all classifiers show a higher performance for the ultrafast acquisition (two out of four results are significantly better).",
"Compact Substrate Integrated Waveguide (SIW) Monopulse Network for
Ku
-Band Tracking System Applications","A compact single-layer substrate integrated waveguide (SIW) monopulse network for Ku-band tracking system applications is investigated and demonstrated in this work. The feeding network and the monopulse comparator are integrated into a substrate with a structure size of 8.2λ0×9λ0 at center frequency while 32 output ports are welded perpendicularly for connecting active transmit/receive modules. The optimal design of a 3-dB coupler with metallic slots and phase shifter with dual steps is presented. The relative frequency bandwidth ( | S11|, | S22|, and ) of the network is 6%, in which the phase imbalance of all ports is less than 5.5° [root mean square (rms)], the power imbalance is about 0.5 dB (rms). The insertion losses are about 3-5 dB and the isolations between the three channels are all better than 25 dB. The good performances of this SIW-based monopulse network are validated by measurements, showing the advantages of low cost, light weight, easy fabrication, etc. It presents an excellent candidate for Ku-band tracking systems or up-band millimeter-wave systems.","Ports (Computers),
Phase shifters,
Couplers,
Microstrip,
Bandwidth,
Substrates,
Rectangular waveguides"
Combing the Communication Hairball: Visualizing Parallel Execution Traces using Logical Time,"With the continuous rise in complexity of modern supercomputers, optimizing the performance of large-scale parallel programs is becoming increasingly challenging. Simultaneously, the growth in scale magnifies the impact of even minor inefficiencies - potentially millions of compute hours and megawatts in power consumption can be wasted on avoidable mistakes or sub-optimal algorithms. This makes performance analysis and optimization critical elements in the software development process. One of the most common forms of performance analysis is to study execution traces, which record a history of per-process events and interprocess messages in a parallel application. Trace visualizations allow users to browse this event history and search for insights into the observed performance behavior. However, current visualizations are difficult to understand even for small process counts and do not scale gracefully beyond a few hundred processes. Organizing events in time leads to a virtually unintelligible conglomerate of interleaved events and moderately high process counts overtax even the largest display. As an alternative, we present a new trace visualization approach based on transforming the event history into logical time inferred directly from happened-before relationships. This emphasizes the code's structural behavior, which is much more familiar to the application developer. The original timing data, or other information, is then encoded through color, leading to a more intuitive visualization. Furthermore, we use the discrete nature of logical timelines to cluster processes according to their local behavior leading to a scalable visualization of even long traces on large process counts. We demonstrate our system using two case studies on large-scale parallel codes.",
Extension of the Fuzzy Integral for General Fuzzy Set-Valued Information,"The fuzzy integral (FI) is an extremely flexible aggregation operator. It is used in numerous applications, such as image processing, multicriteria decision making, skeletal age-at-death estimation, and multisource (e.g., feature, algorithm, sensor, and confidence) fusion. To date, a few works have appeared on the topic of generalizing Sugeno's original real-valued integrand and fuzzy measure (FM) for the case of higher order uncertain information (both integrand and measure). For the most part, these extensions are motivated by, and are consistent with, Zadeh's extension principle (EP). Namely, existing extensions focus on fuzzy number (FN), i.e., convex and normal fuzzy set- (FS) valued integrands. Herein, we put forth a new definition, called the generalized FI (gFI), and efficient algorithm for calculation for FS-valued integrands. In addition, we compare the gFI, numerically and theoretically, with our non-EP-based FI extension called the nondirect FI (NDFI). Examples are investigated in the areas of skeletal age-at-death estimation in forensic anthropology and multisource fusion. These applications help demonstrate the need and benefit of the proposed work. In particular, we show there is not one supreme technique. Instead, multiple extensions are of benefit in different contexts and applications.",
FIDES: A trust-based framework for secure user incentivization in participatory sensing,"Participatory sensing (PS) has recently attracted tremendous attention given its potential for a wide variety of sensing applications. Due to the fact that PS systems rely completely on the data provided by the users, incentivizing users' active participation while guaranteeing data reliability is paramount to effectively employ PS systems in practical scenarios. In this paper, we first define a set of attacks which compromise data reliability of existing PS applications. Next, we propose a scalable and secure trust-based framework, called FIDES, which relies on the concept of mobile security agents (MSAs) and Josang's trust model to rule out incorrect reports and reward reliable users. By simulating the FIDES framework on mobility traces of taxi cabs in San Francisco, we demonstrate that FIDES secures the PS system from the proposed attacks, guarantees high data reliability, and saves significant amount of revenue with respect to existing reward mechanisms.","Reliability,
Sensors,
Mobile communication,
Security,
Accuracy,
Uncertainty,
Data models"
The Capacity Region of the Source-Type Model for Secret Key and Private Key Generation,"The problem of simultaneously generating a secret key (SK) and private key (PK) pair among three terminals via public discussion is investigated. In this problem, each terminal observes a component of correlated sources. All three terminals are required to generate the common SK to be concealed from an eavesdropper that has access to the public discussion, while two designated terminals are required to generate an extra PK to be concealed from both the eavesdropper and the remaining terminal. An outer bound on the SK-PK capacity region was established by Ye and Narayan, and was shown to be achievable for a special case. In this paper, the SK-PK capacity region is established in general by developing schemes to achieve the outer bound for the remaining two cases. The main technique lies in the novel design of a random binning-joint decoding scheme that achieves the existing outer bound.","Zinc,
Indexes,
Joints,
Random variables,
Decoding,
Source coding,
Electronic mail"
A Hybrid Particle-Swarm Tabu Search Algorithm for Solving Job Shop Scheduling Problems,"This paper proposes a method for the job shop scheduling problem (JSSP) based on the hybrid metaheuristic method. This method makes use of the merits of an improved particle swarm optimization (PSO) and a tabu search (TS) algorithm. In this work, based on scanning a valuable region thoroughly, a balance strategy is introduced into the PSO for enhancing its exploration ability. Then, the improved PSO could provide diverse and elite initial solutions to the TS for making a better search in the global space. We also present a new local search strategy for obtaining better results in JSSP. A real-integer encode and decode scheme for associating a solution in continuous space to a discrete schedule solution is designed for the improved PSO and the tabu algorithm to directly apply their solutions for intensifying the search of better solutions. Experimental comparisons with several traditional metaheuristic methods demonstrate the effectiveness of the proposed PSO-TS algorithm.","Job shop scheduling,
Algorithm design and analysis,
Particle swarm optimization"
Can 2D-Nanocrystals Extend the Lifetime of Floating-Gate Transistor Based Nonvolatile Memory?,"Conventional floating-gate (FG) transistors (made with Si/poly-Si) that form the building blocks of the widely employed nonvolatile flash memory technology face severe scaling challenges beyond the 12-nm node. In this paper, for the first time, a comprehensive evaluation of the FG transistor made from emerging nanocrystals in the form of 2-dimensional (2D) transition metal dichalcogenides (TMDs) and multilayer graphene (MLG) is presented. It is shown that TMD based 2D channel materials have excellent gate length scaling potential due to their atomic scale thicknesses. On the other hand, employing MLG as FG greatly reduces cell-to-cell interference and alleviates reliability concerns. Moreover, it is also revealed that TMD/MLG heterostructures enable new mechanism for improving charge retention, thereby allowing the effective oxide thickness of gate dielectrics to be scaled to a few nanometers. Thus, this work indicates that judiciously selected 2D-nanocrystals can significantly extend the lifetime of the FG-based memory cell.","Transistors,
Logic gates,
Graphene,
Silicon,
Threshold voltage,
Metals"
A study of big data processing constraints on a low-power Hadoop cluster,"Big Data processing with Hadoop has been emerging recently, both on the computing cloud and enterprise deployment. However, wide-spread security exploits may hurt the reputation of public clouds. If Hadoop on the cloud is not an option, an organization has to build its own Hadoop clusters. But having a data center is not worth for a small organization both in terms of building and operating costs. Another viable solution is to build a cluster with low-cost ARM system-on-chip boards. This paper presents a study of a Hadoop cluster for processing Big Data built atop 22 ARM boards. The Hadoop's MapReduce was replaced by Spark and experiments on three different hardware configurations were conducted to understand limitations and constraints of the cluster. From the experimental results, it can be concluded that processing Big Data on an ARM cluster is highly feasible. The cluster could process a 34 GB Wikipedia article file in acceptable time, while generally consumed the power 0.061-0.322 kWh for all benchmarks. It has been found that I/O of the hardware is fast enough, but the power of CPUs is inadequate because they are largely spent for the Hadoop's I/O.","Big data,
Sparks,
Benchmark testing,
Software,
Power demand,
Hardware"
An accurate frame error rate approximation of coded diversity systems with non-identical diversity branches,"This paper presents an accurate approximation of the frame error rate (FER) of coded wireless communication systems with receiver diversity, such as single-input multiple-output (SIMO) systems with maximum ratio combining (MRC) or hybrid automatic repeat request (HARQ) systems with Chase combining. The signals at different diversity branches experience independent but non-identically distributed Rayleigh fading. The FER approximation is obtained with a threshold-based method. Specifically, the threshold value, which is critical to the FER approximation accuracy, is modeled as a linear function of the frame length in the log-domain, with the slope and intercept of the linear function determined by the underlying modulation and channel coding schemes. The analytical FER approximation is expressed as an explicit function of parameters related to modulation, coding, frame length, number of diversity branches, and the power distribution across the diversity branches. Such an FER approximation summarizes the complex physical layer operations into a few parameters, and it provides the parametric flexibility that is not available in most existing FER approximations. Simulation results show that the proposed FER approximation can accurately predict the FER performance of a wide range of receiver diversity systems.","Approximation methods,
Fading,
Modulation,
Signal to noise ratio,
Diversity reception,
Receivers,
Encoding"
Error Floor Approximation for LDPC Codes in the AWGN Channel,"This paper addresses the prediction of error floors of low-density parity-check codes transmitted over the additive white Gaussian noise channel. Using a linear state-space model to estimate the behavior of the sum-product algorithm (SPA) decoder in the vicinity of trapping sets (TSs), we study the performance of the SPA decoder in the log-likelihood ratio (LLR) domain as a function of the LLR saturation level. When applied to several widely studied codes, the model accurately predicts a significant decrease in the error floor as the saturation level is allowed to increase. For nonsaturating decoders, however, we find that the state-space model breaks down after a small number of iterations due to the strong correlation of LLR messages. We then revisit Richardson's importance-sampling methodology for estimating error floors due to TSs when those floors are too low for Monte Carlo simulation. We propose modifications that account for the behavior of a nonsaturating decoder and present the resulting error floor estimates for the Margulis code. These estimates are much lower, significantly steeper, and more sensitive to iteration count than those previously reported.",
Verilog-A Based Effective Complementary Resistive Switch Model for Simulations and Analysis,"Resistive memory, also known as memristor, is recently emerging as a potential successor to traditional charge-based memories. However, the nanoscale features of these devices introduce challenges in modeling and simulation. In this paper, we propose a novel Verilog-A based complementary resistive switch memory model for effective simulation and analysis. Our proposed model captures desired nonlinear characteristics using voltage based state control as opposed to recently proposed current based state control. We demonstrate that such state control has advantages for our proposed CRS model based crossbar arrays in terms of symmetric ON/OFF voltages and significantly reduced sneak path currents with high noise margin compared to traditional memristor based architectures. Moreover, to validate the effectiveness of our Verilog-A based model we carry out extensive simulations and analyses for different crossbar array architectures using traditional EDA tools.","Memristors,
Resistance,
Analytical models,
Voltage control,
Hardware design languages,
Computer architecture,
Switches"
C-KLAM: Constrained keyframe-based localization and mapping,"In this paper, we present C-KLAM, a Maximum A Posteriori (MAP) estimator-based keyframe approach for SLAM. Instead of discarding information from non-keyframes for reducing the computational complexity, the proposed C-KLAM presents a novel, elegant, and computationally-efficient technique for incorporating most of this information in a consistent manner, resulting in improved estimation accuracy. To achieve this, C-KLAM projects both proprioceptive and exteroceptive information from the non-keyframes to the keyframes, using marginalization, while maintaining the sparse structure of the associated information matrix, resulting in fast and efficient solutions. The performance of C-KLAM has been tested in experiments, using visual and inertial measurements, to demonstrate that it achieves performance comparable to that of the computationally-intensive batch MAP-based 3D SLAM, that uses all available measurement information.","Approximation methods,
Simultaneous localization and mapping,
Cameras,
Trajectory,
Cost function,
Jacobian matrices"
Implementation of 802.15.4 for designing of home automation and power monitoring system,"Innovation in the field of wireless technologies has revolutionized automation in industrial, commercial and residential sectors. With the proliferation of wireless technologies, it is important to implement an appropriate wireless protocol according to the application area. This paper provides a brief overview of the existing home automation systems and describes ZigBee (over IEEE 802.15.4) technology, along with its comparative study with other protocols. It suggests, ZigBee is an emerging technology in the field of Home Automation system (HAS). It also demonstrates the designing and implementation of HAS for remote controlling and monitoring of various domestic loads/appliances using ZigBee protocol. An efficient method of power utilization through real-time power monitoring with the help of a PC-based GUI application is illustrated.","Zigbee,
Home automation,
Wireless communication,
Wireless sensor networks,
Graphical user interfaces,
Power demand,
Monitoring"
vGASA: Adaptive Scheduling Algorithm of Virtualized GPU Resource in Cloud Gaming,"As the virtualization technology for GPUs matures, cloud gaming has become an emerging application among cloud services. In addition to the poor default mechanisms of GPU resource sharing, the performance of cloud games is inevitably undermined by various runtime uncertainties such as rendering complex game scenarios. The question of how to handle the runtime uncertainties for GPU resource sharing remains unanswered. To address this challenge, we propose vGASA, a virtualized GPU resource adaptive scheduling algorithm in cloud gaming. vGASA interposes scheduling algorithms in the graphics API of the operating system, and hence the host graphic driver or the guest operating system remains unmodified. To fulfill the service level agreement as well as maximize GPU usage, we propose three adaptive scheduling algorithms featuring feedback control that mitigates the impact of the runtime uncertainties on the system performance. The experimental results demonstrate that vGASA is able to maintain frames per second of various workloads at the desired level with the performance overhead limited to 5-12 percent.","Graphics processing units,
Games,
Algorithm design and analysis,
Virtualization,
Runtime,
Uncertainty,
Scheduling"
MRI Upsampling Using Feature-Based Nonlocal Means Approach,"In magnetic resonance imaging (MRI), spatial resolution is limited by several factors such as acquisition time, short physiological phenomena, and organ motion. The acquired image usually has higher resolution in two dimensions (the acquisition plane) in comparison with the third dimension, resulting in highly anisotropic voxel size. Interpolation of these low resolution (LR) images using standard techniques, such as linear or spline interpolation, results in distorted edges in the planes perpendicular to the acquisition plane. This poses limitation on conducting quantitative analyses of LR images, particularly on their voxel-wise analysis and registration. We have proposed a new non-local means feature-based technique that uses structural information of a high resolution (HR) image with a different contrast and interpolates the LR image. In this approach, the similarity between voxels is estimated using a feature vector that characterizes the laminar pattern of the brain structures, resulting in a more accurate similarity measure in comparison with conventional patch-based approach. This technique can be applied to LR images with both anisotropic and isotropic voxel sizes. Experimental results conducted on brain MRI scans of patients with brain tumors, multiple sclerosis, epilepsy, as well as schizophrenic patients and normal controls show that the proposed method is more accurate, requires fewer computations, and thus is significantly faster than a previous state-of-the-art patch-based technique. We also show how the proposed method may be used to upsample regions of interest drawn on LR images.","Interpolation,
Magnetic resonance imaging,
Image edge detection,
Image reconstruction,
Standards,
Spatial resolution"
Competition of Wireless Providers for Atomic Users,We study a problem where wireless service providers compete for heterogenous wireless users. The users differ in their utility functions as well as in the perceived quality of service of individual providers. We model the interaction of an arbitrary number of providers and users as a two-stage multi-leader-follower game. We prove existence and uniqueness of the subgame perfect Nash equilibrium for a generic channel model and a wide class of users' utility functions. We show that the competition of resource providers leads to a globally optimal outcome under mild technical conditions. Most users will purchase the resource from only one provider at the unique subgame perfect equilibrium. The number of users who connect to multiple providers at the equilibrium is always smaller than the number of providers. We also present a decentralized algorithm that globally converges to the unique system equilibrium with only local information under mild conditions on the update rates.,
Designing and Managing Data centers Powered by Renewable Energy,"On-site renewable energy has the potential to reduce datacenters' carbon footprint and power and energy costs. The authors built Parasol, a solar-powered datacenter, and GreenSwitch, a system for scheduling workloads, to explore this potential in a controlled research setting.","Green products,
Batteries,
Data centers,
Solar energy,
Renewable energy sources,
Computer science,
Computer architecture"
Linguistic Prototypes for Data From Eldercare Residents,"We present a model for the analysis of time series sensor data collected at an eldercare facility. The sensors measure restlessness in bed and bedroom motion of residents during the night. Our model builds sets of linguistic summaries from the sensor data that describe different events that may occur each night. A dissimilarity measure produces a distance matrix D between selected sets of summaries. Visual examination of the image of a reordered version of D provides an estimate for the number of clusters to seek in D. Then, clustering with single linkage or non-Euclidean relational fuzzy c-means produces groups of summaries. Subsequently, each group is represented by a linguistic medoid prototype. The prototypes can be used for resident monitoring, two types of anomaly detection, and interresident comparisons. We illustrate our model with real data for two residents collected at TigerPlace: the “aging in place” facility in Columbia, MO, USA.","Pragmatics,
Prototypes,
Monitoring,
Biomedical monitoring,
Time series analysis,
Visualization,
Medical services"
A Markov Random Field Groupwise Registration Framework for Face Recognition,"In this paper, we propose a new framework for tackling face recognition problem. The face recognition problem is formulated as groupwise deformable image registration and feature matching problem. The main contributions of the proposed method lie in the following aspects: (1) Each pixel in a facial image is represented by an anatomical signature obtained from its corresponding most salient scale local region determined by the survival exponential entropy (SEE) information theoretic measure. (2) Based on the anatomical signature calculated from each pixel, a novel Markov random field based groupwise registration framework is proposed to formulate the face recognition problem as a feature guided deformable image registration problem. The similarity between different facial images are measured on the nonlinear Riemannian manifold based on the deformable transformations. (3) The proposed method does not suffer from the generalizability problem which exists commonly in learning based algorithms. The proposed method has been extensively evaluated on four publicly available databases: FERET, CAS-PEAL-R1, FRGC ver 2.0, and the LFW. It is also compared with several state-of-the-art face recognition approaches, and experimental results demonstrate that the proposed method consistently achieves the highest recognition rates among all the methods under comparison.",
A Planar Wideband Dual-Polarized Array for Active Antenna System,"A ±45° polarized wideband slot array antenna is proposed for active antenna system (AAS). The proposed array has a planar structure that integrates all the elements on a single substrate. Metal columns are used to reduce the coupling between adjacent elements. A prototype of a 2 × 2 array antenna is fabricated and measured. The measured results show that the proposed array covers the bands LTE2300 (2300-2400 MHz) and LTE2500 (2500-2690 MHz), and the polarization isolation is higher than 30 dB while the coupling between elements is less than -22 dB.","Arrays,
Antenna arrays,
Couplings,
Metals,
Antenna measurements,
Ports (Computers)"
KEEP: Fast secret key extraction protocol for D2D communication,"Device to device (D2D) communication is expected to become a promising technology of the next-generation wireless communication systems. Security issues have become technical barriers of D2D communication due to its “open-air” nature and lack of centralized control. Generating symmetric keys individually on different communication parties without key exchange or distribution is desirable but challenging. Recent work has proposed to extract keys from the measurement of physical layer random variations of a wireless channel, e.g., the channel state information (CSI) from orthogonal frequency-division multiplexing (OFDM). Existing CSI-based key extraction methods usually use the measurement results of individual subcarriers. However, our real world experiment results show that CSI measurements from near-by subcarriers have strong correlations and a generated key may have a large proportion of repeated bit segments. Hence attackers may crack the key in a relatively short time and hence reduce the security level of the generated keys. In this work, we propose a fast secret key extraction protocol, called KEEP. KEEP uses a validation-recombination mechanism to obtain consistent secret keys from CSI measurements of all subcarriers. It achieves high security level of the keys and fast key-generation rate. We implement KEEP using off-the-shelf 802.11n devices and evaluate its performance via extensive experiments. Both theoretical analysis and experimental results demonstrate that KEEP is safer and more effective than the state-of-the-art approaches.","Quality of service,
Cryptography,
Educational institutions,
Wireless communication,
Data mining,
Linux,
Optical design"
Social based throwbox placement in large-scale throwbox-assisted Delay Tolerant Networks,"Recent advances in Delay Tolerant Networks (DTNs) allow delivering packets among mobile devices via opportunistic communications during intermittent contacts. However, the lack of rich contact opportunities still causes poor delivery ratio and long delay of DTN routing, especially for large-scale networks. Deployment of additional stationary throwboxes can create a greater number of contact opportunities, thus improve the performance of DTN routing. However, the locations of deployed throwboxes are critical to such improvement. In this paper, we investigate where to deploy throwboxes in a large-scale throwbox-assisted DTN. By leveraging the social properties discovered from real-life tracing data, we propose a set of social-based throwbox placement algorithms which smartly pick the location of each throwbox. Extensive simulations are conducted with a real-life wireless tracing dataset and a wide range of existing DTN routing methods. The results confirm the efficiency of the proposed methods.","Mobile communication,
Routing,
Delays,
Poles and towers,
Mobile computing,
Wireless communication"
Camera Selection for Adaptive Human-Computer Interface,"Video analytics has become a very important topic in computer vision. This paper introduces advanced video analytics human-computer interfaces for a video surveillance system to ease the tasks of security operators. The visualization of the most relevant views is provided by the human-computer interface module that preemptively activates cameras that will probably cover the motion of interesting objects. Human-computer interaction principles have been considered to develop the novel user interface. Four prototypes have been designed and usability performance has been evaluated, exploiting standard methods. Results obtained from such evaluations show the efficiency of the novel information visualization technique.","Cameras,
Trajectory,
Human computer interaction,
Streaming media,
Organizations,
Video surveillance"
Far-Field Prediction Using Only Magnetic Near-Field Scanning for EMI Test,"Far-field prediction for electromagnetic interference (EMI) testing is achieved using only magnetic near-field on a Huygens's surface. The electrical field on the Huygens's surface is calculated from the magnetic near-field using the finite element method (FEM). Two examples are used to verify the proposed method. The first example uses the field radiated by an infinitesimal electric dipole. The calculated results are compared with the analytical solution. In the second example, the calculated results are compared with full-wave simulation results for the radiation of a print circuit board (PCB). The validity of this method when the near-field is high-impedance field is verified as well. Sensitivity of the far field to noise in both magnitude and phase in the near-field data is also investigated. The results indicate that the proposed method is very robust to the random variation of both. The effect of using only four sides of the Huygens's box is investigated as well, revealing that, in some instances, the incomplete Huygens's box can be used to predict the far field well. The proposed method is validated using near-field measurement data taken from a sleeve dipole antenna. The error for the maximum far-field value is in only 1.3 dB.","Noise measurement,
Electromagnetic interference,
Finite element analysis,
Magnetic resonance imaging,
Surface impedance"
Verification of Code Motion Techniques Using Value Propagation,"An equivalence checking method of finite state machines with datapath based on value propagation over model paths is presented here for validation of code motion transformations commonly applied during the scheduling phase of high-level synthesis. Unlike many other reported techniques, the method is able to handle code motions across loop bodies. It consists in propagating the variable values over a path to the subsequent paths on discovery of mismatch in the values for some live variable, until the values match or the final path segments are accounted for without finding a match. Checking loop invariance of the values being propagated beyond the loops has been identified to play an important role. Along with uniform and nonuniform code motions, the method is capable of handling control structure modifications as well. The complexity analysis depicts identical worst case performance as that of a related earlier method of path extension which fails to handle code motion across loops. The method has been implemented and satisfactorily tested on the outputs of a basic block-based scheduler, a path-based scheduler, and the high-level synthesis tool SPARK for some benchmark examples.","Vectors,
Motion segmentation,
Computational modeling,
Complexity theory,
Integrated circuit modeling,
Sparks,
Benchmark testing"
System Light-Loading Technology for mHealth: Manifold-Learning-Based Medical Data Cleansing and Clinical Trials in WE-CARE Project,"Cardiovascular disease (CVD) is a major issue to public health. It contributes 41% to the Chinese death rate each year. This huge loss encouraged us to develop a Wearable Efficient teleCARdiology systEm (WE-CARE) for early warning and prevention of CVD risks in real time. WE-CARE is expected to work 24/7 online for mobile health (mHealth) applications. Unfortunately, this purpose is often disrupted in system experiments and clinical trials, even if related enabling technologies work properly. This phenomenon is rooted in the overload issue of complex Electrocardiogram (ECG) data in terms of system integration. In this study, our main objective is to get a system light-loading technology to enable mHealth with a benchmarked ECG anomaly recognition rate. To achieve this objective, we propose an approach to purify clinical features from ECG raw data based on manifold learning, called the Manifold-based ECG-feature Purification algorithm. Our clinical trials verify that our proposal can detect anomalies with a recognition rate of up to 94% which is highly valuable in daily public health-risk alert applications based on clinical criteria. Most importantly, the experiment results demonstrate that the WE-CARE system enabled by our proposal can enhance system reliability by at least two times and reduce false negative rates to 0.76%, and extend the battery life by 40.54%, in the system integration level.","Electrocardiography,
Manifolds,
Mobile communication,
Proposals,
Wireless communication,
Clinical trials,
Real-time systems"
A Study on Low Resolution Androgenic Hair Patterns for Criminal and Victim Identification,"Identifying criminals and victims in images (e.g., child pornography and masked gunmen) can be a challenging task, especially when neither their faces nor tattoos are observable. Skin mark patterns and blood vessel patterns are recently proposed to address this problem. However, they are invisible in low-resolution images and dense androgenic hair can cover them completely. Medical research results have implied that androgenic hair patterns are a stable biometric trait and have potential to overcome the weaknesses of skin mark patterns and blood vessel patterns. To the best of our knowledge, no one has studied androgenic hair patterns for criminal and victim identification before. This paper aims to study matching performance of androgenic hair patterns in low-resolution images. An algorithm designed for this paper uses Gabor filters to compute orientation fields of androgenic hair patterns, histograms on a dynamic grid system to describe their local orientation fields, and the blockwise Chi-square distance to measure the dissimilarity between two patterns. The 4552 images from 283 different legs with resolutions of 25, 18.75, 12.5, and 6.25 dpi were examined. The experimental results indicate that androgenic hair patterns even in low-resolution images are an effective biometric trait and the proposed Gabor orientation histograms are comparable with other well-known texture recognition methods, including local binary patterns, local Gabor binary patterns, and histograms of oriented gradients.","Hair,
Image resolution,
Biomedical imaging,
Legged locomotion,
Skin,
Blood vessels,
Forensics"
People as a Service: A Mobile-centric Model for Providing Collective Sociological Profiles,"Researchers from sociological disciplines could greatly benefit from collective information from the many people who use mobile devices to communicate via various social apps and services. However, processing that information is difficult because it's scattered among numerous social platforms. Furthermore, users are becoming increasingly concerned about how and by whom their information is being accessed. A new mobile-centric computing model allows sociological profiles of people to be generated, kept, and securely provided to third parties as a service. With this model, device owners can be fully aware and in control of how their information is accessed, while still contributing to collective sociological information.","Mobile handsets,
Computational modeling,
Computer architecture,
Next generation networking,
Mobile communication,
Mobile computing,
Sociology"
Fast Motion Estimation Based on Confidence Interval,"A new video standard called High Efficiency Video Coding (HEVC) has been recently finalized. In comparison with the H.264/AVC video coding standard, HEVC further improves the video coding rate distortion (RD) performance, but at the price of significant increase in its encoding complexity, especially in its motion estimation (ME) due to large block sizes and complicated block partition. To reduce the ME complexity in HEVC while maintaining its RD performance, in this paper we first formulate ME at the integer pixel level as a statistical inference problem and then propose a confidence interval-based ME (CIME) method. The proposed CIME method can be applied either on top of the existing fast search implemented in HEVC or on its own to replace the existing fast search implemented in HEVC. Experiments show that for the low-delay main test configuration of HEVC: 1) when applied on top of the existing fast search in HEVC, the proposed CIME method further reduces, on average, the integer-level ME time by 70% with only 1.0% increase in bit rate while maintaining the same reconstruction quality in PSNR and 2) when applied on its own to replace the existing fast search implemented in HEVC, the proposed CIME method achieves performance comparable with that of the fast search in HEVC reference software and better than that of the dynamic system fast algorithm proposed recently in the literature.","Video coding,
Complexity theory,
Noise,
Encoding,
Gaussian distribution,
Motion estimation,
Standards"
Localization Based on Adaptive Regulated Neighborhood Distance for Wireless Sensor Networks With a General Radio Propagation Model,"Many range-free localization algorithms estimate the distance in between two nodes based on the hop-count information, which, however, is a coarse proximity measure. Recently, the regulated neighborhood distance (RND) has been proposed as a new proximity measure, and can greatly improve the localization accuracy, compared with those hop-count-based algorithms. However, the RND algorithm and most previous hop-based approaches are based on the disk communication model, and cannot be directly applied into the practical world with some general radio propagation model. In this paper, we revisit the RND-based localization with a general propagation model, where the received transmission power is modeled as a random variable and its expectation is a nonincreasing function of the distance between a transmitter and receiver pair. In particular, we define the neighborhood based on the packet reception ratio (PRR), and propose an optimal PRR threshold selection algorithm to adaptively adjust the RND-based distance estimation. We verify the effectiveness of the adaptive RND-based localization for the log-normal shadowing model and a polynomial fitting model from our field experiments. Simulation results show that the adaptive selection of the best PRR threshold helps to improve localization accuracy. Furthermore, the proposed adaptive RND-based localization can achieve higher localization accuracy, compared with the classical DV-hop localization with the same network configurations.",
Histogram Equalization for Image Enhancement Using MRI Brain Images,"Medical image processing plays an essential role in providing information in wide area for such advanced images. Magnetic resonance imaging (MRI) is an advanced medical imaging technique providing rich information about the human soft tissue anatomy. MRI of the brain is an invaluable tool to help physicians to diagnose and treat various brain diseases including stroke, cancer, and epilepsy. The specific information to evaluate the diseases. Histogram equalization is one of the important steps in image enhancement technique for MRI. There are several methods of image enhancement and each of them is needed for a different type of analysis. In this paper study and compare different Techniques like Global Histogram Equalization (GHE), Local histogram equalization (LHE), Brightness preserving Dynamic Histogram equalization (BPDHE) and Adaptive Histogram Equalization (AHE) using different objective quality measures for MRI brain image Enhancement.","Histograms,
Magnetic resonance imaging,
Adaptive equalizers,
Brain,
Image enhancement,
Brightness,
Computer science"
DEM Corrections Before Unwrapping in a Small Baseline Strategy for InSAR Time Series Analysis,"Synthetic aperture radar interferometry (InSAR) is limited by temporal decorrelation and topographic errors, which can result in unwrapping errors in partially incoherent and mountainous areas. In this paper, we present an algorithm to estimate and remove local digital elevation model (DEM) errors from a series of wrapped interferograms. The method is designed to be included in a small baseline subset (SBAS) approach for InSAR time series analysis of ground deformation in natural environment. It is easy to implement and can be applied to all pixels of a radar scene. The algorithm is applied to a series of wrapped interferograms computed from ENVISAT radar images acquired across the Himalayan mountain range. The DEM error correction performance is quantified by the reduction of the local phase dispersion and of the number of residues computed during the unwrapping procedure. It thus improves the automation of the spatial unwrapping step.","Coherence,
Synthetic aperture radar,
Remote sensing,
Decorrelation,
Time series analysis,
Algorithm design and analysis"
A Photonic Temporal Integrator With an Ultra-Long Integration Time Window Based on an InP-InGaAsP Integrated Ring Resonator,"A photonic temporal integrator with an ultra-wide integration time window implemented based on a photonic integrated circuit (PIC) in an InP-InGaAsP material system consisting of semiconductor optical amplifiers (SOAs) and current-injection phase modulators (PMs) is proposed and experimentally demonstrated. The proposed photonic integrated integrator employs a ring structure coupled with two bypass waveguides. The tunable coupling between the ring and the waveguides is realized by a multi-mode interference (MMI) Mach-Zehnder interferometer coupler. Within the ring, two SOAs are incorporated to compensate for the insertion loss. In addition, there is a current injection PM in the ring for wavelength tuning. The use of the device provides a photonic temporal integrator with an ultra-wide integration time window and a tunable operation wavelength in a single PIC. The proposed integrator is fabricated and experimentally verified. The integration time window as wide as 6331 ps is achieved, which is an order of magnitude longer than that provided by the previously reported photonic integrators.",
The Playtime Principle: Large-scale cross-games interest modeling,"The collection and analysis of behavioral telemetry in digital games has in the past five years become an integral part of game development. One of the key challenges in game analytics is the development of methods for characterizing and predicting player behavior as it evolves over time. Characterizing behavior is necessary for monitoring player populations and gradually improve game design and the playing experience. Predicting behavior is necessary to describe player engagement and prevent future player churn. In this paper, methods and theory from kernel archetype analysis and random process models are utilized to evaluate the playtime behavior, i.e. time spent playing specific games as a function of time, of over 6 million players, across more than 3000 PC and console games from the Steam platform, covering a combined playtime of more than 5 billion hours. A number of conclusions can be derived from this large-scale analysis, notably that playtime as a function of time, across the thousands of games in the dataset, and irrespective of local differences in the playtime frequency distribution, can be modeled using the same model: the Weibull distribution. This suggests that there are fundamental properties governing player engagement as it evolves over time, which we here refer to as the Playtime Principle. Additionally, the analysis shows that there are distinct clusters, or archetypes, in the playtime frequency distributions of the investigated games. These archetypal groups correspond to specific playtime distributions. Finally, the analysis reveals information about player behavior across a very large dataset, showing for example that the vast majority of games are players for less than 10 hours, and very few players spend more than 30-35 hours on any specific game.",Games
High-Frequency Oscillations Recorded on the Scalp of Patients With Epilepsy Using Tripolar Concentric Ring Electrodes,"Epilepsy is the second most prevalent neurological disorder (~1% prevalence) affecting ~67 million people worldwide with up to 75% from developing countries. The conventional electroencephalogram is plagued with artifacts from movements, muscles, and other sources. Tripolar concentric ring electrodes automatically attenuate muscle artifacts and provide improved signal quality. We performed basic experiments in healthy humans to show that tripolar concentric ring electrodes can indeed record the physiological alpha waves while eyes are closed. We then conducted concurrent recordings with conventional disc electrodes and tripolar concentric ring electrodes from patients with epilepsy. We found that we could detect high frequency oscillations, a marker for early seizure development and epileptogenic zone, on the scalp surface that appeared to become more narrow-band just prior to seizures. High frequency oscillations preceding seizures were present in an average of 35.5% of tripolar concentric ring electrode data channels for all the patients with epilepsy whose seizures were recorded and absent in the corresponding conventional disc electrode data. An average of 78.2% of channels that contained high frequency oscillations were within the seizure onset or irritative zones determined independently by three epileptologists based on conventional disc electrode data and videos.","Electrodes,
Electroencephalography,
Epilepsy,
Hafnium compounds,
Scalp,
Oscillators,
Educational institutions"
Robust MEMS Gyroscope Based on Thermal Principles,"Two variants of a novel single-axis thermal gyroscope without seismic mass are designed, fabricated, and characterized in this paper. The operating principle of the device is differential temperature detection due to the Coriolis effect on an oscillatory gas stream created by alternating two resistive microheaters. The fabrication process is based on a bulk micromachining technology on a silicon substrate using platinum as the only conductor layer. The device structure consists of two resistive temperature detectors equally spaced from the two microheaters. The 170-nm-thick platinum heater and detector microstructures are freely suspended over a cavity etched into the substrate, with minimal structural support. A computer-controlled precision rotary stage is constructed to accurately measure the device performance. The devices demonstrate excellent linearity within the tested ±3.5 revolution per second angular rate of rotation and show sensitivities of 0.947 and 1.287 mV/ °/s at 20 mW heater powers. The robustness of the devices has been validated by the drop shocks of 2,722 to 16,398g (9.81 m/s2).","Temperature measurement,
Acceleration,
Gyroscopes,
Heating,
Detectors,
Force,
Micromechanical devices"
Protein Function Prediction with Incomplete Annotations,"Automated protein function prediction is one of the grand challenges in computational biology. Multi-label learning is widely used to predict functions of proteins. Most of multi-label learning methods make prediction for unlabeled proteins under the assumption that the labeled proteins are completely annotated, i.e., without any missing functions. However, in practice, we may have a subset of the ground-truth functions for a protein, and whether the protein has other functions is unknown. To predict protein functions with incomplete annotations, we propose a Protein Function Prediction method with Weak-label Learning (ProWL) and its variant ProWL-IF. Both ProWL and ProWL-IF can replenish the missing functions of proteins. In addition, ProWL-IF makes use of the knowledge that a protein cannot have certain functions, which can further boost the performance of protein function prediction. Our experimental results on protein-protein interaction networks and gene expression benchmarks validate the effectiveness of both ProWL and ProWL-IF.","Proteins,
Correlation,
Training,
Computational biology,
Bioinformatics"
Cupid: Cluster-Based Exploration of Geometry Generators with Parallel Coordinates and Radial Trees,"Geometry generators are commonly used in video games and evaluation systems for computer vision to create geometric shapes such as terrains, vegetation or airplanes. The parameters of the generator are often sampled automatically which can lead to many similar or unwanted geometric shapes. In this paper, we propose a novel visual exploration approach that combines the abstract parameter space of the geometry generator with the resulting 3D shapes in a composite visualization. Similar geometric shapes are first grouped using hierarchical clustering and then nested within an illustrative parallel coordinates visualization. This helps the user to study the sensitivity of the generator with respect to its parameter space and to identify invalid parameter settings. Starting from a compact overview representation, the user can iteratively drill-down into local shape differences by clicking on the respective clusters. Additionally, a linked radial tree gives an overview of the cluster hierarchy and enables the user to manually split or merge clusters. We evaluate our approach by exploring the parameter space of a cup generator and provide feedback from domain experts.","Shape analysis,
Three-dimensional displays,
Video games,
Games,
Computer vision,
Data visualization"
PSaD: A Privacy-Preserving Social-Assisted Content Dissemination Scheme in DTNs,"Content dissemination is very useful for many mobile applications, like instant messaging, file sharing, and advertisement broadcast, etc. In real life, for various kinds of time-insensitive contents, such as family photos and video clips, the process of content dissemination forms a delay tolerant networks (DTNs). To improve the data forwarding performance in DTNs, several social-based approaches have been proposed, most of which leverage mobile users' social information, including contact history, moving trajectory, and personal profiles as metrics to design routing schemes. However, although the social-based approaches provide better performance, the revealing of mobile users' information apparently compromises their privacy. Moreover, users' contents may only be shared with a particular group of users rather everyone in the system. In this paper, we propose the PSaD: a Privacy-preserving Social-assisted content Dissemination scheme in DTNs. We apply users' verifiable attributes to establish their social relationships in terms of identical attributes in a privacy-preserving way. Besides, to provide the confidentiality of contents, our approach enables users to encrypt contents before the dissemination process, and only allows users who have particular attributes to decrypt them. By trace-driven simulations and experiments, we show the performance, privacy preservation, and efficiency of our proposed scheme.","Privacy,
Mobile communication,
Routing,
Information retrieval,
Social network services,
Encryption,
Fault tolerance,
Social network services"
Collective Learning for the Emergence of Social Norms in Networked Multiagent Systems,"Social norms such as social rules and conventions play a pivotal role in sustaining system order by regulating and controlling individual behaviors toward a global consensus in large-scale distributed systems. Systematic studies of efficient mechanisms that can facilitate the emergence of social norms enable us to build and design robust distributed systems, such as electronic institutions and norm-governed sensor networks. This paper studies the emergence of social norms via learning from repeated local interactions in networked multiagent systems. A collective learning framework, which imitates the opinion aggregation process in human decision making, is proposed to study the impact of agent local collective behaviors on the emergence of social norms in a number of different situations. In the framework, each agent interacts repeatedly with all of its neighbors. At each step, an agent first takes a best-response action toward each of its neighbors and then combines all of these actions into a final action using ensemble learning methods. Extensive experiments are carried out to evaluate the framework with respect to different network topologies, learning strategies, numbers of actions, influences of nonlearning agents, and so on. Experimental results reveal some significant insights into the manipulation and control of norm emergence in networked multiagent systems achieved through local collective behaviors.",
Reputation-based sensing-as-a-service for crowd management over the cloud,"Cloud computing model can enable provisioning of sensing services through mobile phones, namely Sensing-as-a-Service (S2aaS). In this paper, we study S2aaS over social networking services for crowd management problem where malicious users report false sensor readings leading to severe disinformation at the crowd control platform. To this end, we propose Trustworthy Sensing for Crowd Management (TSCM) which is a reputation-based crowd management scheme over the cloud platform where sensing data is collected from smart phones based on an auction mechanism. TSCM periodically runs an auction in order to assign dynamically arriving sensing task requests to the smart phone users forming a crowd connected through a social network. User bids, task values and user reputation values are taken as the inputs whereas the outputs are the utility of the crowd management platform and the average utility per user while reputation of a user is a function of the accuracy of the sensed data. Through simulations, we show that TSCM significantly improves the platform utility while degrading the ratio of the maliciously crowdsourced task by 75%. Furthermore, we also show that under TSCM, reputation of malicious users converge to a low value at the order of 40% following a few auctions.","Sensors,
Social network services,
Smart phones,
Cloud computing,
Databases,
Publishing,
Clouds"
Image Denoising With 2D Scale-Mixing Complex Wavelet Transforms,"This paper introduces an image denoising procedure based on a 2D scale-mixing complex-valued wavelet transform. Both the minimal (unitary) and redundant (maximum overlap) versions of the transform are used. The covariance structure of white noise in wavelet domain is established. Estimation is performed via empirical Bayesian techniques, including versions that preserve the phase of the complex-valued wavelet coefficients and those that do not. The new procedure exhibits excellent quantitative and visual performance, which is demonstrated by simulation on standard test images.","Discrete wavelet transforms,
Wavelet domain,
Bayes methods,
Covariance matrices,
Noise"
Quo Vadis CAVE: Does Immersive Visualization Still Matter?,"Over 10 years' experience with VR displays, visualization applications, and informal feedback from scientists using these applications has convinced RWTH Aachen University researchers that the combination of full immersion, high image quality, and advanced interaction metaphors makes immersive visualization valuable as an analysis tool in simulation science.","Three-dimensional displays,
Data visualization,
Navigation,
Brightness,
Brain modeling,
Feedback,
Virtual environments"
ClubCF: A Clustering-Based Collaborative Filtering Approach for Big Data Application,"Spurred by service computing and cloud computing, an increasing number of services are emerging on the Internet. As a result, service-relevant data become too big to be effectively processed by traditional approaches. In view of this challenge, a clustering-based collaborative filtering approach is proposed in this paper, which aims at recruiting similar services in the same clusters to recommend services collaboratively. Technically, this approach is enacted around two stages. In the first stage, the available services are divided into small-scale clusters, in logic, for further processing. At the second stage, a collaborative filtering algorithm is imposed on one of the clusters. Since the number of the services in a cluster is much less than the total number of the services available on the web, it is expected to reduce the online execution time of collaborative filtering. At last, several experiments are conducted to verify the availability of the approach, on a real data set of 6225 mashup services collected from ProgrammableWeb.","Cloud computing,
Filtering,
Mashups,
Clustering algorithms,
Information management,
Data handling,
Data storage systems"
Weighted localization in Vehicular Ad Hoc Networks using vehicle-to-vehicle communication,"Vehicular Ad Hoc Networks (VANETs) have attracted the interest of many researchers all over the world. With advances in technologies in wireless networks, vehicles will be able to communicate with each other and roadside units (RSU), to exchange road and traffic information. VANET and many other applications demand a real-time, accurate position of a vehicle; highlighting the importance of accurate localization. A number of methods and protocols have been proposed to fulfill this requirement, However, they have not attained high location accuracy required for VANET safety applications. We propose two new localization methods that assist vehicles in estimating their positions: 1) weighted localization (WL) using signal to interference-noise ratio (SINR) obtained from the exchange messages, and 2) weighted localization using SINR and distance between the neighboring vehicles (WLD). Our methods expand the concept of centroid localization (CL) by assigning a weight to each of the neighboring vehicles' coordinates, based on SINR values and the distance. We develop a simulation program to evaluate our methods against CL and relative span weighted localization (RWL). Our simulation results show that WLD demonstrates a better performance with less average location errors than CL and RWL in varying of densities.","Vehicles,
Interference,
Signal to noise ratio,
Vehicular ad hoc networks,
Accuracy,
Equations,
Mathematical model"
Smart meters with TV gray spaces connectivity: A feasibility study for two reference network topologies,"With an increasing demand for monitoring energy consumption at granularity levels down to single household appliances, it is necessary to develop new means to collect sensor measurements in a robust and cost-efficient manner. The smart grid paradigm foresees using wireless links for data transfer, albeit no dedicated spectrum bands have been designated for this purpose. In this paper we study the feasibility of opportunistic spectrum access for smart grids, and focus on underlay spectrum sharing over occupied TV channels. These frequency bands, which are commonly denoted as TV gray spaces, provide superior propagation characteristics, but are locally used by high-power (mostly DTV) broadcasting transmitters. For selected reference geometries of intra-meter and meter-to-operator communications, we study the smart meter performance (in terms of achievable throughput and transmission range), and the necessary power limits. We compare our results from a small-scale measurement campaigns against existing wireless technologies for low-power communications in other adjacent bands. Our results show that wall shielding and fading in indoor to outdoor propagation channels sufficiently protects the primary system from the interference introduced by gray space meter-to-meter communications, but that the required transmit powers to send operations data from indoor meters to outdoor collection point severely limit the applicability of TV gray spaces for such network topologies.","Buildings,
Smart meters,
Digital TV,
Interference,
Transmitters,
Network topology,
Receivers"
EasiSee: Real-Time Vehicle Classification and Counting via Low-Cost Collaborative Sensing,"In the field of traffic-information acquisition, one pervasive solution is to use wireless sensor networks (WSNs) to realize vehicle classification and counting. By adopting heterogeneous sensors in a WSN, we can explore the potential of using complementary physical information to perform more complicated sensing computation. However, the collaboration among heterogeneous sensors, such as the collaborative sensing mechanism (CSM), is not well studied in current state-of-the-art research. In this paper, we design and implement EasiSee, a real-time vehicle classification and counting system based on WSNs. Our contributions are as follows. First, we propose a CSM, which coordinates the power-hungry camera sensor and the power-efficient magnetic sensors, reducing the overall system energy consumption and maximizing system lifetime. Second, we propose a robust vehicle image-processing algorithm, i.e., a low-cost image processing algorithm (LIPA). LIPA reduces environment noise and interference with low computation complexity. In the verification section, the vehicle detection accuracy turned out to be 95.31%, which pave the way for CSM. The time of image processing is around 200 ms, which indicates that our LIPA is computationally economical. With the overall energy consumption reduced, EasiSee achieves classification accuracy of 93%. Based on these experiments and analysis, we conclude that EasiSee is a practical and low-cost affordable solution for traffic-information acquisition.","Vehicles,
Cameras,
Magnetic sensors,
Image sensors,
Wireless sensor networks,
Vehicle detection"
Decentralized Model Predictive Control for Wave Energy Converter Arrays,"Most of the research on wave energy conversion has been focused on the characterization of the dynamic behavior of arrays of uncontrolled wave energy converters (WECs) in specific configurations, in order to quantify changes in the wave fields and absorbed power without active control. To maximize wave energy conversion, however, it is necessary to apply active control techniques to the WECs that conform the array. In this paper, we propose the application of decentralized model predictive control (MPC) to the elements of an array by considering each individual WEC as a subsystem. Each decentralized MPC optimizes the absorbed power of its own WEC under the same input and state constraints that a centralized MPC otherwise would.","Hydrodynamics,
Mathematical model,
Predictive control,
Surface waves,
Wave power,
Decentralized control"
Spatial Statistics of Image Features for Performance Comparison,"When matching images for applications such as mosaicking and homography estimation, the distribution of features across the overlap region affects the accuracy of the result. This paper uses the spatial statistics of these features, measured by Ripley's K-function, to assess whether feature matches are clustered together or spread around the overlap region. A comparison of the performances of a dozen state-of-the-art feature detectors is then carried out using analysis of variance and a large image database. Results show that SFOP introduces significantly less aggregation than the other detectors tested. When the detectors are rank-ordered by this performance measure, the order is broadly similar to those obtained by other means, suggesting that the ordering reflects genuine performance differences. Experiments on stitching images into mosaics confirm that better coverage values yield better quality outputs.","Feature extraction,
Detectors,
Performance evaluation,
Robustness,
Image processing,
Algorithm design and analysis,
Spatial analysis"
Evolutionary-Algorithm-Assisted Joint Channel Estimation and Turbo Multiuser Detection/Decoding for OFDM/SDMA,"The development of evolutionary algorithms (EAs), such as genetic algorithms (GAs), repeated weighted boosting search (RWBS), particle swarm optimization (PSO), and differential evolution algorithms (DEAs), have stimulated wide interests in the communication research community. However, the quantitative performance-versus-complexity comparison of GA, RWBS, PSO, and DEA techniques applied to the joint channel estimation (CE) and turbo multiuser detection (MUD)/decoding in the context of orthogonal frequency-division multiplexing/space-division multiple-access systems is a challenging problem, which has to consider both the CE problem formulated over a continuous search space and the MUD optimization problem defined over a discrete search space. We investigate the capability of the GA, RWBS, PSO, and DEA to achieve optimal solutions at an affordable complexity in this challenging application. Our study demonstrates that the EA-assisted joint CE and turbo MUD/decoder is capable of approaching both the Cramér-Rao lower bound of the optimal CE and the bit error ratio (BER) performance of the idealized optimal maximum-likelihood (ML) turbo MUD/decoder associated with perfect channel state information, respectively, despite imposing only a fraction of the idealized turbo ML-MUD/decoder's complexity.","Multiuser detection,
OFDM,
Optimization,
Joints,
Decoding,
Iterative decoding,
Channel estimation"
Toward robust control of minimally rigid undirected formations,"Gradient control is a method based on potential functions to locally stabilize rigid undirected formations. However, when there is a mismatch in two neighboring agents' understandings of what the target distance between them is supposed to be, such a potential-based control will typically cause a rigid undirected formation to rotate in the plane. This paper investigates an appropriate modification of the gradient control, which eliminates this rotation and locally stabilizes the triangular formation with no restriction on the number of mismatches and any minimally rigid formation consisting of four or more agents with only one mismatch.","Decentralized control,
Nickel,
Sun,
Autonomous agents,
Vectors,
Extraterrestrial measurements,
Silicon"
Control of a Novel 2-DoF MEMS Nanopositioner With Electrothermal Actuation and Sensing,"This paper presents the full characterization, modeling, and control of a 2-degrees-of-freedom microelectromechanical systems (MEMS) nanopositioner with fully integrated electrothermal actuators and sensors. Made from nickel Z-shaped beams, the actuators are able to move the device's stage in positive and negative directions (contrary to classical V-shaped electrothermal actuators) and along two axes (x and y). The integrated electrothermal sensors are based on polysilicon resistors, which are heated via Joule heating due to an applied electrical bias voltage. The stage displacement is effectively measured by variations in their resistance, which is dependent on the position of the stage. The characterization tests carried out show that the MEMS nanopositioner can achieve a range of displacement in excess of ±5 μm for each of the x and y axes, with a response time better than 300 ms. A control scheme based on the combination of feedforward and internal model control-feedback is constructed to enhance the general performance of the MEMS device, and in particular to reject the cross-coupling between the two axes and to enhance the accuracy and the response time. The experimental results demonstrate the efficiency of the proposed scheme and demonstrate the suitability of the designed device for nanopositioning applications.","Nanopositioning,
Micromechanical devices,
Actuators,
Heating,
Sensor phenomena and characterization,
Feedforward neural networks"
MEMS Rotary Microgripper With Integrated Electrothermal Force Sensor,"A microelectromechanical systems (MEMS) rotary microgripper incorporating electrothermal force sensors is reported. The device is fabricated using a standard SOI-MEMS process and achieves a stroke of (90 μm) m) at a relatively low voltage (<;80 V). The electrothermal force sensor has a small footprint, is quite linear, and operates with a high accuracy. Being fabricated from biocompatible material (silicon) with sufficiently long gripping arms, the gripper can be used to manipulate living cells, tissues, and other biologically relevant samples. A pick-and-place experiment on a soft cell is conducted to verify performance of the proposed rotary microgripper.","Grippers,
Force sensors,
Micromechanical devices,
Force,
Sensitivity,
Temperature measurement"
A Cumulant-Based Method for Direction Finding in Uniform Linear Arrays With Mutual Coupling,"The problem of direction finding in uniform linear arrays (ULAs) with unknown mutual coupling is considered. A new fourth-order cumulant (FOC)-based method for estimating directions of arrivals (DOAs) of far-field signals is developed. In our proposed method, an FOC matrix is first derived. Then, it is shown that the null space of the Khatri-Rao (KR) product of the steering matrices can be obtained via the eigen decomposition of the FOC matrix. Finally, by taking advantage of the banded complex symmetric Toeplitz structure of the mutual coupling matrix (MCM), a determinant-based spatial spectrum is introduced to determine the DOAs. Computer simulations for different signal-to-noise ratios (SNRs) and numbers of snapshots are included to demonstrate the superior performance of the proposed method over its conventional counterpart.","Mutual coupling,
Direction-of-arrival estimation,
Covariance matrices,
Estimation,
Vectors,
Antennas,
Matrix decomposition"
Spatiotemporal Grid Flow for Video Retargeting,"Video retargeting is a useful technique to adapt a video to a desired display resolution. It aims to preserve the information contained in the original video and the shapes of salient objects while maintaining the temporal coherence of contents in the video. Existing video retargeting schemes achieve temporal coherence via constraining each region/pixel to be deformed consistently with its corresponding region/pixel in neighboring frames. However, these methods often distort the shapes of salient objects, since they do not ensure the content consistency for regions/pixels constrained to be coherently deformed along time axis. In this paper, we propose a video retargeting scheme to simultaneously meet the two requirements. Our method first segments a video clip into spatiotemporal grids called grid flows, where the consistency of the content associated with a grid flow is maintained while retargeting the grid flow. After that, due to the coarse granularity of grid, there still may exist content inconsistency in some grid flows. We exploit the temporal redundancy in a grid flow to avoid that the grids with inconsistent content be incorrectly constrained to be coherently deformed. In particular, we use grid flows to select a set of key-frames which summarize a video clip, and resize subgrid-flows in these key-frames. We then resize the remaining nonkey-frames by simply interpolating their grid contents from the two nearest retargeted key-frames. With the key-frame-based scheme, we only need to solve a small-scale quadratic programming problem to resize subgrid-flows and perform grid interpolation, leading to low computation and memory costs. The experimental results demonstrate the superior performance of our scheme.","Coherence,
Shape,
Educational institutions,
Spatiotemporal phenomena,
Media,
Interpolation,
Quadratic programming"
"A 0.5 {\rm cm}^{3}
Four-Channel 1.1 mW Wireless Biosignal Interface With 20 m Range","This paper presents a self-contained, single-chip biosignal monitoring system with wireless programmability and telemetry interface suitable for mainstream healthcare applications. The system consists of low-noise front end amplifiers, ADC, MICS/ISM transmitter and infrared programming capability to configure the state of the chip. An on-chip packetizer ensures easy pairing with standard off-the-shelf receivers. The chip is realized in the IBM 130 nm CMOS process with an area of 2×2 mm2. The entire system consumes 1.07 mW from a 1.2 V supply. It weighs 0.6 g including a zinc-air battery. The system has been extensively tested in in vivo biological experiments and requires minimal human interaction or calibration.","wireless sensor networks,
biological techniques,
lab-on-a-chip,
telemetry,
wireless channels"
Hybrid Unmanned Aerial Underwater Vehicle: Modeling and simulation,"The complete modeling and simulation of an unmanned vehicle with combined aerial and underwater capabilities, called Hybrid Unmanned Aerial Underwater Vehicle (HUAUV), is presented in this paper. The best architecture for this kind of vehicle was evaluated based on the adaptation of typical platforms for aerial and underwater vehicles, to allow the navigation in both environments. The model selected was based on a quadrotor-like aerial platform, adapted to dive and move underwater. Kinematic and dynamic models are presented here, and the parameters for a small dimension prototype was estimated and simulated. Finally, controllers were used and validated in realistic simulation, including air and water navigation, and the environment transition problem. To the best of our knowledge, it is the first vehicle that is able to navigate in both environment without mechanical adaptation during the medium transitions.","Vehicles,
Propellers,
Underwater vehicles,
Robots,
Navigation,
Force,
Vectors"
Reorienting Driver Attention with Dynamic Tactile Cues,"A series of three experiments was designed to investigate whether the presentation of moving tactile warning signals that are presented in a particular spatiotemporal configuration may be particularly effective in terms of facilitating a driver's response to a target event. In the experiments reported here, participants' visual attention was manipulated such that they were either attending to the frontal object that might occasionally approach them on a collision course, or else they were distracted by a color discrimination task presented from behind. We measured how rapidly participants were able to initiate a braking response to a looming visual target following the onset of vibrotactile warning signals presented from around their waist. The vibrotactile warning signals consisted of single, double, and triple upward moving cues (Experiment 1), triple upward and downward moving cues (Experiment 2), and triple random cues (Experiment 3). The results demonstrated a significant performance advantage following the presentation of dynamic triple cues over the static single tactile cues, regardless of the specific configuration of the triple cues. These findings point to the potential benefits of embedding dynamic information in warning signals for dynamic target events. These findings have important implications for the design of future vibrotactile warning signals.","Vehicles,
Visualization,
Head,
Color,
Vibrations,
Educational institutions,
Image color analysis"
Analytical design procedure for resonant inductively coupled wireless power transfer system with class-DE inverter and class-E rectifier,"This paper presents a resonant inductive coupling wireless power transfer (RIC-WPT) system with a class-DE and class-E rectifier along with its analytical design procedure. By using the class-DE inverter as a transmitter and the class-E rectifier as a receiver, the designed WPT system can achieve a high power-conversion efficiency because of the class-E ZVS/ZDS conditions satisfied in both the inverter and the rectifier. In the simulation results, the system achieved 79.0 % overall efficiency at 5 W (50 Ω) output power, coupling coefficient 0.072, and 1 MHz operating frequency. Additionally, the simulation results showed good agreement with the design specifications, which indicates the validity of the design procedure.",
Robust ladder-climbing with a humanoid robot with application to the DARPA Robotics Challenge,"This paper presents an autonomous planning and control framework for humanoid robots to climb general ladder- and stair-like structures. The approach consists of two major components: 1) a multi-limbed locomotion planner that takes as input a ladder model and automatically generates a whole-body climbing trajectory that satisfies contact, collision, and torque limit constraints; 2) a compliance controller which allows the robot to tolerate errors from sensing, calibration, and execution. Simulations demonstrate that the robot is capable of climbing a wide range of ladders and tolerating disturbances and errors. Physical experiments demonstrate the DRC-Hubo humanoid robot successfully mounting, climbing, and dismounting an industrial ladder similar to the one intended to be used in the DARPA Robotics Challenge Trials.","Joints,
Planning,
Foot,
Collision avoidance,
Robot sensing systems,
Robot kinematics"
Gene Selection Using Locality Sensitive Laplacian Score,"Gene selection based on microarray data, is highly important for classifying tumors accurately. Existing gene selection schemes are mainly based on ranking statistics. From manifold learning standpoint, local geometrical structure is more essential to characterize features compared with global information. In this study, we propose a supervised gene selection method called locality sensitive Laplacian score (LSLS), which incorporates discriminative information into local geometrical structure, by minimizing local within-class information and maximizing local between-class information simultaneously. In addition, variance information is considered in our algorithm framework. Eventually, to find more superior gene subsets, which is significant for biomarker discovery, a two-stage feature selection method that combines the LSLS and wrapper method (sequential forward selection or sequential backward selection) is presented. Experimental results of six publicly available gene expression profile data sets demonstrate the effectiveness of the proposed approach compared with a number of state-of-the-art gene selection methods.","Laplace equations,
Gene expression,
Feature extraction,
Genomics,
Computational biology,
Bioinformatics"
Model Selection and Classification With Multiple Kernel Learning for Hyperspectral Images via Sparsity,"The goal of multiple kernel learning (MKL) is to simultaneously learn a kernel and the associated predictor in task of supervised learning. In this paper, a new sparse MKL (SMKL) algorithm is proposed to simultaneously carry out classification and kernel interpretation on hyperspectral remote sensing images. First, the multiscale Gaussian kernels are adopted as basis kernels, and learning from these basis kernels is then formulated as a problem of maximizing variance projection, which can be solved by singular value decomposition (SVD). A cardinality-based constraint is then involved to control the sparsity of the MKL and selection of the Gaussian kernel scales for improving the interpretability. This cardinality-constrained optimization can be further converted to a convex optimization. The proposed MKL algorithm can achieve a good classification performance by using a linear combination of only a few kernels. The experiments are conducted on three real hyperspectral datasets, and the results prove the effectiveness of the SMKL in terms of classification statistics and computational feasibility, by comparing it with the state-of-the-art MKL algorithms. More important, interpretability of learning model can be preliminary addressed by the proposed SMKL.","Kernel,
Optimization,
Support vector machines,
Hyperspectral imaging,
Vectors"
Towards understanding cyberbullying behavior in a semi-anonymous social network,"Cyberbullying has emerged as an important and growing social problem, wherein people use online social networks and mobile phones to bully victims with offensive text, images, audio and video on a 24/7 basis. This paper studies negative user behavior in the Ask.fm social network, a popular new site that has led to many cases of cyberbullying, some leading to suicidal behavior.We examine the occurrence of negative words in Ask.fm's question+answer profiles along with the social network of “likes” of questions+answers. We also examine properties of users with “cutting” behavior in this social network.","Educational institutions,
Correlation,
Conferences,
Twitter,
Facebook"
Uncontrolled Manifold Analysis of Arm Joint Angle Variability During Robotic Teleoperation and Freehand Movement of Surgeons and Novices,"Teleoperated robot-assisted surgery (RAS) is used to perform a wide variety of minimally invasive procedures. However, current understanding of the effect of robotic manipulation on the motor coordination of surgeons is limited. Recent studies in human motor control suggest that we optimize hand movement stability and task performance while minimizing control effort and improving robustness to unpredicted disturbances. To achieve this, the variability of joint angles and muscle activations is structured to reduce task-relevant variability and increase task-irrelevant variability. In this study, we determine whether teleoperation of a da Vinci Si surgical system in a nonclinical task of simple planar movements changes this structure of variability in experienced surgeons and novices. To answer this question, we employ the UnControlled manifold analysis that partitions users' joint angle variability into task-irrelevant and task-relevant manifolds. We show that experienced surgeons coordinate their joint angles to stabilize hand movements more than novices, and that the effect of teleoperation depends on experience-experts increase teleoperated stabilization relative to freehand whereas novices decrease it. We suggest that examining users' exploitation of the task-irrelevant manifold for stabilization of hand movements may be applied to: (1) evaluation and optimization of teleoperator design and control parameters, and (2) skill assessment and optimization of training in RAS.","Surgery,
Minimally invasive surgery,
Manipulator dynamics,
Redundancy,
Teleoperators"
Energy management system control and experiment for future home,"To enable zero net-energy consumption and optimal power management for future homes or buildings, the dc electric distribution systems (dc nano-grid) finds feasibility and simplicity for integrating multi-type renewable energy sources. However, integrating all the sources and loads in a simple, reliable and smart way is still challenging. This paper introduces a 380V emulator testbed of 10kW, and then proposes a distributed droop control method to integrate all source converters. Control functions in components level and system level will be defined and discussed, and energy storage management and its control law in dc nano-grid is proposed. System level energy management control strategies in a day/24 hours are examined and discussed with considerations of residential load demand profile, local renewable energy source profile and schedules of electricity rate. System level static experiments within 24h are given for verification purposes.","Batteries,
Renewable energy sources,
Discharges (electric),
Electricity,
Voltage control"
Incremental Learning With Selective Memory (ILSM): Towards Fast Prostate Localization for Image Guided Radiotherapy,"Image-guided radiotherapy (IGRT) requires fast and accurate localization of the prostate in 3-D treatment-guided radiotherapy, which is challenging due to low tissue contrast and large anatomical variation across patients. On the other hand, the IGRT workflow involves collecting a series of computed tomography (CT) images from the same patient under treatment. These images contain valuable patient-specific information yet are often neglected by previous works. In this paper, we propose a novel learning framework, namely incremental learning with selective memory (ILSM), to effectively learn the patient-specific appearance characteristics from these patient-specific images. Specifically, starting with a population-based discriminative appearance model, ILSM aims to “personalize” the model to fit patient-specific appearance characteristics. The model is personalized with two steps: backward pruning that discards obsolete population-based knowledge and forward learning that incorporates patient-specific characteristics. By effectively combining the patient-specific characteristics with the general population statistics, the incrementally learned appearance model can localize the prostate of a specific patient much more accurately. This work has three contributions: 1) the proposed incremental learning framework can capture patient-specific characteristics more effectively, compared to traditional learning schemes, such as pure patient-specific learning, population-based learning, and mixture learning with patient-specific and population data; 2) this learning framework does not have any parametric model assumption, hence, allowing the adoption of any discriminative classifier; and 3) using ILSM, we can localize the prostate in treatment CTs accurately (DSC ~ 0.89) and fast ( ~ 4 s), which satisfies the real-world clinical requirements of IGRT.","Computed tomography,
Image segmentation,
Sociology,
Statistics,
Training,
Detectors,
Planning"
Social learning networks: A brief survey,"Social Learning Network (SLN) is a type of social network among students, instructors, and modules of learning. It consists of the dynamics of learning behavior over a variety of graphs representing the relationships among the people and processes involved in learning. Recent innovations in online education, including open online courses at various scales, in flipped classroom instruction, and in professional and corporate training have presented interesting questions about SLN. Collecting, analyzing, and leveraging data about SLN lead to potential answers to these questions, with help from a convergence of modeling languages and design methods, such as social network theory, science of learning, and education information technology. This survey article overviews some of these topics, including prediction, recommendation, and personalization, in this emergent research area.",Accuracy
Novel Feed Network for Circular Polarization Antenna Diversity,"In this letter, we propose a novel feed network for circular polarization (CP) diversity antennas to enhance communications performances. The previous CP diversity systems adopted dual polarization diversity using right-hand circular polarization (RHCP) and left-hand circular polarization (LHCP) within a small space. However, the same rotational CPs need further antenna distance. To overcome the space limitation for the same CP diversity antenna, we propose a feed network for CP antenna using conventional CP with orthogonal polarization radiation characteristics of a linear polarization (LP) diversity system without additional antennas. The port isolation characteristics and impedance matching conditions are numerically verified for the diversity system and antenna characteristics. The proposed feed network with CP patch antennas is fabricated and measured in a reverberation chamber for diversity performances, and their validity is verified.","Ports (Computers),
Antenna feeds,
Antenna measurements,
Polarization,
Diversity reception"
"Salient features of the dual-frequency, dual-polarized, Doppler radar for remote sensing of precipitation","The global precipitation measurement (GPM) mission is an international satellite mission to obtain accurate observations of precipitation on a global scale every 3 h. Its (GPM) core satellite was launched on 27 February 2014 with two science instruments: the microwave imager and the dual-frequency precipitation radar. Ground validation is an integral part of the GPM mission where instruments are deployed to complement and correlate with spacecraft instruments. The dual-frequency, dual-polarization, Doppler radar (D3R) is a critical ground validation instrument that was developed for the GPM program. This paper describes the salient features of the D3R in the context of the GPM ground validation mission. The engineering and architectural overview of the radar is described, and observations from successful GPM ground validation field experiments are presented.","Spaceborne radar,
Antennas,
Doppler radar,
Measurement by laser beam,
Radio transmitters,
Receivers"
A 1/2.5 inch VGA 400 fps CMOS Image Sensor With High Sensitivity for Machine Vision,"Machine vision requires CMOS image sensors (CISs) with high frame rate, short exposure time, and fine spatial resolution. Recently, capacitive transimpedance amplifier (CTIA) is used in the high-speed pixel circuit to achieve high sensitivity by expediting the charge transfer from the photodiode to a tiny integration capacitor ( CINT). Existing CTIA pixel designs have large pixel sizes due to the multiple sampling capacitors and switches for global shutter and CDS, which unfavorably limits the spatial resolution. In this paper, we present a 400 fps CIS design with 640 × 480 pixel array for machine vision. With simplified pixel circuits, the new sensor has a CTIA pixel size of 8.7 × 8.22 μm2, which is the smallest in the category. The pixel implements a new multi-layer MOM capacitor with good uniformity as the tiny CINT, which achieves high sensitivity (36.5 V/lux·s) without calibration. Pixel-wise CDS is implemented in this global-shutter CIS to minimize the pixel noise. The pixel signals are quantized by 640 column processing slices with 12 bit resolution at 411 kS/s. The size of the column SAR ADC is minimized with a simple calibration technique. The CIS is fabricated in a 0.18 μm mixed-signal CMOS process. The temporal noise is 15.6 erms-. With the new MOM capacitor, FPN of the CIS is 0.55% without calibration. The new pixel design achieves the highest sensitivity per unit area.","Capacitors,
Noise,
Sensitivity,
Arrays,
Method of moments,
Calibration,
Photodiodes"
Circularly Polarized S-Band Satellite Antenna With Parasitic Elements and Its Arrays,"A structural modification of S-band turnstile antenna with cylindrical parasitic elements around a main radiator is introduced and investigated with respect to its gain, axial-ratio (AR) beamwidth, and radiation pattern. The overall structure is composed of a main radiator of two crossed bowtie-shaped dipole antennas and a feeding network using a Wilkinson power divider with phase differences between two parts. A final optimization of the parameter values for the enhancement of AR beamwidth is carried out from the parametric studies. The proposed antenna has not only a broad 5-dB AR bandwidth of 12.3% ranging from 2025 to 2290 MHz, but also a stable peak gain of 7.6 dBic with circular polarization (CP) characteristic.",
Evolutionary Design of Decision-Tree Algorithms Tailored to Microarray Gene Expression Data Sets,"Decision-tree induction algorithms are widely used in machine learning applications in which the goal is to extract knowledge from data and present it in a graphically intuitive way. The most successful strategy for inducing decision trees is the greedy top-down recursive approach, which has been continuously improved by researchers over the past 40 years. In this paper, we propose a paradigm shift in the research of decision trees: instead of proposing a new manually designed method for inducing decision trees, we propose automatically designing decision-tree induction algorithms tailored to a specific type of classification data set (or application domain). Following recent breakthroughs in the automatic design of machine learning algorithms, we propose a hyper-heuristic evolutionary algorithm called hyper-heuristic evolutionary algorithm for designing decision-tree algorithms (HEAD-DT) that evolves design components of top-down decision-tree induction algorithms. By the end of the evolution, we expect HEAD-DT to generate a new and possibly better decision-tree algorithm for a given application domain. We perform extensive experiments in 35 real-world microarray gene expression data sets to assess the performance of HEAD-DT, and compare it with very well known decision-tree algorithms such as C4.5, CART, and REPTree. Results show that HEAD-DT is capable of generating algorithms that significantly outperform the baseline manually designed decision-tree algorithms regarding predictive accuracy and F-measure.","Decision trees,
Algorithm design and analysis,
Machine learning algorithms,
Training,
Prediction algorithms,
Accuracy,
Evolutionary computation"
"Frequency-Agile, Efficient, Near-Field Resonant Parasitic Monopole Antenna","A simple, frequency-agile, efficient, near-field resonant parasitic (NFRP) monopole antenna is presented. The NFRP element is a capacitively-loaded loop (CLL) augmented with a varactor diode to achieve the frequency tunability. The numerical and experimental studies agree reasonably well. The experimental results demonstrate that this frequency-agile antenna exhibits a 5.56% 10-dB fractional impedance bandwidth, which is more than four times larger than the 1.33% value of the original fixed-capacitor passive system. Good impedance matching (|S11|min ≤ -20 dB), relatively high radiation efficiency ( RE >76%), stable and uniform radiation patterns, and peak gain values between 3.57-4.05 dBi were measured over this frequency-agile range.","Antennas,
Resonant frequency,
Varactors,
Antenna measurements,
Capacitance,
Bandwidth,
Frequency measurement"
Characterization of Heavy-Ion-Induced Single-Event Effects in 65 nm Bulk CMOS ASIC Test Chips,"Two 65 nm bulk complementary metal-oxide-semiconductor (CMOS) digital application-specific integrated circuit (ASIC) chips were designed, and then tested in a heavy ion accelerator to characterize single-event effects (SEE). Test chip 1 incorporates test structures, and test chip 2 implements an unhardened and a hardened digital signal processing (DSP) core. Our testing results reveal the radiation effects on the low-voltage and high-frequency operations of the ASIC chips. At a low supply voltage of 0.7 V, cross sections increase by a factor of 2 to 5 at low linear energy transfer (LET), while the increase in cross section at high LET is almost negligible, suggesting that the charge conveyed by heavy ion has far exceeded the critical charge and tuning the supply voltage is not effective. Increasing the clock frequency increases the relative importance of single-event transients (SET) compared to single-event upsets (SEU), especially in hardened designs due to their better SEU immunity. The hardened DSP core experiences a factor of 2 increase in cross section when its clock frequency is increased from 100 MHz to 500 MHz.","Testing,
Clocks,
Tunneling magnetoresistance,
Application specific integrated circuits,
Radiation hardening (electronics),
Field programmable gate arrays,
Digital signal processing"
PhaseCode: Fast and efficient compressive phase retrieval based on sparse-graph codes,"We consider the problem of recovering a complex signal x ϵ Cn from m intensity measurements of the form |aix|, 1 ≤ i ≤ m, where ai is a measurement row vector. Our main focus is on the case where the measurement vectors are unconstrained, and where x is exactly K-sparse, or the so-called general compressive phase-retrieval problem. We introduce PhaseCode, a novel family of fast and efficient algorithms (that includes Unicolor PhaseCode and Multicolor PhaseCode) that are based on a sparse-graph coding framework. As one instance, our Unicolor PhaseCode algorithm can provably recover, with high probability, all but a tiny 10-7 fraction of the significant signal components, using at most m = 14K measurements, which is a small constant factor from the fundamental limit, with an optimal O(K) decoding time and an optimal O(K) memory complexity. We provide extensive simulation results that validate the practical power of our proposed algorithms. A key contribution of our work is the novel use of coding-theoretic tools like density evolution methods for the design and analysis of fast and efficient algorithms for compressive phase-retrieval problems. This contrasts and complements popular approaches to the phase retrieval problem based on alternating-minimization, convex-relaxation, and semi-definite programming.","Color,
Phase measurement,
Decoding,
Algorithm design and analysis,
Extraterrestrial measurements,
Complexity theory,
Runtime"
NFD: A practical scheme to detect non-technical loss fraud in smart grid,"Non-Technical Loss (NTL) fraud is a consistent problem harassing utility companies all over the world. Most of the previous researches on NTL depend fully on user behaviour monitoring, analysis, and feature extraction. In this paper, we propose a practical scheme, named NTL Fraud Detection (NFD), to detect NTL without knowing any extra information about customers. The proposed scheme differentiates tampered meters from normal meters using the approximated difference between the billing electricity and the actually consumed electricity.","Electricity,
Smart grids,
Polynomials,
Security,
Support vector machines,
Observers"
Substrate-Coupled Cross-Talk Effects on an AlGaN/GaN-on-Si Smart Power IC Platform,"Cross talks between low-voltage peripheral devices and high-voltage (HV) power devices on an AlGaN/GaN-on-Si smart power IC platform are investigated by monitoring the transfer, output, and transient characteristics of a low-voltage AlGaN/GaN high-electron mobility transistor (HEMT) with an HV bias stress applied to an adjacent isolated electrode. The electric measurement was conducted under two types of substrate termination, i.e., floating and grounded. The substrate termination is shown to be the critical factor in the cross talk. The low-voltage HEMT exhibits significant drain-current degradation with a floating substrate, but remains stable with a grounded substrate. It is determined that a coupling path of the switched HV stress is formed from the HV node to the floating low-resistivity Si substrate, and then from the substrate to the HEMT. The negative net charges in the GaN buffer are caused by the electrons injected from the 2DEG channel. It is found that a grounded substrate is helpful for eliminating the cross-talk effect.","Substrates,
Stress,
Switches,
Gallium nitride,
HEMTs,
Logic gates,
Silicon"
"Testing of Flow-Based Microfluidic Biochips: Fault Modeling, Test Generation, and Experimental Demonstration","Recent advances in flow-based microfluidics have led to the emergence of biochemistry-on-a-chip as a new paradigm in clinical diagnostics and biomolecular recognition. However, a potential roadblock in the deployment of microfluidic biochips is the lack of test techniques to screen defective devices before they are used for biochemical analysis. Defective chips lead to repetition of experiments, which is undesirable due to high reagent cost and limited availability of samples. Prior work on fault detection in biochips has been limited to digital (“droplet”) microfluidics and other electrode-based technology platforms. The paper proposes the first approach for automated testing of flow-based microfluidic biochips that are designed using membrane-based valves for flow control. The proposed test technique is based on a behavioral abstraction of physical defects in microchannels and valves. The flow paths and flow control in the microfluidic device are modeled as a logic circuit composed of Boolean gates, which allows test generation to be carried out using standard automatic test pattern generation tools. The tests derived using the logic circuit model are then mapped to fluidic operations involving pumps and pressure sensors in the biochip. Feedback from pressure sensors can be compared to expected responses based on the logic circuit model, whereby the types and positions of defects are identified. We show how a fabricated biochip can be tested using the proposed method, and demonstrate experimental results for two additional fabricated chips.",
Optimal Index Policies for Anomaly Localization in Resource-Constrained Cyber Systems,"The problem of anomaly localization in a resource-constrained cyber system is considered. Each anomalous component of the system incurs a cost per unit time until its anomaly is identified and fixed. Different anomalous components may incur different costs depending on their criticality to the system. Due to resource constraints, only one component can be probed at each given time. The observations from a probed component are realizations drawn from two different distributions depending on whether the component is normal or anomalous. The objective is a probing strategy that minimizes the total expected cost, incurred by all the components during the detection process, under reliability constraints. We consider both independent and exclusive models. In the former, each component can be abnormal with a certain probability independent of other components. In the latter, one and only one component is abnormal. We develop optimal index policies under both models. The proposed index policies apply to a more general case where a subset (more than one) of the components can be probed simultaneously. The problem under study also finds applications in spectrum scanning in cognitive radio networks and event detection in sensor networks.","Testing,
Indexes,
Computational modeling,
Delays,
Optimization,
Approximation methods,
Search problems"
Mathematical and Experimental Analyses of Oppositional Algorithms,"Evolutionary algorithms (EAs) are widely employed for solving optimization problems with rugged fitness landscapes. Opposition-based learning (OBL) is a recent tool developed to improve the convergence rate of EAs. In this paper, we derive the probabilities that distances between OBL points and the optimization problem solution are less than the distance between a given EA individual and the optimal solution. We find that the quasi-reflected opposition point yields the highest probability and is the most likely candidate to be closer to the optimal solution. We then employ CEC 2013 competition benchmark problems and select a set of trajectory optimization problems from the European Space Agency to study the performance of three OBL algorithms in conjunction with three different EAs. The CEC 2013 test suit simulations indicate that quasi-reflection accelerates the performance of the EA, especially for more difficult composition functions. The space trajectory experiments reveal that differential evolution with opposition generally returns the best objective function value for the chosen minimization problems.","Optimization,
Sociology,
Statistics,
Algorithm design and analysis,
Genetic algorithms,
Benchmark testing,
Convergence"
Soft-Decoding-Based Strategies for Relay and Interference Channels: Analysis and Achievable Rates Using LDPC Codes,"We provide a rigorous mathematical analysis of two communication strategies: soft decode-and-forward (soft-DF) for relay channels and soft partial interference-cancelation (soft-IC) for interference channels. Both strategies involve soft estimation, which assists the decoding process. We consider LDPC codes, not because of their practical benefits, but because of their analytic tractability, which enables an asymptotic analysis similar to random coding methods of information theory. Unlike some works on the closely-related demodulate-and-forward, we assume non-memoryless, code-structure-aware estimation. With soft-DF, we develop simultaneous density evolution to bound the decoding error probability at the destination. This result applies to erasure relay channels. In one variant of soft-DF, the relay applies Wyner-Ziv coding to enhance its communication with the destination, borrowing from compress-and-forward. To analyze soft-IC, we adapt existing techniques for iterative multiuser detection, and focus on binary-input additive white Gaussian noise interference channels. We prove that optimal point-to-point codes are unsuitable for soft-IC, as well as for all strategies that apply partial decoding to improve upon single-user detection and multiuser detection, including Han-Kobayashi.","Relays,
Decoding,
Interference channels,
Estimation,
Iterative decoding,
Vectors"
Multiscale electromagnetic computations using a hierarchical multilevel fast multipole algorithm,"A hierarchical multilevel fast multipole method (H-MLFMM) is proposed herein to accelerate the solutions of surface integral equation methods. The proposed algorithm is particularly suitable for solutions of wideband and multiscale electromagnetic problems. As documented in Zhao and Chew (2000) that the multilevel fast multipole method (MLFMM) achieves O(N log N) computational complexity in the fixed mesh size scenario, hk = cst, where h is the mesh size and k is the corresponding wave number, for problems discretized under conventional mesh density. However, its performance deteriorates drastically for overly dense meshes where the couplings between different groups are dominated by evanescent waves or circuit physics. In the H-MLFMM algorithm, two different types of basis functions are proposed to address these two different natures of physics corresponding to the electrical size of the elements. Specifically, for the propagating wave couplings, the plane wave basis function adopted by MLFMM are effective and they are inherited by H-MLFMM. Whereas in the circuit physics and for the evanescent waves, H-MLFMM employs the so-called skeleton basis. Moreover, the proposed H-MLFMM unifies the procedures to account for the couplings using these two distinct types of basis functions. O(N) complexity is observed for both memory and CPU time from a set of numerical examples with fixed mesh sizes. Numerical results are included to demonstrate that H-MLFMM is error controllable and robust for a wide range of applications.","Couplings,
Acceleration,
Integral equations,
Matrix decomposition,
Green's function methods,
Electromagnetics"
Probability-Based Rendering for View Synthesis,"In this paper, a probability-based rendering (PBR) method is described for reconstructing an intermediate view with a steady-state matching probability (SSMP) density function. Conventionally, given multiple reference images, the intermediate view is synthesized via the depth image-based rendering technique in which geometric information (e.g., depth) is explicitly leveraged, thus leading to serious rendering artifacts on the synthesized view even with small depth errors. We address this problem by formulating the rendering process as an image fusion in which the textures of all probable matching points are adaptively blended with the SSMP representing the likelihood that points among the input reference images are matched. The PBR hence becomes more robust against depth estimation errors than existing view synthesis approaches. The MP in the steady-state, SSMP, is inferred for each pixel via the random walk with restart (RWR). The RWR always guarantees visually consistent MP, as opposed to conventional optimization schemes (e.g., diffusion or filtering-based approaches), the accuracy of which heavily depends on parameters used. Experimental results demonstrate the superiority of the PBR over the existing view synthesis approaches both qualitatively and quantitatively. Especially, the PBR is effective in suppressing flicker artifacts of virtual video rendering although no temporal aspect is considered. Moreover, it is shown that the depth map itself calculated from our RWR-based method (by simply choosing the most probable matching point) is also comparable with that of the state-of-the-art local stereo matching methods.",
Collaborative Online Multitask Learning,"We study the problem of online multitask learning for solving multiple related classification tasks in parallel, aiming at classifying every sequence of data received by each task accurately and efficiently. One practical example of online multitask learning is the micro-blog sentiment detection on a group of users, which classifies micro-blog posts generated by each user into emotional or non-emotional categories. This particular online learning task is challenging for a number of reasons. First of all, to meet the critical requirements of online applications, a highly efficient and scalable classification solution that can make immediate predictions with low learning cost is needed. This requirement leaves conventional batch learning algorithms out of consideration. Second, classical classification methods, be it batch or online, often encounter a dilemma when applied to a group of tasks, i.e., on one hand, a single classification model trained on the entire collection of data from all tasks may fail to capture characteristics of individual task; on the other hand, a model trained independently on individual tasks may suffer from insufficient training data. To overcome these challenges, in this paper, we propose a collaborative online multitask learning method, which learns a global model over the entire data of all tasks. At the same time, individual models for multiple related tasks are jointly inferred by leveraging the global model through a collaborative online learning approach. We illustrate the efficacy of the proposed technique on a synthetic dataset. We also evaluate it on three real-life problems-spam email filtering, bioinformatics data classification, and micro-blog sentiment detection. Experimental results show that our method is effective and scalable at the online classification of multiple related tasks.","Collaboration,
Data models,
Training,
Vectors,
Support vector machine classification,
Training data,
Computational modeling"
Optimal Incentive Design for Targeted Penetration of Renewable Energy Sources,"Environmental concerns arising from fossil-fuel-based generation have propelled the integration of less-polluting energy sources in the generation portfolio and simultaneously have motivated increased energy conservation programs. In today's deregulated electricity market, most participants [e.g., GENCOs and local distribution companies (LDCs)] focus on maximizing their profits, and thus they need to be incentivized to invest in renewable generation and energy conservation, which are otherwise not profitable ventures. Therefore, this paper proposes a novel holistic generation expansion plan (GEP) model that enables the central planning authority (CPA) to design optimal incentive rates for renewable integration and energy conservation targets, considering the investor interests and constraints. The model also determines the siting, sizing, timing, and technology required to adequately supply the projected demand over the planning horizon. The model is applied to the generation planning of Ontario, Canada, based on realistic data, to determine appropriate incentives for investors in renewable generation and energy conservation by LDCs. The obtained optimal incentives are shown to be similar to the ones currently in place in Ontario, with a slightly shorter payback period for investors. The effect of uncertainties associated with solar and wind energy availability on the GEP model is also examined using Monte Carlo simulations.","Energy conservation,
Investment,
Power generation,
Renewable energy sources,
Power system planning,
Incentive schemes"
Challenges in Engineering Cyber-Physical Systems,"To successfully make the transition from traditional physical products to next-generation cyber-physical systems, many manufacturers will have to reinvent their innovation and development processes and take a user-centric engineering approach.","Software testing,
Physical layer,
Educational institutions,
Technological innovation,
Navigation,
Computer science"
Indirect Performance Sensing for On-Chip Self-Healing of Analog and RF Circuits,"The advent of the nanoscale integrated circuit (IC) technology makes high performance analog and RF circuits increasingly susceptible to large-scale process variations. On-chip self-healing has been proposed as a promising remedy to address the variability issue. The key idea of on-chip self-healing is to adaptively adjust a set of on-chip tuning knobs (e.g., bias voltage) in order to satisfy all performance specifications. One major challenge with on-chip self-healing is to efficiently implement on-chip sensors to accurately measure various analog and RF performance metrics. In this paper, we propose a novel indirect performance sensing technique to facilitate inexpensive-yet-accurate on-chip performance measurement. Towards this goal, several advanced statistical algorithms (i.e., sparse regression and Bayesian inference) are adopted from the statistics community. A 25 GHz differential Colpitts voltage-controlled oscillator (VCO) designed in a 32 nm CMOS SOI process is used to validate the proposed indirect performance sensing and self-healing methodology. Our silicon measurement results demonstrate that the parametric yield of the VCO is significantly improved for a wafer after the proposed self-healing is applied.","Sensors,
System-on-chip,
Data models,
Mathematical model,
Calibration,
Radio frequency,
Bayes methods"
Combining top-down spatial reasoning and bottom-up object class recognition for scene understanding,"Many robot perception systems are built to only consider intrinsic object features to recognise the class of an object. By integrating both top-down spatial relational reasoning and bottom-up object class recognition the overall performance of a perception system can be improved. In this paper we present a unified framework that combines a 3D object class recognition system with learned, spatial models of object relations. In robot experiments we show that our combined approach improves the classification results on real world office desks compared to pure bottom-up perception. Hence, by using spatial knowledge during object class recognition perception becomes more efficient and robust and robots can understand scenes more effectively.","Robots,
Three-dimensional displays,
Training,
Cognition,
Measurement,
Keyboards,
Context"
Vision and Attention Theory Based Sampling for Continuous Facial Emotion Recognition,"Affective computing-the emergent field in which computers detect emotions and project appropriate expressions of their own-has reached a bottleneck where algorithms are not able to infer a person's emotions from natural and spontaneous facial expressions captured in video. While the field of emotion recognition has seen many advances in the past decade, a facial emotion recognition approach has not yet been revealed which performs well in unconstrained settings. In this paper, we propose a principled method which addresses the temporal dynamics of facial emotions and expressions in video with a sampling approach inspired from human perceptual psychology. We test the efficacy of the method on the Audio/Visual Emotion Challenge 2011 and 2012, CohnKanade and the MMI Facial Expression Database. The method shows an average improvement of 9.8 percent over the baseline for weighted accuracy on the Audio/Visual Emotion Challenge 2011 video-based frame-level subchallenge testing set.",
An Observe-Model-Exercise* Paradigm to Test Event-Driven Systems with Undetermined Input Spaces,"System testing of software applications with a graphical-user interface (GUI) front-end requires that sequences of GUI events, that sample the application's input space, be generated and executed as test cases on the GUI. However, the context-sensitive behavior of the GUI of most of today's non-trivial software applications makes it practically impossible to fully determine the software's input space. Consequently, GUI testers-both automated and manual-working with undetermined input spaces are, in some sense, blindly navigating the GUI, unknowingly missing allowable event sequences, and failing to realize that the GUI implementation may allow the execution of some disallowed sequences. In this paper, we develop a new paradigm for GUI testing, one that we call Observe-Model-Exercise* (OME*) to tackle the challenges of testing context-sensitive GUIs with undetermined input spaces. Starting with an incomplete model of the GUI's input space, a set of coverage elements to test, and test cases, OME* iteratively observes the existence of new events during execution of the test cases, expands the model of the GUI's input space, computes new coverage elements, and obtains new test cases to exercise the new elements. Our experiment with 8 open-source software subjects, more than 500,000 test cases running for almost 1,100 machine-days, shows that OME* is able to expand the test space on average by 464.11 percent; it detected 34 faults that had never been detected before.","Graphical user interfaces,
Computational modeling,
Blogs,
Testing,
Software,
Context,
Layout"
Ovis: A Framework for Visual Analysisof Ocean Forecast Ensembles,"We present a novel integrated visualization system that enables interactive visual analysis of ensemble simulations of the sea surface height that is used in ocean forecasting. The position of eddies can be derived directly from the sea surface height and our visualization approach enables their interactive exploration and analysis.The behavior of eddies is important in different application settings of which we present two in this paper. First, we show an application for interactive planning of placement as well as operation of off-shore structures using real-world ensemble simulation data of the Gulf of Mexico. Off-shore structures, such as those used for oil exploration, are vulnerable to hazards caused by eddies, and the oil and gas industry relies on ocean forecasts for efficient operations. We enable analysis of the spatial domain, as well as the temporal evolution, for planning the placement and operation of structures.Eddies are also important for marine life. They transport water over large distances and with it also heat and other physical properties as well as biological organisms. In the second application we present the usefulness of our tool, which could be used for planning the paths of autonomous underwater vehicles, so called gliders, for marine scientists to study simulation data of the largely unexplored Red Sea.","Data visualization,
Uncertainty,
Sea surface,
Data models,
Three-dimensional displays,
Predictive models"
Sentiment analysis of twitter data using machine learning approaches and semantic analysis,"The wide spread of World Wide Web has brought a new way of expressing the sentiments of individuals. It is also a medium with a huge amount of information where users can view the opinion of other users that are classified into different sentiment classes and are increasingly growing as a key factor in decision making. This paper contributes to the sentiment analysis for customers' review classification which is helpful to analyze the information in the form of the number of tweets where opinions are highly unstructured and are either positive or negative, or somewhere in between of these two. For this we first pre-processed the dataset, after that extracted the adjective from the dataset that have some meaning which is called feature vector, then selected the feature vector list and thereafter applied machine learning based classification algorithms namely: Naive Bayes, Maximum entropy and SVM along with the Semantic Orientation based WordNet which extracts synonyms and similarity for the content feature. Finally we measured the performance of classifier in terms of recall, precision and accuracy.","Feature extraction,
Semantics,
Support vector machine classification,
Sentiment analysis,
Entropy,
Accuracy"
Segmentation of High Angular Resolution Diffusion MRI Using Sparse Riemannian Manifold Clustering,"We address the problem of segmenting high angular resolution diffusion imaging (HARDI) data into multiple regions (or fiber tracts) with distinct diffusion properties. We use the orientation distribution function (ODF) to model diffusion and cast the ODF segmentation problem as a clustering problem in the space of ODFs. Our approach integrates tools from sparse representation theory and Riemannian geometry into a graph theoretic segmentation framework. By exploiting the Riemannian properties of the space of ODFs, we learn a sparse representation for each ODF and infer the segmentation by applying spectral clustering to a similarity matrix built from these representations. In cases where regions with similar (resp. distinct) diffusion properties belong to different (resp. same) fiber tracts, we obtain the segmentation by incorporating spatial and user-specified pairwise relationships into the formulation. Experiments on synthetic data evaluate the sensitivity of our method to image noise and to the concentration parameters, and show its superior performance compared to alternative methods when analyzing complex fiber configurations. Experiments on phantom and real data demonstrate the accuracy of the proposed method in segmenting simulated fibers and white matter fiber tracts of clinical importance.","Manifolds,
Image segmentation,
Vectors,
Measurement,
Clustering algorithms,
Magnetic resonance imaging"
An extensive study of the Bag-of-Words approach for gender identification of Arabic articles,"The prevalent use of Online Social Networks (OSN) and the anonymity and lack of accountability they inherent from being online give rise to many problems related to finding the connection between the massive amount of text data on OSN and the people who actually wrote them. Analyzing text data for such purposes is called authorship analysis. This work is focused on one specific type of authorship analysis, which is identifying the author's gender. Gender identification has various applications from marketing to security. The focus of this work is on Arabic articles. The problem is basically a classification problem and the current approaches differ in the way they compute the features of each document. However, they all agree on following some “stylometric features” approach. Unlike these works, ours treat this problem as a variation of the Text Classification (TC) problem and follow the Bag-Of-Words (BOW) approach for feature selection. We perform an extensive set of experiments on the feature selection and classification phase and the results show that such an approach yield surprisingly high results.",
Protecting cryptographic hardware against malicious attacks by nonlinear robust codes,"Fault-based attacks against cryptographic circuits must be addressed by techniques that are different from approaches designed for random transient faults. We systematically investigate robust error-detecting codes that specifically target malicious attacks and guarantee minimal bounds on detection probability. Our study is based on FPGA-supported fault-injection campaigns on the circuit implementation of a recent lightweight block cipher and its sub-modules. We quantify the detection capabilities of different robust and non-robust codes with respect to both random faults and malicious attacks, as well as the required overheads. For the first time, we report performance of a novel punctured cubic code on actual cryptographic circuitry. Experimental results show that robust codes with a certain number of redundant bits have better detection properties in security context and higher predictability than their conventional linear counterparts.","Circuit faults,
Robustness,
Vectors,
Measurement,
Cryptography,
Hardware,
Transient analysis"
Complex event processing for the Internet of Things and its applications,"In this paper, we present a distributed complex event processing (CEP) engine for Internet of Things and its applications. A CEP Engine combines information from a variety of sources. It looks for patterns in these event streams and then responds in real-time. Complex event processing is an effective mechanism to analyze object data, to reason sensing events, and to trigger responding actions for the intelligence of IoT application. A building controlled by a building automation system (BAS) is often referred to as an intelligent building, smart building, or a smart home. BAS core functionality keeps building climate within a specified range, lights rooms based on an occupancy schedule, monitors performance and device failures in all systems, and provides malfunction alarms to building engineering contractors and maintenance staff. The advantages of employing a distributed CEP engine for smart building are demonstrated.","Conferences,
Automation,
Computer aided software engineering"
Accelerating Fuzzy-C Means Using an Estimated Subsample Size,"Many algorithms designed to accelerate the fuzzy c-means (FCM) clustering algorithm randomly sample the data. Typically, no statistical method is used to estimate the subsample size, despite the impact subsample sizes have on speed and quality. This paper introduces two new accelerated algorithms, i.e., geometric progressive fuzzy c-means (GOFCM) and minimum sample estimate random fuzzy c-means (MSERFCM), that use a statistical method to estimate the subsample size. GOFCM, which is a variant of single-pass fuzzy c-means (SPFCM), also leverages progressive sampling. MSERFCM, which is a variant of random sampling plus extension fuzzy c-means, gains a speedup from improved initialization. A general, novel stopping criterion for accelerated clustering is introduced. The new algorithms are compared with FCM and four accelerated variants of FCM. GOFCM's speedup was four-47 times that of FCM and faster than SPFCM on each of the six datasets that are used in the experiments. For five of the datasets, partitions were within 1% of those of FCM. MSERFCM's speedup was five-26 times that of FCM and produced partitions within 3% of those of FCM on all datasets. A unique dataset, consisting of plankton images, exposed the strengths and weaknesses of many of the algorithms tested. It is shown that the new stopping criterion is effective in speeding up algorithms such as SPFCM and the final partitions are very close to those of FCM.","Clustering algorithms,
Acceleration,
Runtime,
Partitioning algorithms,
Algorithm design and analysis,
Statistical analysis,
Optimization"
Self-assessment of freshmen students' base competencies,"Not all incoming students are sufficiently well endowed with those base competencies (such as self organization, analytical thinking or communication skills) that are prerequisite for acquiring complex new knowledge as well as coping with the study process itself. As lecturers, we have to be aware of our incoming students' base competency profile, in order to pick them up where they are and help them develop whatever they need to study successfully. To investigate the students' initial skills regarding their base competencies, we developed a self-assessment focusing on selected self competencies, practical and cognitive skills as well as social competencies that are crucial to study computer science or related topics. In this paper, we present our assessment approach and its design. An initial evaluation in which 320 students were involved indicates that deficits in base competencies can be made tangible for students. Based on the deficits we identified, we are going to optimize our courses to meet freshmen students' needs in a better way.","Educational institutions,
Computer science,
Cultural differences,
Engineering education,
Conferences,
Graphics"
Pulse-Vanishing Test for Interposers Wires in 2.5-D IC,"In this paper, we present a general at-speed test method for die-to-die interconnects and demonstrate its particular application to the interposer wires in a 2.5-D IC. At the heart of this method is a pulse-vanishing test technique (called PV-test), in which a short-duration pulse signal is applied to an interposer wire under test at the driver end. If this pulse vanishes at the receiver's output, then it indicates the presence of a delay fault. This PV-test technique is effective for detecting not only resistive open faults, but also resistive bridging faults between interposer wires. This method has several other advantages. For example, the implementation is especially easy as it incorporates only logic cells and can be merged with boundary scan cells. Also, it can support on-the-spot diagnosis which is desirable in applications where subsequent built-in self-repair is needed.","Wires,
Circuit faults,
Delays,
Clocks,
Integrated circuit interconnections"
Reliable and Timely Event Notification for Publish/Subscribe Services Over the Internet,"The publish/subscribe paradigm is gaining attention for the development of several applications in wide area networks (WANs) due to its intrinsic time, space, and synchronization decoupling properties that meet the scalability and asynchrony requirements of those applications. However, while the communication in a WAN may be affected by the unpredictable behavior of the network, with messages that can be dropped or delayed, existing publish/subscribe solutions pay just a little attention to addressing these issues. On the contrary, applications such as business intelligence, critical infrastructures, and financial services require delivery guarantees with strict temporal deadlines. In this paper, we propose a framework that enforces both reliability and timeliness for publish/subscribe services over WAN. Specifically, we combine two different approaches: gossiping, to retrieve missing packets in case of incomplete information, and network coding, to reduce the number of retransmissions and, consequently, the latency. We provide an analytical model that describes the information recovery capabilities of our algorithm and a simulation-based study, taking into account a real workload from the Air Traffic Control domain, which evidences how the proposed solution is able to ensure reliable event notification over a WAN within a reasonable bounded time window.","Reliability,
Encoding,
Network coding,
Protocols,
Quality of service,
Internet,
Peer to peer computing"
Overlay network architectures for peer-to-peer Remote Access Laboratories,"Remote Access Laboratories are been used for practical learning activities in engineering education in the universities worldwide. Usually these systems follow a centralised client-server paradigm. This work proposes a peer-to-peer remote access laboratory architecture where participants are both users of experiments as well as makers. The feasibility of a peer-to-peer remote laboratories system is investigated. The system is built around a VPN service that allows direct access to makers' node from user nodes. To simplify the configuration a preconfigured VPN gateway node is introduced. This box is a network router that handles authentication, port forwarding and allocation of address space. The Remote Access Laboratories for fun, innovation and education (RALfie) project is a collaborative research and innovation project with the aim to engage children in STEM topics involving academics from engineering and education disciplines. In the context of RALfie, a prototype system has been developed and trial has been undertaken to establish whether children understand the RAL concept and to test their ability to configure remote experiments on their own. A brief summary trial results for the prototype implementation are reported.","Peer-to-peer computing,
Virtual private networks,
Logic gates,
Internet,
Educational institutions,
Ports (Computers),
Laboratories"
OSRI: A Rotationally Invariant Binary Descriptor,"Binary descriptors are becoming widely used in computer vision field because of their high matching efficiency and low memory requirements. Since conventional approaches, which first compute a floating-point descriptor then binarize it, are computationally expensive, some recent efforts have focused on directly computing binary descriptors from local image patches. Although these binary descriptors enable a significant speedup in processing time, their performances usually drop a lot due to orientation estimation errors and limited description abilities. To address these issues, we propose a novel binary descriptor based on the ordinal and spatial information of regional invariants (OSRIs) over a rotation invariant sampling pattern. Our main contributions are twofold: 1) each bit in OSRI is computed based on difference tests of regional invariants over pairwise sampling-regions instead of difference tests of pixel intensities commonly used in existing binary descriptors, which can significantly enhance the discriminative ability and 2) rotation and illumination changes are handled well by ordering pixels according to their intensities and gradient orientations, meanwhile, which is also more reliable than those methods that resort to a reference orientation for rotation invariance. Besides, a statistical analysis of discriminative abilities of different parts in the descriptor is conducted to design a cascade filter which can reject nonmatching descriptors at early stages by comparing just a small portion of the whole descriptor, further reducing the matching time. Extensive experiments on four challenging data sets (Oxford, 53 Objects, ZuBuD, and Kentucky) show that OSRI significantly outperforms two state-of-the-art binary descriptors (FREAK and ORB). The matching performance of OSRI with only 512 bits is also better than the well-known floating-point descriptor SIFT (4K bits) and is comparable with the state-of-the-art floating-point descriptor MROGH (6K bits), while it is two orders of magnitude faster to match than SIFT and MROGH.","Robustness,
Shape,
Lighting,
Graphical models,
Distribution functions,
Computer vision,
Real-time systems"
A Logarithmic Opinion Pool Based STAPLE Algorithm for the Fusion of Segmentations With Associated Reliability Weights,"Pelvic floor dysfunction is common in women after childbirth and precise segmentation of magnetic resonance images (MRI) of the pelvic floor may facilitate diagnosis and treatment of patients. However, because of the complexity of its structures, manual segmentation of the pelvic floor is challenging and suffers from high inter and intra-rater variability of expert raters. Multiple template fusion algorithms are promising segmentation techniques for these types of applications, but they have been limited by imperfections in the alignment of templates to the target, and by template segmentation errors. A number of algorithms sought to improve segmentation performance by combining image intensities and template labels as two independent sources of information, carrying out fusion through local intensity weighted voting schemes. This class of approach is a form of linear opinion pooling, and achieves unsatisfactory performance for this application. We hypothesized that better decision fusion could be achieved by assessing the contribution of each template in comparison to a reference standard segmentation of the target image and developed a novel segmentation algorithm to enable automatic segmentation of MRI of the female pelvic floor. The algorithm achieves high performance by estimating and compensating for both imperfect registration of the templates to the target image and template segmentation inaccuracies. A local image similarity measure is used to infer a local reliability weight, which contributes to the fusion through a novel logarithmic opinion pooling. We evaluated our new algorithm in comparison to nine state-of-the-art segmentation methods and demonstrated our algorithm achieves the highest performance.","Image segmentation,
Reliability,
Estimation,
Standards,
Manuals,
Accuracy,
Magnetic resonance imaging"
"Event-Based Mobile Social Networks: Services, Technologies, and Applications","Event-based mobile social networks (MSNs) are a special type of MSN that has an immanently temporal common feature, which allows any smart phone user to create events to share group messaging, locations, photos, and insights among participants. The emergence of Internet of Things and event-based social applications integrated with context-awareness ability can be helpful in planning and organizing social events like meetings, conferences, and tradeshows. This paper first provides review of the event-based social networks and the basic principles and architecture of event-based MSNs. Next, event-based MSNs with smartphone contained technology elements, such as context-aware mobility and multimedia sharing, are presented. By combining the feature of context-aware mobility with multimedia sharing in event-based MSNs, event organizers, and planners with the service providers optimize their capability to recognize value for the multimedia services they deliver. The unique features of the current event-based MSNs give rise to the major technology trends to watch for designing applications. These mobile applications and their main features are described. At the end, discussions on the evaluation of the event-based mobile applications based on their main features are presented. Some open research issues and challenges in this important area of research are also outlined.","Social network services,
Mobile communication,
Smart phones,
Event detection,
Computer applications"
Scale Adaptive Dictionary Learning,"Dictionary learning has been widely used in many image processing tasks. In most of these methods, the number of basis vectors is either set by experience or coarsely evaluated empirically. In this paper, we propose a new scale adaptive dictionary learning framework, which jointly estimates suitable scales and corresponding atoms in an adaptive fashion according to the training data, without the need of prior information. We design an atom counting function and develop a reliable numerical scheme to solve the challenging optimization problem. Extensive experiments on texture and video data sets demonstrate quantitatively and visually that our method can estimate the scale, without damaging the sparse reconstruction ability.","Dictionaries,
Vectors,
Optimization,
Image processing,
Computational modeling,
Visualization,
Adaptation models"
Efficient Acceleration of Mutual Information Computation for Nonrigid Registration Using CUDA,"In this paper, we propose an efficient acceleration method for the nonrigid registration of multimodal images that uses a graphics processing unit. The key contribution of our method is efficient utilization of on-chip memory for both normalized mutual information (NMI) computation and hierarchical B-spline deformation, which compose a well-known registration algorithm. We implement this registration algorithm as a compute unified device architecture program with an efficient parallel scheme and several optimization techniques such as hierarchical data organization, data reuse, and multiresolution representation. We experimentally evaluate our method with four clinical datasets consisting of up to 512 × 512 × 296 voxels. We find that exploitation of on-chip memory achieves a 12-fold increase in speed over an off-chip memory version and, therefore, it increases the efficiency of parallel execution from 4% to 46%. We also find that our method running on a GeForce GTX 580 card is approximately 14 times faster than a fully optimized CPU-based implementation running on four cores. Some multimodal registration results are also provided to understand the limitation of our method. We believe that our highly efficient method, which completes an alignment task within a few tens of seconds, will be useful to realize rapid nonrigid registration.","Graphics processing units,
Histograms,
Instruction sets,
Joints,
Acceleration,
Memory management,
Splines (mathematics)"
A Stackelberg Game-Based Optimization Framework of the Smart Grid With Distributed PV Power Generations and Data Centers,"The emergence of cloud computing has established a trend toward building massive, energy-hungry, and geographically distributed data centers. Due to their enormous energy consumption, data centers are expected to have a major impact on the electric power grid by significantly increasing the load at locations where they are built. Dynamic energy pricing policies in the recently proposed smart power grid technology can incentivize the cloud controller to shift the computation load toward data centers in regions with cheaper electricity or with excessive electricity generated by renewable energy sources, e.g., photovoltaic (PV) and wind power. On the other hand, distributed data centers in the cloud also provide opportunities to help the power grid with distributed renewable energy sources to improve robustness and load balancing. To shed some light into these opportunities, this paper considers an interaction system of the smart power grid with distributed PV power generation and the cloud computing system, jointly accounting for the service request dispatch and routing problem in the cloud with the power flow analysis in power grid. The Stackelberg (sequential) game formulation is provided for the interaction system under two different dynamic pricing scenarios: 1) real-time power-dependent pricing; and 2) time-ahead pricing. The two players in the Stackelberg games are the power grid controller that sets the pricing signal and the cloud controller that performs resource allocation among data centers. The objective of the power grid controller is to maximize its own profit and perform load balancing among power buses, i.e., minimizing the power flow from one power bus to the others, whereas the objective of the cloud computing controller is to maximize its own profit with respect to the location-dependent pricing signal. Based on the backward induction method, this paper derives the near-optimal or suboptimal strategies of the two players in Stackelberg game using convex optimization and simulated annealing techniques.","Pricing,
Servers,
Cloud computing,
Smart grids,
Power generation,
Power demand"
Hierarchical auction-based mechanism for real-time resource retrieval in cloud mobile robotic system,"In order to share information in the cloud for multi-robot systems, efficient data transmission is essential for real-time operations such as coordinated robotic missions. As a limited resource, bandwidth is ubiquitously required by applications among physical multi-robot systems. In this paper, we proposed a hierarchical auction-based mechanism, namely LQM (Link Quality Matrix)-auction. It consists of multiple procedures, such as hierarchical auction, proxy scheduling. Note that the proposed method is designed for real-time resource retrieval for physical multi-robot systems, instead of simulated virtual agents. We validate the proposed mechanism through real-time experiments. The results show that LQM-auction is suitable for scheduling a group of robots, leading to optimized performance for resource retrieval.","Relays,
Robot kinematics,
Bandwidth,
Real-time systems,
Robot sensing systems,
Spread spectrum communication"
Mainlobe Interference Suppression Based on Eigen-Projection Processing and Covariance Matrix Reconstruction,"A mainlobe interference suppression method is proposed based on eigen-projection processing and covariance matrix reconstruction. In the proposed method, the eigen-projection matrix is calculated based on the eigenvector of mainlobe interference to suppress the mainlobe interference in received echo data. The interference covariance matrix is reconstructed after the eigenvalue of mainlobe interference is replaced by the average value of noise eigenvalues to eliminate the effect of mainlobe interference to adaptive weight vector. Finally, the output of adaptive beamforming is calculated by processed echo data and adaptive weight vector obtained based on reconstructed covariance matrix. Simulation results show that the proposed method can suppress the mainlobe interference effectively and achieve excellent performance .","Interference,
Covariance matrices,
Vectors,
Eigenvalues and eigenfunctions,
Arrays,
Array signal processing,
Noise"
Prediction of Essential Proteins Based on Overlapping Essential Modules,"Many computational methods have been proposed to identify essential proteins by using the topological features of interactome networks. However, the precision of essential protein discovery still needs to be improved. Researches show that majority of hubs (essential proteins) in the yeast interactome network are essential due to their involvement in essential complex biological modules and hubs can be classified into two categories: date hubs and party hubs. In this study, combining with gene expression profiles, we propose a new method to predict essential proteins based on overlapping essential modules, named POEM. In POEM, the original protein interactome network is partitioned into many overlapping essential modules. The frequencies and weighted degrees of proteins in these modules are employed to decide which categories does a protein belong to? The comparative results show that POEM outperforms the classical centrality measures: Degree Centrality (DC), Information Centrality (IC), Eigenvector Centrality (EC), Subgraph Centrality (SC), Betweenness Centrality (BC), Closeness Centrality (CC), Edge Clustering Coefficient Centrality (NC), and two newly proposed essential proteins prediction methods: PeC and CoEWC. Experimental results indicate that the precision of predicting essential proteins can be improved by considering the modularity of proteins and integrating gene expression profiles with network topological features.","Proteins,
Gene expression,
Electronics packaging,
Network topology,
Nanobioscience,
Educational institutions"
A 65-nm CMOS 10-GS/s 4-bit Background-Calibrated Noninterleaved Flash ADC for Radio Astronomy,"This paper presents a 4-bit noninterleaved single-clock-phase 10-GS/s analog-to-digital converter (ADC) fabricated in TSMC 65-nm CMOS technology. The ADC is realized using novel switched dynamic comparators (SDCs), which alleviate the clock-frequency-limiting long regeneration time in prior-art dynamic comparators, and avoid the phase-skew issue associated with time-interleaved ADCs that limits their signal-to-noise-and-distortion ratio (SNDR) and spurious-free dynamic range. The SDC employs a reference-free topology and has no static power consumption. The trip voltage errors of the SDCs are corrected by an efficient on-chip digital background calibration technique. The noninterleaved ADC presents an estimated 100 fF of capacitance at its input, excluding bondpad capacitance, with most of it contributed by the traces leading to the ADC and the shielding structures associated with the input traces. At 10-GS/s sampling rate, the prototype ADC achieves an SNDR of 24.9 dB [3.84 effective number of bit (ENOB)], and 23.4 dB (3.59 ENOB) at low input signal frequencies and Nyquist, respectively. The chip consumes 104 mW from a 1.3 V supply. The ADC has an active area of 0.1 mm2.","Calibration,
Clocks,
Capacitance,
Transistors,
Latches,
Switches,
Noise"
Throughput Enhancement for Phase Change Memories,"Phase Change Memory (PCM) has emerged as a promising candidate for future memories. PCM has high cell density, zero cell leakage, and high stability in deep sub-micron technologies. Although PCM has limited endurance, recent endeavors have shown that its lifetime can be improved by orders of magnitude. However, a major hurdle for PCM is the long write latency and high write power. For this reason, PCM cannot deliver satisfactory memory bandwidth for high-end computing environment such as multi-processing and server systems. In this paper, we develop a non-blocking PCM bank design such that subsequent reads or writes can be carried in parallel with an on-going write. This is effective in removing long blocking time due to serial operations. Moreover, we propose novel memory request scheduling algorithms to exploit intra-bank parallelism brought by our non-blocking hardware. Our non-blocking hardware with scheduling enhancement improves PCM memory throughput by 51% on average. Finally, we propose a fine-grained power budgeting scheme to achieve more throughput improvement under power budgets. Experiments show that our scheduler enhanced with power budgeting scheme can achieve a throughput improvement of 118% on average.","phase change memories,
multiprocessing systems"
Stability analysis on four agent tetrahedral formations,"We consider a four agent tetrahedral formation of mobile agents in 3-dimensional Euclidean space. Each agent is required to maintain prescribed inter-agent distances from its neighbors so that they collectively form a desired formation shape, a task which is now called distance-based formation control. Under a common gradient-based control law, there exists an incorrect equilibrium set in which the agents do not achieve the desired formation shape. By investigating the linearized dynamics of the system, we prove that all incorrect equilibria are unstable, which results in that desired formation shape is almost globally asymptotically stable. Numerical simulation results are also included.",
Dense depth maps-based human pose tracking and recognition in dynamic scenes using ridge data,"This paper addresses the problem of automatic detection, tracking and recognition of three-dimensional human poses from monocular depth video sequences for machine vision applications. In this paper, we present a real-time tracking system for body parts pose recognition utilizing ridge data of depth maps. At first, the depth maps are processed to extract features by considering ridge data surrounded by binary edges silhouettes acting as skeleton shape of human body. Then, the pose estimation is applied to initialize each body parts having joint points information using predefined pose. For body part tracking, all features (i.e., ridge data or depth values) are extracted according to a continuously updated torso-center, head and body part joint points. This help to provide the estimation of 3D body joint angles using the forward kinematic analysis. Our experimental results believe that the proposed method is reliable and efficient for tracking and recognizing the exact skeleton for even dynamic scenes and complex human pose.","Joints,
Torso,
Feature extraction,
Three-dimensional displays,
Shoulder,
Accuracy"
Circle Condition-Based Feedback Controller Design for Fast and Precise Positioning,"This paper presents a novel feedback (FB) controller design methodology for fast and precise positioning of mechatronic systems. Improvement of disturbance suppression performance is one of the general and important indexes in the FB controller design to realize the precision performance. However, since the stability of FB system generally restricts the disturbance suppression capability, improvements in both disturbance suppression and stability performance are difficult to be achieved. In this paper, therefore, a circle condition-based FB controller design is proposed to provide the required disturbance suppression with the desired stability. The proposed FB controller specifies a stability margin (i.e., gain and phase margins) as a circle condition on the Nyquist diagram using a linear matrix inequality (LMI) technique, whereas the disturbance suppression capability is determined by giving arbitrary poles in the FB control system. In addition, the proposed FB controller can be systematically designed on the basis of an optimization technique using the LMI. Effectiveness of the proposed approach has been verified by numerical simulations and experiments using a prototype of a linear motor-driven table system.",
Block-Based CS in a CMOS Image Sensor,"An implementation of the compressive sensing (CS) method with a CMOS image sensor is presented. The conventional three-transistor active pixel sensor (APS) structure and switched capacitor circuits are exploited to develop an analog implementation of the CS encoding in a CMOS sensor. With the analog implementation, the sensing and encoding are performed in the same time interval and making a real-time encoding process to optimize the frame rate of the imager. A block readout strategy is proposed to capture the required CS measurements for different blocks of the image, rather than the common column-row readout method. All measurement circuits are placed outside the array by this readout strategy, and the imager becomes scalable for larger array sizes. Because there is no extra in-pixel element for the CS measurement process, the fill factor of the imager is the same as its corresponding APS imager without CS. The proposed structure is designed and fabricated in 0.13-μm CMOS technology for a 2 × 2 array. The experimental results confirm the validity of the design in making monotonic and appropriate CS measurements. The functionality of the block readout method and the scalability of the imager are confirmed by fabrication of a 4×4 block and a 16×16 array.","Image coding,
Arrays,
Adders,
CMOS integrated circuits,
Time measurement,
Matching pursuit algorithms,
Sensors"
Optimal Load Balancing and Energy Cost Management for Internet Data Centers in Deregulated Electricity Markets,"Along with the rapid increasing energy consumption, the energy cost of Internet data centers (IDCs) has been skyrocketing. A novel scheme of geographical load balancing was proposed to reduce electricity bills for service providers. However, one important challenge faced by service providers has not been considered properly. In service systems, the service delay faced by consumers includes the queuing delay and the transmission delay. While existing work only consider the queuing delay, the transmission delay introduced by geographical load balancing has been overlooked. It is one of the most important factors affecting the quality of service for real-time service systems. In this paper, we take the transmission delay into our design consideration and formulate a mixed-integer nonlinear programming (MINLP) problem with coupled constraint to achieve the optimal load balancing and energy cost management for IDCs while meeting the service-level agreements (SLA) of consumers. A novel heuristic based branch and bound with feedback (HBBF) algorithm is proposed to decouple the MINLP problem with coupled constraint efficiently. Extensive performance evaluations based on real electricity price data and site-to-site transmission delay data demonstrate the effectiveness of our proposed algorithm.",
Multi-pitch Streaming of Harmonic Sound Mixtures,"Multi-pitch analysis of concurrent sound sources is an important but challenging problem. It requires estimating pitch values of all harmonic sources in individual frames and streaming the pitch estimates into trajectories, each of which corresponds to a source. We address the streaming problem for monophonic sound sources. We take the original audio, plus frame-level pitch estimates from any multi-pitch estimation algorithm as inputs, and output a pitch trajectory for each source. Our approach does not require pre-training of source models from isolated recordings. Instead, it casts the problem as a constrained clustering problem, where each cluster corresponds to a source. The clustering objective is to minimize the timbre inconsistency within each cluster. We explore different timbre features for music and speech. For music, harmonic structure and a newly proposed feature called uniform discrete cepstrum (UDC) are found effective; while for speech, MFCC and UDC works well. We also show that timbre-consistency is insufficient for effective streaming. Constraints are imposed on pairs of pitch estimates according to their time-frequency relationships. We propose a new constrained clustering algorithm that satisfies as many constraints as possible while optimizing the clustering objective. We compare the proposed approach with other state-of-the-art supervised and unsupervised multi-pitch streaming approaches that are specifically designed for music or speech. Better or comparable results are shown.",
Vehicular Security Through Reputation and Plausibility Checks,"Vehicular ad hoc networks (VANETs) are essentially used to communicate real-time traffic and safety information. In this paper, we present vehicular security through reputation and plausibility checks to address the most important issue of security in VANETs. The algorithm provides security against the attacks of event modification, false event generation, data aggregation and data dropping. It performs not only detection but also the isolation of malicious nodes in the network. It employs sensors in a reputation-based system and presents a very robust yet cost efficient approach as it utilizes just vehicle to vehicle communication, thereby reducing the security issues and cost associated with the roadside infrastructure. The algorithm has been simulated and tested on various scenarios and has been observed to be very effective and efficient in terms of the percentage of malicious nodes detected, number of control packets sent after detection of malicious nodes, average time taken to detect nodes which are generating false information, number of packets dropped, and the number of packets received by malicious nodes.",
A New Slit-Type Vacuum-Channel Transistor,"A new vacuum-channel transistor with a carbon nanotube cathode and nanometer-scale channel length-called a slit-type vacuum-channel transistor is proposed and investigated. The suggested device structure features distinguishable cutoff, linear, and saturation regions with a negligible gate leakage current. Its channel length is almost the same as the mean free path of carriers in air, which suggests that the device can operate not only in vacuum but also in air, without any performance degradation. Because of its geometrical characteristics, it is possible for this device to be operated when the anode bias is almost the same as the gate bias with negligible oxide leakage. Therefore, the device can be used as an elemental device component in digital integrated circuits.","Anodes,
Logic gates,
Transistors,
Cathodes,
Leakage currents,
Performance evaluation,
Vacuum systems"
Automated Screening System for Acute Myelogenous Leukemia Detection in Blood Microscopic Images,"Acute myelogenous leukemia (AML) is a subtype of acute leukemia, which is prevalent among adults. The average age of a person with AML is 65 years. The need for automation of leukemia detection arises since current methods involve manual examination of the blood smear as the first step toward diagnosis. This is time-consuming, and its accuracy depends on the operator's ability. In this paper, a simple technique that automatically detects and segments AML in blood smears is presented. The proposed method differs from others in: 1) the simplicity of the developed approach; 2) classification of complete blood smear images as opposed to subimages; and 3) use of these algorithms to segment and detect nucleated cells. Computer simulation involved the following tests: comparing the impact of Hausdorff dimension on the system before and after the influence of local binary pattern, comparing the performance of the proposed algorithms on subimages and whole images, and comparing the results of some of the existing systems with the proposed system. Eighty microscopic blood images were tested, and the proposed framework managed to obtain 98% accuracy for the localization of the lymphoblast cells and to separate it from the subimages and complete images.","Image color analysis,
Blood,
Image segmentation,
Feature extraction,
High definition video,
Shape,
Image edge detection"
Adaptive Force/Motion Control System Based on Recurrent Fuzzy Wavelet CMAC Neural Networks for Condenser Cleaning Crawler-Type Mobile Manipulator Robot,"In this paper, an adaptive motion/force control system is proposed for condenser cleaning crawler-type mobile manipulator robot (CCCMMR). With the merits of recurrent fuzzy wavelet cerebellar model articulation control neural networks, the unknown dynamics and parameter variations of the CCCMMR control system are relaxed by an approximation process. In addition, an adaptive robust compensator is also proposed to eliminate uncertainties that consist of the unknown approximation errors and disturbances. According to the adaptive position tracking control design, we develop an adaptive robust control strategy for the nonholonomic constraint force of the CCCMMR. The design of the adaptive online learning algorithms is derived using the Lyapunov stability theorem. Therefore, the proposed controllers prove that they not only can guarantee the stability and robustness, but also the tracking performances of the CCCMMR control system. The effectiveness and robustness of the proposed control system are verified by comparative simulation and experimental results.","Control systems,
Mobile communication,
Vectors,
Manipulators,
Force,
Robustness"
Augmenting Image Descriptions Using Structured Prediction Output,"The need for richer descriptions of images arises in a wide spectrum of applications ranging from image understanding to image retrieval. While the Automatic Image Annotation (AIA) has been extensively studied, image descriptions with the output labels lack sufficient information. This paper proposes to augment image descriptions using structured prediction output. We define a hierarchical tree-structured semantic unit to describe images, from which we can obtain not only the class and subclass one image belongs to, but also the attributes one image has. After defining a new feature map function of structured SVM, we decompose the loss function into every node of the hierarchical tree-structured semantic unit and then predict the tree-structured semantic unit for testing images. In the experiments, we evaluate the performance of the proposed method on two open benchmark datasets and compare with the state-of-the-art methods. Experimental results show the better prediction performance of the proposed method and demonstrate the strength of augmenting image descriptions.",
A New Strategy for Protein Interface Identification Using Manifold Learning Method,"Protein interactions play vital roles in biological processes. The study for protein interface will allow people to elucidate the mechanism of protein interaction. However, a large portion of protein interface data is incorrectly collected in current studies. In this paper, a novel strategy of dataset reconstruction using manifold learning method has been proposed for dealing with the noises in the interaction interface data whose definition is based on the residue distances among the different chains within protein complexes. Three support vector machine-based predictors are constructed using different protein features to identify the functional sites involved in the formation of protein interface. The experimental results achieved in this work demonstrate that our strategy can remove noises, and therefore improve the ability for identification of protein interfaces with 77.8% accuracy.","Proteins,
Manifolds,
Support vector machines,
Amino acids,
Learning systems,
Nanobioscience,
Vectors"
Development of converter based reconfigurable power grid emulator,"A Hardware Test-Bed (HTB) is developed to serve as a platform for power grid emulation. For maximum flexibility, power converters, which can accommodate various control algorithms and behave distinctively based on the applied model and control, is adopted. With the developed emulators, such as generator, load, wind turbine, and PV emulators, diverse research and experiments can be performed by using the HTB. This paper introduces the emulating method, hardware, control and communication structure of the HTB. At the same time, experimental results are compared with simulation to verify the emulation.","Generators,
Mathematical model,
Synchronization,
Nickel,
Testing,
Transient analysis"
Beamforming-Enhanced Inverse Scattering for Microwave Breast Imaging,"We present a focal-beamforming-enhanced formulation of the distorted Born iterative method (DBIM) for microwave breast imaging. Incorporating beamforming into the imaging algorithm has the potential to mitigate the effect of noise on the image reconstruction. We apply the focal-beamforming-enhanced DBIM algorithm to simulated array measurements from two MRI-derived, anatomically realistic numerical breast phantoms and compare its performance to that of the DBIM formulated with two non-focal schemes. The first scheme simply averages scattered field data from reciprocal antenna pairs while the second scheme discards reciprocal pairs. Images of the dielectric properties are reconstructed for signal-to-noise ratios (SNR) ranging from 35 dB down to 0 dB. We show that, for low SNR, the focal beamforming algorithm creates reconstructions that are of higher fidelity with respect to the exact dielectric profiles of the phantoms as compared to reconstructions created using the non-focal schemes. At high SNR, the focal and non-focal reconstructions are of comparable quality.","Signal to noise ratio,
Vectors,
Image reconstruction,
Breast,
Array signal processing,
Phantoms"
Framework for Optimal Fault-Tolerant Control Synthesis: Maximize Prefault While Minimize Post-Fault Behaviors,"In an earlier work, we introduced a framework for fault-tolerant supervisory control of discrete event systems and presented a necessary and sufficient condition for its existence. In this paper, we introduce the synthesis of an optimal fault-tolerant supervisory controller. Given a discrete event plant with both post-fault and prefault behaviors, an optimal fault-tolerant supervisor we synthesize enforces a set of behaviors in which: 1) a recovery is guaranteed within a bounded delay following any fault; 2) all safety and nonblocking properties are satisfied; 3) the enforced set of prefault behaviors is maximized, and 4) a minimal set of post-fault behaviors is tolerated to achieve recovery in a minimal number of steps. An optimal solution requires a simultaneous maximization (of prefault behaviors) and minimization (of post-fault and prerecovery behaviors), which is quite novel. The optimal solution further minimizes the delay of recovery. The computation has complexity quadratic in the size of plant.","Fault tolerance,
Fault tolerant systems,
Delays,
Supervisory control,
Safety,
Discrete-event systems"
Top K Query for QoS-Aware Automatic Service Composition,"With the proliferation of Web services, service engineers demand automatic service composition algorithms that not only synthesize the correct service compositions from thousands of services but also satisfy the quality requirements of users. This is known as QoS-aware automatic service composition problem. Our observation is that current research of only finding the optimal service composition result has several shortcomings. Users have to utilize the optimal one, which will make it rigid, and consequently bring about problems, such as overload of “hot services” and lack of choices for users. To cope with these problems, a top k query mechanism is introduced in this paper, and a progressive and incremental Key-Path-Based Loose (KPL) algorithm with 100 percent accuracy is proposed. Our QSynth, which won the performance championship of Web Service Challenge 2009 and 2010, is extended to support top k query based on KPL algorithm. Evaluations show that, compared to the state of the art, KPL algorithm achieves superior scalability and accuracy with respect to a large variety of composition scenarios. Moreover, we generalize a new graph problem: top k DAGs (Directed Acyclic Graphs) problem based on the above work. Applications of this new graph problem contain API recommender, supply chain, and so on. KPL algorithm illustrated in this paper can address them efficiently, too.",
Compressibility Constrained Sparse Representation With Learnt Dictionary for Low Bit-Rate Image Compression,"This paper proposes a compressibility constrained sparse representation (CCSR) approach to low bit-rate image compression using a learnt over-complete dictionary of texture patches. Conventional sparse representation approaches for image compression are based on matching pursuit (MP) algorithms. Actually, the weakness of these approaches is that they are not stable in terms of sparsity of the estimated coefficients, thereby resulting in the inferior performance in low bit-rate image compression. In comparison with MP, convex relaxation approaches are more stable for sparse representation. However, it is intractable to directly apply convex relaxation approaches to image compression, as their coefficients are not always compressible. To utilize convex relaxation in image compression, we first propose in this paper a CCSR formulation, imposing the compressibility constraint on the coefficients of sparse representation for each image patch. In addition, we work out the CCSR formulation to obtain sparse and compressible coefficients, through recursively solving the
ℓ
1
-norm optimization problem of sparse representation. Given these coefficients, each image patch can be represented by the linear combination of texture elements encoded in an over-complete dictionary, learnt from other training images. Finally, low bit-rate image compression can be achieved, owing to the sparsity and compressibility of coefficients by our CCSR approach. The experimental results demonstrate the effectiveness and superiority of the CCSR approach on compressing the natural and remote sensing images at low bit-rates.","Image coding,
Dictionaries,
Matching pursuit algorithms,
Image reconstruction,
Training,
Equations,
Quantization (signal)"
A Novel Text Detection System Based on Character and Link Energies,"We propose a novel method by using three new character features to detect text objects comprising two or more isolated characters in images and videos. A new text model is constructed to describe text objects. Each character is a part in the model and every two neighboring characters are connected by a link. Two characters and the link connecting them are defined as a text unit. For every candidate part, we compute character energy based on our observation that each character stroke forms two edges with high similarities in length, curvature, and orientation. For every candidate link, we compute link energy based on the similarities in color, size, stroke width, and spacing between characters that are aligned along a particular direction. For every candidate text unit, we combine character and link energies to compute text unit energy which measures the likelihood that the candidate is a text object. We evaluated the performance of the proposed method on ICDAR 2003/2005 data set, Microsoft Street view data set, and video analysis and content exploitation video data set. The experimental results demonstrate that our method can capture the inherent properties of characters and discriminate text from other objects effectively.","Image edge detection,
Noise,
Videos,
Computational modeling,
Image color analysis,
Feature extraction,
Vectors"
Bioluminescence Tomography by an Iterative Reweighted {\bm {l_{2}}}-Norm Optimization,"Bioluminescence tomography is a promising tool in preclinical research, enabling noninvasive real-time in vivo imaging as well as quantitative analysis in small animal studies. Due to the difficulty of reconstruction, continuous efforts are still made to find more practical and efficient approaches. In this paper, we present an iterative reweighted l2-norm optimization incorporating anatomical structures in order to enhance the performance of bioluminescence tomography. The structure priors have been utilized to generate a heterogeneous mouse model by extracting the internal organs and tissues, which can assist in establishing a more precise photon diffusion model, as well as reflecting a more specific position of the reconstruction results inside the mouse. To evaluate the performance of the iterative reweighted approach, several numerical simulation studies including comparative analyses and multisource cases have been conducted to reconstruct the same datasets. The results suggest that the proposed method is able to ensure the accuracy, robustness, and efficiency of bioluminescence tomography. Finally, an in vivo experiment was performed to further validate its feasibility in a practical application.","Bioluminescence,
Optimization,
Biological system modeling,
Photonics,
Mice,
Tomography,
Iterative methods"
Ferrofluid Sacrificial Microfabrication of Capacitive Pressure Sensors,"A novel production approach to the fabrication of capacitive micropressure sensors is reported. A magnetic fluid known as ferrofluid is used as the liquid-phase sacrificial layer in the microfabrication process, enabling extremely simple, fast, and low-cost production of the sensors while eliminating the need for photolithographic, bonding, and/or chemical processes. The entire sensor fabrication is performed at/near room temperature. The sensors are designed to be constructed on the 1.5 × 1.5-mm2 stainless-steel chip, being micromachined to have capacitive cavities with 10-30 μm depths. A Parylene-C membrane with a titanium electrode is formed to seal the cavity by depositing it directly on top of the ferrofluid filled in the cavity. The ferrofluid is magnetically extracted from the cavity after the formation of the membrane, suspending it to establish the sensing capacitor. A highly linear response of 12.4 fF/KPa is obtained with the fabricated device. The temperature dependence of the sensor capacitance is experimentally characterized and reported as well.","Cavity resonators,
Capacitive sensors,
Temperature sensors,
Magnetic liquids,
Sensor phenomena and characterization,
Temperature measurement"
Face Authentication With Makeup Changes,"Recent studies have shown that facial cosmetics have an impact on face recognition. To develop a face recognition system that is robust to facial makeup, we propose performing correlation mapping between makeup and nonmakeup faces on features extracted from local patches. Three methods are explored to learn the correlations. We also study the problem of makeup detection. Four categories of features are proposed to characterize cosmetics, including skin color tone, skin smoothness, texture, and highlight. A patch selection scheme and discriminative mapping are presented to enhance the performance of makeup detection. A complete system is then developed for face verification utilizing the makeup detection result. Experimental results show that our system is robust to cosmetics in face authentication. An accuracy of about 80.0% can be achieved on a database of about 500 pairs of makeup and nonmakeup face images.","Face,
Correlation,
Feature extraction,
Image color analysis,
Face recognition,
Skin,
Robustness"
Omnidirectional stereo vision using fisheye lenses,This work presents an omnidirectional stereo system with a direct application to autonomous logistics. The omnidirectional system uses fisheye lenses to inspect the surroundings of the automated forklift. The lenses are mounted on the top of the vehicle to allow a 360° scene reconstruction with a single stereo pair. The system provides the list of obstacles detected around the vehicle. The reconstruction of the scene is possible via a division of the fisheye images into several rectified images. A stereo matching algorithm is applied to each pair of rectified images. The computed 3D points corresponding to the rectified pairs are unified into a single cloud. The obstacle detection module operates on the unified cloud of 3D points.,"Lenses,
Sensors,
Cameras,
Three-dimensional displays,
Calibration,
Stereo image processing,
Accuracy"
Three dimensional modeling of an MRI actuated steerable catheter system,"This paper presents the three dimensional kinematic modeling of a novel steerable robotic ablation catheter system. The catheter, embedded with a set of current-carrying micro-coils, is actuated by the magnetic forces generated by the magnetic field of the MRI scanner. This paper develops a 3D model of the MRI actuated steerable catheter system by using finite differences approach. For each finite segment, a quasi-static torque-deflection equilibrium equation is calculated using beam theory. By using the deflection displacements and torsion angles, the kinematic modeling of the catheter system is derived. The proposed models are evaluated by comparing the simulation results of the proposed model with the experimental results of a proof-of-concept prototype.","Catheters,
Coils,
Magnetic resonance imaging,
Mathematical model,
Force,
Prototypes,
Magnetic separation"
MRISIMUL: A GPU-Based Parallel Approach to MRI Simulations,"A new step-by-step comprehensive MR physics simulator (MRISIMUL) of the Bloch equations is presented. The aim was to develop a magnetic resonance imaging (MRI) simulator that makes no assumptions with respect to the underlying pulse sequence and also allows for complex large-scale analysis on a single computer without requiring simplifications of the MRI model. We hypothesized that such a simulation platform could be developed with parallel acceleration of the executable core within the graphic processing unit (GPU) environment. MRISIMUL integrates realistic aspects of the MRI experiment from signal generation to image formation and solves the entire complex problem for densely spaced isochromats and for a densely spaced time axis. The simulation platform was developed in MATLAB whereas the computationally demanding core services were developed in CUDA-C. The MRISIMUL simulator imaged three different computer models: a user-defined phantom, a human brain model and a human heart model. The high computational power of GPU-based simulations was compared against other computer configurations. A speedup of about 228 times was achieved when compared to serially executed C-code on the CPU whereas a speedup between 31 to 115 times was achieved when compared to the OpenMP parallel executed C-code on the CPU, depending on the number of threads used in multithreading (2-8 threads). The high performance of MRISIMUL allows its application in large-scale analysis and can bring the computational power of a supercomputer or a large computer cluster to a single GPU personal computer.","Computational modeling,
Mathematical model,
Magnetic resonance imaging,
Computers,
Vectors,
Magnetization,
Radio frequency"
"Integration of System-Dynamics, Aspect-Programming, and Object-Orientation in System Information Modeling","Contemporary information modeling of enterprise systems only focuses on the technical aspect of the systems, though it is known that they are social-technical (socio-tech) systems in essence. In fact, there are many lessons that can be learned from failures in the management of enterprise systems, which range from a small one (e.g., failure to install a printer driver) to a large one (e.g., nuclear power plant post-accident management). This paper, therefore, proposes that the enterprise system should be viewed as a socio-tech system. The paper presents a novel integrated approach to information modeling of socio-tech enterprise systems. In particular, the approach integrates object-orientation, systems-dynamics (as a means to represent high-level dynamics), and aspect-programming. The paper discusses an example to illustrate how the proposed approach works.","Unified modeling language,
Water pollution,
Sociotechnical systems,
Object oriented modeling,
Educational institutions,
Context"
GECC: Gene Expression Based Ensemble Classification of Colon Samples,"Gene expression deviates from its normal composition in case a patient has cancer. This variation can be used as an effective tool to find cancer. In this study, we propose a novel gene expressions based colon classification scheme (GECC) that exploits the variations in gene expressions for classifying colon gene samples into normal and malignant classes. Novelty of GECC is in two complementary ways. First, to cater overwhelmingly larger size of gene based data sets, various feature extraction strategies, like, chi-square, F-Score, principal component analysis (PCA) and minimum redundancy and maximum relevancy (mRMR) have been employed, which select discriminative genes amongst a set of genes. Second, a majority voting based ensemble of support vector machine (SVM) has been proposed to classify the given gene based samples. Previously, individual SVM models have been used for colon classification, however, their performance is limited. In this research study, we propose an SVM-ensemble based new approach for gene based classification of colon, wherein the individual SVM models are constructed through the learning of different SVM kernels, like, linear, polynomial, radial basis function (RBF), and sigmoid. The predicted results of individual models are combined through majority voting. In this way, the combined decision space becomes more discriminative. The proposed technique has been tested on four colon, and several other binary-class gene expression data sets, and improved performance has been achieved compared to previously reported gene based colon cancer detection techniques. The computational time required for the training and testing of 208 × 5,851 data set has been 591.01 and 0.019 s, respectively.",
Flowing on Riemannian Manifold: Domain Adaptation by Shifting Covariance,"Domain adaptation has shown promising results in computer vision applications. In this paper, we propose a new unsupervised domain adaptation method called domain adaptation by shifting covariance (DASC) for object recognition without requiring any labeled samples from the target domain. By characterizing samples from each domain as one covariance matrix, the source and target domain are represented into two distinct points residing on a Riemannian manifold. Along the geodesic constructed from the two points, we then interpolate some intermediate points (i.e., covariance matrices), which are used to bridge the two domains. By utilizing the principal components of each covariance matrix, samples from each domain are further projected into intermediate feature spaces, which finally leads to domain-invariant features after the concatenation of these features from intermediate points. In the multiple source domain adaptation task, we also need to effectively integrate different types of features between each pair of source and target domains. We additionally propose an SVM based method to simultaneously learn the optimal target classifier as well as the optimal weights for different source domains. Extensive experiments demonstrate the effectiveness of our method for both single source and multiple source domain adaptation tasks.","Covariance matrices,
Manifolds,
Support vector machines,
Vectors,
Symmetric matrices,
Feature extraction,
Measurement"
SMT-based synthesis of integrated task and motion plans from plan outlines,"We present a new approach to integrated task and motion planning (ITMP) for robots performing mobile manipulation. In our approach, the user writes a high-level specification that captures partial knowledge about a mobile manipulation setting. In particular, this specification includes a plan outline that syntactically defines a space of plausible integrated plans, a set of logical requirements that the generated plan must satisfy, and a description of the physical space that the robot manipulates. A synthesis algorithm is now used to search for an integrated plan that falls within the space defined by the plan outline, and also satisfies all requirements. Our synthesis algorithm complements continuous motion planning algorithms with calls to a Satisfiability Modulo Theories (SMT) solver. From the scene description, a motion planning algorithm is used to construct a placement graph, an abstraction of a manipulation graph whose paths represent feasible, low-level motion plans. An SMT-solver is now used to symbolically explore the space of all integrated plans that correspond to paths in the placement graph, and also satisfy the constraints demanded by the plan outline and the requirements. Our approach is implemented in a system called Ro-bosynth. We have evaluated Robosynth on a generalization of an ITMP problem investigated in prior work. The experiments demonstrate that our method is capable of generating integrated plans for a number of interesting variations on the problem.",
DR. Swap: Energy-efficient paging for smartphones,"Smartphones are becoming increasingly energy-hungry to support feature-rich applications, posing a lot of pressure on battery lifetime and making energy consumption a non-negligible issue. In particular, DRAM is among the most demanding components in energy consumption. In this paper, we propose DR. Swap, an energy-efficient paging design to reduce energy consumption in smartphones. We adopt emerging energy-efficient non-volatile memory (NVM) and use it as the swap area. Utilizing NVM's byte-addressability, we propose direct read which guarantees zero-copy for read-only pages in the swap area. Experimental results based on the Google Nexus 5 smartphone show that our technique can effectively reduce energy consumption.","smart phones,
DRAM chips,
paged storage,
power aware computing"
Achieving High-Quality Three-Dimensional InISAR Imageries of Maneuvering Target via Super-Resolution ISAR Imaging by Exploiting Sparseness,"Interferometric inverse synthetic aperture radar (InISAR) can achieve 3-D imageries of maneuvering target. However, the quality of 3-D imageries suffers from the noise and sidelobes seriously. In addition, the defocusing effect due to the nonlinear moving of the target can also bring into a bad effect for 3-D imaging. To tackle these issues, a 3-D InISAR imaging approach via compressed sensing (CS)-based super-resolution (SR) ISAR imageries is proposed. First, we establish the target sparsity-constraint optimization model containing both amplitude and phase information of scatterers. Second, a Bayesian CS approach is adopted to get high-quality SR ISAR image. The quasi-Newton solver guarantees both high amplitude and phase information recovery precision. At last, a high-quality 3-D view of the target is achieved via the conventional ISAR imagery pair interferometry technique. Computer simulation and real data experimental results verify the effectiveness of the proposed method.","Imaging,
Radar imaging,
Remote sensing,
Image resolution,
Bayes methods,
Airplanes,
Noise"
Vanishing Point-Based Image Transforms for Enhancement of Probabilistic Occupancy Map-Based People Localization,"The widespread use of vision-based surveillance systems has inspired many research efforts on people localization. In this paper, a series of novel image transforms based on the vanishing point of vertical lines is proposed for enhancement of the probabilistic occupancy map (POM)-based people localization scheme. Utilizing the characteristic that the extensions of vertical lines intersect at a vanishing point, the proposed transforms, based on image or ground plane coordinate system, aims at producing transformed images wherein each standing/walking person will have an upright appearance. Thus, the degradation in localization accuracy due to the deviation of camera configuration constraint specified can be alleviated, while the computation efficiency resulted from the applicability of integral image can be retained. Experimental results show that significant improvement in POM-based people localization for more general camera configurations can indeed be achieved with the proposed image transforms.",
Nighttime Turn Signal Detection by Scatter Modeling and Reflectance-Based Direction Recognition,"The rapid expansion of car ownership worldwide has further raised the importance of vehicle safety. The reduced cost of cameras and optical devices has made it economically feasible to deploy front-mounted intelligent systems for visual-based event detection for forward collision avoidance and mitigation. While driving at night, vehicles in front are generally visible by their tail lights. The turn signals are particularly important because they signal lane change and potential collision. Therefore, this paper proposes a novel visual-based approach, based on the Nakagami-m distribution, for detecting turn signals at night by scatter modeling of tail lights. In addition, to recognize the direction of turn signals, reflectance is decomposed from the original image. Rather than using knowledge of heuristic features, such as the symmetry, position, and size of the rear-facing vehicle, we focus on finding the invariant features to model turn signal scattering by Nakagami imaging and therefore, conduct the detection process in a part-based manner. Experiments on an extensive data set show that our proposed system can effectively detect vehicle braking under different lighting and traffic conditions, and thus, demonstrates its feasibility in real-world environments.",
SAR target recognition based on deep learning,"Deep learning algorithms such as convolutional neural networks (CNN) have been successfully applied in computer vision. This paper attempts to adapt the optical camera-oriented CNN to its microwave counterpart, i.e. synthetic aperture radar (SAR). As a preliminary study, a single layer of convolutional neural network is used to automatically learn features from SAR images. Instead of using the classical backpropagation algorithm, the convolution kernel is trained on randomly sampled image patches using unsupervised sparse auto-encoder. After convolution and pooling, an input SAR image is then transformed into a series of feature maps. These feature maps are then used to train a final softmax classifier. Initial experiments on MSTAR public data set show that an accuracy of 90.1% can be achieved on three types of targets classification task, and an accuracy of 84.7% is achievable on ten types of targets classification task.",
Throughput Optimizing Localized Link Scheduling for Multihop Wireless Networks under Physical Interference Model,"We study throughput-optimum localized link scheduling in wireless networks. The majority of results on link scheduling assume binary interference models that simplify interference constraints in actual wireless communication. While the physical interference model reflects the physical reality more precisely, the problem becomes notoriously harder under the physical interference model. There have been just a few existing results on link scheduling under the physical interference model, and even fewer on more practical distributed or localized scheduling. In this paper, we tackle the challenges of localized link scheduling posed by the complex physical interference constraints. By integrating the partition and shifting strategies into the pick-and-compare scheme, we present a class of localized scheduling algorithms with provable throughput guarantee subject to physical interference constraints. The algorithm in the oblivious power setting is the first localized algorithm that achieves at least a constant fraction of the optimal capacity region subject to physical interference constraints. The algorithm in the uniform power setting is the first localized algorithm with a logarithmic approximation ratio to the optimal solution. Our extensive simulation results demonstrate performance efficiency of our algorithms.",
Augmenting Reality and Formality of Informal and Non-Formal Settings to Enhance Blended Learning,"Visits to museums and city tours have been part of higher and secondary education curriculum activities for many years. However these activities are typically considered “less formal” when compared to those carried out in the classroom, mainly because they take place in informal or non-formal settings. Augmented Reality (AR) technologies and smartphones can transform such informal and non-formal settings into digitally augmented learning settings by superimposing “digital” layers of information over physical objects or spaces. At the same time, the formality of these settings increases when connected to formal settings through these digital layers. The right combination of AR and mobile technologies with computer-based educational tools such as Learning Management Systems (LMSs) drives this digital connection, leading to articulated blended learning activities across formal, non-formal and informal settings. This paper contributes to the TEL field with: (1) three blended learning activities illustrating the idea of augmented informal/non-formal settings; (2) results from the cross-analysis of these activities that evidence the impact of technology to enhance blended learning; and (3) a set of lessons learned about the possibilities of NFC/GPS AR technologies and LMSs for blended learning. This work provides insights for the design and implementation of similar technology-enhanced blended learning activities.","Smart phones,
Context,
Mobile communication,
Urban areas,
Augmented reality,
Global Positioning System"
Nontraditional Computation Using Beyond-CMOS Tunneling Devices,"Amongst potential post-CMOS technologies, tunnel field-effect transistors (TFETs) are attractive for low-power systems. While TFETs are functionally somewhat similar to MOSFETs, the newly proposed tunneling transistors such as SymFETs and BiSFETs demonstrate more “exotic” characteristics that are significantly different from MOSFETs. We look at the possible applications of TFETs and SymFETs for unconventional signal processing by employing their signature behaviors. We focus on networks of interconnected nonlinear elements which can process data coming from a large number of inputs (e.g., sensors) in an analog fashion. Specifically, we investigate several applications of TFET and SymFET in directional and anisotropic diffusion, estimating Gaussian distance of different patterns in analog associative memories, and estimating minimum/maximum or variance of analog data. We show that such circuits have reduced complexity and/or enhanced power efficiency.","Tunneling,
Field effect transistors,
Neural networks,
Power dissipation,
Low-power electronics"
Simulation and formal verification of x86 machine-code programs that make system calls,"We present an approach to modeling and verifying machine-code programs that exhibit non-determinism. Specifically, we add support for system calls to our formal, executable model of the user-level x86 instruction-set architecture (ISA). The resulting model, implemented in the ACL2 theorem-proving system, allows both formal analysis and efficient simulation of x86 machine-code programs; the logical mode characterizes an external environment to support reasoning about programs that interact with an operating system, and the execution mode directly queries the underlying operating system to support simulation. The execution mode of our x86 model is validated against both its logical mode and the real machine, providing test-based assurance that our model faithfully represents the semantics of an actual x86 processor. Our framework is the first that enables mechanical proofs of functional correctness of user-level x86 machine-code programs that make system calls. We demonstrate the capabilities of our model with the mechanical verification of a machine-code program, produced by the GCC compiler, that computes the number of characters, lines, and words in an input stream. Such reasoning is facilitated by our libraries of ACL2 lemmas that allow automated proofs of a program's memory-related properties.","Computational modeling,
Cognition,
Registers,
Standards,
Operating systems,
Analytical models,
Semantics"
"Joint mode selection, MCS assignment, resource allocation and power control for D2D communication underlaying cellular networks","Device-to-device (D2D) communication underlaying a cellular infrastructure has been proposed as a means of facilitating rich local services and offloading the base station traffic. However, D2D communication presents a challenge in radio resource management due to the potential interference it may cause to the cellular network. In this paper, the joint optimization problem of D2D mode selection, modulation and coding schemes (MCSs) assignment, radio resources and power allocation is formulated to minimize the overall power consumption under minimum required rate guarantee. The problem is decoupled into two sub-problems which are solved by Lagrangian relaxation and tabu search methods, respectively. Simulation results show its performance superiority over other schemes, especially in the scenarios with high required rate and limited resources.","Resource management,
Power demand,
Interference,
Algorithm design and analysis,
Power control,
Signal to noise ratio,
Downlink"
Metric Optimization for Surface Analysis in the Laplace-Beltrami Embedding Space,"In this paper, we present a novel approach for the intrinsic mapping of anatomical surfaces and its application in brain mapping research. Using the Laplace-Beltrami eigen-system, we represent each surface with an isometry invariant embedding in a high dimensional space. The key idea in our system is that we realize surface deformation in the embedding space via the iterative optimization of a conformal metric without explicitly perturbing the surface or its embedding. By minimizing a distance measure in the embedding space with metric optimization, our method generates a conformal map directly between surfaces with highly uniform metric distortion and the ability of aligning salient geometric features. Besides pairwise surface maps, we also extend the metric optimization approach for group-wise atlas construction and multi-atlas cortical label fusion. In experimental results, we demonstrate the robustness and generality of our method by applying it to map both cortical and hippocampal surfaces in population studies. For cortical labeling, our method achieves excellent performance in a cross-validation experiment with 40 manually labeled surfaces, and successfully models localized brain development in a pediatric study of 80 subjects. For hippocampal mapping, our method produces much more significant results than two popular tools on a multiple sclerosis study of 109 subjects.","Measurement,
Optimization,
Surface treatment,
Shape,
Educational institutions,
Biomedical imaging,
Brain mapping"
Addressing Short Trapped-Flux Lifetime in High-Density Field-Reversed Configuration Plasmas in FRCHX,"The objective of the field-reversed configuration heating experiment (FRCHX) is to obtain a better understanding of the fundamental scientific issues associated with high-energy density laboratory plasmas (HEDLPs) in strong, closed-field-line magnetic fields. These issues have relevance to such topics as magneto-inertial fusion, laboratory astrophysical research, and intense radiation sources, among others. To create HEDLP conditions, a field-reversed configuration (FRC) plasma of moderate density is first formed via reversed-field theta pinch. It is then translated into a cylindrical aluminum flux conserver (solid liner), where it is trapped between two magnetic mirrors and then compressed by the magnetically driven implosion of the solid liner. A requirement is that, once the FRC is stopped within the solid liner, the trapped flux inside the FRC must persist while the compression process is completed. With the present liner dimensions and implosion drive bank parameters, the total time required for implosion is ~25 μs. Lifetime measurements of recent FRCHX FRCs indicate that trapped lifetimes following capture are now approaching ~14 μs (and therefore, total lifetimes after formation are now approaching ~19 μs). By separating the mirror and translation coil banks into two so that the mirror fields can be set lower initially, the liner compression can now be initiated 7-9 μs before the FRC is formed. A discussion of FRC lifetime-limiting mechanisms and various experimental approaches to extending the FRC lifetime will be presented.",
Real-Time and Offline Performance of Pattern Recognition Myoelectric Control Using a Generic Electrode Grid With Targeted Muscle Reinnervation Patients,"Targeted muscle reinnervation (TMR) is a surgical technique that creates myoelectric prosthesis control sites for high-level amputees. The electromyographic (EMG) signal patterns provided by the reinnervated muscles are well-suited for pattern recognition control. Pattern recognition allows for control of a greater number of degrees of freedom (DOF) than the conventional, EMG amplitude-based approach. Previous pattern recognition studies have shown benefit in placing electrodes directly over the reinnervated muscles. Localizing the optimal TMR locations is inconvenient and time consuming. In this contribution, we demonstrate that a clinically practical grid arrangement of electrodes yields real-time control performance that is equivalent to, or better than, the site-specific electrode placement for simultaneous control of multiple DOFs using pattern recognition. Additional findings indicate that grid-like electrode arrangement yields significantly lower classification errors for classifiers with a large number of movement classes (>9). These findings suggest that a grid electrode arrangement can be effectively used to control a multi-DOF upper limb prosthesis while reducing the time and effort associated with fitting the prosthesis due to clinical localization of control sites on amputee patients.","Electrodes,
Electromyography,
Elbow,
Muscles,
Real-time systems,
Pattern recognition,
Prosthetics"
The SDN controller placement problem for WAN,"Large networks are always partitioned into several small networks when deploying software defined networking (SDN). The network partitioning with SDN control planes open many unanswered questions such as latency, reliability, and load balancing. This paper opens the investigation by focusing on two specific questions: given a wide-area network topology, how to partition it into several small SDN domains, and where should the controller go in each SDN domain? To answer these questions, we propose a novel approach to efficiently and accurately evaluate SDN controller placement problem for WAN. This approach uses the Spectral Clustering placement algorithm to partition a large network into several small SDN domains. After presenting our metrics of the SDN controller placement problem, we evaluate our approach using the Internet2 topology and other available WAN topologies. For testing purposes we developed a new framework to test the SDN controller in WAN. The results show its effectiveness for the SDN controller placement problem.","Wide area networks,
Measurement,
Clustering algorithms,
Topology,
Reliability,
Partitioning algorithms,
Switches"
RSMOA: A revenue and social welfare maximizing online auction for dynamic cloud resource provisioning,"We study online cloud resource auctions where users can arrive anytime and bid for heterogeneous types of virtual machines (VMs) assembled and provisioned on the fly. The proposed auction mechanism RSMOA, to the authors' knowledge, represents the first truthful online mechanism that timely responds to incoming users' demands and makes dynamic resource provisioning and allocation decisions, while guaranteeing efficiency in both the provider's revenue and system social welfare. RSMOA consists of two components: (1) an online mechanism that computes resource allocation and users' payments based on a global, non-decreasing pricing curve, and guarantees truthfulness; (2) a judiciously designed pricing curve, which is derived from a threat-based strategy and guarantees a competitive ratio O(ln(p)) in both system social welfare and the provider's revenue, as compared to the celebrated offline Vickrey-Clarke-Groves (VCG) auction. Here p is the ratio between the upper and lower bounds of users' marginal valuation of a type of resource. The efficacy of RSMOA is validated through extensive theoretical analysis and trace-driven simulation studies.","Cost accounting,
Resource management,
Pricing,
Algorithm design and analysis,
Approximation methods,
Quality of service,
Dynamic scheduling"
Unified Structured Learning for Simultaneous Human Pose Estimation and Garment Attribute Classification,"In this paper, we utilize structured learning to simultaneously address two intertwined problems: 1) human pose estimation (HPE) and 2) garment attribute classification (GAC), which are valuable for a variety of computer vision and multimedia applications. Unlike previous works that usually handle the two problems separately, our approach aims to produce an optimal joint estimation for both HPE and GAC via a unified inference procedure. To this end, we adopt a preprocessing step to detect potential human parts from each image (i.e., a set of candidates) that allows us to have a manageable input space. In this way, the simultaneous inference of HPE and GAC is converted to a structured learning problem, where the inputs are the collections of candidate ensembles, outputs are the joint labels of human parts and garment attributes, and joint feature representation involves various cues such as pose-specific features, garment-specific features, and cross-task features that encode correlations between human parts and garment attributes. Furthermore, we explore the strong edge evidence around the potential human parts so as to derive more powerful representations for oriented human parts. Such evidences can be seamlessly integrated into our structured learning model as a kind of energy function, and the learning process could be performed by standard structured support vector machines algorithm. However, the joint structure of the two problems is a cyclic graph, which hinders efficient inference. To resolve this issue, we compute instead approximate optima using an iterative procedure, where in each iteration, the variables of one problem are fixed. In this way, satisfactory solutions can be efficiently computed by dynamic programming. Experimental results on two benchmark data sets show the state-of-the-art performance of our approach.","Structured learning,
Feature extraction,
Estimation,
Support vector machines,
Inference algorithms"
Optical Differentiator Based on an Integrated Sidewall Phase-Shifted Bragg Grating,We report the implementation of an all-optical temporal differentiator based on an integrated phase-shifted Bragg grating (PSBG) in a compact single-mode silicon-on-insulator ridge waveguide. The integrated PSBG is designed to have a wide reflection notch by creating deep corrugations on the sidewalls of the ridge. The device is fabricated using a CMOS compatible process with 248-nm deep ultraviolet lithography. An experiment is performed. The use of the integrated PSBG for the implementation of an all-optical temporal differentiator is demonstrated.,"Optical waveguides,
Gratings,
Bragg gratings,
Optical device fabrication,
Silicon,
Reflection,
Strips"
DPPC: Dynamic Power Partitioning and Control for Improved Chip Multiprocessor Performance,"A key challenge in chip multiprocessor (CMP) design is to optimize the performance within a power budget limited by the CMP's cooling, packaging, and power supply capacities. Most existing solutions rely solely on dynamic voltage and frequency scaling (DVFS) to adapt the power consumption of CPU cores, without coordinating with the last-level on-chip (e.g., L2) cache. This paper proposes DPPC, a chip-level power partitioning and control strategy that can dynamically and explicitly partition the chip-level power budget among different CPU cores and the shared last-level cache in a CMP based on the workload characteristics measured online. DPPC features a novel performance-power model and an online model estimator to quantitatively estimate the performance contributed by each core and the cache with their respective local power budgets. DPPC then re-partitions the chip-level power budget among them for optimized CMP performance. The partitioned local power budgets for the CPU cores and cache are precisely enforced by power control algorithms designed rigorously based on feedback control theory. Our extensive experimental results demonstrate that DPPC achieves better CMP performance, within a given power budget, than several state-of-the-art power control solutions for both SPEC CPU2006 benchmarks and multi-threaded SPLASH-2 workloads.","Power demand,
Power control,
Central Processing Unit,
Monitoring,
Modulation,
Temperature sensors,
Temperature measurement"
A Short-Term Energy Storage System for Voltage Quality Improvement in Distributed Wind Power,"Wind power (WP) penetration in weak distribution networks is associated with adverse impacts on voltage quality. The installation of an energy storage system (ESS) is a possible voltage quality remedy in such milieus. This paper proposes a supercapacitor ESS for alleviation of voltage flicker resulting from WP integration. The proposed ESS control and management are tailored to that purpose such that the ESS offsets the flicker-producing fluctuations in the generated WP. The proposed power sizing of the ESS is defined by the estimated turbulence intensity and wind speed average at the installation site. A 2 MW wind generator of the doubly fed induction generator type is employed as a source of WP and simulations are conducted on a simplified test system, as well as a detailed 25 kV distribution network on which results are compared with acknowledged reactive power flicker mitigation approaches and verified by prototyping in a real-time simulation platform. The flicker measurement procedure is conducted per IEC Standard 61000-4-15.","Wind speed,
Voltage control,
Supercapacitors,
Oscillators,
Current control,
Wind turbines"
Picosecond Resolution Time-to-Digital Converter Using {{\rm G}_{\rm m}} \hbox{-C} Integrator and SAR-ADC,"A picosecond resolution time-to-digital converter (TDC) is presented. The resolution of a conventional delay chain TDC is limited by the delay of a logic buffer. Various types of recent TDCs are successful in breaking this limitation, but they require a significant calibration effort to achieve picosecond resolution with a sufficient linear range. To address these issues, we propose a simple method to break the resolution limitation without any calibration: a Gm-C integrator followed by a successive approximation register analog-to-digital converter (SAR-ADC). This translates the time interval into charge, and then the charge is quantized. A prototype chip was fabricated in 90 nm CMOS. The measurement results reveal a 1 ps resolution, a -0.6/0.7 LSB differential nonlinearity (DNL), a -1.1/2.3 LSB integral nonlinearity (INL), and a 9-bit range. The measured 11.74 ps single-shot precision is caused by the noise of the integrator. We analyze the noise of the integrator and propose an improved front-end circuit to reduce this noise. The proposal is verified by simulations showing the maximum single-shot precision is less than 1 ps. The proposed front-end circuit can also diminish the mismatch effects.","Noise,
Capacitors,
Switches,
Computer architecture,
Calibration,
Delays"
Prediction of Power Supply Noise From Switching Activity in an FPGA,"Switching current drawn by an integrated circuit (IC) creates dynamic power supply noise on the IC and on the printed circuit board (PCB), which in turn causes jitter in I/ O signals and reduces the maximum clock frequency. Predicting power supply noise is challenging due to the complexity of determining the dynamic current drawn by the IC and the impedance of the power delivery network. In this paper, a methodology is developed for predicting dynamic power supply noise on the PCB resulting from logic activity in a field-programmable gate array (FPGA). Time-domain switching currents within the FPGA are found by performing power simulations of the implemented logic over small time intervals. A high-frequency model of the die-package-PCB power delivery network is developed based on the inductance and capacitance of the package and die and a cavity model description of the PCB. The technique is shown to accurately predict noise on the PCB in both the time and frequency domains.","Noise,
Impedance,
Field programmable gate arrays,
Capacitors,
Ports (Computers),
Integrated circuit modeling,
Power supplies"
Multi-target visual tracking with aerial robots,"We study the problem of tracking mobile targets using a team of aerial robots. Each robot carries a camera to detect targets moving on the ground. The overall goal is to plan for the trajectories of the robots in order to track the most number of targets, and accurately estimate the target locations using the images. The two objectives can conflict since a robot may fly to a higher altitude and potentially cover a larger number of targets at the expense of accuracy. We start by showing that k ≥ 3 robots may not be able to track all n targets while maintaining a constant factor approximation of the optimal quality of tracking at all times. Next, we study the problem of choosing robot trajectories to maximize either the number of targets tracked or the quality of tracking. We formulate this problem as the weighted version of a combinatorial optimization problem known as the Maximum Group Coverage (MGC) problem. A greedy algorithm yields a 1/2 approximation for the weighted MGC problem. Finally, we evaluate the algorithm and the sensing model through simulations and preliminary experiments.","Target tracking,
Trajectory,
Cameras,
Robot vision systems"
Neonatal Seizure Detection Using Atomic Decomposition With a Novel Dictionary,"Atomic decomposition (AD) can be used to efficiently decompose an arbitrary signal. In this paper, we present a method to detect neonatal electroencephalogram (EEG) seizure based on AD via orthogonal matching pursuit using a novel, application-specific, dictionary. The dictionary consists of pseudoperiodic Duffing oscillator atoms which are designed to be coherent with the seizure epochs. The relative structural complexity (a measure of the rate of convergence of AD) is used as the sole feature for seizure detection. The proposed feature was tested on a large clinical dataset of 826 h of EEG data from 18 full-term newborns with 1389 seizures. The seizure detection system using the proposed dictionary was able to achieve a median receiver operator characteristic area of 0.91 (IQR 0.87-0.95) across 18 neonates.",
Manipulating the Experience of Reality for Rehabilitation Applications,"Augmented reality (AR) has the potential to change the way therapy and rehabilitation is understood and administered. It can be used to manipulate the experience of reality, resulting in novel rehabilitative applications including but not limited to augmented mirror box (AMB) manipulations. We present a conceptual framework for the effective use of AR in a therapeutic context developed around the aspects of belief, interactivity, predictability, and decoupling. This framework is based on previous work in perception and emotion manipulation and is derived from and illustrated with a number of empirical studies. In particular, we describe how our augmented reflection technology (ART) system is able to manipulate the experience of reality in an effective way and how this demonstrates the potential of augmented environments to improve health and wellbeing.",
Biometric Recognition via Probabilistic Spatial Projection of Eye Movement Trajectories in Dynamic Visual Environments,"This paper proposes a method for the extraction of biometric features from the spatial patterns formed by eye movements during an inspection of dynamic visual stimulus. In the suggested framework, each eye movement signal is transformed into a time-constrained decomposition by using a probabilistic representation of spatial and temporal features related to eye fixations and called fixation density map (FDM). The results for a large collection of eye movements recorded from 200 individuals indicate the best equal error rate of 10.8% and Rank-1 identification rate as high as 51%, which is a significant improvement over existing eye movement-driven biometric methods. In addition, our experiments reveal that a person recognition approach based on the FDM performs well even in cases when eye movement data are captured at lower than optimum sampling frequencies. This property is very important for the future ocular biometric systems where existing iris recognition devices could be employed to combine eye movement traits with iris information for increased security and accuracy. Considering that commercial iris recognition devices are able to implement eye image sampling usually at a relatively low rate, the ability to perform eye movement-driven biometrics at such rates is of great significance.",
A Semantically Enriched Context-Aware OER Recommendation Strategy and Its Application to a Computer Science OER Repository,"This paper describes a knowledge-based strategy for recommending educational resources-worked problems, exercises, quiz questions, and lecture notes-to learners in the first two courses in the introductory sequence of a computer science major (CS1 and CS2). The goal of the recommendation strategy is to provide support for personalized access to the resources that exist in open educational repositories. The strategy uses: 1) a description of the resources based on metadata standards enriched by ontology-based semantic indexing, and 2) contextual information about the user (her knowledge of that particular field of learning). The results of an experimental analysis of the strategy's performance are presented. These demonstrate that the proposed strategy offers a high level of personalization and can be adapted to the user. An application of the strategy to a repository of computer science open educational resources was well received by both educators and students and had promising effects on the student performance and dropout rates.",
Efficient Coding for Interactive Communication,"We revisit the problem of reliable interactive communication over a noisy channel and obtain the first fully (randomized) efficient constant-rate emulation procedure for reliable interactive communication. Our protocol works for any discrete memoryless noisy channel with constant capacity and fails with exponentially small probability in the total length of the protocol. Following a work by Schulman (1993), our simulation uses a tree-code, yet as opposed to the nonefficient construction of absolute tree-code used by Schulman, we introduce a relaxation in the notion of goodness for a tree code and define a potent tree code. This relaxation allows us to construct an efficient emulation procedure for any two-party protocol. Our results also extend to the case of interactive multiparty communication. We show that a randomly generated tree code (with suitable constant alphabet size) is an efficiently decodable potent tree code with overwhelming probability. Furthermore, we are able to partially derandomize this result by means of epsilon-biased distributions using only O(N) random bits, where N is the depth of the tree.","Protocols,
Emulation,
Hamming distance,
Noise measurement,
Encoding,
Reliability,
Capacity planning"
"A LLC-Type Dual-Bridge Resonant Converter: Analysis, Design, Simulation, and Experimental Results","In this paper, a high-frequency isolated dual-bridge LLC -type resonant converter is proposed. The steady-state analysis of the proposed converter is performed using a modified fundamental harmonics approximation approach, by which the component stress can be obtained quickly without complicated calculation. Necessary and sufficient conditions for zero-voltage switching of all switches are derived too. To illustrate the usefulness of the FHA analysis for a fast design, a design example of a 100 kHz, 200 V input, 40-48 V output 300 W converter is given. Computer simulation and experiment results are included for the purpose of validation. It is shown that this converter is able to maintain zero-voltage switching operation for a wide load range while keeping high efficiency.","Zero voltage switching,
Bridge circuits,
Steady-state,
Switches,
Hafnium,
Harmonic analysis,
Switching frequency"
TenniVis: Visualization for Tennis Match Analysis,"Existing research efforts into tennis visualization have primarily focused on using ball and player tracking data to enhance professional tennis broadcasts and to aid coaches in helping their students. Gathering and analyzing this data typically requires the use of an array of synchronized cameras, which are expensive for non-professional tennis matches. In this paper, we propose TenniVis, a novel tennis match visualization system that relies entirely on data that can be easily collected, such as score, point outcomes, point lengths, service information, and match videos that can be captured by one consumer-level camera. It provides two new visualizations to allow tennis coaches and players to quickly gain insights into match performance. It also provides rich interactions to support ad hoc hypothesis development and testing. We first demonstrate the usefulness of the system by analyzing the 2007 Australian Open men's singles final. We then validate its usability by two pilot user studies where two college tennis coaches analyzed the matches of their own players. The results indicate that useful insights can quickly be discovered and ad hoc hypotheses based on these insights can conveniently be tested through linked match videos.","Games,
Entertainment,
Data visualization,
Image color analysis,
Cameras,
Information analysis"
Active Learning of Pareto Fronts,"This paper introduces the active learning of Pareto fronts (ALP) algorithm, a novel approach to recover the Pareto front of a multiobjective optimization problem. ALP casts the identification of the Pareto front into a supervised machine learning task. This approach enables an analytical model of the Pareto front to be built. The computational effort in generating the supervised information is reduced by an active learning strategy. In particular, the model is learned from a set of informative training objective vectors. The training objective vectors are approximated Pareto-optimal vectors obtained by solving different scalarized problem instances. The experimental results show that ALP achieves an accurate Pareto front approximation with a lower computational effort than state-of-the-art estimation of distribution algorithms and widely known genetic techniques.","Training,
Vectors,
Optimization,
Uncertainty,
Approximation methods,
Linear programming,
Analytical models"
Diagnostic expert system of transformer insulation systems using the acoustic emission method,"The subject matter of this paper refers to the improvement of the acoustic emission (AE) method when used for detection, measurement and location of partial discharges (PDs) in oil insulation systems of power appliances. In particular, presents the basic assumptions and describe the individual elements of an expert diagnostic system, which uses an acoustic method to asset the state of the measured power transformer insulation, performed during their normal work in industrial conditions. The system will consist of four basic modules, i.e. measuring system, processing-analyzing system, knowledge base and classifier. These modules are characterized successively in Point 2 of the paper. Special attention is given to the description of the group of multiparametric descriptors characterizing the AE signals in the time, frequency and time-frequency domains, to descriptive statistics indexes and correlative parameters. Accordant descriptors make it possible, at strictly defined metrological conditions, to recognize basic PD forms that may occur in paper-oil insulation. In this way a catalogued knowledge base containing the socalled 'fingerprints' was created for basic types of high-voltage defects of insulation system.","Partial discharges,
Insulation,
Frequency measurement,
Acoustic measurements,
Power transformer insulation,
Power measurement"
Dynamic Wide Area Voltage Control Strategy Based on Organized Multi-Agent System,"Employment of multi-agent system (MAS) principle in power systems can provide a discipline for interrelations between the host computers in different substations in order to enhance the effectiveness and efficiency of remedial actions and consequently power system operation against disturbance occurrence. In this paper, two types of these disciplines, each of which constructs an organization for agents, are explained and their performances in voltage control of a power system (in the context of steady state regime) are examined and compared on Nordic32 as test power system. These MASs may be implemented as the main structure of a wide area monitoring, protection and control (WAMPAC) system.","Voltage control,
Multi-agent systems,
Power system dynamics,
Power system stability,
Wide area measurements"
Constructing Limited Scale-Free Topologies over Peer-to-Peer Networks,"Overlay network topology together with peer/data organization and search algorithm are the crucial components of unstructured peer-to-peer (P2P) networks as they directly affect the efficiency of search on such networks. Scale-free (power-law) overlay network topologies are among structures that offer high performance for these networks. A key problem for these topologies is the existence of hubs, nodes with high connectivity. Yet, the peers in a typical unstructured P2P network may not be willing or able to cope with such high connectivity and its associated load. Therefore, some hard cutoffs are often imposed on the number of edges that each peer can have, restricting feasible overlays to limited or truncated scale-free networks. In this paper, we analyze the growth of such limited scale-free networks and propose two different algorithms for constructing perfect scale-free overlay network topologies at each instance of such growth. Our algorithms allow the user to define the desired scale-free exponent ( γ). They also induce low communication overhead when network grows from one size to another. Using extensive simulations, we demonstrate that these algorithms indeed generate perfect scale free networks (at each step of network growth) that provide better search efficiency in various search algorithms than the networks generated by the existing solutions.","Peer-to-peer computing,
Network topology,
Topology,
Overlay networks,
Computational modeling,
Barium,
Biological system modeling"
Performance of a Massively Parallel Higher-Order Method of Moments Code Using Thousands of CPUs and Its Applications,"The efficiency of a parallel higher-order method of moments is illustrated using up to 4096 CPU cores on a supercomputer. The scattering problems solved include the analysis from two full scale airplanes and the radiation problems include performance of a microstrip patch phased array antenna mounted on an airplane. Both the scattering and radiation problems are simulated to demonstrate the efficiency of the algorithm implementation. Numerical results show that one can achieve above 60% efficiency when the used memory to the total memory ratio is larger than 15%, and the time can reach a theoretical value between O (N2) and O (N3), where N is the number of unknowns. Due to its high efficiency, the algorithm is able to accurately solve large complex electromagnetic problems including composite and multiscale structures.",
On-Chip Sample Preparation for Multiple Targets Using Digital Microfluidics,"In many biochemical protocols, sample preparation is an extremely important step for mixing multiple reagents in a given ratio. Dilution of a biochemical sample/reagent is the special case of mixing or solution preparation where only two fluids (sample and buffer) are mixed at a certain ratio corresponding to the desired concentration factor. Many bioassays often require multiple concentration values of the same sample/reagent, and implementing them efficiently on a digital microfluidic biochip is a challenge. In this paper, we present an algorithmic solution for the problem of producing a set of different target droplets in a minimum number of mix-split steps, and satisfying a given upper bound in concentration error. Unlike prior methods, this approach does not require any intermediate storage. We represent the underlying search space using a binary de Brujin graph and show that a shortest mix-split sequence can be obtained by solving an asymmetric traveling salesman problem therein. Simulation results over a large data set reveal that the proposed technique outperforms existing methods in terms of the number of mix-split steps, waste droplets, and reactant usage. The method is applicable in general scenarios of either one mixer or more mixers on the chip. A digital microfluidic platform can be easily designed to implement such a technique for rapid on-chip sample preparation.","System-on-chip,
Accuracy,
Buffer storage,
Minimization,
Real-time systems,
Sugar,
Proteins"
"Asymptotically near-optimal RRT for fast, high-quality, motion planning","We present Lower Bound Tree-RRT (LBT-RRT), a single-query sampling-based algorithm that is asymptotically near-optimal. Namely, the solution extracted from LBT-RRT converges to a solution that is within an approximation factor of 1 + ε of the optimal solution. Our algorithm allows for a continuous interpolation between the fast RRT algorithm and the asymptotically optimal RRT* and RRG algorithms. When the approximation factor is 1 (i.e., no approximation is allowed), LBT-RRT behaves like the RRT* algorithm. When the approximation factor is unbounded, LBT-RRT behaves like the RRT algorithm. In between, LBT-RRT is shown to produce paths that have higher quality than RRT would produce and run faster than RRT* would run. This is done by maintaining a tree which is a sub-graph of the RRG roadmap and a second, auxiliary tree, which we call the lower-bound tree. The combination of the two trees, which is faster to maintain than the tree maintained by RRT*, efficiently guarantee asymptotic near-optimality. We suggest to use LBT-RRT for high-quality, anytime motion planning. We demonstrate the performance of the algorithm for scenarios ranging from 3 to 12 degrees of freedom and show that even for small approximation factors, the algorithm produces high-quality solutions (comparable to RRT*) with little runtime overhead when compared to RRT.","Approximation algorithms,
Approximation methods,
Robots,
Algorithm design and analysis,
Motion-planning,
Convergence"
A new class of learning automata for selecting an optimal subset,"Interacting with a random environment, Learning Automata (LAs) are automata that, generally, have the task of learning the optimal action based on responses from the environment. Distinct from the traditional goal of Learning Automata to select only the optimal action out of a set of actions, this paper considers a multiple-action selection problem and proposes a novel class of Learning Automata for selecting an optimal subset of actions. Their objective is to identify the optimal subset: the top k out of r actions. Based on conventional continuous pursuit and discretized pursuit learning schemes, this paper introduces four pursuit learning schemes for selecting the optimal subset, called continuous equal pursuit, discretized equal pursuit, continuous unequal pursuit and discretized unequal pursuit learning schemes, respectively. In conjunction with a reward-inaction learning paradigm, the above four schemes lead to four versions of pursuit Learning Automata for selecting the optimal subset. The simulation results present a quantitative comparison between them.","Learning automata,
Vectors,
Pursuit algorithms,
Optimization,
Cybernetics,
Equations,
Simulation"
Communication technologies for smart metering infrastructure,"Major components of smart metering infrastructure are smart meter, communication network, meter data collection system and meter data management system. Smart meter measures energy usage at different time intervals and transmit measured data to utility through communications technology networks. This infrastructure shall provide a reliable, efficient and secure power supply to the consumers and reduce the cost of electricity. In this paper, we review smart metering infrastructure model, smart metering infrastructure communication network options and outline smart metering infrastructure challenges.","Smart grids,
Communication networks,
Wide area networks,
IEEE 802.15 Standards,
Reliability,
Load management"
Investigating the Energy Sink-Hole Problem in Connected k -Covered Wireless Sensor Networks,"In immobile wireless sensor networks with constant data reporting, the sensors nearer the sink are responsible for forwarding data to it on behalf of all other sensors in the network. Those sensors suffer from a severe batter power depletion problem, also known as the energy sink-hole problem. In this paper, we study the above problem in duty-cycled connected \mbik-covered wireless sensor networks, where each point in a field of interest is covered by at least \mbik sensor. In order to change the neighbors of a sink over time, our solutions suggest the use of mobile proxy sinks that collect data from source sensors and drop them off at an immobile sink. Our proposed three-tier architecture has immobile source sensors, immobile sinks, and mobile proxy sinks. First, we present our fundamental results for the design of duty-cycled connected \mbik-covered wireless sensor networks. Second, we provide the first formal analysis of the performance of joint mobility and routing in this type of network. Precisely, we investigate the best mobility strategy of mobile proxy sinks to minimize the total energy consumption for data collection. Third, we propose joint mobility and routing schemes based on the number of immobile sinks and mobile proxy sinks. We provide a thorough analytical model for our schemes. Finally, we evaluate their performance by simulation. Our results show their significant improvement of the network lifetime compared to a solution without mobile proxy sinks.","Wireless sensor networks,
Mobile communication,
Sensors,
Energy consumption,
Data collection,
Routing protocols"
Numerical Simulation of the Characteristics of Heavy Particles in Bar-Plate DC Positive Corona Discharge Based on a Hybrid Model,"An improved, multicomponent, and 2-D hybrid model is presented in detail for the simulation of bar-plate dc corona discharge in dry air (O2:N2=1:4). The model is based on plasma hydrodynamics, and chemical models in which 12 species (e, O, O2, O3, O2+, O4+, O2-, O-, N2, N2+, N4+, and N2 O2+) and 32 collision reactions between such species are considered. In addition, the photoionization and secondary electron emission effects are also incorporated within the model. The simulation is established with a bar-plate electrode configuration with an interelectrode gap of 5.0 mm, where the positive dc voltage applied to the bar is 3.0 kV, the pressure in air discharge is fixed at 1.0 atm, and the gas temperature is assumed to be a constant (300 K). Using individual discharge current waveform and V-I curve, the effectiveness of this developed model is validated by experimental results. With this hybrid model, electric field distribution and net space charge distribution at four representative time points during a pulse are discussed. Moreover, the composition and distribution of particles are analyzed emphatically. The obtained results show that, among all reactions, the reaction rate of R1, which is the collision reaction between electron and N2 is maximal, whereas the N2+ density is significantly less than O4+ and O2+. O2- has the largest number of negative ions and thus restrains the electron collision process significantly. In addition to N2 and O2, O is the major neutral particle, but owing to the small quantity of neutral particles, the effect is relatively weak. The obtained results will provide valuable insights into the physical mechanism of positive corona discharge in air.",
Data-Dependent Hashing Based on p-Stable Distribution,"The p-stable distribution is traditionally used for data-independent hashing. In this paper, we describe how to perform data-dependent hashing based on p-stable distribution. We commence by formulating the Euclidean distance preserving property in terms of variance estimation. Based on this property, we develop a projection method, which maps the original data to arbitrary dimensional vectors. Each projection vector is a linear combination of multiple random vectors subject to p-stable distribution, in which the weights for the linear combination are learned based on the training data. An orthogonal matrix is then learned data-dependently for minimizing the thresholding error in quantization. Combining the projection method and orthogonal matrix, we develop an unsupervised hashing scheme, which preserves the Euclidean distance. Compared with data-independent hashing methods, our method takes the data distribution into consideration and gives more accurate hashing results with compact hash codes. Different from many data-dependent hashing methods, our method accommodates multiple hash tables and is not restricted by the number of hash functions. To extend our method to a supervised scenario, we incorporate a supervised label propagation scheme into the proposed projection method. This results in a supervised hashing scheme, which preserves semantic similarity of data. Experimental results show that our methods have outperformed several state-of-the-art hashing approaches in both effectiveness and efficiency.",
Soft biometrics for subject identification using clothing attributes,"Recently, soft biometrics has emerged as a novel attribute-based person description for identification. It is likely that soft biometrics can be deployed where other biometrics cannot, and have stronger invariance properties than vision-based biometrics, such as invariance to illumination and contrast. Previously, a variety of bodily soft biometrics has been used for identifying people. Describing a person by their clothing properties is a natural task performed by people. As yet, clothing descriptions have attracted little attention for identification purposes. There has been some usage of clothing attributes to augment biometric description, but a detailed description has yet to be used. We show here how clothing traits can be exploited for identification purposes. We explore the validity and usability of a set of proposed semantic attributes. Human identification is performed, evaluated and compared using different proposed forms of soft clothing traits in addition and in isolation.",
Ultralow Sub-1-nA Operating Current Resistive Memory With Intrinsic Non-Linear Characteristics,"Sub-1-nA operating current conductive-bridge resistive memory devices showing pronounced rectifying behavior have been demonstrated in a cell structure consisting of Cu top electrode, atomic layer deposition Al2O3 switching film and polysilicon bottom electrode as an in-cell resistor. This ultralow current provides energy savings by minimizing write, erase, and read currents. Despite having such low currents, excellent retention, ON/OFF ratio, and endurance have been demonstrated. Devices programmed with <;1-nA peak current pass 6 h retention test at 85°C and show no significant degradation after 10000 write/erase cycles. Due to the partially formed filament, the devices at ON-state exhibit pronounced nonlinear I-V and current rectification-both factors are very beneficial for RRAM array operation. Multilevel storage can be obtained by controlling the filament shape through compliance current.","Random access memory,
Atomic layer deposition,
Nonvolatile memory,
Resistance,
Aluminum oxide,
Electron mobility"
Perceptual Annotation: Measuring Human Vision to Improve Computer Vision,"For many problems in computer vision, human learners are considerably better than machines. Humans possess highly accurate internal recognition and learning mechanisms that are not yet understood, and they frequently have access to more extensive training data through a lifetime of unbiased experience with the visual world. We propose to use visual psychophysics to directly leverage the abilities of human subjects to build better machine learning systems. First, we use an advanced online psychometric testing platform to make new kinds of annotation data available for learning. Second, we develop a technique for harnessing these new kinds of information-“perceptual annotations”-for support vector machines. A key intuition for this approach is that while it may remain infeasible to dramatically increase the amount of data and high-quality labels available for the training of a given system, measuring the exemplar-by-exemplar difficulty and pattern of errors of human annotators can provide important information for regularizing the solution of the system at hand. A case study for the problem face detection demonstrates that this approach yields state-of-the-art results on the challenging FDDB data set.","Face,
Training,
Support vector machines,
Face detection,
Visualization,
Training data,
Accuracy"
Dynamic Rate Adaptation for Improved Throughput and Delay in Wireless Network Coded Broadcast,"In this paper, we provide theoretical and simulation-based study of the delivery delay performance of a number of existing throughput-optimal coding schemes and use the results to design a new dynamic rate adaptation scheme that achieves improved overall throughput-delay performance. Under a baseline rate control scheme, the receivers' delay performance is examined. Based on their Markov states, the knowledge difference between the sender and receiver, three distinct methods for packet delivery are identified: zero state, leader state, and coefficient-based delivery. We provide analyses of each of these and show that, in many cases, zero state delivery alone presents a tractable approximation of the expected packet delivery behavior. Interestingly, while coefficient-based delivery has so far been treated as a secondary effect in the literature, we find that the choice of coefficients is extremely important in determining the delay, and a well-chosen encoding scheme can, in fact, contribute a significant improvement to the delivery delay. Based on our delivery delay model, we develop a dynamic rate adaptation scheme that uses performance prediction models to determine the sender transmission rate. Surprisingly, taking this approach leads us to the simple conclusion that the sender should regulate its addition rate based on the total number of undelivered packets stored at the receivers. We show that despite its simplicity, our proposed dynamic rate adaptation scheme results in noticeably improved throughput-delay performance over existing schemes in the literature.","Receivers,
Delays,
Encoding,
Markov processes,
Throughput,
Decoding,
Network coding"
Measure the Semantic Similarity of GO Terms Using Aggregate Information Content,"The rapid development of gene ontology (GO) and huge amount of biomedical data annotated by GO terms necessitate computation of semantic similarity of GO terms and, in turn, measurement of functional similarity of genes based on their annotations. In this paper we propose a novel and efficient method to measure the semantic similarity of GO terms. The proposed method addresses the limitations in existing GO term similarity measurement techniques; it computes the semantic content of a GO term by considering the information content of all of its ancestor terms in the graph. The aggregate information content (AIC) of all ancestor terms of a GO term implicitly reflects the GO term's location in the GO graph and also represents how human beings use this GO term and all its ancestor terms to annotate genes. We show that semantic similarity of GO terms obtained by our method closely matches the human perception. Extensive experimental studies show that this novel method also outperforms all existing methods in terms of the correlation with gene expression data. We have developed web services for measuring semantic similarity of GO terms and functional similarity of genes using the proposed AIC method and other popular methods. These web services are available at http://bioinformatics.clemson.edu/G-SESAME.",
Learning Multi-Boosted HMMs for Lip-Password Based Speaker Verification,"This paper proposes a concept of lip motion password (simply called lip-password hereinafter), which is composed of a password embedded in the lip movement and the underlying characteristic of lip motion. It provides a double security to a visual speaker verification system, where the speaker is verified by both of the private password information and the underlying behavioral biometrics of lip motions simultaneously. Accordingly, the target speaker saying the wrong password or an impostor who knows the correct password will be detected and rejected. To this end, we shall present a multi-boosted Hidden Markov model (HMM) learning approach to such a system. Initially, we extract a group of representative visual features to characterize each lip frame. Then, an effective lip motion segmentation algorithm is addressed to segment the lip-password sequence into a small set of distinguishable subunits. Subsequently, we integrate HMMs with boosting learning framework associated with a random subspace method and data sharing scheme to formulate a precise decision boundary for these subunits verification, featuring on high discrimination power. Finally, the lip-password, whether spoken by the target speaker with the pre-registered password or not, is identified based on all the subunit verification results learned from multi-boosted HMMs. The experimental results show that the proposed approach performs favorably compared with the state-of-the-art methods.","Hidden Markov models,
Feature extraction,
Visualization,
Mouth,
Motion segmentation,
Boosting,
Biometrics (access control)"
Modeling of GaN-Based Normally-Off FinFET,"In this letter, a macromodel for normally-off (enhancement mode) AlGaN/GaN-based FinFET (2-DEG channel at top with two MOS like sidewall channels) is proposed. AlGaN/GaN-based FinFET devices have improved gate control on the channel due to additional sidewall gates compared with planar structures, but device characteristics exhibit strong nonlinear dependence on fin-width. The proposed model captures both 2-DEG and sidewall channel conduction as well as the fin-width dependency on device characteristics. Model shows excellent agreement with state-of-the-art experimental data.","Gallium nitride,
Aluminum gallium nitride,
FinFETs,
Logic gates,
Data models,
HEMTs"
Autonomous MAV guidance with a lightweight omnidirectional vision sensor,"This study describes the design and implementation of several bioinspired algorithms for providing guidance to an ultra-lightweight micro-aerial vehicle (MAV) using a 2.6 g omnidirectional vision sensor. Using this visual guidance system we demonstrate autonomous speed control, centring, and heading stabilisation on board a 30 g MAV flying in a corridor-like environment. In addition to the computation of wide-field optic flow, the comparatively high-resolution omnidirectional imagery provided by this sensor also offers the potential for image-based algorithms such as landmark recognition to be implemented in the future.",
Layered image/video softcast with hybrid digital-analog transmission for robust wireless visual communication,"Due to the mobility of transceivers and the interference from other signals, the condition of a wireless channel may vary drastically and unpredictably. In such scenario, conventional communication systems usually suffer from cliff effect due to the nature of entropy coding and channel coding. The recently proposed SoftCast scheme, on the contrary, achieves smooth quality degradation by employing analog-like transmission, together with efficient decorrelation and power allocation. However, the analog-like transmission in SoftCast is not always efficient in terms of power usage, when compared with digital approaches. In this paper, we propose a layered image/video SoftCast scheme, in which a coarse approximation of the image is coded in a base layer and transmitted in digital way while the remained image details are represented in an enhancement layer and sent out using the SoftCast way. Since a major part of the signal energy is transmitted in the base layer using digital approach, the efficiency of power usage in the enhancement layer is improved remarkably. Experimental results show that the proposed scheme can outperform the original SoftCast scheme remarkably, while still preserving the smooth quality degradation characteristic of SoftCast.",
Private Empirical Risk Minimization: Efficient Algorithms and Tight Error Bounds,"Convex empirical risk minimization is a basic tool in machine learning and statistics. We provide new algorithms and matching lower bounds for differentially private convex empirical risk minimization assuming only that each data point's contribution to the loss function is Lipschitz and that the domain of optimization is bounded. We provide a separate set of algorithms and matching lower bounds for the setting in which the loss functions are known to also be strongly convex. Our algorithms run in polynomial time, and in some cases even match the optimal nonprivate running time (as measured by oracle complexity). We give separate algorithms (and lower bounds) for (ε, 0)and (ε, δ)-differential privacy; perhaps surprisingly, the techniques used for designing optimal algorithms in the two cases are completely different. Our lower bounds apply even to very simple, smooth function families, such as linear and quadratic functions. This implies that algorithms from previous work can be used to obtain optimal error rates, under the additional assumption that the contributions of each data point to the loss function is smooth. We show that simple approaches to smoothing arbitrary loss functions (in order to apply previous techniques) do not yield optimal error rates. In particular, optimal algorithms were not previously known for problems such as training support vector machines and the high-dimensional median.","Privacy,
Convex functions,
Algorithm design and analysis,
Support vector machines,
Optimization,
Noise measurement,
Risk management"
Three New Families of Zero-Difference Balanced Functions With Applications,"Zero-difference balanced (ZDB) functions integrate a number of subjects in combinatorics and algebra, and have many applications in coding theory, cryptography, and communications engineering. In this paper, three new families of ZDB functions are presented. The first construction gives ZDB functions defined on the abelian groups (GF(q1)×,...,×GF(qk),+) with new and flexible parameters. The other two constructions are based on 2-cyclotomic cosets and yield ZDB functions on \BBZn with new parameters. The parameters of optimal constant composition codes, optimal, and perfect difference systems of sets obtained from these new families of ZDB functions are also summarized.",
Automatic Detection and Measurement of Structures in Fetal Head Ultrasound Volumes Using Sequential Estimation and Integrated Detection Network (IDN),"Routine ultrasound exam in the second and third trimesters of pregnancy involves manually measuring fetal head and brain structures in 2-D scans. The procedure requires a sonographer to find the standardized visualization planes with a probe and manually place measurement calipers on the structures of interest. The process is tedious, time consuming, and introduces user variability into the measurements. This paper proposes an automatic fetal head and brain (AFHB) system for automatically measuring anatomical structures from 3-D ultrasound volumes. The system searches the 3-D volume in a hierarchy of resolutions and by focusing on regions that are likely to be the measured anatomy. The output is a standardized visualization of the plane with correct orientation and centering as well as the biometric measurement of the anatomy. The system is based on a novel framework for detecting multiple structures in 3-D volumes. Since a joint model is difficult to obtain in most practical situations, the structures are detected in a sequence, one-by-one. The detection relies on Sequential Estimation techniques, frequently applied to visual tracking. The interdependence of structure poses and strong prior information embedded in our domain yields faster and more accurate results than detecting the objects individually. The posterior distribution of the structure pose is approximated at each step by sequential Monte Carlo. The samples are propagated within the sequence across multiple structures and hierarchical levels. The probabilistic model helps solve many challenges present in the ultrasound images of the fetus such as speckle noise, signal drop-out, shadows caused by bones, and appearance variations caused by the differences in the fetus gestational age. This is possible by discriminative learning on an extensive database of scans comprising more than two thousand volumes and more than thirteen thousand annotations. The average difference between ground truth and automatic measurements is below 2 mm with a running time of 6.9 s (GPU) or 14.7 s (CPU). The accuracy of the AFHB system is within inter-user variability and the running time is fast, which meets the requirements for clinical use.","Ultrasonic variables measurement,
Ultrasonic imaging,
Three-dimensional displays,
Image segmentation,
Computational modeling,
Fetal ultrasound"
Optimal Index Codes With Near-Extreme Rates,"The min-rank of a digraph was shown to represent the length of an optimal scalar linear solution of the corresponding instance of the Index Coding with Side Information (ICSI) problem. In this paper, the graphs and digraphs of near-extreme min-ranks are studied. Those graphs and digraphs correspond to the ICSI instances having near-extreme transmission rates when using optimal scalar linear index codes. In particular, it is shown that the decision problem whether a digraph has min-rank two is NP-complete. By contrast, the same question for graphs can be answered in polynomial time. In addition, a circuit-packing bound is revisited, and several families of digraphs, optimal with respect to this bound, whose min-ranks can be found in polynomial time, are presented.","Indexes,
Polynomials,
Educational institutions,
Encoding,
Color,
Receivers,
Electronic mail"
Time-Domain-Based Assessment of Data Transmission Error Probability in Smart Grids With Electromagnetic Interference,"Reliable operation of the smart grid requires assurance of the electromagnetic compatibility of sensitive smart metering systems and power electronic converters, which introduce high-level electromagnetic interference. As it has been experimentally shown, currently available, normalized, and frequency domain tests are ineffective for the evaluation of data transmission error hazards. The mathematical time-domain model proposed in this paper enables assessment of the probability of errors occurring in a given transmission signal for known interference parameters. The validity of the model and its practical applicability have been experimentally verified.",
Network formation games for the link selection of cooperative localization in wireless networks,"Recently, localization has become an indispensable technique for wireless applications. In view of the limitation of global position system (GPS) in certain environments, alternative approaches are in demand. In this paper, we consider a cooperative localization approach named sum-product algorithm over a wireless network (SPAWN). Although SPAWN theoretically facilitates cooperative localization, it has several practical limitations. Specifically, SPAWN results in high computational complexity and increased network traffic. The main complexity of SPAWN lies in the selection of agents/anchors involved in the cooperative localization. To this end, we formulate the agent/anchor selection problem into a network formation game. Together with a practical limit on the number of agents/anchors used for cooperative localization, our proposed approach can markedly reduce the computational complexity and the resultant network traffic. Simulations show that these advantages come with a slight degradation in the localization mean squared error (MSE) performance.","Games,
Signal processing algorithms,
Wireless networks,
Computational complexity,
Nickel,
Signal processing"
Deterministic Blind Rendezvous in Cognitive Radio Networks,"Blind rendezvous is a fundamental problem in cognitive radio networks. The problem involves a collection of agents (radios) that wish to discover each other (i.e., rendezvous) in the blind setting where there is no shared infrastructure and they initially have no knowledge of each other. Time is divided into discrete slots and spectrum is divided into discrete channels, [n] = 1, 2, ..., n. Each agent may access (or hop on) a single channel in a single time slot and two agents rendezvous when they hop on the same channel in the same time slot. The goal is to design deterministic channel hopping schedules for each agent so as to guarantee rendezvous between any pair of agents with access to overlapping sets of channels. The problem has three complicating considerations: first, the agents are asymmetric, i.e., each agent Ai only has access to a particular subset Si ⊂ [n] of the channels and different agents may have access to different subsets of channels (clearly, two agents can rendezvous only if their channel subsets overlap), second, the agents are synchronous, i.e., they do not possess a common sense of absolute time, so different agents may commence their channel schedules at different times (they do have a common sense of slot duration), lastly, agents are anonymous i.e., they do not possess an identity, and hence the schedule for Ai must depend only on Si. Whether guaranteed blind rendezvous in the asynchronous model was even achievable was an open problem. In a recent breakthrough, two independent sets of authors, Shin et al. (Communications Letters, 2010) and Lin et al. (INFOCOM, 2011), gave the first constructions guaranteeing asynchronous blind rendezvous in O (n2) and O (n3) time, respectively. We present a substantially improved and conceptually simpler construction guaranteeing that any two agents, Ai, Aj, will rendezvous in O (|Si||Sj| log log n) time. Our results are the first that achieve nontrivial dependence on |Si|, the sizes of the sets of available channels. This allows us, for example, to save roughly a quadratic factor over the best previous results in the important case when channel subsets have constant size. We also achieve the best possible bound of O (1) rendezvous time for the symmetric situation, previous works could do no better than O (n). Using techniques from the probabilistic method and Ramsey theory we establish that our construction is nearly optimal: we show both an Ω (|Si||Sj|) lower bound and an Ω(log log n) lower bound when |Si|, |Sj| ≤ n/2.","Schedules,
Silicon,
Cognitive radio,
Color,
Computer science,
Educational institutions,
Communities"
High performance MPI library over SR-IOV enabled infiniband clusters,"Virtualization has become a central role in HPC Cloud due to easy management and low cost of computation and communication. Recently, Single Root I/O Virtualization (SR-IOV) technology has been introduced for high-performance interconnects such as InfiniBand and can attain near to native performance for inter-node communication. However, the SR-IOV scheme lacks locality aware communication support, which leads to performance overheads for inter-VM communication within a same physical node. To address this issue, this paper first proposes a high performance design of MPI library over SR-IOV enabled InfiniBand clusters by dynamically detecting VM locality and coordinating data movements between SR-IOV and Inter-VM shared memory (IVShmem) channels. Through our proposed design, MPI applications running in virtualized mode can achieve efficient locality-aware communication on SR-IOV enabled InfiniBand clusters. In addition, we optimize communications in IVShmem and SR-IOV channels by analyzing the performance impact of core mechanisms and parameters inside MPI library to deliver better performance in virtual machines. Finally, we conduct comprehensive performance studies by using point-to-point and collective benchmarks, and HPC applications. Experimental evaluations show that our proposed MPI library design can significantly improve the performance for point-to-point and collective operations, and MPI applications with different InfiniBand transport protocols (RC and UD) by up to 158%, 76%, 43%, respectively, compared with SR-IOV. To the best of our knowledge, this is the first study to offer a high performance MPI library that supports efficient locality aware MPI communication over SR-IOV enabled InfiniBand clusters.","Libraries,
Virtualization,
Performance evaluation,
Kernel,
Detectors,
Bandwidth,
Cloud computing"
Assisted Common Information With an Application to Secure Two-Party Sampling,"An important subclass of secure multiparty computation is secure sampling: two parties output samples of a pair of jointly distributed random variables such that neither party learns more about the other party's output than what its own output reveals. The parties make use of a setup - correlated random variables with a different distribution - as well as unlimited noiseless communication. An upperbound on the rate of producing samples of a desired distribution from a given setup is presented. The region of tension developed in this paper measures how well the dependence between a pair of random variables can be resolved by a piece of common information. The bounds on rate are a consequence of a monotonicity property; a protocol between two parties can only lower the tension between their views. Connections are drawn between the region of tension and the notion of common information. A generalization of the Gács-Körner common information, called the assisted common information, which takes into account almost common information ignored by Gács-Körner common information is defined. The region of tension is shown to be related to the rate regions of both the assisted common information and the Gray-Wyner systems (and, a fortiori, Wyner's common information).","Random variables,
Cryptography,
Joints,
Mutual information,
Protocols,
Complexity theory"
"A state of the art review on the Internet of Things (IoT) history, technology and fields of deployment","Internet and its applications have become an integral part of today's human lifestyle. It has become an essential tool in every aspect. Due to the tremendous demand and necessity, researchers went beyond connecting just computers into the web. These researches led to the birth of a sensational gizmo, Internet of Things (IoT). Communication over the internet has grown from user - user interaction to device - device interactions these days. The IoT concepts were proposed years back but still it's in the initial stage of commercial deployment. Home automation industry and transportation industries are seeing rapid growth with IoT. Yet not many articles have been published in this field of study. This paper aims in structuring a state of the art review on IoT. The technology, history and applications have been discussed briefly along with various statistics.","IEEE 802.11 Standards,
Radiofrequency identification,
Bluetooth,
Zigbee,
Internet,
Wireless communication,
Packet loss"
Thermal Facial Analysis for Deception Detection,"Thermal imaging technology can be used to detect stress levels in humans based on the radiated heat from their face. In this paper, we use thermal imaging to monitor the periorbital region's thermal variations and test whether it can offer a discriminative signature for detecting deception. We start by presenting an overview on automated deception detection and propose a novel methodology, which we validate experimentally on 492 thermal responses (249 lies and 243 truths) extracted from 25 participants. The novelty of this paper lies in scoring a larger number of questions per subject, emphasizing a within-person approach for learning from data, proposing a framework for validating the decision making process, and correct evaluation of the generalization performance. A k
-nearest neighbor classifier was used to classify the thermal responses using different strategies for data representation. We report an 87% ability to predict the lie/truth responses based on a within-person methodology and fivefold cross validation. Our results also show that the between-person approach for modeling deception does not generalize very well across the training data.","Accuracy,
Imaging,
Interviews,
Feature extraction,
Thermal analysis,
Stress,
Robustness"
Sensor data collection and irrigation control on vegetable crop using smart phone and wireless sensor networks for smart farm,"Feeding of the world in the 21st century is the biggest challenge, especially for smart farm business. The smart farm has used agriculture automation system instead of traditional agriculture. Traditional agricultural methods employed by the local people are highly sustainable, although the all inclusive cost is not cheap. Our research goal is to provide long term sustainable solution for automation of agriculture. Agriculture automation has several methods to getting data from vegetable crop like sensor for environmental measurement. Therefore, we developed a portable measurement technology including soil moisture sensor, air humidity sensor and air temperature sensor. Moreover, irrigation system using wireless sensor network has installed these sensors, with the purpose for collecting the environment data and controlling the irrigation system via smart phone. The purpose of the experiment is to find better ways of controlling an irrigation system with automatic system and manual control by smart phone. In order to control an irrigation system, we have developed the communication methodology of the wireless sensor network for collected environment data and sending control command to turn on/off irrigation system. It is successful for controlling the irrigation system and controlling the water near the vegetable roots. In this paper, we have attempted to demonstrate the automation of the irrigation system that is useful for farm business which make it comfortable than using traditional agriculture by using smart phone for monitoring and controlling the system. Accordingly, in the long-term has reduced cost as well. The experimental result shows that the accuracy of sending and receiving command control for irrigation system is 96 percent and accuracy of environment collection is 98 percent.","Wireless sensor networks,
Peer-to-peer computing,
Irrigation,
Temperature sensors,
Web servers,
Soil moisture"
TransCom: A Virtual Disk-Based Cloud Computing Platform for Heterogeneous Services,"This paper presents the design, implementation, and evaluation of TransCom, a virtual disk (Vdisk) based cloud computing platform that supports heterogeneous services of operating systems (OSes) and their applications in enterprise environments. In TransCom, clients store all data and software, including OS and application software, on Vdisks that correspond to disk images located on centralized servers, while computing tasks are carried out by the clients. Users can choose to boot any client for using the desired OS, including Windows, and access software and data services from Vdisks as usual without consideration of any other tasks, such as installation, maintenance, and management. By centralizing storage yet distributing computing tasks, TransCom can greatly reduce the potential system maintenance and management costs. We have implemented a multi-platform TransCom prototype that supports both Windows and Linux services. The extensive evaluation based on both test-bed experiments and real-usage experiments has demonstrated that TransCom is a feasible, scalable, and efficient solution for successful real-world use.","Servers,
IP networks,
Cloud computing,
Kernel,
Hard disks,
Linux"
Local Phase Tensor Features for 3-D Ultrasound to Statistical Shape+Pose Spine Model Registration,"Most conventional spine interventions are performed under X-ray fluoroscopy guidance. In recent years, there has been a growing interest to develop nonionizing imaging alternatives to guide these procedures. Ultrasound guidance has emerged as a leading alternative. However, a challenging problem is automatic identification of the spinal anatomy in ultrasound data. In this paper, we propose a local phase-based bone feature enhancement technique that can robustly identify the spine surface in ultrasound images. The local phase information is obtained using a gradient energy tensor filter. This information is used to construct local phase tensors in ultrasound images, which highlight the spine surface. We show that our proposed approach results in a more distinct enhancement of the bone surfaces compared to recently proposed techniques based on monogenic scale-space filters and logarithmic Gabor filters. We also demonstrate that registration accuracy of a statistical shape+pose model of the spine to 3-D ultrasound images can be significantly improved, using the proposed method, compared to those obtained using monogenic scale-space filters and logarithmic Gabor filters.","Bones,
Feature extraction,
Shape,
Three-dimensional displays,
Image edge detection,
Tensile stress,
Pain"
A survey of AUV and robot simulators for multi-vehicle operations,"This paper presents a survey of a selection of currently available simulation software for robots and unmanned vehicles. In particular, the simulators selected are reviewed for their suitability for the simulation of Autonomous Underwater Vehicles (AUVs), as well as their suitability for the simulation of multi-vehicle operations. The criteria for selection are based on the following features: sufficient physical fidelity to allow modelling of manipulators and end effectors; a programmatic interface, via scripting or middleware; modelling of optical and/or acoustic sensors; adequate documentation; previous use in academic research. A subset of the selected simulators are reviewed in greater detail; these are UWSim, MORSE, and Gazebo. This subset of simulators allow virtual sensors to be simulated, such as GPS, sonar, and multibeam sonar making them suitable for the design and simulation of navigation and mission planning algorithms. We conclude that simulation for underwater vehicles remains a niche problem, but with some additional effort researchers wishing to simulate such vehicles may do so, basing their work on existing software.","Robots,
Vehicles,
Engines,
Software,
Sensors,
Physics,
Rendering (computer graphics)"
"A High-Directivity, Wideband, Efficient, Electrically Small Antenna System","A high-directivity, wideband, efficient, near-field resonant parasitic, electrically small antenna system is presented. By introducing two different near-field resonant parasitic (NFRP) Egyptian axe dipole elements oriented in parallel in the near field of a traditional small dipole antenna, two nearby fundamental resonance modes are produced. Both are much lower in frequency than the fundamental mode of the driven dipole. The corresponding frequency bands of both resonators are optimized to be overlapping in order to create a wide operating bandwidth. The resulting antenna has linear polarization radiation characteristics broadside to the stack of planes containing the radiating elements. The currents on the NFRP elements dominate the radiation process and are designed to be out-of-phase to achieve a high directivity endfire effect perpendicular to the element stack. A prototype of the antenna is fabricated and tested to demonstrate the effectiveness of this design. The measured results show that this low-profile ( total height = 0.092 λL, where λL indicates the free-space wavelength corresponding to the lower bound of the operating frequency band) and electrically small ( ka = 0.679) antenna provides broadside realized gains in the range of 2.62 ±0.99 dB with ~ 10% fractional bandwidth. The performance characteristics of a yet smaller version ( ka = 0.494) are also explored numerically.","Resonant frequency,
Dipole antennas,
Bandwidth,
Impedance,
Gain,
Antenna measurements"
Reduced-Order Models for Electromagnetic Scattering Problems,"We consider model-order reduction of systems occurring in electromagnetic scattering problems, where the inputs are current distributions operating in the presence of a scatterer, and the outputs are their corresponding scattered fields. Using the singular-value decomposition (SVD), we formally derive minimal-order models for such systems. We then use a discrete empirical interpolation method (DEIM) to render the minimal-order models more suitable to numerical computation. These models consist of a set of elementary sources and a set of observation points, both interior to the scatterer, and located automatically by the DEIM. A single matrix then maps the values of any incident field at the observation points to the amplitudes of the sources needed to approximate the corresponding scattered field. Similar to a Green's function, these models can be used to quickly analyze the interaction of the scatterer with other nearby scatterers or antennas.",
Uncertainty Representation of Grey Numbers and Grey Sets,"In the literature, there is a presumption that a grey set and an interval-valued fuzzy set are equivalent. This presumption ignores the existence of discrete components in a grey number. In this paper, new measurements of uncertainties of grey numbers and grey sets, consisting of both absolute and relative uncertainties, are defined to give a comprehensive representation of uncertainties in a grey number and a grey set. Some simple examples are provided to illustrate that the proposed uncertainty measurement can give an effective representation of both absolute and relative uncertainties in a grey number and a grey set. The relationships between grey sets and interval-valued fuzzy sets are also analyzed from the point of view of the proposed uncertainty representation. The analysis demonstrates that grey sets and interval-valued fuzzy sets provide different but overlapping models for uncertainty representation in sets.","Uncertainty,
Fuzzy sets,
Measurement uncertainty,
Cybernetics,
Rough sets,
Computer science,
Educational institutions"
Bumping: A Bump-Aided Inertial Navigation Method for Indoor Vehicles Using Smartphones,"Equipped with accelerometers and gyroscopes, modern smartphones provide an appealing approach to infrastructure-free navigation for vehicles in indoor environments (for example parking garages). However, a smartphone-based inertial navigation system (INS) faces two serious problems. First, it is subject to errors that accumulate over time rather quickly, which may grow to a level that renders the navigation meaningless. Second, without human input or external references, the smartphone can hardly infer its initial position/velocity, which is the basis for distance calculation, since all that a smartphone can learn is its acceleration. This raises a practical concern, as users often need to start indoor navigation precisely when they are uncertain of their current whereabouts. In this paper, we present Bumping , a Bump-Aided Inertial Navigation method that significantly alleviates the above two problems. At the core of this method is a Bump Matching algorithm, which exploits the position information of the readily available speed bumps to provide useful references for the INS. The proposed method is easy to implement, requires no infrastructures, and incurs nearly zero extra energy. We conducted real experiments in tree parking garages of different environmental characteristics. The Bumping method produces an average position error of 4-5 m in these scenarios, improving the accuracy by up to 87.1 percent, compared to the basic inertial navigation method.","Hidden Markov models,
Smart phones,
Navigation,
Vehicles,
Trajectory,
Roads,
Accuracy"
"Modeling, Simulation, and Performance Evaluation of a Novel Microfluidic Impedance Cytometer for Morphology-Based Cell Discrimination","The performance of a novel microfluidic impedance cytometer [1] for single-cell analysis is investigated in-silico by means of a finite element model. The main feature of the device is the ability to probe impedance of flowing cells along two orthogonal directions. As proved by means of numerical simulations involving spherical and ellipsoidal cells, this allows to extract information on cell morphology. In particular, simple anisotropy indices are devised, which are independent from cell volume and rather insensitive to small imperfections in the focusing system. In addition, simulations with budding yeasts show the capability of the device to identify the cell division stage.","Electrodes,
Anisotropic magnetoresistance,
Impedance,
Shape,
Ellipsoids,
Current measurement,
Indexes"
Quantum Dynamics Simulation of Electrons in Materials on High-Performance Computers,"Advancement in high-performance computing allows us to calculate properties of increasingly complex materials with unprecedented accuracy. At the same time, to take full advantage of modern leadership-class supercomputers, the calculations need to scale well on hundreds of thousands of processing cores. We demonstrate such high scalability of our recently developed implementation of Ehrenfest non-adiabatic electron-ion dynamics up to 1 million floating-point processing units on two different leadership-class computing architectures. As a representative example of material properties that derive from quantum dynamics of electrons, we demonstrate the accurate calculation of electronic stopping power, which characterizes the rate of energy transfer from a high-energy particle to electrons in materials. We discuss the specific case of crystalline gold with a hydrogen atom as the high-energy particle, and we illustrate detailed scientific insights that can be obtained from the quantum dynamics simulation at the electronic structure level. Please note that two animation videos of the time evolution for Figure 3 are available as Web extras at http://youtu.be/WxiMZ2DVBbM and http://youtu.be/bAcaxF9ARzM.",
Machine learning tool and meta-heuristic based on genetic algorithms for plagiarism detection over mail service,"One of the most modern problems that computer science try to resolve is the plagiarism, in this article we present a new approach for automatic plagiarism detection in world of mail service. Our system is based on the n-gram character for the representation of the texts and tfidf as weighting to calculate the importance of term in the corpus, we use also a combination between the machine learning methods as a way to detect if a document is plagiarized or not, we use pan 09 corpus for the construction and evaluation of the prediction model then we simulate a meta-heuristic method based on genetic algorithms with a variations of parameters to know if it can improve the results. The main objective of our work is to protect intellectual property and improve the efficiency of plagiarism detection system.","Plagiarism,
Electronic mail,
Servers,
Entropy,
Genetic algorithms,
Detectors,
Classification algorithms"
Stacked convolutional auto-encoders for steganalysis of digital images,"In this paper, we point out that SRM (Spatial-domain Rich Model), the most successful steganalysis framework of digital images possesses a similar architecture to CNN (convolutional neural network). The reasonable expectation is that the steganalysis performance of a well-trained CNN should be comparable to or even better than that of the hand-coded SRM. However, a CNN without pre-training always get stuck at local plateaus or even diverge which result in rather poor solutions. In order to circumvent this obstacle, we use convolutional auto-encoder in the pre-training procedure. A stack of convolutional auto-encoders forms a CNN. The experimental results show that initializing a CNN with the mixture of the filters from a trained stack of convolutional auto-encoders and feature pooling layers, although still can not compete with SRM, yields superior performance compared to traditional CNN for the detection of HUGO generated stego images in BOSSBase image database.",
Impedance Measurement and Characterization of Ag-Ge30Se70-Based Programmable Metallization Cells,"Chalcogenide glass-based programmable metallization cell (PMC) devices undergo Ag+-ion transport and controlled resistance change under the application of electrical bias. In this paper, photo-doped PMC devices are characterized with impedance spectroscopy. Photo doping is an important step in PMC fabrication as it introduces the mobile Ag into the electrolyte and, therefore, has a significant effect on device characteristics. Data obtained from measurements on devices with different areas in both their high resistance state (HRS) and low resistance state (LRS) are used to parameterize equivalent circuit models. The models elucidate the differences in the HRS and LRS electrical properties.","Resistance,
Capacitance,
Impedance,
Switches,
Impedance measurement,
Anodes,
Cathodes"
Optimizing the Hierarchical Prediction and Coding in HEVC for Surveillance and Conference Videos With Background Modeling,"For the real-time and low-delay video surveillance and teleconferencing applications, the newly video coding standard HEVC can achieve much higher coding efficiency over H.264/AVC. However, we still argue that the hierarchical prediction structure in the HEVC low-delay encoder still does not fully utilize the special characteristics of surveillance and conference videos that are usually captured by stationary cameras. In this case, the background picture (G-picture), which is modeled from the original input frames, can be used to further improve the HEVC low-delay coding efficiency meanwhile reducing the complexity. Therefore, we propose an optimization method for the hierarchical prediction and coding in HEVC for these videos with background modeling. First, several experimental and theoretical analyses are conducted on how to utilize the G-picture to optimize the hierarchical prediction structure and hierarchical quantization. Following these results, we propose to encode the G-picture as the long-term reference frame to improve the background prediction, and then present a G-picture-based bit-allocation algorithm to increase the coding efficiency. Meanwhile, according to the proportions of background and foreground pixels in coding units (CUs), an adaptive speed-up algorithm is developed to classify each CU into different categories and then adopt different speed-up strategies to reduce the encoding complexity. To evaluate the performance, extensive experiments are performed on the HEVC test model. Results show our method can averagely save 39.09% bits and reduce the encoding complexity by 43.63% on surveillance videos, whereas those are 5.27% and 43.68% on conference videos.",
Data-aware DRAM refresh to squeeze the margin of retention time in hybrid memory cube,"With the increase of storage density, DRAM refresh leads to higher overhead of power and bandwidth, particularly in emerging 3D stacked memory design like Hybrid Memory Cube (HMC). To exploit the hardware resources for a smarter solution, we propose a data-aware refresh control scheme, Trial and Error (Trial-n-Error), which leverages the data-pattern dependence characteristics of the cells' retention time to reduce refresh operations. Trial-n-Error is a systematic approach that employs our proposed Synergy Testing to capture the refresh bottleneck of DRAM memory: “weak” cells that have a relatively shorter retention time. By locating the dominant weak cells sensitized by applications, Trial-n-Error can avoid the worst-case refresh setting, and adjust the refresh rate under the control of our self-tuning algorithm. Thus, Trial-n-Error can gradually approach to the possible lower-bound of refresh rate for less energy and memory bandwidth consumption. In experiments of 3D-stacked DRAMs, we successfully eliminate an average of 28% refresh operations and save 21% refresh energy for a set of pre-profiled synthetic data patterns and real benchmarks.",
Plug-and-play model predictive control for electric vehicle charging and voltage control in smart grids,"This paper presents a predictive controller for handling plug-and-play (P&P) charging requests of electric vehicles (EVs) in a distribution system. The proposed method uses a two-stage hierarchical control scheme based on a model predictive control (MPC) formulation for tracking periodic references. The first stage computes a reachable periodic reference that trades off deviation from the nominal voltage with the required generation control. The second stage computes a controller that tracks this reference and charges the EVs, while satisfying system constraints at all times. Under the assumption of a time-periodic load, it is shown that the proposed controller is recursively feasible and exponentially stable i.e. the EVs' state of charge (SOC) and bus voltages converge to the desired SOC and to the optimal periodic reference respectively. Finally, the proposed scheme is illustrated in a set of examples.","Voltage control,
System-on-chip,
Trajectory,
Mathematical model,
Reactive power,
Steady-state,
Equations"
Minimum Latency Multiple Data MULE Trajectory Planning in Wireless Sensor Networks,"This paper investigates the problem of computing the optimal trajectories of multiple data MULEs (e.g., robots, vehicles, etc.) to minimize data collection latency in wireless sensor networks. By relying on a slightly different assumption, we define two interesting problems, the k-traveling salesperson problem with neighborhood ( k-TSPN) and the k-rooted path cover problem with neighborhood ( k-PCPN). Since both problems are NP-hard, we propose constant factor approximation algorithms for them along with two simpler heuristic algorithms. We also conduct simulations to compare the performance of the proposed approaches with the existing alternatives. Our simulation results indicate that the proposed algorithms outperform the competitors on average.","Approximation algorithms,
Approximation methods,
Trajectory,
Wireless sensor networks,
Robot sensing systems,
Polynomials,
Wireless communication"
Energy Consumption of Visual Sensor Networks: Impact of Spatio-Temporal Coverage,"Wireless visual sensor networks (VSNs) are expected to play a major role in future IEEE 802.15.4 personal area networks (PANs) under recently established collision-free medium access control (MAC) protocols, such as the IEEE 802.15.4e-2012 MAC. In such environments, the VSN energy consumption is affected by a number of camera sensors deployed (spatial coverage), as well as a number of captured video frames of which each node processes and transmits data (temporal coverage). In this paper we explore this aspect for uniformly formed VSNs, that is, networks comprising identical wireless visual sensor nodes connected to a collection node via a balanced cluster-tree topology, with each node producing independent identically distributed bitstream sizes after processing the video frames captured within each network activation interval. We derive analytic results for the energy-optimal spatio-temporal coverage parameters of such VSNs under a priori known bounds for the number of frames to process per sensor and the number of nodes to deploy within each tier of the VSN. Our results are parametric to the probability density function characterizing the bitstream size produced by each node and the energy consumption rates of the system of interest. Experimental results are derived from a deployment of TelosB motes and reveal that our analytic results are always within 7% of the energy consumption measurements for a wide range of settings. In addition, results obtained via motion JPEG encoding and feature extraction on a multimedia subsystem (BeagleBone Linux Computer) show that the optimal spatio-temporal settings derived by our framework allow for substantial reduction of energy consumption in comparison with ad hoc settings.","Energy consumption,
Visualization,
Multimedia communication,
Relays,
Streaming media,
Cameras,
Topology"
Behavioral Imaging and Autism,Behavioral imaging encompasses the use of computational sensing and modeling techniques to measure and analyze human behavior. This article discusses a research program focused on the study of dyadic social interactions between children and their caregivers and peers. The study has resulted in a dataset containing semi-structured play interactions between children and adults. Behavioral imaging could broadly affect the quality of care for individuals with a developmental or behavioral disorder.,
Evolution-in-materio: A frequency classifier using materials,"Evolution-in-materio (EIM) is a method that uses artificial evolution to exploit properties of materials to solve computational problems without requiring a detailed understanding of such properties. In this paper, we describe experiments using a purpose-built EIM platform called Mecobo to classify whether an applied square wave signal is above or below a user-defined threshold. This is the first demonstration that electrical configurations of materials (carbon nanotubes and a polymer) can be evolved to act as frequency classifiers.","Materials,
Electrodes,
Hardware,
Time-frequency analysis,
Arrays,
Voltage measurement,
Field programmable gate arrays"
Micro-Masonry of MEMS Sensors and Actuators,"Micro-masonry is a route to microassembly that involves elastomeric-stamp-based micromanipulation and direct bonding. This paper presents the assembly of MEMS mechanical sensors and actuators using micro-masonry, demonstrating its capability of constructing 3-D microdevices that are impossible or difficult to realize with monolithic microfabrication. Microfabrication processes for retrievable MEMS components (e.g., combs, spacers, and flexure beams) are developed. As micromanipulation tools, microtipped elastomeric stamps with reversible dry adhesion are also designed and fabricated to pick up and deterministically place those components. After the manipulation, the components are permanently bonded together via rapid thermal annealing without using any additional intermediate layers. The assembled MEMS device is modeled and analyzed in consideration of the microassembly misalignment. The sensing and actuating capabilities of the assembled MEMS devices are experimentally characterized.","Substrates,
Silicon,
Resists,
Micromechanical devices,
Assembly,
Capacitance,
Gold"
Experimental analysis of dynamic covariance scaling for robust map optimization under bad initial estimates,"Non-linear error minimization methods became widespread approaches for solving the simultaneous localization and mapping problem. If the initial guess is far away from the global minimum, converging to the correct solution and not to a local one can be challenging and sometimes even impossible. This paper presents an experimental analysis of dynamic covariance scaling, a recently proposed method for robust optimization of SLAM graphs, in the context of a poor initialization. Our evaluation shows that dynamic covariance scaling is able to mitigate the effects of poor initializations. In contrast to other methods that first aim at finding a good initial guess to seed the optimization, our method is more elegant because it does not require an additional method for initialization. Furthermore, it can robustly handle data association outliers. Experiments performed with real world and simulated datasets show that dynamic covariance scaling outperforms existing methods, both in the presence and absence of data association outliers.","Optimization,
Three-dimensional displays,
Simultaneous localization and mapping,
Robustness,
Convergence"
Fundus Image Mosaicking for Information Augmentation in Computer-Assisted Slit-Lamp Imaging,"Laser photocoagulation is currently the standard treatment for sight-threatening diseases worldwide, namely diabetic retinopathy and retinal vein occlusions. The slit lamp biomicroscope is the most commonly used device for this procedure, specially for the treatment of the eye periphery. However, only a small portion of the retina can be visualized through the biomicroscope, complicating the task of localizing and identifying surgical targets, increasing treatment duration and patient discomfort. In order to assist surgeons, we propose a method for creating intraoperative retina maps for view expansion using a slit-lamp device. Based on the mosaicking method described by Richa et al., 2012, the proposed method is a combination of direct and feature-based methods, suitable for the textured nature of the human retina. In this paper, we describe three major enhancements to the original formulation. The first is a visual tracking method using local illumination compensation to cope with the challenging visualization conditions. The second is an efficient pixel selection scheme for increased computational efficiency. The third is an entropy-based mosaic update method to dynamically improve the retina map during exploration. To evaluate the performance of the proposed method, we conducted several experiments on human subjects with a computer-assisted slit-lamp prototype. We also demonstrate the practical value of the system for photo documentation, diagnosis and intraoperative navigation.","Retina,
Visualization,
Lighting,
Image color analysis,
Imaging,
Entropy,
Surgery"
Partial-Information State-Based Optimization of Partially Observable Markov Decision Processes and the Separation Principle,"We propose a partial-information state based approach to the optimization of the long-run average performance in a partially observable Markov decision process (POMDP). In this approach, the information history is summarized (at least partially) by a (or a few) statistic(s), not necessary sufficient, called a partial-information state, and actions depend on the partial-information state, rather than system states. We first propose the “single-policy based comparison principle,” under which we derive an HJB-type of optimality equation and policy iteration for the optimal policy in the partial-information-state based policy space. We then introduce the Q-sufficient statistics and show that if the partial-information state is Q-sufficient, then the optimal policy in the partial-information state based policy space is optimal in the space of all feasible information state based policies. We show that with some further conditions the well-known separation principle holds. The results are obtained by applying the direct comparison based approach initially developed for discrete event dynamic systems.",
Constructive Models of Discrete and Continuous Physical Phenomena,"This paper studies the semantics of models for discrete physical phenomena, such as rigid body collisions and switching in electronic circuits. This paper combines generalized functions (specifically the Dirac delta function), superdense time, modal models, and constructive semantics to get a rich, flexible, efficient, and rigorous approach to modeling such systems. It shows that many physical scenarios that have been problematic for modeling techniques manifest as nonconstructive models, and that constructive versions of some of the models properly reflect uncertainty in the behavior of the physical systems that plausibly arise from the principles of the underlying physics. This paper argues that these modeling difficulties are not reasonably solved by more detailed continuous models of the underlying physical phenomena. Such more detailed models simply shift the uncertainty to other aspects of the model. Since such detailed models come with a high computational cost, there is little justification in using them unless the goal of modeling is specifically to understand these more detailed physical processes. All models in this paper are implemented in the Ptolemy II modeling and simulation environment and made available online.","Semantics,
Collision avoidance,
Discrete-time systems,
Computational modeling,
Integrated circuit modeling,
Switching circuits,
Electronic circuits"
The Lossy Common Information of Correlated Sources,"The two most prevalent notions of common information (CI) are due to Wyner and Gács-Körner and both the notions can be stated as two different characteristic points in the lossless Gray-Wyner region. Although the information theoretic characterizations for these two CI quantities can be easily evaluated for random variables with infinite entropy (e.g., continuous random variables), their operational significance is applicable only to the lossless framework. The primary objective of this paper is to generalize these two CI notions to the lossy Gray-Wyner network, which hence extends the theoretical foundation to general sources and distortion measures. We begin by deriving a single letter characterization for the lossy generalization of Wyner's CI, defined as the minimum rate on the shared branch of the Gray-Wyner network, maintaining minimum sum transmit rate when the two decoders reconstruct the sources subject to individual distortion constraints. To demonstrate its use, we compute the CI of bivariate Gaussian random variables for the entire regime of distortions. We then similarly generalize Gács and Körner's definition to the lossy framework. The latter half of this paper focuses on studying the tradeoff between the total transmit rate and receive rate in the Gray-Wyner network. We show that this tradeoff yields a contour of points on the surface of the Gray-Wyner region, which passes through both the Wyner and Gács-Körner operating points, and thereby provides a unified framework to understand the different notions of CI. We further show that this tradeoff generalizes the two notions of CI to the excess sum transmit rate and receive rate regimes, respectively.","Random variables,
Joints,
Entropy,
Distortion measurement,
Rate-distortion,
Markov processes,
Decoding"
The lord of the sense: A privacy preserving reputation system for participatory sensing applications,"Electronic devices we use on a daily basis collect sensitive information without preserving user's privacy. In this paper, we propose the lord of the sense (LotS), a privacy preserving reputation system for participatory sensing applications. Our system maintains the privacy and anonymity of information with the use of cryptographic techniques and combines voting approaches to support users' reputation. Furthermore, LotS maintains accountability by tracing back a misbehaving user while maintaining k-anonymity. A detailed security analysis is presented with the current advantages and disadvantages of our system.","Protocols,
Sensors,
Privacy,
Communities,
Public key"
Analysis and Predictive Modeling of Body Language Behavior in Dyadic Interactions From Multimodal Interlocutor Cues,"During dyadic interactions, participants adjust their behavior and give feedback continuously in response to the behavior of their interlocutors and the interaction context. In this paper, we study how a participant in a dyadic interaction adapts his/her body language to the behavior of the interlocutor, given the interaction goals and context. We apply a variety of psychology-inspired body language features to describe body motion and posture. We first examine the coordination between the dyad's behavior for two interaction stances: friendly and conflictive. The analysis empirically reveals the dyad's behavior coordination, and helps identify informative interlocutor features with respect to the participant's target body language features. The coordination patterns between the dyad's behavior are found to depend on the interaction stances assumed. We apply a Gaussian-Mixture-Model-based (GMM) statistical mapping in combination with a Fisher kernel framework for automatically predicting the body language of an interacting participant from the speech and gesture behavior of an interlocutor. The experimental results show that the Fisher kernel-based approach outperforms methods using only the GMM-based mapping, and using the support vector regression, in terms of correlation coefficient and RMSE. These results suggest a significant level of predictability of body language behavior from interlocutor cues.","Speech,
Feature extraction,
Correlation,
Context,
Kernel,
Predictive models,
Databases"
Bi-Polynomial Modeling of Low-Frequency Reflectances,"We present a bi-polynomial reflectance model that can precisely represent the low-frequency component of reflectance. Most existing reflectance models aim at accurately representing the complete reflectance domain for photo-realistic rendering purposes. In contrast, our bi-polynomial model is developed for the purpose of accurately solving inverse problems by effectively discarding the high-frequency component while retaining nonlinear variations in the low-frequency part. The bi-polynomial reflectance model is useful for estimating reflectance and shape of an object. Experimental evaluation in comparison with other parametric reflectance models demonstrates that the proposed model achieves better performance in reflectometry and photometric stereo applications.","Mathematical model,
Lighting,
Brain modeling,
Computational modeling,
Materials,
Polynomials"
Semi-Supervised Linear Discriminant Clustering,"This paper devises a semi-supervised learning method called semi-supervised linear discriminant clustering (Semi-LDC). The proposed algorithm considers clustering and dimensionality reduction simultaneously by connecting K-means and linear discriminant analysis (LDA). The goal is to find a feature space where the K-means can perform well in the new space. To exploit the information brought by unlabeled examples, this paper proposes to use soft labels to denote the labels of unlabeled examples. The Semi-LDC uses the proposed algorithm, called constrained-PLSA, to estimate the soft labels of unlabeled examples. We use soft LDA with hard labels of labeled examples and soft labels of unlabeled examples to find a projection matrix. The clustering is then performed in the new feature space. We conduct experiments on three data sets. The experimental results indicate that the proposed method can generally outperform other semi-supervised methods. We further discuss and analyze the influence of soft labels on classification performance by conducting experiments with different percentages of labeled examples. The finding shows that using soft labels can improve performance particularly when the number of available labeled examples is insufficient to train a robust and accurate model. Additionally, the proposed method can be viewed as a framework, since different soft label estimation methods can be used in the proposed method according to application requirements.","Clustering algorithms,
Vectors,
Semisupervised learning,
Measurement,
Linear programming,
Equations,
Algorithm design and analysis"
Forced-Air Cooling System Design Under Weight Constraint for High-Temperature SiC Converter,"An analytical model has been developed for predicting the forced-air cooling system performance, including a detailed optimization process to minimize the total weight. With a design example in a high-density high-temperature SiC converter, the presented design method was verified through numerical simulations and experiments.","Heating,
Cooling,
Ducts,
Geometry,
Heat transfer,
Silicon carbide"
Comparison of Image Patches Using Local Moment Invariants,"We propose a new set of moment invariants based on Krawtchouk polynomials for comparison of local patches in 2D images. Being computed from discrete functions, these moments do not carry the error due to discretization. Unlike many orthogonal moments, which usually capture global features, Krawtchouk moments can be used to compute local descriptors from a region-of-interest in an image. This can be achieved by changing two parameters, and hence shifting the center of interest region horizontally or vertically or both. This property enables comparison of two arbitrary local regions. We show that Krawtchouk moments can be written as a linear combination of geometric moments, so easily converted to rotation, size, and position independent invariants. We also construct local Hu-based invariants using Hu invariants and utilizing them on images localized by the weight function given in the definition of Krawtchouk polynomials. We give the formulation of local Krawtchouk-based and Hu-based invariants, and evaluate their discriminative performance on local comparison of artificially generated test images.","Polynomials,
Image reconstruction,
Object recognition,
Image recognition,
Feature extraction,
Chebyshev approximation"
K-means based clustering approach for data aggregation in periodic sensor networks,"In-network data aggregation becomes an important technique to achieve efficient data transmission in wireless sensor networks (WSN). Energy efficiency, data latency and data accuracy are the major key elements evaluating the performance of an in-network data aggregation technique. The trade-offs among them largely depends on the specific application. For instance, prefix frequency filtering (PFF) is a good recently example for an in-network data aggregation technique that optimizing energy consumption and data accuracy. The objective of PFF is to find similar data sets generated by neighboring nodes in order to reduce redundancy of the data over the network and thus to preserve the nodes energy. Unfortunately, this technique has a heavy computational load. In this paper, we propose an enhanced new version of the PFF technique called KPFF technique. In this new technique, we propose to integrate a K-means clustering algorithm on data before applying the PFF on the generated clusters. By this way we minimize the number of comparisons to find similar data sets and thus we decrease the data latency. Experiments on real sensors data show that our new technique can significantly reduce the computational time without affecting the data aggregation performance of the PFF technique.","Frequency measurement,
Clustering algorithms,
Wireless sensor networks,
Temperature measurement,
Mathematical model,
Classification algorithms,
Conferences"
An hybrid clustering algorithm for optimal clusters in Wireless sensor networks,"Clustering is a technique that alleviates network congestion and increase the energy efficiency of the Wireless sensor network. Hierarchical clustering and k-means clustering are well established clustering algorithms. The convergence of hierarchical clustering is only based on the inconsistency criterion while the k-means clustering requires the number of clusters (k) which are user defined. It is only by trial and error better values for inconsistency and k can be obtained. This may not be optimal and clustering without optimal number of clusters leads to energy inefficient network. Hence, a new hybrid self decisive clustering technique based on Hierarchical Agglomerative Clustering and k-means algorithm is proposed here. The main objective of this algorithm is to arrive at an optimal number of clusters for a given set of nodes distributed over the geographical area. Added to this, the algorithm identifies the Cluster Head also. The proposed algorithm is implemented in Matlab and compared with the existing techniques. Results demonstrate the supremacy of the proposal with that of Hierarchical and k-means clustering.",
Network Virtualization for Smart Grid Communications,"Information exchange is critical in smart grid for system control and management. Optical fibers are widely used in transmission grid and substations to provide high-capacity and high-reliability communications. However, due to high cost and inflexibility, optical fibers are not suitable for information transmission in distribution grid. Wireless mesh network (WMN) and power line communication (PLC) network are more appropriate for distribution grid communications. Nonetheless, both WMN and PLC technologies tend to suffer from bit error and packet loss due to interference and attenuation. It is extremely difficult to provide real-time services with low delay and high reliability in both of them. Network virtualization (NV) is a promising technology to support customized end-to-end performance of various services. In this paper, an NV-based framework is proposed for smart grid communications. In the framework, real-time services are supported by virtual networks (VNs) that are mapped to two physical networks simultaneously, i.e., WMN and PLC network. The WMN for NV is designed to adopt orthogonal frequency division multiple access as the multiple access scheme. In this way, different VNs are allocated distinct subcarriers. Concurrent transmissions in multiple subcarriers bring the benefit of additional diversity. The enhanced transmission diversity through the two networks and the allocated subcarriers contributes to the reliability guarantee of the real-time services. Since the VN mapping and subcarrier assignment problem is nondeterministic polynomial-time hard, a heuristic solution is developed to solve the problem efficiently and effectively. Simulation results reveal the effectiveness of our proposed framework.","Smart grids,
Reliability,
Real-time systems,
Delays,
Optical attenuators,
OFDM,
Tin"
FiberScout: An Interactive Tool for Exploring and Analyzing Fiber Reinforced Polymers,"Advanced composites such as fiber reinforced polymers are promising candidate materials for future components as they allow integrating the continuously rising demands of industry regarding cost-effectiveness, function-orientation, integration and weight. The most important structures of fiber reinforced polymers are the individual fibers, as their characteristics (stiffness, strength, ductility, durability, etc.) to a large extent determine the properties of the final component. The main contribution of this paper is the introduction of a new system for interactive exploration and visual analysis of fiber properties in X-ray computed tomography data of fiber reinforced polymers. The presented tool uses parallel coordinates to define and configure initial fiber classes. Using a scatter plot matrix linked to the parallel coordinates the initial classification may be refined. This allows to analyze hidden relationships between individual fiber properties. 2D and 3D views depict the resulting fiber classifications. By using polar plots an intuitive rendering of the fiber orientation distribution is provided. In addition, two modules of higher abstraction are proposed: The Blob visualization creates a hull around fibers with similar characteristics. The fiber metadata visualization allows to calculate overlays for 2D and 3D views containing regional information of particular material characteristics. The proposed system has been evaluated by two groups of domain experts. Applying the presented concepts the user feedback shows that the domain experts are now able to efficiently perform tasks as classification of fibers, visualization of fiber lengths and orientations, and visualization of fiber regions. The insights gained can be forwarded to the design office as well as to material development and simulation, in order to speed up the development of novel composite components.","Data visualization,
Three-dimensional displays,
Visualization,
Image color analysis,
Plastics,
Pipelines"
Opportunistic relay selection in multicast relay networks using compressive sensing,"Relay selection is a simple technique that achieves spatial diversity in cooperative relay networks. However, for relay selection algorithms to make a selection decision, channel state information (CSI) from all cooperating relays is usually required at a central node. This requirement poses two important challenges. Firstly, CSI acquisition generates a great deal of feedback overhead (air-time) that could result in significant transmission delays. Secondly, the fed back channel information is usually corrupted by additive noise. This could lead to transmission outages if the central node selects the set of cooperating relays based on inaccurate feedback information. In this paper, we introduce a limited feedback relay selection algorithm for a multicast relay network. The proposed algorithm exploits the theory of compressive sensing to first obtain the identity of the ""strong"" relays with limited feedback. Following that, the CSI of the selected relays is estimated using linear minimum mean square error estimation. To minimize the effect of noise on the fed back CSI, we introduce a back-off strategy that optimally backs-off on the noisy estimated CSI. For a fixed group size, we provide closed form expressions for the scaling law of the maximum equivalent SNR for both Decode and Forward (DF) and Amplify and Forward (AF) cases. Numerical results show that the proposed algorithm drastically reduces the feedback air-time and achieves a rate close to that obtained by selection algorithms with dedicated error-free feedback channels.","Relays,
Signal to noise ratio,
Signal processing algorithms,
Vectors,
Throughput,
Noise measurement"
High Stroke and High Deflection Bulk-PZT Diaphragm and Cantilever Micro Actuators and Effect of Pre-Stress on Device Performance,"This paper presents the design, simulation, fabrication, and experimental characterization of high-performance piezoelectric diaphragm and cantilever beam out-of-plane micro actuators that are fabricated from bulk lead zirconium titanate (PZT) films integrated on silicon. The utilized fabrication technology involves low-temperature diffusion solder bonding of a bulk piezoelectric ceramic on silicon, and subsequent lapping to achieve a desired PZT thickness. Different piezoelectric actuation modes (conventional longitudinal and transverse modes, and a novel shear mode) are explored and compared in terms of displacement range, and the diaphragm structures and electrodes are optimized via finite-element analysis (FEA). The effect of bonding prestress on the device performance is analytically characterized and verified through measurements. The close match between test data and simulation results suggests that the piezoelectric properties of integrated bulk-PZT5A films are mostly preserved without any necessity of re-polarization. Fabricated devices are tested for dynamic displacement range, power consumption, and temperature response, and FEA is used to evaluate the actuation forces. A 25- μm thick 1- mm2 sized diaphragm can provide 12 μmPP displacement at 111 kHz with power consumption, while 1-3.5 mm long cantilever beams of similar thickness provide 0.1-1 mmPP displacement at resonance frequencies of 0.7-7.4 kHz. The introduced devices can be leveraged in various ultrasonic and acoustic applications.","Electrodes,
Actuators,
Silicon,
Bonding,
Resonant frequency,
Frequency measurement"
"Live demonstration: A versatile, low-cost platform for testing large ReRAM cross-bar arrays","We demonstrate a practical application of memristors in a cross-bar memory array. The full set-up consists of only a PC, an mBED microcontroller and a PCB hosting external components and the memristor cross-bar chip. The system can be used for general purpose memory storage, but in this case we use it as a binary image storage device. A MATLAB interface allows the user to load a binary image into the memory and observe the resulting internal memory states of each memristor in the array along with key performance metrics describing the speed and degree of success of the memory `write' operation.","Memristors,
MATLAB,
Microcontrollers,
Testing,
Educational institutions,
Electronic mail,
Computer science"
Controlling articulated robots in task-space with spiking silicon neurons,"Emulating how humans coordinate articulated limbs within the brain's power budget promises to accelerate progress in building autonomous biomimetic robots. Here, we used a neuromorphic approach - low-power analog silicon spiking neurons - to control an articulated robot in real-time. We obtained a closed-form control function that computes robot motor torques given the robot's joint angles (state) and desired end-effector forces; factorized the function into a set of sub-functions over five unique three-dimensional domains; and regressed each sub-function on to the steady-state spiking responses of one out of five silicon spiking-neuron pools. The spiking pools controlled a three degree-of-freedom robot's motor torques in real-time and performed reaches to arbitrary locations in space with less than 2 cm root-mean-square trajectory tracking error (of an analytical controller). The controller is compliant and can draw shapes with a pen on a dynamically perturbed surface while remaining stable. Using force control resulted in linear responses to perturbations in end-effector coordinates (task-space), which effectively filtered noise due to neuron spikes. Factorizing the controller reduced the neural regression's complexity to cubic in the dynamic range of the robot's state and desired forces. Doing so made acquiring spiking responses for regression tractable in time (~2-3 min), and enabled reliable trajectory tracking with only 1280 neurons. This is the first time a neuromorphic system has achieved realtime manipulation for an articulated robot with three or more degrees-of-freedom.","Neurons,
Trajectory,
Robot kinematics,
Neuromorphics,
Field programmable gate arrays,
Joints"
Visual Abstraction and Exploration of Multi-class Scatterplots,"Scatterplots are widely used to visualize scatter dataset for exploring outliers, clusters, local trends, and correlations. Depicting multi-class scattered points within a single scatterplot view, however, may suffer from heavy overdraw, making it inefficient for data analysis. This paper presents a new visual abstraction scheme that employs a hierarchical multi-class sampling technique to show a feature-preserving simplification. To enhance the density contrast, the colors of multiple classes are optimized by taking the multi-class point distributions into account. We design a visual exploration system that supports visual inspection and quantitative analysis from different perspectives. We have applied our system to several challenging datasets, and the results demonstrate the efficiency of our approach.","Image color analysis,
Data visualization,
Visualization,
Noise,
Estimation,
Market research,
Statistical analysis"
Network Coding-Aware Queue Management for TCP Flows Over Coded Wireless Networks,"In this paper, we are interested in improving the performance of TCP flows over wireless networks with a given constructive intersession network coding scheme. We are motivated by the observation that TCP does not fully exploit the potential of the underlying network coding opportunities. In order to improve the performance of TCP flows over coded wireless networks, without introducing changes to TCP itself, we propose a network-coding aware queue management scheme (NCAQM) that is implemented at intermediate network coding nodes and bridges the gap between network coding and TCP rate control. The design of NCAQM is grounded on the network utility maximization (NUM) framework and includes the following mechanisms. NCAQM: 1) stores coded packets at intermediate nodes in order to use the buffer space more efficiently; 2) determines what fraction of the flows should be coded together; and 3) drops packets at intermediate nodes so that it matches the rates of parts of different TCP flows that are coded together. We demonstrate, via simulation, that NCAQM significantly improves TCP throughput compared to TCP over baseline queue management schemes.","Network coding,
Wireless networks,
Throughput,
Encoding,
Unicast,
Buffer storage"
Reliable resource allocation for optically interconnected distributed clouds,"In this paper, we study the reliable resource allocation (RRA) problem of allocating virtual machines (VMs) from multiple optically interconnected data centers (DCs) with the objective of minimizing the total failure probability based on the information obtained from the optical network virtulization. We first describe the framework of resource allocation, formulate the RRA problem, and prove that RRA is NP-complete. We provide an algorithm, named Minimum Failure Cover (MFC), to obtain optimal solutions for small scale problems. We then provide a greedy algorithm, named VM-over-Reliability (VOR), to solve large scale problems. Numerical results show that VOR achieves results close to optimal solutions gained by MFC for small scale problems. Numerical results also show that VOR outperforms the resource allocation through random DC selection (RDS).","Reliability,
Resource management,
Optical fiber networks,
Delays,
Upper bound,
Network topology,
Topology"
Detecting k-Balanced Trusted Cliques in Signed Social Networks,"k-Clique detection enables computer scientists and sociologists to analyze social networks' latent structure and thus understand their structural and functional properties. However, the existing k-clique-detection approaches are not applicable to signed social networks directly because of positive and negative links. The authors' approach to detecting k-balanced trusted cliques in such networks bases the detection algorithm on formal context analysis. It constructs formal contexts using the modified adjacency matrix after converting a signed social network into an unweighted one. Experimental results demonstrate that their algorithm can efficiently identify the trusted cliques.",
"Dynamic Modeling of Radiation-Induced State Changes in
HfO
2
/Hf
1T1R RRAM","Single and multiple-event upsets in HfO2/Hf one transistor, one resistor (1T1R) resistive random access memory (RRAM) structures are modeled dynamically using 3-D technology computer-aided design (TCAD) simulations. A dynamic single-event compact model is presented that allows direct correlation of the ion-generated voltage transient across the RRAM and the change in RRAM resistance. Experiments and modeling demonstrate an exponential relationship between the susceptibility of the RRAM and the applied voltage. Two implementations of the model are also presented including hardening voltage-susceptible resistive memory technologies and the impact of highly scaled access transistors.","Radiation effects,
Single event upsets,
Resistors,
Random access memory,
Nonvolatile memory,
Transient analysis,
Hafnium,
Hafnium oxide"
Evaluating Combinational Illumination Estimation Methods on Real-World Images,"Illumination estimation is an important component of color constancy and automatic white balancing. A number of methods of combining illumination estimates obtained from multiple subordinate illumination estimation methods now appear in the literature. These combinational methods aim to provide better illumination estimates by fusing the information embedded in the subordinate solutions. The existing combinational methods are surveyed and analyzed here with the goals of determining: 1) the effectiveness of fusing illumination estimates from multiple subordinate methods; 2) the best method of combination; 3) the underlying factors that affect the performance of a combinational method; and 4) the effectiveness of combination for illumination estimation in multiple-illuminant scenes. The various combinational methods are categorized in terms of whether or not they require supervised training and whether or not they rely on high-level scene content cues (e.g., indoor versus outdoor). Extensive tests and enhanced analyzes using three data sets of real-world images are conducted. For consistency in testing, the images were labeled according to their high-level features (3D stages, indoor/outdoor) and this label data is made available on-line. The tests reveal that the trained combinational methods (direct combination by support vector regression in particular) clearly outperform both the non-combinational methods and those combinational methods based on scene content cues.","Image color analysis,
Lighting,
Estimation,
Training,
Support vector machines,
Geometry,
Image edge detection"
"Efficient
k
-Means++ Approximation with MapReduce","k-means is undoubtedly one of the most popular clustering algorithms owing to its simplicity and efficiency. However, this algorithm is highly sensitive to the chosen initial centers and thus a proper initialization is crucial for obtaining an ideal solution. To address this problem, k-means++ is proposed to sequentially choose the centers so as to achieve a solution that is provably close to the optimal one. However, due to its weak scalability, k-means++ becomes inefficient as the size of data increases. To improve its scalability and efficiency, this paper presents Map Reduce k-means++ method which can drastically reduce the number of Map Reduce jobs by using only one MapReduce job to obtain k centers. The k-means++ initialization algorithm is executed in the Mapper phase and the weighted k-means++ initialization algorithm is run in the Reducer phase. As this new Map Reduce k-means++ method replaces the iterations among multiple machines with a single machine, it can reduce the communication and I/O costs significantly. We also prove that the proposed Map Reduce k-means++ method obtains O(α 2)approximation to the optimal solution of k-means. To reduce the expensive distance computation of the proposed method, we further propose a pruning strategy that can greatly avoid a large number of redundant distance computations. Extensive experiments on real and synthetic data are conducted and the performance results indicate that the proposed Map Reduce k-means++ method is much more efficient and can achieve a good approximation.","Clustering algorithms,
Approximation algorithms,
Approximation methods,
Algorithm design and analysis,
Standards,
Scalability,
Educational institutions"
Approximate Algorithm for Fast Calculating Voltage Unbalance Factor of Three-Phase Power System,"The method of calculating voltage unbalance factor (VUF) recommended by the IEC61000-4-27 has the disadvantage of requiring square root operation. This paper focuses on the fast and accurate calculation of VUF of three-phase power system. The approximate algorithm for calculating the magnitude of the zero, positive, and negative sequences by simple algebraic equation is presented. In the proposed method, the square root operation is first transformed to simple trigonometric equations based on the geometric figure, and then the trigonometric equations are approximated by the algebraic operations, which thus reduced the computation burden sufficiently. The simulation and practical experiment results show that the proposed method can achieve the same level of precision as the method recommended by the IEC61000-4-27, while much less clock cycles are required, which indicates its wide application in digital signal processor (DSP).","Power systems,
Mathematical model,
Equations,
Clocks,
IEC,
Simulation,
Informatics"
Vulnerability assessment and defense technology for smart home cybersecurity considering pricing cyberattacks,"Smart home, which controls the end use of the power grid, has become a critical component in the smart grid infrastructure. In a smart home system, the advanced metering infrastructure (AMI) is used to connect smart meters with the power system and the communication system of a smart grid. The electricity pricing information is transmitted from the utility to the local community, and then broadcast through wired or wireless networks to each smart meter within AMI. In this work, the vulnerability of the above process is assessed. Two closely related pricing cyberattacks which manipulate the guideline electricity prices received at smart meters are considered and they aim at reducing the expense of the cyberattacker and increasing the peak energy usage in the local community. A countermeasure technique which uses support vector regression and impact difference for detecting anomaly pricing is then proposed. These pricing cyberattacks explore the interdependance between the transmitted electricity pricing in the communication system and the energy load in the power system, which are the first such cyber-attacks in the smart home context. Our simulation results demonstrate that the pricing cyberattack can reduce the attacker's bill by 34.3% at the cost of the increase of others' bill by 7.9% on average. In addition, the pricing cyberattack can unbalance the energy load of the local power system as it increases the peak to average ratio by 35.7%. Furthermore, our simulation results show that the proposed countermeasure technique can effectively detect the electricity pricing manipulation.","Pricing,
Guidelines,
Electricity,
Computer crime,
Smart homes,
Energy consumption,
Smart meters"
Least Upper Bounds of the Powers Extracted and Scattered by Bi-anisotropic Particles,"The least upper bounds of the powers extracted and scattered by bi-anisotropic particles are investigated analytically. A rigorous derivation for particles having invertible polarizability tensors is presented, and the particles with singular polarizability tensors that have been reported in the literature are treated explicitly. The analysis concludes that previous upper bounds presented for isotropic particles can be extrapolated to bi-anisotropic particles. In particular, it is shown that neither nonreciprocal nor magnetoelectric coupling phenomena can further increase those upper bounds on the extracted and scattered powers. The outcomes are illustrated further with approximate circuit model examples of two dipole antennas connected via a generic lossless network.","Upper bound,
Magnetoelectric effects,
Couplings,
Scattering,
Integrated circuit modeling,
Magnetic resonance,
Magnetic moments"
Generalized Geometric Control Manifolds of Power Converters in a DC Microgrid,"In power electronics-based microgrids, the computational requirements needed to implement an optimized online control strategy can be prohibitive. This paper proposes the derivation of a geometric manifold in the energy-power domain that is based on the a-priori computation of the optimal reactions and trajectories for classes of events in a dc microgrid. The proposed states are the stored energy and power of the dc-dc converter. It is anticipated that calculating a large enough set of dissimilar transient scenarios will also span many scenarios not specifically used to develop the surface. These geometric manifolds will, then, be used as reference surfaces in any type of controller, such as a sliding mode hysteretic controller.",
Multiset Canonical Correlations Using Globality Preserving Projections With Applications to Feature Extraction and Recognition,"Multiset features extracted from the same patterns always represent different characteristics of data. Thus, it is very valuable to perform the extraction on multiple feature sets. This paper addresses the issue of multiset correlation feature extraction (MCFE) in multiple feature representations. A novel method is proposed to carry out the MCFE for classification, called multiset canonical correlations using globality-preserving projections (MCC-GPs), which can perform joint dimensionality reduction for high-dimensional data. MCC-GP integrates correlational characteristics of feature pairs and global geometric information of data in the transformed low-dimensional space. This makes MCC-GPs have better discriminant ability than a previous method proposed by the authors, called multiset integrated canonical correlation analysis (MICCA), which only considers correlations for recognition tasks. Furthermore, MCC-GP can subsume two popular feature extraction methods into its framework under some constraints. This also provides a new insight for these two methods. The proposed method is applied to pattern recognition and examined using the COIL-100 and ETH-80 object databases and AR, CMU PIE, and Yale face databases. Extensive experimental results show that MCC-GP outperforms MICCA and multiset canonical correlation analysis in terms of classification accuracy and efficiency.","Correlation,
Feature extraction,
Vectors,
Kernel,
Principal component analysis,
Covariance matrices,
Eigenvalues and eigenfunctions"
Spatial Reuse and Fairness of Ad Hoc Networks With Channel-Aware CSMA Protocols,"We investigate the benefits of channel-aware (opportunistic) scheduling of transmissions in ad hoc networks. The key challenge in optimizing the performance of such systems is finding a good compromise among three interdependent quantities: 1) the density of scheduled transmitters; 2) the quality of transmissions; and 3) the long term fairness among nodes. We propose two new channel-aware slotted CSMA protocols opportunistic CSMA and quantile-based CSMA (QT-CSMA) and develop new stochastic geometric models to quantify their performance in terms of spatial reuse and spatial fairness. When properly optimized, these protocols offer substantial improvements in performance relative to CSMA - particularly, when the density of nodes is moderate to high. In addition, we show that a simple version of QT-CSMA can achieve robust performance gains without requiring careful parameter optimization. The quantitative results in this paper suggest that channel-aware scheduling in ad hoc networks can provide substantial benefits which might far outweigh the associated implementation overheads.","Transmitters,
Multiaccess communication,
Interference,
Receivers,
Protocols,
Ad hoc networks,
Fading"
Robust Hybrid Control Based on PD and Novel CMAC With Improved Architecture and Learning Scheme for Electric Load Simulator,"Considering the intrinsic nonlinear factors of electric load simulator and interference of surplus torque, new control strategy is required. This paper improves the architecture and learning scheme of cerebellar model articulation controller (CMAC) and proposes a novel CMAC-Proportional Derivative (PD) hybrid controller. The instruction torque and the output torque are regarded as stimulus signals of CMAC. A method of nonuniform quantization is proposed to fit the sinusoidal density of sampling distribution. Introducing quantitative distance and utilizing Gaussian weighting coefficient to distribute error, the approximation ability of CMAC is promoted for high-order differentiable input signals. A new learning scheme for CMAC is investigated to resolve its overlearning issue and restrain external disturbance as well. The results of dynamic simulation and experimental analysis indicate that the hybrid control algorithm can effectively restrain interference, smooth output error, and avoid overlearning of CMAC.","Quantization (signal),
Torque,
Load modeling,
PD control,
Analytical models,
Aerospace electronics,
Nonhomogeneous media"
Investigation of Single Event Induced Soft Errors in Programmable Metallization Cell Memory,"Programmable metallization cell (PMC) devices belong to a class of non-volatile ionic resistive memory devices that have already demonstrated tolerance to high total doses of ionizing radiation. In this work, the susceptibility of integrated 1T-1R PMC memory array to ion strike induced single event upsets is analyzed. Circuit simulations that model single event transients in 1T-1R elements are performed using a PMC compact model which captures the voltage driven resistance change mechanism experimentally observed in such devices. The relationship between incident ion LET and change in PMC resistance and its consequent susceptibility to an upset is investigated through both simulation and experiment.",
Predicting kinematic configuration from string length for a snake-like manipulator not exhibiting constant curvature bending,"We have recently developed a snake-like manipulator for use in orthopaedic environments. One example application is the treatment of osteolysis (bone degradation) due to total hip arthroplasty. Recent literature suggest constant curvature models to define manipulator configuration from string (or actuator cable) length; however, our manipulator does not conform to constant curvature bending. In this paper, we present a two-step model to predict the kinematic configuration directly from string length with no assumptions regarding constant curvature bending. We experimentally identify the model parameters and validate the model on an additional experimental data set. The results indicate our model achieved an average maximum error of 1.0 ± 0.90mm in predicting manipulator configuration compared to the ground truth over the test data set.","Kinematics,
Data models,
Minimization,
Manipulator dynamics,
Predictive models,
DC motors"
Proper Quaternion Gaussian Graphical Models,"In this paper, we extend Gaussian graphical models to proper quaternion Gaussian distributions. The properness assumption reduces the number of unknowns by a factor of four while graphical models reduce the number of degrees of freedom via sparsity. Each of the methods allows accurate estimation using a small number of samples. To enjoy both gains, we show that the proper quaternion Gaussian inverse covariance estimation problem is convex and has a closed form solution. We proceed to demonstrate that the additional sparsity constraints on the inverse covariance matrix also lead to a convex problem, and the optimizations can be efficiently solved by standard numerical methods. In the special but practical case of a chordal graph, we provide a closed form solution. We demonstrate the improved performance of our suggested estimators on both synthetic and real data.","Quaternions,
Covariance matrices,
Graphical models,
Estimation,
Symmetric matrices,
Markov random fields,
Vectors"
Bias Dependence of Total Ionizing Dose Effects in SiGe-MOS FinFETs,"The total ionizing dose (TID) response of double-gate SiGe- SiO2/HfO2 pMOS FinFET devices is investigated under different device bias conditions. Negative bias irradiation leads to the worst-case degradation due to increased hole trapping in the HfO2 layer, in contrast to what is typically observed for devices with SiO2 or HfO2 gate dielectrics. This occurs in the devices because radiation-induced holes that are generated in the SiO2 interfacial layer can transport and become trapped in the HfO2 under negative bias, leading to a more negative threshold voltage shift than observed at 0 V bias. Similarly, radiation-induced electrons that are generated in the SiO2 interfacial layer can transport into the HfO2 and become trapped under positive bias, leading to a more positive threshold voltage shift than observed at 0 V bias.","Radiation effects,
Double-gate FETs,
FinFETs,
Silicon germanium,
Electron traps,
Threshold voltage,
Hafnium oxide"
An Investigation of Single-Event Transients in C-SiGe HBT on SOI Current Mirror Circuits,"The single-event effect sensitivity of three different commonly employed current mirror circuits, as well as an unconventional inverse-mode current mirror, all implemented in C-SiGe (NPN + PNP) HBT on SOI technology are investigated. Comparisons of the measured data of the basic NPN and PNP current mirror circuits show higher single-event radiation tolerance of PNP SiGe HBTs compared with NPN SiGe HBTs. The concept of utilizing inverse-mode SiGe HBTs in current mirror circuits is investigated. Measurement results validate the feasibility of employing inverse-mode PNP SiGe HBTs in current mirrors and show an excellent resilience against ion-strikes. Full 3-D NanoTCAD models of the SiGe HBTs are developed and used in mixed-mode TCAD simulations (within Cadence) to validate the measurement results. Finally, based on the measurement data and analysis of the four current mirrors, some practical suggestions and observations are offered for operation of such circuits in extreme environments.","Mirrors,
Silicon germanium,
Transient analysis,
Heterojunction bipolar transistors,
Single event upsets,
Single event transients,
Radiation hardening (electronics)"
Formal property verification in a conformance testing framework,"In model-based design of cyber-physical systems, such as switched mixed-signal circuits or software-controlled physical systems, it is common to develop a sequence of system models of different fidelity and complexity, each appropriate for a particular design or verification task. In such a sequence, one model is often derived from the other by a process of simplification or implementation. E.g. a Simulink model might be implemented on an embedded processor via automatic code generation. Three questions naturally present themselves: how do we quantify closeness between the two systems? How can we measure such closeness? If the original system satisfies some formal property, can we automatically infer what properties are then satisfied by the derived model? This paper addresses all three questions: we quantify the closeness between original and derived model via a distance measure between their outputs. We then propose two computational methods for approximating this closeness measure. Finally, we derive syntactical re-writing rules which, when applied to a Metric Temporal Logic specification satisfied by the original model, produce a formula satisfied by the derived model. We demonstrate the soundness of the theory with several experiments.","Computational modeling,
Testing,
Integrated circuit modeling,
Educational institutions,
Software packages,
Switches,
Measurement"
"A Scalable, 2.9 mW, 1 Mb/s e-Textiles Body Area Network Transceiver With Remotely-Powered Nodes and Bi-Directional Data Communication","This paper presents transceivers and a wireless power delivery system for a Body-Area Network (BAN) that uses an e-textiles-based physical layer (PHY) capable of linking a diverse set of sensor nodes monitoring vital signs on the user's body. A central base station in the network controls power delivery and communication resource allotment for every node using a general-purpose on-chip Node Network Interface (NNI). The architecture of the network ensures fault-tolerance, reconfigurability and ease of use through a dual wireless-wireline topology. The nodes are powered at a peak end-to-end efficiency of 1.2% and can transmit measured data at a peak rate of 1 Mb/s. Modulation schemes for communication in both directions have been chosen and a Medium Access and Control (MAC) protocol has been designed and implemented on chip to reduce complexity at the power-constrained nodes, and move it to the base station. While transferring power to a single node at maximum efficiency, the base station consumes 2.9 mW power and the node recovers 34 µW, of which 14 µW is used to power the network interface circuits while the rest can be used to power signal acquisition circuitry. Fabricated in 0.18 µm CMOS technology, the base station and the NNI occupy 2.95 mm 2 and 1.46 mm 2 area, respectively.",
"Interference Channels With Coordinated Multipoint Transmission: Degrees of Freedom, Message Assignment, and Fractional Reuse","Coordinated multipoint (CoMP) transmission is an infrastructural enhancement under consideration for next generation wireless networks. In this paper, the capacity gain achieved through CoMP transmission is studied in various models of wireless networks that have practical significance. The capacity gain is analyzed through the degrees of freedom (DoF) criterion. The DoF available for communication provides an analytically tractable way to characterize the capacity of interference channels. The considered channel model has K transmitter/receiver pairs, and each receiver is interested in one unique message from a set of K independent messages. Each message can be available at more than one transmitter. The maximum number of transmitters at which each message can be available, is defined as the cooperation order M. For fully connected interference channels, it is shown that the asymptotic per user DoF, as K goes to infinity, remains at 1/2 as M is increased from 1 to 2. Furthermore, the same negative result is shown to hold for all M ≥ 2 for any message assignment that satisfies a local cooperation constraint. On the other hand, when the assumption of full connectivity is relaxed to local connectivity, and each transmitter is connected only to its own receiver as well as L neighboring receivers, it is shown that local cooperation is optimal. The asymptotic per user DoF is shown to be at least max {1/2, 2M/(2M + L)} for locally connected channels, and is shown to be 2M/(2M + 1) for the special case of Wyner's asymmetric model where L = 1. An interesting feature of the proposed achievability scheme is that it relies on simple zero-forcing transmit beams and does not require symbol extensions. Also, to achieve the optimal per user DoF for Wyner's model, messages are assigned to transmitters in an asymmetric fashion unlike traditional assignments where message i has to be available at transmitter i. It is also worth noting that some receivers have to be inactive, and fractional reuse is needed to achieve equal DoF for all users.","Receivers,
Channel models,
Radio transmitters,
Interference channels,
Indexes"
Generalised Kalman filter tracking with multiplicative measurement noise in a wireless sensor network,"A new generalised Kalman filtering algorithm using a multiplicative measurement noise model is developed for tracking moving targets in a wireless sensor network. This multiplicative error model facilitates more accurate characterisation of the distance dependence measurement errors of range-estimating sensors. Two new formulations of extended Kalman filter (EKF) and unscented Kalman filter (UKF), called generalised EKF (GEKF) and generalised UKF (GUKF) are derived. Comparing with conventional EKF and UKF formulations, it is shown that GEKF and GUKF can achieve smaller tracking error than traditional EKF and UKF. Simulation results are also reported that demonstrated the superior performance of GEKF and GUKF over existing methods.","Kalman filters,
nonlinear filters,
wireless sensor networks"
Limitations and trade-offs in gene expression due to competition for shared cellular resources,"Gene circuits share transcriptional and translational resources in the cell. The fact that these common resources are available only in limited amounts leads to unexpected couplings in protein expressions. As a result, our predictive ability of describing the behavior of gene circuits is limited. In this paper, we consider the simultaneous expression of proteins and describe the coupling among protein concentrations due to competition for RNA polymerase and ribosomes. In particular, we identify the limitations and trade-offs in gene expression by characterizing the attainable combinations of protein concentrations. We further present two application examples of our results: we show that even in the absence of regulatory linkages, genes can seemingly behave as repressors, and surprisingly, as activators to each other, purely due to the limited availability of shared cellular resources.","Proteins,
Silicon,
Availability,
Approximation methods,
Couplings,
Gene expression"
Learning Cascaded Shared-Boost Classifiers for Part-Based Object Detection,"This paper focuses on the problem of detecting a number of different class objects in images. We present a novel part-based model for object detection with cascaded classifiers. The coarse root and fine part classifiers are combined into the model. Different from the existing methods which learn root and part classifiers independently, we propose a shared-Boost algorithm to jointly train multiple classifiers. This paper is distinguished by two key contributions. The first is to introduce a new definition of shared features for similar pattern representation among multiple classifiers. Based on this, a shared-Boost algorithm which jointly learns multiple classifiers by reusing the shared feature information is proposed. The second contribution is a method for constructing a discriminatively trained part-based model, which fuses the outputs of cascaded shared-Boost classifiers as high-level features. The proposed shared-Boost-based part model is applied for both rigid and deformable object detection experiments. Compared with the state-of-the-art method, the proposed model can achieve higher or comparable performance. In particular, it can lift up the detection rates in low-resolution images. Also the proposed procedure provides a systematic framework for information reusing among multiple classifiers for part-based object detection.",
Towards an inclusive Parkinson's screening system,"In this study, brain, and gait dynamic information were combined and used for diagnosis and monitoring of Parkinson's disease (the most important Neurodegenerative Disorder). Analysis of the information corresponding to a prescribed movement involving tremor, and the related changes in brain connectivity is novel and original. Analytically, developing a space-time nonlinear adaptive system which fuses brain and gait information algorithmically is proposed here for the first time. The overall dynamic system will be constrained by the clinical impressions of the patient symptoms embedded in a knowledge-based system. The entire complex constrained problem were solved to enable a powerful model for recognition and monitoring of Parkinson's disease and establishing appropriate rules for its clinical following up.","Brain modeling,
Adaptation models,
Parkinson's disease,
Chaos,
Signal processing algorithms,
Nonlinear dynamical systems"
Web-Based Workflow Planning Platform Supporting the Design and Execution of Complex Multiscale Cancer Models,"Significant Virtual Physiological Human efforts and projects have been concerned with cancer modeling, especially in the European Commission Seventh Framework research program, with the ambitious goal to approach personalized cancer simulation based on patient-specific data and thereby optimize therapy decisions in the clinical setting. However, building realistic in silicopredictive models targeting the clinical practice requires interactive, synergetic approaches to integrate the currently fragmented efforts emanating from the systems biology and computational oncology communities all around the globe. To further this goal, we propose an intelligent graphical workflow planning system that exploits the multiscale and modular nature of cancer and allows building complex cancer models by intuitively linking/interchanging highly specialized models. The system adopts and extends current standardization efforts, key tools, and infrastructure in view of building a pool of reliable and reproducible models capable of improving current therapies and demonstrating the potential for clinical translation of these technologies.",
"Design and Analysis of a Highly User-Friendly, Secure, Privacy-Preserving, and Revocable Authentication Method","A large portion of system breaches are caused by authentication failure, either during the login process or in the post-authentication session; these failures are themselves related to the limitations associated with existing authentication methods. Current authentication methods, whether proxy based or biometrics based, are not user-centric and/or endanger users' (biometric) security and privacy. In this paper, we propose a biometrics based user-centric authentication approach. This method involves introducing a reference subject (RS), securely fusing the user's biometrics with the RS, generating a BioCapsule (BC) from the fused biometrics, and employing BCs for authentication. Such an approach is user friendly, identity bearing yet privacy-preserving, resilient, and revocable once a BC is compromised. It also supports “one-click sign-on” across systems by fusing the user's biometrics with a distinct RS on each system. Moreover, active and non-intrusive authentication can be automatically performed during post-authentication sessions. We formally prove that the secure fusion based approach is secure against various attacks. Extensive experiments and detailed comparison with existing approaches show that its performance (i.e., authentication accuracy) is comparable to existing typical biometric approaches and the new BC based approach also possesses many desirable features such as diversity and revocability.","Authentication,
Feature extraction,
Iris recognition,
Privacy,
Measurement"
Surface-Enhanced Raman Spectroscopy Sensors From Nanobiosilica With Self-Assembled Plasmonic Nanoparticles,"We present an innovative surface-enhanced Raman spectroscopy (SERS) sensor based on a biological-plasmonic hybrid nanostructure by self-assembling silver (Ag) nanoparticles into diatom frustules. The photonic-crystal-like diatom frustules provide a spatially confined electric field with enhanced intensity that can form hybrid photonic-plasmonic modes through the optical coupling with Ag nanoparticles. The experimental results demonstrate 4-6× and 9-12× improvement of sensitivities to detect the Raman dye for resonance and nonresonance SERS sensing, respectively. Such low-cost and high-sensitivity SERS sensors have significant potentials for label-free biosensing.","Substrates,
Glass,
Raman scattering,
Sensors,
Plasmons,
Nanobioscience,
Photonic crystals"
Inter-symbol interference analysis of synaptic channel in molecular communications,"Neuro-spike communication is an important branch of molecular communications and has attracted much attention recently. Seminal works on the analyses of signal processing and channel models for the synaptic communication have recently been carried out. However, these works do not consider interference. In this paper, we propose an interference model for synaptic channels with particular focus on InterSymbol Interference (ISI) and Single-Input Single-Output (SISO) channel. We have investigated the overlapping between the two consecutively signals which are sent from a presynaptic terminal to a postsynaptic terminal and their interferences. Furthermore, important parameters of synaptic communication channel that are related to the ISI are also analyzed. The relationship between channel rate region and ISI is also studied.","Communication channels,
Neurons,
Interference,
Molecular communication,
Neurotransmitters,
Firing,
Signal processing"
Code generation from a domain-specific language for C-based HLS of hardware accelerators,"As today's computer architectures are becoming more and more heterogeneous, a plethora of options including CPUs, GPUs, DSPs, reconfigurable logic (FPGAs), and other application-specific processors come into consideration for close-to-sensor processing. Especially, in the domain of image processing on mobile devices, among numerous design challenges, a very stringent energy budget is of utmost importance, making embedded GPUs and FPGAs ideal targets for implementation. Recently, the HIPAcc framework was proposed as a means for automatic code generation of image processing algorithms for embedded GPUs, based on a Domain-Specific Language (DSL). Despite of huge advancements in High-Level Synthesis (HLS) for FPGAs, designers are still required to have detailed knowledge about coding techniques and the targeted architecture to achieve efficient solutions. As a remedy, in this work, we propose code generation techniques for C-based HLS from a common high-level DSL description targeting FPGAs. Our approach includes FPGA-specific memory architectures for handling point and local operators, numerous high-level transformations, and automatic test bench generation. We evaluate our approach by comparing the resulting hardware accelerators to existing frameworks in terms of performance and resource requirements. Moreover, we assess the achieved energy efficiency in contrast to software implementations, generated by HIPAcc from the same code base, executed on GPUs.","Kernel,
Field programmable gate arrays,
Image processing,
DSL,
Hardware,
Laplace equations,
Computer architecture"
Retrospective Rigid Motion Correction in k-Space for Segmented Radial MRI,"Motion occurring during magnetic resonance imaging acquisition is a major factor of image quality degradation. Self-navigation can help reduce artefacts by estimating motion from the acquired data to enable motion correction. Popular self-navigation techniques rely on the availability of a fully-sampled motion-free reference to register the motion corrupted data with. In the proposed technique, rigid motion parameters are derived using the inherent correlation between radial segments in k-space. The registration is performed exclusively in k-space using the Phase Correlation Method, a popular registration technique in computer vision. Robust and accurate registration has been carried out from radial segments composed of as few as 32 profiles. Successful self-navigation has been performed on 2-D dynamic brain scans corrupted with continuous motion for six volunteers. Retrospective motion correction using the derived self-navigation parameters resulted in significant improvement of image quality compared to the conventional sliding window. This work also demonstrates the benefits of using a bit-reversed ordering scheme to limit undesirable effects specific to retrospective motion correction on radial trajectories. This method provides a fast and efficient mean of measuring rigid motion directly in k-space from dynamic radial data under continuous motion.","Motion control,
Magnetic resonance imaging,
Biomedical image processing"
Self-organizing aerial mesh networks for emergency communication,"Guaranteeing network connectivity in post-disaster scenarios is challenging yet crucial to save human lives and to coordinate the operations of first responders. In this paper, we investigate the utilization of low-altitude aerial mesh networks composed by Small Unmanned Aerial Vehicles (SUAVs) in order to re-enstablish connectivity among isolated end-user (EU) devices located on the ground. Aerial ad-hoc networks provide the advantage to be deployable also on critical scenarios where terrestrial mobile devices might not operate, however their implementation is challenging from the point of view of mobility management and of coverage lifetime. In this paper, we address both these issues with three novel research contributions. First, we propose a distributed mobility algorithm, based on the virtual spring model, through which the SUAV-based mesh node-called also Repairing Units (RUs) in this study- can self-organize into a mesh structure by guaranteeing Quality of Service (QoS) over the aerial link, and connecting the maximum number of EU devices. Second, we evaluate our scheme on a realistic 3D environment with buildings, and we demonstrate the effectiveness of the aerial deployment compared to a terrestrial one, in terms of coverage and wireless link reliability. Third, we address the problem of energy lifetime, and we propose a distributed charging scheduling scheme, through which a persistent coverage of RUs can be guaranteed over the emergency scenario.","Buildings,
Springs,
Three-dimensional displays,
Solid modeling,
Mesh networks,
Quality of service,
Force"
Information hiding in HEVC standard using adaptive coding block size decision,"In this work, an information hiding techniques is proposed using the coding block size decision in HEVC. This approach manipulates the CB (coding block) size decision on every coding tree unit to embed information based on the predefined mapping rules. Each CB is forced to assume certain size to encode the external information without significantly compromising perceptual quality. To improve payload, the odd-even based information hiding technique is further deployed by manipulating the nonzero DCT coefficients in certain ranges, in which case each range depends on the CB size. Results suggest that by combining both approaches, improvement is achieved in the terms of payload for the higher bitrate scenario and insignificant degradation in perceptual video quality for the low bitrate scenario.","Bit rate,
Encoding,
Payloads,
Standards,
Video coding,
Discrete cosine transforms,
Video sequences"
Relative Generalized Hamming Weights of One-Point Algebraic Geometric Codes,"Security of linear ramp secret sharing schemes can be characterized by the relative generalized Hamming weights of the involved codes. In this paper, we elaborate on the implication of these parameters and devise a method to estimate their value for general one-point algebraic geometric codes. As it is demonstrated, for Hermitian codes, our bound is often tight. Furthermore, for these codes, the relative generalized Hamming weights are often much larger than the corresponding generalized Hamming weights.","Cryptography,
Linear codes,
Hamming weight,
Vectors,
Electronic mail,
Materials,
Random variables"
Efficient Implementation of Hyperspectral Anomaly Detection Techniques on GPUs and Multicore Processors,"Anomaly detection is an important task for hyperspectral data exploitation. Although many algorithms have been developed for this purpose in recent years, due to the large dimensionality of hyperspectral image data, fast anomaly detection remains a challenging task. In this work, we exploit the computational power of commodity graphics processing units (GPUs) and multicore processors to obtain implementations of a well-known anomaly detection algorithm developed by Reed and Xiaoli (RX algorithm), and a local (LRX) variant, which basically consists in applying the same concept to a local sliding window centered around each image pixel. LRX has been shown to be more accurate to detect small anomalies but computationally more expensive than RX. Our interest is focused on improving the computational aspects, not only through efficient parallel implementations, but also by analyzing the mathematical issues of the method and adopting computationally inexpensive solvers. Futhermore, we also assess the energy consumption of the newly developed parallel implementations, which is very important in practice. Our optimizations (based on software and hardware techniques) result in a significant reduction of execution time and energy consumption, which are keys to increase the practical interest of the considered algorithms. Indeed, for RX, the runtime obtained is less than the data acquisition time when real hyperspectral images are used. Our experimental results also indicate that the proposed optimizations and the parallelization techniques can significantly improve the general performance of the RX and LRX algorithms while retaining their anomaly detection accuracy.","Graphics processing units,
Correlation,
Hyperspectral imaging,
Multicore processing,
Optimization"
Fabrication and Characterization of a Vacuum Encapsulated Curved Beam Switch for Harsh Environment Application,"A vacuum-encapsulated silicon switch with a curved electrode is characterized for operation in harsh environments. An ultraclean vacuum encapsulation process (episeal) seals the switch after release, providing a pristine operating environment for switching operations. In these devices, the curved beam of the actuator enhances the overdrive voltage tolerance to be more than 100 V. The ON/OFF cycle tests were carried out up to 105 cycles at room temperature, and at least 104 cycles under an elevated temperature of 300°C. Throughout the 300°C tests, an average contact resistance of ~ 28 kΩ is measured, demonstrating the stability of the contact. Finally, high speed pulse I-V monitoring unit was used to observe 13-μs switching speed.","Switches,
Logic gates,
Contacts,
Force,
Electrostatics,
Structural beams,
Silicon"
Learning Cross-Media Joint Representation With Sparse and Semisupervised Regularization,"Cross-media retrieval has become a key problem in both research and application, in which users can search results across all of the media types (text, image, audio, video, and 3-D) by submitting a query of any media type. How to measure the content similarity among different media is the key challenge. Existing cross-media retrieval methods usually focus on modeling the pairwise correlation or semantic information separately. In fact, these two kinds of information are complementary to each other and optimizing them simultaneously can further improve the accuracy. In this paper, we propose a novel feature learning algorithm for cross-media data, called joint representation learning (JRL), which is able to explore jointly the correlation and semantic information in a unified optimization framework. JRL integrates the sparse and semisupervised regularization for different media types into one unified optimization problem, while existing feature learning methods generally focus on a single media type. On one hand, JRL learns sparse projection matrix for different media simultaneously, so different media can align with each other, which is robust to the noise. On the other hand, both the labeled data and unlabeled data of different media types are explored. Unlabeled examples of different media types increase the diversity of training data and boost the performance of joint representation learning. Furthermore, JRL can not only reduce the dimension of the original features, but also incorporate the cross-media correlation into the final representation, which further improves the performance of both cross-media retrieval and single-media retrieval. Experiments on two datasets with up to five media types show the effectiveness of our proposed approach, as compared with the state-of-the-art methods.",
Verification on the extreme scalability of STT-MRAM without loss of thermal stability below 15 nm MTJ cell,"Scalability of interface driven perpendicular magnetic anisotropy (i-PMA) magnetic tunnel junctions (MTJs) has been improved down to 1X node which verifies STT-MRAM for future standalone memory. With developing a novel damage-less MTJ patterning process, robust magnetic and electrical performances of i-PMA MTJ cell down to 15 nm node could be achieved.","Thermal stability,
Magnetic tunneling,
Switches,
Stability analysis,
Magnetic switching,
Thermal factors,
Scalability"
An Omnidirectional MEMS Ultrasonic Energy Harvester for Implanted Devices,"This paper presents the design and characterization of a microelectromechanical systems (MEMS)-based energy harvester with target applications, including implanted biomedical sensors and actuators. The harvester is designed to utilize ultrasonic waves from an external transmitter for mechanical excitation, with electrostatic transducers being used to convert the vibrations of a central mass structure into electrical energy. The device features a novel 3-degrees of freedom design, which enables energy to be produced by the harvester in any orientation. The harvester is fabricated using a conventional silicon-on-insulator MEMS process, with experimental testing showing that the system is able to generate 24.7, 19.8, and 14.5nW of electrical power, respectively, via the device's x-, y- and z-axis resonance modes over a 15-s period.",
Outage performance analysis of underlay cognitive RF and FSO wireless channels,"In this work, the outage performance analysis of a dual-hop transmission system composed of asymmetric radio frequency (RF) channel cascaded with a free-space optical (FSO) link is presented. For the RF link, an underlay cognitive network is considered where the secondary users share the spectrum with licensed primary users. Indoor femtocells act as a practical example for such networks. More specifically, it is assumed that the RF link applies power control to maintain the interference at the primary network below a predetermined threshold. While the RF channel is modeled by the Rayleigh fading distribution, the FSO link is modeled by a unified Gamma-Gamma turbulence distribution. The FSO link accounts for pointing errors and both types of detection techniques (i.e. heterodyne detection as well as intensity modulation/direct detection (IM/DD)). With this model, a new exact closed-form expression is derived for the outage probability of the end-to-end signal-to-noise ratio of these systems in terms of the Meijer's G function and the Fox's H functions under fixed amplify-and-forward relay scheme. All new analytical results are verified via computer-based Monte-Carlo simulations and are illustrated by some selected numerical results.","Radio frequency,
Adaptive optics,
Signal to noise ratio,
Relays,
Wireless communication,
Interference,
Optical fiber communication"
Frequency Prediction of Power Systems in FNET Based on State-Space Approach and Uncertain Basis Functions,"In this paper, we discuss the modeling and prediction of power frequency. Power frequency is one of the most essential parameters in the monitoring, control, and protection of power systems and electric equipments because when a significant disturbance occurs in a power system, the frequency varies in time and space. It is critical to employ a dependable model in order to optimize the efficiency and reliability of power systems in the Frequency Monitoring Network (FNET ), and thus, prevent frequency oscillation in power grid. This paper describes the use of a state-space model and basis functions to predict power frequency. In the state-space method, expectation maximization (EM) and prediction error minimization (PEM) algorithms are used to dynamically estimate the model's parameters. In the basis functions method, we employ random basis functions to predict the frequency. The algorithms are easy to implement online, having both high precision and a short response time. Numerical results are presented to demonstrate that the proposed techniques are able to achieve good performance in frequency prediction.",
Genetic Algorithms for Evolving Computer Chess Programs,"This paper demonstrates the use of genetic algorithms for evolving: 1) a grandmaster-level evaluation function, and 2) a search mechanism for a chess program, the parameter values of which are initialized randomly. The evaluation function of the program is evolved by learning from databases of (human) grandmaster games. At first, the organisms are evolved to mimic the behavior of human grandmasters, and then these organisms are further improved upon by means of coevolution. The search mechanism is evolved by learning from tactical test suites. Our results show that the evolved program outperforms a two-time world computer chess champion and is at par with the other leading computer chess programs.","Organisms,
Games,
Computers,
Tuning,
Genetic algorithms,
Biological cells,
Sociology"
JPEG quantization tables selection by the firefly algorithm,"JPEG is the prevailing compression algorithm used for digital images. Compression ratio and quality depend on quantization tables that are matrixes of 64 integers. The quality of compression for many applications has to be determined not by human judgment, but by software systems that perform some processing on compressed images, based on successfulness of such processing. Since there are many such applications, there is not unique best quantization table but it has to be selected for each application. Quantization table selection is intractable combinatorial problem that can be successfully solved by swarm intelligence metaheuristics. In this paper we present framework for application of the recently introduced firefly algorithm to the quantization table selection problem for different image similarity metrics.","Image coding,
Quantization (signal),
Transform coding,
Discrete cosine transforms,
Standards,
Particle swarm optimization,
Optimization"
Behavior Analysis of Internet Traffic via Bipartite Graphs and One-Mode Projections,"As Internet traffic continues to grow in size and complexity, it has become an increasingly challenging task to understand behavior patterns of end-hosts and network applications. This paper presents a novel approach based on behavioral graph analysis to study the behavior similarity of Internet end-hosts. Specifically, we use bipartite graphs to model host communications from network traffic and build one-mode projections of bipartite graphs for discovering social-behavior similarity of end-hosts. By applying simple and efficient clustering algorithms on the similarity matrices and clustering coefficient of one-mode projection graphs, we perform network-aware clustering of end-hosts in the same network prefixes into different end-host behavior clusters and discover inherent clustered groups of Internet applications. Our experiment results based on real datasets show that end-host and application behavior clusters exhibit distinct traffic characteristics that provide improved interpretations on Internet traffic. Finally, we demonstrate the practical benefits of exploring behavior similarity in profiling network behaviors, discovering emerging network applications, and detecting anomalous traffic patterns.","graph theory,
Internet,
matrix algebra,
pattern clustering,
telecommunication traffic"
A New Hardware-Efficient Algorithm and Reconfigurable Architecture for Image Contrast Enhancement,"Contrast enhancement is crucial when generating high quality images for image processing applications, such as digital image or video photography, liquid crystal display processing, and medical image analysis. In order to achieve real-time performance for high-definition video applications, it is necessary to design efficient contrast enhancement hardware architecture to meet the needs of real-time processing. In this paper, we propose a novel hardware-oriented contrast enhancement algorithm which can be implemented effectively for hardware design. In order to be considered for hardware implementation, approximation techniques are proposed to reduce these complex computations during performance of the contrast enhancement algorithm. The proposed hardware-oriented contrast enhancement algorithm achieves good image quality by measuring the results of qualitative and quantitative analyzes. To decrease hardware cost and improve hardware utilization for real-time performance, a reduction in circuit area is proposed through use of parameter-controlled reconfigurable architecture. The experiment results show that the proposed hardware-oriented contrast enhancement algorithm can provide an average frame rate of 48.23 frames/s at high definition resolution 1920 × 1080.",
An Algebraic Approach to Non-malleability,"In their seminal work on non-malleable cryptography, Dolev, Dwork and Naor, showed how to construct a non-malleable commitment with logarithmically-many ""rounds""/""slots"", the idea being that any adversary may successfully maul in some slots but would fail in at least one. Since then new ideas have been introduced, ultimately resulting in constant-round protocols based on any one-way function. Yet, in spite of this remarkable progress, each of the known constructions of non-malleable commitments leaves something to be desired. In this paper we propose a new technique that allows us to construct a non-malleable protocol with only a single ""slot"", and to improve in at least one aspect over each of the previously proposed protocols. Two direct byproducts of our new ideas are a four round non-malleable commitment and a four round non-malleable zero-knowledge argument, the latter matching the round complexity of the best known zero-knowledge argument (without the non-malleability requirement). The protocols are based on the existence of one-way functions and admit very efficient instantiations via standard homomorphic commitments and sigma protocols. Our analysis relies on algebraic reasoning, and makes use of error correcting codes in order to ensure that committers' tags differ in many coordinates. One way of viewing our construction is as a method for combining many atomic sub-protocols in a way that simultaneously amplifies soundness and non-malleability, thus requiring much weaker guarantees to begin with, and resulting in a protocol which is much trimmer in complexity compared to the existing ones.","Protocols,
Vectors,
Complexity theory,
Error correction codes,
Receivers,
Educational institutions,
Security"
On Skyline Groups,"We formulate and investigate the novel problem of finding the skyline k-tuple groups from an n-tuple data set-i.e., groups of k tuples which are not dominated by any other group of equal size, based on aggregate-based group dominance relationship. The major technical challenge is to identify effective anti-monotonic properties for pruning the search space of skyline groups. To this end, we first show that the anti-monotonic property in the well-known Apriori algorithm does not hold for skyline group pruning. Then, we identify two anti-monotonic properties with varying degrees of applicability: order-specific property which applies to SUM, MIN, and MAX as well as weak candidate-generation property which applies to MIN and MAX only. Experimental results on both real and synthetic data sets verify that the proposed algorithms achieve orders of magnitude performance gain over the baseline method.","Aggregates,
Vectors,
Games,
Databases,
Computer science,
Educational institutions,
Electronic mail"
"Survey on smart grid technologies- smart metering, IoT and EMS","The application of communication and information technology in electrical utility makes consumers to be very comfortable. From the perspective of energy saving and power efficiency in Generation, Utility, Industry and homes an effective supervising of appliances is required. Now a day, smart grid conceptusing various cost effective communication technology and architecture proves electrical sector to have a bidirectional communication with utility and consumers as well as remote monitoring. Research and development in smart grid come up with new technology to make human life easier. This paper gives a strong idea about various technologies and standards for smart grid as well as smart metering /AMI. Also it provides knowledge on energy management system (EMS) and Internet of Things (IoT) for various applications.","Standards,
Smart grids,
Zigbee,
Protocols,
Energy management,
Internet,
Computer architecture"
LACS: A Locality-Aware Cost-Sensitive Cache Replacement Algorithm,"The design of an effective last-level cache (LLC) in general-and an effective cache replacement/partitioning algorithm in particular-is critical to the overall system performance. The processor's ability to hide the LLC miss penalty differs widely from one miss to another. The more instructions the processor manages to issue during the miss, the better it is capable of hiding the miss penalty and the lower the cost of that miss. This nonuniformity in the processor's ability to hide LLC miss latencies, and the resultant nonuniformity in the performance impact of LLC misses, opens up an opportunity for a new cost-sensitive cache replacement algorithm. This paper makes two key contributions. First, It proposes a framework for estimating the costs of cache blocks at run-time based on the processor's ability to (partially) hide their miss latencies. Second, It proposes a simple, low-hardware overhead, yet effective, cache replacement algorithm that is locality-aware and cost-sensitive (LACS). LACS is thoroughly evaluated using a detailed simulation environment. LACS speeds up 12 LLC-performance-constrained SPEC CPU2006 benchmarks by up to 51% and 11% on average. When evaluated using a dual/quad-core CMP with a shared LLC, LACS significantly outperforms LRU in terms of performance and fairness, achieving improvements up to 54%.","Prediction algorithms,
Partitioning algorithms,
Algorithm design and analysis,
Benchmark testing,
Aggregates,
Estimation,
Optimization"
Delay performance modeling and analysis in clustered cognitive radio networks,"Cognitive radio networks (CRNs) emerge as a promising solution for overcoming the shortage and inefficient use of bandwidth resources by allowing secondary users (SUs) to access the primary users' (PUs) channels so long as they do not interfere with them. The random availability of the PU channels makes the delay analysis of the SU, which accesses the channels opportunistically, plays a crucial role as a quality of service measure. In this paper, we model and characterize the total average delay the SUs experience in a CRN. The cognitive radio system is modeled as a discrete-time queueing system. The availability of the N independent and identical PU channels is modeled as a two states Markov chain. Our contributions in this paper is that we provide a solid performance evaluation that gives a closed-formula for the two delay components experienced by the SUs, namely the waiting delay and the service delay. We derive the waiting delay using the residual time concept. We characterize the service time distribution by considering the buffered-slotted-ALOHA systems. We also provide numerical results to show the effects of the analysis on the CRN design.","Delays,
Cognitive radio,
Analytical models,
Queueing analysis,
Ad hoc networks,
Availability,
Markov processes"
Closed-Form Expressions for the Noise Voltage Caused by a Burst Train of IC Switching Currents on a Power Distribution Network,"A burst stimulus of data is a common activity in circuits and systems. The supply noise voltage waveform induced by a burst train of integrated circuit (IC) switching currents is rigorously derived for a power distribution network (PDN) with power traces, commonly used in handheld devices. Closed-form expressions are proposed to quickly estimate the amount of voltage drop and overshoot and to develop more complete PDN design methodology as improved target impedances. The proposed PDN noise expressions are also validated with SPICE simulation and measurements using a fabricated IC and PCB.","Noise measurement,
Capacitors,
Switches,
Impedance,
Closed-form solutions,
Integrated circuit modeling"
Spherical Blurred Shape Model for 3-D Object and Pose Recognition: Quantitative Analysis and HCI Applications in Smart Environments,"The use of depth maps is of increasing interest after the advent of cheap multisensor devices based on structured light, such as Kinect. In this context, there is a strong need of powerful 3-D shape descriptors able to generate rich object representations. Although several 3-D descriptors have been already proposed in the literature, the research of discriminative and computationally efficient descriptors is still an open issue. In this paper, we propose a novel point cloud descriptor called spherical blurred shape model (SBSM) that successfully encodes the structure density and local variabilities of an object based on shape voxel distances and a neighborhood propagation strategy. The proposed SBSM is proven to be rotation and scale invariant, robust to noise and occlusions, highly discriminative for multiple categories of complex objects like the human hand, and computationally efficient since the SBSM complexity is linear to the number of object voxels. Experimental evaluation in public depth multiclass object data, 3-D facial expressions data, and a novel hand poses data sets show significant performance improvements in relation to state-of-the-art approaches. Moreover, the effectiveness of the proposal is also proved for object spotting in 3-D scenes and for real-time automatic hand pose recognition in human computer interaction scenarios.","Shape,
Vectors,
Quaternions,
Human computer interaction,
Solid modeling,
Computational modeling,
Context"
Network-Based Drug-Target Interaction Prediction with Probabilistic Soft Logic,"Drug-target interaction studies are important because they can predict drugs' unexpected therapeutic or adverse side effects. In silico predictions of potential interactions are valuable and can focus effort on in vitro experiments. We propose a prediction framework that represents the problem using a bipartite graph of drug-target interactions augmented with drug-drug and target-target similarity measures and makes predictions using probabilistic soft logic (PSL). Using probabilistic rules in PSL, we predict interactions with models based on triad and tetrad structures. We apply (blocking) techniques that make link prediction in PSL more efficient for drug-target interaction prediction. We then perform extensive experimental studies to highlight different aspects of the model and the domain, first comparing the models with different structures and then measuring the effect of the proposed blocking on the prediction performance and efficiency. We demonstrate the importance of rule weight learning in the proposed PSL model and then show that PSL can effectively make use of a variety of similarity measures. We perform an experiment to validate the importance of collective inference and using multiple similarity measures for accurate predictions in contrast to non-collective and single similarity assumptions. Finally, we illustrate that our PSL model achieves state-of-the-art performance with simple, interpretable rules and evaluate our novel predictions using online data sets.","Drugs,
Predictive models,
Bioinformatics,
Computational biology,
Probabilistic logic,
Measurement"
Block-Wise QR-Decomposition for the Layered and Hybrid Alamouti STBC MIMO Systems: Algorithms and Hardware Architectures,"Unlike the channel matrix in the spatial division multiplexing (SDM) multiple-input multiple-output (MIMO) communication system, the equivalent channel matrix in the layered Alamouti space-time block coding (STBC) MIMO system comprised 2-by-2 Alamouti sub-blocks. One novel property, found by Sayed about the QR-decomposition (QRD) of this equivalent channel matrix is that the produced Q- and R-matrices are also matrices with Alamouti sub-blocks. Taking advantage of this property, we propose a new block-wise complex Givens rotation (BCGR) based algorithm and a triangular systolic array (TSA) to compute the QRD of the equivalent channel matrix in an Alamouti block by block manner. Implementation results reveal that our new TSA can compute QRDs of 4-by-4 equivalent channel matrices faster than any architecture that has been developed for the SDM MIMO system. This property of fast QRD makes our TSA very attractive for the layered Alamouti STBC MIMO system combined with the orthogonal frequency division multiplexing. Our new BCGR based approach can also be applied to the hybrid Alamouti STBC MIMO system, which is also a system with equivalent channel matrix consisting of Alamouti sub-blocks.","MIMO,
Signal processing algorithms,
Computer architecture,
Hardware,
Receiving antennas,
Educational institutions,
Transmitting antennas"
Cloud gaming onward: research opportunities and outlook,"Cloud gaming has become increasingly more popular in the academia and the industry, evident by the large numbers of related research papers and startup companies. Some public cloud gaming services have attracted hundreds of thousands subscribers, demonstrating the initial success of cloud gaming services. Pushing the cloud gaming services forward, however, faces various challenges, which open up many research opportunities. In this paper, we share our views on the future cloud gaming research, and point out several research problems spanning over a wide spectrum of different directions: including distributed systems, video codecs, virtualization, human-computer interaction, quality of experience, resource allocation, and dynamic adaptation. Solving these research problems will allow service providers to offer high-quality cloud gaming services yet remain profitable, which in turn results in even more successful cloud gaming eco-environment. In addition, we believe there will be many more novel ideas to capitalize the abundant and elastic cloud resources for better gaming experience, and we will see these ideas and associated challenges in the years to come.","Games,
Servers,
Graphics processing units,
Cloud computing,
Rendering (computer graphics),
Mobile communication,
Delays"
Incremental unsupervised topological place discovery,"This paper describes an online place discovery and recognition engine that fuses information over time to create topologically distinct places. A key motivation is the recognition that a single image may be a poor exemplar of what constitutes a place. Images are not `places' nor are they `documents'. Instead, by treating image-sequences as a multimodal distribution over topics - and by discovering topics incrementally and online - it is possible to both reduce the memory footprint of place recognition systems, and to improve precision and recall. Distinctive key-places are represented by a cluster topics found from the covisibility graph of a relative simultaneous localization and mapping engine - key-places inherently span many images. A dynamic vocabulary of visual words and density based clustering is used to continually estimate a set of visual topics, changes in which drive the place-recognition process. The system is evaluated using an indoor robot sequence, a standard outdoor robot sequence and a long-term sequence from a static camera. Experiments demonstrate qualitatively distinct themes associated with discovered places - from common place types such as `hallway', or `desk-area', to temporal concepts such as `dusk', `dawn' or `mid-day'. Compared to traditional image-based place-recognition, this reduces the information that must be stored without reducing place-recognition performance.","Vocabulary,
Visualization,
Robots,
Semantics,
Streaming media,
Image recognition,
Engines"
GMM-Based Intermediate Matching Kernel for Classification of Varying Length Patterns of Long Duration Speech Using Support Vector Machines,"Dynamic kernel (DK)-based support vector machines are used for the classification of varying length patterns. This paper explores the use of intermediate matching kernel (IMK) as a DK for classification of varying length patterns of long duration speech represented as sets of feature vectors. The main issue in construction of IMK is the choice for the set of virtual feature vectors used to select the local feature vectors for matching. This paper proposes to use components of class-independent Gaussian mixture model (CIGMM) as a representation for the set of virtual feature vectors. For every component of CIGMM, a local feature vector each from the two sets of local feature vectors that has the highest probability of belonging to that component is selected and a base kernel is computed between the selected local feature vectors. The IMK is computed as the sum of all the base kernels corresponding to different components of CIGMM. It is proposed to use the responsibility term weighted base kernels in computation of IMK to improve its discrimination ability. This paper also proposes the posterior probability weighted DKs (including the proposed IMKs) to improve their classification performance and reduce the number of support vectors. The performance of the support vector machine (SVM)-based classifiers using the proposed IMKs is studied for speech emotion recognition and speaker identification tasks and compared with that of the SVM-based classifiers using the state-of-the-art DKs.",
Load-aware modeling for uplink cellular networks in a multi-channel environment,"We exploit tools from stochastic geometry to develop a tractable analytical approach for modeling uplink cellular networks. The developed model is load aware and accounts for per-user power control as well as the limited transmit power constraint for the users' equipment (UEs). The proposed analytical paradigm is based on a simple per-user power control scheme in which each user inverts his path-loss such that the signal is received at his serving base station (BS) with a certain power threshold ρ Due to the limited transmit power of the UEs, users that cannot invert their path-loss to their serving BSs are allowed to transmit with their maximum transmit power. We show that the proposed power control scheme not only provides a balanced cell center and cell edge user performance, it also facilitates the analysis when compared to the state-of-the-art approaches in the literature. To this end, we discuss how to manipulate the design variable ρ in response to the network parameters to optimize one or more of the performance metrics such as the outage probability, the network capacity, and the energy efficiency.",
Route swarm: Wireless network optimization through mobility,"In this paper, we demonstrate a novel hybrid architecture for coordinating networked robots in sensing and information routing applications. The proposed INformation and Sensing driven PhysIcally REconfigurable robotic network (INSPIRE), consists of a Physical Control Plane (PCP) which commands agent position, and an Information Control Plane (ICP) which regulates information flow towards communication/sensing objectives. We describe an instantiation where a mobile robotic network is dynamically reconfigured to ensure high quality routes between static wireless nodes, which act as source/destination pairs for information flow. We demonstrate our propositions through simulation under a realistic wireless network regime.","Iterative closest point algorithm,
Optimization,
Robot sensing systems,
Bridges,
Mobile nodes"
A Lower Bound on the Sum Rate of Multiple Description Coding With Symmetric Distortion Constraints,"We derive a single-letter lower bound on the minimum sum rate of multiple description coding with symmetric distortion constraints. For the binary uniform source with the erasure distortion measure or Hamming distortion measure, this lower bound can be evaluated with the aid of certain minimax theorems. A similar minimax theorem is established in the quadratic Gaussian setting, which is further leveraged to analyze the special case where the minimum sum rate subject to two levels of distortion constraints (with the second level imposed on the complete set of descriptions) is attained; in particular, we determine the minimum achievable distortions at the intermediate levels.",
Remote Manipulation With a Stationary Computer-Controlled Magnetic Dipole Source,"In this paper, we examine several magnetic control methods that utilize the fully controllable dipole field generated by the single stationary dipole source. Since the magnetic field generated by a dipole source is nonuniform, it applies both forces and torques to magnetic objects and can be used to manipulate magnetic tools. Recently, the Omnimagnet, a computer-controlled magnetic dipole source capable of varying both its dipole-moment direction and magnitude, was developed to perform magnetic manipulation. The equations and methods are developed generally; therefore, they can be applied to any omnidirectional dipole source, but their effectiveness is demonstrated using the Omnimagnet.","Force,
Magnetic moments,
Torque,
Magnetic resonance imaging,
Magnetic cores,
Robots,
Vectors"
Time-Domain Characterization of Short-Pulse Networks and Antennas Using Signal Space Method,"Signal space method for time-domain characterization of short-pulse networks and antennas is presented and described. The short-duration pulses, which are usually recognized as energy signals, belong to the signal space L2 (ℜ). By means of the signal space analysis, the Euclid distance on L2 (ℜ) is related to fidelity and amplitude ratio, and thus can be used for comprehensively characterizing short-duration pulse waveform distortion and amplitude variation, resulting in an overall description of networks and antennas. Three numerical examples, microstrip transmission line, microstrip pulse power divider, and antipodal Vivaldi antenna, are given to demonstrate the usage and significance of this method for characterization of networks and antennas.","Antennas,
Ports (Computers),
Time-domain analysis,
Delays,
Distortion measurement,
Distortion,
Microstrip"
Environment-independent formation flight for micro aerial vehicles,"Some aerial tasks are achieved more efficiently and at a lower cost by a group of independently controlled micro aerial vehicles (MAVs) when compared to a single, more sophisticated robot. Controlling formation flight can be cast as a two-level problem: stabilization of relative distances of agents (formation shape control) and control of the center of gravity of the formation. To date, accurate shape control of a formation of MAVs usually relies on external tracking devices (e.g. fixed cameras) or signals (e.g. GPS) and uses centralized control, which severely limits its deployment. In this paper, we present an environment-independent approach for relative MAV formation flight, using a distributed control algorithm which relies only on embedded sensing and agentto- agent communication. In particular, an on-board monocular camera is used to acquire relative distance measurements in combination with a consensus-based distributed Kalman filter. We evaluate our methods in- and outdoors with a formation of three MAVs while controlling the formation's center of gravity manually.","Bismuth,
Vectors,
Cameras,
Gravity,
Robot sensing systems,
Kalman filters,
Global Positioning System"
Refresh Now and Then,"DRAM stores information in electric charge. Because DRAM cells lose stored charge over time due to leakage, they have to be “refreshed” in a periodic manner to retain the stored information. This refresh activity is a source of increased energy consumption as the DRAM density grows. It also incurs nontrivial performance loss due to the unavailability of memory arrays during refresh. This paper first presents a comprehensive measurement-based characterization study of the cell-level data retention behavior of modern low-power DRAM chips. About 99.7% of the cells could retain the stored information for longer than 1 s at a high temperature. This average cell retention behavior strongly indicates that we can deeply reduce the energy and performance penalty of DRAM refreshing with proper system support. The second part of this paper, accordingly, develops two practical techniques to reduce the frequency of DRAM refresh operations by excluding a few leaky memory cells from use and by skipping refreshing of unused DRAM regions. We have implemented the proposed techniques completely in the Linux OS for experimentation, and measured performance improvement of up to 17.2% with the refresh operation reduction of 93.8% on smartphone like low-power platforms.","Temperature sensors,
Hardware,
DRAM chips,
Power demand,
Semiconductor device measurement,
Temperature distribution"
Authenticating Location-Based Skyline Queries in Arbitrary Subspaces,"With the ever-increasing use of smartphones and tablet devices, location-based services (LBSs) have experienced explosive growth in the past few years. To scale up services, there has been a rising trend of outsourcing data management to Cloud service providers, which provide query services to clients on behalf of data owners. However, in this data-outsourcing model, the service provider can be untrustworthy or compromised, thereby returning incorrect or incomplete query results to clients, intentionally or not. Therefore, empowering clients to authenticate query results is imperative for outsourced databases. In this paper, we study the authentication problem for location-based arbitrary-subspace skyline queries (LASQs), which represent an important class of LBS applications. We propose a basic Merkle Skyline R-tree method and a novel Partial S4-tree method to authenticate one-shot LASQs. For the authentication of continuous LASQs, we develop a prefetching-based approach that enables clients to compute new LASQ results locally during movement, without frequently contacting the server for query re-evaluation. Experimental results demonstrate the efficiency of our proposed methods and algorithms under various system settings.","Authentication,
Indexes,
Query processing,
Servers,
Educational institutions,
Computer science"
Analysis of FSS Radomes Based on Physical Optics Method and Ray Tracing Technique,"In this letter, we analyze the electromagnetic characteristic of a frequency selective surface (FSS) radome using the physical optics (PO) method and ray tracing technique. We consider the cross-loop slot FSS and the tangent-ogive radome. Radiation pattern of the FSS radome is computed to illustrate the electromagnetic transmission characteristic.","Frequency selective surfaces,
Ray tracing,
Antenna radiation patterns,
Dielectrics,
Physical optics,
Nonhomogeneous media,
Electromagnetics"
On placement and dynamic power control of femtocells in LTE HetNets,"Femto cells a.k.a. Low Power Nodes (LPNs) are used to improve indoor data rates as well as to reduce traffic load on macro Base Stations (BSs) in LTE cellular networks. These LPNs are deployed inside office buildings and residential apartment complexes to provide high data rates to indoor Users. With high SINR (Signal-to-Interference plus Noise Ratio) the users experience good throughput, but the SINR decreases significantly because of interference and obstacles such as building walls, present in the communication path. So, efficient placement of Femtos in buildings while considering Macro-Femto interference is very crucial for attaining desirable SINR. At the same time, minimizing the power leakage in order to improve the signal strength of outdoor users in a high interference (HIZone) around the building area is important. In our work, we have considered obstacles (walls, floors) and interference between Macro and Femto BSs. To be fair to both indoor and outdoor users, we designed an efficient placement and power control SON (Self organizing Network) algorithm which optimally places Femtos and dynamically adjusts the transmission power of Femtos based on the occupancy of Macro users in the HIZone. To do this, we solve two Mixed Integer Programming (MIP) methods namely: Minimize number of Femtos (MinNF) method which guarantees threshold SINR (SINRTh) -2dB for all indoor users and optimal Femto power (OptFP) allocation method which guarantees SINRTh (- 4 dB) for indoor users with the Macro users SINR degradation as lesser than 2dB.",
Algorithms for Smartphone and Tablet Image Analysis for Healthcare Applications,"Smartphones and tablets are finding their way into healthcare delivery to the extent that mobile health (mHealth) has become an identifiable field within eHealth. In prior work, a mobile app to document chronic wounds and wound care, specifically pressure ulcers (bedsores) was developed for Android smartphones and tablets. One feature of the mobile app allowed users to take images of the wound using the smartphone or tablet's integrated camera. In a user trial with nurses at a personal care home, this feature emerged as a key benefit of the mobile app. This paper developed image analysis algorithms that facilitate noncontact measurements of irregularly shaped images (e.g., wounds), where the image is taken with a sole smartphone or tablet camera. The image analysis relies on the sensors integrated in the smartphone or tablet with no auxiliary or add-on instrumentation on the device. Three approaches to image analysis were developed and evaluated: 1) computing depth using autofocus data; 2) a custom sensor fusion of inertial sensors and feature tracking in a video stream; and 3) a custom pinch/zoom approach. The pinch/zoom approach demonstrated the strongest potential and thus developed into a fully functional prototype complete with a measurement mechanism. While image analysis is a very well developed field, this paper contributes to image analysis applications and implementation in mHealth, specifically for wound care.","Smart phones,
Image analysis,
Biomedical image processing,
Image sensors,
Electronic medical records,
Mobile communication,
Algorithm design and analysis"
Marker-Based Surgical Instrument Tracking Using Dual Kinect Sensors,"This paper presents a passive-marker-based optical tracking system utilizing dual Kinect sensors and additional custom optical tracking components. To obtain sub-millimeter tracking accuracy, we introduce robust calibration of dual infrared sensors and point correspondence establishment in a stereo configuration. The 3D localization is subsequently accomplished using multiple back projection lines. The proposed system extends existing inexpensive consumer electronic devices, implements tracking algorithms, and shows the feasibility of applying the proposed low-cost system to surgical training for computer assisted surgeries.",
Haptic Simulation of Organ Deformation and Hybrid Contacts in Dental Operations,"There are two main challenges in simulating bi-manual dental operations with six-degrees-of-freedom (6-DoF) haptic rendering. One is to simulate large deformation and force response of a tongue under multi-region contacts with a dental mirror, and the other is to simulate the force response when a dental probe inserts into a narrow periodontal pocket, which leads to simultaneous contacts of different types between the probe and both rigid and deformable objects (i.e., a rigid tooth and its surrounding deformable gingiva), which we call hybrid contacts, as well as frequent contact switches. In this paper, we address both challenges. We first introduce a novel method for modeling deformation based on a sphere-tree representation of deformable objects. A configuration-based constrained optimization method is utilized for determining the six-dimensional configuration of the graphic tool and the contact force/torque. This approach conducts collision detection, deformation computation, and tool configuration optimization very efficiently, avoids inter-penetration, and maintains stability of haptic display without using virtual coupling. To simulate the force response due to fine manipulation of the probe inside a narrow periodontal pocket, we propose an efficient method to simulate the local deformation of the gingiva and stable haptic feedback under frequent contact switches. Simulations on typical dental operations were carried out to validate the efficiency and stability of our approach.","Haptic interfaces,
Computational modeling,
Deformable models,
Force,
Graphics,
Skeleton,
Dentistry"
Dynamic Image-to-Class Warping for Occluded Face Recognition,"Face recognition (FR) systems in real-world applications need to deal with a wide range of interferences, such as occlusions and disguises in face images. Compared with other forms of interferences such as nonuniform illumination and pose changes, face with occlusions has not attracted enough attention yet. A novel approach, coined dynamic image-to-class warping (DICW), is proposed in this work to deal with this challenge in FR. The face consists of the forehead, eyes, nose, mouth, and chin in a natural order and this order does not change despite occlusions. Thus, a face image is partitioned into patches, which are then concatenated in the raster scan order to form an ordered sequence. Considering this order information, DICW computes the image-to-class distance between a query face and those of an enrolled subject by finding the optimal alignment between the query sequence and all sequences of that subject along both the time dimension and within-class dimension. Unlike most existing methods, our method is able to deal with occlusions which exist in both gallery and probe images. Extensive experiments on public face databases with various types of occlusions have confirmed the effectiveness of the proposed method.","Face recognition,
Biometrics (access control),
Image recognition,
Time warp simulation,
Facial features"
A Graph Derivation Based Approach for Measuring and Comparing Structural Semantics of Ontologies,"Ontology reuse offers great benefits by measuring and comparing ontologies. However, the state of art approaches for measuring ontologies neglects the problems of both the polymorphism of ontology representation and the addition of implicit semantic knowledge. One way to tackle these problems is to devise a mechanism for ontology measurement that is stable, the basic criteria for automatic measurement. In this paper, we present a graph derivation representation based approach (GDR) for stable semantic measurement, which captures structural semantics of ontologies and addresses those problems that cause unstable measurement of ontologies. This paper makes three original contributions. First, we introduce and define the concept of semantic measurement and the concept of stable measurement. We present the GDR based approach, a three-phase process to transform an ontology to its GDR. Second, we formally analyze important properties of GDRs based on which stable semantic measurement and comparison can be achieved successfully. Third but not the least, we compare our GDR based approach with existing graph based methods using a dozen real world exemplar ontologies. Our experimental comparison is conducted based on nine ontology measurement entities and distance metric, which stably compares the similarity of two ontologies in terms of their GDRs.","Ontologies,
Semantics,
OWL,
Unified modeling language,
Graphical models,
Transforms,
Educational institutions"
Vivaldi: A Domain-Specific Language for Volume Processing and Visualization on Distributed Heterogeneous Systems,"As the size of image data from microscopes and telescopes increases, the need for high-throughput processing and visualization of large volumetric data has become more pressing. At the same time, many-core processors and GPU accelerators are commonplace, making high-performance distributed heterogeneous computing systems affordable. However, effectively utilizing GPU clusters is difficult for novice programmers, and even experienced programmers often fail to fully leverage the computing power of new parallel architectures due to their steep learning curve and programming complexity. In this paper, we propose Vivaldi, a new domain-specific language for volume processing and visualization on distributed heterogeneous computing systems. Vivaldi's Python-like grammar and parallel processing abstractions provide flexible programming tools for non-experts to easily write high-performance parallel computing code. Vivaldi provides commonly used functions and numerical operators for customized visualization and high-throughput image processing applications. We demonstrate the performance and usability of Vivaldi on several examples ranging from volume rendering to image segmentation.","Graphics processing units,
Rendering (computer graphics),
Data visualization,
Computational modeling,
Parallel processing,
Data models,
Image classification"
Dynamic Virtual Machine migration algorithms using enhanced energy consumption model for green cloud data centers,"Cloud data centers consume an enormous amount of energy. Virtual Machine (VM) migration technology can be applied to reduce energy consumption by consolidating VMs onto the minimal number of servers and turn idle servers into power-saving modes. While most existing energy models consider mainly computing energy, an enhanced energy consumption model is formulated, which includes energy consumption for computation, for servers to switch from standby to active modes, and for communication during VM migrations. Next, two new dynamic VM migration algorithms are proposed. They apply a local regression method to predict potentially over-utilized servers, and the 0-1 knapsack dynamic programming to find the best-fit combination of VMs for migration. The time complexity of these algorithms is analyzed, which indicates that they are highly scalable. Performance is evaluated and compared with existing algorithms. The two new heuristics have significantly reduced the number of VM migration, the number of rebooted servers, and energy consumption. Furthermore, one of them has achieved the least overall SLA violations. We believe that the new energy formulation and the two new heuristics contribute significantly towards achieving green cloud computing.","Servers,
Heuristic algorithms,
Energy consumption,
Switches,
Prediction algorithms,
Power demand,
Computational modeling"
A Compound Pressure Signal Acquisition System for Multichannel Wrist Pulse Signal Analysis,"In traditional Chinese pulse diagnosis (TCPD), to analyze the health condition of a patient, a practitioner should put three fingers on the wrist of the patient to adaptively feel the fluctuations in the radial pulse at the styloid processes. Thus, for comprehensive pulse signal acquisition, we should efficiently and accurately capture pulse signals at different positions and under different pressures. However, most conventional pulse signal acquisition devices can only capture signal at one position and under a fixed pressure, and thus only capture limited pulse diagnostic information. In this paper, we propose our novel solution to the problems of sensor positioning, sensor array design, pressure adjustment, and mechanical structure design, resulting in a compound system for multichannel pulse signal acquisition. Compared with the other systems, our system provides a systematic solution to sensor positioning, is effective in measuring the width of the pulse, and can capture multichannel pulse signals together with subsignals under different hold down pressures. Experimental results show that multichannel signals can achieve higher classification performance than single-channel signals.","Wrist,
Probes,
Strain,
Bridge circuits,
Noise,
Power supplies,
Arrays"
A New Memetic Algorithm With Fitness Approximation for the Defect-Tolerant Logic Mapping in Crossbar-Based Nanoarchitectures,"The defect-tolerant logic mapping (DTLM), which has been proved to be an NP-complete combinatorial search problem, is a key step for logic implementation in emerging crossbar-based nano-architectures. However, no practically satisfactory solution has been suggested for the DTLM until now. In this paper, the problem of DTLM is first modeled as a combinatorial optimization problem through the introduction of maximum-bipartite-matching. Then, a new memetic algorithm with fitness approximation (MA/FA) is proposed to solve the optimization problem efficiently. In MA/FA, a new greedy reassignment local search operator, capable of utilizing the domain knowledge and information from problem instances, is designed to help the algorithm find optimal logic mapping with consumption of relatively lower computational resources. A fitness approximation method is adopted to reduce the time consumption of fitness evaluation dramatically. In addition, a hybrid fitness evaluation strategy that combines the exact and approximated fitness evaluation methods is presented to balance the accuracy and time efficiency of fitness evaluation. The effectiveness and efficiency of the proposed methods are testified and evaluated on a large set of benchmark instances of various scales, and the advantage of MA/FA on keeping good balance between effectiveness and efficiency is also observed.","Bipartite graph,
Approximation algorithms,
Algorithm design and analysis,
Heuristic algorithms,
Logic functions,
Approximation methods,
Search problems"
Feedforward Compensation by Specified Step Settling With Frequency Shaping of Position Reference,"This paper presents a frequency shaping of position reference in a framework of deadbeat feedforward compensation with specified step settling. In the proposed compensation, a control design freedom is additionally expanded to the frequency shaping in the original position reference, while the feedforward compensation ensures the specified step settling performance under the conventional control scheme. As a result, a two-degree-of-freedom positioning controller using the proposed approach can improve the settling performance with residual vibration suppression rather than the conventional approach. The effectiveness of the proposed shaping has been verified by experiments using a prototype of linear-motor-driven table system.","vibration control,
compensation,
control system synthesis,
feedforward,
linear motors,
position control"
Compression-based arabic text classification,"Text classification (TC) is one of the fundamental problems in text mining. Plenty of works exist on TC with interesting approaches and excellent results; however, most of these works follow a word-based approach for feature extraction. In this work, we are interested in an alternative (byte-based or character-based) approach known as compression-based TC (CTC). CTC has been used for some languages such as English and Portuguese and it is shown to have certain advantages/ disadvantages compared with word-based approaches. This work applies CTC on the Arabic language with the purpose of investigating whether these advantages/disadvantages exists for the Arabic language as well. The results are encouraging as they show the viability of using CTC for Arabic TC.",
Improving System Reliability Against Rational Attacks Under Given Resources,"System reliability has always been a challenging issue for many systems. In order to achieve high reliability, redundancy and voting schemes are often used to tolerate unintentional component failures. For unintentional failures caused by, for instance, normal wear-outs, hardware failures, or software bugs, etc., adding more redundancies often improves a system's reliability. However, when attack-caused failures exist, the number of redundant components and the number of participating voting entities may not be positively proportional to system reliability. In this paper, we study system reliability and system defense strategies when the system is under rational attacks. In particular, we analyze how defense and attack strategies may impact system reliability when both the defender and attacker are given a fixed amount of resources that can only be used for adding camouflaging components or enhancing existing components' cyber protection by defenders, or selecting a subset of components to attack by attackers, respectively. We also present an algorithm to decide the optimal defense strategy in fighting against rational attacks.","Redundancy,
Resource management,
Games,
Software reliability,
Cybernetics,
Hardware"
Distributed stochastic optimization and learning,"We consider the problem of distributed stochastic optimization, where each of several machines has access to samples from the same source distribution, and the goal is to jointly optimize the expected objective w.r.t. the source distribution, minimizing: (1) overall runtime; (2) communication costs; (3) number of samples used. We study this problem systematically, highlighting fundamental limitations, and differences versus distributed consensus problems where each machine has a different, independent, objective. We show how the best known guarantees are obtained by an accelerated mini-batched SGD approach, and contrast the runtime and sample costs of the approach with those of other distributed optimization algorithms.","Complexity theory,
Runtime,
Optimization,
Stochastic processes,
Approximation methods,
Vectors,
Presses"
Evaluation of Enhanced Low Dose Rate Sensitivity in Fourth-Generation SiGe HBTs,"The total ionizing dose response of 4th-generation SiGe HBTs is assessed at both low and high dose rates to evaluate enhanced low dose rate sensitivity (ELDRS) in a new SiGe BiCMOS technology. Both device and circuit results are presented. A bandgap reference circuit topology is chosen to monitor for ELDRS in TID-induced collector current shifts, which have previously been reported in low dose rate studies of SiGe HBTs. The results in this paper also cover previous technology generations from this foundry in order to incorporate a broader view of dose rate effects in SiGe HBTs. No indication of ELDRS was found in any technology generation.",
A Novel Crowding Genetic Algorithm and Its Applications to Manufacturing Robots,"A niche genetic algorithm (GA) based on a novel twin-space crowding (TC) approach is proposed for solving multimodal manufacturing optimization problems. The proposed TC method is designed in a parameter-free paradigm. That is, when cooperatively exploring solutions with GAs, it does not require prior knowledge related to the solution space to design additional problem-dependent parameters in the evolutionary process. This feature makes the proposed TC method suitable for assisting GAs in solving real-world engineering optimization problems involving intractable solution landscapes. A set of numerical benchmark functions is used to compare effectiveness and efficiency in the proposed TCGA, in different niche GAs, and in several evolutionary computation methods. The TCGA is then used to solve multimodal joint-space inverse problems in serial-link robots to compare its convergence performance with that of conventional methods that apply the sharing function. Finally, the TCGA is used to solve iterative collision-free design problems for linkage-bar robotic hands to demonstrate its effectiveness for generating diverse solutions during the design process.",
Single-Event Transient and Total Dose Response of Precision Voltage Reference Circuits Designed in a 90-nm SiGe BiCMOS Technology,"This paper presents an investigation of the impact of single-event transients (SETs) and total ionization dose (TID) on precision voltage reference circuits designed in a fourth-generation, 90-nm SiGe BiCMOS technology. A first-order uncompensated bandgap reference (BGR) circuit is used to benchmark the SET and TID responses of these voltage reference circuits (VRCs). Based on the first-order BGR radiation response, new circuit-level radiation-hardening-by-design (RHBD) techniques are proposed. An RHBD technique using inverse-mode (IM) transistors is demonstrated in a BGR circuit. In addition, a PIN diode VRC is presented as a potential SET and TID tolerant, circuit-level RHBD alternative.","Silicon germanium,
Transient response,
PIN photodiodes,
Heterojunction bipolar transistors,
Temperature measurement,
Radiation hardening (electronics),
BiCMOS integrated circuits,
Single event transients,
Radiation effects"
Optimal Detection Ordering for Coded V-BLAST,"Optimum ordering strategies for the coded Vertical Bell Labs Layered Space-Time (V-BLAST) architecture with capacity achieving temporal codes on each stream are analytically studied, including 4 different power/rate allocation strategies among data streams. Compact closed-form solutions are obtained for the case of zero-forcing (ZF) V-BLAST with two transmit antennas and necessary optimality conditions are found for the general case. The optimal rate allocation is shown to have a major impact (stronger streams are detected last) while the optimal power allocation does not alter the original Foschini ordering (stronger streams are detected first). Sufficient conditions for the optimality of the greedy ordering are established: it is optimal for the ZF V-BLAST under an optimal rate allocation with two transmit antennas at any SNR and with any number of antennas in the low and high SNR regimes. It satisfies the necessary optimality conditions for larger systems at any SNR and is nearly-optimal in many cases. An SNR gain of ordering is introduced and studied, including closed-form expressions as well as lower and upper bounds and the conditions for their achievability. For the minimum mean square error (MMSE) V-BLAST under an optimal rate allocation, any ordering is shown to deliver the same system capacity. All the results also apply to a multiple-access channel with the successive interference cancelation receiver.","Resource management,
Signal to noise ratio,
Antennas,
Interference cancellation,
Vectors,
MIMO"
An authentication and access control framework for CoAP-based Internet of Things,"Internet of Things (IoT) and Cyber-physical Systems (CPS) are two very hot research topics today, and more and more products are starting to appear on the market. Research has shown that the use of Service Oriented Architecture (SOA) can enable distributed application and devices to device communication, even on very resource constrained devices, and thus play an important role for IoT and CPS. In order to realize the vision of Internet of Things, communication between devices must be secured. Security mechanisms for resource constrained devices has attracted much interest from the academic community, where research groups have shown solutions like IPsec, VPN-tunnels, (D)TLS, etc. are feasible to use on this type of networks. However, even though the use of well-known security mechanisms are vital for SOA-based IoT/CPS networks and systems to be protected, they do not provide any fine-grain access control. In this paper, a CoAP-based framework for service-level access control on low-power devices is presented. The framework allows fine grain access control on a per service and method basis. For example, by using this approach a device can allow read/write access to its services to one group of users while only allowing read access to another group. Users without the right credentials are not even allowed to discover available services. To demonstrate the validity of the proposed approach, several implementations are presented together with test results. The aim is to provide a holistic framework for secure SOA-based low power networks comprise by resource constrain devices.","Protocols,
Authentication,
Access control,
Servers,
IP networks,
Service-oriented architecture"
The Reduction of Interval Type-2 LR Fuzzy Sets,"Type reduction of interval type-2 (IT2) fuzzy sets is essential in conducting the type-2 fuzzy sets expressed with the resolution forms of IT2 fuzzy sets. Several type reduction methods, such as KM, EKM, and centroid flow, have been proposed. These methods are relatively easy to implement but still computation-intensive because they need to invoke an iterative switching point finding procedure. This study derives a theorem and proposes a heuristic algorithm, which can fast and accurately identify the minimum and maximum switching points of a piecewise smooth IT2 fuzzy set. It also demonstrates that it is easy to derive the close-form expressions of the switching points of a piecewise smooth IT2 fuzzy set if both of its upper and lower membership functions can be parameterized as LR fuzzy sets, which are defined in this paper. Then, the type reduction of piecewise smooth IT2 fuzzy sets can be simplified to solve the close-form expressions of their switching points in terms of LR parameters. Experiments on IT2 fuzzy sets with various piecewise smooth membership functions, including linear, Gaussian, and hybrid-shaped ones were made. The results showed that the proposed type reduction method can obtain solutions which accurately approximate to the desired switching points with much lower computational overhead than the Karnik-Mondel (KM) and enhanced KM (EKM) methods.","Switches,
Fuzzy sets,
Approximation methods,
Iterative methods,
Equations,
Fuzzy systems,
Sorting"
Identifying base competencies as prerequisites for software engineering education,"Over the recent years, we experienced that a significant percentage of first-year students shows difficulties in acquiring even introductory software development knowledge, as well as in coping with the study process itself. In most cases, the core problem is not a lack of general intellectual capacity, but rather significant deficiencies in certain base competencies (i.e. self-, practical and cognitive as well as social competencies). We imply that these base competencies are crucial for successfully studying computer science or related topics. In order to identify these base competencies, we collected a superset of competencies from literature, structured this set, and performed filtering and clustering steps, resulting in almost 100 remaining base competencies that are relevant in our teaching context. As it is impossible for any lecturer to develop all these competencies in a single effort, we finally boiled this set down to a selection of those competencies that we deem to be most relevant for successfully studying software related topics at university level. Towards this end, for each competence, we defined what we the lecturers expect from our incoming freshmen students. In addition, we specified the skill level expected by the job market. Furthermore, we assessed the skill level of those 70% of our students that have obvious difficulties in coping with study requirements. Finally, we selected those competencies with a large difference between what is expected from our graduates and what we find in our incoming cohort. This analysis resulted in a selection of 27 competencies that we deem to be highly essential prerequisites for software engineering education, and which are not sufficiently well developed in the vast majority of freshmen students. For each of these base competencies we provide definitions and denote reasons for their selection.",
Comparison of Virtual Reality Based Therapy With Customized Vestibular Physical Therapy for the Treatment of Vestibular Disorders,"We examined outcomes in persons with vestibular disorders after receiving virtual reality based therapy (VRBT) or customized vestibular physical therapy (PT) as an intervention for habituation of dizziness symptoms. Twenty subjects with vestibular disorders received VRBT and 18 received PT. During the VRBT intervention, subjects walked on a treadmill within an immersive virtual grocery store environment, for six sessions approximately one week apart. The PT intervention consisted of gaze stabilization, standing balance and walking exercises individually tailored to each subject. Before, one week after, and at six months after the intervention, subjects completed self-report and balance performance measures. Before and after each VRBT session, subjects also reported symptoms of nausea, headache, dizziness, and visual blurring. In both groups, significant improvements were noted on the majority of self-report and performance measures one week after the intervention. Subjects maintained improvements on self report and performance measures at six months follow up. There were not between group differences. Nausea, headache, dizziness and visual blurring increased significantly during the VRBT sessions, but overall symptoms were reduced at the end of the six-week intervention. While this study did not find a difference in outcomes between PT and VRBT, the mechanism by which subjects with chronic dizziness demonstrated improvement in dizziness and balance function may be different.","Medical treatment,
Visualization,
Educational institutions,
Virtual reality,
Legged locomotion,
Abstracts,
Indexes"
Link Quality Aware Code Dissemination in Wireless Sensor Networks,"Wireless reprogramming is a crucial technique for software deployment in wireless sensor networks (WSNs). Code dissemination is a basic building block to enable wireless reprogramming. We present ECD, an Efficient Code Dissemination protocol leveraging 1-hop link quality information based on the TinyOS platform. Compared to prior works, ECD has three salient features. First, it supports dynamically configurable packet sizes. By increasing the packet size for high PHY rate radios, it significantly improves the transmission efficiency. Second, it employs an accurate sender selection algorithm to mitigate transmission collisions and transmissions over poor links. Third, it employs a simple impact-based backoff timer design to shorten the time spent in coordinating multiple eligible senders so that the largest impact sender is most likely to transmit. We implement ECD based on TinyOS and evaluate its performance extensively via testbed experiments and simulations. Results show that ECD outperforms state-of-the-art protocols, Deluge and MNP, in terms of completion time and data traffic (e.g., about 20 percent less traffic and 20-30 percent shorter completion time compared to Deluge).","Protocols,
Receivers,
Estimation,
Wireless sensor networks,
Reliability,
Educational institutions,
Software"
Biomedical image denoising using variational mode decomposition,"This paper compares three biomedical image denoising techniques based on the recently introduced variational mode decomposition (VMD), the empirical mode decomposition (EMD), and the well-known discrete wavelet transform (DWT). The work focuses on using the VMD lowest mode or the EMD residue for denoising images corrupted with Gaussian noise, as opposed to DWT decomposition with thresholding. The comparison is made on a data set composed of a brain magnetic resonance image (MRI), a prostate tissue image, and a retina digital image. Based on peak-signal-to-noise ratio (PSNR), the results show that the VMD and EMD approaches outperform the conventional DWT-based thresholding approach, and that the VMD performed best overall. It is concluded that biomedical image denoising based on the VMD lowest mode or the EMD residue is a promising approach in comparison to DWT thresholding.","Discrete wavelet transforms,
Noise reduction,
Image denoising,
Gaussian noise,
PSNR,
Biomedical imaging"
Combining Global and Local Trust for Service Recommendation,"Recommending trusted services to users is of paramount value in service-oriented environments. Reputation has been widely used to measure the trustworthiness of services, and various reputation models for service recommendation have been proposed. Reputation is basically a global trust score obtained by aggregating trust from a community of users, which could be conflicting with an individual's personal opinion on the service. Evaluating a service's trustworthiness locally based on the evaluating user's own or his/her friends' experiences is sometimes more accurate. However, local trust assessment may fail to work when no trust path from an evaluating user to a target service exists. This paper proposes a hybrid trust-aware service recommendation method for service-oriented environment with social networks via combining global trust and local trust evaluation. A global trust metric and a local trust metric are firstly presented, and then a strategy for combining them to predict the final trust of service is proposed. To evaluate the proposed method's performance, we conducted several simulations based on a synthesized dataset. The simulation results show that our proposed method outperforms the other methods in service recommendation.","Measurement,
Social network services,
Educational institutions,
Computer science,
Communities,
Reliability,
Vectors"
Extending MapReduce across Clouds with BStream,"Today, batch processing frameworks like Hadoop MapReduce are difficult to scale to multiple clouds due to latencies involved in inter-cloud data transfer and synchronization overheads during shuffle-phase. This inhibits the MapReduce framework from guaranteeing performance at variable load surges without over-provisioning in the internal cloud (IC). We propose BStream, a cloud bursting framework for MapReduce that couples stream-processing in the external cloud (EC) with Hadoop in the internal cloud (IC). Stream processing in EC enables pipelined uploading, processing and downloading of data to minimize network latencies. We use this framework to meet job deadlines. BStream uses an analytical model to minimize the usage of EC. We propose different checkpointing strategies that overlap output transfer with input transfer/processing and simultaneously reduce the computation involved in merging the results from EC and IC. Checkpointing further reduces job completion time. We experimentally compare BStream with other related works and illustrate performance benefits due to stream processing and checkpointing strategies in EC. Lastly, we characterize the operational regime of BStream.",
Categorizing Extent of Tumor Cell Death Response to Cancer Therapy Using Quantitative Ultrasound Spectroscopy and Maximum Mean Discrepancy,"Quantitative ultrasound (QUS) spectroscopic techniques in conjunction with maximum mean discrepancy (MMD) have been proposed to detect, and to classify noninvasively the levels of cell death in response to cancer therapy administration in tumor models. Evaluation of xenograft tumor responses to cancer treatments were carried out using conventional-frequency ultrasound at different times after chemotherapy exposure. Ultrasound data were analyzed using spectroscopic techniques and multi-parametric QUS spectral maps were generated. MMD was applied as a distance criterion, measuring alterations in each tumor in response to chemotherapy, and the extent of cell death was classified into less/more than 20% and 40% categories. Statistically significant differences were observed between “pre-” and “post-treatment” groups at different times after chemotherapy exposure, suggesting a high capability of proposed framework for detecting tumor response noninvasively. Promising results were also obtained for categorizing the extent of cell death response in each tumor using the proposed framework, with gold standard histological quantification of cell death as ground truth. The best classification results were obtained using MMD when applied on histograms of QUS parametric maps. In this case, classification accuracies of 84.7% and 88.2% were achieved for categorizing extent of tumor cell death into less/more than 20% and 40%, respectively.","Tumors,
Ultrasonic imaging,
Cancer,
Biomedical imaging,
Chemotherapy"
Accuracy-Constrained Privacy-Preserving Access Control Mechanism for Relational Data,"Access control mechanisms protect sensitive information from unauthorized users. However, when sensitive information is shared and a Privacy Protection Mechanism (PPM) is not in place, an authorized user can still compromise the privacy of a person leading to identity disclosure. A PPM can use suppression and generalization of relational data to anonymize and satisfy privacy requirements, e.g., k-anonymity and l-diversity, against identity and attribute disclosure. However, privacy is achieved at the cost of precision of authorized information. In this paper, we propose an accuracy-constrained privacy-preserving access control framework. The access control policies define selection predicates available to roles while the privacy requirement is to satisfy the k-anonymity or l-diversity. An additional constraint that needs to be satisfied by the PPM is the imprecision bound for each selection predicate. The techniques for workload-aware anonymization for selection predicates have been discussed in the literature. However, to the best of our knowledge, the problem of satisfying the accuracy constraints for multiple roles has not been studied before. In our formulation of the aforementioned problem, we propose heuristics for anonymization algorithms and show empirically that the proposed approach satisfies imprecision bounds for more permissions and has lower total imprecision than the current state of the art.",
Mechanism Design for Crowdsourcing: An Optimal 1-1/e Competitive Budget-Feasible Mechanism for Large Markets,"In this paper we consider a mechanism design problem in the context of large-scale crowdsourcing markets such as Amazon's Mechanical Turk mturk, ClickWorker clickworker, CrowdFlower crowdflower. In these markets, there is a requester who wants to hire workers to accomplish some tasks. Each worker is assumed to give some utility to the requester on getting hired. Moreover each worker has a minimum cost that he wants to get paid for getting hired. This minimum cost is assumed to be private information of the workers. The question then is -- if the requester has a limited budget, how to design a direct revelation mechanism that picks the right set of workers to hire in order to maximize the requester's utility? We note that although the previous work (Singer (2010) chen et al. (2011)) has studied this problem, a crucial difference in which we deviate from earlier work is the notion of large-scale markets that we introduce in our model. Without the large market assumption, it is known that no mechanism can achieve a competitive ratio better than 0.414 and 0.5 for deterministic and randomized mechanisms respectively (while the best known deterministic and randomized mechanisms achieve an approximation ratio of 0.292 and 0.33 respectively). In this paper, we design a budget-feasible mechanism for large markets that achieves a competitive ratio of 1 - 1/e ≃ 0.63. Our mechanism can be seen as a generalization of an alternate way to look at the proportional share mechanism, which is used in all the previous works so far on this problem. Interestingly, we can also show that our mechanism is optimal by showing that no truthful mechanism can achieve a factor better than 1 - 1/e, thus, fully resolving this setting. Finally we consider the more general case of submodular utility functions and give new and improved mechanisms for the case when the market is large.","Approximation methods,
Resource management,
Crowdsourcing,
Additives,
Standards,
Pricing,
Polynomials"
On Quantizer Design for Distributed Bayesian Estimation in Sensor Networks,"We consider the problem of distributed estimation under the Bayesian criterion and explore the design of optimal quantizers in such a system. We show that, for a conditionally unbiased and efficient estimator at the fusion center and when local observations have identical distributions, it is optimal to partition the local sensors into groups, with all sensors within a group using the same quantization rule. When all the sensors use identical number of decision regions, use of identical quantizers at the sensors is optimal. When the network is constrained by the capacity of the wireless multiple access channel over which the sensors transmit their quantized observations, we show that binary quantizers at the local sensors are optimal under certain conditions. Based on these observations, we address the location parameter estimation problem and present our optimal quantizer design approach. We also derive the performance limit for distributed location parameter estimation under the Bayesian criterion and find the conditions when the widely used threshold quantizer achieves this limit. We corroborate this result using simulations. We then relax the assumption of conditionally independent observations and derive the optimality conditions of quantizers for conditionally dependent observations. Using counter-examples, we also show that the previous results do not hold in this setting of dependent observations and, therefore, identical quantizers are not optimal.","Estimation,
Bayes methods,
Cost function,
Parameter estimation,
Random variables,
Silicon,
Distributed databases"
AGC Signal Modeling for Energy Storage Operations,"Energy storage resources (ESRs) are being used for secondary frequency regulation in the bulk electric power grid. In order to optimize the economic scheduling of an ESR using look-ahead model predictive control, predictive models of the automatic generation control (AGC) signal and its effect on an ESR's state of charge are needed. In this letter, we suggest a straightforward and effective procedure for forecasting the next state of charge for an ESR that provides regulation service in a liberalized market setting.","Automatic generation control,
Mathematical model,
System-on-chip,
Autoregressive processes,
Predictive models,
Forecasting,
Frequency control"
Human Movement Analysis as a Measure for Fatigue: A Hidden Markov-Based Approach,"Fatigue influences the way a training exercise is performed and alters the kinematics of the movement. Monitoring the increase of fatigue during rehabilitation and sport exercises is beneficial to avoid the risk of injuries. This study investigates the use of a parametric hidden Markov model (PHMM) to estimate fatigue from observing kinematic changes in the way the exercise is performed. The PHMM is compared to linear regression. A top-level hidden Markov model with variable state transitions incorporates knowledge about the progress of fatigue during the exercise and the initial condition of a subject. The approach is tested on a squat database recorded with optical motion capture. The estimates of fatigue for a single squat, a set of squats, and an entire exercise correlate highly with subjective ratings.","Fatigue,
Hidden Markov models,
Joints,
Muscles,
Training,
Kinematics,
Linear regression"
Training Quality-Aware Filters for No-Reference Image Quality Assessment,"With the rapid increase of digital imaging and communication technology usage, there's now great demand for fast and practical image quality assessment (IQA) algorithms that can predict an image's quality as consistently as humans. The authors propose a general-purpose, no-reference image quality assessment (NR-IQA) with the goal of developing a model that does not require prior knowledge about nondistorted reference images and the types of distortions. The key is to obtain effective image representations using learning quality-aware filters (QAFs). Unlike other regression models, they also use a random forest to train the mapping from the feature space. Extensive experiments conducted on the LIVE and CSIQ datasets demonstrate that the proposed NR-IQA metric QAF can achieve better prediction performance than the other state-of-the-art approaches in terms of both prediction accuracy and generalization capability.","Feature extraction,
Image quality,
Training,
Research and development,
Filtering,
Image coding,
Predictive models,
Digital imaging"
On the Use of Side Information for Mining Text Data,"In many text mining applications, side-information is available along with the text documents. Such side-information may be of different kinds, such as document provenance information, the links in the document, user-access behavior from web logs, or other non-textual attributes which are embedded into the text document. Such attributes may contain a tremendous amount of information for clustering purposes. However, the relative importance of this side-information may be difficult to estimate, especially when some of the information is noisy. In such cases, it can be risky to incorporate side-information into the mining process, because it can either improve the quality of the representation for the mining process, or can add noise to the process. Therefore, we need a principled way to perform the mining process, so as to maximize the advantages from using this side information. In this paper, we design an algorithm which combines classical partitioning algorithms with probabilistic models in order to create an effective clustering approach. We then show how to extend the approach to the classification problem. We present experimental results on a number of real data sets in order to illustrate the advantages of using such an approach.","Clustering algorithms,
Database systems,
Partitioning algorithms,
Noise measurement,
Probabilistic logic,
Coherence,
Approximation methods"
The use of dielectric coatings in capacitive power transfer systems,"Capacitive power transfer (CPT) is emerging as a competitive alternative to inductive power transfer (IPT) for non-contact applications over short distances. One distinct advantage CPT has is that the electric field is mostly contained between the coupling plates. These plates are in or near contact with each other but are galvanically isolated by an insulating coating. This paper discusses the function dielectric coating have in CPT and gives insight to their design. Ceramic coatings are presented as a viable option given their durability, high permittivity, dielectric strength and ease of application. Specifically, titanium dioxide is identified as a ceramic coating ideally suited for CPT applications. Titanium dioxide is coated on both aluminum and stainless steel substrates via relatively new sol-gel process. This process is documented step by step with the thickness and chemical composition of the coating verified by scanning electron microscope. The effective permittivity and dielectric breakdown strength of the titanium dioxide coatings are measured.","Coatings,
Surface treatment,
Permittivity,
Couplings,
Substrates,
Aluminum,
Capacitance"
Continuous user identification via touch and movement behavioral biometrics,"With the increased popularity of smartphones, various security threats and privacy leakages targeting them are discovered and investigated. In this work, we present SilentSense, a framework to authenticate users silently and transparently by exploiting dynamics mined from the user touch behavior biometrics and the micro-movement of the device caused by user's screen-touch actions. We build a “touch-based biometrics” model of the owner by extracting some principle features, and then verify whether the current user is the owner or guest/attacker. When using the smartphone, some unique operating dynamics of the user is detected and learnt by collecting the sensor data and touch events silently. When users are mobile, the micro-movement of mobile devices caused by touch is suppressed by that due to the large scale user-movement which will render the touch-based biometrics ineffective. To address this, we integrate a movement-based biometrics for each user with previous touch-based biometrics. We conduct extensive evaluations of our approaches on the Android smartphone, we show that the user identification accuracy is over 99%.",
A ground-based optical system for autonomous landing of a fixed wing UAV,"This paper presents a new ground-based visual approach for guidance and safe landing of an unmanned aerial vehicle (UAV) in Global Navigation Satellite System(GNSS)-denied environments. In our previous work, the old system consists of one pan-tilt unit(PTU) with two cameras, whose detection range is limited by the baseline. To achieve long-range detection and cover wide field of regard, we mounted two separate sets of PTU integrated with visible light camera on both sides of the runway instead of our previous assembled stereo vision system. Then, the well-known AdaBoost method was evaluated with regard to detecting and tracking the target. To achieve the relative position between the UAV and landing area, we used triangulation to calculate the 3D coordinates of the UAV. By combining the estimated position in the closed loop control, we obtain the autonomous landing strategy. Finally, we present several real flights in outdoor environments, and compare its accuracy with ground truth provided by GNSS. The results support the validity and accuracy of the presented system.","Cameras,
Global Positioning System,
Adaptive optics,
Optical imaging,
Aircraft,
Atmospheric modeling,
Visualization"
Noninvasive Transmural Electrophysiological Imaging Based on Minimization of Total-Variation Functional,"While tomographic imaging of cardiac structure and kinetics has improved substantially, electrophysiological mapping of the heart is still restricted to the surface with little or no depth information beneath. The progress in reconstructing 3-D action potential from surface voltage data has been hindered by the intrinsic ill-posedness of the problem and the lack of a unique solution in the absence of prior assumptions. In this work, we propose a novel adaption of the total-variation (TV) prior to exploit the unique spatial property of transmural action potential of being piecewise smooth with a steep boundary (gradient) separating depolarized and repolarized regions. We present a variational TV-prior instead of a common discrete TV-prior for improved robustness to mesh resolution, and solve the TV-minimization by a sequence of weighted, first-order L2-norm minimization. In a large set of phantom experiments, the proposed method is shown to outperform existing quadratic methods in preserving the steep gradient of action potential along the border of infarcts, as well as in capturing the disruption to the normal path of electrical wavefronts. Real-data experiments also further demonstrate the potential of the proposed method in revealing the location and shape of infarcts when quadratic methods fail to do so.",
Optical strain based recognition of subtle emotions,"This paper presents a novel method to recognize subtle emotions based on optical strain magnitude feature extraction from the temporal point of view. The common way that subtle emotions are exhibited by a person is in the form of visually observed micro-expressions, which usually occur only over a brief period of time. Optical strain allows small deformations on the face to be computed between successive frames although these subtle changes can be minute. We perform temporal sum pooling for each frame in the video to a single strain map to summarize the features over time. To reduce the dimensionality of the input space, the strain maps are then resized to a pre-defined resolution for consistency across the database. Experiments were conducted on the SMIC (Spontaneous Micro-expression) Database, which was recently established in 2013. A best three-class recognition accuracy of 53.56% is achieved, with the proposed method outperforming the baseline reported in the original work by almost 5%. This is the first known optical strain based classification of micro-expressions. The closest related work employed optical strain to spot micro-expressions, but did not investigate its potential for determining the specific type of micro-expression.","Strain,
Optical imaging,
Databases,
Feature extraction,
Face,
Noise,
Kernel"
Probabilistic Diffusion of Social Influence with Incentives,"With explosive growth of social media, social computing becomes a new IT feature. A core functionality of social computing is social network analysis, which studies dynamics of social connectivity among people, including how people influence one another and how fast information diffuses in a social network and what factors stimulate influence diffusion. One of the models for information diffusion is the heat diffusion model. Although it is simple in capturing the basic principle of social influence, there are several limitations. First, the uniform heat diffusion is no longer hold in social networks. Second, high degree nodes are not always most influential in all contexts. We propose a probabilistic approach of social influence diffusion model with incentives. Our approach has three features. First we define an influence diffusion probability for each node instead of uniform probability. Second, we categorize nodes into two classes: active and inactive. Active nodes have chances to influence inactive nodes but not vice versa. Third, we utilize a system defined diffusion threshold to control how influence is propagated. We study how incentives can be utilized to boost the influence diffusion.","Heating,
Social network services,
Computational modeling,
Probabilistic logic,
Technological innovation,
Stochastic processes,
Heat transfer"
A Minimax Framework for Classification with Applications to Images and High Dimensional Data,"This paper introduces a minimax framework for multiclass classification, which is applicable to general data including, in particular, imagery and other types of high-dimensional data. The framework consists of estimating a representation model that minimizes the fitting errors under a class of distortions of interest to an application, and deriving subsequently categorical information based on the estimated model. A variety of commonly used regression models, including lasso, elastic net and ridge regression, can be regarded as special cases that correspond to specific classes of distortions. Optimal decision rules are derived for this classification framework. By using kernel techniques the framework can account for nonlinearity in the input space. To demonstrate the power of the framework we consider a class of signal-dependent distortions and build a new family of classifiers as new special cases. This family of new methods-minimax classification with generalized multiplicative distortions-often outperforms the state-of-the-art classification methods such as the support vector machine in accuracy. Extensive experimental results on images, gene expressions and other types of data verify the effectiveness of the proposed framework.","Nonlinear distortion,
Manifolds,
Face recognition,
Support vector machines,
Uncertainty,
Training,
Kernel"
Novel Optimal and Scalable Nonfunctional Service Matchmaking Techniques,"Service-orientation paves the way for the Internet of Services (IoS), where millions of services will be available to realize the everyday user applications or tasks. Consequently, as a great number of functionally equivalent services will be available for a specific user task, the service nonfunctional aspect should be considered for filtering and selecting among these services. The state-of-the-art approaches in nonfunctional service discovery exploit constraint solving techniques to optimize the matchmaking time between a service offer and demand pair. However, they do not scale well, as matchmaking time is proportional to the offer number, so they are not yet suitable for the IoS. To this end, this article proposes three novel alternative techniques that intelligently organize the service offer space to improve the overall matchmaking time. These techniques are theoretically and experimentally evaluated. The results show that all techniques optimize the matchmaking time without sacrificing accuracy and that each technique is better in different circumstances.","Service-oriented architecture,
Semantics,
Programming,
Transforms"
Transmit Designs for the MIMO Broadcast Channel With Statistical CSI,"We investigate the multiple-input multiple-output broadcast channel with statistical channel state information available at the transmitter. The so-called linear assignment operation is employed, and necessary conditions are derived for the optimal transmit design under general fading conditions. Based on this, we introduce an iterative algorithm to maximize the linear assignment weighted sum-rate by applying a gradient descent method. To reduce complexity, we derive an upper bound of the linear assignment achievable rate of each receiver, from which a simplified closed-form expression for a near-optimal linear assignment matrix is derived. This reveals an interesting construction analogous to that of dirty-paper coding. In light of this, a low-complexity transmission scheme is provided. Numerical examples illustrate the significant performance of the proposed low complexity scheme.","Receivers,
MIMO,
Fading,
Transmitters,
Complexity theory,
Upper bound,
Educational institutions"
A Dynamic Secure Group Sharing Framework in Public Cloud Computing,"With the popularity of group data sharing in public cloud computing, the privacy and security of group sharing data have become two major issues. The cloud provider cannot be treated as a trusted third party because of its semi-trust nature, and thus the traditional security models cannot be straightforwardly generalized into cloud based group sharing frameworks. In this paper, we propose a novel secure group sharing framework for public cloud, which can effectively take advantage of the cloud servers' help but have no sensitive data being exposed to attackers and the cloud provider. The framework combines proxy signature, enhanced TGDH and proxy re-encryption together into a protocol. By applying the proxy signature technique, the group leader can effectively grant the privilege of group management to one or more chosen group members. The enhanced TGDH scheme enables the group to negotiate and update the group key pairs with the help of cloud servers, which does not require all of the group members been online all the time. By adopting proxy re-encryption, most computationally intensive operations can be delegated to cloud servers without disclosing any private information. Extensive security and performance analysis shows that our proposed scheme is highly efficient and satisfies the security requirements for public cloud based secure group sharing.",
Enhancing Memory Recall via an Intelligent Social Contact Management System,"Human memory often fails. People are frequently beset with questions like “Who is that person? I think I met him in Tokyo last year.” Existing memory aid tools cannot well support the recall of names effectively. This paper explores the memory recall enhancement issue from the perspective of memory cue extraction and associative search, and proposes a generic methodology to extract memory cues from heterogeneous, multimodal, physical/virtual data sources. Specifically, we use the contact name recall in the academic community as the target application to showcase our proposed methodology. We further develop an intelligent social contact manager that supports 1) autocollection of rich contact data from a combination of pervasive sensors and Web data sources, and 2) associative search of contacts when human memory fails. The system is validated by testing the performance of contact data collection techniques. An empirical user study on contact memory recall is also conducted, through which several findings about contact memorizing and recall are presented. Classic cognitive psychology theories are used to interpret these findings.","Sensors,
Memory management,
Data mining,
Communities,
Context,
Business,
Feature extraction"
WaP: Indoor localization and tracking using WiFi-Assisted Particle filter,"High accurate indoor localization and tracking of smart phones is critical to pervasive applications. Most radio-based solutions either exploit some error prone power-distance models or require some labor-intensive process of site survey to construct RSS fingerprint database. This study offers a new perspective to exploit RSS readings by their contrast relationship rather than absolute values, leading to three observations and functions called turn verifying, room distinguishing and entrance discovering. On this basis, we design WaP (WiFi-Assisted Particle filter), an indoor localization and tracking system exploiting particle filters to combine dead reckoning, RSS-based analyzing and knowledge of floor plan together. All the prerequisites of WaP are the floor plan and the coarse locations on which room the APs reside. WaP prototype is realized on off-the-shelf smartphones with limited particle number typically 400, and validated in a college building covering 1362m2. Experiment results show that WaP can achieve average localization error of 0.71m for 100 trajectories by 8 pedestrians.","Wireless application protocol,
Vectors,
Smart phones,
IEEE 802.11 Standards,
Trajectory,
Databases,
Dead reckoning"
The relations between the senior upper general exponent and the upper Bohl exponents,"The Bohl exponents, similarly to the Lyapunov exponents, are among the most important numerical characteristics of dynamical systems used in control theory. Properties of the Lyapunov characteristics are well described in the literature. Properties of the Bohl exponents are investigated much less. In this paper we consider the so-called senior upper general exponent of a discrete linear time-varying system and present some alternative formulas for it. Moreover, we discuss relations between upper Bohl exponents of the perturbed system and the senior upper general exponent of the unperturbed system.","Linear systems,
Asymptotic stability,
Differential equations,
Time-varying systems,
Stability criteria,
Numerical stability"
Photometric Stereo Using Sparse Bayesian Regression for General Diffuse Surfaces,"Most conventional algorithms for non-Lambertian photometric stereo can be partitioned into two categories. The first category is built upon stable outlier rejection techniques while assuming a dense Lambertian structure for the inliers, and thus performance degrades when general diffuse regions are present. The second utilizes complex reflectance representations and non-linear optimization over pixels to handle non-Lambertian surfaces, but does not explicitly account for shadows or other forms of corrupting outliers. In this paper, we present a purely pixel-wise photometric stereo method that stably and efficiently handles various non-Lambertian effects by assuming that appearances can be decomposed into a sparse, non-diffuse component (e.g., shadows, specularities, etc.) and a diffuse component represented by a monotonic function of the surface normal and lighting dot-product. This function is constructed using a piecewise linear approximation to the inverse diffuse model, leading to closed-form estimates of the surface normals and model parameters in the absence of non-diffuse corruptions. The latter are modeled as latent variables embedded within a hierarchical Bayesian model such that we may accurately compute the unknown surface normals while simultaneously separating diffuse from non-diffuse components. Extensive evaluations are performed that show state-of-the-art performance using both synthetic and real-world images.","Lighting,
Mathematical model,
Bayes methods,
Computational modeling,
Robustness,
Materials,
Vectors"
Robust 3D Reconstruction With an RGB-D Camera,"We present a novel 3D reconstruction approach using a low-cost RGB-D camera such as Microsoft Kinect. Compared with previous methods, our scanning system can work well in challenging cases where there are large repeated textures and significant depth missing problems. For robust registration, we propose to utilize both visual and geometry features and combine SFM technique to enhance the robustness of feature matching and camera pose estimation. In addition, a novel prior-based multicandidates RANSAC is introduced to efficiently estimate the model parameters and significantly speed up the camera pose estimation under multiple correspondence candidates. Even when serious depth missing occurs, our method still can successfully register all frames together. Loop closure also can be robustly detected and handled to eliminate the drift problem. The missing geometry can be completed by combining multiview stereo and mesh deformation techniques. A variety of challenging examples demonstrate the effectiveness of the proposed approach.","Three-dimensional displays,
Feature extraction,
Image reconstruction,
Geometry,
Robustness,
Image registration,
Cameras"
"Broadband Measurements of S
-Parameters With the Use of a Single 8 \times
8 Butler Matrix","A novel application of an 8 × 8 Butler matrix in broadband multiport measuring systems has been presented. The proposed measuring system consists solely of a single broadband 8 × 8 Butler matrix and only one isolator allowing for measurements of all S-matrix coefficients of any two-port device. It has been shown that the properties of the applied 8 × 8 Butler matrix allow to obtain high measurement accuracy, which has been estimated with a numerical procedure for a different number of applied power detectors. The improved analytical procedure of calibration necessary for the transmission coefficient measurement has been presented. Performance of the proposed measuring system has been experimentally verified in a wide frequency range of 2-3.5 GHz, by measurements of S-parameters of seven exemplary attenuators and a narrowband bandpass filter. The measurement results are very close to the values obtained with the use of a commercial vector network analyzer.","Ports (Computers),
Butler matrices,
Power measurement,
Transmission line measurements,
Isolators,
Calibration,
Accuracy"
Recognizing infants and toddlers using fingerprints: Increasing the vaccination coverage,"One of the major goals of most national, international and non-governmental health organizations is to eradicate the occurrence of vaccine-preventable childhood diseases (e.g., polio). Without a high vaccination coverage in a country or a geographical region, these deadly diseases take a heavy toll on children. Therefore, it is important for an effective immunization program to keep track of children who have been immunized and those who have received the required booster shots during the first 4 years of life to improve the vaccination coverage. Given that children, as well as the adults, in low income countries typically do not have any form of identification documents which can be used for this purpose, we address the following question: can fingerprints be effectively used to recognize children from birth to 4 years? We have collected 1,600 fingerprint images (500 ppi) of 20 infants and toddlers captured over a 30-day period in East Lansing, Michigan and 420 fingerprints of 70 infants and toddlers at two different health clinics in Benin, West Africa. We devised the following strategies to improve the fingerprint recognition accuracy when comparing the acquired fingerprints against an extended gallery database of 32,768 infant fingerprints collected by VaxTrac in Benin: (i) upsample the acquired fingerprint image to facilitate minutiae extraction, (ii) match the query print against templates created from each enrollment impression and fuse the match scores, (iii) fuse the match scores of the thumb and index finger, and (iv) update the gallery with fingerprints acquired over multiple sessions. A rank-1 (rank-10) identification accuracy of 83.8% (89.6%) on the East Lansing data, and 40.00% (48.57%) on the Benin data is obtained after incorporating these strategies when matching infant and toddler fingerprints using a commercial fingerprint SDK. This is an improvement of about 38% and 20%, respectively, on the two datasets without using the proposed strategies. A state-of-the-art latent finger-print SDK achieves an even higher rank-1 (rank-10) identification accuracy of 98.97% (99.39%) and 67.14% (71.43%) on the two datasets, respectively, using these strategies; an improvement of about 23% and 24%, respectively, on the two datasets without using the proposed strategies.","Pediatrics,
Fingerprint recognition,
Databases,
Optical sensors,
Skin,
Accuracy"
Multiple Event Detection and Recognition Through Sparse Unmixing for High-Resolution Situational Awareness in Power Grid,"A situational awareness system is essential to provide accurate understanding of power system dynamics, such that proper actions can be taken in real time in response to system disturbances and to avoid cascading blackouts. Event analysis has been an important component in any situational awareness system. However, most state-of-the-art techniques can only handle single event analysis. This paper tackles the challenging problem of multiple event detection and recognition. We propose a new conceptual framework, referred to as event unmixing, where we consider real-world events mixtures of more than one constituent root event. This concept is a key enabler for analysis of events to go beyond what are immediately detectable in a system, providing high-resolution data understanding at a finer scale. We interpret the event formation process from a linear mixing perspective and propose an innovative nonnegative sparse event unmixing (NSEU) algorithm for multiple event separation and temporal localization. The proposed framework has been evaluated using both PSS/E simulated cases and real event cases collected from the frequency disturbance recorders (FDRs) of the Frequency Monitoring Network (FNET). The experimental results demonstrate that the framework is reliable to detect and recognize multiple cascading events as well as their time of occurrence with high accuracy.",
Design of Gate-All-Around Silicon MOSFETs for 6-T SRAM Area Efficiency and Yield,"Gate-all-around (GAA) MOSFETs relevant for the 11.9-nm CMOS technology node are optimized with device dimensions following the scale length rule. Variability in transistor performance due to systematic and random variations is estimated with the aid of TCAD 3-D device simulations, for these well-tempered GAA structures. The tradeoff between read stability and write-ability of 6-T static RAM cell designs implemented with GAA MOSFETs with either square or rectangular nanowire channel regions is then investigated, and a calibrated transistor I-V compact model is used to estimate cell yield. The results indicate that a rectangular (thin and wide) channel design achieves the optimal balance between the read yield and write yield and hence provides for the lowest minimum cell operating voltage, estimated to be ~0.45 V, as well as smaller cell area.","MOSFET,
SRAM cells,
Logic gates,
Layout,
Resource description framework"
Optimization of Total Energy Consumption in Flexible Manufacturing Systems Using Weighted P-Timed Petri Nets and Dynamic Programming,"Schedule optimization is crucial to reduce energy consumption of flexible manufacturing systems (FMSs) with shared resources and route flexibility. Based on the weighted p-timed Petri Net (WTPN) models of FMS, this paper considers a scheduling problem which minimizes both productive and idle energy consumption subjected to general production constraints. The considered problem is proven to be a nonconvex mixed integer nonlinear program (MINLP). A new reachability graph (RG)-based discrete dynamic programming (DP) approach is proposed for generating near energy-optimal schedules within adequate computational time. The nonconvex MINLP is sampled, and the reduced RG is constructed such that only reachable paths are retained for computation of the energy-optimal path. Each scheduling subproblem is linearized, and each optimal substructure is computed to store in a routing table. It is proven that the sampling-induced error is bounded, and this upper bound can be reduced by increasing the sampling frequency. Experiment results on an industrial stamping system show the effectiveness of our proposed scheduling method in terms of computational complexity and deviation from optimality.","Dynamic programming,
Energy consumption,
Discrete-event systems,
Processor scheduling,
Optimization,
Petri nets,
Flexible manufacturing systems"
Integrating user preferences and decomposition methods for many-objective optimization,"Evolutionary algorithms that rely on dominance ranking often suffer from a low selection pressure problem when dealing with many-objective problems. Decomposition and user-preference based methods can help to alleviate this problem to a great extent. In this paper, a user-preference based evolutionary multi-objective algorithm is proposed that uses decomposition methods for solving many-objective problems. Decomposition techniques that are widely used in multi-objective evolutionary optimization require a set of evenly distributed weight vectors to generate a diverse set of solutions on the Pareto-optimal front. The newly proposed algorithm, R-MEAD2, improves the scalability of its previous version, R-MEAD, which uses a simplexlattice design method for generating weight vectors. This makes the population size is dependent on the dimension size of the objective space. R-MEAD2 uses a uniform random number generator to remove the coupling between dimension and the population size. This paper shows that a uniform random number generator is simple and able to generate evenly distributed points in a high dimensional space. Our comparative study shows that R-MEAD2 outperforms the dominance-based method R-NSGA-II on many-objective problems.","Vectors,
Sociology,
Statistics,
Optimization,
Algorithm design and analysis,
Generators,
Convergence"
Sherlock: Micro-Environment Sensing for Smartphones,"Context-awareness is getting increasingly important for a range of mobile and pervasive applications on nowadays smartphones. Whereas human-centric contexts (e.g., indoor/ outdoor, at home/in office, driving/walking) have been extensively researched, few attempts have studied from phones' perspective (e.g., on table/sofa, in pocket/bag/hand). We refer to such immediate surroundings as micro-environment, usually several to a dozen of centimeters, around a phone. In this study, we design and implement Sherlock, a micro-environment sensing platform that automatically records sensor hints and characterizes the micro-environment of smartphones. The platform runs as a daemon process on a smartphone and provides finer-grained environment information to upper layer applications via programming interfaces. Sherlock is a unified framework covering the major cases of phone usage, placement, attitude, and interaction in practical uses with complicated user habits. As a long-term running middleware, Sherlock considers both energy consumption and user friendship. We prototype Sherlock on Android OS and systematically evaluate its performance with data collected on fifteen scenarios during three weeks. The preliminary results show that Sherlock achieves low energy cost, rapid system deployment, and competitive sensing accuracy.","Smart phones,
Acceleration,
Histograms,
Legged locomotion,
Sensors,
Materials,
Cameras"
Peak Load Curtailment in a Smart Grid Via Fuzzy System Approach,"Among many significant smart grid initiatives and challenges considered by many utilities and within the research community, are those associated with the energy management and conservation, in particular the management of energy demand during peak load periods. In this paper, a novel method for peak load curtailment by using a fuzzy system approach is presented. The proposed method is based on the application of fuzzy logic principles for peak load curtailment in a smart grid environment. The inputs to the system are the utility peak load data consisting of many energy demand scenarios, and the outputs are the necessary demand response power reductions required for the load curtailment during the peak load periods. The proposed method considers different peak load profiles and power consumption sources for multiple city regions. Furthermore, it is adaptable for use in many scenarios, such as those encompassing many input sources of power consumption with diverse input parameters of control (i.e., temperature offsets, duty cycle control, etc.) within numerous city regions. Thus, it can be applied to multiple output variables of control.","Fuzzy systems,
Urban areas,
Water heating,
Smart grids,
Heat pumps,
Power demand"
Real-time gesture recognition using a humanoid robot with a deep neural architecture,"Dynamic gesture recognition is one of the most interesting and challenging areas of Human-Robot-Interaction (HRI). Problems like image segmentation, temporal and spatial feature extraction and real time recognition are the most promising issues to name in this context. This work proposes a deep neural model to recognize dynamic gestures with minimal image preprocessing and real time recognition in an experimental set up using a humanoid robot. We conducted two experiments with command gestures in an offline fashion and for demonstration in a Human-Robot-Interaction (HRI) scenario. Our results showed that the proposed model achieves high classification rates of the gestures executed by different subjects, who perform them with varying speed. With our additional audio feedback we demonstrate that our system performs in real time.","Feature extraction,
Computer architecture,
Kernel,
Training,
Gesture recognition,
Robots,
Real-time systems"
Optimization of limiting reactors design for DC fault protection of multi-terminal HVDC networks,"In multi-terminal dc networks (MTdc) reactors are required to limit the rate of rise and the peak values of the fast developing currents in case of a dc fault. In this way, dc breakers have more time to isolate a fault and the system can restore its post-fault operation. This paper proposes a methodology to optimize the design of limiting reactors used for the protection of voltage-source converter (VSC) based MTdc networks. The limiting reactors were optimized using the covariance matrix adaptation evolution strategy (CMA-ES) optimization algorithm with two design objectives: first, the minimization of the reactor inductance value at the output of each VSC station to achieve N-1 security and second, the minimization of the reactors cost and mass and the peak dc fault current. Following the methodology steps, the effect of the dc fault location and the pre-fault power level of the converters on the dc fault network response are investigated in a four-terminal radially-connected grid. It resulted that the VSC stations controlling the dc voltage of the MTdc network are the first to respond to a dc fault and thus, limiting reactors higher than 97 mH are required in their dc output, in combination with dc breakers faster than 5 ms, to successfully protect the grid of the present case study.","Inductors,
Power conversion,
Limiting,
Optimization,
Inductance,
Fault currents"
SprintNet: A high performance server-centric network architecture for data centers,"This paper presents the design, implementation and evaluation of SprintNet, a novel network architecture for data centers. SprintNet achieves high performance in network capacity, fault tolerance, and network latency. SprintNet is also a scalable, yet low-diameter network architecture where the maximum shortest distance between any pair of servers can be limited by no more than four and is independent of the number of layers. The specially designed routing schemes for SprintNet strengthen its merits. Both theoretical analysis and simulation experiments are conducted to evaluate its overall performance with respect to average path length, aggregate bottleneck throughput, and fault tolerance.",
Silicon Effect-Aware Full-Chip Extraction and Mitigation of TSV-to-TSV Coupling,"This paper presents a silicon effect-aware multiTSV model. Through-silicon-via (TSV) depletion region, silicon substrate discharging path and electrical field distribution around TSV neighbor are modeled and studied in full-chip design. Verification with field solver and full-chip TSV-to-TSV coupling analysis in both the worst case and the average case show this model is accurate and efficient. It is found that 3-D nets receive more noise than their 2-D counterparts due to TSV-to-TSV coupling. To alleviate this coupling noise on TSV nets, two new optimization methods are investigated. One way is to utilize guard rings around the victim TSV so as to form a stronger discharging path, an alternative approach is to adopt differential signal transmission to improve noise immunity. These techniques have been implemented on 3-D IC designs with TSVs placed regularly or irregularly. Full-chip analysis results show that our approaches are effective in noise reduction with small area overhead.","Through-silicon vias,
Optimization methods,
Integrated circuit modeling,
Noise,
Three-dimensional integrated circuits"
Online generation of homotopically distinct navigation paths,"In mobile robot navigation, cost functions are a popular approach to generate feasible, safe paths that avoid obstacles and that allow the robot to get from its starting position to the goal position. Alternative ways to navigate around the obstacles typically correspond to different local minima in the cost function. In this paper we present a highly effective approach to overcome such local minima and to quickly propose a set of alternative, topologically different and optimized paths. We furthermore describe how to maintain a set of optimized trajectory alternatives to reduce optimization efforts when the robot has to adapt to changes in the environment. We demonstrate in experiments that our method outperforms a state-of-the-art approach by an order of magnitude in computation time, which allows a robot to use our method online during navigation. We furthermore demonstrate that the approach of using a set of qualitatively different trajectories is beneficial in shared autonomy settings, where a user operating a wheelchair can quickly switch between topologically different trajectories.",
Red Blood Cell Tracking Using Optical Flow Methods,"The investigation of microcirculation is an important task in biomedical and physiological research because the microcirculation information, such as flow velocity and vessel density, is critical to monitor human conditions and develop effective therapies of some diseases. As one of the tasks of the microcirculation study, red blood cell (RBC) tracking presents an effective approach to estimate some parameters in microcirculation. The common method for RBC tracking is based on spatiotemporal image analysis, which requires the image to have high qualification and cells should have fixed velocity. Besides, for in vivo cell tracking, cells may disappear in some frames, image series may have spatial and temporal distortions, and vessel distribution can be complex, which increase the difficulties of RBC tracking. In this paper, we propose an optical flow method to track RBCs. It attempts to describe the local motion for each visible point in the frames using a local displacement vector field. We utilize it to calculate the displacement of a cell in two adjacent frames. Additionally, another optical flow-based method, scale invariant feature transform (SIFT) flow, is also presented. The experimental results show that optical flow is quite robust to the case where the velocity of cell is unstable, while SIFT flow works well when there is a large displacement of the cell between two adjacent frames. Our proposed methods outperform other methods when doing in vivo cell tracking, which can be used to estimate the blood flow directly and help to evaluate other parameters in microcirculation.",
Power Blurring: Fast Static and Transient Thermal Analysis Method for Packaged Integrated Circuits and Power Devices,"High-temperature and temperature nonuniformity in high-performance integrated circuits (ICs) can significantly degrade chip performance and reliability. Thus, accurate temperature information is a critical factor in chip design and verification. Conventional volume grid-based techniques, such as finite-difference and finite-element methods (FEMs), are computationally expensive. In an effort to reduce the computation time, we have developed a new method, called power blurring (PB), for calculating temperature distributions using a matrix convolution technique in analogy with image blurring. The PB method considers the finite size and boundaries of the chip as well as 3-D heat spreading in the heat sink. PB is applicable to both static and transient thermal simulations. Comparative studies with a commercial FEM tool show that the PB method is accurate within 2%, with orders of magnitude speedup compared with FEM methods. PB can be applied to very fine power maps with a grid size as small as 10 μm for a fully packaged IC or submicrometer heat sources in power electronic transistor arrays. In comparison with architecture-level thermal simulators, such as HotSpot, PB provides much more accurate temperature profiles with reduced computation time.","Heating,
Heat sinks,
Integrated circuits,
Geometry,
Silicon,
Thermal analysis,
Temperature distribution"
Interference Channel With a Causal Relay Under Strong and Very Strong Interference,"In this paper, we study a two-user interference channel with a causal relay, where the relay's transmit symbol depends not only on its past received symbols, but also on its present received symbol. This is an appropriate model for studying amplify-and-forward type relaying when the bandwidth delay-spread product is much smaller than one. For the discrete memoryless interference channel with a causal relay, we derive a genie-aided outer bound. For the Gaussian interference channel with a causal relay, we define strong and very strong interference conditions and propose an outer bound for each case. We also propose an achievable scheme based on instantaneous amplify-and-forward (AF) relaying for the Gaussian interference channel with a causal relay and so it achieves capacity under some conditions. Our result extends the previous result by El Gamal, Hassanpour, and Mammen on the optimality of instantaneous AF relaying for the Gaussian relay channel with a causal relay to that of the Gaussian interference channel with a causal relay under strong and very strong interference.","Relays,
Interference channels,
Zirconium,
Encoding,
Receivers,
Upper bound"
Active Orientation Models for Face Alignment In-the-Wild,"We present Active Orientation Models (AOMs), generative models of facial shape and appearance, which extend the well-known paradigm of Active Appearance Models (AAMs) for the case of generic face alignment under unconstrained conditions. Robustness stems from the fact that the proposed AOMs employ a statistically robust appearance model based on the principal components of image gradient orientations. We show that when incorporated within standard optimization frameworks for AAM learning and fitting, this kernel Principal Component Analysis results in robust algorithms for model fitting. At the same time, the resulting optimization problems maintain the same computational cost. As a result, the main similarity of AOMs with AAMs is the computational complexity. In particular, the project-out version of AOMs is as computationally efficient as the standard project-out inverse compositional algorithm, which is admittedly one of the fastest algorithms for fitting AAMs. We verify experimentally that: 1) AOMs generalize well to unseen variations and 2) outperform all other state-of-the-art AAM methods considered by a large margin. This performance improvement brings AOMs at least in par with other contemporary methods for face alignment. Finally, we provide MATLAB code at http://ibug.doc.ic.ac.uk/resources.","Active appearance model,
Shape,
Deformable models,
Face,
Robustness,
Principal component analysis"
Three-Mask Polysilicon Thin-Film Transistor Biosensor,"Biosensors are commonly produced using a siliconon-insulator (SOI) CMOS process and advanced lithography to define nanowires. In this paper, a simpler and cheaper junctionless three-mask process is investigated, which uses thin-film technology to avoid the use of SOI wafers, in situ doping to avoid the need for ion implantation and direct contact to a low-doped polysilicon film to eliminate the requirement for heavily doped source/drain contacts. Furthermore, TiN is used to contact the biosensor source/drain because it is a hard resilient material that allows the biosensor chip to be directly connected to a printed circuit board without wire bonding. pH sensing experiments, combined with device modeling, are used to investigate the effects of contact and series resistance on the biosensor performance, as this is a key issue when contacting directly to low-doped silicon. It is shown that in situ phosphorus doping concentrations in the range 4 × 1017-3 × 1019 cm-3 can be achieved using 0.1% PH3 flows between 4 and 20 sccm. Furthermore, TiN makes an ohmic contact to the polysilicon even at the bottom end of this doping range. Operation as a biosensor is demonstrated by the detection of C-reactive protein, an inflammatory biomarker for respiratory disease.",
Energy-Efficient Multi-Mode Compressed Sensing System for Implantable Neural Recordings,"Widely utilized in the field of Neuroscience, implantable neural recording devices could capture neuron activities with an acquisition rate on the order of megabytes per second. In order to efficiently transmit neural signals through wireless channels, these devices require compression methods that reduce power consumption. Although recent Compressed Sensing (CS) approaches have successfully demonstrated their power, their full potential is yet to be explored. Built upon our previous on-chip CS implementation, we propose an energy efficient multi-mode CS framework that focuses on improving the off-chip components, including (i) a two-stage sensing strategy, (ii) a sparsifying dictionary directly using data, (iii) enhanced compression performance from Full Signal CS mode and Spike Restoration mode to Spike CS + Restoration mode and; (iv) extension of our framework to the Tetrode CS recovery using joint sparsity. This new framework achieves energy efficiency, implementation simplicity and system flexibility simultaneously. Extensive experiments are performed on simulation and real datasets. For our Spike CS + Restoration mode, we achieve a compression ratio of 6% with a reconstruction SNDR > 10 dB and a classification accuracy > 95% for synthetic datasets. For real datasets, we get a 10% compression ratio with ~ 10 dB for Spike CS + Restoration mode.","Sensors,
Dictionaries,
System-on-chip,
Electrodes,
Compressed sensing,
Wavelet transforms,
Power demand"
A Bayesian Bounded Asymmetric Mixture Model With Segmentation Application,"Segmentation of a medical image based on the modeling and estimation of the tissue intensity probability density functions via a Gaussian mixture model has recently received great attention. However, the Gaussian distribution is unbounded and symmetrical around its mean. This study presents a new bounded asymmetric mixture model for analyzing both univariate and multivariate data. The advantage of the proposed model is that it has the flexibility to fit different shapes of observed data such as non-Gaussian, nonsymmetric, and bounded support data. Another advantage is that each component of the proposed model has the ability to model the observed data with different bounded support regions, which is suitable for application on image segmentation. Our method is intuitively appealing, simple, and easy to implement. We also propose a new method to estimate the model parameters in order to minimize the higher bound on the data negative log-likelihood function. Numerical experiments are presented where the proposed model is tested in various images from simulated to real 3- D medical ones.","Bayes methods,
biological tissues,
Gaussian distribution,
image segmentation,
medical image processing,
parameter estimation"
Fuzzy logic controlled MPPT assisted PV-FC power generation for motor driven water pumping system,"This paper presents a hybrid Photovoltaic/Fuel cell (PV/FC) power generation system using renewable energy (RE) sources e.g. solar photovoltaic (PV) system and proton exchange membrane fuel cell (PEMFC). Generated electrical power is utilized for water pumping system used in agriculture applications. In this paper, a PV system is considered as main power generating source and FC is considered as secondary source for supplying the induction motor driven water pumping system. The design and implementation of a fuzzy logic based maximum power point tracker (MPPT) to extract the maximum power point (MPP) of PV system is also proposed. The modeling and analysis of PV and PEMFC based systems have been done using MATLAB Simulink.",
The Sensitive and Efficient Detection of Quadriceps Muscle Thickness Changes in Cross-Sectional Plane Using Ultrasonography: A Feasibility Investigation,"As a direct determinant parameter to quantify muscle activity, the muscle thickness (MT) has been investigated in many aspects and for various purposes. Ultrasonography (US) is a promising modality to detect muscle morphological changes during contractions since it is portable, noninvasive, and real time. However, there are few reports on sensitive and efficient estimation of changes of MT in a cross-sectional plane. In this feasibility investigation, we proposed a coarse-to-fine method based on a compressive-tracking algorithm for estimation of MT changes during an example task of isometric knee extension using ultrasound images. The sensitivity and efficiency are evaluated with 1920 US images from quadriceps muscle (QM) in eight subjects. The detection results were compared with those obtained from both traditional manual measurement and the well known normalized cross-correlation method, and the effect of the size of tracking window on detection performance was evaluated as well. It is demonstrated that the proposed method agrees well with the manual measurement. Meanwhile, it is not only sensitive to relatively small changes of MT but also computationally efficient.","Muscles,
Ultrasonic imaging,
Biomedical measurement,
Torque,
Manuals,
Ultrasonic variables measurement,
Probes"
A Proxy-Based Authentication and Billing Scheme With Incentive-Aware Multihop Forwarding for Vehicular Networks,"To support the high mobility of vehicles, the Internet Engineering Task Force (IETF) defines proxy mobile IPv6 (PMIPv6) to reduce the signaling overhead. However, the design of PMIPv6 does not thoroughly consider security issues, such as man-in-the-middle and impersonation attacks. Moreover, the traditional authentication/authorization/accounting (AAA) server architecture in PMIPv6 could impede the localized advantage because of the long-distance delivery between a mobile access gateway (MAG) and the AAA server. In practice, the billing is a crucial issue that is, unfortunately, rarely discussed in vehicular ad hoc networks (VANETs). In this paper, a local-based authentication and billing scheme is proposed to lessen the long-distance communication overhead. An incentive-aware multihop forwarding procedure is also offered to stimulate the help of forwarding others' messages in a vehicle-to-vehicle (V2V) environment. Therefore, the proposed billing scheme is designed for full VANETs, including the vehicle-to-infrastructure (V2I) and V2V environments. Lightweight keyed hash functions and batch verification are employed for efficient computation and concise communication overhead. Only a few signatures are used in the first message to ensure the nonrepudiation payment approval. Security analysis and performance evaluation show that the proposed scheme is secure and efficient, compared with a conventional public-key based scheme. The advantages of the proposed scheme include: 1) mutual authentication and session key agreement; 2) privacy preservation; 3) confidentiality, integrity, free-riding resistance, double-spending avoidance, and nonrepudiation properties; and 4) efficient billing and payment clearance.","Authentication,
Vehicles,
Magnetic tunneling,
Servers,
Indexes,
Mobile communication"
Representation of solutions in genetic VLSI placement algorithms,"The VLSI placement problem is presented in this article. A mechanism of representation of solutions for further genetic algorithm implementation is described. The proposed encoding algorithm is based on a placement tree and reverse Polish notation. The decoding algorithm is implemented in two stages: twinning of elements in macroblocks and calculation of real coordinates of elements. Experimental results show time-response characteristics of the proposed coding and decoding mechanisms. The time complexity of the encoding algorithm is represented by O(n) whereas the time complexity of the decoding algorithm is represented by O(n log n), where n is the number of elements.","Very large scale integration,
Encoding,
Decoding,
Algorithm design and analysis,
Biological cells,
Genetic algorithms,
Educational institutions"
Effective and Efficient Clustering Methods for Correlated Probabilistic Graphs,"Recently, probabilistic graphs have attracted significant interests of the data mining community. It is observed that correlations may exist among adjacent edges in various probabilistic graphs. As one of the basic mining techniques, graph clustering is widely used in exploratory data analysis, such as data compression, information retrieval, image segmentation, etc. Graph clustering aims to divide data into clusters according to their similarities, and a number of algorithms have been proposed for clustering graphs, such as the pKwikCluster algorithm, spectral clustering, k-path clustering, etc. However, little research has been performed to develop efficient clustering algorithms for probabilistic graphs. Particularly, it becomes more challenging to efficiently cluster probabilistic graphs when correlations are considered. In this paper, we define the problem of clustering correlated probabilistic graphs. To solve the challenging problem, we propose two algorithms, namely the PEEDR and the CPGS clustering algorithm. For each of the proposed algorithms, we develop several pruning techniques to further improve their efficiency. We evaluate the effectiveness and efficiency of our algorithms and pruning methods through comprehensive experiments.","Probabilistic logic,
Clustering algorithms,
Correlation,
Algorithm design and analysis,
Probability,
Joints,
Data mining"
Energy-Responsive Aggregate Context for Energy Saving in a Multi-Resident Environment,"Human activity is among the critical information for a context-aware energy saving system since knowing what activities are undertaken is important for judging if energy is well spent. Most of the prior works on energy saving do not make the best of context-awareness especially in a multiuser environment to assist the energy saving system. In addition, they often ignore whether appliances are operating implicitly or explicitly related to the context. These factors may compromise the practicality and acceptability of most of the currently available energy saving systems, thus failing to meet real user needs. Therefore, we propose Energy-Responsive Aggregate Context (ERAC) to model multi-resident activities and their associated energy consumption. Based on the relationship, implicit or explicit, between a given appliance and its associated context, an energy saving system and its users can better determine whether the power consumed by the appliance is wasted. Our experimental results demonstrate the effectiveness of the proposed approach.","Context,
Aggregates,
Home appliances,
Context modeling,
Energy consumption,
Smart homes,
Power demand"
ANTELOPE: A Semantic-Aware Data Cube Scheme for Cloud Data Center Networks,"Today's cloud data centers contain more than millions of servers and offer high bandwidth. A fundamental problem is how to significantly improve the large-scale system's scalability to interconnect a large number of servers and meanwhile support various online services in cloud computing. One way is to deal with the challenge of potential mismatching between the network architecture and the data placement. To address this challenge, we present ANTELOPE, a scalable distributed data-centric scheme in cloud data centers, in which we systematically take into account both the property of network architecture and the optimization of data placement. The basic idea behind ANTELOPE is to leverage precomputation based data cube to support online cloud services. Since the construction of data cube suffers from the high costs of full materialization, we use a semantic-aware partial materialization solution to significantly reduce the operation and space overheads. Extensive experiments on real system implementations demonstrate the efficacy and efficiency of our proposed scheme.","Web services,
cloud computing,
computer centres,
network servers,
network theory (graphs),
optimisation"
Theoretical and Empirical Evaluation of Surface Roughness Effects on Conductivity in the Terahertz Regime,"While models for conductivity in the terahertz regime are improving, there is limited data on the effects of submicrometer roughness features on conductivity. We present direct measurements of the effective conductivity of samples with periodic controlled roughness features using an open quasi-optical resonator at 400 and 650 GHz. The empirical results are compared with two closed-form models and a finite-element simulation. We find that the Mie-scattering-based model and finite-element approach are more accurate for samples that are smooth relative to the skin depth. For surface features greater than the skin depth, we found the Hammerstad and Bekkadal model to be a better predictor of effective conductivity. The observed discrepancies identify the need for further advances in theoretical understanding of the underlying physics. The empirical results of this study can be used to benchmark new and improved models of effective conductivity in the terahertz regime.","Conductivity,
Rough surfaces,
Surface roughness,
Mirrors,
Conductivity measurement,
Materials,
Gratings"
App stores for the brain: Privacy & security in Brain-Computer Interfaces,"An increasing number of Brain-Computer Interfaces (BCIs) are being developed in medical and nonmedical fields, including marketing, gaming and entertainment industries. BCI-enabled technology carries a great potential to improve and enhance the quality of human lives. It provides people suffering from severe neuromuscular disorders with a way to interact with the external environment. It also enables a more personalized user experience in gaming and entertainment. These BCI applications are, however, not without risk. Established engineering practices set guarantees on performance, reliability and physical safety of BCIs. But no guarantees or standards are currently in place regarding user privacy and security. In this paper, we identify privacy and security issues arising from possible misuse or inappropriate use of BCIs. In particular, we explore how current and emerging non-invasive BCI platforms can be used to extract private information, and we suggest an interdisciplinary approach to mitigating this problem. We then propose a tool to prevent this side-channel extraction of users' private information. This is a first step towards making BCI-enabled technologies secure and privacy preserving.","Privacy,
Data mining,
Security,
Law,
Feature extraction,
Signal processing algorithms"
Exemplar-Based Human Action Pose Correction,"The launch of Xbox Kinect has built a very successful computer vision product and made a big impact on the gaming industry. This sheds lights onto a wide variety of potential applications related to action recognition. The accurate estimation of human poses from the depth image is universally a critical step. However, existing pose estimation systems exhibit failures when facing severe occlusion. In this paper, we propose an exemplar-based method to learn to correct the initially estimated poses. We learn an inhomogeneous systematic bias by leveraging the exemplar information within a specific human action domain. Furthermore, as an extension, we learn a conditional model by incorporation of pose tags to further increase the accuracy of pose correction. In the experiments, significant improvements on both joint-based skeleton correction and tag prediction are observed over the contemporary approaches, including what is delivered by the current Kinect system. Our experiments for the facial landmark correction also illustrate that our algorithm can improve the accuracy of other detection/estimation systems.","Joints,
Estimation,
Training,
Vegetation,
Cameras,
Systematics"
A Generic Interference Model for Uplink OFDMA Networks With Fractional Frequency Reuse,"Fractional frequency reuse (FFR) has emerged as a viable solution to coordinate and mitigate cochannel interference (CCI) in orthogonal frequency-division multiple-access (OFDMA)-based wireless cellular networks. The incurred CCI in cellular networks with FFR is highly uncertain and varies as a function of various design parameters that include the user scheduling schemes, the transmit power distribution among multiple allocated subcarriers, the partitioning of the cellular region into cell-edge and cell-center zones, the allocation of spectrum within each zone, and the channel reuse factors. To this end, this paper derives a generic analytical model for uplink CCI in multicarrier OFDMA networks with FFR. The derived expressions capture several network design parameters and are applicable to any composite fading-channel models. The accuracy of the derivations is verified via Monte Carlo simulations. Moreover, their usefulness is demonstrated by obtaining closed-form expressions for the Rayleigh fading-channel model and by evaluating important network performance metrics such as ergodic capacity. Numerical results provide useful system design guidelines and highlight the tradeoffs associated with the deployment of FFR schemes in OFDMA-based networks.","Uplink,
Fading,
Round robin,
Interference,
OFDM,
Downlink,
Resource management"
Self-Organized P2P Approach to Manufacturing Service Discovery for Cross-Enterprise Collaboration,"The combination of service-oriented architecture (SOA) and peer-to-peer (P2P) architecture plays a promising role in distributed manufacturing environments in that the peer service can be used to facilitate the integration and discovery of distributed manufacturing resources and achieve communication and collaboration across distributed virtual enterprises. However, the large size, dynamic nature, and heterogeneous expression of distributed manufacturing resources bring forth a serious challenge in scalability and efficiency. This paper presents a self-organized P2P framework that supports scalable and efficient manufacturing service (MS) discovery for cross-enterprise collaboration by forming and maintaining autonomous enterprise peer groups (PG). Each enterprise exhibits as a peer that provides some sharable MSs that are represented comprehensively and formally with a generalized ontology. Each enterprise PG dynamically clusters a set of enterprise peers offering semantically similar MSs, and elects the most reputed peer through multicriteria trust evaluation as its core (i.e., super peer, SP). Then, a MS request can be first routed to the suitable SP and further to its leaf peer in a systematic way, thus supporting efficient service discovery. A prototype system is implemented on JXTA for real application and validated through an experimental case study.","Peer-to-peer computing,
Manufacturing,
Ontologies,
Collaboration,
Computer architecture,
Scalability,
Service-oriented architecture"
A Collaborative Computing Framework of Cloud Network and WBSN Applied to Fall Detection and 3-D Motion Reconstruction,"As cloud computing and wireless body sensor network technologies become gradually developed, ubiquitous healthcare services prevent accidents instantly and effectively, as well as provides relevant information to reduce related processing time and cost. This study proposes a co-processing intermediary framework integrated cloud and wireless body sensor networks, which is mainly applied to fall detection and 3-D motion reconstruction. In this study, the main focuses includes distributed computing and resource allocation of processing sensing data over the computing architecture, network conditions and performance evaluation. Through this framework, the transmissions and computing time of sensing data are reduced to enhance overall performance for the services of fall events detection and 3-D motion reconstruction.","Sensors,
Mobile handsets,
Cloud computing,
Informatics,
Three-dimensional displays,
Medical services,
Collaboration"
Real-Time Monte Carlo Tree Search in Ms Pac-Man,"In this paper, Monte Carlo tree search (MCTS) is introduced for controlling the Pac-Man character in the real-time game Ms Pac-Man. MCTS is used to find an optimal path for an agent at each turn, determining the move to make based on the results of numerous randomized simulations. Several enhancements are introduced in order to adapt MCTS to the real-time domain. Ms Pac-Man is an arcade game, in which the protagonist has several goals but no conclusive terminal state. Unlike games such as Chess or Go there is no state in which the player wins the game. Instead, the game has two subgoals, 1) surviving and 2) scoring as many points as possible. Decisions must be made in a strict time constraint of 40 ms. The Pac-Man agent has to compete with a range of different ghost teams, hence limited assumptions can be made about their behavior. In order to expand the capabilities of existing MCTS agents, four enhancements are discussed: 1) a variable-depth tree; 2) simulation strategies for the ghost team and Pac-Man; 3) including long-term goals in scoring; and 4) reusing the search tree for several moves with a decay factor γ. The agent described in this paper was entered in both the 2012 World Congress on Computational Intelligence (WCCI'12, Brisbane, Qld., Australia) and the 2012 IEEE Conference on Computational Intelligence and Games (CIG'12, Granada, Spain) Pac-Man Versus Ghost Team competitions, where it achieved second and first places, respectively. In the experiments, we show that using MCTS is a viable technique for the Pac-Man agent. Moreover, the enhancements improve overall performance against four different ghost teams.","Games,
Real-time systems,
Junctions,
Monte Carlo methods,
Artificial intelligence,
Computational intelligence,
Planning"
OpenNet: A simulator for software-defined wireless local area network,"This study is motivated by a plan to install a software-defined wireless local area network (SDWLAN) on campus, which possesses a desired property that both data flow and device behaviors can be software-definable. Because the installation involves hundreds of access points, we must conduct simulations beforehand to verify the design and scalability of the target system. However, existing SDN simulator like Mininet does not support modeling of wireless channel and mobility. On the other hand, common network simulator like ns-3 only has limited support for software-defined controllers and does not fully implement handover process. We thus develop OpenNet, which connects Mininet to ns3 to enjoy both Mininet's advantage of controller compatibility and ns-3's ability in the wireless/mobility modeling. OpenNet also complements ns-3 by adding probe mechanism, which is missing in the current ns-3 implementation. Our simulation result demonstrates the effectiveness of OpenNet.","Handover,
Wireless communication,
IEEE 802.11 Standards,
Probes,
Signal to noise ratio,
Mobile nodes"
Subspace Projection Method Based Clustering Analysis in Load Profiling,"Customers of different contract types have different shapes in daily load profiles in the manner of different characteristics. Therefore, maximally capture local and global shape variability is essential in load profiling which exhibits the customers' different behaviors and characteristics. Existing approaches are focusing on the global property by considering all dimensions in the data set. However, the load shapes are determined by subspace of dimensions in most of the time. In this paper, we use subspace projection methods (subspace clustering and projected clustering) to capture such subspaces of load diagrams which maximize the difference between particular load shapes in different groups of customers. Also, we have treated clustering as classification to select most appropriate cluster numbers. The contribution of our study is that we have interpreted the strength and weakness of subspace projection method in load profiling. The result shows that subspace projection based method outperforms traditional clustering algorithms.","Clustering algorithms,
Data mining,
Load flow analysis"
Efficient Probabilistic Classification Vector Machine With Incremental Basis Function Selection,"Probabilistic classification vector machine (PCVM) is a sparse learning approach aiming to address the stability problems of relevance vector machine for classification problems. Because PCVM is based on the expectation maximization algorithm, it suffers from sensitivity to initialization, convergence to local minima, and the limitation of Bayesian estimation making only point estimates. Another disadvantage is that PCVM was not efficient for large data sets. To address these problems, this paper proposes an efficient PCVM (EPCVM) by sequentially adding or deleting basis functions according to the marginal likelihood maximization for efficient training. Because of the truncated prior used in EPCVM, two approximation techniques, i.e., Laplace approximation and expectation propagation (EP), have been used to implement EPCVM to obtain full Bayesian solutions. We have verified Laplace approximation and EP with a hybrid Monte Carlo approach. The generalization performance and computational effectiveness of EPCVM are extensively evaluated. Theoretical discussions using Rademacher complexity reveal the relationship between the sparsity and the generalization bound of EPCVM.","Approximation methods,
Support vector machines,
Probabilistic logic,
Training,
Vectors,
Bayes methods,
Approximation algorithms"
Evaluation of Thermal Cycling Reliability of Sintered Nanosilver Versus Soldered Joints by Curvature Measurement,"Low-temperature silver sintering technology is emerging as a lead-free die-attach solution to significantly improve the heat dissipation and reliability packaging of power devices and modules die attached by solder alloys. With the recent introduction of nanosilver materials, which dramatically simplify the bonding process by lowering the required pressure down to a few megapascals, the silver sintering die-attach solution is poised for wide use in the manufacture of electronic products. In this paper, the thermomechanical reliability of sintered-silver joints was studied in comparison with soldered joints of two lead-free solders, SN100C and SAC305. Die-attach samples were fabricated by bonding 10 mm × 10 mm silicon mechanical chips to silver-metalized copper blocks and direct-bond copper (DBC) substrates according to the respective heating profiles of a nanosilver paste and the two solders. The die-attach samples were thermally cycled between -40 °C and +125 °C. The bonding reliability was evaluated by measuring the bending curvatures of the cycled samples and examining the cross sections of the samples under an electron microscope. Bending of the bonded structures, which is the result of mismatched coefficients of thermal expansion between silicon and copper or DBC, offered a nondestructive method for monitoring the integrity of the bond line. The bending curvatures of all of the die-attach samples decreased rapidly after they were thermally cycled. Most of the drop in curvature can be attributed to stress relaxation in the bonding materials without bond-line cracking. However, in the samples on copper blocks, after 800 cycles, the curvatures of the soldered samples decreased to near 0 μm-1, but those of the silver-sintered samples still had about 30% of the original curvatures. Scanning electron microscopy images showed that the joints of the soldered samples with near 0 μm-1 curvature had been cracked almost all the way through, but the joints of the sintered samples were still intact. These results demonstrate that the sintered-silver joints are more reliable than the soldered joints.","Joints,
Silver,
Substrates,
Reliability,
Silicon,
Copper"
Improving the Robustness of Local Network Alignment: Design and Extensive Assessmentof a Markov Clustering-Based Approach,"The analysis of protein behavior at the network level had been applied to elucidate the mechanisms of protein interaction that are similar in different species. Published network alignment algorithms proved to be able to recapitulate known conserved modules and protein complexes, and infer new conserved interactions confirmed by wet lab experiments. In the meantime, however, a plethora of continuously evolving protein-protein interaction (PPI) data sets have been developed, each featuring different levels of completeness and reliability. For instance, algorithms performance may vary significantly when changing the data set used in their assessment. Moreover, existing papers did not deeply investigate the robustness of alignment algorithms. For instance, some algorithms performances vary significantly when changing the data set used in their assessment. In this work, we design an extensive assessment of current algorithms discussing the robustness of the results on the basis of input networks. We also present AlignMCL, a local network alignment algorithm based on an improved model of alignment graph and Markov Clustering. AlignMCL performs better than other state-of-the-art local alignment algorithms over different updated data sets. In addition, AlignMCL features high levels of robustness, producing similar results regardless the selected data set.","Proteins,
Algorithm design and analysis,
Clustering algorithms,
Markov processes,
Computational biology"
Industrial AGVs: Toward a pervasive diffusion in modern factory warehouses,"This paper describes the technology behind the automation of modern factory warehouses with multiple Automated Guided Vehicles (AGVs). In particular, we focus on intermediate results of Plug-and-Navigate Robots (PAN-Robots) project describing how the latest developed technologies have dealt with main issues about traffic, safety and performance of an automated warehouse. A survey about the market impact produced by first outcomes is then drafted and a roadmap to a pervasive diffusion of AGVs is finally presented.",
E-Assessment with interactive images,"Besides the fact that e-Assessment systems can efficiently conduct all paper based tests to evaluate knowledge and skills, they can offer a lot of new features via sophisticated information and communication technologies, including adaptive testing, immediate evaluation, etc. Most of the realised e-Assessment systems use pictures in the realisation of e-Testing, but the pictures are mainly used as supported media enhancement of the multiple choice questions. We introduce a brand new idea to use interactive images, where the user can navigate and zoom the picture and provide answers by clicking on an appropriate graphical object, mark a region, annotate, set an answer/comment on a given position, etc. The application domain of this innovation is huge, including e-Assessment for those sciences, where image analysis is essential, such as analysis of medical images, gathering map selective user's opinion etc. We have developed three new question types based on interactive images that offer these innovations. The impact is not just in enhancement of offered technology, but also on preventing various cheating methods, such as memorising, guessing, etc. These innovations can improve the assessment results, by a more correct evaluation and knowledge assessment.","Navigation,
Testing,
Engines,
Technological innovation,
Computers,
Cultural differences,
Engineering education"
Online Discriminative Kernel Density Estimator With Gaussian Kernels,"We propose a new method for a supervised online estimation of probabilistic discriminative models for classification tasks. The method estimates the class distributions from a stream of data in the form of Gaussian mixture models (GMMs). The reconstructive updates of the distributions are based on the recently proposed online kernel density estimator (oKDE). We maintain the number of components in the model low by compressing the GMMs from time to time. We propose a new cost function that measures loss of interclass discrimination during compression, thus guiding the compression toward simpler models that still retain discriminative properties. The resulting classifier thus independently updates the GMM of each class, but these GMMs interact during their compression through the proposed cost function. We call the proposed method the online discriminative kernel density estimator (odKDE). We compare the odKDE to oKDE, batch state-of-the-art kernel density estimators (KDEs), and batch/incremental support vector machines (SVM) on the publicly available datasets. The odKDE achieves comparable classification performance to that of best batch KDEs and SVM, while allowing online adaptation from large datasets, and produces models of lower complexity than the oKDE.","data compression,
Gaussian processes,
mixture models,
pattern classification,
probability,
support vector machines"
A study on emotion recognition from body gestures using Kinect sensor,"This novel work is aimed at the study of emotion recognition from gestures using Kinect sensor. The Kinect sensor along with Software Development Kit (SDK) generates the human skeleton represented by 3-dimensional coordinates corresponding to twenty body joints. Using the co-ordinates of eleven such joints from the upper body and the hands, a set of nine features based on the distances, accelerations and angles between the different joints have been extracted. These features are able to uniquely identify gestures corresponding to five basic human emotional states, namely, `Anger', `Fear', `Happiness', `Sadness' and `Relaxation'. The goal of the proposed system is to classify an emotion based on body gesture. A comparison of classification using binary decision tree, ensemble decision tree, k-nearest neighbour, support vector machine with radial basis function kernel and neural network classifier based on back-propagation learning is made, in terms of average classification accuracy and computation time. A high overall recognition rate of 90.83% is obtained from the ensemble decision tree.","Barium,
Educational institutions"
Synthesis of maximally permissive non-blocking supervisors for partially observed discrete event systems,"We present new results on the synthesis of safe, non-blocking, and maximally permissive supervisors for partially observed discrete event systems. We consider the case where the legal language is a non-prefix-closed sublanguage of the system language and non-blockingness must be ensured in addition to safety. Our approach is based on the construction of a new bipartite transition system, called the Non-blocking All Inclusive Controller (NB-AIC), that embeds all safe and non-blocking supervisors. We present an algorithm for the construction of the NB-AIC and discuss its properties. We then provide a synthesis algorithm, based on the NB-AIC, that constructs a supervisor that is safe, non-blocking and maximally permissive. This is the first algorithm with such properties.","Safety,
System recovery,
Automata,
Law,
Supervisory control,
Discrete-event systems"
Scene Text Recognition in Mobile Applications by Character Descriptor and Structure Configuration,"Text characters and strings in natural scene can provide valuable information for many applications. Extracting text directly from natural scene images or videos is a challenging task because of diverse text patterns and variant background interferences. This paper proposes a method of scene text recognition from detected text regions. In text detection, our previously proposed algorithms are applied to obtain text regions from scene image. First, we design a discriminative character descriptor by combining several state-of-the-art feature detectors and descriptors. Second, we model character structure at each character class by designing stroke configuration maps. Our algorithm design is compatible with the application of scene text extraction in smart mobile devices. An Android-based demo system is developed to show the effectiveness of our proposed method on scene text information extraction from nearby objects. The demo system also provides us some insight into algorithm design and performance improvement of scene text extraction. The evaluation results on benchmark data sets demonstrate that our proposed scheme of text recognition is comparable with the best existing methods.",
Shifting-and-Scaling Correlation Based Biclustering Algorithm,"The existence of various types of correlations among the expressions of a group of biologically significant genes poses challenges in developing effective methods of gene expression data analysis. The initial focus of computational biologists was to work with only absolute and shifting correlations. However, researchers have found that the ability to handle shifting-and-scaling correlation enables them to extract more biologically relevant and interesting patterns from gene microarray data. In this paper, we introduce an effective shifting-and-scaling correlation measure named Shifting and Scaling Similarity (SSSim), which can detect highly correlated gene pairs in any gene expression data. We also introduce a technique named Intensive Correlation Search (ICS) biclustering algorithm, which uses SSSim to extract biologically significant biclusters from a gene expression data set. The technique performs satisfactorily with a number of benchmarked gene expression data sets when evaluated in terms of functional categories in Gene Ontology database.","Correlation,
Gene expression,
Noise measurement,
Clustering algorithms,
Algorithm design and analysis"
"Evaluating Network Rigidity in Realistic Systems: Decentralization, Asynchronicity, and Parallelization","In this paper, we consider the problem of evaluating the rigidity of a planar network, while satisfying common objectives of real-world systems: decentralization, asynchronicity, and parallelization. The implications that rigidity has in fundamental multirobot problems, e.g., guaranteed formation stability and relative localizability, motivates this study. We propose the decentralization of the pebble game algorithm of Jacobs et al. , which is an O(n2) method that determines the generic rigidity of a planar network. Our decentralization is based on asynchronous messaging and distributed memory, coupled with auctions for electing leaders to arbitrate rigidity evaluation. Further, we provide a parallelization that takes inspiration from gossip algorithms to yield significantly reduced execution time and messaging. An analysis of the correctness, finite termination, and complexity is given, along with a simulated application in decentralized rigidity control. Finally, we provide Monte Carlo analysis in a Contiki networking environment, illustrating the real-world applicability of our methods, and yielding a bridge between rigidity theory and realistic interacting systems.","Games,
Algorithm design and analysis,
Jacobian matrices,
Robot sensing systems,
Clocks,
Complexity theory"
Optimal Odd-Length Binary Z-Complementary Pairs,"A pair of sequences is called a Golay complementary pair (GCP) if their aperiodic autocorrelation sums are zero for all out-of-phase time shifts. Existing known binary GCPs only have even-lengths in the form of 2α 10β 26γ (where \(α, β, γ) are nonnegative integers). To fill the gap left by the odd-lengths, we investigate the optimal odd-length binary (OB) pairs, which display the closest correlation property to that of GCPs. Our criteria of closeness is that each pair has the maximum possible zero-correlation zone (ZCZ) width and minimum possible out-of-zone aperiodic autocorrelation sums. Such optimal pairs are called optimal OB Z-complementary pairs (OB-ZCP) in this paper. We show that each optimal OB-ZCP has maximum ZCZ width of (N+1)/2, and minimum out-of-zone aperiodic sum magnitude of 2, where N denotes the sequence length (odd). Systematic constructions of such optimal OP-ZCPs are proposed by insertion and deletion of certain binary GCPs, which settle the 2011 Li-Fan-Tang-Tu open problem positively. The proposed optimal OB-ZCPs may serve as a replacement for GCPs in many engineering applications, where odd sequence lengths are preferred. In addition, they give rise to a new family of base-two almost difference families, which are useful in studying partially balanced incomplete block design.",
The Butterfly-Shaped Feedback Loop in Networked Control Systems for the Unknown Delay Compensation,"Available model-based networked control system (NCS) design approaches are basically formulated from the known system model and the information of the networked-induced delay time. Because the delay in remote control systems is significant and time-varied as commercial networks involved, available model-based NCS design approaches may thus become impractical. The increase of time delay due to the limited communication bandwidth usually induces data dropout to make NCS design even more difficult. In this paper, the scheme of the perfect delay compensation (PDC) is proposed by introducing the butterfly-shaped inner feedback loop in NCS to deal with the unknown network-induced time delay. Furthermore, analytical results indicate that the controller obtained in general control systems can be directly implemented on NCS with the proposed PDC scheme. Both simulation and experimental results were successfully carried out on an ac servo motor at a distance of 15 km through Ethernet to maintain a stable remote control system.",
Evaluation of the Cytotoxic Effects of PLGA Coated Iron Oxide Nanoparticles as a Carrier of 5- Fluorouracil and Mega-Voltage X-Ray Radiation in DU145 Prostate Cancer Cell Line,"The purpose of this study was to investigate the uptake and cytotoxic effects of magnetic poly lactic-co-glycolic acid (PLGA)-coated iron oxide nanoparticles as a carrier of 5-fluorouracil (5-FU) and X-ray on the level of proliferation capacity of DU145 prostate carcinoma cell line in monolayer culture. Following monolayer culture, DU 145 cells were treated with different concentrations of 5-FU or 5-FU loaded nanoparticles for 24 h and 2Gy X-ray (6 Mega-voltage (MV)). The rate of nanoparticles penetration was then measured using atomic adsorption spectroscopy (AAS). The cytotoxicity effect of these nanoparticles with/ without X-ray radiation was evaluated using colony formation assay. Spectroscopy results showed that iron content and therefore the cellular uptake of 5-FU loaded nanoparticles increased with increasing nanoparticle concentrations. Further, the proliferation capacity of the cells decreased with the increase of 5-FU and 5- FU loaded nanoparticle concentrations in combination with X-ray radiation. However the extent of reduction in colony number following treatment with 5-FU-loaded nanoparticles in combination with 2Gy of megavoltage X-ray radiation was significantly more than for free 5-FU. Thus, drug-loaded nanoparticles could deliver 5-FU more efficiently into the cells. PLGA coated iron oxide nanoparticles are therefore effective drug delivery vehicles for 5-FU. PLGA coated iron oxide nanoparticles are biocompatible and this coating is an appropriate surface that can penetrate into the cells.",
Enabling GLOSA for adaptive traffic lights,"Green Light Optimized Speed Advisory (GLOSA) systems aim at giving ideal target speed recommendations to the driver when approaching a traffic light to lower CO2 emissions (and fuel consumption) and to reduce the number of unnecessary stops. These systems have been shown to work well with static traffic light programs, unfortunately, a large portion of traffic lights in inner cities are adaptive and can change their behaviour with almost no lead time. This paper presents and validates (using field tests and simulation) a method to help overcome this problem and forecast fully and semi-adaptive traffic lights. First, we transformed the state graph of the traffic light controller into a transition graph focusing on signal changes and their occurrence probability. We then reduced routing possibilities within the graph using real life observations and recorded detector data of the traffic light. We further optimized our system in terms of needed storage and computationally efficiency. Our results show that in 80% of all cases we could predict signal changes 15s in the future with a high enough accuracy to enable GLOSA for adaptive traffic lights.","Detectors,
Vehicles,
Prognostics and health management,
Equations,
Probability,
Cities and towns,
Conferences"
Dynamic spectrum and core allocation with spectrum region reducing costs of building modules in AoD nodes,"In order to expand the transmission capacity of optical backbone networks, many innovative technologies such as Elastic Optical Network (EON) and Space Division Multiplexing (SDM) have intensively researched. These advanced network technologies require new optical node structures which can fully utilize the additional channels of the next-generation networks. Architecture on Demand (AoD) concept enables to construct flexible and scalable optical node structure by dynamically reconfiguring interconnections of building modules according to switching requests. Because resource allocation methods have impact on switching requests, the number and the types of building modules required for AoD nodes are dependent on not only traffic patterns but also spectrum allocations. In this paper, we propose spectrum and core allocation method based on spectrum region which is related with corresponding building modules of AoD nodes in Multi-Core Fiber Elastic Optical Networks (MCF-EONs). The proposed spectrum regions make two advantages. The one is reducing spectrum fragmentation which is an challenging issue in EONs. The other is replacing building modules of AoD nodes with simple and low-cost ones. Finally, we evaluate the proposed spectrum and core allocation method through computer simulations. The simulation results demonstrate that reducing spectrum fragmentation improves blocking probabilities and replacing building modules reduces modular costs of AoD nodes.","Resource management,
Optical fiber networks,
Buildings,
Optical switches,
Bandwidth,
Topology,
Optical fibers"
Coordinating Garbage Collectionfor Arrays of Solid-State Drives,"Although solid-state drives (SSDs) offer significant performance improvements over hard disk drives (HDDs) for a number of workloads, they can exhibit substantial variance in request latency and throughput as a result of garbage collection (GC). When GC conflicts with an I/O stream, the stream can make no forward progress until the GC cycle completes. GC cycles are scheduled by logic internal to the SSD based on several factors such as the pattern, frequency, and volume of write requests. When SSDs are used in a RAID with currently available technology, the lack of coordination of the SSD-local GC cycles amplifies this performance variance. We propose a global garbage collection (GGC) mechanism to improve response times and reduce performance variability for a RAID of SSDs. We include a high-level design of SSD-aware RAID controller and GGC-capable SSD devices and algorithms to coordinate the GGC cycles. We develop reactive and proactive GC coordination algorithms and evaluate their I/O performance and block erase counts for various workloads. Our simulations show that GC coordination by a reactive scheme improves average response time and reduces performance variability for a wide variety of enterprise workloads. For bursty, write-dominated workloads, response time was improved by 69 percent and performance variability was reduced by 71 percent. We show that a proactive GC coordination algorithm can further improve the I/O response times by up to 9 percent and the performance variability by up to 15 percent. We also observe that it could increase the lifetimes of SSDs with some workloads (e.g., Financial) by reducing the number of block erase counts by up to 79 percent relative to a reactive algorithm for write-dominant enterprise workloads.",
Virtual and Remote Industrial Laboratory: Integration in Learning Management Systems,"During the last few decades, many industrial remote and virtual laboratories have been designed and implemented at different universities and schools with the goal of providing online experiments that are remotely available to their students from anywhere and at any time. Research into virtual and remote laboratories has shown that the vast majority of these laboratories are built using learning tools and resources that are suited to a specific institution. Thus, different universities implement the software for their particular needs and consume a significant amount of time and energy in the process. This article describes a different approach: the design and implementation of a learning management system (LMS) activity that allows sharing of electronic, control and automation, and electrical remote laboratories from different universities within industrial courses without requiring the teacher to program a single line of code.","Remote laboratories,
Electronic learning,
Learning systems,
Remote laboratories,
Virtual environments,
Industries,
Education courses"
Formal modeling and verification of an enhanced variant of the IEEE 802.11 CSMA/CA protocol,"In this paper, we present a formal method for modeling and checking an enhanced version of the carrier sense multiple access with collision avoidance protocol related to the IEEE 802.11 MAC layer, which has been proposed as the standard protocol for wireless local area networks. We deal mainly with the distributed coordination function (DCF) procedure of this protocol throughout a sequence of transformation steps. First, we use the unified modeling language state machines to thoroughly capture the behavior of wireless stations implementing a DCF, and then translate them into the input language of the UPPAAL model checking tool, which is a network of communicating timed automata. Finally, we proceed by checking of some of the safety and liveness properties, such as deadlock-freedom, using this tool.","Protocols,
Unified modeling language,
Multiaccess communication,
Automata,
Wireless communication,
Wireless sensor networks,
IEEE 802.11 Standards"
PuLP: Scalable multi-objective multi-constraint partitioning for small-world networks,"We present PuLP, a parallel and memory-efficient graph partitioning method specifically designed to partition low-diameter networks with skewed degree distributions. Graph partitioning is an important Big Data problem because it impacts the execution time and energy efficiency of graph analytics on distributed-memory platforms. Partitioning determines the in-memory layout of a graph, which affects locality, intertask load balance, communication time, and overall memory utilization of graph analytics. A novel feature of our method PuLP (Partitioning using Label Propagation) is that it optimizes for multiple objective metrics simultaneously, while satisfying multiple partitioning constraints. Using our method, we are able to partition a web crawl with billions of edges on a single compute server in under a minute. For a collection of test graphs, we show that PuLP uses 8-39× less memory than state-of-the-art partitioners and is up to 14.5× faster, on average, than alternate approaches (with 16-way parallelism). We also achieve better partitioning quality results for the multi-objective scenario.","Partitioning algorithms,
Communities,
Heuristic algorithms,
Clustering algorithms,
Measurement,
Layout,
Memory management"
Highly Efficient Linear Regression Outsourcing to a Cloud,"With cloud computing and mobile computing becoming more and more popular, there are a lot potential applications for computation outsourcing to the cloud. This paper investigates the linear regression outsourcing problem, which is a quite common engineering task and employed in various applications, as a case study to find out the possible problems that need to be solved. We propose two protocols which can enable secure and efficient outsourcing of linear regression problems to the cloud. The protocols can protect the client's data privacy well and at the same time have good efficiency. We show all subtleties and the techniques in designing such protocols. The main idea to protect the privacy is employing some transformations to the original linear regression problem to get a new problem which is sent to the cloud; and then transforming the answer returned back from the cloud to get the true solution to the original problem. Experimental results validate the practical usability of our protocols.","Computer security,
Linear regression,
Outsourcing,
Data privacy,
Computational modeling,
Cloud computing"
Profit Incentive in Trading Nonexclusive Access on a Secondary Spectrum Market Through Contract Design,"In this paper, we formulate a contract design problem where a primary license holder wishes to profit from its excess spectrum capacity by selling it to potential secondary users/buyers. It needs to determine how to optimally price the excess spectrum so as to maximize its profit, knowing that this excess capacity is stochastic in nature, does not come with exclusive access, and cannot provide deterministic service guarantees to a buyer. At the same time, buyers are of different types, characterized by different communication needs, tolerance for the channel uncertainty, and so on, all of which are a buyer's private information. The license holder must then try to design different contracts catered to different types of buyers in order to maximize its profit. We address this problem by adopting as a reference a traditional spectrum market where the buyer can purchase exclusive access with fixed/deterministic guarantees. We fully characterize the optimal solution in the cases where there is a single buyer type, and when multiple types of buyers share the same known channel condition as a result of the primary user activity. In the most general case, we construct an algorithm that generates a set of contracts in a computationally efficient manner and show that this set is optimal when the buyer types satisfy a monotonicity condition.",
Performance Enhancements of Flip-Chip Light-Emitting Diodes With High-Density n-Type Point-Contacts,"Novel gallium nitride-based flip-chip light-emitting diodes (FCLEDs) with high-density distributed n-type point-contacts were designed and fabricated. With high density and uniformly distributed n-type point-contacts, the point-contact (PC) FCLEDs had higher light output power (LOP) by 18% over the reference flip-chip LED with conventional contacts fabricated from the same wafer. The forward voltage of the PC-FCLEDs was 0.16 V lower than the reference FCLED and the wall-plug efficiency was increased by 24% at the same current level. The maximum LOP of the PC-FCLEDs measured at 2.4 A was 43% more than the maximum obtained by the reference LED at 1.8 A. It was also found that the PC-FCLEDs suffered lower efficiency droop. The optical performance improvement of the PC-FCLEDs is attributed to an increase of the light extraction and the uniform carrier distribution, which results from the small and high density deeply etched holes and PCs. The electrical performance was enhanced through a minimized lateral current spreading distance.",
Generalized Efficiency Bounds in Distributed Resource Allocation,"Game theory is emerging as a popular tool for distributed control of multiagent systems. To take advantage of these game theoretic tools, the interactions of the autonomous agents must be designed within a game-theoretic environment. A central component of this game-theoretic design is the assignment of a local utility function to each agent. One promising approach to utility design is assigning each agent a utility function according to the agent's Shapley value. This method frequently results in games that possess many desirable features, such as the existence of pure Nash equilibria with near-optimal efficiency. In this paper, we explore the relationship between the Shapley value utility design and the resulting efficiency of both pure Nash equilibria and coarse correlated equilibria. To study this relationship, we introduce a simple class of resource allocation problems. Within this class, we derive an explicit relationship between the structure of the resource allocation problem and the efficiency of the resulting equilibria. Lastly, we derive a bicriteria bound for this class of resource allocation problems-a bound on the value of the optimal allocation relative to the value of an equilibrium allocation with additional agents.",
Firelight LED Source: Toward a Balanced Approach to the Performance of Solid-State Lighting for Outdoor Environments,"We report on a blue-amber (“firelight”) cluster of light-emitting diodes (LEDs) with extra-low correlated color temperature (~1860 K) optimized for outdoor lighting under mesopic conditions. When compared with common white LEDs, the firelight LED cluster shows considerably reduced indexes of melatonin suppression and skyglow, increased retinal illuminance for elderly people, but a reduced performance of perceiving colors, which, however, can be tolerated at mesopic luminance. In comparison with an almost metameric high-pressure sodium lamp, the cluster exhibits a potentially higher luminous efficacy, similar reaction time and detection threshold of luminance contrasts for achromatic targets, and noticeably improved color discrimination characteristics.","Light emitting diodes,
Color,
Lighting,
Image color analysis,
Indexes,
Phosphors"
An Efficient Approach for Outlier Detection with Imperfect Data Labels,"The task of outlier detection is to identify data objects that are markedly different from or inconsistent with the normal set of data. Most existing solutions typically build a model using the normal data and identify outliers that do not fit the represented model very well. However, in addition to normal data, there also exist limited negative examples or outliers in many applications, and data may be corrupted such that the outlier detection data is imperfectly labeled. These make outlier detection far more difficult than the traditional ones. This paper presents a novel outlier detection approach to address data with imperfect labels and incorporate limited abnormal examples into learning. To deal with data with imperfect labels, we introduce likelihood values for each input data which denote the degree of membership of an example toward the normal and abnormal classes respectively. Our proposed approach works in two steps. In the first step, we generate a pseudo training dataset by computing likelihood values of each example based on its local behavior. We present kernel
k
-means clustering method and kernel LOF-based method to compute the likelihood values. In the second step, we incorporate the generated likelihood values and limited abnormal examples into SVDD-based learning framework to build a more accurate classifier for global outlier detection. By integrating local and global outlier detection, our proposed method explicitly handles data with imperfect labels and enhances the performance of outlier detection. Extensive experiments on real life datasets have demonstrated that our proposed approaches can achieve a better tradeoff between detection rate and false alarm rate as compared to state-of-the-art outlier detection approaches.","Data models,
Kernel,
Computational modeling,
Training,
Support vector machines,
Training data,
Educational institutions"
Analyzing Implicit Social Networks in Multiplayer Online Games,"Understanding the social structures that people implicitly form when playing networked games helps developers create innovative gaming services to benefit both players and operators. But how can we extract and analyze this implicit social structure? The authors' proposed formalism suggests various ways to map interactions to social structure. Applying this formalism to real-world data collected from three game genres reveals the implications of the mappings on in-game and gaming-related services, ranging from network and socially aware player matchmaking to an investigation of social network robustness against player departure.",
A Configurable State Class Method for Temporal Analysis of Time Petri Nets,"A task' s end-to-end delay in its execution is a key requirement to real-time systems. This paper presents a configurable state class method based on time Petri nets for their quantitative analysis. The proposed method has a flexible state class structure. A firing domain is separated into a kernel domain that supports the basic evolution of state classes, and a configurable domain that is used to evaluate end-to-end delays. Since both domains adopt a uniform representation for time constraints, end-to-end delays can be computed synchronously with the evolution of state classes via the same firing rules. Firing rules are decomposed into basic timing operations. This treatment not only makes the calculation of end-to-end delays more flexible, but also provides a scalable way to add new timing operations into a time Petri net model. The proposed method computes arbitrary end-to-end delays along a trace with time O(ml2) and space O(l2), where m is the number of firing transitions along the trace and l is the maximum number of transitions in configurable and kernel domains. Compared with the existing state class methods, it has better performance and flexibility in on-the-fly computation of end-to-end delays.",
Scale-Limited Activating Sets and Multiperiodicity for Threshold-Linear Networks on Time Scales,"The existing results for multiperiodicity of threshold-linear networks (TLNs) are scale-free on time evolution and hence exhibit some restrictions. Due to the nature of the scale-limited activating set, it is interesting to study the dynamical properties of neurons on time scales. In this paper we analyze and obtain results concerning nondivergence, attractivity, and multiperiodic dynamics of TLNs on time scales. Using the notion of exponential functions on time scales, we obtain results for scale-limited type criteria for boundedness and global attractivity of TLNs. Moreover, by constructing simple algebraic inequalities over scale-limited activating sets, we achieve results regarding multiperiodicity of TLNs. This will show that each scale-limited activating set depends on scale-synchronous self-excitation, and the existence of inactive neurons will slow down convergence of TLNs. At the end of the paper, we perform computer simulations to illustrate the obtained new theories.","algebra,
neural nets,
set theory"
Offset Suppression in a Micromachined Lorentz Force Magnetic Sensor by Current Chopping,"We present a method to reduce offset in micromachined Lorentz force magnetic sensors by chopping the Lorentz force bias current. By switching the polarity of this current, the sensitivity of the magnetic sensor alternates its sign, whereas the offset remains the same. A residual offset of 31 μT is obtained from the initial offset of 25 mT. The proposed method significantly reduces the long-term drift of the magnetic sensor at the same time. A 9-h measurement shows the maximum drift error is reduced from ±500 μT to ±1 μT. Allan deviation measurements demonstrate that the longterm drift is reduced by a factor of 120. With 0.9 mArms bias current the white noise is 400 nT/rt-Hz, limited by the thermal-mechanical noise.","Magnetometers,
Magnetic sensors,
Noise,
Lorentz covariance,
Sensitivity,
Oscillators"
An analysis of LSB based image steganography techniques,"Steganography refers to information or a file that has been concealed inside a digital picture, video or audio file. If a person views the object in which the information is hidden inside, he or she will have no indication that there is any hidden information. So the person will not try to decrypt the information. Steganography can be divided into Text Steganography, Image Steganography, Audio/Video Steganography. Image Steganography is one of the common methods used for hiding the information in the cover image. LSB is very efficient algorithm used to embed the information in a cover file. This paper presents the detail knowledge about the LSB based image steganography and its applications to various file formats. In this paper we also analyze the available image based steganography along with cryptography technique to achieve security.","Cryptography,
Image color analysis,
Computers,
Computer science,
Informatics,
Art,
Gray-scale"
Modeling Energy Consumption of Data Transmission Over Wi-Fi,"Wireless data transmission consumes a significant part of the overall energy consumption of smartphones, due to the popularity of Internet applications. In this paper, we investigate the energy consumption characteristics of data transmission over Wi-Fi, focusing on the effect of Internet flow characteristics and network environment. We present deterministic models that describe the energy consumption of Wi-Fi data transmission with traffic burstiness, network performance metrics like throughput and retransmission rate, and parameters of the power saving mechanisms in use. Our models are practical because their inputs are easily available on mobile platforms without modifying low-level software or hardware components. We demonstrate the practice of model-based energy profiling on Maemo, Symbian, and Android phones, and evaluate the accuracy with physical power measurement of applications including file transfer, web browsing, video streaming, and instant messaging. Our experimental results show that our models are of adequate accuracy for energy profiling and are easy to apply.","IEEE 802.11 Standards,
Uplink,
Energy consumption,
Downlink,
Internet,
Power demand,
Hardware"
About the properties of the upper Bohl exponents of diagonal discrete linear time-varying systems,"One of the most important numerical characteristics of dynamical systems used in control theory are the Bohl exponents. By contrast with the Lyapunov characteristics, the properties of the Bohl exponents are much less investigated in the literature. In this paper, we show the example of two-dimensional discrete time-varying linear system with bounded coefficients for which the number of upper Bohl exponents of solutions may be greater than dimension of the system.","Linear systems,
Asymptotic stability,
Time-varying systems,
Differential equations,
Stability criteria,
Control systems"
SAGE2: A new approach for data intensive collaboration using Scalable Resolution Shared Displays,"Current web-based collaboration systems, such as Google Hangouts, WebEx, and Skype, primarily enable single users to work with remote collaborators through video conferencing and desktop mirroring. The original SAGE software, developed in 2004 and adopted at over one hundred international sites, was designed to enable groups to work in front of large shared displays in order to solve problems that required juxtaposing large volumes of information in ultra high-resolution. We have developed SAGE2, as a complete redesign and implementation of SAGE, using cloud-based and web browser technologies in order to enhance data intensive co-located and remote collaboration. This paper provides an overview of SAGE2's infrastructure, the technical design challenges, and the afforded benefits to data intensive collaboration. Lastly, we provide insight on how future collaborative applications can be developed to support large displays and demonstrate the power and flexibility that SAGE2 offers in collaborative scenarios through a series of use cases.","Collaboration,
Browsers,
Servers,
Rendering (computer graphics),
Real-time systems,
Synchronization"
Crowdsourcing swarm manipulation experiments: A massive online user study with large swarms of simple robots,"Micro- and nanorobotics have the potential to revolutionize many applications including targeted material delivery, assembly, and surgery. The same properties that promise breakthrough solutions - small size and large populations - present unique challenges to generating controlled motion. We want to use large swarms of robots to perform manipulation tasks; unfortunately, human-swarm interaction studies as conducted today are limited in sample size, are difficult to reproduce, and are prone to hardware failures. We present an alternative. This paper examines the perils, pitfalls, and possibilities we discovered by launching SwarmControl.net, an online game where players steer swarms of up to 500 robots to complete manipulation challenges. We record statistics from thousands of players, and use the game to explore aspects of large-population robot control. We present the game framework as a new, open-source tool for large-scale user experiments. Our results have potential applications in human control of micro- and nanorobots, supply insight for automatic controllers, and provide a template for large online robotic research experiments.","Robot sensing systems,
Servers,
Noise,
Sociology,
Statistics,
Browsers"
On Signaling-Free Failure Dependent Restoration in All-Optical Mesh Networks,"Failure dependent protection (FDP) is known to achieve optimal capacity efficiency among all types of protection, at the expense of longer recovery time and more complicated signaling overhead. This particularly hinders the usage of FDP in all-optical mesh networks. As a remedy, this paper investigates a new restoration framework that enables all-optical fault management and device configuration via state-of-the-art failure localization techniques, such as the FDP restoration process. It can be implemented without relying on any control plane signaling. With the proposed restoration framework, a novel spare capacity allocation problem is defined and is further analyzed on circulant topologies for any single link failure, aiming to gain a solid understanding of the problem. By allowing reuse of monitoring resources for restoration capacity, we are particularly interested in the monitoring resource hidden property, where less or even no monitoring resources are consumed as more working traffic is in place. To deal with general topologies, we introduce a novel heuristic approach to the proposed spare capacity allocation problem, which comprises a generic FDP survivable routing scheme followed by a novel monitoring resource allocation method. Extensive simulation is conducted to examine the proposed scheme and verify the proposed restoration framework.",
A Method to Estimate Biomechanics and Mechanical Properties of Optic Nerve Head Tissues From Parameters Measurable Using Optical Coherence Tomography,"Optic nerve head (ONH) tissue properties and biomechanics remain mostly unmeasurable in the experiment. We hypothesized that these can be estimated numerically from ocular parameters measurable in vivo with optical coherence tomography (OCT). Using parametric models representing human ONHs we simulated acute intraocular pressure (IOP) increases (10 mmHg). Statistical models were fit to predict, from OCT-measurable parameters, 15 outputs, including ONH tissue properties, stresses, and deformations. The calculations were repeated adding parameters that have recently been proposed as potentially measurable with OCT. We evaluated the sensitivity of the predictions to variations in the experimental parameters. Excellent fits were obtained to predict all outputs from the experimental parameters, with cross-validated R2s between 0.957 and 0.998. Incorporating the potentially measurable parameters improved fits significantly. Predictions of tissue stiffness were accurate to within 0.66 MPa for the sclera and 0.24 MPa for the lamina cribrosa. Predictions of strains and stresses were accurate to within 0.62% and 4.9 kPa, respectively. Estimates of ONH biomechanics and tissue properties can be obtained quickly from OCT measurements using an applet that we make freely available. These estimates may improve understanding of the eye sensitivity to IOP and assessment of patient risk for development or progression of glaucoma.","Biomechanics,
Stress,
Strain,
Irrigation,
Sensitivity,
Biomedical optical imaging"
Ridge body parts features for human pose estimation and recognition from RGB-D video data,"This paper addresses the issues of 3D human pose estimation, tracking and recognition from RGB-D video sequences using a generative structured framework. Most existing approaches focus on these issues using discriminative models. However, a discriminative model has certain drawbacks: a) it requires expensive training steps and large amount of training samples for covering inherently wide pose space, and (b) not suitable for real-time applications due to its slow algorithmic inferences. In this work, a real-time tracking system has been proposed for human pose recognition utilizing ridge body parts features. Initially, depth silhouettes extract ridge data inside the binary edges and initialize each body joints information using predefined pose. Then, body parts tracking incorporates appearance learning to handle occlusions and manage body joints features. Lastly, Support Vector Machine is used to recognize different poses. Experimental results demonstrate that the proposed method is reliable and efficient in recognizing human poses at different realistic scenes.","Feature extraction,
Joints,
Torso,
Support vector machines,
Estimation,
Training,
Data mining"
A fine-grained spatial cloaking scheme for privacy-aware users in Location-Based Services,"In Location-Based Services (LBSs) mobile users submit location-related queries to the untrusted LBS server to get service. However, such queries increasingly induce privacy concerns from mobile users. To address this problem, we propose FGcloak, a novel fine-grained spatial cloaking scheme for privacy-aware mobile users in LBSs. Based on a novel use of modified Hilbert Curve in a particular area, our scheme effectively guarantees k-anonymity and at the same time provides larger cloaking region. It also uses a parameter σ for users to make fine-grained control on the system overhead based on the resource constraints of mobile devices. Security analysis and empirical evaluation results verify the effectiveness and efficiency of our scheme.","Servers,
Privacy,
Mobile communication,
Standards,
Algorithm design and analysis,
Security,
Control systems"
Optimizing multi-copy two-hop routing in mobile social networks,"In this paper, an opportunistic multi-copy two-hop routing algorithm is proposed for mobile social networks (MSNs) to minimize the expected data delivery delay, using local information. For each source-destination pair, the source dynamically maintains a forwarding set consisting of relay nodes. The forwarding set selection is based on the number of remaining message copies, as well as the number and quality of relays that have not received a message copy. The source only forwards its message to the relay nodes in its forwarding set, which will in turn forward the message to the destination directly. We propose a greedy approach to select the forwarding set with n message copies at the source, in an MSN with m (m>n) relays. All forwarding sets can be determined with a time complexity of O(m log m+nm). Then, the proposed multi-copy two-hop routing algorithm is applied to a feature space routing scheme, where the contact frequencies are estimated by social feature distances. Finally, the competitive performance of the proposed schemes are shown in real trace-driven simulations.","Relays,
Routing,
Delays,
Frequency estimation,
Time complexity,
Conferences,
Sensors"
Depth map-based human activity tracking and recognition using body joints features and Self-Organized Map,"In this paper, we implement human activity tracking and recognition system utilizing body joints features using depth maps. During HAR settings, depth maps are processed to track human silhouettes by considering temporal continuity constraints of human motion information and compute centroids for each activity based on contour generation. In body joints features, depth silhouettes are computed first through geodesic distance to identify anatomical landmarks which produce joint points information from specific body parts. Then, body joints are processed to produce centroid distance features and key joints distance features. Finally, Self-Organized Map (SOM) is employed to train and recognize different human activities from the features. Experimental results show that body joints features achieved high recognition rate over the conventional features. The proposed system should be applicable as e-healthcare systems for monitoring elderly people, surveillance systems for observing pedestrian traffic areas and indoor environment systems which recognize activities of multiple users.","Joints,
Feature extraction,
Conferences,
Training,
Smart homes,
Legged locomotion"
SUM: Spectrum Utilization Maximization in Energy-Constrained Cooperative Cognitive Radio Networks,"Cooperative cognitive radio networks (CCRNs) enable secondary users (SUs) to access primary resource by cooperation with active primary users (PUs). For the cooperation-generated resource, existing schemes in CCRNs allocate the resource only to the relay SUs. However, this may lead to inefficient spectrum utilization, when the relay SUs have poor channel condition or little traffic load for their own secondary transmissions. In this paper, considering user diversity in secondary networks, we focus on network-level throughput optimization for secondary networks, by allowing all SUs to optimally share the cooperation-generated period. Besides, considering the energy constraint on SUs, we formulate the resource allocation problem from long-term perspective, to reflect the time-varying change of user diversity in channel condition, traffic load and energy amount. We present an online SUM scheme to solve the long-term optimization problem. Although a mixed-integer and non-convex problem is involved in the SUM scheme, we transform the problem into multiple convex subproblems, and then optimally solve it with low computational complexity. Extensive simulations show that the proposed SUM scheme significantly outperforms the existing schemes.","Relays,
Resource management,
Throughput,
Optimization,
Cognitive radio,
Energy consumption"
SDN-based Virtual Machine management for Cloud Data Centers,"Software-Defined Networking (SDN) is an emerging paradigm to logically centralize the network control plane and automate the configuration of individual network elements. At the same time, in Cloud Data Centers (DCs), even though network and server resources converge over the same infrastructure and typically under a single administrative entity, disjoint control mechanisms are used for their respective management. In this paper, we propose a unified server-network control mechanism for converged ICT environments. We present a SDN-based orchestration framework for live Virtual Machine (VM) management where server hypervisors exploit temporal network information to migrate VMs and minimize the network-wide communication cost of the resulting traffic dynamics. A prototype implementation is presented and Mininet is used to evaluate the impact of diverse orchestration algorithms.","Virtual machine monitors,
Servers,
Topology,
Network topology,
IP networks,
Resource management,
Control systems"
Topology-Aware Partial Virtual Cluster Mapping Algorithm on Shared Distributed Infrastructures,"Novel virtualized HPC centers provide isolated and configurable Virtual Clusters (VC) on shared distributed infrastructures as execution environments for parallel and distributed applications. These VCs are usually customized and deployed per job in runtime. Allocating physical resources for VC is known as Virtual Cluster Mapping (VCM) problem, which is a critical issue that affects both performance of the VC and resource utilization of the system. Most previous works treat all Virtual Machines (VMs) in a VC request equally. However, because sub-jobs in a parallel job usually perform different roles, the corresponding VMs in a VC that execute these sub-jobs respectively should have different levels of importance. Based on this argument, this paper introduces the concept of partial VC mapping in contrast to the full mapping methodology in the current literatures. To fulfill partial mapping, the important backbone communication structure of parallel job called Communication Skeleton (CS) is derived based on the network topology among virtual nodes. To generate the CS of a job, mechanisms for evaluating the importance of nodes are proposed. Eventually, a Topology-aware Partial Virtual Cluster Mapping algorithm (TOP-VCM) is proposed which is based on sub-graph isomorphism detection. TOP-VCM can fully satisfy the nodes/links requirements in CS to ensure the execution performance with only slight degradation of other trivial nodes/links to significantly reduce the mapping difficulty. Simulation results have shown that TOP-VCM has significantly improved the total revenue, the utilization of physical resources and the performance of mapping algorithm while satisfying the VC requirements.","Peer-to-peer computing,
Substrates,
Clustering algorithms,
Skeleton,
Topology,
Bandwidth,
Resource management"
A Robust Motion Detection Technique for Dynamic Environment Monitoring: A Framework for Grid-Based Monitoring of the Dynamic Environment,"The Bayesian occupancy filter (BOF) provides a framework for grid-based monitoring of the dynamic environment. It allows us to estimate dynamic grids, containing both information of occupancy and velocity. Clustering such grids then provides detection of the objects in the observed scene.","Vehicle dynamics,
Motion detection,
Robot sensing systems,
Dynamics,
Monitoring,
Bayes methods,
Autonomous vehicles,
Navigation"
Opportunistic Service Composition in Dynamic Ad Hoc Environments,"Mobile devices capture, process, and exchange sensory data about their operating environment making them attractive service providers for pervasive computing. Composing services from different devices supports context-aware applications for smart spaces. However, carrier mobility and participation autonomy cause frequent changes to the network and service topology and impose a high failure probability on composites. Decentralised composition solutions assign service providers at runtime to provide for flexibility and to avoid a single point of failure. However, existing solutions rely on a pre-established service overlay network and employ a conservative allocation strategy which limits their applicability for highly dynamic environments. This paper presents a novel service composition protocol that allocates and invokes service providers opportunistically to minimise the impact of topology changes and to reduce failure. The protocol supports service sequences and parallel service flows. Automated model checking verifies that the protocol does not deadlock and that it terminates in a valid end state after having allocated the correct number of service providers for all required sub-services. The results of the simulation-based evaluation demonstrate that the opportunistic approach generally reduces composition failure. At the same time, the evaluation reveals the protocol's limits with regard to composite complexity, network density, and service demand.","Mobile communication,
Synchronization,
Network topology,
Ad hoc networks,
Resource management,
Dynamic scheduling"
Microelectromechanical Relay and Logic Circuit Design for Zero Crowbar Current,"A compact microelectromechanical (MEM) switch design and associated family of logic gates, memory cells, and other basic very-large-scale integration (VLSI) digital circuit sub blocks are proposed to ensure zero crowbar current in addition to zero leakage current while minimizing mechanical delay. The circuit design methodology introduced in this paper also provides for lower device count and hence lower operating power consumption. A prototype of the MEM switch design is demonstrated.","Electrodes,
Switches,
Switching circuits,
Relays,
Logic gates,
Contacts,
Force"
GOST: A Geometric-Optical Model for Sloping Terrains,"GOST is a geometric-optical (GO) model for sloping terrains developed in this study based on the four-scale GO model, which simulates the bidirectional reflectance distribution function (BRDF) of forest canopies on flat surfaces. The four-scale GO model considers four scales of canopy architecture: tree groups, tree crowns, branches, and shoots. In order to make this model suitable for sloping terrains, the mathematical description for the projection of tree crowns on the ground has been modified to consider the fact that trees grow vertically rather than perpendicularly to sloping grounds. The simulated canopy gap fraction and the area ratios of the four scene components (sunlit foliage, sunlit background, shaded foliage, and shaded background) by GOST compare well with those simulated by 3-D virtual canopy computer modeling techniques for a hypothetical forest. GOST simulations show that the differences in area ratios of the four scene components between flat and sloping terrains can reach up to 50%-60% in the principal plane and about 30% in the perpendicular plane. Two case studies are conducted to compare modeled canopy reflectance with observations. One comparison is made against Landsat-5 Thematic Mapper (TM) reflectance, demonstrating the ability of GOST to model canopy reflectance variations with slope and aspect of the terrain. Another comparison is made against MODIS surface reflectance, showing that GOST with topographic consideration outperforms that without topographic consideration. These comparisons confirm the ability of GOST to model canopy reflectance on sloping terrains over a large range of view angles.",
Multiatlas Segmentation as Nonparametric Regression,"This paper proposes a novel theoretical framework to model and analyze the statistical characteristics of a wide range of segmentation methods that incorporate a database of label maps or atlases; such methods are termed as label fusion or multiatlas segmentation. We model these multiatlas segmentation problems as nonparametric regression problems in the high-dimensional space of image patches. We analyze the nonparametric estimator's convergence behavior that characterizes expected segmentation error as a function of the size of the multiatlas database. We show that this error has an analytic form involving several parameters that are fundamental to the specific segmentation problem (determined by the chosen anatomical structure, imaging modality, registration algorithm, and label-fusion algorithm). We describe how to estimate these parameters and show that several human anatomical structures exhibit the trends modeled analytically. We use these parameter estimates to optimize the regression estimator. We show that the expected error for large database sizes is well predicted by models learned on small databases. Thus, a few expert segmentations can help predict the database sizes required to keep the expected error below a specified tolerance level. Such cost-benefit analysis is crucial for deploying clinical multiatlas segmentation systems.","Image segmentation,
Databases,
Kernel,
Analytical models,
Anatomical structure,
Predictive models"
Multi-arm robotic swimming with octopus-inspired compliant web,"This paper presents an 8-arm compliant robot, able to propel itself underwater by movements of its arms, either alone or interconnected via a passively-compliant web. The robot is inspired by the morphology and outstanding locomotor capabilities of the octopus, and is fabricated primarily from compliant materials. This robotic swimmer is first investigated computationally via dynamical models capturing the arm and web compliance, and indicating the effect of various kinematic parameters of the system on its motion. The performance of the robotic prototype is, then, tested experimentally, to demonstrate this novel mode of underwater propulsion by combining various patterns of sculling movements of the arms and web. Speeds of 0.5 body lengths per second and propulsive forces of up to 10.5 N were achieved, with a cost of transport as low as 0.62.","Prototypes,
Manipulators,
Joints,
Computational modeling,
Propulsion,
Simulation"
Continuation-Based Pull-In and Lift-Off Simulation Algorithms for Microelectromechanical Devices,"The voltages at which microelectromechanical actuators and sensors become unstable, known as pull-in and lift-off voltages, are critical parameters in microelectromechanical systems (MEMS) design. The state-of-the-art MEMS simulators compute these parameters by simply sweeping the voltage, leading to either excessively large computational cost or to convergence failure near the pull-in or lift-off points. This paper proposes to simulate the behavior at pull-in and lift-off employing two continuation-based algorithms. The first algorithm appropriately adapts standard continuation methods, providing a complete set of static solutions. The second algorithm uses continuation to trace two kinds of curves and generates the sweep-up or sweep-down curves, which can provide more intuition for MEMS designers. The algorithms presented in this paper are robust and suitable for general-purpose industrial MEMS designs. Our algorithms have been implemented in a commercial MEMS/integrated circuits codesign tool, and their effectiveness is validated by comparisons against measurement data and the commercial finite-element/boundary-element (FEM/BEM) solver CoventorWare.","Micromechanical devices,
Algorithm design and analysis,
Mathematical model,
Computational modeling,
Stability analysis,
Solid modeling,
Standards"
Carbon Nanotubes Blowing New Life Into NP Dynamic CMOS Circuits,"Low-power, compact, and high-performance NP dynamic CMOS circuits are presented in this paper assuming a 16 nm carbon nanotube transistor technology. The performances of two-stage pipeline 32-bit carry lookahead adders are evaluated based on HSPICE simulation with the following four different implementations: silicon MOSFET (Si-MOSFET) domino logic, Si-MOSFET NP dynamic CMOS, carbon nanotube MOSFET (CN-MOSFET) domino logic, and CN-MOSFET NP dynamic CMOS. While providing similar propagation delay, the total area of CN-MOSFET NP dynamic CMOS adder is reduced by 35.53%, 77.96%, and 15.52% as compared to the Si-MOSFET domino, Si-MOSFET NP dynamic CMOS, and CN-MOSFET domino adders, respectively. Miniaturization of the CN-MOSFET NP dynamic CMOS circuit reduces the dynamic switching power consumption by 80.54%, 95.57%, and 25.66% as compared to the Si-MOSFET domino, Si-MOSFET NP dynamic CMOS, and CN-MOSFET domino circuits, respectively. Furthermore, the CN-MOSFET NP dynamic CMOS adder provides up to 99.98% savings in leakage power consumption as compared to the other adder circuits that are evaluated in this study.",
Improving the Accuracy of Automated GUI Testing for Embedded Systems,"Automated GUIs test application user interfaces and verify their functionalities. However, due to the uncertainty of runtime execution environments, the device under test (DUT) might not reproduce GUI operations on time, resulting in test failures. The Smart Phone Automated GUI (SPAG) avoids nondeterministic events by batching event sequences and directly reproducing them on the DUT. SPAG dynamically changes the timing of following operations so that all event sequences can be performed on time. Experiments conducted on an Acer Liquid smartphone comparing SPAG to MonkeyRunner showed that SPAG can maintain up to 99.5 percent accuracy.","Graphical user interfaces,
Smart phones,
Software quality,
Testing,
Runtime,
Computer science,
Software testing"
Schedulability analysis of Ethernet AVB switches,"Ethernet AVB is being actively considered by the automotive industry as a candidate for in-vehicle communication backbone. However, several questions pertaining to schedulability of hard real-time messages transmitted via such a switch remain unanswered. In this paper, we attempt to fill this void. We derive equations to perform worst-case response time analysis on Ethernet AVB switches by considering its credit-based shaping algorithm. Also, we propose several approaches to reduce the pessimism in the analysis to provide tighter bounds.",
PORTR: Pre-Operative and Post-Recurrence Brain Tumor Registration,"We propose a new method for deformable registration of pre-operative and post-recurrence brain MR scans of glioma patients. Performing this type of intra-subject registration is challenging as tumor, resection, recurrence, and edema cause large deformations, missing correspondences, and inconsistent intensity profiles between the scans. To address this challenging task, our method, called PORTR, explicitly accounts for pathological information. It segments tumor, resection cavity, and recurrence based on models specific to each scan. PORTR then uses the resulting maps to exclude pathological regions from the image-based correspondence term while simultaneously measuring the overlap between the aligned tumor and resection cavity. Embedded into a symmetric registration framework, we determine the optimal solution by taking advantage of both discrete and continuous search methods. We apply our method to scans of 24 glioma patients. Both quantitative and qualitative analysis of the results clearly show that our method is superior to other state-of-the-art approaches.","Tumors,
Pathology,
Image segmentation,
Cavity resonators,
Registers,
Sociology,
Statistics"
Improving Worst-Case Latency Analysis for Rate-Constrained Traffic in the Time-Triggered Ethernet Network,Traditional performance analysis models based on the network calculus approach are not fit for the time-triggered Ethernet (TTEthernet) network due to the porosity characteristic of timed-triggered (TT) traffic in the TT-schedule. This paper introduces the porosity concept into the arrival curve model of TT traffic and gives a general method for the worst-case end-to-end latency analysis of rate-constrained (RC) traffic. Experiments show that our models give tighter latency bounds than results from other already known models and may be used to guide the design of the TT-schedule.,
Intervention Tailoring in Augmented Cognition Systems for Elders With Dementia,"We present an approach for personalizing nonpharmacological interventions for people with dementia (PwD) using ontologies. We conducted two case studies to derive an ontological model to personalize the planning and execution of interventions to address problematic behaviors. The paper describes how the ontology was derived, and illustrates how it is used to tailor an ambient-assisted intervention system (AAIS) at two stages: first, to decide on the services that the AAIS will offer the PwD, and then to adapt these services at runtime using contextual information. The results of a deployment of an AAIS during 2 months in the home of a PwD, indicate that the AAIS successfully addressed some of the problematic behaviors exhibited by the PwD, helping to reduce the burden of the caregiver.","ambient intelligence,
cognition,
diseases,
geriatrics,
health care,
medical computing,
ontologies (artificial intelligence),
patient care"
Extending self-organizing network availability using genetic algorithm,"In this paper, we propose a novel method based on genetic algorithm for constructing the wireless sensor network to extend its functionality and availability. In our proposed method, the structure of the network is dynamically decided and the organization differs after each message transmission round. With the goal of optimizing the lifespan of the entire network, genetic algorithm is employed to search for the most suitable sensor nodes as the cluster heads to relay the messages to base station. Using the chosen cluster heads, sensor clusters are formed that minimize the total inner cluster node-to-cluster head distance. Compared with eight other methods, our experimental results demonstrated that our proposed method greatly extended the network life. The network life improvement rate with respect to the second best cases is in the range of 13% to 43.44%. In each transmission round, the remaining energy of sensor nodes are fairly even with some fluctuations. That is, as a consequence of our proposed method, the variance among remaining energy is quite low, which implies that the sensor nodes shared the burden of relaying messages and, hence, elongated the overall network life.","Base stations,
Wireless sensor networks,
Genetic algorithms,
Energy consumption,
Availability,
Biological cells,
Relays"
CSMMI: Class-Specific Maximization of Mutual Information for Action and Gesture Recognition,"In this paper, we propose a novel approach called class-specific maximization of mutual information (CSMMI) using a submodular method, which aims at learning a compact and discriminative dictionary for each class. Unlike traditional dictionary-based algorithms, which typically learn a shared dictionary for all of the classes, we unify the intraclass and interclass mutual information (MI) into an single objective function to optimize class-specific dictionary. The objective function has two aims: 1) maximizing the MI between dictionary items within a specific class (intrinsic structure) and 2) minimizing the MI between the dictionary items in a given class and those of the other classes (extrinsic structure). We significantly reduce the computational complexity of CSMMI by introducing an novel submodular method, which is one of the important contributions of this paper. This paper also contributes a state-of-the-art end-to-end system for action and gesture recognition incorporating CSMMI, with feature extraction, learning initial dictionary per each class by sparse coding, CSMMI via submodularity, and classification based on reconstruction errors. We performed extensive experiments on synthetic data and eight benchmark data sets. Our experimental results show that CSMMI outperforms shared dictionary methods and that our end-to-end system is competitive with other state-of-the-art approaches.","Dictionaries,
Feature extraction,
Linear programming,
Complexity theory,
Gesture recognition,
Entropy,
Histograms"
Local Coordinate Concept Factorization for Image Representation,"Learning sparse representation of high-dimensional data is a state-of-the-art method for modeling data. Matrix factorization-based techniques, such as nonnegative matrix factorization and concept factorization (CF), have shown great advantages in this area, especially useful for image representation. Both of them are linear learning problems and lead to a sparse representation of the images. However, the sparsity obtained by these methods does not always satisfy locality conditions. For example, the learned new basis vectors may be relatively far away from the original data. Thus, we may not be able to achieve the optimal performance when using the new representation for other learning tasks, such as classification and clustering. In this paper, we introduce a locality constraint into the traditional CF. By requiring the concepts (basis vectors) to be as close to the original data points as possible, each datum can be represented by a linear combination of only a few basis concepts. Thus, our method is able to achieve sparsity and locality simultaneously. We analyze the complexity of our novel algorithm and demonstrate the effectiveness in comparison with the state-of-the-art approaches through a set of evaluations based on realworld applications.","Vectors,
Linear programming,
Algorithm design and analysis,
Encoding,
Sparse matrices,
Approximation methods,
Data models"
Scalable Compression of Stream Cipher Encrypted Images Through Context-Adaptive Sampling,"This paper proposes a novel scalable compression method for stream cipher encrypted images, where stream cipher is used in the standard format. The bit stream in the base layer is produced by coding a series of nonoverlapping patches of the uniformly down-sampled version of the encrypted image. An off-line learning approach can be exploited to model the reconstruction error from pixel samples of the original image patch, based on the intrinsic relationship between the local complexity and the length of the compressed bit stream. This error model leads to a greedy strategy of adaptively selecting pixels to be coded in the enhancement layer. At the decoder side, an iterative, multiscale technique is developed to reconstruct the image from all the available pixel samples. Experimental results demonstrate that the proposed scheme outperforms the state-of-the-arts in terms of both rate-distortion performance and visual quality of the reconstructed images at low and medium rate regions.","Image coding,
Streaming media,
Image reconstruction,
Encoding,
Ciphers,
Encryption"
Influence in social networks: A unified model?,"Understanding how information flows in online social networks is of great importance. It is generally difficult to obtain accurate prediction results of cascades over such networks, therefore a variety of diffusion models have been proposed in the literature to simulate diffusion processes instead. We argue that such models require extensive simulation results to produce good estimates of future spreads. In this work, we take a complimentary approach. We present a generalized, analytical model of influence in social networks that captures social influence at various levels of granularity, ranging from pairwise influence, to local neighborhood, to the general population, and external events, therefore capturing the complex dynamics of human behavior. We demonstrate that our model can integrate a variety of diffusion models. Particularly, we show that commonly used diffusion models in social networks can be reduced to special cases of our model, by carefully defining their parameters. Our goal is to provide a closed-form expression to approximate the probability of infection for every node in an arbitrary, directed network at any time t. We quantitatively evaluate the approximation quality of our analytical solution as compared to numerous popular diffusion models on a real-world dataset and a series of synthetic graphs.",Computational modeling
Extending the Agile Development Process to Develop Acceptably Secure Software,"The agile software development approach makes developing secure software challenging. Existing approaches for extending the agile development process, which enables incremental and iterative software development, fall short of providing a method for efficiently ensuring the security of the software increments produced at the end of each iteration. This article (a) proposes a method for security reassurance of software increments and demonstrates it through a simple case study, (b) integrates security engineering activities into the agile software development process and uses the security reassurance method to ensure producing acceptably secure-by the business owner-software increments at the end of each iteration, and (c) discusses the compliance of the proposed method with the agile values and its ability to produce secure software increments.","Computer security,
Software development,
Variable speed drives,
Software assurance,
Logic gates,
Encoding"
Multi-task policy search for robotics,"Learning policies that generalize across multiple tasks is an important and challenging research topic in reinforcement learning and robotics. Training individual policies for every single potential task is often impractical, especially for continuous task variations, requiring more principled approaches to share and transfer knowledge among similar tasks. We present a novel approach for learning a nonlinear feedback policy that generalizes across multiple tasks. The key idea is to define a parametrized policy as a function of both the state and the task, which allows learning a single policy that generalizes across multiple known and unknown tasks. Applications of our novel approach to reinforcement and imitation learning in real-robot experiments are shown.",
A Phase-Leg Power Module Packaged With Optimized Planar Interconnections and Integrated Double-Sided Cooling,"A multilayer planar interconnection structure was used for the packaging of liquid-cooled automotive power modules. The power semiconductor switch dies are sandwiched between two symmetric substrates, providing planar electrical interconnections and insulation. Two minicoolers are directly bonded to the outside of these substrates, allowing double-sided, integrated cooling. The power switch dies are orientated in a face-up/face-down 3-D interconnection configuration to form a phase leg. The bonding areas between the dies and substrates, and the substrates and coolers are designed to use identical materials and are formed in one heating process. A special packaging process has been developed so that high-efficiency production can be implemented. Incorporating high-efficiency cooling and low-loss electrical interconnections allows dramatic improvements in systems' cost, and electrical conversion efficiency. These features are demonstrated in a planar bond-packaged prototype of a 200 A/1200 V phase-leg power module made of silicon (Si) insulated gate bipolar transistor and PiN diodes.","Multichip modules,
Cooling,
Electronic packaging thermal management,
Insulated gate bipolar transistors,
Inductance"
Real-Time Stochastic Optimization of Complex Energy Systems on High-Performance Computers,"A scalable approach computes in operationally-compatible time the energy dispatch under uncertainty for electrical power grid systems of realistic size with thousands of scenarios. The authors propose several algorithmic and implementation advances in their parallel solver PIPS-IPM for stochastic optimization problems. New developments include a novel, incomplete, augmented, multicore, sparse factorization implemented within the PARDISO linear solver and new multicore- and GPU-based dense matrix implementations. They show improvement on the interprocess communication on Cray XK7 and XC30 systems. PIPS-IPM is used to solve 24-hour horizon power grid problems with up to 1.95 billion decision variables and 1.94 billion constraints on Cray XK7 and Cray XC30, with observed parallel efficiencies and solution times within an operationally defined time interval. To the authors' knowledge, ""real-time""-compatible performance on a broad range of architectures for this class of problems hasn't been possible prior to this work.","High performance computing,
Power grids,
Linear systems,
Symmetric matrices,
Scalability,
Generators,
Multicore processing"
A 45nm 1.3GHz 16.7 double-precision GFLOPS/W RISC-V processor with vector accelerators,"A 64-bit dual-core RISC-V processor with vector accelerators has been fabricated in a 45nm SOI process. This is the first dual-core processor to implement the open-source RISC-V ISA designed at the University of California, Berkeley. In a standard 40nm process, the RISC-V scalar core scores 10% higher in DMIPS/MHz than the Cortex-A5, ARM's comparable single-issue in-order scalar core, and is 49% more area-efficient. To demonstrate the extensibility of the RISC-V ISA, we integrate a custom vector accelerator alongside each single-issue in-order scalar core. The vector accelerator is 1.8× more energy-efficient than the IBM Blue Gene/Q processor, and 2.6× more than the IBM Cell processor, both fabricated in the same process. The dual-core RISC-V processor achieves maximum clock frequency of 1.3GHz at 1.2V and peak energy efficiency of 16.7 double-precision GFLOPS/W at 0.65V with an area of 3mm2.","Vectors,
Rockets,
Random access memory,
Computer architecture,
Field programmable gate arrays,
Pipelines,
Hazards"
A model based development approach for building automation systems,"As of today, building automation systems are present in almost any commercial building. They perform climate control, lightning control, access control, surveillance, and quite a few other tasks. As a result of their evolutionary development, building automation systems are divided into separate silos of disciplines that are not well integrated with each other. As of today, a variety of communication protocols, data models and engineering approaches are used by different vendors. Existing standardized building automation protocols as BACnet or KNX allow integration of some disciplines on the communication level but fail to provide means for common description of devices, services and data on the semantic level. This means that building automation applications that span multiple disciplines require a high effort for development, engineering and maintenance. If devices from multiple vendors are integrated in one installation, a set of different engineering tools and vendor-specific knowledge is required. In the ITEA “Building as a Service” (BaaS) project we try to overcome these deficiencies and define a common way to develop, engineer, commission, operate and maintain building automation systems following a service oriented approach. The whole process will be supported by semantic models to reduce costs and time-to-market, which is a quite new approach. In this paper we will present the current state of the work with special regard to domain modeling and model driven processes that are currently being specified for the BaaS platform.","Semantics,
Building automation,
Data models,
Protocols,
Ontologies,
Domain specific languages"
A MATLAB based occupant driven dynamic model for predicting residential power demand,"This paper presents a MATLAB based dynamic model for predicting residential power demand. Markov chain based occupant behavior models developed using data gathered by the U.S. Census Bureau in the American Time Use Survey (ATUS) are used in conjunction with models of the most common residential loads to predict residential power demand on a one-second time scale. First, the methods utilized for the modeling of each residential load are presented. Next, an explanation of how these load models are combined with occupant behavior models to predict residential power demand is given. Simulation results showing the overall contribution of each load to the overall residential sector power demand are shown for both winter and summer cases. Finally, future work will involve the use of this high-resolution dynamic residential model to estimate the potential for demand response from residential loads.","Load modeling,
Power demand,
Mathematical model,
Water heating,
Atmospheric modeling,
Lighting,
Computational modeling"
Designing a disaster-resilient network with software defined networking,"With the wide deployment of network facilities and the increasing requirement of network reliability, the disruptive event like natural disaster, power outage or malicious attack has become a non-negligible threat to the current communication network. Such disruptive event can simultaneously destroy all devices in a specific geographical area and affect many network based applications for a long time. Hence, it is essential to build disaster-resilient network for future highly survivable communication services. In this paper, we focus on the integrated approach through the technique of software defined networking to mitigate disaster risks while cut down the investment and management costs. Our design consists of a sub-graph based proactive protection approach for fast rerouting at the network nodes and a splicing approach at the controller for effective post-disaster restoration. Such a systematic design is implemented in OpenFlow framework through the Mininet emulator and Nox controller. Numerical results show that our approach can achieve high reliability, fast recovery and low control overhead.","Topology,
Network topology,
Splicing,
Routing,
Ports (Computers),
Control systems,
Prototypes"
Cooperative Search of Multiple Unknown Transient Radio Sources Using Multiple Paired Mobile Robots,"We develop a localization method to enable a team of mobile robots to search for multiple unknown transient radio sources. Because of signal source anonymity, short transmission durations, and dynamic transmission patterns, robots cannot treat the radio sources as continuous radio beacons. Moreover, robots do not know the source transmission power and have limited sensing ranges. To cope with these challenges, we pair up robots and develop a cooperative sensing model using signal strength ratios from the paired robots. We formally prove that the joint conditional posterior probability of source locations for the m-robot team can be obtained by combining the pairwise joint posterior probabilities, which can be derived from signal strength ratios. Moreover, we propose a pairwise ridge walking algorithm (PRWA) to coordinate the robot pairs based on the clustering of high-probability regions and the minimization of local Shannon entropy. We have implemented and validated the algorithm under both the hardware-driven simulation and physical experiments. Experimental results show that the PRWA-based localization scheme consistently outperforms the other four heuristics.","Robot sensing systems,
Robot kinematics,
Planning,
Transient analysis,
Mobile robots"
Chroma Intra Prediction Based on Inter-Channel Correlation for HEVC,"In this paper, we investigate a new inter-channel coding mode called LM mode proposed for the next generation video coding standard called high efficiency video coding. This mode exploits inter-channel correlation using reconstructed luma to predict chroma linearly with parameters derived from neighboring reconstructed luma and chroma pixels at both encoder and decoder to avoid overhead signaling. In this paper, we analyze the LM mode and prove that the LM parameters for predicting original chroma and reconstructed chroma are statistically the same. We also analyze the error sensitivity of the LM parameters. We identify some LM mode problematic situations and propose three novel LM-like modes called LMA, LML, and LMO to address the situations. To limit the increase in complexity due to the LM-like modes, we propose some fast algorithms with the help of some new cost functions. We further identify some potentially-problematic conditions in the parameter estimation (including regression dilution problem) and introduce a novel model correction technique to detect and correct those conditions. Simulation results suggest that considerable BD-rate reduction can be achieved by the proposed LM-like modes and model correction technique. In addition, the performance gain of the two techniques appears to be essentially additive when combined.","Image color analysis,
Image reconstruction,
Correlation,
Image coding,
Video coding,
Encoding,
Standards"
CIVSched: A Communication-Aware Inter-VM Scheduling Technique for Decreased Network Latency between Co-Located VMs,"Server consolidation in cloud computing environments makes it possible for multiple servers or desktops to run on a single physical server for high resource utilization, low cost, and reduced energy consumption. However, the scheduler in the virtual machine monitor (VMM), such as Xen credit scheduler, is agnostic about the communication behavior between the guest operating systems (OS). The aforementioned behavior leads to increased network communication latency in consolidated environments. In particular, the CPU resources management has a critical impact on the network latency between co-located virtual machines (VMs) when there are CPUand I/O-intensive workloads running simultaneously. This paper presents the design and implementation of a communication-aware inter-VM scheduling (CIVSched) technique that takes into account the communication behavior between inter-VMs running on the same virtualization platform. The CIVSched technique inspects the network packets transmitted between local co-resident domains to identify the target VM and process that will receive the packets. Thereafter, the target VM and process are preferentially scheduled by the VMM and the guest OS. The cooperation of these two schedulers makes the network packets to be timely received by the target application. Experimental results on the Xen virtualization platform depict that the CIVSched technique can reduce the average response time of network traffic by approximately 19 percent for the highly consolidated environment, while keeping the inherent fairness of the VMM scheduler.","Servers,
Scheduling,
Virtualization,
Cloud computing,
Processor scheduling,
Resource management,
Virtual machine monitors"
Energy-efficient smart metering for green smart grid communication,"In a smart grid, smart meters are expected to be the key technology to support bi-directional information exchange between service providers and end-users. The on-growing demand of smart meters (residential customers and plug-in hybrid electric vehicles) would result in huge energy consumption, while communicating with the entities in the smart grid. Therefore, green wireless communication technologies are expected to help in reducing their impact on environment. Therefore, it is important to design energy-efficient schemes that can reduce CO2 emissions and cost-effective energy management in the smart grid. In this paper, an energy-efficient smart metering scheme is proposed - an effort towards minimizing the energy consumption by the smart meters for green smart grid communication. We incorporate the use of coalition game to form multiple coalitions among smart meters to communicate with the service provider. We show that there exists a stable condition of the coalitions for which the payoff values of the smart meters are maximized. The simulation results show that using the proposed approach, energy consumption by the smart meters can be reduced, which, in turn, would enable green wireless communication in the smart grid.","Smart meters,
Smart grids,
Energy consumption,
Green products,
Games,
Delays,
Air pollution"
Virtual holonomic constraint based direction following control of planar snake robots described by a simplified model,"This paper considers direction following control of planar snake robots for which the equations of motion are described based on a simplified model. In particular, we aim to regulate the orientation and the forward velocity of the robot to a constant vector, while guaranteeing the boundedness of the states of the controlled system. To this end, we first stabilize a constraint manifold for the fully-actuated body shape variables of the robot. The definition of the constraint manifold is inspired by the well-known reference joint angle trajectories which induce lateral undulatory motion for snake robots. Subsequently, we reduce the dynamics of the system to the invariant constraint manifold. Furthermore, we design two dynamic compensators which control the orientation and velocity of the robot on this manifold. Using numerical analysis and a formal stability proof, we show that the solutions of the dynamic compensators remain bounded. Numerical simulations are presented to validate the theoretical design.","Robot kinematics,
Joints,
Mobile robots,
Manifolds,
Mathematical model,
Shape"
An Explicit Shape-Constrained MRF-Based Contour Evolution Method for 2-D Medical Image Segmentation,"Image segmentation is, in general, an ill-posed problem and additional constraints need to be imposed in order to achieve the desired segmentation result. While segmenting organs in medical images, which is the topic of this paper, a significant amount of prior knowledge about the shape, appearance, and location of the organs is available that can be used to constrain the solution space of the segmentation problem. Among the various types of prior information, the incorporation of prior information about shape, in particular, is very challenging. In this paper, we present an explicit shape-constrained MAP-MRF-based contour evolution method for the segmentation of organs in 2-D medical images. Specifically, we represent the segmentation contour explicitly as a chain of control points. We then cast the segmentation problem as a contour evolution problem, wherein the evolution of the contour is performed by iteratively solving a MAP-MRF labeling problem. The evolution of the contour is governed by three types of prior information, namely: (i) appearance prior, (ii) boundary-edgeness prior, and (iii) shape prior, each of which is incorporated as clique potentials into the MAP-MRF problem. We use the master-slave dual decomposition framework to solve the MAP-MRF labeling problem in each iteration. In our experiments, we demonstrate the application of the proposed method to the challenging problem of heart segmentation in non-contrast computed tomography data.","cardiology,
computerised tomography,
image segmentation,
medical image processing"
Single-Trial EEG Classification Using Logistic Regression Based on Ensemble Synchronization,"In this paper, we propose an ensemble synchronization measure across all EEG channel pairs of a cluster based on Frobenius norm of the phase synchronization matrix, in a 0-1 scale enabling a direct comparison between clusters with different number of channels. Using this metric, we studied the intrahemispheric EEG synchronization in the lower gamma band (30-40 Hz) during 1229 single trials of an audio-visual integration cross modal task (CMT) recorded from five patients with schizophrenia and five healthy control subjects. Using ensemble synchronization measure and response latency of single trials recorded during the CMT as features for logistic regression, we could classify each single trial of EEG as belonging to a patient with schizophrenia or a healthy control subject with 73% accuracy, with an area under receiver operating characteristics curve of 0.83. We also propose a likelihood rating to denote the possibility of a subject belonging to the schizophrenia group.","Synchronization,
Electroencephalography,
Accuracy,
Informatics,
Visualization,
Training"
Cosimulation of Electromagnetics-Circuit Systems Exploiting DGTD and MNA,"A hybrid electromagnetics (EM)-circuit simulator exploiting the discontinuous Galerkin time domain (DGTD) method and the modified nodal analysis (MNA) algorithm is developed for analyzing hybrid distributive and nonlinear multiport lumped circuit systems. The computational domain is split into two subsystems. One is the EM subsystem that is analyzed by DGTD, while the other is the circuit subsystem that is solved by the MNA method. The coupling between the EM and circuit subsystems is enforced at the lumped port where related field and circuit unknowns are coupled via the use of numerical flux, port voltages, and current sources. Since the spatial operations of DGTD are localized, thanks to the use of numerical flux, coupling matrices between EM and circuit subsystems are small and are directly inverted. To handle nonlinear devices within the circuit subsystem, the standard Newton-Raphson method is applied to the nonlinear coupling matrix system. In addition, a local time-stepping scheme is applied to improve the efficiency of the hybrid solver. Numerical examples including single and multiport linear/nonlinear circuit networks are presented to validate the proposed solver.","Ports (Computers),
Circuit subsystems,
Mathematical model,
Time-domain analysis,
Integrated circuit modeling,
Couplings,
Equations"
Model-Resolution-Based Basis Pursuit Deconvolution Improves Diffuse Optical Tomographic Imaging,"The image reconstruction problem encountered in diffuse optical tomographic imaging is ill-posed in nature, necessitating the usage of regularization to result in stable solutions. This regularization also results in loss of resolution in the reconstructed images. A frame work, that is attributed by model-resolution, to improve the reconstructed image characteristics using the basis pursuit deconvolution method is proposed here. The proposed method performs this deconvolution as an additional step in the image reconstruction scheme. It is shown, both in numerical and experimental gelatin phantom cases, that the proposed method yields better recovery of the target shapes compared to traditional method, without the loss of quantitativeness of the results.","Image reconstruction,
Optical imaging,
Deconvolution,
Optical scattering,
Jacobian matrices,
Biomedical optical imaging,
Tomography"
Decentralized cooperative trajectory estimation for autonomous underwater vehicles,"Autonomous agents that can communicate and make relative measurements of each other can improve their collective localization accuracies. This is referred to as cooperative localization (CL). Autonomous underwater vehicle (AUV) CL is constrained by the low throughput, high latency, and unreliability of of the acoustic channel used to communicate when submerged. Here we propose a CL algorithm specifically designed for full trajectory, or maximum a posteriori, estimation for AUVs. The method is exact and has the advantage that the broadcast packet sizes increase only linearly with the number of AUVs in the collective and do not grow at all in the case of packet loss. The approach allows for AUV missions to be achieved more efficiently since: 1) vehicles waste less time surfacing for GPS fixes, and 2) payload data is more accurately localized through the smoothing approach.","Vehicles,
Acoustics,
Trajectory,
Estimation,
Acoustic measurements,
Global Positioning System,
Time measurement"
Example of a Complementary Use of Model Checking and Human Performance Simulation,"Aircraft automation designers are faced with the challenge to develop and improve automation such that it is transparent to the pilots using it. To identify problems that may arise between pilots and automation, methods are needed that can uncover potential problems with automation early in the design process. In this paper, simulation and model checking are combined and their respective advantages leveraged to find problematic human-automation interaction using methods that would be available early in the design process. A particular problem of interest is automation surprises, which describe events when pilots are surprised by the actions of the automation. The Tarom flight 381 incident involving the former Airbus automatic speed protection logic, leading to an automation surprise, is used as a common case study. Results of this case study indicate that both methods identified the automation surprise found in the Tarom flight 381 incident, and that the simulation identified additional automation surprises associated with that flight logic. The work shows that the methods can be symbiotically combined, and the joint method is suitable to identify problematic human-automation interaction such as automation surprise.","Automation,
Atmospheric modeling,
Aircraft,
Model checking,
Analytical models,
Mathematical model,
Cognitive science"
Automatic Myonuclear Detection in Isolated Single Muscle Fibers Using Robust Ellipse Fitting and Sparse Representation,"Accurate and robust detection of myonuclei in isolated single muscle fibers is required to calculate myonuclear domain size. However, this task is challenging because: 1) shape and size variations of the nuclei, 2) overlapping nuclear clumps, and 3) multiple z-stack images with out-of-focus regions. In this paper, we have proposed a novel automatic detection algorithm to robustly quantify myonuclei in isolated single skeletal muscle fibers. The original z-stack images are first converted into one all-in-focus image using multi-focus image fusion. A sufficient number of ellipse fitting hypotheses are then generated from the myonuclei contour segments using heteroscedastic errors-in-variables (HEIV) regression. A set of representative training samples and a set of discriminative features are selected by a two-stage sparse model. The selected samples with representative features are utilized to train a classifier to select the best candidates. A modified inner geodesic distance based mean-shift clustering algorithm is used to produce the final nuclei detection results. The proposed method was extensively tested using 42 sets of z-stack images containing over 1,500 myonuclei. The method demonstrates excellent results that are better than current state-of-the-art approaches.",
Detecting movement intent from scalp EEG in a novel upper limb robotic rehabilitation system for stroke,"Stroke can be a source of significant upper extremity dysfunction and affect the quality of life (QoL) in survivors. In this context, novel rehabilitation approaches employing robotic rehabilitation devices combined with brain-machine interfaces can greatly help in expediting functional recovery in these individuals by actively engaging the user during therapy. However, optimal training conditions and parameters for these novel therapeutic systems are still unknown. Here, we present preliminary findings demonstrating successful movement intent detection from scalp electroencephalography (EEG) during robotic rehabilitation using the MAHI Exo-II in an individual with hemiparesis following stroke. These findings have strong clinical implications for the development of closed-loop brain-machine interfaces to robotic rehabilitation systems.",
The Bounded Capacity of Fuzzy Neural Networks (FNNs) Via a New Fully Connected Neural Fuzzy Inference System (F-CONFIS) With Its Applications,"In this paper, a fuzzy neural network (FNN) is transformed into an equivalent three-layer fully connected neural inference system (F-CONFIS). This F-CONFIS is a new type of a neural network whose links are with dependent and repeated weights between the input layer and hidden layer. For these special dependent repeated links of the F-CONFIS, some special properties are revealed. A new learning algorithm with these special properties is proposed in this paper for the F-CONFIS. The F-CONFIS is therefore applied for finding the capacity of the FNN. The lower bound and upper bound of the capacity of the FNN can be found from a new theorem proposed in this paper. Several examples are illustrated with satisfactory simulation results for the capacity of the F-CONFIS (or the FNN). These include “within capacity training of the FNN,” “over capacity training of the FNN,” “training by increasing the capacity of the FNN,” and “impact of the capacity of the FNN in clustering Iris Data.” It is noted that the finding of the capacity of the F-CONFIS, or FNN, has its emerging values in all engineering applications using fuzzy neural networks. This is to say that all engineering applications using FNN should not exceed the capacity of the FNN to avoid unexpected results. The clustering of Iris data using FNN illustrated in this paper is one of the most relevant engineering applications in this regards.",
Audio Matters in Visual Attention,"There is a dearth of information on how perceived auditory information guides image-viewing behavior. To investigate auditory-driven visual attention, we first generated a human eye-fixation database from a pool of 200 static images and 400 image-audio pairs viewed by 48 subjects. The eye tracking data for the image-audio pairs were captured while participants viewed images, which took place immediately after exposure to coherent/incoherent audio samples. The database was analyzed in terms of time to first fixation, fixation durations on the target object, entropy, AUC, and saliency ratio. It was found that coherent audio information is an important cue for enhancing the feature-specific response to the target object. Conversely, incoherent audio information attenuates this response. Finally, a system predicting the image-viewing with the influence of different audio sources was developed. The detailedly discussed top-down module in the system is composed of auditory estimation based on Gaussian mixture model-maximum a posteriori algorithm-universal background model structure, as well as visual estimation based on the conditional random field model and sparse latent variables. The evaluation experiments show that the proposed models in the system exhibit strong consistency with eye fixations.","Visualization,
Entropy,
Object oriented modeling,
Tracking,
Computational modeling,
Educational institutions,
Motorcycles"
Efficient and Effective Hierarchical Feature Propagation,"Many methods have been recently proposed to deal with the large amount of data provided by the new remote sensing technologies. Several of those methods rely on the use of segmented regions. However, a common issue in region-based applications is the definition of the appropriate representation scale of the data, a problem usually addressed by exploiting multiple scales of segmentation. The use of multiple scales, however, raises new challenges related to the definition of effective and efficient mechanisms for extracting features. In this paper, we address the problem of extracting features from a hierarchy by proposing two approaches that exploit the existing relationships among regions at different scales. The H-Propagation propagates any histogram-based low-level descriptors. The bag-of-visual-word (BoW)-Propagation approach uses the BoWs model to propagate features along multiple scales. The proposed methods are very efficient, as features need to be extracted only at the base of the hierarchy and yield comparable results to low-level extraction approaches.","Feature extraction,
Visualization,
Dictionaries,
Histograms,
Image segmentation,
Remote sensing,
Encoding"
Evolution-in-materio: Solving function optimization problems using materials,"Evolution-in-materio (EIM) is a method that uses artificial evolution to exploit properties of materials to solve computational problems without requiring a detailed understanding of such properties. In this paper, we show that using a purpose-built hardware platform called Mecobo, it is possible to evolve voltages and signals applied to physical materials to solve computational problems. We demonstrate for the first time that this methodology can be applied to function optimization. We evaluate the approach on 23 function optimization benchmarks and in some cases results come very close to the global optimum or even surpass those provided by a well-known software-based evolutionary approach. This indicates that EIM has promise and further investigations would be fruitful.","Materials,
Electrodes,
Optimization,
Hardware,
Biological cells,
Benchmark testing,
Arrays"
A Discriminative Structural Similarity Measure and its Application to Video-Volume Registration for Endoscope Three-Dimensional Motion Tracking,"Endoscope 3-D motion tracking, which seeks to synchronize preand intra-operative images in endoscopic interventions, is usually performed as video-volume registration that optimizes the similarity between endoscopic video and pre-operative images. The tracking performance, in turn, depends significantly on whether a similarity measure can successfully characterize the difference between video sequences and volume rendering images driven by pre-operative images. The paper proposes a discriminative structural similarity measure, which uses the degradation of structural information and takes image correlation or structure, luminance, and contrast into consideration, to boost video-volume registration. By applying the proposed similarity measure to endoscope tracking, it was demonstrated to be more accurate and robust than several available similarity measures, e.g., local normalized cross correlation, normalized mutual information, modified mean square error, or normalized sum squared difference. Based on clinical data evaluation, the tracking error was reduced significantly from at least 14.6 mm to 4.5 mm. The processing time was accelerated more than 30 frames per second using graphics processing unit.","Computed tomography,
Endoscopes,
Tracking,
Cameras,
Current measurement,
Rendering (computer graphics),
Decision support systems"
A tale of two clouds: Computing on data encrypted under multiple keys,"Cloud computing provides a convenient platform for big data computation such as machine learning and data mining. However, privacy conscious users often encrypt their data with their own keys before uploading them to the cloud. Existing techniques for computation on encrypted data are either in the single key setting or far from practical. In this paper, we show how two non-colluding servers can leverage proxy re-encryption to jointly compute arithmetic functions over the ciphertexts of multiple users without learning the inputs, intermediate or final results. Moreover, the computation is non-interactive to users and only requires minimal server-to-server interactions. Experimental results demonstrate that our schemes significantly improve the efficiency of outsourced computation when compared to the existing approach.","Servers,
Ash,
Encryption,
Computational modeling,
Public key"
Learning parameterized motor skills on a humanoid robot,"We demonstrate a sample-efficient method for constructing reusable parameterized skills that can solve families of related motor tasks. Our method uses learned policies to analyze the policy space topology and learn a set of regression models which, given a novel task, appropriately parameterizes an underlying low-level controller. By identifying the disjoint charts that compose the policy manifold, the method can separately model the qualitatively different sub-skills required for solving distinct classes of tasks. Such sub-skills are useful because they can be treated as new discrete, specialized actions by higher-level planning processes. We also propose a method for reusing seemingly unsuccessful policies as additional, valid training samples for synthesizing the skill, thus accelerating learning. We evaluate our method on a humanoid iCub robot tasked with learning to accurately throw plastic balls at parameterized target locations.","Training,
Manifolds,
Vectors,
Robot kinematics,
Torso,
Topology"
Building a machine learning classifier for malware detection,"Current signature-based antivirus software is ineffective against many modern malicious software threats. Machine learning methods can be used to create more effective antimalware software, capable of detecting even zero-day attacks. Some studies have investigated the plausibility of applying machine learning to malware detection, primarily using features from n-grams of an executables file's byte code. We propose an approach that primarily learns from metadata, mostly contained in the headers of executable files, specifically the Windows Portable Executable 32-bit (PE32) file format. Our experiments indicate that executable file metadata is highly discriminative between malware and benign software. We also employ various machine learning methods, finding that Decision Tree classifiers outperform Logistic Regression and Naive Bayes in this setting. We analyze various features of the PE32 header and identify those most suitable for machine learning classifiers. Finally, we evaluate changes in classifier performance when the malware prevalence (fraction of malware versus benign software) is varied.","Malware,
Software,
Training,
Databases,
Decision trees,
Feature extraction,
Logistics"
Comparison of Silica and Sapphire Fiber SERS Probes Fabricated by a Femtosecond Laser,"Different types of fibers were compared for construction of reflection-based surface-enhanced Raman-scattering (SERS) fiber probes. The probes were made by direct femtosecond (fs) laser micromachining of nanometer structures on the fiber endface and subsequent chemical plating of a thin layer of silver. Rhodamine 6G solutions were used to evaluate the performance of the SERS probes. In comparison with the silica fibers, the single-crystal sapphire fiber has much lower background Raman scattering. The fs laser is found effective to fabricate high-quality sapphire fiber SERS probes for detection of weak Raman signals in a reflection configuration.","Optical fibers,
Probes,
Optical fiber sensors,
Fiber lasers,
Raman scattering,
Optical fiber LAN,
Silicon compounds"
Local descriptors to improve off-line handwriting-based gender prediction,"Gender prediction based on the handwritten text becomes to earn a considerable importance for the document analysis community Gender prediction based on the handwritten text becomes to earn a considerable importance for the document analysis community. It is helpful for person identification as well as in some situations where one needs to classify population according to women-men categories. However, only a few studies have been carried out in this field. In the present work, we propose the use of local descriptors in order to improve the gender classification based on offline handwritten text. Specifically, we employ Histogram of Oriented Gradients (HOG), Local Binary Patterns (LBP) as well as grid features, which are successful in various pattern recognition applications. The prediction task is achieved by SVM classifier. The results obtained on samples extracted from IAM dataset show that local descriptors provide quite promising results.",
Design of a Multichannel Low-Noise Front-End Readout ASIC Dedicated to CZT Detectors for PET Imaging,"In this paper, we present the design and preliminary results of a novel low-noise front-end readout application-specific integrated circuit (ASIC) for a PET imaging system whose objective is to achieve the following performances: the spatial resolution of 1 mm3, the detection efficiency of 15% and the time resolution of 1 ns. A cascode amplifier based on the PMOS input transistor is selected to realize the charge-sensitive amplifier (CSA) for the sake of good noise performances. The output of the CSA is split into two branches. One is connected to a slow shaper for energy measurements. The other is connected to a fast shaper for time acquisition. A novel monostable circuits is designed to adjust the time delay of the trigger signals so that the peak value of the shaped voltages can be sampled and stored. An eight-channel front-end readout prototype chip is designed and implemented in 0.35 μm CMOS process. The die size is 2.286 mm ×2.282 mm. The input range of the ASIC is from 2000 e- to 180000 e-, reflecting to the energy level of the gamma ray from 11.2 keV to 1 MeV. The gain of the readout channel is 65 mV/fC. The tested result of ENC is 86.5 e- at zero farad plus 9.3 e- per picofarad. The nonlinearity is less than 3%. The crosstalk is less than 2%. The power dissipation is about 3 mW/channel.","Detectors,
Noise,
Application specific integrated circuits,
Positron emission tomography,
Resistors,
Energy resolution"
Using U-Shaped Localized Surface Plasmon Resonance Sensors to Compensate for Nonspecific Interactions,We report a simple label-free localized surface plasmon resonance sensor that uses the multiple resonances of a U-shaped gold nanostructure to differentiate the target interaction of interest from background refractive index interference and nonspecific binding of interfering molecules. U-shaped nanostructures were fabricated using electron-beam lithography and their sensing capabilities were tested by introducing different solutions to simulate various specific and nonspecific effects. The three resonances of the nanostructure yield distinct bulk as well as specific and nonspecific surface sensitivities that allow for the differentiation of the three effects.,
Semiquantitative Group Testing,"We propose a novel group testing method, termed semiquantitative group testing (SQGT), motivated by a class of problems arising in genome screening experiments. The SQGT is a (possibly) nonbinary pooling scheme that may be viewed as a concatenation of an adder channel and an integer-valued quantizer. In its full generality, SQGT may be viewed as a unifying framework for group testing, in the sense that most group testing models are special instances of SQGT. For the new testing scheme, we define the notion of SQ-disjunct and SQ-separable codes, representing generalizations of classical disjunct and separable codes. We describe several combinatorial and probabilistic constructions for such codes. While for most of these constructions, we assume that the number of defectives is much smaller than total number of test subjects, we also consider the case in which there is no restriction on the number of defectives and they may be as large as the total number of subjects. For the codes constructed in this paper, we describe a number of efficient decoding algorithms. In addition, we describe a belief propagation decoder for sparse SQGT codes for which no other efficient decoder is currently known.",
Evolutionary clustering algorithm for community detection using graph-based information,"The problem of community detection has become highly relevant due to the growing interest in social networks. The information contained in a social network is often represented as a graph. The idea of graph partitioning of graph theory can be apply to split a graph into node groups based on its topology information. In this paper the problem of detecting communities within a social network is handled applying graph clustering algorithms based on this idea. The new approach proposed is based on a genetic algorithm. A new fitness function has been designed to guide the clustering process combining different measures of network topology (Density, Centralization, Heterogeneity, Neighbourhood, Clustering Coefficient). These different network measures have been experimentally tested using a real-world social network. Experimental results show that the proposed approach is able to detect communities and the results obtained in previous work have been improved.",
Double Trouble: Differentiating Identical Twins by Face Recognition,"Facial recognition algorithms should be able to operate even when similar-looking individuals are encountered, or even in the extreme case of identical twins. An experimental data set comprised of 17486 images from 126 pairs of identical twins (252 subjects) collected on the same day and 6864 images from 120 pairs of identical twins (240 subjects) with images taken a year later was used to measure the performance on seven different face recognition algorithms. Performance is reported for variations in illumination, expression, gender, and age for both the same day and cross-year image sets. Regardless of the conditions of image acquisition, distinguishing identical twins are significantly harder than distinguishing subjects who are not identical twins for all algorithms.","Face recognition,
Lighting,
Face,
Cameras,
Sociology,
Statistics,
Algorithm design and analysis"
NovoHCD: De novo Peptide Sequencing From HCD Spectra,"In recent years, de novo peptide sequencing from mass spectrometry data has developed as one of the major peptide identification methods with the emergence of new instruments and advanced computational methods. However, there are still limitations to this method; for example, the typically used spectrum graph model cannot represent all the information and relationships inherent in tandem mass spectra (MS/MS spectra). Here, we present a new method named NovoHCD which applies a spectrum graph model with multiple types of edges (called a multi-edge graph), and integrates into it amino acid combination (AAC) information and peptide tags. In addition, information on immonium ions observed particularly in higher-energy collisional dissociation (HCD) spectra is incorporated. Comparisons between NovoHCD and another successful de novo peptide sequencing method for HCD spectra, pNovo, were performed. Experiments were conducted on five HCD spectral datasets. Results show that NovoHCD outperforms pNovo in terms of full length peptide identification accuracy; specifically, the accuracy increases 13%-21% over the five datasets.","Peptides,
Ions,
Amino acids,
Sequential analysis,
Databases,
Nanobioscience,
Computational modeling"
Towards training-free appearance-based localization: Probabilistic models for whole-image descriptors,"Whole image descriptors have been shown to be remarkably robust to perceptual change especially compared to local features. However, whole-image-based localization systems typically rely on heuristic methods for determining appropriate matching thresholds in a particular environment. These environment-specific tuning requirements and the lack of a meaningful interpretation of arbitrary thresholds limit the general applicability of these systems. In this paper we present a Bayesian model of probability for whole-image descriptors that can be seamlessly integrated into localization systems designed for probabilistic visual input. We demonstrate this method using CAT-Graph, an appearance-based visual localization system originally designed for a FAB-MAP-style probabilistic input. We show that using whole-image descriptors as visual input extends CAT-Graph's functionality to environments that experience a greater amount of perceptual change. We also present a method of estimating whole-image probability models in an online manner, removing the need for a prior training phase. We show that this online, automated training method can perform comparably to pre-trained, manually tuned local descriptor methods.",
Stochastic Stability of Switched Genetic Regulatory Networks With Time-Varying Delays,"This paper investigates the exponential stability problem of switched stochastic genetic regulatory networks (GRNs) with time-varying delays. Two types of switched systems are studied respectively: one is the stochastic switched delayed GRNs with only stable subsystems and the other is the stochastic switched delayed GRNs with both stable and unstable subsystems. By using switching analysis techniques and the modified Halanay differential inequality, new criteria are developed for the exponential stability of switched stochastic GRNs with time-varying delays. Finally, an example is given to illustrate the main results.",
A Comparative Study on the Effects of Annealing on the Characteristics of Zinc Oxide Thin-Film Transistors With Gate-Stacks of Different Gas-Permeability,"The effects of different thermal processing on the characteristics of zinc oxide (ZnO) thin-film transistors (TFTs) with either gas-permeable or sealed gate-stack were studied and compared. The characteristics of a TFT heat-treated in a nonoxidizing ambience or under a sealed configuration degraded with increasing annealing temperature, though the former offered a comparatively wider process margin. On the other hand, the oxidization of the channel region of a TFT allowed by a gas-permeable gate-stack resulted in significant improvement in the transistor characteristics, e.g., eliminating the hysteresis and increasing the field-effect mobility to a relatively high value of 55 cm2/Vs. The difference in behavior is attributed to the annealing-dependent generation and annihilation of defects in ZnO under different coverage configurations, and suggests a general guideline on the thermal processing of ZnO TFTs.","Thin film transistors,
Annealing,
Zinc oxide,
Logic gates,
Heating,
Hysteresis"
Adaptable Enterprise Architectures for Software Evolution of SmartLife Ecosystems,"SmartLife ecosystems are emerging as intelligent user-centered systems that will shape future trends in technology and communication. Biological metaphors of living adaptable ecosystems provide the logical foundation for self-optimizing and self-healing run-time environments for intelligent adaptable business services and related information systems with service-oriented enterprise architectures. The present research in progress work investigates mechanisms for adaptable enterprise architectures for the development of service-oriented ecosystems with integrated technologies like Semantic Technologies, Web Services, Cloud Computing and Big Data Management. With a large and diverse set of ecosystem services with different owners, our scenario of service-based SmartLife ecosystems can pose challenges in their development, and more importantly, for maintenance and software evolution. Our research explores the use of knowledge modeling using ontologies and flexible metamodels for adaptable enterprise architectures to support program comprehension for software engineers during maintenance and evolution tasks of service-based applications. Our previous reference enterprise architecture model ESARC -- Enterprise Services Architecture Reference Cube -- and the Open Group SOA Ontology was extended to support agile semantic analysis, program comprehension and software evolution for a SmartLife applications scenario. The Semantic Browser is a semantic search tool that was developed to provide knowledge-enhanced investigation capabilities for service-oriented applications and their architectures.","Computer architecture,
Business,
Computational modeling,
Cloud computing,
Ontologies,
Service-oriented architecture,
Architecture"
How Behavior Trees modularize robustness and safety in hybrid systems,"Behavior Trees (BTs) have become a popular framework for designing controllers of in-game opponents in the computer gaming industry. In this paper, we formalize and analyze the reasons behind the success of the BTs using standard tools of robot control theory, focusing on how properties such as robustness and safety are addressed in a modular way. In particular, we show how these key properties can be traced back to the ideas of subsumption and sequential compositions of robot behaviors. Thus BTs can be seen as a recent addition to a long research effort towards increasing modularity, robustness and safety of robot control software. To illustrate the use of BTs, we provide a set of solutions to example problems.","Safety,
Robustness,
Robots,
Switches,
Computers,
Games,
Vehicles"
Design of a Probability Density Function Targeting Energy-Efficient Node Deployment in Wireless Sensor Networks,"In wireless sensor networks the issue of preserving energy requires utmost attention. One primary way of conserving energy is judicious deployment of sensor nodes within the network area so that the energy flow remains balanced throughout the network and prevents the problem of occurrence of energy holes. Firstly, we have analyzed network lifetime, found node density as the parameter which has significant influence on network lifetime and derived the desired parameter values for balanced energy consumption. Then to meet the requirement of energy balancing, we have proposed a probability density function (PDF), derived the PDF's intrinsic characteristics and shown its suitability to model the network architecture considered for the work. A node deployment algorithm is also developed based on this PDF. Performance of the deployment scheme is evaluated in terms of coverage-connectivity, energy balance and network lifetime. In qualitative analysis, we have shown the extent to which our proposed PDF has been able to provide desired node density derived from the analysis on network lifetime. Finally, the scheme is compared with three existing deployment schemes based on various distributions. Simulation results confirm our scheme's supremacy over all the existing schemes in terms of all the three performance metrics.","Wireless sensor networks,
Energy consumption,
Sensors,
Probability density function,
Routing,
Algorithm design and analysis,
Corona"
EEG Gamma Band Oscillations Differentiate the Planning of Spatially Directed Movements of the Arm Versus Eye: Multivariate Empirical Mode Decomposition Analysis,"The neural dynamics underlying the coordination of spatially-directed limb and eye movements in humans is not well understood. Part of the difficulty has been a lack of signal processing tools suitable for the analysis of nonstationary electroencephalographic (EEG) signals. Here, we use multivariate empirical mode decomposition (MEMD), a data-driven approach that does not employ predefined basis functions. High-density EEG, and arm and eye movements were synchronously recorded in 10 subjects performing time-constrained reaching and/or eye movements. Subjects were allowed to move both the hand and the eyes, only the hand, or only the eyes following a 500-700 ms delay interval where the hand and gaze remained on a central fixation cross. An additional condition involved a nonspatially-directed “lift” movement of the hand. The neural activity during a 500 ms delay interval was decomposed into intrinsic mode functions (IMFs) using MEMD. Classification analysis revealed that gamma band (30 Hz <;) IMFs produced more classifiable features differentiating the EEG according to the different upcoming movements. A benchmark test using conventional algorithms demonstrated that MEMD was the best algorithm for extracting oscillatory bands from EEG, yielding the best classification of the different movement conditions. The gamma rhythm decomposed using MEMD showed a higher correlation with the eventual movement accuracy than any other band rhythm and than any other algorithm.","Electroencephalography,
Planning,
Noise,
Rhythm,
Wavelet transforms,
Oscillators,
Electronic mail"
A steganalytic algorithm for 3D polygonal meshes,"We propose a steganalytic algorithm for watermarks embedded by Cho et al.'s mean-based algorithm [1]. The main observation is that while in a clean model the means of Cho et al.'s normalized histogram bins are expected to follow a Gaussian distribution, in a marked model their distribution will be bimodal. The proposed algorithm estimates the number of bins through an exhaustive search and then the presence of a watermark is decided by a tailor made normality test. We also propose a modification of Cho et al.'s algorithm which is more resistant to the steganalytic attack and offers an improved robustness/capacity trade-off.","Watermarking,
Robustness,
Three-dimensional displays,
Signal processing algorithms,
Standards,
Rabbits,
Accuracy"
The Entropy Power Inequality and Mrs. Gerber's Lemma for Groups of Order {2^{n}},"Shannon's entropy power inequality can be viewed as characterizing the minimum differential entropy achievable by the sum of two independent random variables with fixed differential entropies. The entropy power inequality has played a key role in resolving a number of problems in information theory. It is therefore interesting to examine the existence of a similar inequality for discrete random variables. In this paper, we obtain an entropy power inequality for random variables taking values in a group of order 2n, i.e., for such a group G, we explicitly characterize the function fG(x, y) giving the minimum entropy of the sum of two independent G-valued random variables with respective entropies x and y. Random variables achieving the extremum in this inequality are thus the analogs of Gaussians in this case, and these are also determined. It turns out that fG(x, y) is convex in x for fixed y and, by symmetry, convex in y for fixed x. This is a generalization to groups of order 2n of the result known as Mrs. Gerber's Lemma.","Entropy,
Random variables,
Government,
Cramer-Rao bounds,
Information theory,
Materials,
Covariance matrices"
Episodic non-Markov localization: Reasoning about short-term and long-term features,"Markov localization and its variants are widely used for localization of mobile robots. These methods assume Markov independence of observations, implying that observations made by a robot correspond to a static map. However, in real human environments, observations include occlusions due to unmapped objects like chairs and tables, and dynamic objects like humans. We introduce an episodic non-Markov localization algorithm that maintains estimates of the belief over the trajectory of the robot while explicitly reasoning about observations and their correlations arising from unmapped static objects, moving objects, as well as objects from the static map. Observations are classified as arising from long-term features, short-term features, or dynamic features, which correspond to mapped objects, unmapped static objects, and unmapped dynamic objects respectively. By detecting time steps along the robot's trajectory where unmapped observations prior to such time steps are unrelated to those afterwards, non-Markov localization limits the history of observations and pose estimates to “episodes” over which the belief is computed. We demonstrate non-Markov localization in challenging real world indoor and outdoor environments over multiple datasets, comparing it with alternative state-of-the-art approaches, showing it to be robust as well as accurate.",
A New Highly Efficient Differential Evolution Scheme and Its Application to Waveform Inversion,"In this letter, a new differential evolution (DE) algorithm is proposed and applied to waveform inversion. The traditional evolution strategy of this algorithm is not efficient because it treats the individuals in a population equally and evolves all of them in each generation. In order to overcome this shortcoming, we propose a new population evolution strategy (PES) to decrease the population size based on the differences among individuals during an evolution process. We embed the new strategy into the cooperative coevolutionary DE (CCDE) and obtain a new highly efficient DE (HEDE). We apply this new algorithm to waveform inversion experiments of both synthetic and real seismic data to test its performance and demonstrate its validity. The results have clearly shown that, under the same inversion precision, the HEDE can reduce the runtime by about 50% compared with the CCDE.","Sociology,
Statistics,
Evolution (biology),
Runtime,
Linear programming,
Geophysics,
Computational modeling"
Reconciling the Overlay and Underlay Tussle,"In the presence of multiple overlays and underlays, the emerging global network behavior is the result of interactions of self-serving overlay routing decisions and independent underlay management actions. It is crucial for network operators, service, and content providers to have a good grasp of the underlying principles in order to better design and manage current and future networks and services. In this paper, we describe special game scenarios wherein the interaction of noncooperative overlays and underlays in multidomain networks can result in an operable global configuration in linear time and the overall convergence is polynomial in the unweighed case. For weighted games, we find that weighted Shapley potential can achieve linear time convergence to an operable state. Furthermore, we analyze the interaction of overlays and underlays as a two-stage congestion game and recommend simple operational guidelines to ensure global stability. We further explore the use of Shapley value as an enabler of mutual cooperation in an otherwise competitive environment. Our simulation results confirm our findings and demonstrate its effectiveness in general networks.","Games,
Convergence,
Cost function,
Routing,
Nash equilibrium,
Polynomials,
Stability analysis"
Detecting adverse drug events with multiple representations of clinical measurements,"Adverse drug events (ADEs) are grossly under-reported in electronic health records (EHRs). This could be mitigated by methods that are able to detect ADEs in EHRs, thereby allowing for missing ADE-specific diagnosis codes to be identified and added. A crucial aspect of constructing such systems is to find proper representations of the data in order to allow the predictive modeling to be as accurate as possible. One category of EHR data that can be used as indicators of ADEs are clinical measurements. However, using clinical measurements as features is not unproblematic due to the high rate of missing values and they can be repeated a variable number of times in each patient health record. In this study, five basic representations of clinical measurements are proposed and evaluated to handle these two problems. An empirical investigation using random forest on 27 datasets from a real EHR database with different ADE targets is presented, demonstrating that the predictive performance, in terms of accuracy and area under ROC curve, is higher when representing clinical measurements crudely as whether they were taken or how many times they were taken by a patient. Furthermore, a sixth alternative, combining all five basic representations, significantly outperforms using any of the basic representation except for one. A subsequent analysis of variable importance is also conducted with this fused feature set, showing that when clinical measurements have a high missing rate, the number of times they were taken by one patient is ranked as more informative than looking at their actual values. The observation from random forest is also confirmed empirically using other commonly employed classifiers. This study demonstrates that the way in which clinical measurements from EHRs are presented has a high impact for ADE detection, and that using multiple representations outperforms using a basic representation.","Accuracy,
Drugs,
Predictive models,
Time measurement,
Vegetation,
Prediction algorithms,
Frequency measurement"
"Degrees of Freedom for a MIMO Gaussian
K
-Way Relay Channel: Successive Network Code Encoding and Decoding","This paper studies a network information flow problem for a multiple-input multiple-output (MIMO) Gaussian wireless network with K users and a single intermediate relay having M antennas. In this network, each user sends a multicast message to all other users while receiving K-1 independent messages from the other users via an intermediate relay. This network information flow is termed a MIMO Gaussian K-way relay channel. For this channel, it is shown that the optimal sum degrees of freedom (sum-DoF) is KM/K-1, assuming that all nodes have global channel knowledge and operate in full-duplex. A converse argument is derived by cut-set bounds. The achievability is shown by a repetition coding scheme with random beamforming in encoding and a zero-forcing method combined with self-interference cancelation in decoding. Furthermore, under the premise that all nodes have local channel state information at the receiver only and operate in half-duplex mode, it is shown that a total K/2 DoF is achievable when M=K-1. The key to showing this result is a novel encoding and decoding scheme, which creates a set of network code messages with a chain structure during the multiple access phase and performs successive interference cancelation using side-information for the broadcast phase. One major implication of the derived results is that efficient exploitation of the transmit message as side-information leads to an increase in the sum-DoF gain in a multiway relay channel with multicast messages.","Relays,
MIMO,
Encoding,
Decoding,
Vectors,
Array signal processing,
Protocols"
Data-driven model-free control of twin rotor aerodynamic systems: Algorithms and experiments,This paper suggests new data-driven Model-Free Control (MFC) and Model-Free Adaptive Control (MFAC) algorithms for Multi Input-Multi Output (MIMO) twin rotor aerodynamic systems. The discrete-time formulation of the algorithms is given in the framework of a MIMO control system structure with azimuth and pitch position control loops. The MFC and MFAC algorithms are validated by a set of experimental results on representative laboratory equipment. The performance comparison of the MFC- and MFAC-based MIMO control systems and azimuth and pitch position control is carried out considering three experimental scenarios.,"MIMO,
Azimuth,
Vectors,
Heuristic algorithms,
Aerodynamics,
Rotors,
Tuning"
Large-Scale Linear RankSVM,"Linear rankSVM is one of the widely used methods for learning to rank. Although its performance may be inferior to nonlinear methods such as kernel rankSVM and gradient boosting decision trees, linear rankSVM is useful to quickly produce a baseline model. Furthermore, following its recent development for classification, linear rankSVM may give competitive performance for large and sparse data. A great deal of works have studied linear rankSVM. The focus is on the computational efficiency when the number of preference pairs is large. In this letter, we systematically study existing works, discuss their advantages and disadvantages, and propose an efficient algorithm. We discuss different implementation issues and extensions with detailed experiments. Finally, we develop a robust linear rankSVM tool for public use.",
Broadband Chaotic Signals and Breather Oscillations in an Optoelectronic Oscillator Incorporating a Microwave Photonic Filter,"We propose a technique to generate broadband chaotic and breather signals employing an optoelectronic oscillator (OEO) comprising a phase modulator (PM) and a linearly chirped fiber Bragg grating (LCFBG). The joint operation of the PM and the LCFBG forms a broadband microwave photonic filter (MPF), which allows the OEO to generate chaotic signals and breathers taking advantage of the interplay between the broadband MPF and the time-delayed feedback loop provided by a long optical fiber delay line. The breather excitations are characterized by nanosecond chaotic oscillations breathing periodically at a significantly lower time-scale determined by the OEO large delay time. A theoretical analysis based on a modified Ikeda time-delayed model to include the effect of the broadband filtering process is provided. The analysis is verified by an experiment. The proposed LCFBG-based OEO and the possibility to control in the optical domain its broadband bandpass characteristics considering the flexibility, accuracy, and precision in FBG fabrication can find applications in chaos-based communications and in fast optical processing systems, such as random number generation, or optical processing in reservoir computing taking advantage of the intrinsic multiple time scales of the LCFBG-based OEO.","Optical fibers,
Optical feedback,
Optical filters,
Optical attenuators,
Broadband communication,
Nonlinear optics"
Moral competence in social robots,"We propose that any robots that collaborate with, look after, or help humans-in short, social robots-must have moral competence. But what does moral competence consist of? We offer a framework for moral competence that attempts to be comprehensive in capturing capacities that make humans morally competent and that therefore represent candidates for a morally competent robot. We posit that human moral competence consists of four broad components: (1) A system of norms and the language and concepts needed to communicate about these norms; (2) moral cognition and affect; (3) moral decision making and action; and (4) moral communication. We sketch what we know and don't know about these four elements of moral competence in humans and, for each component, ask how we could equip an artificial agent with these capacities.","Ethics,
Robots,
Cognition,
Communities,
Psychology,
Decision making,
Context"
A Simulation Study of Oxygen Vacancy-Induced Variability in {\rm HfO}_{2} /Metal Gated SOI FinFET,"Deposition of a metal gate on high-K dielectric HfO2 is known to generate oxygen vacancy (OVs) defects. Positively charged OVs in the dielectric affect the gate electrostatics and modulate the effective gate workfunction (WF). Count and spatial allocation of OVs varies from device-to-device and induces significant local variability in WF and Vth. This paper presents the statistical models to simulate OV concentration and placement depending on the gate formation conditions. OV-induced variability is studied for SOI FinFET, and compared against the other sources of variability across the technologies. The implications of gate first and gate last processes to the OV concentration/distribution are studied. Simulations show that with channel length and gate dielectric thickness scaling, the OV-induced variability becomes a significant concern.","Logic gates,
Hafnium compounds,
FinFETs,
Oxygen,
Energy states,
Tin"
Improving performance of small-file accessing in Hadoop,"The Hadoop Distributed File System (HDFS) is an open source system which is designed to run on commodity hardware and is suitable for applications that have large data sets (terabytes). As HDFS architecture bases on single master (NameNode) to handle metadata management for multiple slaves (Datanode), NameNode often becomes bottleneck, especially when handling large number of small files. To maximize efficiency, NameNode stores the entire metadata of HDFS in its main memory. With too many small files, NameNode can be running out of memory. In this paper, we propose a mechanism based on Hadoop Archive (HAR), called New Hadoop Archive (NHAR), to improve the memory utilization for metadata and enhance the efficiency of accessing small files in HDFS. In addition, we also extend HAR capabilities to allow additional files to be inserted into the existing archive files. Our experiment results show that our approach can to improve the access efficiencies of small files drastically as it outperforms HAR up to 85.47%.","public domain software,
distributed processing,
file organisation,
meta data"
Visual Analysis of Public Utility Service Problems in a Metropolis,"Issues about city utility services reported by citizens can provide unprecedented insights into the various aspects of such services. Analysis of these issues can improve living quality through evidence-based decision making. However, these issues are complex, because of the involvement of spatial and temporal components, in addition to having multi-dimensional and multivariate natures. Consequently, exploring utility service problems and creating visual representations are difficult. To analyze these issues, we propose a visual analytics process based on the main tasks of utility service management. We also propose an aggregate method that transforms numerous issues into legible events and provide visualizations for events. In addition, we provide a set of tools and interaction techniques to explore such issues. Our approach enables administrators to make more informed decisions.","Visual analytics,
Color analysis,
Graphical models,
Distribution functions,
Urban areas"
Min(e)d your tags: Analysis of Question response time in StackOverflow,"Given a newly posted question on a Question and Answer (Q&A) site, how long will it take until an answer is received? Does response time relate to factors about how the question asker composes their question? If so, what are those factors? With advances in social media and the Web, Q&A sites have become a major source of information for Internet users. Response time of a question is an important aspect in these sites as it is associated with the users' satisfaction and engagement, and thus the lifespan of these online communities. In this paper we study and estimate response time for questions in StackOverflow, a popular online Q&A forum where software developers post and answer questions related to programming. We analyze a long list of factors in the data and identify those that have clear relation with response time. Our key finding is that tag-related factors, such as their “popularity” (how often the tag is used) and the number of their “subscribers” (how many users can answer questions containing the tag), provide much stronger evidence than factors not related to tags. Finally, we learn models using the identified evidential features for predicting the response time of questions, which also demonstrate the significance of tags chosen by the question asker.","Time factors,
Correlation,
Social network services,
Conferences,
Programming,
Predictive models,
Internet"
Novel Decentralized Control of Power Systems With Penetration of Renewable Energy Sources in Small-Scale Power Systems,"In this paper, the power grid with penetration of renewable energy sources is modeled as a multigenerator interconnected power network. The power grid includes distributed energy resources including conventional synchronous generators and renewable energy sources; here called renewable generators that are connected to the grid via grid-tie inverters (GTIs). With the proposed modeling, the GTI resembles a synchronous generator with excitation control. The modeling takes into account the dc-link capacitor stored energy as a dynamical state, in contrast with the available methods, and through an appropriate controller assures the stability of the dc link and the entire grid without needing an abundant-energy dc link. Next, the power grid comprising the synchronous and renewable generators is converted to decentralized control form with subsystems in Brunovsky canonical form whose interactions with the rest of the grid are unknown. A decentralized adaptive neural network (NN) feedback controller is proposed with quadratic update law to stabilize the rotor speed and dc-link voltage oscillations in asymptotic fashion in the presence of grid disturbances. The proposed controller is then simplified. Though the solar power interacting with conventional synchronous generators is considered in this paper, the proposed modeling and controller design can be applied to many other renewable energy systems. Simulation results on the IEEE 14-bus power system with penetration of solar power are provided to show the effectiveness of the approach in damping oscillations that occur after disturbances.","Synchronous generators,
Power system stability,
Stability criteria,
Asymptotic stability,
Inverters"
A Beamforming Approach to Smart Grid Systems Based on Cloud Cognitive Radio,"In this paper, we desire to use cognitive radio (CR) channels for communication among a wireless network of smart meters. However, self-interference critically limits the performance of CR systems. This is due to the coexistence of many unplanned systems simultaneously accessing the same signaling bands in an uncoordinated manner. To solve this problem, we show a beamforming approach that effectively mitigates the self-interference effects of the smart meter channel. The beamforming approach is based on minimum mean squared error (MMSE) method in smart meter systems. The MMSE beamformer usually requires accurate channel estimates and noise-plus-interference power estimates for effective mitigation of self-interference in CR systems. In this paper, we propose novel channel estimation and noise-plus-interference power estimation methodologies that efficiently exploit the preamble feature of the IEEE802.22 wireless regional area network (WRAN). Our framework is premised upon the utilization of a cloud computing smart grid infrastructure that hosts the IEEE 802.22 WRAN CR standard. The simulation results for a smart grid system with the MMSE beamformer illustrate significant improvements in system capacity and BER.","Smart grids,
Estimation,
Channel estimation,
Array signal processing,
Interference,
Protocols,
Uplink"
Inferring air pollution by sniffing social media,"The first step to deal with the significant issue of air pollution in China and elsewhere in the world is to monitor it. While more physical monitoring stations are built, current coverage is limited to large cities with most other places under-monitored. In this paper we propose a complementary approach to monitor Air Quality Index (AQI): using machine learning models to estimate AQI from social media posts. We propose a series of progressively more sophisticated machine learning models, culminating in a Markov Random Field model that utilizes the text content in social media as well as the spatiotemporal correlation among cities and days. Our extensive experiments on Sina Weibo data from 108 cities during a one-month period demonstrate the accurate AQI prediction performance of our approach.","Cities and towns,
Training,
Atmospheric modeling,
Correlation,
Spatiotemporal phenomena,
Monitoring,
Pollution"
"Modeling, Fabrication, and Characterization of Low-Cost and High-Performance Polycrystalline Panel-Based Silicon Interposer With Through Vias and Redistribution Layers","Interconnections between integrated circuits and print circuit boards are primarily achieved currently with organic packages at high I/O pitch. Organic packages, however, are limited by poor thermal and dimension stabilities for them to act as fine pitch interposers. To address these challenges, silicon interposers are being developed. Current silicon interposers, based on through-silicon via (TSV) techniques, suffer from high production cost, because of expensive CMOS-grade silicon, expensive TSV process and smaller wafer sizes. They also suffer from high electrical loss in spite of thin SiO2 interfacial layers. This paper, for the first time, demonstrates a lower cost and higher performance silicon interposer. It is based on panel-based polycrystalline silicon with through-package vias (TPVs) and redistribution layers, and a simple and double-side process with thick polymer liner inside the TPV. Electrical modeling was carried out that shows the better electrical performance of polycrystalline silicon interposer compared with traditional single-crystalline silicon interposer. The polycrystalline silicon interposer test vehicles with up to four metal layers were demonstrated and characterized. The measurement results showed good electrical performance and matched well with the simulations.","Silicon,
Polymers,
Insertion loss,
Laser ablation,
Substrates,
Through-silicon vias,
Lamination"
Three-Dimensional Microfabricated Broadband Patch Antenna for WiGig Applications,"The design, microfabrication, and characterization of a broadband patch antenna capable of covering the entire IEEE 802.11ad (WiGig) frequency band (57-66 GHz) are presented in this letter. A conductor-backed (CB) coplanar waveguide (CPW)-fed loop slot couples the energy to the patch antenna, resulting in a broad bandwidth. The feed circuitry along with the loop is formed on a quartz substrate (εr = 3.9, tan δ = 0.0002 at 60 GHz), on top of which an SU-8-based three-dimensional (3-D) structure with air cavities is microfabricated. The patch metallization is deposited on top of this 3-D structure. While the main role of the structure made out of SU-8 material is to provide a mechanical support for the patch metallization, the antenna takes advantage of the air cavities underneath, thus resulting in an antenna substrate with a very low loss. This, in turn, improves the overall antenna performances. The simulated and measured impedance characteristics agree well, showing ~15% bandwidth. Also, the radiation pattern results demonstrate the integrity of radiation pattern with reasonably constant gain values (average ~6.4 dB) in the broadside direction over the entire WiGig band.","Substrates,
Patch antennas,
Antenna measurements,
Coplanar waveguides,
Broadband antennas,
Cavity resonators"
Type-II opposition-based differential evolution,"The concept of opposition-based learning (OBL) can be categorized into Type-I and Type-II OBL methodologies. The Type-I OBL is based on the opposite points in the variable space while the Type-II OBL considers the opposite of function value on the landscape. In the past few years, many research works have been conducted on development of Type-I OBL-based approaches with application in science and engineering, such as opposition-based differential evolution (ODE). However, compared to Type-I OBL, which cannot address a real sense of opposition in term of objective value, the Type-II OBL is capable to discover more meaningful knowledge about problem's landscape. Due to natural difficulty of proposing a Type-II-based approach, very limited research has been reported in that direction. In this paper, for the first time, the concept of Type-II OBL has been investigated in detail in optimization; also it is applied on the DE algorithm as a case study. The proposed algorithm is called opposition-based differential evolution Type-II (ODE-II) algorithm; it is validated on the testbed proposed for the IEEE Congress on Evolutionary Computation 2013 (IEEE CEC-2013) contest with 28 benchmark functions. Simulation results on the benchmark functions demonstrate the effectiveness of the proposed method as the first step for further developments in Type-II OBL-based schemes.","Sociology,
Statistics,
Vectors,
Optimization,
Table lookup,
Linear programming,
Interpolation"
Heavy-Ion and Laser Induced Charge Collection in SiGe Channel p{\rm MOSFETs},"Heavy-ion and two-photon-absorption (TPA) experiments have been performed on ultra-thin implant-free quantum well SiGe channel pMOSFETs. Both the single-event-transient pulse magnitude and polarity can depend strongly on the location of the strike along the device channel. The polarity inversion occurs primarily because very limited transient charge collection occurs below the quantum well, as confirmed by two-dimensional TCAD simulation.","Silicon germanium,
Transient analysis,
Single event transients,
Lasers,
MOSFET,
Performance evaluation"
Extracting Salient Brain Patterns for Imaging-Based Classification of Neurodegenerative Diseases,"Neurodegenerative diseases comprise a wide variety of mental symptoms whose evolution is not directly related to the visual analysis made by radiologists, who can hardly quantify systematic differences. Moreover, automatic brain morphometric analyses, that do perform this quantification, contribute very little to the comprehension of the disease, i.e., many of these methods classify but they do not produce useful anatomo-functional correlations. This paper presents a new fully automatic image analysis method that reveals discriminative brain patterns associated to the presence of neurodegenerative diseases, mining systematic differences and therefore grading objectively any neurological disorder. This is accomplished by a fusion strategy that mixes together bottom-up and top-down information flows. Bottom-up information comes from a multiscale analysis of different image features, while the top-down stage includes learning and fusion strategies formulated as a max-margin multiple-kernel optimization problem. The capacity of finding discriminative anatomic patterns was evaluated using the Alzheimer's disease (AD) as the use case. The classification performance was assessed under different configurations of the proposed approach in two public brain magnetic resonance datasets (OASIS-MIRIAD) with patients diagnosed with AD, showing an improvement varying from 6.2% to 13% in the equal error rate measure, with respect to what has been reported by the feature-based morphometry strategy. In terms of the anatomical analysis, discriminant regions found by the proposed approach highly correlates to what has been reported in clinical studies of AD.","Kernel,
Visualization,
Mathematical model,
Diseases,
Feature extraction,
Brain modeling,
Pathology"
Electromagnetic and Particle-in-Cell Simulation Studies of a High Power Strap and Vane CW Magnetron,"This paper presents electromagnetic and particle-in-cell (PIC) simulation studies of ring strapped vane resonator of a 2.45 GHz 1-kW magnetron using Computer Simulation technology microwave studio and MAGIC-3-D. The aim was to gain design understanding through the analysis of constituent parts of the resonant system and to deduce results having significant engineering value. The electromagnetic analysis includes modeling the effect of the end-gap length, the straps, the coupling antenna, and the surface roughness of cavity wall on resonant frequency. It was found that a clearance of 4 mm and beyond between cavity resonator and end plate have negligible effect on resonance frequency. Straps influence the resonant frequency of the π mode maximum, and can be used to control and fine tune the resonant frequency of the desired π mode. A surface roughness of 1 μm or more affects the unloaded Q of the resonator cavity adversely. Coupling antenna height is found to play an important role to achieve desired Ql and Qext for the segment loaded axial extraction of power. The PIC simulation study predicted that the hot resonant frequency differ from cold resonant frequency by ~9 MHz. The computed frequency, power, and efficiency were found to be 2.462 GHz, 1.3 kW, and 70%, respectively.",
The RNA Polymerase Flow Model of Gene Transcription,"Gene expression is a fundamental cellular process by which proteins are synthesized based on the information coded in the genes. The two major steps of this process are the transcription of the DNA segment corresponding to a gene to mRNA molecules and the translation of the mRNA molecules to proteins by the ribosome. Thus, understanding, modeling and engineering the different stages of this process have both important biotechnological applications and contributions to basic life science. In previous studies we have introduced the Homogenous Ribosome Flow Model (HRFM) and demonstrated its advantages in analyses of the translation process. In this study we introduce the RNA Polymerase Flow Model (RPFM), a non trivial extension of the HRFM, which also includes a backward flow and can be used for modeling transcription and maybe other similar processes. We compare the HRFM and the RPFM in the three regimes of the transcription process: rate limiting initiation, rate limiting elongation and rate limiting termination via a simulative and analytical analysis. In addition, based on experimental data, we show that RPFM is a better choice for modeling transcription process.","RNA,
Mathematical model,
DNA,
Polymers,
Biological system modeling,
Steady-state,
Proteins"
Joint Sampling Rate and Bit-Depth Optimization in Compressive Video Sampling,"Compressed sensing is a novel technology that exploits sparsity of a signal to perform sampling below the Nyquist rate, and thus has great potential in low-complexity video sampling and compression applications, due to the significant reduction of the sampling rate ( SR) and computational complexity. However, most current work about compressive video sampling (CVS) has focused on real-valued measurements without being quantized, and thus is not applicable to engineering practices. Moreover, in many circumstances, the total number of bits is often constrained. Therefore, how to achieve a compromise between the number of measurements and the number of bits per measurement to maximize the visual quality is a great challenge for CVS, which has still not been addressed in literature. In this paper, we first present a novel distortion model that reveals the relationship between distortion, SR, and quantization bit-depth ( B). Then, using this model, we propose a joint SR - B optimization algorithm, by which we are able to easily derive the values of SR and B. Finally, we present an adaptive and unidirectional CVS framework with rate-distortion (RD) optimized rate allocation, wherein we use video characteristics extracted from partial sampling to allocate the required bits for each block, and then implement “optimized” video sampling and measurement quantization with the estimated SR and B, respectively. Simulation results show that our proposal offers comparable RD performance to the conventional method, with a 4.6 dB improvement in the average PSNR.","Quantization (signal),
Resource management,
Distortion measurement,
Optimization,
Joints,
Sensors,
Adaptation models"
Leveraging appearance and geometry for kinship verification,"Kinship verification has become a very active topic recently. Many kinship verification algorithms have been proposed, however, many problems still need to be solved, such as how to locate familial traits of two individuals with kinship and how to make use of facial geometry information to verify kinship relation. To solve these problems, we propose one feature matching scheme to locate familial traits between two facial images. We also advocate a method using geometry information for kinship verification. This approach achieves more than 17% improvement compared with the state of the art. In addition, preliminary results show that the proposed problems can be accurately addressed when fusing appearance and geometry feature.","Face,
Feature extraction,
Shape,
Geometry,
Manifolds,
Vectors,
Face recognition"
Maximal Likelihood Correspondence Estimation for Face Recognition Across Pose,"Due to the misalignment of image features, the performance of many conventional face recognition methods degrades considerably in across pose scenario. To address this problem, many image matching-based methods are proposed to estimate semantic correspondence between faces in different poses. In this paper, we aim to solve two critical problems in previous image matching-based correspondence learning methods: 1) fail to fully exploit face specific structure information in correspondence estimation and 2) fail to learn personalized correspondence for each probe image. To this end, we first build a model, termed as morphable displacement field (MDF), to encode face specific structure information of semantic correspondence from a set of real samples of correspondences calculated from 3D face models. Then, we propose a maximal likelihood correspondence estimation (MLCE) method to learn personalized correspondence based on maximal likelihood frontal face assumption. After obtaining the semantic correspondence encoded in the learned displacement, we can synthesize virtual frontal images of the profile faces for subsequent recognition. Using linear discriminant analysis method with pixel-intensity features, state-of-the-art performance is achieved on three multipose benchmarks, i.e., CMU-PIE, FERET, and MultiPIE databases. Owe to the rational MDF regularization and the usage of novel maximal likelihood objective, the proposed MLCE method can reliably learn correspondence between faces in different poses even in complex wild environment, i.e., labeled face in the wild database.","Face,
Three-dimensional displays,
Solid modeling,
Semantics,
Shape,
Face recognition,
Feature extraction"
Spatiotemporal indexing techniques for efficiently mining spatiotemporal co-occurrence patterns,"In this paper, we investigate using specifically-designated spatiotemporal indexing techniques for mining cooccurrence patterns from spatiotemporal datasets with evolving polygon-based representations. Previously, suggested techniques for spatiotemporal pattern mining algorithms did not take spatiotemporal indexing techniques into account. We present a new framework for mining spatiotemporal co-occurrence patterns that can use various indexing techniques for efficiently accessing data. Two well-studied spatiotemporal indexing structures, Scalable and Efficient Trajectory Index (SETI) and Chebyshev Polynomial Indexing are currently implemented and available in our framework.","Spatiotemporal phenomena,
Indexing,
Data mining,
Trajectory,
Atmospheric measurements,
Particle measurements"
Admission Control-Based Multichannel Data Broadcasting for Real-Time Multi-Item Queries,"Owing to its potential to satisfy all outstanding queries for the same data item with a single response, on-demand data broadcast becomes a widely accepted approach to dynamic and scalable wireless information dissemination. In some emerging applications, such as road traffic navigation system, users may query multiple data items which have to be received before a deadline. However, in existing works, a client only knows that its query is satisfied when it receives all the required data items or not satisfied when the deadline expires. In this paper, admission control is introduced in data broadcast systems such that clients can be informed in a timely manner. On the one hand, when a query has no hope to be satisfied, it is a waste of time and resources for the client listening to the channels. Instead, an early notification allows the client to take prompt remedial actions to recover the situation. On the other hand, when a query has a very high chance to be served before its deadline, an early guarantee provides a better quality of service to the client. Furthermore, a matching-based allocation scheme is proposed to maximize data sharing among queries and minimize switching among channels in multichannel architectures. Extensive simulations are performed to analyze the validity and efficiency of the proposed admission control and channel allocation schemes on existing scheduling algorithms in a wide range of circumstances.","Admission control,
Resource management,
Real-time systems,
Channel allocation"
Context-Aware Discovery of Visual Co-Occurrence Patterns,"Once an image is decomposed into a number of visual primitives, e.g., local interest points or regions, it is of great interests to discover meaningful visual patterns from them. Conventional clustering of visual primitives, however, usually ignores the spatial and feature structure among them, thus cannot discover high-level visual patterns of complex structure. To overcome this problem, we propose to consider spatial and feature contexts among visual primitives for pattern discovery. By discovering spatial co-occurrence patterns among visual primitives and feature co-occurrence patterns among different types of features, our method can better address the ambiguities of clustering visual primitives. We formulate the pattern discovery problem as a regularized k-means clustering where spatial and feature contexts are served as constraints to improve the pattern discovery results. A novel self-learning procedure is proposed to utilize the discovered spatial or feature patterns to gradually refine the clustering result. Our self-learning procedure is guaranteed to converge and experiments on real images validate the effectiveness of our method.","Visualization,
Context,
Vectors,
Spatial databases,
Manganese,
Clustering algorithms,
Prototypes"
Video Colorization Using Parallel Optimization in Feature Space,"We present a new scheme for video colorization using optimization in rotation-aware Gabor feature space. Most current methods of video colorization incur temporal artifacts and prohibitive processing costs, while this approach is designed in a spatiotemporal manner to preserve temporal coherence. The parallel implementation on graphics hardware is also facilitated to achieve realtime performance of color optimization. By adaptively clustering video frames and extending Gabor filtering to optical flow computation, we can achieve real-time color propagation within and between frames. Temporal coherence is further refined through user scribbles in video frames. The experimental results demonstrate that our proposed approach is efficient in producing high-quality colorized videos.",
Big Data and the SP Theory of Intelligence,"This paper is about how the SP theory of intelligence and its realization in the SP machine may, with advantage, be applied to the management and analysis of big data. The SP system-introduced in this paper and fully described elsewhere-may help to overcome the problem of variety in big data; it has potential as a universal framework for the representation and processing of diverse kinds of knowledge, helping to reduce the diversity of formalisms and formats for knowledge, and the different ways in which they are processed. It has strengths in the unsupervised learning or discovery of structure in data, in pattern recognition, in the parsing and production of natural language, in several kinds of reasoning, and more. It lends itself to the analysis of streaming data, helping to overcome the problem of velocity in big data. Central in the workings of the system is lossless compression of information: making big data smaller and reducing problems of storage and management. There is potential for substantial economies in the transmission of data, for big cuts in the use of energy in computing, for faster processing, and for smaller and lighter computers. The system provides a handle on the problem of veracity in big data, with potential to assist in the management of errors and uncertainties in data. It lends itself to the visualization of knowledge structures and inferential processes. A high-parallel, open-source version of the SP machine would provide a means for researchers everywhere to explore what can be done with the system and to create new versions of it.","Unsupervised learning,
Pattern recognition,
Data storage systems,
Data compression,
Computational efficiency,
Cognitive science,
Artificial intelligence"
A Compact Low-Power 320-Gb/s WDM Transmitter Based on Silicon Microrings,"We demonstrate a compact and low-power wavelength-division multiplexing transmitter near a 1550-nm wavelength using silicon microrings. The transmitter is implemented on a silicon-on-insulator photonics platform with a compact footprint of 0.5 mm2. The transmitter incorporates 8 wavelength channels with 200-GHz spacing. Each channel achieved error-free operation at 40 Gb/s, resulting in an aggregated data transmission capability of 320 Gb/s. To our knowledge, this is the highest aggregated data rate demonstrated in silicon wavelength-division multiplexing transmitters. Owing to the small device capacitance and the efficient pn-junction modulator design, the transmitter achieves low energy-per-bit values of 36 fJ/bit under 2.4 Vpp drive and 144 fJ/bit under 4.8 Vpp drive. Comparisons are made to a commercial lithium niobate modulator in terms of bit-error-rate versus optical signal-to-noise ratio.","Optical transmitters,
Modulation,
Wavelength division multiplexing,
Tuning,
Silicon,
Optical waveguides,
Junctions"
Compact tri-band metamaterial-inspired antenna based on CRLH resonant structures,"A single-cell tri-band composite right/left-handed (CRLH) resonant antenna is presented. The antenna is designed on a single-layer coplanar waveguide-fed based on the T-junction discontinuity equivalent circuit. The proposed antenna provides compact size, easy fabrication process, multi-band feature and higher efficiency in comparison with the previously reported CRLH resonant antennas. The single-cell CRLH resonant antenna is fabricated and the measurements are consistent with the simulation result.","coplanar waveguides,
equivalent circuits,
metamaterial antennas,
multifrequency antennas"
Low delay and secure M2M communication mechanism for eHealthcare,"Currently, the eHealthcare information management is the most critical and hot research topic. Especially with the involvement of new and promising telecommunication technologies like Machine to Machine (M2M) Communication. In M2M communication the devices interact and exchange information with each other in an autonomous manner to accomplish the required tasks. Mostly machine communicate to another machine wirelessly. The wireless communication opens the medium for enormous vulnerabilities and make it very easy for hackers to access the confidential information and can perform malicious activities. In this paper, we propose a Machine to Machine (M2M) Low Delay and Secure (LDS) communication system for e-healthcare community based on random distributive key management scheme and modified Kerberos realm to ensure data security. The system is capable to perform the tasks in an autonomous and intelligent manner that minimizes the workload of medical staffs, and improves the quality of patient care as well as the system performance. We show how the different actors in the e-healthcare community can interact with each other in a secure manner. The system handles dynamic assignments of doctors to specific patients. The proposed architecture further provides security against false attack, false triggering and temper attack. Finally, the simulation type implementation is performed on Visual Basic .net 2013 that shows the feasibility of the proposed Low Delay and Secure (LDS) algorithm.","Decision support systems,
Conferences,
Information management,
System analysis and design,
Delays"
A comparative analysis of microarchitecture effects on CPU and GPU memory system behavior,"While heterogeneous CPU/GPU systems have been traditionally implemented on separate chips, each with their own private DRAM, heterogeneous processors are integrating these different core types on the same die with access to a common physical memory. Further, emerging heterogeneous CPU-GPU processors promise to offer tighter coupling between core types via a unified virtual address space and cache coherence. To adequately address the potential opportunities and pitfalls that may arise from this tighter coupling, it is important to have a deep understanding of application- and memory-level demands from both CPU and GPU cores. This paper presents a detailed comparison of memory access behavior for parallel applications executing on each core type in tightly-controlled heterogeneous CPU-GPU processor simulation. This characterization indicates that applications are typically designed with similar algorithmic structures for CPU and GPU cores, and each core type's memory access path has a similar locality filtering role. However, the different core and cache microarchitectures expose substantially different memory-level parallelism (MLP), which results in different instantaneous memory access rates and sensitivity to memory hierarchy architecture.","Graphics processing units,
Instruction sets,
Benchmark testing,
Registers,
Bandwidth,
Pipelines"
Modeling 20-nm Germanium FinFET With the Industry Standard FinFET Model,"In this letter, we present modeling results for germanium p-type FinFETs using the industry standard Berkeley Spice Common Multi-gate Field Effect Transistor (BSIM-CMG) model. The effect of perpendicular electrical field on hole mobility in germanium FinFETs is found to be different from silicon FinFETs. We present an updated Ge mobility equation to account for this difference. With this single update, BSIM-CMG agrees very well with the measured I-V data of Ge FinFETs with a gate-length from 130 to 20 nm. We conclude that a production quality standard model is available for simulation of circuits employing p-type Ge FinFET.","FinFETs,
Silicon,
Semiconductor device modeling,
Integrated circuit modeling,
Germanium,
Mathematical model,
Logic gates"
Touchscreen Everywhere: On Transferring a Normal Planar Surface to a Touch-Sensitive Display,"We address how a human-computer interface with small device size, large display, and touch-input facility can be made possible by a mere projector and camera. The realization is through the use of a properly embedded structured light sensing scheme that enables a regular light-colored table surface to serve the dual roles of both a projection screen and a touch-sensitive display surface. A random binary pattern is employed to code structured light in pixel accuracy, which is embedded into the regular projection display in a way that the user perceives only regular display but not the structured pattern hidden in the display. With the projection display on the table surface being imaged by a camera, the observed image data, plus the known projection content, can work together to probe the 3-D workspace immediately above the table surface, like deciding if there is a finger present and if the finger touches the table surface, and if so, at what position on the table surface the contact is made. All the decisions hinge upon a careful calibration of the projector-camera-table surface system, intelligent segmentation of the hand in the image data, and exploitation of the homography mapping existing between the projector's display panel and the camera's image plane. Extensive experimentation including evaluation of the display quality, hand segmentation accuracy, touch detection accuracy, trajectory tracking accuracy, multitouch capability and system efficiency are shown to illustrate the feasibility of the proposed realization.","Cameras,
Arrays,
Sensors,
Encoding,
Image segmentation,
Accuracy,
Computers"
CheetahFlow: Towards low latency software-defined network,"Software defined networking (SDN), which enables programmability, has the advantage of global visibility and high flexibility. However, when forwarding new flows in SDN, the interaction between the switch and the controller imposes extra latency such as round-trip time and routing path search time. Even though such latency is acceptable for elephant flows since it only takes limited ratio of total transmission time of elephant flows, it is an overkill to pay certain overheads for mice flows due to the their short transmission time. Moreover, the controller is frequently invoked by the mice flows since the number of mice flows accounts for a large portion of the total number of flows. Hence, the frequent controller invocation is mainly responsible for the controller performance degradation, and thus increasing the flow setup latency significantly. To solve this problem, we propose CheetahFlow, a novel scheme to predict frequent communication pairs via support vector machine and proactively setup wildcard rules to reduce flow setup latency. Particularly, in order to avoid congestion along a fixed path, elephant flows are detected and rerouted to the non-congestion path efficiently by applying blocking island paradigm. Extensive experiments show that CheetahFlow prominently reduces latency without any loss of flexibility of SDN.",
Core Body Temperature Control by Total Liquid Ventilation Using a Virtual Lung Temperature Sensor,"In total liquid ventilation (TLV), the lungs are filled with a breathable liquid perfluorocarbon (PFC) while a liquid ventilator ensures proper gas exchange by renewal of a tidal volume of oxygenated and temperature-controlled PFC. Given the rapid changes in core body temperature generated by TLV using the lung has a heat exchanger, it is crucial to have accurate and reliable core body temperature monitoring and control. This study presents the design of a virtual lung temperature sensor to control core temperature. In the first step, the virtual sensor, using expired PFC to estimate lung temperature noninvasively, was validated both in vitro and in vivo. The virtual lung temperature was then used to rapidly and automatically control core temperature. Experimentations were performed using the Inolivent-5.0 liquid ventilator with a feedback controller to modulate inspired PFC temperature thereby controlling lung temperature. The in vivo experimental protocol was conducted on seven newborn lambs instrumented with temperature sensors at the femoral artery, pulmonary artery, oesophagus, right ear drum, and rectum. After stabilization in conventional mechanical ventilation, TLV was initiated with fast hypothermia induction, followed by slow posthypothermic rewarming for 1 h, then by fast rewarming to normothermia and finally a second fast hypothermia induction phase. Results showed that the virtual lung temperature was able to provide an accurate estimation of systemic arterial temperature. Results also demonstrate that TLV can precisely control core body temperature and can be favorably compared to extracorporeal circulation in terms of speed.","Temperature sensors,
Temperature control,
Temperature measurement,
Lungs,
Arteries"
Composite Bloom Filters for Secure Record Linkage,"The process of record linkage seeks to integrate instances that correspond to the same entity. Record linkage has traditionally been performed through the comparison of identifying field values (e.g., Surname), however, when databases are maintained by disparate organizations, the disclosure of such information can breach the privacy of the corresponding individuals. Various private record linkage (PRL) methods have been developed to obscure such identifiers, but they vary widely in their ability to balance competing goals of accuracy, efficiency and security. The tokenization and hashing of field values into Bloom filters (BF) enables greater linkage accuracy and efficiency than other PRL methods, but the encodings may be compromised through frequency-based cryptanalysis. Our objective is to adapt a BF encoding technique to mitigate such attacks with minimal sacrifices in accuracy and efficiency. To accomplish these goals, we introduce a statistically-informed method to generate BF encodings that integrate bits from multiple fields, the frequencies of which are provably associated with a minimum number of fields. Our method enables a user-specified tradeoff between security and accuracy. We compare our encoding method with other techniques using a public dataset of voter registration records and demonstrate that the increases in security come with only minor losses to accuracy.",
A Novel Null Scanning Antenna Using Even and Odd Modes of a Shorted Patch,"A novel null scanning patch antenna operating at 2.4 GHz is presented. Unlike the existing reconfigurable techniques, the even and odd modes of a shorted patch are adopted to first achieve a broadside pattern and pattern null on broadside. Continuous null scanning is achieved by combining these two modes with different exciting powers. The mechanism of null scanning is discussed from both theoretical analysis and simulated/measured results. A rat-race switching network is used to excite the two modes and simultaneously obtain high port isolation. A prototype is fabricated and tested. The measured results verified the null scanning capability of the proposed design.","Ports (Computers),
Antenna measurements,
Antennas,
Impedance matching,
Arrays,
Scattering parameters"
Virtual impedance based stability improvement for DC microgrids with constant power loads,"In this paper, in order to improve the stability of DC microgrids with constant power loads (CPLs), a virtual impedance based method is proposed. The CPLs have inherent instability issues induced by negative incremental impedances. To enhance the system stability, two types of virtual impedance based stabilizers comprised of series-connected inductance and resistance are employed. Type I stabilizer locates at the output capacitor branch, and Type II stabilizer locates at the output inductance branch. Meanwhile, considering that the parallel interfacing converters are commonly in parallel in a microgrid, droop control is taken into account. To validate the stability of the above stabilizers in a DC microgrid with parallel interfacing converters and CPLs, the impedance matching approach is employed. It is demonstrated that, the instable poles can be moved to the stable region in the frequency domain by the proposed stabilizers. Simulations with three interfacing converters are conducted by using MATLAB/Simulink, which verify the effectiveness of the proposed methods. It is shown that both of the proposed virtual impedance based stabilizers can effectively enhance the system stability with CPLs.","Impedance,
Microgrids,
Stability analysis,
Inductance,
Power system stability,
Capacitors,
Resistance"
Modeling On-Board Via Stubs and Traces in High-Speed Channels for Achieving Higher Data Bandwidth,"To achieve a target data bandwidth in high-speed channels, an on-board channel modeling study was presented in this paper. A design guideline was found by observing the variation of link performance, depending on parameters such as channel length, baud rate, and the number of signal layers. The channel performance was investigated using a newly developed parametric simulation environment supported by a fast multilayered via transition modeling tool. The extensive parameter sweep simulations showed that an allowable channel reach has a lower and an upper bound limited by stub via effect and trace loss, respectively. Under a specified channel reach, the aggregate data bandwidths were estimated using a particle swarm optimization routine, and a tradeoff relation among the wiring capability and the maximum allowable data rate was observed. From these observations, the approach provides a guideline to select the number of signal layers for achieving the required data bandwidth.","Bandwidth,
Data models,
Guidelines,
Channel estimation,
Channel models,
Manufacturing,
Integrated circuit modeling"
Glottal Spectral Separation for Speech Synthesis,"This paper proposes an analysis method to separate the glottal source and vocal tract components of speech that is called Glottal Spectral Separation (GSS). This method can produce high-quality synthetic speech using an acoustic glottal source model. In the source-filter models commonly used in speech technology applications it is assumed the source is a spectrally flat excitation signal and the vocal tract filter can be represented by the spectral envelope of speech. Although this model can produce high-quality speech, it has limitations for voice transformation because it does not allow control over glottal parameters which are correlated with voice quality. The main problem with using a speech model that better represents the glottal source and the vocal tract filter is that current analysis methods for separating these components are not robust enough to produce the same speech quality as using a model based on the spectral envelope of speech. The proposed GSS method is an attempt to overcome this problem, and consists of the following three steps. Initially, the glottal source signal is estimated from the speech signal. Then, the speech spectrum is divided by the spectral envelope of the glottal source signal in order to remove the glottal source effects from the speech signal. Finally, the vocal tract transfer function is obtained by computing the spectral envelope of the resulting signal. In this work, the glottal source signal is represented using the Liljencrants-Fant model (LF-model). The experiments we present here show that the analysis-synthesis technique based on GSS can produce speech comparable to that of a high-quality vocoder that is based on the spectral envelope representation. However, it also permit control over voice qualities, namely to transform a modal voice into breathy and tense, by modifying the glottal parameters.",
Effects of Phasor Measurement Uncertainty on Power Line Outage Detection,"Phasor measurement unit (PMU) technology provides an effective tool to enhance the wide-area monitoring systems (WAMSs) in power grids. Although extensive studies have been conducted to develop several PMU applications in power systems (e.g., state estimation, oscillation detection and control, voltage stability analysis, and line outage detection), the uncertainty aspects of PMUs have not been adequately investigated. This paper focuses on quantifying the impact of PMU uncertainty on power line outage detection and identification, in which a limited number of PMUs installed at a subset of buses are utilized to detect and identify the line outage events. Specifically, the line outage detection problem is formulated as a multi-hypothesis test, and a general Bayesian criterion is used for the detection procedure, in which the PMU uncertainty is analytically characterized. We further apply the minimum detection error criterion for the multi-hypothesis test and derive the expected detection error probability in terms of PMU uncertainty. The framework proposed provides fundamental guidance for quantifying the effects of PMU uncertainty on power line outage detection. Case studies are provided to validate our analysis and show how PMU uncertainty influences power line outage detection.","Phasor measurement units,
Measurement uncertainty,
Bayes methods,
Smart grids,
Error probability"
Efficient segmentation methods for tumor detection in MRI images,"Brain tumor extraction and its analysis are challenging tasks in medical image processing because brain image and its structure is complicated that can be analyzed only by expert radiologists. Segmentation plays an important role in the processing of medical images. MRI (magnetic resonance imaging) has become a particularly useful medical diagnostic tool for diagnosis of brain and other medical images. This paper presents a comparative study of three segmentation methods implemented for tumor detection. The methods include k-means clustering with watershed segmentation algorithm, optimized k-means clustering with genetic algorithm and optimized c- means clustering with genetic algorithm. Traditional k-means algorithm is sensitive to the initial cluster centers. Genetic c-means and k-means clustering techniques are used to detect tumor in MRI of brain images. At the end of process the tumor is extracted from the MR image and its exact position and the shape are determined. The experimental results indicate that genetic c-means not only eliminate the over-segmentation problem, but also provide fast and efficient clustering results.","Tumors,
Clustering algorithms,
Image segmentation,
Magnetic resonance imaging,
Genetic algorithms,
Sociology,
Statistics"
A learning based approach to control synthesis of Markov decision processes for linear temporal logic specifications,"We propose to synthesize a control policy for a Markov decision process (MDP) such that the resulting traces of the MDP satisfy a linear temporal logic (LTL) property. We construct a product MDP that incorporates a deterministic Rabin automaton generated from the desired LTL property. The reward function of the product MDP is defined from the acceptance condition of the Rabin automaton. This construction allows us to apply techniques from learning theory to the problem of synthesis for LTL specifications even when the transition probabilities are not known a priori. We prove that our method is guaranteed to find a controller that satisfies the LTL property with probability one if such a policy exists, and we suggest empirically that our method produces reasonable control strategies even when the LTL property cannot be satisfied with probability one.",
Language independent analysis and classification of discussion threads in Coursera MOOC forums,"In this work, we analyze the discussion threads from the forums of 60 Massive Open Online Courses (MOOCs) offered by Coursera and taught in 4 different languages. The types of interactions in such threads vary: there are discussions on close ended problems (e.g. solutions to assignments), open ended topics, course logistics, or just small talk among fellow students. We first study the evolution of the forum activities with respect to the normalized course duration. Then we investigate several language independent features to classify the discussion threads based on the types of the interactions among the users. We use default Coursera subforum categories (Study Groups, Assignments, Lectures, ...) to define the classes of interest and so the labels. We extract features related to structure, popularity, temporal dynamics of threads and diversity of the ids of the users. Text related features, word count aside, are avoided to apply the methods across discussion threads written in different languages and with various technical terminologies. Experiments show a classification performance with ROCAUC between 0.58 and 0.89, depending on the subforum class considered and with possibly noisy labels.","Message systems,
Computer science,
Communities,
Educational institutions,
Logistics,
Feature extraction"
Differentiating Between Psychogenic Nonepileptic Seizures and Epilepsy Based on Common Spatial Pattern of Weighted EEG Resting Networks,"Discriminating psychogenic nonepileptic seizures (PNES) from epilepsy is challenging, and a reliable and automatic classification remains elusive. In this study, we develop an approach for discriminating between PNES and epilepsy using the common spatial pattern extracted from the brain network topology (SPN). The study reveals that 92% accuracy, 100% sensitivity, and 80% specificity were reached for the classification between PNES and focal epilepsy. The newly developed SPN of resting EEG may be a promising tool to mine implicit information that can be used to differentiate PNES from epilepsy.","Epilepsy,
Electroencephalography,
Network topology,
Educational institutions,
Feature extraction,
Electrodes,
Coherence"
RSU cloud and its resource management in support of enhanced vehicular applications,"We propose Roadside Unit (RSU) Clouds as a novel way to offer non-safety application with QoS for VANETs. The architecture of RSU Clouds is delineated, and consists of traditional RSUs and specialized micro-datacenters and virtual machines (VMs) using Software Defined Networking (SDN). SDN offers the flexibility to migrate or replicate virtual services and reconfigure the data forwarding rules dynamically. However, frequent changes to service hosts and data flows not only result in degradation of services, but are also costly for service providers. In this paper, we use Mininet to analyze and formally quantify the reconfiguration overhead. Our unique RSU Cloud Resource Management (CRM) model jointly minimizes reconfiguration overhead, cost of service deployment and infrastructure routing delay. To the best of our knowledge, we are the first to utilize this approach. We compare the performance of purist approach to our Integer Linear Programming (ILP) model and our innovative heuristic for the CRM technique and discuss the results. We will show the benefits of a holistic approach in Cloud Resource Management with SDN.",
A seamless handover for WSN using LMS filter,"We propose a MAC protocol that supports the mobility of nodes in wireless sensor networks. The protocol enables burst transmission and seamless handover to achieve high throughput and to reduce packet delivery latency and packet loss. An adaptive filter continuously evaluates the RSSI values of received acknowledgment packets and decides whether a mobile node should transfer a communication to a nearby relay node with a better link quality. The handover process itself takes place without breaking an existing link. This paper presents the design, implementation and evaluation of the MAC protocol.","Adaptive filters,
Media Access Protocol,
Access control"
Modeling Biological Pathway Dynamics With Timed Automata,"Living cells are constantly subjected to a plethora of environmental stimuli that require integration into an appropriate cellular response. This integration takes place through signal transduction events that form tightly interconnected networks. The understanding of these networks requires capturing their dynamics through computational support and models. ANIMO (analysis of Networks with Interactive Modeling) is a tool that enables the construction and exploration of executable models of biological networks, helping to derive hypotheses and to plan wet-lab experiments. The tool is based on the formalism of Timed Automata, which can be analyzed via the UPPAAL model checker. Thanks to Timed Automata, we can provide a formal semantics for the domain-specific language used to represent signaling networks. This enforces precision and uniformity in the definition of signaling pathways, contributing to the integration of isolated signaling events into complex network models. We propose an approach to discretization of reaction kinetics that allows us to efficiently use UPPAAL as the computational engine to explore the dynamic behavior of the network of interest. A user-friendly interface hides the use of Timed Automata from the user, while keeping the expressive power intact. Abstraction to single-parameter kinetics speeds up construction of models that remain faithful enough to provide meaningful insight. The resulting dynamic behavior of the network components is displayed graphically, allowing for an intuitive and interactive modeling experience.",
Leaky-Wave Antennas Using Negative-Refractive-Index Transmission-Line Metamaterial Supercells,"Leaky-wave antennas (LWAs) are designed based on supercells which are expanded versions of conventional negative-refractive-index transmission line (NRI-TL) unit cells. In the proposed LWAs with NRI-TL supercells, the number and values of inductors are reduced by half, decreasing the complexity of their design and reducing the Ohmic loss, which increases the antenna gain and efficiency. Compared with conventional NRI-TL unit cells, NRI-TL supercells operate over narrower bandwidth while showing proper Bloch impedance behavior over both left-hand (LH) and right-hand (RH) regions, leading to broadband impedance matching. Using coplanar waveguide (CPW) technology, closed-stopband LWAs based on NRI-TL supercells are designed, and their performance compared with that of the conventional unit cell LWAs. Finally, by using CPW supercells with a backing ground and vias, high-gain LWAs with sharp beams and suppressed backlobes are designed and realized.","Dispersion,
Inductors,
Shunts (electrical),
Coplanar waveguides,
Loading,
Impedance,
Bandwidth"
On the secrecy capacity of the MISO wiretap channel under imperfect channel estimation,"We consider a wiretap channel consisting of a source with multiple antennas, a legitimate receiver and an eavesdropper with a single antenna each. The channels between the source and the receivers undergo fast fading. We assume that the transmitter, in addition to the statistics of both channels, is only aware of a noisy version of the CSI to the legitimate receiver referred to as main channel. The legitimate receiver is aware of both its instantaneous channel gain and the transmitter's estimate of the main channel. On the other hand, the eavesdropper's receiver, in addition to its instantaneous channel realization, is aware of the actual main CSI and the transmitter's estimate as well. While the capacity of this channel is still open even with perfect CSI at the transmitter, we provide in this paper upper and lower bounds on the secrecy capacity. The upper bound is tighter than the one corresponding to perfect main CSI and the gap between the two upper bounds is characterized in function of the channel estimation error variance, at high-SNR. Furthermore, we show that our upper and lower bounds coincide in the case of no main CSI providing a trivial secrecy capacity.","Receivers,
Transmitters,
Upper bound,
Channel estimation,
Eigenvalues and eigenfunctions,
Fading,
Channel capacity"
Understanding the limitations and impact factors of wide bandgap devices' high switching-speed capability in a voltage source converter,"This paper focuses on understanding the key impacting factors for switching speed of wide bandgap (WBG) devices in a voltage source converter. First, the constraints and challenges of WBG devices during fast switching transients are summarized. Special attention is given to the transient gate-source and drain-source voltages. Second, the impacts of major components in voltage source converter, including gate drivers, parasitics, inductive loads, and cooling systems, on the switching performance of power devices are systematically investigated. The critical parameters for each component are highlighted. Finally, design criteria are suggested to maximize switching speed of WBG devices.","Switches,
Logic gates,
Transient analysis,
Induction motors,
Capacitance,
Impedance,
Performance evaluation"
Subcarrier and power optimization for device-to-device underlay communication using auction games,"An auction-based joint subcarrier and power allocation approach is investigated to improve the performance of device-to-device (D2D) communication underlay cellular networks with uplink (UL) resource sharing. To maximize the system sum rate over the resource reuse of multiple D2D pairs, we introduce a reverse iterative combinatorial auction to formulate the optimization problem. In the auction, cellular channels are viewed as bidders competing to obtain rate increase while packages of D2D pairs and the corresponding transmit power are auctioned as goods in each round. We first give the evaluation of bidders' optimal value for packages, and then explain a descending price auction in detail, also give properties of convergency and low-complexity. The simulation results are finally provided to indicate the efficiency of the proposed auction-based algorithm.","Resource management,
Cost accounting,
Interference,
Joints,
Optimization,
Games,
Wireless communication"
Using multi-level cell STT-RAM for fast and energy-efficient local checkpointing,"High reliability, availability, and serviceability are critical for modern large-scale computing systems. As an effective error recovery mechanism, checkpointing has been widely used in such systems for their survival from unexpected failures. The conventional checkpointing schemes, however, are time-consuming due to the limited I/O bandwidth between the DRAM-based main memory and the backup storage. To mitigate the checkpoint overhead, we propose a fast local checkpointing scheme by leveraging Multi-Level Cell (MLC) STT-RAM. We take advantage of the unique features of MLC STT-RAM to accelerate local checkpointing. Our experimental results show that the average performance overhead is less than 1% in a multi-programmed four-core process node with a 1-second local checkpoint interval. The evaluation results also demonstrate that using MLC STT-RAM is an energy-efficient solution.","Checkpointing,
Phase change random access memory,
Nonvolatile memory,
Magnetic tunneling,
Switches,
Resistance"
Spark-based anomaly detection over multi-source VMware performance data in real-time,"Anomaly detection refers to identifying the patterns in data that deviate from expected behavior. These non-conforming patterns are often termed as outliers, malwares, anomalies or exceptions in different application domains. This paper presents a novel, generic real-time distributed anomaly detection framework for multi-source stream data. As a case study, we have decided to detect anomaly for multi-source VMware-based cloud data center. The framework monitors VMware performance stream data (e.g., CPU load, memory usage, etc.) continuously. It collects these data simultaneously from all the VMwares connected to the network. It notifies the resource manager to reschedule its resources dynamically when it identifies any abnormal behavior of its collected data. We have used Apache Spark, a distributed framework for processing performance stream data and making prediction without any delay. Spark is chosen over a traditional distributed framework (e.g., Hadoop and MapReduce, Mahout, etc.) that is not ideal for stream data processing. We have implemented a flat incremental clustering algorithm to model the benign characteristics in our distributed Spark based framework. We have compared the average processing latency of a tuple during clustering and prediction in Spark with Storm, another distributed framework for stream data processing. We experimentally find that Spark processes a tuple much quicker than Storm on average.","Sparks,
Real-time systems,
Data models,
Training,
Clustering algorithms,
Predictive models,
Dynamic scheduling"
TSV-to-TSV inductive coupling-aware coding scheme for 3D Network-on-Chip,"A reliable Three Dimensional Network-on-Chip (3D NoC) is required for future many-core systems. Through-silicon Via (TSV) is the prominent component of 3D NoC to support better performance and lower power consumption. Inductive TSV coupling has large disruptive effects on Signal Integrity (SI) and transmission delay. In this paper, TSV inductive coupling is analyzed based on technology process, TSV length, and TSV radius for a range of frequencies. A classification of inductive coupling voltage is presented for different TSV configurations. A novel coding technique is devised to mitigate the inductive coupling effects by adjusting the current flow pattern. Simulations for a 4×8 TSV matrix show 23% coupled voltage mitigation, imposing 12.5% information redundancy.","Through-silicon vias,
Couplings,
Encoding,
Three-dimensional displays,
Fault tolerance,
Fault tolerant systems,
Receivers"
Iterative refinement of multiple targets tracking of solar events,"In this paper, we combine two approaches to multiple-target tracking: the first is a hierarchical approach to iteratively growing track fragments across gaps in detections, and the second is a network flow based optimization method for data association. We introduce a new parallel algorithm for initial track fragment formation as the base of the hierarchical approach. The network flow based optimization method is then utilized for the remaining levels of the hierarchy. This process is applied to solar data retrieved from the Heliophysics Event Knowledgebase (HEK). We compare our results to labeled data from the same, and show improvements over a non-hierarchical sequential approach.",
Closed form fuzzy interpolation with interval type-2 fuzzy sets,"Fuzzy rule interpolation enables fuzzy inference with sparse rule bases by interpolating inference results, and may help to reduce system complexity by removing similar (often redundant) neighbouring rules. In particular, the recently proposed closed form fuzzy interpolation offers a unique approach which guarantees convex interpolated results in a closed form. However, the difficulty in defining the required precise-valued membership functions still poses significant restrictions over the applicability of this approach. Such limitations can be alleviated by employing type-2 fuzzy sets as their membership functions are themselves fuzzy. This paper extends the closed form fuzzy rule interpolation using interval type-2 fuzzy sets. In this way, as illustrated in the experiments, closed form fuzzy interpolation is able to deal with uncertainty in data and knowledge with more flexibility.",
Rethinking RAID-5 Data Layout for Better Scalability,"In RAID-5, data and parity blocks are distributed across all disks in a round-robin fashion. Previous approaches to RAID-5 scaling preserve such round-robin distribution, therefore requiring all the data to be migrated. In this paper, we rethink RAID-5 data layout and propose a new approach to RAID-5 scaling called MiPiL. First, MiPiL minimizes data migration while maintaining a uniform data distribution, not only for regular data but also for parity data. It moves the minimum number of data blocks from old disks to new disks for regaining a uniform data distribution. Second, MiPiL optimizes online data migration with piggyback parity updates and lazy metadata updates. Piggyback parity updates during data migration reduce the numbers of additional XOR computations and disk I/Os. Lazy metadata updates minimize the number of metadata writes without compromising data reliability. We implement MiPiL in Linux Kernel 2.6.32.9, and evaluate its performance by replaying three real-system traces. The results demonstrate that MiPiL consistently outperforms the existing “moving-everything” approach by 74.07-77.57% in redistribution time and by 25.78-70.50% in user response time. The experiments also illustrate that under the WebSearch2 and Financial1 workloads, the performance of the RAID-5 scaled using MiPiL is almost identical to that of the round-robin RAID-5.","Metadata,
Disk arrays,
Data models,
Parity check codes"
A Multi-Agent based vehicles re-routing system for unexpected traffic congestion avoidance,"As urbanization has been spreading across the world for decades, the traffic congestion problem becomes increasingly serious in most of the major cities. Among the root causes of urban traffic congestion, en route events are the main source of the sudden increase of the road traffic load, especially during peak hours. The current solutions, such as on-board navigation systems for individual vehicles, can only provide optimal routes using current traffic data without considering any traffic changes in the future. Those solutions are thus unable to provide a better alternative route quickly enough if an unexpected congestion occurs. Moreover, using the same alternative routes may lead to new bottlenecks that cannot be avoided. Thus a global traffic load balance cannot be achieved. To deal with these problems, we propose a Multi Agent System (MAS) that can achieve a trade-off between the individual and global benefits by giving the vehicles optimal turn suggestions to bypass a blocked road ahead. The simulation results show that our strategy achieves a substantial gain in average trip time reduction under realistic scenarios. Moreover, the negative impact of selfish re-routing is investigated to show the importance of altruistic re-routing applied in our strategy.","Vehicles,
Roads,
Resource management,
Navigation,
Educational institutions,
Junctions,
Cities and towns"
100-kV High Voltage Power Supply With Bipolar Voltage Output and Adaptive Digital Control,"This paper presents a 100-kV high frequency transformer/rectifier package, which is capable of a dual output polarity operation. An H-Bridge inverter drives the primary of the high voltage (HV) transformer at a frequency of 20 kHz. The inverter is driven by a Microchip dsPIC33F digital signal controller using peak current mode control with adaptive slope compensation. The HV-tank has two HV-coax output cables with a grounded shield on each cable. If the center conductor of the coax cable designated as negative output is grounded, positive voltage is obtained from the coax cable designated as positive output and vice versa. This paper provides design details and experimental results from tests of the entire system.",
Mobility-aware trustworthy crowdsourcing in cloud-centric Internet of Things,"In the Internet of Things (IoT) era, smart devices that are equipped with various types of sensors can enable access to the IoT architecture through a cloud-inspired service model, namely Sensing-as-a-Service (S2aaS). S2aaS can provide crowdsourced data to an application running on a cloud platform. The crowdsourced data can be used for several purposes such as public safety. One of the biggest challenges here is the incentive mechanisms for the users who are requested to provide S2aaS. In this paper, we propose mobility-aware trustworthy crowdsourcing (MATCS) framework in a cloud-centric IoT architecture which adopts and extends a previous scheme, Trustworthy Sensing for Crowd Management (TSCM) [1] by incorporating user mobility-awareness in the presence of maliciously altered sensing data. MATCS employs a user-centric incentive mechanism which collects sensing data based on an auction procedure. In the auction procedure, MATCS uses users' reputations, bids, current location and their estimated dislocation during crowdsourcing process. Furthermore, in order to investigate the benefits of reputation-awareness, we also propose reputation-unaware Mobility-Aware Crowdsourcing (MACS). Performance of MATCS is evaluated via simulations, and it is compared to MACS and a benchmark scheme, which aims at making a compromise between the utilities of the users and the platform by considering neither mobility nor trustworthiness. Simulation results confirm that mobility-awareness improves the utility of the platform significantly whereas combining reputation-awareness and mobility-awareness by MATCS can triple the improvement. Besides, user incomes are not significantly impacted by MACS or MATCS when users are mobile. Furthermore, maliciously altered data ratio can be degraded by 20%~55% by reputation-awareness in MATCS.","Sensors,
Cities and towns,
Crowdsourcing,
Safety,
Social network services,
Cloud computing,
Computer architecture"
Evolution and Controllability of Cancer Networks: A Boolean Perspective,"Cancer forms a robust system capable of maintaining stable functioning (cell sustenance and proliferation) despite perturbations. Cancer progresses as stages over time typically with increasing aggressiveness and worsening prognosis. Characterizing these stages and identifying the genes driving transitions between them is critical to understand cancer progression and to develop effective anti-cancer therapies. In this work, we propose a novel model for the `cancer system' as a Boolean state space in which a Boolean network, built from protein-interaction and gene-expression data from different stages of cancer, transits between Boolean satisfiability states by “editing” interactions and “flipping” genes. Edits reflect rewiring of the PPI network while flipping of genes reflect activation or silencing of genes between stages. We formulate a minimization problem min flip to identify these genes driving the transitions. The application of our model (called BoolSpace) on three case studies-pancreatic and breast tumours in human and post spinal-cord injury (SCI) in rats-reveals valuable insights into the phenomenon of cancer progression: (i) interactions involved in core cell-cycle and DNA-damage repair pathways are significantly rewired in tumours, indicating significant impact to key genome-stabilizing mechanisms; (ii) several of the genes flipped are serine/threonine kinases which act as biological switches, reflecting cellular switching mechanisms between stages; and (iii) different sets of genes are flipped during the initial and final stages indicating a pattern to tumour progression. Based on these results, we hypothesize that robustness of cancer partly stems from “passing of the baton” between genes at different stages-genes from different biological processes and/or cellular components are involved in different stages of tumour progression thereby allowing tumour cells to evade targeted therapy, and therefore an effective therapy should target a “cover set” of these genes. A C/C++ implementation of BoolSpace is freely available at: http://www.bioinformatics.org.au/tools-data.",
Agile Urban Parking Recommendation Service for Intelligent Vehicular Guiding System,"Nowadays, Intelligent Transportation Systems (ITS) technologies are exploring a wide range of services such as freeway management, crash prevention & safety, driver assistance, and infotainment of drivers and/or passengers. In this paper, an agile urban parking recommendation service for vehicular intelligent guiding system is designed to facilitate city citizens with fully efficient, real-time and precise parking lot guiding suggestions for the sustainability of the future green city. The system offers drivers a friendly parking lot recommendation sequence and saves driver's time circling around by the accurate prediction of the successful parking probability in each parking lot. The proposed cost model constructs an optimal recommendation sequence considering successful parking probability and time to reach the parking lot. Through the collection and analysis of realistic records from parking lots in Taipei city, a prediction algorithm is developed to estimate the successful parking probability by using current available space counts. Extensive experiments are conducted to demonstrate the effectiveness of the prediction algorithm.","Road vehicles,
Urban areas,
Traffic control,
Real-time systems,
Prediction algorithms"
Characterizing flexibility of an aggregation of deferrable loads,"Flexibility from distributed deferrable loads presents an enormous potential to provide fast ramping resources that are necessary to vastly integrate renewable energy resources. In this paper, we study aggregation, characterization, and scheduling of a collection of deferrable loads to facilitate integrating renewable generation into the power system. A generation profile is called exactly adequate if there exists a scheduling policy that could allocate the power to satisfy the energy requirements of all deferrable loads without surplus or deficit. We provide sufficient and/or necessary characterizations on the adequacy of allocated generation profiles. Moreover, we propose a novel scheduling algorithm to service deferrable loads. Heuristic algorithms such as Earliest Deadline First (EDF) and Least Laxity First (LLF) policies are used in numerical experiments to compare with the proposed algorithm. Extensive simulations show that our scheduling policy generally can fulfill the energy requirements of all loads without surplus or deficit for exactly adequate generation profiles, while the EDF and LLF policies cannot meet this objective in most cases.","Batteries,
Heuristic algorithms,
Load modeling,
Scheduling algorithms,
Vectors,
Scheduling,
Upper bound"
Iterative Discovery of Multiple AlternativeClustering Views,"Complex data can be grouped and interpreted in many different ways. Most existing clustering algorithms, however, only find one clustering solution, and provide little guidance to data analysts who may not be satisfied with that single clustering and may wish to explore alternatives. We introduce a novel approach that provides several clustering solutions to the user for the purposes of exploratory data analysis. Our approach additionally captures the notion that alternative clusterings may reside in different subspaces (or views). We present an algorithm that simultaneously finds these subspaces and the corresponding clusterings. The algorithm is based on an optimization procedure that incorporates terms for cluster quality and novelty relative to previously discovered clustering solutions. We present a range of experiments that compare our approach to alternatives and explore the connections between simultaneous and iterative modes of discovery of multiple clusterings.",
"Diversified Key-Frame Selection Using Structured {L_{2,1}} Optimization","In this paper, a structured L2,1 optimization model, which simultaneously characterizes the reconstruction capability and diversity, is proposed to provide a semantically meaningful representation of a short video clip acquired from digital cameras or a mobile robot. In this model, a mutual inhabitation penalty term is imposed to prevent similar samples from being selected simultaneously. The proposed model is highly flexible to incorporate different mutual inhabitation terms and the temporal redundancy in video is exploited to encourage the diversity. The constructed objective function is nonconvex and an iterative algorithm is developed to solve the optimization problem. The performance is evaluated using various video clips from YouTube and also based on practical video captured by an indoor mobile robot. The results clearly indicate that the proposed strategy helps the optimization model to achieve more diversified key frames than the other existing work method.","Optimization,
Dictionaries,
Encoding,
Linear programming,
Image reconstruction,
Iterative methods,
Vectors"
On the Identification of Circulating Tumor Cells in Breast Cancer,"Breast cancer is a highly heterogeneous disease and very common among western women. The main cause of death is not the primary tumor but its metastases at distant sites, such as lymph nodes and other organs (preferentially lung, liver, and bones). The study of circulating tumor cells (CTCs) in peripheral blood resulting from tumor cell invasion and intravascular filtration highlights their crucial role concerning tumor aggressiveness and metastasis. Genomic research regarding CTCs monitoring for breast cancer is limited due to the lack of indicative genes for their detection and isolation. Instead of direct CTC detection, in our study, we focus on the identification of factors in peripheral blood that can indirectly reveal the presence of such cells. Using selected publicly available breast cancer and peripheral blood microarray datasets, we follow a two-step elimination procedure for the identification of several discriminant factors. Our procedure facilitates the identification of major genes involved in breast cancer pathology, which are also indicative of CTCs presence.",
Networked Estimation of Relative Sensing Multiagent Systems Using Reconfigurable Sets of Subobservers,"In this paper, a networked estimation framework for a team of relative sensing multiagent systems is proposed. This framework is constructed based on the developed notion of subobservers (SOs). Within a group of SOs, each SO is estimating certain team states that are conditioned on a given input, output, and other state information. The overall team estimation process is then modeled by a weighted estimation (WE) digraph. By selecting an optimal path in the WE digraph, a high-level supervisor provides a decision on the selection and reconfiguration of the set of SOs to successfully estimate all the states of the multiagent system. In presence of unreliable information due to either large disturbances, noise, and actuator faults, or communication delays certain SOs may become invalid and carry a high cost. In this case, the supervisor reconfigures the set of SOs by selecting a new path in the estimation digraph such that the impacts of these unreliabilities are managed and confined. This will consequently prevent the propagation of unreliabilities to the entire estimation process and avoid performance degradations to the multiagent system. Simulation results are conducted for a five spacecraft formation flight system in deep space where the validity and advantages of our analytical developed schemes are confirmed.","Estimation,
Nonlinear systems,
Multi-agent systems,
Observability,
Actuators,
Sensors"
An SDN-based energy-aware routing model for intra-domain networks,"Energy has become an important issue in many areas due to increasing energy costs and environmental issues. The Internet is one of the major energy consuming areas. In this paper1, we proposed an energy-aware routing and resource management model for large-scale networks by adapting an SDN (Software Defined Networking) based approach. Controller uses pre-established multi-paths (PMPs) and perform routing, admission control based on these paths. PMPs are turned on or off based on traffic conditions to save energy. The experimental results verify the achievements of the proposed model under various traffic conditions.",
A novel cognitive architecture for a human-like virtual player in the mirror game,"The so called mirror game, which in its simplest formulation involves two people mirroring each other's hand's movement, provides a paradigm to study social interaction. However, a customized virtual player can replace either of the two human participants and hopefully help with the rehabilitation of patients suffering from social disorders by regulating its kinematics. In this paper we investigate the coordination movement between an avatar (virtual player) and a human player in the mentioned game. A novel cognitive architecture is proposed to drive the motion of the virtual player so that it generates a human-like trajectory in two different experimental models. In order to achieve this objective, the Haken-Kelso-Bunz (HKB) equation is adopted to describe the social motor coordination between the virtual and the human player. In addition, both an adaptive algorithm for the coupling parameters in the HKB equation and a feedback controller are developed in order to guarantee human features for the virtual player in its kinematics. Finally, extensive experiments are conducted to validate the approach described above.","Games,
Mathematical model,
Mirrors,
Avatars,
Adaptation models,
Time series analysis,
Equations"
"Polar Quantizer for Wireless Receivers: Theory, Analysis, and CMOS Implementation","This paper presents the theory and analysis of IF polar receiver (PRX) architecture. By using new quantization techniques in the polar domain, the proposed receiver can boost the signal to quantization noise ratio (SQNR) compared to a traditional rectangular (I/Q) receiver. The proposed PRX is composed of a magnitude and a phase quantizer. The magnitude quantizer is similar to the conventional rectangular quantizer in voltage domain. The phase quantizer employs a time-to-digital converter (TDC) for phase detection. Furthermore, an intuitive graphical method is used to analyze the quantization properties of the polar quantization. A 10 bit polar quantizer is designed and fabricated in 130 nm CMOS, and achieves 2- to 5-dB of SQNR improvement compared to rectangular quantizer for signal bandwidths as high as 20 MHz.",
Detecting Directionality in Random Fields Using the Monogenic Signal,"Detecting and analyzing directional structures in images is important in many applications since one-dimensional patterns often correspond to important features such as object contours or trajectories. Classifying a structure as directional or nondirectional requires a measure to quantify the degree of directionality and a threshold, which needs to be chosen based on the statistics of the image. In order to do this, we model the image as a random field. So far, little research has been performed on analyzing directionality in random fields. In this paper, we propose a measure to quantify the degree of directionality based on the random monogenic signal, which enables a unique decomposition of a 2-D signal into local amplitude, local orientation, and local phase. We investigate the second-order statistical properties of the monogenic signal for isotropic, anisotropic, and unidirectional random fields. We analyze our measure of directionality for finite-size sample images and determine a threshold to distinguish between unidirectional and nonunidirectional random fields, which allows the automatic classification of images.",
New Insights Into the Single Event Transient Propagation Through Static and TSPC Logic,"An investigation of the Single Event Transient (SET) characteristics (amplitude and width) variation while propagating through static and True Single Phase Clock (TSPC) logic is presented. The dependencies of the SET characteristics on the input patterns, propagation paths, pulse polarity, diverging paths, and re-converging paths are investigated. New insights on the propagation induced pulse broadening (PIPB) phenomenon in different combinations of static and TSPC logic are reported. The worst and the best propagation paths for SET pulse broadening and attenuation are identified. Our results demonstrate that SET pulses propagation can lead to Byzantine faults as they propagate through diverging paths. A new way to abstract all possible interpretations of the SET induced Byzantine fault phenomenon is proposed.","Logic gates,
Clocks,
CMOS integrated circuits,
Transistors,
Pulse generation,
Semiconductor device modeling,
Single event transients"
Reducing Masking Effects in CombinatorialInteraction Testing: A Feedback DrivenAdaptive Approach,"The configuration spaces of modern software systems are too large to test exhaustively. Combinatorial interaction testing (CIT) approaches, such as covering arrays, systematically sample the configuration space and test only the selected configurations. The basic justification for CIT approaches is that they can cost-effectively exercise all system behaviors caused by the settings of t or fewer options. We conjecture, however, that in practice some of these behaviors are not actually tested because of unanticipated masking effects - test case failures that perturb system execution so as to prevent some behaviors from being exercised. While prior research has identified this problem, most solutions require knowing the masking effects a priori. In practice this is impractical, if not impossible. In this work, we reduce the harmful consequences of masking effects. First we define a novel interaction testing criterion, which aims to ensure that each test case has a fair chance to test all valid t-way combinations of option settings. We then introduce a feedback driven adaptive combinatorial testing process (FDA-CIT) to materialize this criterion in practice. At each iteration of FDA-CIT, we detect potential masking effects, heuristically isolate their likely causes (i.e., fault characterization), and then generate new samples that allow previously masked combinations to be tested in configurations that avoid the likely failure causes. The iterations end when the new interaction testing criterion has been satisfied. This paper compares two different fault characterization approaches - an integral part of the proposed approach, and empirically assesses their effectiveness and efficiency in removing masking effects on two widely used open source software systems. It also compares FDA-CIT against error locating arrays, a state of the art approach for detecting and locating failures. Furthermore, the scalability of the proposed approach is evaluated by comparing it with perfect test scenarios, in which all masking effects are known a priori. Our results suggest that masking effects do exist in practice, and that our approach provides a promising and efficient way to work around them, without requiring that masking effects be known a priori.",
W-RGB-D: Floor-plan-based indoor global localization using a depth camera and WiFi,"Localization approaches typically rely on an already available map to identify the position of the sensor in the environment. Such maps are usually built beforehand and often require the user to record data from the same sensor used for localization. In this paper, we relax this assumption and present a localization approach based on architectural floor plans. In general, floor plans are readily available for most man-made buildings but only represent basic architectural structures. The incomplete knowledge leads to ambiguous pose estimates. To solve this problem, we present W-RGB-D, a new method for indoor global localization based on WiFi and an RGB-D camera. We introduce a sensor model for RGB-D cameras that is suitable to be used with abstract floor plans. To resolve ambiguities during global localization, we estimate a coarse initial distribution about the sensor position using the WiFi signal strength. We evaluate our W-RGB-D localization method in indoor environments and compare its performance with RGB-D-based Monte Carlo localization. Our results demonstrate that the use of WiFi information as proposed with our approach improves the localization in terms of convergence speed and quality of the solution.",
Probabilistic Aspect Mining Model for Drug Reviews,"Recent findings show that online reviews, blogs, and discussion forums on chronic diseases and drugs are becoming important supporting resources for patients. Extracting information from these substantial bodies of texts is useful and challenging. We developed a generative probabilistic aspect mining model (PAMM) for identifying the aspects/topics relating to class labels or categorical meta-information of a corpus. Unlike many other unsupervised approaches or supervised approaches, PAMM has a unique feature in that it focuses on finding aspects relating to one class only rather than finding aspects for all classes simultaneously in each execution. This reduces the chance of having aspects formed from mixing concepts of different classes; hence the identified aspects are easier to be interpreted by people. The aspects found also have the property that they are class distinguishing: They can be used to distinguish a class from other classes. An efficient EM-algorithm is developed for parameter estimation. Experimental results on reviews of four different drugs show that PAMM is able to find better aspects than other common approaches, when measured with mean pointwise mutual information and classification accuracy. In addition, the derived aspects were also assessed by humans based on different specified perspectives, and PAMM was found to be rated highest.","Drugs,
Probabilistic logic,
Data models,
Data mining,
Mathematical model,
Noise,
Feature extraction"
Visualizing and Measuring Enterprise Application Architecture: An Exploratory Telecom Case,"We test a method for visualizing and measuring enterprise application architectures. The method was designed and previously used to reveal the hidden internal architectural structure of software applications. The focus of this paper is to test if it can also uncover new facts about the applications and their relationships in an enterprise architecture, i.e., if the method can reveal the hidden external structure between software applications. Our test uses data from a large international telecom company. In total, we analyzed 103 applications and 243 dependencies. Results show that the enterprise application structure can be classified as a core-periphery architecture with a propagation cost of 25%, core size of 34%, and architecture flow through of 64%. These findings suggest that the method could be effective in uncovering the hidden structure of an enterprise application architecture.",
Vision based robot localization by ground to satellite matching in GPS-denied situations,"This paper studies the problem of matching images captured from an unmanned ground vehicle (UGV) to those from a satellite or high-flying vehicle. We focus on situations where the UGV navigates in remote areas with few man-made structures. This is a difficult problem due to the drastic change in perspective between the ground and aerial imagery and the lack of environmental features for image comparison. We do not rely on GPS, which may be jammed or uncertain. We propose a two-step approach: (1) the UGV images are warped to obtain a bird's eye view of the ground, and (2) this view is compared to a grid of satellite locations using whole-image descriptors. We analyze the performance of a variety of descriptors for different satellite map sizes and various terrain and environment types. We incorporate the air-ground matching into a particle-filter framework for localization using the best-performing descriptor. The results show that vision-based UGV localization from satellite maps is not only possible, but often provides better position estimates than GPS estimates, enabling us to improve the location estimates of Google Street View.","Satellites,
Global Positioning System,
Vehicles,
Google,
Databases,
Visualization,
Buildings"
Preventing False Discovery in Interactive Data Analysis Is Hard,"We show that, under a standard hardness assumption, there is no computationally efficient algorithm that given n samples from an unknown distribution can give valid answers to n3+o(1) adaptively chosen statistical queries. A statistical query asks for the expectation of a predicate over the underlying distribution, and an answer to a statistical query is valid if it is ""close"" to the correct expectation over the distribution. Our result stands in stark contrast to the well known fact that exponentially many statistical queries can be answered validly and efficiently if the queries are chosen non-adaptively (no query may depend on the answers to previous queries). Moreover, Dwork et al. [1], showed how to accurately answer exponentially many adaptively chosen statistical queries via a computationally inefficient algorithm. They also gave efficient algorithm that can answer nearly n2 adaptively chosen queries, which shows our result is almost quantitatively tight. Conceptually, our result demonstrates that achieving statistical validity alone can be a source of computational intractability in adaptive settings. For example, in the modern large collaborative research environment, data analysts typically choose a particular approach based on previous findings. False discovery occurs if a research finding is supported by the data but not by the underlying distribution. While the study of preventing false discovery in Statistics is decades old, to the best of our knowledge our result is the first to demonstrate a computational barrier. In particular, our result suggests that the perceived difficulty of preventing false discovery in today's collaborative research environment may be inherent.","Privacy,
Encryption,
Algorithm design and analysis,
Accuracy,
Adaptation models,
Standards,
Polynomials"
Towards Efficient Authenticated Subgraph Query Service in Outsourced Graph Databases,"Graphs are powerful tools suitable for a large variety of applications including chemical databases and the Semantic Web, among others. A fundamental query of graph databases is the subgraph query: given a query graph q, it retrieves the data graphs from a database that contain q. Due to the cost of managing massive data coupled with the computational hardness of subgraph query processing, outsourcing the processing to a third-party service provider is an appealing alternative. However, security properties such as data integrity and the response time are critical Quality of Service (QoS) issues in query services. Unfortunately, to our knowledge, authenticated subgraph query services have not been addressed before. To support the service, we propose Merkle IFTree (MIFTree) where Merkle hash trees are applied into our Intersection-aware Feature-subgraph Tree (IFTree). IFTree aims to minimize I/O in a well-received subgraph query paradigm called the filtering-and-verification framework. The structures that need to be introduced to verification objects ( VOs) and the authentication time are both minimized. Subsequently, the overall response time is minimized. For optimizations, we propose an enhanced authentication method on MIFTree. Our detailed experiments on both real and synthetic datasets demonstrate that MIFTree is clearly more efficient than a baseline method.",
Conservative edge sparsification for graph SLAM node removal,"This paper reports on optimization-based methods for producing a sparse, conservative approximation of the dense potentials induced by node marginalization in simultaneous localization and mapping (SLAM) factor graphs. The proposed methods start with a sparse, but overconfident, Chow-Liu tree approximation of the marginalization potential and then use optimization-based methods to adjust the approximation so that it is conservative subject to minimizing the Kullback-Leibler divergence (KLD) from the true marginalization potential. Results are presented over multiple real-world SLAM graphs and show that the proposed methods enforce a conservative approximation, while achieving low KLD from the true marginalization potential.",
Skill-based differences in spatio-temporal team behaviour in defence of the Ancients 2 (DotA 2),"Multiplayer Online Battle Arena (MOBA) games are among the most played digital games in the world. In these games, teams of players fight against each other in arena environments, and the gameplay is focussed on tactical combat. In this paper, we present three data-driven measures of spatio-temporal behaviour in Defence of the Ancients 2 (DotA 2): 1) Zone changes; 2) Distribution of team members and: 3) Time series clustering via a fuzzy approach. We present a method for obtaining accurate positional data from DotA 2. We investigate how behaviour varies across these measures as a function of the skill level of teams, using four tiers from novice to professional players. Results from three analyses indicate that spatio-temporal behaviour of MOBA teams is highly related to team skill.","Games,
Valves,
Trajectory,
Communities,
Data mining,
Poles and towers,
Artificial intelligence"
Hidden in plain sight: Automatically identifying security requirements from natural language artifacts,"Natural language artifacts, such as requirements specifications, often explicitly state the security requirements for software systems. However, these artifacts may also imply additional security requirements that developers may overlook but should consider to strengthen the overall security of the system. The goal of this research is to aid requirements engineers in producing a more comprehensive and classified set of security requirements by (1) automatically identifying security-relevant sentences in natural language requirements artifacts, and (2) providing context-specific security requirements templates to help translate the security-relevant sentences into functional security requirements. Using machine learning techniques, we have developed a tool-assisted process that takes as input a set of natural language artifacts. Our process automatically identifies security-relevant sentences in the artifacts and classifies them according to the security objectives, either explicitly stated or implied by the sentences. We classified 10,963 sentences in six different documents from healthcare domain and extracted corresponding security objectives. Our manual analysis showed that 46% of the sentences were security-relevant. Of these, 28% explicitly mention security while 72% of the sentences are functional requirements with security implications. Using our tool, we correctly predict and classify 82% of the security objectives for all the sentences (precision). We identify 79% of all security objectives implied by the sentences within the documents (recall). Based on our analysis, we develop context-specific templates that can be instantiated into a set of functional security requirements by filling in key information from security-relevant sentences.","Security,
Natural languages,
Object recognition,
Software systems,
Availability,
Medical services,
Text categorization"
An Extraction of Two-Port Noise Parameters From Measured Noise Powers Using an Extended Six-Port Network,"In this paper, we present a formulation for extracting the noise wave correlation matrix of a linear two-port device-under-test (DUT) from measured noise powers using a designed six-port network. The noise powers are measured using a conventional noise figure analyzer. The extracted noise wave correlation matrix can then be converted into conventional two-port noise parameters. The proposed measurement equipment is very simple and leads to a very low cost. The proposed method is experimentally verified through measurements of various DUT samples.","Noise,
Ports (Computers),
Noise measurement,
Impedance,
Tuners,
Correlation,
Vectors"
Internet of things in home automation and energy efficient smart home technologies,"This paper explores the history and implementation of the Internet of Things and how it can be used in home automation. Smart homes can have great benefits for energy and water management, comfort and conveniences, and even for helping impoverished people save money on their basic needs, which will be explored later on in the paper. The conclusion of the paper reviews modern technology and determines how close implementation actually is.",
Perceptual computing based performance control mechanism for power efficiency in mobile embedded systems,"A computing with words/Per-C based user feedback collection model for controlling the processor power efficiency is introduced. Needless to say that CWW/Per-C is a very efficient tool in modelling human perceptions. Here the objects of computation are the words drawn from natural language instead of numbers [22], [23]. Perceptions alone don't make the sole criteria rather the backed logic of reasoning is also a supportive tool in the same scenario. In our present work, we have proposed a new algorithm viz. UFOPeC (user feedback optimized perceptual computing) for obtaining the optimal power efficiency in adaptive computing systems that can run at multiple operating voltages. Our approach models the user satisfaction very well and more realistically as compared to than the other existing mechanisms like HAPPE [1] as we have taken the user feedback in terms of words and modelled the same using the IT2 FSs (interval type-2 fuzzy sets). An appropriate numerical example has been chosen to demonstrate the design of our model.","Frequency selective surfaces,
Uncertainty,
Computational modeling,
Decoding,
Adaptation models,
Pragmatics,
Decision making"
A Joint FED Watermarking System Using Spatial Fusion for Verifying the Security Issues of Teleradiology,"Teleradiology allows transmission of medical images for clinical data interpretation to provide improved e-health care access, delivery, and standards. The remote transmission raises various ethical and legal issues like image retention, fraud, privacy, malpractice liability, etc. A joint FED watermarking system means a joint fingerprint/encryption/dual watermarking system is proposed for addressing these issues. The system combines a region based substitution dual watermarking algorithm using spatial fusion, stream cipher algorithm using symmetric key, and fingerprint verification algorithm using invariants. This paper aims to give access to the outcomes of medical images with confidentiality, availability, integrity, and its origin. The watermarking, encryption, and fingerprint enrollment are conducted jointly in protection stage such that the extraction, decryption, and verification can be applied independently. The dual watermarking system, introducing two different embedding schemes, one used for patient data and other for fingerprint features, reduces the difficulty in maintenance of multiple documents like authentication data, personnel and diagnosis data, and medical images. The spatial fusion algorithm, which determines the region of embedding using threshold from the image to embed the encrypted patient data, follows the exact rules of fusion resulting in better quality than other fusion techniques. The four step stream cipher algorithm using symmetric key for encrypting the patient data with fingerprint verification system using algebraic invariants improves the robustness of the medical information. The experiment result of proposed scheme is evaluated for security and quality analysis in DICOM medical images resulted well in terms of attacks, quality index, and imperceptibility.","Watermarking,
Biomedical imaging,
Encryption,
Ciphers,
Authentication,
Equations"
RGB-D object classification using covariance descriptors,"In this paper, we introduce a new covariance based feature descriptor to be used on “colored” point clouds gathered by a mobile robot equipped with an RGB-D camera. Although many recent descriptors provide adequate results, there is not yet a clear consensus on how to best tackle “colored” point clouds. We present the notion of a covariance on RGB-D data. Covariances have not only been proven to be successful in image processing, but in other domains as well. Their main advantage is that they provide a compact and flexible description of point clouds. Our work is a first step towards demonstrating the usability of the concept of covariances in conjunction with RGB-D data. Experiments performed on an RGB-D database and compared to previous results show the increased performance of our method.",
A 94-GHz Extremely Thin Metasurface-Based BiCMOS On-Chip Antenna,"A novel fully on-chip antenna based on a metasurface fabricated in a 180-nm BiCMOS process is presented. Inspired by the concept of high impedance surface (HIS), this metasurface is not used as a reflector below an antenna as commonly done. Instead, it is used as a radiator by itself. The extremely thin metasurface is composed of a patterned top two metal layers and the ground plane placed in the lowest metal layer in the process. The ground plane on the lowest metal layer of the process provides a solid shielding from the substrate and other possible circuitries. The fundamental of the antenna radiation and design are described. The measured antenna shows -2.5 dBi peak broadside gain with 8-GHz 3-dB gain bandwidth and an impedance bandwidth larger than 10 GHz. In its class of broadside radiating fully on-chip antennas, with a ground plane on the lower metal layer of the process, and without additional fabrication processing, this structure achieves the widest impedance bandwidth at W-band and one of the highest gain and gain bandwidth. It is noteworthy that this is achieved with an extremely thin antenna substrate thickness and a shielding ground plane.",
SupraPeds: Humanoid contact-supported locomotion for 3D unstructured environments,"Maintaining humanoid robot stability in unstructured environments is nontrivial because robots lack humanlike tactile sensing and require complex task-specific controllers to integrate information from multiple sensors. To deploy humanoid robots in cluttered and unstructured environments such as disaster sites, it is necessary to develop advanced techniques in both locomotion and control. This paper proposes to incorporate a pair of actuated smart staffs with vision and force sensing that transforms biped humanoids into tripeds or quadrupeds or more generally, SupraPeds. The concept of SuprePeds not only improves the stability of humanoid robots while traversing rough terrain but also retains the manipulation capabilities. In order to control the potentially numerous contact forces on SupraPeds, we develop a friction-consistent whole-body control framework that implements generic multi-contact control for arbitrary humanoids, which enables autonomous balancing while complying with friction constraints. The simulation results are presented to demonstrate that the proposed control framework can efficiently deal with multi-contact locomotion in 3D unstructured environments.","Robot sensing systems,
Force,
Humanoid robots,
Friction,
Three-dimensional displays"
Securing underwater acoustic communications through analog network coding,"We propose a new secure underwater acoustic communication scheme designed to let a user (Alice) transmit a confidential message to another user (Bob) in the presence of an eavesdropper (Eve). A typical approach in conventional wireless physical-layer security is to rely on a friendly jammer to jam Eve through artificial noise (AN). Instead, for the first time, we propose a secure underwater communication scheme that relies on cooperative friendly jamming through CDMA-based analog network coding (ANC). The cooperative friendly jammer transmits information using the same spreading code used in the legitimate Alice-Bob link. The information transmitted by the cooperative jammer is known a priori to Bob, but not to Eve. Although the jammer's packet will also interfere at Bob, we show that after jointly estimating the two multipath-affected channels, Bob can suppress the interfering packet and decode Alice's packet, while Eve cannot. We also formulate the problem of joint optimal selection of friendly jammer and power allocation (for Alice and the jammer) that minimize Eve's capability of intercepting the signal while guaranteeing a predefined level of quality of service (QoS) for Bob. The proposed scheme is implemented in a testbed based on Teledyne Benthos Telesonar SM-975 underwater modems and tested extensively in Lake LaSalle at the University at Buffalo. Experiments and simulations demonstrate that, for a given energy budget, the proposed scheme can guarantee much higher bit error rate (BER) at Eve, while creating minimal BER disturbance at Bob, compared to the AN-aided approach.","Jamming,
Interference,
Signal to noise ratio,
Channel estimation,
Bit error rate,
Wireless communication"
Distributed Hybrid Power State Estimation Under PMU Sampling Phase Errors,"Phasor measurement units (PMUs) have the advantage of providing direct measurements of power states. However, as the number of PMUs in a power system is limited, the traditional supervisory control and data acquisition (SCADA) system cannot be replaced by the PMU-based system overnight. Therefore, hybrid power state estimation taking advantage of both systems is important. As experiments show that sampling phase errors among PMUs are inevitable in practical deployment, this paper proposes a distributed power state estimation algorithm under PMU phase errors. The proposed distributed algorithm only involves local computations and limited information exchange between neighboring areas, thus alleviating the heavy communication burden compared to the centralized approach. Simulation results show that the performance of the proposed algorithm is very close to that of centralized optimal hybrid state estimates without sampling phase error.","Phasor measurement units,
State estimation,
Power measurement,
SCADA systems,
Measurement uncertainty,
Current measurement,
Voltage measurement"
Adaptive heterogeneous scheduling for integrated GPUs,"Many processors today integrate a CPU and GPU on the same die, which allows them to share resources like physical memory and lowers the cost of CPU-GPU communication. As a consequence, programmers can effectively utilize both the CPU and GPU to execute a single application. This paper presents novel adaptive scheduling techniques for integrated CPU-GPU processors. We present two online profiling-based scheduling algorithms: naïve and asymmetric. Our asymmetric scheduling algorithm uses low-overhead online profiling to automatically partition the work of dataparallel kernels between the CPU and GPU without input from application developers. It does profiling on the CPU and GPU in a way that doesn't penalize GPU-centric workloads that run significantly faster on the GPU. It adapts to application characteristics by addressing: 1) load imbalance via irregularity caused by, e.g., data-dependent control flow, 2) different amounts of work on each kernel call, and 3) multiple kernels with different characteristics. Unlike many existing approaches primarily targeting NVIDIA discrete GPUs, our scheduling algorithm does not require offline processing. We evaluate our asymmetric scheduling algorithm on a desktop system with an Intel 4th Generation Core Processor using a set of sixteen regular and irregular workloads from diverse application areas. On average, our asymmetric scheduling algorithm performs within 3.2% of the maximum throughput with a CPU-and-GPU oracle that always chooses the best work partitioning between the CPU and GPU. These results underscore the feasibility of online profile-based heterogeneous scheduling on integrated CPU-GPU processors.","Graphics processing units,
Kernel,
Scheduling algorithms,
Programming,
C++ languages"
Hyperspectral Image Visualization Using Band Selection,"Several simple but efficient hyperspectral image display approaches are proposed to use selected bands for Red-Green-Blue (RGB) color composite construction, where visualization-oriented spectral segmentation and integration are developed. A series of band selection algorithms, including minimum estimated abundance covariance (MEAC) and linear prediction (LP), are implemented and compared. The resulting color displays are evaluated in terms of class separability using a statistical classifier, and perceptual color distance. Experimental results demonstrate that the color composite displays using MEAC and LP-selected bands can outperform other band selection methods with low computational cost, and their performance is also better than those of one-bit transform (1BT) and principal component analysis (PCA)-based hyperspectral visualization methods in the literature.","Image color analysis,
Hyperspectral imaging,
Training,
Principal component analysis,
Visualization,
Color"
Detecting replicated nodes in Wireless Sensor Networks using random walks and network division,"Wireless Sensor Networks are vulnerable to node replication attacks due to deployment in unattended environments and the lack of physical tamper-resistance. An adversary can easily capture and compromise sensor nodes and after replicating them, he inserts arbitrary number of replicas into the network to mount a wide variety of internal attacks. In this paper we propose a novel distributed solution (RAND) for the detection of node replication attack in static WSNs which combines random walks with network division and works in two phases. In the first phase called network configuration phase, the entire network is divided into different areas. In the second phase called replica detection phase, the clone is detected by following a claimer-reporter-witness framework and a random walk is employed within each area for the selection of witness nodes. Simulation results show that our scheme outperforms the existing witness node based strategies with moderate communication and memory overhead.","Cloning,
Protocols,
Wireless sensor networks,
Security,
Mobile computing,
Mobile communication,
Wireless networks"
A CFAR Adaptive Subspace Detector Based on a Single Observation in System-Dependent Clutter Background,"In this paper, the problem of detecting target in system-dependent clutter (SDC) background with a single observation from the test cell is researched. Classical detectors, such as the generalized likelihood ratio detectors (GLRDs) and the adaptive matched filters (AMFs), etc., usually deal with the clutter and the noise as a whole. The low rank detectors (LRDs) make use of the low rank property of the clutter to improve the detection performance. However, the performance of LRDs degrades when the signal is not orthogonal with respect to (w.r.t.) the clutter. In this paper, an adaptive subspace detector for SDC (SDC-ASD) background which deals with the clutter and the noise separately is proposed. The SDC-ASD designs the test statistic by replacing the signal and the clutter covariance matrix with their maximum likelihood estimations (MLEs). Its theoretical false alarm probability and detection probability are analytically deduced. Analytical results show that the test statistic has the form of non-central F distribution. Besides, it is shown that the SDC-ASD has constant false alarm rate (CFAR) performance w.r.t. the clutter and the noise. Numerical experiments are provided to validate the detection performance of the SDC-ASD in dealing with the target detection in SDC background.","Clutter,
Detectors,
Noise,
Covariance matrices,
Variable speed drives,
Object detection,
Vectors"
Real-time power aware scheduling for tasks with type-2 fuzzy timing constraints,"The timing constraint of tasks in the mobile real-time computing systems plays the central role in deciding the task schedule as timely completion of the task is very important in such systems. These timing constraints are however completely unquantifiable during the time of system modeling and designing. Thus we consider type-2 fuzzy sets for modeling the timing constraints in mobile and time-critical computing systems and propose a new algorithm FT2EDF (Fuzzy Type-2 Earliest Deadline First) for task scheduling. On the other hand, because of the limitation of the storage power, power efficiency is another foremost design objective for designing mobile real-time computing systems. However, reduction of processor power pulls down the system performance. Timely task completion and power efficiency are therefore two mutually conflicting criteria. In this paper, we propose a heuristic based solution approach that with a modified version of the non-dominated sorting genetic algorithm-II (NSGA-II). Our approach allows that a processor dynamically switches between different voltage levels to ensure optimum reduction in the power requirements without compromising the timeliness of the task completion. The efficacy of our approach is demonstrated with two numerical examples. Comparison with the previous results show that our solution ensures approximately 44% of energy saving as compared to the around 25% of the earlier results.","Timing,
Schedules,
Real-time systems,
Energy efficiency,
Mobile communication,
Uncertainty,
Processor scheduling"
SEW-ing a Simple Endorsement Web to incentivize trustworthy participatory sensing,"Two crucial issues to the success of participatory sensing are (a) how to incentivize the large crowd of mobile users to participate and (b) how to ensure the sensing data to be trustworthy. While they are traditionally being studied separately in the literature, this paper proposes a Simple Endorsement Web (SEW) to address both issues in a synergistic manner. The key idea is (a) introducing a social concept called nepotism into participatory sensing, by linking mobile users into a social “web of participants” with endorsement relations, and (b) overlaying this network with investment-like economic implications. The social and economic layers are interleaved to provision and enhance incentives and trustworthiness. We elaborate the social implications of SEW, and analyze the economic implications under a Stackelberg game framework. We derive the optimal design parameter that maximizes the utility of the sensing campaign organizer, while ensuring participants to strictly have incentive to participate. We also design algorithms for participants to optimally “sew” SEW, namely to manipulate the endorsement links of SEW such that their economic benefits are maximized and social constrains are satisfied. Finally, we provide two numerical examples for an intuitive understanding.","Sensors,
Economics,
Games,
Biological system modeling,
Conferences,
Nash equilibrium,
Mobile communication"
High Performance SQL,"In the contemporary world the size of database(s) is rising exponentially. Increased size of database inevitably necessitates performance maintenance in order that performance is enhanced or sustained. The suggested model is envisioned to serve as benchmark for High Performance Database Administration via High performance SQL Query Tuning and thus improving database performance. The strategy of tuning falls on how effectively we can tune the single problem queries and database memory. This paper elucidates sundry tactics to escalate query as well as database performance and can function as a utility for Database Administrators, SQL programmers and Data Center Managers. Experimental outcomes of our analysis designate that performance is enhanced by saving CPU and I/O.","Indexes,
Tuning,
Delays,
Optimization,
Maintenance engineering,
Benchmark testing"
A Scalable Carrier-Grade DPI System Architecture Using Synchronization of Flow Information,"In this paper, the concept of deep packet inspection (DPI) is explained, and technical issues in deployment of DPI systems in a backbone network of Internet service provider (ISP) are mainly discussed. First, technologies of content identification using DPI are briefly explained, and types of clustering mechanisms that support a large bandwidth with a number of DPI systems are dealt with in detail. Second, a flow synchronization-based DPI architecture is introduced in order to achieve high scalability in system configuration and identification accuracy without rerouting of data flows. Based on the proposed architecture, flow information synchronization and adaptive traffic control using polling-based bandwidth arbitration and virtual queue synchronization are proposed, so that flows, which are randomly distributed over DPI modules by asymmetric routing, can be identified and controlled accurately. The proposed system architecture is practically manufactured as a 40-Gb/s system with four 10-Gb/s DPI modules, and performances of the proposed mechanisms are proved by practical tests that are executed using real traffic in an ISP backbone network. Finally, the scalability and the flexibility of the proposed mechanisms are reviewed from the viewpoint of enabling technologies of smart networks.","Synchronization,
Accuracy,
Bandwidth,
Payloads,
Scalability,
Distributed databases,
Ports (Computers)"
A Robust Likelihood Function for 3D Human Pose Tracking,"Recent works on 3D human pose tracking using unsupervised methods typically focus on improving the optimization framework to find a better maximum in the likelihood function (i.e., the tracker). In contrast, in this paper, we focus on improving the likelihood function, by making it more robust and less ambiguous, thus making the optimization task easier. In particular, we propose an exponential chamfer distance for model matching that is robust to small pose changes, and a part-based model that is better able to localize partially occluded and overlapping parts. Using a standard annealing particle filter and simple diffusion motion model, the proposed likelihood function obtains significantly lower error than other unsupervised tracking methods on the HumanEva dataset. Noting that the joint system of the tracker's body model is different than the joint system of the motion capture ground-truth model, we propose a novel method for transforming between the two joint systems. Applying this bias correction, our part-based likelihood obtains results equivalent to state-of-the-art supervised tracking methods.","Three-dimensional displays,
Tracking,
Predictive models,
Joints,
Solid modeling,
Robustness,
Image edge detection"
A column-row-parallel ultrasound imaging architecture for 3d plane-wave imaging and Tx 2nd-order harmonic distortion (HD2) reduction,"We propose a Column-Row-Parallel (CRP) architecture for integrated and low-power 3D medical ultrasound imaging applications. CRP offers linear-scaling interconnection, acquisition and programming time, while supporting rich functionality and fault-tolerance against possible transducer element defects. A 16×16 CMUT-ASIC CRP imaging system is fabricated and assembled to demonstrate the highly versatile architecture. 3D plane-wave coherent compounding on CRP facilitates fast frame rate (62.5 volume/s), high quality 3D ultrasonic imaging. An interleaved checker board pattern with I&Q excitations is also demonstrated on CRP for tissue harmonic imaging, reducing CMUT 2nd harmonic distortion (HD2) emission by over 20dB.","Arrays,
Three-dimensional displays,
Apertures,
Ultrasonic imaging,
Transducers,
Biomedical imaging"
A search-based approach for generating Angry Birds levels,"This paper presents a genetic algorithm (GA) for the procedural generation of levels in the Angry Birds game. The GA evaluates the levels based on a simulation which measures the elements' movement during a period of time. The algorithm's objective is to minimize this metric to generate stable structures. The level evaluation also considers some restrictions, leading the levels to have certain characteristics. Since there is no open source code of the game, a game clone has been developed independently of our algorithm. This implementation can be used to support experiments with procedural content generation (PCG) methods for this game type. We performed experiments in order to evaluate the expressivity of the level generator and the results showed that the proposed algorithm could generate levels with interesting stable structures.",
A survey on security and trust of FPGA-based systems,"This survey reviews the security and trust issues related to FPGA-based systems from the market perspective. For each party involved in FPGA supply and demand, we show the security and trust problems they need to be aware of and the solutions that are available.",
Multiscale Symmetry Detection in Scalar Fields by Clustering Contours,"The complexity in visualizing volumetric data often limits the scope of direct exploration of scalar fields. Isocontour extraction is a popular method for exploring scalar fields because of its simplicity in presenting features in the data. In this paper, we present a novel representation of contours with the aim of studying the similarity relationship between the contours. The representation maps contours to points in a high-dimensional transformation-invariant descriptor space. We leverage the power of this representation to design a clustering based algorithm for detecting symmetric regions in a scalar field. Symmetry detection is a challenging problem because it demands both segmentation of the data and identification of transformation invariant segments. While the former task can be addressed using topological analysis of scalar fields, the latter requires geometry based solutions. Our approach combines the two by utilizing the contour tree for segmenting the data and the descriptor space for determining transformation invariance. We discuss two applications, query driven exploration and asymmetry visualization, that demonstrate the effectiveness of the approach.","Shape analysis,
Noise measurement,
Isosurfaces,
Level set,
Feature extraction,
Clustering algorithms,
Multi-scale systems,
Volume measurement"
Software-defined radio: a new paradigm for integrated curriculum delivery,"Software-defined radio is a rapidly developing field that is driving the development of and innovation in communications technology, and promises to significantly impact all communications sectors. Entities developing these SDR systems require a trained workforce that has been prepared with the mindset, knowledge, skills, and tools required to address both the system (breadth) and technical (depth) aspects of SDR systems. Developing SDRs necessarily involves a collection of disciplines including, but not limited to, electromagnetics, radio-frequency engineering, communications, digital signal processing, embedded systems, computer programming, and systems engineering. Whereas electrical engineering and computer science and engineering curricula at the university level may include courses in all of these areas, a student's typical curriculum does not; nor does it usually involve the integration of all these topics. However, SDR can be employed as an integrative construct that facilitates systems thinking and cross-domain learning via peers. In this article, we present several significant educational efforts across six U.S. universities that have developed integrated curricula in SDR, most including a significant laboratory component.","Radio frequency,
Software defined radio,
Education courses,
Digital signal processing,
Electrical engineering education,
Training"
A Framework for Fusion of Human Sensor and Physical Sensor Data,Many disaster warning and response systems can improve their surveillance coverage of the threatened area by supplementing in situ and remote physical sensor data with crowdsourced human sensor data captured and sent by people in the area. This paper presents fusion methods which enable a crowdsourcing enhanced system to use human sensor data and physical sensor data synergistically to improve its sensor coverage and the quality of its decisions. The methods are built on results of classical statistical detection and estimation theory and use value fusion and decision fusion of human sensor data and physical sensor data in a coherent way. They are the building blocks of a central fusion unit in a crowdsourcing support system for disaster surveillance and early warning applications.,
Simulation Study of the Selectively Implanted Deep-N-Well for PMOS SET Mitigation,"In this paper, a novel well structure for PMOS single-event transient (SET) mitigation is studied by way of technology computer-aided design (TCAD) numerical simulations. Based on a 90-nm CMOS technology, the simulation results show that the proposed selectively implanted deep-N-well (SIDNW) can significantly reduce the SET pulsewidth without area, power, and performance overheads, when compared with the conventional dual-well process. A comparison is also made with the triple-well process.","Doping,
Semiconductor process modeling,
Electric potential,
Solid modeling,
Three-dimensional displays,
MOS devices,
Inverters"
A Dual-Wavelength Fiber Ring Laser Incorporating an Injection-Coupled Optoelectronic Oscillator and Its Application to Transverse Load Sensing,"A novel configuration for a dual-wavelength fiber ring laser with improved lasing stability realized through the use of an injection-coupled optoelectronic oscillator (OEO) is proposed and demonstrated, and its application to transverse load sensing is studied. The OEO-coupled dual-wavelength laser has two mutually coupled loops: the fiber ring loop and the OEO loop. In the fiber ring loop, a polarization-maintaining phase-shifted fiber Bragg grating is incorporated to generate two optical wavelengths with the wavelength spacing determined by the birefringence of the polarization-maintaining (PM) fiber. In the OEO loop, a microwave signal with its frequency also determined by the birefringence of the PM fiber is generated, which is fed into the fiber ring loop to injection lock the dual wavelengths. Due to the injection locking, a very stable dual-wavelength operation is established. The use of the dual wavelengths for high-resolution and high-speed transverse load sensing is then implemented. The sensitivity of the transverse load sensor is measured as high as +9.7573 and -9.7350 GHz/(N/mm), along the fast and slow axes, respectively. The high frequency purity and stability of the generated microwave signal permits very reliable and high accuracy measurement and the microwave frequency interrogation allows the system to operate at an ultra-high speed.","Optical fiber sensors,
Optical fiber polarization,
Masers,
Fiber lasers,
Microwave oscillators"
Distributed delay-energy aware user association in 3-tier HetNets with hybrid energy sources,"With tremendous attention for green communications, base station (BS) which is powered by both the power grid and renewable energy sources, is regarded as a promising paradigm to reduce energy consumption as well as provide uninterrupted service. In this paper, we propose distributed Delay-Energy Aware (IDEA) user association in 3-tier HetNets with hybrid energy sources. IDEA user association aims to reduce on-grid power consumption by maximizing the utilization of green power harvested from renewable energy sources, as well as enhance network quality of service by minimizing the average traffic delay. To this end, a convex optimization problem is formulated which enables a flexible tradeoff between average traffic delay and on-grid power consumption. We prove that the proposed IDEA user association converges to the globally optimal solution. We then address admission control for the case where the traffic load is heavy to ensure IDEA user association works when network traffic demand is over network capacity. Simulation results indicate that the proposed IDEA user association is able to adjust the loads of BSs and RSs along with the distributions of green power, substantially reduces on-grid power consumption and achieves comparable average traffic delay compared with the existing algorithm which aims to minimize average traffic delay.","Power demand,
Green products,
Delays,
Renewable energy sources,
Conferences,
Power grids,
Macrocell networks"
Minimum Pearson Distance Detection for Multilevel Channels With Gain and/or Offset Mismatch,"The performance of certain transmission and storage channels, such as optical data storage and nonvolatile memory (flash), is seriously hampered by the phenomena of unknown offset (drift) or gain. We will show that minimum Pearson distance (MPD) detection, unlike conventional minimum Euclidean distance detection, is immune to offset and/or gain mismatch. MPD detection is used in conjunction with T-constrained codes that consist of q-ary codewords, where in each codeword T reference symbols appear at least once. We will analyze the redundancy of the new q-ary coding technique and compute the error performance of MPD detection in the presence of additive noise. Implementation issues of MPD detection will be discussed, and results of simulations will be given.",
Embedded Iterative Semi-Blind Channel Estimation for Three-Stage-Concatenated MIMO-Aided QAM Turbo Transceivers,"The lack of accurate and efficient channel estimation (CE) for multiple-input-multiple-output (MIMO) channel state information (CSI) has long been the stumbling block of near-MIMO-capacity operation. We propose a semi-blind joint CE and three-stage iterative detection/decoding scheme for near-capacity MIMO systems. The main novelty is that our decision-directed (DD) CE exploits the a posteriori information produced by the MIMO soft demapper within the inner turbo loop to select a “just sufficient number” of high-quality detected soft bit blocks or symbols for DDCE, which significantly improves the accuracy and efficiency of DDCE. Moreover, our DDCE is naturally embedded into the iterative three-stage detection/decoding process, without imposing an additional external iterative loop between the DDCE and the three-stage turbo detector/decoder. Hence, the computational complexity of our joint CE and three-stage turbo detector/decoder remains similar to that of the three-stage turbo detection/decoding scheme associated with the perfect CSI. Most significantly, the mean square error (MSE) of our DD channel estimator approaches the Cramér-Rao lower bound (CRLB) associated with the optimal-training-based CE, whereas the bit error rate (BER) of our semi-blind scheme is capable of achieving the optimal maximum-likelihood (ML) performance bound associated with the perfect CSI.",
SRRank: Leveraging Semantic Roles for Extractive Multi-Document Summarization,"Extractive multi-document summarization systems usually rank sentences in a document set with some ranking strategy and then select a few highly ranked sentences into the summary. One of the most popular ranking algorithms is the graph-based ranking algorithm. In this paper, we investigate making use of semantic role information to enhance the graph-based ranking algorithm for multi-document summarization. We first parse the sentences and obtain the semantic roles, and then propose a novel SRRank algorithm and two extensions to make better use of the semantic role information. Our proposed algorithms can simultaneously rank the sentences, semantic roles and words in a heterogeneous ranking process. Experimental results on two DUC datasets demonstrate that our proposed algorithms significantly outperform a few baselines, and the semantic role information is validated to be very helpful for multi-document summarization.","Semantics,
Telescopes,
IEEE transactions,
Speech,
Speech processing,
Data mining,
Nickel"
Supervised Hierarchical Bayesian Model-Based Electomyographic Control and Analysis,"This work suggests a supervised hierarchical Bayesian model for surface electromyography (sEMG)-based motion classification and its strategy analysis. The proposed model unifies the optimal feature extraction and classification through probabilistic inference and learning by identifying the latent neural states (LNSs) that govern a collection of sEMG signals. In addition, the inference step provides an approach to identify distinct muscle activation strategies according to sEMG patterns based on LNSs. To validate the model, nine-class classification using four sEMG sensors on the limb motions is tested. The model performance is evaluated with relatively high and low activation levels, generalized classification across subjects and online classification. The model, based on LNSs to capture various motions, is assessed with respect to activation levels, individual subjects and transition during online classification. Our approach cannot only classify sEMG patterns, but also provide the interpretation of sEMG strategic patterns. This work supports the potential of the proposed model for sEMG control-based applications.","Vectors,
Hidden Markov models,
Wrist,
Muscles,
Electrodes,
Bayes methods,
Analytical models"
A scalable and efficient user authentication scheme for cloud computing environments,"Cloud computing is an emerging technology that is still unclear to many security problems and user authentication, access control, and ensuring the security of stored data in cloud servers are the most challenging issues in cloud-based environment. Accordingly, this paper offers an efficient and scalable user authentication scheme for cloud computing environment. It the suggested model, various tools and techniques have been introduced and used by using the concept of agent. Therefore, a client-based user authentication agent has been introduced to confirm identity of the user in client-side. Furthermore, a cloud-based software-as-a-service application has been used to confirm the process of authentication for unregistered devices. Moreover, there are two separate servers for storing authentication and cryptography resources from main servers to decrease the dependency of user authentication and encryption processes from main server. Cryptography agent was also introduced to encrypt resources before storing on cloud servers. In overall, the theoretical analysis of the suggested scheme shows that, designing this user authentication and access control model will enhance the reliability and rate of trust in cloud computing environments as an emerging and powerful technology in various industries.","Authentication,
Servers,
Cloud computing,
Computational modeling,
Encryption"
Development of Polycrystalline Silicon Based Photonic Crystal Membrane for Mid-Infrared Applications,"Free-standing polycrystalline silicon (Si) based photonic crystal (PhC) membranes with etched circular and square holes are developed to display high reflectivity in the mid-infrared (MIR) region. Greater than 90% reflection was measured in the MIR wavelengths around 3.58 μm. By using square air holes in the PhC membrane, the mechanical strength of the polycrystalline Si membrane can be enhanced as square air holes have a lower filling factor of 36% of air holes, compared to 49% in circular air holes while keeping the reflectance around 3.45 μm more than 90%. Such Si PhC membranes offer opportunities for specific applications like filters. To illustrate the feasibility of such devices, simulation works are done by configuring two Si PhC membranes to create a Fabry-Perot interferometer operating in MIR region. The filtered peak shows a full width half maximum of 0.08 nm which corresponds to a quality factor of around 43800, thus demonstrating the possibility of high-resolution applications such as gas sensing and hyperspectral imaging.","Silicon,
Atmospheric modeling,
Mirrors,
Photonic band gap,
Wavelength measurement,
Cavity resonators,
Q-factor"
Solar PV stand-alone water pumping system employing PMSM drive,This paper deals with the stand alone solar PV (Photo Voltaic) supplied PMSM (Permanent Magnet Synchronous Motor) drive for water pumping system. An interlink Boost converter is used between solar PV panel and DC bus of PMSM drive. The DC bus voltage of PMSM drive is maintained constant by controlling the duty cycle of boost converter. Three phase VSI (Voltage Source Inverter) is controlled to supply PMSM under change in solar irradiation to regulate discharge of water. Solar PV stand-alone water pumping system employing PMSM drive is modelled in MATLAB/SIMULINK environment using the sim power system toolboxes. The performance of the proposed system is obtained under wide variation in PMSM speed with change in solar irradiation.,"Radiation effects,
Voltage control,
Torque,
Arrays,
Insulated gate bipolar transistors,
Stators,
Steady-state"
Triple patterning lithography aware optimization for standard cell based design,"Triple Patterning Lithography (TPL) is regarded as a promising technique to handle the manufacturing challenges in 14nm and beyond technology node. It is necessary to consider TPL in early design stages to make the layout more TPL friendly and reduce the manufacturing cost. In this paper, we propose a flow to co-optimize cell layout decomposition and detailed placement. Our cell decomposition approach can enumerate all coloring solutions with the minimum number of stitches. Experimental results show that our approach can outperform the existing work in all aspects of stitch number, HPWL and running time.",
An ensemble of deep neural networks for object tracking,"Object tracking in complex backgrounds with dramatic appearance variations is a challenging problem in computer vision. We tackle this problem by a novel approach that incorporates a deep learning architecture with an on-line AdaBoost framework. Inspired by its multi-level feature learning ability, a stacked denoising autoencoder (SDAE) is used to learn multi-level feature descriptors from a set of auxiliary images. Each layer of the SDAE, representing a different feature space, is subsequently transformed to a discriminative object/background deep neural network (DNN) classifier by adding a classification layer. By an on-line AdaBoost feature selection framework, the ensemble of the DNN classifiers is then updated on-line to robustly distinguish the target from the background. Experiments on an open tracking benchmark show promising results of the proposed tracker as compared with several state-of-the-art approaches.","Boosting,
Robustness,
Target tracking,
Neural networks,
Object tracking,
Noise reduction"
Design and Implementation of Power-Efficient K-Best MIMO Detector for Configurable Antennas,"In this brief, a power-efficient multiple-input multiple-output (MIMO) detector that can flexibly support multiple antenna configurations and modulations is presented. This detector uses a sorting-free K-best algorithm named distributed K-best (DKB) algorithm and successive interference cancellation (SIC) to decrease computational complexity. The DKB and SIC schemes are designed as several elementary building blocks. Then, the antenna configurable architecture can be flexibly constructed by these elementary blocks. The multistage hardware architecture is proposed to achieve that only K clock cycles are required to find out the best K candidates, and the sorting circuit for the conventional K-best algorithm is avoided in our design. In addition, a shift multiplier which simply uses bit shift and additions is applied to replace the conventional multiplier for further reducing power consumption. The proposed configurable MIMO detector has been fabricated in 90-nm CMOS technology with core area of 0.7744 mm2. For 8 × 8, 64-QAM, and K = 10 configuration, the proposed chip achieves 489-Mb/s throughput rate with 17-mW power consumption at 102-MHz operating frequency and 1 V supply voltage. The performance results show that the proposed design has better power efficiency and antenna configurability than other related works.","MIMO,
Detectors,
Antennas,
Decoding,
Silicon carbide,
Very large scale integration,
Algorithm design and analysis"
Multi-Bound-Dependent Stability Criterion for Digital Filters With Overflow Arithmetics and Time Delay,"In this brief, a new criterion for checking the global asymptotic stability of fixed-point state-space digital filters with time-varying delay and overflow arithmetics is presented. Compared with some existing results, a distinctive feature of the proposed criterion is that it is multi-bound-dependent criterion and can be less conservative than existing results. Two examples are given to show this improvement over the existing conditions.","Stability criteria,
Asymptotic stability,
Circuit stability,
Delays,
Delay effects,
Educational institutions"
A Comparison Study of High-Frequency Isolated DC/AC Converter Employing an Unfolding LCI for Grid-Connected Alternative Energy Applications,A high-frequency (HF) isolated dc/ac converter including an unfolding line connected inverter can be used as the interface between a small-scale alternative energy generation system and the utility line. This paper presents the review of operation of several different topologies of HF isolated dc/ac converters. They are designed for illustration purpose and compared for their performance. It is found that the dual-LCL series resonant dc/ac converter can maintain zero-voltage switching (ZVS) operation for all switches with low line-current total harmonics distortion (THD) and high efficiency. Experimental results on a 500-W prototype converter are included for validation purpose.,
Fast parallel algorithm for unfolding of communities in large graphs,Detecting community structures in graphs is a well studied problem in graph data analytics. Unprecedented growth in graph structured data due to the development of the world wide web and social networks in the past decade emphasizes the need for fast graph data analytics techniques. In this paper we present a simple yet efficient approach to detect communities in large scale graphs by modifying the sequential Louvain algorithm for community detection. The proposed distributed memory parallel algorithm targets the costly first iteration of the initial method by parallelizing it. Experimental results on a MPI setup with 128 parallel processes shows that up to ≈5× performance improvement is achieved as compared to the sequential version while not compromising the correctness of the final result.,
An efficient animal detection system for smart cars using cascaded classifiers,"Animal-Vehicle Collisions (AVCs) have been a challenging problem since the creation of cars. Consequently, such collisions cause hundreds of human and animal deaths, thousands of injuries, and billions of dollars in property damage every year. To cope with this challenge, vehicles have to be equipped with smart systems able to detect animals (e.g., moose), which cross roadways, and warn drivers about the imminent danger. In this paper, we develop a new animal detection system following two criteria: detection accuracy and detection speed. To achieve these requirements, a two-stage strategy system is investigated. In the first stage, we use the LBP-Adaboost algorithm which supplies the second stage by a set of ROIs containing moose and other similar-objects. Whereas the second stage is based on an adapted version of HOG-SVM classifier. In this stage, the non-moose ROIs are rejected. To train and test our system, we create our own dataset, which is frequently updated by adding new images. Through an extensive set of simulations, we show that our system is able to detect more than 83% of moose.","Animals,
Support vector machines,
Feature extraction,
Videos,
Computer architecture,
Vehicles,
Training"
Why Walking the Dog Takes Time: Frechet Distance Has No Strongly Subquadratic Algorithms Unless SETH Fails,"The Fréchet distance is a well-studied and very popular measure of similarity of two curves. Many variants and extensions have been studied since Alt and Godau introduced this measure to computational geometry in 1991. Their original algorithm to compute the Fréchet distance of two polygonal curves with n vertices has a runtime of O(n^2 log n). More than 20 years later, the state of the art algorithms for most variants still take time more than O(n2 / log n), but no matching lower bounds are known, not even under reasonable complexity theoretic assumptions. To obtain a conditional lower bound, in this paper we assume the Strong Exponential Time Hypothesis or, more precisely, that there is no O*((2-&delta;)N) algorithm for CNF-SAT for any delta > 0. Under this assumption we show that the Fréchet distance cannot be computed in strongly subquadratic time, i.e., in time O(n2-&delta;) for any delta > 0. This means that finding faster algorithms for the Fréchet distance is as hard as finding faster CNF-SAT algorithms, and the existence of a strongly subquadratic algorithm can be considered unlikely. Our result holds for both the continuous and the discrete Fréchet distance. We extend the main result in various directions. Based on the same assumption we (1) show non-existence of a strongly subquadratic 1.001-approximation, (2) present tight lower bounds in case the numbers of vertices of the two curves are imbalanced, and (3) examine realistic input assumptions (c-packed curves).","Polynomials,
Runtime,
Approximation algorithms,
Approximation methods,
Vectors,
Bismuth,
Time measurement"
Synthesizing manipulation sequences for under-specified tasks using unrolled Markov Random Fields,"Many tasks in human environments require performing a sequence of navigation and manipulation steps involving objects. In unstructured human environments, the location and configuration of the objects involved often change in unpredictable ways. This requires a high-level planning strategy that is robust and flexible in an uncertain environment. We propose a novel dynamic planning strategy, which can be trained from a set of example sequences. High level tasks are expressed as a sequence of primitive actions or controllers (with appropriate parameters). Our score function, based on Markov Random Field (MRF), captures the relations between environment, controllers, and their arguments. By expressing the environment using sets of attributes, the approach generalizes well to unseen scenarios. We train the parameters of our MRF using a maximum margin learning method. We provide a detailed empirical validation of our overall framework demonstrating successful plan strategies for a variety of tasks.","Robots,
Planning,
Vectors,
Liquids,
Markov random fields,
Sequential analysis,
Navigation"
A framework for crowd-sourced data collection and context-aware services in Hajj and Umrah,"We propose a context aware framework that offers a set of cloud-based services to support a very large Hajj and Umrah crowd by capturing their contexts using smartphones. The proposed framework captures the individual's context, provides a set of adapted services, and allows being in touch with a subset of one's community of interest. We leverage the spatiotemporal sensory data captured by our framework to define users' contexts for optimized services. Our proposed framework is also envisioned to assist the Hajj and Umrah authorities to (1) improve Hajj & Umrah documentation, (2) improve Hajj organization through better understanding of pilgrims' (individual and crowd) spatial and temporal behavior and needs, and (3) protect pilgrims' environment through environmental monitoring. In particular, the developed methods, techniques, and algorithms will support the pilgrimage quality of experience. We have tested our system through end-user subjects and due to apply for the upcoming Hajj events. We present our implementation details and the general impression of end users about our system.","Context,
Smart phones,
Social network services,
Communities,
Context-aware services,
Temperature sensors"
Taking Participatory Citizen Science to Extremes,University College London's Extreme Citizen Science research group (UCL ExCiteS) is experimenting with ways to incorporate the most marginalized communities into participatory citizen science activities through which they can share their indigenous knowledge. The group works with communities at the extremes of the globalized world--both because of nonliteracy and the remote or forbidding environments they inhabit. These groups are the gatekeepers of some key environments on which the future health of the planet depend--from tropical forests to Arctic sea-ice. This article presents the methodologies and tools the group is developing to give these people a voice. This article is part of a special issue on pervasive analytics and citizen science.,
A Five-Level Design Framework for Bicluster Visualizations,"Analysts often need to explore and identify coordinated relationships (e.g., four people who visited the same five cities on the same set of days) within some large datasets for sensemaking. Biclusters provide a potential solution to ease this process, because each computed bicluster bundles individual relationships into coordinated sets. By understanding such computed, structural, relations within biclusters, analysts can leverage their domain knowledge and intuition to determine the importance and relevance of the extracted relationships for making hypotheses. However, due to the lack of systematic design guidelines, it is still a challenge to design effective and usable visualizations of biclusters to enhance their perceptibility and interactivity for exploring coordinated relationships. In this paper, we present a five-level design framework for bicluster visualizations, with a survey of the state-of-the-art design considerations and applications that are related or that can be applied to bicluster visualizations. We summarize pros and cons of these design options to support user tasks at each of the five-level relationships. Finally, we discuss future research challenges for bicluster visualizations and their incorporation into visual analytics tools.","Cluster approximation,
Navigation,
Data mining,
Visual analytics,
Bioinformatics"
Human activity recognition using smartphone sensors with two-stage continuous hidden Markov models,"Recognizing human activities from temporal streams of sensory data observations is a very important task on a wide variety of applications in context recognition. Especially for time-series sensory data, a method that takes into account the inherent sequential characteristics of the data is needed. Moreover, activities are hierarchical in nature, in as much that complex activities can be decomposed to a number of simpler ones. In this paper, we propose a two-stage continuous hidden Markov model (CHMM) approach for the task of activity recognition using accelerometer and gyroscope sensory data gathered from a smartphone. The proposed method consists of first-level CHMMs for coarse classification, which separates stationary and moving activities, and second-level CHMMs for fine classification, which classifies the data into their corresponding activity classes. Random Forests (RF) variable importance measures are exploited to determine the optimal feature subsets for both coarse and fine classification. Experiments show that with the use of a significantly reduced number of features, the proposed method shows competitive performance in comparison to other classification algorithms, achieving an over-all accuracy of 91.76%.","Hidden Markov models,
Accelerometers,
Radio frequency,
Legged locomotion,
Feature extraction,
Sensors,
Gyroscopes"
Monitoring activities of daily living based on wearable wireless body sensor network,"With recent advances in microprocessor chip technology, wireless communication, and biomedical engineering it is possible to develop miniaturized ubiquitous health monitoring devices that are capable of recording physiological and movement signals during daily life activities. The aim of the research is to implement and test the prototype of health monitoring system. The system consists of the body central unit with Bluetooth module and wearable sensors: the custom-designed ECG sensor, the temperature sensor, the skin humidity sensor and accelerometers placed on the human body or integrated with clothes and a network gateway to forward data to a remote medical server. The system includes custom-designed transmission protocol and remote web-based graphical user interface for remote real time data analysis. Experimental results for a group of humans who performed various activities (eg. working, running, etc.) showed maximum 5% absolute error compared to certified medical devices. The results are promising and indicate that developed wireless wearable monitoring system faces challenges of multi-sensor human health monitoring during performing daily activities and opens new opportunities in developing novel healthcare services.","Monitoring,
Biomedical monitoring,
Temperature sensors,
Skin,
Wireless communication,
Electrocardiography,
Humidity"
WizSync: Exploiting Wi-Fi Infrastructure for Clock Synchronization in Wireless Sensor Networks,"Time synchronization is a fundamental service for wireless sensor networks (WSNs). Although a number of message passing protocols can achieve satisfactory synchronization accuracy, they suffer poor scalability and high transmission overhead. An alternative approach is to utilize the global time references such as those induced by GPS and timekeeping radios. However, they require the hardware receiver to decode the out of band clock signal, which introduces extra cost and design complexity. This paper proposes a novel WSN time synchronization approach by exploiting the existing Wi-Fi infrastructure. Our approach leverages the fact that 802.15.4 sensors and Wi-Fi nodes often occupy the same or overlapping radio frequency bands in the 2.4 GHz unlicensed spectrum. As a result, a 802.15.4 node can detect and synchronize to the periodic beacons broadcasted by Wi-Fi access points (APs). A key advantage of our approach is that, due to the long communication range of Wi-Fi, a large number of 802.15.4 sensors can synchronize clock rates to the same beacons without any message exchange. This paper makes several key contributions. First, we experimentally characterize the spatial and temporal characteristics of Wi-Fi beacons in an enterprise Wi-Fi network consisting of over 50 APs deployed in a 300,000 square foot office building. Motivated by our measurement results, we design a novel synchronization protocol called WizSync. WizSync employs digital signal processing (DSP) techniques to detect periodic Wi-Fi beacons and use them to calibrate the frequency of native clocks. WizSync can intelligently predict the clock skew and adaptively schedules nodes to sleep to conserve energy. We implement WizSync in TinyOS 2.1.1 and conduct extensive evaluation on a testbed consisting of 19 TelosB motes. Our results show that WizSync can achieve an average synchronization error of 0.12 milliseconds over a period of 10 days with radio power consumption of 50.9 microwatts/node.","IEEE 802.11 Standards,
WiFi,
Synchronization,
Wireless sensor networks"
On crop height estimation with UAVs,"Remote sensing by Unmanned Aerial Vehicles (UAVs) is changing the way agriculture operates by increasing the spatial-temporal resolution of data collection. Micro-UAVs have the potential to further improve and enrich the data collected by operating close to the crops, enabling the collection of higher spatio-temporal resolution data. In this paper, we present a UAV-mounted measurement system that utilizes a laser scanner to compute crop heights, a critical indicator of crop health. The system filters, transforms, and analyzes the cluttered range data in real-time to determine the distance to the ground and to the top of the crops. We assess the system in an indoor testbed and in a corn field. Our findings indicate that despite the dense canopy and highly variable sensor readings, we can precisely fly over crops and measure its height to within 5cm of measurements gathered using current measurement technology.","Agriculture,
Measurement by laser beam,
Lasers,
Laser radar,
Estimation,
Spatial resolution,
Simultaneous localization and mapping"
PSR Enhancement Through Super Gain Boosting and Differential Feed-Forward Noise Cancellation in a 65-nm CMOS LDO Regulator,"This paper presents a 65-nm CMOS low-dropout (LDO) regulator employing a super gain amplifier (SGA) and differential feed-forward noise cancellation to maximize the power supply rejection (PSR). The SGA in the error amplifier is augmented by a positive feedback current mirror, and this SGA boosts the loop gain through local negative feedback. With 1.2 V supply voltage, the LDO regulator has a 200 mV drop-out voltage and the ability to handle a maximum 25 mA load current. The measurement results show a -47 dB PSR ratio of up to 10 MHz and dc load regulation under 1 mV for full load current change.","Regulators,
Resistance,
Logic gates,
Gain,
Noise,
Boosting,
CMOS integrated circuits"
A Novel Turtle Shell Based Scheme for Data Hiding,"Data hiding is a well-known technique which embeds the secret data into a digital media. Most of the existing schemes either have the low image quality, or provide the restricted embedding capacity. In this paper, a new data hiding scheme based on turtle shell is proposed to obtain better image quality and higher embedding capacity. In the proposed scheme, a secret digit is embedded into each cover pixel pair with the guidance of the turtle shell. Experimental results reveal that the proposed scheme ensures not only higher embedding capacity, but also obtains better visual quality compared with the existing schemes.","Visualization,
PSNR,
Educational institutions,
Computer science,
Vectors,
Encoding,
Gray-scale"
A lattice-based approach to multi-robot motion planning for non-holonomic vehicles,"Coordinating fleets of autonomous, non-holonomic vehicles is paramount to many industrial applications. While there exists solutions to efficiently calculate trajectories for individual vehicles, an effective methodology to coordinate their motions and to avoid deadlocks is still missing. Decoupled approaches, where motions are calculated independently for each vehicle and then centrally coordinated for execution, have the means to identify deadlocks, but not to solve all of them. We present a novel approach that overcomes this limitation and that can be used to complement the deficiencies of decoupled solutions with centralized coordination. Here, we formally define an extension of the framework of lattice-based motion planning to multi-robot systems and we validate it experimentally. Our approach can jointly plan for multiple vehicles and it generates kinematically feasible and deadlock-free motions.","Planning,
Robot kinematics,
Space exploration,
Space vehicles,
System recovery"
A Fine-Grain Dynamically Reconfigurable Architecture Aimed at Reducing the FPGA-ASIC Gaps,"Prior work has shown that due to the overhead incurred in enabling reconfigurability, field-programmable gate arrays (FPGAs) require 21× more silicon area, 3× larger delay, and 10× more dynamic power consumption compared with application-specific integrated circuits (ASICs). We have earlier presented a hybrid CMOS/nanotechnology reconfigurable architecture (NATURE). It uses the concept of temporal logic folding and fine-grain (i.e., cycle-level) dynamic reconfiguration to increase logic density by an order of magnitude. Since logic folding reduces area usage significantly, on-chip communications tend to become localized. To take full advantage of this fact, we propose a new architecture, called fine-grain dynamically reconfigurable (FDR), that consists of an array of homogeneous reconfigurable logic elements (LEs). Each LE can be arbitrarily configured into a lookup table (LUT) or interconnect or a combination of both. This significantly enhances the flexibility of allocating hardware resources between LUTs and interconnects based on application needs. The proposed FDR architecture eliminates most of the long-distance and global wires, which occupy most of the area in conventional FPGAs. Fine-grain dynamic reconfiguration is enabled by local embedded static RAM blocks. The experiments show that, on an average, area, delay, and power are improved by 9.14×, 1.11×, and 1.45×, compared with a conventional FPGA architecture that does not use the concept of logic folding. Compared with NATURE with deep logic folding, area, delay, and power are improved by 2.12×, 3.28×, and 1.74×, respectively. Although this does not eliminate the FPGA-ASIC area/delay/power gaps, it makes progress toward bridging these gaps.","Delays,
Table lookup,
Random access memory,
Field programmable gate arrays,
Integrated circuit interconnections,
Wires"
Efficient Mitigation of Data and Control Flow Errors in Microprocessors,"The use of microprocessor-based systems is gaining importance in application domains where safety is a must. For this reason, there is a growing concern about the mitigation of SEU and SET effects. This paper presents a new hybrid technique aimed to protect both the data and the control-flow of embedded applications running on microprocessors. On one hand, the approach is based on software redundancy techniques for correcting errors produced in the data. On the other hand, control-flow errors can be detected by reusing the on-chip debug interface, existing in most modern microprocessors. Experimental results show an important increase in the system reliability even superior to two orders of magnitude, in terms of mitigation of both SEUs and SETs. Furthermore, the overheads incurred by our technique can be perfectly assumable in low-cost systems.","Microprocessors,
Software,
Hardware,
Registers,
Radiation detectors,
Clocks,
Monitoring"
First Quantization Matrix Estimation From Double Compressed JPEG Images,"One of the most common problems in the image forensics field is the reconstruction of the history of an image or a video. The data related to the characteristics of the camera that carried out the shooting, together with the reconstruction of the (possible) further processing, allow us to have some useful hints about the originality of the visual document under analysis. For example, if an image has been subjected to more than one JPEG compression, we can state that the considered image is not the exact bitstream generated by the camera at the time of shooting. It is then useful to estimate the quantization steps of the first compression, which, in case of JPEG images edited and then saved again in the same format, are no more available in the embedded metadata. In this paper, we present a novel algorithm to achieve this goal in case of double JPEG compressed images. The proposed approach copes with the case when the second quantization step is lower than the first one, exploiting the effects of successive quantizations followed by dequantizations. To improve the results of the estimation, a proper filtering strategy together with a function devoted to find the first quantization step, have been designed. Experimental results and comparisons with the state-of-the-art methods, confirm the effectiveness of the proposed approach.","Quantization (signal),
Histograms,
Image coding,
Discrete cosine transforms,
Transform coding,
Estimation,
Noise"
Fuzzy multi-objective reliability-redundancy allocation problem,"Reliability is the measure of the result of the quality of the system over a long run. The reliability-redundancy allocation problem (RRAP) aims to ensure high systems reliability in the presence of optimally redundant systems components. This is one of the most important design considerations for the systems designers. Several researchers have addressed this important issue during last few decades. However, due to the embedded uncertainty in the parameters of the system components, reliability as well as the costs of the whole system fits very well to be modeled as fuzzy quantity. We therefore modeled this problem as a fuzzy multi-objective optimization problem (MORRAP) that is addressed using the popular multi-objective evolutionary algorithm, NSGA-II (non-dominated sorting genetic algorithm-II). We have considered the based MORRAP with fuzzy type-2 uncertainty. As far as we know, no research has been reported where MORRAP was considered under type-2 fuzzy uncertainty. A typical numerical example is included and results are compared showing that our approach outperforms other recently reported results.",
Single Pass Spectral Sparsification in Dynamic Streams,"We present the first single pass algorithm for computing spectral sparsifiers of graphs in the dynamic semi-streaming model. Given a single pass over a stream containing insertions and deletions of edges to a graph, G, our algorithm maintains a randomized linear sketch of the incidence matrix into dimension O(1/∈2npolylog(n)). Using this sketch, the algorithm can output a (1±∈) spectral sparsifier for G with high probability. While O(1/∈2n polylog(n)) space algorithms are known for computing cut sparsifiers in dynamic streams [1], [2] and spectral sparsifiers in insertion-only streams [3], prior to our work, the best known single pass algorithm for maintaining spectral sparsifiers in dynamic streams required sketches of dimension Ω(1/∈2n5/3). To achieve our result, we show that, using a coarse sparsifier of G and a linear sketch of G's incidence matrix, it is possible to sample edges by effective resistance, obtaining a spectral sparsifier of arbitrary precision. Sampling from the sketch requires a novel application of ℓ2/ℓ2 sparse recovery, a natural extension of the ℓ0 methods used for cut sparsifiers in [1]. Recent work of [2] on row sampling for matrix approximation gives a recursive approach for obtaining the required coarse sparsifiers. Under certain restrictions, our approach also extends to the problem of maintaining a spectral approximation for a general matrix AT A given a stream of updates to rows in A.","Approximation methods,
Heuristic algorithms,
Approximation algorithms,
Sparse matrices,
Laplace equations,
Computational modeling,
Resistance"
Compact and accurate stochastic circuits with shared random number sources,"Stochastic computing, which is an approximate computation with probabilities (called stochastic numbers), draws attention as an alternative method of deterministic computing. In this paper, we discuss a design of compact and accurate stochastic circuits. Stochastic circuits are known as a way to stochastically compute complex calculation at low hardware cost, while stochastic number generators (SNGs), which are used for converting deterministic numbers into stochastic numbers, account for a large fraction of the circuits. To reduce such SNGs in stochastic circuits, we propose a technique to share random number generators with several SNGs. This sharing method employs circular shift of the output of LFSRs to reduce the correlation between stochastic numbers. We also discuss the influence of input correlation around a multiplexer, which is a scaled adder for stochastic computing, so as to avoid over reducing the input correlation. Application of the proposed techniques to two stochastic image processing shows the reduction in the size of SNGs without greatly sacrificing accuracy.","Correlation,
Multiplexing,
Accuracy,
Generators,
Hardware,
Image segmentation,
Image edge detection"
RF Performance of Proton-Irradiated AlGaN/GaN HEMTs,"AlGaN/GaN high electron mobility transistors (HEMTs) irradiated with 1.8-MeV protons show more relative degradation in RF power/current gain, cutoff frequency fT, and maximum oscillation frequency fmax than DC transconductance. These result from radiation-induced increases in fast bulk and surface trap densities, as well as increasing impedance mismatch at high frequencies with increasing proton fluence. NH3-rich MBE devices show less degradation in DC transconductance, but more degradation in RF gain than Ga-rich devices.","Protons,
Radio frequency,
Degradation,
Radiation effects,
HEMTs,
MODFETs,
Gallium nitride,
Aluminum gallium nitride"
Camera Compensation Using a Feature Projection Matrix for Person Reidentification,"Matching individuals within a group of spatially nonoverlapping surveillance cameras, also known as person reidentification, has recently attracted a lot of research interest. Current methods mainly focus on feature representation or distance measure, which directly compare person images captured by different cameras. However, it is still a problem because of various surveillance conditions; for example, view switching, lighting variations, and image scaling. Although the brightness transfer function was proposed to address the problem of illumination variation, it could not handle view and scale changes among various cameras. In this paper, we propose a new approach to compensate for the inconsistency of feature distributions of person images captured by different cameras. More precisely, a feature projection matrix (FPM) is learned to project image features of one camera to the feature space of another camera, from which the latent device difference can be effectively eliminated for the person reidentification task. In particular, we formulate the FPM learning as a smooth unconstrained convex optimization problem and use a simple gradient descent algorithm with stochastic samples to accelerate the solving process. Extensive comparative experiments conducted on three standard datasets have shown the promising prospect of the proposed method.","Cameras,
Measurement,
Learning systems,
Brightness,
Linear programming,
Vectors,
Lighting"
Composite Retrieval of Diverse and Complementary Bundles,"Users are often faced with the problem of finding complementary items that together achieve a single common goal (e.g., a starter kit for a novice astronomer, a collection of question/answers related to low-carb nutrition, a set of places to visit on holidays). In this paper, we argue that for some application scenarios returning item bundles is more appropriate than ranked lists. Thus we define composite retrieval as the problem of finding k bundles of complementary items. Beyond complementarity of items, the bundles must be valid w.r.t. a given budget, and the answer set of k bundles must exhibit diversity. We formally define the problem and show that in its general form is NP-hard and that also the special cases in which each bundle is formed by only one item, or only one bundle is sought, are hard. Our characterization however suggests how to adopt a two-phase approach (Produce-and-Choose, or PAC) in which we first produce many valid bundles, and then we choose k among them. For the first phase we devise two ad-hoc clustering algorithms, while for the second phase we adapt heuristics with approximation guarantees for a related problem. We also devise another approach which is based on first finding a k-clustering and then selecting a valid bundle from each of the produced clusters (Cluster-and-Pick, or CAP). We compare experimentally the proposed methods on two real-world data sets: the first data set is given by a sample of touristic attractions in 10 large European cities, while the second is a large database of user-generated restaurant reviews from Yahoo! Local. Our experiments show that when diversity is highly important, CAP is the best option, while when diversity is less important, a PAC approach constructing bundles around randomly chosen pivots, is better.","Approximation methods,
Complexity theory,
Linear programming,
Urban areas,
Approximation algorithms,
Polynomials,
Clustering algorithms"
Leveling to the last mile: Near-zero-cost bit level wear leveling for PCM-based main memory,"Phase change memory (PCM) has demonstrated great potential as an alternative of DRAM to serve as main memory due to its favorable characteristics of non-volatility, scalability and near-zero leakage power. However, the comparatively poor endurance of PCM largely limits its adoption. Wear leveling strategies targeting to even write distributions have been proposed at different granularities and on various memory hierarchies for PCM endurance enhancement. Write operations are distributed across the memory through migrating data from heavily written locations to less burdened ones, which is usually guided by counters recording the number of writes. However, evenly distributing writes at a coarse granularity cannot deliver the best endurance results as write distributions are highly imbalanced even at the bit level. In this work, we propose a near-zero-cost bit-level wear leveling strategy to improve PCM endurance. The proposed technique can be combined with various coarse-grained wear leveling strategies. Experiment results show 102% endurance enhancement on average, which is 34% higher than the most related work, with significantly lower storage, performance and energy overheads.","Phase change materials,
Radiation detectors,
Registers,
Benchmark testing,
Educational institutions,
Random access memory,
Round robin"
Detecting multiple information sources in networks under the SIR model,"In this paper, we study the problem of detecting multiple information sources in networks under the Susceptible-Infected-Recovered (SIR) model. First, assuming the number of information sources is known, we develop a sample-path-based algorithm, named clustering and localization, for trees. For g-regular trees, the estimators produced by the proposed algorithm are within a constant distance from the real sources with a high probability. We further present a heuristic algorithm for general networks and an algorithm for estimating the number of sources when the number of real sources is unknown.","Heuristic algorithms,
Clustering algorithms,
Computational modeling,
Approximation algorithms,
Signal processing algorithms,
Educational institutions,
Computers"
Generation of Correlated Finite Alphabet Waveforms Using Gaussian Random Variables,"Correlated waveforms have a number of applications in different fields, such as radar and communication. It is very easy to generate correlated waveforms using infinite alphabets, but for some of the applications, it is very challenging to use them in practice. Moreover, to generate infinite alphabet constant envelope correlated waveforms, the available research uses iterative algorithms, which are computationally very expensive. In this work, we propose simple novel methods to generate correlated waveforms using finite alphabet constant and non-constant-envelope symbols. To generate finite alphabet waveforms, the proposed method map the Gaussian random variables onto the phase-shift-keying, pulse-amplitude, and quadrature-amplitude modulation schemes. For such mapping, the probability-density-function of Gaussian random variables is divided into M regions, where M is the number of alphabets in the corresponding modulation scheme. By exploiting the mapping function, the relationship between the cross-correlation of Gaussian and finite alphabet symbols is derived. To generate equiprobable symbols, the area of each region is kept same. If the requirement is to have each symbol with its own unique probability, the proposed scheme allows us that as well. Although, the proposed scheme is general, the main focus of this paper is to generate finite alphabet waveforms for multiple-input multiple-output radar, where correlated waveforms are used to achieve desired beam patterns.","Radar antennas,
Covariance matrices,
Radar,
MIMO,
Transmitting antennas,
Correlation,
Face"
Software-defined home networking devices for multi-home visual sharing,"Existing home-networking protocols do not robustly incorporate universal connectivity among multiple homes, which leaves their use restricted to a single home. In addition, even in a single home network, new functional requirements ask for more diversified forms of networking control. This paper presents in-home consumer electronic devices that incorporate the emerging SDN (Software Defined Networking) paradigm. The proposed devices enable ondemand provisioning for protocol-agnostic home networking and thus provide a high degree of flexibility for intra-home networking as well as wider connectivity for inter-home networking. The feasibility of the prototype devices is verified by realizing a multi-home visual-sharing scenario and by supporting diverse future scenarios.",
Cellular-based vehicle to pedestrian (V2P) adaptive communication for collision avoidance,"Road safety is one of the most important applications of vehicular networks. However, improving pedestrian safety via vehicle-to-pedestrian (V2P) wireless communication has not been extensively addressed. In this paper, our vision is to propose a method which enables development of V2P road safety applications via wireless communication and only utilizing the existing infrastructure and devices. As pedestrians' smartphones do not support the IEEE 802.11p amendment which is customized for vehicular networking, we have initiated an approach that utilizes cellular technologies. Study shows potential of utilizing 3G and LTE for highly mobile entities of vehicular network applications. In addition, some vehicles are already equipped with cellular connectivity but otherwise the driver's smartphone is used as an alternative. However, smartphone limited battery life is a bottleneck in realization of such pedestrian safety system. To tackle the energy limitation in smartphones, we employ an adaptive multi-level approach which operates in an energy-saving mode in risk-free situations but switches to normal mode as it detects a risky situation. Based on our evaluation and analysis, this adaptive approach considerably saves electrical energy and thus makes the cellular-based road-safety system practical.",
Passive Wireless Strain Sensors Using Microfabricated Magnetoelastic Beam Elements,"This paper describes resonant wireless strain sensors fabricated from magnetoelastic alloys. The transduction mechanism is the ΔE effect-the change in stiffness of magnetoelastic materials with applied strain or magnetic field. This is measured as a shift in the resonant frequency and is detected wirelessly using pick-up coils utilizing the magnetoelastic coupling of these materials. The sensors are fabricated from a 28-μm-thick foil of Metglas 2826 MB (Fe40Ni38Mo4B18), a ferromagnetic magnetoelastic alloy, using microelectrodischarge machining. Two sensor types are described-single and differential. The single sensor has an active area of 7 × 2 mm2, excluding the anchors. At 23°C, it operates at a resonant frequency of 230.8 kHz and has a sensitivity of 13 × 103 ppm/mstrain; the dynamic range is 0.05-1.05 mstrain. The differential sensor includes a strain independent reference resonator of area 2 × 0.5 mm2 in addition to a sensing element of area 2.5 × 0.5 mm2 that is divided into two segments. The sensor resonance is at 266.4 kHz and reference resonance is at 492.75 kHz. The differential sensor provides a dynamic range for 0-1.85 mstrain with a sensitivity of 12.5 × 103 ppm/mstrain at 23°C. The reference resonator of the differential sensor is used to compensate for the temperature dependence of the Young's modulus of Metglas 2826 MB, which is experimentally estimated to be -524 ppm/°C. For an increment of 35°C, uncompensated sensors exhibit a resonant frequency shift of up to 42% of the dynamic range for the single sensor and 30% of the dynamic range of the differential sensor, underscoring the necessity of temperature compensation. The geometry of both types of sensors can be modified to accommodate a variety of sensitivity and dynamic range requirements.",
A Graphene-Based Hybrid Plasmonic Waveguide With Ultra-Deep Subwavelength Confinement,"Reduction of propagation loss of terahertz graphene plasmon can be made by increasing the chemical potential of graphene layer, but at the cost of significantly increased modal area, which fundamentally limits the packing density on a chip. By utilizing the strong coupling between the dielectric waveguide and plasmonic modes, we propose hybrid plasmonic terahertz waveguides that not only significantly suppress the mode field confinement, but also maintain a compact modal size. A typical propagation length is 127 μm, and optical field is confined into an ultra-small area of approximately 32.6 μm2 at 3 THz. This structure also exhibits ultra-low crosstalk, which shows great promise for constructing various functional devices in future terahertz integrated circuits.",
The Effect of Memory Size on the Evolutionary Stability of Strategies in Iterated Prisoner's Dilemma,"The iterated prisoner's dilemma is an ideal model for the evolution of cooperation among payoff-maximizing individuals. It has attracted wide interest in the development of novel strategies since the success of tit-for-tat in Axelrod's iterated prisoner's dilemma competitions. Every strategy for iterated prisoner's dilemma utilizes a certain length of historical interactions with the opponent, which is regarded as the size of the memory, in making its choices. Intuitively, longer memory strategies must have an advantage over shorter memory strategies. In practice, however, most of the well known strategies are short memory strategies that utilize only the recent history of previous interactions. In this paper, the effect of the memory size of strategies on their evolutionary stability in both infinite length and indefinite length n-person iterated prisoner's dilemma is studied. Based on the concept of a counter strategy, we develop a theoretical methodology for evaluating the evolutionary stability of strategies and prove that longer memory strategies outperform shorter memory strategies statistically in the sense of evolutionary stability. We also give an example of a memory-two strategy to show how the theoretical study of evolutionary stability assists in developing novel strategies.",
Towards consistent visual-inertial navigation,"Visual-inertial navigation systems (VINS) have prevailed in various applications, in part because of the complementary sensing capabilities and decreasing costs as well as sizes. While many of the current VINS algorithms undergo inconsistent estimation, in this paper we introduce a new extended Kalman filter (EKF)-based approach towards consistent estimates. To this end, we impose both state-transition and obervability constraints in computing EKF Jacobians so that the resulting linearized system can best approximate the underlying nonlinear system. Specifically, we enforce the propagation Jacobian to obey the semigroup property, thus being an appropriate state-transition matrix. This is achieved by parametrizing the orientation error state in the global, instead of local, frame of reference, and then evaluating the Jacobian at the propagated, instead of the updated, state estimates. Moreover, the EKF linearized system ensures correct observability by projecting the most-accurate measurement Jacobian onto the observable subspace so that no spurious information is gained. The proposed algorithm is validated by both Monte-Carlo simulation and real-world experimental tests.",
Incentive mechanism and protocol design for crowdsourcing systems,"Crowdsourcing systems such as Amazon Mechanical Turk, Yahoo!Answers, and Google Helpouts have attracted extensive attention over the past few years. In a crowdsourcing system, a large group of “workers” solve the tasks outsourced by “requesters”. To make a crowdsourcing system sustainable, it is vital to attract users (both requesters and workers) to participate, and incentivize high-quality solutions. To achieve this objective, we design an effective incentive mechanism and reputation protocol. Our design incorporates various important elements of a crowdsourcing system such as workers having heterogeneous skill sets (i.e., some are “experts” while others are “novices”), and task assignment process, rating system, etc. Our incentive mechanism is composed of a rating system and a reward dividing scheme, and requires the system administrator to divide the reward based on requesters' rating on the solution quality. We derive the minimum reward needed so that “expert” workers are guaranteed provide high-quality solutions. We show that “novice” workers provide low-quality solutions, and our reputation protocol eliminates this undesirable behavior by tracking a worker's solution history and penalizing him when his reputation is poor. We apply repeated game-theoretic frameworks to quantify the impact of this reputation protocol on requesters' cost in guaranteeing high quality solutions.",
A moving-target defense strategy for Cloud-based services with heterogeneous and dynamic attack surfaces,"Due to deep automation, the configuration of many Cloud infrastructures is static and homogeneous, which, while easing administration, significantly decreases a potential attacker's uncertainty on a deployed Cloud-based service and hence increases the chance of the service being compromised. Moving-target defense (MTD) is a promising solution to the configuration staticity and homogeneity problem. This paper presents our findings on whether and to what extent MTD is effective in protecting a Cloud-based service with heterogeneous and dynamic attack surfaces - these attributes, which match the reality of current Cloud infrastructures, have not been investigated together in previous works on MTD in general network settings. We 1) formulate a Cloud-based service security model that incorporates Cloud-specific features such as VM migration/snapshotting and the diversity/compatibility of migration, 2) consider the accumulative effect of the attacker's intelligence on the target service's attack surface, 3) model the heterogeneity and dynamics of the service's attack surfaces, as defined by the (dynamic) probability of the service being compromised, as an S-shaped generalized logistic function, and 4) propose a probabilistic MTD service deployment strategy that exploits the dynamics and heterogeneity of attack surfaces for protecting the service against attackers. Through simulation, we identify the conditions and extent of the proposed MTD strategy's effectiveness in protecting Cloud-based services. Namely, 1) MTD is more effective when the service deployment is dense in the replacement pool and/or when the attack is strong, and 2) attack-surface heterogeneity-and-dynamics awareness helps in improving MTD's effectiveness.","Mathematical model,
Equations,
Security,
Information systems,
Uncertainty,
Probabilistic logic,
Probes"
3DOM: A 3 Degree of Freedom Manipulandum to Investigate Redundant Motor Control,"This paper presents a novel robotic interface to investigate the neuromechanical control of redundant planar arm movements. A unique aspect of this device is the third axis by which the wrist, and hence the pose of the arm can be fully constrained. The topology is based on a 5R, closed loop pantograph, with a decoupled wrist flexion/extension cable actuated mechanism. The design and characterization (in terms of range of motion, impedance, friction and dynamics) are described in this paper. This device is lightweight, safe and has high force capabilities and low impedance. Simple experiments illustrate the advantages of this device for the investigation of redundant motor control in humans.",
On-board inertial-assisted visual odometer on an embedded system,"In this paper, we propose a novel inertial-assisted visual odometry system intended for low-cost micro aerial vehicles (MAVs). The system sensor assembly consists of two downward-facing cameras and an inertial measurement unit (IMU) with three-axis accelerometers/gyroscopes. Real-time implementation of the system is enabled by a low-cost embedded system via two important features: firstly, simple pixel-level algorithms are integrated in a low-end FPGA and accelerated via pipeline and combinational logic techniques; secondly, a fast yaw-and-translation estimation algorithm works well with a novel outlier rejection scheme based on probabilistic predetermined operations rather than hypothesis testing iterations. We illustrate the performance of our system by hovering a MAV in a GPS-denied environment. Its feasibility and robustness is also illustrated in complex outdoor environments.","Cameras,
Visualization,
Feature extraction,
Real-time systems,
Equations,
Robot sensing systems,
Field programmable gate arrays"
Wide bandgap power devices based high efficiency power converters for data center application,"Wide band gap (WBG) power devices, such as Silicon Carbide (SiC) and Gallium Nitride (GaN) devices, have been innovatively applied in the data center power converters, which are based on the high voltage DC (HVDC) power distribution architecture, to evaluate the potential efficiency improvement. For the front-end AC-DC rectifier, a buck rectifier using SiC devices was implemented. The SiC devices were tested at first to obtain the static and switching characteristics. The number of devices in parallel, the switching frequency and the input/output filters were investigated. A prototype of 7.5 kW, 3 phase 480 VAC input, 400 VDC output front-end rectifier was built and tested. The peak efficiency reaches up to 98.55%, and the full load efficiency is 98.54%. For the intermediate DC-DC bus converter, the impact of the GaN devices on the LLC resonant converter efficiency was evaluated and compared with the Si counterparts. Based on the device loss analysis and the FEA simulation on the transformer winding loss, the GaN devices exhibited the reduced device loss, and also the capabilities to reduce the transformer winding loss. A 300 W, 400 VDC input, 12 VDC output GaN device based DC-DC bus converter was built and tested by 96.3% peak efficiency and 96.1% full load efficiency.","Windings,
Gallium nitride,
Rectifiers,
Silicon carbide,
Silicon,
Inductors,
Computer architecture"
A novel feature selection by clustering coefficients of variations,"One of the challenges in inferring a classification model with good prediction accuracy is to select the relevant features that contribute to maximum predictive power. Many feature selection techniques have been proposed and studied in the past, but none so far claimed to be the best. In this paper, a novel and efficient feature selection method called Clustering Coefficients of Variation (CCV) is proposed. CCV is based on a very simple principle of variance-basis which finds an optimal balance between generalization and overfitting. Through a computer simulation experiment, 44 datasets with substantially large number of features are tested by CCV in comparison to four popular feature selection techniques. Results show that CCV outperformed them in all aspects of averaged performances and speed. By the simplicity of design it is anticipated that CCV will be a useful alternative of pre-processing method for classification especially with those datasets that are characterized by many features.","Correlation,
Predictive models,
Complexity theory,
Computational modeling,
Training,
Accuracy,
Standards"
On the Conceptualization of Performance Evaluation of IaaS Services,"Cloud Computing has been increasingly accepted as a promising computing paradigm in industry, with one of the most common delivery models being Infrastructure as a Service (IaaS). An increasing number of providers have started to supply public IaaS services with different terminologies, definitions, and goals. As such, understanding the full scope of performance evaluation of candidate services would be crucial and beneficial for both service customers (e.g., cost-benefit analysis) and providers (e.g., direction of improvement). Given the numerous and diverse IaaS service features to be evaluated, a natural strategy is to implement different types of evaluation experiments separately. Unfortunately, it could be hard to fairly distinguish between different experimental types due to different environments and techniques that may be adopted by different evaluators. To overcome such obstacles, we have first established a novel taxonomy to help profile and clarify the nature of IaaS services performance evaluation and then built a three-layer conceptual model to generalize the existing performance evaluation practices. Using relevant elements/classifiers in the taxonomy and conceptual model, evaluators can construct natural language-style descriptions and experimental design blueprints to outline the evaluation scope and also to guide new evaluation implementations. In essence, the generated descriptions and blueprints abstractly define and characterize the actual evaluation work. This enables relatively fair and rational comparisons between different performance evaluations according to their abstract characteristics.","Performance evaluation,
Cloud computing,
Taxonomy,
Scalability,
Context modeling"
Temperature-Dependent Instability of Bias Stress in InGaZnO Thin-Film Transistors,"The instability of the gate bias and drain bias stresses is observed at high temperature in amorphous InGaZnO thin-film transistors (a-IGZO TFTs). The transfer characteristics of a-IGZO TFTs at different temperatures are also investigated in this paper. The transfer curve exhibits an apparent subthreshold current stretchout phenomenon at high temperature. The stretchout phenomenon becomes more serious with the increase of the temperature. In addition, thermally induced holes are accumulated by the negative gate voltage and get trapped in the gate dielectric or at the dielectric/channel interface at high temperature. The negative threshold voltage shifts with stress time and this is because the trapped holes induce more electrons. For drain bias stress at high temperature, the transfer curve exhibits an apparent shift during drain bias stress at high temperature compared with the same at room temperature. At high temperature, thermally induced holes are trapped in the gate insulator, especially near the drain region. Capacitance-voltage measurements have been used to prove the nonuniform hole-trapping phenomenon. Furthermore, the simulation of the capacitance-voltage and current-voltage curves also have been applied to confirm the hole-trapping distribution. The obtained results clarify that the instability is caused by nonuniform hole-trapping phenomenon.","Stress,
Logic gates,
Thin film transistors,
Temperature,
Temperature measurement,
Educational institutions"
A Power Efficient and Compact Optical Interconnect for Network-on-Chip,"Optical interconnect is a promising alternative to substitute the electrical interconnect for intra-chip communications. The topology of optical Network-on-Chip (ONoC) has a great impact on the network performance. However, the size of ONoC is limited by the power consumption and crosstalk noise, which are mainly resulted from the waveguide crossings in the topology. In this paper, a diagonal Mesh topology (DMesh) is proposed to relieve the limitation of scalability by reducing the number of waveguide crossing, which is only 20% that of Mesh. In addition, the number of optical routers in DMesh is less than half of that in Mesh-based ONoC. Due to its compact architecture and favorable scalability, DMesh topology is suitable for large-scale ONoC design.","Wavelength division multiplexing,
Network topology,
Optical routers,
Optical interconnects"
Pre-Energized Auxiliary Circuits for Very Fast Transient Loads: Coping With Load-Informed Power Management for Computer Loads,"The recent development in computer science that the power demand and required time of code execution can be accurately predicted is paving a path that may lead to a new paradigm shift in power supply design. Specifically, while the design of power supplies now normally assumes that load current changes at random times and with unknown magnitudes (within a range), future computer loads may communicate with power supplies to provide information that facilitates power management. Such information would include the exact times of occurrence of load transients and their magnitudes. Following this trend of development where the power supply is “informed” by the load, we propose to use an auxiliary circuit that generates a slowly rising current prior to the occurrence of the actual transient. The slowly rising current can cause the power supply to shift its operation point to a new level slowly without exhibiting output voltage fluctuation. The actual load exhibits very fast current transient, but the combination of actual load and auxiliary circuit behaves as a slowly changing load which can be dealt with by an ordinary power supply capable of handling slowly changing load current. Thus, this method essentially buffers the power supply from large and fast transients. Our proposed approach involves the necessary algorithm for controlling the auxiliary circuit in accordance with the information provided by the microprocessor. The design of the auxiliary circuit is explained and experimental results for a 1.5 V load with 15 A step current are provided for verification.",
A miniature 25 grams running and jumping robot,"In this paper, we present the design and development of a miniature robot that is able to run and jump. This robot can use wheeled locomotion to travel on the flat ground. When it encounters a large obstacle compared to its size, it can stand up and leap over the obstacle. The robot has a mass of 25 grams and a maximum size of 9 centimeters. Experimental results show that with a take-off angle 80°, the robot can jump up to 1.44 meter in height and 0.59 meter in distance. Moreover, it has on-board energy, control, and communication abilities, which enables tetherless or autonomous operation. With the multi-modal locomotion abilities, the robot is expected to have many applications ranging from environmental monitoring, search and rescue, to military surveillance.",
Transfer Learning of Structured Representation for Face Recognition,"Face recognition under uncontrolled conditions, e.g., complex backgrounds and variable resolutions, is still challenging in image processing and computer vision. Although many methods have been proved well-performed in the controlled settings, they are usually of weak generality across different data sets. Meanwhile, several properties of the source domain, such as background and the size of subjects, play an important role in determining the final classification results. A transferrable representation learning model is proposed in this paper to enhance the recognition performance. To deeply exploit the discriminant information from the source domain and the target domain, the bioinspired face representation is modeled as structured and approximately stable characterization for the commonality between different domains. The method outputs a grouped boost of the features, and presents a reasonable manner for highlighting and sharing discriminant orientations and scales. Notice that the method can be viewed as a framework, since other feature generation operators and classification metrics can be embedded therein, and then, it can be applied to more general problems, such as low-resolution face recognition, object detection and categorization, and so forth. Experiments on the benchmark databases, including uncontrolled Face Recognition Grand Challenge v2.0 and Labeled Faces in the Wild show the efficacy of the proposed transfer learning algorithm.",
A Learning-Based Semi-Autonomous Controller for Robotic Exploration of Unknown Disaster Scenes While Searching for Victims,"Semi-autonomous control schemes can address the limitations of both teleoperation and fully autonomous robotic control of rescue robots in disaster environments by allowing a human operator to cooperate and share such tasks with a rescue robot as navigation, exploration, and victim identification. In this paper, we present a unique hierarchical reinforcement learning-based semi-autonomous control architecture for rescue robots operating in cluttered and unknown urban search and rescue (USAR) environments. The aim of the controller is to enable a rescue robot to continuously learn from its own experiences in an environment in order to improve its overall performance in exploration of unknown disaster scenes. A direction-based exploration technique is integrated in the controller to expand the search area of the robot via the classification of regions and the rubble piles within these regions. Both simulations and physical experiments in USAR-like environments verify the robustness of the proposed HRL-based semi-autonomous controller to unknown cluttered scenes with different sizes and varying types of configurations.",
A 41-mW 30-Gb/s CMOS optical receiver with digitally-tunable cascaded equalization,"This paper presents a 65-nm CMOS, 1-V, 1.37-pJ/bit optical receiver with embedded equalizer, enabling adaptability to overcome channel losses and component variations. The digitally-controlled continuous-time linear equalizer (CTLE) consists of three cascaded tunable peaking stages offering 16-dB of adjustable low-frequency gain. Optical measurement results with a 30-Gb/s photodetector (PD) show that the receiver achieves 10-12 BER at 30 Gb/s for a 215-1 PRBS input with a -5.6-dBm input sensitivity. Using a lower bandwidth 14-Gb/s PD, the receiver can still reach 30 Gb/s at 10-12 BER with only a 0.6-dB degradation in input sensitivity. These measurement results demonstrate the effectiveness of the proposed receiver and the programmable cascaded CTLE.","Optical receivers,
Optical variables measurement,
CMOS integrated circuits,
Optical sensors,
Gain,
Sensitivity"
Joint energy and delay-aware scheme for 5G mobile cognitive radio networks,"This paper proposes a delay-assisted cooperative scheme for optimal TV White Spaces (TVWS) exploitation and maximum energy conservation in a 5G mobile cognitive radio (CR) network architecture. This architecture utilizes a radio spectrum broker, which administrates the process of network resources management among several 5G base-stations to support Quality of Service (QoS) provision and minimum energy consumption. The proposed scheme is based on the comparison of the delays of both the secondary nodes and the Radio Access Points, when a delay sensitive transmission is requested. The validity of the proposed scheme is verified through several experimental tests, performed under controlled simulation conditions. The performance evaluation results include the energy consumption level and the lifetime span of each wireless node, the throughput response of the system during the delay-sensitive resource exchange process, as well as quantitative measurements of the energy efficiency levels of the proposed scheme.","Mobile communication,
Delays,
Peer-to-peer computing,
Mobile computing,
Energy efficiency,
Relays,
Tin"
Distribution system voltage regulation by distributed energy resources,This paper proposes a control method to regulate voltages in 3 phase unbalanced electrical distribution systems. A constrained optimization problem to minimize voltage deviations and maximize distributed energy resource (DER) active power output is solved by harmony search algorithm. IEEE 13 Bus Distribution Test System was modified to test three different cases: a) only voltage regulator controlled system b) only DER controlled system and c) both voltage regulator and DER controlled system. The simulation results show that systems with both voltage regulators and DER control provide better voltage profile.,
Dynamic Analysis of Cross Flow Heat Exchangers in Data Centers Using Transient Effectiveness Method,"Heat exchangers are important facilities used in data center cooling systems. The effectiveness of heat exchangers strongly influences the thermal performance of cooling systems. Rear door heat exchangers, in-row, overhead coolers, and fully contained cabinets are some examples of executing liquid and hybrid cooling systems used in data centers. A liquid to liquid heat exchanger is an important component of the coolant distribution unit, which supplies chilled water to the aforementioned heat exchangers. Computer room air handler units are also typically liquid to air cross flow heat exchangers. It is important to characterize the dynamic behavior of these heat exchangers for the thermal management of data centers, to improve the design of control strategies, and energy efficiency. The transient response of a 2-D unmixed-unmixed cross flow heat exchanger, with a finite wall capacitance, is investigated. The transient effectiveness concept is used to build the mathematical models that will be used to solve and analyze the transient problems involving cross flow heat exchangers. Several transient cases are investigated numerically for step, ramp, and exponential variations in the inlet temperature of the minimum capacity rate fluid, as well as step and ramp changes in the flow rate of hot and cold fluids. The transient effectiveness characteristics are tested in parametric studies. The results obtained show that transient effectiveness is a useful method of analyzing and predicting the dynamic performance of cross flow heat exchangers.","Cooling,
Transient analysis,
Mathematical model,
Heat transfer,
Steady-state,
Boundary conditions,
Liquid cooling"
"Fast Inversion in
GF(
2
m
)
with Normal Basis Using Hybrid-Double Multipliers","Fast inversion in finite fields is crucial for high-performance cryptography and codes. We present techniques to exploit the recently proposed hybrid-double multipliers for fast inversions in binary fields GF(2m) with normal bases. A hybrid-double multiplier computes a double multiplication, the product of three elements in GF(2m), with a latency comparable to the latency of single multiplication of two elements. Traditional approaches, such as Itoh-Tsujii, cannot utilize hybrid-double multipliers. We devise a new inversion algorithm based on ternary representations that exploits their potential. The algorithm reduces the latency of inversion significantly for the fields recommended by NIST if hybrid-double multipliers are employed. For example, the algorithm computes an inversion in GF(2163) with only five double multiplications whereas the Itoh-Tsujii algorithm requires nine single or double multiplications. We propose a new inverter architecture using this new algorithm and a hybrid-double multiplier. We show that it is faster than the existing techniques by providing ASIC synthesis results using 65-nm CMOS technology. For example, our inverter for GF(2163) achieves about 34 percent shorter computation time than an inverter using the Itoh-Tsujii algorithm and a single multiplier.",
IPv4 Address Sharing Mechanism Classification and Tradeoff Analysis,"The growth of the Internet has made IPv4 addresses a scarce resource. Due to slow IPv6 deployment, IANA-level IPv4 address exhaustion was reached before the world could transition to an IPv6-only Internet. The continuing need for IPv4 reachability will only be supported by IPv4 address sharing. This paper reviews ISP-level address sharing mechanisms, which allow Internet service providers to connect multiple customers who share a single IPv4 address. Some mechanisms come with severe and unpredicted consequences, and all of them come with tradeoffs. We propose a novel classification, which we apply to existing mechanisms such as NAT444 and DS-Lite and proposals such as 4rd, MAP, etc. Our tradeoff analysis reveals insights into many problems including: abuse attribution, performance degradation, address and port usage efficiency, direct intercustomer communication, and availability.","IP networks,
Internet"
A Printable CNT-Based FM Passive Wireless Sensor Tag on a Flexible Substrate With Enhanced Sensitivity,"In this paper, we report a frequency-modulated (FM) passive wireless sensor tag for ammonia (NH3) sensing. The passive wireless sensor tag consists of a single-walled carbon nanotube (SWCNT) network based NH3 sensor, a radio frequency antenna, a ring oscillator, and other supporting circuits. The SWCNT network-based NH3 sensor is fabricated on a flexible plastic substrate through printable processes. The printable SWCNT-based NH3 sensor shows an enhanced sensitivity of 0.76% per part per million primarily due to the large surface area of the SWCNT network. The sensor also exhibits a high linearity between the resistance of the sensor and logarithm of the NH3 concentration (referred to as log [NH3] henceforth). A simple FM circuit is designed to convert the resistance change of the sensor to the oscillating frequency shift of the circuit. By properly designing the circuit, we have obtained a linear response between the frequency shift and log [NH3]. The linear response allows one to precisely predict the NH3 concentration by measuring the frequency shift of the FM wireless sensor tag. Such an FM-modulated passive wireless sensor tag with linear response and enhanced sensitivity is promising for power-less stand-alone low-level NH3 sensing and monitoring with high accuracy.",
Deep learning representation using autoencoder for 3D shape retrieval,"We study the problem of how to build a deep learning representation for 3D shape. Deep learning has shown to be very effective in variety of visual applications, such as image classification and object detection. However, it has not been successfully applied to 3D shape recognition. This is because 3D shape has complex structure in 3D space and there are limited number of 3D shapes for feature learning. To address these problems, we project 3D shapes into 2D space and use autoencoder for feature learning on the 2D images. High accuracy 3D shape retrieval performance is obtained by aggregating the features learned on 2D images. In addition, we show the proposed deep learning feature is complementary to conventional local image descriptors. By combing the global deep learning representation and the local descriptor representation, our method can obtain the state-of-the-art performance on 3D shape retrieval benchmarks.","Three-dimensional displays,
Shape,
Solid modeling,
Vectors,
Image reconstruction,
Training,
Visualization"
Efficient synthesis of quantum circuits implementing clifford group operations,"Quantum circuits established themselves as a promising emerging technology and, hence, attracted considerable attention in the domain of computer-aided design. As a result, many approaches for synthesis of corresponding netlists have been proposed in the last decade. However, as the design of quantum circuits faces serious obstacles caused by phenomena such as superposition, entanglement, and phase shifts, automatic synthesis still represents a significant challenge. In this paper, we propose an automatic synthesis approach for quantum circuits that implement Clifford Group operations. These circuits are essential for many quantum applications and cover core aspects of quantum functionality. The proposed approach exploits specific properties of the unitary transformation matrices that are associated to quantum operations. Furthermore, Quantum Multiple-Valued Decision Diagrams (QMDDs) are employed for an efficient representation of these matrices. Experimental results confirm that this enables a compact realization of the respective quantum functionality.","Logic gates,
Quantum computing,
Quantum entanglement,
Generators,
Libraries,
Computer science"
"Design, Modeling, and Simulation of On-Demand Communication Mechanisms for Cyber-Physical Energy Systems","Advanced communication technology is the enabling factor for distributed sensing and control in smart grid. The performance of communication has a significant effect on the performance of the controllers that manage a power system. This effect is more profound when transient level behavior and critical applications are concerned. In these cases, an important issue is to design control-aware communication strategies for utilizing available communication technologies. Such strategies should describe what needs to be communicated when and between which nodes. In this paper, an “on-demand” strategy is presented that describes how communication subsystems should be configured, almost agnostically to the underlying technologies, to achieve significant performance improvement for the application. The on-demand method relies on the concept of error-dependent communication for tracking dynamical systems over communication networks. The paper also introduces the design of an embedded communication simulator integrated with PSCAD for cosimulation of communication strategies/protocols and power system components.","Smart grids,
Protocols,
PSCAD,
Communication networks"
A progressive random walk algorithm for sampling continuous fitness landscapes,A number of fitness landscape analysis approaches are based on random walks through discrete search spaces. Applying these approaches to real-encoded problems requires the notion of a random walk in continuous space. This paper proposes a progressive random walk algorithm and the use of multiple walks to sample neighbourhood structure in continuous multi-dimensional spaces. It is shown that better coverage of a search space is provided by progressive random walks than simple unbiased random walks.,"Algorithm design and analysis,
Search problems,
Hypercubes,
Correlation,
Vectors,
Optimization,
Atmospheric measurements"
Control of the coupled motion of a 6 DoF robotic arm and a continuum manipulator for the treatment of pelvis osteolysis,"The paper addresses the coupled motion of a 6 degree of freedom robot and a snake-like dexterous manipulator (SDM) designed for the treatment of bone defects behind the implant during total hip arthroplasty revision surgery. We have formulated the problem as a weighted, multi-objective constraint, linear optimization. A remote center of motion (RCM) acts as a virtual constraint for the robot. The coupled robot kinematics does not assume piecewise-constant curvature for the SDM. We have evaluated our method by simulating the coupled system inside a potential lesion area.","Manipulators,
Robot kinematics,
Kinematics,
Optimization,
Lesions,
Shafts"
Fabrication Attacks: Zero-Overhead Malicious Modifications Enabling Modern Microprocessor Privilege Escalation,"The wide deployment of general purpose and embedded microprocessors has emphasized the need for defenses against cyber-attacks. Due to the globalized supply chain, however, there are several stages where a processor can be maliciously modified. The most promising stage, and the hardest during which to inject the hardware trojan, is the fabrication stage. As modern microprocessor chips are characterized by very dense, billion-transistor designs, such attacks must be very carefully crafted. In this paper, we demonstrate zero overhead malicious modifications on both high-performance and embedded microprocessors. These hardware trojans enable privilege escalation through execution of an instruction stream that excites the necessary conditions to make the modification appear. The minimal footprint, however, comes at the cost of a small window of attack opportunities. Experimental results show that malicious users can gain escalated privileges within a few million clock cycles. In addition, no system crashes were reported during normal operation, rendering the modifications transparent to the end user.","Microprocessors,
Trojan horses,
Fabrication,
Hardware,
Embedded systems,
Logic gates,
Computer architecture"
Planning with the STAR(s),"We present our findings on the first application of motion planning methodologies to the recently introduced Sprawl Tuned Autonomous Robot (STAR). The reported results provide a first glimpse on the capabilities of this novel, 3D-printed robot in performing autonomously non-trivial motion planning tasks in environments populated with obstacles. We employ methods from sampling-based motion planning under nonholonomic constraints, and implement in open loop the generated path on the physical robot for various environments of increasing complexity.",
Catheter-Induced Errors in Pressure Measurements in Vessels: An In-Vitro and Numerical Study,"Accurate measurement of blood pressure is important because it is a biomarker for cardiovascular disease. Diagnostic catheterization is routinely used for pressure acquisition in vessels despite being subject to significant measurement errors. To investigate these errors, this study compares pressure measurement using two different techniques in vitro and numerical simulations. Pressure was acquired in a pulsatile flow phantom using a 6F fluid-filled catheter and a 0.014'' pressure wire, which is considered the current gold standard. Numerical simulations of the experimental set-up with and without a catheter were also performed. Despite the low catheter-to-vessel radius ratio, the catheter traces showed a 24% peak systolic pressure overestimation compared to the wire. The numerical models replicated this difference and indicated the cause for overestimation was the increased flow resistance due to the presence of the catheter. Further, the higher frequency pressure oscillations observed in the wire and numerical data were absent in the catheter, resulting in an overestimation of the pulse wave velocity with the latter modality. These results show that catheter geometry produces significant measurement bias in both the peak pressure and the waveform shape even with radius ratios considered acceptable in clinical practice. The wire allows for more accurate pressure quantification, in agreement with the numerical model without a catheter.","Catheters,
Wires,
Numerical models,
Pressure measurement,
In vitro,
Biomedical measurement,
Frequency measurement"
Merged physical and virtual reality in collaborative virtual workspaces: The VirCA approach,"Recently emerging paradigms of the so called Future Internet induce significant changes in consumer and industrial ICT applications. Remote collaboration in mixed physical and virtual realities made possible thanks to the increasing network bandwidth further empowered by the achievements of Internet of Things, Cloud Computing and Internet of Services. This enticing vision brings benefits for several application fields ranging from STEM education to smart factories. The paper discusses some new possibilities through the VirCA (Virtual Collaboration Arena) framework as a pilot realization. A brief introduction is given to VirCA focusing on the basic concepts and features that make it well suited for collaborative work in mixed virtual and physical reality. Through a concrete life-like example, the paper illustrates the way of involving real industrial devices into remote collaboration scenarios and reviews the typical uses of such a shared infrastructure considering the relationship of the virtual and real entities.","Service robots,
Collaboration,
Robot sensing systems,
Internet,
Engines"
Optimal Error Rates for Interactive Coding II: Efficiency and List Decoding,"We study coding schemes for error correction in interactive communications. Such interactive coding schemes simulate any n-round interactive protocol using N rounds over an adversarial channel that corrupts up to ρN transmissions. Important performance measures for a coding scheme are its maximum tolerable error rate ρ, communication complexity N, and computational complexity. We give the first coding scheme for the standard setting which performs optimally in all three measures: Our randomized non-adaptive coding scheme has a near-linear computational complexity and tolerates any error rate δ <; 1/4 with a linear N = Θ(n) communication complexity. This improves over prior results [1]-[4] which each performed well in two of these measures. We also give results for other settings of interest, namely, the first computationally and communication efficient schemes that tolerate ρ <; 2/7 adaptively, ρ <; 1/3 if only one party is required to decode, and ρ <; 1/2 if list decoding is allowed. These are the optimal tolerable error rates for the respective settings. These coding schemes also have near linear computational and communication complexity. These results are obtained via two techniques: We give a general black-box reduction which reduces unique decoding, in various settings, to list decoding. We also show how to boost the computational and communication efficiency of any list decoder to become near linear1.","Encoding,
Decoding,
Protocols,
Error analysis,
Computational complexity,
Error correction codes"
Extension of Modularity Density for overlapping community structure,"Modularity is widely used to effectively measure the strength of the disjoint community structure found by community detection algorithms. Although several overlapping extensions of modularity were proposed to measure the quality of overlapping community structure, there is lack of systematic comparison of different extensions. To fill this gap, we overview overlapping extensions of modularity to select the best. In addition, we extend the Modularity Density metric to enable its usage for overlapping communities. The experimental results on four real networks using overlapping extensions of modularity, overlapping modularity density, and six other community quality metrics show that the best results are obtained when the product of the belonging coefficients of two nodes is used as the belonging function. Moreover, our experiments indicate that overlapping modularity density is a better measure of the quality of overlapping community structure than other metrics considered.","Communities,
Measurement,
Equations,
Mathematical model,
Social network services,
Conferences,
Image edge detection"
"Emission Behavior of Three Conditioned Carbon Fiber Cathode Types in UHV-Sealed Tubes at 200 A/
cm
2","When subjected to high electric fields in vacuum, carbon fiber cathodes produce intense electron beams suitable for high-power microwave (HPM) generation at very high current densities. However, the production mechanisms of these intense electron beams are not fully understood. This paper presents the postmortem examination of three conditioned carbon fiber cathode types. The three cathode types consist of an uncoated, bare unimodal fiber structure, a bare bimodal fiber structure, and a cesium-iodide (CsI)-coated bimodal fiber structure, all with identical fiber coverage of 2% by area. Each cathode was conditioned prior to testing by single pulse operation driven by an 80 J Marx generator for 10 000 pulses. HPM, voltage, and current waveforms of each cathode are presented. The bare bimodal cathode radiated more microwave power than the CsI-coated cathode and bare unimodal cathode. Scanning electron microscopy imagery presents evidence of two emission mechanisms: 1) explosive electron emission and 2) surface flashover, which both were found on the CsI-coated cathode. In addition, no evidence of surface flashover was found on either uncoated cathode.","Cathodes,
Carbon dioxide,
Electron beams,
Microwave imaging,
Microwave oscillators,
Shafts"
Diversified social influence maximization,"For better viral marketing, there has been a lot of research on social influence maximization. However, the problem that who is influenced and how diverse the influenced population is, which is important in real-world marketing, has largely been neglected. To that end, in this paper, we propose to consider the magnitude of influence and the diversity of the influenced crowd simultaneously. Specifically, we formulate it as an optimization problem, i.e., diversified social influence maximization. First, we present a general framework for this problem, under which we construct a class of diversity measures to quantify the diversity of the influenced crowd. Meanwhile, we prove that a simple greedy algorithm guarantees to provide a near-optimal solution to the optimization problem. Furthermore, we relax the problem by focusing on the diversity of the nodes targeted for initial activation, and show how this relaxed form could be used to diversify the results of many heuristics, e.g., PageRank. Finally, we run extensive experiments on two real-world datasets, showing that our formulation is effective in generating diverse results.","Cultural differences,
Motion pictures,
Greedy algorithms,
Social network services,
Equations,
Integrated circuit modeling,
Mathematical model"
GaN-Based Resonant-Cavity LEDs Featuring a Si-Diffusion-Defined Current Blocking Layer,"GaN-based resonant-cavity light-emitting diode (RCLED) featuring a Si-diffusion-defined confinement structure is reported for the first time. The charge-coupled device images exhibited round, bright spots of sizes corresponding to the diffusion-defined aperture sizes under continuous-wave high-current-density operation and at room temperature. The full widths at half maximum of the electroluminescence spectra were 2 and 1.5 nm for 10- and 5-mu-diameter RCLEDs, respectively. A stable peak wavelength of 406.6 nm was maintained at various injection currents. The results suggest Si diffusion is an effective means to reduce aperture size. The design and fabrication of the devices are described.",
Soft OR approaches in problem formulation stage of a hybrid M&S study,"A simulation study consists of several well-defined stages, e.g., problem formulation, model implementation and experimentation. The application of multiple techniques in the model implementation stage is referred to as hybrid simulation, which we distinguish in this paper from a hybrid M&S study, the latter referring to studies that apply methods and techniques from disciplines like Operations Research, Systems Engineering and Computer Science to one or more stages of a simulation study. We focus on the first stage of a simulation study (and by extension a hybrid M&S study), viz., eliciting the system requirements, and conduct a review of literature in Soft Systems Methodology for healthcare operations management. We discuss the potential for the use of Qualitative System Dynamics as an additional soft OR method, complementing (rather than supplanting) existing approaches, which can further aid the understanding of the system in the problem formulation/conceptual modelling stage of a Hybrid M&S study.",
"Relating Diagnosability, Strong Diagnosability and Conditional Diagnosability of Strong Networks","An interconnection network's diagnosability is an important measure of its self-diagnostic capability. Based on the classical notion of diagnosability, strong diagnosability and conditional diagnosability were proposed later to better reflect the networks' self-diagnostic capability under more realistic assumptions. In this paper, we study a class of interconnection networks called strong networks, which are n-regular, (n - 1)-connected, and with cn-number no more than n - 3. We build a relationship among the three diagnosability measures for strong networks. Under both PMC and MM* models, given a strong network G with diagnosability t, we prove that G is strongly t-diagnosable if and only if G's conditional diagnosability is greater than t. A simple check can show that almost all well-known regular interconnection networks are strong networks. The significance of this paper's result is that it reveals an important relationship between strong and conditional diagnosabilities, and the proof of strong diagnosability for many interconnection networks under MM* or PMC model is not necessary if their conditional diagnosability can be shown to be strictly larger than their diagnosability.","Multiprocessor interconnection,
Program processors,
Computational modeling,
Multiprocessing systems,
Fault tolerance,
Fault tolerant systems,
Educational institutions"
A 128 Kbit SRAM With an Embedded Energy Monitoring Circuit and Sense-Amplifier Offset Compensation Using Body Biasing,"Embedded SRAMs are continuing to be one of the most critical components that limit the performance and energy budget of today's systems. To enable better system level optimization, this paper introduces an embedded energy monitoring circuit that measures the absolute energy consumption of a 128 kbit SRAM circuit that is fabricated using a 65 nm low-power CMOS process. Monitoring circuit results are measured to be accurate within 10% of the actual energy consumption and it works with minimal overhead (below 1% active power). Secondly, to achieve energy-efficient and high-performance SRAM operation, various circuit techniques are employed. 8T bit-cells with word-line voltage boosting is used to enable operation for a wide supply range from 370 mV to 1.2 V. Since variation effects are more prominent at low-voltages, SRAM performance is improved by using a two stage sensing scheme. Global sensing is performed by offset compensated sense amplifiers that leverage body biasing to achieve up to 2x offset reduction for only 3.5% area overhead compared to SRAM area.","Random access memory,
Sensors,
Calibration,
Monitoring,
Energy consumption,
Transistors,
Inverters"
Islanding detection based on probabilistic PCA with missing values in PMU data,"This paper proposes a probabilistic principal component analysis (PCA) approach applied to islanding detection study based on wide area PMU data. The increasing probability of uncontrolled islanding operation, according to many power system operators, is one of the biggest concerns with a large penetration of distributed renewable generation. The traditional islanding detection methods, such as RoCoF and vector shift, are however extremely sensitive and may result in many unwanted trips. The proposed probabilistic PCA aims to improve islanding detection accuracy and reduce the risk of unwanted tripping based on PMU measurements, while addressing a practical issue on missing data. The reliability and accuracy of the proposed probabilistic PCA approach are demonstrated using real data recorded in the UK power system by the OpenPMU project. The results show that the proposed methods can detect islanding accurately, without being falsely triggered by generation trips, even in the presence of missing values.","Principal component analysis,
Probabilistic logic,
Phasor measurement units,
Islanding,
Monitoring,
Distributed power generation"
An SDN-based cloud computing architecture and its mathematical model,"Software-defined Networking (SDN) has emerged as the dominant programmable network architecture that separates the control plane from the data plane. SDN allows the network administrators and data centers to efficiently and flexibly manage their networking equipment using software that runs on external servers. SDN adopts OpenFLow protocol to communicate between network switch and controller. In this paper, we first establish a SDN-based cloud computing environment via open source OpenFLow switch and controller packages. Thereafter, we extend the functionality of OpenFLow controller to provide load balancing, power-saving, and monitoring mechanisms. To verify the feasibility of our architecture, we also develop a queueing model for SDN and calculate its analytical solution for the steady-state probabilities. The experimental results show that SDN-based environment can provide QoS guaranteed cloud computing services.",
Hop-by-Hop Message Authenticationand Source Privacy in WirelessSensor Networks,"Message authentication is one of the most effective ways to thwart unauthorized and corrupted messages from being forwarded in wireless sensor networks (WSNs). For this reason, many message authentication schemes have been developed, based on either symmetric-key cryptosystems or public-key cryptosystems. Most of them, however, have the limitations of high computational and communication overhead in addition to lack of scalability and resilience to node compromise attacks. To address these issues, a polynomial-based scheme was recently introduced. However, this scheme and its extensions all have the weakness of a built-in threshold determined by the degree of the polynomial: when the number of messages transmitted is larger than this threshold, the adversary can fully recover the polynomial. In this paper, we propose a scalable authentication scheme based on elliptic curve cryptography (ECC). While enabling intermediate nodes authentication, our proposed scheme allows any node to transmit an unlimited number of messages without suffering the threshold problem. In addition, our scheme can also provide message source privacy. Both theoretical analysis and simulation results demonstrate that our proposed scheme is more efficient than the polynomial-based approach in terms of computational and communication overhead under comparable security levels while providing message source privacy.",
Online self-supervised multi-instance segmentation of dynamic objects,"This paper presents a method for the continuous segmentation of dynamic objects using only a vehicle mounted monocular camera without any prior knowledge of the object's appearance. Prior work in online static/dynamic segmentation [1] is extended to identify multiple instances of dynamic objects by introducing an unsupervised motion clustering step. These clusters are then used to update a multi-class classifier within a self-supervised framework. In contrast to many tracking-by-detection based methods, our system is able to detect dynamic objects without any prior knowledge of their visual appearance shape or location. Furthermore, the classifier is used to propagate labels of the same object in previous frames, which facilitates the continuous tracking of individual objects based on motion. The proposed system is evaluated using recall and false alarm metrics in addition to a new multi-instance labelled dataset to measure the performance of segmenting multiple instances of objects.",
Analysis and Optimization of a Protocol for Mobile Element Discovery in Sensor Networks,"Recent studies have demonstrated that mobile elements (MEs) are an efficient solution to help decrease dramatically energy consumption in wireless sensor networks (WSNs). However, in most of cases, sensors use duty cycle schemes to save energy, and unless the ME mobility pattern is deterministic, each sensor node has to discover the presence of the ME in the nearby area before starting to exchange data with it. Therefore, in such wireless sensor networks with mobile elements (in short, WSN-MEs), the definition and analysis of a protocol for efficient ME discovery becomes of fundamental importance. In this paper, we propose an extensive performance analysis of an easy-to-implement, hierarchical discovery protocol for WSN-MEs, called Dual Beacon Discovery (2BD) protocol, taking into account stochastic, multi-path, variable speed ME mobility patterns. We also derive the optimal parameter values that minimize the energy consumption of sensor nodes, while guaranteeing the minimum node throughput required by the applications under consideration. Finally, we compare the 2BD protocol with a classical solution based on Periodic Listening (PL). Our results show that 2BD can exploit its hierarchical mechanism and thus significantly increase lifetime, especially when the ME discovery phase is relatively long.","Protocols,
Wireless sensor networks,
Mobile computing,
Mobile communication,
Analytical models,
Optimization,
Energy consumption"
Vector Gaussian Multiterminal Source Coding,"We derive an outer bound of the rate region of the vector Gaussian L -terminal CEO problem by establishing a lower bound on each supporting hyperplane of the rate region. To this end, we prove a new extremal inequality by exploiting the connection between differential entropy and Fisher information as well as some fundamental estimation-theoretic inequalities. It is shown that the outer bound matches the Berger-Tung inner bound in the high-resolution regime. We then derive a lower bound on each supporting hyperplane of the rate region of the direct vector Gaussian L -terminal source coding problem by coupling it with the CEO problem through a limiting argument. The tightness of this lower bound in the high-resolution regime and the weak-dependence regime is also proved.","Nickel,
Vectors,
Source coding,
Upper bound,
Entropy,
Covariance matrices,
Limiting"
Scalable Effort Hardware Design,"Applications from several application domains exhibit the property of inherent application resilience, offering entirely new avenues for performance and power optimization by relaxing the conventional requirement of exact (numerical or Boolean) equivalence between the specification and hardware implementation. We propose scalable effort hardware as a design approach to tap the reservoir of application resilience and translate it into highly efficient hardware implementations. The first tenet of the scalable effort design approach is to identify mechanisms at each level of design abstraction (circuit, architecture, and algorithm) that can be used to vary the computational effort expended toward generation of the correct (exact) result, and to expose these mechanisms as control knobs in the implementation. These scaling mechanisms can be utilized to achieve improved energy efficiency while maintaining an acceptable (and often, near identical) level of quality of the overall result. The second tenet of the scalable effort design approach is that fully exploiting the potential of application resilience requires synergistic cross-layer optimization of scaling mechanisms identified at different levels of design abstraction. We have implemented an energy-efficient recognition and mining (RM) processor based on the proposed scalable effort design approach. Results from the execution of support vector machine training and classification, generalized learning vector quantization training, and k-means clustering on the scalable effort RM processor show that it can achieve energy reductions of 1.2×-5× with negligible impact on output quality, and 2.2×-50× with moderate loss in output quality, across various data sets. Our results also establish that cross-layer optimization across different scaling mechanisms leads to higher energy savings (1.4×-2× on an average) for a given output quality compared with each of the individual techniques.",
Governance of Cloud Computing Services for the Life Sciences,"The authors analyze legal regulation issues surrounding cloud computing in healthcare. As a result of the authors' expertise in cloud-based data processing for organizations in the areas of healthcare and life sciences, they propose an implementation roadmap. The roadmap is intended to provide guidance for organizations in the life sciences regarding the governance of health data processing and storage. This article is part of a special issue on life sciences computing.","Cloud computing,
Data processing,
Science - general,
Medical services,
Legal aspects,
Computational modeling,
Outsourcing,
Law,
Medical services"
Cross-View Action Recognition Using Contextual Maximum Margin Clustering,"Recently, maximum margin clustering (MMC) has been proposed for a cross-view action recognition. However, such a method neglects the temporal relationship between contiguous frames in the same action video. In this paper we propose a novel method called contextual maximum margin clustering (CMMC) to tackle cross-view action recognition. In CMMC, we add temporal regularization to give a high penalty when the contiguous frames are dissimilar. Thus, the CMMC not only achieves the goal of finding maximum margin hyperplanes, but also explicitly considers the temporal information among contiguous frames. Our method is verified on the IXMAS dataset and the experimental results demonstrate that our method can achieve better performance than the state-of-the-art methods.","Accuracy,
Optimization,
Computer vision,
Pattern recognition,
Training,
Support vector machines,
Convergence"
You Are the Only Possible Oracle: Effective Test Selection for End Users of Interactive Machine Learning Systems,"How do you test a program when only a single user, with no expertise in software testing, is able to determine if the program is performing correctly? Such programs are common today in the form of machine-learned classifiers. We consider the problem of testing this common kind of machine-generated program when the only oracle is an end user: e.g., only you can determine if your email is properly filed. We present test selection methods that provide very good failure rates even for small test suites, and show that these methods work in both large-scale random experiments using a “gold standard” and in studies with real users. Our methods are inexpensive and largely algorithm-independent. Key to our methods is an exploitation of properties of classifiers that is not possible in traditional software testing. Our results suggest that it is plausible for time-pressured end users to interactively detect failures-even very hard-to-find failures-without wading through a large number of successful (and thus less useful) tests. We additionally show that some methods are able to find the arguably most difficult-to-detect faults of classifiers: cases where machine learning algorithms have high confidence in an incorrect result.",
Spectrogram-based audio classification of nutrition intake,"Acoustic monitoring of food intake in an unobtrusive, wearable form-factor can encourage healthy dietary choices by enabling individuals to monitor their eating patterns, maintain regularity in their meal times, and ensure adequate hydration levels. In this paper, we describe a system capable of monitoring food intake by means of a throat microphone, classifying the data based on the food being consumed among several categories through spectrogram analysis, and providing user feedback in the form of mobile application. We are able to classify sandwich swallows, sandwich chewing, water swallows, and none, with an F-Measure of 0.836.",
Improved WLS-TF algorithm for dynamic synchronized angle and frequency estimation,"This paper proposes an improved method for estimating synchronized angle and frequency under both steady-state and dynamic conditions based on the weighted least squares Taylor expansion Fourier (WLS-TF) method. The WLS-TF method using classical windows as weighting factors assumes the input signal is a narrowband band-pass signal, and it has efficient performance under most conditions. However, error arises when the signal is not a band-pass signal, which is the case for the waveforms of power system. This paper extends the band-pass signal model to a more general signal model that considers 2nd order harmonic and proposes a new method to estimate the frequency. Examples of the proposed method are illustrated following different steady-state and dynamic conditions considered in power system.",
Locking Range Derivations for Injection-Locked Class-E Oscillator Applying Phase Reduction Theory,"This paper presents a numerical locking-range prediction for the injection-locked class-E oscillator using the phase reduction theory (PRT). By applying this method to the injection-locked class-E oscillator designs, which is in the field of electrical engineering, the locking ranges of the oscillator on any injection-signal waveform can be efficiently obtained. The locking ranges obtained from the proposed method quantitatively agreed with those obtained from the simulations and circuit experiments, showing the validity and effectiveness of the locking-range derivation method based on PRT.","Oscillators,
MOSFET,
Synchronization,
Switches,
Limit-cycles,
Equations,
Capacitance"
Discriminant Hyper-Laplacian projections with its application to face recognition,"Discriminant Locality Preserving Projections (DLPP) is one of the most influential supervised subspace learning algorithms that considers both discriminative and geometric (manifold) information. There is an obvious drawback of DLPP that it only considers the pairwise geometric relationship of samples. However, in many real-world issues, relationships among the samples are often more complex than pairwise. Naively squeezing the complex into pairwise ones will inevitably lead to loss of some information, which are crucial for classification and clustering. We address this issue via using the Hyper-Laplacian instead of the regular Laplacian in DLPP, which only can depict the pairwise relationship. This new DLPP algorithm is exactly a generalization of DLPP and we name it Discriminant Hyper-Laplacian Projection (DHLP). Five popular face databases are adopted for validating our work. The results demonstrate the superiority of DHLP over DLPP, particularly in face recognition in the wild.",
Deduction of fighting-game countermeasures using the k-nearest neighbor algorithm and a game simulator,"This paper proposes an artificial intelligence algorithm that uses the k-nearest neighbor algorithm to predict its opponent's attack action and a game simulator to deduce a countermeasure action for controlling an in-game character in a fighting game. This AI algorithm (AI) aims at achieving good results in the fighting-game AI competition having been organized by our laboratory since 2013. It is also a sample AI, called MizunoAI, publicly available for the 2014 competition at CIG 2014. In fighting games, every action is either advantageous or disadvantageous against another. By predicting its opponent's next action, our AI can devise a countermeasure which is advantageous against that action, leading to higher scores in the game. The effectiveness of the proposed AI is confirmed by the results of matches against the top-three AI entries of the 2013 competition.",
Performance analysis of stochastic behavior trees,"This paper presents a mathematical framework for performance analysis of Behavior Trees (BTs). BTs are a recent alternative to Finite State Machines (FSMs), for doing modular task switching in robot control architectures. By encoding the switching logic in a tree structure, instead of distributing it in the states of a FSM, modularity and reusability are improved. In this paper, we compute performance measures, such as success/failure probabilities and execution times, for plans encoded and executed by BTs. To do this, we first introduce Stochastic Behavior Trees (SBT), where we assume that the probabilistic performance measures of the basic action controllers are given. We then show how Discrete Time Markov Chains (DTMC) can be used to aggregate these measures from one level of the tree to the next. The recursive structure of the tree then enables us to step by step propagate such estimates from the leaves (basic action controllers) to the root (complete task execution). Finally, we verify our analytical results using massive Monte Carlo simulations, and provide an illustrative example of the results for a complex robotic task.","Markov processes,
Robots,
Probabilistic logic,
Transient analysis,
Switches,
Vectors,
Reliability"
CLU: Co-Optimizing Locality and Utility in Thread-Aware Capacity Management for Shared Last Level Caches,"Most chip-multiprocessors nowadays adopt a large shared last-level cache (SLLC). This paper is motivated by our analysis and evaluation of state-of-the-art cache management proposals which reveal a common weakness. That is, the existing alternative replacement policies and cache partitioning schemes, targeted at optimizing either locality or utility of co-scheduled threads, cannot deliver consistently the best performance under a variety of workloads. Therefore, we propose a novel adaptive scheme, called CLU, to interactively co-optimize the locality and utility of co-scheduled threads in thread-aware SLLC capacity management. CLU employs lightweight monitors to dynamically profile the LRU (least recently used) and BIP (bimodal insertion policy) hit curves of individual threads on runtime, enabling the scheme to co-optimize the locality and utility of concurrent threads and thus adapt to more diverse workloads than the existing approaches. We provide results from extensive execution-driven simulation experiments to demonstrate the feasibility and efficacy of CLU over the existing approaches (TADIP, NUCACHE, TA-DRRIP, UCP, and PIPP).",
Detection on application layer DDoS using random walk model,"Application Layer Distributed Denial of Service (ALDDoS) attacks have been increasing rapidly with the growth of Botnets and Ubiquitous computing. Differentiate to the former DDoS attacks, ALDDoS attacks cannot be efficiently detected, as attackers always adopt legitimate requests with real IP address, and the traffic has high similarity to legitimate traffic. In spite of that, we think, the attackers' browsing behavior will have great disparity from that of the legitimate users'. In this paper, we put forward a novel user behavior-based method to detect the application layer asymmetric DDoS attack. We introduce an extended random walk model to describe user browsing behavior and establish the legitimate pattern of browsing sequences. For each incoming browser, we observe his page request sequence and predict subsequent page request sequence based on random walk model. The similarity between the predicted and the observed page request sequence is used as a criterion to measure the legality of the user, and then attacker would be detected based on it. Evaluation results based on real collected data set has demonstrated that our method is very effective in detecting asymmetric ALDDoS attacks.",
A New Entropy Power Inequality for Integer-Valued Random Variables,"The entropy power inequality (EPI) yields lower bounds on the differential entropy of the sum of two independent real-valued random variables in terms of the individual entropies. Versions of the EPI for discrete random variables have been obtained for special families of distributions with the differential entropy replaced by the discrete entropy, but no universal inequality is known (beyond trivial ones). More recently, the sumset theory for the entropy function yields a sharp inequality H(X + X') - H(X) ≥ 1/2 - o(1) when X, X' are independent identically distributed (i.i.d.) with high entropy. This paper provides the inequality H(X + X') - H(X)≥ g(H(X)), where X, X' are arbitrary i.i.d. integer-valued random variables and where g is a universal strictly positive function on R+ satisfying g(0) = 0. Extensions to nonidentically distributed random variables and to conditional entropies are also obtained.","Random variables,
Entropy,
Probability distribution,
Vectors,
Covariance matrices,
Educational institutions,
Electronic mail"
Multi-agent reinforcement learning for traffic signal control,"Optimal control of traffic lights at junctions or traffic signal control (TSC) is essential for reducing the average delay experienced by the road users amidst the rapid increase in the usage of vehicles. In this paper, we formulate the TSC problem as a discounted cost Markov decision process (MDP) and apply multi-agent reinforcement learning (MARL) algorithms to obtain dynamic TSC policies. We model each traffic signal junction as an independent agent. An agent decides the signal duration of its phases in a round-robin (RR) manner using multi-agent Q-learning with either ε-greedy or UCB [3] based exploration strategies. It updates its Q-factors based on the cost feedback signal received from its neighbouring agents. This feedback signal can be easily constructed and is shown to be effective in minimizing the average delay of the vehicles in the network. We show through simulations over VISSIM that our algorithms perform significantly better than both the standard fixed signal timing (FST) algorithm and the saturation balancing (SAT) algorithm [15] over two real road networks.",
Cross Flow Heat Exchanger Modeling of Transient Temperature Input Conditions,"The effectiveness of heat exchangers strongly influences the thermal performance of data center cooling systems. Rear door heat exchangers, in-row and overhead coolers, and fully contained water cooled cabinets are some examples of liquid and hybrid cooling systems used in data centers. Modeling the dynamic behavior of heat exchangers is important for the design of control strategies to improve energy efficiency. In this paper, an existing 2-D model of the transient temperature response of an unmixed-unmixed cross flow heat exchanger, of the type that is widely used in data center cooling equipment, is solved numerically. A detailed analysis of the transient response to a step, ramp, or exponential change in the hot fluid inlet temperature is conducted. The heat capacity rate ratio (E), thermal resistance (R), capacitance ratio (V), and number of transfer units are varied over a wide range to determine their influence on the heat exchanger dynamic thermal performance under different transient input conditions. In addition, the thermal response to the magnitude and time period of the transient input functions are evaluated. The modeling results are used to analyze specific data center cooling scenarios, and provide a means for predicting the transient behavior of heat exchangers used in data center cooling equipment.","Heating,
Mathematical model,
Time factors,
Transient analysis,
Boundary conditions,
Equations,
Capacitance"
A Selective Retraction-Based RRT Planner for Various Environments,"We present a novel randomized path planner for rigid robots to efficiently handle various environments that have different characteristics. We first present a bridge line test that can identify narrow passage regions and then selectively performs an optimization-based retraction only at those regions. We also propose a noncolliding line test, which is a dual operator to the bridge line test, as a culling method to avoid generating samples near wide-open free spaces. These two line tests are performed with a small computational overhead. We have tested our method with different benchmarks that have varying amounts of narrow passages. Our method achieves up to several times improvements over prior RRT-based planners and consistently shows the best performance across all the tested benchmarks.","Bridges,
Robots,
Principal component analysis,
Benchmark testing,
Algorithm design and analysis,
Planning,
Probabilistic logic"
Parallel computing using memristive crossbar networks: Nullifying the processor-memory bottleneck,"We are quickly reaching an impasse to the number of transistors that can be squeezed onto a single chip. This has led to a scramble for new nanotechnologies and the subsequent emergence of new computing architectures capable of exploiting these nano-devices. The memristor is a promising More-than-Moore device because of its unique ability to store and manipulate data on the same device. In this paper, we propose a flexible architecture of memristive crossbar networks for computing Boolean formulas. Our design nullifies the gap between processor and memory in von Neumann architectures by using the crossbar both for the storage of data and for performing Boolean computations. We demonstrate the effectiveness of our approach on practically important computations, including parallel Boolean matrix multiplication.",
Spectrum-Efficient Multi-Channel Design for Coexisting IEEE 802.15.4 Networks: A Stochastic Geometry Approach,"For networks with random topologies (e.g., wireless ad-hoc and sensor networks) and dynamically varying channel gains, choosing the long term operating parameters that optimize the network performance metrics is very challenging. In this paper, we use stochastic geometry analysis to develop a novel framework to design spectrum-efficient multi-channel random wireless networks based on the IEEE 802.15.4 standard. The proposed framework maximizes both spatial and time domain frequency utilization under channel gain uncertainties to minimize the number of frequency channels required to accommodate a certain population of coexisting IEEE 802.15.4 networks. The performance metrics are the outage probability and the self admission failure probability. We relax the single channel assumption that has been used traditionally in the stochastic geometry analysis. We show that the intensity of the admitted networks does not increase linearly with the number of channels and the rate of increase of the intensity of the admitted networks decreases with the number of channels. By using graph theory, we obtain the minimum required number of channels to accommodate a certain intensity of coexisting networks under a self admission failure probability constraint. To this end, we design a superframe structure for the coexisting IEEE 802.15.4 networks and a method for time-domain interference alignment.",
QueueSense: Collaborative recognition of queuing on mobile phones,"Nowadays people spend a substantial amount of time waiting in different places such as supermarkets and amusement parks. Detecting the status of queuing may benefit both users and business. In this paper, we present QueueSense, a queuing recognition system on mobile phones to assist in a queue management system. QueueSense extracts features of queuing behavior and classifies queueing via collaboration among people waiting in line. It measures the disparity of people in different lines using relative position changing rate and partitions different queues using a hierarchical clustering approach. We implement a prototype of QueueSense on Android platforms using widely available multi-modal sensors and it is the first queue detection system on mobile phones. We conduct real-world experiments at a dining hall and a supermarket near a university campus. Through implementation and evaluation, we demonstrate that QueueSense is capable of detecting waiting lines that occur in our daily lives with high accuracy.",
Lossy Cutset Coding of Bilevel Images Based on Markov Random Fields,"An effective, low complexity method for lossy compression of scenic bilevel images, called lossy cutset coding, is proposed based on a Markov random field model. It operates by losslessly encoding pixels in a square grid of lines, which is a cutset with respect to a Markov random field model, and preserves key structural information, such as borders between black and white regions. Relying on the Markov random field model, the decoder takes a MAP approach to reconstructing the interior of each grid block from the pixels on its boundary, thereby creating a piecewise smooth image that is consistent with the encoded grid pixels. The MAP rule, which reduces to finding the block interiors with fewest black-white transitions, is directly implementable for the most commonly occurring block boundaries, thereby avoiding the need for brute force or iterative solutions. Experimental results demonstrate that the new method is computationally simple, outperforms the current lossy compression technique most suited to scenic bilevel images, and provides substantially lower rates than lossless techniques, e.g., JBIG, with little loss in perceived image quality.",
"A Non-Contact Waveguide Probe for On-Wafer S
-Parameter Measurements for Submillimeter-Wave to Terahertz Band","This paper presents a non-contact on-wafer S- parameter measurement method for submillimeter-wave and terahertz frequency range. The proposed method is based on using open-ended waveguide probes along with on-wafer waveguide transitions to measure the S-parameters of waveguide based components and devices. To enable non-contact measurements, an RF choke is designed and machined on the metallic cross section of the probes using electric discharge machining. Additionally, to enhance the accuracy and repeatability of the measurements, a probe aligner is micromachined over the on-wafer transition. In order to validate the measurement concept, a full-band transition operating at J-band (220-325 GHz) is designed and tested. To achieve high accuracy, the fabrication of the on-wafer waveguide and the transition is performed using silicon micromachining. It is shown that the designed back-to-back transition has a return loss of better than 15 dB and an insertion loss of less than 0.2 dB over the entire frequency band. The measurement results of the fabricated transition also show a good agreement with the simulated results.","Probes,
Waveguide transitions,
Inductors,
Waveguide components,
Silicon,
Rectangular waveguides"
