Title,Abstract,Keywords
A Secure and Dynamic Multi-Keyword Ranked Search Scheme over Encrypted Cloud Data,"Due to the increasing popularity of cloud computing, more and more data owners are motivated to outsource their data to cloud servers for great convenience and reduced cost in data management. However, sensitive data should be encrypted before outsourcing for privacy requirements, which obsoletes data utilization like keyword-based document retrieval. In this paper, we present a secure multi-keyword ranked search scheme over encrypted cloud data, which simultaneously supports dynamic update operations like deletion and insertion of documents. Specifically, the vector space model and the widely-used TF x IDF model are combined in the index construction and query generation. We construct a special tree-based index structure and propose a “Greedy Depth-first Search” algorithm to provide efficient multi-keyword ranked search. The secure kNN algorithm is utilized to encrypt the index and query vectors, and meanwhile ensure accurate relevance score calculation between encrypted index and query vectors. In order to resist statistical attacks, phantom terms are added to the index vector for blinding search results. Due to the use of our special tree-based index structure, the proposed scheme can achieve sub-linear search time and deal with the deletion and insertion of documents flexibly. Extensive experiments are conducted to demonstrate the efficiency of the proposed scheme.",
Enabling Personalized Search over Encrypted Outsourced Data with Efficiency Improvement,"In cloud computing, searchable encryption scheme over outsourced data is a hot research field. However, most existing works on encrypted search over outsourced cloud data follow the model of “one size fits all” and ignore personalized search intention. Moreover, most of them support only exact keyword search, which greatly affects data usability and user experience. So how to design a searchable encryption scheme that supports personalized search and improves user search experience remains a very challenging task. In this paper, for the first time, we study and solve the problem of personalized multi-keyword ranked search over encrypted data (PRSE) while preserving privacy in cloud computing. With the help of semantic ontology WordNet, we build a user interest model for individual user by analyzing the user's search history, and adopt a scoring mechanism to express user interest smartly. To address the limitations of the model of “one size fit all” and keyword exact search, we propose two PRSE schemes for different search intentions. Extensive experiments on real-world dataset validate our analysis and show that our proposed solution is very efficient and effective.",
A Privacy-Preserving and Copy-Deterrence Content-Based Image Retrieval Scheme in Cloud Computing,"With the increasing importance of images in people's daily life, content-based image retrieval (CBIR) has been widely studied. Compared with text documents, images consume much more storage space. Hence, its maintenance is considered to be a typical example for cloud storage outsourcing. For privacy-preserving purposes, sensitive images, such as medical and personal images, need to be encrypted before outsourcing, which makes the CBIR technologies in plaintext domain to be unusable. In this paper, we propose a scheme that supports CBIR over encrypted images without leaking the sensitive information to the cloud server. First, feature vectors are extracted to represent the corresponding images. After that, the pre-filter tables are constructed by locality-sensitive hashing to increase search efficiency. Moreover, the feature vectors are protected by the secure kNN algorithm, and image pixels are encrypted by a standard stream cipher. In addition, considering the case that the authorized query users may illegally copy and distribute the retrieved images to someone unauthorized, we propose a watermark-based protocol to deter such illegal distributions. In our watermark-based protocol, a unique watermark is directly embedded into the encrypted images by the cloud server before images are sent to the query user. Hence, when image copy is found, the unlawful query user who distributed the image can be traced by the watermark extraction. The security analysis and the experiments show the security and efficiency of the proposed scheme.","Watermarking,
Servers,
Encryption,
Cloud computing,
Outsourcing"
Toward Efficient Multi-Keyword Fuzzy Search Over Encrypted Outsourced Data With Accuracy Improvement,"Keyword-based search over encrypted outsourced data has become an important tool in the current cloud computing scenario. The majority of the existing techniques are focusing on multi-keyword exact match or single keyword fuzzy search. However, those existing techniques find less practical significance in real-world applications compared with the multi-keyword fuzzy search technique over encrypted data. The first attempt to construct such a multi-keyword fuzzy search scheme was reported by Wang et al., who used locality-sensitive hashing functions and Bloom filtering to meet the goal of multi-keyword fuzzy search. Nevertheless, Wang's scheme was only effective for a one letter mistake in keyword but was not effective for other common spelling mistakes. Moreover, Wang's scheme was vulnerable to server out-of-order problems during the ranking process and did not consider the keyword weight. In this paper, based on Wang et al.'s scheme, we propose an efficient multi-keyword fuzzy ranked search scheme based on Wang et al.'s scheme that is able to address the aforementioned problems. First, we develop a new method of keyword transformation based on the uni-gram, which will simultaneously improve the accuracy and creates the ability to handle other spelling mistakes. In addition, keywords with the same root can be queried using the stemming algorithm. Furthermore, we consider the keyword weight when selecting an adequate matching file set. Experiments using real-world data show that our scheme is practically efficient and achieve high accuracy.",
"Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning","Remarkable progress has been made in image recognition, primarily due to the availability of large-scale annotated datasets and deep convolutional neural networks (CNNs). CNNs enable learning data-driven, highly representative, hierarchical image features from sufficient training data. However, obtaining datasets as comprehensively annotated as ImageNet in the medical imaging domain remains a challenge. There are currently three major techniques that successfully employ CNNs to medical image classification: training the CNN from scratch, using off-the-shelf pre-trained CNN features, and conducting unsupervised CNN pre-training with supervised fine-tuning. Another effective method is transfer learning, i.e., fine-tuning CNN models pre-trained from natural image dataset to medical image tasks. In this paper, we exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems. We first explore and evaluate different CNN architectures. The studied models contain 5 thousand to 160 million parameters, and vary in numbers of layers. We then evaluate the influence of dataset scale and spatial image context on performance. Finally, we examine when and why transfer learning from pre-trained ImageNet (via fine-tuning) can be useful. We study two specific computer-aided detection (CADe) problems, namely thoraco-abdominal lymph node (LN) detection and interstitial lung disease (ILD) classification. We achieve the state-of-the-art performance on the mediastinal LN detection, and report the first five-fold cross-validation classification results on predicting axial CT slices with ILD categories. Our extensive empirical evaluation, CNN model analysis and valuable insights can be extended to the design of high performance CAD systems for other medical imaging tasks.",
An Overview of Signal Processing Techniques for Millimeter Wave MIMO Systems,"Communication at millimeter wave (mmWave) frequencies is defining a new era of wireless communication. The mmWave band offers higher bandwidth communication channels versus those presently used in commercial wireless systems. The applications of mmWave are immense: wireless local and personal area networks in the unlicensed band, 5G cellular systems, not to mention vehicular area networks, ad hoc networks, and wearables. Signal processing is critical for enabling the next generation of mmWave communication. Due to the use of large antenna arrays at the transmitter and receiver, combined with radio frequency and mixed signal power constraints, new multiple-input multiple-output (MIMO) communication signal processing techniques are needed. Because of the wide bandwidths, low complexity transceiver algorithms become important. There are opportunities to exploit techniques like compressed sensing for channel estimation and beamforming. This article provides an overview of signal processing challenges in mmWave wireless systems, with an emphasis on those faced by using MIMO communication at higher carrier frequencies.","MIMO,
Wireless communication,
Array signal processing,
Millimeter wave communication,
Signal processing algorithms"
Region-Based Convolutional Networks for Accurate Object Detection and Segmentation,"Object detection performance, as measured on the canonical PASCAL VOC Challenge datasets, plateaued in the final years of the competition. The best-performing methods were complex ensemble systems that typically combined multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 50 percent relative to the previous best result on VOC 2012-achieving a mAP of 62.4 percent. Our approach combines two ideas: (1) one can apply high-capacity convolutional networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data are scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, boosts performance significantly. Since we combine region proposals with CNNs, we call the resulting model an R-CNN or Region-based Convolutional Network. Source code for the complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.",
5G Ultra-Dense Cellular Networks,"Traditional ultra-dense wireless networks are recommended as a complement for cellular networks and are deployed in partial areas, such as hotspot and indoor scenarios. Based on the massive multiple-input multi-output antennas and the millimeter wave communication technologies, the 5G ultra-dense cellular network is proposed to deploy in overall cellular scenarios. Moreover, a distribution network architecture is presented for 5G ultra-dense cellular networks. Furthermore, the backhaul network capacity and the backhaul energy efficiency of ultra-dense cellular networks are investigated to answer an important question, that is, how much densification can be deployed for 5G ultra-dense cellular networks. Simulation results reveal that there exist densification limits for 5G ultra-dense cellular networks with backhaul network capacity and backhaul energy efficiency constraints.",
Extreme Learning Machine for Multilayer Perceptron,"Extreme learning machine (ELM) is an emerging learning algorithm for the generalized single hidden layer feedforward neural networks, of which the hidden node parameters are randomly generated and the output weights are analytically computed. However, due to its shallow architecture, feature learning using ELM may not be effective for natural signals (e.g., images/videos), even with a large number of hidden nodes. To address this issue, in this paper, a new ELM-based hierarchical learning framework is proposed for multilayer perceptron. The proposed architecture is divided into two main components: 1) self-taught feature extraction followed by supervised feature classification and 2) they are bridged by random initialized hidden weights. The novelties of this paper are as follows: 1) unsupervised multilayer encoding is conducted for feature extraction, and an ELM-based sparse autoencoder is developed via ℓ1 constraint. By doing so, it achieves more compact and meaningful feature representations than the original ELM; 2) by exploiting the advantages of ELM random feature mapping, the hierarchically encoded outputs are randomly projected before final decision making, which leads to a better generalization with faster learning speed; and 3) unlike the greedy layerwise training of deep learning (DL), the hidden layers of the proposed framework are trained in a forward manner. Once the previous layer is established, the weights of the current layer are fixed without fine-tuning. Therefore, it has much better learning efficiency than the DL. Extensive experiments on various widely used classification data sets show that the proposed algorithm achieves better and faster convergence than the existing state-of-the-art hierarchical learning methods. Furthermore, multiple applications in computer vision further confirm the generality and capability of the proposed learning scheme.","Feature extraction,
Training,
Nonhomogeneous media,
Optimization,
Least squares approximations,
Artificial neural networks"
Optimal DoS Attack Scheduling in Wireless Networked Control System,"Recently, many literature works have considered the security issues of wireless networked control system (WNCS). However, few works studied how the attacker should optimize its attack schedule in order to maximize the effect on the system performance due to the insufficiency of energy at the attacker side. This paper fills this gap from the aspect of control system performance. We consider the optimal jamming attack that maximizes the Linear Quadratic Gaussian (LQG) control cost function under energy constraint. After analyzing the properties of the cost function under an arbitrary attack schedule, we derive the optimal jamming attack schedule and the corresponding cost function. System stability under this optimal attack schedule is also considered. We further investigate the optimal attack schedule in a WNCS with multiple subsystems. Different examples are provided to demonstrate the effectiveness of the proposed optimal denial-of-service attack schedule.",
Next Generation 5G Wireless Networks: A Comprehensive Survey,"The vision of next generation 5G wireless communications lies in providing very high data rates (typically of Gbps order), extremely low latency, manifold increase in base station capacity, and significant improvement in users' perceived quality of service (QoS), compared to current 4G LTE networks. Ever increasing proliferation of smart devices, introduction of new emerging multimedia applications, together with an exponential rise in wireless data (multimedia) demand and usage is already creating a significant burden on existing cellular networks. 5G wireless systems, with improved data rates, capacity, latency, and QoS are expected to be the panacea of most of the current cellular networks' problems. In this survey, we make an exhaustive review of wireless evolution toward 5G networks. We first discuss the new architectural changes associated with the radio access network (RAN) design, including air interfaces, smart antennas, cloud and heterogeneous RAN. Subsequently, we make an in-depth survey of underlying novel mm-wave physical layer technologies, encompassing new channel model estimation, directional antenna design, beamforming algorithms, and massive MIMO technologies. Next, the details of MAC layer protocols and multiplexing schemes needed to efficiently support this new physical layer are discussed. We also look into the killer applications, considered as the major driving force behind 5G. In order to understand the improved user experience, we provide highlights of new QoS, QoE, and SON features associated with the 5G evolution. For alleviating the increased network energy consumption and operating expenditure, we make a detail review on energy awareness and cost efficiency. As understanding the current status of 5G implementation is important for its eventual commercialization, we also discuss relevant field trials, drive tests, and simulation experiments. Finally, we point out major existing research issues and identify possible future research directions.","5G mobile communication,
Wireless communication,
Computer architecture,
Microprocessors,
MIMO,
Streaming media"
Data Gathering Optimization by Dynamic Sensing and Routing in Rechargeable Sensor Networks,"In rechargeable sensor networks (RSNs), energy harvested by sensors should be carefully allocated for data sensing and data transmission to optimize data gathering due to time-varying renewable energy arrival and limited battery capacity. Moreover, the dynamic feature of network topology should be taken into account, since it can affect the data transmission. In this paper, we strive to optimize data gathering in terms of network utility by jointly considering data sensing and data transmission. To this end, we design a data gathering optimization algorithm for dynamic sensing and routing (DoSR), which consists of two parts. In the first part, we design a balanced energy allocation scheme (BEAS) for each sensor to manage its energy use, which is proven to meet four requirements raised by practical scenarios. Then in the second part, we propose a distributed sensing rate and routing control (DSR2C) algorithm to jointly optimize data sensing and data transmission, while guaranteeing network fairness. In DSR2C, each sensor can adaptively adjust its transmit energy consumption during network operation according to the amount of available energy, and select the optimal sensing rate and routing, which can efficiently improve data gathering. Furthermore, since recomputing the optimal data sensing and routing strategies upon change of energy allocation will bring huge communications for information exchange and computation, we propose an improved BEAS to manage the energy allocation in the dynamic environments and a topology control scheme to reduce computational complexity. Extensive simulations are performed to demonstrate the efficiency of the proposed algorithms in comparison with existing algorithms.","Resource management,
Sensors,
Routing,
Data communication,
Heuristic algorithms,
Algorithm design and analysis,
Batteries"
Spatial Reusability-Aware Routing in Multi-Hop Wireless Networks,"In the problem of routing in multi-hop wireless networks, to achieve high end-to-end throughput, it is crucial to find the “best” path from the source node to the destination node. Although a large number of routing protocols have been proposed to find the path with minimum total transmission count/time for delivering a single packet, such transmission count/time minimizing protocols cannot be guaranteed to achieve maximum end-to-end throughput. In this paper, we argue that by carefully considering spatial reusability of the wireless communication media, we can tremendously improve the end-to-end throughput in multi-hop wireless networks. To support our argument, we propose spatial reusability-aware single-path routing (SASR) and anypath routing (SAAR) protocols, and compare them with existing single-path routing and anypath routing protocols, respectively. Our evaluation results show that our protocols significantly improve the end-to-end throughput compared with existing protocols. Specifically, for single-path routing, the median throughput gain is up to 60 percent, and for each source-destination pair, the throughput gain is as high as 5.3x; for anypath routing, the maximum per-flow throughput gain is 71.6 percent, while the median gain is up to 13.2 percent.","Routing,
Routing protocols,
Throughput,
Measurement,
Media,
Wireless networks"
The Application of MIMO to Non-Orthogonal Multiple Access,"This paper considers the application of multiple-input multiple-output (MIMO) techniques to nonorthogonal multiple access (NOMA) systems. A new design of precoding and detection matrices for MIMO-NOMA is proposed and its performance is analyzed for the case with a fixed set of power allocation coefficients. To further improve the performance gap between MIMO-NOMA and conventional orthogonal multiple access schemes, user pairing is applied to NOMA and its impact on the system performance is characterized. More sophisticated choices of power allocation coefficients are also proposed to meet various quality-of-service requirements. Finally, computer simulation results are provided to facilitate the performance evaluation of MIMO-NOMA and also demonstrate the accuracy of the developed analytical results.","Signal to noise ratio,
Interference,
Resource management,
Base stations,
Antennas,
Silicon carbide,
Wireless communication"
Cooperative Non-orthogonal Multiple Access With Simultaneous Wireless Information and Power Transfer,"In this paper, the application of simultaneous wireless information and power transfer (SWIPT) to nonorthogonal multiple access (NOMA) networks in which users are spatially randomly located is investigated. A new co-operative SWIPT NOMA protocol is proposed, in which near NOMA users that are close to the source act as energy harvesting relays to help far NOMA users. Since the locations of users have a significant impact on the performance, three user selection schemes based on the user distances from the base station are proposed. To characterize the performance of the proposed selection schemes, closed-form expressions for the outage probability and system throughput are derived. These analytical results demonstrate that the use of SWIPT will not jeopardize the diversity gain compared to the conventional NOMA. The proposed results confirm that the opportunistic use of node locations for user selection can achieve low outage probability and deliver superior throughput in comparison to the random selection scheme.",
Convolutional Neural Networks for Medical Image Analysis: Full Training or Fine Tuning?,"Training a deep convolutional neural network (CNN) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence. A promising alternative is to fine-tune a CNN that has been pre-trained using, for instance, a large set of labeled natural images. However, the substantial differences between natural and medical images may advise against such knowledge transfer. In this paper, we seek to answer the following central question in the context of medical image analysis: Can the use of pre-trained deep CNNs with sufficient fine-tuning eliminate the need for training a deep CNN from scratch? To address this question, we considered four distinct medical imaging applications in three specialties (radiology, cardiology, and gastroenterology) involving classification, detection, and segmentation from three different imaging modalities, and investigated how the performance of deep CNNs trained from scratch compared with the pre-trained CNNs fine-tuned in a layer-wise manner. Our experiments consistently demonstrated that 1) the use of a pre-trained CNN with adequate fine-tuning outperformed or, in the worst case, performed as well as a CNN trained from scratch; 2) fine-tuned CNNs were more robust to the size of training sets than CNNs trained from scratch; 3) neither shallow tuning nor deep tuning was the optimal choice for a particular application; and 4) our layer-wise fine-tuning scheme could offer a practical way to reach the best performance for the application at hand based on the amount of available data.","Biomedical imaging,
Training,
Feature extraction,
Image segmentation,
Computed tomography,
Image analysis,
Tuning"
"A Survey on Wireless Security: Technical Challenges, Recent Advances, and Future Trends","Due to the broadcast nature of radio propagation, the wireless air interface is open and accessible to both authorized and illegitimate users. This completely differs from a wired network, where communicating devices are physically connected through cables and a node without direct association is unable to access the network for illicit activities. The open communications environment makes wireless transmissions more vulnerable than wired communications to malicious attacks, including both the passive eavesdropping for data interception and the active jamming for disrupting legitimate transmissions. Therefore, this paper is motivated to examine the security vulnerabilities and threats imposed by the inherent open nature of wireless communications and to devise efficient defense mechanisms for improving the wireless network security. We first summarize the security requirements of wireless networks, including their authenticity, confidentiality, integrity, and availability issues. Next, a comprehensive overview of security attacks encountered in wireless networks is presented in view of the network protocol architecture, where the potential security threats are discussed at each protocol layer. We also provide a survey of the existing security protocols and algorithms that are adopted in the existing wireless network standards, such as the Bluetooth, Wi-Fi, WiMAX, and the long-term evolution (LTE) systems. Then, we discuss the state of the art in physical-layer security, which is an emerging technique of securing the open communications environment against eavesdropping attacks at the physical layer. Several physical-layer security techniques are reviewed and compared, including information-theoretic security, artificial-noise-aided security, security-oriented beamforming, diversity-assisted security, and physical-layer key generation approaches. Since a jammer emitting radio signals can readily interfere with the legitimate wireless users, we also introduce the family of various jamming attacks and their countermeasures, including the constant jammer, intermittent jammer, reactive jammer, adaptive jammer, and intelligent jammer. Additionally, we discuss the integration of physical-layer security into existing authentication and cryptography mechanisms for further securing wireless networks. Finally, some technical challenges which remain unresolved at the time of writing are summarized and the future trends in wireless security are discussed.",
Fast Motion Estimation Based on Content Property for Low-Complexity H.265/HEVC Encoder,"The high definition (HD) and ultra HD videos can be widely applied in broadcasting applications. However, with the increased resolution of video, the volume of the raw HD visual information data increases significantly, which becomes a challenge for storage, processing, and transmitting the HD visual data. The state-of-the-art video compression standard-H.265/High Efficiency Video Coding (HEVC) compresses the raw HD visual data efficiently, while the high compression rate comes at the cost of heavy computation load. Hence, reducing the encoding complexity becomes vital for the H.265/HEVC encoder to be used in broadcasting applications. In this paper, based on the best motion vector selection correlation among the different size prediction modes, we propose a fast motion estimation (ME) method to reduce the encoding complexity of the H.265/HEVC encoder. First, according to the prediction unit (PU) partition type, all PUs are classified into two classes, parent PU and children PUs, respectively. Then, based on the best motion vector selection correlation between the parent PU and children PUs, the block matching search process of the children PUs is adaptively skipped if their parent PU chooses the initial search point as its final optimal motion vector in the ME process. Experimental results show that the proposed method achieves an average of 20% ME time saving as compared with the original HM-TZSearch. Meanwhile, the rate distortion performance degradation is negligible.","Encoding,
High definition video,
Computational complexity,
Video coding,
Visualization,
Correlation"
User Association in 5G Networks: A Survey and an Outlook,"The fifth generation (5G) mobile networks are envisioned to support the deluge of data traffic with reduced energy consumption and improved quality of service (QoS) provision. To this end, key enabling technologies, such as heterogeneous networks (HetNets), massive multiple-input multiple-output (MIMO), and millimeter wave (mmWave) techniques, have been identified to bring 5G to fruition. Regardless of the technology adopted, a user association mechanism is needed to determine whether a user is associated with a particular base station (BS) before data transmission commences. User association plays a pivotal role in enhancing the load balancing, the spectrum efficiency, and the energy efficiency of networks. The emerging 5G networks introduce numerous challenges and opportunities for the design of sophisticated user association mechanisms. Hence, substantial research efforts are dedicated to the issues of user association in HetNets, massive MIMO networks, mmWave networks, and energy harvesting networks. We introduce a taxonomy as a framework for systematically studying the existing user association algorithms. Based on the proposed taxonomy, we then proceed to present an extensive overview of the state-of-the-art in user association algorithms conceived for HetNets, massive MIMO, mmWave, and energy harvesting networks. Finally, we summarize the challenges as well as opportunities of user association in 5G and provide design guidelines and potential solutions for sophisticated user association mechanisms.","5G mobile communication,
MIMO,
Energy harvesting,
Wireless communication,
Communication system security,
Resource management,
Quality of service"
Middleware for Internet of Things: A Survey,"The Internet of Things (IoT) envisages a future in which digital and physical things or objects (e.g., smartphones, TVs, cars) can be connected by means of suitable information and communication technologies, to enable a range of applications and services. The IoT's characteristics, including an ultra-large-scale network of things, device and network level heterogeneity, and large numbers of events generated spontaneously by these things, will make development of the diverse applications and services a very challenging task. In general, middleware can ease a development process by integrating heterogeneous computing and communications devices, and supporting interoperability within the diverse applications and services. Recently, there have been a number of proposals for IoT middleware. These proposals mostly addressed wireless sensor networks (WSNs), a key component of IoT, but do not consider RF identification (RFID), machine-to-machine (M2M) communications, and supervisory control and data acquisition (SCADA), other three core elements in the IoT vision. In this paper, we outline a set of requirements for IoT middleware, and present a comprehensive review of the existing middleware solutions against those requirements. In addition, open research issues, challenges, and future research directions are highlighted.","Middleware,
Wireless sensor networks,
Internet of things,
Security,
Real-time systems,
Radiofrequency identification"
"Software-Defined Networking (SDN) and Distributed Denial of Service (DDoS) Attacks in Cloud Computing Environments: A Survey, Some Research Issues, and Challenges","Distributed Denial of Service (DDoS) attacks in cloud computing environments are growing due to the essential characteristics of cloud computing. With recent advances in software-defined networking (SDN), SDN-based cloud brings us new chances to defeat DDoS attacks in cloud computing environments. Nevertheless, there is a contradictory relationship between SDN and DDoS attacks. On one hand, the capabilities of SDN, including software-based traffic analysis, centralized control, global view of the network, dynamic updating of forwarding rules, make it easier to detect and react to DDoS attacks. On the other hand, the security of SDN itself remains to be addressed, and potential DDoS vulnerabilities exist across SDN platforms. In this paper, we discuss the new trends and characteristics of DDoS attacks in cloud computing, and provide a comprehensive survey of defense mechanisms against DDoS attacks using SDN. In addition, we review the studies about launching DDoS attacks on SDN, as well as the methods against DDoS attacks in SDN. To the best of our knowledge, the contradictory relationship between SDN and DDoS attacks has not been well addressed in previous works. This work can help to understand how to make full use of SDN's advantages to defeat DDoS attacks in cloud computing environments and how to prevent SDN itself from becoming a victim of DDoS attacks, which are important for the smooth evolution of SDN-based cloud without the distraction of DDoS attacks.",
Adaptive Sliding Mode Control for Interval Type-2 Fuzzy Systems,"This paper is concerned with the adaptive sliding mode control problem of uncertain nonlinear systems. Interval type-2 Takagi-Sugeno (T-S) fuzzy model is employed to represent uncertain nonlinear systems. The input matrices of the nonlinear systems are allowed to be different for the sliding mode controller design. The uncertain parameters are described by the lower and upper membership functions. An integral sliding mode surface is designed for analysis of sliding motion. Based on the sliding mode surface, a novel sliding mode controller is designed to guarantee that the closed-loop system is uniformly ultimately bounded. Some simulation results are given to illustrate the effectiveness of the presented control scheme.","Fuzzy systems,
Nonlinear systems,
Adaptive systems,
Uncertainty,
Adaptation models,
Sliding mode control,
Closed loop systems"
Salient Band Selection for Hyperspectral Image Classification via Manifold Ranking,"Saliency detection has been a hot topic in recent years, and many efforts have been devoted in this area. Unfortunately, the results of saliency detection can hardly be utilized in general applications. The primary reason, we think, is unspecific definition of salient objects, which makes that the previously published methods cannot extend to practical applications. To solve this problem, we claim that saliency should be defined in a context and the salient band selection in hyperspectral image (HSI) is introduced as an example. Unfortunately, the traditional salient band selection methods suffer from the problem of inappropriate measurement of band difference. To tackle this problem, we propose to eliminate the drawbacks of traditional salient band selection methods by manifold ranking. It puts the band vectors in the more accurate manifold space and treats the saliency problem from a novel ranking perspective, which is considered to be the main contributions of this paper. To justify the effectiveness of the proposed method, experiments are conducted on three HSIs, and our method is compared with the six existing competitors. Results show that the proposed method is very effective and can achieve the best performance among the competitors.","Hyperspectral imaging,
Manifolds,
Feature extraction,
Adaptation models,
Machine learning,
Transforms,
Computer vision"
Block-Row Sparse Multiview Multilabel Learning for Image Classification,"In image analysis, the images are often represented by multiple visual features (also known as multiview features), that aim to better interpret them for achieving remarkable performance of the learning. Since the processes of feature extraction on each view are separated, the multiple visual features of images may include overlap, noise, and redundancy. Thus, learning with all the derived views of the data could decrease the effectiveness. To address this, this paper simultaneously conducts a hierarchical feature selection and a multiview multilabel (MVML) learning for multiview image classification, via embedding a proposed a new block-row regularizer into the MVML framework. The block-row regularizer concatenating a Frobenius norm (F-norm) regularizer and an l2,1-norm regularizer is designed to conduct a hierarchical feature selection, in which the F-norm regularizer is used to conduct a high-level feature selection for selecting the informative views (i.e., discarding the uninformative views) and the 12,1-norm regularizer is then used to conduct a low-level feature selection on the informative views. The rationale of the use of a block-row regularizer is to avoid the issue of the over-fitting (via the block-row regularizer), to remove redundant views and to preserve the natural group structures of data (via the F-norm regularizer), and to remove noisy features (the 12,1-norm regularizer), respectively. We further devise a computationally efficient algorithm to optimize the derived objective function and also theoretically prove the convergence of the proposed optimization method. Finally, the results on real image datasets show that the proposed method outperforms two baseline algorithms and three state-of-the-art algorithms in terms of classification performance.","Joints,
Learning systems,
Visualization,
Noise measurement,
Linear programming,
Transforms,
Optimization"
Hybrid Digital and Analog Beamforming Design for Large-Scale Antenna Arrays,"The potential of using of millimeter wave (mmWave) frequency for future wireless cellular communication systems has motivated the study of large-scale antenna arrays for achieving highly directional beamforming. However, the conventional fully digital beamforming methods which require one radio frequency (RF) chain per antenna element is not viable for large-scale antenna arrays due to the high cost and high power consumption of RF chain components in high frequencies. To address the challenge of this hardware limitation, this paper considers a hybrid beamforming architecture in which the overall beamformer consists of a low-dimensional digital beamformer followed by an RF beamformer implemented using analog phase shifters. Our aim is to show that such an architecture can approach the performance of a fully digital scheme with much fewer number of RF chains. Specifically, this paper establishes that if the number of RF chains is twice the total number of data streams, the hybrid beamforming structure can realize any fully digital beamformer exactly, regardless of the number of antenna elements. For cases with fewer number of RF chains, this paper further considers the hybrid beamforming design problem for both the transmission scenario of a point-to-point multiple-input multiple-output (MIMO) system and a downlink multi-user multiple-input single-output (MU-MISO) system. For each scenario, we propose a heuristic hybrid beamforming design that achieves a performance close to the performance of the fully digital beamforming baseline. Finally, the proposed algorithms are modified for the more practical setting in which only finite resolution phase shifters are available. Numerical simulations show that the proposed schemes are effective even when phase shifters with very low resolution are used.","Array signal processing,
Radio frequency,
Antenna arrays,
MIMO,
Phase shifters,
Signal processing algorithms"
A Historical Account of Types of Fuzzy Sets and Their Relationships,"In this paper, we review the definition and basic properties of the different types of fuzzy sets that have appeared up to now in the literature. We also analyze the relationships between them and enumerate some of the applications in which they have been used.",
Learning Rotation-Invariant Convolutional Neural Networks for Object Detection in VHR Optical Remote Sensing Images,"Object detection in very high resolution optical remote sensing images is a fundamental problem faced for remote sensing image analysis. Due to the advances of powerful feature representations, machine-learning-based object detection is receiving increasing attention. Although numerous feature representations exist, most of them are handcrafted or shallow-learning-based features. As the object detection task becomes more challenging, their description capability becomes limited or even impoverished. More recently, deep learning algorithms, especially convolutional neural networks (CNNs), have shown their much stronger feature representation power in computer vision. Despite the progress made in nature scene images, it is problematic to directly use the CNN feature for object detection in optical remote sensing images because it is difficult to effectively deal with the problem of object rotation variations. To address this problem, this paper proposes a novel and effective approach to learn a rotation-invariant CNN (RICNN) model for advancing the performance of object detection, which is achieved by introducing and learning a new rotation-invariant layer on the basis of the existing CNN architectures. However, different from the training of traditional CNN models that only optimizes the multinomial logistic regression objective, our RICNN model is trained by optimizing a new objective function via imposing a regularization constraint, which explicitly enforces the feature representations of the training samples before and after rotating to be mapped close to each other, hence achieving rotation invariance. To facilitate training, we first train the rotation-invariant layer and then domain-specifically fine-tune the whole RICNN network to further boost the performance. Comprehensive evaluations on a publicly available ten-class object detection data set demonstrate the effectiveness of the proposed method.","Object detection,
Feature extraction,
Training,
Remote sensing,
Optical imaging,
Optical sensors,
Computer architecture"
Efficient Multi-User Computation Offloading for Mobile-Edge Cloud Computing,"Mobile-edge cloud computing is a new paradigm to provide cloud computing capabilities at the edge of pervasive radio access networks in close proximity to mobile users. In this paper, we first study the multi-user computation offloading problem for mobile-edge cloud computing in a multi-channel wireless interference environment. We show that it is NP-hard to compute a centralized optimal solution, and hence adopt a game theoretic approach for achieving efficient computation offloading in a distributed manner. We formulate the distributed computation offloading decision making problem among mobile device users as a multi-user computation offloading game. We analyze the structural property of the game and show that the game admits a Nash equilibrium and possesses the finite improvement property. We then design a distributed computation offloading algorithm that can achieve a Nash equilibrium, derive the upper bound of the convergence time, and quantify its efficiency ratio over the centralized optimal solutions in terms of two important performance metrics. We further extend our study to the scenario of multi-user computation offloading in the multi-channel wireless contention environment. Numerical results corroborate that the proposed algorithm can achieve superior computation offloading performance and scale well as the user size increases.","Cloud computing,
Mobile handsets,
Wireless communication,
Mobile communication,
Games,
Computational modeling,
Decision making"
Observer-Based Adaptive Backstepping Consensus Tracking Control for High-Order Nonlinear Semi-Strict-Feedback Multiagent Systems,"Combined with backstepping techniques, an observer-based adaptive consensus tracking control strategy is developed for a class of high-order nonlinear multiagent systems, of which each follower agent is modeled in a semi-strict-feedback form. By constructing the neural network-based state observer for each follower, the proposed consensus control method solves the unmeasurable state problem of high-order nonlinear multiagent systems. The control algorithm can guarantee that all signals of the multiagent system are semi-globally uniformly ultimately bounded and all outputs can synchronously track a reference signal to a desired accuracy. A simulation example is carried out to further demonstrate the effectiveness of the proposed consensus control method.",
Multi-Directional Multi-Level Dual-Cross Patterns for Robust Face Recognition,"To perform unconstrained face recognition robust to variations in illumination, pose and expression, this paper presents a new scheme to extract “Multi-Directional Multi-Level Dual-Cross Patterns” (MDML-DCPs) from face images. Specifically, the MDML-DCPs scheme exploits the first derivative of Gaussian operator to reduce the impact of differences in illumination and then computes the DCP feature at both the holistic and component levels. DCP is a novel face image descriptor inspired by the unique textural structure of human faces. It is computationally efficient and only doubles the cost of computing local binary patterns, yet is extremely robust to pose and expression variations. MDML-DCPs comprehensively yet efficiently encodes the invariant characteristics of a face image from multiple levels into patterns that are highly discriminative of inter-personal differences but robust to intra-personal variations. Experimental results on the FERET, CAS-PERL-R1, FRGC 2.0, and LFW databases indicate that DCP outperforms the state-of-the-art local descriptors (e.g., LBP, LTP, LPQ, POEM, tLBP, and LGXP) for both face identification and face verification tasks. More impressively, the best performance is achieved on the challenging LFW and FRGC 2.0 databases by deploying MDML-DCPs in a simple recognition scheme.","Face,
Face recognition,
Facial features,
Robustness,
Feature extraction,
Lighting,
Histograms"
Enabling Fine-Grained Multi-Keyword Search Supporting Classified Sub-Dictionaries over Encrypted Cloud Data,"Using cloud computing, individuals can store their data on remote servers and allow data access to public users through the cloud servers. As the outsourced data are likely to contain sensitive privacy information, they are typically encrypted before uploaded to the cloud. This, however, significantly limits the usability of outsourced data due to the difficulty of searching over the encrypted data. In this paper, we address this issue by developing the fine-grained multi-keyword search schemes over encrypted cloud data. Our original contributions are three-fold. First, we introduce the relevance scores and preference factors upon keywords which enable the precise keyword search and personalized user experience. Second, we develop a practical and very efficient multi-keyword search scheme. The proposed scheme can support complicated logic search the mixed “AND”, “OR” and “NO” operations of keywords. Third, we further employ the classified sub-dictionaries technique to achieve better efficiency on index building, trapdoor generating and query. Lastly, we analyze the security of the proposed schemes in terms of confidentiality of documents, privacy protection of index and trapdoor, and unlinkability of trapdoor. Through extensive experiments using the real-world dataset, we validate the performance of the proposed schemes. Both the security analysis and experimental results demonstrate that the proposed schemes can achieve the same security level comparing to the existing ones and better performance in terms of functionality, query complexity and efficiency.",
"Wireless Charging Technologies: Fundamentals, Standards, and Network Applications","Wireless charging is a technology of transmitting power through an air gap to electrical devices for the purpose of energy replenishment. The recent progress in wireless charging techniques and development of commercial products have provided a promising alternative way to address the energy bottleneck of conventionally portable battery-powered devices. However, the incorporation of wireless charging into the existing wireless communication systems also brings along a series of challenging issues with regard to implementation, scheduling, and power management. In this paper, we present a comprehensive overview of wireless charging techniques, the developments in technical standards, and their recent advances in network applications. In particular, with regard to network applications, we review the static charger scheduling strategies, mobile charger dispatch strategies and wireless charger deployment strategies. Additionally, we discuss open issues and challenges in implementing wireless charging technologies. Finally, we envision some practical future network applications of wireless charging.","Inductive charging,
Wireless communication,
Wireless sensor networks,
Couplings,
Energy harvesting,
Radio frequency,
Microwave theory and techniques"
Locality Sensitive Deep Learning for Detection and Classification of Nuclei in Routine Colon Cancer Histology Images,"Detection and classification of cell nuclei in histopathology images of cancerous tissue stained with the standard hematoxylin and eosin stain is a challenging task due to cellular heterogeneity. Deep learning approaches have been shown to produce encouraging results on histopathology images in various studies. In this paper, we propose a Spatially Constrained Convolutional Neural Network (SC-CNN) to perform nucleus detection. SC-CNN regresses the likelihood of a pixel being the center of a nucleus, where high probability values are spatially constrained to locate in the vicinity of the centers of nuclei. For classification of nuclei, we propose a novel Neighboring Ensemble Predictor (NEP) coupled with CNN to more accurately predict the class label of detected cell nuclei. The proposed approaches for detection and classification do not require segmentation of nuclei. We have evaluated them on a large dataset of colorectal adenocarcinoma images, consisting of more than 20,000 annotated nuclei belonging to four different classes. Our results show that the joint detection and classification of the proposed SC-CNN and NEP produces the highest average F1 score as compared to other recently published approaches. Prospectively, the proposed methods could offer benefit to pathology practice in terms of quantitative analysis of tissue constituents in whole-slide images, and potentially lead to a better understanding of cancer.",
Neural Controller Design-Based Adaptive Control for Nonlinear MIMO Systems With Unknown Hysteresis Inputs,"This paper studies an adaptive neural control for nonlinear multiple-input multiple-output systems in interconnected form. The studied systems are composed of
N
subsystems in pure feedback structure and the interconnection terms are contained in every equation of each subsystem. Moreover, the studied systems consider the effects of Prandtl-Ishlinskii (PI) hysteresis model. It is for the first time to study the control problem for such a class of systems. In addition, the proposed scheme removes an important assumption imposed on the previous works that the bounds of the parameters in PI hysteresis are known. The radial basis functions neural networks are employed to approximate unknown functions. The adaptation laws and the controllers are designed by employing the backstepping technique. The closed-loop system can be proven to be stable by using Lyapunov theorem. A simulation example is studied to validate the effectiveness of the scheme.","Hysteresis,
Artificial neural networks,
MIMO,
Adaptive control,
Mathematical model,
Adaptation models"
A Comprehensive Survey of Recent Advancements in Molecular Communication,"With much advancement in the field of nanotechnology, bioengineering, and synthetic biology over the past decade, microscales and nanoscales devices are becoming a reality. Yet the problem of engineering a reliable communication system between tiny devices is still an open problem. At the same time, despite the prevalence of radio communication, there are still areas where traditional electromagnetic waves find it difficult or expensive to reach. Points of interest in industry, cities, and medical applications often lie in embedded and entrenched areas, accessible only by ventricles at scales too small for conventional radio waves and microwaves, or they are located in such a way that directional high frequency systems are ineffective. Inspired by nature, one solution to these problems is molecular communication (MC), where chemical signals are used to transfer information. Although biologists have studied MC for decades, it has only been researched for roughly 10 year from a communication engineering lens. Significant number of papers have been published to date, but owing to the need for interdisciplinary work, much of the results are preliminary. In this survey, the recent advancements in the field of MC engineering are highlighted. First, the biological, chemical, and physical processes used by an MC system are discussed. This includes different components of the MC transmitter and receiver, as well as the propagation and transport mechanisms. Then, a comprehensive survey of some of the recent works on MC through a communication engineering lens is provided. The survey ends with a technology readiness analysis of MC and future research directions.","Receivers,
Radio transmitters,
Chemicals,
Nanoscale devices,
Molecular communication,
Electromagnetic scattering"
Edge Computing: Vision and Challenges,"The proliferation of Internet of Things (IoT) and the success of rich cloud services have pushed the horizon of a new computing paradigm, edge computing, which calls for processing the data at the edge of the network. Edge computing has the potential to address the concerns of response time requirement, battery life constraint, bandwidth cost saving, as well as data safety and privacy. In this paper, we introduce the definition of edge computing, followed by several case studies, ranging from cloud offloading to smart home and city, as well as collaborative edge to materialize the concept of edge computing. Finally, we present several challenges and opportunities in the field of edge computing, and hope this paper will gain attention from the community and inspire more research in this direction.","Cloud computing,
Internet of things,
Bandwidth,
Time factors,
Mobile handsets,
Data privacy,
Smart homes"
Stacked Sparse Autoencoder (SSAE) for Nuclei Detection on Breast Cancer Histopathology Images,"Automated nuclear detection is a critical step for a number of computer assisted pathology related image analysis algorithms such as for automated grading of breast cancer tissue specimens. The Nottingham Histologic Score system is highly correlated with the shape and appearance of breast cancer nuclei in histopathological images. However, automated nucleus detection is complicated by 1) the large number of nuclei and the size of high resolution digitized pathology images, and 2) the variability in size, shape, appearance, and texture of the individual nuclei. Recently there has been interest in the application of “Deep Learning” strategies for classification and analysis of big image data. Histopathology, given its size and complexity, represents an excellent use case for application of deep learning strategies. In this paper, a Stacked Sparse Autoencoder (SSAE), an instance of a deep learning strategy, is presented for efficient nuclei detection on high-resolution histopathological images of breast cancer. The SSAE learns high-level features from just pixel intensities alone in order to identify distinguishing features of nuclei. A sliding window operation is applied to each image in order to represent image patches via high-level features obtained via the auto-encoder, which are then subsequently fed to a classifier which categorizes each image patch as nuclear or non-nuclear. Across a cohort of 500 histopathological images (2200 × 2200) and approximately 3500 manually segmented individual nuclei serving as the groundtruth, SSAE was shown to have an improved F-measure 84.49% and an average area under Precision-Recall curve (AveP) 78.83%. The SSAE approach also out-performed nine other state of the art nuclear detection strategies.",
Secure D2D Communication in Large-Scale Cognitive Cellular Networks: A Wireless Power Transfer Model,"In this paper, we investigate secure device-to-device (D2D) communication in energy harvesting large-scale cognitive cellular networks. The energy constrained D2D transmitter harvests energy from multiantenna equipped power beacons (PBs), and communicates with the corresponding receiver using the spectrum of the primary base stations (BSs). We introduce a power transfer model and an information signal model to enable wireless energy harvesting and secure information transmission. In the power transfer model, three wireless power transfer (WPT) policies are proposed: 1) co-operative power beacons (CPB) power transfer, 2) best power beacon (BPB) power transfer, and 3) nearest power beacon (NPB) power transfer. To characterize the power transfer reliability of the proposed three policies, we derive new expressions for the exact power outage probability. Moreover, the analysis of the power outage probability is extended to the case when PBs are equipped with large antenna arrays. In the information signal model, we present a new comparative framework with two receiver selection schemes: 1) best receiver selection (BRS), where the receiver with the strongest channel is selected; and 2) nearest receiver selection (NRS), where the nearest receiver is selected. To assess the secrecy performance, we derive new analytical expressions for the secrecy outage probability and the secrecy throughput considering the two receiver selection schemes using the proposed WPT policies. We presented Monte carlo simulation results to corroborate our analysis and show: 1) secrecy performance improves with increasing densities of PBs and D2D receivers due to larger multiuser diversity gain; 2) CPB achieves better secrecy performance than BPB and NPB but consumes more power; and 3) BRS achieves better secrecy performance than NRS but demands more instantaneous feedback and overhead. A pivotal conclusion is reached that with increasing number of antennas at PBs, NPB offers a comparable secrecy performance to that of BPB but with a lower complexity.",
Non-Rigid Point Set Registration by Preserving Global and Local Structures,"In previous work on point registration, the input point sets are often represented using Gaussian mixture models and the registration is then addressed through a probabilistic approach, which aims to exploit global relationships on the point sets. For non-rigid shapes, however, the local structures among neighboring points are also strong and stable and thus helpful in recovering the point correspondence. In this paper, we formulate point registration as the estimation of a mixture of densities, where local features, such as shape context, are used to assign the membership probabilities of the mixture model. This enables us to preserve both global and local structures during matching. The transformation between the two point sets is specified in a reproducing kernel Hilbert space and a sparse approximation is adopted to achieve a fast implementation. Extensive experiments on both synthesized and real data show the robustness of our approach under various types of distortions, such as deformation, noise, outliers, rotation, and occlusion. It greatly outperforms the state-of-the-art methods, especially when the data is badly degraded.",
Lung Pattern Classification for Interstitial Lung Diseases Using a Deep Convolutional Neural Network,"Automated tissue characterization is one of the most crucial components of a computer aided diagnosis (CAD) system for interstitial lung diseases (ILDs). Although much research has been conducted in this field, the problem remains challenging. Deep learning techniques have recently achieved impressive results in a variety of computer vision problems, raising expectations that they might be applied in other domains, such as medical image analysis. In this paper, we propose and evaluate a convolutional neural network (CNN), designed for the classification of ILD patterns. The proposed network consists of 5 convolutional layers with 2 × 2 kernels and LeakyReLU activations, followed by average pooling with size equal to the size of the final feature maps and three dense layers. The last dense layer has 7 outputs, equivalent to the classes considered: healthy, ground glass opacity (GGO), micronodules, consolidation, reticulation, honeycombing and a combination of GGO/reticulation. To train and evaluate the CNN, we used a dataset of 14696 image patches, derived by 120 CT scans from different scanners and hospitals. To the best of our knowledge, this is the first deep CNN designed for the specific problem. A comparative analysis proved the effectiveness of the proposed CNN against previous methods in a challenging dataset. The classification performance ( ~ 85.5%) demonstrated the potential of CNNs in analyzing lung patterns. Future work includes, extending the CNN to three-dimensional data provided by CT volume scans and integrating the proposed method into a CAD system that aims to provide differential diagnosis for ILDs as a supportive tool for radiologists.","Lungs,
Computed tomography,
Diseases,
Feature extraction,
Convolution,
Design automation,
Neural networks"
Adaptive Robust Finite-Time Trajectory Tracking Control of Fully Actuated Marine Surface Vehicles,"In this brief, an adaptive robust finite-time tracking control (ARFTTC) scheme for trajectory tracking of a fully actuated marine surface vehicle with unknown disturbances is proposed. A new finite-time disturbance observer is incorporated into the proposed finite-time tracking control (FTTC) structure that facilitates faster convergence and better robustness to disturbances. Hence, in the presence of unknown disturbances, the ARFTTC can cause tracking error to converge to zero in a finite time. Simulation studies and comprehensive comparisons with conventional backstepping technique demonstrate remarkable performance and superiority of the ARFTTC in terms of both tracking accuracy and robustness.",
A New Dominance Relation-Based Evolutionary Algorithm for Many-Objective Optimization,"Many-objective optimization has posed a great challenge to the classical Pareto dominance-based multiobjective evolutionary algorithms (MOEAs). In this paper, an evolutionary algorithm based on a new dominance relation is proposed for many-objective optimization. The proposed evolutionary algorithm aims to enhance the convergence of the recently suggested nondominated sorting genetic algorithm III by exploiting the fitness evaluation scheme in the MOEA based on decomposition, but still inherit the strength of the former in diversity maintenance. In the proposed algorithm, the nondominated sorting scheme based on the introduced new dominance relation is employed to rank solutions in the environmental selection phase, ensuring both convergence and diversity. The proposed algorithm is evaluated on a number of well-known benchmark problems having 3-15 objectives and compared against eight state-of-the-art algorithms. The extensive experimental results show that the proposed algorithm can work well on almost all the test functions considered in this paper, and it is compared favorably with the other many-objective optimizers. Additionally, a parametric study is provided to investigate the influence of a key parameter in the proposed algorithm.",
A survey on mobile edge computing,"Mobile Edge Computing is an emerging technology that provides cloud and IT services within the close proximity of mobile subscribers. Traditional telecom network operators perform traffic control flow (forwarding and filtering of packets), but in Mobile Edge Computing, cloud servers are also deployed in each base station. Therefore, network operator has a great responsibility in serving mobile subscribers. Mobile Edge Computing platform reduces network latency by enabling computation and storage capacity at the edge network. It also enables application developers and content providers to serve context-aware services (such as collaborative computing) by using real time radio access network information. Mobile and Internet of Things devices perform computation offloading for compute intensive applications, such as image processing, mobile gaming, to leverage the Mobile Edge Computing services. In this paper, some of the promising real time Mobile Edge Computing application scenarios are discussed. Later on, a state-of-the-art research efforts on Mobile Edge Computing domain is presented. The paper also presents taxonomy of Mobile Edge Computing, describing key attributes. Finally, open research challenges in successful deployment of Mobile Edge Computing are identified and discussed.",
Full-View Area Coverage in Camera Sensor Networks: Dimension Reduction and Near-Optimal Solutions,"We study the problem of minimum-number full-view area coverage in camera sensor networks, i.e., how to select the minimum number of camera sensors to guarantee the full-view coverage of a given region. Full-view area coverage is challenging because the full-view coverage of a 2-D continuous domain has to be considered. To tackle this challenge, we first study the intrinsic geometric relationship between the full-view area coverage and the full-view point coverage and prove that the full-view area coverage can be guaranteed, as long as a selected full-view ensuring set of points is full-view covered. This leads to a significant dimension reduction for the full-view area coverage problem. Next, we prove that the minimum-number full-view point coverage is NP-hard and propose two approximation algorithms to solve it from two different perspectives, respectively: 1) By introducing a full-view coverage ratio function, we quantify the “contribution” of each camera sensor to the full-view coverage through which we transform the full-view point coverage into a submodular set cover problem and propose a greedy algorithm (GA); and 2) by studying the geometric relationship between the full-view coverage and the traditional coverage, we propose a set-cover-based algorithm (SCA). We analyze the performance of these two approximation algorithms and characterize their approximation ratios. Furthermore, we devise two distributed algorithms that obtain the same approximation ratios as GA and SCA, respectively. Finally, we provide extensive simulation results to validate our analysis.","Cameras,
Approximation methods,
Approximation algorithms,
Sensors,
Silicon,
Algorithm design and analysis,
Surveillance"
A Survey on Mobile Anchor Node Assisted Localization in Wireless Sensor Networks,"Localization is one of the key technologies in wireless sensor networks (WSNs), since it provides fundamental support for many location-aware protocols and applications. Constraints on cost and power consumption make it infeasible to equip each sensor node in the network with a global position system (GPS) unit, especially for large-scale WSNs. A promising method to localize unknown nodes is to use mobile anchor nodes (MANs), which are equipped with GPS units moving among unknown nodes and periodically broadcasting their current locations to help nearby unknown nodes with localization. A considerable body of research has addressed the mobile anchor node assisted localization (MANAL) problem. However, to the best of our knowledge, no updated surveys on MAAL reflecting recent advances in the field have been presented in the past few years. This survey presents a review of the most successful MANAL algorithms, focusing on the achievements made in the past decade, and aims to become a starting point for researchers who are initiating their endeavors in MANAL research field. In addition, we seek to present a comprehensive review of the recent breakthroughs in the field, providing links to the most interesting and successful advances in this research field.",
Content-Centric Sparse Multicast Beamforming for Cache-Enabled Cloud RAN,"This paper presents a content-centric transmission design in a cloud radio access network by incorporating multicasting and caching. Users requesting the same content form a multicast group and are served by a same cluster of base stations (BSs) cooperatively. Each BS has a local cache, and it acquires the requested contents either from its local cache or from the central processor via backhaul links. We investigate the dynamic content-centric BS clustering and multicast beamforming with respect to both channel condition and caching status. We first formulate a mixed-integer nonlinear programming problem of minimizing the weighted sum of backhaul cost and transmit power under the quality-of-service constraint for each multicast group. Theoretical analysis reveals that all the BSs caching a requested content can be included in the BS cluster of this content, regardless of the channel conditions. Then, we reformulate an equivalent sparse multicast beamforming (SBF) problem. By adopting smoothed ℓ0-norm approximation and other techniques, the SBF problem is transformed into the difference of convex programs and effectively solved using the convex-concave procedure algorithms. Simulation results demonstrate significant advantage of the proposed content-centric transmission. The effects of heuristic caching strategies are also evaluated.","Array signal processing,
Radio access networks,
Wireless communication,
Multicast communication,
Quality of service,
Programming,
Mobile communication"
Pulmonary Nodule Detection in CT Images: False Positive Reduction Using Multi-View Convolutional Networks,"We propose a novel Computer-Aided Detection (CAD) system for pulmonary nodules using multi-view convolutional networks (ConvNets), for which discriminative features are automatically learnt from the training data. The network is fed with nodule candidates obtained by combining three candidate detectors specifically designed for solid, subsolid, and large nodules. For each candidate, a set of 2-D patches from differently oriented planes is extracted. The proposed architecture comprises multiple streams of 2-D ConvNets, for which the outputs are combined using a dedicated fusion method to get the final classification. Data augmentation and dropout are applied to avoid overfitting. On 888 scans of the publicly available LIDC-IDRI dataset, our method reaches high detection sensitivities of 85.4% and 90.1% at 1 and 4 false positives per scan, respectively. An additional evaluation on independent datasets from the ANODE09 challenge and DLCST is performed. We showed that the proposed multi-view ConvNets is highly suited to be used for false positive reduction of a CAD system.","Design automation,
Solids,
Cancer,
Lungs,
Computed tomography,
Lesions,
Feature extraction"
Internet of Things and Big Data Analytics for Smart and Connected Communities,"This paper promotes the concept of smart and connected communities SCC, which is evolving from the concept of smart cities. SCC are envisioned to address synergistically the needs of remembering the past (preservation and revitalization), the needs of living in the present (livability), and the needs of planning for the future (attainability). Therefore, the vision of SCC is to improve livability, preservation, revitalization, and attainability of a community. The goal of building SCC for a community is to live in the present, plan for the future, and remember the past. We argue that Internet of Things (IoT) has the potential to provide a ubiquitous network of connected devices and smart sensors for SCC, and big data analytics has the potential to enable the move from IoT to real-time control desired for SCC. We highlight mobile crowdsensing and cyber-physical cloud computing as two most important IoT technologies in promoting SCC. As a case study, we present TreSight, which integrates IoT and big data analytics for smart tourism and sustainable cultural heritage in the city of Trento, Italy.","Internet of things,
Smart cities,
Big data,
Sensors,
Cultural differences,
Economics,
Urban areas,
Data analytics,
Sustainable development"
The Analysis of Image Contrast: From Quality Assessment to Automatic Enhancement,"Proper contrast change can improve the perceptual quality of most images, but it has largely been overlooked in the current research of image quality assessment (IQA). To fill this void, we in this paper first report a new large dedicated contrast-changed image database (CCID2014), which includes 655 images and associated subjective ratings recorded from 22 inexperienced observers. We then present a novel reduced-reference image quality metric for contrast change (RIQMC) using phase congruency and statistics information of the image histogram. Validation of the proposed model is conducted on contrast related CCID2014, TID2008, CSIQ and TID2013 databases, and results justify the superiority and efficiency of RIQMC over a majority of classical and state-of-the-art IQA methods. Furthermore, we combine aforesaid subjective and objective assessments to derive the RIQMC based Optimal HIstogram Mapping (ROHIM) for automatic contrast enhancement, which is shown to outperform recently developed enhancement technologies.",
Single-Carrier SM-MIMO: A Promising Design for Broadband Large-Scale Antenna Systems,"The main limitations of employing large-scale antenna (LSA) architectures for broadband frequency-selective channels include, but are not limited to their complexity, power consumption, and the high cost of multiple radio frequency (RF) chains. Promising solutions can be found in the recently proposed family of single-carrier (SC) spatial modulation (SM) transmission techniques. Since the SM scheme's transmit antenna (TA) activation process is carried out in the context of a SC-SM architecture, the benefits of a low-complexity and low-cost single-RF transmitter are maintained, while a high MIMO multiplexing gain can be attained. Moreover, owing to its inherent SC structure, the transmit signals of SC-SM have attractive peak power characteristics and a high robustness to RF hardware impairments, such as the RF carrier frequency offset (CFO) and phase noise. In this paper, we present a comprehensive overview of the latest research achievements of SC-SM, which has recently attracted considerable attention. We outline the associated transceiver design, the benefits and potential tradeoffs, the LSA aided multiuser (MU) transmission developments, the relevant open research issues as well as the potential solutions of this appealing transmission technique.","MIMO,
Radio frequency,
Broadband antennas,
Transmitting antennas,
OFDM,
Electronic mail,
Transceivers"
Demand Response Program in Smart Grid Using Supply Function Bidding Mechanism,"In smart grid, customers have access to the electricity consumption and the price data via smart meters; thus, they are able to participate in the demand response (DR) programs. In this paper, we address the interaction among multiple utility companies and multiple customers in smart grid by modeling the DR problem as two noncooperative games: the supplier and customer side games. In the first game, supply function bidding mechanism is employed to model the utility companies' profit maximization problem. In the proposed mechanism, the utility companies submit their bids to the data center, where the electricity price is computed and is sent to the customers. In the second game, the price anticipating customers determine optimal shiftable load profile to maximize their daily payoff. The existence and uniqueness of the Nash equilibrium in the mentioned games are studied and a computationally tractable distributed algorithm is designed to determine the equilibrium. Simulation results demonstrate the superior performance of the proposed DR method in increasing the utility companies' profit and customers' payoff, as well as in reducing the peak-to-average ratio in the aggregate load demand. Finally, the algorithm performance is compared with a DR method in the literature to demonstrate the similarities and differences.","Companies,
Games,
Nash equilibrium,
Smart grids,
Load modeling,
Smart meters,
Aggregates"
Alternating Minimization Algorithms for Hybrid Precoding in Millimeter Wave MIMO Systems,"Millimeter wave (mmWave) communications has been regarded as a key enabling technology for 5G networks, as it offers orders of magnitude greater spectrum than current cellular bands. In contrast to conventional multiple-input-multiple-output (MIMO) systems, precoding in mmWave MIMO cannot be performed entirely at baseband using digital precoders, as only a limited number of signal mixers and analog-to-digital converters can be supported considering their cost and power consumption. As a cost-effective alternative, a hybrid precoding transceiver architecture, combining a digital precoder and an analog precoder, has recently received considerable attention. However, the optimal design of such hybrid precoders has not been fully understood. In this paper, treating the hybrid precoder design as a matrix factorization problem, effective alternating minimization (AltMin) algorithms will be proposed for two different hybrid precoding structures, i.e., the fully-connected and partially-connected structures. In particular, for the fully-connected structure, an AltMin algorithm based on manifold optimization is proposed to approach the performance of the fully digital precoder, which, however, has a high complexity. Thus, a low-complexity AltMin algorithm is then proposed, by enforcing an orthogonal constraint on the digital precoder. Furthermore, for the partially-connected structure, an AltMin algorithm is also developed with the help of semidefinite relaxation. For practical implementation, the proposed AltMin algorithms are further extended to the broadband setting with orthogonal frequency division multiplexing modulation. Simulation results will demonstrate significant performance gains of the proposed AltMin algorithms over existing hybrid precoding algorithms. Moreover, based on the proposed algorithms, simulation comparisons between the two hybrid precoding structures will provide valuable design insights.","Algorithm design and analysis,
Radio frequency,
Signal processing algorithms,
MIMO,
Minimization,
Antennas"
Automatic Detection of Cerebral Microbleeds From MR Images via 3D Convolutional Neural Networks,"Cerebral microbleeds (CMBs) are small haemorrhages nearby blood vessels. They have been recognized as important diagnostic biomarkers for many cerebrovascular diseases and cognitive dysfunctions. In current clinical routine, CMBs are manually labelled by radiologists but this procedure is laborious, time-consuming, and error prone. In this paper, we propose a novel automatic method to detect CMBs from magnetic resonance (MR) images by exploiting the 3D convolutional neural network (CNN). Compared with previous methods that employed either low-level hand-crafted descriptors or 2D CNNs, our method can take full advantage of spatial contextual information in MR volumes to extract more representative high-level features for CMBs, and hence achieve a much better detection accuracy. To further improve the detection performance while reducing the computational cost, we propose a cascaded framework under 3D CNNs for the task of CMB detection. We first exploit a 3D fully convolutional network (FCN) strategy to retrieve the candidates with high probabilities of being CMBs, and then apply a well-trained 3D CNN discrimination model to distinguish CMBs from hard mimics. Compared with traditional sliding window strategy, the proposed 3D FCN strategy can remove massive redundant computations and dramatically speed up the detection process. We constructed a large dataset with 320 volumetric MR scans and performed extensive experiments to validate the proposed method, which achieved a high sensitivity of 93.16% with an average number of 2.74 false positives per subject, outperforming previous methods using low-level descriptors or 2D CNNs by a significant margin. The proposed method, in principle, can be adapted to other biomarker detection tasks from volumetric medical data.","Three-dimensional displays,
Feature extraction,
Kernel,
Biomarkers,
MIMICs,
Medical diagnostic imaging"
Distributed Event-Triggered Scheme for Economic Dispatch in Smart Grids,"To reduce information exchange requirements in smart grids, an event-triggered communication-based distributed optimization is proposed for economic dispatch. In this work, the θ-logarithmic barrier-based method is employed to reformulate the economic dispatch problem, and the consensus-based approach is considered for developing fully distributed technology-enabled algorithms. Specifically, a novel distributed algorithm utilizes the minimum connected dominating set (CDS), which efficiently allocates the task of balancing supply and demand for the entire power network at the beginning of economic dispatch. Further, an event-triggered communication-based method for the incremental cost of each generator is able to reach a consensus, coinciding with the global optimality of the objective function. In addition, a fast gradient-based distributed optimization method is also designed to accelerate the convergence rate of the event-triggered distributed optimization. Simulations based on the IEEE 57-bus test system demonstrate the effectiveness and good performance of proposed algorithms.",
A Survey on Evolutionary Computation Approaches to Feature Selection,"Feature selection is an important task in data mining and machine learning to reduce the dimensionality of the data and increase the performance of an algorithm, such as a classification algorithm. However, feature selection is a challenging task due mainly to the large search space. A variety of methods have been applied to solve feature selection problems, where evolutionary computation (EC) techniques have recently gained much attention and shown some success. However, there are no comprehensive guidelines on the strengths and weaknesses of alternative approaches. This leads to a disjointed and fragmented field with ultimately lost opportunities for improving performance and successful applications. This paper presents a comprehensive survey of the state-of-the-art work on EC for feature selection, which identifies the contributions of these different algorithms. In addition, current issues and challenges are also discussed to identify promising areas for future research.","Search problems,
Machine learning algorithms,
Evolutionary computation,
Optimization,
Data mining,
Feature extraction,
Computational efficiency"
A Reference Vector Guided Evolutionary Algorithm for Many-Objective Optimization,"In evolutionary multiobjective optimization, maintaining a good balance between convergence and diversity is particularly crucial to the performance of the evolutionary algorithms (EAs). In addition, it becomes increasingly important to incorporate user preferences because it will be less likely to achieve a representative subset of the Pareto-optimal solutions using a limited population size as the number of objectives increases. This paper proposes a reference vector-guided EA for many-objective optimization. The reference vectors can be used not only to decompose the original multiobjective optimization problem into a number of single-objective subproblems, but also to elucidate user preferences to target a preferred subset of the whole Pareto front (PF). In the proposed algorithm, a scalarization approach, termed angle-penalized distance, is adopted to balance convergence and diversity of the solutions in the high-dimensional objective space. An adaptation strategy is proposed to dynamically adjust the distribution of the reference vectors according to the scales of the objective functions. Our experimental results on a variety of benchmark test problems show that the proposed algorithm is highly competitive in comparison with five state-of-the-art EAs for many-objective optimization. In addition, we show that reference vectors are effective and cost-efficient for preference articulation, which is particularly desirable for many-objective optimization. Furthermore, a reference vector regeneration strategy is proposed for handling irregular PFs. Finally, the proposed algorithm is extended for solving constrained many-objective optimization problems.",
Object Recognition Using Tactile Measurements: Kernel Sparse Coding Methods,"Dexterous robots have emerged in the last decade in response to the need for fine-motor-control assistance in applications as diverse as surgery, undersea welding, and mechanical manipulation in space. Crucial to the fine operation and contact environmental perception are tactile sensors that are fixed on the robotic fingertips. These can be used to distinguish material texture, roughness, spatial features, compliance, and friction. In this paper, we regard the investigated tactile data as time sequences, of which dissimilarity can be evaluated by the popular dynamic time warping method. A kernel sparse coding method is therefore developed to address the tactile data representation and classification problem. However, the naive use of sparse coding neglects the intrinsic relation between individual fingers, which simultaneously contact the object. To tackle this problem, we develop a joint kernel sparse coding model to solve the multifinger tactile sequence classification problem. In this model, the intrinsic relations between fingers are explicitly taken into account using the joint sparse coding, which encourages all of the coding vectors to share the same sparsity support pattern. The experimental results show that the joint sparse coding achieves better performance than conventional sparse coding.","Encoding,
Kernel,
Silicon,
Object recognition,
Sensors,
Training,
Robots"
Sampling of Graph Signals With Successive Local Aggregations,"A new scheme to sample signals defined on the nodes of a graph is proposed. The underlying assumption is that such signals admit a sparse representation in a frequency domain related to the structure of the graph, which is captured by the so-called graph-shift operator. Instead of using the value of the signal observed at a subset of nodes to recover the signal in the entire graph, the sampling scheme proposed here uses as input observations taken at a single node. The observations correspond to sequential applications of the graph-shift operator, which are linear combinations of the information gathered by the neighbors of the node. When the graph corresponds to a directed cycle (which is the support of time-varying signals), our method is equivalent to the classical sampling in the time domain. When the graph is more general, we show that the Vandermonde structure of the sampling matrix, critical when sampling time-varying signals, is preserved. Sampling and interpolation are analyzed first in the absence of noise, and then noise is considered. We then study the recovery of the sampled signal when the specific set of frequencies that is active is not known. Moreover, we present a more general sampling scheme, under which, either our aggregation approach or the alternative approach of sampling a graph signal by observing the value of the signal at a subset of nodes can be both viewed as particular cases. Numerical experiments illustrating the results in both synthetic and real-world graphs close the paper.",
RMER: Reliable and Energy-Efficient Data Collection for Large-Scale Wireless Sensor Networks,"We propose a novel event data collection approach named reliability and multipath encounter routing (RMER) for meeting reliability and energy efficiency requirements. The contributions of the RMER approach are as follows. 1) Fewer monitor nodes are selected in hotspot areas that are close to the Sink, and more monitor nodes are selected in nonhotspot areas, which can lead to increased network lifetime and event detection reliability. 2) The RMER approach sends data to the Sink by converging multipath routes of event monitoring nodes into a one-path route to aggregate data. Thus, energy consumption can be greatly reduced, thereby enabling further increased network lifetime. Both theoretical and experimental simulation results show that RMER applied to event detection outperforms other solutions. Our results clearly indicate that RMER increases energy efficiency by 51% and network lifetime by 23% over other solutions while guaranteeing event detection reliability.","Reliability,
Energy consumption,
Event detection,
Monitoring,
Protocols,
Energy efficiency"
Joint Optimization of Lifetime and Transport Delay under Reliability Constraint Wireless Sensor Networks,"This paper first presents an analysis strategy to meet requirements of a sensing application through trade-offs between the energy consumption (lifetime) and source-to-sink transport delay under reliability constraint wireless sensor networks. A novel data gathering protocol named Broadcasting Combined with Multi-NACK/ACK (BCMN/A) protocol is proposed based on the analysis strategy. The BCMN/A protocol achieves energy and delay efficiency during the data gathering process both in intra-cluster and inter-cluster. In intra-cluster, after each round of TDMA collection, a cluster head broadcasts NACK to indicate nodes which fail to send data in order to prevent nodes that successfully send data from retransmission. The energy for data gathering in intra-cluster is conserved and transport delay is decreased with multi-NACK mechanism. Meanwhile in inter-clusters, multi-ACK is returned whenever a sensor node sends any data packet. Although the number of ACKs to be sent is increased, the number of data packets to be retransmitted is significantly decreased so that consequently it reduces the node energy consumption. The BCMN/A protocol is evaluated by theoretical analysis as well as extensive simulations and these results demonstrate that our proposed protocol jointly optimizes the network lifetime and transport delay under network reliability constraint.",
A General MIMO Framework for NOMA Downlink and Uplink Transmission Based on Signal Alignment,"The application of multiple-input multiple-output (MIMO) techniques to nonorthogonal multiple access (NOMA) systems is important to enhance the performance gains of NOMA. In this paper, a novel MIMO-NOMA framework for downlink and uplink transmission is proposed by applying the concept of signal alignment. By using stochastic geometry, closed-form analytical results are developed to facilitate the performance evaluation of the proposed framework for randomly deployed users and interferers. The impact of different power allocation strategies, namely fixed power allocation and cognitive radio inspired power allocation, on the performance of MIMO-NOMA is also investigated. Computer simulation results are provided to demonstrate the performance of the proposed framework and the accuracy of the developed analytical results.","Base stations,
Interference,
Resource management,
Downlink,
MIMO,
Antennas,
Uplink"
"The Essential Role and the Continuous Evolution of Modulation Techniques for Voltage-Source Inverters in the Past, Present, and Future Power Electronics","The cost reduction of power-electronic devices, the increase in their reliability, efficiency, and power capability, and lower development times, together with more demanding application requirements, has driven the development of several new inverter topologies recently introduced in the industry, particularly medium-voltage converters. New more complex inverter topologies and new application fields come along with additional control challenges, such as voltage imbalances, power-quality issues, higher efficiency needs, and fault-tolerant operation, which necessarily requires the parallel development of modulation schemes. Therefore, recently, there have been significant advances in the field of modulation of dc/ac converters, which conceptually has been dominated during the last several decades almost exclusively by classic pulse-width modulation (PWM) methods. This paper aims to concentrate and discuss the latest developments on this exciting technology, to provide insight on where the state-of-the-art stands today, and analyze the trends and challenges driving its future.",
Learning Spatio-Temporal Representations for Action Recognition: A Genetic Programming Approach,"Extracting discriminative and robust features from video sequences is the first and most critical step in human action recognition. In this paper, instead of using handcrafted features, we automatically learn spatio-temporal motion features for action recognition. This is achieved via an evolutionary method, i.e., genetic programming (GP), which evolves the motion feature descriptor on a population of primitive 3D operators (e.g., 3D-Gabor and wavelet). In this way, the scale and shift invariant features can be effectively extracted from both color and optical flow sequences. We intend to learn data adaptive descriptors for different datasets with multiple layers, which makes fully use of the knowledge to mimic the physical structure of the human visual cortex for action recognition and simultaneously reduce the GP searching space to effectively accelerate the convergence of optimal solutions. In our evolutionary architecture, the average cross-validation classification error, which is calculated by an support-vector-machine classifier on the training set, is adopted as the evaluation criterion for the GP fitness function. After the entire evolution procedure finishes, the best-so-far solution selected by GP is regarded as the (near-)optimal action descriptor obtained. The GP-evolving feature extraction method is evaluated on four popular action datasets, namely KTH, HMDB51, UCF YouTube, and Hollywood2. Experimental results show that our method significantly outperforms other types of features, either hand-designed or machine-learned.","Feature extraction,
Three-dimensional displays,
Visualization,
Image color analysis,
Optical imaging,
Genetic algorithms,
Robustness"
"Full-Duplex Wireless Communications: Challenges, Solutions, and Future Research Directions","The family of conventional half-duplex (HD) wireless systems relied on transmitting and receiving in different time slots or frequency subbands. Hence, the wireless research community aspires to conceive full-duplex (FD) operation for supporting concurrent transmission and reception in a single time/frequency channel, which would improve the attainable spectral efficiency by a factor of two. The main challenge encountered in implementing an FD wireless device is the large power difference between the self-interference (SI) imposed by the device’s own transmissions and the signal of interest received from a remote source. In this survey, we present a comprehensive list of the potential FD techniques and highlight their pros and cons. We classify the SI cancellation techniques into three categories, namely passive suppression, analog cancellation and digital cancellation, with the advantages and disadvantages of each technique compared. Specifically, we analyze the main impairments (e.g., phase noise, power amplifier nonlinearity, as well as in-phase and quadrature-phase (I/Q) imbalance, etc.) that degrading the SI cancellation. We then discuss the FD-based media access control (MAC)-layer protocol design for the sake of addressing some of the critical issues, such as the problem of hidden terminals, the resultant end-to-end delay and the high packet loss ratio (PLR) due to network congestion. After elaborating on a variety of physical/MAC-layer techniques, we discuss potential solutions conceived for meeting the challenges imposed by the aforementioned techniques. Furthermore, we also discuss a range of critical issues related to the implementation, performance enhancement and optimization of FD systems, including important topics such as hybrid FD/HD scheme, optimal relay selection and optimal power allocation, etc. Finally, a variety of new directions and open problems associated with FD technology are pointed out. Our hope is that this treatise will stimulate future research efforts in the emerging field of FD communications.","Wireless communication,
High definition video,
Phase noise,
Cooperative communication,
Power amplifiers,
Resource management,
Analog cancellation,
Decode and forward"
No-Reference Image Blur Assessment Based on Discrete Orthogonal Moments,"Blur is a key determinant in the perception of image quality. Generally, blur causes spread of edges, which leads to shape changes in images. Discrete orthogonal moments have been widely studied as effective shape descriptors. Intuitively, blur can be represented using discrete moments since noticeable blur affects the magnitudes of moments of an image. With this consideration, this paper presents a blind image blur evaluation algorithm based on discrete Tchebichef moments. The gradient of a blurred image is first computed to account for the shape, which is more effective for blur representation. Then the gradient image is divided into equal-size blocks and the Tchebichef moments are calculated to characterize image shape. The energy of a block is computed as the sum of squared non-DC moment values. Finally, the proposed image blur score is defined as the variance-normalized moment energy, which is computed with the guidance of a visual saliency model to adapt to the characteristic of human visual system. The performance of the proposed method is evaluated on four public image quality databases. The experimental results demonstrate that our method can produce blur scores highly consistent with subjective evaluations. It also outperforms the state-of-the-art image blur metrics and several general-purpose no-reference quality metrics.",
Approximate Orthogonal Sparse Embedding for Dimensionality Reduction,"Locally linear embedding (LLE) is one of the most well-known manifold learning methods. As the representative linear extension of LLE, orthogonal neighborhood preserving projection (ONPP) has attracted widespread attention in the field of dimensionality reduction. In this paper, a unified sparse learning framework is proposed by introducing the sparsity or L1 -norm learning, which further extends the LLE-based methods to sparse cases. Theoretical connections between the ONPP and the proposed sparse linear embedding are discovered. The optimal sparse embeddings derived from the proposed framework can be computed by iterating the modified elastic net and singular value decomposition. We also show that the proposed model can be viewed as a general model for sparse linear and nonlinear (kernel) subspace learning. Based on this general model, sparse kernel embedding is also proposed for nonlinear sparse feature extraction. Extensive experiments on five databases demonstrate that the proposed sparse learning framework performs better than the existing subspace learning algorithm, particularly in the cases of small sample sizes.",
Linear Precoding of Data and Artificial Noise in Secure Massive MIMO Systems,"In this paper, we consider secure downlink transmission in a multicell massive multiple-input multiple-output (MIMO) system where the numbers of base station (BS) antennas, mobile terminals, and eavesdropper antennas are asymptotically large. The channel state information of the eavesdropper is assumed to be unavailable at the BS and hence, linear precoding of data and artificial noise (AN) are employed for secrecy enhancement. Four different data precoders (i.e., selfish zero-forcing (ZF)/regularized channel inversion (RCI) and collaborative ZF/RCI precoders) and three different AN precoders (i.e., random, selfish/collaborative null-space-based precoders) are investigated and the corresponding achievable ergodic secrecy rates are analyzed. Our analysis includes the effects of uplink channel estimation, pilot contamination, multicell interference, and path-loss. Furthermore, to strike a balance between complexity and performance, linear precoders that are based on matrix polynomials are proposed for both data and AN precoding. The polynomial coefficients of the data and AN precoders are optimized, respectively, for minimization of the sum-mean-squared-error of and the AN leakage to the mobile terminals in the cell of interest using tools from free probability and random matrix theory. Our analytical and simulation results provide interesting insights for the design of secure multicell massive MIMO systems and reveal that the proposed polynomial data and AN precoders closely approach the performance of selfish RCI data and null-space-based AN precoders, respectively.",
Struck: Structured Output Tracking with Kernels,"Adaptive tracking-by-detection methods are widely used in computer vision for tracking arbitrary objects. Current approaches treat the tracking problem as a classification task and use online learning techniques to update the object model. However, for these updates to happen one needs to convert the estimated object position into a set of labelled training examples, and it is not clear how best to perform this intermediate step. Furthermore, the objective for the classifier (label prediction) is not explicitly coupled to the objective for the tracker (estimation of object position). In this paper, we present a framework for adaptive visual object tracking based on structured output prediction. By explicitly allowing the output space to express the needs of the tracker, we avoid the need for an intermediate classification step. Our method uses a kernelised structured output support vector machine (SVM), which is learned online to provide adaptive tracking. To allow our tracker to run at high frame rates, we (a) introduce a budgeting mechanism that prevents the unbounded growth in the number of support vectors that would otherwise occur during tracking, and (b) show how to implement tracking on the GPU. Experimentally, we show that our algorithm is able to outperform state-of-the-art trackers on various benchmark videos. Additionally, we show that we can easily incorporate additional features and kernels into our framework, which results in increased tracking performance.",
Negative Capacitance in Short-Channel FinFETs Externally Connected to an Epitaxial Ferroelectric Capacitor,We report subthreshold swings as low as 8.5 mV/decade over as high as eight orders of magnitude of drain current in short-channel negative capacitance FinFETs (NC-FinFETs) with gate length Lg = 100 nm. NC-FinFETs are constructed by connecting a high-quality epitaxial bismuth ferrite (BiFeO3) ferroelectric capacitor to the gate terminal of both n-type and p-type FinFETs. We show that a self-consistent simulation scheme based on Berkeley SPICE Insulated-Gate-FET Model:Common Multi Gate model and Landau-Devonshire formalism could quantitatively match the experimental NC-FinFET transfer characteristics. This also allows a general procedure to extract the effective S-shaped ferroelectric charge-voltage characteristics that provides important insights into the device operation.,
Privacy Protection for Preventing Data Over-Collection in Smart City,"In smart city, all kinds of users' data are stored in electronic devices to make everything intelligent. A smartphone is the most widely used electronic device and it is the pivot of all smart systems. However, current smartphones are not competent to manage users' sensitive data, and they are facing the privacy leakage caused by data over-collection. Data over-collection, which means smartphones apps collect users' data more than its original function while within the permission scope, is rapidly becoming one of the most serious potential security hazards in smart city. In this paper, we study the current state of data over-collection and study some most frequent data over-collected cases. We present a mobile-cloud framework, which is an active approach to eradicate the data over-collection. By putting all users' data into a cloud, the security of users' data can be greatly improved. We have done extensive experiments and the experimental results have demonstrated the effectiveness of our approach.","Security,
Smart phones,
Mobile communication,
Data privacy,
Privacy,
Operating systems"
Breaking the Hierarchy: Distributed Control and Economic Optimality in Microgrids,"Modeled after the hierarchical control architecture of power transmission systems, a layering of primary, secondary, and tertiary control has become the standard operation paradigm for islanded microgrids. Despite this superficial similarity, the control objectives in microgrids across these three layers are varied and ambitious, and they must be achieved while allowing for robust plug-and-play operation and maximal flexibility, without hierarchical decision making and time-scale separations. In this paper, we explore control strategies for these three layers and illuminate some possibly unexpected connections and dependencies among them. Building from a first-principle analysis of decentralized primary droop control, we study centralized, decentralized, and distributed architectures for secondary frequency regulation. We find that averaging-based distributed controllers using communication among the generation units offer the best combination of flexibility and performance. We further leverage these results to study constrained ac economic dispatch in a tertiary control layer. Surprisingly, we show that the minimizers of the economic dispatch problem are in one-to-one correspondence with the set of steady states reachable by droop control. In other words, the adoption of droop control is necessary and sufficient to achieve economic optimization. This equivalence results in simple guidelines to select the droop coefficients, which include the known criteria for power sharing. We illustrate the performance and robustness of our designs through simulations.","Microgrids,
Synchronization,
Inverters,
Load modeling,
Mathematical model,
Frequency control,
Control systems"
What Else Does Your Biometric Data Reveal? A Survey on Soft Biometrics,"Recent research has explored the possibility of extracting ancillary information from primary biometric traits viz., face, fingerprints, hand geometry, and iris. This ancillary information includes personal attributes, such as gender, age, ethnicity, hair color, height, weight, and so on. Such attributes are known as soft biometrics and have applications in surveillance and indexing biometric databases. These attributes can be used in a fusion framework to improve the matching accuracy of a primary biometric system (e.g., fusing face with gender information), or can be used to generate qualitative descriptions of an individual (e.g., young Asian female with dark eyes and brown hair). The latter is particularly useful in bridging the semantic gap between human and machine descriptions of the biometric data. In this paper, we provide an overview of soft biometrics and discuss some of the techniques that have been proposed to extract them from the image and the video data. We also introduce a taxonomy for organizing and classifying soft biometric attributes, and enumerate the strengths and limitations of these attributes in the context of an operational biometric system. Finally, we discuss open research problems in this field. This survey is intended for researchers and practitioners in the field of biometrics.","Face,
Feature extraction,
Iris recognition,
Accuracy,
Bioinformatics,
Hair,
Data mining"
Subspace Regularized Sparse Multitask Learning for Multiclass Neurodegenerative Disease Identification,"The high feature-dimension and low sample-size problem is one of the major challenges in the study of computer-aided Alzheimer's disease (AD) diagnosis. To circumvent this problem, feature selection and subspace learning have been playing core roles in the literature. Generally, feature selection methods are preferable in clinical applications due to their ease for interpretation, but subspace learning methods can usually achieve more promising results. In this paper, we combine two different methodological approaches to discriminative feature selection in a unified framework. Specifically, we utilize two subspace learning methods, namely, linear discriminant analysis and locality preserving projection, which have proven their effectiveness in a variety of fields, to select class-discriminative and noise-resistant features. Unlike previous methods in neuroimaging studies that mostly focused on a binary classification, the proposed feature selection method is further applicable for multiclass classification in AD diagnosis. Extensive experiments on the Alzheimer's disease neuroimaging initiative dataset showed the effectiveness of the proposed method over other state-of-the-art methods.","Learning systems,
Positron emission tomography,
Magnetic resonance imaging,
Neuroimaging,
Support vector machines,
Alzheimer's disease"
Analysis and Control of Epidemics: A Survey of Spreading Processes on Complex Networks,"This article reviews and presents various solved and open problems in the development, analysis, and control of epidemic models. The proper modeling and analysis of spreading processes has been a long-standing area of research among many different fields, including mathematical biology, physics, computer science, engineering, economics, and the social sciences. One of the earliest epidemic models conceived was by Daniel Bernoulli in 1760, which was motivated by studying the spread of smallpox [1]. In addition to Bernoulli, there were many different researchers also working on mathematical epidemic models around this time [2]. These initial models were quite simplistic, and the further development and study of such models dates back to the 1900s [3]-[6], where still-simple models were studied to provide insight into how various diseases can spread through a population. In recent years, there has been a resurgence of interest in these problems as the concept of ""networks"" becomes increasingly prevalent in modeling many different aspects of the world today. A more comprehensive review of the history of mathematical epidemiology can be found in [7] and [8].","Medical services,
Epidemics,
Statistical analysis,
Mathematical model,
Predictive models,
Complex networks,
Diseases,
Stochastic processes,
Analytical models"
Cosaliency Detection Based on Intrasaliency Prior Transfer and Deep Intersaliency Mining,"As an interesting and emerging topic, cosaliency detection aims at simultaneously extracting common salient objects in multiple related images. It differs from the conventional saliency detection paradigm in which saliency detection for each image is determined one by one independently without taking advantage of the homogeneity in the data pool of multiple related images. In this paper, we propose a novel cosaliency detection approach using deep learning models. Two new concepts, called intrasaliency prior transfer and deep intersaliency mining, are introduced and explored in the proposed work. For the intrasaliency prior transfer, we build a stacked denoising autoencoder (SDAE) to learn the saliency prior knowledge from auxiliary annotated data sets and then transfer the learned knowledge to estimate the intrasaliency for each image in cosaliency data sets. For the deep intersaliency mining, we formulate it by using the deep reconstruction residual obtained in the highest hidden layer of a self-trained SDAE. The obtained deep intersaliency can extract more intrinsic and general hidden patterns to discover the homogeneity of cosalient objects in terms of some higher level concepts. Finally, the cosaliency maps are generated by weighted integration of the proposed intrasaliency prior, deep intersaliency, and traditional shallow intersaliency. Comprehensive experiments over diverse publicly available benchmark data sets demonstrate consistent performance gains of the proposed method over the state-of-the-art cosaliency detection methods.","Encoding,
Machine learning,
Data mining,
Feature extraction,
Training,
Robustness,
Visualization"
Visual Place Recognition: A Survey,"Visual place recognition is a challenging problem due to the vast range of ways in which the appearance of real-world places can vary. In recent years, improvements in visual sensing capabilities, an ever-increasing focus on long-term mobile robot autonomy, and the ability to draw on state-of-the-art research in other disciplines-particularly recognition in computer vision and animal navigation in neuroscience-have all contributed to significant advances in visual place recognition systems. This paper presents a survey of the visual place recognition research landscape. We start by introducing the concepts behind place recognition-the role of place recognition in the animal kingdom, how a “place” is defined in a robotics context, and the major components of a place recognition system. Long-term robot operations have revealed that changing appearance can be a significant factor in visual place recognition failure; therefore, we discuss how place recognition solutions can implicitly or explicitly account for appearance change within the environment. Finally, we close with a discussion on the future of visual place recognition, in particular with respect to the rapid advances being made in the related fields of deep learning, semantic scene understanding, and video description.",
Balancing Convergence and Diversity in Decomposition-Based Many-Objective Optimizers,"The decomposition-based multiobjective evolutionary algorithms (MOEAs) generally make use of aggregation functions to decompose a multiobjective optimization problem into multiple single-objective optimization problems. However, due to the nature of contour lines for the adopted aggregation functions, they usually fail to preserve the diversity in high-dimensional objective space even by using diverse weight vectors. To address this problem, we propose to maintain the desired diversity of solutions in their evolutionary process explicitly by exploiting the perpendicular distance from the solution to the weight vector in the objective space, which achieves better balance between convergence and diversity in many-objective optimization. The idea is implemented to enhance two well-performing decomposition-based algorithms, i.e., MOEA, based on decomposition and ensemble fitness ranking. The two enhanced algorithms are compared to several state-of-the-art algorithms and a series of comparative experiments are conducted on a number of test problems from two well-known test suites. The experimental results show that the two proposed algorithms are generally more effective than their predecessors in balancing convergence and diversity, and they are also very competitive against other existing algorithms for solving many-objective optimization problems.",
The Geneva Minimalistic Acoustic Parameter Set (GeMAPS) for Voice Research and Affective Computing,"Work on voice sciences over recent decades has led to a proliferation of acoustic parameters that are used quite selectively and are not always extracted in a similar fashion. With many independent teams working in different research areas, shared standards become an essential safeguard to ensure compliance with state-of-the-art methods allowing appropriate comparison of results across studies and potential integration and combination of extraction and recognition systems. In this paper we propose a basic standard acoustic parameter set for various areas of automatic voice analysis, such as paralinguistic or clinical speech analysis. In contrast to a large brute-force parameter set, we present a minimalistic set of voice parameters here. These were selected based on a) their potential to index affective physiological changes in voice production, b) their proven value in former studies as well as their automatic extractability, and c) their theoretical significance. The set is intended to provide a common baseline for evaluation of future research and eliminate differences caused by varying parameter sets or even different implementations of the same parameters. Our implementation is publicly available with the openSMILE toolkit. Comparative evaluations of the proposed feature set and large baseline feature sets of INTERSPEECH challenges show a high performance of the proposed set in relation to its size.","Speech,
Mel frequency cepstral coefficient,
Standards,
Harmonic analysis,
Licenses,
Frequency measurement"
Physical Layer Security in Heterogeneous Cellular Networks,"The heterogeneous cellular network (HCN) is a promising approach to the deployment of 5G cellular networks. This paper comprehensively studies physical layer security in a multitier HCN where base stations (BSs), authorized users, and eavesdroppers are all randomly located. We first propose an access threshold-based secrecy mobile association policy that associates each user with the BS providing the maximum truncated average received signal power beyond a threshold. Under the proposed policy, we investigate the connection probability and secrecy probability of a randomly located user and provide tractable expressions for the two metrics. Asymptotic analysis reveals that setting a larger access threshold increases the connection probability while decreases the secrecy probability. We further evaluate the network-wide secrecy throughput and the minimum secrecy throughput per user with both connection and secrecy probability constraints. We show that introducing a properly chosen access threshold significantly enhances the secrecy throughput performance of a HCN.",
Mixed-ADC Massive MIMO,"Motivated by the demand for energy-efficient communication solutions in the next generation cellular network, a mixed-ADC architecture for massive multiple-input-multiple-output (MIMO) systems is proposed, which differs from previous works in that herein one-bit analog-to-digital converters (ADCs) partially replace the conventionally assumed high-resolution ADCs. The information-theoretic tool of generalized mutual information (GMI) is exploited to analyze the achievable data rates of the proposed system architecture and an array of analytical results of engineering interest are obtained. For fixed single-input-multiple-output (SIMO) channels, a closed-form expression of the GMI is derived, based on which the linear combiner is optimized. The analysis is then extended to ergodic fading channels, for which tight lower and upper bounds of the GMI are obtained. Impacts of dithering and imperfect channel state information (CSI) are also investigated, and it is shown that dithering can remarkably improve the system performance while imperfect CSI only introduces a marginal rate loss. Finally, the analytical framework is applied to the multiuser access scenario. Numerical results demonstrate that the mixed-ADC architecture with a relatively small number of high-resolution ADCs is able to achieve a large fraction of the channel capacity of conventional architecture, while reduce the energy consumption considerably even compared with antenna selection, for both single-user and multiuser scenarios.","MIMO,
Antennas,
Hardware,
Fading channels,
Quantization (signal),
Receivers,
Mutual information"
Pinning Control for Synchronization of Coupled Reaction-Diffusion Neural Networks With Directed Topologies,"This paper proposes a directed complex dynamical network consisting of N linearly and diffusively coupled identical reaction-diffusion neural networks. Based on the Lyapunov functional method and the pinning control technique, some sufficient conditions are obtained to guarantee the synchronization of the proposed network model. In addition, an adaptive strategy is proposed to obtain appropriate coupling strength for achieving network synchronization. Furthermore, the pinning adaptive synchronization problem is also investigated in this paper, and a general criterion for ensuring network synchronization is established. Finally, a numerical example is provided to illustrate the effectiveness of the proposed criteria.",
LSDT: Latent Sparse Domain Transfer Learning for Visual Adaptation,"We propose a novel reconstruction-based transfer learning method called latent sparse domain transfer (LSDT) for domain adaptation and visual categorization of heterogeneous data. For handling cross-domain distribution mismatch, we advocate reconstructing the target domain data with the combined source and target domain data points based on ℓ1-norm sparse coding. Furthermore, we propose a joint learning model for simultaneous optimization of the sparse coding and the optimal subspace representation. In addition, we generalize the proposed LSDT model into a kernel-based linear/nonlinear basis transformation learning framework for tackling nonlinear subspace shifts in reproduced kernel Hilbert space. The proposed methods have three advantages: 1) the latent space and the reconstruction are jointly learned for pursuit of an optimal subspace transfer; 2) with the theory of sparse subspace clustering, a few valuable source and target data points are formulated to reconstruct the target data with noise (outliers) from source domain removed during domain adaptation, such that the robustness is guaranteed; and 3) a nonlinear projection of some latent space with kernel is easily generalized for dealing with highly nonlinear domain shift (e.g., face poses). Extensive experiments on several benchmark vision data sets demonstrate that the proposed approaches outperform other state-of-the-art representation-based domain adaptation methods.",
Hierarchical Codebook Design for Beamforming Training in Millimeter-Wave Communication,"In millimeter-wave communication, large antenna arrays are required to achieve high power gain by steering toward each other with narrow beams, which poses the problem to efficiently search the best beam direction in the angle domain at both Tx and Rx sides. As the exhaustive search is time consuming, hierarchical search has been widely accepted to reduce the complexity, and its performance is highly dependent on the codebook design. In this paper, we propose two basic criteria for the hierarchical codebook design, and devise an efficient hierarchical codebook by jointly exploiting sub-array and deactivation (turning-off) antenna processing techniques, where closed-form expressions are provided to generate the codebook. Performance evaluations are conducted under different system and channel models. Results show superiority of the proposed codebook over the existing alternatives.","Antenna arrays,
Array signal processing,
Transmitting antennas,
Wireless communication,
Radio frequency"
LSCD: A Low-Storage Clone Detection Protocol for Cyber-Physical Systems,"Cyber-physical systems (CPSs) have recently become an important research field not only because of their important and varied application scenarios, including transportation systems, smart homes, surveillance systems, and wearable devices but also because the fundamental infrastructure has yet to be well addressed. Wireless sensor networks (WSNs), as a type of supporting infrastructure, play an irreplaceable role in CPS design. Specifically, secure communication in WSNs is vital because information transferred in the networks can be easily stolen or replaced. Therefore, this paper presents a novel distributed low-storage clone detection protocol (LSCD) for WSNs. We first design a detection route along the perpendicular direction of a witness path with witness nodes deployed in a ring path. This ensures that the detection route must encounter the witness path because the distance between any two detection routes must be smaller than the witness path length. In the LSCD protocol, clone detection is processed in a nonhotspot region where a large amount of energy remains, which can improve energy efficiency as well as network lifetime. Extensive simulations demonstrate that the lifetime, storage requirements, and detection probability of our protocol are substantially improved over competing solutions from the literature.","Cloning,
Routing protocols,
Wireless sensor networks,
Security,
Base stations,
Robustness"
Wideband Spectrum Sensing on Real-Time Signals at Sub-Nyquist Sampling Rates in Single and Cooperative Multiple Nodes,"This paper presents two new algorithms for wideband spectrum sensing at sub-Nyquist sampling rates, for both single nodes and cooperative multiple nodes. In single-node spectrum sensing, a two-phase spectrum sensing algorithm based on compressive sensing is proposed to reduce the computational complexity and improve the robustness at secondary users (SUs). In the cooperative multiple nodes case, the signals received at SUs exhibit a sparsity property that yields a low-rank matrix of compressed measurements at the fusion center. This therefore leads to a two-phase cooperative spectrum sensing algorithm for cooperative multiple SUs based on low-rank matrix completion. In addition, the two proposed spectrum sensing algorithms are evaluated on the TV white space (TVWS), in which pioneering work aimed at enabling dynamic spectrum access into practice has been promoted by both the Federal Communications Commission and the U.K. Office of Communications. The proposed algorithms are tested on the real-time signals after they have been validated by the simulated signals in TVWS. The numerical results show that our proposed algorithms are more robust to channel noise and have lower computational complexity than the state-of-the-art algorithms.","Sensors,
Signal processing algorithms,
Wideband,
Cascading style sheets,
Computational complexity,
Robustness,
Algorithm design and analysis"
Finite-Time Consensus of Multiagent Systems With a Switching Protocol,"In this paper, we study the problem of finite-time consensus of multiagent systems on a fixed directed interaction graph with a new protocol. Existing finite-time consensus protocols can be divided into two types: 1) continuous and 2) discontinuous, which were studied separately in the past. In this paper, we deal with both continuous and discontinuous protocols simultaneously, and design a centralized switching consensus protocol such that the finite-time consensus can be realized in a fast speed. The switching protocol depends on the range of the initial disagreement of the agents, for which we derive an exact bound to indicate at what time a continuous or a discontinuous protocol should be selected to use. Finally, we provide two numerical examples to illustrate the superiority of the proposed protocol and design method.",
A Generalized Hopfield Network for Nonsmooth Constrained Convex Optimization: Lie Derivative Approach,"This paper proposes a generalized Hopfield network for solving general constrained convex optimization problems. First, the existence and the uniqueness of solutions to the generalized Hopfield network in the Filippov sense are proved. Then, the Lie derivative is introduced to analyze the stability of the network using a differential inclusion. The optimality of the solution to the nonsmooth constrained optimization problems is shown to be guaranteed by the enhanced Fritz John conditions. The convergence rate of the generalized Hopfield network can be estimated by the second-order derivative of the energy function. The effectiveness of the proposed network is evaluated on several typical nonsmooth optimization problems and used to solve the hierarchical and distributed model predictive control four-tank benchmark.",
Multihop-Cluster-Based IEEE 802.11p and LTE Hybrid Architecture for VANET Safety Message Dissemination,"Several vehicular ad hoc network (VANET) studies have focused on communication methods based on IEEE 802.11p, which forms the standard for wireless access for vehicular environments. In networks employing IEEE 802.11p only, the broadcast storm and disconnected network problems at high and low vehicle densities, respectively, degrade the delay and delivery ratio of safety message dissemination. Recently, as an alternative to the IEEE 802.11p-based VANET, the usage of cellular technologies has been investigated due to their low latency and wide-range communication. However, a pure cellular-based VANET communication is not feasible due to the high cost of communication between the vehicles and the base stations and the high number of handoff occurrences at the base station, considering the high mobility of the vehicles. This paper proposes a hybrid architecture, namely, VMaSC-LTE, combining IEEE 802.11p-based multihop clustering and the fourth-generation (4G) cellular system, i.e., Long-Term Evolution (LTE), with the goal of achieving a high data packet delivery ratio (DPDR) and low delay while keeping the usage of the cellular architecture at a minimum level. In VMaSC-LTE, vehicles are clustered based on a novel approach named Vehicular Multihop algorithm for Stable Clustering (VMaSC). The features of VMaSC are cluster head (CH) selection using the relative mobility metric calculated as the average relative speed with respect to the neighboring vehicles, cluster connection with minimum overhead by introducing a direct connection to the neighbor that is already a head or a member of a cluster instead of connecting to the CH in multiple hops, disseminating cluster member information within periodic hello packets, reactive clustering to maintain the cluster structure without excessive consumption of network resources, and efficient size- and hop-limited cluster merging mechanism based on the exchange of cluster information among CHs. These features decrease the number of CHs while increasing their stability, therefore minimizing the usage of the cellular architecture. From the clustered topology, elected CHs operate as dual-interface nodes with the functionality of the IEEE 802.11p and LTE interface to link the VANET to the LTE network. Using various key metrics of interest, including DPDR, delay, control overhead, and clustering stability, we demonstrate the superior performance of the proposed architecture compared with both previously proposed hybrid architectures and alternative routing mechanisms, including flooding and cluster-based routing via extensive simulations in ns-3 with the vehicle mobility input from the Simulation of Urban Mobility. The proposed architecture also allows achieving higher required reliability of the application quantified by the DPDR at the cost of higher LTE usage measured by the number of CHs in the network.","Vehicles,
Delays,
Vehicular ad hoc networks,
Safety,
Computer architecture,
Long Term Evolution"
Data-Assisted Low Complexity Compressive Spectrum Sensing on Real-Time Signals Under Sub-Nyquist Rate,"In this paper, we present a novel hybrid framework combining compressive spectrum sensing with geo-location database to find spectrum holes in a decentralized cognitive radio. In the hybrid framework, a geo-location database algorithm is proposed to be stored locally at secondary users (SUs) to remove the extra transmission link to a centralized remote geo-location database. Specifically, by utilizing the output of the locally stored geo-location database algorithm, a data-assisted noniteratively reweighted least squares (DNRLS)-based compressive spectrum sensing algorithm is proposed to improve detection performance under sub-Nyquist sampling rates for wideband spectrum sensing, and to reduce the computational complexity of signal recovery. In addition, an efficient method for the calculation of maximum allowable equivalent isotropic radiated power in TV white space (TVWS) is also designed to further support SUs. The convergence and complexity of the proposed DNRLS algorithm are analyzed theoretically. Furthermore, the proposed framework is pioneered on real-time “from air” signals and data after having been validated by simulated signals and data in TVWS.",
Exact Recovery in the Stochastic Block Model,"The stochastic block model with two communities, or equivalently the planted bisection model, is a popular model of random graph exhibiting a cluster behavior. In the symmetric case, the graph has two equally sized clusters and vertices connect with probability p within clusters and q across clusters. In the past two decades, a large body of literature in statistics and computer science has focused on providing lower bounds on the scaling of | p - q| to ensure exact recovery. In this paper, we identify a sharp threshold phenomenon for exact recovery: if α = pn/log(n) and β = qn/ log(n) are constant (with α > β), recovering the communities with high probability is possible if (α + β/2) - √(αβ) > 1 and is impossible if (α + β/2) - √(αβ) <; 1. In particular, this improves the existing bounds. This also sets a new line of sight for efficient clustering algorithms. While maximum likelihood (ML) achieves the optimal threshold (by definition), it is in the worst case NP-hard. This paper proposes an efficient algorithm based on a semidefinite programming relaxation of ML, which is proved to succeed in recovering the communities close to the threshold, while numerical experiments suggest that it may achieve the threshold. An efficient algorithm that succeeds all the way down to the threshold is also obtained using a partial recovery algorithm combined with a local improvement procedure.","Stochastic processes,
Clustering algorithms,
Maximum likelihood decoding,
Computational modeling,
Machine learning algorithms,
Maximum likelihood estimation,
Computer science"
Dynamic Channel Access to Improve Energy Efficiency in Cognitive Radio Sensor Networks,"Wireless sensor networks operating in the license-free spectrum suffer from uncontrolled interference as those spectrum bands become increasingly crowded. The emerging cognitive radio sensor networks (CRSNs) provide a promising solution to address this challenge by enabling sensor nodes to opportunistically access licensed channels. However, since sensor nodes have to consume considerable energy to support CR functionalities, such as channel sensing and switching, the opportunistic channel accessing should be carefully devised for improving the energy efficiency in CRSN. To this end, we investigate the dynamic channel accessing problem to improve the energy efficiency for a clustered CRSN. Under the primary users' protection requirement, we study the resource allocation issues to maximize the energy efficiency of utilizing a licensed channel for intra-cluster and inter-cluster data transmission, respectively. Moreover, with the consideration of the energy consumption in channel sensing and switching, we further determine the condition when sensor nodes should sense and switch to a licensed channel for improving the energy efficiency, according to the packet loss rate of the license-free channel. In addition, two dynamic channel accessing schemes are proposed to identify the channel sensing and switching sequences for intra-cluster and inter-cluster data transmission, respectively. Extensive simulation results demonstrate that the proposed channel accessing schemes can significantly reduce the energy consumption in CRSNs.",
Multi-Modal Clique-Graph Matching for View-Based 3D Model Retrieval,"Multi-view matching is an important but a challenging task in view-based 3D model retrieval. To address this challenge, we propose an original multi-modal clique graph (MCG) matching method in this paper. We systematically present a method for MCG generation that is composed of cliques, which consist of neighbor nodes in multi-modal feature space and hyper-edges that link pairwise cliques. Moreover, we propose an image set-based clique/edgewise similarity measure to address the issue of the set-to-set distance measure, which is the core problem in MCG matching. The proposed MCG provides the following benefits: 1) preserves the local and global attributes of a graph with the designed structure; 2) eliminates redundant and noisy information by strengthening inliers while suppressing outliers; and 3) avoids the difficulty of defining high-order attributes and solving hyper-graph matching. We validate the MCG-based 3D model retrieval using three popular single-modal data sets and one novel multi-modal data set. Extensive experiments show the superiority of the proposed method through comparisons. Moreover, we contribute a novel real-world 3D object data set, the multi-view RGB-D object data set. To the best of our knowledge, it is the largest real-world 3D object data set containing multi-modal and multi-view information.",
Joint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks,"Face detection and alignment in unconstrained environment are challenging due to various poses, illuminations, and occlusions. Recent studies show that deep learning approaches can achieve impressive performance on these two tasks. In this letter, we propose a deep cascaded multitask framework that exploits the inherent correlation between detection and alignment to boost up their performance. In particular, our framework leverages a cascaded architecture with three stages of carefully designed deep convolutional networks to predict face and landmark location in a coarse-to-fine manner. In addition, we propose a new online hard sample mining strategy that further improves the performance in practice. Our method achieves superior accuracy over the state-of-the-art techniques on the challenging face detection dataset and benchmark and WIDER FACE benchmarks for face detection, and annotated facial landmarks in the wild benchmark for face alignment, while keeps real-time performance.","Face,
Face detection,
Training,
Convolution,
Detectors,
Computer architecture,
Benchmark testing"
Personalized Travel Package With Multi-Point-of-Interest Recommendation Based on Crowdsourced User Footprints,"Location-based social networks (LBSNs) provide people with an interface to share their locations and write reviews about interesting places of attraction. The shared locations form the crowdsourced digital footprints, in which each user has many connections to many locations, indicating user preference to locations. In this paper, we propose an approach for personalized travel package recommendation to help users make travel plans. The approach utilizes data collected from LBSNs to model users and locations, and it determines users' preferred destinations using collaborative filtering approaches. Recommendations are generated by jointly considering user preference and spatiotemporal constraints. A heuristic search-based travel route planning algorithm was designed to generate travel packages. We developed a prototype system, which obtains users' travel demands from mobile client and generates travel packages containing multiple points of interest and their visiting sequence. Experimental results suggest that the proposed approach shows promise with respect to improving recommendation accuracy and diversity.","Trajectory,
Poles and towers,
Planning,
Entertainment industry,
Man machine systems,
Urban areas"
Hyperspectral Image Classification via Multitask Joint Sparse Representation and Stepwise MRF Optimization,"Hyperspectral image (HSI) classification is a crucial issue in remote sensing. Accurate classification benefits a large number of applications such as land use analysis and marine resource utilization. But high data correlation brings difficulty to reliable classification, especially for HSI with abundant spectral information. Furthermore, the traditional methods often fail to well consider the spatial coherency of HSI that also limits the classification performance. To address these inherent obstacles, a novel spectral-spatial classification scheme is proposed in this paper. The proposed method mainly focuses on multitask joint sparse representation (MJSR) and a stepwise Markov random filed framework, which are claimed to be two main contributions in this procedure. First, the MJSR not only reduces the spectral redundancy, but also retains necessary correlation in spectral field during classification. Second, the stepwise optimization further explores the spatial correlation that significantly enhances the classification accuracy and robustness. As far as several universal quality evaluation indexes are concerned, the experimental results on Indian Pines and Pavia University demonstrate the superiority of our method compared with the state-of-the-art competitors.","Optimization,
Feature extraction,
Correlation,
Joints,
Hyperspectral imaging,
Markov processes,
Cybernetics"
Neural Network-Based Event-Triggered State Feedback Control of Nonlinear Continuous-Time Systems,"This paper presents a novel approximation-based event-triggered control of multi-input multi-output uncertain nonlinear continuous-time systems in affine form. The controller is approximated using a linearly parameterized neural network (NN) in the context of event-based sampling. After revisiting the NN approximation property in the context of event-based sampling, an event-triggered condition is proposed using the Lyapunov technique to reduce the network resource utilization and to generate the required number of events for the NN approximation. In addition, a novel weight update law for aperiodic tuning of the NN weights at triggered instants is proposed to relax the knowledge of complete system dynamics and to reduce the computation when compared with the traditional NN-based control. Nonetheless, a nonzero positive lower bound for the inter-event times is guaranteed to avoid the accumulation of events or Zeno behavior. For analyzing the stability, the event-triggered system is modeled as a nonlinear impulsive dynamical system and the Lyapunov technique is used to show local ultimate boundedness of all signals. Furthermore, in order to overcome the unnecessary triggered events when the system states are inside the ultimate bound, a dead-zone operator is used to reset the event-trigger errors to zero. Finally, the analytical design is substantiated with numerical results.","Artificial neural networks,
Function approximation,
Stability analysis,
Context,
Nonlinear dynamical systems,
Numerical stability"
Mobile Target Detection in Wireless Sensor Networks With Adjustable Sensing Frequency,"How to sense and monitor the environment with high quality is an important research subject in the Internet of Things (IOT). This paper deals with the important issue of the balance between the quality of target detection and lifetime in wireless sensor networks. Two target-monitoring schemes are proposed. One scheme is Target Detection with Sensing Frequency K (TDSFK), which distributes the sensing time that currently is only on a portion of the sensing period into the entire sensing period. That is, the sensing frequency increases from 1 to K. The other scheme is Target Detection with Adjustable Sensing Frequency (TDASF), which adjusts the sensing frequency on those nodes that have residual energy. The simulation results show that the TDASF scheme can improve the network lifetime by more than 17.4% and can reduce the weighted detection delay by more than 101.6%.",
Photovoltaic Hot-Spot Detection for Solar Panel Substrings Using AC Parameter Characterization,"Hot spotting is a problem in photovoltaic (PV) systems that reduces panel power performance and accelerates cell degradation. In present day systems, bypass diodes are used to mitigate hot spotting, but it does not prevent hot spotting or the damage it causes. This paper presents an active hot-spot detection method to detect hot spotting within a series of PV cells, using ac parameter characterization. A PV cell is comprised of series and parallel resistances and parallel capacitance, which are affected by voltage bias, illumination, and temperature. Experimental results have shown that when a PV string is under a maximum power point tracking control, hot spotting in a single cell results in a capacitance increase and dc impedance increase. The capacitance change is detectable by measuring the ac impedance magnitude in the 10-70 kHz frequency range. An impedance value change due to hot spotting can be detected by monitoring one high-frequency measurement in the capacitive region and one low-frequency measurement in the dc impedance region. Alternatively, the dc impedance can also be calculated using dc operating point measurements. The proposed hot-spot detection method can be integrated into a dc-dc power converter that operates at the panel or subpanel level.","Capacitance,
Impedance,
Resistance,
Lighting,
Impedance measurement,
Temperature measurement,
Integrated circuit modeling"
Towards efficient content-aware search over encrypted outsourced data in cloud,"With the increasing adoption of cloud computing, a growing number of users outsource their datasets into cloud. The datasets usually are encrypted before outsourcing to preserve the privacy. However, the common practice of encryption makes the effective utilization difficult, for example, search the given keywords in the encrypted datasets. Many schemes are proposed to make encrypted data searchable based on keywords. However, keyword-based search schemes ignore the semantic representation information of users retrieval, and cannot completely meet with users search intention. Therefore, how to design a content-based search scheme and make semantic search more effective and context-aware is a difficult challenge. In this paper, we proposed an innovative semantic search scheme based on the concept hierarchy and the semantic relationship between concepts in the encrypted datasets. More specifically, our scheme first indexes the documents and builds trapdoor based on the concept hierarchy. To further improve the search efficiency, we utilize a tree-based index structure to organize all the document index vectors. Our experiment results based on the real world datasets show the scheme is more efficient than previous scheme. We also study the threat model of our approach and prove it does not introduce any security risk.","Semantics,
Indexes,
Cryptography,
Feature extraction,
Cloud computing,
Servers,
Computers"
On the Achievable Rate of OFDM With Index Modulation,"Orthogonal frequency division multiplexing with index modulation (OFDM-IM) is a recently developed transmission technique that extends the principle of spatial modulation to OFDM subcarriers. In this paper, the performance of OFDM-IM is studied in terms of the achievable rate assuming an M-ary constellation and that channel state information is available at the receiver. A closed-form lower bound is derived, based on which an interleaved grouping method is proposed for the use of subcarriers. In comparison with the existing grouping method, the proposed one can better benefit from the diversity effects over frequency-selective fading channels, especially when the spacing of any two subcarriers within a subcarrier group is larger than the coherence bandwidth. Through numerical results, it is revealed that OFDM-IM with interleaved grouping outperforms classical OFDM for small M and certain ranges of signal-to-noise ratio. Finally, the effects of modulation types on the performance of OFDM-IM are studied. It is found that the superiority of OFDM-IM over classical OFDM is greater for phase-shift keying than for quadrature amplitude modulation.","OFDM,
Modulation,
Indexes,
Transmitting antennas,
Receivers,
Signal to noise ratio,
Electronic mail"
A Unified Approach to Adaptive Neural Control for Nonlinear Discrete-Time Systems With Nonlinear Dead-Zone Input,"In this paper, an effective adaptive control approach is constructed to stabilize a class of nonlinear discrete-time systems, which contain unknown functions, unknown dead-zone input, and unknown control direction. Different from linear dead zone, the dead zone, in this paper, is a kind of nonlinear dead zone. To overcome the noncausal problem, which leads to the control scheme infeasible, the systems can be transformed into a
m
-step-ahead predictor. Due to nonlinear dead-zone appearance, the transformed predictor still contains the nonaffine function. In addition, it is assumed that the gain function of dead-zone input and the control direction are unknown. These conditions bring about the difficulties and the complicacy in the controller design. Thus, the implicit function theorem is applied to deal with nonaffine dead-zone appearance, the problem caused by the unknown control direction can be resolved through applying the discrete Nussbaum gain, and the neural networks are used to approximate the unknown function. Based on the Lyapunov theory, all the signals of the resulting closed-loop system are proved to be semiglobal uniformly ultimately bounded. Moreover, the tracking error is proved to be regulated to a small neighborhood around zero. The feasibility of the proposed approach is demonstrated by a simulation example.","Discrete-time systems,
Control systems,
Nonlinear systems,
Artificial neural networks,
Approximation methods,
Adaptive control"
Deep Dynamic Neural Networks for Multimodal Gesture Segmentation and Recognition,"This paper describes a novel method called Deep Dynamic Neural Networks (DDNN) for multimodal gesture recognition. A semi-supervised hierarchical dynamic framework based on a Hidden Markov Model (HMM) is proposed for simultaneous gesture segmentation and recognition where skeleton joint information, depth and RGB images, are the multimodal input observations. Unlike most traditional approaches that rely on the construction of complex handcrafted features, our approach learns high-level spatiotemporal representations using deep neural networks suited to the input modality: a Gaussian-Bernouilli Deep Belief Network (DBN) to handle skeletal dynamics, and a 3D Convolutional Neural Network (3DCNN) to manage and fuse batches of depth and RGB images. This is achieved through the modeling and learning of the emission probabilities of the HMM required to infer the gesture sequence. This purely data driven approach achieves a Jaccard index score of 0.81 in the ChaLearn LAP gesture spotting challenge. The performance is on par with a variety of state-of-the-art hand-tuned feature-based approaches and other learning-based methods, therefore opening the door to the use of deep learning techniques in order to further explore multimodal time series data.",
Exploiting Caching and Multicast for 5G Wireless Networks,"The landscape toward 5G wireless communication is currently unclear, and, despite the efforts of academia and industry in evolving traditional cellular networks, the enabling technology for 5G is still obscure. This paper puts forward a network paradigm toward next-generation cellular networks, targeting to satisfy the explosive demand for mobile data while minimizing energy expenditures. The paradigm builds on two principles; namely caching and multicast. On one hand, caching policies disperse popular content files at the wireless edge, e.g., pico-cells and femto-cells, hence shortening the distance between content and requester. On other hand, due to the broadcast nature of wireless medium, requests for identical files occurring at nearby times are aggregated and served through a common multicast stream. To better exploit the available cache space, caching policies are optimized based on multicast transmissions. We show that the multicast-aware caching problem is NP-hard and develop solutions with performance guarantees using randomized-rounding techniques. Trace-driven numerical results show that in the presence of massive demand for delay tolerant content, combining caching and multicast can indeed reduce energy costs. The gains over existing caching schemes are 19% when users tolerate delay of three minutes, increasing further with the steepness of content access pattern.",
Adaptive Neural Control of a Class of Output-Constrained Nonaffine Systems,"In this paper, we present a novel tracking controller for a class of uncertain nonaffine systems with time-varying asymmetric output constraints. Firstly, the original nonaffine constrained (in the sense of the output signal) control system is transformed into a output-feedback control problem of an unconstrained affine system in normal form. As a result, stabilization of the transformed system is sufficient to ensure constraint satisfaction. It is subsequently shown that the output tracking is achieved without violation of the predefined asymmetric time-varying output constraints. Therefore, we are capable of quantifying the system performance bounds as functions of time on both transient and steady-state stages. Furthermore, the transformed system is linear with respect to a new input signal and the traditional backstepping scheme is avoided, which makes the synthesis extremely simplified. All the signals in the closed-loop system are proved to be semi-globally, uniformly, and ultimately bounded via Lyapunov synthesis. Finally, the simulation results are presented to illustrate the performance of the proposed controller.","Artificial neural networks,
Observers,
Vectors,
Adaptive systems,
Control systems,
Time-varying systems"
Energy-Aware Traffic Offloading for Green Heterogeneous Networks,"With small cell base stations (SBSs) densely deployed in addition to conventional macro base stations (MBSs), the heterogeneous cellular network (HCN) architecture can effectively boost network capacity. To support the huge power demand of HCNs, renewable energy harvesting technologies can be leveraged. In this paper, we aim to make efficient use of the harvested energy for on-grid power saving while satisfying the quality of service (QoS) requirement. To this end, energy-aware traffic offloading schemes are proposed, whereby user associations, ON-OFF states of SBSs, and power control are jointly optimized according to the statistical information of energy arrival and traffic load. Specifically, for the single SBS case, the power saving gain achieved by activating the SBS is derived in closed form, based on which the SBS activation condition and optimal traffic offloading amount are obtained. Furthermore, a two-stage energy-aware traffic offloading (TEATO) scheme is proposed for the multiple-SBS case, considering various operating characteristics of SBSs with different power sources. Simulation results demonstrate that the proposed scheme can achieve more than 50% power saving gain for typical daily traffic and solar energy profiles, compared with the conventional traffic offloading schemes.",
Change Detection in Synthetic Aperture Radar Images Based on Deep Neural Networks,"This paper presents a novel change detection approach for synthetic aperture radar images based on deep learning. The approach accomplishes the detection of the changed and unchanged areas by designing a deep neural network. The main guideline is to produce a change detection map directly from two images with the trained deep neural network. The method can omit the process of generating a difference image (DI) that shows difference degrees between multitemporal synthetic aperture radar images. Thus, it can avoid the effect of the DI on the change detection results. The learning algorithm for deep architectures includes unsupervised feature learning and supervised fine-tuning to complete classification. The unsupervised feature learning aims at learning the representation of the relationships between the two images. In addition, the supervised fine-tuning aims at learning the concepts of the changed and unchanged pixels. Experiments on real data sets and theoretical analysis indicate the advantages, feasibility, and potential of the proposed method. Moreover, based on the results achieved by various traditional algorithms, respectively, deep learning can further improve the detection performance.","Neural networks,
Synthetic aperture radar,
Change detection algorithms,
Algorithm design and analysis,
Noise,
Training,
Joints"
EEG Source Imaging Enhances the Decoding of Complex Right-Hand Motor Imagery Tasks,"Goal: Sensorimotor-based brain-computer interfaces (BCIs) have achieved successful control of real and virtual devices in up to three dimensions; however, the traditional sensor-based paradigm limits the intuitive use of these systems. Many control signals for state-of-the-art BCIs involve imagining the movement of body parts that have little to do with the output command, revealing a cognitive disconnection between the user's intent and the action of the end effector. Therefore, there is a need to develop techniques that can identify with high spatial resolution the self-modulated neural activity reflective of the actions of a helpful output device. Methods: We extend previous EEG source imaging (ESI) work to decoding natural hand/wrist manipulations by applying a novel technique to classifying four complex motor imaginations of the right hand: flexion, extension, supination, and pronation. Results: We report an increase of up to 18.6% for individual task classification and 12.7% for overall classification using the proposed ESI approach over the traditional sensor-based method. Conclusion: ESI is able to enhance BCI performance of decoding complex right-hand motor imagery tasks. Significance: This study may lead to the development of BCI systems with naturalistic and intuitive motor imaginations, thus facilitating broad use of noninvasive BCIs.",
Facial Image Hallucination Through Coupled-Layer Neighbor Embedding,"As the facial image captured by a low-cost camera is typically very low resolution (LR), blurring, and noisy, traditional neighbor-embedding-based facial image hallucination methods from one single manifold (i.e., the LR image manifold) fail to reliably estimate the intention geometrical structure, consequently leading to a bias to the image reconstruction result. In this paper, we introduce the notion of neighbor embedding (NE) from the LR and the high-resolution (HR) image manifolds simultaneously and propose a novel NE model, termed the coupled-layer NE (CLNE), for facial image hallucination. CLNE differs substantially from other NE models in that it has two layers: the LR and the HR layers. The LR layer in this model is the local geometrical structure of the LR patch manifold, which is characterized by the reconstruction weights of the LR patches; the HR layer is the intrinsic geometry that can geometrically constrain the reconstruction weights. With this coupled-constraint paradigm between the adaptation of the LR layer and the HR one, CLNE can achieve a more robust NE through iteratively updating the LR patch reconstruction weights and the estimated HR patch. The experimental results in simulation and real conditions confirm that the proposed method outperforms the related state-of-the-art methods in both quantitative and visual comparisons.","Manifolds,
Face,
Image reconstruction,
Image resolution,
Training,
Linear programming,
Geometry"
Anticipating Human Activities Using Object Affordances for Reactive Robotic Response,"An important aspect of human perception is anticipation, which we use extensively in our day-to-day activities when interacting with other humans as well as with our surroundings. Anticipating which activities will a human do next (and how) can enable an assistive robot to plan ahead for reactive responses. Furthermore, anticipation can even improve the detection accuracy of past activities. The challenge, however, is two-fold: We need to capture the rich context for modeling the activities and object affordances, and we need to anticipate the distribution over a large space of future human activities. In this work, we represent each possible future using an anticipatory temporal conditional random field (ATCRF) that models the rich spatial-temporal relations through object affordances. We then consider each ATCRF as a particle and represent the distribution over the potential futures using a set of particles. In extensive evaluation on CAD-120 human activity RGB-D dataset, we first show that anticipation improves the state-of-the-art detection results. We then show that for new subjects (not seen in the training set), we obtain an activity anticipation accuracy (defined as whether one of top three predictions actually happened) of 84.1, 74.4 and 62.2 percent for an anticipation time of 1, 3 and 10 seconds respectively. Finally, we also show a robot using our algorithm for performing a few reactive responses.","Trajectory,
Robots,
Videos,
Heating,
Hidden Markov models,
Context,
Context modeling"
The GRASP Taxonomy of Human Grasp Types,"In this paper, we analyze and compare existing human grasp taxonomies and synthesize them into a single new taxonomy (dubbed “The GRASP Taxonomy” after the GRASP project funded by the European Commission). We consider only static and stable grasps performed by one hand. The goal is to extract the largest set of different grasps that were referenced in the literature and arrange them in a systematic way. The taxonomy provides a common terminology to define human hand configurations and is important in many domains such as human-computer interaction and tangible user interfaces where an understanding of the human is basis for a proper interface. Overall, 33 different grasp types are found and arranged into the GRASP taxonomy. Within the taxonomy, grasps are arranged according to 1) opposition type, 2) the virtual finger assignments, 3) type in terms of power, precision, or intermediate grasp, and 4) the position of the thumb. The resulting taxonomy incorporates all grasps found in the reviewed taxonomies that complied with the grasp definition. We also show that due to the nature of the classification, the 33 grasp types might be reduced to a set of 17 more general grasps if only the hand configuration is considered without the object shape/size.","Taxonomy,
Thumb,
Force,
Robots,
Grasping,
Shape,
Man machine systems"
Unmanned Aerial Vehicle With Underlaid Device-to-Device Communications: Performance and Tradeoffs,"In this paper, the deployment of an unmanned aerial vehicle (UAV) as a flying base station used to provide the fly wireless communications to a given geographical area is analyzed. In particular, the coexistence between the UAV, that is transmitting data in the downlink, and an underlaid device-to-device (D2D) communication network is considered. For this model, a tractable analytical framework for the coverage and rate analysis is derived. Two scenarios are considered: a static UAV and a mobile UAV. In the first scenario, the average coverage probability and the system sum-rate for the users in the area are derived as a function of the UAV altitude and the number of D2D users. In the second scenario, using the disk covering problem, the minimum number of stop points that the UAV needs to visit in order to completely cover the area is computed. Furthermore, considering multiple retransmissions for the UAV and D2D users, the overall outage probability of the D2D users is derived. Simulation and analytical results show that, depending on the density of D2D users, the optimal values for the UAV altitude, which lead to the maximum system sum-rate and coverage probability, exist. Moreover, our results also show that, by enabling the UAV to intelligently move over the target area, the total required transmit power of UAV while covering the entire area, can be minimized. Finally, in order to provide full coverage for the area of interest, the tradeoff between the coverage and delay, in terms of the number of stop points, is discussed.",
Vehicular Fog Computing: A Viewpoint of Vehicles as the Infrastructures,"With the emergence of ever-growing advanced vehicular applications, the challenges to meet the demands from both communication and computation are increasingly prominent. Without powerful communication and computational support, various vehicular applications and services will still stay in the concept phase and cannot be put into practice in the daily life. Thus, solving this problem is of great importance. The existing solutions, such as cellular networks, roadside units (RSUs), and mobile cloud computing, are far from perfect because they highly depend on and bear the cost of additional infrastructure deployment. Given tremendous number of vehicles in urban areas, putting these underutilized vehicular resources into use offers great opportunity and value. Therefore, we conceive the idea of utilizing vehicles as the infrastructures for communication and computation, named vehicular fog computing (VFC), which is an architecture that utilizes a collaborative multitude of end-user clients or near-user edge devices to carry out communication and computation, based on better utilization of individual communication and computational resources of each vehicle. By aggregating abundant resources of individual vehicles, the quality of services and applications can be enhanced greatly. In particular, by discussing four types of scenarios of moving and parked vehicles as the communication and computational infrastructures, we carry on a quantitative analysis of the capacities of VFC. We unveil an interesting relationship among the communication capability, connectivity, and mobility of vehicles, and we also find out the characteristics about the pattern of parking behavior, which benefits from the understanding of utilizing the vehicular resources. Finally, we discuss the challenges and open problems in implementing the proposed VFC system as the infrastructures. Our study provides insights for this novel promising paradigm, as well as research topics about vehicular information infrastructures.","Vehicles,
Cloud computing,
Computer architecture,
Mobile communication,
Mobile computing,
Real-time systems,
Urban areas"
Curve-Like Structure Extraction Using Minimal Path Propagation With Backtracking,"Minimal path techniques can efficiently extract geometrically curve-like structures by finding the path with minimal accumulated cost between two given endpoints. Though having found wide practical applications (e.g., line identification, crack detection, and vascular centerline extraction), minimal path techniques suffer from some notable problems. The first one is that they require setting two endpoints for each line to be extracted (endpoint problem). The second one is that the connection might fail when the geodesic distance between the two points is much shorter than the desirable minimal path (shortcut problem). In addition, when connecting two distant points, the minimal path connection might become inefficient as the accumulated cost increases over the propagation and results in leakage into some non-feature regions near the starting point (accumulation problem). To address these problems, this paper proposes an approach termed minimal path propagation with backtracking. We found that the information in the process of backtracking from reached points can be well utilized to overcome the above problems and improve the extraction performance. The whole algorithm is robust to parameter setting and allows a coarse setting of the starting point. Extensive experiments with both simulated and realistic data are performed to validate the performance of the proposed method.",
Multi-Instance Deep Learning: Discover Discriminative Local Anatomies for Bodypart Recognition,"In general image recognition problems, discriminative information often lies in local image patches. For example, most human identity information exists in the image patches containing human faces. The same situation stays in medical images as well. “Bodypart identity” of a transversal slice-which bodypart the slice comes from-is often indicated by local image information, e.g., a cardiac slice and an aorta arch slice are only differentiated by the mediastinum region. In this work, we design a multi-stage deep learning framework for image classification and apply it on bodypart recognition. Specifically, the proposed framework aims at: 1) discover the local regions that are discriminative and non-informative to the image classification problem, and 2) learn a image-level classifier based on these local regions. We achieve these two tasks by the two stages of learning scheme, respectively. In the pre-train stage, a convolutional neural network (CNN) is learned in a multi-instance learning fashion to extract the most discriminative and and non-informative local patches from the training slices. In the boosting stage, the pre-learned CNN is further boosted by these local patches for image classification. The CNN learned by exploiting the discriminative local appearances becomes more accurate than those learned from global image context. The key hallmark of our method is that it automatically discovers the discriminative and non-informative local patches through multi-instance deep learning. Thus, no manual annotation is required. Our method is validated on a synthetic dataset and a large scale CT dataset. It achieves better performances than state-of-the-art approaches, including the standard deep CNN.","Image recognition,
Algorithm design and analysis,
Machine learning,
Three-dimensional displays,
Image analysis,
DICOM"
Bidding Strategy for Microgrid in Day-Ahead Market Based on Hybrid Stochastic/Robust Optimization,"This paper proposes an optimal bidding strategy in the day-ahead market of a microgrid consisting of intermittent distributed generation (DG), storage, dispatchable DG, and price responsive loads. The microgrid coordinates the energy consumption or production of its components, and trades electricity in both day-ahead and real-time markets to minimize its operating cost as a single entity. The bidding problem is challenging due to a variety of uncertainties, including power output of intermittent DG, load variation, and day-ahead and real-time market prices. A hybrid stochastic/robust optimization model is proposed to minimize the expected net cost, i.e., expected total cost of operation minus total benefit of demand. This formulation can be solved by mixed-integer linear programming. The uncertain output of intermittent DG and day-ahead market price are modeled via scenarios based on forecast results, while a robust optimization is proposed to limit the unbalanced power in real-time market taking account of the uncertainty of real-time market price. Numerical simulations on a microgrid consisting of a wind turbine, a photovoltaic panel, a fuel cell, a micro-turbine, a diesel generator, a battery, and a responsive load show the advantage of stochastic optimization, as well as robust optimization.","Real-time systems,
Microgrids,
Optimization,
Robustness,
Stochastic processes,
Batteries,
Uncertainty"
Secure Massive MIMO Transmission With an Active Eavesdropper,"In this paper, we investigate secure and reliable transmission strategies for multi-cell multi-user massive multiple-input multiple-output systems with a multi-antenna active eavesdropper. We consider a time-division duplex system where uplink training is required and an active eavesdropper can attack the training phase to cause pilot contamination at the transmitter. This forces the precoder used in the subsequent downlink transmission phase to implicitly beamform toward the eavesdropper, thus increasing its received signal power. Assuming matched filter precoding and artificial noise (AN) generation at the transmitter, we derive an asymptotic achievable secrecy rate when the number of transmit antennas approaches infinity. For the case of a single-antenna active eavesdropper, we obtain a closed-form expression for the optimal power allocation policy for the transmit signal and the AN, and find the minimum transmit power required to ensure reliable secure communication. Furthermore, we show that the transmit antenna correlation diversity of the intended users and the eavesdropper can be exploited in order to improve the secrecy rate. In fact, under certain orthogonality conditions of the channel covariance matrices, the secrecy rate loss introduced by the eavesdropper can be completely mitigated.",
Software-Defined Device-to-Device (D2D) Communications in Virtual Wireless Networks With Imperfect Network State Information (NSI),"Software-defined networking (SDN) and network function virtualization (NFV) are a promising system architecture and control mechanism for future networks. Although some works have been done on wireless SDN and NFV, recent advancements in device-to-device (D2D) communications are largely ignored in this novel framework. In this paper, we study the integration of D2D communication in the framework of SDN and NFV. An inherent challenge in supporting software-defined D2D is the imperfectness of network state information, including channel state information (CSI) and queuing state information, in virtual wireless (QSI) networks. To address this challenge, we formulate the resource sharing problem in this framework as a discrete stochastic optimization problem and develop discrete stochastic approximation algorithms to solve this problem. Such algorithms can reduce the computational complexity compared with exhaustive search while achieving satisfactory performance. Both the static wireless channel and time-varying channels are considered. Extensive simulations show that users can benefit from both wireless network virtualization and software-defined D2D communications, and our proposed scheme can achieve considerable performance gains in both system throughput and user utility under practical network settings.","Wireless networks,
Resource management,
Indium phosphide,
III-V semiconductor materials,
Software,
Approximation algorithms"
Global Exponential Stability for Complex-Valued Recurrent Neural Networks With Asynchronous Time Delays,"In this paper, we investigate the global exponential stability for complex-valued recurrent neural networks with asynchronous time delays by decomposing complex-valued networks to real and imaginary parts and construct an equivalent real-valued system. The network model is described by a continuous-time equation. There are two main differences of this paper with previous works: 1) time delays can be asynchronous, i.e., delays between different nodes are different, which make our model more general and 2) we prove the exponential convergence directly, while the existence and uniqueness of the equilibrium point is just a direct consequence of the exponential convergence. Using three generalized norms, we present some sufficient conditions for the uniqueness and global exponential stability of the equilibrium point for delayed complex-valued neural networks. These conditions in our results are less restrictive because of our consideration of the excitatory and inhibitory effects between neurons; so previous works of other researchers can be extended. Finally, some numerical simulations are given to demonstrate the correctness of our obtained results.","Delay effects,
Artificial neural networks,
Stability criteria,
Delays,
Numerical stability,
Asymptotic stability"
A Framework for Structural Input/Output and Control Configuration Selection in Large-Scale Systems,"This paper addresses problems on the structural design of large-scale control systems. An efficient and unified framework is proposed to select the minimum number of manipulated/measured variables to achieve structural controllability/observability of the system, and to select the minimum number of feedback interconnections between measured and manipulated variables such that the closed-loop system has no structural fixed modes. Global solutions are computed using polynomial complexity algorithms in the number of the state variables of the system. Finally, graph-theoretic characterizations are proposed, which allow a characterization of all possible solutions.",
Demand Response Management in the Smart Grid in a Large Population Regime,"In this paper, we introduce a hierarchical system model that captures the decision making processes involved in a network of multiple providers and a large number of consumers in the smart grid, incorporating multiple processes from power generation to market activities and to power consumption. We establish a Stackelberg game between providers and end users, where the providers behave as leaders maximizing their profit and end users act as the followers maximizing their individual welfare. We obtain closed-form expressions for the Stackelberg equilibrium of the game and prove that a unique equilibrium solution exists. In the large population regime, we show that a higher number of providers help to improve profits for the providers. This is inline with the goal of facilitating multiple distributed power generation units, one of the main design considerations in the smart grid. We further prove that there exist a unique number of providers that maximize their profits, and develop an iterative and distributed algorithm to obtain it. Finally, we provide numerical examples to illustrate the solutions and to corroborate the results.",
A Survey on Software Fault Localization,"Software fault localization, the act of identifying the locations of faults in a program, is widely recognized to be one of the most tedious, time consuming, and expensive - yet equally critical - activities in program debugging. Due to the increasing scale and complexity of software today, manually locating faults when failures occur is rapidly becoming infeasible, and consequently, there is a strong demand for techniques that can guide software developers to the locations of faults in a program with minimal human intervention. This demand in turn has fueled the proposal and development of a broad spectrum of fault localization techniques, each of which aims to streamline the fault localization process and make it more effective by attacking the problem in a unique way. In this article, we catalog and provide a comprehensive overview of such techniques and discuss key issues and concerns that are pertinent to software fault localization as a whole.","Debugging,
Software engineering,
Computer bugs,
Software debugging,
Fault diagnosis,
Complexity theory"
Joint Downlink Cell Association and Bandwidth Allocation for Wireless Backhauling in Two-Tier HetNets With Large-Scale Antenna Arrays,"The problem of joint downlink cell association (CA) and wireless backhaul bandwidth allocation (WBBA) in two-tier cellular heterogeneous networks (HetNets) is investigated. Large-scale antenna array is implemented at the macro base station (BS), while the small cells within the macro cell range are single-antenna BSs and they rely on over-the-air links to the macro BS for backhauling. A sum logarithmic user rate maximization problem is studied under the wireless backhaul constraints. Duplex and spectrum sharing with co-channel reverse time-division duplex (TDD) and dynamic soft frequency reuse is considered for interference management in the two-tier HetNet employing large-scale antenna arrays at the macro BS and wireless backhauling for small cells. Two in-band WBBA scenarios, namely, unified bandwidth allocation and per-small-cell bandwidth allocation, are investigated for joint CA-WBBA in the HetNet. A two-level hierarchical decomposition method for relaxed optimization is employed to solve the mixed-integer nonlinear program (MINLP). Solutions based on the General Algorithm Modeling System (GAMS) optimization solver and fast heuristics are also proposed for cell association in the per-small-cell WBBA scenario. It is shown that when all small cells have to use in-band wireless backhaul, the system load has more impact on both the sum logarithmic rate and per-user rate performance than the number of small cells deployed within the macro cell range. The proposed joint CA-WBBA algorithms have an optimal load approximately equal to the size of the large-scale antenna array at the macro BS. The cell range expansion (CRE) strategy, which is an efficient cell association scheme for HetNets with ideal backhauling, is shown to be inefficient when in-band wireless backhauling for small cells comes into play.",
Temperature-Dependent Short-Circuit Capability of Silicon Carbide Power MOSFETs,"This paper presents a comprehensive short-circuit ruggedness evaluation and numerical investigation of up-to-date commercial silicon carbide (SiC) MOSFETs. The short-circuit capability of three types of commercial 1200-V SiC MOSFETs is tested under various conditions, with case temperatures from 25 to 200 °C and dc bus voltages from 400 to 750 V. It is found that the commercial SiC MOSFETs can withstand short-circuit current for only several microseconds with a dc bus voltage of 750 V and case temperature of 200 °C. The experimental short-circuit behaviors are compared, and analyzed through numerical thermal dynamic simulation. Specifically, an electrothermal model is built to estimate the device internal temperature distribution, considering the temperature-dependent thermal properties of SiC material. Based on the temperature information, a leakage current model is derived to calculate the main leakage current components (i.e., thermal, diffusion, and avalanche generation currents). Numerical results show that the short-circuit failure mechanisms of SiC MOSFETs can be thermal generation current induced thermal runaway or high-temperature-related gate oxide damage.","Silicon carbide,
MOSFET,
Logic gates,
Temperature dependence,
Leakage currents,
Temperature,
Integrated circuit modeling"
Online mobile Micro-Task Allocation in spatial crowdsourcing,"With the rapid development of smartphones, spatial crowdsourcing platforms are getting popular. A foundational research of spatial crowdsourcing is to allocate micro-tasks to suitable crowd workers. Most existing studies focus on offline scenarios, where all the spatiotemporal information of micro-tasks and crowd workers is given. However, they are impractical since micro-tasks and crowd workers in real applications appear dynamically and their spatiotemporal information cannot be known in advance. In this paper, to address the shortcomings of existing offline approaches, we first identify a more practical micro-task allocation problem, called the Global Online Micro-task Allocation in spatial crowdsourcing (GOMA) problem. We first extend the state-of-art algorithm for the online maximum weighted bipartite matching problem to the GOMA problem as the baseline algorithm. Although the baseline algorithm provides theoretical guarantee for the worst case, its average performance in practice is not good enough since the worst case happens with a very low probability in real world. Thus, we consider the average performance of online algorithms, a.k.a online random order model.We propose a two-phase-based framework, based on which we present the TGOA algorithm with 1 over 4 -competitive ratio under the online random order model. To improve its efficiency, we further design the TGOA-Greedy algorithm following the framework, which runs faster than the TGOA algorithm but has lower competitive ratio of 1 over 8. Finally, we verify the effectiveness and efficiency of the proposed methods through extensive experiments on real and synthetic datasets.","Crowdsourcing,
Resource management,
Algorithm design and analysis,
Spatiotemporal phenomena,
Heuristic algorithms,
Real-time systems,
Mobile communication"
AggNet: Deep Learning From Crowds for Mitosis Detection in Breast Cancer Histology Images,"The lack of publicly available ground-truth data has been identified as the major challenge for transferring recent developments in deep learning to the biomedical imaging domain. Though crowdsourcing has enabled annotation of large scale databases for real world images, its application for biomedical purposes requires a deeper understanding and hence, more precise definition of the actual annotation task. The fact that expert tasks are being outsourced to non-expert users may lead to noisy annotations introducing disagreement between users. Despite being a valuable resource for learning annotation models from crowdsourcing, conventional machine-learning methods may have difficulties dealing with noisy annotations during training. In this manuscript, we present a new concept for learning from crowds that handle data aggregation directly as part of the learning process of the convolutional neural network (CNN) via additional crowdsourcing layer (AggNet). Besides, we present an experimental study on learning from crowds designed to answer the following questions. 1) Can deep CNN be trained with data collected from crowdsourcing? 2) How to adapt the CNN to train on multiple types of annotation datasets (ground truth and crowd-based)? 3) How does the choice of annotation and aggregation affect the accuracy? Our experimental setup involved Annot8, a self-implemented web-platform based on Crowdflower API realizing image annotation tasks for a publicly available biomedical image database. Our results give valuable insights into the functionality of deep CNN learning from crowd annotations and prove the necessity of data aggregation integration.","Biomedical imaging,
Crowdsourcing,
Noise measurement,
Machine learning,
Computational modeling,
Robustness,
Data models"
Constrained Multilegged Robot System Modeling and Fuzzy Control With Uncertain Kinematics and Dynamics Incorporating Foot Force Optimization,"This paper studies the optimal distribution of feet forces and control of multilegged robots with uncertainties in both kinematics and dynamics. First, a constrained dynamics for multilegged robots and the constrained environment model are established by considering both kinematic and dynamic uncertainties. Under an external wrench for multilegged robots, the foot forces and moments of the supporting legs can be formulated as quadratic programming problems subject to linear and nonlinear constraints. The neurodynamics of recurrent neural network is developed for foot force optimization. For the obtained optimized tip-point force and the motion of legs, we propose a hybrid task-space trajectory and force tracking based on fuzzy system and adaptive mechanism that are used to compensate for the external perturbation, kinematics, and dynamics uncertainties. The tracking of task-space trajectory and constraint force is achieved under unknown dynamical parameters, constraints, and disturbances. Extensive simulations have been provided to verify the effectiveness of the proposed scheme.",
An Event-Triggered Approach to State Estimation for a Class of Complex Networks With Mixed Time Delays and Nonlinearities,"In this paper, the state estimation problem is investigated for a class of discrete-time complex networks subject to nonlinearities, mixed delays, and stochastic noises. A set of event-based state estimators is constructed so as to reduce unnecessary data transmissions in the communication channel. Compared with the traditional state estimator whose measurement signal is received under a periodic clock-driven rule, the event-based estimator only updates the measurement information from the sensors when the prespecified “event” is violated. Attention is focused on the analysis and design problem of the event-based estimators for the addressed discrete-time complex networks such that the estimation error is exponentially bounded in mean square. A combination of the stochastic analysis approach and Lyapunov theory is employed to obtain sufficient conditions for ensuring the existence of the desired estimators and the upper bound of the estimation error is also derived. By using the convex optimization technique, the gain parameters of the desired estimators are provided in an explicit form. Finally, a simulation example is used to demonstrate the effectiveness of the proposed estimation strategy.","Complex networks,
State estimation,
Estimation error,
Stochastic processes,
Silicon,
Nickel,
Noise"
Approximate Computing: A Survey,"As one of the most promising energy-efficient computing paradigms, approximate computing has gained a lot of research attention in the past few years. This paper presents a survey of state-of-the-art work in all aspects of approximate computing and highlights future research challenges in this field.",
Ultra-Dense Networks: A Survey,"The exponential growth and availability of data in all forms is the main booster to the continuing evolution in the communications industry. The popularization of traffic-intensive applications including high definition video, 3-D visualization, augmented reality, wearable devices, and cloud computing defines a new era of mobile communications. The immense amount of traffic generated by today's customers requires a paradigm shift in all aspects of mobile networks. Ultradense network (UDN) is one of the leading ideas in this racetrack. In UDNs, the access nodes and/or the number of communication links per unit area are densified. In this paper, we provide a survey-style introduction to dense small cell networks. Moreover, we summarize and compare some of the recent achievements and research findings. We discuss the modeling techniques and the performance metrics widely used to model problems in UDN. Also, we present the enabling technologies for network densification in order to understand the state-of-the-art. We consider many research directions in this survey, namely, user association, interference management, energy efficiency, spectrum sharing, resource management, scheduling, backhauling, propagation modeling, and the economics of UDN deployment. Finally, we discuss the challenges and open problems to the researchers in the field or newcomers who aim to conduct research in this interesting and active area of research.",
Motor Bearing Fault Detection Using Spectral Kurtosis-Based Feature Extraction Coupled With K-Nearest Neighbor Distance Analysis,"Bearing faults are the main contributors to the failure of electric motors. Although a number of vibration analysis methods have been developed for the detection of bearing faults, false alarms still result in losses. This paper presents a method that detects bearing faults and monitors the degradation of bearings in electric motors. Based on spectral kurtosis (SK) and cross correlation, the method extracts fault features that represent different faults, and the features are then combined to form a health index using principal component analysis (PCA) and a semisupervised k-nearest neighbor (KNN) distance measure. The method was validated by experiments using a machinery fault simulator and a computer cooling fan motor bearing. The method is able to detect incipient faults and diagnose the locations of faults under masking noise. It also provides a health index that tracks the degradation of faults without missing intermittent faults. Moreover, faulty reference data are not required.",
Laplacian Regularized Low-Rank Representation and Its Applications,"Low-rank representation (LRR) has recently attracted a great deal of attention due to its pleasing efficacy in exploring low-dimensional subspace structures embedded in data. For a given set of observed data corrupted with sparse errors, LRR aims at learning a lowest-rank representation of all data jointly. LRR has broad applications in pattern recognition, computer vision and signal processing. In the real world, data often reside on low-dimensional manifolds embedded in a high-dimensional ambient space. However, the LRR method does not take into account the non-linear geometric structures within data, thus the locality and similarity information among data may be missing in the learning process. To improve LRR in this regard, we propose a general Laplacian regularized low-rank representation framework for data representation where a hypergraph Laplacian regularizer can be readily introduced into, i.e., a Non-negative Sparse Hyper-Laplacian regularized LRR model (NSHLRR). By taking advantage of the graph regularizer, our proposed method not only can represent the global low-dimensional structures, but also capture the intrinsic non-linear geometric information in data. The extensive experimental results on image clustering, semi-supervised image classification and dimensionality reduction tasks demonstrate the effectiveness of the proposed method.","Manifolds,
Laplace equations,
Data models,
Principal component analysis,
Robustness,
Optimization"
Everything you wanted to know about smart cities: The Internet of things is the backbone,"This article is a single-source introduction to the emerging concept of smart cities. It can be used for familiarizing researchers with the vast scope of research possible in this application domain. The smart city is primarily a concept, and there is still not a clear and consistent definition among practitioners and academia. As a simplistic explanation, a smart city is a place where traditional networks and services are made more flexible, efficient, and sustainable with the use of information, digital, and telecommunication technologies to improve the city's operations for the benefit of its inhabitants. Smart cities are greener, safer, faster, and friendlier. The different components of a smart city include smart infrastructure, smart transportation, smart energy, smart health care, and smart technology. These components are what make the cities smart and efficient. Information and communication technology (ICT) are enabling keys for transforming traditional cities into smart cities. Two closely related emerging technology frameworks, the Internet of Things (IoT) and big data (BD), make smart cities efficient and responsive. The technology has matured enough to allow smart cities to emerge. However, there is much needed in terms of physical infrastructure, a smart city, the digital technologies translate into better public services for inhabitants and better use of resources while reducing environmental impacts. One of the formal definitions of the smart city is the following: a city ""connecting the physical infrastructure, the information-technology infrastructure, the social infrastructure, and the business infrastructure to leverage the collective intelligence of the city"". Another formal and comprehensive definition is ""a smart sustainable city is an innovative city that uses information and communication technologies (ICTs) and other means to improve quality of life, efficiency of urban operations and services, and competitiveness, while ensuring that it meets the needs of present and future generations with respect to economic, social and environmental aspects"". Any combination of various smart components can make cities smart. A city need not have all the components to be labeled as smart. The number of smart components depends on the cost and available technology.",
MobilityGraphs: Visual Analysis of Mass Mobility Dynamics via Spatio-Temporal Graphs and Clustering,"Learning more about people mobility is an important task for official decision makers and urban planners. Mobility data sets characterize the variation of the presence of people in different places over time as well as movements (or flows) of people between the places. The analysis of mobility data is challenging due to the need to analyze and compare spatial situations (i.e., presence and flows of people at certain time moments) and to gain an understanding of the spatio-temporal changes (variations of situations over time). Traditional flow visualizations usually fail due to massive clutter. Modern approaches offer limited support for investigating the complex variation of the movements over longer time periods. We propose a visual analytics methodology that solves these issues by combined spatial and temporal simplifications. We have developed a graph-based method, called MobilityGraphs, which reveals movement patterns that were occluded in flow maps. Our method enables the visual representation of the spatio-temporal variation of movements for long time series of spatial situations originally containing a large number of intersecting flows. The interactive system supports data exploration from various perspectives and at various levels of detail by interactive setting of clustering parameters. The feasibility our approach was tested on aggregated mobility data derived from a set of geolocated Twitter posts within the Greater London city area and mobile phone call data records in Abidjan, Ivory Coast. We could show that MobilityGraphs support the identification of regular daily and weekly movement patterns of resident population.",
"A Survey of Fuzzy Systems Software: Taxonomy, Current Research Trends, and Prospects","Fuzzy systems have been used widely thanks to their ability to successfully solve a wide range of problems in different application fields. However, their replication and application require a high level of knowledge and experience. Furthermore, few researchers publish the software and/or source code associated with their proposals, which is a major obstacle to scientific progress in other disciplines and in industry. In recent years, most fuzzy system software has been developed in order to facilitate the use of fuzzy systems. Some software is commercially distributed, but most software is available as free and open-source software, reducing such obstacles and providing many advantages: quicker detection of errors, innovative applications, faster adoption of fuzzy systems, etc. In this paper, we present an overview of freely available and open-source fuzzy systems software in order to provide a well-established framework that helps researchers to find existing proposals easily and to develop well-founded future work. To accomplish this, we propose a two-level taxonomy, and we describe the main contributions related to each field. Moreover, we provide a snapshot of the status of the publications in this field according to the ISI Web of Knowledge. Finally, some considerations regarding recent trends and potential research directions are presented.","Fuzzy systems,
Frequency selective surfaces,
Software,
Libraries,
Proposals,
Taxonomy,
Communities"
Subcarrier-Index Modulation Aided OFDM - Will It Work?,"The achievable performance of subcarrier-index modulation (SIM) is analyzed in terms of its minimum Euclidean distance, constrained and unconstrained average mutual information, as well as its peak-to-average power ratio (PAPR). Our performance investigations identify the beneficial operating region of the SIM scheme over its conventional orthogonal frequency-division multiplexing (OFDM) counterpart, hence providing general design guidelines for the SIM parameters. More specifically, an SIM scheme is shown to be beneficial for the scenario of a relatively low transmission rate below 2 b/s/Hz. In addition, we demonstrate that the PAPR of the SIM scheme is comparable with that of its OFDM counterpart under the idealized simplifying assumption of having Gaussian input symbols.","OFDM,
Subcarrier indexes,
Parallel processing,
Peak to average power ratio,
Capacity planning,
Spatial modulation"
Security Enhancement for IoT Communications Exposed to Eavesdroppers With Uncertain Locations,"The Internet of Things (IoT) depicts a bright future, where any devices having sensorial and computing capabilities can interact with each other. Among all existing technologies, the techniques for the fifth generation (5G) systems are the main driving force for the actualization of IoT concept. However, due to the heterogeneous environment in 5G networks and the broadcast nature of radio propagation, the security assurance against eavesdropping is a vital yet challenging task. In this paper, we focus on the transmission design for secure relay communications in IoT networks, where the communication is exposed to eavesdroppers with unknown number and locations. The randomize-and-forward relay strategy specially designed for secure multi-hop communications is employed in our transmission protocol. First, we consider a single-antenna scenario, where all the devices in the network are equipped with the single antenna. We derive the expression for the secrecy outage probability of the two-hop transmission. Following this, a secrecy-rate-maximization problem subject to a secrecy-outage-probability constraint is formulated. The optimal power allocation and codeword rate design are obtained. Furthermore, we generalize the above analyses to a more generic scenario, where the relay and eavesdroppers are equipped with multiple antennas. Numerical results show that the proper use of relay transmission can enhance the secrecy throughput and extend the secure coverage range.","Radio propagation,
Internet of things,
5G mobile communication,
Antenna measurements,
Sensors,
Security,
Resource management"
Dynamic Computation Offloading for Mobile-Edge Computing With Energy Harvesting Devices,"Mobile-edge computing (MEC) is an emerging paradigm to meet the ever-increasing computation demands from mobile applications. By offloading the computationally intensive workloads to the MEC server, the quality of computation experience, e.g., the execution latency, could be greatly improved. Nevertheless, as the on-device battery capacities are limited, computation would be interrupted when the battery energy runs out. To provide satisfactory computation performance as well as achieving green computing, it is of significant importance to seek renewable energy sources to power mobile devices via energy harvesting (EH) technologies. In this paper, we will investigate a green MEC system with EH devices and develop an effective computation offloading strategy. The execution cost, which addresses both the execution latency and task failure, is adopted as the performance metric. A low-complexity online algorithm is proposed, namely, the Lyapunov optimization-based dynamic computation offloading algorithm, which jointly decides the offloading decision, the CPU-cycle frequencies for mobile execution, and the transmit power for computation offloading. A unique advantage of this algorithm is that the decisions depend only on the current system state without requiring distribution information of the computation task request, wireless channel, and EH processes. The implementation of the algorithm only requires to solve a deterministic problem in each time slot, for which the optimal solution can be obtained either in closed form or by bisection search. Moreover, the proposed algorithm is shown to be asymptotically optimal via rigorous analysis. Sample simulation results shall be presented to corroborate the theoretical analysis as well as validate the effectiveness of the proposed algorithm.",
"Past, Present, and Future of Simultaneous Localization and Mapping: Toward the Robust-Perception Age","Simultaneous localization and mapping (SLAM) consists in the concurrent construction of a model of the environment (the map), and the estimation of the state of the robot moving within it. The SLAM community has made astonishing progress over the last 30 years, enabling large-scale real-world applications and witnessing a steady transition of this technology to industry. We survey the current state of SLAM and consider future directions. We start by presenting what is now the de-facto standard formulation for SLAM. We then review related work, covering a broad set of topics including robustness and scalability in long-term mapping, metric and semantic representations for mapping, theoretical performance guarantees, active SLAM and exploration, and other new frontiers. This paper simultaneously serves as a position paper and tutorial to those who are users of SLAM. By looking at the published research with a critical eye, we delineate open challenges and new research issues, that still deserve careful scientific investigation. The paper also contains the authors' take on two questions that often animate discussions during robotics conferences: Do robots need SLAM? and Is SLAM solved?",
Wireless Energy Harvesting in a Cognitive Relay Network,"Wireless energy harvesting is regarded as a promising energy supply alternative for energy-constrained wireless networks. In this paper, a new wireless energy harvesting protocol is proposed for an underlay cognitive relay network with multiple primary user (PU) transceivers. In this protocol, the secondary nodes can harvest energy from the primary network (PN) while sharing the licensed spectrum of the PN. In order to assess the impact of different system parameters on the proposed network, we first derive an exact expression for the outage probability for the secondary network (SN) subject to three important power constraints: 1) the maximum transmit power at the secondary source (SS) and at the secondary relay (SR); 2) the peak interference power permitted at each PU receiver; and 3) the interference power from each PU transmitter to the SR and to the secondary destination (SD). To obtain practical design insights into the impact of different parameters on successful data transmission of the SN, we derive throughput expressions for both the delay-sensitive and the delay-tolerant transmission modes. We also derive asymptotic closed-form expressions for the outage probability and the delay-sensitive throughput and an asymptotic analytical expression for the delay-tolerant throughput as the number of PU transceivers goes to infinity. The results show that the outage probability improves when PU transmitters are located near SS and sufficiently far from SR and SD. Our results also show that when the number of PU transmitters is large, the detrimental effect of interference from PU transmitters outweighs the benefits of energy harvested from the PU transmitters.",
A Novel Sensory Data Processing Framework to Integrate Sensor Networks With Mobile Cloud,"Taking advantage of the data gathering capability of wireless sensor networks (WSNs) as well as the data storage and processing ability of mobile cloud computing (MCC), WSN-MCC integration is attracting significant attention from both academia and industry. This paper focuses on processing of the sensory data in WSN-MCC integration, by identifying the critical issues concerning WSN-MCC integration and proposing a novel sensory data processing framework, which aims at transmitting desirable sensory data to the mobile users in a fast, reliable, and secure manner. The proposed framework could prolong the WSN lifetime, decrease the storage requirements of the sensors and the WSN gateway, and reduce the traffic load and bandwidth requirement of sensory data transmissions. In addition, the framework is capable of monitoring and predicting the future trend of the sensory data traffic, as well as improving its security. The framework further decreases the storage and processing overhead of the cloud, while enabling mobile users to securely obtain their desired sensory data faster. Analytical and experimental results are presented to demonstrate the effectiveness of the proposed framework.","Wireless sensor networks,
Mobile communication,
Logic gates,
Monitoring,
Data processing,
Clouds,
Educational institutions"
Nonfragile H_{\infty} Fuzzy Filtering With Randomly Occurring Gain Variations and Channel Fadings,"This paper is concerned with the nonfragile H∞ filtering problem for a class of discrete-time Takagi-Sugeno (T-S) fuzzy systems with both randomly occurring gain variations (ROGVs) and channel fadings. the phenomenon of the ROGVs is introduced into the system model so as to account for the parameter fluctuations occurring during the filter implementation. Two sequences of random variables obeying the Bernoulli distribution are employed to describe the phenomenon of the ROGVs bounded by prescribed norms. In addition, the Rice fading model is utilized to describe the phenomena of channel fadings, where the occurrence probabilities of the random channel coefficients are allowed to time varying. Through stochastic analysis and Lyapunov functional approach, sufficient conditions are established under which the filtering error dynamics is exponentially mean-square stable with a prespecified H∞ performance. The set of the desired nonfragile H∞ filters is characterized by solving a convex optimization problem via the semidefinite programming method. An illustrative example is given to show the usefulness and effectiveness of the proposed design method in this paper.","Fading,
Fuzzy systems,
Symmetric matrices,
Mathematical model,
Stochastic processes,
Nonlinear systems,
Noise"
Uncertainty Analysis for the Keyword System of Web Events,"Webpage recommendations for hot Web events can assist people to easily follow the evolution of these Web events. At the same time, there are different levels of semantic uncertainty underlying the amount of Webpages for a Web event, such as recapitulative information and detailed information. Apparently, the grasp of the semantic uncertainty of Web events could improve the satisfactoriness of Webpage recommendations. However, traditional hit-rate-based or clustering-based Webpage recommendation methods have overlooked these different levels of semantic uncertainty. In this paper, we propose a framework to identify the different underlying levels of semantic uncertainty in terms of Web events, and then utilize these for Webpage recommendations. Our idea is to consider a Web event as a system composed of different keywords, and the uncertainty of this keyword system is related to the uncertainty of the particular Web event. Based on keyword association linked network Web event representation and Shannon entropy, we identify the different levels of semantic uncertainty, and construct a semantic pyramid (SP) to express the uncertainty hierarchy of a Web event. Finally, an SP-based Webpage recommendation system is developed. Experiments show that the proposed algorithm can significantly capture the different levels of the semantic uncertainties of Web events and it can be applied to Webpage recommendations.",
Optimal Transceiver Design for SWIPT in K-User MIMO Interference Channels,"This paper investigates simultaneous wireless information and power transfer (SWIPT) in K-user multiple-input multiple-output (MIMO) interference channels. In particular, the power splitting (PS) technique is leveraged at each receiver to divide the received signal into two flows, for information decoding (ID) and energy harvesting (EH), respectively. As a whole system, our objective is to minimize the total transmit power of all transmitters by jointly designing transmit beamformers, power splitters, and receive filters, subject to the signal-to-interference-plus-noise ratio (SINR) constraint for ID and the harvested power constraint for EH at each receiver. Due to the coupling nature of all variables, the formulated joint transceiver design problem is nonconvex, and has not yet been well addressed in the literature. In this paper, we first propose a semidefinite relaxation-based alternating optimization (SDRAO) solution to approach the optimal solution of the problem. Then, we semidecouple the joint optimization by the derived diversity interference alignment (DIA) technique, and obtain a solution of lower complexity. Finally, a closed-form solution is further developed relying on the transmitter-side zero-forcing (TZF), which can be implemented in a distributed manner, with the lowest computational complexity and CSI exchanging overhead.","MIMO,
Receivers,
Interference,
Wireless communication,
Transceivers,
Signal to noise ratio,
Optimization"
Fast Convolutional Neural Network Training Using Selective Data Sampling: Application to Hemorrhage Detection in Color Fundus Images,"Convolutional neural networks (CNNs) are deep learning network architectures that have pushed forward the state-of-the-art in a range of computer vision applications and are increasingly popular in medical image analysis. However, training of CNNs is time-consuming and challenging. In medical image analysis tasks, the majority of training examples are easy to classify and therefore contribute little to the CNN learning process. In this paper, we propose a method to improve and speed-up the CNN training for medical image analysis tasks by dynamically selecting misclassified negative samples during training. Training samples are heuristically sampled based on classification by the current status of the CNN. Weights are assigned to the training samples and informative samples are more likely to be included in the next CNN training iteration. We evaluated and compared our proposed method by training a CNN with (SeS) and without (NSeS) the selective sampling method. We focus on the detection of hemorrhages in color fundus images. A decreased training time from 170 epochs to 60 epochs with an increased performance-on par with two human experts-was achieved with areas under the receiver operating characteristics curve of 0.894 and 0.972 on two data sets. The SeS CNN statistically outperformed the NSeS CNN on an independent test set.","Training,
Hemorrhaging,
Biomedical imaging,
Observers,
Image color analysis,
Image analysis,
Databases"
Energy Efficiency of Downlink Transmission Strategies for Cloud Radio Access Networks,"This paper studies the energy efficiency of the cloud radio access network (C-RAN), specifically focusing on two fundamental and different downlink transmission strategies, namely the data-sharing strategy and the compression strategy. In the data-sharing strategy, the backhaul links connecting the central processor (CP) and the base-stations (BSs) are used to carry user messages-each user's messages are sent to multiple BSs; the BSs locally form the beamforming vectors then cooperatively transmit the messages to the user. In the compression strategy, the user messages are precoded centrally at the CP, which forwards a compressed version of the analog beamformed signals to the BSs for cooperative transmission. This paper compares the energy efficiencies of the two strategies by formulating an optimization problem of minimizing the total network power consumption subject to user target rate constraints, where the total network power includes the BS transmission power, BS activation power, and load-dependent backhaul power. To tackle the discrete and nonconvex nature of the optimization problems, we utilize the techniques of reweighted ℓ1 minimization and successive convex approximation to devise provably convergent algorithms. Our main finding is that both the optimized data-sharing and compression strategies in C-RAN achieve much higher energy efficiency as compared to the nonoptimized coordinated multipoint transmission, but their comparative effectiveness in energy saving depends on the user target rate. At low user target rate, data-sharing consumes less total power than compression; however, as the user target rate increases, the backhaul power consumption for data-sharing increases significantly leading to better energy efficiency of compression at the high user rate regime.",
From Denoising to Compressed Sensing,"A denoising algorithm seeks to remove noise, errors, or perturbations from a signal. Extensive research has been devoted to this arena over the last several decades, and as a result, todays denoisers can effectively remove large amounts of additive white Gaussian noise. A compressed sensing (CS) reconstruction algorithm seeks to recover a structured signal acquired using a small number of randomized measurements. Typical CS reconstruction algorithms can be cast as iteratively estimating a signal from a perturbed observation. This paper answers a natural question: How can one effectively employ a generic denoiser in a CS reconstruction algorithm? In response, we develop an extension of the approximate message passing (AMP) framework, called denoising-based AMP (D-AMP), that can integrate a wide class of denoisers within its iterations. We demonstrate that, when used with a high-performance denoiser for natural images, D-AMP offers the state-of-the-art CS recovery performance while operating tens of times faster than competing methods. We explain the exceptional performance of D-AMP by analyzing some of its theoretical features. A key element in D-AMP is the use of an appropriate Onsager correction term in its iterations, which coerces the signal perturbation at each iteration to be very close to the white Gaussian noise that denoisers are typically designed to remove.",
A Survey of Software Techniques for Using Non-Volatile Memories for Storage and Main Memory Systems,"Non-volatile memory (NVM) devices, such as Flash, phase change RAM, spin transfer torque RAM, and resistive RAM, offer several advantages and challenges when compared to conventional memory technologies, such as DRAM and magnetic hard disk drives (HDDs). In this paper, we present a survey of software techniques that have been proposed to exploit the advantages and mitigate the disadvantages of NVMs when used for designing memory systems, and, in particular, secondary storage (e.g., solid state drive) and main memory. We classify these software techniques along several dimensions to highlight their similarities and differences. Given that NVMs are growing in popularity, we believe that this survey will motivate further research in the field of software technology for NVMs.","Nonvolatile memory,
Flash memories,
Phase change materials,
Software,
Memory management,
Phase change random access memory"
Ultra Dense Small Cell Networks: Turning Density Into Energy Efficiency,"In this paper, a novel approach for joint power control and user scheduling is proposed for optimizing energy efficiency (EE), in terms of bits per unit energy, in ultra dense small cell networks (UDNs). Due to severe coupling in interference, this problem is formulated as a dynamic stochastic game (DSG) between small cell base stations (SBSs). This game enables capturing the dynamics of both the queues and channel states of the system. To solve this game, assuming a large homogeneous UDN deployment, the problem is cast as a mean-field game (MFG) in which the MFG equilibrium is analyzed with the aid of low-complexity tractable partial differential equations. Exploiting the stochastic nature of the problem, user scheduling is formulated as a stochastic optimization problem and solved using the drift plus penalty (DPP) approach in the framework of Lyapunov optimization. Remarkably, it is shown that by weaving notions from Lyapunov optimization and mean-field theory, the proposed solution yields an equilibrium control policy per SBS, which maximizes the network utility while ensuring users' quality-of-service. Simulation results show that the proposed approach achieves up to 70.7% gains in EE and 99.5% reductions in the network's outage probabilities compared to a baseline model, which focuses on improving EE while attempting to satisfy the users' instantaneous quality-of-service requirements.",
Optimal Workload Allocation in Fog-Cloud Computing Toward Balanced Delay and Power Consumption,"Mobile users typically have high demand on localized and location-based information services. To always retrieve the localized data from the remote cloud, however, tends to be inefficient, which motivates fog computing. The fog computing, also known as edge computing, extends cloud computing by deploying localized computing facilities at the premise of users, which prestores cloud data and distributes to mobile users with fast-rate local connections. As such, fog computing introduces an intermediate fog layer between mobile users and cloud, and complements cloud computing toward low-latency high-rate services to mobile users. In this fundamental framework, it is important to study the interplay and cooperation between the edge (fog) and the core (cloud). In this paper, the tradeoff between power consumption and transmission delay in the fog-cloud computing system is investigated. We formulate a workload allocation problem which suggests the optimal workload allocations between fog and cloud toward the minimal power consumption with the constrained service delay. The problem is then tackled using an approximate approach by decomposing the primal problem into three subproblems of corresponding subsystems, which can be, respectively, solved. Finally, based on simulations and numerical results, we show that by sacrificing modest computation resources to save communication bandwidth and reduce transmission latency, fog computing can significantly improve the performance of cloud computing.","Cloud computing,
Servers,
Mobile communication,
Energy consumption,
Power demand,
Internet of things,
Resource management,
Load management"
Energy-Efficient Resource Allocation for D2D Communications Underlaying Cloud-RAN-Based LTE-A Networks,"Device-to-device (D2D) communication is a key enabler to facilitate the realization of the Internet of Things (IoT). In this paper, we study the deployment of D2D communications as an underlay to long-term evolution-advanced (LTE-A) networks based on novel architectures such as cloud radio access network (C-RAN). The challenge is that both energy efficiency (EE) and quality of service (QoS) are severely degraded by the strong intracell and intercell interference due to dense deployment and spectrum reuse. To tackle this problem, we propose an energy-efficient resource allocation algorithm through joint channel selection and power allocation design. The proposed algorithm has a hybrid structure that exploits the hybrid architecture of C-RAN: distributed remote radio heads (RRHs) and centralized baseband unit (BBU) pool. The distributed resource allocation problem is modeled as a noncooperative game, and each player optimizes its EE individually with the aid of distributed RRHs. We transform the nonconvex optimization problem into a convex one by applying constraint relaxation and nonlinear fractional programming. We propose a centralized interference mitigation algorithm to improve the QoS performance. The centralized algorithm consists of an interference cancellation technique and a transmission power constraint optimization technique, both of which are carried out in the centralized BBU pool. The achievable performance of the proposed algorithm is analyzed through simulations, and the implementation issues and complexity analysis are discussed in detail.","Interference,
Resource management,
Computer architecture,
Quality of service,
Games,
Microprocessors,
Power demand"
Ordinal Regression Methods: Survey and Experimental Study,"Ordinal regression problems are those machine learning problems where the objective is to classify patterns using a categorical scale which shows a natural order between the labels. Many real-world applications present this labelling structure and that has increased the number of methods and algorithms developed over the last years in this field. Although ordinal regression can be faced using standard nominal classification techniques, there are several algorithms which can specifically benefit from the ordering information. Therefore, this paper is aimed at reviewing the state of the art on these techniques and proposing a taxonomy based on how the models are constructed to take the order into account. Furthermore, a thorough experimental study is proposed to check if the use of the order information improves the performance of the models obtained, considering some of the approaches within the taxonomy. The results confirm that ordering information benefits ordinal models improving their accuracy and the closeness of the predictions to actual targets in the ordinal scale.","Training,
Biological system modeling,
Predictive models,
Taxonomy,
Support vector machines,
Standards,
Sorting"
Unsupervised Deep Learning Applied to Breast Density Segmentation and Mammographic Risk Scoring,"Mammographic risk scoring has commonly been automated by extracting a set of handcrafted features from mammograms, and relating the responses directly or indirectly to breast cancer risk. We present a method that learns a feature hierarchy from unlabeled data. When the learned features are used as the input to a simple classifier, two different tasks can be addressed: i) breast density segmentation, and ii) scoring of mammographic texture. The proposed model learns features at multiple scales. To control the models capacity a novel sparsity regularizer is introduced that incorporates both lifetime and population sparsity. We evaluated our method on three different clinical datasets. Our state-of-the-art results show that the learned breast density scores have a very strong positive relationship with manual ones, and that the learned texture scores are predictive of breast cancer. The model is easy to apply and generalizes to many other segmentation and scoring problems.","Breast cancer,
Computer architecture,
Machine learning,
Mammography,
Manuals,
Image segmentation"
Artificial Noise Aided Secrecy Information and Power Transfer in OFDMA Systems,"In this paper, we study simultaneous wireless information and power transfer (SWIPT) in orthogonal frequency division multiple access (OFDMA) systems with the coexistence of information receivers (IRs) and energy receivers (ERs). The IRs are served with best-effort secrecy data and the ERs harvest energy with minimum required harvested power. To enhance the physical layer security for IRs and yet satisfy energy harvesting requirements for ERs, we propose a new frequency-domain artificial noise (AN) aided transmission strategy. With the new strategy, we study the optimal resource allocation for the weighted sum secrecy rate maximization for IRs by power and subcarrier allocation at the transmitter. The studied problem is shown to be a mixed integer programming problem and thus nonconvex, while we propose an efficient algorithm for solving it based on the Lagrange duality method. To further reduce the computational complexity, we also propose a suboptimal algorithm of lower complexity. The simulation results illustrate the effectiveness of proposed algorithms as compared against other heuristic schemes.",
Structure-Preserving Binary Representations for RGB-D Action Recognition,"In this paper, we propose a novel binary local representation for RGB-D video data fusion with a structure-preserving projection. Our contribution consists of two aspects. To acquire a general feature for the video data, we convert the problem to describing the gradient fields of RGB and depth information of video sequences. With the local fluxes of the gradient fields, which include the orientation and the magnitude of the neighborhood of each point, a new kind of continuous local descriptor called Local Flux Feature(LFF) is obtained. Then the LFFs from RGB and depth channels are fused into a Hamming spacevia the Structure Preserving Projection (SPP). Specifically, an orthogonal projection matrix is applied to preserve the pairwise structure with a shape constraint to avoid the collapse of data structure in the projected space. Furthermore, a bipartite graph structure of data is taken into consideration, which is regarded as a higher level connection between samples and classes than the pairwise structure of local features. The extensive experiments show not only the high efficiency of binary codes and the effectiveness of combining LFFs from RGB-D channels via SPP on various action recognition benchmarks of RGB-D data, but also the potential power of LFF for general action recognition.","Feature extraction,
Binary codes,
Three-dimensional displays,
Video sequences,
Shape,
Histograms,
Manifolds"
Power and Voltage Balance Control of a Novel Three-Phase Solid-State Transformer Using Multilevel Cascaded H-Bridge Inverters for Microgrid Applications,"This paper presents a new application of power and voltage balance control schemes for the cascaded H-bridge multilevel inverter (CHMI)-based solid-state transformer (SST) topology. To reduce load on the controller and simplify modulation algorithm, a master-slave control (MSC) strategy is designed for the dual active bridge (DAB) stage. The master controller executes all control and modulation calculations, and the slave controllers manage only device switching and protection. Due to the inherent power and dc-link voltage unbalance in cascaded H-bridge-based SST, this paper presents a compensation strategy based on three-phase dq decoupled current controller. An optimum zero-sequence component is injected in the modulation scheme so that the three-phase grid currents are balanced. Furthermore, to tightly regulate the output voltage of all the DAB modules to target value, a dynamic reference voltage method is also implemented. With this proposed control method, the three-phase grid currents and dc-link voltage in each module can be simultaneously balanced. Finally, simulation and experimental results are presented to validate the performance of the controller and its application to microgrid SST.",
Event-Triggered Generalized Dissipativity Filtering for Neural Networks With Time-Varying Delays,"This paper is concerned with event-triggered generalized dissipativity filtering for a neural network (NN) with a time-varying delay. The signal transmission from the NN to its filter is completed through a communication channel. It is assumed that the network measurement of the NN is sampled periodically. An event-triggered communication scheme is introduced to design a suitable filter such that precious communication resources can be saved significantly while certain filtering performance can be ensured. On the one hand, the event-triggered communication scheme is devised to select only those sampled signals violating a certain threshold to be transmitted, which directly leads to saving of precious communication resources. On the other hand, the filtering error system is modeled as a time-delay system closely dependent on the parameters of the event-triggered scheme. Based on this model, a suitable filter is designed such that certain filtering performance can be ensured, provided that a set of linear matrix inequalities are satisfied. Furthermore, since a generalized dissipativity performance index is introduced, several kinds of event-triggered filtering issues, such as H∞ filtering, passive filtering, mixed H∞ and passive filtering, (Q, S, R)-dissipative filtering, and L2-L∞ filtering, are solved in a unified framework. Finally, two examples are given to illustrate the effectiveness of the proposed method.",
Real-Time Wireless Sensor-Actuator Networks for Industrial Cyber-Physical Systems,"With recent adoption of wireless sensor-actuator networks (WSANs) in industrial automation, industrial wireless control systems have emerged as a frontier of cyber-physical systems. Despite their success in industrial monitoring applications, existing WSAN technologies face significant challenges in supporting control systems due to their lack of real-time performance and dynamic wireless conditions in industrial plants. This article reviews a series of recent advances in real-time WSANs for industrial control systems: 1) real-time scheduling algorithms and analyses for WSANs; 2) implementation and experimentation of industrial WSAN protocols; 3) cyber-physical codesign of wireless control systems that integrate wireless and control designs; and 4) a wireless cyber-physical simulator for codesign and evaluation of wireless control systems. This article concludes by highlighting research directions in industrial cyber-physical systems.",
Manifold Ranking-Based Matrix Factorization for Saliency Detection,"Saliency detection is used to identify the most important and informative area in a scene, and it is widely used in various vision tasks, including image quality assessment, image matching, and object recognition. Manifold ranking (MR) has been used to great effect for the saliency detection, since it not only incorporates the local spatial information but also utilizes the labeling information from background queries. However, MR completely ignores the feature information extracted from each superpixel. In this paper, we propose an MR-based matrix factorization (MRMF) method to overcome this limitation. MRMF models the ranking problem in the matrix factorization framework and embeds query sample labels in the coefficients. By incorporating spatial information and embedding labels, MRMF enforces similar saliency values on neighboring superpixels and ranks superpixels according to the learned coefficients. We prove that the MRMF has good generalizability, and develops an efficient optimization algorithm based on the Nesterov method. Experiments using popular benchmark data sets illustrate the promise of MRMF compared with the other state-of-the-art saliency detection methods.",
Secure Resource Allocation for OFDMA Two-Way Relay Wireless Sensor Networks Without and With Cooperative Jamming,"We consider secure resource allocations for orthogonal frequency division multiple access (OFDMA) two-way relay wireless sensor networks (WSNs). The joint problem of subcarrier (SC) assignment, SC pairing and power allocations, is formulated under scenarios of using and not using cooperative jamming (CJ) to maximize the secrecy sum rate subject to limited power budget at the relay station (RS) and orthogonal SC allocation policies. The optimization problems are shown to be mixed integer programming and nonconvex. For the scenario without CJ, we propose an asymptotically optimal algorithm based on the dual decomposition method and a suboptimal algorithm with lower complexity. For the scenario with CJ, the resulting optimization problem is nonconvex, and we propose a heuristic algorithm based on alternating optimization. Finally, the proposed schemes are evaluated by simulations and compared with the existing schemes.","Wireless sensor networks,
Resource management,
Wireless communication,
Sensors,
Relays,
Communication system security,
Jamming"
Wireless Networks with Energy Harvesting and Power Transfer: Joint Power and Time Allocation,"In this letter, we consider wireless powered communication networks which could operate perpetually, as the base station (BS) broadcasts energy to the multiple energy harvesting (EH) information transmitters. These employ “harvest then transmit” mechanism, as they spend all of their energy harvested during the previous BS energy broadcast to transmit the information towards the BS. Assuming time division multiple access (TDMA), we propose a novel transmission scheme for jointly optimal allocation of the BS broadcasting power and time sharing among the wireless nodes, which maximizes the overall network throughput, under the constraint of average transmit power and maximum transmit power at the BS. The proposed scheme significantly outperforms “state of the art” schemes that employ only the optimal time allocation. If a single EH transmitter is considered, we generalize the optimal solutions for the case of fixed circuit power consumption, which refers to a much more practical scenario.","Fading,
Throughput,
Wireless sensor networks,
Time division multiple access,
Resource management,
Wireless communication,
Optimization"
Enhanced Fingerprinting and Trajectory Prediction for IoT Localization in Smart Buildings,"Location service is one of the primary services in smart automated systems of Internet of Things (IoT). For various location-based services, accurate localization has become a key issue. Recently, research on IoT localization systems for smart buildings has been attracting increasing attention. In this paper, we propose a novel localization approach that utilizes the neighbor relative received signal strength to build the fingerprint database and adopts a Markov-chain prediction model to assist positioning. The approach is called the novel localization method (LNM) in short. In the proposed LNM scheme, the history data of the pedestrian's locations are analyzed to further lower the unpredictable signal fluctuations in a smart building environment, meanwhile enabling calibration-free positioning for various devices. The performance evaluation conducted in a realistic environment shows that the presented method demonstrates superior localization performance compared with well-known existing schemes, especially when the problems of device heterogeneity and WiFi signals fluctuation exist.",
Managing Big City Information Based on WebVRGIS,"A 3-D Shenzhen City Web platform based on the Web virtual reality geographical information system is presented. A 3-D global browser is employed to load multiple types of demand data from the city, such as 3-D building model data, residents' information, and real-time and historical traffic data. Using these data, a 3-D analysis and visualization of the city's information are conducted on a platform. The amount of information that can be visualized with this platform is very large, and the GIS-based navigational scheme enables great flexibility to access different available data sources. All the presented functions of the platform are extracted from the customers' practical demand. The system design considers some existing geographic human-computer interaction research results.","Urban areas,
Big data,
Three-dimensional displays,
Government,
Data visualization,
Solid modeling,
Urban areas,
China"
Multifactorial Evolution: Toward Evolutionary Multitasking,"The design of evolutionary algorithms has typically been focused on efficiently solving a single optimization problem at a time. Despite the implicit parallelism of population-based search, no attempt has yet been made to multitask, i.e., to solve multiple optimization problems simultaneously using a single population of evolving individuals. Accordingly, this paper introduces evolutionary multitasking as a new paradigm in the field of optimization and evolutionary computation. We first formalize the concept of evolutionary multitasking and then propose an algorithm to handle such problems. The methodology is inspired by biocultural models of multifactorial inheritance, which explain the transmission of complex developmental traits to offspring through the interactions of genetic and cultural factors. Furthermore, we develop a cross-domain optimization platform that allows one to solve diverse problems concurrently. The numerical experiments reveal several potential advantages of implicit genetic transfer in a multitasking environment. Most notably, we discover that the creation and transfer of refined genetic material can often lead to accelerated convergence for a variety of complex optimization functions.",
Analysis of EEG Signals and Facial Expressions for Continuous Emotion Detection,"Emotions are time varying affective phenomena that are elicited as a result of stimuli. Videos and movies in particular are made to elicit emotions in their audiences. Detecting the viewers' emotions instantaneously can be used to find the emotional traces of videos. In this paper, we present our approach in instantaneously detecting the emotions of video viewers' emotions from electroencephalogram (EEG) signals and facial expressions. A set of emotion inducing videos were shown to participants while their facial expressions and physiological responses were recorded. The expressed valence (negative to positive emotions) in the videos of participants' faces were annotated by five annotators. The stimuli videos were also continuously annotated on valence and arousal dimensions. Long-short-term-memory recurrent neural networks (LSTM-RNN) and continuous conditional random fields (CCRF) were utilized in detecting emotions automatically and continuously. We found the results from facial expressions to be superior to the results from EEG signals. We analyzed the effect of the contamination of facial muscle activities on EEG signals and found that most of the emotionally valuable content in EEG features are as a result of this contamination. However, our statistical analysis showed that EEG signals still carry complementary information in presence of facial expressions.",
A Four-Plate Compact Capacitive Coupler Design and LCL-Compensated Topology for Capacitive Power Transfer in Electric Vehicle Charging Application,"This paper proposes a four-plate compact capacitive coupler and its circuit model for large air-gap distance capacitive power transfer (CPT). The four plates are arranged vertically, instead of horizontally, to save space in the electric vehicle charging application. The two plates that are on the same side are placed close to each other to maintain a large coupling capacitance, and they are of different sizes to maintain the coupling between the primary and secondary sides. The circuit model of the coupler is presented, considering all six coupling capacitors. The LCL compensation topology is used to resonate with the coupler and provide high voltage on the plates to transfer high power. The circuit model of the coupler is simplified to design the parameters of the compensation circuit. Finite-element analysis is employed to simulate the coupling capacitance and design the dimensions of the coupler. The circuit performance is simulated in LTspice to design the specific parameter values. A prototype of the CPT system was designed and constructed with the proposed vertical plate structure. The prototype achieved an efficiency of 85.87% at 1.88-kW output power with a 150-mm air-gap distance.",
Demonstration of L-Shaped Tunnel Field-Effect Transistors,"An L-shaped tunnel FET (TFET), which features band-to-band tunneling (BTBT) perpendicular to the channel direction, is experimentally demonstrated for the first time. It is more scalable than other vertical-BTBT-based TFET designs and provides more than 1000× higher ON-current (ION) than a conventional planar TFET with the same gate overdrive (Vov) of 0.8 V, due to improved subthreshold swing (S) and larger tunnel junction area. Its temperature dependence, constant S, and nonlinear output characteristics are discussed.","Logic gates,
Tunneling,
Silicon,
Junctions,
Doping,
Transistors,
Electrical engineering"
"Smart Cloud Storage Service Selection Based on Fuzzy Logic, Theory of Evidence and Game Theory","Cloud platforms encompass a large number of storage services that can be used to manage the needs of customers. Each of these services, offered by a different provider, is characterized by specific features, limitations and prices. In presence of multiple options, it is crucial to select the best solution fitting the customer requirements in terms of quality of service and costs. Most of the available approaches are not able to handle uncertainty in the expression of subjective preferences from customers, and can result in wrong (or sub-optimal) service selections in presence of rational/selfish providers, exposing untrustworthy indications concerning the quality of service levels and prices associated to their offers. In addition, due to its multi-objective nature, the optimal service selection process results in a very complex task to be managed, when possible, in a distributed way, for well-known scalability reasons. In this work, we aim at facing the above challenges by proposing three novel contributions. The fuzzy sets theory is used to express vagueness in the subjective preferences of the customers. The service selection is resolved with the distributed application of fuzzy inference or Dempster-Shafer theory of evidence. The selection strategy is also complemented by the adoption of a game theoretic approach for promoting truth-telling ones among service providers. We present empirical evidence of the proposed solution effectiveness through properly crafted simulation experiments.","Cloud computing,
Biological cells,
Quality of service,
Reliability,
Fuzzy logic,
Uncertainty,
Optimization"
Exploiting Surroundedness for Saliency Detection: A Boolean Map Approach,"We demonstrate the usefulness of surroundedness for eye fixation prediction by proposing a Boolean Map based Saliency model (BMS). In our formulation, an image is characterized by a set of binary images, which are generated by randomly thresholding the image's feature maps in a whitened feature space. Based on a Gestalt principle of figure-ground segregation, BMS computes a saliency map by discovering surrounded regions via topological analysis of Boolean maps. Furthermore, we draw a connection between BMS and the Minimum Barrier Distance to provide insight into why and how BMS can properly captures the surroundedness cue via Boolean maps. The strength of BMS is verified by its simplicity, efficiency and superior performance compared with 10 state-of-the-art methods on seven eye tracking benchmark datasets.",
An Inductive and Capacitive Combined Wireless Power Transfer System With LC-Compensated Topology,"This paper proposes a combined inductive and capacitive wireless power transfer (WPT) system with LC -compensated topology for electric vehicle charging application. The circuit topology is a combination of the LCC-compensated inductive power transfer (IPT) system and the LCLC-compensated capacitive power transfer (CPT) system. The working principle of the combined circuit topology is analyzed in detail, providing the relationship between the circuit parameters and the system power. The design of the inductive and capacitive coupling is implemented by the finite-element analysis. The equivalent circuit model of the coupling plates is derived. A 3.0-kW WPT system is designed and implemented as an example of combined inductive and capacitive coupling. The inductive coupler size is 300 mm × 300 mm and the capacitive coupler is 610 mm × 610 mm. The air-gap distance is 150 mm for both couplers. The output power of the combined system is the sum of the IPT and CPT system. The prototype has achieved 2.84-kW output power with 94.5% efficiency at 1-MHz switching frequency, and performs better under misalignment than the IPT System. This demonstrates that the inductive-capacitive combined WPT system is a potential solution to the electric vehicle charging application.",
Adaptive Dynamic Programming and Adaptive Optimal Output Regulation of Linear Systems,"This note studies the adaptive optimal output regulation problem for continuous-time linear systems, which aims to achieve asymptotic tracking and disturbance rejection by minimizing some predefined costs. Reinforcement learning and adaptive dynamic programming techniques are employed to compute an approximated optimal controller using input/partial-state data despite unknown system dynamics and unmeasurable disturbance. Rigorous stability analysis shows that the proposed controller exponentially stabilizes the closed-loop system and the output of the plant asymptotically tracks the given reference signal. Simulation results on a LCL coupled inverter-based distributed generation system demonstrate the effectiveness of the proposed approach.","Regulators,
Mathematical model,
Linear systems,
Adaptive control,
Dynamic programming,
Learning (artificial intelligence)"
An Efficient SVD-Based Method for Image Denoising,"Nonlocal self-similarity of images has attracted considerable interest in the field of image processing and has led to several state-of-the-art image denoising algorithms, such as block matching and 3-D, principal component analysis with local pixel grouping, patch-based locally optimal wiener, and spatially adaptive iterative singular-value thresholding. In this paper, we propose a computationally simple denoising algorithm using the nonlocal self-similarity and the low-rank approximation (LRA). The proposed method consists of three basic steps. First, our method classifies similar image patches by the block-matching technique to form the similar patch groups, which results in the similar patch groups to be low rank. Next, each group of similar patches is factorized by singular value decomposition (SVD) and estimated by taking only a few largest singular values and corresponding singular vectors. Finally, an initial denoised image is generated by aggregating all processed patches. For low-rank matrices, SVD can provide the optimal energy compaction in the least square sense. The proposed method exploits the optimal energy compaction property of SVD to lead an LRA of similar patch groups. Unlike other SVD-based methods, the LRA in SVD domain avoids learning the local basis for representing image patches, which usually is computationally expensive. The experimental results demonstrate that the proposed method can effectively reduce noise and be competitive with the current state-of-the-art denoising algorithms in terms of both quantitative metrics and subjective visual quality.","Noise reduction,
Noise,
Image denoising,
Least squares approximations,
Principal component analysis,
Noise measurement"
Modern Advances in Wireless Power Transfer Systems for Roadway Powered Electric Vehicles,"Wireless power transfer system (WPTS)-based wireless electric vehicles, classified into roadway-powered electric vehicles (RPEVs) and stationary charging electric vehicles (SCEVs), are in the spotlight as future mainstream transportations. RPEVs are free from serious battery problems such as large, heavy, and expensive battery packs and long charging time because they get power directly from the road while moving. The power transfer capacity, efficiency, lateral tolerance, electromagnetic field, air-gap, size, weight, and cost of the WPTSs have been improved by virtues of innovative semiconductor switches, better coil designs, roadway construction techniques, and higher operating frequency. Recent advances in WPTSs for RPEVs are summarized in this review paper. The fifth- and sixth-generation online electric vehicles, which reduce infrastructure cost for commercialization, and the interoperability between RPEVs and SCEVs are addressed in detail in this paper. Major milestones of the developments of other RPEVs are also summarized. The rest of this paper deals with a few important technical issues such as coil structures, power supply schemes, and segmentation switching techniques of a lumped inductive power transfer system for RPEVs.",
Spiking Neural P Systems With White Hole Neurons,"Spiking neural P systems (SN P systems) are a class of parallel and distributed spiking neural network models, which are inspired from the way biological neurons spiking and communicating by means of spikes. White hole rules, abstracted from the biological observation of neural information rejection, were recently introduced into SN P systems, by which a neuron consumes its complete contents when it fires. In this work, SN P systems with white hole neurons are proposed, in which each neuron has only white hole rules. The computational power of general and bounded SN P systems with white hole neurons are obtained. Specifically, it is achieved in a constructive way that i) general SN P systems (having both bounded and unbounded) white hole neurons are Turing universal as number generators; ii) bounded SN P systems with white hole neurons can only characterize semi-linear sets of numbers. These results show that “information storage capacity” of certain key neurons provides some “programming capacity” useful for SN P systems achieving a desired computation power.","Neurons,
Biololgical neural networks,
Biological system modeling,
Number generators,
Parallel processing"
Spin-Transfer Torque Devices for Logic and Memory: Prospects and Perspectives,"As CMOS technology begins to face significant scaling challenges, considerable research efforts are being directed to investigate alternative device technologies that can serve as a replacement for CMOS. Spintronic devices, which utilize the spin of electrons as the state variable for computation, have recently emerged as one of the leading candidates for post-CMOS technology. Recent experiments have shown that a nano-magnet can be switched by a spin-polarized current and this has led to a number of novel device proposals over the past few years. In this paper, we provide a review of different mechanisms that manipulate the state of a nano-magnet using current-induced spin-transfer torque and demonstrate how such mechanisms have been engineered to develop device structures for energy-efficient on-chip memory and logic.","Frequency modulation,
Magnetization,
Magnetic tunneling,
Spin valves,
Torque,
Saturation magnetization,
Perpendicular magnetic anisotropy"
An Improved Multiobjective Optimization Evolutionary Algorithm Based on Decomposition for Complex Pareto Fronts,"The multiobjective evolutionary algorithm based on decomposition (MOEA/D) has been shown to be very efficient in solving multiobjective optimization problems (MOPs). In practice, the Pareto-optimal front (POF) of many MOPs has complex characteristics. For example, the POF may have a long tail and sharp peak and disconnected regions, which significantly degrades the performance of MOEA/D. This paper proposes an improved MOEA/D for handling such kind of complex problems. In the proposed algorithm, a two-phase strategy (TP) is employed to divide the whole optimization procedure into two phases. Based on the crowdedness of solutions found in the first phase, the algorithm decides whether or not to delicate computational resources to handle unsolved subproblems in the second phase. Besides, a new niche scheme is introduced into the improved MOEA/D to guide the selection of mating parents to avoid producing duplicate solutions, which is very helpful for maintaining the population diversity when the POF of the MOP being optimized is discontinuous. The performance of the proposed algorithm is investigated on some existing benchmark and newly designed MOPs with complex POF shapes in comparison with several MOEA/D variants and other approaches. The experimental results show that the proposed algorithm produces promising performance on these complex problems.","Vectors,
Optical fibers,
Sociology,
Statistics,
Optimization,
Evolutionary computation,
Shape"
Median Robust Extended Local Binary Pattern for Texture Classification,"Local binary patterns (LBP) are considered among the most computationally efficient high-performance texture features. However, the LBP method is very sensitive to image noise and is unable to capture macrostructure information. To best address these disadvantages, in this paper, we introduce a novel descriptor for texture classification, the median robust extended LBP (MRELBP). Different from the traditional LBP and many LBP variants, MRELBP compares regional image medians rather than raw image intensities. A multiscale LBP type descriptor is computed by efficiently comparing image medians over a novel sampling scheme, which can capture both microstructure and macrostructure texture information. A comprehensive evaluation on benchmark data sets reveals MRELBP's high performance-robust to gray scale variations, rotation changes and noise-but at a low computational cost. MRELBP produces the best classification scores of 99.82%, 99.38%, and 99.77% on three popular Outex test suites. More importantly, MRELBP is shown to be highly robust to image noise, including Gaussian noise, Gaussian blur, salt-and-pepper noise, and random pixel corruption.","Robustness,
Feature extraction,
Nickel,
Electronic mail,
Image analysis,
Microstructure,
Benchmark testing"
Efficient Deployment of Multiple Unmanned Aerial Vehicles for Optimal Wireless Coverage,"In this letter, the efficient deployment of multiple unmanned aerial vehicles (UAVs) acting as wireless base stations that provide coverage for ground users is analyzed. First, the downlink coverage probability for UAVs as a function of the altitude and the antenna gain is derived. Next, using circle packing theory, the 3-D locations of the UAVs is determined in a way that the total coverage area is maximized while maximizing the coverage lifetime of the UAVs. Our results show that, in order to mitigate interference, the altitude of the UAVs must be properly adjusted based on the beamwidth of the directional antenna as well as coverage requirements. Furthermore, the minimum number of UAVs needed to guarantee a target coverage probability for a given geographical area is determined. Numerical results evaluate various tradeoffs.","Interference,
Wireless communication,
Base stations,
Directional antennas,
Downlink,
Wireless sensor networks,
Atmospheric modeling"
Evidence Combination From an Evolutionary Game Theory Perspective,"Dempster-Shafer evidence theory is a primary methodology for multisource information fusion because it is good at dealing with uncertain information. This theory provides a Dempster's rule of combination to synthesize multiple evidences from various information sources. However, in some cases, counter-intuitive results may be obtained based on that combination rule. Numerous new or improved methods have been proposed to suppress these counter-intuitive results based on perspectives, such as minimizing the information loss or deviation. Inspired by evolutionary game theory, this paper considers a biological and evolutionary perspective to study the combination of evidences. An evolutionary combination rule (ECR) is proposed to help find the most biologically supported proposition in a multievidence system. Within the proposed ECR, we develop a Jaccard matrix game to formalize the interaction between propositions in evidences, and utilize the replicator dynamics to mimick the evolution of propositions. Experimental results show that the proposed ECR can effectively suppress the counter-intuitive behaviors appeared in typical paradoxes of evidence theory, compared with many existing methods. Properties of the ECR, such as solution's stability and convergence, have been mathematically proved as well.","Sociology,
Statistics,
Games,
Game theory,
Evolution (biology),
Stability analysis"
"Interference Alignment and Its Applications: A Survey, Research Issues, and Challenges","The capacity of interference network is a fundamental issue that eludes the researchers for decades. Interference alignment (IA) is an emerging interference management technique that is degrees of freedom (DoFs) optimal, which means it can approach the capacity of interference network at very high signal-to-noise ratio (SNR). In IA networks, the signals are constrained into the same subspaces at the unintended receivers through cooperative precoding, and the desired signal can be recovered at each receiver by eliminating the aligned interferences using decoding matrix. Due to its promising performance in interference management, IA has successfully been applied to many kinds of multiuser wireless networks with excellent performance. Nevertheless, there are still some challenges for the practical utilization of IA, e.g., the overhead of channel state information (CSI) feedback, performance degradation at low and moderate SNRs, etc. In this review, we provide a survey on IA and its applications and discuss some research issues and challenges. The dimensions, networks topologies, and applications of IA are first introduced. Then some fundamental aspects of IA are discussed, including feasibility condition, performance metrics, iterative algorithms, and CSI. We also present some recent research issues of opportunistic IA, spectrum sharing, green IA, topology management, and physical layer security. Finally, some research challenges of IA are identified.","Interference,
Signal to noise ratio,
Receivers,
Network topology,
Wireless communication,
Antennas,
Channel state information"
Person Re-Identification by Dual-Regularized KISS Metric Learning,"Person re-identification aims to match the images of pedestrians across different camera views from different locations. This is a challenging intelligent video surveillance problem that remains an active area of research due to the need for performance improvement. Person re-identification involves two main steps: feature representation and metric learning. Although the keep it simple and straightforward (KISS) metric learning method for discriminative distance metric learning has been shown to be effective for the person re-identification, the estimation of the inverse of a covariance matrix is unstable and indeed may not exist when the training set is small, resulting in poor performance. Here, we present dual-regularized KISS (DR-KISS) metric learning. By regularizing the two covariance matrices, DR-KISS improves on KISS by reducing overestimation of large eigenvalues of the two estimated covariance matrices and, in doing so, guarantees that the covariance matrix is irreversible. Furthermore, we provide theoretical analyses for supporting the motivations. Specifically, we first prove why the regularization is necessary. Then, we prove that the proposed method is robust for generalization. We conduct extensive experiments on three challenging person re-identification datasets, VIPeR, GRID, and CUHK 01, and show that DR-KISS achieves new state-of-the-art performance.","Measurement,
Covariance matrices,
Robustness,
Feature extraction,
Image color analysis,
Electronic mail,
Training"
Multi-Scale Patch-Based Image Restoration,"Many image restoration algorithms in recent years are based on patch processing. The core idea is to decompose the target image into fully overlapping patches, restore each of them separately, and then merge the results by a plain averaging. This concept has been demonstrated to be highly effective, leading often times to the state-of-the-art results in denoising, inpainting, deblurring, segmentation, and other applications. While the above is indeed effective, this approach has one major flaw: the prior is imposed on intermediate (patch) results, rather than on the final outcome, and this is typically manifested by visual artifacts. The expected patch log likelihood (EPLL) method by Zoran and Weiss was conceived for addressing this very problem. Their algorithm imposes the prior on the patches of the final image, which in turn leads to an iterative restoration of diminishing effect. In this paper, we propose to further extend and improve the EPLL by considering a multi-scale prior. Our algorithm imposes the very same prior on different scale patches extracted from the target image. While all the treated patches are of the same size, their footprint in the destination image varies due to subsampling. Our scheme comes to alleviate another shortcoming existing in patch-based restoration algorithms-the fact that a local (patch-based) prior is serving as a model for a global stochastic phenomenon. We motivate the use of the multi-scale EPLL by restricting ourselves to the simple Gaussian case, comparing the aforementioned algorithms and showing a clear advantage to the proposed method. We then demonstrate our algorithm in the context of image denoising, deblurring, and super-resolution, showing an improvement in performance both visually and quantitatively.","Noise reduction,
Image restoration,
Mathematical model,
Closed-form solutions,
Approximation methods,
Context awareness"
Incremental Semi-Supervised Clustering Ensemble for High Dimensional Data Clustering,"Traditional cluster ensemble approaches have three limitations: (1) They do not make use of prior knowledge of the datasets given by experts. (2) Most of the conventional cluster ensemble methods cannot obtain satisfactory results when handling high dimensional data. (3) All the ensemble members are considered, even the ones without positive contributions. In order to address the limitations of conventional cluster ensemble approaches, we first propose an incremental semi-supervised clustering ensemble framework (ISSCE) which makes use of the advantage of the random subspace technique, the constraint propagation approach, the proposed incremental ensemble member selection process, and the normalized cut algorithm to perform high dimensional data clustering. The random subspace technique is effective for handling high dimensional data, while the constraint propagation approach is useful for incorporating prior knowledge. The incremental ensemble member selection process is newly designed to judiciously remove redundant ensemble members based on a newly proposed local cost function and a global cost function, and the normalized cut algorithm is adopted to serve as the consensus function for providing more stable, robust, and accurate results. Then, a measure is proposed to quantify the similarity between two sets of attributes, and is used for computing the local cost function in ISSCE. Next, we analyze the time complexity of ISSCE theoretically. Finally, a set of nonparametric tests are adopted to compare multiple semisupervised clustering ensemble approaches over different datasets. The experiments on 18 real-world datasets, which include six UCI datasets and 12 cancer gene expression profiles, confirm that ISSCE works well on datasets with very high dimensionality, and outperforms the state-of-the-art semi-supervised clustering ensemble approaches.","Linear programming,
Clustering algorithms,
Cost function,
Algorithm design and analysis,
Search problems,
Gene expression,
Cancer"
"Free-Space Optical Communications: Capacity Bounds, Approximations, and a New Sphere-Packing Perspective","The capacity of the free-space optical channel is studied. A new recursive approach for bounding the capacity of the channel based on sphere-packing is proposed. This approach leads to new capacity upper bounds for a channel with a peak intensity constraint or an average intensity constraint. Under an average constraint only, the derived bound is tighter than an existing sphere-packing bound derived earlier by Farid and Hranilovic. The achievable rate of a truncated-Gaussian input distribution is also derived. It is shown that under both average and peak constraints, this achievable rate and the sphere-packing bounds are within a small gap at high SNR, leading to a simple high-SNR capacity approximation. Simple fitting functions that capture the best known achievable rate for the channel are provided. These functions can be of practical importance especially for the study of systems operating under atmospheric turbulence and misalignment conditions.","Signal to noise ratio,
Channel capacity,
Upper bound,
High-speed optical techniques,
Optical mixing,
Random variables,
Yttrium"
Time-Delay Controller Design for Position Control of Autonomous Underwater Vehicle Under Disturbances,"This paper presents an enhanced time-delay controller (TDC) for the position control of an autonomous underwater vehicle (AUV) under disturbances. A conventional TDC performs well when the involved data acquisition rate is fast. However, in AUV control applications that use a Doppler velocity log (DVL) navigation system, we cannot keep the data acquisition rate sufficiently fast because a DVL sensor generally supplies data at a slow acquisition rate, which degrades the performance of the TDC. To overcome this problem, we propose an integral sliding-mode controller to be supplemented to the conventional TDC to improve the control precision even if the DVL navigation system is in operation. The proposed controller is computationally simple and robust to unmodeled dynamics and disturbances. We performed computer simulations and experiments with the Cyclops AUV to demonstrate the validity of the proposed controller.",
Robust Visual Tracking via Convolutional Networks Without Training,"Deep networks have been successfully applied to visual tracking by learning a generic representation offline from numerous training images. However, the offline training is time-consuming and the learned generic representation may be less discriminative for tracking specific objects. In this paper, we present that, even without offline training with a large amount of auxiliary data, simple two-layer convolutional networks can be powerful enough to learn robust representations for visual tracking. In the first frame, we extract a set of normalized patches from the target region as fixed filters, which integrate a series of adaptive contextual filters surrounding the target to define a set of feature maps in the subsequent frames. These maps measure similarities between each filter and useful local intensity patterns across the target, thereby encoding its local structural information. Furthermore, all the maps together form a global representation, via which the inner geometric layout of the target is also preserved. A simple soft shrinkage method that suppresses noisy values below an adaptive threshold is employed to de-noise the global representation. Our convolutional networks have a lightweight structure and perform favorably against several state-of-the-art methods on the recent tracking benchmark data set with 50 challenging videos.","Feature extraction,
Visualization,
Target tracking,
Robustness,
Layout,
Training,
Computer architecture"
Structured Compressive Sensing-Based Spatio-Temporal Joint Channel Estimation for FDD Massive MIMO,"Massive MIMO is a promising technique for future 5G communications due to its high spectrum and energy efficiency. To realize its potential performance gain, accurate channel estimation is essential. However, due to massive number of antennas at the base station (BS), the pilot overhead required by conventional channel estimation schemes will be unaffordable, especially for frequency division duplex (FDD) massive MIMO. To overcome this problem, we propose a structured compressive sensing (SCS)-based spatio-temporal joint channel estimation scheme to reduce the required pilot overhead, whereby the spatio-temporal common sparsity of delay-domain MIMO channels is leveraged. Particularly, we first propose the nonorthogonal pilots at the BS under the framework of CS theory to reduce the required pilot overhead. Then, an adaptive structured subspace pursuit (ASSP) algorithm at the user is proposed to jointly estimate channels associated with multiple OFDM symbols from the limited number of pilots, whereby the spatio-temporal common sparsity of MIMO channels is exploited to improve the channel estimation accuracy. Moreover, by exploiting the temporal channel correlation, we propose a space-time adaptive pilot scheme to further reduce the pilot overhead. Additionally, we discuss the proposed channel estimation scheme in multicell scenario. Simulation results demonstrate that the proposed scheme can accurately estimate channels with the reduced pilot overhead, and it is capable of approaching the optimal oracle least squares estimator.","Channel estimation,
MIMO,
Transmitting antennas,
Delays,
Correlation,
OFDM,
Wireless communication"
Hybrid Block Diagonalization for Massive Multiuser MIMO Systems,"For a massive multiple-input multiple-output (MIMO) system, restricting the number of RF chains to far less than the number of antenna elements can significantly reduce the implementation cost compared to the full complexity RF chain configuration. In this paper, we consider the downlink communication of a massive multiuser MIMO (MU-MIMO) system and propose a low-complexity hybrid block diagonalization (Hy-BD) scheme to approach the capacity performance of the traditional BD processing method. We aim to harvest the large array gain through the phase-only RF precoding and combining and then digital BD processing is performed on the equivalent baseband channel. The proposed Hy-BD scheme is examined in both the large Rayleigh fading channels and millimeter wave (mmWave) channels. A performance analysis is further conducted for single-path channels and large number of transmit and receive antennas. Finally, simulation results demonstrate that our Hy-BD scheme, with a lower implementation and computational complexity, achieves a capacity performance that is close to (sometimes even higher than) that of the traditional high-dimensional BD processing.",
Complex Ratio Masking for Monaural Speech Separation,"Speech separation systems usually operate on the short-time Fourier transform (STFT) of noisy speech, and enhance only the magnitude spectrum while leaving the phase spectrum unchanged. This is done because there was a belief that the phase spectrum is unimportant for speech enhancement. Recent studies, however, suggest that phase is important for perceptual quality, leading some researchers to consider magnitude and phase spectrum enhancements. We present a supervised monaural speech separation approach that simultaneously enhances the magnitude and phase spectra by operating in the complex domain. Our approach uses a deep neural network to estimate the real and imaginary components of the ideal ratio mask defined in the complex domain. We report separation results for the proposed method and compare them to related systems. The proposed approach improves over other methods when evaluated with several objective metrics, including the perceptual evaluation of speech quality (PESQ), and a listening test where subjects prefer the proposed approach with at least a 69% rate.","Speech,
Noise measurement,
Time-frequency analysis,
Signal to noise ratio,
Speech enhancement,
Spectrogram"
Domain Adaptation for the Classification of Remote Sensing Data: An Overview of Recent Advances,"The success of the supervised classification of remotely sensed images acquired over large geographical areas or at short time intervals strongly depends on the representativity of the samples used to train the classification algorithm and to define the model. When training samples are collected from an image or a spatial region that is different from the one used for mapping, spectral shifts between the two distributions are likely to make the model fail. Such shifts are generally due to differences in acquisition and atmospheric conditions or to changes in the nature of the object observed. To design classification methods that are robust to data set shifts, recent remote sensing literature has considered solutions based on domain adaptation (DA) approaches. Inspired by machine-learning literature, several DA methods have been proposed to solve specific problems in remote sensing data classification. This article provides a critical review of the recent advances in DA approaches for remote sensing and presents an overview of DA methods divided into four categories: 1) invariant feature selection, 2) representation matching, 3) adaptation of classifiers, and 4) selective sampling. We provide an overview of recent methodologies, examples of applications of the considered techniques to real remote sensing images characterized by very high spatial and spectral resolution as well as possible guidelines for the selection of the method to use in real application scenarios.","Remote sensing,
Adaptation models,
Training,
Sensors,
Image sensors,
Data models,
Supervised learning"
A Unified Framework for Representation-Based Subspace Clustering of Out-of-Sample and Large-Scale Data,"Under the framework of spectral clustering, the key of subspace clustering is building a similarity graph, which describes the neighborhood relations among data points. Some recent works build the graph using sparse, low-rank, and ℓ2-norm-based representation, and have achieved the state-of-the-art performance. However, these methods have suffered from the following two limitations. First, the time complexities of these methods are at least proportional to the cube of the data size, which make those methods inefficient for solving the large-scale problems. Second, they cannot cope with the out-of-sample data that are not used to construct the similarity graph. To cluster each out-of-sample datum, the methods have to recalculate the similarity graph and the cluster membership of the whole data set. In this paper, we propose a unified framework that makes the representation-based subspace clustering algorithms feasible to cluster both the out-of-sample and the large-scale data. Under our framework, the large-scale problem is tackled by converting it as the out-of-sample problem in the manner of sampling, clustering, coding, and classifying. Furthermore, we give an estimation for the error bounds by treating each subspace as a point in a hyperspace. Extensive experimental results on various benchmark data sets show that our methods outperform several recently proposed scalable methods in clustering a large-scale data set.","Clustering algorithms,
Yttrium,
Encoding,
Error analysis,
Laplace equations,
Sparse matrices,
Clustering methods"
Software-Defined Industrial Internet of Things in the Context of Industry 4.0,"In recent years, there have been great advances in industrial Internet of Things (IIoT) and its related domains, such as industrial wireless networks (IWNs), big data, and cloud computing. These emerging technologies will bring great opportunities for promoting industrial upgrades and even allow the introduction of the fourth industrial revolution, namely, Industry 4.0. In the context of Industry 4.0, all kinds of intelligent equipment (e.g., industrial robots) supported by wired or wireless networks are widely adopted, and both real-time and delayed signals coexist. Therefore, based on the advancement of software-defined networks technology, we propose a new concept for industrial environments by introducing software-defined IIoT in order to make the network more flexible. In this paper, we analyze the IIoT architecture, including physical layer, IWNs, industrial cloud, and smart terminals, and describe the information interaction among different devices. Then, we propose a software-defined IIoT architecture to manage physical devices and provide an interface for information exchange. Subsequently, we discuss the prominent problems and possible solutions for software-defined IIoT. Finally, we select an intelligent manufacturing environment as an assessment test bed, and implement the basic experimental analysis. This paper will open a new research direction of IIoT and accelerate the implementation of Industry 4.0.","Cloud computing,
Industries,
Sensors,
Physical layer,
Information exchange,
Wireless networks,
Manufacturing"
Game Theoretic Resource Allocation in Media Cloud With Mobile Social Users,"Due to the rapid increases in both the population of mobile social users and the demand for quality of experience (QoE), providing mobile social users with satisfied multimedia services has become an important issue. Media cloud has been shown to be an efficient solution to resolve the above issue, by allowing mobile social users to connect to it through a group of distributed brokers. However, as the resource in media cloud is limited, how to allocate resource among media cloud, brokers, and mobile social users becomes a new challenge. Therefore, in this paper, we propose a game theoretic resource allocation scheme for media cloud to allocate resource to mobile social users though brokers. First, a framework of resource allocation among media cloud, brokers, and mobile social users is presented. Media cloud can dynamically determine the price of the resource and allocate its resource to brokers. A mobile social user can select his broker to connect to the media cloud by adjusting the strategy to achieve the maximum revenue, based on the social features in the community. Next, we formulate the interactions among media cloud, brokers, and mobile social users by a four-stage Stackelberg game. In addition, through the backward induction method, we propose an iterative algorithm to implement the proposed scheme and obtain the Stackelberg equilibrium. Finally, simulation results show that each player in the game can obtain the optimal strategy where the Stackelberg equilibrium exists stably.",
Fundamental Duty Modulation of Dual-Active-Bridge Converter for Wide-Range Operation,"This paper proposed a modulation scheme for the dual-active-bridge (DAB) converter to reduce rms current in wide-range operating conditions. The operating principle of the proposed fundamental duty modulation (FDM) is formulated based on the fundamental component analysis of the DAB converter. By modulating the PWM signals in the fundamental component domain, the optimal operation is implemented with a simple controller structure not requiring an operating mode classification, offline calculation, or current information. Operating characteristics including rms current level and ZVS characteristics are analyzed to compare loss breakdowns of the proposed scheme to those of recent related works. The proposed FDM achieves high efficiency under wide operation conditions due to reduced conduction level and wide ZVS range. Experimental results are obtained under various voltage gain and load conditions to confirm the operation of the proposed modulation scheme. A thorough experimental comparison with other sophisticated modulation schemes has verified the efficiency improvement of FDM.","Frequency division multiplexing,
Time-domain analysis,
Mathematical model,
Pulse width modulation,
Voltage control,
Inductors"
"TinyOS-New Trends, Comparative Views, and Supported Sensing Applications: A Review","The wireless sensor network (WSN) is an interesting area for modern day research groups. Tiny sensor nodes are deployed in a diversity of environments but with limited resources. Scarce resources compel researchers to employ an operating system that requires limited memory and minimum power. Tiny operating system (TinyOS) is a widely used operating system for sensor nodes, which provides concurrency and flexibility while adhering to the constraints of scarce resources. Comparatively, TinyOS is considered to be the most robust, innovative, energy-efficient, and widely used operating system in sensor networks. This paper looks at the state-of-the-art TinyOS and the different dimensions of its design paradigm, programming model, execution model, scheduling algorithms, concurrency, memory management, hardware support platforms, and other features. The addition of different features in TinyOS makes it the operating system of choice for WSNs. Sensing nodes with TinyOS seem to show more flexibility in supporting diverse types of sensing applications.","Sensors,
Wireless sensor networks,
Operating systems,
Concurrent computing,
Programming,
Instruction sets,
Adaptation models"
A Robust Indoor Positioning System Based on the Procrustes Analysis and Weighted Extreme Learning Machine,"Indoor positioning system (IPS) has become one of the most attractive research fields due to the increasing demands on location-based services (LBSs) in indoor environments. Various IPSs have been developed under different circumstances, and most of them adopt the fingerprinting technique to mitigate pervasive indoor multipath effects. However, the performance of the fingerprinting technique severely suffers from device heterogeneity existing across commercial off-the-shelf mobile devices (e.g., smart phones, tablet computers, etc.) and indoor environmental changes (e.g., the number, distribution and activities of people, the placement of furniture, etc.). In this paper, we transform the received signal strength (RSS) to a standardized location fingerprint based on the Procrustes analysis, and introduce a similarity metric, termed signal tendency index (STI), for matching standardized fingerprints. An analysis of the capability of the proposed STI to handle device heterogeneity and environmental changes is presented. We further develop a robust and precise IPS by integrating the merits of both the STI and weighted extreme learning machine (WELM). Finally, extensive experiments are carried out and a performance comparison with existing solutions verifies the superiority of the proposed IPS in terms of robustness to device heterogeneity.","IEEE 802.11 Standard,
Robustness,
Mobile handsets,
Training,
Accuracy,
Shape,
Databases"
Deep Ranking for Person Re-Identification via Joint Representation Learning,"This paper proposes a novel approach to person re-identification, a fundamental task in distributed multi-camera surveillance systems. Although a variety of powerful algorithms have been presented in the past few years, most of them usually focus on designing hand-crafted features and learning metrics either individually or sequentially. Different from previous works, we formulate a unified deep ranking framework that jointly tackles both of these key components to maximize their strengths. We start from the principle that the correct match of the probe image should be positioned in the top rank within the whole gallery set. An effective learning-to-rank algorithm is proposed to minimize the cost corresponding to the ranking disorders of the gallery. The ranking model is solved with a deep convolutional neural network (CNN) that builds the relation between input image pairs and their similarity scores through joint representation learning directly from raw image pixels. The proposed framework allows us to get rid of feature engineering and does not rely on any assumption. An extensive comparative evaluation is given, demonstrating that our approach significantly outperforms all the state-of-the-art approaches, including both traditional and CNN-based methods on the challenging VIPeR, CUHK-01, and CAVIAR4REID datasets. In addition, our approach has better ability to generalize across datasets without fine-tuning.","Measurement,
Feature extraction,
Image color analysis,
Machine learning,
Cameras,
Algorithm design and analysis,
Probes"
Adaptive Processing for Distributed Skyline Queries over Uncertain Data,"Query processing over uncertain data has gained growing attention, because it is necessary to deal with uncertain data in many real-life applications. In this paper, we investigate skyline queries over uncertain data in distributed environments (DSUD query) whose research is only in an early stage. The state-of-the-art algorithm, called e-DSUD algorithm, is designed for processing this query. It has the desirable characteristics of progressiveness and minimum bandwidth consumption. However, it still needs to be perfected in three aspects. (1) Progressiveness. Each time it only returns one query result at most. (2) Efficiency. There are a significant amount of redundant I/O cost and numerous iterations which causes a long total query time. (3) Universality. It is restricted to the case where local skyline tuples are incomparability. To address these concerns, we first present a detailed analysis of the e-DSUD algorithm and then develop an improved framework for the DSUD query, namely IDSUD. Based on the new framework, we propose an adaptive algorithm, called ADSUD, for the DSUD query. In the algorithm, we redefine the approximate global skyline probability and choose local representative tuples due to minimum probabilistic bounding rectangle adaptively. Furthermore, we design a progressive pruning method and apply the reuse mechanism to improve its efficiency. The results of extensive experiments verify the better overall performance of our algorithm than the e-DSUD algorithm.","Distributed databases,
Servers,
Algorithm design and analysis,
Approximation algorithms,
Probabilistic logic,
Bandwidth"
An Automatic Learning-Based Framework for Robust Nucleus Segmentation,"Computer-aided image analysis of histopathology specimens could potentially provide support for early detection and improved characterization of diseases such as brain tumor, pancreatic neuroendocrine tumor (NET), and breast cancer. Automated nucleus segmentation is a prerequisite for various quantitative analyses including automatic morphological feature computation. However, it remains to be a challenging problem due to the complex nature of histopathology images. In this paper, we propose a learning-based framework for robust and automatic nucleus segmentation with shape preservation. Given a nucleus image, it begins with a deep convolutional neural network (CNN) model to generate a probability map, on which an iterative region merging approach is performed for shape initializations. Next, a novel segmentation algorithm is exploited to separate individual nuclei combining a robust selection-based sparse shape model and a local repulsive deformable model. One of the significant benefits of the proposed framework is that it is applicable to different staining histopathology images. Due to the feature learning characteristic of the deep CNN and the high level shape prior modeling, the proposed method is general enough to perform well across multiple scenarios. We have tested the proposed algorithm on three large-scale pathology image datasets using a range of different tissue and stain preparations, and the comparative experiments with recent state of the arts demonstrate the superior performance of the proposed approach.","Shape,
Image segmentation,
Image color analysis,
Robustness,
Computational modeling,
Tumors,
Breast cancer"
Real-Time Locating Systems Using Active RFID for Internet of Things,"The proliferation of the Internet of Things (IoT) has fostered growing attention to real-time locating systems (RTLSs) using radio frequency identification (RFID) for asset management, which can automatically identify and track physical objects within indoor or confined environments. Various RFID indoor locating systems have been proposed. However, most of them are inappropriate for large-scale IoT applications owing to severe radio multipath, diffraction, and reflection. In this paper, we propose a newly fashioned RTLS using active RFID for the IoT, i.e., iLocate, which locates objects at high levels of accuracy up to 30 cm with ultralong distance transmission. To achieve fine-grained localization accuracy, iLocate presents the concept of virtual reference tags. To overcome signal multipath, iLocate employs a frequency-hopping technique to schedule RFID communication. To support large-scale RFID networks, iLocate leverages the ZigBee. We implement all hardware using 2.45-GHz RFID chips so that each active tag can communicate with readers that are around 1000 m away in a free space. Our empirical study and real project deployment show the superiority of the proposed system with respect to the localization accuracy and the data transmission rate for large-scale active RFID networks.","Active RFID tags,
Accuracy,
Real-time systems,
Antennas,
Radio frequency,
Educational institutions"
Containment Control of Multiagent Systems With Dynamic Leaders Based on a PI^{n} -Type Approach,"This paper studies the containment control of multiagent systems (MASs) with multiple dynamic leaders in both continuous-time domain and discrete-time domain. The leaders' motions are described by the nth-order polynomial trajectories. This setting makes practical sense because given some critical points, the leaders' trajectories are usually planned by the polynomial interpolations. In order to drive all followers into the convex hull spanned by the leaders, a PIn-type containment algorithm is proposed (P and I are short for proportional and integral, respectively; In implies that the algorithm includes up to the n-thorder integral terms). It is theoretically proved that the PIn-type containment algorithm is able to solve the containment problem of MASs where the followers are described by any order integral dynamics. Compared to the previous results on the MASs with dynamic leaders, the distinguished features of this paper are that: 1) the containment problem is studied not only in the continuoustime domain but also in the discrete-time domain while most existing results only work in the continuous-time domain; 2) to deal with the leaders with the nth-order polynomial trajectories, existing results require the follower's dynamics to be the (n + 1)th-order integral while the followers considered in this paper can be described by any-order integral dynamics; 3) the “sign” function is not employed in the proposed algorithm, which avoids the chattering phenomenon; and 4) both disturbance and measurement noise are taken into account. Finally, some simulation examples are given to demonstrate the effectiveness of the proposed algorithm.",
Social-Aware Video Multicast Based on Device-to-Device Communications,"To meet the explosive demand on delivering high-definition video steams over cellular networks, we design a Social-aware video multiCast (SoCast) system leveraging device-to-device (D2D) communications. One salient feature of SoCast is to stimulate effective cooperation among mobile users (clients), by making use of two types of important social ties, i.e., social trust and social reciprocity. By using SoCast, clients form groups to obtain missing packets from other clients and restore incomplete video frames, according to the unique video encoding structure. In return, the user perception of the mobile video quality can be substantially improved. Specifically, we first cast the problem of social ties based group formation among clients for cooperative video multicast as a coalitional game, and then devise a distributed algorithm to obtain the core solution (group formation) for the formulated coalitional game. Further, a resource allocation scheme is proposed for the base station to handle D2D radio resource requests from client groups. Extensive numerical studies using real video traces corroborate the significant gain using SoCast.","Streaming media,
Mobile communication,
Mobile computing,
Encoding,
Resource management,
Engines,
Video recording"
High Capacity Reversible Data Hiding in Encrypted Images by Patch-Level Sparse Representation,"Reversible data hiding in encrypted images has attracted considerable attention from the communities of privacy security and protection. The success of the previous methods in this area has shown that a superior performance can be achieved by exploiting the redundancy within the image. Specifically, because the pixels in the local structures (like patches or regions) have a strong similarity, they can be heavily compressed, thus resulting in a large hiding room. In this paper, to better explore the correlation between neighbor pixels, we propose to consider the patch-level sparse representation when hiding the secret data. The widely used sparse coding technique has demonstrated that a patch can be linearly represented by some atoms in an over-complete dictionary. As the sparse coding is an approximation solution, the leading residual errors are encoded and self-embedded within the cover image. Furthermore, the learned dictionary is also embedded into the encrypted image. Thanks to the powerful representation of sparse coding, a large vacated room can be achieved, and thus the data hider can embed more secret messages in the encrypted image. Extensive experiments demonstrate that the proposed method significantly outperforms the state-of-the-art methods in terms of the embedding rate and the image quality.","Encryption,
Data mining,
Image coding,
Receivers,
Encoding,
Data hiding"
Nonsmooth Finite-Time Synchronization of Switched Coupled Neural Networks,"This paper is concerned with the finite-time synchronization (FTS) issue of switched coupled neural networks with discontinuous or continuous activations. Based on the framework of nonsmooth analysis, some discontinuous or continuous controllers are designed to force the coupled networks to synchronize to an isolated neural network. Some sufficient conditions are derived to ensure the FTS by utilizing the well-known finite-time stability theorem for nonlinear systems. Compared with the previous literatures, such synchronization objective will be realized when the activations and the controllers are both discontinuous. The obtained results in this paper include and extend the earlier works on the synchronization issue of coupled networks with Lipschitz continuous conditions. Moreover, an upper bound of the settling time for synchronization is estimated. Finally, numerical simulations are given to demonstrate the effectiveness of the theoretical results.",
Sub-Markov Random Walk for Image Segmentation,"A novel sub-Markov random walk (subRW) algorithm with label prior is proposed for seeded image segmentation, which can be interpreted as a traditional random walker on a graph with added auxiliary nodes. Under this explanation, we unify the proposed subRW and other popular random walk (RW) algorithms. This unifying view will make it possible for transferring intrinsic findings between different RW algorithms, and offer new ideas for designing novel RW algorithms by adding or changing auxiliary nodes. To verify the second benefit, we design a new subRW algorithm with label prior to solve the segmentation problem of objects with thin and elongated parts. The experimental results on both synthetic and natural images with twigs demonstrate that the proposed subRW method outperforms previous RW algorithms for seeded image segmentation.",
A Survey on Metamorphic Testing,"A test oracle determines whether a test execution reveals a fault, often by comparing the observed program output to the expected output. This is not always practical, for example when a program's input-output relation is complex and difficult to capture formally. Metamorphic testing provides an alternative, where correctness is not determined by checking an individual concrete output, but by applying a transformation to a test input and observing how the program output “morphs” into a different one as a result. Since the introduction of such metamorphic relations in 1998, many contributions on metamorphic testing have been made, and the technique has seen successful applications in a variety of domains, ranging from web services to computer graphics. This article provides a comprehensive survey on metamorphic testing: It summarises the research results and application areas, and analyses common practice in empirical studies of metamorphic testing as well as the main open challenges.","Testing,
Search engines,
Google,
Libraries,
Concrete,
Distance measurement,
Web services"
Interference Alignment Based on Antenna Selection With Imperfect Channel State Information in Cognitive Radio Networks,"Interference alignment (IA) is a promising technique that can eliminate interference in wireless networks effectively and has been applied to spectrum sharing in cognitive radio (CR) networks. However, most existing IA schemes neglect the quality of the desired signal, which may lead to poor performance, particularly at poor channel status. In this paper, we analyze the problem of the decrease in the signal-to-interference-plus-noise ratio (SINR) of the desired signal and propose a novel IA scheme based on antenna selection (AS) to improve the received SINR of each user in IA-based CR networks. In the proposed scheme, multiple antennas are equipped at each secondary receiver, and some of them are chosen to achieve optimal performance. Furthermore, the condition of imperfect channel state information (CSI) is also considered, which can impact the performance of IA-AS. To face this problem, a scheme called CSI filtering is proposed to weaken the influence of the imperfect CSI. Moreover, considering the considerable computational complexity brought by the selection among mass of antenna combinations, an efficient IA-AS algorithm based on discrete stochastic optimization (DSO) is thus proposed, which can converge quickly to the optimum with low computational complexity. To further improve the tracking performance of the algorithm under a time-varying channel environment, we propose an adaptive DSO scheme with window CSI filtering for IA-AS to give the algorithm a good tracking capability. Simulation results are presented to show that the proposed schemes can significantly improve the performance of IA-based CR networks.","Interference,
Signal to noise ratio,
Receiving antennas,
Upper bound,
Transmitters"
Saliency-Guided Quality Assessment of Screen Content Images,"With the widespread adoption of multidevice communication, such as telecommuting, screen content images (SCIs) have become more closely and frequently related to our daily lives. For SCIs, the tasks of accurate visual quality assessment, high-efficiency compression, and suitable contrast enhancement have thus currently attracted increased attention. In particular, the quality evaluation of SCIs is important due to its good ability for instruction and optimization in various processing systems. Hence, in this paper, we develop a new objective metric for research on perceptual quality assessment of distorted SCIs. Compared to the classical MSE, our method, which mainly relies on simple convolution operators, first highlights the degradations in structures caused by different types of distortions and then detects salient areas where the distortions usually attract more attention. A comparison of our algorithm with the most popular and state-of-the-art quality measures is performed on two new SCI databases (SIQAD and SCD). Extensive results are provided to verify the superiority and efficiency of the proposed IQA technique.","Visualization,
Image coding,
Convolution,
Quality assessment,
Degradation,
Distortion,
Image color analysis"
Sparsity-Induced Similarity Measure and Its Applications,"The structures of feature vectors-based semisupervised/supervised learning have gained considerable interest in recent years due to their effectiveness for better object modeling and classification. In many machine learning and computer vision tasks, a critical issue is the similarity between two feature vectors. In this paper, we present a novel technique to measure similarities among feature vectors by decomposing each feature vector as an ℓ1 sparse linear combination of the rest of the feature vectors. The main idea is that the coefficients in such sparse decomposition reflect the features' neighborhood structure, thus providing better similarity measures among the decomposed feature vector and the rest of the feature vectors. The proposed approach is applied to label propagation and action recognition, and is evaluated on several commonly used datasets. The experimental results show that the proposed sparsity-induced similarity measure significantly improves the performance of both label propagation and action recognition.","Vectors,
Encoding,
Computer vision,
Semisupervised learning,
Supervised learning,
Machine learning,
Electronic mail"
A Switching Approach to Designing Finite-Time Synchronization Controllers of Coupled Neural Networks,"This paper is concerned with the finite-time synchronization issue of nonlinear coupled neural networks by designing a new switching pinning controller. For the fixed network topology and control strength, the newly designed controller could optimize the synchronization time by regulating a parameter α (0 ≤ α <; 1). The control law presented in this paper covers both continuous controllers and discontinuous ones, which were studied separately in the past. Some criteria are discussed in detail on how to shorten the synchronization time for the strongly connected networks. Finally, the results are generalized to any network topologies containing a directed spanning tree, and one numerical example is given to demonstrate the effectiveness of the theoretical results.","Synchronization,
Neural networks,
Switches,
Convergence,
Network topology,
Couplings"
A Hierarchical Security Framework for Defending Against Sophisticated Attacks on Wireless Sensor Networks in Smart Cities,"In smart cities, wireless sensor networks (WSNs) act as a type of core infrastructure that collects data from the city to implement smart services. The security of WSNs is one of the key issues of smart cities. In resource-restrained WSNs, dynamic ongoing or unknown attacks usually steer clear of isolated defense components. Therefore, to resolve this problem, we propose a hierarchical framework based on chance discovery and usage control (UCON) technologies to improve the security of WSNs while still taking the low-complexity and high security requirements of WSNs into account. The features of continuous decision and dynamic attributes in UCON can address ongoing attacks using advanced persistent threat detection. In addition, we use a dynamic adaptive chance discovery mechanism to detect unknown attacks. To design and implement a system using the mechanism described above, a unified framework is proposed in which low-level attack detection with simple rules is performed in sensors, and high-level attack detection with complex rules is performed in sinks and at the base station. Moreover, software-defined networking and network function virtualization technologies are used to perform attack mitigation when either low-level or high-level attacks are detected. An experiment was performed to acquire an attack data set for evaluation. Then, a simulation was created to evaluate the resource consumption and attack detection rate. The results demonstrate the feasibility and efficiency of the proposed scheme.","Wireless sensor networks,
Sensors,
Base stations,
Access control,
Smart cities,
Hierarchical systems"
"A Wearable Patch to Enable Long-Term Monitoring of Environmental, Activity and Hemodynamics Variables","We present a low power multi-modal patch designed for measuring activity, altitude (based on high-resolution barometric pressure), a single-lead electrocardiogram, and a tri-axial seismocardiogram (SCG). Enabled by a novel embedded systems design methodology, this patch offers a powerful means of monitoring the physiology for both patients with chronic cardiovascular diseases, and the general population interested in personal health and fitness measures. Specifically, to the best of our knowledge, this patch represents the first demonstration of combined activity, environmental context, and hemodynamics monitoring, all on the same hardware, capable of operating for longer than 48 hours at a time with continuous recording. The three-channels of SCG and one-lead ECG are all sampled at 500 Hz with high signal-to-noise ratio, the pressure sensor is sampled at 10 Hz, and all signals are stored to a microSD card with an average current consumption of less than 2 mA from a 3.7 V coin cell (LIR2450) battery. In addition to electronic characterization, proof-of-concept exercise recovery studies were performed with this patch, suggesting the ability to discriminate between hemodynamic and electrophysiology response to light, moderate, and heavy exercise.","Biomedical monitoring,
Electrocardiography,
Microcontrollers,
Monitoring,
Hemodynamics,
Electrodes"
Vibration Control of Flexible Marine Riser Systems With Input Saturation,"In this paper, boundary control is designed to suppress transverse vibration of a flexible marine riser with input saturation in the ocean environment. Two cases are investigated: 1) state feedback boundary control, and 2) output feedback boundary control. In order to compensate for the input saturation, we propose an auxiliary system. First, state feedback boundary control with an auxiliary system is proposed when the boundary states of the riser can be measured. Subsequently, output feedback boundary control is developed when there are unmeasurable system states. High-gain observers are employed to estimate those unmeasurable states. Based on Lyapunov's direct method, the proposed control ensures that the deflection of the riser is uniformly bounded in the presence of the ocean disturbances. By choosing a set of appropriate parameters, numerical simulations are provided to verify the effectiveness of the proposed boundary control.","Vibrations,
IEEE transactions,
Mechatronics,
Oceans,
Output feedback,
Control design,
Observers"
An Early Clinical Study of Time-Domain Microwave Radar for Breast Health Monitoring,"This study reports on monthly scans of healthy patient volunteers with the clinical prototype of a microwave imaging system. The system uses time-domain measurements, and incorporates a multistatic radar approach to imaging. It operates in the 2-4 GHz range and contains 16 wideband sensors embedded in a hemispherical dielectric radome. The system has been previously tested on tissue phantoms in controlled experiments. With this system prototype, we scanned 13 patients (26 breasts) over an eight-month period, collecting a total of 342 breast scans. The goal of the study described in this paper was to investigate how the system measurements are impacted by multiple factors that are unavoidable in monthly monitoring of human subjects. These factors include both biological variability (e.g., tissue variations due to hormonal changes or weight gain) and measurement variability (e.g., inconsistencies in patient positioning, system noise). For each patient breast, we process the results of the monthly scans to assess the variability in both the raw measured signals and in the generated images. The significance of this study is that it quantifies how much variability should be anticipated when conducting microwave breast imaging of a healthy patient over a longer period. This is an important step toward establishing the feasibility of the microwave radar imaging system for frequent monitoring of breast health.","Breast,
Microwave imaging,
Antennas,
Microwave theory and techniques,
Ultrasonic imaging,
Microwave measurement,
Radar imaging"
Inverse-Free Extreme Learning Machine With Optimal Information Updating,"The extreme learning machine (ELM) has drawn insensitive research attentions due to its effectiveness in solving many machine learning problems. However, the matrix inversion operation involved in the algorithm is computational prohibitive and limits the wide applications of ELM in many scenarios. To overcome this problem, in this paper, we propose an inverse-free ELM to incrementally increase the number of hidden nodes, and update the connection weights progressively and optimally. Theoretical analysis proves the monotonic decrease of the training error with the proposed updating procedure and also proves the optimality in every updating step. Extensive numerical experiments show the effectiveness and accuracy of the proposed algorithm.","Training,
Least squares approximations,
Accuracy,
Neural networks,
Approximation error,
Approximation algorithms"
Outage Performance of Cognitive Relay Networks With Wireless Information and Power Transfer,"In this paper, we consider underlay cognitive radio (CR) networks with one primary receiver, one cognitive transmitter-receiver pair, and one energy harvesting relay. The transmission power of the secondary source is opportunistically determined by its interference to the primary receiver, and the relay transmission is powered by the energy harvested from the radio-frequency observations at the relay. For the considered CR networks with simultaneous wireless information and power transfer (SWIPT), we derive analytical expressions for the outage probability, as well as their high signal-to-noise ratio (SNR) approximations in closed form. The developed analytical results demonstrate that the use of SWIPT will not cause any loss in diversity gain, but the outage probability achieved by the SWIPT-CR scheme asymptotically decays as log SNR/SNR, whereas a decaying rate of 1/SNR is achieved by a conventional CR network. Computer simulation results are also provided to demonstrate the accuracy of the presented analysis.","Relays,
Energy harvesting,
Receivers,
Radio transmitters,
Signal to noise ratio,
Interference"
Near Optimal Event-Triggered Control of Nonlinear Discrete-Time Systems Using Neurodynamic Programming,"This paper presents an event-triggered near optimal control of uncertain nonlinear discrete-time systems. Event-driven neurodynamic programming (NDP) is utilized to design the control policy. A neural network (NN)-based identifier, with event-based state and input vectors, is utilized to learn the system dynamics. An actor-critic framework is used to learn the cost function and the optimal control input. The NN weights of the identifier, the critic, and the actor NNs are tuned aperiodically once every triggered instant. An adaptive event-trigger condition to decide the trigger instants is derived. Thus, a suitable number of events are generated to ensure a desired accuracy of approximation. A near optimal performance is achieved without using value and/or policy iterations. A detailed analysis of nontrivial inter-event times with an explicit formula to show the reduction in computation is also derived. The Lyapunov technique is used in conjunction with the event-trigger condition to guarantee the ultimate boundedness of the closed-loop system. The simulation results are included to verify the performance of the controller. The net result is the development of event-driven NDP.","Artificial neural networks,
Approximation methods,
Optimal control,
Cost function,
Discrete-time systems,
System dynamics,
Mirrors"
Evolutionary Multi-Objective Workflow Scheduling in Cloud,"Cloud computing provides promising platforms for executing large applications with enormous computational resources to offer on demand. In a Cloud model, users are charged based on their usage of resources and the required quality of service (QoS) specifications. Although there are many existing workflow scheduling algorithms in traditional distributed or heterogeneous computing environments, they have difficulties in being directly applied to the Cloud environments since Cloud differs from traditional heterogeneous environments by its service-based resource managing method and pay-per-use pricing strategies. In this paper, we highlight such difficulties, and model the workflow scheduling problem which optimizes both makespan and cost as a Multi-objective Optimization Problem (MOP) for the Cloud environments. We propose an evolutionary multi-objective optimization (EMO)-based algorithm to solve this workflow scheduling problem on an infrastructure as a service (IaaS) platform. Novel schemes for problem-specific encoding and population initialization, fitness evaluation and genetic operators are proposed in this algorithm. Extensive experiments on real world workflows and randomly generated workflows show that the schedules produced by our evolutionary algorithm present more stability on most of the workflows with the instance-based IaaS computing and pricing models. The results also show that our algorithm can achieve significantly better solutions than existing state-of-the-art QoS optimization scheduling algorithms in most cases. The conducted experiments are based on the on-demand instance types of Amazon EC2; however, the proposed algorithm are easy to be extended to the resources and pricing models of other IaaS services.","Pricing,
Schedules,
Scheduling,
Processor scheduling,
Encoding,
Quality of service,
Computational modeling"
Preprocessing Reference Sensor Pattern Noise via Spectrum Equalization,"Although sensor pattern noise (SPN) has been proved to be an effective means to uniquely identify digital cameras, some non-unique artifacts, shared among cameras undergo the same or similar in-camera processing procedures, often give rise to false identifications. Therefore, it is desirable and necessary to suppress these unwanted artifacts so as to improve the accuracy and reliability. In this paper, we propose a novel preprocessing approach for attenuating the influence of the non-unique artifacts on the reference SPN to reduce the false identification rate. Specifically, we equalize the magnitude spectrum of the reference SPN through detecting and suppressing the peaks according to the local characteristics, aiming at removing the interfering periodic artifacts. Combined with six SPN extractions or enhancement methods, our proposed spectrum equalization algorithm is evaluated on the Dresden image database as well as our own database, and compared with the state-of-the-art preprocessing schemes. The experimental results indicate that the proposed procedure outperforms, or at least performs comparable with, the existing methods in terms of the overall receiver operating characteristic curves and kappa statistic computed from a confusion matrix, and tends to be more resistant to JPEG compression for medium and small image blocks.","Noise,
Cameras,
Discrete Fourier transforms,
Transform coding,
Image coding,
Forensics,
Digital images"
Multiple Extended Target Tracking With Labeled Random Finite Sets,"Targets that generate multiple measurements at a given instant in time are commonly known as extended targets. These present a challenge for many tracking algorithms, as they violate one of the key assumptions of the standard measurement model. In this paper, a new algorithm is proposed for tracking multiple extended targets in clutter, which is capable of estimating the number of targets, as well the trajectories of their states, comprising the kinematics, measurement rates, and extents. The proposed technique is based on modeling the multi-target state as a generalized labeled multi-Bernoulli (GLMB) random finite set (RFS), within which the extended targets are modeled using gamma Gaussian inverse Wishart (GGIW) distributions. A cheaper variant of the algorithm is also proposed, based on the labelled multi-Bernoulli (LMB) filter. The proposed GLMB/LMB-based algorithms are compared with an extended target version of the cardinalized probability hypothesis density (CPHD) filter, and simulation results show that the (G)LMB has improved estimation and tracking performance.",
Local Rademacher Complexity for Multi-Label Learning,"We analyze the local Rademacher complexity of empirical risk minimization-based multi-label learning algorithms, and in doing so propose a new algorithm for multi-label learning. Rather than using the trace norm to regularize the multi-label predictor, we instead minimize the tail sum of the singular values of the predictor in multi-label learning. Benefiting from the use of the local Rademacher complexity, our algorithm, therefore, has a sharper generalization error bound. Compared with methods that minimize over all singular values, concentrating on the tail singular values results in better recovery of the low-rank structure of the multi-label predictor, which plays an important role in exploiting label correlations. We propose a new conditional singular value thresholding algorithm to solve the resulting objective function. Moreover, a variance control strategy is employed to reduce the variance of variables in optimization. Empirical studies on real-world data sets validate our theoretical results and demonstrate the effectiveness of the proposed algorithm for multi-label learning.",
Relay Selection for Cooperative NOMA,"This letter studies the impact of relay selection (RS) on the performance of cooperative non-orthogonal multiple access (NOMA). In particular, a two-stage RS strategy is proposed, and analytical results are developed to demonstrate that this two-stage strategy can achieve the minimal outage probability among all possible RS schemes, and realize the maximal diversity gain. The provided simulation results show that cooperative NOMA with this two-stage RS scheme outperforms that based on the conventional max-min approach, and can also yield a significant performance gain over orthogonal multiple access.",
Quantized Massive MU-MIMO-OFDM Uplink,"Coarse quantization at the base station (BS) of a massive multi-user (MU) multiple-input multiple-output (MIMO) wireless system promises significant power and cost savings. Coarse quantization also enables significant reductions of the raw analog-to-digital converter data that must be transferred from a spatially separated antenna array to the baseband processing unit. The theoretical limits as well as practical transceiver algorithms for such quantized MU-MIMO systems operating over frequency-flat, narrowband channels have been studied extensively. However, the practically relevant scenario where such communication systems operate over frequency-selective, wideband channels is less well understood. This paper investigates the uplink performance of a quantized massive MU-MIMO system that deploys orthogonal frequency-division multiplexing (OFDM) for wideband communication. We propose new algorithms for quantized maximum a posteriori channel estimation and data detection, and we study the associated performance/quantization tradeoffs. Our results demonstrate that coarse quantization (e.g., four to six bits, depending on the ratio between the number of BS antennas and the number of users) in massive MU-MIMO-OFDM systems entails virtually no performance loss compared with the infinite-precision case at no additional cost in terms of baseband processing complexity.",
Universal Droop Control of Inverters With Different Types of Output Impedance,"Droop control is a well-known strategy for the parallel operation of inverters. However, the droop control strategy changes its form for inverters with different types of output impedance, and so far, it is impossible to operate inverters with inductive and capacitive output impedances in parallel. In this paper, it is shown that there exists a universal droop control principle for inverters with output impedance having a phase angle between -(π/2) rad and (π/2) rad. It takes the form of the droop control for inverters with resistive output impedance (R-inverters). Hence, the robust droop controller recently proposed in the literature for R-inverters actually provides one way to implement such a universal droop controller that can be applied to all practical inverters without the need of knowing the impedance angle. The small-signal stability of an inverter equipped with the universal droop controller is analyzed, and it is shown to be stable when the phase angle of the output impedance changes from -(π/2) rad to (π/2) rad. Both real-time simulation results and experimental results from a test rig consisting of an R-inverter, an L-inverter, and a C-inverter operated in parallel are presented to validate the proposed strategy.","Inverters,
Impedance,
Reactive power,
Robustness,
Voltage control,
Stability analysis,
Frequency control,
Droop controllers,
Stability analysis,
Real-time systems"
Joint Power Coordination for Spectral-and-Energy Efficiency in Heterogeneous Small Cell Networks: A Bargaining Game-Theoretic Perspective,"Extensive deployment of small cells in heterogenous cellular networks introduces both challenges and opportunities. Challenges come with the reuse of the limited frequency resource for improving spectral efficiency, which always introduces serious mutual inter- and intracell interference between or among small cells and macrocells. The opportunities refer to more potential chances of inter- and intratier cooperations among small cells and macrocells. Energy efficiency will be a critical performance requirement for future green communications, especially when small cells are densely deployed to enhance the quality of user's experience. We exploit the potential cooperation diversities to combat the interference and energy management challenges. To capture the complicated interference interaction and also the possible coordination behavior among small cells and macrocells, this paper proposes a novel bargaining cooperative game (BCG) framework for energy efficient and interference-aware power coordination in a dense small cell network. In particular, a new adjustable utility function is employed in the BCG framework to jointly address both the spectral efficiency and energy efficiency issues. Using the BCG framework, we then derive the closed-form power coordination solutions and further propose a joint interference-aware power coordination scheme (Joint) with the considerations of both interference mitigation and energy saving. Moreover, a simplified algorithm (Simplified) is presented to combat the heavy signaling overhead, which is one of the significant challenges in the scenario of extensive deployment of small cells. Finally, numerical results are provided to illustrate the effectiveness of the proposed Joint and Simplified schemes.",
Feature Knowledge Based Fault Detection of Induction Motors Through the Analysis of Stator Current Data,"The fault detection of electrical or mechanical anomalies in induction motors has been a challenging problem for researchers over decades to ensure the safety and economic operations of industrial processes. To address this issue, this paper studies the stator current data obtained from inverter-fed laboratory induction motors and investigates the unique signatures of the healthy and faulty motors with the aim of developing knowledge based fault detection method for performing online detection of motor fault problems, such as broken-rotor-bar and bearing faults. Stator current data collected from induction motors were analyzed by leveraging fast Fourier transform (FFT), and the FFT results were further analyzed by the independent component analysis (ICA) method to obtain independent components and signature features that are referred to as FFT-ICA features of stator currents. The resulting FFT-ICA features contain rich information on the signatures of the healthy and faulty motors, which are further analyzed to build a feature knowledge database for online fault detection. Through case studies, this paper demonstrated the high accuracy, simplicity, and robustness of the proposed fault detection scheme for fault detection of induction motors. In addition, with the integration of the feature knowledge database, prior knowledge of the motor parameters, such as rotor speed and per-unit slip, which are needed by the other motor current signature analysis (MCSA) methods, is not required for the proposed method, which makes it more efficient compared with the other MCSA methods.","Induction motors,
Feature extraction,
Stators,
Fault detection,
Inverters,
Harmonic analysis,
Databases"
Placement Optimization of Energy and Information Access Points in Wireless Powered Communication Networks,"The applications of wireless power transfer technology to wireless communications can help build a wireless powered communication network (WPCN) with more reliable and sustainable power supply compared to the conventional battery-powered network. However, due to the fundamental differences in wireless information and power transmissions, many important aspects of conventional battery-powered wireless communication networks need to be redesigned for efficient operations of WPCNs. In this paper, we study the placement optimization of energy and information access points in WPCNs, where the wireless devices (WDs) harvest the radio frequency energy transferred by dedicated energy nodes (ENs) in the downlink, and use the harvested energy to transmit data to information access points (APs) in the uplink. In particular, we are interested in minimizing the network deployment cost with minimum number of ENs and APs by optimizing their locations, while satisfying the energy harvesting and communication performance requirements of the WDs. Specifically, we first study the minimum-cost placement problem when the ENs and APs are separately located, where an alternating optimization method is proposed to jointly optimize the locations of ENs and APs. Then, we study the placement optimization when each pair of EN and AP is colocated and integrated as a hybrid access point, and propose an efficient algorithm to solve this problem. Simulation results show that the proposed methods can effectively reduce the network deployment cost and yet guarantee the given performance requirements, which is a key consideration in future applications of WPCNs.","Wireless communication,
Optimization,
Wireless sensor networks,
Energy harvesting,
Radio frequency,
Information processing,
Batteries"
Multi-Target Tracking by Discrete-Continuous Energy Minimization,"The task of tracking multiple targets is often addressed with the so-called tracking-by-detection paradigm, where the first step is to obtain a set of target hypotheses for each frame independently. Tracking can then be regarded as solving two separate, but tightly coupled problems. The first is to carry out data association, i.e., to determine the origin of each of the available observations. The second problem is to reconstruct the actual trajectories that describe the spatio-temporal motion pattern of each individual target. The former is inherently a discrete problem, while the latter should intuitively be modeled in continuous space. Having to deal with an unknown number of targets, complex dependencies, and physical constraints, both are challenging tasks on their own and thus most previous work focuses on one of these subproblems. Here, we present a multi-target tracking approach that explicitly models both tasks as minimization of a unified discrete-continuous energy function. Trajectory properties are captured through global label costs, a recent concept from multi-model fitting, which we introduce to tracking. Specifically, label costs describe physical properties of individual tracks, e.g., linear and angular dynamics, or entry and exit points. We further introduce pairwise label costs to describe mutual interactions between targets in order to avoid collisions. By choosing appropriate forms for the individual energy components, powerful discrete optimization techniques can be leveraged to address data association, while the shapes of individual trajectories are updated by gradient-based continuous energy minimization. The proposed method achieves state-of-the-art results on diverse benchmark sequences.",
An Efficient File Hierarchy Attribute-Based Encryption Scheme in Cloud Computing,"Ciphertext-policy attribute-based encryption (CP-ABE) has been a preferred encryption technology to solve the challenging problem of secure data sharing in cloud computing. The shared data files generally have the characteristic of multilevel hierarchy, particularly in the area of healthcare and the military. However, the hierarchy structure of shared files has not been explored in CP-ABE. In this paper, an efficient file hierarchy attribute-based encryption scheme is proposed in cloud computing. The layered access structures are integrated into a single access structure, and then, the hierarchical files are encrypted with the integrated access structure. The ciphertext components related to attributes could be shared by the files. Therefore, both ciphertext storage and time cost of encryption are saved. Moreover, the proposed scheme is proved to be secure under the standard assumption. Experimental simulation shows that the proposed scheme is highly efficient in terms of encryption and decryption. With the number of the files increasing, the advantages of our scheme become more and more conspicuous.","Encryption,
Cloud computing,
Authorization,
Cardiology,
Periodic structures"
Person Reidentification With Reference Descriptor,"Person identification across nonoverlapping cameras, also known as person reidentification, aims to match people at different times and locations. Reidentifying people is of great importance in crucial applications such as wide-area surveillance and visual tracking. Due to the appearance variations in pose, illumination, and occlusion in different camera views, person reidentification is inherently difficult. To address these challenges, a reference-based method is proposed for person reidentification across different cameras. Instead of directly matching people by their appearance, the matching is conducted in a reference space where the descriptor for a person is translated from the original color or texture descriptors to similarity measures between this person and the exemplars in the reference set. A subspace is first learned in which the correlations of the reference data from different cameras are maximized using regularized canonical correlation analysis (RCCA). For reidentification, the gallery data and the probe data are projected onto this RCCA subspace and the reference descriptors (RDs) of the gallery and probe are generated by computing the similarity between them and the reference data. The identity of a probe is determined by comparing the RD of the probe and the RDs of the gallery. A reranking step is added to further improve the results using a saliency-based matching scheme. Experiments on publicly available datasets show that the proposed method outperforms most of the state-of-the-art approaches.","Cameras,
Probes,
Feature extraction,
Measurement,
Image color analysis,
Correlation,
Covariance matrices"
A Vertical Handoff Method via Self-Selection Decision Tree for Internet of Vehicles,"Vehicles often communicate among different networks in Internet of Vehicles (IoVs). However, existing unstable network statuses and different user preferences result in vehicle frequent vertical handoffs (VHOs). In this paper, we propose a novel VHO method based on a self-selection decision tree for IoVs. We first establish the respective handoff probability distribution of vehicles according to network attributes and movement trend. Then, based on handoff probability distributions and defined user preferences, we propose a novel handoff method by the self-selection decision tree for IoVs. Finally, we also present a feedback decision method according to the feedback of vehicle handoff, to improve next handoff quality when vehicle movement trend and vehicle service status change. Simulation results show that the proposed method not only supports the VHO among Wireless Access in Vehicular Environments, Worldwide Interoperability for Microwave Access, and third-generation cellular but also reduces switching times and ensures the network update rate and the vehicles' service quality.","Vehicles,
Decision trees,
WiMAX,
Switches,
Bit error rate,
Market research,
Wireless LAN"
Target Classification Using the Deep Convolutional Networks for SAR Images,"The algorithm of synthetic aperture radar automatic target recognition (SAR-ATR) is generally composed of the extraction of a set of features that transform the raw input into a representation, followed by a trainable classifier. The feature extractor is often hand designed with domain knowledge and can significantly impact the classification accuracy. By automatically learning hierarchies of features from massive training data, deep convolutional networks (ConvNets) recently have obtained state-of-the-art results in many computer vision and speech recognition tasks. However, when ConvNets was directly applied to SAR-ATR, it yielded severe overfitting due to limited training images. To reduce the number of free parameters, we present a new all-convolutional networks (A-ConvNets), which only consists of sparsely connected layers, without fully connected layers being used. Experimental results on the Moving and Stationary Target Acquisition and Recognition (MSTAR) benchmark data set illustrate that A-ConvNets can achieve an average accuracy of 99% on classification of ten-class targets and is significantly superior to the traditional ConvNets on the classification of target configuration and version variants.","Convolution,
Synthetic aperture radar,
Feature extraction,
Computer architecture,
Training,
Target recognition,
Training data"
Twenty Security Considerations for Cloud-Supported Internet of Things,"To realize the broad vision of pervasive computing, underpinned by the “Internet of Things” (IoT), it is essential to break down application and technology-based silos and support broad connectivity and data sharing; the cloud being a natural enabler. Work in IoT tends toward the subsystem, often focusing on particular technical concerns or application domains, before offloading data to the cloud. As such, there has been little regard given to the security, privacy, and personal safety risks that arise beyond these subsystems; i.e., from the wide-scale, cross-platform openness that cloud services bring to IoT. In this paper, we focus on security considerations for IoT from the perspectives of cloud tenants, end-users, and cloud providers, in the context of wide-scale IoT proliferation, working across the range of IoT technologies (be they things or entire IoT subsystems). Our contribution is to analyze the current state of cloud-supported IoT to make explicit the security considerations that require further work.",
Green 5G Heterogeneous Networks Through Dynamic Small-Cell Operation,"Traditional macrocell networks are experiencing an upsurge of data traffic, and small-cells are deployed to help offload the traffic from macrocells. Given the massive deployment of small-cells in a macrocell, the aggregate power consumption of small-cells (though being low individually) can be larger than that of the macrocell. Compared to the macrocell base station (MBS) whose power consumption increases significantly with its traffic load, the power consumption of a small-cell base station (SBS) is relatively flat and independent of its load. To reduce the total power consumption of the heterogeneous networks (HetNets), we dynamically change the operating states (on and off) of the SBSs, while keeping the MBS on to avoid any service failure outside active small-cells. First, we consider that the wireless users are uniformly distributed in the network, and propose an optimal location-based operation scheme by gradually turning off the SBSs closer to the MBS. We then extend the operation problem to a more general case where users are nonuniformly distributed in the network. Although this problem is NP-hard, we propose a joint location and user density based operation scheme to achieve near-optimum (with less than 1% performance loss in our simulations) in polynomial time.","Power demand,
5G mobile communication,
Base stations,
Heterogeneous networks,
Wireless communication,
Load modeling,
Heuristic algorithms"
FakeMask: A Novel Privacy Preserving Approach for Smartphones,"Users can enjoy personalized services provided by various context-aware applications that collect users' contexts through sensor-equipped smartphones. Meanwhile, serious privacy concerns arise due to the lack of privacy preservation mechanisms. Currently, most mechanisms apply passive defense policies in which the released contexts from a privacy preservation system are always real, leading to a great probability with which an adversary infers the hidden sensitive contexts about the users. In this paper, we apply a deception policy for privacy preservation and present a novel technique, FakeMask, in which fake contexts may be released to provably preserve users' privacy. The output sequence of contexts by FakeMask can be accessed by the untrusted context-aware applications or be used to answer queries from those applications. Since the output contexts may be different from the original contexts, an adversary has greater difficulty in inferring the real contexts. Therefore, FakeMask limits what adversaries can learn from the output sequence of contexts about the user being in sensitive contexts, even if the adversaries are powerful enough to have the knowledge about the system and the temporal correlations among the contexts. The essence of FakeMask is a privacy checking algorithm which decides whether to release a fake context for the current context of the user. We present a novel privacy checking algorithm and an efficient one to accelerate the privacy checking process. Extensive evaluation experiments on real smartphone context traces of users demonstrate the improved performance of FakeMask over other approaches.",
Incentive Mechanisms for Crowdsensing: Crowdsourcing With Smartphones,"Smartphones are programmable and equipped with a set of cheap but powerful embedded sensors, such as accelerometer, digital compass, gyroscope, GPS, microphone, and camera. These sensors can collectively monitor a diverse range of human activities and the surrounding environment. Crowdsensing is a new paradigm which takes advantage of the pervasive smartphones to sense, collect, and analyze data beyond the scale of what was previously possible. With the crowdsensing system, a crowdsourcer can recruit smartphone users to provide sensing service. Existing crowdsensing applications and systems lack good incentive mechanisms that can attract more user participation. To address this issue, we design incentive mechanisms for crowdsensing. We consider two system models: the crowdsourcer-centric model where the crowdsourcer provides a reward shared by participating users, and the user-centric model where users have more control over the payment they will receive. For the crowdsourcer-centric model, we design an incentive mechanism using a Stackelberg game, where the crowdsourcer is the leader while the users are the followers. We show how to compute the unique Stackelberg Equilibrium, at which the utility of the crowdsourcer is maximized, and none of the users can improve its utility by unilaterally deviating from its current strategy. For the user-centric model, we design an auction-based incentive mechanism, which is computationally efficient, individually rational, profitable, and truthful. Through extensive simulations, we evaluate the performance and validate the theoretical properties of our incentive mechanisms.","Sensors,
Games,
Smart phones,
Computational modeling,
Crowdsourcing,
IEEE transactions,
Mechanical factors"
A General Framework for Robust Output Synchronization of Heterogeneous Nonlinear Networked Systems,"The paper aims to establish a general framework for robust output synchronization of a group of networked agents. The agents under investigation have nonlinear, uncertain and heterogeneous dynamics. Output synchronization denotes that all agents, through collaborative control, achieve output agreement and follow a desired pattern. In particular, the agreed trajectory is not defined by nor known to any agent in advance. Collaborative control is achieved using only output information from neighboring agents. Two concurrent actions are revealed in the proposed synchronization framework. This framework involves design strategies for both perturbed consensus and perturbed regulation problems, subject to a class of small gain conditions. The success of the framework is verified by constructive proof and numerical simulation.","Synchronization,
Trajectory,
Mathematical model,
Robustness,
Vehicle dynamics,
Eigenvalues and eigenfunctions,
Uncertainty"
"A Provably Secure, Efficient, and Flexible Authentication Scheme for Ad hoc Wireless Sensor Networks","In 2014, Turkanovic et al. proposed a smart card-based authentication scheme for heterogeneous ad hoc wireless sensor network. This scheme is very efficient since it employs only hash function and XOR operation. However, we found that Turkanovic et al.'s scheme is vulnerable to impersonation attack with node capture, stolen smart card attack, sensor node spoofing attack, stolen verifier attack, and fails to ensure backward secrecy. We propose an efficient scheme to overcome all those weaknesses. Moreover, we also propose an advanced scheme, which provides perfect forward secrecy without much modification from the first proposed scheme.",
Capacity Estimation for Vehicle-to-Grid Frequency Regulation Services With Smart Charging Mechanism,"Due to various green initiatives, renewable energy will be massively incorporated into the future smart grid. However, the intermittency of the renewables may result in power imbalance, thus adversely affecting the stability of a power system. Frequency regulation may be used to maintain the power balance at all times. As electric vehicles (EVs) become popular, they may be connected to the grid to form a vehicle-to-grid (V2G) system. An aggregation of EVs can be coordinated to provide frequency regulation services. However, V2G is a dynamic system where the participating EVs come and go independently. Thus, it is not easy to estimate the regulation capacities for V2G. In a preliminary study, we modeled an aggregation of EVs with a queueing network, whose structure allows us to estimate the capacities for regulation-up and regulation-down separately. The estimated capacities from the V2G system can be used for establishing a regulation contract between an aggregator and the grid operator, and facilitating a new business model for V2G. In this paper, we extend our previous development by designing a smart charging mechanism that can adapt to given characteristics of the EVs and make the performance of the actual system follow the analytical model.",
Massive Online Crowdsourced Study of Subjective and Objective Picture Quality,"Most publicly available image quality databases have been created under highly controlled conditions by introducing graded simulated distortions onto high-quality photographs. However, images captured using typical real-world mobile camera devices are usually afflicted by complex mixtures of multiple distortions, which are not necessarily well-modeled by the synthetic distortions found in existing databases. The originators of existing legacy databases usually conducted human psychometric studies to obtain statistically meaningful sets of human opinion scores on images in a stringently controlled visual environment, resulting in small data collections relative to other kinds of image analysis databases. Toward overcoming these limitations, we designed and created a new database that we call the LIVE In the Wild Image Quality Challenge Database, which contains widely diverse authentic image distortions on a large number of images captured using a representative variety of modern mobile devices. We also designed and implemented a new online crowdsourcing system, which we have used to conduct a very large-scale, multi-month image quality assessment (IQA) subjective study. Our database consists of over 350 000 opinion scores on 1162 images evaluated by over 8100 unique human observers. Despite the lack of control over the experimental environments of the numerous study participants, we demonstrate excellent internal consistency of the subjective data set. We also evaluate several top-performing blind IQA algorithms on it and present insights on how the mixtures of distortions challenge both end users as well as automatic perceptual quality prediction models. The new database is available for public use at <;uri xlink:href=""http://live.ece.utexas.edu/research/ChallengeDB/index.html"" xlink:type=""simple"">http://live.ece.utexas.edu/research/ChallengeDB/index.html<;/uri>.","Databases,
Distortion,
Image quality,
Crowdsourcing,
Cameras,
Mobile handsets,
Visualization"
Joint Beamforming and Power Control for Device-to-Device Communications Underlaying Cellular Networks,"In this paper, we address the issue of joint beamforming (BF) and power control for a device-to-device (D2D) communication underlaying cellular network, where the wireless channels of the D2D link and the base station to user equipment link experience Rician and correlated Rayleigh fading, respectively. Based on the property of the integral network, we first formulate a constrained optimization problem to minimize the total transmit power of the devices in the network, while meeting the quality-of-service requirement of both the D2D and cellular users and suppressing the mutual interference to a certain level. Then, by adopting the available statistical channel state information and proposing an approximation method to relax the constraints, a support-vector-machine-based algorithm is presented to solve the optimization problem for the transmit powers and BF weight vectors of each user. Furthermore, we derive the analytical expressions for the cumulative density function and the generalized moments of the output signal-to-interference-plus-noise ratios, thereby developing some novel theoretical formulas for the ergodic capacity and the average symbol error rate of each user in the network. Finally, computer simulation results are provided to demonstrate the validity and efficiency of the proposed scheme and its performance analysis.","Interference,
Optimization,
Support vector machines,
Quality of service,
Rayleigh channels,
Resource management"
Anchor-Assisted and Vote-Based Trustworthiness Assurance in Smart City Crowdsensing,"Smart city sensing calls for crowdsensing via mobile devices that are equipped with various built-in sensors. As incentivizing users to participate in distributed sensing is still an open research issue, the trustworthiness of crowdsensed data is expected to be a grand challenge if this cloud-inspired recruitment of sensing services is to be adopted. Recent research proposes reputation-based user recruitment models for crowdsensing; however, there is no standard way of identifying adversaries in smart city crowdsensing. This paper adopts previously proposed vote-based approaches, and presents a thorough performance study of vote-based trustworthiness with trusted entities that are basically a subset of the participating smartphone users. Those entities are called trustworthy anchors of the crowdsensing system. Thus, an anchor user is fully trustworthy and is fully capable of voting for the trustworthiness of other users, who participate in sensing of the same set of phenomena. Besides the anchors, the reputations of regular users are determined based on vote-based (distributed) reputation. We present a detailed performance study of the anchor-based trustworthiness assurance in smart city crowdsensing through simulations, and compare it with the purely vote-based trustworthiness approach without anchors, and a reputation-unaware crowdsensing approach, where user reputations are discarded. Through simulation findings, we aim at providing specifications regarding the impact of anchor and adversary populations on crowdsensing and user utilities under various environmental settings. We show that significant improvement can be achieved in terms of usefulness and trustworthiness of the crowdsensed data if the size of the anchor population is set properly.","Smart cities,
Recruitment,
Intelligent sensors,
Social factors,
Statistics,
Crowdsourcing,
Smart phones,
Sensors,
Social network services"
Analysis of Distortion Distribution for Pooling in Image Quality Prediction,"Image quality assessment (IQA) has been an active research area during last decades. Many existing objective IQA models share a similar two-step structure with measuring local distortion before pooling. Compared with the rapid development for local distortion measurement, seldom effort has been made dedicated to effective pooling schemes. In this paper, we design a new pooling model via the analysis of distortion distribution affected by image content and distortion. That is, distributions of distortion position, distortion intensity, frequency changes, and histogram changes are comprehensively considered to infer an overall quality score. Experimental results conducted on four large-scale image quality databases (LIVE, TID2008, CSIQ, and CCID2014) concluded with three valuable findings. First, the proposed technique leads to consistent improvement in the IQA performance for studied local distortion measures. Second, relative to the traditional pooling, the performance gain of our algorithm is beyond 15% on average. Third, the best overall performance made by the proposed strategy outperforms state-of-the-art competitors.",
Wireless Power Transfer Charging System for AIMDs and Pacemakers,"This paper deals with the electric and magnetic field (EMF) safety aspects of a wireless power transfer (WPT) system based on magnetic resonant coupling between two coils. The primary coil is assumed to be on-body, while the secondary coil is assumed to be inside the human body and connected to a battery recharge system of an active implantable medical device such as a pacemaker. This study allows us to identify a good preliminary solution of the WPT coil configuration, compensation capacitor topology, and operational frequency. Demonstrative WPT systems operating at two different frequencies are proposed in order to verify the WPT performances. The EMF safety has been finally assessed by numerical dosimetry studies using anatomically realistic human body models revealing no particular concerns about this application.",
Are All the Subproblems Equally Important? Resource Allocation in Decomposition-Based Multiobjective Evolutionary Algorithms,Decomposition-based multiobjective evolutionary algorithms (MOEAs) decompose a multiobjective optimization problem into a set of scalar objective subproblems and solve them in a collaborative way. A naïve way to distribute computational effort is to treat all the subproblems equally and assign the same computational resource to each subproblem. This paper proposes a generalized resource allocation (GRA) strategy for decomposition-based MOEAs by using a probability of improvement vector. Each subproblem is chosen to invest according to this vector. An offline measurement and an online measurement of the subproblem hardness are used to maintain and update this vector. Utility functions are proposed and studied for implementing a reasonable and stable online resource allocation strategy. Extensive experimental studies on the proposed GRA strategy have been conducted.,"Resource management,
Iron,
Sociology,
Statistics,
Evolutionary computation,
Linear programming,
Optimization"
Predicting Hub Genes Associated with Cervical Cancer through Gene Co-Expression Networks,"Cervical cancer is the third most common malignancy in women worldwide. It remains a leading cause of cancer-related death for women in developing countries. In order to contribute to the treatment of the cervical cancer, in our work, we try to find a few key genes resulting in the cervical cancer. Employing functions of several bioinformatics tools, we selected 143 differentially expressed genes (DEGs) associated with the cervical cancer. The results of bioinformatics analysis show that these DEGs play important roles in the development of cervical cancer. Through comparing two differential co-expression networks (DCNs) at two different states, we found a common sub-network and two differential sub-networks as well as some hub genes in three sub-networks. Moreover, some of the hub genes have been reported to be related to the cervical cancer. Those hub genes were analyzed from Gene Ontology function enrichment, pathway enrichment and protein binding three aspects. The results can help us understand the development of the cervical cancer and guide further experiments about the cervical cancer.","Cervical cancer,
Bioinformatics,
Computational biology,
Gene expression"
Design Study of a Fundamental Mode Input Coupler for a 372-GHz Gyro-TWA I: Rectangular-to-Circular Coupling Methods,"The design of two fundamental mode rectangular-to-circular waveguide input couplers for a low-terahertz gyrotron-traveling wave amplifier (gyro-TWA) is presented. A T-junction input coupler with a Bragg reflector and a multiple-hole directional coupler were optimized for operation between 360 and 384 GHz, the proposed gyro-TWA bandwidth. The T-junction coupler and the multiple-hole coupler achieved the respective bandwidths of 10% and 35%. The benefits and potential limitations of the low-terahertz wave coupler topologies are discussed alongside the challenging manufacturing methods of the submillimeter-wave components.","Couplers,
Couplings,
Bandwidth,
Cavity resonators,
Ports (Computers),
Rectangular waveguides"
Transmit Precoded Spatial Modulation: Maximizing the Minimum Euclidean Distance Versus Minimizing the Bit Error Ratio,"In this paper, we investigate a pair of transmit precoding (TPC) algorithms conceived for spatial modulation (SM) systems communicating over flat-fading multiple-input multiple-output (MIMO) channels. In order to retain all the benefits of conventional SM, we design the TPC matrix to be diagonal and introduce two design criteria for optimizing the elements of the TPC matrix. Specifically, we first investigate a TPC design based on maximizing the minimum Euclidean distance dmin (max-dmin) between the SM signal points at the receiver side. A closed-form solution of the optimal max-dmin-based TPC matrix is derived. Then, another TPC design algorithm is proposed for directly minimizing the bit error ratio (BER) upper bound of SM, which is capable of jointly optimizing the overall Euclidean distance between all received signal points. In the minimum BER (min-BER)-based TPC algorithm, the theoretical gradient of the BER with respect to the diagonal TPC matrix is derived and a simplified iterative conjugate gradient (SCG) algorithm is invoked for TPC optimization. Our simulation results demonstrate that the proposed max-dmin-based TPC algorithm is optimal in terms of the minimum distance. However, increasing dmin does not achieve a further BER improvement. We also confirm that the min-BER-based TPC outperforms the max-dmin-based TPC schemes in terms of the achievable BER performance.","Bit error rate,
Optimized production technology,
Receivers,
MIMO,
Modulation,
Euclidean distance,
Closed-form solutions"
A Deep Ensemble Learning Method for Monaural Speech Separation,"Monaural speech separation is a fundamental problem in robust speech processing. Recently, deep neural network (DNN)-based speech separation methods, which predict either clean speech or an ideal time-frequency mask, have demonstrated remarkable performance improvement. However, a single DNN with a given window length does not leverage contextual information sufficiently, and the differences between the two optimization objectives are not well understood. In this paper, we propose a deep ensemble method, named multicontext networks, to address monaural speech separation. The first multicontext network averages the outputs of multiple DNNs whose inputs employ different window lengths. The second multicontext network is a stack of multiple DNNs. Each DNN in a module of the stack takes the concatenation of original acoustic features and expansion of the soft output of the lower module as its input, and predicts the ratio mask of the target speaker; the DNNs in the same module employ different contexts. We have conducted extensive experiments with three speech corpora. The results demonstrate the effectiveness of the proposed method. We have also compared the two optimization objectives systematically and found that predicting the ideal time-frequency mask is more efficient in utilizing clean training speech, while predicting clean speech is less sensitive to SNR variations.","Speech,
Training,
Speech processing,
Optimization,
Signal to noise ratio,
Context,
Acoustics"
Dynamic Learning From Neural Control for Strict-Feedback Systems With Guaranteed Predefined Performance,"This paper focuses on dynamic learning from neural control for a class of nonlinear strict-feedback systems with predefined tracking performance attributes. To reduce the number of neural network (NN) approximators used and make the convergence of neural weights verified easily, state variables are introduced to transform the state-feedback control of the original strict-feedback systems into the output-feedback control of the system in the normal form. Then, using the output error transformation based on performance functions, the constrained tracking control problem of the normal systems is transformed into the stabilization problem of an equivalent unconstrained one. By combining the backstepping method, a high-gain observer with radial basis function (RBF) NNs, a novel adaptive neural control (ANC) scheme is proposed to guarantee the predefined tracking error performance as well as the ultimate boundedness of all other closed-loop signals. In particular, only one NN is employed to approximate the lumped unknown system dynamics during the controller design. Under the satisfaction of the partial persistent excitation condition for RBF NNs, the proposed stable ANC scheme is shown to be capable of achieving knowledge acquisition, expression, and storage of unknown system dynamics. The stored knowledge is reused to develop a neural learning controller for improving the control performance of the closed-loop system. When the initial condition satisfies the predefined performance, the proposed neural learning control can still guarantee the predefined tracking performance. Simulation results on a third-order one-link robot are given to show the effectiveness of the proposed method.","Artificial neural networks,
Convergence,
Steady-state,
Control systems,
Nonlinear systems,
Transient analysis,
Backstepping"
Constrained Subproblems in a Decomposition-Based Multiobjective Evolutionary Algorithm,"A decomposition approach decomposes a multiobjective optimization problem into a number of scalar objective optimization subproblems. It plays a key role in decomposition-based multiobjective evolutionary algorithms. However, many widely used decomposition approaches, originally proposed for mathematical programming algorithms, may not be very suitable for evolutionary algorithms. To help decomposition-based multiobjective evolutionary algorithms balance the population diversity and convergence in an appropriate manner, this letter proposes to impose some constraints on the subproblems. Experiments have been conducted to demonstrate that our proposed constrained decomposition approach works well on most test instances. We further propose a strategy for adaptively adjusting constraints by using information collected from the search. Experimental results show that it can significantly improve the algorithm performance.","Sociology,
Statistics,
Linear programming,
Measurement,
Evolutionary computation,
Optimization,
Convergence"
Automatic Shadow Detection and Removal from a Single Image,"We present a framework to automatically detect and remove shadows in real world scenes from a single image. Previous works on shadow detection put a lot of effort in designing shadow variant and invariant hand-crafted features. In contrast, our framework automatically learns the most relevant features in a supervised manner using multiple convolutional deep neural networks (ConvNets). The features are learned at the super-pixel level and along the dominant boundaries in the image. The predicted posteriors based on the learned features are fed to a conditional random field model to generate smooth shadow masks. Using the detected shadow masks, we propose a Bayesian formulation to accurately extract shadow matte and subsequently remove shadows. The Bayesian formulation is based on a novel model which accurately models the shadow generation process in the umbra and penumbra regions. The model parameters are efficiently estimated using an iterative optimization procedure. Our proposed framework consistently performed better than the state-of-the-art on all major shadow databases collected under a variety of conditions.","Feature extraction,
Image color analysis,
Lighting,
Training,
Bayes methods,
Visualization,
Databases"
Big Data Analytics in Mobile Cellular Networks,"Mobile cellular networks have become both the generators and carriers of massive data. Big data analytics can improve the performance of mobile cellular networks and maximize the revenue of operators. In this paper, we introduce a unified data model based on the random matrix theory and machine learning. Then, we present an architectural framework for applying the big data analytics in the mobile cellular networks. Moreover, we describe several illustrative examples, including big signaling data, big traffic data, big location data, big radio waveforms data, and big heterogeneous data, in mobile cellular networks. Finally, we discuss a number of open research challenges of the big data analytics in the mobile cellular networks.","Cellular networks,
Mobile communication,
Big data,
Data analytics,
Random matrix theory ,
Machine learning"
An enhanced deep feature representation for person re-identification,"Feature representation and metric learning are two critical components in person re-identification models. In this paper, we focus on the feature representation and claim that hand-crafted histogram features can be complementary to Convolutional Neural Network (CNN) features. We propose a novel feature extraction model called Feature Fusion Net (FFN) for pedestrian image representation. In FFN, back propagation makes CNN features constrained by the handcrafted features. Utilizing color histogram features (RGB, HSV, YCbCr, Lab and YIQ) and texture features (multi-scale and multi-orientation Gabor features), we get a new deep feature representation that is more discriminative and compact. Experiments on three challenging datasets (VIPeR, CUHK01, PRID450s) validates the effectiveness of our proposal.",
Distributed Consensus of Second-Order Multi-Agent Systems With Heterogeneous Unknown Inertias and Control Gains Under a Directed Graph,"In this paper, we study the consensus problem for second-order multi-agent systems with heterogeneous unknown inertias and control gains under a general directed graph. Unlike the existing consensus algorithms for second-order multi-agent systems in which all agents are assumed to have common unit inertias or share common control gains, we allow the inertias and the control gains to be heterogeneous and time-varying for each agent. We propose fully distributed consensus algorithms over a general directed graph when there exist, respectively, absolute velocity damping and relative velocity damping. Novel integral-type Lyapunov functions are proposed to study the consensus convergence. Moreover, the adaptive σ-modification schemes for the gain adaptation are proposed, which renders smaller control gains and thus requires smaller amplitude on the control input without sacrificing consensus convergence. Furthermore, we show that one proposed algorithm also works for consensus of agents with intrinsic Lipschitz nonlinear dynamics. The control gains are varying and updated by distributed adaptive laws. As a result, the proposed algorithms require no global information and thus can be implemented in a fully distributed manner.",
mDASH: A Markov Decision-Based Rate Adaptation Approach for Dynamic HTTP Streaming,"Dynamic adaptive streaming over HTTP (DASH) has recently been widely deployed in the Internet. It, however, does not impose any adaptation logic for selecting the quality of video fragments requested by clients. In this paper, we propose a novel Markov decision-based rate adaptation scheme for DASH aiming to maximize the quality of user experience under time-varying channel conditions. To this end, our proposed method takes into account those key factors that make a critical impact on visual quality, including video playback quality, video rate switching frequency and amplitude, buffer overflow/underflow, and buffer occupancy. Besides, to reduce computational complexity, we propose a low-complexity sub-optimal greedy algorithm which is suitable for real-time video streaming. Our experiments in network test-bed and real-world Internet all demonstrate the good performance of the proposed method in both objective and subjective visual quality.","Streaming media,
Bandwidth,
Bit rate,
Visualization,
Switches,
Markov processes,
Adaptation models"
Survey on 3D Hand Gesture Recognition,"Three-dimensional hand gesture recognition has attracted increasing research interests in computer vision, pattern recognition, and human-computer interaction. The emerging depth sensors greatly inspired various hand gesture recognition approaches and applications, which were severely limited in the 2D domain with conventional cameras. This paper presents a survey of some recent works on hand gesture recognition using 3D depth sensors. We first review the commercial depth sensors and public data sets that are widely used in this field. Then, we review the state-of-the-art research for 3D hand gesture recognition in four aspects: 1) 3D hand modeling; 2) static hand gesture recognition; 3) hand trajectory gesture recognition; and 4) continuous hand gesture recognition. While the emphasis is on 3D hand gesture recognition approaches, the related applications and typical systems are also briefly summarized for practitioners.","Three-dimensional displays,
Gesture recognition,
Sensors,
Solid modeling,
Trajectory,
Assistive technology,
Cameras"
Wide-Area-Measurement System Development at the Distribution Level: An FNET/GridEye Example,"The electric power grid wide-area monitoring system (WAMS) has been extended from the transmission to distribution level. As the first WAMS deployed at the distribution level, the frequency monitoring network FNET/GridEye uses global positioning system-time-synchronized monitors, called frequency disturbance recorders, to capture dynamic grid behaviors. In this paper, the latest developments of monitor design and the state-of-the-art data analytics applications of FNET/GridEye are introduced. Its innovations and uniqueness are also discussed. Thanks to its low cost, easy installation, and multifunctionalities, FNET/GridEye works as a cost-effective situational awareness tool for power grid operators and pioneers the development of WAMS in electric power grids.","Real-time systems,
Oscillators,
Global Positioning System,
Timing,
Monitoring,
Power grids,
Phasor measurement units"
Robust Image Hashing With Ring Partition and Invariant Vector Distance,"Robustness and discrimination are two of the most important objectives in image hashing. We incorporate ring partition and invariant vector distance to image hashing algorithm for enhancing rotation robustness and discriminative capability. As ring partition is unrelated to image rotation, the statistical features that are extracted from image rings in perceptually uniform color space, i.e., CIE L*a*b* color space, are rotation invariant and stable. In particular, the Euclidean distance between vectors of these perceptual features is invariant to commonly used digital operations to images (e.g., JPEG compression, gamma correction, and brightness/contrast adjustment), which helps in making image hash compact and discriminative. We conduct experiments to evaluate the efficiency with 250 color images, and demonstrate that the proposed hashing algorithm is robust at commonly used digital operations to images. In addition, with the receiver operating characteristics curve, we illustrate that our hashing is much better than the existing popular hashing algorithms at robustness and discrimination.","Feature extraction,
Image color analysis,
Robustness,
Image coding,
Standards,
Transform coding,
Discrete cosine transforms"
Overlapping Community Detection Using Neighborhood-Inflated Seed Expansion,"Community detection is an important task in network analysis. A community (also referred to as a cluster) is a set of cohesive vertices that have more connections inside the set than outside. In many social and information networks, these communities naturally overlap. For instance, in a social network, each vertex in a graph corresponds to an individual who usually participates in multiple communities. In this paper, we propose an efficient overlapping community detection algorithm using a seed expansion approach. The key idea of our algorithm is to find good seeds, and then greedily expand these seeds based on a community metric. Within this seed expansion method, we investigate the problem of how to determine good seed nodes in a graph. In particular, we develop new seeding strategies for a personalized PageRank clustering scheme that optimizes the conductance community score. An important step in our method is the neighborhood inflation step where seeds are modified to represent their entire vertex neighborhood. Experimental results show that our seed expansion algorithm outperforms other state-of-the-art overlapping community detection methods in terms of producing cohesive clusters and identifying ground-truth communities. We also show that our new seeding strategies are better than existing strategies, and are thus effective in finding good overlapping communities in real-world networks.","Clustering algorithms,
Kernel,
Image edge detection,
Collaboration,
MySpace"
Detecting Densely Distributed Graph Patterns for Fine-Grained Image Categorization,"Fine-grained image categorization is a challenging task aiming at distinguishing objects belonging to the same basic-level category, e.g., leaf or mushroom. It is a useful technique that can be applied for species recognition, face verification, and so on. Most of the existing methods either have difficulties to detect discriminative object components automatically, or suffer from the limited amount of training data in each sub-category. To solve these problems, this paper proposes a new fine-grained image categorization model. The key is a dense graph mining algorithm that hierarchically localizes discriminative object parts in each image. More specifically, to mimic the human hierarchical perception mechanism, a superpixel pyramid is generated for each image. Thereby, graphlets from each layer are constructed to seamlessly capture object components. Intuitively, graphlets representative to each super-/sub-category is densely distributed in their feature space. Thus, a dense graph mining algorithm is developed to discover graphlets representative to each super-/sub-category. Finally, the discovered graphlets from pairwise images are integrated into an image kernel for fine-grained recognition. Theoretically, the learned kernel can generalize several state-of-the-art image kernels. Experiments on nine image sets demonstrate the advantage of our method. Moreover, the discovered graphlets from each sub-category accurately capture those tiny discriminative object components, e.g., bird claws, heads, and bodies.","Kernel,
Birds,
Detectors,
Computational modeling,
Visualization,
Training data,
Data mining"
Protecting Your Right: Verifiable Attribute-Based Keyword Search with Fine-Grained Owner-Enforced Search Authorization in the Cloud,"Search over encrypted data is a critically important enabling technique in cloud computing, where encryption-before-outsourcing is a fundamental solution to protecting user data privacy in the untrusted cloud server environment. Many secure search schemes have been focusing on the single-contributor scenario, where the outsourced dataset or the secure searchable index of the dataset are encrypted and managed by a single owner, typically based on symmetric cryptography. In this paper, we focus on a different yet more challenging scenario where the outsourced dataset can be contributed from multiple owners and are searchable by multiple users, i.e., multi-user multi-contributor case. Inspired by attribute-based encryption (ABE), we present the first attribute-based keyword search scheme with efficient user revocation (ABKS-UR) that enables scalable fine-grained (i.e., file-level) search authorization. Our scheme allows multiple owners to encrypt and outsource their data to the cloud server independently. Users can generate their own search capabilities without relying on an always online trusted authority. Fine-grained search authorization is also implemented by the owner-enforced access policy on the index of each file. Further, by incorporating proxy re-encryption and lazy re-encryption techniques, we are able to delegate heavy system update workload during user revocation to the resourceful semi-trusted cloud server. We formalize the security definition and prove the proposed ABKS-UR scheme selectively secure against chosen-keyword attack. To build confidence of data user in the proposed secure search system, we also design a search result verification scheme. Finally, performance evaluation shows the efficiency of our scheme.","Indexes,
Keyword search,
Authorization,
Encryption,
Servers"
Cooperative Dynamic Positioning of Multiple Marine Offshore Vessels: A Modular Design,"In this paper, a new cooperative control scheme is presented for the dynamic positioning of multiple offshore vessels, subject to the influence of persistent ocean disturbances induced by wind, waves, and ocean currents. The vessels are interconnected through an underlying directed network. Unlike the traditional dynamic positioning of individual marine surface vessels, cooperative dynamic positioning controllers are developed based on a modular design approach. Specifically, a predictor module is proposed for estimating the unknown ocean disturbances, which is able to achieve the disturbance estimation as fast as possible. Then, the controller module is designed based on a dynamic surface control technique. The input-to-state stability of the closed-loop network system is established via cascade theory. Furthermore, this result is extended to output feedback, where only the position-yaw information is available. Another predictor module is developed for estimating the unmeasured velocities, as well as unknown ocean disturbances. Then, the dynamic surface control technique is employed to devise the output feedback controller. The proposed designs result in decoupled estimate and control, and can achieve fast adaptation for both state and output feedbacks. Results of comparative studies are given to substantiate the efficacy of the proposed methods.","Sea surface,
Output feedback,
Stability analysis,
Observers,
IEEE transactions,
Mechatronics"
Modeling and Analysis of Wireless Power Transfer in Heterogeneous Cellular Networks,"In this paper, we model and analyze the downlink (DL) wireless power transfer and uplink (UL) information transmission of K-tier heterogeneous cellular networks (HCNs) with randomly located base stations (BSs) and mobile terminals (MTs). In the DL and UL, each energy-constrained MT pairs up with its corresponding BS, which provides the maximum received power at the MT. Due to the densely located BSs and universal frequency reuse between all tiers in HCNs, the typical MT is allowed to harvest energy from the serving BS by direct beamforming as well as from the other interfering BSs. Equipped with large storage battery, the typical MT utilizes the harvested energy to provide constant transmit power for the UL information transmission. Stochastic geometry is used to model and evaluate the intrinsic relationship between the energy harvested from the BSs in the DL and the information transmission performance in the UL. To well evaluate the system performance, we first derive exact expressions for the maximum transmit power at MT, the UL outage probability, and the UL average ergodic rate per MT. As the number of BS antennas goes to infinity, we further derive asymptotic expressions for the maximum transmit power at MT, the UL outage probability, and the UL average ergodic rate per MT. Our results show that the UL outage probability per MT first decreases and then increases with increasing the time allocation factor (the fraction of time allocated to the DL), and the UL outage probability, and the UL average ergodic rate per MT, can be largely improved by using the massive antenna arrays at the BSs.","Radio frequency,
Antenna arrays,
Array signal processing,
Information processing,
Transmitting antennas,
Analytical models"
Deep Learning of Part-Based Representation of Data Using Sparse Autoencoders With Nonnegativity Constraints,"We demonstrate a new deep learning autoencoder network, trained by a nonnegativity constraint algorithm (nonnegativity-constrained autoencoder), that learns features that show part-based representation of data. The learning algorithm is based on constraining negative weights. The performance of the algorithm is assessed based on decomposing data into parts and its prediction performance is tested on three standard image data sets and one text data set. The results indicate that the nonnegativity constraint forces the autoencoder to learn features that amount to a part-based representation of data, while improving sparsity and reconstruction quality in comparison with the traditional sparse autoencoder and nonnegative matrix factorization. It is also shown that this newly acquired representation improves the prediction performance of a deep neural network.","Training,
Feature extraction,
Artificial neural networks,
Machine learning,
Image reconstruction,
Encoding,
Cost function"
A Review of Algorithms for Compliant Control of Stiff and Fixed-Compliance Robots,"This survey presents the state of the art of basic compliant control algorithms in a unified view of past and present literature. Compliant control is fundamental when dealing with unstructured environments, as in the case of human-robot interaction. This is because it implicitly controls the energy transfer to the environment, providing a safe interaction. In this review, we analyze solutions from traditional robotics, usually involving stiff joints, and recent literature to find common control concepts and differences. To this aim, we bring back every schemas and relative mathematics formulation to a common and simplified scenario. Then, for each schema, we explain its intuitive meaning and report issues raised in the literature. We also propose an expansion of taxonomy to account for recent research.",
"A High-Temperature Superconducting Maglev Ring Test Line Developed in Chengdu, China","A 45-m-long high-temperature superconducting (HTS) Maglev ring test line, named “Super-Maglev,” has been successfully developed in Chengdu, China, in February 2013, 12 years after the birth of the first man-loading HTS Maglev test vehicle. The Maglev vehicle (2.2 m in length, 1.1 m in width) is designed for one passenger with a levitation height of 10–20 mm; the permanent-magnet guideway (PMG) (45 m in length, 0.77 m of track gauge) is a racetrack shape with a curve radius of 6 m; the driving is accomplished by a linear induction motor with a maximum running speed of 50 km/h. The linear motor is composed of four submotors installed at one straight section in the middle of the double PMGs, and the total length is 3 m. This second-generation HTS Maglev vehicle system is highlighted by the cost-performance and the wireless multiparameter onboard monitoring function. The current same-level load capability has been achieved over a small-section low-cost PMG whose cross-sectional area is only 3000 mm2. On the vehicle, parameters of levitation weight, levitation height, running speed, acceleration, lateral offset, online position, and total running distance of the vehicle are real-time monitored and displayed on the onboard tablet computer. The system component and test data are reported in detail in this paper.","Yttrium barium copper oxide,
Superconducting magnets,
Magnetic levitation,
High-temperature superconductors,
Induction motors,
Real-time systems,
Vehicles"
Gradient-Based Fingerprinting for Indoor Localization and Tracking,"Of the different branches of indoor localization research, WiFi fingerprinting has drawn significant attention over the past decade. These localization systems function by comparing WiFi received signal strength indicator (RSSI) and a pre-established location-specific fingerprint map. However, due to the time-variant wireless signal strength, the RSSI fingerprint map needs to be calibrated periodically, incurring high labor and time costs. In addition, biased RSSI measurements across devices along with transmission power control techniques of WiFi routers further undermine the fidelity of existing fingerprint-based localization systems. To remedy these problems, we propose GradIent FingerprinTing (GIFT) which leverages a more stable RSSI gradient. GIFT first builds a gradient-based fingerprint map (Gmap) by comparing absolute RSSI values at nearby positions, and then runs an online extended particle filter (EPF) to localize the user/device. By incorporating Gmap, GIFT is more adaptive to the time-variant RSSI in indoor environments, thus effectively reducing the overhead of fingerprint map calibration. We implemented GIFT on Android smartphones and tablets, and conducted extensive experiments in a five-story campus building. GIFT is shown to achieve an 80 percentile accuracy of 5.6 m with dynamic WiFi signals.","IEEE 802.11 Standard,
Wireless communication,
Radio frequency,
Sensors,
Indoor environments,
Received signal strength indicator,
Calibration"
Efficient Algorithms for Mining Top-K High Utility Itemsets,"High utility itemsets (HUIs) mining is an emerging topic in data mining, which refers to discovering all itemsets having a utility meeting a user-specified minimum utility threshold min_util. However, setting min_util appropriately is a difficult problem for users. Generally speaking, finding an appropriate minimum utility threshold by trial and error is a tedious process for users. If min_util is set too low, too many HUIs will be generated, which may cause the mining process to be very inefficient. On the other hand, if min_util is set too high, it is likely that no HUIs will be found. In this paper, we address the above issues by proposing a new framework for top-k high utility itemset mining, where k is the desired number of HUIs to be mined. Two types of efficient algorithms named TKU (mining Top-K Utility itemsets) and TKO (mining Top-K utility itemsets in One phase) are proposed for mining such itemsets without the need to set min_util. We provide a structural comparison of the two algorithms with discussions on their advantages and limitations. Empirical evaluations on both real and synthetic datasets show that the performance of the proposed algorithms is close to that of the optimal case of state-of-the-art utility mining algorithms.",
Fair Network Bandwidth Allocation in IaaS Datacenters via a Cooperative Game Approach,"With wide application of virtualization technology, tenants are able to access isolated cloud services by renting the shared resources in Infrastructure-as-a-Service (IaaS) datacenters. Unlike resources such as CPU and memory, datacenter network, which relies on traditional transport-layer protocols, suffers unfairness due to a lack of virtual machine (VM)-level bandwidth guarantees. In this paper, we model the datacenter bandwidth allocation as a cooperative game, toward VM-based fairness across the datacenter with two main objectives: 1) guarantee bandwidth for VMs based on their base bandwidth requirements, and 2) share residual bandwidth in proportion to the weights of VMs. Through a bargaining game approach, we propose a bandwidth allocation algorithm, Falloc, to achieve the asymmetric Nash bargaining solution (NBS) in datacenter networks, which exactly meets our objectives. The cooperative structure of the algorithm is exploited to develop an online algorithm for practical real-world implementation. We validate Falloc with experiments under diverse scenarios and show that by adapting to different network requirements of VMs, Falloc can achieve fairness among VMs and balance the tradeoff between bandwidth guarantee and proportional bandwidth sharing. Our large-scale trace-driven simulations verify that Falloc achieves high utilization while maintaining fairness among VMs in datacenters.","Bandwidth,
Channel allocation,
Resource management,
Servers,
Games,
Vectors,
Protocols"
"Burst Mode Elimination in High-Power
LLC
Resonant Battery Charger for Electric Vehicles","In order to recover and fully charge batteries in electric vehicles, smart battery chargers should not only work under different loading conditions and output voltage regulations (close to zero to 1.5 times the nominal output voltage), but also provide a ripple-free charging current for battery packs and a noise-free environment for the battery management system (BMS). In this paper, an advanced LLC design procedure is investigated to provide advantageous extreme regulation and eliminate detrimental burst mode operation. A modified, special LLC tank driven by both variable frequency and phase shift proves to be a successful solution to achieve all the regulation requirements for battery charging (from recovery, bulk, equalization, to finish). The proposed solution can eliminate the negative impact of burst mode noises on the BMS, provide a ripple-free charging current for batteries in different states of charge, reduce the switching frequency variation, and facilitate the EMI filter and magnetic components designs procedure. In order to fully consider the characteristics of the full bridge LLC resonant converter, especially the output voltage regulation range and soft transitions of the MOSFETs in the fixed frequency phase shift mode, a new set of analytical equations is obtained for the LLC resonant converter with consideration of separated primary and secondary leakage inductances of the high frequency transformer. Based on the proposed strategy and analytical equations, multivariate statistical design methodology is employed to design and optimize a 120 VDC, 3-kW battery charger. The experimental results exhibit the excellent performance of the resulting converter, which has a peak efficiency of 96.5% with extreme regulation capability.","Batteries,
Resonant frequency,
RLC circuits,
Inductance,
Capacitance,
Voltage control,
Battery chargers"
Skyrmion-Electronics: An Overview and Outlook,"The well-known empirical phenomenon known as Moore's Law has held true for the past half century. However, it is beginning to break down, owing to limitations arising from leakage currents caused by the quantum effect. As a result, the search for alternatives or complementary technologies that can aid the downscaling of complementary metal-oxide-semiconductor (CMOS) technology has been accelerated in the field of electronics. Among various potential candidates, spintronic technology has attracted considerable interest and attention, especially for the topological spin textures known as magnetic skyrmions. Magnetic skyrmions are expected to have topologically protected stability and nanoscale size, and require a very low driving current density, therefore they are considered as potential building blocks for future spintronic devices and integrated circuits. Furthermore, recent experimental demonstrations of the control of individual nanometer-scale skyrmions, including their creation, detection, transportation, and manipulation at room temperature, further highlight their potential for future electronic applications. In this paper, we review the current status and outlook of skyrmions from the viewpoint of electronic applications. First, the fundamental and elementary functionality of skyrmions, such as electric write-in, read-out, transmission, and manipulation, are introduced. Then, potential electronic applications of skyrmions for nonvolatile memory and logic circuits are described with case studies. Finally, we conclude with an analysis of current challenges, limitations, and future trends of skyrmion research.","Transistors,
Perpendicular magnetic anisotropy,
Magnetic resonance imaging,
Superconducting magnets,
Magnetic circuits,
Electric potential,
Spintronics"
An Intelligent Information Forwarder for Healthcare Big Data Systems With Distributed Wearable Sensors,"An increasing number of the elderly population wish to live an independent lifestyle, rather than rely on intrusive care programmes. A big data solution is presented using wearable sensors capable of carrying out continuous monitoring of the elderly, alerting the relevant caregivers when necessary and forwarding pertinent information to a big data system for analysis. A challenge for such a solution is the development of context-awareness through the multidimensional, dynamic and nonlinear sensor readings that have a weak correlation with observable human behaviours and health conditions. To address this challenge, a wearable sensor system with an intelligent data forwarder is discussed in this paper. The forwarder adopts a Hidden Markov Model for human behaviour recognition. Locality sensitive hashing is proposed as an efficient mechanism to learn sensor patterns. A prototype solution is implemented to monitor health conditions of dispersed users. It is shown that the intelligent forwarders can provide the remote sensors with context-awareness. They transmit only important information to the big data server for analytics when certain behaviours happen and avoid overwhelming communication and data storage. The system functions unobtrusively, whilst giving the users peace of mind in the knowledge that their safety is being monitored and analysed.","Information management,
Data handling,
Data storage systems,
Sensors,
Medical services,
Hidden Markov models,
Monitoring"
Sensors in Assisted Living: A survey of signal and image processing methods,"Our society will face a notable demographic shift in the near future. According to a United Nations report, the ratio of the elderly population (aged 60 years or older) to the overall population increased from 9.2% in 1990 to 11.7% in 2013 and is expected to reach 21.1% by 2050 [1]. According to the same report, 40% of older people live independently in their own homes. This ratio is about 75% in the developed countries. These facts will result in many societal challenges as well as changes in the health-care system, such as an increase in diseases and health-care costs, a shortage of caregivers, and a rise in the number of individuals unable to live independently [2]. Thus, it is imperative to develop ambient intelligence-based assisted living (AL) tools that help elderly people live independently in their homes. The recent developments in sensor technology and decreasing sensor costs have made the deployment of various sensors in various combinations viable, including static setups as well as wearable sensors. This article presents a survey that concentrates on the signal processing methods employed with different types of sensors. The types of sensors covered are pyro-electric infrared (PIR) and vibration sensors, accelerometers, cameras, depth sensors, and microphones.",
Covert Communication Over Noisy Channels: A Resolvability Perspective,"We consider the situation in which a transmitter attempts to communicate reliably over a discrete memoryless channel, while simultaneously ensuring covertness (low probability of detection) with respect to a warden, who observes the signals through another discrete memoryless channel. We develop a coding scheme based on the principle of channel resolvability, which generalizes and extends prior work in several directions. First, it shows that irrespective of the quality of the channels, it is possible to communicate on the order of √n reliable and covert bits over n channel uses if the transmitter and the receiver share on the order of √n key bits. This improves upon earlier results requiring on the order of √n log n key bits. Second, it proves that if the receiver's channel is better than the warden's channel in a sense that we make precise, it is possible to communicate on the order of √n reliable and covert bits over n channel uses without a secret key. This generalizes earlier results established for binary symmetric channels. We also identify the fundamental limits of covert and secret communications in terms of the optimal asymptotic scaling of the message size and key size, and we extend the analysis to Gaussian channels. The main technical problem that we address is how to develop concentration inequalities for low-weight sequences. The crux of our approach is to define suitably modified typical sets that are amenable to concentration inequalities.",
Streaming High-Quality Mobile Video with Multipath TCP in Heterogeneous Wireless Networks,"The proliferating wireless infrastructures with complementary characteristics prompt the bandwidth aggregation for concurrent video transmission in heterogeneous access networks. Multipath TCP (MPTCP) is an important transport-layer protocol recommended by IETF to integrate different access medium (e.g., Cellular and Wi-Fi). This paper investigates the problem of mobile video delivery using MPTCP in heterogeneous wireless networks with multihomed terminals. To achieve the optimal quality of real-time video streaming, we have to seriously consider the path asymmetry in different access networks and the disadvantages of the data retransmission mechanism in MPTCP. Motivated by addressing these critical issues, this study presents a novel quAlity-Driven MultIpath TCP (ADMIT) scheme that integrates the utility maximization based Forward Error Correction (FEC) coding and rate allocation. We develop an analytical framework to model the MPTCP-based video delivery quality over multiple communication paths. ADMIT is able to effectively integrate the most reliable access networks with FEC coding to minimize the end-to-end video distortion. The performance of ADMIT is evaluated through extensive semi-physical emulations in Exata involving H.264 video streaming. Experimental results show that ADMIToutperforms the reference transport protocols in terms of video PSNR (Peak Signal-to-Noise Ratio), end-to-end delay, and goodput. Thus, we recommend ADMIT for streaming high-quality mobile video in heterogeneous wireless networks with multihomed terminals.","Streaming media,
Delays,
Forward error correction,
Encoding,
Wireless networks,
Packet loss"
Social-Aware Data Collection Scheme Through Opportunistic Communication in Vehicular Mobile Networks,"To enable the intelligent management of Smart City and improve overall social welfare, it is desirable for the status of infrastructures detected and reported by intelligent devices embedded in them to be forwarded to the data centers. Using “SCmules” such as taxis, to opportunistically communicate with intelligent devices and collect data from the sparse networks formed by them in the process of moving is an economical and effective way to achieve this goal. In this paper, the social welfare data collection paradigm SWDCP-SCmules data collection framework is proposed to collect data generated by intelligent devices and forward them to data centers, in which “SCmules” are data transmitters picking up data from nearby intelligent devices and then store-carry-forwarding them to nearby data centers via short-range wireless connections in the process of moving. Because of the storage limitations, “SCmules” need to weigh the value of data and select some less valuable data to discard when necessary. To quantify the value of data and find a well-performed selection strategy, the concept of priority is introduced to the SWDCP-SCmules scheme, and then, the simulated annealing for priority assignment SA-PA algorithm is proposed to guide the priority assignment. The SA-PA algorithm is a universal algorithm that can improve the performance of SWDCP-SCmules scheme by finding better priority assignment with respect to various optimization targets, such as maximizing collection rate or minimizing redundancy rate, in which priority assignment problem is converted into an optimization problem and simulated annealing is used to optimize the priority assignment. From the perspective of machine learning, the process of optimization is equal to automatically learn social-aware patterns from past GPS trajectory data. Experiments based on real GPS trajectory data of taxis in Beijing are conducted to show the effectiveness and efficiency of SWDCP-SCmules scheme and SA-PA algorithm.","Optimization,
Public transportation,
Global Positioning System,
Trajectory,
Smart cities,
Data collection,
Transmitters"
The 2014 General Video Game Playing Competition,"This paper presents the framework, rules, games, controllers, and results of the first General Video Game Playing Competition, held at the IEEE Conference on Computational Intelligence and Games in 2014. The competition proposes the challenge of creating controllers for general video game play, where a single agent must be able to play many different games, some of them unknown to the participants at the time of submitting their entries. This test can be seen as an approximation of general artificial intelligence, as the amount of game-dependent heuristics needs to be severely limited. The games employed are stochastic real-time scenarios (where the time budget to provide the next action is measured in milliseconds) with different winning conditions, scoring mechanisms, sprite types, and available actions for the player. It is a responsibility of the agents to discover the mechanics of each game, the requirements to obtain a high score and the requisites to finally achieve victory. This paper describes all controllers submitted to the competition, with an in-depth description of four of them by their authors, including the winner and the runner-up entries of the contest. The paper also analyzes the performance of the different approaches submitted, and finally proposes future tracks for the competition.","Games,
Artificial intelligence,
Sprites (computer),
Avatars,
Benchmark testing,
Educational institutions,
Training"
Automated Polyp Detection in Colonoscopy Videos Using Shape and Context Information,"This paper presents the culmination of our research in designing a system for computer-aided detection (CAD) of polyps in colonoscopy videos. Our system is based on a hybrid context-shape approach, which utilizes context information to remove non-polyp structures and shape information to reliably localize polyps. Specifically, given a colonoscopy image, we first obtain a crude edge map. Second, we remove non-polyp edges from the edge map using our unique feature extraction and edge classification scheme. Third, we localize polyp candidates with probabilistic confidence scores in the refined edge maps using our novel voting scheme. The suggested CAD system has been tested using two public polyp databases, CVC-ColonDB, containing 300 colonoscopy images with a total of 300 polyp instances from 15 unique polyps, and ASU-Mayo database, which is our collection of colonoscopy videos containing 19,400 frames and a total of 5,200 polyp instances from 10 unique polyps. We have evaluated our system using free-response receiver operating characteristic (FROC) analysis. At 0.1 false positives per frame, our system achieves a sensitivity of 88.0% for CVC-ColonDB and a sensitivity of 48% for the ASU-Mayo database. In addition, we have evaluated our system using a new detection latency analysis where latency is defined as the time from the first appearance of a polyp in the colonoscopy video to the time of its first detection by our system. At 0.05 false positives per frame, our system yields a polyp detection latency of 0.3 seconds.",
Energy-Efficient Resource Allocation Optimization for Multimedia Heterogeneous Cloud Radio Access Networks,"The heterogeneous cloud radio access network (H-CRAN) is a promising paradigm that incorporates cloud computing into heterogeneous networks (HetNets), thereby taking full advantage of cloud radio access networks (C-RANs) and HetNets. Characterizing cooperative beamforming with fronthaul capacity and queue stability constraints is critical for multimedia applications to improve the energy efficiency (EE) in H-CRANs. An energy-efficient optimization objective function with individual fronthaul capacity and intertier interference constraints is presented in this paper for queue-aware multimedia H-CRANs. To solve this nonconvex objective function, a stochastic optimization problem is reformulated by introducing the general Lyapunov optimization framework. Under the Lyapunov framework, this optimization problem is equivalent to an optimal network-wide cooperative beamformer design algorithm with instantaneous power, average power, and intertier interference constraints, which can be regarded as a weighted sum EE maximization problem and solved by a generalized weighted minimum mean-square error approach. The mathematical analysis and simulation results demonstrate that a tradeoff between EE and queuing delay can be achieved, and this tradeoff strictly depends on the fronthaul constraint.","Optimization,
Resource management,
Delays,
Multimedia communication,
Interference,
Cloud computing,
Radio access networks"
Active Management of Low-Voltage Networks for Mitigating Overvoltages Due to Photovoltaic Units,"In this paper, the overvoltage problems that might arise from the integration of photovoltaic (PV) panels into low-voltage (LV) distribution networks is addressed. A distributed scheme is proposed that adjusts the reactive and active power output of inverters to prevent or alleviate such problems. The proposed scheme is model-free and makes use of limited communication between the controllers in the form of a distress signal only during emergency conditions. It prioritizes the use of reactive power, while active power curtailment is performed only as a last resort. The behavior of the scheme is studied using dynamic simulations on a single LV feeder and on a larger network composed of 14 LV feeders. Its performance is compared with a centralized scheme based on the solution of an optimal power flow (OPF) problem, whose objective function is to minimize the active power curtailment. The proposed scheme successfully mitigates overvoltage situations due to high PV penetration and performs almost as well as the OPF-based solution with significantly less information and communication requirements.",
Category Specific Dictionary Learning for Attribute Specific Feature Selection,"Attributes, as mid-level features, have demonstrated great potential in visual recognition tasks due to their excellent propagation capability through different categories. However, existing attribute learning methods are prone to learning the correlated attributes. To discover the genuine attribute specific features, many feature selection methods have been proposed. However, these feature selection methods are implemented at the level of raw features that might be very noisy, and these methods usually fail to consider the structural information in the feature space. To address this issue, in this paper, we propose a label constrained dictionary learning approach combined with a multilayer filter. The feature selection is implemented at dictionary level, which can better preserve the structural information. The label constrained dictionary learning suppresses the intra-class noise by encouraging the sparse representations of intra-class samples to lie close to their center. A multilayer filter is developed to discover the representative and robust attribute specific bases. The attribute specific bases are only shared among the positive samples or the negative samples. The experiments on the challenging Animals with Attributes data set and the SUN attribute data set demonstrate the effectiveness of our proposed method.","Semantics,
Nonhomogeneous media,
Dictionaries,
Image color analysis,
Visualization,
Vocabulary"
Adaptive Replacement Strategies for MOEA/D,"Multiobjective evolutionary algorithms based on decomposition (MOEA/D) decompose a multiobjective optimization problem into a set of simple optimization subproblems and solve them in a collaborative manner. A replacement scheme, which assigns a new solution to a subproblem, plays a key role in balancing diversity and convergence in MOEA/D. This paper proposes a global replacement scheme which assigns a new solution to its most suitable subproblems. We demonstrate that the replacement neighborhood size is critical for population diversity and convergence, and develop an approach for adjusting this size dynamically. A steady-state algorithm and a generational one with this approach have been designed and experimentally studied. The experimental results on a number of test problems have shown that the proposed algorithms have some advantages.",
Bayesian Coalition Negotiation Game as a Utility for Secure Energy Management in a Vehicles-to-Grid Environment,"In recent times, Plug-in Electric Vehicles (PEVs) have emerged as a new alternative to increase the efficiency of smart grids (SGs) in a vehicles-to-grid (V2G) environment. The V2G environment provides a bidirectional power and information flow, so that users can have an optimized usage as per their requirements. However, uncontrolled and unmanaged power distribution may lead to an overall performance degradation in V2G environment. One reason for this uncontrolled and unmanaged flow may be due to the usage of power by unauthorized users. To address this issue, we propose a Bayesian Coalition Negotiation Game (BCNG) as a utility for secure energy management for PEVs in the V2G environment. We have used a BCNG along with Learning Automata (LA), wherein LA are stationed on PEVs and are assumed as the players in the game. To provide an approach based on resilience for any misuse of electricity consumption, a new Secure Payoff Function (SPF) is proposed. The players take actions and update their action probability vector using the SPF. A Nash Equilibrium (NE) is also achieved in the game using convergence theory. Our proposal is evaluated with various metrics. The proposed scheme also provides mutual authentication and resilience against various attacks during power distribution.","Games,
Learning automata,
Equations,
Bayes methods,
Automata,
Vectors,
Vehicles"
Pedestrian Detection with Spatially Pooled Features and Structured Ensemble Learning,"Many typical applications of object detection operate within a prescribed false-positive range. In this situation the performance of a detector should be assessed on the basis of the area under the ROC curve over that range, rather than over the full curve, as the performance outside the prescribed range is irrelevant. This measure is labelled as the partial area under the ROC curve (pAUC). We propose a novel ensemble learning method which achieves a maximal detection rate at a user-defined range of false positive rates by directly optimizing the partial AUC using structured learning. In addition, in order to achieve high object detection performance, we propose a new approach to extracting low-level visual features based on spatial pooling. Incorporating spatial pooling improves the translational invariance and thus the robustness of the detection process. Experimental results on both synthetic and realworld data sets demonstrate the effectiveness of our approach, and we show that it is possible to train state-of-the-art pedestrian detectors using the proposed structured ensemble learning method with spatially pooled features. The result is the current best reported performance on the Caltech-USA pedestrian detection dataset.",
"Energy-Efficient Cell Activation, User Association, and Spectrum Allocation in Heterogeneous Networks","Next generation (5G) cellular networks are expected to be supported by an extensive infrastructure with many-fold increase in the number of cells per unit area compared to today. The total energy consumption of base transceiver stations (BTSs) is an important issue for both economic and environmental reasons. In this paper, an optimization-based framework is proposed for energy-efficient global radio resource management in heterogeneous wireless networks. Specifically, with stochastic arrivals of known rates intended for users, the smallest set of BTSs is activated with jointly optimized user association and spectrum allocation to stabilize the network. The average delay is subsequently minimized. The scheme can be carried out periodically on a relatively slow timescale to adapt to aggregate traffic variations and average channel conditions. Numerical results show that the proposed scheme significantly reduces energy consumption and increases quality of service compared to existing schemes.","Resource management,
Bandwidth,
Quality of service,
Delays,
Energy consumption,
Optimization,
Aggregates"
Resilient Control of Networked Control System Under DoS Attacks: A Unified Game Approach,"We consider the problem of resilient control of networked control system (NCS) under denial-of-service (DoS) attack via a unified game approach. The DoS attacks lead to extra constraints in the NCS, where the packets may be jammed by a malicious adversary. Considering the attack-induced packet dropout, optimal control strategies with multitasking and central-tasking structures are developed using game theory in the delta domain, respectively. Based on the optimal control structures, we propose optimality criteria and algorithms for both cyber defenders and DoS attackers. Both simulation and experimental results are provided to illustrate the effectiveness of the proposed design procedure.","Computer crime,
Optimization,
Informatics,
Optimal control,
Games,
Degradation"
A Survey of Task Allocation and Load Balancing in Distributed Systems,"In past decades, significant attention has been devoted to the task allocation and load balancing in distributed systems. Although there have been some related surveys about this subject, each of which only made a very preliminary review on the state of art of one single type of distributed systems. To correlate the studies in varying types of distributed systems and make a comprehensive taxonomy on them, this survey mainly categorizes and reviews the representative studies on task allocation and load balancing according to the general characteristics of varying distributed systems. First, this survey summarizes the general characteristics of distributed systems. Based on these general characteristics, this survey reviews the studies on task allocation and load balancing with respect to the following aspects: 1) typical control models; 2) typical resource optimization methods; 3) typical methods for achieving reliability; 4) typical coordination mechanisms among heterogeneous nodes; and 5) typical models considering network structures. For each aspect, we summarize the existing studies and discuss the future research directions. Through the survey, the related studies in this area can be well understood based on how they can satisfy the general characteristics of distributed systems.",
MAPS: A Quantitative Radiomics Approach for Prostate Cancer Detection,"This paper presents a quantitative radiomics feature model for performing prostate cancer detection using multiparametric MRI (mpMRI). It incorporates a novel tumor candidate identification algorithm to efficiently and thoroughly identify the regions of concern and constructs a comprehensive radiomics feature model to detect tumorous regions. In contrast to conventional automated classification schemes, this radiomics-based feature model aims to ground its decisions in a way that can be interpreted and understood by the diagnostician. This is done by grouping features into high-level feature categories which are already used by radiologists to diagnose prostate cancer: Morphology, Asymmetry, Physiology, and Size (MAPS), using biomarkers inspired by the PI-RADS guidelines for performing structured reporting on prostate MRI. Clinical mpMRI data were collected from 13 men with histology-confirmed prostate cancer and labeled by an experienced radiologist. These annotated data were used to train classifiers using the proposed radiomics-driven feature model in order to evaluate the classification performance. The preliminary experimental results indicated that the proposed model outperformed each of its constituent feature groups as well as a comparable conventional mpMRI feature model. A further validation of the proposed algorithm will be conducted using a larger dataset as future work.","Prostate cancer,
Tumors,
Feature extraction,
Magnetic resonance imaging,
Morphology,
Biological system modeling"
Person Re-Identification by Discriminative Selection in Video Ranking,"Current person re-identification (ReID) methods typically rely on single-frame imagery features, whilst ignoring space-time information from image sequences often available in the practical surveillance scenarios. Single-frame (single-shot) based visual appearance matching is inherently limited for person ReID in public spaces due to the challenging visual ambiguity and uncertainty arising from non-overlapping camera views where viewing condition changes can cause significant people appearance variations. In this work, we present a novel model to automatically select the most discriminative video fragments from noisy/incomplete image sequences of people from which reliable space-time and appearance features can be computed, whilst simultaneously learning a video ranking function for person ReID. Using the PRID2011, iLIDS-VID, and HDA+ image sequence datasets, we extensively conducted comparative evaluations to demonstrate the advantages of the proposed model over contemporary gait recognition, holistic image sequence matching and state-of-the-art single-/multi-shot ReID methods.",
The Application of Visual Saliency Models in Objective Image Quality Assessment: A Statistical Evaluation,"Advances in image quality assessment have shown the potential added value of including visual attention aspects in its objective assessment. Numerous models of visual saliency are implemented and integrated in different image quality metrics (IQMs), but the gain in reliability of the resulting IQMs varies to a large extent. The causes and the trends of this variation would be highly beneficial for further improvement of IQMs, but are not fully understood. In this paper, an exhaustive statistical evaluation is conducted to justify the added value of computational saliency in objective image quality assessment, using 20 state-of-the-art saliency models and 12 best-known IQMs. Quantitative results show that the difference in predicting human fixations between saliency models is sufficient to yield a significant difference in performance gain when adding these saliency models to IQMs. However, surprisingly, the extent to which an IQM can profit from adding a saliency model does not appear to have direct relevance to how well this saliency model can predict human fixations. Our statistical analysis provides useful guidance for applying saliency models in IQMs, in terms of the effect of saliency model dependence, IQM dependence, and image distortion dependence. The testbed and software are made publicly available to the research community.","Image quality,
Visualization,
Distortion,
Computational modeling,
Predictive models,
Measurement,
Databases"
Measurements and Performance Factor Comparisons of Magnetic Materials at High Frequency,"The design of power magnetic components for operation at high frequency (HF, 3-30 MHz) has been hindered by a lack of magnetic material performance data and by the limited design theory in that frequency range. To address these deficiencies, we have measured and present core loss data for a variety of commercially available magnetic materials in the HF range. In addition, we extend the theory of performance factor for appropriate use in the HF design. Since magnetic materials suitable for HF applications tend to have low permeability, we also consider the impact of low permeability on design. We conclude that, with appropriate material selection and design, increased frequencies can continue to yield improved power density well into the HF regime.",
Lightweight and Energy-Efficient Mutual Authentication and Key Agreement Scheme With User Anonymity for Secure Communication in Global Mobility Networks,"User authentication is an imperative security mechanism for recognizing legal roaming users. However, designing an expeditious anonymous-user authentication scheme in the global mobility networking (GLOMONET) environment is always a challenging task. Because, due to the broadcast nature of the wireless channels, wireless networks are often susceptible to various attacks and mobile devices powered by batteries that have limited communication, processing, and storage capabilities. In this paper, we propose a lightweight, secure, and an expeditious authentication scheme, which can preserve the user anonymity for roaming services in GLOMONET. In this regard, we use the low-cost cryptographic primitives such as one-way hash functions and exclusive-or operations to accomplish goals, which is more suitable for battery-powered mobile devices. Although some authentication protocols for GLOMONET security have already been proposed, however, they are unable to achieve the desired imperative security properties, such as anonymity, privacy against eavesdroppers, communication security, etc. As a consequence of that, they are vulnerable to various security issues. Security and performance analyses show that our proposed scheme is secure and even more efficient, as compared with other related authentication schemes in GLOMONET.","Authentication,
Protocols,
Mobile communication,
Smart cards,
Cryptography,
Forgery"
A Nonnegative Latent Factor Model for Large-Scale Sparse Matrices in Recommender Systems via Alternating Direction Method,"Nonnegative matrix factorization (NMF)-based models possess fine representativeness of a target matrix, which is critically important in collaborative filtering (CF)-based recommender systems. However, current NMF-based CF recommenders suffer from the problem of high computational and storage complexity, as well as slow convergence rate, which prevents them from industrial usage in context of big data. To address these issues, this paper proposes an alternating direction method (ADM)-based nonnegative latent factor (ANLF) model. The main idea is to implement the ADM-based optimization with regard to each single feature, to obtain high convergence rate as well as low complexity. Both computational and storage costs of ANLF are linear with the size of given data in the target matrix, which ensures high efficiency when dealing with extremely sparse matrices usually seen in CF problems. As demonstrated by the experiments on large, real data sets, ANLF also ensures fast convergence and high prediction accuracy, as well as the maintenance of nonnegativity constraints. Moreover, it is simple and easy to implement for real applications of learning systems.",
A Planar End-Fire Circularly Polarized Complementary Antenna With Beam in Parallel With Its Plane,"Operation principle and design approach of a novel planar end-lire circularly polarized (CP) complementary antenna is proposed. A vertically polarized printed magnetic dipole and a horizontally polarized printed dipole are combined on the same substrate, and a planar CP antenna with end-lire beam in parallel with its plane is thus designed. Prototype antennas centered at 5.80 GHz are then fabricated and measured to validate the operation principle and the design approach. The experimental prototype reported that the impedance bandwidth (20 log |S11| ( <; -10 dB) is about 1.90%, from 5.75 to 5.86 GHz and the 3-dB axial ratio (AR) bandwidth is about 14.48%, from 5.19 to 6.00 GHz. Therefore, the proposed design is applicable as a low-prolile handheld reader antenna in radio-frequency identilication (RFID) systems.","Dipole antennas,
Apertures,
Bandwidth,
Antenna radiation patterns,
Substrates,
Impedance"
Support Tensor Machines for Classification of Hyperspectral Remote Sensing Imagery,"In recent years, the support vector machines (SVMs) have been very successful in remote sensing image classification, particularly when dealing with high-dimensional data and limited training samples. Nevertheless, the vector-based feature alignment of the SVM can lead to an information loss in representation of hyperspectral images, which intrinsically have a tensor-based data structure. In this paper, a new multiclass support tensor machine (STM) is specifically developed for hyperspectral image classification. Our newly proposed STM processes the hyperspectral image as a data cube and then identifies the information classes in tensor space. The multiclass STM is developed from a set of binary STM classifiers using the one-against-one parallel strategy. As a part of our tensor-based processing chain, a multilinear principal component analysis (MPCA) is used for preprocessing, in order to reduce the tensorial data redundancy and, at the same time, preserve the tensorial structure information in sparse and high-order subspaces. As a result, the contributions of this work are twofold: a new multiclass STM model for hyperspectral image classification is developed, and a tensorial image interpretation framework is constructed, which provides a system consisting of tensor-based feature representation, feature extraction, and classification. Experiments with four hyperspectral data sets, covering agricultural and urban areas, are conducted to validate the effectiveness of the proposed framework. Our experimental results show that the proposed STM and MPCA-STM can achieve better results than traditional SVM-based classifiers.",
Compressive Covariance Sensing: Structure-based compressive sensing beyond sparsity,"Compressed sensing deals with the reconstruction of signals from sub-Nyquist samples by exploiting the sparsity of their projections onto known subspaces. In contrast, this article is concerned with the reconstruction of second-order statistics, such as covariance and power spectrum, even in the absence of sparsity priors. The framework described here leverages the statistical structure of random processes to enable signal compression and offers an alternative perspective at sparsity-agnostic inference. Capitalizing on parsimonious representations, we illustrate how compression and reconstruction tasks can be addressed in popular applications such as power-spectrum estimation, incoherent imaging, direction-of-arrival estimation, frequency estimation, and wideband spectrum sensing.",
DISC: Deep Image Saliency Computing via Progressive Representation Learning,"Salient object detection increasingly receives attention as an important component or step in several pattern recognition and image processing tasks. Although a variety of powerful saliency models have been intensively proposed, they usually involve heavy feature (or model) engineering based on priors (or assumptions) about the properties of objects and backgrounds. Inspired by the effectiveness of recently developed feature learning, we provide a novel deep image saliency computing (DISC) framework for fine-grained image saliency computing. In particular, we model the image saliency from both the coarse-and fine-level observations, and utilize the deep convolutional neural network (CNN) to learn the saliency representation in a progressive manner. In particular, our saliency model is built upon two stacked CNNs. The first CNN generates a coarse-level saliency map by taking the overall image as the input, roughly identifying saliency regions in the global context. Furthermore, we integrate superpixel-based local context information in the first CNN to refine the coarse-level saliency map. Guided by the coarse saliency map, the second CNN focuses on the local context to produce fine-grained and accurate saliency map while preserving object details. For a testing image, the two CNNs collaboratively conduct the saliency computing in one shot. Our DISC framework is capable of uniformly highlighting the objects of interest from complex background while preserving well object details. Extensive experiments on several standard benchmarks suggest that DISC outperforms other state-of-the-art methods and it also generalizes well across data sets without additional training. The executable version of DISC is available online: <;uri xlink:type=""simple"">http://vision.sysu.edu.cn/projects/DISC<;/uri>.","Computational modeling,
Context,
Image color analysis,
Visualization,
Object detection,
Computer vision,
Histograms"
Physics-Based Circuit-Compatible SPICE Model for Ferroelectric Transistors,"We present a SPICE model for ferroelectric transistors (FEFETs) based on time-dependent Landau-Khalatnikov equation solved self-consistently with the transistor equations. The model also considers depolarization fields due to non-ideal contacts. We experimentally characterize FE films to calibrate our model, based on which we analyze the device and circuit implications of FEFETs. We discuss the dependence of the ON current and gate capacitance of FEFETs on the FE thickness and FE material parameters. A ring oscillator analysis shows delay reduction up to 97% at iso-energy for FEFETs compared with MOSFETs at VDD <; 0.4 V. FEFET-based SRAMs show 47%-68% larger read stability and 50%-57% lower access time, albeit with an increase in the write time.",
Decomposition-Based Algorithms Using Pareto Adaptive Scalarizing Methods,"Decomposition-based algorithms have become increasingly popular for evolutionary multiobjective optimization. However, the effect of scalarizing methods used in these algorithms is still far from being well understood. This paper analyzes a family of frequently used scalarizing methods, the Lp methods, and shows that the p value is crucial to balance the selective pressure toward the Pareto optimal and the algorithm robustness to Pareto optimal front (PF) geometries. It demonstrates that an Lp method that can maximize the search ability of a decomposition-based algorithm exists and guarantees that, given some weight, any solution along the PF can be found. Moreover, a simple yet effective method called Pareto adaptive scalarizing (PaS) approximation is proposed to approximate the optimal p value. In order to demonstrate the effectiveness of PaS, we incorporate PaS into a state-of-the-art decomposition-based algorithm, i.e., multiobjective evolutionary algorithm based on decomposition (MOEA/D), and compare the resultant MOEA/D-PaS with some other MOEA/D variants on a set of problems with different PF geometries and up to seven conflicting objectives. Experimental results demonstrate that the PaS is effective.","Pareto optimization,
Chebyshev approximation,
Approximation algorithms,
Geometry,
Evolutionary computation,
Linear programming"
Conflict-Aware Event-Participant Arrangement and Its Variant for Online Setting,"With the rapid development of Web 2.0 and Online To Offline (O2O) marketing model, various online event-based social networks (EBSNs) are getting popular. An important task of EBSNs is to facilitate the most satisfactory event-participant arrangement for both sides, i.e., events enroll more participants and participants are arranged with personally interesting events. Existing approaches usually focus on the arrangement of each single event to a set of potential users, or ignore the conflicts between different events, which leads to infeasible or redundant arrangements. In this paper, to address the shortcomings of existing approaches, we first identify a more general and useful event-participant arrangement problem, called Global E vent-participant Arrangement with Conflict and C apacity (
GEACC
) problem, focusing on the conflicts of different events and making event-participant arrangements in a global view. We find that the GEACC problem is NP-hard due to the conflicts among events. Thus, we design two approximation algorithms with provable approximation ratios and an exact algorithm with pruning technique to address this problem. In addition, we propose an online setting of GEACC, called OnlineGEACC, which is also practical in real-world scenarios. We further design an online algorithm with provable performance guarantee. Finally, we verify the effectiveness and efficiency of the proposed methods through extensive experiments on real and synthetic datasets.","Algorithm design and analysis,
Approximation algorithms,
Social network services,
Web 2.0,
Recruitment,
Games,
Computer science"
Energy Efficient Resource Allocation for Wireless Power Transfer Enabled Collaborative Mobile Clouds,"In order to fully enjoy high rate broadband multimedia services, prolonging the battery lifetime of user equipment is critical for mobile users, especially for smartphone users. In this paper, the problem of distributing cellular data via a wireless power transfer enabled collaborative mobile cloud (WeCMC) in an energy efficient manner is investigated. WeCMC is formed by a group of users who have both functionalities of information decoding and energy harvesting, and are interested for cooperating in downloading content from the operators. Through device-to-device communications, the users inside WeCMC are able to cooperate during the downloading procedure and offload data from the base station to other WeCMC members. When considering multi-input multi-output wireless channel and wireless power transfer, an efficient algorithm is presented to optimally schedule the data offloading and radio resources in order to maximize energy efficiency as well as fairness among mobile users. Specifically, the proposed framework takes energy minimization and quality of service requirement into consideration. Performance evaluations demonstrate that a significant energy saving gain can be achieved by the proposed schemes.",
"Internet of Vehicles: Motivation, Layered Architecture, Network Model, Challenges, and Future Aspects","Internet of Things is smartly changing various existing research areas into new themes, including smart health, smart home, smart industry, and smart transport. Relying on the basis of “smart transport,” Internet of Vehicles (IoV) is evolving as a new theme of research and development from vehicular ad hoc networks (VANETs). This paper presents a comprehensive framework of IoV with emphasis on layered architecture, protocol stack, network model, challenges, and future aspects. Specifically, following the background on the evolution of VANETs and motivation on IoV an overview of IoV is presented as the heterogeneous vehicular networks. The IoV includes five types of vehicular communications, namely, vehicle-to-vehicle, vehicle-to-roadside, vehicle-to-infrastructure of cellular networks, vehicle-to-personal devices, and vehicle-to-sensors. A five layered architecture of IoV is proposed considering functionalities and representations of each layer. A protocol stack for the layered architecture is structured considering management, operational, and security planes. A network model of IoV is proposed based on the three network elements, including cloud, connection, and client. The benefits of the design and development of IoV are highlighted by performing a qualitative comparison between IoV and VANETs. Finally, the challenges ahead for realizing IoV are discussed and future aspects of IoV are envisioned.","Intelligent vehicles,
Internet of things,
Vehicular ad hoc networks,
Cloud computing,
Computer architecture,
Heterogeneous networks,
Reliability"
Finite-Time Consensus for Multiagent Systems With Cooperative and Antagonistic Interactions,"This paper deals with finite-time consensus problems for multiagent systems that are subject to hybrid cooperative and antagonistic interactions. Two consensus protocols are constructed by employing the nearest neighbor rule. It is shown that under the presented protocols, the states of all agents can be guaranteed to reach an agreement in a finite time regarding consensus values that are the same in modulus but may not be the same in sign. In particular, the second protocol can enable all agents to reach a finite-time consensus with a settling time that is not dependent upon the initial states of agents. Simulation results are given to demonstrate the effectiveness and finite-time convergence of the proposed consensus protocols.","Protocols,
Multi-agent systems,
Nickel,
Artificial neural networks,
Laplace equations,
Learning systems,
Convergence"
Two Time-Scale Tracking Control of Nonholonomic Wheeled Mobile Robots,"In this paper, a practical control law is proposed for wheeled mobile robots in order to both improve the transient performance and repress the tracking errors. In particular, a two time-scale filtering technique, which can derive a fast variable to compensate for the disturbance, is applied during the carbot's moving process. The nominal system is governed using a controller derived under the back-stepping framework. Such a design can effectively realize the system's tracking objective and enhance robustness via properly configured parameters. In the meantime, a two time-scale filter is applied to the system function to estimate the disturbances, essentially improving the system's precision. By virtue of this innovative technique, the final performance of the system is satisfactory in terms of both transient response and tracking error rejection. A previous sliding mode based control law is compared with the propounded one with respect to transient behavior and steady-state errors, and two types of disturbances, respectively the constant and sinusoid are simulated to verify the filter's effectiveness. Since, from the results, there is significant improvement in both transient and steady-state performance, the proposed method is confirmed to be practical for tracking control of the wheeled mobile robots.","Mobile robots,
Robustness,
Transient response,
Backstepping,
Control systems,
Robot kinematics,
Trajectory tracking"
Joint Content Replication and Request Routing for Social Video Distribution Over Cloud CDN: A Community Clustering Method,"The increasing popularity of online social networks (OSNs) has been transforming the dissemination pattern of social video contents. We can utilize the social information propagation pattern to improve the efficiency of social video distribution. In this paper, motivated by the social community classification, we present a social video replication and user request dispatching mechanism in the cloud content delivery network architecture to reduce the system operational cost, while guaranteeing the averaged service latency. Specifically, we first present a community classification method that clusters social users with social relationships, close geolocations, and similar video watching interests into various communities. Then, we conduct a large-scale measurement on a real OSN system to study the diversities of social video propagation and the effectiveness of our communities on smoothing the diversity. Finally, we propose the community-based video replication and request dispatching strategy and formulate it as a constrained optimization problem. Based on a stochastic optimization framework, we derive an online solution and rigorously prove the optimality. We evaluate our algorithm on a real trace under realistic settings and demonstrate that our algorithm can reduce the monetary cost by 30% against traditional approaches with the same service latency.","Communities,
Streaming media,
Social network services,
Cloud computing,
Dispatching,
Peer-to-peer computing,
Optimization"
NUS-PRO: A New Visual Tracking Challenge,"Numerous approaches on object tracking have been proposed during the past decade with demonstrated success. However, most tracking algorithms are evaluated on limited video sequences and annotations. For thorough performance evaluation, we propose a large-scale database which contains 365 challenging image sequences of pedestrians and rigid objects. The database covers 12 kinds of objects, and most of the sequences are captured from moving cameras. Each sequence is annotated with target location and occlusion level for evaluation. A thorough experimental evaluation of 20 state-of-the-art tracking algorithms is presented with detailed analysis using different metrics. The database is publicly available and evaluation can be carried out online for fair assessments of visual tracking algorithms.","Databases,
Image sequences,
Torso,
Helicopters,
Performance evaluation,
Cameras,
Airplanes"
Attribute-Based Data Sharing Scheme Revisited in Cloud Computing,"Ciphertext-policy attribute-based encryption (CP-ABE) is a very promising encryption technique for secure data sharing in the context of cloud computing. Data owner is allowed to fully control the access policy associated with his data which to be shared. However, CP-ABE is limited to a potential security risk that is known as key escrow problem, whereby the secret keys of users have to be issued by a trusted key authority. Besides, most of the existing CP-ABE schemes cannot support attribute with arbitrary state. In this paper, we revisit attribute-based data sharing scheme in order to solve the key escrow issue but also improve the expressiveness of attribute, so that the resulting scheme is more friendly to cloud computing applications. We propose an improved two-party key issuing protocol that can guarantee that neither key authority nor cloud service provider can compromise the whole secret key of a user individually. Moreover, we introduce the concept of attribute with weight, being provided to enhance the expression of attribute, which can not only extend the expression from binary to arbitrary state, but also lighten the complexity of access policy. Therefore, both storage cost and encryption complexity for a ciphertext are relieved. The performance analysis and the security proof show that the proposed scheme is able to achieve efficient and secure data sharing in cloud computing.","Cloud computing,
Encryption,
Protocols,
Logic gates,
Complexity theory,
Electronic mail"
Range and coexistence analysis of long range unlicensed communication,"A broad range of emerging applications require very low power, very long range yet low throughput communication. Different standards are being proposed to meet these novel requirements. In this paper, the technical differences between a wideband spread spectrum (LoRa-like) and an ultra narrowband (Sigfox-like) network will be explained and evaluated. On the physical layer, simulation results show that an ultra narrowband network has a larger coverage, while wideband spread spectrum networks are less sensitive to interference. When considering the contention between nodes and interference between different networks, simulations show that adaptation of frequency and modulation is imperative for efficiently dealing with varying contention and interference in long range unlicensed networks. Depending on network load, size and distance, a device in a wideband network can send 6 times more packets to the base station when there is active rate and frequency management and an intra-technology control plane.","Cascading style sheets,
Interference,
Binary phase shift keying,
Bit error rate,
Bandwidth,
Throughput,
Standards"
Pairwise Constraint-Guided Sparse Learning for Feature Selection,"Feature selection aims to identify the most informative features for a compact and accurate data representation. As typical supervised feature selection methods, Lasso and its variants using L1-norm-based regularization terms have received much attention in recent studies, most of which use class labels as supervised information. Besides class labels, there are other types of supervised information, e.g., pairwise constraints that specify whether a pair of data samples belong to the same class (must-link constraint) or different classes (cannot-link constraint). However, most of existing L1-norm-based sparse learning methods do not take advantage of the pairwise constraints that provide us weak and more general supervised information. For addressing that problem, we propose a pairwise constraint-guided sparse (CGS) learning method for feature selection, where the must-link and the cannot-link constraints are used as discriminative regularization terms that directly concentrate on the local discriminative structure of data. Furthermore, we develop two variants of CGS, including: 1) semi-supervised CGS that utilizes labeled data, pairwise constraints, and unlabeled data and 2) ensemble CGS that uses the ensemble of pairwise constraint sets. We conduct a series of experiments on a number of data sets from University of California-Irvine machine learning repository, a gene expression data set, two real-world neuroimaging-based classification tasks, and two large-scale attribute classification tasks. Experimental results demonstrate the efficacy of our proposed methods, compared with several established feature selection methods.",
Secure Switch-and-Stay Combining (SSSC) for Cognitive Relay Networks,"In this paper, we study a two-phase underlay cognitive relay network, where there exists an eavesdropper who can overhear the message. The secure data transmission from the secondary source to secondary destination is assisted by two decode-and-forward (DF) relays. Although the traditional opportunistic relaying technique can choose one relay to provide the best secure performance, it needs to continuously have the channel state information (CSI) of both relays, and may result in a high relay switching rate. To overcome these limitations, a secure switch-and-stay combining (SSSC) protocol is proposed where only one out of the two relays is activated to assist the secure data transmission, and the secure relay switching occurs when the relay cannot support the secure communication any longer. This security switching is assisted by either instantaneous or statistical eavesdropping CSI. For these two cases, we study the system secure performance of SSSC protocol, by deriving the analytical secrecy outage probability as well as an asymptotic expression for the high main-to-eavesdropper ratio (MER) region. We show that SSSC can substantially reduce the system complexity while achieving or approaching the full diversity order of opportunistic relaying in the presence of the instantaneous or statistical eavesdropping CSI.","Switches,
Relay networks (telecommunications),
Data communication,
Security,
Protocols,
Interference"
TrajGraph: A Graph-Based Visual Analytics Approach to Studying Urban Network Centralities Using Taxi Trajectory Data,"We propose TrajGraph, a new visual analytics method, for studying urban mobility patterns by integrating graph modeling and visual analysis with taxi trajectory data. A special graph is created to store and manifest real traffic information recorded by taxi trajectories over city streets. It conveys urban transportation dynamics which can be discovered by applying graph analysis algorithms. To support interactive, multiscale visual analytics, a graph partitioning algorithm is applied to create region-level graphs which have smaller size than the original street-level graph. Graph centralities, including Pagerank and betweenness, are computed to characterize the time-varying importance of different urban regions. The centralities are visualized by three coordinated views including a node-link graph view, a map view and a temporal information view. Users can interactively examine the importance of streets to discover and assess city traffic patterns. We have implemented a fully working prototype of this approach and evaluated it using massive taxi trajectories of Shenzhen, China. TrajGraph's capability in revealing the importance of city streets was evaluated by comparing the calculated centralities with the subjective evaluations from a group of drivers in Shenzhen. Feedback from a domain expert was collected. The effectiveness of the visual interface was evaluated through a formal user study. We also present several examples and a case study to demonstrate the usefulness of TrajGraph in urban transportation analysis.","Urban areas,
Public transportation,
Roads,
Trajectory,
Visual analytics"
A Hierarchical Framework for Coordinated Charging of Plug-In Electric Vehicles in China,"Plug-in electric vehicle (PEV) technology has drawn increasing amounts of attention in the last decade. As the world's largest automotive market, China has recently made the electrification of transportation central to its national strategic plan. Because of the unique nature of the vertically regulated power industry, China's massive deployment of PEVs has to face unique challenges that may not be encountered by any other country/region. Therefore, a comprehensive coordinated PEV charging scheme is urgently needed to facilitate the smooth grid integration of PEVs at all levels (e.g., transmission systems, distribution systems, and charging stations). This paper presents detailed mathematical modeling of a novel hierarchical framework for coordinated PEV charging at multiple timescales (i.e., day-ahead and real-time). The proposed three-level (e.g., provincial level, municipal level, and charging station level) PEV charging strategy jointly optimizes system load profile and charging costs while satisfying customer charging requirements. The interrelationships between various levels in terms of energy transaction and information exchange are clearly identified. Case studies on Guangdong Province, China, are carried out and simulation results demonstrate the effectiveness of our proposed hierarchical control framework in reducing system peak demand and charging costs.","Urban areas,
Batteries,
Charging stations,
Real-time systems,
Electric vehicles,
System-on-chip,
Power grids"
"An Overview of Industrial Alarm Systems: Main Causes for Alarm Overloading, Research Status, and Open Problems","Alarm systems play critically important roles for the safe and efficient operation of modern industrial plants. However, most existing industrial alarm systems suffer from poor performance, noticeably having too many alarms to be handled by operators in control rooms. Such alarm overloading is extremely detrimental to the important role played by alarm systems. This paper provides an overview of industrial alarm systems. Four main causes are identified as the culprits for alarm overloading, namely, chattering alarms due to noise and disturbance, alarm variables incorrectly configured, alarm design isolated from related variables, and abnormality propagation owing to physical connections. Industrial examples from a large-scale thermal power plant are provided as supportive evidences. The current research status for industrial alarm systems is summarized by focusing on existing studies related to these main causes. Eight fundamental research problems to be solved are formulated for the complete lifecycle of alarm variables including alarm configuration, alarm design, and alarm removal. Note to Practitioners-Alarm systems are critical assets for operational safety and efficiency of plants in various industrial sectors, such as power and utility, process and manufacturing, and oil and gas. However, industrial alarm systems are generally suffering from alarm overloading. This paper provides an overview of industrial alarm systems, by proposing main causes for alarm overloading, summarizing current research status and formulating open problems. In presenting this overview, we hope to attract direct attentions from more researchers and engineers into the study of industrial alarm systems.","Alarm systems,
Noise,
Standards,
Temperature measurement,
Temperature sensors,
Power generation,
Safety"
Double Kill: Compressive-Sensing-Based Narrow-Band Interference and Impulsive Noise Mitigation for Vehicular Communications,"Narrow-band interference (NBI) and impulsive noise (IN) are two kinds of non-Gaussian noise that have a severe impact on vehicular communications. In this paper, a novel compressive sensing (CS)-based method of simultaneous NBI and IN mitigation is proposed, which is a double kill of the two kinds of unfavorable disturbances. A CS-based time-frequency-measuring orthogonal frequency-division multiplexing (CS-TFM-OFDM) frame structure is introduced, in which the temporal repeated training sequences (TSs) are exploited by the proposed CS-based differential measuring (CS-DM) method to acquire the CS measurement vector of the NBI. With the aid of the a priori partial support, we further proposed the a priori-aided sparsity adaptive matching pursuit (PA-SAMP) to improve the accuracy and stability of NBI recovery. Meanwhile, the measurement vector of the IN is acquired from the null subcarriers in the CS-TFM-OFDM frame. After partial support of the IN is obtained, the IN is reconstructed using the proposed PA-SAMP algorithm. Hence, the two categories of non-Gaussian noise are both thoroughly eliminated, leading to the stability and robustness of vehicular communications. The proposed CS-based approach outperforms the conventional noise suppression methods in vehicular communications environments, which is validated by theoretical analysis and computer simulations.",
Engineering Parallel Algorithms for Community Detection in Massive Networks,"The amount of graph-structured data has recently experienced an enormous growth in many applications. To transform such data into useful information, fast analytics algorithms and software tools are necessary. One common graph analytics kernel is disjoint community detection (or graph clustering). Despite extensive research on heuristic solvers for this task, only few parallel codes exist, although parallelism will be necessary to scale to the data volume of real-world applications. We address the deficit in computing capability by a flexible and extensible community detection framework with shared-memory parallelism. Within this framework we design and implement efficient parallel community detection heuristics: A parallel label propagation scheme; the first large-scale parallelization of the well-known Louvain method, as well as an extension of the method adding refinement; and an ensemble scheme combining the above. In extensive experiments driven by the algorithm engineering paradigm, we identify the most successful parameters and combinations of these algorithms. We also compare our implementations with state-of-the-art competitors. The processing rate of our fastest algorithm often reaches 50 M edges/second. We recommend the parallel Louvain method and our variant with refinement as both qualitatively strong and fast. Our methods are suitable for massive data sets with billions of edges. (A preliminary version of this paper appeared in Proceedings of the 42nd International Conference on Parallel Processing (ICPP 2013) [35].)","Communities,
Clustering algorithms,
Parallel processing,
Algorithm design and analysis,
Image edge detection,
Instruction sets,
Software algorithms"
Service Selection for Composition with QoS Correlations,"QoS as an important criterion has attracted more and more attention in the service selection process. Various QoS-aware service selection methods have been proposed in recent years. However, few of them take into account of the QoS correlations between services, causing several performance issues. QoS correlations can be defined as that some QoS attributes of a service are not only dependent on the service itself but are also correlated to other services. Since such correlations will affect QoS values, it is important to study how to select appropriate candidate services while taking into account of QoS correlations when generating composite services with optimal QoS values. To this end, we propose a novel method of service selection, called the correlation-aware service pruning (CASP) method. It manages QoS correlations by accounting for all services that may be integrated into optimal composite services and prunes services that are not the optimal candidate services. Our experiments show that this method can manage complicated correlations between services and significantly improve the QoS values of the generated composite services.",
An Efficient Modeling Technique to Simulate and Control Submodule-Integrated PV System for Single-Phase Grid Connection,"The photovoltaic (PV) system that is based on submodule-integrated converters (subMICs) is capable of maximizing solar energy harvest by eradicating power losses due to intrapanel mismatch. Modeling and simulation of subMIC-based systems are important to study the effect of PV partial shading, prove new control strategies, analyze distributed system dynamics, optimize system configurations, and determine system parameters, etc. However, the simulation of such systems can be very challenging due to the large number of switching-mode power units, nonlinear nature of PV generators, and complication of the coordinating control. This paper provides an effective solution to simulate and control single-phase grid-tied PV systems that are based on a practical subMICs configuration. The approach includes the simplified PV cell model and averaged model for power converters, which consider all dynamic interactions among the maximum power point tracking (MPPT), PV submodule voltage regulation, dc-link voltage control, and double frequency ripple. The effectiveness of the proposed simulation and the subMIC system is validated by the comparison with a practical system based on centralized PV inverter under the real-world solar irradiance and various PV mismatch conditions, e.g., partial shading and uneven temperature distribution etc.","Mathematical model,
Inverters,
Integrated circuit modeling,
Switches,
Voltage control,
Computational modeling"
Unsupervised Sparse Pattern Diagnostic of Defects With Inductive Thermography Imaging System,This paper proposes an unsupervised method for diagnosing and monitoring defects in inductive thermography imaging system. The proposed method is fully automated and does not require manual selection from the user of the specific thermal frame images for defect diagnosis. The core of the method is a hybrid of physics-based inductive thermal mechanism with signal processing-based pattern extraction algorithm using sparse greedy-based principal component analysis (SGPCA). An internal functionality is built into the proposed algorithm to control the sparsity of SGPCA and to render better accuracy in sizing the defects. The proposed method is demonstrated on automatically diagnosing the defects on metals and the accuracy of sizing the defects. Experimental tests and comparisons with other methods have been conducted to verify the efficacy of the proposed method. Very promising results have been obtained where the performance of the proposed method is very near to human perception.,"Inductive thermal imaging,
Eddy currents,
Cameras,
Principal component analysis,
Temperature measurement,
Signal processing algorithms"
A Real-Time Big Data Gathering Algorithm Based on Indoor Wireless Sensor Networks for Risk Analysis of Industrial Operations,"The era of big data has begun and an enormous amount of real-time data is used for the risk analysis of various industrial applications. However, a technical challenge exists in gathering real-time big data in a complex indoor industrial environment. Indoor wireless sensor networks (WSNs) technology can overcome this limitation by collecting the big data generated from source nodes and transmitting them to the data center in real time. In this study, typical residence, office, and manufacturing environments were chosen. The signal transmission characteristics of an indoor WSN were obtained by analyzing the test data. According to these characteristics, a real-time big data gathering (RTBDG) algorithm based on an indoor WSN is proposed for the risk analysis of industrial operations. In this algorithm, sensor nodes can screen the data collected from the environment and equipment according to the requirements of risk analysis. Clustering data transmission structure is then established on the basis of the received signal strength indicator (RSSI) and residual energy information. Experimental results show that RTBDG not only uses the limited energy of network nodes efficiently, but also balances the energy consumption of all nodes. In the near future, the algorithm will be widely applied to risk analysis in different industrial operations.","Floors,
Wireless sensor networks,
Clustering algorithms,
Routing,
Real-time systems,
Algorithm design and analysis,
Testing"
A Dynamic Charging System With Reduced Output Power Pulsation for Electric Vehicles,"This paper proposes a continuous dynamic wireless power transfer system for electric vehicles that reduces power pulsations during the charging process. Multiple rectangular unipolar coils are used at the primary side as the transmitters, and another unipolar coil works as a receiver at the secondary side. The transmitters are placed closely together to reduce the variation of magnetic fields along the moving track of the receiver. This structure induces self-coupling between the adjacent transmitters. An LCC-compensated circuit topology is utilized, and a compensation parameter design is provided which considers self-coupling between the primary coils. Finite-element analysis of the dynamic charging system is performed using Maxwell. The receiver size is optimized to reduce the variation of the coupling coefficient. A 1.4-kW dynamic charging prototype is constructed according to the designed coil structure and circuit parameters. There are six transmitters, each with dimensions 388 mm×400 mm, and one receiver with dimensions 485 mm×400 mm. Experimental results show that the output power pulsation is within ±7.5% in the dynamic charging process, and the maximum efficiency is 89.78%. If the edge effects of the transmitters are neglected, then the power pulsation is within ±2.9%.","Transmitters,
Coils,
Receivers,
Couplings,
Vehicle dynamics,
Vehicles,
Power generation"
Coupon-Based Demand Response Considering Wind Power Uncertainty: A Strategic Bidding Model for Load Serving Entities,"With the growing development in demand response, load serving entities (LSEs) may participate in electricity market as strategic bidders by offering coupon-based demand response (C-DR) programs to customers. However, due to customers' versatile electricity consumption patterns under C-DR programs as well as the increasing penetration of wind power generation, obtaining the deterministic bidding decision becomes unprecedented complex for LSEs. To address this challenge, a new strategic bidding model for an LSE is proposed in which the primary objective is to maximize the LSE's profit by providing optimal C-DR considering high wind power penetration. The proposed strategic bidding is a bi-level optimization problem with the LSE's net revenue maximization as the upper level problem and the ISO's economic dispatch (ED) for generation cost minimization as the lower level problem. This bi-level model is converted to a stochastic mathematic program with equilibrium constraints (MPEC) by recasting the lower level problem as its Karush-Kuhn-Tucher (KKT) optimality conditions. Then, the stochastic MPEC is transformed to a mixed-integer linear programming (MILP) problem, which is solvable using available optimization software, based on strong duality theory. In addition, the effectiveness of the proposed method has been verified with simulation studies of two sample systems.","Wind power generation,
Uncertainty,
Probability distribution,
Load management,
Load modeling,
Probabilistic logic,
Electricity supply industry"
Recent Developments and Design Challenges of High-Performance Ring Oscillator CMOS Time-to-Digital Converters,"Time-to-digital converters (TDCs) are increasingly used as building blocks in biomedical imaging, digital communication, and measurement instrumentation systems. When fabricated in deep-submicrometer (DSM) CMOS technology, TDCs have outstanding time stamping capability on the order of picoseconds. Typically, the timing resolution of a TDC directly determines the minimum resolvable spatial resolution in time-of-flight (ToF) measurements. It also limits the signal-to-noise ratio in ToF positron emission tomography and the in-band noise in an all-digital phase-locked-loop. In TDCs, good linearity and precision result in high measurement accuracy, while the detectable range is limited by its dynamic range. In addition, size and power consumption are of significant importance in large-scale array implementations such as image sensors. Here, we discuss the most recent developments in CMOS TDCs, with an emphasis on ring-oscillator-based TDC and its variants, due to their suitability for array designs with less area overhead. In addition, key performance metrics, and accurate cost-effective characterization methods will be discussed. Finally, future perspectives of CMOS TDCs will be highlighted.","Positron emission tomography,
CMOS integrated circuits,
CMOS technology,
Image resolution,
Phase locked loops,
Biomedical imaging"
A Multiscale Pyramid Transform for Graph Signals,"Multiscale transforms designed to process analog and discrete-time signals and images cannot be directly applied to analyze high-dimensional data residing on the vertices of a weighted graph, as they do not capture the intrinsic topology of the graph data domain. In this paper, we adapt the Laplacian pyramid transform for signals on Euclidean domains so that it can be used to analyze high-dimensional data residing on the vertices of a weighted graph. Our approach is to study existing methods and develop new methods for the four fundamental operations of graph downsampling, graph reduction, and filtering and interpolation of signals on graphs. Equipped with appropriate notions of these operations, we leverage the basic multiscale constructs and intuitions from classical signal processing to generate a transform that yields both a multiresolution of graphs and an associated multiresolution of a graph signal on the underlying sequence of graphs.","Laplace equations,
Transforms,
Eigenvalues and eigenfunctions,
Signal resolution,
Image resolution,
Bipartite graph"
A Privacy-Preserving Scheme for Incentive-Based Demand Response in the Smart Grid,"The advanced metering infrastructure (AMI) in the smart grid provides real-time information to both grid operators and customers, exploiting the full potential of demand response (DR). However, it introduces new privacy threats to customers. Prior works have proposed privacy-preserving methods in the AMI, such as temporal or spatial aggregation. A main assumption in these works is that fine-grained data do not need to be attributable to individuals. However, this assumption does not hold in incentive-based demand response (IDR) programs where fine-grained metering data are required to analyze individual demand curtailments, and hence, need to be attributable. In this paper, we propose a privacy-preserving scheme for IDR programs in the smart grid, which enables the DR provider to compute individual demand curtailments and DR rewards while preserving customer privacy. Moreover, a customer can reveal his/her identity and prove ownership of his/her power usage profile in certain situations, such as legal disputes. We achieve both privacy and efficiency in our scheme through a combination of several cryptographic primitives, such as identity-committable signatures and partially blind signatures. As far as we know, we are the first to identify and address privacy issues for IDR programs in the smart grid.",
Delay-Optimal Virtualized Radio Resource Scheduling in Software-Defined Vehicular Networks via Stochastic Learning,"Due to the high density of vehicles and various types of vehicular services, it is challenging to guarantee the quality of vehicular services in current Long-Term Evolution (LTE) networks in a cost-efficient manner. Fortunately, with the development of fifth-generation (5G) technology, the installation of a large number of small cells is foreseen as one of the practical ways to achieve the low-delay requirement in vehicular environments. However, it may cause a huge operating expense and capital expenditure to mobile network operators due to the limited backhaul capacity and the explosion of signaling. In this paper, we integrate software-defined networking and radio resource virtualization into an LTE system for vehicular networks, i.e., software-defined heterogeneous vehicular network (SERVICE) . Based on this proposed system framework, a delay-optimal virtualized radio resource scheduling scheme is proposed via stochastic learning. The delay optimal problem is formulated as an infinite-horizon average-cost partially observed Markov decision process (POMDP). Then, an equivalent Bellman equation is derived to solve it. The proposed scheme can be divided into two stages, i.e., macro virtualization resource allocation (MaVRA) and micro virtualization resource allocation (MiVRA). The former is executed based on large timescale variables (traffic density), whereas the latter is operated according to short timescale variables (channel state and queue state). Simulation results show that the proposed scheme outperforms traditional schemes.","Resource management,
Virtualization,
Computer architecture,
Wireless communication,
Mobile communication,
Delays,
Safety"
Event-Triggered Distributed Average Consensus Over Directed Digital Networks With Limited Communication Bandwidth,"In this paper, we consider the event-triggered distributed average-consensus of discrete-time first-order multiagent systems with limited communication data rate and general directed network topology. In the framework of digital communication network, each agent has a real-valued state but can only exchange finite-bit binary symbolic data sequence with its neighborhood agents at each time step due to the digital communication channels with energy constraints. Novel event-triggered dynamic encoder and decoder for each agent are designed, based on which a distributed control algorithm is proposed. A scheme that selects the number of channel quantization level (number of bits) at each time step is developed, under which all the quantizers in the network are never saturated. The convergence rate of consensus is explicitly characterized, which is related to the scale of network, the maximum degree of nodes, the network structure, the scaling function, the quantization interval, the initial states of agents, the control gain and the event gain. It is also found that under the designed event-triggered protocol, by selecting suitable parameters, for any directed digital network containing a spanning tree, the distributed average consensus can be always achieved with an exponential convergence rate based on merely one bit information exchange between each pair of adjacent agents at each time step. Two simulation examples are provided to illustrate the feasibility of presented protocol and the correctness of the theoretical results.",
Joint Resource Optimization for Multicell Networks With Wireless Energy Harvesting Relays,"This paper first considers a multicell network deployment where the base station (BS) of each cell communicates with its cell-edge user with the assistance of an amplify-and-forward (AF) relay node. Equipped with a power splitter and a wireless energy harvester, the self-sustaining relay scavenges radio-frequency (RF) energy from the received signals to process and forward information. Our aim is to develop a resource allocation scheme that jointly optimizes 1) BS transmit power, 2) received power-splitting factors for energy harvesting and information processing at the relays, and 3) relay transmit power. In the face of strong intercell interference and limited radio resources, we formulate three highly nonconvex problems with the objectives of sum-rate maximization, max-min throughput fairness, and sum-power minimization. To solve such challenging problems, we propose applying the successive convex approximation approach and devising iterative algorithms based on geometric programming and difference-of-convex-function programming. The proposed algorithms transform the nonconvex problems into a sequence of convex problems, each of which is solved very efficiently by the interior-point method. We prove that our algorithms converge to the locally optimal solutions that satisfy the Karush-Kuhn-Tucker (KKT) conditions of the original nonconvex problems. We then extend our results to the case of decode-and-forward (DF) relaying with variable timeslot durations. We show that our resource allocation solutions in this case offer better throughput than that of the AF counterpart with equal timeslot durations, albeit at higher computational complexity. Numerical results confirm that the proposed joint optimization solutions substantially improve network performance, compared with cases where the radio resource parameters are individually optimized.",
Estimating CT Image From MRI Data Using Structured Random Forest and Auto-Context Model,"Computed tomography (CT) imaging is an essential tool in various clinical diagnoses and radiotherapy treatment planning. Since CT image intensities are directly related to positron emission tomography (PET) attenuation coefficients, they are indispensable for attenuation correction (AC) of the PET images. However, due to the relatively high dose of radiation exposure in CT scan, it is advised to limit the acquisition of CT images. In addition, in the new PET and magnetic resonance (MR) imaging scanner, only MR images are available, which are unfortunately not directly applicable to AC. These issues greatly motivate the development of methods for reliable estimate of CT image from its corresponding MR image of the same subject. In this paper, we propose a learning-based method to tackle this challenging problem. Specifically, we first partition a given MR image into a set of patches. Then, for each patch, we use the structured random forest to directly predict a CT patch as a structured output, where a new ensemble model is also used to ensure the robust prediction. Image features are innovatively crafted to achieve multi-level sensitivity, with spatial information integrated through only rigid-body alignment to help avoiding the error-prone inter-subject deformable registration. Moreover, we use an auto-context model to iteratively refine the prediction. Finally, we combine all of the predicted CT patches to obtain the final prediction for the given MR image. We demonstrate the efficacy of our method on two datasets: human brain and prostate images. Experimental results show that our method can accurately predict CT images in various scenarios, even for the images undergoing large shape variation, and also outperforms two state-of-the-art methods.",
Weakly Supervised Learning Based on Coupled Convolutional Neural Networks for Aircraft Detection,"Aircraft detection from very high resolution (VHR) remote sensing images has been drawing increasing interest in recent years due to the successful civil and military applications. However, several challenges still exist: 1) extracting the high-level features and the hierarchical feature representations of the objects is difficult; 2) manual annotation of the objects in large image sets is generally expensive and sometimes unreliable; and 3) locating objects within such a large image is difficult and time consuming. In this paper, we propose a weakly supervised learning framework based on coupled convolutional neural networks (CNNs) for aircraft detection, which can simultaneously solve these problems. We first develop a CNN-based method to extract the high-level features and the hierarchical feature representations of the objects. We then employ an iterative weakly supervised learning framework to automatically mine and augment the training data set from the original image. We propose a coupled CNN method, which combines a candidate region proposal network and a localization network to extract the proposals and simultaneously locate the aircraft, which is more efficient and accurate, even in large-scale VHR images. In the experiments, the proposed method was applied to three challenging high-resolution data sets: the Sydney International Airport data set, the Tokyo Haneda Airport data set, and the Berlin Tegel Airport data set. The extensive experimental results confirm that the proposed method can achieve a higher detection accuracy than the other methods.","Feature extraction,
Aircraft,
Supervised learning,
Remote sensing,
Training data,
Military aircraft,
Proposals"
egoSlider: Visual Analysis of Egocentric Network Evolution,"Ego-network, which represents relationships between a specific individual, i.e., the ego, and people connected to it, i.e., alters, is a critical target to study in social network analysis. Evolutionary patterns of ego-networks along time provide huge insights to many domains such as sociology, anthropology, and psychology. However, the analysis of dynamic ego-networks remains challenging due to its complicated time-varying graph structures, for example: alters come and leave, ties grow stronger and fade away, and alter communities merge and split. Most of the existing dynamic graph visualization techniques mainly focus on topological changes of the entire network, which is not adequate for egocentric analytical tasks. In this paper, we present egoSlider, a visual analysis system for exploring and comparing dynamic ego-networks. egoSlider provides a holistic picture of the data through multiple interactively coordinated views, revealing ego-network evolutionary patterns at three different layers: a macroscopic level for summarizing the entire ego-network data, a mesoscopic level for overviewing specific individuals' ego-network evolutions, and a microscopic level for displaying detailed temporal information of egos and their alters. We demonstrate the effectiveness of egoSlider with a usage scenario with the DBLP publication records. Also, a controlled user study indicates that in general egoSlider outperforms a baseline visualization of dynamic networks for completing egocentric analytical tasks.","Visualization,
Data visualization,
Microscopy,
Feature extraction,
Measurement,
Social network services,
Data analysis"
Learning Robust and Discriminative Subspace With Low-Rank Constraints,"In this paper, we aim at learning robust and discriminative subspaces from noisy data. Subspace learning is widely used in extracting discriminative features for classification. However, when data are contaminated with severe noise, the performance of most existing subspace learning methods would be limited. Recent advances in low-rank modeling provide effective solutions for removing noise or outliers contained in sample sets, which motivates us to take advantage of low-rank constraints in order to exploit robust and discriminative subspace for classification. In particular, we present a discriminative subspace learning method called the supervised regularization-based robust subspace (SRRS) approach, by incorporating the low-rank constraint. SRRS seeks low-rank representations from the noisy data, and learns a discriminative subspace from the recovered clean data jointly. A supervised regularization function is designed to make use of the class label information, and therefore to enhance the discriminability of subspace. Our approach is formulated as a constrained rank-minimization problem. We design an inexact augmented Lagrange multiplier optimization algorithm to solve it. Unlike the existing sparse representation and low-rank learning methods, our approach learns a low-dimensional subspace from recovered data, and explicitly incorporates the supervised information. Our approach and some baselines are evaluated on the COIL-100, ALOI, Extended YaleB, FERET, AR, and KinFace databases. The experimental results demonstrate the effectiveness of our approach, especially when the data contain considerable noise or variations.","Learning systems,
Robustness,
Noise,
Noise measurement,
Feature extraction,
Data models,
Optimization"
Overview of the MPEG-CDVS Standard,"Compact descriptors for visual search (CDVS) is a recently completed standard from the ISO/IEC moving pictures experts group (MPEG). The primary goal of this standard is to provide a standardized bitstream syntax to enable interoperability in the context of image retrieval applications. Over the course of the standardization process, remarkable improvements were achieved in reducing the size of image feature data and in reducing the computation and memory footprint in the feature extraction process. This paper provides an overview of the technical features of the MPEG-CDVS standard and summarizes its evolution.","Feature extraction,
Standards,
Transform coding,
Visualization,
Image coding,
Mobile handsets,
Servers"
Local Feature Discriminant Projection,"In this paper, we propose a novel subspace learning algorithm called Local Feature Discriminant Projection (LFDP) for supervised dimensionality reduction of local features. LFDP is able to efficiently seek a subspace to improve the discriminability of local features for classification. We make three novel contributions. First, the proposed LFDP is a general supervised subspace learning algorithm which provides an efficient way for dimensionality reduction of large-scale local feature descriptors. Second, we introduce the Differential Scatter Discriminant Criterion (DSDC) to the subspace learning of local feature descriptors which avoids the matrix singularity problem. Third, we propose a generalized orthogonalization method to impose on projections, leading to a more compact and less redundant subspace. Extensive experimental validation on three benchmark datasets including UIUC-Sports, Scene-15 and MIT Indoor demonstrates that the proposed LFDP outperforms other dimensionality reduction methods and achieves state-of-the-art performance for image classification.","Integrated circuits,
Algorithm design and analysis,
Optimization,
Feature extraction,
Covariance matrices,
Principal component analysis,
Kernel"
Cloud Performance Modeling with Benchmark Evaluation of Elastic Scaling Strategies,"In this paper, we present generic cloud performance models for evaluating Iaas, PaaS, SaaS, and mashup or hybrid clouds. We test clouds with real-life benchmark programs and propose some new performance metrics. Our benchmark experiments are conducted mainly on IaaS cloud platforms over scale-out and scale-up workloads. Cloud benchmarking results are analyzed with the efficiency, elasticity, QoS, productivity, and scalability of cloud performance. Five cloud benchmarks were tested on Amazon IaaS EC2 cloud: namely YCSB, CloudSuite, HiBench, BenchClouds, and TPC-W. To satisfy production services, the choice of scale-up or scale-out solutions should be made primarily by the workload patterns and resources utilization rates required. Scaling-out machine instances have much lower overhead than those experienced in scale-up experiments. However, scaling up is found more cost-effective in sustaining heavier workload. The cloud productivity is greatly attributed to system elasticity, efficiency, QoS and scalability. We find that auto-scaling is easy to implement but tends to over provision the resources. Lower resource utilization rate may result from auto-scaling, compared with using scale-out or scale-up strategies. We also demonstrate that the proposed cloud performance models are applicable to evaluate PaaS, SaaS and hybrid clouds as well.","Productivity,
Benchmark testing,
Measurement,
Quality of service,
Scalability,
Computational modeling,
Availability"
"Smoothed L_p
-Minimization for Green Cloud-RAN With User Admission Control","The cloud radio access network (Cloud-RAN) has recently been proposed as one of the cost-effective and energy-efficient techniques for 5G wireless networks. By moving the signal processing functionality to a single baseband unit (BBU) pool, centralized signal processing and resource allocation are enabled in cloud-RAN, thereby providing the promise of improving the energy efficiency via effective network adaptation and interference management. In this paper, we propose a holistic sparse optimization framework to design green cloud-RAN by taking into consideration the power consumption of the fronthaul links, multicast services, as well as user admission control. Specifically, we first identify the sparsity structures in the solutions of both the network power minimization and user admission control problems, which call for adaptive remote radio head (RRH) selection and user admission. However, finding the optimal sparsity structures turns out to be NP-hard, with the coupled challenges of the ℓ0-norm-based objective functions and the nonconvex quadratic QoS constraints due to multicast beamforming. In contrast to the previous works on convex but nonsmooth sparsity inducing approaches, e.g., the group sparse beamforming algorithm based on the mixed ℓ1/ℓ2-norm relaxation, we adopt the nonconvex but smoothed ℓp-minimization (0 <; p ≤ 1) approach to promote sparsity in the multicast setting, thereby enabling efficient algorithm design based on the principle of the majorization-minimization (MM) algorithm and the semidefinite relaxation (SDR) technique. In particular, an iterative reweighted-ℓ2 algorithm is developed, which will converge to a Karush-Kuhn-Tucker (KKT) point of the relaxed smoothed ℓp-minimization problem from the SDR technique. We illustrate the effectiveness of the proposed algorithms with extensive simulations for network power minimization and user admission control in multicast cloud-RAN.","Array signal processing,
Optimization,
Minimization,
Admission control,
Algorithm design and analysis,
Cloud computing"
Robust Energy Management of Microgrid With Uncertain Renewable Generation and Load,"A scenario-based robust energy management method accounting for the worst-case amount of renewable generation (RG) and load is developed in this paper. The economic and robust model is formulated to maximize the total exchange cost while getting the minimum social benefits cost at the same time. Uncertainty of RG and load is described as an uncertain set produced by interval prediction. Then, the Taguchi's orthogonal array (OA) testing method is used to provide possible testing scenarios. A simple, but practical, search strategy based on OA is designed for solving the optimization problem. By optimizing the worst-case scenario, the energy management solution of the proposed model is robust against most of the possible realizations of the modeled uncertain set by Monte Carlo verification. Numerical cases on the typical microgrid system show the effectiveness of the model and solution strategy. In addition, the influence of exchange electricity price and other parameters are also discussed in the cases.","Robustness,
Microgrids,
Optimization,
Energy management,
Testing,
Load modeling,
Uncertainty"
An Online Mechanism for Resource Allocation and Pricing in Clouds,"Cloud providers provision their various resources such as CPUs, memory, and storage in the form of virtual machine (VM) instances which are then allocated to the users. The users are charged based on a pay-as-you-go model, and their payments should be determined by considering both their incentives and the incentives of the cloud providers. Auction markets can capture such incentives, where users name their own prices for their requested VMs. We design an auction-based online mechanism for VM provisioning, allocation, and pricing in clouds that considers several types of resources. Our proposed online mechanism makes no assumptions about future demand of VMs, which is the case in real cloud settings. The proposed online mechanism is invoked as soon as a user places a request or some of the allocated resources are released and become available. The mechanism allocates VM instances to selected users for the period they are requested for, and ensures that the users will continue using their VM instances for the entire requested period. In addition, the mechanism determines the payment the users have to pay for using the allocated resources. We prove that the mechanism is incentive-compatible, that is, it gives incentives to the users to reveal their actual requests. We investigate the performance of our proposed mechanism through extensive experiments.","Resource management,
Pricing,
Silicon,
Cost accounting,
Heuristic algorithms,
Dynamic scheduling,
Mechanical factors"
A Dual-Hop Virtual MIMO Architecture Based on Hybrid Differential Spatial Modulation,"In this paper, we propose a novel virtual multi-input-multi-output (VMIMO) architecture to convey information from the source node (SN) to the destination node (DN) via multiple relay nodes (RNs). As it is built on dual-hop networks with differential spatial modulation (DSM), we call it dual-hop hybrid DSM (DH-HDSM). In order to harvest the diversity provided by the SN and reduce the complexity at the RNs, DH-HDSM forms a precoding aided DSM pattern in the first hop and applies incoherent detection in a centralized or distributed manner at the RNs. Based on the decode-and-forward protocol, DSM transmission is carried out in the second hop and achieves high energy efficiency via statistical single RN activation at any time instant. We analyze the performance of DH-HDSM in terms of the average bit error probability and make comparisons with dual-hop hybrid spatial modulation (DH-HSM) and differential VMIMO systems with either a single relay or best relay selection. Theoretical results and Monte Carlo simulations confirm that DH-HDSM outperforms DH-HSM and other differential relay schemes in terms of error performance when the DN is equipped with multiple antennas.","Relays,
Computer architecture,
MIMO,
Modulation,
Antennas,
Precoding,
Complexity theory"
Fingerprint Liveness Detection Using Convolutional Neural Networks,"With the growing use of biometric authentication systems in the recent years, spoof fingerprint detection has become increasingly important. In this paper, we use convolutional neural networks (CNNs) for fingerprint liveness detection. Our system is evaluated on the data sets used in the liveness detection competition of the years 2009, 2011, and 2013, which comprises almost 50 000 real and fake fingerprints images. We compare four different models: two CNNs pretrained on natural images and fine-tuned with the fingerprint images, CNN with random weights, and a classical local binary pattern approach. We show that pretrained CNNs can yield the state-of-the-art results with no need for architecture or hyperparameter selection. Data set augmentation is used to increase the classifiers performance, not only for deep architectures but also for shallow ones. We also report good accuracy on very small training sets (400 samples) using these large pretrained networks. Our best model achieves an overall rate of 97.1% of correctly classified samples-a relative improvement of 16% in test error when compared with the best previously published results. This model won the first prize in the fingerprint liveness detection competition 2015 with an overall accuracy of 95.5%.","Feature extraction,
Support vector machines,
Principal component analysis,
Kernel,
Convolution,
Fingerprint recognition,
Neural networks"
Domain Decomposition Preconditioning for Surface Integral Equations in Solving Challenging Electromagnetic Scattering Problems,"We propose and study a nonoverlapping and nonconforming domain decomposition method for the integral-equation-based solution of large, complex electromagnetic (EM) scattering problems. The continuity of the electric surface current across the boundary between adjacent subdomains is enforced by a skew-symmetric interior penalty formulation. A nonoverlapping additive Schwarz preconditioner is designed and analyzed for the solution of the linear system of equations resulting from Galerkin boundary-element discretization. We show that the preconditioned system exhibits a uniformly confined eigenspectrum with respect to changing problem and discretization parameters. Numerical examples are presented to demonstrate the fast convergence of iterative solvers and the superior accuracy of the solutions obtained by our method. The proposed work can be viewed as an effective preconditioning scheme that reduces the condition number of very large systems of equations in challenging EM scattering problems. The strength and capability of the proposed method will be illustrated by means of several examples of practical interest.","Mathematical model,
Integral equations,
Antennas,
Electromagnetic scattering,
Electric potential,
Solid modeling"
Power-Normalized Cepstral Coefficients (PNCC) for Robust Speech Recognition,"This paper presents a new feature extraction algorithm called power normalized Cepstral coefficients (PNCC) that is motivated by auditory processing. Major new features of PNCC processing include the use of a power-law nonlinearity that replaces the traditional log nonlinearity used in MFCC coefficients, a noise-suppression algorithm based on asymmetric filtering that suppresses background excitation, and a module that accomplishes temporal masking. We also propose the use of medium-time power analysis in which environmental parameters are estimated over a longer duration than is commonly used for speech, as well as frequency smoothing. Experimental results demonstrate that PNCC processing provides substantial improvements in recognition accuracy compared to MFCC and PLP processing for speech in the presence of various types of additive noise and in reverberant environments, with only slightly greater computational cost than conventional MFCC processing, and without degrading the recognition accuracy that is observed while training and testing using clean speech. PNCC processing also provides better recognition accuracy in noisy environments than techniques such as vector Taylor series (VTS) and the ETSI advanced front end (AFE) while requiring much less computation. We describe an implementation of PNCC using “online processing” that does not require future knowledge of the input.","Speech,
Speech recognition,
Mel frequency cepstral coefficient,
Speech processing,
IEEE transactions,
Feature extraction"
Genetic Learning Particle Swarm Optimization,"Social learning in particle swarm optimization (PSO) helps collective efficiency, whereas individual reproduction in genetic algorithm (GA) facilitates global effectiveness. This observation recently leads to hybridizing PSO with GA for performance enhancement. However, existing work uses a mechanistic parallel superposition and research has shown that construction of superior exemplars in PSO is more effective. Hence, this paper first develops a new framework so as to organically hybridize PSO with another optimization technique for “learning.” This leads to a generalized “learning PSO” paradigm, the *L-PSO. The paradigm is composed of two cascading layers, the first for exemplar generation and the second for particle updates as per a normal PSO algorithm. Using genetic evolution to breed promising exemplars for PSO, a specific novel *L-PSO algorithm is proposed in the paper, termed genetic learning PSO (GL-PSO). In particular, genetic operators are used to generate exemplars from which particles learn and, in turn, historical search information of particles provides guidance to the evolution of the exemplars. By performing crossover, mutation, and selection on the historical information of particles, the constructed exemplars are not only well diversified, but also high qualified. Under such guidance, the global search ability and search efficiency of PSO are both enhanced. The proposed GL-PSO is tested on 42 benchmark functions widely adopted in the literature. Experimental results verify the effectiveness, efficiency, robustness, and scalability of the GL-PSO.","Genetic algorithms,
Genetics,
Sociology,
Statistics,
Animals,
Convergence,
Algorithm design and analysis"
Recovery of Sparse Signals via Generalized Orthogonal Matching Pursuit: A New Analysis,"As an extension of orthogonal matching pursuit (OMP) for improving the recovery performance of sparse signals, generalized OMP (gOMP) has recently been studied in the literature. In this paper, we present a new analysis of the gOMP algorithm using the restricted isometry property (RIP). We show that if a measurement matrix Φ ∈ ℜm×n satisfies the RIP with isometry constant δmax{9,S+1}K ≤ 1/8, then gOMP performs stable reconstruction of all K-sparse signals x ∈ ℜn from the noisy measurements y=Φx+v, within max{K,⌊8K/S⌋} iterations, where v is the noise vector and S is the number of indices chosen in each iteration of the gOMP algorithm. For Gaussian random measurements, our result indicates that the number of required measurements is essentially m=O(Klogn/K), which is a significant improvement over the existing result m=O(K2logn/K), especially for large K.","Matching pursuit algorithms,
Signal processing algorithms,
Noise measurement,
Computational complexity,
Algorithm design and analysis,
Indexes,
Electronic mail"
Statistical Learning Theory and ELM for Big Social Data Analysis,"The science of opinion analysis based on data from social networks and other forms of mass media has garnered the interest of the scientific community and the business world. Dealing with the increasing amount of information present on the Web is a critical task and requires efficient models developed by the emerging field of sentiment analysis. To this end, current research proposes an efficient approach to support emotion recognition and polarity detection in natural language text. In this paper, we show how to exploit the most recent technological tools and advances in Statistical Learning Theory (SLT) in order to efficiently build an Extreme Learning Machine (ELM) and assess the resultant model's performance when applied to big social data analysis. ELM represents a powerful learning tool, developed to overcome some issues in back-propagation networks. The main problem with ELM is in training them to work in the event of a large number of available samples, where the generalization performance has to be carefully assessed. For this reason, we propose an ELM implementation that exploits the Spark distributed in memory technology and show how to take advantage of the most recent advances in SLT in order to address the issue of selecting ELM hyperparameters that give the best generalization performance.","Social network services,
Analytical models,
Big data,
Data models,
Predictive models,
Data analysis,
Sentiment analysis,
Emotion recognition"
Bitcoin and Beyond: A Technical Survey on Decentralized Digital Currencies,"Besides attracting a billion dollar economy, Bitcoin revolutionized the field of digital currencies and influenced many adjacent areas. This also induced significant scientific interest. In this survey, we unroll and structure the manyfold results and research directions. We start by introducing the Bitcoin protocol and its building blocks. From there we continue to explore the design space by discussing existing contributions and results. In the process, we deduce the fundamental structures and insights at the core of the Bitcoin protocol and its applications. As we show and discuss, many key ideas are likewise applicable in various other fields, so that their impact reaches far beyond Bitcoin itself.","Online banking,
Tutorials,
Protocols,
Space exploration,
Contracts,
Internet,
Cryptography"
Mixed-ADC Massive MIMO Detectors: Performance Analysis and Design Optimization,"The hardware cost and power consumption of a massive multiple-input multiple-output (MIMO) system can be remarkably reduced by using a very low-resolution analog-to-digital converter (ADC) unit in each antenna. However, such a pure low-resolution ADC architecture complicates parameter estimation problems. These issues can be resolved and the potential of a pure low-resolution ADC architecture can be achieved by applying a mixed ADC architecture, whose antennas are equipped with low-precision ADCs, while few antennas are composed of high-precision ADCs. In this paper, a unified framework is presented to develop a family of detectors on a massive MIMO uplink system through probabilistic Bayesian inference. Our basic setup comprises an optimal detector, which is developed to provide a minimum mean-squared-error estimate on data symbols. Considering that highly nonlinear steps are involved in quantization, we also investigate the potential for complexity reduction on an optimal detector by postulating a common pseudo-quantization noise model. We provide asymptotic performance expressions, including mean squared error and bit error rate for optimal and suboptimal MIMO detectors. These expressions can be evaluated rapidly and efficiently. Thus, they can be used for system design optimization.","MIMO,
Detectors,
Antennas,
Computer architecture,
Quantization (signal),
Receivers,
Signal to noise ratio"
High-Performance Solar MPPT Using Switching Ripple Identification Based on a Lock-In Amplifier,"Photovoltaic (PV) power converters and maximum power point tracking (MPPT) algorithms are required to ensure maximum energy transfer between the PV panel and the load. The requirements for the MPPT algorithms have increased over the years-the algorithms are required to be increasingly accurate, fast, and versatile, while reducing the intrusiveness on the overall performance of the PV panel and converter. The family of hill-climbing algorithms such as incremental conductance (InCond) and perturb and observe (P&O) has gained popularity given their simplicity and accuracy, but it requires the injection of a perturbation that changes the operating point even in steady state and are prone to errors during changing environmental conditions. In recent literature, the use of the switching ripple has been proposed to replace the perturbation in the hill-climbing algorithms given its inherent presence in the system and speed. The constant work toward smaller and faster ripples presents challenges to the signal detection involved in this kind of algorithm. This paper develops and implements a new InCond MPPT technique based on switching ripple detection using a digital lock-in amplifier (LIA) to extract the amplitude of the oscillation ripple even in the presence of noise. The use of this advanced technique allows to push forward the reduction of the ripple in order to virtually eliminate the oscillation in steady state maximizing the efficiency. The accurate detection allows for adaptive-step features for fast tracking of changing environmental conditions while keeping the efficiency at maximum during the steady state. Detailed mathematical analysis of the proposed technique is provided. Overall, the use of the proposed LIA allows to push the reduction of the ripple even more while keeping accuracy and delivering superior performance. Simulations and experimental results are provided for the proposed technique and the InCond technique in order to validate the proposed approach.","Maximum power point trackers,
Switches,
Steady-state,
Oscillators,
Standards,
Heuristic algorithms,
Voltage measurement"
BGM-BLA: A New Algorithm for Dynamic Migration of Virtual Machines in Cloud Computing,"Cloud computing is getting more prevalent and finding a way to reduce the cost of cloud computing platform through the migration of virtual machines (VM) is a concerned issue. In this paper, the problem of dynamic migration of VMs (DM-VM) in the cloud computing platform (or simply the cloud) is investigated. A triple-objective optimization model for DM-VM is established, which takes energy consumption, communication between VMs, and migration cost into account under the situation that the platform works normally. The DM-VM problem is divided into two parts: (i) forming VMs into groups, and (ii) determining the best way to place the groups into certain physical nodes. A binary graph matching-based bucket-code learning algorithm (BGM-BLA) is designed for solving the DM-VM problem. In BGM-BLA, bucket-coding and learning is employed for finding the optimal solutions, and binary graph matching is used for evaluating the candidate solutions. The computational results demonstrate that the proposed BGM-BLA algorithm performs relatively well in terms of the Pareto sets obtained and computational time in comparison with two optimization algorithms, i.e., Non-dominated Sorting Genetic Algorithm (NSGA-II) and binary graph matching-based common-coding algorithm.",
Compact Dual-Polarized UWB Quasi-Self-Complementary MIMO/Diversity Antenna With Band-Rejection Capability,"A novel compact ultrawideband (UWB) multiple-input-multiple-output (MIMO) antenna system with dual polarization and band-rejection capabilities is proposed. The proposed MIMO antenna system consists of two quasi-self-complementary (QSC) antenna elements. The elements are arranged orthogonally and fed perpendicularly to obtain polarization diversity. High isolation can be achieved without additional decoupling structure owing to the inherent advantage of the self-complementary structure. Notched band at WLAN system can be realized by etching a bent slit in each of the radiating elements. Moreover, a four-element MIMO system is also proposed and investigated to fully reveal its potential use. Diversity performance in terms of envelope correlation coefficient (ECC) and the mean effective gain (MEG) ratio are studied. Measured results show that the proposed antenna has a wide bandwidth ranging from 3 to 12 GHz with band rejection at WLAN system and high port isolation (S12 ≤ -20 dB at most of the band), which demonstrate the proposed MIMO/diversity antenna system can be a good candidate for UWB applications.",
Multi-Modal Event Topic Model for Social Event Analysis,"With the massive growth of social events in Internet , it has become more and more difficult to exactly find and organize the interesting events from massive social media data, which is useful to browse, search, and monitor social events by users or governments . To deal with this problem, we propose a novel multi-modal social event tracking and evolution framework to not only effectively capture multi-modal topics of social events, but also obtain the evolutionary trends of social events and generate effective event summary details over time. To achieve this goal, we propose a novel multi-modal event topic model (mmETM), which can effectively model social media documents, including long text with related images, and learn the correlations between textual and visual modalities to separate the visual-representative topics and non-visual-representative topics. To apply the mmETM model to social event tracking, we adopt an incremental learning strategy denoted as incremental mmETM, which can obtain informative textual and visual topics of social events over time to help understand these events and their evolutionary trends. To evaluate the effectiveness of our proposed algorithm, we collect a real-world dataset to conduct various experiments. Both qualitative and quantitative evaluations demonstrate that the proposed mmETM algorithm performs favorably against several state-of-the-art methods.","Media,
Visualization,
Hidden Markov models,
Google,
Market research,
Multimedia communication,
Streaming media"
Balancing Power Demand Through EV Mobility in Vehicle-to-Grid Mobile Energy Networks,"Vehicle-to-grid (V2G) technology enables bidirectional energy flow between electric vehicles (EVs) and power grid, which provides flexible demand response management (DRM) for the reliability of smart grid. EV mobility is a unique and inherent feature of the V2G system. However, the inter-relationship between EV mobility and DRM is not obvious. In this paper, we focus on the exploration of EV mobility to impact DRM in V2G systems in smart grid. We first present a dynamic complex network model of V2G mobile energy networks, considering the fact that EVs travel across multiple districts, and hence EVs can be acting as energy transporters among different districts. We formulate the districts' DRM dynamics, which is coupled with each other through EV fleets. In addition, a complex network synchronization method is proposed to analyze the dynamic behavior in V2G mobile energy networks. Numerical results show that EVs mobility of symmetrical EV fleet is able to achieve synchronous stability of network and balance the power demand among different districts. This observation is also validated by simulation with real world data.",
Overview: Collective Control of Multiagent Systems,"Collective control of a multiagent system is concerned with designing strategies for a group of autonomous agents operating in a networked environment. The aim is to achieve a global control objective through distributed sensing, communication, computing, and control. It has attracted many researchers from a wide range of disciplines, including the literature of automatic control. This paper aims to give a general framework that is able to accommodate many of these outcomes. Within this framework, the development on this topic is systematically reviewed and the representative outcomes can be sorted out from four aspects: 1) agent dynamics; 2) network topologies; 3) feedback and communication mechanisms; and 4) collective behaviors. Thus, the state-of-the-art approach and technology is described. Moreover, within this framework, further interesting and promising directions on this research topic are envisioned.","Network topology,
Topology,
Synchronization,
Multi-agent systems,
Robustness,
Switches"
Fountain-Coding Aided Strategy for Secure Cooperative Transmission in Industrial Wireless Sensor Networks,"Cooperative relaying communications is an efficient paradigm for end-to-end data delivery in industrial wireless sensor networks. However, due to the broadcast nature of radio propagation, it is challenging to guarantee the secrecy of cooperative transmissions under eavesdropping attacks. To deal with this issue, a fountain-coding aided relaying scheme is proposed in this paper, for which all the source packets are first encoded with fountain codes (FCs) and then transmitted over the channels. Based on the basic characteristic of FC transmissions, a sufficient number of coded packets have to be successfully received to recover the original data. Therefore, transmission secrecy is guaranteed if the legitimate receiver can accumulate the required number of FC packets before the eavesdropper does. To satisfy this condition, a cooperative jamming method is utilized to worsen the received signal quality at the eavesdropper. By applying the constellation rotation approach, the information-bearing signal and the jamming signal are designed carefully to reduce the negative effect of the jamming procedure on the legitimate receiver. To evaluate how the scheme behaves in wireless fading channels, the authors propose a novel performance metric, i.e., the quality-of-service violating probability (QVP), and derive its closed-form expression. Compared to the commonly used metrics in physical-layer security such as secrecy outage probability, QVP can give a more comprehensive performance evaluation for the system, including the delay, the reliability, and the security level as well. Finally, the theoretical analysis is validated by simulation results.","Protocols,
Jamming,
Security,
Relays,
Wireless sensor networks,
Reliability,
Informatics"
High-Efficiency DAB Converter Using Switching Sequences and Burst Mode,"Dual active bridge converters enable bidirectional power flow in buck and boost operating modes. This paper presents an advanced switching sequence and burst-mode strategy to balance conduction, switching, and magnetic losses under light, medium, and heavy loading conditions, leading to improved operating efficiency. The implementation of the switching sequence employs the natural state-plane trajectories of the converter and contributes to higher efficiency and the ability to perform burst mode. The proposed switching sequences improve the overall efficiency of the converter by enabling soft switching and adjusting the frequency to match the minimum RMS transformer current in the full operating range. Furthermore, it incorporates a fully controlled burst-mode switching sequence for light loading conditions to further extend the efficiency gains. As a result, maximum efficiency is obtained by taking advantage of all the possible switching structures of the converter. The analysis provides insight into the natural trajectories of the converter, which produce soft-switching transitions and enable the converter structures to achieve the target operating point directly. Simulation and experimental results are presented to validate the benefits of the switching sequence and illustrate the burst-mode operation.","Switches,
Trajectory,
Switching frequency,
Bridge circuits,
Loading,
Modulation,
Soft switching"
On the Age of Information in Status Update Systems With Packet Management,"We consider a communication system in which status updates arrive at a source node, and should be transmitted through a network to the intended destination node. The status updates are samples of a random process under observation, transmitted as packets, which also contain the time stamp to identify when the sample was generated. The age of the information available to the destination node is the time elapsed, since the last received update was generated. In this paper, we model the source-destination link using the queuing theory, and we assume that the time it takes to successfully transmit a packet to the destination is an exponentially distributed service time. We analyze the age of information in the case that the source node has the capability to manage the arriving samples, possibly discarding packets in order to avoid wasting network resources with the transmission of stale information. In addition to characterizing the average age, we propose a new metric, called peak age, which provides information about the maximum value of the age, achieved immediately before receiving an update.",
Accelerated PSO Swarm Search Feature Selection for Data Stream Mining Big Data,"Big Data though it is a hype up-springing many technical challenges that confront both academic research communities and commercial IT deployment, the root sources of Big Data are founded on data streams and the curse of dimensionality. It is generally known that data which are sourced from data streams accumulate continuously making traditional batch-based model induction algorithms infeasible for real-time data mining. Feature selection has been popularly used to lighten the processing load in inducing a data mining model. However, when it comes to mining over high dimensional data the search space from which an optimal feature subset is derived grows exponentially in size, leading to an intractable demand in computation. In order to tackle this problem which is mainly based on the high-dimensionality and streaming format of data feeds in Big Data, a novel lightweight feature selection is proposed. The feature selection is designed particularly for mining streaming data on the fly, by using accelerated particle swarm optimization (APSO) type of swarm search that achieves enhanced analytical accuracy within reasonable processing time. In this paper, a collection of Big Data with exceptionally large degree of dimensionality are put under test of our new feature selection algorithm for performance evaluation.",
Design and Evaluation of the Optimal Cache Allocation for Content-Centric Networking,"Content-centric networking (CCN) is a promising framework to rebuild the Internet's forwarding substrate around the concept of content. CCN advocates ubiquitous in-network caching to enhance content delivery, and thus each router has storage space to cache frequently requested content. In this work, we focus on the cache allocation problem, namely, how to distribute the cache capacity across routers under a constrained total storage budget for the network. We first formulate this problem as a content placement problem and obtain the optimal solution by a two-step method. We then propose a suboptimal heuristic method based on node centrality, which is more practical in dynamic networks with frequent content publishing. We investigate through simulations the factors that affect the optimal cache allocation, and perhaps more importantly we use a real-life Internet topology and video access logs from a large scale Internet video provider to evaluate the performance of various cache allocation methods. We observe that network topology and content popularity are two important factors that affect where exactly should cache capacity be placed. Further, the heuristic method comes with only a very limited performance penalty compared to the optimal allocation. Finally, using our findings, we provide recommendations for network operators on the best deployment of CCN caches capacity over routers.","Resource management,
Servers,
Topology,
Network topology,
Optimization,
Heuristic algorithms,
Complexity theory"
"Facial Emotion Recognition Based on Biorthogonal Wavelet Entropy, Fuzzy Support Vector Machine, and Stratified Cross Validation","Emotion recognition represents the position and motion of facial muscles. It contributes significantly in many fields. Current approaches have not obtained good results. This paper aimed to propose a new emotion recognition system based on facial expression images. We enrolled 20 subjects and let each subject pose seven different emotions: happy, sadness, surprise, anger, disgust, fear, and neutral. Afterward, we employed biorthogonal wavelet entropy to extract multiscale features, and used fuzzy multiclass support vector machine to be the classifier. The stratified cross validation was employed as a strict validation model. The statistical analysis showed our method achieved an overall accuracy of 96.77±0.10%. Besides, our method is superior to three state-of-the-art methods. In all, this proposed method is efficient.","Support vector machines,
Wavelet transforms,
Entropy,
Feature extraction,
Face recognition,
Low-pass filters,
Fuzzy logic,
Emotion recognition"
Ambipolar Black Phosphorus MOSFETs With Record n-Channel Transconductance,"Ambipolar black phosphorus MOSFETs with record n-channel extrinsic transconductance are reported. The devices consist of multilayer black phosphorus aligned to a local back-gate electrode with 10-nm-thick HfO2 gate dielectric. Before passivation, devices with 0.3-μm gate length behaved as p-MOSFETs with peak extrinsic transconductance, gm, of 282 μS/μm at VDS = -2 V. After passivation, the same devices displayed the ambipolar behavior, and when tested as n-MOSFETs, had peak gm = 66 μS/μm at VDS = +2 V, and similar devices on the same wafer had gm as high as 80 μS/μm. These results are an important step toward the realization of high-performance black phosphorus complementary logic circuits.","Logic gates,
MOSFET circuits,
MOSFET,
Passivation,
Phosphorus,
Transconductance,
Dielectrics"
Surveillance Video Synopsis via Scaling Down Objects,"Video synopsis is an effective technique to provide a compact representation of the original video by removing spatiotemporal redundancies and by preserving the essential activities. Most current approaches for video synopsis will cause collisions among objects, especially when the video is condensed much. In this paper, we present an approach for video synopsis to reduce the collisions. Our approach first shifts active objects along the time axis to compact the original video. Then, the sizes of the objects are reduced when collisions occur. Meanwhile, the geometric centroids of the objects will be kept unchanged to preserve the location information. Our contributions are threefold. First, an approach is proposed to decrease collisions in the synopsis video through reducing the sizes of the objects. Second, an optimization framework is developed to indicate the optimal time position and the appropriate reduction coefficient for each object. Finally, some metrics are proposed, and several experiments are carried out to evaluate the proposed approach. The experiments have demonstrated that the synopsis video produced by our approach has much fewer collisions while the compression ratio is high.",
A Highly Accurate Prediction Algorithm for Unknown Web Service QoS Values,"Quality of service (QoS) guarantee is an important component of service recommendation. Generally, some QoS values of a service are unknown to its users who has never invoked it before, and therefore the accurate prediction of unknown QoS values is significant for the successful deployment of web service-based applications. Collaborative filtering is an important method for predicting missing values, and has thus been widely adopted in the prediction of unknown QoS values. However, collaborative filtering originated from the processing of subjective data, such as movie scores. The QoS data of web services are usually objective, meaning that existing collaborative filtering-based approaches are not always applicable for unknown QoS values. Based on real world web service QoS data and a number of experiments, in this paper, we determine some important characteristics of objective QoS datasets that have never been found before. We propose a prediction algorithm to realize these characteristics, allowing the unknown QoS values to be predicted accurately. Experimental results show that the proposed algorithm predicts unknown web service QoS values more accurately than other existing approaches.",
A Real-Time Human Action Recognition System Using Depth and Inertial Sensor Fusion,"This paper presents a human action recognition system that runs in real time and simultaneously uses a depth camera and an inertial sensor based on a previously developed sensor fusion method. Computationally efficient depth image features and inertial signals features are fed into two computationally efficient collaborative representative classifiers. A decision-level fusion is then performed. The developed real-time system is evaluated using a publicly available multimodal human action recognition data set by considering a comprehensive set of human actions. The overall classification rate of the developed real-time system is shown to be >97%, which is at least 9% higher than when each sensing modality is used individually. The results from both offline and real-time experimentations demonstrate the effectiveness of the system and its real-time throughputs.",
Meal Detection in Patients With Type 1 Diabetes: A New Module for the Multivariable Adaptive Artificial Pancreas Control System,A novel meal-detection algorithm is developed based on continuous glucose measurements. Bergman's minimal model is modified and used in an unscented Kalman filter for state estimations. The estimated rate of appearance of glucose is used for meal detection. Data from nine subjects are used to assess the performance of the algorithm. The results indicate that the proposed algorithm works successfully with high accuracy. The average change in glucose levels between the meals and the detection points is 16(±9.42) [mg/dl] for 61 successfully detected meals and snacks. The algorithm is developed as a new module of an integrated multivariable adaptive artificial pancreas control system. Meal detection with the proposed method is used to administer insulin boluses and prevent most of postprandial hyperglycemia without any manual meal announcements. A novel meal bolus calculation method is proposed and tested with the UVA/Padova simulator. The results indicate significant reduction in hyperglycemia.,"Sugar,
Insulin,
Biomedical measurement,
Estimation,
Kalman filters,
Control systems,
Plasmas"
High-Gain Single-Stage Boosting Inverter for Photovoltaic Applications,"This paper introduces a high-gain single-stage boosting inverter (SSBI) for alternative energy generation. As compared to the traditional two-stage approach, the SSBI has a simpler topology and a lower component count. One cycle control was employed to generate ac voltage output. This paper presents theoretical analysis, simulation and experimental results obtained from a 200 W prototype. The experimental results reveal that the proposed SSBI can achieve high dc input voltage boosting, good dc-ac power decoupling, good quality of ac output waveform, and good conversion efficiency.","Capacitors,
Switches,
Topology,
Inductors,
Inverters,
Magnetic separation,
Boosting"
Trust-Based Service Management for Social Internet of Things Systems,"A social internet of things (IoT) system can be viewed as a mix of traditional peer-to-peer networks and social networks, where “things” autonomously establish social relationships according to the owners' social networks, and seek trusted “things” that can provide services needed when they come into contact with each other opportunistically. We propose and analyze the design notion of adaptive trust management for social IoT systems in which social relationships evolve dynamically among the owners of IoT devices. We reveal the design tradeoff between trust convergence versus trust fluctuation in our adaptive trust management protocol design. With our adaptive trust management protocol, a social IoT application can adaptively choose the best trust parameter settings in response to changing IoT social conditions such that not only trust assessment is accurate but also the application performance is maximized. We propose a table-lookup method to apply the analysis results dynamically and demonstrate the feasibility of our proposed adaptive trust management scheme with two real-world social IoT service composition applications.","Peer-to-peer computing,
Adaptive systems,
Social network services,
Social factors,
Internet of things"
SARLock: SAT attack resistant logic locking,"Logic locking is an Intellectual Property (IP) protection technique that thwarts IP piracy, hardware Trojans, reverse engineering, and IC overproduction. Researchers have taken multiple attempts in breaking logic locking techniques and recovering its secret key. A Boolean Satisfiability (SAT) based attack has been recently presented that breaks all the existing combinational logic locking techniques. In this paper, we develop a lightweight countermeasure against this and other attacks that aim at gradually pruning the key search space. Our proposed logic locking technique, referred to as SARLock, maximizes the required number of distinguishing input patterns to recover the secret key. SARLock thwarts the SAT attack by rendering the attack effort exponential in the number of bits in the secret key, while its overhead grows only linearly.",
Storage-Less and Converter-Less Photovoltaic Energy Harvesting With Maximum Power Point Tracking for Internet of Things,"Energy harvesting from natural environment gives range of benefits for the Internet of things. Scavenging energy from photovoltaic (PV) cells is one of the most practical solutions in terms of power density among existing energy harvesting sources. PV power systems mandate the maximum power point tracking (MPPT) to scavenge the maximum possible solar energy. In general, a switching-mode power converter, an MPPT charger, controls the charging current to the energy storage element (a battery or equivalent), and the energy storage element provides power to the load device. The mismatch between the maximum power point (MPP) current and the load current is managed by the energy storage element. However, such architecture causes significant energy loss (typically over 20%) and a significant weight/volume and a high cost due to the cascaded power converters and the energy storage element. This paper pioneers a converter-less PV power system with the MPPT that directly supplies power to the load without the power converters or the energy storage element. The proposed system uses a nonvolatile microprocessor to enable an extremely fine-grain dynamic power management in a few hundred microseconds. This makes it possible to match the load current with the MPP current. We present detailed modeling, simulation, and optimization of the proposed energy harvesting system including the radio frequency transceiver. Experiments show that the proposed setup achieves an 87.1% of overall system efficiency during a day, 30.6% higher than the conventional MPPT methods in actual measurements, and thus a significantly higher duty cycle under a weak solar irradiance.","Nonvolatile memory,
Maximum power point trackers,
Microprocessors,
Switches,
DC-DC power converters,
Energy storage"
CONCOLOR: Constrained Non-Convex Low-Rank Model for Image Deblocking,"Due to independent and coarse quantization of transform coefficients in each block, block-based transform coding usually introduces visually annoying blocking artifacts at low bitrates, which greatly prevents further bit reduction. To alleviate the conflict between bit reduction and quality preservation, deblocking as a post-processing strategy is an attractive and promising solution without changing existing codec. In this paper, in order to reduce blocking artifacts and obtain high-quality image, image deblocking is formulated as an optimization problem within maximum a posteriori framework, and a novel algorithm for image deblocking using constrained non-convex low-rank model is proposed. The lp (0 <; p <; 1) penalty function is extended on singular values of a matrix to characterize low-rank prior model rather than the nuclear norm, while the quantization constraint is explicitly transformed into the feasible solution space to constrain the non-convex low-rank optimization. Moreover, a new quantization noise model is developed, and an alternatively minimizing strategy with adaptive parameter adjustment is developed to solve the proposed optimization problem. This parameter-free advantage enables the whole algorithm more attractive and practical. Experiments demonstrate that the proposed image deblocking algorithm outperforms the current state-of-the-art methods in both the objective quality and the perceptual quality.",
Soft Pilot Reuse and Multicell Block Diagonalization Precoding for Massive MIMO Systems,"The users at cell edge of a massive multiple-input-multiple-output (MIMO) system suffer from severe pilot contamination (PC), which leads to poor quality of service (QoS). To enhance the QoS for these edge users, soft pilot reuse (SPR) combined with multicell block diagonalization (MBD) precoding is proposed. Specifically, the users are divided into two groups according to their large-scale fading coefficients, which are referred to as the center users, who only suffer from modest PC, and the edge users, who suffer from severe PC. Based on this distinction, the SPR scheme is proposed for improving the QoS for the edge users, whereby a cell-center pilot group is reused for all cell-center users in all cells, whereas a cell-edge pilot group is applied for the edge users in the adjacent cells. By extending the classical block diagonalization precoding to a multicell scenario, the MBD precoding scheme projects the downlink transmit signal onto the null space of the subspace spanned by the intercell channels of the edge users in adjacent cells. Thus, the intercell interference contaminating the edge users' signals in the adjacent cells can be efficiently mitigated, and hence, the QoS of these edge users can be further enhanced. Our theoretical analysis and simulation results demonstrate that both the uplink and downlink rates of the edge users are significantly improved, albeit at the cost of the slightly decreased rate of center users.","Channel estimation,
Quality of service,
Fading,
MIMO,
Interference,
Contamination,
Signal to noise ratio"
SDN and Virtualization Solutions for the Internet of Things: A Survey,"The imminent arrival of the Internet of Things (IoT), which consists of a vast number of devices with heterogeneous characteristics, means that future networks need a new architecture to accommodate the expected increase in data generation. Software defined networking (SDN) and network virtualization (NV) are two technologies that promise to cost-effectively provide the scale and versatility necessary for IoT services. In this paper, we survey the state of the art on the application of SDN and NV to IoT. To the best of our knowledge, we are the first to provide a comprehensive description of every possible IoT implementation aspect for the two technologies. We start by outlining the ways of combining SDN and NV. Subsequently, we present how the two technologies can be used in the mobile and cellular context, with emphasis on forthcoming 5G networks. Afterward, we move to the study of wireless sensor networks, arguably the current foremost example of an IoT network. Finally, we review some general SDN-NV-enabled IoT architectures, along with real-life deployments and use-cases. We conclude by giving directions for future research on this topic.",
Robust Multi-Focus Image Fusion Using Multi-Task Sparse Representation and Spatial Context,"We present a novel fusion method based on a multi-task robust sparse representation (MRSR) model and spatial context information to address the fusion of multi-focus gray-level images with misregistration. First, we present a robust sparse representation (RSR) model by replacing the conventional least-squared reconstruction error by a sparse reconstruction error. We then propose a multi-task version of the RSR model, viz., the MRSR model. The latter is then applied to multi-focus image fusion by employing the detailed information regarding each image patch and its spatial neighbors to collaboratively determine both the focused and defocused regions in the input images. To achieve this, we formulate the problem of extracting details from multiple image patches as a joint multi-task sparsity pursuit based on the MRSR model. Experimental results demonstrate that the suggested algorithm is competitive with the current state-of-the-art and superior to some approaches that use traditional sparse representation methods when input images are misregistered.","Image fusion,
Robustness,
Image reconstruction,
Transforms,
Context modeling,
Sparse representation"
Leveraging Multiscale Hessian-Based Enhancement With a Novel Exudate Inpainting Technique for Retinal Vessel Segmentation,"Accurate vessel detection in retinal images is an important and difficult task. Detection is made more challenging in pathological images with the presence of exudates and other abnormalities. In this paper, we present a new unsupervised vessel segmentation approach to address this problem. A novel inpainting filter, called neighborhood estimator before filling, is proposed to inpaint exudates in a way that nearby false positives are significantly reduced during vessel enhancement. Retinal vascular enhancement is achieved with a multiple-scale Hessian approach. Experimental results show that the proposed vessel segmentation method outperforms state-of-the-art algorithms reported in the recent literature, both visually and in terms of quantitative measurements, with overall mean accuracy of 95.62% on the STARE dataset and 95.81% on the HRF dataset.","Image segmentation,
Informatics,
Retinal vessels,
Biomedical imaging,
Pathology,
Eigenvalues and eigenfunctions"
An integrated cloud-based smart home management system with community hierarchy,"This paper presents a smart home management system in which a community broker role is used for integrating community services, thereby reducing the workload of community management staff, providing electronic information services, and deepening the community's integration with the surrounding environment. At the home end, a home intranet was created by integrating a fixed touch panel with a home controller system and various sensors and devices to deliver, for example, energy, scenario information, and security functions. The community end comprises a community server and community personal computers, and connects to devices (e.g., video cameras and building automation devices) in other community systems and to the home networks. Furthermore, to achieve multiple inhome displays, standard interface devices can be employed to separate the logic and user interfaces. This study also determined that the message queuing telemetry transport protocol can provide optimal home control services in smart home systems, whereas hypertext transfer protocol is optimal for delivering location-based information integration services.","Smart homes,
Cloud computing,
Sensor systems,
Computer architecture,
Control systems,
Intelligent sensors"
Scalable Semi-Supervised Learning by Efficient Anchor Graph Regularization,"Many graph-based semi-supervised learning methods for large datasets have been proposed to cope with the rapidly increasing size of data, such as Anchor Graph Regularization (AGR). This model builds a regularization framework by exploring the underlying structure of the whole dataset with both datapoints and anchors. Nevertheless, AGR still has limitations in its two components: (1) in anchor graph construction, the estimation of the local weights between each datapoint and its neighboring anchors could be biased and relatively slow; and (2) in anchor graph regularization, the adjacency matrix that estimates the relationship between datapoints, is not sufficiently effective. In this paper, we develop an Efficient Anchor Graph Regularization (EAGR) by tackling these issues. First, we propose a fast local anchor embedding method, which reformulates the optimization of local weights and obtains an analytical solution. We show that this method better reconstructs datapoints with anchors and speeds up the optimizing process. Second, we propose a new adjacency matrix among anchors by considering the commonly linked datapoints, which leads to a more effective normalized graph Laplacian over anchors. We show that, with the novel local weight estimation and normalized graph Laplacian, EAGR is able to achieve better classification accuracy with much less computational costs. Experimental results on several publicly available datasets demonstrate the effectiveness of our approach.","Laplace equations,
Semisupervised learning,
Estimation,
Computational modeling,
Computational efficiency,
Optimization"
Image Classification by Selective Regularized Subspace Learning,"Feature learning is an intensively studied research topic in image classification. Although existing methods like sparse coding, locality-constrained linear coding, fisher vector encoding, etc., have shown their effectiveness in image representation, most of them overlook a phenomenon called thesmall sample size problem, where the number of training samples is relatively smaller than the dimensionality of the features, which may limit the predictive power of the classifier. Subspace learning is a strategy to mitigate this problem by reducing the dimensionality of the features. However, most conventional subspace learning methods attempt to learn a global subspace to discriminate all the classes, which proves to be difficult and ineffective in multi-class classification task. To this end, we propose to learn a local subspace for each sample instead of learning a global subspace for all samples. Our key observation is that, in multi-class image classification, the label of each testing sample is only confused by a few classes which have very similar visual appearance to it. Thus, in this work, we propose a coarse-to-fine strategy, which first picks out such classes, and then conducts a local subspace learning to discriminate them. As the subspace learning method is regularized and conducted within some selected classes, we term it selective regularized subspace learning (SRSL), and we term our classification pipeline selective regularized subspace learning based multi-class image classification (SRSL_MIC). Experimental results on four representative datasets (Caltech-101, Indoor-67, ORL Faces and AR Faces) demonstrate the effectiveness of the proposed method.","Learning systems,
Testing,
Encoding,
Feature extraction,
Training,
Principal component analysis,
Image representation"
Red Lesion Detection Using Dynamic Shape Features for Diabetic Retinopathy Screening,"The development of an automatic telemedicine system for computer-aided screening and grading of diabetic retinopathy depends on reliable detection of retinal lesions in fundus images. In this paper, a novel method for automatic detection of both microaneurysms and hemorrhages in color fundus images is described and validated. The main contribution is a new set of shape features, called Dynamic Shape Features, that do not require precise segmentation of the regions to be classified. These features represent the evolution of the shape during image flooding and allow to discriminate between lesions and vessel segments. The method is validated per-lesion and per-image using six databases, four of which are publicly available. It proves to be robust with respect to variability in image resolution, quality and acquisition system. On the Retinopathy Online Challenge's database, the method achieves a FROC score of 0.420 which ranks it fourth. On the Messidor database, when detecting images with diabetic retinopathy, the proposed method achieves an area under the ROC curve of 0.899, comparable to the score of human experts, and it outperforms state-of-the-art approaches.","Lesions,
Image color analysis,
Shape,
Diabetes,
Retina,
Feature extraction,
Colored noise"
On Improving the Security of Logic Locking,"Due to globalization of integrated circuit (IC) design flow, rogue elements in the supply chain can pirate ICs, overbuild ICs, and insert hardware Trojans. EPIC locks the design by randomly inserting additional gates; only a correct key makes the design to produce correct outputs. We demonstrate that an attacker can decipher the locked netlist, in a time linear to the number of keys, by sensitizing the key-bits to the output. We then develop techniques to fix this vulnerability and make an attacker's effort truly exponential in the number of inserted keys. We introduce a new security metric and a method to deliver strong logic locking.",
Effects of the Variation of Ferroelectric Properties on Negative Capacitance FET Characteristics,"We study the effects of the variation of ferroelectric material properties (thickness, polarization, and coercivity) on the performance of negative capacitance FETs (NCFETs). Based on this, we propose the concept of conservative design of NCFETs, where any unintentional yet reasonable and simultaneous variation (~±3%) in ferroelectric parameters does not result in the emergence of hysteresis and causes only a reasonable variation in the ON-current (≤5%) and, within these constraints, the enhancement of ON-current due to the addition of the ferroelectric gate oxide, which is is maximized.","Capacitance,
Hysteresis,
MOSFET,
Logic gates,
CMOS integrated circuits,
Ferroelectric materials"
Distributed Virtual Resource Allocation in Small-Cell Networks With Full-Duplex Self-Backhauls and Virtualization,"Wireless network virtualization has attracted great attention from both academia and industry. Another emerging technology for next-generation wireless networks is in-band full-duplex (FD) communications. Due to its promising performance, FD communication has been considered to be an effective way of achieving self-backhauls for small cells. In this paper, we introduce wireless virtualization into small-cell networks and propose a virtualized small-cell network architecture with FD self-backhauls. We formulate the virtual-resource-allocation problem in virtualized small-cell networks with FD self-backhauls as an optimization problem. Since the formulated problem is a mixed combinatorial and nonconvex optimization problem, its computational complexity is high. Moreover, the centralized scheme may suffer from signaling overhead, outdated dynamics information, and scalability issues. To solve it efficiently, we divide the original problem into two subproblems. For the first subproblem, we transfer it to a convex optimization problem and then solve it by an efficient alternating direction method of multipliers (ADMM)-based distributed algorithm. The second subproblem is a convex problem, which can be solved by each infrastructure provider. Extensive simulations are conducted with different system configurations to show the effectiveness of the proposed scheme.",
Interactive Visual Discovering of Movement Patterns from Sparsely Sampled Geo-tagged Social Media Data,"Social media data with geotags can be used to track people's movements in their daily lives. By providing both rich text and movement information, visual analysis on social media data can be both interesting and challenging. In contrast to traditional movement data, the sparseness and irregularity of social media data increase the difficulty of extracting movement patterns. To facilitate the understanding of people's movements, we present an interactive visual analytics system to support the exploration of sparsely sampled trajectory data from social media. We propose a heuristic model to reduce the uncertainty caused by the nature of social media data. In the proposed system, users can filter and select reliable data from each derived movement category, based on the guidance of uncertainty model and interactive selection tools. By iteratively analyzing filtered movements, users can explore the semantics of movements, including the transportation methods, frequent visiting sequences and keyword descriptions. We provide two cases to demonstrate how our system can help users to explore the movement patterns.","Media,
Semantics,
Uncertainty,
Transportation,
Reliability,
Data models,
Data mining"
Zero-Shot Person Re-identification via Cross-View Consistency,"Person re-identification, aiming to identify images of the same person from various cameras configured in different places, has attracted much attention in the multimedia retrieval community. In this problem, choosing a proper distance metric is a crucial aspect, and many classic methods utilize a uniform learnt metric. However, their performance is limited due to ignoring the zero-shot and fine-grained characteristics presented in real person re-identification applications. In this paper, we investigate two consistencies across two cameras, which are cross-view support consistency and cross-view projection consistency. The philosophy behind it is that, in spite of visual changes in two images of the same person under two camera views, the support sets in their respective views are highly consistent, and after being projected to the same view, their context sets are also highly consistent. Based on the above phenomena, we propose a data-driven distance metric (DDDM) method, re-exploiting the training data to adjust the metric for each query-gallery pair. Experiments conducted on three public data sets have validated the effectiveness of the proposed method, with a significant improvement over three baseline metric learning methods. In particular, on the public VIPeR dataset, the proposed method achieves an accuracy rate of 42.09% at rank-1, which outperforms the state-of-the-art methods by 4.29%.","Measurement,
Cameras,
Training,
Training data,
Learning systems,
Visualization,
Electronic mail"
A Multiobjective Evolutionary Algorithm Based on Decision Variable Analyses for Multiobjective Optimization Problems With Large-Scale Variables,"State-of-the-art multiobjective evolutionary algorithms (MOEAs) treat all the decision variables as a whole to optimize performance. Inspired by the cooperative coevolution and linkage learning methods in the field of single objective optimization, it is interesting to decompose a difficult high-dimensional problem into a set of simpler and low-dimensional subproblems that are easier to solve. However, with no prior knowledge about the objective function, it is not clear how to decompose the objective function. Moreover, it is difficult to use such a decomposition method to solve multiobjective optimization problems (MOPs) because their objective functions are commonly conflicting with one another. That is to say, changing decision variables will generate incomparable solutions. This paper introduces interdependence variable analysis and control variable analysis to deal with the above two difficulties. Thereby, an MOEA based on decision variable analyses (DVAs) is proposed in this paper. Control variable analysis is used to recognize the conflicts among objective functions. More specifically, which variables affect the diversity of generated solutions and which variables play an important role in the convergence of population. Based on learned variable linkages, interdependence variable analysis decomposes decision variables into a set of low-dimensional subcomponents. The empirical studies show that DVA can improve the solution quality on most difficult MOPs. The code and supplementary material of the proposed algorithm are available at http://web.xidian.edu.cn/fliu/paper.html.","Optimization,
Couplings,
Linear programming,
Algorithm design and analysis,
Buildings,
Genetic algorithms,
Evolutionary computation"
Sparse Sensing for Distributed Detection,"An offline sampling design problem for distributed detection is considered in this paper. To reduce the sensing, storage, transmission, and processing costs, the natural choice for the sampler is the sparsest one that results in a desired global error probability. Since the numerical optimization of the error probabilities is difficult, we adopt simpler costs related to distance measures between the conditional distributions of the sensor observations. We design sparse samplers for the Bayesian as well as the Neyman-Pearson setting. The developed theory can be applied to sensor placement/selection, sample selection, and fully decentralized data compression. For conditionally independent observations, we give an explicit solution, which is optimal in terms of the error exponents. More specifically, the best subset of sensors is the one with the smallest local average root-likelihood ratio and largest local average log-likelihood ratio in the Bayesian and Neyman-Pearson setting, respectively. We supplement the proposed framework with a thorough analysis for Gaussian observations, including the case when the sensors are conditionally dependent, and also provide examples for other observation distributions. One of the results shows that, for nonidentical Gaussian sensor observations with uncommon means and common covariances under both hypotheses, the number of sensors required to achieve a desired detection performance reduces significantly as the sensors become more coherent.","Bayes methods,
Error probability,
Optimization,
Detectors,
Measurement uncertainty,
Symmetric matrices"
A Fast Optimization Method for General Binary Code Learning,"Hashing or binary code learning has been recognized to accomplish efficient near neighbor search, and has thus attracted broad interests in recent retrieval, vision, and learning studies. One main challenge of learning to hash arises from the involvement of discrete variables in binary code optimization. While the widely used continuous relaxation may achieve high learning efficiency, the pursued codes are typically less effective due to accumulated quantization error. In this paper, we propose a novel binary code optimization method, dubbed discrete proximal linearized minimization (DPLM), which directly handles the discrete constraints during the learning process. Specifically, the discrete (thus nonsmooth nonconvex) problem is reformulated as minimizing the sum of a smooth loss term with a nonsmooth indicator function. The obtained problem is then efficiently solved by an iterative procedure with each iteration admitting an analytical discrete solution, which is thus shown to converge very fast. In addition, the proposed method supports a large family of empirical loss functions, which is particularly instantiated in this paper by both a supervised and an unsupervised hashing losses, together with the bits uncorrelation and balance constraints. In particular, the proposed DPLM with a supervised ℓ2 loss encodes the whole NUS-WIDE database into 64-b binary codes within 10 s on a standard desktop computer. The proposed approach is extensively evaluated on several large-scale data sets and the generated binary codes are shown to achieve very promising results on both retrieval and classification tasks.","Binary codes,
Minimization,
Optimization methods,
Quantization (signal),
Image coding,
Electronic mail"
To Combat Multi-Class Imbalanced Problems by Means of Over-Sampling Techniques,"Class imbalance problem is quite pervasive in our nowadays human practice. This problem basically refers to the skewness in the data underlying distribution which, in turn, imposes many difficulties on typical machine learning algorithms. To deal with the emerging issues arising from multi-class skewed distributions, existing efforts are mainly divided into two categories: model-oriented solutions and data-oriented techniques. Focusing on the latter, this paper presents a new over-sampling technique which is inspired by Mahalanobis distance. The presented over-sampling technique, called MDO (Mahalanobis Distance-based Over-sampling technique), generates synthetic samples which have the same Mahalanobis distance from the considered class mean as other minority class examples. By preserving the covariance structure of the minority class instances and intelligently generating synthetic samples along the probability contours, new minority class instances are modelled better for learning algorithms. Moreover, MDO can reduce the risk of overlapping between different class regions which are considered as a serious challenge in multi-class problems. Our theoretical analyses and empirical observations across wide spectrum multi-class imbalanced benchmarks indicate that MDO is the method of choice by offering statistical superior MAUC and precision compared to the popular over-sampling techniques.","Mathematical model,
Training,
Accuracy,
Eigenvalues and eigenfunctions,
Machine learning algorithms,
Algorithm design and analysis,
Benchmark testing"
Joint Label Consistent Dictionary Learning and Adaptive Label Prediction for Semisupervised Machine Fault Classification,"In this paper, we propose a semisupervised label consistent dictionary learning (SSDL) framework for machine fault classification. SSDL is a semisupervised extension of recent fully supervised label consistent dictionary learning approach, since the number of labeled machine data is usually limited in practice. To enable the supervised dictionary learning model to use both labeled and commonly readily available unlabeled data for enhancing performance, we propose to incorporate the merits of label prediction and present a joint label consistent dictionary learning and adaptive label prediction technique. In this setting, we first employ the existing label prediction model to estimate the labels of unlabeled training signals in a transductive fashion for enriching supervised prior. Then, we use predicted labeled data for label consistent dictionary learning. After that, we apply the discriminant sparse codes as the adaptive reconstruction weights for label prediction to update the estimated labels of unlabeled training data and the discriminative sparse codes matrix for label consistent dictionary learning so that classification performance can be enhanced. Thus, an informative dictionary, a sparse-code matrix, and an optimal multiclass classifier can be alternately obtained from one objective function. Besides, the tricky process of choosing optimal kernel width and neighborhood size can also be effectively voided in our scheme due to the adaptive weights. Extensive simulations on several machine fault datasets show that our SSDL method can deliver enhanced performance over other state-of-the-arts for machine fault classification.","Training,
Sparse matrices,
Optimization,
Linear programming,
Training data,
Encoding"
Distributed Software Infrastructure for General Purpose Services in Smart Grid,"In this paper, the design of an event-driven middleware for general purpose services in smart grid (SG) is presented. The main purpose is to provide a peer-to-peer distributed software infrastructure to allow the access of new multiple and authorized actors to SGs information in order to provide new services. To achieve this, the proposed middleware has been designed to be: 1) event-based; 2) reliable; 3) secure from malicious information and communication technology attacks; and 4) to enable hardware independent interoperability between heterogeneous technologies. To demonstrate practical deployment, a numerical case study applied to the whole U.K. distribution network is presented, and the capabilities of the proposed infrastructure are discussed.","Sensors,
Interoperability,
Web services,
Peer-to-peer computing,
Reliability"
Efficient Two-Dimensional Direction-of-Arrival Estimation for a Mixture of Circular and Noncircular Sources,"In this paper, the two-dimensional (2-D) direction-of-arrival (DOA) estimation problem for a mixture of circular and noncircular sources is considered. In particular, we focus on a 2-D array structure consisting of two parallel uniform linear arrays and build a general array model with mixed circular and noncircular sources. The received array data and its conjugate counterparts are combined together to form a new data vector, based on which a series of 2-D DOA estimators is derived. Compared with existing methods, the proposed one has three main advantages. First, it can give a more accurate estimation in situations, where the number of sources is within the traditional limit of high-resolution methods. Second, it can still work effectively when the number of mixed signals is larger than that of the array elements. Finally, the paired 2-D DOAs of the proposed method can be obtained automatically without the complicated 2-D spectrum peak search and, therefore, has a much lower computational complexity.","Direction-of-arrival estimation,
Arrays,
Estimation,
Covariance matrices,
Sensors,
Matrix decomposition,
Two dimensional displays"
Argo: A Real-Time Network-on-Chip Architecture With an Efficient GALS Implementation,"In this paper, we present an area-efficient, globally asynchronous, locally synchronous network-on-chip (NoC) architecture for a hard real-time multiprocessor platform. The NoC implements message-passing communication between processor cores. It uses statically scheduled time-division multiplexing (TDM) to control the communication over a structure of routers, links, and network interfaces (NIs) to offer real-time guarantees. The area-efficient design is a result of two contributions: 1) asynchronous routers combined with TDM scheduling and 2) a novel NI microarchitecture. Together they result in a design in which data are transferred in a pipelined fashion, from the local memory of the sending core to the local memory of the receiving core, without any dynamic arbitration, buffering, and clock synchronization. The routers use two-phase bundled-data handshake latches based on the Mousetrap latch controller and are extended with a clock gating mechanism to reduce the energy consumption. The NIs integrate the direct memory access functionality and the TDM schedule, and use dual-ported local memories to avoid buffering, flow-control, and synchronization. To verify the design, we have implemented a 4 × 4 bitorus NoC in 65-nm CMOS technology and we present results on area, speed, and energy consumption for the router, NI, NoC, and postlayout.",
Analysis of High-Power Switched-Capacitor Converter Regulation Based on Charge-Balance Transient-Calculation Method,"Switched-capacitor (SC) converters were initially introduced for low-power applications and monolithic integration. In recent years, SC converter has found high-power applications. However, voltage regulation remains an issue. This paper addresses regulation challenges for high-power SC converters, based on charge-balance transient-calculation (CT) modeling method and peak current stress estimation. With the help of CT model, due to its accuracy and comprehensive relationship, circuit and control parameters' impacts on regulation become straightforward and concerns on components stresses can be addressed quantitatively. The suitability of CT method for regulation analysis is confirmed by comparison with traditional modeling methods. The CT method is used in a 1-kW 3X two-switch boosting switched-capacitor converter (TBSC) circuit for steady-state analysis and current stress estimation. The soft rising input current and nature interleaving properties of 3X TBSC make it well suited for high-power application. Finally, the small-signal model of the 3X TBSC is developed and a closed-loop operation is achieved under 1 kW power rating.","Integrated circuit modeling,
Mathematical model,
Switches,
Capacitors,
Stress,
Impedance,
Voltage control"
Placing dynamic content in caches with small population,"This paper addresses a fundamental limitation for the adoption of caching for wireless access networks due to small population sizes. This shortcoming is due to two main challenges: making timely estimates of varying content popularity and inferring popular content from small samples. We propose a framework which alleviates such limitations. To timely estimate varying popularity in a context of a single cache we propose an Age-Based Threshold (ABT) policy which caches all contents requested more times than a threshold N (τ), where τ is the content age. We show that ABT is asymptotically hit rate optimal in the many contents regime, which allows us to obtain the first characterization of the optimal performance of a caching system in a dynamic context. We then address small sample sizes focusing on L local caches and one global cache. On the one hand we show that the global cache learns L times faster by aggregating all requests from local caches, which improves hit rates. On the other hand, aggregation washes out local characteristics of correlated traffic which penalizes hit rate. This motivates coordination mechanisms which combine global learning of popularity scores in clusters and Least-Recently-Used (LRU) policy with prefetching.",
Deploying chains of virtual network functions: On the relation between link and server usage,"Recently, Network Function Virtualization (NFV) has been proposed to transform from network hardware appliances to software middleboxes. Normally, a demand needs to invoke several Virtual Network Functions (VNFs) in a particular order following the service chain along a routing path. In this paper, we study the joint problem of VNF placement and path selection to better utilize the network. We discover that the relation between the link and server usage plays a crucial role in the problem. We first propose a systematic way to elastically tune the proper link and server usage of each demand based on network conditions and demand properties. In particular, we compute a proper routing path length, and decide, for each VNF in the service chain, whether to use additional server resources or to reuse resources provided by existing servers. We then propose a chain deployment algorithm to follow the guidance of this link and server usage. Via simulations, we show that our design effectively adapts resource usage to network dynamics, and, hence, serves more demands than other heuristics.","Servers,
Bandwidth,
Silicon,
Hardware,
Routing,
Algorithm design and analysis"
A Universal Framework for Salient Object Detection,"In this paper, we propose a novel universal framework for salient object detection, which aims to enhance the performance of any existing saliency detection method. First, rough salient regions are extracted from any existing saliency detection model with distance weighting, adaptive binarization, and morphological closing. With the superpixel segmentation, a Bayesian decision model is adopted to refine the rough saliency map to obtain a more accurate saliency map. An iterative optimization method is designed to obtain better saliency results by exploiting the characteristics of the output saliency map each time. Through the iterative optimization process, the rough saliency map is updated step by step with better and better performance until an optimal saliency map is obtained. Experimental results on the public salient object detection datasets with ground truth demonstrate the promising performance of the proposed universal framework subjectively and objectively.","Visualization,
Feature extraction,
Computational modeling,
Object detection,
Image color analysis,
Optimization,
Adaptation models"
Residential Load Scheduling in Smart Grid: A Cost Efficiency Perspective,"In smart grid, residential consumers adopt different load scheduling methods to manage their power consumptions with specific objectives. The conventional load scheduling methods aim to maximize the consumption payoff or minimize the consumption cost. In this paper, we introduce a novel concept of cost efficiency-based residential load scheduling framework to improve the economical efficiency of the residential electricity consumption. The cost efficiency is defined as the ratio of consumer's total consumption benefit to its total electricity payment during a certain period. We develop a cost-efficient load scheduling algorithm for the demand-side's day-ahead bidding process and real-time pricing mechanism by using a fractional programing approach. Results show that the proposed scheduling algorithm can effectively reflect and affect user's consumption behavior and achieve the optimal cost-efficient energy consumption profile. For practical consideration, we also take into account the service fee and distributed energy resources (DERs) in our framework, and analyze their impacts on the cost efficiency. Simulation results confirm that the proposed algorithm significantly improves consumer's cost efficiency. It is shown that a higher service fee will decrease the cost efficiency, while the integration of DERs can effectively improve the cost efficiency.","Home appliances,
Measurement,
Scheduling algorithms,
Pricing,
Shape,
Production,
Barium"
Beyond the Sparsity-Based Target Detector: A Hybrid Sparsity and Statistics-Based Detector for Hyperspectral Images,"Hyperspectral images provide great potential for target detection, however, new challenges are also introduced for hyperspectral target detection, resulting that hyperspectral target detection should be treated as a new problem and modeled differently. Many classical detectors are proposed based on the linear mixing model and the sparsity model. However, the former type of model cannot deal well with spectral variability in limited endmembers, and the latter type of model usually treats the target detection as a simple classification problem and pays less attention to the low target probability. In this case, can we find an efficient way to utilize both the high-dimension features behind hyperspectral images and the limited target information to extract small targets? This paper proposes a novel sparsity-based detector named the hybrid sparsity and statistics detector (HSSD) for target detection in hyperspectral imagery, which can effectively deal with the above two problems. The proposed algorithm designs a hypothesis-specific dictionary based on the prior hypotheses for the test pixel, which can avoid the imbalanced number of training samples for a class-specific dictionary. Then, a purification process is employed for the background training samples in order to construct an effective competition between the two hypotheses. Next, a sparse representation-based binary hypothesis model merged with additive Gaussian noise is proposed to represent the image. Finally, a generalized likelihood ratio test is performed to obtain a more robust detection decision than the reconstruction residual-based detection methods. Extensive experimental results with three hyperspectral data sets confirm that the proposed HSSD algorithm clearly outperforms the state-of-the-art target detectors.","Hyperspectral imaging,
Object detection,
Detectors,
Training,
Face,
Dictionaries"
Multi-Modal Curriculum Learning for Semi-Supervised Image Classification,"Semi-supervised image classification aims to classify a large quantity of unlabeled images by typically harnessing scarce labeled images. Existing semi-supervised methods often suffer from inadequate classification accuracy when encountering difficult yet critical images, such as outliers, because they treat all unlabeled images equally and conduct classifications in an imperfectly ordered sequence. In this paper, we employ the curriculum learning methodology by investigating the difficulty of classifying every unlabeled image. The reliability and the discriminability of these unlabeled images are particularly investigated for evaluating their difficulty. As a result, an optimized image sequence is generated during the iterative propagations, and the unlabeled images are logically classified from simple to difficult. Furthermore, since images are usually characterized by multiple visual feature descriptors, we associate each kind of features with a teacher, and design a multi-modal curriculum learning (MMCL) strategy to integrate the information from different feature modalities. In each propagation, each teacher analyzes the difficulties of the currently unlabeled images from its own modality viewpoint. A consensus is subsequently reached among all the teachers, determining the currently simplest images (i.e., a curriculum), which are to be reliably classified by the multi-modal learner. This well-organized propagation process leveraging multiple teachers and one learner enables our MMCL to outperform five state-of-the-art methods on eight popular image data sets.","Reliability,
Kernel,
Visualization,
Semisupervised learning,
Electronic mail,
Image processing,
Pattern recognition"
Emerging Physical Unclonable Functions With Nanotechnology,"Physical unclonable functions (PUFs) are increasingly used for authentication and identification applications as well as the cryptographic key generation. An important feature of a PUF is the reliance on minute random variations in the fabricated hardware to derive a trusted random key. Currently, most PUF designs focus on exploiting process variations intrinsic to the CMOS technology. In recent years, progress in emerging nanoelectronic devices has demonstrated an increase in variation as a consequence of scaling down to the nanoregion. To date, emerging PUFs with nanotechnology have not been fully established, but they are expected to emerge. Initial research in this area aims to provide security primitives for emerging integrated circuits with nanotechnology. In this paper, we review emerging nanotechnology-based PUFs.","Nanotechnology,
Cloning,
Physical unclonable functions,
Nanoscale devices,
Object recognition,
CMOS integrated circuits,
Computer security,
Private key cryptography,
Cryptography"
Fast Multiclass Dictionaries Learning With Geometrical Directions in MRI Reconstruction,"Objective: Improve the reconstructed image with fast and multiclass dictionaries learning when magnetic resonance imaging is accelerated by undersampling the k-space data. Methods: A fast orthogonal dictionary learning method is introduced into magnetic resonance image reconstruction to provide adaptive sparse representation of images. To enhance the sparsity, image is divided into classified patches according to the same geometrical direction and dictionary is trained within each class. A new sparse reconstruction model with the multiclass dictionaries is proposed and solved using a fast alternating direction method of multipliers. Results: Experiments on phantom and brain imaging data with acceleration factor up to 10 and various undersampling patterns are conducted. The proposed method is compared with state-of-the-art magnetic resonance image reconstruction methods. Conclusion: Artifacts are better suppressed and image edges are better preserved than the compared methods. Besides, the computation of the proposed approach is much faster than the typical K-SVD dictionary learning method in magnetic resonance image reconstruction. Significance: The proposed method can be exploited in undersampled magnetic resonance imaging to reduce data acquisition time and reconstruct images with better image quality.","Dictionaries,
Image reconstruction,
Magnetic resonance imaging,
Training,
Learning systems,
Transforms,
Magnetic resonance"
Building Energy Management Systems: The Age of Intelligent and Adaptive Buildings,"Building automation systems (BAS), or building control systems (BCS), typically consist of building energy management systems (BEMSs), physical security and access control, fire/life safety, and other systems (elevators, public announcements, and closed-circuit television). BEMSs control heating, ventilation, and air conditioning (HVAC) and lighting systems in buildings; more specifically, they control HVAC's primary components such as air handling units (AHUs), chillers, and heating elements. BEMSs are essential components of modern buildings, tasked with seemingly contradicting requirements?minimizing energy consumption while maintaining occupants? comfort [1]. In the United States, about 40% of total energy consumption and 70% of electricity consumption are spent on buildings every year. These numbers are comparable to global statistics that about 30% of total energy consumption and 60% of electricity consumption are spent on buildings. Buildings are an integral part of global cyber-physical systems (smart cities) and evolve and interact with their surroundings. As buildings undergo years of exploitation, their thermal characteristics deteriorate, indoor spaces (especially in commercial buildings) get rearranged, and usage patterns change. In time, their inner (and outer) microclimates adjust to changes in surrounding buildings, overshadowing patterns, and city climates, not to mention building retrofitting. Thus, even in cases of ideally designed BEMS/HVAC systems, because of ever-changing and uncertain indoor and outdoor environments, their performance frequently falls short of expectations. Unfortunately, the complexity of BEMSs, large amounts of constantly changing data, and evolving interrelations among sensor feeds make identifying these suboptimal behaviors difficult. Therefore, traditional data-mining algorithms and data-analysis tools are often inadequate.This article provides an overview of issues related to modern BEMSs with a multitude of (often conflicting) requirements. Because of massive and often incomplete data sets, control, sensing, and the evolving nature of these complex systems, computational intelligence (CI) techniques present a natural solution to optimal energy efficiency, energy security, and occupant comfort in buildings. The article further presents an overall architecture where CI can be used in BEMSs and concludes with a case study of the practical applications of using CI techniques in the BEMS domain.",
Verifiable Computation over Large Database with Incremental Updates,"The notion of verifiable database (VDB) enables a resource-constrained client to securely outsource a very large database to an untrusted server so that it could later retrieve a database record and update a record by assigning a new value. Also, any attempt by the server to tamper with the data will be detected by the client. When the database undergoes frequent while small modifications, the client must re-compute and update the encrypted version (ciphertext) on the server at all times. For very large data, it is extremely expensive for the resources-constrained client to perform both operations from scratch. In this paper, we formalize the notion of verifiable database with incremental updates (Inc-VDB). Besides, we propose a general Inc-VDB framework by incorporating the primitive of vector commitment and the encrypt-then-incremental MAC mode of encryption. We also present a concrete Inc-VDB scheme based on the computational Diffie-Hellman (CDH) assumption. Furthermore, we prove that our construction can achieve the desired security properties.","Databases,
Servers,
Outsourcing,
Encryption,
Electronic mail"
An ensemble sinusoidal parameter adaptation incorporated with L-SHADE for solving CEC2014 benchmark problems,"An effective and efficient self-adaptation framework is proposed to improve the performance of the L-SHADE algorithm by providing successful alternative adaptation for the selection of control parameters. The proposed algorithm, namely LSHADE-EpSin, uses a new ensemble sinusoidal approach to automatically adapt the values of the scaling factor of the Differential Evolution algorithm. This ensemble approach consists of a mixture of two sinusoidal formulas: A non-Adaptive Sinusoidal Decreasing Adjustment and an adaptive History-based Sinusoidal Increasing Adjustment. The objective of this sinusoidal ensemble approach is to find an effective balance between the exploitation of the already found best solutions, and the exploration of non-visited regions. A local search method based on Gaussian Walks is used at later generations to increase the exploitation ability of LSHADE-EpSin. The proposed algorithm is tested on the IEEE CEC2014 problems used in the Special Session and Competitions on Real-Parameter Single Objective Optimization of the IEEE CEC2016. The results statistically affirm the efficiency and robustness of the proposed approach to obtain better results compared to L-SHADE algorithm and other state-of-the-art algorithms.",
Hybrid k -Nearest Neighbor Classifier,"Conventional k-nearest neighbor (KNN) classification approaches have several limitations when dealing with some problems caused by the special datasets, such as the sparse problem, the imbalance problem, and the noise problem. In this paper, we first perform a brief survey on the recent progress of the KNN classification approaches. Then, the hybrid KNN (HBKNN) classification approach, which takes into account the local and global information of the query sample, is designed to address the problems raised from the special datasets. In the following, the random subspace ensemble framework based on HBKNN (RS-HBKNN) classifier is proposed to perform classification on the datasets with noisy attributes in the high-dimensional space. Finally, the nonparametric tests are proposed to be adopted to compare the proposed method with other classification approaches over multiple datasets. The experiments on the real-world datasets from the Knowledge Extraction based on Evolutionary Learning dataset repository demonstrate that RS-HBKNN works well on real datasets, and outperforms most of the state-of-the-art classification approaches.","Training,
Noise measurement,
Computational efficiency,
Euclidean distance,
Noise,
Remote sensing"
Image Classification by Cross-Media Active Learning With Privileged Information,"In this paper, we propose a novel cross-media active learning algorithm to reduce the effort on labeling images for training. The Internet images are often associated with rich textual descriptions. Even though such textual information is not available in test images, it is still useful for learning robust classifiers. In light of this, we apply the recently proposed supervised learning paradigm, learning using privileged information, to the active learning task. Specifically, we train classifiers on both visual features and privileged information, and measure the uncertainty of unlabeled data by exploiting the learned classifiers and slacking function. Then, we propose to select unlabeled samples by jointly measuring the cross-media uncertainty and the visual diversity. Our method automatically learns the optimal tradeoff parameter between the two measurements, which in turn makes our algorithms particularly suitable for real-world applications. Extensive experiments demonstrate the effectiveness of our approach.",
Very Low-Programming-Current RRAM With Self-Rectifying Characteristics,"To resolve the sneak leakage problem and reduce the power consumption in crossbar RRAM arrays, a Cu/Al2O3/aSi/Ta cell with self-rectifying characteristics is developed. The cell exhibits low operating current (~nA), high ON/OFF ratios (>100×), and pronounced nonlinearity. The use of low-programming-current RRAM elements avoids the current-driving capability bottleneck of selectors, while the integrated rectifying layer improves the RRAM operation reliability. Endurance of over 500 cycles with ~100 ON/OFF ratio was achieved without external current compliance. Even at such low programming levels, retention over 104 s at 100 °C can still be obtained.","Electrodes,
Switches,
Resistance,
Temperature measurement,
Reliability,
Programming,
Films"
We Can Hear You with Wi-Fi!,"Recent literature advances Wi-Fi signals to “see” people's motions and locations. This paper asks the following question: Can Wi-Fi “hear” our talks? We present WiHear, which enables Wi-Fi signals to “hear” our talks without deploying any devices. To achieve this, WiHear needs to detect and analyze fine-grained radio reflections from mouth movements. WiHear solves this micro-movement detection problem by introducing Mouth Motion Profile that leverages partial multipath effects and wavelet packet transformation. Since Wi-Fi signals do not require line-of-sight, WiHear can “hear” people talks within the radio range. Further, WiHear can simultaneously “hear” multiple people's talks leveraging MIMO technology. We implement WiHear on both USRP N210 platform and commercial Wi-Fi infrastructure. Results show that within our pre-defined vocabulary, WiHear can achieve detection accuracy of 91 percent on average for single individual speaking no more than six words and up to 74 percent for no more than three people talking simultaneously. Moreover, the detection accuracy can be further improved by deploying multiple receivers from different angles.","Mouth,
IEEE 802.11 Standard,
MIMO,
Receivers,
Wireless communication,
Motion detection,
Tracking"
Sequential Compact Code Learning for Unsupervised Image Hashing,"Effective hashing for large-scale image databases is a popular research area, attracting much attention in computer vision and visual information retrieval. Several recent methods attempt to learn either graph embedding or semantic coding for fast and accurate applications. In this paper, a novel unsupervised framework, termed evolutionary compact embedding (ECE), is introduced to automatically learn the task-specific binary hash codes. It can be regarded as an optimization algorithm that combines the genetic programming (GP) and a boosting trick. In our architecture, each bit of ECE is iteratively computed using a weak binary classification function, which is generated through GP evolving by jointly minimizing its empirical risk with the AdaBoost strategy on a training set. We address this as greedy optimization by embedding high-dimensional data points into a similarity-preserved Hamming space with a low dimension. We systematically evaluate ECE on two data sets, SIFT 1M and GIST 1M, showing the effectiveness and the accuracy of our method for a large-scale similarity search.","Optimization,
Boosting,
Training,
Computer architecture,
Hamming distance,
Genetics,
Sociology"
Hyperspectral Image Classification Via Shape-Adaptive Joint Sparse Representation,"A new shape-adaptive joint sparse representation classification (SAJSRC) method is proposed for hyperspectral images (HSIs) classification. The proposed method adaptively explores the spatial information and incorporates it into a joint sparse representation classifier. First, the HSI is transformed with the principal component analysis (PCA) algorithm. Then, the first principal component (PC), which represents the most spatial variation in the HSI, is used in the shape-adaptive algorithm to construct a shape-adaptive local smooth region for each test pixel. Unlike the fixed-sized window used in other sparse representation-based methods, the shape-adaptive regions have adaptive sizes and shapes, and conform to the spatial structure of the HSI as far as possible. Finally, the label of the test pixel is determined by applying the joint sparse representation classifier to the first several PCs of pixels within the corresponding SA region. According to the experiments performed on several HSIs, the proposed SAJSRC method outperforms some widely used HSIs classification approaches.","Joints,
Support vector machines,
Sparse matrices,
Image edge detection,
Hyperspectral imaging,
Principal component analysis,
Training"
A Survey of Stochastic Simulation and Optimization Methods in Signal Processing,"Modern signal processing (SP) methods rely very heavily on probability and statistics to solve challenging SP problems. SP methods are now expected to deal with ever more complex models, requiring ever more sophisticated computational inference techniques. This has driven the development of statistical SP methods based on stochastic simulation and optimization. Stochastic simulation and optimization algorithms are computationally intensive tools for performing statistical inference in models that are analytically intractable and beyond the scope of deterministic inference methods. They have been recently successfully applied to many difficult problems involving complex statistical models and sophisticated (often Bayesian) statistical inference techniques. This survey paper offers an introduction to stochastic simulation and optimization methods in signal and image processing. The paper addresses a variety of high-dimensional Markov chain Monte Carlo (MCMC) methods as well as deterministic surrogate methods, such as variational Bayes, the Bethe approach, belief and expectation propagation and approximate message passing algorithms. It also discusses a range of optimization methods that have been adopted to solve stochastic problems, as well as stochastic methods for deterministic optimization. Subsequently, areas of overlap between simulation and optimization, in particular optimization-within-MCMC and MCMC-driven optimization are discussed.","Signal processing algorithms,
Approximation algorithms,
Stochastic processes,
Computational modeling,
Optimization,
Monte Carlo methods,
Proposals"
Stain Specific Standardization of Whole-Slide Histopathological Images,"Variations in the color and intensity of hematoxylin and eosin (H&E) stained histological slides can potentially hamper the effectiveness of quantitative image analysis. This paper presents a fully automated algorithm for standardization of whole-slide histopathological images to reduce the effect of these variations. The proposed algorithm, called whole-slide image color standardizer (WSICS), utilizes color and spatial information to classify the image pixels into different stain components. The chromatic and density distributions for each of the stain components in the hue-saturation-density color model are aligned to match the corresponding distributions from a template whole-slide image (WSI). The performance of the WSICS algorithm was evaluated on two datasets. The first originated from 125 H&E stained WSIs of lymph nodes, sampled from 3 patients, and stained in 5 different laboratories on different days of the week. The second comprised 30 H&E stained WSIs of rat liver sections. The result of qualitative and quantitative evaluations using the first dataset demonstrate that the WSICS algorithm outperforms competing methods in terms of achieving color constancy. The WSICS algorithm consistently yields the smallest standard deviation and coefficient of variation of the normalized median intensity measure. Using the second dataset, we evaluated the impact of our algorithm on the performance of an already published necrosis quantification system. The performance of this system was significantly improved by utilizing the WSICS algorithm. The results of the empirical evaluations collectively demonstrate the potential contribution of the proposed standardization algorithm to improved diagnostic accuracy and consistency in computer-aided diagnosis for histopathology data.","Image color analysis,
Standardization,
Training,
Transforms,
Design automation,
Robustness,
Optical imaging"
A theoretical bilevel control scheme for power networks with large-scale penetration of distributed renewable resources,"In this paper, we present a bilevel control framework to achieve a highly-reliable smart distribution network with large-scale penetration of distributed renewable resources (DRRs). We assume that the power distribution network consists of several residential/commercial communities. In the first level of the proposed control scheme, distributed community-level controllers are designed based on the stochastic model of demand and generation. These controllers utilize the local storage units and DRRs to maintain a certain level of reliability for the community. In order to formulate the residential demand and DRRs, we use the Gaussian white noise added to some periodic signals, formulated as a stochastic process. In the second level of the proposed control framework, we take the advantage of bulk generation units to improve the reliability by a global flow controller. In other words, we get help from a few number of bulk power plants in the grid to improve its reliability in the context of satisfying the residential demand with high probability. The global controller dispatches the available non-renewable power plants between communities to enhance the reliability of each community. Using our stochastic model, we obtain a theoretical low-threshold for the certainty of the demand satisfaction in the smart power distribution network.","Reliability,
Stochastic processes,
Power system reliability,
White noise,
Smart grids,
Energy storage"
A Novel Approach to Solve Power Flow for Islanded Microgrids Using Modified Newton Raphson With Droop Control of DG,"The study of power flow analysis for microgrids has gained importance where several methods have been proposed to solve these problems. However, these schemes are complicated and not easy to implement due to the absence of a slack bus as well as the dependence of the power on frequency as a result of the droop characteristics. This paper proposes simple and effective modifications to the conventional method (Newton Raphson) to compute the power flow for microgrids. The presented method provides a simple, easy to implement, and accurate approach to solve the power flow equations for microgrids. The proposed method is applied to two test systems: a 6-bus system and a 38-bus system. The results are compared against simulation results from PSCAD/EMTDC which validate the effectiveness of the developed method. The proposed technique can be easily integrated in current commercially available power system software and can be applied for power system studies.",
Ergodic Achievable Secrecy Rate of Multiple-Antenna Relay Systems With Cooperative Jamming,"This paper investigates the ergodic achievable secrecy rate (EASR) of multiple-antenna amplify-and-forward relay systems, where one eavesdropper can wiretap the relay. To reveal the capability of the multiple-antenna relay in improving the secrecy performance, we derive new tight closed-form expressions of the EASR for three secure transmission schemes: artificial noise aided precoding (ANP), destination based jamming (DBJ) and eigen-beamforming (EB). We also derive the lower bounds of the EASR for ANP and DBJ with a large antenna array at the relay, and investigate their corresponding asymptotic performance in the high SNR and low SNR regimes to show valuable intrinsic insights as well. Based on the asymptotic analysis, we optimally allocate the power to the information signal and the artificial noise. Both the analysis and simulation results indicate that, in the moderate-to-high SNR regime, ANP achieves considerable performance gain over DBJ and EB, while in the low SNR regime, EB outperforms the other two schemes with equal power allocation. As SNR grows large, the EASR of EB approaches a constant independent of the first hop channel. Moreover, in the high SNR regime, it is optimal to allocate around half of total power to artificial noise for ANP and most of the power to artificial noise for DBJ.","Relays,
Signal to noise ratio,
Jamming,
Wireless communication,
Array signal processing,
Numerical models,
Communication system security"
Very deep multilingual convolutional neural networks for LVCSR,"Convolutional neural networks (CNNs) are a standard component of many current state-of-the-art Large Vocabulary Continuous Speech Recognition (LVCSR) systems. However, CNNs in LVCSR have not kept pace with recent advances in other domains where deeper neural networks provide superior performance. In this paper we propose a number of architectural advances in CNNs for LVCSR. First, we introduce a very deep convolutional network architecture with up to 14 weight layers. There are multiple convolutional layers before each pooling layer, with small 3×3 kernels, inspired by the VGG Imagenet 2014 architecture. Then, we introduce multilingual CNNs with multiple untied layers. Finally, we introduce multi-scale input features aimed at exploiting more context at negligible computational cost. We evaluate the improvements first on a Babel task for low resource speech recognition, obtaining an absolute 5.77% WER improvement over the baseline PLP DNN by training our CNN on the combined data of six different languages. We then evaluate the very deep CNNs on the Hub5'00 benchmark (using the 262 hours of SWB-1 training data) achieving a word error rate of 11.8% after cross-entropy training, a 1.4% WER improvement (10.6% relative) over the best published CNN result so far.","Training,
Context,
Hidden Markov models,
Neural networks,
Computer architecture,
Kernel,
Training data"
Fast logic synthesis for RRAM-based in-memory computing using Majority-Inverter Graphs,"Resistive Random Access Memories (RRAMs) have gained high attention for a variety of promising applications especially the design of non-volatile in-memory computing devices. In this paper, we present an approach for the synthesis of RRAM-based logic circuits using the recently proposed Majority-Inverter Graphs (MIGs). We propose a bi-objective algorithm to optimize MIGs with respect to the number of required RRAMs and computational steps in both MAJ-based and IMP-based realizations. Since the number of computational steps is recognized as the main drawback of the RRAM-based logic, we also present an effective algorithm to reduce the number of required steps. Experimental results show that the proposed algorithms achieve higher efficiency compared to the general purpose MIG optimization algorithms, either in finding a good trade-off between both cost metrics or reducing the number of steps. In comparison with the RRAM-based circuits implemented by the state-of-the-art approaches using other well-known data structures the number of required computational steps obtained by our proposed MIG-oriented synthesis approach for large benchmark circuits is reduced up to factor of 26. This strong gain comes from the use of MIGs that provide an efficient and intrinsic representation for RRAM-based computing - particularly in MAJ-based realizations - and the use of techniques proposed for optimization.","Logic gates,
Optimization,
Data structures,
Switches,
Boolean functions,
Algorithm design and analysis,
Memristors"
Diffusion LMS Strategies in Sensor Networks With Noisy Input Data,"We investigate the performance of distributed least-mean square (LMS) algorithms for parameter estimation over sensor networks where the regression data of each node are corrupted by white measurement noise. Under this condition, we show that the estimates produced by distributed LMS algorithms will be biased if the regression noise is excluded from consideration. We propose a bias-elimination technique and develop a novel class of diffusion LMS algorithms that can mitigate the effect of regression noise and obtain an unbiased estimate of the unknown parameter vector over the network. In our development, we first assume that the variances of the regression noises are known a priori. Later, we relax this assumption by estimating these variances in real time. We analyze the stability and convergence of the proposed algorithms and derive closed-form expressions to characterize their mean-square error performance in transient and steady-state regimes. We further provide computer experiment results that illustrate the efficiency of the proposed algorithms and support the analytical findings.","Least squares approximations,
Noise,
Vectors,
Noise measurement,
Algorithm design and analysis,
Signal processing algorithms,
Estimation"
Stabilization of a Cascaded DC Converter System via Adding a Virtual Adaptive Parallel Impedance to the Input of the Load Converter,"Connecting converters in cascade is a basic configuration of dc distributed power systems (DPS). The impedance interaction between individually designed converters may make the cascaded system become unstable. The previous presented stabilization approaches not only need to know the information of the regulated converter, but also have to know the characteristics of the other converters in the system, which are contradictory to the modularization characteristic of dc DPS. This letter proposes an adaptive-input-impedance-regulation (AIIR) method, which connects an adaptive virtual impedance in parallel with the input impedance of the load converter, to stabilize the cascaded system. This virtual impedance can adaptively regulate its characteristic for different source converters. Therefore, with the AIIR method, all the load converters can be designed to a fixed standard module to stably adapt various source converters. In addition, at any cases, the AIIR approach only changes the load converter's input impedance in a very small frequency range to keep the load converter's original dynamic performance. The requirements on the AIIR method are derived and the control strategies to achieve the AIIR method are proposed. Finally, considering the worst stability problem that often occurs at the system whose source converter is an LC filter, a load converter cascaded with two different LC input filters is fabricated and tested to validate the effectiveness of the proposed AIIR control method.","Impedance,
Voltage control,
Frequency conversion,
Stability criteria,
Resistors,
Regulators,
Power system stability"
Trading Delay for Distortion in One-Way Video Communication Over the Internet,"We study the problem of one-way video communication in a single-source, multiple-destination scenario over the lossy Internet. Forward error correction (FEC) coding is commonly adopted for data protection in implementing loss-resilient video transmission systems. However, the burst packet losses over the Internet frequently degrade FEC performance and induce video quality deteriorations. To address the challenging problem, we propose a novel transmission scheme dubbed trading delay for distortion (TELFORD) that includes three components: 1) adaptive multidestination status estimation; 2) delay-constrained transmission rate assignment; and 3) differentiated FEC packet spreading. We analytically formulate and solve the problem of FEC packet allocation and scheduling to minimize the end-to-end video distortion. The proposed TELFORD is able to cope with multiple-destination scheduling separately. We conduct performance evaluation through semiphysical emulations in Exata using real-time H.264 video streaming. Experimental results show that TELFORD outperforms existing error control transmission schemes in improving the video peak signal-to-noise ratio and mitigating packet transmission impairments.","Streaming media,
Delays,
Forward error correction,
Internet,
Encoding,
Video recording,
Quality assessment"
Flexible and Time-Efficient Tag Scanning with Handheld Readers,"Tag scanning is an important issue to dynamically manage tag IDs in radio frequency identification (RFID) systems. Different from tag identification that collects IDs of all the tags, tag scanning first verifies whether or not a responding tag has already been identified and retrieves its ID when the answer is yes, and collects the tag's ID only when it is unidentified. In this paper, we present the first study on spot scanning with a handheld reader, which aims to scan tags in the reader's interrogation range at an arbitrarily specified position in the system. Existing studies mainly focus on continuous scanning, and they are highly time inefficient in performing spot scanning. The inefficiency stems from the small overlap between tag populations in different spot scanning operations, in which case existing solutions cannot efficiently recognize unidentified tags. We develop a novel technique called LOCK to efficiently recognize unidentified tags even when the overlapped tags are few. LOCK does not simply use a tag's reply slot index but also compact short responses from tags to efficiently distinguish unidentified tags from identified ones. The valuable compact short responses are firstly investigated, which are the keys for efficient tag identification in the paper. Based on LOCK, three tag scanning protocols are proposed to solve the spot scanning problem. Simulation results show that, for spot scanning, our best protocol reduces per tag scanning time by up to 70 percent when compared with the state-of-the-art solution. Moreover, the proposed protocols can also be employed to perform continuous scanning with better time efficiency than the best existing solutions.",
LBT-Based Adaptive Channel Access for LTE-U Systems,"Driven by the demand for more radio spectrum resources, mobile operators are looking to exploit the unlicensed spectrum as a complement to the licensed spectrum. LTE-unlicensed (LTE-U), also referred to as licensed-assisted access by the third generation partnership project, is an extension of the LTE standard operating on the unlicensed spectrum. To realize LTE-U, its coexistence with Wi-Fi systems is the main challenge and must be addressed. In this paper, a listen-before-talk access mechanism featuring an adaptive distributed control function protocol is adopted for the small base stations (SBSs), whereby the backoff window size is adaptively adjusted according to the available licensed spectrum bandwidth and the Wi-Fi traffic load to satisfy the quality-of-service requirements of small cell users and minimize the collision probability of Wi-Fi users. Meanwhile, both licensed and unlicensed spectrum bands are jointly allocated to optimize spectrum efficiency. An admission control mechanism is further developed for the SBS to limit collision with Wi-Fi traffic. Extensive simulation results show that the proposed schemes achieve fair and harmonious coexistence between LTE-U small cells and the surrounding Wi-Fi service sets and substantially outperform baseline non-adaptive channel access mechanisms in the unlicensed spectrum.","IEEE 802.11 Standard,
Wireless communication,
Long Term Evolution,
Bandwidth,
Quality of service,
Electronic mail,
Throughput"
Speaker-aware training of LSTM-RNNS for acoustic modelling,"Long Short-Term Memory (LSTM) is a particular type of recurrent neural network (RNN) that can model long term temporal dynamics. Recently it has been shown that LSTM-RNNs can achieve higher recognition accuracy than deep feed-forword neural networks (DNNs) in acoustic modelling. However, speaker adaption for LSTM-RNN based acoustic models has not been well investigated. In this paper, we study the LSTM-RNN speaker-aware training that incorporates the speaker information during model training to normalise the speaker variability. We first present several speaker-aware training architectures, and then empirically evaluate three types of speaker representation: I-vectors, bottleneck speaker vectors and speaking rate. Furthermore, to factorize the variability in the acoustic signals caused by speakers and phonemes respectively, we investigate the speaker-aware and phone-aware joint training under the framework of multi-task learning. In AMI meeting speech transcription task, speaker-aware training of LSTM-RNNs reduces word error rates by 6.5% relative to a very strong LSTM-RNN baseline, which uses FMLLR features.",
On the Performance Analysis of Dual-Hop Mixed FSO/RF Systems,"This paper presents novel results for the performance analysis of dual-hop free-space optical/radio frequency (FSO/RF) transmission systems where the FSO link is modeled by the Gamma-Gamma distribution with pointing error impairments and under both heterodyne detection and intensity modulation with direct detection (IM/DD), and the RF link experiences the generalized Nakagami-
m
fading. Using amplify-and-forward fixed-gain relaying as well as channel-state-information(CSI)-assisted relaying, we derive closed-form expressions for the outage probability, the average bit-error rate (BER), and the ergodic capacity in terms of the bivariate H-Fox function. For a special case, we obtain simplified results for Nakagami-
m
fading channels in the RF link. Furthermore, new asymptotic results for the outage probability and the average BER at high signal-to-noise ratio (SNR) regime are presented in terms of simple functions. Numerical and Monte-Carlo simulation results are provided to verify the accuracy of the newly proposed results, and a perfect agreement is observed.",
Multi-Graph Matching via Affinity Optimization with Graduated Consistency Regularization,"This paper addresses the problem of matching common node correspondences among multiple graphs referring to an identical or related structure. This multi-graph matching problem involves two correlated components: i) the local pairwise matching affinity across pairs of graphs; ii) the global matching consistency that measures the uniqueness of the pairwise matchings by different composition orders. Previous studies typically either enforce the matching consistency constraints in the beginning of an iterative optimization, which may propagate matching error both over iterations and across graph pairs; or separate affinity optimization and consistency enforcement into two steps. This paper is motivated by the observation that matching consistency can serve as a regularizer in the affinity objective function especially when the function is biased due to noises or inappropriate modeling. We propose composition-based multi-graph matching methods to incorporate the two aspects by optimizing the affinity score, meanwhile gradually infusing the consistency. We also propose two mechanisms to elicit the common inliers against outliers. Compelling results on synthetic and real images show the competency of our algorithms.","Optimization,
Pattern matching,
Accuracy,
Electronic mail,
Noise,
Matrix converters,
Smoothing methods"
Oscillator-Based Reactance Sensors With Injection Locking for High-Throughput Flow Cytometry Using Microwave Dielectric Spectroscopy,"This paper presents the analysis and design of oscillator-based reactance sensors employing injection locking for high-throughput label-free single-cell analysis using dielectric spectroscopy at microwave frequencies. By injection-locking two sensing LC-oscillators with an I/Q excitation source, the measurement of the sample-induced frequency shift caused by the interaction with the electromagnetic fields is performed through phase detection with injection-strength-dependent transducer gain. Such inherent phase amplification offered by the injection locking not only relaxes the design requirement for the readout circuits but also maintains the highest rejection against common-mode errors associated with the drift of the supply voltage and the environmental parameters. To reduce flicker noise contribution, a chopping technique employing phase modulation is exploited. In addition, this paper presents a novel ping-pong chopping approach to alleviate chopping-induced dc offset. In this prototype, four sensing channels, covering frequencies between 6.5 and 30 GHz, are distributed along a microfluidic channel fabricated with standard photolithography. Measurements show that the proposed microwave capacitive sensors achieve a sub-aFrms of noise sensitivity at 100 kHz filtering bandwidth, enabling measurement throughput exceeding 1 k cells/s. The sensor prototype is implemented in 65 nm CMOS technology and consumes 65 mW at 1 V supply.","Sensors,
Electrodes,
Permittivity,
Capacitance,
Permittivity measurement,
Microwave measurement"
Analysis and Design of DC System Protection Using Z-Source Circuit Breaker,"A modified Z-source breaker topology is introduced to minimize the reflected fault current drawn from a source while retaining a common return ground path. Conventional Z-source breaker topologies do not provide steady-state overload protection and can only guard against extremely large transient faults. The Z-source breaker can be designed for considerations affecting both rate of fault current rise and absolute fault current level, analogous in some respects to a thermal-magnetic breaker. Detailed analysis and design equations are presented to provide a framework for sizing components in the Z-source breaker topology. In addition, the proposed manual tripping mechanism enables protection against both instantaneous current surges and longer-term overcurrent conditions. The fault operation intervals of the proposed Z-source breaker topologies are both demonstrated in SPICE simulation and validated in experimental characterization.","Topology,
Fault currents,
Capacitors,
Circuit faults,
Thyristors,
Inductors,
Transient analysis"
Active Balancing System for Electric Vehicles With Incorporated Low-Voltage Bus,"Electric-drive vehicles, including hybrid, plug-in hybrid, and electric vehicles, require a high-voltage (HV) battery pack for propulsion and a low-voltage (LV) dc bus for auxiliary loads. This paper presents an architecture that uses modular dc-dc bypass converters to perform active battery cell balancing and to supply current to auxiliary loads, eliminating the need for a separate HV-to-LV high step-down dc-dc converter. The modular architecture, which achieves continuous balancing of all cells, can be used with an arbitrary number of cells in series, requires no control communication between converters, and naturally shares the auxiliary load current according to the relative state-of-charge (SOC) and capacities of the battery cells. Design and control details are provided for LV low-power dual active bridge (DAB) power converters serving as the bypass converter modules. Furthermore, current sharing is examined and worst-case SOC and current deviations are derived for mismatches in cell capacities, SOCs, and parasitic resistances. Experimental results are presented for a system consisting of 21 series 25 Ah Panasonic lithium-ion NMC battery cells and 21 DAB bypass converters, with combined outputs rated to supply a 650-W auxiliary load.","Computer architecture,
Microprocessors,
Batteries,
Vehicles,
Low voltage,
Voltage control,
DC-DC power converters"
Projected Iterative Soft-Thresholding Algorithm for Tight Frames in Compressed Sensing Magnetic Resonance Imaging,"Compressed sensing (CS) has exhibited great potential for accelerating magnetic resonance imaging (MRI). In CS-MRI, we want to reconstruct a high-quality image from very few samples in a short time. In this paper, we propose a fast algorithm, called projected iterative soft-thresholding algorithm (pISTA), and its acceleration pFISTA for CS-MRI image reconstruction. The proposed algorithms exploit sparsity of the magnetic resonance (MR) images under the redundant representation of tight frames. We prove that pISTA and pFISTA converge to a minimizer of a convex function with a balanced tight frame sparsity formulation. The pFISTA introduces only one adjustable parameter, the step size, and we provide an explicit rule to set this parameter. Numerical experiment results demonstrate that pFISTA leads to faster convergence speeds than the state-of-art counterpart does, while achieving comparable reconstruction errors. Moreover, reconstruction errors incurred by pFISTA appear insensitive to the step size.","Analytical models,
Image reconstruction,
Algorithm design and analysis,
Mathematical model,
Magnetic resonance imaging,
Dictionaries"
Modeling and Analysis of Attacks and Counter Defense Mechanisms for Cyber Physical Systems,"In this paper, we develop an analytical model based on stochastic Petri nets to capture the dynamics between adversary behavior and defense for cyber physical systems. We consider several types of failures including attrition failure, pervasion failure, and exfiltration failure which can happen to a cyber physical system. Using a modernized electrical grid as an example, we illustrate the parameterization process. Our results reveal optimal design conditions, including the intrusion detection interval, and the redundancy level, under which the modernized electrical grid's mean time to failure is maximized. Further, there exists a design tradeoff between exfiltration failure, attrition failure, and pervasion failure when using redundancy to improve the overall system reliability.","Actuators,
Analytical models,
Intrusion detection,
Redundancy,
Sensor systems,
Sensor phenomena and characterization"
"Simultaneous Wireless Information and Power Transfer in K
-Tier Heterogeneous Cellular Networks","In this paper, we develop a tractable model for joint downlink (DL) and uplink (UL) transmission of K -tier heterogeneous cellular networks (HCNs) with simultaneous wireless information and power transfer (SWIPT) for efficient spectrum and energy utilization. In the DL, the mobile users (MUs) with power splitting receiver architecture decode information and harvest energy based on SWIPT. While in the UL, the MUs use the harvested energy for information transmission. Since cell association greatly affects the energy harvesting in the DL and the performance of wireless powered HCNs in the UL, we compare the DL and UL performance of a random MU in HCNs with nearest base station (NBS) cell association to that with maximum received power (MRP) cell association. We first derive the DL average received power for the MU with the NBS and the MRP cell associations. To evaluate the system performance, we then derive the outage probability and the average ergodic rate in the DL and UL of a random MU in HCNs with the NBS and MRP cell associations. Our results show that increasing the small cell base station (BS) density, the BS transmit power, the time allocation factor, and the energy conversion efficiency, weakly affects the DL and UL performance of both the cell associations. However, the UL performance of both the cell associations can be improved by increasing the fraction of the DL received power used for energy harvesting.","NIST,
Materials requirements planning,
Wireless communication,
Computer architecture,
Microprocessors,
Energy harvesting,
Interference"
"Blind Quality Assessment of Tone-Mapped Images Via Analysis of Information, Naturalness, and Structure","High dynamic range (HDR) imaging techniques have been working constantly, actively, and validly in the fault detection and disease diagnosis in the astronomical and medical fields, and currently they have also gained much more attention from digital image processing and computer vision communities. While HDR imaging devices are starting to have friendly prices, HDR display devices are still out of reach of typical consumers. Due to the limited availability of HDR display devices, in most cases tone mapping operators (TMOs) are used to convert HDR images to standard low dynamic range (LDR) images for visualization. But existing TMOs cannot work effectively for all kinds of HDR images, with their performance largely depending on brightness, contrast, and structure properties of a scene. To accurately measure and compare the performance of distinct TMOs, in this paper develop an effective and efficient no-reference objective quality metric which can automatically assess LDR images created by different TMOs without access to the original HDR images. Our model is shown to be statistically superior to recent full- and no-reference quality measures on the existing tone-mapped image database and a new relevant database built in this work.","Entropy,
Dynamic range,
Visualization,
Brightness,
Indexes"
The future of mobile cloud computing: Integrating cloudlets and Mobile Edge Computing,"Extending the coverage area of mobile cloud computing services will allow new services to be provisioned to the mobile users. The main obstacle for achieving this goal is related to the deployments challenges and limitations of the Cloudlets system. Mobile Edge Computing (MEC) system emerged recently providing an opportunity to fill the gap of the Cloudlets system by providing resources-rich computing resources with proximity to the end users. In this paper, we are proposing a hierarchical model that is composed of MEC servers and Cloudlets infrastructures. The objective of the proposed model is to increase the coverage area for the mobile users in which the users can accomplish their requested services with minimal costs in terms of power and delay. An extensive experimental evaluation is conducted showing the superiority of the proposed model.",
Machine Learning Methods for Attack Detection in the Smart Grid,"Attack detection problems in the smart grid are posed as statistical learning problems for different attack scenarios in which the measurements are observed in batch or online settings. In this approach, machine learning algorithms are used to classify measurements as being either secure or attacked. An attack detection framework is provided to exploit any available prior knowledge about the system and surmount constraints arising from the sparse structure of the problem in the proposed approach. Well-known batch and online learning algorithms (supervised and semisupervised) are employed with decision- and feature-level fusion to model the attack detection problem. The relationships between statistical and geometric properties of attack vectors employed in the attack scenarios and learning algorithms are analyzed to detect unobservable attacks using statistical learning methods. The proposed algorithms are examined on various IEEE test systems. Experimental analyses show that machine learning algorithms can detect attacks with performances higher than attack detection algorithms that employ state vector estimation methods in the proposed attack detection framework.","Vectors,
Smart grids,
Prediction algorithms,
Kernel,
Statistical learning,
Machine learning algorithms,
Learning systems"
A New Multiinput Three-Level DC/DC Converter,"Power electronics solutions based on multiple converter configurations offer cost-effective solutions by integrating a number of components at input or output power stages. This paper proposes a new multiinput isolated three-level converter for renewable and sustainable energy systems adopting high dc link voltage. Multiple dc sources are integrated to the three-level dc/dc converter before the isolation stage, resulting in reduced part-count, determining dc link voltage level and allowing flexibility in transformer design. The proposed architecture eliminates two boost switches which are present in the two-stage counterpart. The input inductors are operated in discontinuous conduction mode; thus, power can be shared between input sources through proper selection of input inductors. A low voltage prototype has been designed to serve as a proof of concept.","Inductors,
Switches,
Power generation,
Video recording,
Capacitors,
Bridge circuits,
Inductance"
Dynamic User Clustering and Power Allocation for Uplink and Downlink Non-Orthogonal Multiple Access (NOMA) Systems,"Non-orthogonal multiple access (NOMA) has recently been considered as a key enabling technique for 5G cellular systems. In NOMA, by exploiting the channel gain differences, multiple users are multiplexed into transmission power domain and then non-orthogonally scheduled for transmission on the same spectrum resources. Successive interference cancellation (SIC) is then applied at the receivers to decode the message signals. In this paper, first, we briefly describe the differences in the working principles of uplink and downlink NOMA transmissions in a cellular wireless system. Then, for both uplink and downlink NOMAs, we formulate a sum-throughput maximization problem in a cell such that the user clustering (i.e., grouping users into a single cluster or multiple clusters) and power allocations in NOMA clusters can be optimized under transmission power constraints, minimum rate requirements of the users, and SIC constraints. Due to the combinatorial nature of the formulated mixed integer non-linear programming problem, we solve the problem in two steps, i.e., by first grouping users into clusters and then optimizing their respective power allocations. In particular, we propose a low-complexity sub-optimal user grouping scheme. The proposed scheme exploits the channel gain differences among users in an NOMA cluster and groups them into a single cluster or multiple clusters in order to enhance the sum-throughput of the system. For a given set of NOMA clusters, we then derive the optimal power allocation policy that maximizes the sum-throughput per NOMA cluster and in turn maximizes the overall system throughput. Using Karush-Kuhn-Tucker optimality conditions, closed-form solutions for optimal power allocations are derived for any cluster size, considering both uplink and downlink NOMA systems. Numerical results compare the performances of NOMA and OMA and illustrate the significance of NOMA in various network scenarios.","NOMA,
Resource management,
Uplink,
Downlink,
5G mobile communication,
Multiplexing,
Silicon carbide"
A Maximum-Likelihood Channel Estimator for Self-Interference Cancelation in Full-Duplex Systems,"Operation of full-duplex systems requires efficient mitigation of the self-interference signal caused by the simultaneous transmission/reception. In this paper, we propose a maximum-likelihood (ML) approach to jointly estimate the self-interference and intended channels by exploiting its own known transmitted symbols and both the known pilot and unknown data symbols from the other intended transceiver. The ML solution is obtained by maximizing the ML function under the assumption of Gaussian received symbols. A closed-form solution is first derived, and subsequently, an iterative procedure is developed to further improve the estimation performance at moderate-to-high signal-to-noise ratios (SNRs). We establish the initial condition to guarantee the convergence of the iterative algorithm to the ML solution. In the presence of considerable phase noise from the oscillators, a phase noise estimation method is proposed and combined with the ML channel estimator to mitigate the effects of the phase noise. Illustrative results show that the proposed methods offer good cancelation performance close to the Cramer-Rao bound (CRB).","Channel estimation,
Phase noise,
Maximum likelihood estimation,
Transceivers,
Covariance matrices"
Fast Complementary Filter for Attitude Estimation Using Low-Cost MARG Sensors,"This paper proposes a novel quaternion-based attitude estimator with magnetic, angular rate, and gravity (MARG) sensor arrays. A new structure of a fixed-gain complementary filter is designed fusing related sensors. To avoid using iterative algorithms, the accelerometer-based attitude determination is transformed into a linear system. Stable solution to this system is obtained via control theory. With only one matrix multiplication, the solution can be computed. Using the increment of the solution, we design a complementary filter that fuses gyroscope and accelerometer together. The proposed filter is fast, since it is free of iteration. We name the proposed filter the fast complementary filter (FCF). To decrease significant effects of unknown magnetic distortion imposing on the magnetometer, a stepwise filtering architecture is designed. The magnetic output is fused with the estimated gravity from gyroscope and accelerometer using a second complementary filter when there is no significant magnetic distortion. Several experiments are carried out on real hardware to show the performance and some comparisons. Results show that the proposed FCF can reach the accuracy of Kalman filter. It successfully finds a balance between estimation accuracy and time consumption. Compared with iterative methods, the proposed FCF has much less convergence speed. Besides, it is shown that the magnetic distortion would not affect the estimated Euler angles.","Accelerometers,
Magnetometers,
Gyroscopes,
Estimation,
Quaternions,
Magnetic sensors"
Pareto or Non-Pareto: Bi-Criterion Evolution in Multiobjective Optimization,"It is known that Pareto dominance has its own weaknesses as the selection criterion in evolutionary multiobjective optimization. Algorithms based on Pareto criterion (PC) can suffer from problems such as slow convergence to the optimal front and inferior performance on problems with many objectives. Non-Pareto criterion (NPC), such as decomposition-based criterion and indicator-based criterion, has already shown promising results in this regard, but its high selection pressure may lead to the algorithm to prefer some specific areas of the problem's Pareto front, especially when the front is highly irregular. In this paper, we propose a bi-criterion evolution (BCE) framework of the PC and NPC, which attempts to make use of their strengths and compensates for each other's weaknesses. The proposed framework consists of two parts: PC evolution and NPC evolution. The two parts work collaboratively, with an abundant exchange of information to facilitate each other's evolution. Specifically, the NPC evolution leads the PC evolution forward and the PC evolution compensates the possible diversity loss of the NPC evolution. The proposed framework keeps the freedom on the implementation of the NPC evolution part, thus making it applicable for any non-Pareto-based algorithm. In the PC evolution, two operations, population maintenance and individual exploration, are presented. The former is to maintain a set of representative nondominated individuals and the latter is to explore some promising areas that are undeveloped (or not well-developed) in the NPC evolution. Experimental results have shown the effectiveness of the proposed framework. The BCE works well on seven groups of 42 test problems with various characteristics, including those in which Pareto-based algorithms or non-Pareto-based algorithms struggle.","Sociology,
Pareto optimization,
Search problems,
Maintenance engineering,
Convergence"
Interference-Aware Cooperative Communication in Multi-Radio Multi-Channel Wireless Networks,"There are a lot of recent interests on cooperative communication (CC) in wireless networks. Despite the large capacity gain of CC in small wireless networks with its capability of mitigating fading taking advantage of spatial diversity, cooperative communication can result in severe interference in large networks and even degraded throughput. The aim of this work is to concurrently exploit multi-radio and multi-channel (MRMC) technique and cooperative transmission technique to combat co-channel interference and improve the performance of multi-hop wireless network. Our proposed solution concurrently considers cooperative routing, channel assignment, and relay selection and takes advantage of both MRMC technique and spatial diversity in cooperative wireless networks to improve the throughput. We propose two important metrics, contention-aware channel utilization routing metric (CACU) to capture the interference cost from both direct transmission and cooperative transmission, and traffic aware channel condition metric (TACC) to evaluate the channel load condition. Based on these metrics, we propose three algorithms for interference-aware cooperative routing, local channel adjustment, and local path and relay adaptation respectively to ensure high performance communications in dynamic wireless networks. Our algorithms are designed to be fully distributed and can effectively mitigate co-channel interference and achieve cooperative diversity gain. To our best knowledge, this is the first distributed solution that supports cooperative communications in MRMC networks. Our performance studies demonstrate that our proposed algorithms can efficiently support cooperative communications in multi-radio multi-hop networks to significantly increase the aggregate throughput.",
"Secrecy Outage Performance for SIMO Underlay Cognitive Radio Systems With Generalized Selection Combining Over Nakagami-
m
Channels","This paper considers a single-input-multiple-output underlay cognitive wiretap system over Nakagami-m channels with generalized selection combining, where confidential messages transmitted from a single-antenna transmitter to a multiple-antenna legitimate receiver are overheard by a multiple-antenna eavesdropper. Passive eavesdropping scenario is considered in this work, while the channel state information of the eavesdropping channel is not available at the secondary transmitter. We derived the closed-form expression for the exact secrecy outage probability. Simulations are conducted to validate the accuracy of our proposed analytical models.","Fading channels,
Security,
Physical layer,
Diversity reception,
Receivers,
Closed-form solutions,
Transmitting antennas"
Virtual-Flux-Based Predictive Direct Power Control of Three-Phase PWM Rectifiers With Fast Dynamic Response,"This paper proposes a power predictive control (PPC) method for three-phase pulse width modulated rectifiers without a proportional-integral controller. The proposed PPC method calculates the optimized voltage vector by analyzing the relationship between the virtual flux, active power, converter voltage, and filter parameters. Thus, an overshoot does not occur and the fast and accurate power control becomes possible. The predictive algorithm computes the power error that would be produced by applying each vector and selects the one that contributes the minimum error. The simulation and experimental results prove that the proposed method provides an excellent steady-state performance and quick dynamic response.","Rectifiers,
Voltage control,
Power control,
Pulse width modulation,
Reactive power,
Predictive control,
Heuristic algorithms"
Wideband Linear-to-Circular Polarization Converters Based on Miniaturized-Element Frequency Selective Surfaces,"We introduce a new technique for designing wideband polarization converters based on miniaturized-element frequency selective surfaces (MEFSSs). The proposed structure is a two-dimensionally anisotropic periodic structure composed of arrays of subwavelength capacitive patches and inductive wire grids separated by thin dielectric substrates. The structure is designed to behave differently for field components of the two orthogonal polarizations and transmits a circularly polarized wave once illuminated by a linearly polarized plane wave. Using equivalent circuit models for MEFSSs, a synthesis procedure is developed that can be used to design the polarization converter from its required bandwidth and center frequency of operation. Using this procedure, a prototype of the proposed polarization converter operating within the X-band is designed, fabricated, and experimentally characterized using a free-space measurement system. The measurement results confirm the theoretical predictions and the design procedure of the structure and demonstrate that the proposed MEFSS-based polarization converter operates in a wide field of view of ±45° with a fractional bandwidth of 40%.","Polarization,
Frequency selective surfaces,
Wires,
Integrated circuit modeling,
Impedance,
Wideband"
Enabling Cloud Storage Auditing With Verifiable Outsourcing of Key Updates,"Key-exposure resistance has always been an important issue for in-depth cyber defence in many security applications. Recently, how to deal with the key exposure problem in the settings of cloud storage auditing has been proposed and studied. To address the challenge, existing solutions all require the client to update his secret keys in every time period, which may inevitably bring in new local burdens to the client, especially those with limited computation resources, such as mobile phones. In this paper, we focus on how to make the key updates as transparent as possible for the client and propose a new paradigm called cloud storage auditing with verifiable outsourcing of key updates. In this paradigm, key updates can be safely outsourced to some authorized party, and thus the key-update burden on the client will be kept minimal. In particular, we leverage the third party auditor (TPA) in many existing public auditing designs, let it play the role of authorized party in our case, and make it in charge of both the storage auditing and the secure key updates for key-exposure resistance. In our design, TPA only needs to hold an encrypted version of the client's secret key while doing all these burdensome tasks on behalf of the client. The client only needs to download the encrypted secret key from the TPA when uploading new files to cloud. Besides, our design also equips the client with capability to further verify the validity of the encrypted secret keys provided by the TPA. All these salient features are carefully designed to make the whole auditing procedure with key exposure resistance as transparent as possible for the client. We formalize the definition and the security model of this paradigm. The security proof and the performance simulation show that our detailed design instantiations are secure and efficient.",
A Realistic Lightweight Anonymous Authentication Protocol for Securing Real-Time Application Data Access in Wireless Sensor Networks,"User authentication in wireless sensor networks (WSN) is a critical security issue due to their unattended and hostile deployment in the field. Since the sensor nodes are equipped with limited computing power, storage, and communication modules, authenticating remote users in such resource-constrained environment is a paramount security concern. Until now, impressive efforts have been made for designing authentication schemes with user anonymity by using only the lightweight cryptographic primitives, such as symmetric key encryption/decryption and hash functions. However, to the best of our knowledge, none has succeeded so far. In this paper, we take an initial step to shed light on the rationale underlying this prominent issue. In order to do that here at first, we demonstrate that the existing solutions for anonymous user authentication in WSN are impractical. Subsequently, we propose a realistic authentication protocol for WSN, which can ensure various imperative security properties like user anonymity, untraceability, forward/backward secrecy, perfect forward secrecy, etc.",
Sentic LDA: Improving on LDA with semantic similarity for aspect-based sentiment analysis,"The advent of the Social Web has provided netizens with new tools for creating and sharing, in a time- and cost-efficient way, their contents, ideas, and opinions with virtually the millions of people connected to the World Wide Web. This huge amount of information, however, is mainly unstructured as specifically produced for human consumption and, hence, it is not directly machine-processable. In order to enable a more efficient passage from unstructured information to structured data, aspect-based opinion mining models the relations between opinion targets contained in a document and the polarity values associated with these. Because aspects are often implicit, however, spotting them and calculating their respective polarity is an extremely difficult task, which is closer to natural language understanding rather than natural language processing. To this end, Sentic LDA exploits common-sense reasoning to shift LDA clustering from a syntactic to a semantic level. Rather than looking at word co-occurrence frequencies, Sentic LDA leverages on the semantics associated with words and multi-word expressions to improve clustering and, hence, outperform state-of-the-art techniques for aspect extraction.","Semantics,
Sentiment analysis,
Clustering algorithms,
Vocabulary,
Companies,
Electronic mail"
UAV-Assisted Heterogeneous Networks for Capacity Enhancement,"Modern day wireless networks have tremendously evolved driven by a sharp increase in user demands, continuously requesting more data and services. This puts significant strain on infrastructure-based macro cellular networks due to the inefficiency in handling these traffic demands, cost effectively. A viable solution is the use of unmanned aerial vehicles (UAVs) as intermediate aerial nodes between the macro and small cell tiers for improving coverage and boosting capacity. This letter investigates the problem of user-demand-based UAV assignment over geographical areas subject to high traffic demands. A neural-based cost function approach is formulated, in which UAVs are matched to a particular geographical area. It is shown that leveraging multiple UAVs not only provides long-range connectivity but also better load balancing and traffic offload. Simulation study demonstrates that the proposed approach yields significant improvements in terms of fifth percentile spectral efficiency up to 38% and reduced delays up to 37.5% compared with a ground-based network baseline without UAVs.","Cost function,
Delays,
Load modeling,
Computational modeling,
Density functional theory,
Interference,
Base stations"
FluidNet: A Flexible Cloud-Based Radio Access Network for Small Cells,"Cloud-based radio access networks (C-RAN) have been proposed as a cost-efficient way of deploying small cells. Unlike conventional RANs, a C-RAN decouples the baseband processing unit (BBU) from the remote radio head (RRH), allowing for centralized operation of BBUs and scalable deployment of light-weight RRHs as small cells. In this work, we argue that the intelligent configuration of the front-haul network between the BBUs and RRHs, is essential in delivering the performance and energy benefits to the RAN and the BBU pool, respectively. We propose FluidNet-a scalable, light-weight framework for realizing the full potential of C-RAN. FluidNet deploys a logically re-configurable front-haul to apply appropriate transmission strategies in different parts of the network and hence cater effectively to both heterogeneous user profiles and dynamic traffic load patterns. FluidNet's algorithms determine configurations that maximize the traffic demand satisfied on the RAN, while simultaneously optimizing the compute resource usage in the BBU pool. We prototype FluidNet on a 6 BBU, 6 RRH WiMAX C-RAN testbed. Prototype evaluations and large-scale simulations reveal that FluidNet's ability to re-configure its front-haul and tailor transmission strategies provides a 50% improvement in satisfying traffic demands, while reducing the compute resource usage in the BBU pool by 50% compared to baseline schemes.","Interference,
Macrocell networks,
WiMAX,
Multiplexing,
Prototypes"
Undirected Rigid Formations Are Problematic,"In a recent paper, a systematic method was proposed for devising gradient control laws for asymptotically stabilizing a large class of rigid, undirected formations in two-dimensional space assuming all agents are described by kinematic point models. The aim of this paper is to explain what happens to such formations if neighboring agents have slightly different understandings of what the desired distance between them is supposed to be. What one would expect would be a gradual distortion of the formation from its target shape as discrepancies in desired distances increase. While this is observed for the gradient laws in question, something else quite unexpected happens at the same time. It is shown for any rigidity-based, undirected formation of this type which is comprised of three or more agents, that if some neighboring agents have slightly different understandings of what the desired distances between them are supposed to be, then almost for certain, the trajectory of the resulting distorted but rigid formation will converge exponentially fast to a closed circular orbit in two-dimensional space which is traversed periodically at a constant angular speed.",
CloudArmor: Supporting Reputation-Based Trust Management for Cloud Services,"Trust management is one of the most challenging issues for the adoption and growth of cloud computing. The highly dynamic, distributed, and non-transparent nature of cloud services introduces several challenging issues such as privacy, security, and availability. Preserving consumers' privacy is not an easy task due to the sensitive information involved in the interactions between consumers and the trust management service. Protecting cloud services against their malicious users (e.g., such users might give misleading feedback to disadvantage a particular cloud service) is a difficult problem. Guaranteeing the availability of the trust management service is another significant challenge because of the dynamic nature of cloud environments. In this article, we describe the design and implementation of CloudArmor, a reputation-based trust management framework that provides a set of functionalities to deliver trust as a service (TaaS), which includes i) a novel protocol to prove the credibility of trust feedbacks and preserve users' privacy, ii) an adaptive and robust credibility model for measuring the credibility of trust feedbacks to protect cloud services from malicious users and to compare the trustworthiness of cloud services, and iii) an availability model to manage the availability of the decentralized implementation of the trust management service. The feasibility and benefits of our approach have been validated by a prototype and experimental studies using a collection of real-world trust feedbacks on cloud services.","Privacy,
Availability,
Cloud computing,
Adaptation models,
Measurement,
Protocols,
Educational institutions"
Efficient Implementation of NIST-Compliant Elliptic Curve Cryptography for 8-bit AVR-Based Sensor Nodes,"In this paper, we introduce a highly optimized software implementation of standards-compliant elliptic curve cryptography (ECC) for wireless sensor nodes equipped with an 8-bit AVR microcontroller. We exploit the state-of-the-art optimizations and propose novel techniques to further push the performance envelope of a scalar multiplication on the NIST P-192 curve. To illustrate the performance of our ECC software, we develope the prototype implementations of different cryptographic schemes for securing communication in a wireless sensor network, including elliptic curve Diffie-Hellman (ECDH) key exchange, the elliptic curve digital signature algorithm (ECDSA), and the elliptic curve Menezes-Qu-Vanstone (ECMQV) protocol. We obtain record-setting execution times for fixed-base, point variable-base, and double-base scalar multiplication. Compared with the related work, our ECDH key exchange achieves a performance gain of roughly 27% over the best previously published result using the NIST P-192 curve on the same platform, while our ECDSA performs twice as fast as the ECDSA implementation of the well-known TinyECC library. We also evaluate the impact of Karatsuba's multiplication technique on the overall execution time of a scalar multiplication. In addition to offering high performance, our implementation of scalar multiplication has a highly regular execution profile, which helps to protect against certain side-channel attacks. Our results show that NIST-compliant ECC can be implemented efficiently enough to be suitable for resource-constrained sensor nodes.","Wireless sensor networks,
Elliptic curve cryptography,
NIST,
Microcontrollers,
Clocks,
Registers,
Software"
Energy-Efficient Resource Allocation for Downlink Non-Orthogonal Multiple Access Network,"Non-orthogonal multiple access (NOMA) is a promising technique for the fifth generation mobile communication due to its high spectral efficiency. By applying superposition coding and successive interference cancellation techniques at the receiver, multiple users can be multiplexed on the same subchannel in NOMA systems. Previous works focus on subchannel assignment and power allocation to achieve the maximization of sum rate; however, the energy-efficient resource allocation problem has not been well studied for NOMA systems. In this paper, we aim to optimize subchannel assignment and power allocation to maximize the energy efficiency for the downlink NOMA network. Assuming perfect knowledge of the channel state information at base station, we propose a low-complexity suboptimal algorithm, which includes energy-efficient subchannel assignment and power proportional factors determination for subchannel multiplexed users. We also propose a novel power allocation across subchannels to further maximize energy efficiency. Since both optimization problems are non-convex, difference of convex programming is used to transform and approximate the original non-convex problems to convex optimization problems. Solutions to the resulting optimization problems can be obtained by solving the convex sub-problems iteratively. Simulation results show that the NOMA system equipped with the proposed algorithms yields much better sum rate and energy efficiency performance than the conventional orthogonal frequency division multiple access scheme.","NOMA,
Resource management,
Downlink,
Mobile communication,
Silicon carbide,
Receivers,
Multiplexing"
Emerging Security Mechanisms for Medical Cyber Physical Systems,"The following decade will witness a surge in remote health-monitoring systems that are based on body-worn monitoring devices. These Medical Cyber Physical Systems (MCPS) will be capable of transmitting the acquired data to a private or public cloud for storage and processing. Machine learning algorithms running in the cloud and processing this data can provide decision support to healthcare professionals. There is no doubt that the security and privacy of the medical data is one of the most important concerns in designing an MCPS. In this paper, we depict the general architecture of an MCPS consisting of four layers: data acquisition, data aggregation, cloud processing, and action. Due to the differences in hardware and communication capabilities of each layer, different encryption schemes must be used to guarantee data privacy within that layer. We survey conventional and emerging encryption schemes based on their ability to provide secure storage, data sharing, and secure computation. Our detailed experimental evaluation of each scheme shows that while the emerging encryption schemes enable exciting new features such as secure sharing and secure computation, they introduce several orders-of-magnitude computational and storage overhead. We conclude our paper by outlining future research directions to improve the usability of the emerging encryption schemes in an MCPS.","Encryption,
Cloud computing,
Monitoring,
Medical services,
Elliptic curve cryptography"
"Performance Analysis of Physical Layer Security Over Generalized-
K
Fading Channels Using a Mixture Gamma Distribution","In this letter, the secrecy performance of the classic Wyner's wiretap model over generalized-K fading channels is studied. The closed-form expressions for the average secrecy capacity, secure outage probability, and the probability of strictly positive secrecy capacity are derived. The new expressions provide a unified form, which can handle several of the well-known composite fading environments as special or limiting cases. Monte-Carlo simulations are performed to verify the proposed analysis models.","Fading,
Security,
Analytical models,
Capacity planning,
Signal to noise ratio,
Physical layer,
Performance analysis"
HCP: A Flexible CNN Framework for Multi-Label Image Classification,"Convolutional Neural Network (CNN) has demonstrated promising performance in single-label image classification tasks. However, how CNN best copes with multi-label images still remains an open problem, mainly due to the complex underlying object layouts and insufficient multi-label training images. In this work, we propose a flexible deep CNN infrastructure, called Hypotheses-CNN-Pooling (HCP), where an arbitrary number of object segment hypotheses are taken as the inputs, then a shared CNN is connected with each hypothesis, and finally the CNN output results from different hypotheses are aggregated with max pooling to produce the ultimate multi-label predictions. Some unique characteristics of this flexible deep CNN infrastructure include: 1) no ground-truth bounding box information is required for training; 2) the whole HCP infrastructure is robust to possibly noisy and/or redundant hypotheses; 3) the shared CNN is flexible and can be well pre-trained with a large-scale single-label image dataset, e.g., ImageNet; and 4) it may naturally output multi-label prediction results. Experimental results on Pascal VOC 2007 and VOC 2012 multi-label image datasets well demonstrate the superiority of the proposed HCP infrastructure over other state-of-the-arts. In particular, the mAP reaches 90.5% by HCP only and 93.2% after the fusion with our complementary result in [12] based on hand-crafted features on the VOC 2012 dataset.","Training,
Noise measurement,
Neural networks,
Image edge detection,
Robustness,
Fuses,
Predictive models"
An Incremental-and-Static-Combined Scheme for Matrix-Factorization-Based Collaborative Filtering,"Collaborative filtering (CF)-based recommenders are achieved by matrix factorization (MF) to obtain high prediction accuracy and scalability. Most current MF-based models, however, are static ones that cannot adapt to incremental user feedbacks. This work aims to develop a general, incremental- and-static-combined scheme for MF-based CF to obtain highly accurate and computationally affordable incremental recommenders. With it, a recommender is designed to consist of two components, i.e., a static one built on static rating data, and an incremental one built on a sub-matrix related to rating-variations only. Highly reliable predictions are thus generated by fusing their results. The experiments on large industrial datasets show that desired accuracy and acceptable computational complexity are achieved by the resulting recommender with the proposed scheme.","Training,
Accuracy,
Adaptation models,
Computational modeling,
Vectors,
Scalability,
Predictive models"
A Systematic Approach to Modeling Impedances and Current Distribution in Planar Magnetics,"Planar magnetic components using printed circuit board (pcb) windings are attractive due to their high repeatability, good thermal performance, and usefulness for realizing intricate winding patterns. To enable higher system integration at high switching frequency, more sophisticated methods that can rapidly and accurately model planar magnetics are needed. This paper develops a systematic approach to modeling impedances and current distribution in planar magnetics based on a lumped circuit model named as the modular layer model (MLM). Stacked pcb layers are modeled as repeating modular impedance networks, with additional modular impedances representing the magnetic core, air gaps, and vias. The model captures skin and proximity effects, and enables accurate predictions of impedances, losses, stored reactive energy, and current sharing among windings. The MLM can be used to simulate circuits incorporating planar magnetics, to visualize the electromagnetic fields, and to extract parameters for magnetic models by simulations, among many other applications. The modeling results are checked with results of previous theories and finite-element-modeling approaches, with good matching presented. A group of planar magnetic devices, including transformers and inductors with various winding patterns, are prototyped, and measured to validate the proposed approach and clarify the boundaries of its applicability.","Integrated circuit modeling,
Magnetics,
Windings,
Impedance,
Surface impedance,
Mathematical model"
End-to-End Reliability-Aware Scheduling for Wireless Sensor Networks,"Wireless sensor networks (WSNs) are gaining popularity as a flexible and economical alternative to field-bus installations for monitoring and control applications. For mission-critical applications, communication networks must provide end-to-end reliability guarantees, posing substantial challenges for WSN. Reliability can be improved by redundancy, and is often addressed on the MAC layer by resubmission of lost packets, usually applying slotted scheduling. Recently, researchers have proposed a strategy to optimally improve the reliability of a given schedule by repeating the most rewarding slots in a schedule incrementally until a deadline. This Incrementer can be used with most scheduling algorithms but has scalability issues which narrows its usability to offline calculations of schedules, for networks that are rather static. In this paper, we introduce SchedEx, a generic heuristic scheduling algorithm extension, which guarantees a user-defined end-to-end reliability. SchedEx produces competitive schedules to the existing approach, and it does that consistently more than an order of magnitude faster. The harsher the end-to-end reliability demand of the network, the better the SchedEx performs compared to the Incrementer. We further show that SchedEx has a more evenly distributed improvement impact on the scheduling algorithms, whereas the Incrementer favors schedules created by certain scheduling algorithms.","Reliability,
Schedules,
Job shop scheduling,
Wireless sensor networks,
Scheduling algorithms,
Routing,
Transceivers"
An Adaptive Network-Based Reinforcement Learning Method for MPPT Control of PMSG Wind Energy Conversion Systems,"This paper proposes an artificial neural network (ANN)-based reinforcement learning (RL) maximum power point tracking (MPPT) algorithm for permanent-magnet synchronous generator (PMSG)-based variable-speed wind energy conversion systems (WECSs). The proposed MPPT algorithm first learns the optimal relationship between the rotor speed and electrical power of the PMSG through a combination of the ANNs and the Q-learning method. The MPPT algorithm is switched from the online RL to the optimal relation-based online MPPT when the maximum power point is learned. The proposed online learning algorithm enables the WECS to behave like an intelligent agent with memory to learn from its own experience, thus improving the learning efficiency. The online RL process can be reactivated any time when the actual optimal relationship deviates from the learned one due to the aging of the system or a change in the environment. Simulation and experimental results are provided to validate the proposed ANN-based RL MPPT control algorithm for a 5-MW PMSG-based WECS and a small emulated PMSG-based WECS, respectively.",
C-Brain: A deep learning accelerator that tames the diversity of CNNs through adaptive data-level parallelization,"Convolutional neural networks (CNN) accelerators have been proposed as an efficient hardware solution for deep learning based applications, which are known to be both compute-and-memory intensive. Although the most advanced CNN accelerators can deliver high computational throughput, the performance is highly unstable. Once changed to accommodate a new network with different parameters like layers and kernel size, the fixed hardware structure, may no longer well match the data flows. Consequently, the accelerator will fail to deliver high performance due to the underutilization of either logic resource or memory bandwidth. To overcome this problem, we proposed a novel deep learning accelerator, which offers multiple types of data-level parallelism: inter-kernel, intra-kernel and hybrid. Our design can adaptively switch among the three types of parallelism and the corresponding data tiling schemes to dynamically match different networks or even different layers of a single network. No matter how we change the hardware configurations or network types, the proposed network mapping strategy ensures the optimal performance and energy-efficiency. Compared with previous state-of-the-art NN accelerators, it is possible to achieve a speedup of 4.0x-8.3x for some layers of the well-known large scale CNNs. For the whole phase of network forward-propagation, our design achieves 28.04% PE energy saving, 90.3% on-chip memory energy saving on average.","Kernel,
Parallel processing,
Artificial neural networks,
Hardware,
Machine learning,
Convolution,
Tin"
An Improved Circulating Current Injection Method for Modular Multilevel Converters in Variable-Speed Drives,"Modular multilevel converters (MMC) represent an interesting and emerging topology in medium-voltage motor drive applications. The main challenge of using such a topology in variable-speed drives is the large voltage ripple of submodule capacitors at low speed with constant torque. In this paper, an improved circulating current injection method is proposed, which does not completely eliminate the capacitor voltage ripple, but maintains it bounded within reasonable values. As a result, magnitude of injected circulating current is reduced, leading to converter efficiency improvement and reduction of semiconductor current ratings. Dimensioning of submodule capacitance is also discussed, which is an important consideration when designing the MMCs in variable-speed drives. The proposed method has been successfully validated by simulation and experimental results.","Capacitors,
Converters,
Capacitance,
Harmonic analysis,
Modulation,
Variable speed drives,
Topology"
Vehicular Communications for 5G Cooperative Small-Cell Networks,"Cooperative transmission is an effective approach for vehicular communications to improve wireless transmission capacity and reliability in fifth-generation (5G) small-cell networks. Based on distances between the vehicle and cooperative small-cell base stations (BSs), the cooperative probability and the coverage probability have been derived for 5G cooperative small-cell networks where small-cell BSs follow Poisson point process distributions. Furthermore, the vehicular handoff rate and the vehicular overhead ratio have been proposed to evaluate the vehicular mobility performance in 5G cooperative small-cell networks. To balance the vehicular communication capacity and the vehicular handoff ratio, an optimal vehicular overhead ratio can be achieved by adjusting the cooperative threshold of 5G cooperative small-cell networks.",
Consensus-ADMM for General Quadratically Constrained Quadratic Programming,"Nonconvex quadratically constrained quadratic programming (QCQP) problems have numerous applications in signal processing, machine learning, and wireless communications, albeit the general QCQP is NP-hard, and several interesting special cases are NP-hard as well. This paper proposes a new algorithm for general QCQP. The problem is first reformulated in consensus optimization form, to which the alternating direction method of multipliers can be applied. The reformulation is done in such a way that each of the subproblems is a QCQP with only one constraint (QCQP-1), which is efficiently solvable irrespective of (non)convexity. The core components are carefully designed to make the overall algorithm more scalable, including efficient methods for solving QCQP-1, memory efficient implementation, parallel/distributed implementation, and smart initialization. The proposed algorithm is then tested in two applications: multicast beamforming and phase retrieval. The results indicate superior performance over prior state-of-the-art methods.",
IR-UWB-Based Non-Line-of-Sight Identification in Harsh Environments: Principles and Challenges,"Impulse radio ultrawideband ranging has recently received significant attention due to the high accuracy it can achieve. Although most research efforts have focused on ranging in indoor and outdoor environments, other environments such as harsh industrial environments introduce unique challenges. This paper discusses the impact of propagation characteristics of harsh industrial environments on ranging accuracy, and also discusses principles and challenges of non-line-of-sight identification in industrial scenarios. To illustrate these challenges, a measurement campaign using 802.15.4a radios was conducted in a Heavy Machines Laboratory. The results show that the non-line-of-sight condition can be accurately identified if adequate models for such an environment are used.","Distance measurement,
IEEE 802.11 Standard,
Wireless communication,
Delays,
IEEE 802.15 Standard,
Machinery"
GenePrint: Generic and Accurate Physical-Layer Identification for UHF RFID Tags,"Physical-layer identification utilizes unique features of wireless devices as their fingerprints, providing authenticity and security guarantee. Prior physical-layer identification techniques on radio frequency identification (RFID) tags require nongeneric equipments and are not fully compatible with existing standards. In this paper, we propose a novel physical-layer identification system, GenePrint, for UHF passive tags. The GenePrint prototype system is implemented by a commercial reader, a USRP-based monitor, and off-the-shelf UHF passive tags. Our solution is generic and completely compatible with the existing standard, EPCglobal C1G2 specification. GenePrint leverages the internal similarity among pulses of tags' RN16 preamble signals to extract a hardware feature as the fingerprint. We conduct extensive experiments on over 10 000 RN16 preamble signals from 150 off-the-shelf RFID tags. The results show that GenePrint achieves a high identification accuracy of 99.68% +. The feature extraction of GenePrint is resilient to various malicious attacks, such as the feature replay attack.",
SemanticSLAM: Using Environment Landmarks for Unsupervised Indoor Localization,"Indoor localization using mobile sensors has gained momentum lately. Most of the current systems rely on an extensive calibration step to achieve high accuracy. We propose SemanticSLAM, a novel unsupervised indoor localization scheme that bypasses the need for war-driving. SemanticSLAM leverages the idea that certain locations in an indoor environment have a unique signature on one or more phone sensors. Climbing stairs, for example, has a distinct pattern on the phone's accelerometer; a specific spot may experience an unusual magnetic interference while another may have a unique set of Wi-Fi access points covering it. SemanticSLAM uses these unique points in the environment as landmarks and combines them with dead-reckoning in a new Simultaneous Localization And Mapping (SLAM) framework to reduce both the localization error and convergence time. In particular, the phone inertial sensors are used to keep track of the user's path, while the observed landmarks are used to compensate for the accumulation of error in a unified probabilistic framework. Evaluation in two testbeds on Android phones shows that the system can achieve 0.53 meters human median localization errors. In addition, the system can detect the location of landmarks with 0.83 meters median error. This is 62 percent better than a system that does not use SLAM. Moreover, SemanticSLAM has a 33 percent lower convergence time compared to the same systems. This highlights the promise of SemanticSLAM as an unconventional approach for indoor localization.","Elevators,
Simultaneous localization and mapping,
Legged locomotion,
Acceleration,
Mobile computing"
Globally Asymptotic Stability Analysis for Genetic Regulatory Networks with Mixed Delays: An M-Matrix-Based Approach,"This paper deals with the problem of globally asymptotic stability for nonnegative equilibrium points of genetic regulatory networks (GRNs) with mixed delays (i.e., time-varying discrete delays and constant distributed delays). Up to now, all existing stability criteria for equilibrium points of the kind of considered GRNs are in the form of the linear matrix inequalities (LMIs). In this paper, the Brouwer's fixed point theorem is employed to obtain sufficient conditions such that the kind of GRNs under consideration here has at least one nonnegative equilibrium point. Then, by using the nonsingular M-matrix theory and the functional differential equation theory, M-matrix-based sufficient conditions are proposed to guarantee that the kind of GRNs under consideration here has a unique nonnegative equilibrium point which is globally asymptotically stable. The M-matrix-based sufficient conditions derived here are to check whether a constant matrix is a nonsingular M-matrix, which can be easily verified, as there are many equivalent statements on the nonsingular M-matrices. So, in terms of computational complexity, the M-matrix-based stability criteria established in this paper are superior to the LMI-based ones in literature. To illustrate the effectiveness of the approach proposed in this paper, several numerical examples and their simulations are given.","Delays,
Stability criteria,
Mathematical model,
Bioinformatics,
Proteins,
Computational biology"
A Comparison of the SEU Response of Planar and FinFET D Flip-Flops at Advanced Technology Nodes,"Heavy-ion experimental results were used to characterize single-event upset trends in 16 nm bulk FinFET, 20 nm bulk planar, and 28 nm bulk planar D flip-flops. Experimental data show that 16 nm bulk FinFET flip-flops have considerably lower SEU cross sections than their sub-32 nm planar counterparts for linear energy transfer (LET) less than 10 MeV-cm2/mg. However, FinFET SEU cross section improvement compared to the planar technologies is weak for high LET particles. Three-dimensional technology computer-aided design simulations are used to investigate charge collection mechanisms and single-event transient (SET) pulse widths at these advanced fabrication nodes. Simulation results show that SETs follow conventional scaling trends, which are that SET pulse widths reduce with technology scaling.","FinFETs,
Solid modeling,
Three-dimensional displays,
Integrated circuit modeling,
Single event upsets,
Logic gates"
Privacy-Preserving Vehicular Communication Authentication with Hierarchical Aggregation and Fast Response,"Existing secure and privacy-preserving schemes for vehicular communications in vehicular ad hoc networks face some challenges, e.g., reducing the dependence on ideal tamper-proof devices, building efficient member revocation mechanisms and avoiding computation and communication bottlenecks. To cope with those challenges, we propose a highly efficient secure and privacy-preserving scheme based on identity-based aggregate signatures. Our scheme enables hierarchical aggregation and batch verification. The individual identity-based signatures generated by different vehicles can be aggregated and verified in a batch. The aggregated signatures can be re-aggregated by a message collector (e.g., traffic management authority). With our hierarchical aggregation technique, we significantly reduce the transmission/storage overhead of the vehicles and other parties. Furthermore, existing batch verification based schemes in vehicular ad hoc networks require vehicles to wait for enough messages to perform a batch verification. In contrast, we assume that vehicles will generate messages (and the corresponding signatures) in certain time spans, so that vehicles only need to wait for a very short period before they can start the batch verification procedure. Simulation shows that a vehicle can verify the received messages with very low latency and fast response.","Vehicles,
Protocols,
Aggregates,
Privacy,
Security,
Generators,
Vehicular ad hoc networks"
Mobile Cloud Computing Model and Big Data Analysis for Healthcare Applications,"Mobile devices are increasingly becoming an indispensable part of people's daily life, facilitating to perform a variety of useful tasks. Mobile cloud computing integrates mobile and cloud computing to expand their capabilities and benefits and overcomes their limitations, such as limited memory, CPU power, and battery life. Big data analytics technologies enable extracting value from data having four Vs: volume, variety, velocity, and veracity. This paper discusses networked healthcare and the role of mobile cloud computing and big data analytics in its enablement. The motivation and development of networked healthcare applications and systems is presented along with the adoption of cloud computing in healthcare. A cloudlet-based mobile cloud-computing infrastructure to be used for healthcare big data applications is described. The techniques, tools, and applications of big data analytics are reviewed. Conclusions are drawn concerning the design of networked healthcare systems using big data and mobile cloud-computing technologies. An outlook on networked healthcare is given.","Cloud computing,
Medical services,
Mobile communication,
Mobile handsets,
Big data,
Mobile computing,
Computational modeling"
Localized Multifeature Metric Learning for Image-Set-Based Face Recognition,"This paper presents a new approach to image-set-based face recognition, where each training and testing example is a set of face images captured from varying poses, illuminations, expressions, and resolutions. While a number of image set based face recognition methods have been proposed in recent years, most of them model each face image set as a single linear subspace or as the union of linear subspaces, which may lose some discriminative information for face image set representation. To address this shortcoming, we propose exploiting statistics information as feature representations for face image sets and develop a localized multikernel metric learning algorithm to effectively combine different statistics for recognition. Moreover, we propose a localized multikernel multimetric learning method to jointly learn multiple feature-specific distance metrics in the kernel spaces, one for each statistic feature, to better exploit complementary information for recognition. Our methods achieve state-of-the-art performance on four widely used video face datasets including the Honda, MoBo, YouTube Celebrities, and YouTube Face datasets.","Measurement,
Face,
Kernel,
Face recognition,
Feature extraction,
Vectors,
Training"
"Multimodal BCIs: Target Detection, Multidimensional Control, and Awareness Evaluation in Patients With Disorder of Consciousness","Despite rapid advances in the study of brain-computer interfaces (BCIs) in recent decades, two fundamental challenges, namely, improvement of target detection performance and multidimensional control, continue to be major barriers for further development and applications. In this paper, we review the recent progress in multimodal BCIs (also called hybrid BCIs), which may provide potential solutions for addressing these challenges. In particular, improved target detection can be achieved by developing multimodal BCIs that utilize multiple brain patterns, multimodal signals, or multisensory stimuli. Furthermore, multidimensional object control can be accomplished by generating multiple control signals from different brain patterns or signal modalities. Here, we highlight several representative multimodal BCI systems by analyzing their paradigm designs, detection/control methods, and experimental results. To demonstrate their practicality, we report several initial clinical applications of these multimodal BCI systems, including awareness evaluation/detection in patients with disorder of consciousness (DOC). As an evolving research area, the study of multimodal BCIs is increasingly requiring more synergetic efforts from multiple disciplines for the exploration of the underlying brain mechanisms, the design of new effective paradigms and means of neurofeedback, and the expansion of the clinical applications of these systems.","Object detection,
Electroencephalography,
Wheelchairs,
Biomedical signal processing,
Electromyography,
Graphical user interfaces"
Incorporating Objective Function Information Into the Feasibility Rule for Constrained Evolutionary Optimization,"When solving constrained optimization problems by evolutionary algorithms, an important issue is how to balance constraints and objective function. This paper presents a new method to address the above issue. In our method, after generating an offspring for each parent in the population by making use of differential evolution (DE), the well-known feasibility rule is used to compare the offspring and its parent. Since the feasibility rule prefers constraints to objective function, the objective function information has been exploited as follows: if the offspring cannot survive into the next generation and if the objective function value of the offspring is better than that of the parent, then the offspring is stored into a predefined archive. Subsequently, the individuals in the archive are used to replace some individuals in the population according to a replacement mechanism. Moreover, a mutation strategy is proposed to help the population jump out of a local optimum in the infeasible region. Note that, in the replacement mechanism and the mutation strategy, the comparison of individuals is based on objective function. In addition, the information of objective function has also been utilized to generate offspring in DE. By the above processes, this paper achieves an effective balance between constraints and objective function in constrained evolutionary optimization. The performance of our method has been tested on two sets of benchmark test functions, namely, 24 test functions at IEEE CEC2006 and 18 test functions with 10-D and 30-D at IEEE CEC2010. The experimental results have demonstrated that our method shows better or at least competitive performance against other state-of-the-art methods. Furthermore, the advantage of our method increases with the increase of the number of decision variables.","Linear programming,
Optimization,
Sociology,
Statistics,
Evolutionary computation,
Cybernetics,
Next generation networking"
Hybrid Pulsewidth Modulated Single-Phase Quasi-Z-Source Grid-Tie Photovoltaic Power System,"A hybrid pulsewidth modulated single-phase quasi-Z-source grid-tie photovoltaic (PV) power system is proposed. The hybrid pulse-width modulation (HPWM) combines the pulse-width modulation (PWM) and the pulse-amplitude modulation (PAM). The PWM works when the ac output voltage is lower than the dc source voltage; otherwise, the PAM operates the single-phase quasi-Z-source inverter (qZSI). The HPWM leads to the reduction of power loss, and the quasi-Z-source capacitance and inductance. An effective control strategy is proposed for the new PV power system to manage the maximum power point tracking (MPPT) of PV panel, grid-tie power injection, and dc-link voltage. A grid-tie current controller, combining a repetitive controller and a proportional-resonant regulator, achieves strong harmonic suppression, fast dynamic, and zero tracking error. A 500-W prototype is built to verify the new system. Power loss estimation and impedance design are detailed. Experimental tests validate the HPWM, new PV power system with higher efficiency, and the related control method.","Pulse width modulation,
Power systems,
Switches,
Inverters,
Capacitance,
Capacitors"
Online Multi-Modal Distance Metric Learning with Application to Image Retrieval,"Distance metric learning (DML) is an important technique to improve similarity search in content-based image retrieval. Despite being studied extensively, most existing DML approaches typically adopt a single-modal learning framework that learns the distance metric on either a single feature type or a combined feature space where multiple types of features are simply concatenated. Such single-modal DML methods suffer from some critical limitations: (i) some type of features may significantly dominate the others in the DML task due to diverse feature representations; and (ii) learning a distance metric on the combined high-dimensional feature space can be extremely time-consuming using the naive feature concatenation approach. To address these limitations, in this paper, we investigate a novel scheme of online multi-modal distance metric learning (OMDML), which explores a unified two-level online learning scheme: (i) it learns to optimize a distance metric on each individual feature space; and (ii) then it learns to find the optimal combination of diverse types of features. To further reduce the expensive cost of DML on high-dimensional feature space, we propose a low-rank OMDML algorithm which not only significantly reduces the computational cost but also retains highly competing or even better learning accuracy. We conduct extensive experiments to evaluate the performance of the proposed algorithms for multi-modal image retrieval, in which encouraging results validate the effectiveness of the proposed technique.",
Protection of Big Data Privacy,"In recent years, big data have become a hot research topic. The increasing amount of big data also increases the chance of breaching the privacy of individuals. Since big data require high computational power and large storage, distributed systems are used. As multiple parties are involved in these systems, the risk of privacy violation is increased. There have been a number of privacy-preserving mechanisms developed for privacy protection at different stages (e.g., data generation, data storage, and data processing) of a big data life cycle. The goal of this paper is to provide a comprehensive overview of the privacy preservation mechanisms in big data and present the challenges for existing mechanisms. In particular, in this paper, we illustrate the infrastructure of big data and the state-of-the-art privacy-preserving mechanisms in each stage of the big data life cycle. Furthermore, we discuss the challenges and future research directions related to privacy preservation in big data.","Big data,
Cloud computing,
Data privacy,
Memory management,
Privacy"
Capacitive Biopotential Measurement for Electrophysiological Signal Acquisition: A Review,"A conventional clinical biopotential measurement system requires the use of wet electrodes that are in contact with skin using conductive gel. Those systems can acquire high-quality signals but may not be feasible for a long-term purpose due to the skin irritation and allergic contact dermatitis. The emerging of human-centered monitoring calls for alternative solutions. Recent technological advances enable capacitive measurement of electrophysiological measurement, which can acquire signals through cloth or even with an air gap; however, difficulties still exist. This paper systemically reviews the recent progress in capacitive measurement from electrode design, analog front end to high-level system architecture, aiming to provide comprehensive and practical instructions for entire system design. The current development serves as the solid fundamental, raising new solutions for future improvement. In addition, the challenges and the strategies are highlighted in order to demonstrate a technical guide. Some perspectives based on our experience are also discussed hoping to inspire new idea and technique in this area.","Electrodes,
Monitoring,
Wireless communication,
Electrocardiography,
Impedance,
Sensors,
Systems architecture"
"Curvature, Torsion, and Force Sensing in Continuum Robots Using Helically Wrapped FBG Sensors","Due to their small size and flexibility, fiber Bragg grating (FBG) sensors have been integrated into needle-sized continuum robots for shape estimation and force measurement. The challenge in extending previous shape and force sensing technologies to pre-curved continuum robots, such as concentric-tube robots, is that torsion information is essential for accurate shape estimation, and the force-strain relationship is nonlinear. In this letter, a novel helically wrapped FBG sensor design and corresponding force-curvature-strain model are developed to provide simultaneous curvature, torsion, and force measurement. To validate this design and modeling technique, two sensorized Nitinol tubes were fabricated and tested in an experimental setup. The results showed that accurate and sensitive curvature, torsion, and force measurements can be obtained at a 100 Hz sampling rate.","Robot sensing systems,
Strain,
Fiber gratings,
Force"
Reversible data hiding: Advances in the past two decades,"In the past two decades, reversible data hiding (RDH), also referred to as lossless or invertible data hiding, has gradually become a very active research area in the field of data hiding. This has been verified by more and more papers on increasingly wide-spread subjects in the field of RDH research that have been published these days. In this paper, the various RDH algorithms and researches have been classified into the following six categories: 1) RDH into image spatial domain; 2) RDH into image compressed domain (e.g., JPEG); 3) RDH suitable for image semi-fragile authentication; 4) RDH with image contrast enhancement; 5) RDH into encrypted images, which is expected to have wide application in the cloud computation; and 6) RDH into video and into audio. For each of these six categories, the history of technical developments, the current state of the arts, and the possible future researches are presented and discussed. It is expected that the RDH technology and its applications in the real word will continue to move ahead.","Data hiding,
Video communication,
Reversible data hiding,
Classification algorithms,
Image coding,
Transform coding,
Cryptography,
Authentication"
Design and Evaluation of an Interactive Exercise Coaching System for Older Adults: Lessons Learned,"Although the positive effects of exercise on the well-being and quality of independent living for older adults are well accepted, many elderly individuals lack access to exercise facilities, or the skills and motivation to perform exercise at home. To provide a more engaging environment that promotes physical activity, various fitness applications have been proposed. Many of the available products, however, are geared toward a younger population and are not appropriate or engaging for an older population. To address these issues, we developed an automated interactive exercise coaching system using the Microsoft Kinect. The coaching system guides users through a series of video exercises, tracks and measures their movements, provides real-time feedback, and records their performance over time. Our system consists of exercises to improve balance, flexibility, strength, and endurance, with the aim of reducing fall risk and improving performance of daily activities. In this paper, we report on the development of the exercise system, discuss the results of our recent field pilot study with six independently living elderly individuals, and highlight the lessons learned relating to the in-home system setup, user tracking, feedback, and exercise performance evaluation.","Biomedical measurement,
Cameras,
Position measurement,
Informatics,
Real-time systems,
Atmospheric measurements,
Particle measurements"
Trust Evaluation in Online Social Networks Using Generalized Network Flow,"In online social networks (OSNs), to evaluate trust from one user to another indirectly connected user, the trust evidence in the trusted paths (i.e., paths built through intermediate trustful users) should be carefully treated. Some paths may overlap with each other, leading to a unique challenge of path dependence, i.e., how to aggregate the trust values of multiple dependent trusted paths. OSNs bear the characteristic of high clustering, which makes the path dependence phenomenon common. Another challenge is trust decay through propagation, i.e., how to propagate trust along a trusted path, considering the possible decay in each node. We analyze the similarity between trust propagation and network flow, and convert a trust evaluation task with path dependence and trust decay into a generalized network flow problem. We propose a modified flow-based trust evaluation scheme GFTrust, in which we address path dependence using network flow, and model trust decay with the leakage associated with each node. Experimental results, with the real social network data sets of Epinions and Advogato, demonstrate that GFTrust can predict trust in OSNs with a high accuracy, and verify its preferable properties.","Social network services,
Sun,
Credit cards,
Algorithm design and analysis,
Aggregates,
Accuracy,
Electronic mail"
HYDRA: Massively Compositional Model for Cross-Project Defect Prediction,"Most software defect prediction approaches are trained and applied on data from the same project. However, often a new project does not have enough training data. Cross-project defect prediction, which uses data from other projects to predict defects in a particular project, provides a new perspective to defect prediction. In this work, we propose a HYbrid moDel Reconstruction Approach (HYDRA) for cross-project defect prediction, which includes two phases: genetic algorithm (GA) phase and ensemble learning (EL) phase. These two phases create a massive composition of classifiers. To examine the benefits of HYDRA, we perform experiments on 29 datasets from the PROMISE repository which contains a total of 11,196 instances (i.e., Java classes) labeled as defective or clean. We experiment with logistic regression as the underlying classification algorithm of HYDRA. We compare our approach with the most recently proposed cross-project defect prediction approaches: TCA+ by Nam et al., Peters filter by Peters et al., GP by Liu et al., MO by Canfora et al., and CODEP by Panichella et al. Our results show that HYDRA achieves an average F1-score of 0.544. On average, across the 29 datasets, these results correspond to an improvement in the F1-scores of 26.22 , 34.99, 47.43, 28.61, and 30.14 percent over TCA+, Peters filter, GP, MO, and CODEP, respectively. In addition, HYDRA on average can discover 33 percent of all bugs if developers inspect the top 20 percent lines of code, which improves the best baseline approach (TCA+) by 44.41 percent. We also find that HYDRA improves the F1-score of Zero-R which predict all the instances to be defective by 5.42 percent, but improves Zero-R by 58.65 percent when inspecting the top 20 percent lines of code. In practice, Zero-R can be hard to use since it simply predicts all of the instances to be defective, and thus developers have to inspect all of the instances to find the defective ones. Moreover, we notice the improvement of HYDRA over other baseline approaches in terms of F1-score and when inspecting the top 20 percent lines of code are substantial, and in most cases the improvements are significant and have large effect sizes across the 29 datasets.","Genetic algorithms,
Predictive models,
Training,
Buildings,
Architecture,
Data models,
Measurement"
A Joint Time Synchronization and Localization Design for Mobile Underwater Sensor Networks,"Time synchronization and localization are basic services in a sensor network system. Although they often depend on each other, they are usually tackled independently. In this work, we investigate the time synchronization and localization problems in underwater sensor networks, where more challenges are introduced because of the unique characteristics of the water environment. These challenges include long propagation delay and transmission delay, low bandwidth, energy constraint, mobility, etc. We propose a joint solution for localization and time synchronization, in which the stratification effect of underwater medium is considered, so that the bias in the range estimates caused by assuming sound waves travel in straight lines in water environments is compensated. By combining time synchronization and localization, the accuracy of both are improved jointly. Additionally, an advanced tracking algorithm interactive multiple model (IMM) is adopted to improve the accuracy of localization in the mobile case. Furthermore, by combining both services, the number of required exchanged messages is significantly reduced, which saves on energy consumption. Simulation results show that both services are improved and benefit from this scheme.","Synchronization,
Propagation delay,
Accuracy,
Mobile computing,
Estimation,
Joints,
Wireless sensor networks"
Fairness of User Clustering in MIMO Non-Orthogonal Multiple Access Systems,"In this letter, a downlink multiple-input-multiple-output non-orthogonal multiple access scenario is considered. We investigate a dynamic user clustering problem from a fairness perspective. In order to solve this optimization problem, three sub-optimal algorithms, namely, top-down A, top-down B, and bottom up, are proposed to realize the different tradeoffs of complexity and throughput of the worst user. In addition, for each given user clustering case, we optimize the power allocation coefficients for the users in each cluster by adopting a bisection search-based algorithm. Numerical results show that the proposed algorithms can lower the complexity with an acceptable degradation on the throughput compared with the exhaustive search method. It is worth noting that the top-down B algorithm can achieve a good tradeoff between the complexity and the throughput among the three proposed algorithms.","Resource management,
Clustering algorithms,
Throughput,
Complexity theory,
Interference,
Signal to noise ratio"
Dynamic SDN controller assignment in data center networks: Stable matching with transfers,"Software defined networking is becoming increasingly prevalent in data center networks for its programmability that enables centralized network configuration and management. However, since switches are statically assigned to controllers, traffic dynamics cause load imbalance among the controllers. As a result, some controllers are not fully utilized, while switches connected to overloaded controllers may experience long response times. In this paper, we consider dynamic controller assignment so as to minimize the average response time of the control plane. We formulate this problem as a stable matching problem with transfers, and propose a hierarchically two-phase algorithm that integrates key concepts from both matching theory and coalitional games to solve it efficiently. Theoretical analysis proves that our algorithm converges to a near-optimal Nash stable solution within tens of iterations. Extensive simulations show that our approach reduces response time by about 86%, and achieves better load balancing among controllers compared to static assignment.","Control systems,
Time factors,
Games,
Process control,
Load modeling,
Heuristic algorithms,
Topology"
BEST-MAC: Bitmap-Assisted Efficient and Scalable TDMA-Based WSN MAC Protocol for Smart Cities,"Smart cities have been envisioned during the last decade. Moreover, various projects have been initiated to bring this concept into reality. Smart city is basically an emergence of the existing and new Information and Communications Technologies (ICT) to make our living standard more safe and digitized. Wireless communications, such as sensors, actuators, intelligent transportation systems, and smart grids, have played a vital role in the dissemination of information under the given circumstances. Similarly, it is hard to declare any city as a smart city without taking benefits from wireless sensor networks (WSNs). However, with new requirements and delay sensitive applications, the existing WSN requires significant alterations at several layers. In this paper, a new time division multiple access (TDMA)-based medium access control (MAC) protocol, called bitmap-assisted efficient and scalable TDMA-based MAC (BEST-MAC), is proposed for adaptive traffic in hierarchical WSNs that can be deployed in the smart cities. BEST-MAC is specifically designed to improve the quality control of such smart cities applications, where diverse traffic is required and loss or delay in data traffic is unacceptable. The main contributions of BEST-MAC include: 1) it uses small size time slots; 2) the number of those time slots is more than the number of member nodes; 3) knapsack algorithm is used to schedule time slots; and 4) short node address (1 B) is proposed to identify the member nodes. First two contributions of BEST-MAC handle adaptive traffic loads of all members in an efficient manner. The knapsack algorithm not only reduces the job completion time of a node but also minimizes the average packet delay with better link utilization. The short node address reduces the control overhead that improves the energy efficiency. The simulation results verify that the proposed BEST-MAC transmits more data with less delay and energy consumption compared with the existing MAC protocols.",
Two-Factor Data Security Protection Mechanism for Cloud Storage System,"In this paper, we propose a two-factor data security protection mechanism with factor revocability for cloud storage system. Our system allows a sender to send an encrypted message to a receiver through a cloud storage server. The sender only needs to know the identity of the receiver but no other information (such as its public key or its certificate). The receiver needs to possess two things in order to decrypt the ciphertext. The first thing is his/her secret key stored in the computer. The second thing is a unique personal security device which connects to the computer. It is impossible to decrypt the ciphertext without either piece. More importantly, once the security device is stolen or lost, this device is revoked. It cannot be used to decrypt any ciphertext. This can be done by the cloud server which will immediately execute some algorithms to change the existing ciphertext to be un-decryptable by this device. This process is completely transparent to the sender. Furthermore, the cloud server cannot decrypt any ciphertext at any time. The security and efficiency analysis show that our system is not only secure but also practical.",
Static and Dynamic Hand Gesture Recognition in Depth Data Using Dynamic Time Warping,"This paper discusses the development of a natural gesture user interface that tracks and recognizes in real time hand gestures based on depth data collected by a Kinect sensor. The interest space corresponding to the hands is first segmented based on the assumption that the hand of the user is the closest object in the scene to the camera. A novel algorithm is proposed to improve the scanning time in order to identify the first pixel on the hand contour within this space. Starting from this pixel, a directional search algorithm allows for the identification of the entire hand contour. The k-curvature algorithm is then employed to locate the fingertips over the contour, and dynamic time warping is used to select gesture candidates and also to recognize gestures by comparing an observed gesture with a series of prerecorded reference gestures. The comparison of results with state-of-the-art approaches shows that the proposed system outperforms most of the solutions for the static recognition of sign digits and is similar in terms of performance for the static and dynamic recognition of popular signs and for the sign language alphabet. The solution simultaneously deals with static and dynamic gestures as well as with multiple hands within the interest space. An average recognition rate of 92.4% is achieved over 55 static and dynamic gestures. Two possible applications of this work are discussed and evaluated: one for interpretation of sign digits and gestures for a friendlier human-machine interaction and the other one for the natural control of a software interface.","Gesture recognition,
Image color analysis,
Heuristic algorithms,
Assistive technology,
Real-time systems,
Inspection,
Cameras"
Fractal Dimension Estimation for Developing Pathological Brain Detection System Based on Minkowski-Bouligand Method,"It is of enormous significance to detect abnormal brains automatically. This paper develops an efficient pathological brain detection system based on the artificial intelligence method. We first extract brain edges by a Canny edge detector. Next, we estimated the fractal dimension using box counting method with grid sizes of 1, 2, 4, 8, and 16, respectively. Afterward, we employed the single-hidden layer feedforward neural network. Finally, we proposed an improved particle swarm optimization based on three-segment particle representation, time-varying acceleration coefficient, and chaos theory. This three-segment particle representation encodes the weights, biases, and number of hidden neuron. The statistical analysis showed the proposed method achieves the detection accuracies of 100%, 98.19%, and 98.08% over three benchmark data sets. Our method costs merely 0.1984 s to predict one image. Our performance is superior to the 11 state-of-the-art approaches.","Brain models,
Image edge detection,
Artificial intelligence,
Detectors,
Fractals,
Feedforward neural networks,
Particle swarm optimization,
Pathology"
"A Battery-Less, Implantable Neuro-Electronic Interface for Studying the Mechanisms of Deep Brain Stimulation in Rat Models","Although deep brain stimulation (DBS) has been a promising alternative for treating several neural disorders, the mechanisms underlying the DBS remain not fully understood. As rat models provide the advantage of recording and stimulating different disease-related regions simultaneously, this paper proposes a battery-less, implantable neuro-electronic interface suitable for studying DBS mechanisms with a freely-moving rat. The neuro-electronic interface mainly consists of a microsystem able to interact with eight different brain regions bi-directionally and simultaneously. To minimize the size of the implant, the microsystem receives power and transmits data through a single coil. In addition, particular attention is paid to the capability of recording neural activities right after each stimulation, so as to acquire information on how stimulations modulate neural activities. The microsystem has been fabricated with the standard 0.18 μm CMOS technology. The chip area is 7.74 mm 2, and the microsystem is able to operate with a single supply voltage of 1 V. The wireless interface allows a maximum power of 10 mW to be transmitted together with either uplink or downlink data at a rate of 2 Mbps or 100 kbps, respectively. The input referred noise of recording amplifiers is 1.16 μVrms, and the stimulation voltage is tunable from 1.5 V to 4.5 V with 5-bit resolution. After the electrical functionality of the microsystem is tested, the capability of the microsystem to interface with rat brain is further examined and compared with conventional instruments. All experimental results are presented and discussed in this paper.","Capacitors,
Charge pumps,
Neurons,
Computer architecture,
Voltage control,
Satellite broadcasting,
Wireless communication"
On Convergence Rate of Leader-Following Consensus of Linear Multi-Agent Systems With Communication Noises,"This note further studies the previously proposed consensus protocol for linear multi-agent systems with communication noises. Each agent is allowed to have its own time-varying gain to attenuate the effect of communication noises. Therefore, the common assumption that all agents have the same noise-attenuation gain is not necessary. It has been proved that if all noise-attenuation gains are infinitesimal of the same order, then the mean square leader-following consensus can be reached. Furthermore, the convergence rate of the multi-agent system has been investigated. If the noise-attenuation gains belong to a class of functions which are bounded above and below by t-β (β ∈ (0, 1)) asymptotically, then the second-moment of the relative state between each follower agent and the leader agent is characterized by a function bounded above by t-β asymptotically.","Protocols,
Topology,
Convergence,
Multi-agent systems,
Switches,
Transient analysis,
Time-domain analysis"
Placement of Remote-Controlled Switches to Enhance Distribution System Restoration Capability,A smart distribution system should restore service to interrupted customers as quickly as possible after an outage. Upgrading manual switches to remote-controlled switches (RCSs) enhances restoration capability. The placement of RCSs should consider both functional and economic requirements. This paper presents a systematic method to determine the set of switches to be upgraded for an existing distribution system. The maximum restoration capability is achieved by upgrading a near-minimum number of manual switches to RCSs. The RCS placement problem is formulated as a weighed set cover (WSC) problem. A greedy algorithm with a polynomial-time computational efficiency is designed to generate a near-optimal solution for the WSC problem. A 3-feeder 9-node test system and a 4-feeder 1069-node unbalanced test system with microgrids are used to validate the effectiveness of the proposed method.,"Greedy algorithms,
Reliability,
Switches,
Heuristic algorithms,
Manuals,
Interrupters,
Optimization"
Connecting Social Media to E-Commerce: Cold-Start Product Recommendation Using Microblogging Information,"In recent years, the boundaries between e-commerce and social networking have become increasingly blurred. Many e-commerce Web sites support the mechanism of social login where users can sign on the Web sites using their social network identities such as their Facebook or Twitter accounts. Users can also post their newly purchased products on microblogs with links to the e-commerce product Web pages. In this paper, we propose a novel solution for cross-site cold-start product recommendation, which aims to recommend products from e-commerce Web sites to users at social networking sites in “cold-start” situations, a problem which has rarely been explored before. A major challenge is how to leverage knowledge extracted from social networking sites for cross-site cold-start product recommendation. We propose to use the linked users across social networking sites and e-commerce Web sites (users who have social networking accounts and have made purchases on e-commerce Web sites) as a bridge to map users' social networking features to another feature representation for product recommendation. In specific, we propose learning both users' and products' feature representations (called user embeddings and product embeddings, respectively) from data collected from e-commerce Web sites using recurrent neural networks and then apply a modified gradient boosting trees method to transform users' social networking features into user embeddings. We then develop a feature-based matrix factorization approach which can leverage the learnt user embeddings for cold-start product recommendation. Experimental results on a large dataset constructed from the largest Chinese microblogging service Sina Weibo and the largest Chinese B2C e-commerce website JingDong have shown the effectiveness of our proposed framework.","Feature extraction,
Gold,
Transforms,
Media,
Recurrent neural networks,
Facebook"
An Efficient Tag Search Protocol in Large-Scale RFID Systems With Noisy Channel,"Radio frequency identification (RFID) technology has many applications in inventory management, supply chain, product tracking, transportation, and logistics. One research issue of practical importance is to search for a particular group of tags in a large-scale RFID system. Time efficiency is a crucial factor that must be considered when designing a tag search protocol to ensure its execution will not interfere with other normal inventory operations. In this paper, we design a new technique called filtering vector, which can significantly reduce transmission overhead during search process, thereby shortening search time. Based on this technique, we propose an iterative tag search protocol. In each round, we filter out some tags and eventually terminate the search process when the search result meets the accuracy requirement. Furthermore, we extend our protocol to work under noisy channel. The simulation results demonstrate that our protocol performs much better than the best existing work.","Vectors,
Protocols,
Radiofrequency identification,
Cats,
Search problems,
Arrays,
Noise measurement"
A Novel Method for Automated Diagnosis of Epilepsy Using Complex-Valued Classifiers,"The study reported herein proposes a new method for the diagnosis of epilepsy from electroencephalography (EEG) signals based on complex classifiers. To carry out this study, first the features of EEG data are extracted using a dual-tree complex wavelet transformation at different levels of granularity to obtain size reduction. In subsequent phases, five features (based on statistical measurements maximum value, minimum value, arithmetic mean, standard deviation, median value) are obtained by using the feature vectors, and are presented as the input dimension to the complex-valued neural networks. The evaluation of the proposed method is conducted using the k-fold cross-validation methodology, reporting on classification accuracy, sensitivity, and specificity. The proposed method is tested using a benchmark EEG dataset, and high accuracy rates were obtained. The stated results show that the proposed method can be used to design an accurate classification system for epilepsy diagnosis.","Electroencephalography,
Neurons,
Accuracy,
Classification algorithms,
Biological neural networks,
Mathematical model,
Epilepsy"
"An Overview of Dynamic Spectrum Sharing: Ongoing Initiatives, Challenges, and a Roadmap for Future Research","We are in the midst of a major paradigm shift in how we manage radio spectrum. This paradigm shift is necessitated by the growth of wireless services of all types and the demand pressure imposed on limited spectrum resources under legacy management regimes. The shift is feasible because of advances in radio and networking technologies that make it possible to share spectrum dynamically in all possible dimensions-i.e., across frequencies, time, location, users, uses, and networks. Realizing the full potential of this shift to Dynamic Spectrum Sharing will require the co-evolution of wireless technologies, markets, and regulatory policies; a process which is occurring on a global scale. This paper provides a current overview of major technological and regulatory reforms that are leading the way toward a global paradigm shift to more flexible, dynamic, market-based ways to manage and share radio spectrum resources. We focus on current efforts to implement database-driven approaches for managing the shared co-existence of users with heterogeneous access and interference protection rights, and discuss open research challenges.","Wireless communication,
Wireless sensor networks,
FCC,
Interference,
TV,
Sensors,
Broadband communication"
Novel Accurate and Fast Optic Disc Detection in Retinal Images With Vessel Distribution and Directional Characteristics,"A novel accurate and fast optic disc (OD) detection method is proposed by using vessel distribution and directional characteristics. A feature combining three vessel distribution characteristics, i.e., local vessel density, compactness, and uniformity, is designed to find possible horizontal coordinate of OD. Then, according to the global vessel direction characteristic, a General Hough Transformation is introduced to identify the vertical coordinate of OD. By confining the possible OD vertical range and by simplifying vessel structure with blocks, we greatly decrease the computational cost of the algorithm. Four public datasets have been tested. The OD localization accuracy lies from 93.8% to 99.7%, when 8-20% vessel detection results are adopted to achieve OD detection. Average computation times for STARE images are about 3.4-11.5 s, which relate to image size. The proposed method shows satisfactory robustness on both normal and diseased images. It is better than many previous methods with respect to accuracy and efficiency.","Retina,
Image segmentation,
Biomedical imaging,
Accuracy,
Gabor filters,
Informatics,
Blood vessels"
HIPAcc: A Domain-Specific Language and Compiler for Image Processing,"Domain-specific languages (DSLs) provide high-level and domain-specific abstractions that allow expressive and concise algorithm descriptions. Since the description in a DSL hides also the properties of the target hardware, DSLs are a promising path to target different parallel and heterogeneous hardware from the same algorithm description. In theory, the DSL description can capture all characteristics of the algorithm that are required to generate highly efficient parallel implementations. However, most frameworks do not make use of this knowledge and the performance cannot reach that of optimized library implementations. In this article, we present the HIPAcc framework, a DSL and source-to-source compiler for image processing. We show that domain knowledge can be captured in the language and that this knowledge enables us to generate tailored implementations for a given target architecture. Back ends for CUDA, OpenCL, and Renderscript allow us to target discrete graphics processing units (GPUs) as well as mobile, embedded GPUs. Exploiting the captured domain knowledge, we can generate specialized algorithm variants that reach the maximal achievable performance due to the peak memory bandwidth. These implementations outperform state-of-the-art domain-specific languages and libraries significantly.","DSL,
Graphics processing units,
Kernel,
Image processing,
Hardware,
Indexes,
Optimization"
Distributed Data Analytics Platform for Wide-Area Synchrophasor Measurement Systems,"As synchrophasor data start to play a significant role in power system operation and dynamic study, data processing and data analysis capability are critical to wide-area measurement systems (WAMSs). The frequency monitoring network (FNET/GridEye) is a WAMS network that collects data from hundreds of frequency disturbance recorders at the distribution level. The previous FNET/GridEye data center is limited by its data storage capability and computation power. Targeting scalability, extensibility, concurrency, and robustness, a distributed data analytics platform is proposed in this paper to process large volume, high velocity dataset. A variety of real-time and non-real-time synchrophasor data analytics applications are hosted by this platform. The computation load is shared with balance by multiple nodes of the analytics cluster, and big data analytics tools such as Apache Spark are adopted to manage large volume data and to boost the data processing speed. Future data analytics applications can be easily developed and plugged into the system with simple configuration.","Servers,
Real-time systems,
Data analysis,
Clocks,
Big data,
Algorithm design and analysis"
Energy Efficiency With Proportional Rate Fairness in Multirelay OFDM Networks,"This paper investigates the energy efficiency (EE) in multiple relay-aided OFDM systems, where decode-and-forward (DF) relay beamforming is employed to help the information transmission. In order to explore the system performance behavior with user fairness for such a system, an optimization problem is formulated to maximize the EE by jointly considering multiple factors, i.e., the transmission mode selection (DF relay beamforming or direct-link transmission), the helping relay set selection, the subcarrier assignment and the power allocation at the source and relays on subcarriers, under nonlinear proportional rate fairness constraints, where both transmit power consumption and linearly rate-dependent circuit power consumption are taken into account. To solve the nonconvex optimization problem, we propose a low-complexity scheme to approximate it. Simulation results demonstrate its effectiveness. The effects of the circuit power consumption on system performance is also studied and it is observed that with either the constant or the linearly rate-dependent circuit power consumption, system EE grows with the increment of system average channel-to-noise ratio (CNR), but the growth rates show different behaviors. For the constant circuit power consumption, system EE increasing rate is an increasing function of the average CNR, while for the linearly rate-dependent one, system EE increasing rate is a decreasing function of the average CNR. This observation is very important, which indicates that by deducing the circuit dynamic power consumption per unit data rate, system EE can be greatly enhanced. Besides, we also discuss the effects of the number of users and subcarriers on the system EE performance.","Relays,
OFDM,
Power demand,
Resource management,
Wireless communication,
Array signal processing,
Information processing"
Hybrid Probabilistic Wind Power Forecasting Using Temporally Local Gaussian Process,"The demand for sustainable development has resulted in a rapid growth in wind power worldwide. Although various approaches have been proposed to improve the accuracy and to overcome the uncertainties associated with traditional methods, the stochastic and variable nature of wind still remains the most challenging issue in accurately forecasting wind power. This paper presents a hybrid deterministicprobabilistic method where a temporally local moving window technique is used in Gaussian process (GP) to examine estimated forecasting errors. This temporally local GP employs less measurement data with faster and better predictions of wind power from two wind farms, one in the USA and the other in Ireland. Statistical analysis on the results shows that the method can substantially reduce the forecasting error while it is more likely to generate Gaussian-distributed residuals, particularly for short-term forecast horizons due to its capability to handle the time-varying characteristics of wind power.","Forecasting,
Wind power generation,
Predictive models,
Wind farms,
Wind forecasting,
Autoregressive processes,
Analytical models"
Joint Binary Classifier Learning for ECOC-Based Multi-Class Classification,"Error-correcting output coding (ECOC) is one of the most widely used strategies for dealing with multi-class problems by decomposing the original multi-class problem into a series of binary sub-problems. In traditional ECOC-based methods, binary classifiers corresponding to those sub-problems are usually trained separately without considering the relationships among these classifiers. However, as these classifiers are established on the same training data, there may be some inherent relationships among them. Exploiting such relationships can potentially improve the generalization performances of individual classifiers, and, thus, boost ECOC learning algorithms. In this paper, we explore to mine and utilize such relationship through a joint classifier learning method, by integrating the training of binary classifiers and the learning of the relationship among them into a unified objective function. We also develop an efficient alternating optimization algorithm to solve the objective function. To evaluate the proposed method, we perform a series of experiments on eleven datasets from the UCI machine learning repository as well as two datasets from real-world image recognition tasks. The experimental results demonstrate the efficacy of the proposed method, compared with state-of-the-art methods for ECOC-based multi-class classification.","Encoding,
Support vector machines,
Joints,
Kernel,
Optimization,
Decoding,
Classification algorithms"
Probabilistic Fusion of Pixel-Level and Superpixel-Level Hyperspectral Image Classification,"A novel hyperspectral image (HSI) classification method by the probabilistic fusion of pixel-level and superpixel-level classifiers is proposed. Generally, pixel-level classifiers based on spectral information only may generate “salt and pepper” result in the classification map since spatial correlation is not considered. By incorporating spatial information in homogeneous regions, the superpixel-level classifiers can effectively eliminate the noisy appearance. However, the classification accuracy will be deteriorated if undersegmentation cannot be fully avoided in superpixel-based approaches. Therefore, it is proposed to adaptively combine both the pixel-level and superpixel-level classifiers, to improve the classification performance in both homogenous and structural areas. In the proposed method, a support vector machine classifier is first applied to estimate the pixel-level class probabilities. Then, superpixel-level class probabilities are estimated based on a joint sparse representation. Finally, the two levels of class probabilities are adaptively combined in a maximum a posteriori estimation model, and the classification map is obtained by solving the maximum optimization problem. Experimental results on real HSI images demonstrate the superiority of the proposed method over several well-known classification approaches in terms of classification accuracy.","Support vector machines,
Probabilistic logic,
Training,
Adaptation models,
Approximation algorithms,
Optimization,
Estimation"
Weakly Supervised Fine-Grained Categorization With Part-Based Image Representation,"In this paper, we propose a fine-grained image categorization system with easy deployment. We do not use any object/part annotation (weakly supervised) in the training or in the testing stage, but only class labels for training images. Fine-grained image categorization aims to classify objects with only subtle distinctions (e.g., two breeds of dogs that look alike). Most existing works heavily rely on object/part detectors to build the correspondence between object parts, which require accurate object or object part annotations at least for training images. The need for expensive object annotations prevents the wide usage of these methods. Instead, we propose to generate multi-scale part proposals from object proposals, select useful part proposals, and use them to compute a global image representation for categorization. This is specially designed for the weakly supervised fine-grained categorization task, because useful parts have been shown to play a critical role in existing annotation-dependent works, but accurate part detectors are hard to acquire. With the proposed image representation, we can further detect and visualize the key (most discriminative) parts in objects of different classes. In the experiments, the proposed weakly supervised method achieves comparable or better accuracy than the state-of-the-art weakly supervised methods and most existing annotation-dependent methods on three challenging datasets. Its success suggests that it is not always necessary to learn expensive object/part detectors in fine-grained image categorization.","Proposals,
Image representation,
Detectors,
Training,
Testing,
Image recognition,
Birds"
Tracking Interacting Objects Using Intertwined Flows,"In this paper, we show that tracking different kinds of interacting objects can be formulated as a network-flow mixed integer program. This is made possible by tracking all objects simultaneously using intertwined flow variables and expressing the fact that one object can appear or disappear at locations where another is in terms of linear flow constraints. Our proposed method is able to track invisible objects whose only evidence is the presence of other objects that contain them. Furthermore, our tracklet-based implementation yields real-time tracking performance. We demonstrate the power of our approach on scenes involving cars and pedestrians, bags being carried and dropped by people, and balls being passed from one player to the next in team sports. In particular, we show that by estimating jointly and globally the trajectories of different types of objects, the presence of the ones which were not initially detected based solely on image evidence can be inferred from the detections of the others.","Automobiles,
Detectors,
Trajectory,
Linear programming,
Optimization,
Target tracking"
Slew/Translation Positioning and Swing Suppression for 4-DOF Tower Cranes With Parametric Uncertainties: Design and Hardware Experimentation,"As a powerful large-scale construction tool, a tower crane is a strongly nonlinear underactuated system presenting complicated dynamical characteristics. Existing control methods for tower cranes are developed on the basis of simplified (i.e., linearized/approximated) crane dynamics, and most of them require exact model knowledge. However, practical tower cranes usually suffer from uncertainties (e.g., unknown rope length and payload mass); moreover, when the state variables are not close enough to the equilibrium point due to unexpected disturbances, simplified models might not reflect the actual dynamics any longer, which usually badly degrades the control performance. To tackle these problems, this paper proposes an adaptive control scheme for underactuated tower cranes to achieve simultaneous slew/translation positioning and swing suppression, which can reduce unexpected overshoots for the jib/trolley movements. The closed-loop stability is backed up with the rigorous mathematical analysis. To the best of our knowledge, the proposed controller is the first method for tower cranes with parametric uncertainties, which is developed without linearizing/approximating their nonlinear dynamics. Finally, we introduce our self-built multifunctional hardware crane experiment testbed and present experimental studies for the proposed method. Experimental results show that the new control approach is effective and admits satisfactory robustness.",
Enhancing Sensor Pattern Noise via Filtering Distortion Removal,"In this work, we propose a method to obtain higher quality sensor pattern noise (SPN) for identifying source cameras. We believe that some components of SPN have been severely contaminated by the errors introduced by denoising filters and the quality of SPN can be improved by abandoning those components. In our proposed method, some coefficients with higher denoising errors are abandoned in the wavelet representation of SPN and the remaining wavelet coefficients are further enhanced to suppress the scene details in the SPN. These two steps aim to provide better SPN with higher signal-to-noise ratio (SNR) and therefore improve the identification performance. The experimental results on 2,000 images captured by 10 cameras (each responsible for 200 images), show that our method achieves better receiver operating characteristic (ROC) performance when compared with some state-of-the-art methods.","Noise reduction,
Cameras,
Mathematical model,
Correlation,
Radio frequency,
Distortion,
Signal to noise ratio"
Logic Design Within Memristive Memories Using Memristor-Aided loGIC (MAGIC),"Realizing logic operations within passive crossbar memory arrays is a promising approach to enable novel computer architectures, different from conventional von Neumann architecture. Attractive candidates to enable such architectures are memristors, nonvolatile memory elements commonly used within a crossbar, that can also perform logic operations. In such novel architectures, data are stored and processed within the same entity, which we term as memristive memory processing unit (MPU). In this paper, Memristor-Aided loGIC (MAGIC) family is discussed with various design considerations and novel techniques to execute logic within an MPU. We present a novel resistive memory-the transpose memory, which adds additional functionality to the memristive memory, and compare it with a conventional memristive memory. A case study of an adder is presented to demonstrate the design issues discussed in this paper. We compare the proposed design techniques with the memristive IMPLY logic in terms of speed, area, and energy. Our evaluation shows that the proposed MAGIC design is 2.4 × faster and consumes 66.3% less energy as compared with the IMPLY-based computing for N-bit addition within memristive crossbar memory. Additionally, we compare the proposed design with IMPLY logic family on ISCAS-85 benchmarks, which shows significant improvements in speed (2×) and energy (10×), with similar area.","Memristors,
Resistance,
Random access memory,
Adaptation models,
Arrays,
Threshold voltage"
A Uniform Approach for Synthesizing Property-Enforcing Supervisors for Partially-Observed Discrete-Event Systems,"The problem under consideration in this paper is that of enforcement by supervisory control of a given property on a partially-observed discrete-event system. We present a general methodology that is applicable to a large class of properties previously studied (individually) in the literature. These properties include, but are not restricted to, safety, diagnosability, opacity, detectability, anonymity and attractability. When the given system does not satisfy the considered property, the objective is to synthesize a supervisor that restricts the system's behavior and provably enforces the given property; moreover, it is required that this supervisor be maximally permissive. We consider the general case where the system's events are partitioned into observable and unobservable events, and controllable and uncontrollable events, and we do not make any assumptions about these two partitions; in particular, we do not assume that all controllable events are observable. Our uniform approach first maps the considered property to a suitably-defined information state for the partially-observed system and then develops a supervisor synthesis methodology based on a finite bipartite transition system that embeds all reachable information states and all admissible supervisory control strategies. This transition system is called the All Enforcement Structure (or AES). We present an algorithm for the construction of the AES and discuss its properties. Then we use the AES to develop a synthesis algorithm that constructs a supervisor that is provably property enforcing and maximally permissive. We illustrate the application of our uniform approach to the enforcement of the above-mentioned properties.","Safety,
Supervisory control,
Standards,
Observability,
Discrete-event systems,
Context"
Discriminative Feature Extraction via Multivariate Linear Regression for SSVEP-Based BCI,"Many of the most widely accepted methods for reliable detection of steady-state visual evoked potentials (SSVEPs) in the electroencephalogram (EEG) utilize canonical correlation analysis (CCA). CCA uses pure sine and cosine reference templates with frequencies corresponding to the visual stimulation frequencies. These generic reference templates may not optimally reflect the natural SSVEP features obscured by the background EEG. This paper introduces a new approach that utilizes spatio-temporal feature extraction with multivariate linear regression (MLR) to learn discriminative SSVEP features for improving the detection accuracy. MLR is implemented on dimensionality-reduced EEG training data and a constructed label matrix to find optimally discriminative subspaces. Experimental results show that the proposed MLR method significantly outperforms CCA as well as several other competing methods for SSVEP detection, especially for time windows shorter than 1 second. This demonstrates that the MLR method is a promising new approach for achieving improved real-time performance of SSVEP-BCIs.","Feature extraction,
Electroencephalography,
Correlation,
Visualization,
Training data,
Training,
Linear regression"
Symbol-Decision Successive Cancellation List Decoder for Polar Codes,"Polar codes are of great interests because they provably achieve the symmetric capacity of discrete memoryless channels with arbitrary input alphabet sizes while having an explicit construction. Most existing decoding algorithms of polar codes are based on bit-wise hard or soft decisions. In this paper, we propose symbol-decision successive cancellation (SC) and successive cancellation list (SCL) decoders for polar codes, which use symbol-wise hard or soft decisions for higher throughput or better error performance. First, we propose to use a recursive channel combination to calculate symbol-wise channel transition probabilities, which lead to symbol decisions. Our proposed recursive channel combination has lower complexity than simply combining bit-wise channel transition probabilities. The similarity between our proposed method and Arıkan's channel transformations also helps to share hardware resources between calculating bit- and symbol-wise channel transition probabilities. Second, a two-stage list pruning network is proposed to provide a trade-off between the error performance and the complexity of the symbol-decision SCL decoder. Third, since memory is a significant part of SCL decoders, we propose a pre-computation memory-saving technique to reduce memory requirement of an SCL decoder. Finally, to evaluate the throughput advantage of our symbol-decision decoders, we design an architecture based on a semi-parallel successive cancellation list decoder. In this architecture, different symbol sizes, sorting implementations, and message scheduling schemes are considered. Our synthesis results show that in terms of area efficiency, our symbol-decision SCL decoders outperform existing bit-decision and multi-bit SCL decoders.","Decoding,
Signal processing algorithms,
Throughput,
Complexity theory,
Hardware,
Probability,
Memory management"
Pricing and Resource Allocation via Game Theory for a Small-Cell Video Caching System,"Evidence indicates that downloading on-demand videos accounts for a dramatic increase in data traffic over cellular networks. Caching popular videos in the storage of small-cell base stations (SBS), namely, small-cell caching, is an efficient technology for reducing the transmission latency while mitigating the redundant transmissions of popular videos over back-haul channels. In this paper, we consider a commercialized small-cell caching system consisting of a network service provider (NSP), several video retailers (VRs), and mobile users (MUs). The NSP leases its SBSs to the VRs for the purpose of making profits, and the VRs, after storing popular videos in the rented SBSs, can provide faster local video transmissions to the MUs, thereby gaining more profits. We conceive this system within the framework of Stackelberg game by treating the SBSs as specific types of resources. We first model the MUs and SBSs as two independent Poisson point processes, and develop, via stochastic geometry theory, the probability of the specific event that an MU obtains the video of its choice directly from the memory of an SBS. Then, based on the probability derived, we formulate a Stackelberg game to jointly maximize the average profit of both the NSP and the VRs. In addition, we investigate the Stackelberg equilibrium by solving a non-convex optimization problem. With the aid of this game theoretic framework, we shed light on the relationship between four important factors: the optimal pricing of leasing an SBS, the SBSs allocation among the VRs, the storage size of the SBSs, and the popularity distribution of the VRs. Monte Carlo simulations show that our stochastic geometry-based analytical results closely match the empirical ones. Numerical results are also provided for quantifying the proposed game-theoretic framework by showing its efficiency on pricing and resource allocation.","Streaming media,
Games,
Pricing,
Stochastic processes,
Wireless sensor networks,
Wireless communication,
Resource management"
Adversarial Feature Selection Against Evasion Attacks,"Pattern recognition and machine learning techniques have been increasingly adopted in adversarial settings such as spam, intrusion, and malware detection, although their security against well-crafted attacks that aim to evade detection by manipulating data at test time has not yet been thoroughly assessed. While previous work has been mainly focused on devising adversary-aware classification algorithms to counter evasion attempts, only few authors have considered the impact of using reduced feature sets on classifier security against the same attacks. An interesting, preliminary result is that classifier security to evasion may be even worsened by the application of feature selection. In this paper, we provide a more detailed investigation of this aspect, shedding some light on the security properties of feature selection against evasion attacks. Inspired by previous work on adversary-aware classifiers, we propose a novel adversary-aware feature selection model that can improve classifier security against evasion attacks, by incorporating specific assumptions on the adversary's data manipulation strategy. We focus on an efficient, wrapper-based implementation of our approach, and experimentally validate its soundness on different application examples, including spam and malware detection.","Robustness,
Feature extraction,
Malware,
Training,
Accuracy,
Intrusion detection"
Joint User Association and Spectrum Allocation for Small Cell Networks With Wireless Backhauls,"Heterogenous networks and massive MIMO can significantly enhance spectral and energy efficiencies of wireless networks and have recently attracted lots of attention. In this letter, we investigate joint user association and spectrum allocation to further improve spectral efficiency for massive MIMO enabled heterogeneous networks with full-duplex wireless backhauls. The optimization problem is formulated as a mixed-integer nonlinear programming problem, and therefore, is nonconvex and combinational. To solve the problem efficiently, the original optimization problem is divided into two subproblems that can be solved with low-computational-complexity methods. The simulation results confirm our theoretical analysis and demonstrate the performance improvement of the proposed algorithm.","Resource management,
Wireless communication,
Optimization,
MIMO,
Communication system security,
Heterogeneous networks,
Electronic mail"
A Computationally Efficient Algorithm for Rotor Design Optimization of Synchronous Reluctance Machines,"A generalizable algorithm is proposed for the design optimization of synchronous reluctance machine rotors. Single-barrier models are considered to reduce the algorithm's computational complexity and provide a relative comparison for rotors with different slots-per-pole combinations. Two objective values per sampled design (average and ripple torques) are computed using 2-D finite-element analysis simulations. Non-linear regression or surrogate models are trained for the two objectives through a Bayesian regularization backpropagation neural network. A multi-objective genetic algorithm is used to find the validated Pareto front solutions. An analytical ellipse constraint is then suggested to encapsulate optimal solutions. Compared with a direct sampling approach, this restriction captures an optimal region within the double-barrier space for further torque ripple reduction.","Rotors,
Torque,
Stator windings,
Algorithm design and analysis,
Training,
Computational modeling"
Securing SIFT: Privacy-Preserving Outsourcing Computation of Feature Extractions Over Encrypted Image Data,"Advances in cloud computing have greatly motivated data owners to outsource their huge amount of personal multimedia data and/or computationally expensive tasks onto the cloud by leveraging its abundant resources for cost saving and flexibility. Despite the tremendous benefits, the outsourced multimedia data and its originated applications may reveal the data owner's private information, such as the personal identity, locations, or even financial profiles. This observation has recently aroused new research interest on privacy-preserving computations over outsourced multimedia data. In this paper, we propose an effective and practical privacy-preserving computation outsourcing protocol for the prevailing scale-invariant feature transform (SIFT) over massive encrypted image data. We first show that the previous solutions to this problem have either efficiency/security or practicality issues, and none can well preserve the important characteristics of the original SIFT in terms of distinctiveness and robustness. We then present a new scheme design that achieves efficiency and security requirements simultaneously with the preservation of its key characteristics, by randomly splitting the original image data, designing two novel efficient protocols for secure multiplication and comparison, and carefully distributing the feature extraction computations onto two independent cloud servers. We both carefully analyze and extensively evaluate the security and effectiveness of our design. The results show that our solution is practically secure, outperforms the state-of-the-art, and performs comparably with the original SIFT in terms of various characteristics, including rotation invariance, image scale invariance, robust matching across affine distortion, and addition of noise and change in 3D viewpoint and illumination.","Feature extraction,
Protocols,
Servers,
Outsourcing,
Cloud computing,
Encryption"
Dynamic Hand Gesture Recognition With Leap Motion Controller,"Dynamic hand gesture recognition is a crucial but challenging task in the pattern recognition and computer vision communities. In this paper, we propose a novel feature vector which is suitable for representing dynamic hand gestures, and presents a satisfactory solution to recognizing dynamic hand gestures with a Leap Motion controller (LMC) only. These have not been reported in other papers. The feature vector with depth information is computed and fed into the Hidden Conditional Neural Field (HCNF) classifier to recognize dynamic hand gestures. The systematic framework of the proposed method includes two main steps: feature extraction and classification with the HCNF classifier. The proposed method is evaluated on two dynamic hand gesture datasets with frames acquired with a LMC. The recognition accuracy is 89.5% for the LeapMotion-Gesture3D dataset and 95.0% for the Handicraft-Gesture dataset. Experimental results show that the proposed method is suitable for certain dynamic hand gesture recognition tasks.","Gesture recognition,
Feature extraction,
Dynamics,
Hidden Markov models,
Logic gates,
Training,
Systematics"
Characterizing Provenance in Visualization and Data Analysis: An Organizational Framework of Provenance Types and Purposes,"While the primary goal of visual analytics research is to improve the quality of insights and findings, a substantial amount of research in provenance has focused on the history of changes and advances throughout the analysis process. The term, provenance, has been used in a variety of ways to describe different types of records and histories related to visualization. The existing body of provenance research has grown to a point where the consolidation of design knowledge requires cross-referencing a variety of projects and studies spanning multiple domain areas. We present an organizational framework of the different types of provenance information and purposes for why they are desired in the field of visual analytics. Our organization is intended to serve as a framework to help researchers specify types of provenance and coordinate design knowledge across projects. We also discuss the relationships between these factors and the methods used to capture provenance information. In addition, our organization can be used to guide the selection of evaluation methodology and the comparison of study outcomes in provenance research.","Data visualization,
History,
Visual analytics,
Data analysis,
Cognition,
Organizations"
Efficiency Enhancement for Dynamic Wireless Power Transfer System With Segmented Transmitter Array,"Achieving high efficiency with improved power transfer distance and misalignment tolerance is the major design challenge in realizing dynamic wireless power transfer (D-WPT) systems. This paper provides an analysis on designing D-WPT systems. Design parameters such as number of Tx coils, separation between Tx, operating frequency, and load characteristics are analyzed with respect to efficiency for the D-WPT system with segmented transmitter array. A double-spiral repeater (DSR) is proposed for improving efficiency, enhancing transfer distance, and misalignment tolerance. Experimental results of the proposed topology with DSRs show efficiencies of 81% and 60% at normalized transfer distances (normalized to geometric mean of Tx and Rx sizes) of 0.74 and 2.2, respectively. The proposed topology can be effectively used to alleviate efficiency deterioration against transfer distance and misalignment in D-WPT systems.",
Traffic-Aware Cloud RAN: A Key for Green 5G Networks,"Next generation 5G wireless networks envision innovative radio technologies for ultra dense deployment with improved coverage and higher data rates. However, the deployment of ultra dense 5G networks, with relatively smaller cells, raises significant challenges in network energy consumption. Emerging green cloud radio access networks (C-RANs) are providing assurance of energy efficient cellular operations for reduction of both greenhouse emissions and operators' energy bill. Cellular traffic dynamics play a significant role in efficient network energy management. In this paper, we first identify the complexity of the optimal traffic awareness in 5G C-RAN and design a framework for traffic-aware energy optimization. The virtual base station cluster (VBSC) of C-RAN exploits an information theoretic approach to model and analyze the uncertainty of cellular traffic, captured by remote radio heads (RRH). Subsequently, using an online, stochastic game theoretic algorithm, the VBS instances optimize and learn the cellular traffic patterns. Efficient learning makes the C-RAN aware of the near-future traffic. Traffic awareness helps in selective switching of a subset of RRHs, thus reducing the overall energy consumption. Our VBS prototype implementation, testbed experiments, and simulation results, performed with actual cellular traffic traces, demonstrate that our framework results in almost 25% daily energy savings and 35% increased energy efficiency with a negligible overhead.","5G mobile communication,
Entropy,
Uncertainty,
Optimization,
Base stations,
Stochastic processes"
Task Assignment on Multi-Skill Oriented Spatial Crowdsourcing,"With the rapid development of mobile devices and crowdsourcing platforms, the spatial crowdsourcing has attracted much attention from the database community. Specifically, the spatial crowdsourcing refers to sending location-based requests to workers, based on their current positions. In this paper, we consider a spatial crowdsourcing scenario, in which each worker has a set of qualified skills, whereas each spatial task (e.g., repairing a house, decorating a room, and performing entertainment shows for a ceremony) is time-constrained, under the budget constraint, and required a set of skills. Under this scenario, we will study an important problem, namely multi-skill spatial crowdsourcing (MS-SC), which finds an optimal worker-and-task assignment strategy, such that skills between workers and tasks match with each other, and workers’ benefits are maximized under the budget constraint. We prove that the MS-SC problem is NP-hard and intractable. Therefore, we propose three effective heuristic approaches, including greedy,
g
-divide-and-conquer and cost-model-based adaptive algorithms to get worker-and-task assignments. Through extensive experiments, we demonstrate the efficiency and effectiveness of our MS-SC processing approaches on both real and synthetic data sets.","Crowdsourcing,
Adaptive algorithms,
Electronic mail,
Painting,
Cleaning,
Remuneration,
Knowledge engineering"
Hybrid Sampling-Based Clustering Ensemble With Global and Local Constitutions,"Among a number of ensemble learning techniques, boosting and bagging are the most popular sampling-based ensemble approaches for classification problems. Boosting is considered stronger than bagging on noise-free data set with complex class structures, whereas bagging is more robust than boosting in cases where noise data are present. In this paper, we extend both ensemble approaches to clustering tasks, and propose a novel hybrid sampling-based clustering ensemble by combining the strengths of boosting and bagging. In our approach, the input partitions are iteratively generated via a hybrid process inspired by both boosting and bagging. Then, a novel consensus function is proposed to encode the local and global cluster structure of input partitions into a single representation, and applies a single clustering algorithm to such representation to obtain the consolidated consensus partition. Our approach has been evaluated on 2-D-synthetic data, collection of benchmarks, and real-world facial recognition data sets, which show that the proposed technique outperforms the existing benchmarks for a variety of clustering tasks.","Clustering algorithms,
Partitioning algorithms,
Boosting,
Bagging,
Algorithm design and analysis,
Linear programming,
Constitution"
A Review of Compressive Sensing in Information Security Field,"The applications of compressive sensing (CS) in the field of information security have captured a great deal of researchers' attention in the past decade. To supply guidance for researchers from a comprehensive perspective, this paper, for the first time, reviews CS in information security field from two aspects: theoretical security and application security. Moreover, the CS applied in image cipher is one of the most widespread applications, as its characteristics of dimensional reduction and random projection can be utilized and integrated into image cryptosystems, which can achieve simultaneous compression and encryption of an image or multiple images. With respect to this application, the basic framework designs and the corresponding analyses are investigated. Specifically, the investigation proceeds from three aspects, namely, image ciphers based on chaos and CS, image ciphers based on optics and CS, and image ciphers based on chaos, optics, and CS. A total of six frameworks are put forward. Meanwhile, their analyses in terms of security, advantages, disadvantages, and so on are presented. At last, we attempt to indicate some other possible application research topics in future.","Chaos theory,
Information security,
Compressed sensing,
Ciphers,
Optical fiber communication,
Image processing,
Computer security,
Cryptography"
Fine-Grained Two-Factor Access Control for Web-Based Cloud Computing Services,"In this paper, we introduce a new fine-grained two-factor authentication (2FA) access control system for web-based cloud computing services. Specifically, in our proposed 2FA access control system, an attribute-based access control mechanism is implemented with the necessity of both a user secret key and a lightweight security device. As a user cannot access the system if they do not hold both, the mechanism can enhance the security of the system, especially in those scenarios where many users share the same computer for web-based cloud services. In addition, attribute-based control in the system also enables the cloud server to restrict the access to those users with the same set of attributes while preserving user privacy, i.e., the cloud server only knows that the user fulfills the required predicate, but has no idea on the exact identity of the user. Finally, we also carry out a simulation to demonstrate the practicability of our proposed 2FA system.",
Going deeper in facial expression recognition using deep neural networks,"Automated Facial Expression Recognition (FER) has remained a challenging and interesting problem in computer vision. Despite efforts made in developing various methods for FER, existing approaches lack generalizability when applied to unseen images or those that are captured in wild setting (i.e. the results are not significant). Most of the existing approaches are based on engineered features (e.g. HOG, LBPH, and Gabor) where the classifier's hyper-parameters are tuned to give best recognition accuracies across a single database, or a small collection of similar databases. This paper proposes a deep neural network architecture to address the FER problem across multiple well-known standard face datasets. Specifically, our network consists of two convolutional layers each followed by max pooling and then four Inception layers. The network is a single component architecture that takes registered facial images as the input and classifies them into either of the six basic or the neutral expressions. We conducted comprehensive experiments on seven publicly available facial expression databases, viz. MultiPIE, MMI, CK+, DISFA, FERA, SFEW, and FER2013. The results of our proposed architecture are comparable to or better than the state-of-the-art methods and better than traditional convolutional neural networks in both accuracy and training time.","Databases,
Computer architecture,
Face,
Training,
Feature extraction,
Biological neural networks"
Coded Auxiliary Pilots for Channel Estimation in FBMC-OQAM Systems,"In this paper, we propose a novel scattered pilot method for channel estimation in filter-bank multicarrier with offset quadrature amplitude modulation (FBMC-OQAM) systems. We refer to this as the coded auxiliary pilot (CAP) method. It builds on the idea of using a few auxiliary pilot (AP) symbols to eliminate the imaginary interference on each scattered pilot. At the same time, to keep the spectral efficiency of transmission high, the AP symbols are coded to also carry information symbols. Theoretical analysis and numerical results show that the CAP method can maintain high spectral efficiency and high power efficiency, while achieving complete imaginary interference cancelation. Taking the spectral and power efficiency, the imaginary interference cancelation performance, and the coding/decoding complexity into consideration, the CAP method with two to four AP symbols is identified as a good compromised choice for practice.","Interference,
Encoding,
Channel estimation,
Complexity theory,
OFDM,
Prototypes,
Decoding"
Optimal Cell Load and Throughput in Green Small Cell Networks With Generalized Cell Association,"This paper thoroughly explores the fundamental interactions between cell association, cell load, and throughput in a green (energy-efficient) small cell network in which all base stations form a homogeneous Poisson point process (PPP) of intensity λB and all users form another independent PPP of intensity λ∪. Cell voidness, usually disregarded due to rarity in cellular network modeling, is first theoretically analyzed under generalized (channel-aware) cell association (GCA). We show that the void cell probability cannot be neglected any more since it is bounded above by exp(-λ∪/λB) that is typically not small in a small cell network. The accurate expression of the void cell probability for GCA is characterized and it is used to derive the average cell and user throughputs. We learn that cell association and cell load λ∪/λB significantly affect these two throughputs. According to the average cell and user throughputs, the green cell and user throughputs are defined respectively to reflect whether the energy of a base station is efficiently used to transmit information or not. In order to achieve satisfactory throughput with certain level of greenness, cell load should be properly determined. We present the theoretical solutions of the optimal cell loads that maximize the green cell and user throughputs, respectively, and verify their correctness by simulation.","Throughput,
Base stations,
Load modeling,
Bismuth,
Power demand,
Shadow mapping,
Power control"
Control Plane Optimization in Software-Defined Vehicular Ad Hoc Networks,"The vehicle ad hoc network (VANET) is an emerging network technology that is expected to be cost-effective and adaptable, making it ideal to provide network connection service to drivers and passengers on today's roads. In the next generation of VANETs with fifth-generation (5G) networks, software-defined networking (SDN) technology will play a very important role in network management. However, for infotainment applications, high latency in VANET communication imposes a great challenge for network management, whereas direct communication through the cellular networks brings high cost. In this paper, we present an optimizing strategy to balance the latency requirement and the cost on cellular networks, in which we encourage vehicles to send the SDN control requests through the cellular networks by rebating network bandwidth. Furthermore, we model the interaction of the controller and vehicles as a two-stage Stackelberg game and analyze the game equilibrium. From the experimental results, the optimal rebating strategy provides smaller latency than other control plane structures.",
An Improved Artificial Bee Colony Algorithm for Solving Hybrid Flexible Flowshop With Dynamic Operation Skipping,"In this paper, we propose an improved discrete artificial bee colony (DABC) algorithm to solve the hybrid flexible flowshop scheduling problem with dynamic operation skipping features in molten iron systems. First, each solution is represented by a two-vector-based solution representation, and a dynamic encoding mechanism is developed. Second, a flexible decoding strategy is designed. Next, a right-shift strategy considering the problem characteristics is developed, which can clearly improve the solution quality. In addition, several skipping and scheduling neighborhood structures are presented to balance the exploration and exploitation ability. Finally, an enhanced local search is embedded in the proposed algorithm to further improve the exploitation ability. The proposed algorithm is tested on sets of the instances that are generated based on the realistic production. Through comprehensive computational comparisons and statistical analysis, the highly effective performance of the proposed DABC algorithm is favorably compared against several presented algorithms, both in solution quality and efficiency.","Iron,
Heuristic algorithms,
Dynamic scheduling,
Job shop scheduling,
Blast furnaces,
Encoding"
Bleeding Frame and Region Detection in the Wireless Capsule Endoscopy Video,"Wireless capsule endoscopy (WCE) enables noninvasive and painless direct visual inspection of a patient's whole digestive tract, but at the price of long time reviewing large amount of images by clinicians. Thus, an automatic computer-aided technique to reduce the burden of physicians is highly demanded. In this paper, we propose a novel color feature extraction method to discriminate the bleeding frames from the normal ones, with further localization of the bleeding regions. Our proposal is based on a twofold system. First, we make full use of the color information of WCE images and utilize K-means clustering method on the pixel represented images to obtain the cluster centers, with which we characterize WCE images as words-based color histograms. Then, we judge the status of a WCE frame by applying the support vector machine (SVM) and K-nearest neighbor methods. Comprehensive experimental results reveal that the best classification performance is obtained with YCbCr color space, cluster number 80 and the SVM. The achieved classification performance reaches 95.75% in accuracy, 0.9771 for AUC, validating that the proposed scheme provides an exciting performance for bleeding classification. Second, we propose a two-stage saliency map extraction method to highlight bleeding regions, where the first-stage saliency map is created by means of different color channels mixer and the second-stage saliency map is obtained from the visual contrast. Followed by an appropriate fusion strategy and threshold, we localize the bleeding areas. Quantitative as well as qualitative results show that our methods could differentiate the bleeding areas from neighborhoods correctly.","Image color analysis,
Hemorrhaging,
Histograms,
Feature extraction,
Support vector machines,
Visualization,
Accuracy"
Biomimetic Active Touch with Fingertips and Whiskers,"This study provides a synthetic viewpoint that compares, contrasts, and draws commonalities for biomimetic perception over a range of tactile sensors and tactile stimuli. Biomimetic active perception is formulated from three principles: (i) evidence accumulation based on leading models of perceptual decision making; (ii) action selection with an evidence-based policy, here based on overt focal attention; and (iii) sensory encoding of evidence based on neural coding. Two experiments with each of three biomimetic tactile sensors are considered: the iCub (capacitive) fingertip, the TacTip (optical) tactile sensor, and BIOTACT whiskers. For each sensor, one experiment considers a similar task (perception of shape and location) and the other a different tactile perception task. In all experiments, active perception with a biomimetic action selection policy based on focal attention outperforms passive perception with static or random action selection. The active perception also consistently reaches superresolved accuracy (hyperacuity) finer than the spacing between tactile elements. Biomimetic active touch thus offers a common approach for biomimetic tactile sensors to accurately and robustly characterize and explore non-trivial, uncertain environments analogous to how animals perceive the natural world.","Tactile sensors,
Pins,
Biomedical optical imaging,
Optical sensors"
Face recognition using deep multi-pose representations,"We introduce our method and system for face recognition using multiple pose-aware deep learning models. In our representation, a face image is processed by several pose-specific deep convolutional neural network (CNN) models to generate multiple pose-specific features. 3D rendering is used to generate multiple face poses from the input image. Sensitivity of the recognition system to pose variations is reduced since we use an ensemble of pose-specific CNN features. The paper presents extensive experimental results on the effect of landmark detection, CNN layer selection and pose model selection on the performance of the recognition pipeline. Our novel representation achieves better results than the state-of-the-art on IARPA's CS2 and NIST's IJB-A in both verification and identification (i.e. search) tasks.","Face,
Face recognition,
Feature extraction,
Pipelines,
Training,
Three-dimensional displays,
Solid modeling"
"Phase Retrieval from 1D Fourier Measurements: Convexity, Uniqueness, and Algorithms","This paper considers phase retrieval from the magnitude of one-dimensional over-sampled Fourier measurements, a classical problem that has challenged researchers in various fields of science and engineering. We show that an optimal vector in a least-squares sense can be found by solving a convex problem, thus establishing a hidden convexity in Fourier phase retrieval. We then show that the standard semidefinite relaxation approach yields the optimal cost function value (albeit not necessarily an optimal solution). A method is then derived to retrieve an optimal minimum phase solution in polynomial time. Using these results, a new measuring technique is proposed which guarantees uniqueness of the solution, along with an efficient algorithm that can solve large-scale Fourier phase retrieval problems with uniqueness and optimality guarantees.","Phase measurement,
Signal processing algorithms,
Frequency modulation,
Noise measurement,
Correlation,
Discrete Fourier transforms"
Visual Understanding via Multi-Feature Shared Learning With Global Consistency,"Image/video data is usually represented with multiple visual features. Fusion of multi-source information for establishing attributes has been widely recognized. Multi- feature visual recognition has recently received much attention in multimedia applications. This paper studies visual understanding via a newly proposed l2-norm-based multi-feature shared learning framework, which can simultaneously learn a global label matrix and multiple sub-classifiers with the labeled multi-feature data. Additionally, a group graph manifold regularizer composed of the Laplacian and Hessian graph is proposed. It can better preserve the manifold structure of each feature, such that the label prediction power is much improved through semi-supervised learning with global label consistency. For convenience, we call the proposed approach global-label- consistent classifier (GLCC). The merits of the proposed method include the following: 1) the manifold structure information of each feature is exploited in learning, resulting in a more faithful classification owing to the global label consistency; 2) a group graph manifold regularizer based on the Laplacian and Hessian regularization is constructed ; and 3) an efficient alternative optimization method is introduced as a fast solver owing its speed to convex sub-problems. Experiments on several benchmark visual datasets-the 17-category Oxford Flower dataset, the challenging 101- category Caltech dataset, the YouTube and Consumer Videos dataset, and the large-scale NUS-WIDE dataset-have been used for multimedia understanding . The results demonstrate that the proposed approach compares favorably with state-of-the-art algorithms. An extensive experiment using the deep convolutional activation features also shows the effectiveness of the proposed approach. The code will be available on http://www.escience.cn/people/lei/index.html.","Manifolds,
Visualization,
Laplace equations,
Semisupervised learning,
Multimedia communication,
Kernel,
Training"
Power System Real-Time Monitoring by Using PMU-Based Robust State Estimation Method,"Accurate real-time states provided by the state estimator are critical for power system reliable operation and control. This paper proposes a novel phasor measurement unit (PMU)-based robust state estimation method (PRSEM) to real-time monitor a power system under different operation conditions. To be specific, an adaptive weight assignment function to dynamically adjust the measurement weight based on the distance of big unwanted disturbances from the PMU measurements is proposed to increase algorithm robustness. Furthermore, a statistical test-based interpolation matrix H updating judgment strategy is proposed. The processed and resynced PMU information are used as priori information and incorporated to the modified weighted least square estimation to address the measurements imperfect synchronization between supervisory control and data acquisition and PMU measurements. Finally, the innovation analysis-based bad data (BD) detection method, which can handle the smearing effect and critical measurement errors, is presented. We evaluate PRSEM by using IEEE benchmark test systems and a realistic utility system. The numerical results indicate that, in short computation time, PRSEM can effectively track the system real-time states with good robustness and can address several kinds of BD.","Phasor measurement units,
Weight measurement,
Power measurement,
Voltage measurement,
Time measurement,
Interpolation,
Real-time systems"
Deep Fusion of Multiple Semantic Cues for Complex Event Recognition,"We present a deep learning strategy to fuse multiple semantic cues for complex event recognition. In particular, we tackle the recognition task by answering how to jointly analyze human actions (who is doing what), objects (what), and scenes (where). First, each type of semantic features (e.g., human action trajectories) is fed into a corresponding multi-layer feature abstraction pathway, followed by a fusion layer connecting all the different pathways. Second, the correlations of how the semantic cues interacting with each other are learned in an unsupervised cross-modality autoencoder fashion. Finally, by fine-tuning a large-margin objective deployed on this deep architecture, we are able to answer the question on how the semantic cues of who, what, and where compose a complex event. As compared with the traditional feature fusion methods (e.g., various early or late strategies), our method jointly learns the essential higher level features that are most effective for fusion and recognition. We perform extensive experiments on two real-world complex event video benchmarks, MED'11 and CCV, and demonstrate that our method outperforms the best published results by 21% and 11%, respectively, on an event recognition task.","Semantics,
Correlation,
Fuses,
Feature extraction,
Training,
Machine learning,
Kernel"
A Deterministic Analysis for LRR,"The recently proposed low-rank representation (LRR) method has been empirically shown to be useful in various tasks such as motion segmentation, image segmentation, saliency detection and face recognition. While potentially powerful, LRR depends heavily on the configuration of its key parameter, λ. In realistic environments where the prior knowledge about data is lacking, however, it is still unknown how to choose λ in a suitable way. Even more, there is a lack of rigorous analysis about the success conditions of the method, and thus the significance of LRR is a little bit vague. In this paper we therefore establish a theoretical analysis for LRR, striving for figuring out under which conditions LRR can be successful, and deriving a moderately good estimate to the key parameter λ as well. Simulations on synthetic data points and experiments on real motion sequences verify our claims.","Coherence,
Sparse matrices,
Image segmentation,
Information science"
Aligned Image Sets Under Channel Uncertainty: Settling Conjectures on the Collapse of Degrees of Freedom Under Finite Precision CSIT,"A conjecture made by Lapidoth et al. at Allerton 2005 (also an open problem presented at ITA 2006) states that the degrees of freedom (DoF) of a two user broadcast channel, where the transmitter is equipped with two antennas and each user is equipped with one antenna, must collapse under finite precision channel state information at the transmitter (CSIT). That this conjecture, which predates interference alignment, has remained unresolved, is emblematic of a pervasive lack of understanding of the DoF of wireless networks-including interference and X networks-under channel uncertainty at the transmitter(s). In this paper, we prove that the conjecture is true in all non-degenerate settings (e.g., where the probability density function of unknown channel coefficients exists and is bounded). The DoF collapse even when perfect channel knowledge for one user is available to the transmitter. This also settles a related recent conjecture by Tandon et al. The key to our proof is a bound on the number of codewords that can cast the same image (within noise distortion) at the undesired receiver whose channel is subject to finite precision CSIT, while remaining resolvable at the desired receiver whose channel is precisely known by the transmitter. We are also able to generalize the result along two directions. First, if the peak of the probability density function is √ allowed to scale as O(( √P)α), representing the concentration of probability density (improving CSIT) due to, e.g., quantized feedback at rate (α/2) log(P), then the DoF is bounded above by 1+α, which is also achievable under quantized feedback. Second, we generalize the result to arbitrary number of antennas at the transmitter, arbitrary number of single-antenna users, and complex channels. The generalization directly implies a collapse of DoF to unity under non-degenerate channel uncertainty for the general K-user interference and M × N user X networks as well.","Uncertainty,
Interference,
MISO,
Transmitting antennas,
Receivers,
Channel state information"
Reconstruction of Graph Signals Through Percolation from Seeding Nodes,"New schemes to recover signals defined in the nodes of a graph are proposed. Our focus is on reconstructing bandlimited graph signals, which are signals that admit a sparse representation in a frequency domain related to the structure of the graph. Most existing formulations focus on estimating an unknown graph signal by observing its value on a subset of nodes. By contrast, in this paper, we study the problem of inducing a known graph signal using as input a graph signal that is nonzero only for a small subset of nodes. The sparse signal is then percolated (interpolated) across the graph using a graph filter. Alternatively, one can interpret graph signals as network states and study graph-signal reconstruction as a network-control problem where the target class of states is represented by bandlimited signals. Three setups are investigated. In the first one, a single simultaneous injection takes place on several nodes in the graph. In the second one, successive value injections take place on a single node. The third one is a generalization where multiple nodes inject multiple signal values. For noiseless settings, conditions under which perfect reconstruction is feasible are given, and the corresponding schemes to recover the desired signal are specified. Scenarios leading to imperfect reconstruction, either due to insufficient or noisy signal value injections, are also analyzed. Moreover, connections with classical interpolation in the time domain are discussed. Specifically, for time-varying signals, where the ideal interpolator after uniform sampling is a (low-pass) filter, our proposed approach and the reconstruction of a sampled signal coincide. Nevertheless, for general graph signals, we show that these two approaches differ. The last part of the paper presents numerical experiments that illustrate the results developed through synthetic and real-world signal reconstruction problems.","Interpolation,
Signal reconstruction,
Context,
Noise measurement,
Time-domain analysis,
Social network services"
Direction of Arrival Estimation for Off-Grid Signals Based on Sparse Bayesian Learning,"The inherent limitation of the predefined spatial discrete grids greatly restricts the precision and feasibility of many sparse signal representation (SSR)-based direction-of-arrival (DOA) estimators. In this paper, we first propose a perturbed SSR-based model to alleviate this limitation by incorporating a bias parameter into the DOA estimation framework. Using this model, a perturbed sparse Bayesian learning-based algorithm, named PSBL, is developed to solve the DOA estimation problem, followed by a theoretical analysis of PSBL. We then present two algorithms based on the covariance matrix of the array output, named perturbed covariance matrix (PCM) and improved PCM (IPCM), respectively, to improve the convergence speed of PSBL. Extensive experiments show that the PSBL enjoys a high estimation accuracy in the cases of limited snapshots, low signal-to-noise-ratio, correlated, and spatially adjacent signals. In particular, PCM not only keeps the merits of PSBL, but also exhibits superiority over PSBL in terms of computational efficiency. IPCM has a better computational efficiency, but with a small sacrifice of its performance in a correlated signal scenario.","Direction-of-arrival estimation,
Estimation,
Arrays,
Bayes methods,
Phase change materials,
Sensors,
Signal processing algorithms"
Constellation Randomization Achieves Transmit Diversity for Single-RF Spatial Modulation,"The performance of spatial modulation (SM) is known to be dominated by the minimum Euclidean distance (MED) in the received SM constellation. In this paper, a symbol-scaling technique is proposed for SM in the multiple-input-multiple-output (MIMO) channel that enhances the MED to improve the performance of SM. This is achieved by forming fixed sets of candidate prescaling factors for the transmit antennas (TAs), which are randomly generated and are known at both the transmitter and the receiver. For a given channel realization, the transmitter chooses the specific set of factors that maximizes the MED. Given the channel state information (CSI) readily available at the receiver for detection, the receiver independently chooses the same set of prescaling factors and uses them for the detection of both the antenna index (AI) and the symbol of interest. We analytically calculate the attainable gains of the proposed technique, in terms of its transmit diversity order, based on both the distribution of the MED and on the theory of classical order statistics. Furthermore, we show that the proposed scheme offers a scalable performance-complexity tradeoff for SM by varying the number of candidate sets of prescaling factors, with significant performance improvements, compared to conventional SM.",
Molecular MIMO: From Theory to Prototype,"In diffusion-based molecular communication, information transport is governed by diffusion through a fluid medium. The achievable data rates for these channels are very low compared to the radio-based communication system, since diffusion can be a slow process. To improve the data rate, a novel multiple-input multiple-output (MIMO) design for molecular communication is proposed that utilizes multiple molecular emitters at the transmitter and multiple molecular detectors at the receiver (in RF communication these all correspond to antennas). Using particle-based simulators, the channel's impulse response is obtained and mathematically modeled. These models are then used to determine interlink interference (ILI) and intersymbol interference (ISI). It is assumed that when the receiver has incomplete information regarding the system and the channel state, low complexity symbol detection methods are preferred since the receiver is small and simple. Thus, four detection algorithms are proposed-adaptive thresholding, practical zero forcing with channel models excluding/including the ILI and ISI, and Genie-aided zero forcing. The proposed algorithms are evaluated extensively using numerical and analytical evaluations.","MIMO,
Receiving antennas,
Transmitting antennas,
Molecular communication,
Interference"
"Multiple Sclerosis Detection Based on Biorthogonal Wavelet Transform, RBF Kernel Principal Component Analysis, and Logistic Regression","To detect multiple sclerosis (MS) diseases early, we proposed a novel method on the hardware of magnetic resonance imaging, and on the software of three successful methods: biorthogonal wavelet transform, kernel principal component analysis, and logistic regression. The materials were 676 MR slices containing plaques from 38 MS patients, and 880 MR slices from 34 healthy controls. The statistical analysis showed our method achieved a sensitivity of 97.12±.14%, a specificity of 98.25±0.16%, and an accuracy of 97.76±0.10%. Our method is superior to five state-of-the-art approaches in MS detection.","Multiple sclerosis ,
Medical diagnosis,
Wavelet analysis,
Wavelet transforms,
Principal component analysis,
Logical regression,
Biorthogonal wavelet transform"
To Relay or Not to Relay: Learning Device-to-Device Relaying Strategies in Cellular Networks,"We consider a cellular network where mobile transceiver devices that are owned by self-interested users are incentivized to cooperate with each other using tokens, which they exchange electronically to “buy” and “sell” downlink relay services, thereby increasing the network's capacity compared to a network that only supports base station-to-device (B2D) communications. We investigate how an individual device in the network can learn its optimal cooperation policy online, which it uses to decide whether or not to provide downlink relay services for other devices in exchange for tokens. We propose a supervised learning algorithm that devices can deploy to learn their optimal cooperation strategies online given their experienced network environment. We then systematically evaluate the learning algorithm in various deployment scenarios. Our simulation results suggest that devices have the greatest incentive to cooperate when the network contains (i) many devices with high energy budgets for relaying, (ii) many highly mobile users (e.g., users in motor vehicles), and (iii) neither too few nor too many tokens. Additionally, within the token system, self-interested devices can effectively learn to cooperate online, and achieve up to 20 percent throughput gains on average compared to B2D communications alone, all while selfishly maximizing their own utilities.","Relays,
Mobile computing,
Mobile communication,
Downlink,
Interference,
Signal to noise ratio,
Bandwidth"
Transfer Learning in Brain-Computer Interfaces,"The performance of brain-computer interfaces (BCIs) improves with the amount of available training data; the statistical distribution of this data, however, varies across subjects as well as across sessions within individual subjects, limiting the transferability of training data or trained models between them. In this article, we review current transfer learning techniques in BCIs that exploit shared structure between training data of multiple subjects and/or sessions to increase performance. We then present a framework for transfer learning in the context of BCIs that can be applied to any arbitrary feature space, as well as a novel regression estimation method that is specifically designed for the structure of a system based on the electroencephalogram (EEG). We demonstrate the utility of our framework and method on subject-to-subject transfer in a motor-imagery paradigm as well as on session-to-session transfer in one patient diagnosed with amyotrophic lateral sclerosis (ALS), showing that it is able to outperform other comparable methods on an identical dataset.","Training data,
Brain modeling,
Data models,
Brain-computer interfaces,
Spatial filters,
Electroencephalography,
Machine learning"
MixGroup: Accumulative Pseudonym Exchanging for Location Privacy Enhancement in Vehicular Social Networks,"Vehicular social network (VSN) is envisioned to serve as an essential data sensing, exchanging and processing platform for the future Intelligent Transportation Systems. In this paper, we aim to address the location privacy issue in VSNs. In traditional pseudonym-based solutions, the privacy-preserving strength is mainly dependent on the number of vehicles meeting at the same occasion. We notice that an individual vehicle actually has many chances to meet several other vehicles. In most meeting occasions, there are only few vehicles appearing concurrently. Motivated by these observations, we propose a new privacy-preserving scheme, called MixGroup, which is capable of efficiently exploiting the sparse meeting opportunities for pseudonym changing. By integrating the group signature mechanism, MixGroup constructs extended pseudonym-changing regions, in which vehicles are allowed to successively exchange their pseudonyms. As a consequence, for the tracking adversary, the uncertainty of pseudonym mixture is accumulatively enlarged, and therefore location privacy preservation is considerably improved. We carry out simulations to verify the performance of MixGroup. Results indicate that MixGroup significantly outperforms the existing schemes. In addition, MixGroup is able to achieve favorable performance even in low traffic conditions.","Vehicles,
Privacy,
Roads,
Safety,
Social network services,
Target tracking,
Data privacy"
A Novel Recommendation Model Regularized with User Trust and Item Ratings,"We propose TrustSVD, a trust-based matrix factorization technique for recommendations. TrustSVD integrates multiple information sources into the recommendation model in order to reduce the data sparsity and cold start problems and their degradation of recommendation performance. An analysis of social trust data from four real-world data sets suggests that not only the explicit but also the implicit influence of both ratings and trust should be taken into consideration in a recommendation model. TrustSVD therefore builds on top of a state-of-the-art recommendation algorithm, SVD++ (which uses the explicit and implicit influence of rated items), by further incorporating both the explicit and implicit influence of trusted and trusting users on the prediction of items for an active user. The proposed technique is the first to extend SVD++ with social trust information. Experimental results on the four data sets demonstrate that TrustSVD achieves better accuracy than other ten counterparts recommendation techniques.","Predictive models,
Data models,
Recommender systems,
Computational modeling,
Prediction algorithms,
Algorithm design and analysis,
Testing"
Toward Optimal Feature Selection in Naive Bayes for Text Categorization,"Automated feature selection is important for text categorization to reduce feature size and to speed up learning process of classifiers. In this paper, we present a novel and efficient feature selection framework based on the Information Theory, which aims to rank the features with their discriminative capacity for classification. We first revisit two information measures: Kullback-Leibler divergence and Jeffreys divergence for binary hypothesis testing, and analyze their asymptotic properties relating to type I and type II errors of a Bayesian classifier. We then introduce a new divergence measure, called Jeffreys-Multi-Hypothesis (JMH) divergence, to measure multi-distribution divergence for multi-class classification. Based on the JMH-divergence, we develop two efficient feature selection methods, termed maximum discrimination (MD
) and methods, for text categorization. The promising results of extensive experiments demonstrate the effectiveness of the proposed approaches.","Text categorization,
Vocabulary,
Bayes methods,
Biomedical measurement,
Computational efficiency,
Frequency measurement,
Support vector machines"
"Sub-Channel Assignment, Power Allocation, and User Scheduling for Non-Orthogonal Multiple Access Networks","In this paper, we study the resource allocation and user scheduling problem for a downlink non-orthogonal multiple access network where the base station allocates spectrum and power resources to a set of users. We aim to jointly optimize the sub-channel assignment and power allocation to maximize the weighted total sum-rate while taking into account user fairness. We formulate the sub-channel allocation problem as equivalent to a many-to-many two-sided user-subchannel matching game in which the set of users and sub-channels are considered as two sets of players pursuing their own interests. We then propose a matching algorithm, which converges to a two-side exchange stable matching after a limited number of iterations. A joint solution is thus provided to solve the sub-channel assignment and power allocation problems iteratively. Simulation results show that the proposed algorithm greatly outperforms the orthogonal multiple access scheme and a previous non-orthogonal multiple access scheme.","Resource management,
NOMA,
Silicon carbide,
Receivers,
Games,
Interference,
Complexity theory"
Overview of High-Step-Up Coupled-Inductor Boost Converters,"High-step-up, high-efficiency, and cost-effective dc-dc converters, serving as an interfacing cell to boost the low-voltage output of renewable sources to the utility voltage level, are an important part in renewable energy systems. Over the past few years, there has been a substantial amount of studies devoted to high-step-up dc-dc converters. Among them, the category of coupled-inductor boost converters is widely researched and considered to be a promising solution for high-step-up applications. In this paper, these converters are categorized into five groups according to the major topological features. The derivation process, advantages, and disadvantages of these converters are systematically discussed, compared, and scrutinized. This paper aims to provide an introduction, review, and framework for the category of high-step-up coupled-inductor boost converters. General structures for the topologies are proposed to clarify the topological derivation process and to show potential gaps. Furthermore, challenges or directions are presented in this paper for deriving new topologies in this field.","Clamps,
Inductors,
Topology,
Switches,
Switching circuits,
Stress,
Renewable energy sources"
A Real-Time Selective Harmonic Elimination Based on a Transient-Free Inner Closed-Loop Control for Cascaded Multilevel Inverters,"Applying the selective harmonic elimination (SHE) technique to grid-connected-cascaded modular multilevel inverters has been widely discussed in the literature. However, due to the difficulties of solving high-order nonlinear transcendental equations, the SHE technique cannot be implemented in real time so its applications are limited. This paper presents a technique to convert the nonlinear equations to a specific control system and use a look-up table, integral controllers and a decoupling controller to help the system converge to a zero-error steady state. An inner instantaneous observer is introduced to directly extract the harmonic spectrum of the output voltages without applying FFT algorithm to output step voltage waveforms. It can not only simplify software design but also eliminate the phase delay generated by conventional spectrum extracting algorithm. The proposed technique can achieve an accurate switching angle control and a fast response. Simulation and experimental results verified that the system can achieve zero-error steady state within one line period.","Mathematical model,
Equations,
Harmonic analysis,
Switches,
Steady-state,
Observers"
Low-Rank Preserving Projections,"As one of the most popular dimensionality reduction techniques, locality preserving projections (LPP) has been widely used in computer vision and pattern recognition. However, in practical applications, data is always corrupted by noises. For the corrupted data, samples from the same class may not be distributed in the nearest area, thus LPP may lose its effectiveness. In this paper, it is assumed that data is grossly corrupted and the noise matrix is sparse. Based on these assumptions, we propose a novel dimensionality reduction method, named low-rank preserving projections (LRPP) for image classification. LRPP learns a low-rank weight matrix by projecting the data on a low-dimensional subspace. We use the L21 norm as a sparse constraint on the noise matrix and the nuclear norm as a low-rank constraint on the weight matrix. LRPP keeps the global structure of the data during the dimensionality reduction procedure and the learned low rank weight matrix can reduce the disturbance of noises in the data. LRPP can learn a robust subspace from the corrupted data. To verify the performance of LRPP in image dimensionality reduction and classification, we compare LRPP with the state-of-the-art dimensionality reduction methods. The experimental results show the effectiveness and the feasibility of the proposed method with encouraging results.",
Switched-Battery Boost-Multilevel Inverter with GA Optimized SHEPWM for Standalone Application,"This paper presents a boost-multilevel inverter design with integrated battery energy storage system for standalone application. The inverter consists of modular switched-battery cells and a full-bridge. It is multifunctional and has two modes of operation: 1) the charging mode, which charges the battery bank and 2) the inverter mode, which supplies ac power to the load. This inverter topology requires significantly less power switches compared to conventional topology such as cascaded H-bridge multilevel inverter, leading to reduced size/cost and improved reliability. To selectively eliminate low-order harmonics and control the desired fundamental component, nonlinear system equations are represented in fitness function through the manipulation of modulation index and the genetic algorithm (GA) is employed to find the optimum switching angles. A seven-level inverter prototype is implemented and experimental results are provided to verify the feasibility of the proposed inverter design.","Inverters,
Switches,
Topology,
Batteries,
MOSFET,
Genetic algorithms"
Real-Time Nonlinear Magnetic Equivalent Circuit Model of Induction Machine on FPGA for Hardware-in-the-Loop Simulation,"Real-time simulation of induction machine plays a crucial role in hardware-in-the-loop (HIL) scenarios. Due to the key advantages offered by magnetic equivalent circuits (MEC) for modeling induction machines compared with finite element analysis and electric equivalent circuits in terms of computational expense and achieved accuracy, this paper proposes a real-time nonlinear MEC of the induction machine. The model is emulated in real time on the field-programmable gate array (FPGA) by exploiting the parallel hardware architecture and fully pipelined arithmetic processing. The performance of the FPGA-based real-time emulated induction machine model is investigated and compared with the behavior of an experimental setup of induction machine and finite element results to demonstrate the effectiveness and accuracy of proposed approach for HIL applications.","Rotors,
Stator windings,
Real-time systems,
Mathematical model,
Computational modeling,
Integrated circuit modeling"
Stability Margin Improvement of Vehicular Platoon Considering Undirected Topology and Asymmetric Control,"The platooning of autonomous vehicles has the potential to significantly improve traffic capacity, enhance highway safety, and reduce fuel consumption. This paper studies the scalability limitations of large-scale vehicular platoons moving in rigid formation, and proposes two basic ways to improve stability margins, i.e., enlarging information topology and employing asymmetric control. A vehicular platoon is considered as a combination of four components: 1) node dynamics; 2) decentralized controller; 3) information flow topology; and 4) formation geometry. Tools, such as the algebraic graph theory and matrix factorization technique, are employed to model and analyze scalability limitations. The major findings include: 1) under linear identical decentralized controllers, the stability thresholds of control gains are explicitly established for platoons under undirected topologies. It is proved that the stability margins decay to zero as the platoon size increases unless there is a large number of following vehicles pinned to the leader and 2) the stability margins of vehicular platoons under bidirectional topologies using asymmetric controllers are always bounded away from zero and independent of the platoon size. Simulations with a platoon of passenger cars are used to demonstrate the findings.","Topology,
Vehicle dynamics,
Vehicles,
Scalability,
Stability criteria,
Eigenvalues and eigenfunctions"
Automated Crack Detection on Concrete Bridges,"Detection of cracks on bridge decks is a vital task for maintaining the structural health and reliability of concrete bridges. Robotic imaging can be used to obtain bridge surface image sets for automated on-site analysis. We present a novel automated crack detection algorithm, the STRUM (spatially tuned robust multifeature) classifier, and demonstrate results on real bridge data using a state-of-the-art robotic bridge scanning system. By using machine learning classification, we eliminate the need for manually tuning threshold parameters. The algorithm uses robust curve fitting to spatially localize potential crack regions even in the presence of noise. Multiple visual features that are spatially tuned to these regions are computed. Feature computation includes examining the scale-space of the local feature in order to represent the information and the unknown salient scale of the crack. The classification results are obtained with real bridge data from hundreds of crack regions over two bridges. This comprehensive analysis shows a peak STRUM classifier performance of 95% compared with 69% accuracy from a more typical image-based approach. In order to create a composite global view of a large bridge span, an image sequence from the robot is aligned computationally to create a continuous mosaic. A crack density map for the bridge mosaic provides a computational description as well as a global view of the spatial patterns of bridge deck cracking. The bridges surveyed for data collection and testing include Long-Term Bridge Performance program's (LTBP) pilot project bridges at Haymarket, VA, USA, and Sacramento, CA, USA.","Bridges,
Robots,
Robustness,
Laplace equations,
Visualization,
Concrete,
Image segmentation"
A Connectivity-Aware Approximation Algorithm for Relay Node Placement in Wireless Sensor Networks,"In two-tiered wireless sensor networks (WSNs), relay node placement is one of the key factors impacting the network energy consumption and the system overhead. In this paper, a novel connectivity-aware approximation algorithm for relay node placement in the WSNs is proposed to offer a major step forward in saving system overhead. In particular, a unique local search approximation algorithm (LSAA) is introduced to solve the relay node single cover (RNSC) problem. In this proposed LSAA approach, the sensor nodes are allocated into groups and then a local set cover (SC) for each group is achieved by a local search algorithm. The union set of all the local SCs constitutes a SC of the RNSC problem. The approximation ratio and the time complexity of the LSAA are analyzed by rigorous proof. In addition, the LSAA approach has been extended to solve the relay node double cover problem. Then, a relay location selection algorithm (RLSA) is proposed to utilize the resulting SC from the LSAA in combining RLSA with the minimum spanning tree heuristic to build the high-tier connectivity. As the RLSA searches for a nearest location to the sink node for each relay node, the high-tier network built by the RLSA becomes denser than that by existing works. As a result, the number of added relay nodes for building the connectivity of the high-tier WSN can be significantly saved. Simulation results clearly demonstrate that the proposed LSAA outperforms the approaches reported in literature and the RLSA-based algorithm can noticeably save relay nodes newly deployed for the high-tier connectivity.","Relays,
Sensors,
Approximation algorithms,
Approximation methods,
Wireless sensor networks,
Search problems,
Bridges"
Quadrature Spatial Modulation Performance Over Nakagami- m Fading Channels,"This paper analyzes the performance of the recently proposed quadrature spatial modulation (QSM) multiple-input-multiple-output (MIMO) system over Nakagami-m fading channel. In the analysis, the general distribution of the Nakagami-m channel phase is considered. In the literature, performance analysis of spatial modulation (SM) over Nakagami-m channel with uniform phase is conducted. However, apart from the very special case of m = 1, where Nakagami-m fading corresponds to Rayleigh fading, the phase of the Nakagami-m distribution is not uniformly distributed. It is shown in this paper that the phase of the channel has major impact on the performance of spatial multiplexing MIMO systems such as SM and QSM systems. A general upper bound expression for the average bit error ratio (ABER) performance of QSM is derived, and the impact of different channel parameters is studied. Monte Carlo simulation results are provided to corroborate the exactness of the derived analysis.","Signal to noise ratio,
MIMO,
Modulation,
Rayleigh channels,
Indexes,
Antennas"
Impact of NoC interconnect shorts on performance metrics,"Duplication, misrouting, and dropping of packets due to short faults on network-on-chip (NoC) interconnects have become a burden and significant impact on performance metrics. This paper proposes an adaptive approach that detects and locates intra-channel short faults on NoC interconnects, and accounts impact of the faults on performance metrics. The model is scalable with all NoCs. Simulations show the effectiveness of proposed approach and measure different performance metrics with faulty channels on various NoCs.","Wires,
Testing,
Measurement,
Switches,
Payloads,
Silicon,
Fault detection"
Semantics-Based Online Malware Detection: Towards Efficient Real-Time Protection Against Malware,"Recently, malware has increasingly become a critical threat to embedded systems, while the conventional software solutions, such as antivirus and patches, have not been so successful in defending the ever-evolving and advanced malicious programs. In this paper, we propose a hardware-enhanced architecture, GuardOL, to perform online malware detection. GuardOL is a combined approach using processor and field-programmable gate array (FPGA). Our approach aims to capture the malicious behavior (i.e., high-level semantics) of malware. To this end, we first propose the frequency-centric model for feature construction using system call patterns of known malware and benign samples. We then develop a machine learning approach (using multilayer perceptron) in FPGA to train classifier using these features. At runtime, the trained classifier is used to classify the unknown samples as malware or benign, with early prediction. The experimental results show that our solution can achieve high classification accuracy, fast detection, low power consumption, and flexibility for easy functionality upgrade to adapt to new malware samples. One of the main advantages of our design is the support of early prediction-detecting 46% of malware within first 30% of their execution, while 97% of the samples at 100% of their execution, with <;3% false positives.",
Optimal Resource Sharing in 5G-Enabled Vehicular Networks: A Matrix Game Approach,"Vehicular networks are expected to accommodate a large number of data-heavy mobile devices and multiapplication services, whereas it faces a significant challenge when we need to deal with the ever-increasing demand of mobile traffic. In this paper, we present a new paradigm of fifth-generation (5G)-enabled vehicular networks to improve network capacity and system computing capability. We extend the original cloud radio access network (C-RAN) to integrate local cloud services to provide a low-cost, scalable, self-organizing, and effective solution. The new C-RAN is named enhanced C-RAN (EC-RAN). Cloudlets in EC-RAN are geographically distributed for local services. Furthermore, device-to-device (D2D) and heterogeneous networks are essential technologies in 5G systems. They can greatly improve spectrum efficiency and support large-scale live video streaming in short-distance communications. We exploit matrix game theoretical approach to operate the cloudlet resource management and allocation. A Nash equilibrium solution can be obtained by a Karush-Kuhn-Tucker (KKT) nonlinear complementarity approach. Illustrative results indicate that the proposed resource-sharing scheme with the geodistributed cloudlets can improve resource utilization and reduce system power consumption. Moreover, with the integration of a software-defined network architecture, a vehicular network can easily reach a globally optimal solution.","Cloud computing,
Resource management,
Vehicles,
5G mobile communication,
Games,
Computer architecture,
Base stations"
Cooperation via Spectrum Sharing for Physical Layer Security in Device-to-Device Communications Underlaying Cellular Networks,"In this paper, we investigate the cooperation issue via spectrum sharing when employing physical layer security concept into the device-to-device (D2D) communications underlaying cellular networks. First, we derive the optimal joint power control solutions of the cellular communication links and D2D pairs in terms of the secrecy capacity under a simple cooperation case and further propose a secrecy-based access control scheme with the best D2D pair selection mechanism. Then, we consider a more general case that multiple D2D pairs can access the same resource block (RB) and one D2D pair is also permitted to access multiple RBs, and provide a novel cooperation mechanism in the investigated network. Furthermore, we formulate the provided cooperation mechanism among cellular communication links and D2D pairs as a coalitional game. Then, based on a newly defined max-coalition order in the constructed game, we further propose a merge-and-split-based coalition formation algorithm for cellular communication links and D2D pairs to achieve efficient and effective cooperation, leading to improved system secrecy rate and social welfare. Simulation results indicate the efficiency of the proposed secrecy-based access control scheme and the proposed merge-and-split-based coalition formation algorithm.","Interference,
Games,
Uplink,
Physical layer,
Security,
Resource management,
Signal to noise ratio"
LATCH: Learned arrangements of three patch codes,"We present a novel means of describing local image appearances using binary strings. Binary descriptors have drawn increasing interest in recent years due to their speed and low memory footprint. A known shortcoming of these representations is their inferior performance compared to larger, histogram based descriptors such as the SIFT. Our goal is to close this performance gap while maintaining the benefits attributed to binary representations. To this end we propose the Learned Arrangements of Three Patch Codes descriptors, or LATCH. Our key observation is that existing binary descriptors are at an increased risk from noise and local appearance variations. This, as they compare the values of pixel pairs: changes to either of the pixels can easily lead to changes in descriptor values and compromise their performance. In order to provide more robustness, we instead propose a novel means of comparing pixel patches. This ostensibly small change, requires a substantial redesign of the descriptors themselves and how they are produced. Our resulting LATCH representation is rigorously compared to state-of-the-art binary descriptors and shown to provide far better performance for similar computation and space requirements.","Latches,
Histograms,
Feature extraction,
Robustness,
Visualization,
Training data,
Supervised learning"
Dynamic Clustering and on/off Strategies for Wireless Small Cell Networks,"In this paper, a novel cluster-based approach for maximizing the energy efficiency of wireless small cell networks is proposed. A dynamic mechanism is proposed to locally group coupled small cell base stations (SBSs) into clusters based on location and traffic load. Within each formed cluster, SBSs coordinate their transmission parameters to minimize a cost function, which captures the tradeoffs between energy efficiency and flow level performance, while satisfying their users' quality-of-service requirements. Due to the lack of intercluster communications, clusters compete with one another to improve the overall network's energy efficiency. This intercluster competition is formulated as a noncooperative game between clusters that seek to minimize their respective cost functions. To solve this game, a distributed learning algorithm is proposed using which clusters autonomously choose their optimal transmission strategies based on local information. It is shown that the proposed algorithm converges to a stationary mixed-strategy distribution, which constitutes an epsilon-coarse correlated equilibrium for the studied game. Simulation results show that the proposed approach yields significant performance gains reaching up to 36% of reduced energy expenditures and upto 41% of reduced fractional transfer time compared to conventional approaches.","Wireless communication,
Energy consumption,
Peer-to-peer computing,
Games,
Interference,
Switches,
Clustering methods"
Resolving the Vergence-Accommodation Conflict in Head-Mounted Displays,"The vergence-accommodation conflict (VAC) remains a major problem in head-mounted displays for virtual and augmented reality (VR and AR). In this review, I discuss why this problem is pivotal for nearby tasks in VR and AR, present a comprehensive taxonomy of potential solutions, address advantages and shortfalls of each design, and cover various ways to better evaluate the solutions. The review describes how VAC is addressed in monocular, stereoscopic, and multiscopic HMDs, including retinal scanning and accommodation-free displays. Eye-tracking-based approaches that do not provide natural focal cues-gaze-guided blur and dynamic stereoscopy-are also covered. Promising future research directions in this area are identified.","Retina,
Three-dimensional displays,
Lenses,
Optical imaging,
Stereo image processing,
Mirrors"
Efficient and Anonymous Mobile User Authentication Protocol Using Self-Certified Public Key Cryptography for Multi-Server Architectures,"Rapid advances in wireless communication technologies have paved the way for a wide range of mobile devices to become increasingly ubiquitous and popular. Mobile devices enable anytime, anywhere access to the Internet. The fast growth of many types of mobile services used by various users has made the traditional single-server architecture inefficient in terms of its functional requirements. To ensure the availability of various mobile services, there is a need to deploy multi-server architectures. To ensure the security of various mobile service applications, the anonymous mobile user authentication (AMUA) protocol without online registration using the self-certified public key cryptography (SCPKC) for multi-server architectures was proposed in the past. However, most of the past AMUA solutions suffer from malicious attacks or have unacceptable computation and communication costs. To address these drawbacks, we propose a new AMUA protocol that uses the SCPKC for multi-server architectures. In contrast to the existing AMUA protocols, our proposed AMUA protocol incurs lower computation and communication costs. By comparing with two of the latest AMUA protocols, the computation and the communication costs of our protocol are at least 74.93% and 37.43% lower than them, respectively. Moreover, the security analysis of our AMUA protocol demonstrates that it satisfies the security requirements in practical applications and is provably secure in the novel security model. By maintaining security at various levels, our AMUA protocol is more practical for various mobile applications.","Protocols,
Mobile communication,
Computer architecture,
Cryptography,
Servers,
Authentication"
Healthcare Big Data Voice Pathology Assessment Framework,"The fast-growing healthcare big data plays an important role in healthcare service providing. Healthcare big data comprise data from different structured, semi-structured, and unstructured sources. These data sources vary in terms of heterogeneity, volume, variety, velocity, and value that traditional frameworks, algorithms, tools, and techniques are not fully capable of handling. Therefore, a framework is required that facilitates collection, extraction, storage, classification, processing, and modeling of this vast heterogeneous volume of data. This paper proposes a healthcare big data framework using voice pathology assessment (VPA) as a case study. In the proposed VPA system, two robust features, MPEG-7 low-level audio and the interlaced derivative pattern, are used for processing the voice or speech signals. The machine learning algorithms in the form of a support vector machine, an extreme learning machine, and a Gaussian mixture model are used as the classifier. In the experiments, the proposed VPA system shows its efficiency in terms of accuracy and time requirement.","Medical services,
Big data,
Feature extraction,
Pathology,
Data mining,
Biomedical monitoring,
Machine learning algorithms,
Classification"
Seizure Suppression Efficacy of Closed-Loop Versus Open-Loop Deep Brain Stimulation in a Rodent Model of Epilepsy,"We assess and compare the effects of both closed-loop and open-loop neurostimulation of the rat hippocampus by means of a custom low-power programmable therapeutic neurostimulation device on the suppression of spontaneous seizures in a rodent model of epilepsy. Chronic seizures were induced by intraperitoneal kainic acid injection. Two bipolar electrodes were implanted into the CA1 regions of both hippocampi. The electrodes were connected to the custom-built programmable therapeutic neurostimulation device that can trigger an electrical stimulation either in a periodic manner or upon detection of the intracerebral electroencephalographic (icEEE) seizure onset. This device includes a microchip consisting of a 256-channel icEEG recording system and a 64-channel stimulator, and a programmable seizure detector implemented in a field-programmable gate array (FPGA). The neurostimulator was used to evaluate seizure suppression efficacy in ten epileptic rats for a total of 240 subject-days (5760 subject-hours). For this purpose, all rats were randomly divided into two groups: the no-stimulation group and the stimulation group. The no-stimulation group did not receive stimulation. The stimulation group received, first, closed-loop stimulation and, next, open-loop stimulation. The no-stimulation and stimulation groups had a similar seizure frequency baseline, averaging five seizures per day. Closed-loop stimulation reduced seizure frequency by 90% and open-loop stimulation reduced seizure frequency by 17%, both in the stimulation group as compared to the no-stimulation group.","Rats,
Epilepsy,
Electrodes,
Hippocampus,
Electroencephalography,
Electrical stimulation"
RSS Distribution-Based Passive Localization and Its Application in Sensor Networks,"Passive localization is fundamental for many applications such as activity monitoring and real-time tracking. Existing received signal strength (RSS)-based passive localization approaches have been proposed in the literature, which depend on dense deployment of wireless communication nodes to achieve high accuracy. Thus, they are not cost-effective and scalable. This paper proposes the RSS distribution-based localization (RDL) technique, which can achieve high localization accuracy without dense deployment. In essence, RDL leverages the RSS and the diffraction theory to enable RSS-based passive localization in sensor networks. Specifically, we analyze the fine-grained RSS distribution properties at a variety of node distances and reveal that the structure of the triangle is efficient for low-cost passive localization. We further construct a unit localization model aiming at high accuracy localization. Experimental results show that RDL can improve the localization accuracy by up to 50%, compared to existing approaches when the error tolerance is less than 1.5 m. In addition, we apply RDL to facilitate the application of moving trajectory identification. Our moving trajectory identification includes two phases: an offline phase where the possible locations can be estimated by RDL and an online phase where we precisely identify the moving trajectory. We conducted extensive experiments to show its effectiveness for this application - the estimated trajectory is close to the ground truth.","Diffraction,
Fresnel reflection,
Monitoring,
Trajectory,
Wireless communication,
Radar tracking,
Receivers"
Evaluation Criteria for Sparse Matrix Storage Formats,"When authors present new storage formats for sparse matrices, they usually focus mainly on a single evaluation criterion, which is the performance of sparse matrix-vector multiplication (SpMV) in FLOPS. Though such an evaluation is essential, it does not allow to directly compare the presented format with its competitors. Moreover, in case that matrices are within an HPC application constructed in different formats, this criterion alone is not sufficient for the key decision whether or not to convert them into the presented format for the SpMV-based application phase. We establish ten evaluation criteria for sparse matrix storage formats, discuss their advantages and disadvantages, and provide general suggestions for format authors/evaluators to make their work more valuable for the HPC community.",
High Precision Automatic Assembly Based on Microscopic Vision and Force Information,"An automatic system is developed to realize high precision assembly of two components in the size of mm level with an interference fit in 3-dimensional (3-D) space with 6-degree-of- freedoms (DOF), which consists of a manipulator, an adjusting platform, a sensing system and a computer. The manipulator is employed to align component B to the component A in position. The adjusting platform aligns the component A to component B in orientations and inserts A into B. The sensing system includes three microscopes and a force sensor. The three microscopes are mounted approximately orthogonal to observe components from different directions in the aligning stage. The force sensor is introduced to detect the contact force in assembly process. In the aligning stage, a pose control method based on image Jacobian matrix is proposed. In the insertion stage, a position control method based on the contact force is proposed. The calibration of image Jacobian matrix is also presented. Experimental results demonstrate the effectiveness of the proposed system and methods.","Microscopy,
Cameras,
Manipulators,
Assembly,
Feature extraction,
Jacobian matrices,
Force"
Distributed Spatial Modulation: A Cooperative Diversity Protocol for Half-Duplex Relay-Aided Wireless Networks,"In this paper, distributed spatial modulation (DSM) is introduced. DSM is a cooperative diversity protocol for multirelay wireless networks, which is based on the concept of spatial modulation (SM). The distinguishable feature of DSM lies in improving the reliability of the source via distributed diversity and by increasing the aggregate throughput of the network since new data is transmitted during each transmission phase. This is achieved by encoding the data transmitted from the source into the spatial positions of the available relays and by exploiting the signal domain to transmit the data of the relays. At the destination, a diversity combiner that is robust to demodulation errors at the relays is proposed, and its end-to-end error probability and achievable diversity are studied. It is mathematically proved that DSM allows the source to achieve second-order diversity. With the aid of Monte Carlo simulations, DSM is compared against state-of-the-art cooperative protocols, and it is shown to provide a better error probability.","Relays,
Demodulation,
Protocols,
Throughput,
Encoding,
Broadcasting"
Multilayer Extreme Learning Machine With Subnetwork Nodes for Representation Learning,"The extreme learning machine (ELM), which was originally proposed for “generalized” single-hidden layer feedforward neural networks, provides efficient unified learning solutions for the applications of clustering, regression, and classification. It presents competitive accuracy with superb efficiency in many applications. However, ELM with subnetwork nodes architecture has not attracted much research attentions. Recently, many methods have been proposed for supervised/unsupervised dimension reduction or representation learning, but these methods normally only work for one type of problem. This paper studies the general architecture of multilayer ELM (ML-ELM) with subnetwork nodes, showing that: 1) the proposed method provides a representation learning platform with unsupervised/supervised and compressed/sparse representation learning and 2) experimental results on ten image datasets and 16 classification datasets show that, compared to other conventional feature learning methods, the proposed ML-ELM with subnetwork nodes performs competitively or much better than other feature learning methods.","Feature extraction,
Artificial neural networks,
Nonhomogeneous media,
Learning systems,
Training,
Hafnium,
Neurons"
Network-Based Fault Detection Filter and Controller Coordinated Design for Unmanned Surface Vehicles in Network Environments,"This paper is concerned with the network-based modeling, and observer-based fault detection filter (FDF) and controller coordinated design for an unmanned surface vehicle (USV) in network environments. Network-based models for the USV subject to actuator faults and wave-induced disturbances are established for the first time by introducing an observer-based FDF, and considering network-induced characteristics such as delays and packet dropouts in the sampler-to-control station communication network channel and the control station-to-actuator communication network channel. Based on these models, network-based FDF and controller coordinated design criteria are derived to asymptotically stabilize the residual system. The designed network-based FDF and controller can guarantee the sensitivity of the residual signal to faults and the robustness of the USV to external disturbances. Fault detection performance analysis verifies the effectiveness of the proposed network-based FDF and controller coordinated design scheme for the USV in network environments.","Fault detection,
Communication networks,
Marine vehicles,
Vehicles,
Delays,
Actuators,
Informatics"
Inter-Area Resonance in Power Systems From Forced Oscillations,"This paper discusses a recent event in the western American power system when a forced oscillation was observed at a frequency that was close to a well-known 0.38-Hz inter-area electromechanical mode frequency of the western system. The event motivates a systematic investigation in this paper on the possibility of resonant interactions between forced oscillations and electromechanical inter-area oscillatory modes in power systems. When the natural oscillatory mode of a power system is poorly damped, and the forced oscillation occurs at a frequency close to system mode frequency at critical locations for the mode, resonance is observed in simulation test cases of the paper. It is shown that the MW oscillations on tie-lines can be as high as 477 MW from a 10-MW forced oscillation in Kundur test system because of resonance. This paper discusses the underlying system conditions and effects as related to resonance in power systems caused by forced oscillations and discusses ways to detect such scenarios using synchrophasors. Simulated data from Kundur two-area test power system as well as measurement data from western American power system are used to study the effect of forced oscillations in power systems.","Oscillators,
Resonant frequency,
Damping,
Phasor measurement units,
Shape,
Estimation,
Power system stability"
Optimal Precoding for a QoS Optimization Problem in Two-User MISO-NOMA Downlink,"In this letter, based on the non-orthogonal multiple access (NOMA) concept, a quality-of-service optimization problem for two-user multiple-input-single-output broadcast systems is considered, given a pair of target interference levels. The minimal power and the optimal precoding vectors are obtained by considering its Lagrange dual problem and via Newton's iterative algorithm, respectively. Moreover, the closed-form expressions of the minimal transmission power for some special cases are also derived. One of these cases is termed quasi-degraded, which is the key point and will be discussed in detail in this letter. Our analysis further figures out that the proposed NOMA scheme can approach nearly the same performance as optimal dirty paper coding, as verified by computer simulations.",
Wireless Software Defined Networking: A Survey and Taxonomy,"One of the primary architectural principles behind the Internet is the use of distributed protocols, which facilitates fault tolerance and distributed management. Unfortunately, having nodes (i.e., switches and routers) perform control decisions independently makes it difficult to control the network or even understand or debug its overall emergent behavior. As a result, networks are often inefficient, unstable, and fragile. This Internet architecture also poses a significant, often insurmountable, challenge to the deployment of new protocols and evolution of existing ones. Software defined networking (SDN) is a recent networking architecture with promising properties relative to these weaknesses in traditional networks. SDN decouples the control plane, which makes the network forwarding decisions, from the data plane, which mainly forwards the data. This decoupling enables more centralized control where coordinated decisions directly guide the network to desired operating conditions. Moreover, decoupling the control enables graceful evolution of protocols, and the deployment of new protocols without having to replace the data plane switches. In this survey, we review recent work that leverages SDN in wireless network settings, where they are not currently widely adopted or well understood. More specifically, we evaluate the use of SDN in four classes of popular wireless networks: cellular, sensor, mesh, and home networks. We classify the different advantages that can be obtained by using SDN across this range of networks, and hope that this classification identifies unexplored opportunities for using SDN to improve the operation and performance of wireless networks.","Wireless networks,
Software,
Wireless sensor networks,
Control systems,
Protocols,
Computer architecture"
A Bayesian Classification Approach Using Class-Specific Features for Text Categorization,"In this paper, we present a Bayesian classification approach for automatic text categorization using class-specific features. Unlike conventional text categorization approaches, our proposed method selects a specific feature subset for each class. To apply these class-specific features for classification, we follow Baggenstoss's PDF Projection Theorem (PPT) to reconstruct the PDFs in raw data space from the class-specific PDFs in low-dimensional feature subspace, and build a Bayesian classification rule. One noticeable significance of our approach is that most feature selection criteria, such as Information Gain (IG) and Maximum Discrimination (MD), can be easily incorporated into our approach. We evaluate our method's classification performance on several real-world benchmarks, compared with the state-of-the-art feature selection approaches. The superior results demonstrate the effectiveness of the proposed approach and further indicate its wide potential applications in data mining.","Text categorization,
Indexes,
Bayes methods,
Biomedical measurement,
Benchmark testing,
Dictionaries"
Orchestrating Virtualized Network Functions,"Middleboxes or network appliances like firewalls, proxies, and WAN optimizers have become an integral part of today's ISP and enterprise networks. Middlebox functionalities are usually deployed on expensive and proprietary hardware that require trained personnel for deployment and maintenance. Middleboxes contribute significantly to a network's capital and operation costs. In addition, organizations often require their traffic to pass through a specific sequence of middleboxes for compliance with security and performance policies. This makes the middlebox deployment and maintenance tasks even more complicated. Network function virtualization (NFV) is an emerging and promising technology that is envisioned to overcome these challenges. It proposes to move packet processing from dedicated hardware middleboxes to software running on commodity servers. In NFV terminology, software middleboxes are referred to as virtualized network functions (VNFs). It is a challenging problem to determine the required number and placement of VNFs that optimizes network operational costs and utilization, without violating service level agreements. We call this the VNF orchestration problem (VNF-OP) and provide an integer linear programming formulation with implementation in CPLEX. We also provide a dynamic programming-based heuristic to solve larger instances of VNF-OP. Trace driven simulations on realworld network topologies demonstrate that the heuristic can provide solutions that are within 1.3 times of the optimal solution. Our experiments suggest that a VNF-based approach can provide more than 4× reduction in the operational cost of a network.","Middleboxes,
Servers,
Virtualization,
Mathematical model,
Optimization"
Go-ICP: A Globally Optimal Solution to 3D ICP Point-Set Registration,"The Iterative Closest Point (ICP) algorithm is one of the most widely used methods for point-set registration. However, being based on local iterative optimization, ICP is known to be susceptible to local minima. Its performance critically relies on the quality of the initialization and only local optimality is guaranteed. This paper presents the first globally optimal algorithm, named Go-ICP, for Euclidean (rigid) registration of two 3D point-sets under the
L
2
error metric defined in ICP. The Go-ICP method is based on a branch-and-bound scheme that searches the entire 3D motion space
SE(3)
. By exploiting the special structure of
SE(3)
geometry, we derive novel upper and lower bounds for the registration error function. Local ICP is integrated into the BnB scheme, which speeds up the new method while guaranteeing global optimality. We also discuss extensions, addressing the issue of outlier robustness. The evaluation demonstrates that the proposed method is able to produce reliable registration results regardless of the initialization. Go-ICP can be applied in scenarios where an optimal solution is desirable or where a good initialization is not always available.","Iterative closest point algorithm,
Three-dimensional displays,
Robustness,
Convergence,
Optimization,
Yttrium"
A Medium-Scale Distributed System for Computer Science Research: Infrastructure for the Long Term,"The Dutch Advanced School for Computing and Imaging has built five generations of a 200-node distributed system over nearly two decades while remaining aligned with the shifting computer science research agenda. The system has supported years of award-winning research, underlining the benefits of investing in a smaller-scale, tailored design.","Programming,
Protocols,
Supercomputers,
Peer-to-peer computing,
Optical fiber networks,
Image processing"
A Task-Oriented Framework for Networked Wearable Computing,"Body Sensor Networks (BSNs) have become prominent in research and industry alike as a powerful enabler of novel applications in human-centered domains. However, developing applications on such systems is still a cumbersome process, due to the lack of suitable software abstractions and the difficulties in managing wearable computing application within the stringent constraints of embedded systems. In this paper, we introduce a novel framework, SPINE2 (Signal Processing In Node Environment), which allows task-oriented programming on a platform-independent architecture. We demonstrate how fairly sophisticated signal-processing applications can be realized in the form of easy-to-implement embedded processes. The proposed architecture is tested experimentally and its features are illustrated through a nontrivial case study. In the last years, several frameworks and middlewares have been conceived and made available to support high-level programming in WSNs. These provide a generic set of features that can only be used for the most common application domains. However, it is hard to efficiently support the more specific domain of BSNs, which requires specific capabilities. In order to fully satisfy the BSN-based requirements, SPINE2 has been conceived as an effective and efficient tool for developing distributed signal-processing applications. Its task-oriented paradigm allows developers to specify the applications' behavior by abstracting away any low-level details concerning the platform hardware and the communication protocol. Moreover, its platform-independent architecture enables code reusability and portability, as well as application interoperability and platform heterogeneity. To demonstrate the effectiveness of the proposed framework and the efficiency of the runtime environment, a BSN-based activity recognition system has been developed through SPINE2. The easiness in implementing such a complex system thanks to both the provided programming abstractions and the framework components reusability is shown, as well as the efficiency of the whole system whose performance has been evaluated under a range of metrics.","Programming,
Wireless sensor networks,
Middleware,
Hardware,
Runtime,
Computer architecture"
Nonintrusive Load Monitoring Using Wavelet Design and Machine Learning,"This paper presents a new concept based on wavelet design and machine learning applied to nonintrusive load monitoring. The wavelet coefficients of length-6 filter are determined using procrustes analysis and are used to construct new wavelets to match the load signals to be detected, unlike previous work which used previously designed wavelet functions that are special cases of Daubechies filters to suit other nonpower system applications such as communications and image processing. The results of applying the new concept to a test system consisting of four loads have shown that the newly designed wavelet can improve the prediction accuracy compared with that obtained using Daubechies filter of order three while keeping the prominent features of the pattern in the detail levels.","Wavelet transforms,
Feature extraction,
Wavelet analysis,
Indexes,
Transient analysis,
Switches"
Dissipation of Information in Channels With Input Constraints,"One of the basic tenets in information theory, the data processing inequality states that the output divergence does not exceed the input divergence for any channel. For channels without input constraints, various estimates on the amount of such contraction are known, Dobrushin's coefficient for the total variation being perhaps the most well-known. This paper investigates channels with an average input cost constraint. It is found that, while the contraction coefficient typically equals one (no contraction), the information nevertheless dissipates. A certain nonlinear function, the Dobrushin curve of the channel, is proposed to quantify the amount of dissipation. Tools for evaluating the Dobrushin curve of additive-noise channels are developed based on coupling arguments. Some basic applications in stochastic control, uniqueness of Gibbs measures, and fundamental limits of noisy circuits are discussed. As an application, it is shown that, in the chain of n power-constrained relays and Gaussian channels, the end-to-end mutual information and maximal squared correlation decay as O(log log n/log n), which is in stark contrast with the exponential decay in chains of discrete channels. Similarly, the behavior of noisy circuits (composed of gates with bounded fan-in) and broadcasting of information on trees (of bounded degree) does not experience threshold behavior in the signal-to-noise ratio (SNR). Namely, unlike the case of discrete channels, the probability of bit error stays bounded away from 1/2 regardless of the SNR.","TV,
Markov processes,
Relays,
Kernel,
Correlation,
Signal to noise ratio"
Coping With Heterogeneous Video Contributors and Viewers in Crowdsourced Live Streaming: A Cloud-Based Approach,"With the advances in personal computing devices and the prevalence of broadband network and wireless mobile network accesses, end-users are no longer pure content consumers, but contributors, too. In today's crowdsourced streaming systems, numerous broadcasters lively stream their video content, e.g., live events or online game scenes, to fellow viewers. Compared to professional video producers and broadcasters, these new generation broadcasters are geo-distributed globally and highly heterogeneous in terms of the generated video quality and the network/system configurations. The scalability and heterogeneity challenges therefore lie on both broadcasters and the viewers, which call for massive transcoding, and two critical issues: 1) choosing video representation set that maximizes viewer satisfaction and 2) allocating computational resources that minimize operational costs, must be systematically optimized in the global scale. In this paper, we present a generic framework utilizing the powerful and elastic cloud computing services for crowdsourced live streaming with heterogeneous broadcasters and viewers. We jointly consider the viewer satisfaction and the service availability/pricing of geo-distributed cloud resources for transcoding. We develop an optimal scheduler for allocating cloud instances with no regional constraints. We then extend the solution to accommodate regional constraints, and discuss a series of practical enhancements, including popularity forecasting, initialization latency, and viewer feedbacks. Our solutions have been evaluated under diverse networks and cloud system configurations as well as parameter settings. The trace-driven simulation confirms the superiority of our design, while our Planetlab-based experiment offers further practical hints toward real-world migration.","Streaming media,
Cloud computing,
Transcoding,
Servers,
TV,
YouTube,
Games"
Bi-level Protected Compressive Sampling,"Some pioneering works have investigated embedding cryptographic properties in compressive sampling (CS) in a way similar to one-time pad symmetric cipher. This paper tackles the problem of constructing a CS-based symmetric cipher under the key reuse circumstance, i.e., the cipher is resistant to common attacks even when a fixed measurement matrix is used multiple times. To this end, we suggest a bi-level protected CS (BLP-CS) model which makes use of the advantage of measurement matrix construction without restricted isometry property (RIP). Specifically, two kinds of artificial basis mismatch techniques are investigated to construct key-related sparsifying bases. It is demonstrated that the encoding process of BLP-CS is simply a random linear projection, which is the same as the basic CS model. However, decoding the linear measurements requires knowledge of both the key-dependent sensing matrix and its sparsifying basis. The proposed model is exemplified by sampling images as a joint data acquisition and protection layer for resource-limited wireless sensors. Simulation results and numerical analyses have justified that the new model can be applied in circumstances where the measurement matrix can be reused.","Ciphers,
Encoding,
Sensors,
Sparse matrices,
Encryption"
Air Quality Monitoring System Based on ISO/IEC/IEEE 21451 Standards,"An air quality monitoring system (AQMS) based on the IEEE/ISO/IEC 21451 standards is presented. In the development of an AQMS, we have used the GSM wireless communication module. The developed system is capable of the real-time measurement of air polluted gases, such as CO2, CO, NO2, and SO2. The machine-to-machine communication of the air quality monitoring station and PC with the sink node was successfully implemented. Various gas sensor technologies were evaluated for the system and ultimately electrochemical and infrared sensors were used. Hardware and software for an AQMS was designed and implemented. The AQMS uses an array of sensors to take the measurements of the ambient air surrounding it and wirelessly transmits the data to the base station. A graphical user interface (GUI), which makes it easy for end user(s) to interact with the system, was developed. Gas concentration values are plotted on the GUI. The defined calibration of the instruments at time interims assures that the desired accuracy is sustained. This paper offers further elucidations to design disputes raised in earlier studies.","Monitoring,
Air quality,
Sensor arrays,
Gas detectors,
Electrodes,
IEC Standards"
Intra and Inter-Cell Resource Management in Full-Duplex Heterogeneous Cellular Networks,"Full-duplex communication is drawing high attention as a means of enhancing wireless capacity considerably by enabling simultaneous transmission and reception on the same frequency spectrum. While it had been considered infeasible for a long time due to strong self-interference, recent researches have made substantial progress on addressing this challenge. This paper focuses on designing full-duplex cellular networks with co-channel femtocells. Due to relatively high transmit power, cancellation of self-interference by existing techniques could still be imperfect for cellular systems and thus residual interference may impact performance significantly. To overcome this in OFDMA systems, a new radio resource management scheme assigning downlink and uplink transmissions jointly while considering the gain of self-interference cancellation is developed. Three available transmission modes of a frequency resource block and crossover points between their achievable capacities are identified for the mode selection of each resource block. Users are then assigned resource blocks and transmit power levels are determined such that the total utility sum is maximized. To handle new femtocell interference scenarios, the transmit powers of femtocells and their connected users are adjusted by a coordination algorithm such that both data transmission and mode selection of an underlying macrocell are protected.","Interference,
Femtocells,
Macrocell networks,
High definition video,
Computer architecture,
Signal to noise ratio"
Full-Body Musculoskeletal Model for Muscle-Driven Simulation of Human Gait,"Objective: Musculoskeletal models provide a noninvasive means to study human movement and predict the effects of interventions on gait. Our goal was to create an open-source 3-D musculoskeletal model with high-fidelity representations of the lower limb musculature of healthy young individuals that can be used to generate accurate simulations of gait. Methods: Our model includes bony geometry for the full body, 37 degrees of freedom to define joint kinematics, Hill-type models of 80 muscle-tendon units actuating the lower limbs, and 17 ideal torque actuators driving the upper body. The model's musculotendon parameters are derived from previous anatomical measurements of 21 cadaver specimens and magnetic resonance images of 24 young healthy subjects. We tested the model by evaluating its computational time and accuracy of simulations of healthy walking and running. Results: Generating muscle-driven simulations of normal walking and running took approximately 10 minutes on a typical desktop computer. The differences between our muscle-generated and inverse dynamics joint moments were within 3% (RMSE) of the peak inverse dynamics joint moments in both walking and running, and our simulated muscle activity showed qualitative agreement with salient features from experimental electromyography data. Conclusion: These results suggest that our model is suitable for generating muscle-driven simulations of healthy gait. We encourage other researchers to further validate and apply the model to study other motions of the lower extremity. Significance: The model is implemented in the open-source software platform OpenSim. The model and data used to create and test the simulations are freely available at https://simtk.org/home/full_body/, allowing others to reproduce these results and create their own simulations.","Computational modeling,
Muscles,
Biological system modeling,
Data models,
Cadaver,
Pelvis"
Management of structural components complex electronic systems on the basis of adaptive model,"The object of the study encompasses the control systems for functional elements of complex strategic and specialized systems that serve various purposes and are aimed at achieving set criteria quality and can be interpreted in mathematical terms. The study centres on mathemetical modelling of structural elements of complex multi-level systems and the rationale for determining control actions. The article analyses the complex model of radio electronic communication system. The aim of the study is to solve the problem of multi-parameter adaptation of the system elements to the current conditions at different operating stages by the determination of optimum set of control actions. The study was conducted on the basis of systems theory, system analysis and control, and methods of search optimization. The rationale for determining control actions allows to obtain current and prognostic data on control actions assessment. The technique for determining and establishing rational control actions affecting the system components was developed on the basis of set qualitative states of the system. The main advantage of the developed technique is its multi-purpose application to elements of various complex strategic, social and economic, specialized systems. The technique excludes excessive iteration during calculations, which means economic use of time resources. The technique allows to control effectively the system elements within the limits of criteria set level not only when it is necessary to use additional resources but also when the system resources are used inefficiently and unreasonably.","Decision support systems,
Government,
Information technology"
Guided Image Contrast Enhancement Based on Retrieved Images in Cloud,"We propose a guided image contrast enhancement framework based on cloud images, in which the context- sensitive and context-free contrast is jointly improved via solving a multi-criteria optimization problem. In particular, the context-sensitive contrast is improved by performing advanced unsharp masking on the input and edge-preserving filtered images, while the context-free contrast enhancement is achieved by the sigmoid transfer mapping. To automatically determine the contrast enhancement level, the parameters in the optimization process are estimated by taking advantages of the retrieved images with similar content. For the purpose of automatically avoiding the involvement of low-quality retrieved images as the guidance, a recently developed no-reference image quality metric is adopted to rank the retrieved images from the cloud. The image complexity from the free-energy-based brain theory and the surface quality statistics in salient regions are collaboratively optimized to infer the parameters. Experimental results confirm that the proposed technique can efficiently create visually-pleasing enhanced images which are better than those produced by the classical techniques in both subjective and objective comparisons.","Histograms,
Image edge detection,
Image quality,
Cloud computing,
Optimization,
Electronic mail,
Image coding"
q-Space Deep Learning: Twelve-Fold Shorter and Model-Free Diffusion MRI Scans,"Numerous scientific fields rely on elaborate but partly suboptimal data processing pipelines. An example is diffusion magnetic resonance imaging (diffusion MRI), a non-invasive microstructure assessment method with a prominent application in neuroimaging. Advanced diffusion models providing accurate microstructural characterization so far have required long acquisition times and thus have been inapplicable for children and adults who are uncooperative, uncomfortable, or unwell. We show that the long scan time requirements are mainly due to disadvantages of classical data processing. We demonstrate how deep learning, a group of algorithms based on recent advances in the field of artificial neural networks, can be applied to reduce diffusion MRI data processing to a single optimized step. This modification allows obtaining scalar measures from advanced models at twelve-fold reduced scan time and detecting abnormalities without using diffusion models. We set a new state of the art by estimating diffusion kurtosis measures from only 12 data points and neurite orientation dispersion and density measures from only 8 data points. This allows unprecedentedly fast and robust protocols facilitating clinical routine and demonstrates how classical data processing can be streamlined by means of deep learning.","Fitting,
Machine learning,
Data processing,
Pipelines,
Training,
Diffusion tensor imaging"
Delay and Power Consumption in LTE/LTE-A DRX Mechanism With Mixed Short and Long Cycles,"Energy consumption is a major concern in today's wireless communications due to the consensus for a greener world. LTE-Advanced (LTE-A) has been standardized for the fourth-generation mobile communications to meet the growing demands for high-speed wireless communications. However, high-speed signal processing on LTE/LTE-A user equipment (UE) causes excessive power consumption. The discontinuous reception (DRX) mechanism is a critical technique for tackling this issue. Delay constraint and power savings are two contradictory performance metrics associated with the DRX mechanism. Using recursive deduction and Markov model, this paper provides an in-depth analysis on the average delay and average power consumption of the DRX mechanism. Two performance metrics, namely, power-saving factor and relative power saving, are devised to assess the power-saving performance of the DRX mechanism. The accuracy of theoretical analysis is validated by computer simulations using the parameters in compliance with LTE specifications. The performance of the DRX mechanism is governed by a set of parameters that interact with one another in an intricate manner. Therefore, the values of key parameters are tested to assess their impacts on the performance of the DRX mechanism. The results shown in this paper give an insight into the operation and further improvement of the DRX mechanism.","Delays,
Power demand,
Long Term Evolution,
Downlink,
Radio frequency,
Monitoring"
A Theoretical Foundation of Goal Representation Heuristic Dynamic Programming,"Goal representation heuristic dynamic programming (GrHDP) control design has been developed in recent years. The control performance of this design has been demonstrated in several case studies, and also showed applicable to industrial-scale complex control problems. In this paper, we develop the theoretical analysis for the GrHDP design under certain conditions. It has been shown that the internal reinforcement signal is a bounded signal and the performance index can converge to its optimal value monotonically. The existence of the admissible control is also proved. Although the GrHDP control method has been investigated in many areas before, to the best of our knowledge, this is the first study of presenting the theoretical foundation of the internal reinforcement signal and how such an internal reinforcement signal can provide effective information to improve the control performance. Numerous simulation studies are used to validate the theoretical analysis and also demonstrate the effectiveness of the GrHDP design.","Performance analysis,
Convergence,
Algorithm design and analysis,
Upper bound,
Mathematical model,
Approximation algorithms,
Dynamic programming"
Joint Subcarrier and Power Allocation Methods in Full Duplex Wireless Powered Communication Networks for OFDM Systems,"In this paper, we investigate wireless powered communication network for OFDM systems, where a hybrid access point (H-AP) broadcasts energy signals to users in the downlink, and the users transmit information signals to the H-AP in the uplink based on orthogonal frequency division multiple access. We consider a full-duplex H-AP which simultaneously transmits energy signals and receives information signals. In this scenario, we address a joint subcarrier scheduling and power allocation problem to maximize the sum-rate under two cases: perfect self-interference cancellation (SIC) where the H-AP fully eliminates its self-interference (SI) and imperfect SIC where residual SI exists. In general, the problems for both cases are nonconvex due to the subcarrier scheduling, and thus it requires an exhaustive search method, which is prohibitively complicated to obtain an optimal solution. In order to reduce the complexity, for the perfect SIC scenario, we jointly optimize subcarrier scheduling and power allocation by applying the Lagrange duality method. Next, for the imperfect SIC case, the problem becomes more complicated due to the SI at the H-AP. To solve this problem, we propose an iterative algorithm based on the projected gradient method. Simulation results show that the proposed algorithm for the case of perfect SIC exhibits almost the same sum-rate performance compared to the optimal algorithm, and the proposed iterative algorithm for the imperfect SIC case offers a significant performance gain over conventional schemes.","Downlink,
Resource management,
Uplink,
Silicon carbide,
OFDM,
Scheduling,
Wireless communication"
Stackelberg-Game-Based Dynamic Spectrum Access in Heterogeneous Wireless Systems,"In this paper, we investigate a two-stage Stackelberg game for dynamic spectrum access (DSA) in cognitive radio networks using a leader [spectrum provider (SP)] subgame and a follower [secondary user (SU)] subgame. Our research distinguishes itself in a number of ways. First, a two-stage Stackelberg game has been proposed to provide a unique optimal solution that facilitates a tradeoff between quality of service (QoS) of unlicensed SUs and revenue of SPs. Second, comprehensive budget and QoS constraints imposed by the signal-to-interference-plus-noise ratio are defined to fully take into account QoS requirements. Third, a necessary condition and closed form for the existence of the Stackelberg equilibrium are presented for multiradio multichannel DSA. Analytical and simulation studies are carried out to assess the performance of the proposed game, and the numerical results verify that the proposed approach reaches the unique Stackelberg equilibrium.","Games,
Interference,
Signal to noise ratio,
Quality of service,
Geology,
Wireless networks"
Joint Low-Rank and Sparse Principal Feature Coding for Enhanced Robust Representation and Visual Classification,"Recovering low-rank and sparse subspaces jointly for enhanced robust representation and classification is discussed. Technically, we first propose a transductive low-rank and sparse principal feature coding (LSPFC) formulation that decomposes given data into a component part that encodes low-rank sparse principal features and a noise-fitting error part. To well handle the outside data, we then present an inductive LSPFC (I-LSPFC). I-LSPFC incorporates embedded low-rank and sparse principal features by a projection into one problem for direct minimization, so that the projection can effectively map both inside and outside data into the underlying subspaces to learn more powerful and informative features for representation. To ensure that the learned features by I-LSPFC are optimal for classification, we further combine the classification error with the feature coding error to form a unified model, discriminative LSPFC (D-LSPFC), to boost performance. The model of D-LSPFC seamlessly integrates feature coding and discriminative classification, so the representation and classification powers can be enhanced. The proposed approaches are more general, and several recent existing low-rank or sparse coding algorithms can be embedded into our problems as special cases. Visual and numerical results demonstrate the effectiveness of our methods for representation and classification.","Feature extraction,
Image coding,
Principal component analysis,
Encoding,
Robustness,
Sparse matrices"
On WiFi Offloading in Heterogeneous Networks: Various Incentives and Trade-Off Strategies,"Due to the rapid development of wireless access technologies and smart terminals, mobile data traffic is continuously increasing, which is expected to lead to an explosive growth of data in heterogeneous networks especially cellular networks. It is significant for network operators to expand the capacity of cellular networks to avoid congestion and overload so as to guarantee users' satisfaction. Given that contemporary terminals are capable of both WiFi and cellular networks, WiFi offloading is envisioned as a promising solution to utilize the various benefits of WiFi and cellular networks to migrate traffic from cellular networks to WiFi networks. This paper surveys the state-of-the-art progress in the field of WiFi offloading. After discussing the requirements from the emerging 5G technology regarding the coexistence of WiFi and cellular networks, selecting and switching schemes are presented. The bandwidth and capacity of WiFi networks are usually excellent, whereas the coverage and energy efficiency may be unacceptable. We elaborate on several existing solutions of WiFi offloading schemes and discuss how the parameters of several kinds of heterogeneous networks affect the offloading decision. We also illustrate how multiple networks cooperate in heterogeneous networks in order to balance the offloading performance. We classify current various incentives of WiFi offloading into five categories: 1) capacity; 2) cost; 3) energy; 4) rate; and 5) continuity. Improving the capacity is the basic incentive, which can be further classified in terms of delay techniques. From operators' and users' perspectives, we also investigate various state-of-the-art incentives of WiFi offloading such as minimizing cost, saving energy consumption, and improving rate. Furthermore, WiFi offloading schemes that attempt to enhance continuity to deal with frequent disruption problems are further investigated, especially for vehicular scenarios. Finally, future research directions and challenges for WiFi offloading strategies are presented in various incentives of WiFi offloading.",
Cooperative Routing With Relay Assignment in Multiradio Multihop Wireless Networks,"Cooperative communication (CC) for wireless networks has gained a lot of recent interests. It has been shown that CC has the potential to significantly increase the capacity of wireless networks, with its ability of mitigating fading by exploiting spatial diversity. However, most of the works on CC are limited to single radio wireless network. To demonstrate the benefits of CC in multiradio multihop wireless network, this paper studies a joint problem of multiradio cooperative routing and relay assignment to maximize the minimum rate among a set of concurrent communication sessions. We first model this problem as a mixed-integer programming (MIP) problem and prove it to be NP-hard. Then, we propose a centralized algorithm and a distributed algorithm to solve the problem. The centralized algorithm is designed within a branch-and-bound framework by using the relaxation of the formulated MIP, which can find a global (1+ε)-optimal solution. Our distributed algorithm includes two subalgorithms: a cooperative route selection subalgorithm and a fairness-aware route adjustment subalgorithm. Our simulation results demonstrate the effectiveness of the proposed algorithms and the significant rate gains that can be achieved by incorporating CC in multiradio multihop networks.","Relays,
Spread spectrum communication,
Routing,
Wireless networks,
Cooperative communication,
Interference"
"Spin-Transfer Torque Memories: Devices, Circuits, and Systems","Spin-transfer torque magnetic memory (STT-MRAM) has gained significant research interest due to its nonvolatility and zero standby leakage, near unlimited endurance, excellent integration density, acceptable read and write performance, and compatibility with CMOS process technology. However, several obstacles need to be overcome for STT-MRAM to become the universal memory technology. This paper first reviews the fundamentals of STT-MRAM and discusses key experimental breakthroughs. The state of the art in STT-MRAM is then discussed, beginning with the device design concepts and challenges. The corresponding bit-cell design solutions are also presented, followed by the STT-MRAM cache architectures suitable for on-chip applications.","Magnetic tunneling,
Spin valves,
Perpendicular magnetic anisotropy,
Torque control,
System-on-chip,
Memory management,
Cache storage,
Nonvolatile memory"
CEREBRE: A Novel Method for Very High Accuracy Event-Related Potential Biometric Identification,"The vast majority of existing work on brain biometrics has been conducted on the ongoing electroencephalogram. Here, we argue that the averaged event-related potential (ERP) may provide the potential for more accurate biometric identification, as its elicitation allows for some control over the cognitive state of the user to be obtained through the design of the challenge protocol. We describe the Cognitive Event-RElated Biometric REcognition (CEREBRE) protocol, an ERP biometric protocol designed to elicit individually unique responses from multiple functional brain systems (e.g., the primary visual, facial recognition, and gustatory/appetitive systems). Results indicate that there are multiple configurations of data collected with the CEREBRE protocol that all allow 100% identification accuracy in a pool of 50 users. We take this result as the evidence that ERP biometrics are a feasible method of user identification and worthy of further research.","Protocols,
Electroencephalography,
Face,
Brain,
Gratings,
Image color analysis,
Visualization"
Dynamic Energy Management for Smart-Grid-Powered Coordinated Multipoint Systems,"Due to increasing threats of global warming and climate change concerns, green wireless communications have recently drawn intense attention toward reducing carbon emissions. Aligned with this goal, the present paper deals with dynamic energy management for smart-grid powered coordinated multipoint (CoMP) transmissions. To address the intrinsic variability of renewable energy sources, a novel energy transaction mechanism is introduced for grid-connected base stations that are also equipped with an energy storage unit. Aiming to minimize the expected energy transaction cost while guaranteeing the worst-case users' quality of service, an infinite-horizon optimization problem is formulated to obtain the optimal downlink transmit beamformers that are robust to channel uncertainties. Capitalizing on the virtual-queue-based relaxation technique and the stochastic dual-subgradient method, an efficient online algorithm is developed yielding a feasible and asymptotically optimal solution. Numerical tests with synthetic and real data corroborate the analytical performance claims and highlight the merits of the novel approach.",
Deduplication on Encrypted Big Data in Cloud,"Cloud computing offers a new way of service provision by re-arranging various resources over the Internet. The most important and popular cloud service is data storage. In order to preserve the privacy of data holders, data are often stored in cloud in an encrypted form. However, encrypted data introduce new challenges for cloud data deduplication, which becomes crucial for big data storage and processing in cloud. Traditional deduplication schemes cannot work on encrypted data. Existing solutions of encrypted data deduplication suffer from security weakness. They cannot flexibly support data access control and revocation. Therefore, few of them can be readily deployed in practice. In this paper, we propose a scheme to deduplicate encrypted data stored in cloud based on ownership challenge and proxy re-encryption. It integrates cloud data deduplication with access control. We evaluate its performance based on extensive analysis and computer simulations. The results show the superior efficiency and effectiveness of the scheme for potential practical deployment, especially for big data deduplication in cloud storage.","Cloud computing,
Big data,
Data privacy,
Encryption,
Servers"
Inertial Measurement Unit-Based Wearable Computers for Assisted Living Applications: A signal processing perspective,"There has been a very rapid growth in wearable computers over the past few years. Assisted living applications leveraging wearable computers will enable a healthier lifestyle and independence in a variety of target populations, including those suffering from neurological disorders, patients in need of rehabilitation after surgical procedures or injury, the elderly, individuals who might be at high risk of emotional stress, and those who are looking for a healthier lifestyle. Application paradigms for assisted living include activities of daily living (ADLs) monitoring, indoor localization, emergency and fall detection, and rehabilitation. All of these applications require monitoring of movements and physical activities for individuals. Wearable inertial measurement unit (IMU)-based sensors can offer low-cost and ubiquitous monitoring solutions for physical activities. Signal processing techniques with a focus on enhancing accuracy, lowering computational complexity, reducing power consumption, and improving the unobtrusiveness of the wearable computers are of interest in this article, which constitutes the first attempt made at reviewing the literature of wearable IMU-based signal processing techniques for assisted living applications. Various signal processing techniques with the aforementioned performance metrics in mind are reviewed here.","Sensors,
Assisted living,
Monitoring,
Feature extraction,
Legged locomotion,
Band-pass filters,
Inertial measurements,
Wearable computers,
Assistive technology"
Multimodal Spontaneous Emotion Corpus for Human Behavior Analysis,"Emotion is expressed in multiple modalities, yet most research has considered at most one or two. This stems in part from the lack of large, diverse, well-annotated, multimodal databases with which to develop and test algorithms. We present a well-annotated, multimodal, multidimensional spontaneous emotion corpus of 140 participants. Emotion inductions were highly varied. Data were acquired from a variety of sensors of the face that included high-resolution 3D dynamic imaging, high-resolution 2D video, and thermal (infrared) sensing, and contact physiological sensors that included electrical conductivity of the skin, respiration, blood pressure, and heart rate. Facial expression was annotated for both the occurrence and intensity of facial action units from 2D video by experts in the Facial Action Coding System (FACS). The corpus further includes derived features from 3D, 2D, and IR (infrared) sensors and baseline results for facial expression and action unit detection. The entire corpus will be made available to the research community.","Three-dimensional displays,
Two dimensional displays,
Thermal sensors,
Blood pressure,
Sensor systems,
Physiology"
A 45 nm CMOS-SOI Monolithic Photonics Platform With Bit-Statistics-Based Resonant Microring Thermal Tuning,"The microring resonator is critical for dense wavelength division multiplexed (DWDM) chip-to-chip optical I/O, enabling modulation and channel selection at the μm-scale suitable for a VLSI chip. Microring-based links, however, require active tuning to counteract process and thermo-optic variations. Here, we present a bit-statistical tuner that decouples tracking of optical one and zero-levels to realize non-dc-balanced data transmission, an “eye-max”-locking controller, and self-heating cancellation without need for a high-speed sensing frontend. We implement the tuner on a 45 nm CMOS-SOI process with monolithically integrated photonic devices and circuits. The tuner consumes 0.74 mW in the logic while achieving a record 524 GHz (> 50 K temperature) tuning range at 3.8 μW/GHz heater efficiency. To our knowledge, this is the highest range and heater efficiency reported by an on-chip closed-loop thermal tuner to date. The tuner integrates with a 5 Gb/s 30 fJ/bit monolithic microring transmitter, achieving wavelength-lock and immunity to both tracking failures and self-heating events caused by arbitrary, nondc-balanced bitstreams. In addition, the tuner provides critical functionality for an 11-λ DWDM transmitter macro capable of 11 × 8 Gb/s bandwidth on a fiber. Together with the transmitter, a 10 Gb/s on-chip monolithic optical receiver with 10-12 BER sensitivity of 9 μA at 10 Gb/s enables a sub-pJ/bit 5 Gb/s optical chip-to-chip link, with the bit-statistical tuner providing thermally robust microring operation.","Tuners,
Heating,
Optical resonators,
Optical transmitters,
Optical receivers,
Modulation"
Distributed Real-Time Power Balancing in Renewable-Integrated Power Grids With Storage and Flexible Loads,"The large-scale integration of renewable generation directly affects the reliability of power grids. We investigate the problem of power balancing in a general renewable-integrated power grid with storage and flexible loads. We consider a power grid that is supplied by one conventional generator (CG) and multiple renewable generators (RGs) each co-located with storage, and is connected with external markets. An aggregator operates the power grid to maintain power balance between supply and demand. Aiming at minimizing the long-term system cost, we first propose a real-time centralized power balancing solution, taking into account the uncertainty of the renewable generation, loads, and energy prices. We then provide a distributed implementation algorithm, significantly reducing both computational burden and communication overhead. We demonstrate that our proposed algorithm is asymptotically optimal as the storage capacity increases and the CG ramping constraint loosens. Moreover, the distributed implementation enjoys a fast convergence rate, and enables each RG and the aggregator to make their own decisions. Simulation shows that our proposed algorithm outperforms alternatives and can achieve near-optimal performance for a wide range of storage capacity.",
Graceful Performance Modulation for Power-Neutral Transient Computing Systems,"Transient computing systems do not have energy storage, and operate directly from energy harvesting. These systems are often faced with the inherent challenge of low-current or transient power supply. In this paper, we propose “power-neutral” operation, a new paradigm for such systems, whereby the instantaneous power consumption of the system must match the instantaneous harvested power. Power neutrality is achieved using a control algorithm for dynamic frequency scaling, modulating system performance gracefully in response to the incoming power. Detailed system model is used to determine design parameters for selecting the system voltage thresholds where the operating frequency will be raised or lowered, or the system will be hibernated. The proposed control algorithm for power-neutral operation is experimentally validated using a microcontroller incorporating voltage threshold-based interrupts for frequency scaling. The microcontroller is powered directly from real energy harvesters; results demonstrate that a power-neutral system sustains operation for 4%-88% longer with up to 21% speedup in application execution.","Frequency modulation,
Sensors,
Microcontrollers,
Transient analysis,
Energy harvesting,
Batteries,
Heuristic algorithms"
A Single-Phase Four-Switch Rectifier With Significantly Reduced Capacitance,"A single-phase four-switch rectifier with considerably reduced capacitance is investigated in this paper. The rectifier consists of one conventional rectification leg and one neutral leg linked with two capacitors that split the dc bus. The ripple energy in the rectifier is diverted into the lower split capacitor so that the voltage across the upper split capacitor, designed to be the dc output voltage, has very small ripples. The voltage across the lower capacitor is designed to have large ripples on purpose so that the total capacitance needed is significantly reduced and highly reliable film capacitors, instead of electrolytic capacitors, can be used. At the same time, the rectification leg is controlled independently from the neutral leg to regulate the input current to achieve unity power factor and also to maintain the dc-bus voltage. Experimental results are presented to validate the performance of the proposed strategy.","Capacitors,
Voltage control,
Capacitance,
Reliability,
Control systems,
Integrated circuit modeling"
Fully convolutional networks for multi-modality isointense infant brain image segmentation,"The segmentation of infant brain tissue images into white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF) plays an important role in studying early brain development. In the isointense phase (approximately 6–8 months of age), WM and GM exhibit similar levels of intensity in both T1 and T2 MR images, resulting in extremely low tissue contrast and thus making the tissue segmentation very challenging. The existing methods for tissue segmentation in this isointense phase usually employ patch-based sparse labeling on single T1, T2 or fractional anisotropy (FA) modality or their simply-stacked combinations without fully exploring the multi-modality information. To address the challenge, in this paper, we propose to use fully convolutional networks (FCNs) for the segmentation of isointense phase brain MR images. Instead of simply stacking the three modalities, we train one network for each modality image, and then fuse their high-layer features together for final segmentation. Specifically, we conduct a convolution-pooling stream for multimodality information from T1, T2, and FA images separately, and then combine them in high-layer for finally generating the segmentation maps as the outputs. We compared the performance of our approach with that of the commonly used segmentation methods on a set of manually segmented isointense phase brain images. Results showed that our proposed model significantly outperformed previous methods in terms of accuracy. In addition, our results also indicated a better way of integrating multi-modality images, which leads to performance improvement.","Image segmentation,
Computer architecture,
Fuses,
Training,
Brain modeling,
Radio frequency"
Pilot Allocation for Distributed-Compressed-Sensing-Based Sparse Channel Estimation in MIMO-OFDM Systems,"This paper addresses the sparse channel estimation problem in multiple-input-multiple-output orthogonal frequency-division multiplexing (MIMO-OFDM) systems from the perspective of distributed compressed sensing (DCS). It is focused on deterministic pilot allocation of MIMO-OFDM systems to improve the performance of DCS-based channel estimation. By transforming the problem of DCS-based channel estimation to a problem of reconstructing block-sparse signals, a class of mutual coherence-related criteria is first proposed for optimizing pilot locations. By employing the proposed criteria, a genetic algorithm (GA)-based method of optimizing the pilot locations is then presented. Simulation results show that the DCS-based MIMO channel estimation with optimized pilot locations can improve the spectrum efficiency by nearly 36% and the bit error rate (BER) performance by 1.5 dB, as compared with the least squares (LS) channel estimation with equidistant pilot locations. Moreover, the DCS-based MIMO channel estimation yields a 4.7% improvement in spectrum efficiency under the same BER performance over the compressed sensing (CS)-based channel estimation.","Channel estimation,
MIMO,
Transmitting antennas,
Resource management,
Optimization,
Matching pursuit algorithms,
Antenna measurements"
Terahertz Channel Characterization Inside the Human Skin for Nano-Scale Body-Centric Networks,"This paper focuses on the development of a novel radio channel model inside the human skin at the terahertz range, which will enable the interaction among potential nano-machines operating in the inter cellular areas of the human skin. Thorough studies are performed on the attenuation of electromagnetic waves inside the human skin, while taking into account the frequency of operation, distance between the nano-machines and number of sweat ducts. A novel channel model is presented for communication of nano-machines inside the human skin and its validation is performed by varying the aforementioned parameters with a reasonable accuracy. The statistics of error prediction between simulated and modeled data are: mean (μ)= 0.6 dB and standard deviation (σ)= 0.4 dB, which indicates the high accuracy of the prediction model as compared with measurement data from simulation. In addition, the results of proposed channel model are compared with terhaertz time-domain spectroscopy based measurement of skin sample and the statistics of error prediction in this case are: μ = 2.10 dB and σ = 6.23 dB, which also validates the accuracy of proposed model. Results in this paper highlight the issues and related challenges while characterizing the communication in such a medium, thus paving the way towards novel research activities devoted to the design and the optimization of advanced applications in the healthcare domain.","Ducts,
Numerical models,
Nanobioscience,
Computational modeling,
Channel models,
Epidermis"
How do People Make Sense of Unfamiliar Visualizations?: A Grounded Model of Novice's Information Visualization Sensemaking,"In this paper, we would like to investigate how people make sense of unfamiliar information visualizations. In order to achieve the research goal, we conducted a qualitative study by observing 13 participants when they endeavored to make sense of three unfamiliar visualizations (i.e., a parallel-coordinates plot, a chord diagram, and a treemap) that they encountered for the first time. We collected data including audio/video record of think-aloud sessions and semi-structured interview; and analyzed the data using the grounded theory method. The primary result of this study is a grounded model of NOvice's information VIsualization Sensemaking (NOVIS model), which consists of the five major cognitive activities: 1 encountering visualization, 2 constructing a frame, 3 exploring visualization, 4 questioning the frame, and 5 floundering on visualization. We introduce the NOVIS model by explaining the five activities with representative quotes from our participants. We also explore the dynamics in the model. Lastly, we compare with other existing models and share further research directions that arose from our observations.","Data visualization,
Visualization,
Encoding,
Interviews,
Hidden Markov models,
Image color analysis,
Vehicles"
Wearable Camera- and Accelerometer-Based Fall Detection on Portable Devices,"Robust and reliable detection of falls is crucial especially for elderly activity monitoring systems. In this letter, we present a fall detection system using wearable devices, e.g., smartphones, and tablets, equipped with cameras and accelerometers. Since the portable device is worn by the subject, monitoring is not limited to confined areas, and extends to wherever the subject may travel, as opposed to static sensors installed in certain rooms. Moreover, a camera provides an abundance of information, and the results presented here show that fusing camera and accelerometer data not only increases the detection rate, but also decreases the number of false alarms compared to only accelerometer-based or only camera-based systems. We employ histograms of edge orientations together with the gradient local binary patterns for the camera-based part of fall detection. We compared the performance of the proposed method with that of using original histograms of oriented gradients (HOG) as well as a modified version of HOG. Experimental results show that the proposed method outperforms using original HOG and modified HOG, and provides lower false positive rates for the camera-based detection. Moreover, we have employed an accelerometer-based fall detection method, and fused these two sensor modalities to have a robust fall detection system. Experimental results and trials with actual Samsung Galaxy phones show that the proposed method, combining two different sensor modalities, provides much higher sensitivity, and a significant decrease in the number of false positives during daily activities, compared to accelerometer-only and camera-only methods.","Cameras,
Accelerometers,
Histograms,
Sensitivity,
Smart phones,
Sensors,
Image edge detection"
iCrowd: Near-Optimal Task Allocation for Piggyback Crowdsensing,"This paper first defines a novel spatial-temporal coverage metric, k-depth coverage, for mobile crowdsensing (MCS) problems. This metric considers both the fraction of subareas covered by sensor readings and the number of sensor readings collected in each covered subarea. Then iCrowd, a generic MCS task allocation framework operating with the energy-efficient Piggyback Crowdsensing task model, is proposed to optimize the MCS task allocation with different incentives and k-depth coverage objectives/ constraints. iCrowd first predicts the call and mobility of mobile users based on their historical records, then it selects a set of users in each sensing cycle for sensing task participation, so that the resulting solution achieves two dual optimal MCS data collection goals-i.e., Goal. 1 near-maximal k-depth coverage without exceeding a given incentive budget or Goal. 2 near-minimal incentive payment while meeting a predefined k-depth coverage goal. We evaluated iCrowd extensively using a large-scale real-world dataset for these two data collection goals. The results show that: for Goal.1, iCrowd significantly outperformed three baseline approaches by achieving 3-60 percent higher k-depth coverage; for Goal.2, iCrowd required 10.0-73.5 percent less incentives compared to three baselines under the same k-depth coverage constraint.","Sensors,
Resource management,
Mobile communication,
Data collection,
Air quality,
Measurement,
Poles and towers"
WhiteFi Infostation: Engineering Vehicular Media Streaming With Geolocation Database,"The TV white spaces (TVWS) enabled infostation has received significant attention due to its wide area coverage for cost-effective and media-rich content dissemination. In this paper, we engineer WhiteFi infostation, which is dedicated for Internet-based vehicular media streaming by leveraging geolocation database. After demonstrating the empirical observations of unique TVWS features and analyzing the real-world TVWS data collected from geolocation database, we first propose an optimal TVWS network planning to deploy WhiteFi infostation with the objective of maximizing network-wide throughput. The proposed TVWS network planning jointly considers the multi-radio configuration and the channel-power tradeoff, which can be realized by decentralized Markov approximation. Furthermore, we introduce a location-aware contention-free multi-polling access scheduling scheme for vehicular media streaming, which considered both the realistic vehicular applications and dynamics of wireless channel conditions. Through extensive simulations with real-world empirical TVWS data and urban vehicular traces, we demonstrate that our WhiteFi infostation solution can well support both the delay-sensitive and delay-tolerant vehicular media streaming services.","Streaming media,
White spaces,
Geology,
Databases,
TV,
Dynamic scheduling,
Multimedia communication"
Spoof Plasmon-Based Slow-Wave Excitation of Dielectric Resonator Antennas,"A spoof plasmon (SP)-based slow-wave feeding configuration is proposed, experimentally verified and exploited to excite the fundamental horizontally polarized mode of dielectric resonator antennas (DRAs). As an example, a cylindrical DRA operating at 3 GHz is fed by the proposed feeding structure. The simulation and measurement evidence the unique features of TE01δ mode such as lower thickness-dependency of the resonant frequencies, superb miniaturization and ultra-compactness, and omnidirectional radiation for horizontally polarized waves. We anticipate that the ground-free SP-based feeding technique could be applied to effectively excite the more “unusual” modes of the isolated DRAs.","Resonant frequency,
Antenna radiation patterns,
Electric fields,
Dielectric resonator antennas,
Coplanar waveguides,
Dielectrics,
Power transmission lines"
Robust Workload and Energy Management for Sustainable Data Centers,"A large number of geo-distributed data centers begin to surge in the era of data deluge and information explosion. To meet the growing demand in massive data processing, the infrastructure of future data centers must be energy-efficient and sustainable. Facing this challenge, a systematic framework is put forth in this paper to integrate renewable energy sources (RES), distributed storage units, cooling facilities, as well as dynamic pricing into the workload and energy management tasks of a data center network. To cope with RES uncertainty, the resource allocation task is formulated as a robust optimization problem minimizing the worst-case net cost. Compared with existing stochastic optimization methods, the proposed approach entails a deterministic uncertainty set where generated RES reside, thus can be readily obtained in practice. It is further shown that the problem can be cast as a convex program, and then solved in a distributed fashion using the dual decomposition method. By exploiting the spatio-temporal diversity of local temperature, workload demand, energy prices, and renewable availability, the proposed approach outperforms existing alternatives, as corroborated by extensive numerical tests performed using real data.","Cooling,
Robustness,
Uncertainty,
Manganese,
Energy management,
Optimization,
Servers"
Gain-Enhanced Patch Antennas With Loading of Shorting Pins,"A new gain-enhanced patch antenna with loading of shorting pins is proposed in this paper. Four metallic pins are symmetrically placed in the two diagonals of a square patch resonator to electrically short the patch and ground plane. These shorting pins tremendously perturb the field distribution beneath the patch due to their shunt inductive effect. As these four pins are moved outward along the two orthogonal diagonals away from the center, their influence on the field distribution over the patch is strengthened to gradually raise its dominant mode, i.e., TM010 mode, resonant frequency as the pin-to-pin spacing is enlarged. At a fixed resonant frequency, the overall area of this proposed patch antenna with four pins results to be increased. As such, its radiation directivity or gain gets to be enhanced due to the enlarged antenna area. After extensive analysis is executed, two square patch antennas with and without loaded pins are designed and fabricated. The simulated and measured results agree with each other, and they have evidently demonstrated that the radiation directivity can be enhanced up to 11.0 dBi, or about 2.9 dB increment, by virtue of the proposed approach.","Patch antennas,
Pins,
Resonant frequency,
Gain,
Periodic structures,
Antenna radiation patterns"
cvxEDA: A Convex Optimization Approach to Electrodermal Activity Processing,"Goal: This paper reports on a novel algorithm for the analysis of electrodermal activity (EDA) using methods of convex optimization. EDA can be considered as one of the most common observation channels of sympathetic nervous system activity, and manifests itself as a change in electrical properties of the skin, such as skin conductance (SC). Methods: The proposed model describes SC as the sum of three terms: the phasic component, the tonic component, and an additive white Gaussian noise term incorporating model prediction errors as well as measurement errors and artifacts. This model is physiologically inspired and fully explains EDA through a rigorous methodology based on Bayesian statistics, mathematical convex optimization, and sparsity. Results: The algorithm was evaluated in three different experimental sessions to test its robustness to noise, its ability to separate and identify stimulus inputs, and its capability of properly describing the activity of the autonomic nervous system in response to strong affective stimulation. Significance: Results are very encouraging, showing good performance of the proposed method and suggesting promising future applicability, e.g., in the field of affective computing.","Optimization,
Thyristors,
Skin,
Convex functions,
Physiology,
Noise,
Time series analysis"
Rating Prediction Based on Social Sentiment From Textual Reviews,"In recent years, we have witnessed a flourish of review websites. It presents a great opportunity to share our viewpoints for various products we purchase. However, we face an information overloading problem. How to mine valuable information from reviews to understand a user's preferences and make an accurate recommendation is crucial. Traditional recommender systems (RS) consider some factors, such as user's purchase records, product category, and geographic location. In this work, we propose a sentiment-based rating prediction method (RPS) to improve prediction accuracy in recommender systems. Firstly, we propose a social user sentimental measurement approach and calculate each user's sentiment on items/products. Secondly, we not only consider a user's own sentimental attributes but also take interpersonal sentimental influence into consideration. Then, we consider product reputation, which can be inferred by the sentimental distributions of a user set that reflect customers' comprehensive evaluation. At last, we fuse three factors-user sentiment similarity, interpersonal sentimental influence, and item's reputation similarity-into our recommender system to make an accurate rating prediction. We conduct a performance evaluation of the three sentimental factors on a real-world dataset collected from Yelp. Our experimental results show the sentiment can well characterize user preferences, which helps to improve the recommendation performance.","Social network services,
Recommender systems,
Matrix decomposition,
Feature extraction,
Dictionaries,
Prediction methods,
Fuses"
Fully Vertical GaN p-i-n Diodes Using GaN-on-Si Epilayers,"Using GaN-on-Si epilayers, for the first time, fully vertical p-i-n diodes are demonstrated after Si substrate removal, transfer, and n-electrode formation at the top of the device. After SiO2 sidewall passivation, the vertical p-i-n diodes, with n-GaN facing up, exhibit VON of 3.35 V at 1 A/cm2, a low differential ON-resistance of 3.3 mΩcm2 at 300 A/cm2, and a breakdown voltage of 350 V. The corresponding Baliga's figure of merit is 37.0 MW/cm2, a very good value for GaN-based p-i-n rectifiers grown on Si substrates. The results indicate that fully vertical rectifiers using GaN-on-Si epilayers have great potential in achieving cost-effective GaN devices for high-power and high-voltage applications.","P-i-n diodes,
Gallium nitride,
Silicon,
Substrates,
PIN photodiodes,
Metals,
Rough surfaces"
Contact-Aware Data Replication in Roadside Unit Aided Vehicular Delay Tolerant Networks,"Roadside units (RSUs), which enable vehicles-to-infrastructure communications, are deployed along roadsides to handle the ever-growing communication demands caused by explosive increase of vehicular traffics. How to efficiently utilize them to enhance the vehicular delay tolerant network (VDTN) performance are the important problems in designing RSU-aided VDTNs. In this work, we implement an extensive experiment involving tens of thousands of operational vehicles in Beijing city. Based on this newly collected Beijing trace and the existing Shanghai trace, we obtain some invariant properties for communication contacts of large scale RSU-aided VDTNs. Specifically, we find that the contact time between RSUs and vehicles obeys an exponential distribution, while the contact rate between them follows a Poisson distribution. According to these observations, we investigate the problem of communication contact-aware mobile data replication for RSU-aided VDTNs by considering the mobile data dissemination system that transmits data from the Internet to vehicles via RSUs through opportunistic communications. In particular, we formulate the communication contact-aware RSU-aided vehicular mobile data dissemination problem as an optimization problem with realistic VDTN settings, and we provide an efficient heuristic solution for this NP-hard problem. By carrying out extensive simulation using realistic vehicular traces, we demonstrate the effectiveness of our proposed heuristic contact-aware data replication scheme, in comparison with the optimal solution and other existing schemes.","Vehicles,
Mobile communication,
Data models,
Mobile computing,
Delays,
Urban areas,
Servers"
An Open-Switch Fault Diagnosis Method for Single-Phase PWM Rectifier Using a Model-Based Approach in High-Speed Railway Electrical Traction Drive System,"The converter with a single-phase rectifier, a dc-link circuit and a three-phase inverter is widely applied in high-speed railway electrical traction drive system. The fault frequency of single-phase rectifier is higher than that of three-phase inverter. Thus, this paper presents a new and fast model-based approach for open-switch fault diagnosis of the single-phase pulse width modulation rectifier, based on the mixed logical dynamic model and residual generation. It requires no additional hardware but only some measurements and command signals which are available in control system. This diagnosis method is quite suitable for electrical traction application due to the fast diagnosis time, simple structure and high reliability. Experimental results confirm the effectiveness and accuracy of the proposed algorithm. It is shown that such diagnosis method can locate the faulty switch in a few milliseconds which is important to avoid catastrophic consequences.","Circuit faults,
Rectifiers,
Switches,
Pulse width modulation,
Insulated gate bipolar transistors,
Inverters,
Fault diagnosis"
On Pythagorean and Complex Fuzzy Set Operations,"Complex fuzzy logic is a new multivalued logic system that has emerged in the last decade. At this time, there are a limited number of known instances of complex fuzzy logic, and only a partial exploration of their properties. There has also been relatively little progress in developing interpretations of complex-valued membership grades. In this paper, we address both problems by examining the recently developed Pythagorean fuzzy sets (a generalization of intuitionistic fuzzy sets). We first characterize two lattices that have been suggested for Pythagorean fuzzy sets and then extend these results to the unit disc of the complex plane. We thereby identify two new complete, distributive lattices over the unit disc, and explore interpretations of them based on fuzzy antonyms and negations.","Lattices,
Fuzzy sets,
Fuzzy logic,
Computer architecture,
Pragmatics,
Cost accounting,
Boundary conditions"
An End-to-End Neural Network for Polyphonic Piano Music Transcription,"We present a supervised neural network model for polyphonic piano music transcription. The architecture of the proposed model is analogous to speech recognition systems and comprises an acoustic model and a music language model. The acoustic model is a neural network used for estimating the probabilities of pitches in a frame of audio. The language model is a recurrent neural network that models the correlations between pitch combinations over time. The proposed model is general and can be used to transcribe polyphonic music without imposing any constraints on the polyphony. The acoustic and language model predictions are combined using a probabilistic graphical model. Inference over the output variables is performed using the beam search algorithm. We perform two sets of experiments. We investigate various neural network architectures for the acoustic models and also investigate the effect of combining acoustic and music language model predictions using the proposed architecture. We compare performance of the neural network-based acoustic models with two popular unsupervised acoustic models. Results show that convolutional neural network acoustic models yield the best performance across all evaluation metrics. We also observe improved performance with the application of the music language models. Finally, we present an efficient variant of beam search that improves performance and reduces run-times by an order of magnitude, making the model suitable for real-time applications.","Hidden Markov models,
Acoustics,
Computational modeling,
Feature extraction,
Recurrent neural networks,
Spectrogram"
A Review of Power Electronics for Grid Connection of Utility-Scale Battery Energy Storage Systems,"The increasing penetration of renewable energy sources (RES) poses a major challenge to the operation of the electricity grid owing to the intermittent nature of their power output. The ability of utility-scale battery energy storage systems (BESS) to provide grid support and smooth the output of RES in combination with their decrease in cost has fueled research interest in this technology over the last couple of years. Power electronics (PE) is the key enabling technology for connecting utility-scale BESS to the medium-voltage grid. PE ensure energy is delivered while complying with grid codes and dispatch orders. Simultaneously, the PE must regulate the operating point of the batteries, thus for instance preventing overcharge of batteries. This paper presents a comprehensive review of PE topologies for utility BESS that have been proposed either within industry or the academic literature. Moreover, a comparison of the presently most commercially viable topologies is conducted in terms of estimated power conversion efficiency and relative cost.","Batteries,
Topology,
Harmonic analysis,
State of charge,
Power electronics,
Medium voltage"
Identity-Based Proxy-Oriented Data Uploading and Remote Data Integrity Checking in Public Cloud,"More and more clients would like to store their data to public cloud servers (PCSs) along with the rapid development of cloud computing. New security problems have to be solved in order to help more clients process their data in public cloud. When the client is restricted to access PCS, he will delegate its proxy to process his data and upload them. On the other hand, remote data integrity checking is also an important security problem in public cloud storage. It makes the clients check whether their outsourced data are kept intact without downloading the whole data. From the security problems, we propose a novel proxy-oriented data uploading and remote data integrity checking model in identity-based public key cryptography: identity-based proxy-oriented data uploading and remote data integrity checking in public cloud (ID-PUIC). We give the formal definition, system model, and security model. Then, a concrete ID-PUIC protocol is designed using the bilinear pairings. The proposed ID-PUIC protocol is provably secure based on the hardness of computational Diffie-Hellman problem. Our ID-PUIC protocol is also efficient and flexible. Based on the original client's authorization, the proposed ID-PUIC protocol can realize private remote data integrity checking, delegated remote data integrity checking, and public remote data integrity checking.","Protocols,
Cloud computing,
Servers,
Public key cryptography,
Data models"
Optimal transport theory for power-efficient deployment of unmanned aerial vehicles,"In this paper, the optimal deployment of multiple unmanned aerial vehicles (UAVs) acting as flying base stations is investigated. Considering the downlink scenario, the goal is to minimize the total required transmit power of UAVs while satisfying the users' rate requirements. To this end, the optimal locations of UAVs as well as the cell boundaries of their coverage areas are determined. To find those optimal parameters, the problem is divided into two sub-problems that are solved iteratively. In the first sub-problem, given the cell boundaries corresponding to each UAV, the optimal locations of the UAVs are derived using the facility location framework. In the second sub-problem, the locations of UAVs are assumed to be fixed, and the optimal cell boundaries are obtained using tools from optimal transport theory. The analytical results show that the total required transmit power is significantly reduced by determining the optimal coverage areas for UAVs. These results also show that, moving the UAVs based on users' distribution, and adjusting their altitudes can lead to a minimum power consumption. Finally, it is shown that the proposed deployment approach, can improve the system's power efficiency by a factor of 20 χ compared to the classical Voronoi cell association technique with fixed UAVs locations.","Base stations,
Atmospheric modeling,
Wireless communication,
Propagation losses,
Bandwidth,
Unmanned aerial vehicles,
Downlink"
A Novel Probabilistic Optimal Power Flow Model With Uncertain Wind Power Generation Described by Customized Gaussian Mixture Model,"A novel probabilistic optimal power flow (P-OPF) model with chance constraints that considers the uncertainties of wind power generation (WPG) and load is proposed in this paper. An affine generation dispatch strategy is adopted to balance the system power uncertainty by several conventional generators, and thus the linear approximation of the cost function with respect to the power uncertainty is proposed to compute the quantile (which is also recognized as the value-at-risk) corresponding to a given probability value. The proposed model applies this quantile as the objective function and minimizes it to meet distinct probabilistic cost regulation purposes via properly selecting the given probability. In particular, the hedging effect due to the used affine generation dispatch is also thoroughly investigated. In addition, an analytical method to calculate probabilistic load flow (PLF) is developed with the probability density function of WPG, which is proposed to be approximated by a customized Gaussian mixture model whose parameters are easily obtained. Accordingly, it is successful to analytically compute the chance constraints on the transmission line power and the power outputs of conventional units. Numerical studies of two benchmark systems show the satisfactory accuracy of the PLF method, and the effectiveness of the proposed P-OPF model.","Uncertainty,
Approximation methods,
Load modeling,
Probabilistic logic,
Probability density function,
Computational modeling,
Cost function"
Relay Protection Coordination Integrated Optimal Placement and Sizing of Distributed Generation Sources in Distribution Networks,"The integration of distributed generation (DG) sources can cause significant impacts on distribution networks, particularly the changes in magnitudes and directions of short circuit currents that may lead to false tripping or fail to trip over-current protection relays in the system. It is expensive and technically challenging to redesign/reconfigure and/or to replace the original protection system for a distribution network. If not appropriately handled, this issue can be a big hurdle before the wide use of DG. Based on the impact analysis of the number of DGs, their locations and capacities upon short circuit currents, this paper presents an optimal DG placement method to maximize the penetration level of DG in distribution networks without changing the original relay protection schemes. Genetic algorithm is used to find the optimal locations and sizes of DG in distribution networks. Simulation studies have been carried out on a three-feeder test distribution network and a widely used 33-node test system to show the effectiveness of the proposed method.","Short-circuit currents,
Circuit faults,
Fault currents,
Protective relaying,
Impedance,
Optimization"
An Intrinsically Switchable Ladder-Type Ferroelectric BST-on-Si Composite FBAR Filter,"This paper presents a ladder-type bulk acoustic wave (BAW) intrinsically switchable filter based on ferroelectric thin-film bulk acoustic resonators (FBARs). The switchable filter can be turned on and off by the application of an external bias voltage due to the electrostrictive effect in thin-film ferroelectrics. In this paper, Barium Strontium Titanate (BST) is used as the ferroelectric material. A systematic design approach for switchable ladder-type ferroelectric filters is provided based on required filter specifications. A switchable filter is implemented in the form of a BST-on-Si composite structure to control the effective electromechanical coupling coefficient of FBARs. As an experimental verification, a 2.5-stage intrinsically switchable BST-on-Si composite FBAR filter is designed, fabricated, and measured. Measurement results for a typical BST-on-Si composite FBAR show a resonator mechanical quality factor (Qm) of 971, as well as a (Qm) × f of 2423 GHz. The filter presented here provides a measured insertion loss of 7.8 dB, out-of-band rejection of 26 dB, and fractional bandwidth of 0.33% at 2.5827 GHz when the filter is in the on state at a dc bias of 40 V. In its off state, the filter exhibits an isolation of 31 dB.","Resonator filters,
Film bulk acoustic resonators,
Filter banks,
Switches,
Bandwidth,
Insertion loss,
Resonant frequency"
On Distributed Virtual Network Embedding With Guarantees,"To provide wide-area network services, resources from different infrastructure providers are needed. Leveraging the consensus-based resource allocation literature, we propose a general distributed auction mechanism for the (NP-hard) virtual network (VNET) embedding problem. Under reasonable assumptions on the bidding scheme, the proposed mechanism is proven to converge, and it is shown that the solutions guarantee a worst-case efficiency of (1-(1/e)) relative to the optimal node embedding, or VNET embedding if virtual links are mapped to exactly one physical link. This bound is optimal, that is, no better polynomial-time approximation algorithm exists, unless P=NP. Using extensive simulations, we confirm superior convergence properties and resource utilization when compared to existing distributed VNET embedding solutions, and we show how by appropriate policy design, our mechanism can be instantiated to accommodate the embedding goals of different service and infrastructure providers, resulting in an attractive and flexible resource allocation solution.","Vectors,
Resource management,
Indium phosphide,
Design automation,
Convergence,
Solid modeling,
IEEE transactions"
Recent Advances in Biosensing With Photonic Crystal Surfaces: A Review,"Photonic crystal surfaces that are designed to function as wavelength-selective optical resonators have become a widely adopted platform for label-free biosensing, and for enhancement of the output of photon emitting tags used throughout life science research and in vitro diagnostics. While some applications, such as analysis of drug-protein interactions, require extremely high resolution and the ability to accurately correct for measurement artifacts, others require sensitivity that is high enough for detection of disease biomarkers in serum with concentrations ~1 pg/ml. As the analysis of cells becomes increasingly important for studying the behavior of stem cells, cancer cells, and biofilms under a variety of conditions, approaches that enable high-resolution imaging of live cells without cytotoxic stains or photobleachable fluorescent dyes are providing new tools to biologists who seek to observe individual cells over extended time periods. This paper will review several recent advances in photonic crystal biosensor detection instrumentation and device structures that are being applied toward direct detection of small molecules in the context of high-throughput drug screening, photonic crystal fluorescence enhancement as utilized for high sensitivity multiplexed cancer biomarker detection, and label-free high-resolution imaging of cells and individual nanoparticles as a new tool for life science research and single-molecule diagnostics.","Biosensors,
Optical surface waves,
Surface waves,
Proteins,
Instruments,
Optical sensors"
Energy and Memory Efficient Clone Detection in Wireless Sensor Networks,"In this paper, we propose an energy-efficient location-aware clone detection protocol in densely deployed WSNs, which can guarantee successful clone attack detection and maintain satisfactory network lifetime. Specifically, we exploit the location information of sensors and randomly select witnesses located in a ring area to verify the legitimacy of sensors and to report detected clone attacks. The ring structure facilitates energy-efficient data forwarding along the path towards the witnesses and the sink. We theoretically prove that the proposed protocol can achieve
100
percent clone detection probability with trustful witnesses. We further extend the work by studying the clone detection performance with untrustful witnesses and show that the clone detection probability still approaches
98
percent when
10
percent of witnesses are compromised. Moreover, in most existing clone detection protocols with random witness selection scheme, the required buffer storage of sensors is usually dependent on the node density, i.e.,
O(
n
‾
√
)
, while in our proposed protocol, the required buffer storage of sensors is independent of
n
but a function of the hop length of the network radius
h
, i.e.,
O(h)
. Extensive simulations demonstrate that our proposed protocol can achieve long network lifetime by effectively distributing the traffic load across the network.","Cloning,
Protocols,
Sensors,
Buffer storage,
Wireless sensor networks,
Energy consumption,
Indexes"
Convergence Rate for Discrete-Time Multiagent Systems With Time-Varying Delays and General Coupling Coefficients,"Multiagent systems (MASs) are ubiquitous in our real world. There is an increasing attention focusing on the consensus (or synchronization) problem of MASs over the past decade. Although there are numerous results reported on the convergence of a discrete-time MAS based on the infinite products of matrices, few results are on the convergence rate. Because of the switching topology, the traditional eigenvalue analysis and the Lyapunov function methods are both invalid for the convergence rate analysis of an MAS with a switching topology. Therefore, the estimation of the convergence rate for a discrete-time MAS with time-varying delays remains a difficult problem. To overcome the essential difficulty of switching topology, this paper aims at developing a contractive-set approach to analyze the convergence rate of a discrete-time MAS in the presence of time-varying delays and generalized coupling coefficients. Using the proposed approach, we obtain an upper bound of the convergence rate under the condition of joint connectivity. In particular, the proposed method neither requires the nonnegative property of the coupling coefficients nor the basic assumption of a uniform lower bound for all positive coupling coefficients, which have been widely applied in the existing works on this topic. As an application of the main results, we will show that the classical Vicsek model with time delays can realize synchronization if the initial topology is connected.","Convergence,
Topology,
Switches,
Couplings,
Delays,
Synchronization,
Numerical models"
Scalable SoC trust verification using integrated theorem proving and model checking,"The wide usage of hardware Intellectual Property (IP) cores and software programs from untrusted vendors have raised security concerns for system designers. Existing solutions for detecting and preventing software attacks do not usually consider the presence of malicious logic in hardware. Similarly, hardware solutions for detecting Trojans and/or design backdoors do not consider the software running on it. Formal methods provide powerful solutions in detecting malicious behaviors in both hardware and software. However, they suffer from scalability issues and cannot be easily used for large-scale computer systems. To alleviate the scalability challenge, we propose a new integrated formal verification framework to evaluate the trust of computer systems constructed from untrusted third-party software and hardware resources. This framework combines an automated model checker with an interactive theorem prover for proving system-level security properties. We evaluate a vulnerable program executed on a bare metal LEON3 SPARC V8 processor and prove system security with considerable reduction in effort. Our method systematically reduces the effort required for verifying the program running on the System-on-Chip (SoC) compared to traditional interactive theorem proving methods.","Hardware,
Security,
Model checking,
Computers,
Trojan horses,
Explosions"
Maximizing Data Collection Throughput on a Path in Energy Harvesting Sensor Networks Using a Mobile Sink,"In energy harvesting wireless sensor networks (EH-WSNs), maximizing the data collection throughput is one of the most challenging issues. In this paper, we consider the problem of data collection on a pre-specified path using a mobile sink which has a fixed-mobility pattern. As a generalization of the previous works, we propose an optimization model for the problem which incorporates the effective and heterogeneous duration of sensors' transmission in each time slot. To improve the network throughput, a simple condition is proposed which determines the maximum number of available time slots to each sensor node. Accordingly, the proposed condition specifies the constant velocity of the mobile sink. The NP-Hardness of the problem under the proposed condition is proved and an online centralized algorithm with less complexity is designed to handle the problem. Its complexity is in polynomial order and is easily scalable to the networks with large number of sensor nodes. Furthermore, we address the effect of increase in time slot period on the total amount of collected data which has not been yet exploited well. Finally, through extensive simulations on different set of deployed nodes, we observe that the proposed algorithm significantly increases the network throughput when the travelled distance by sink per time slot is reduced down to the adjusted point.","Mobile communication,
Mobile computing,
Data collection,
Throughput,
Energy harvesting,
Data models,
Trajectory"
Hyperspectral Image Super-Resolution via Non-Negative Structured Sparse Representation,"Hyperspectral imaging has many applications from agriculture and astronomy to surveillance and mineralogy. However, it is often challenging to obtain high-resolution (HR) hyperspectral images using existing hyperspectral imaging techniques due to various hardware limitations. In this paper, we propose a new hyperspectral image super-resolution method from a low-resolution (LR) image and a HR reference image of the same scene. The estimation of the HR hyperspectral image is formulated as a joint estimation of the hyperspectral dictionary and the sparse codes based on the prior knowledge of the spatial-spectral sparsity of the hyperspectral image. The hyperspectral dictionary representing prototype reflectance spectra vectors of the scene is first learned from the input LR image. Specifically, an efficient non-negative dictionary learning algorithm using the block-coordinate descent optimization technique is proposed. Then, the sparse codes of the desired HR hyperspectral image with respect to learned hyperspectral basis are estimated from the pair of LR and HR reference images. To improve the accuracy of non-negative sparse coding, a clustering-based structured sparse coding method is proposed to exploit the spatial correlation among the learned sparse codes. The experimental results on both public datasets and real LR hypspectral images suggest that the proposed method substantially outperforms several existing HR hyperspectral image recovery techniques in the literature in terms of both objective quality metrics and computational efficiency.","Hyperspectral imaging,
Spatial resolution,
Estimation,
Sparse matrices"
Pareto Fronts of Many-Objective Degenerate Test Problems,"In general, an M-objective continuous optimization problem has an (M - 1)-dimensional Pareto front in the objective space. If its dimension is smaller than (M - 1), it is called a degenerate Pareto front. Deb-Thiele-Laumanns-Zitzler (DTLZ)5 and Walking Fish Group (WFG)3 have often been used as many-objective continuous test problems with degenerate Pareto fronts. However, it was noted that DTLZ5 has a nondegenerate part of the Pareto front. Constraints have been proposed to remove the nondegenerate part. In this letter, first we show that WFG3 also has a nondegenerate part. Then, we derive constraints to remove the nondegenerate part. Finally, we show that the existence of the nondegenerate part makes WFG3 an interesting test problem through computational experiments.","Pareto optimization,
Shape,
Linear programming,
Minimization,
Indexes,
Computer science"
An Energy-Balanced Heuristic for Mobile Sink Scheduling in Hybrid WSNs,"Wireless sensor networks (WSNs) are integrated as a pillar of collaborative Internet of Things (IoT) technologies for the creation of pervasive smart environments. Generally, IoT end nodes (or WSN sensors) can be mobile or static. In this kind of hybrid WSNs, mobile sinks move to predetermined sink locations to gather data sensed by static sensors. Scheduling mobile sinks energy-efficiently while prolonging the network lifetime is a challenge. To remedy this issue, we propose a three-phase energy-balanced heuristic. Specifically, the network region is first divided into grid cells with the same geographical size. These grid cells are assigned to clusters through an algorithm inspired by the k-dimensional tree algorithm, such that the energy consumption of each cluster is similar when gathering data. These clusters are adjusted by (de)allocating grid cells contained in these clusters, while considering the energy consumption of sink movement. Consequently, the energy to be consumed in each cluster is approximately balanced considering the energy consumption of both data gathering and sink movement. Experimental evaluation shows that this technique can generate an optimal grid cell division within a limited time of iterations and prolong the network lifetime.","Mobile communication,
Energy consumption,
Wireless sensor networks,
Mobile computing,
Robot sensing systems,
Informatics,
Actuators"
Automated Cognitive Health Assessment From Smart Home-Based Behavior Data,"Smart home technologies offer potential benefits for assisting clinicians by automating health monitoring and well-being assessment. In this paper, we examine the actual benefits of smart home-based analysis by monitoring daily behavior in the home and predicting clinical scores of the residents. To accomplish this goal, we propose a clinical assessment using activity behavior (CAAB) approach to model a smart home resident's daily behavior and predict the corresponding clinical scores. CAAB uses statistical features that describe characteristics of a resident's daily activity performance to train machine learning algorithms that predict the clinical scores. We evaluate the performance of CAAB utilizing smart home sensor data collected from 18 smart homes over two years. We obtain a statistically significant correlation ( r=0.72) between CAAB-predicted and clinician-provided cognitive scores and a statistically significant correlation (r=0.45) between CAAB-predicted and clinician-provided mobility scores. These prediction results suggest that it is feasible to predict clinical scores using smart home sensor data and learning-based data analysis.","Smart homes,
Feature extraction,
Prediction algorithms,
Monitoring,
Correlation,
Informatics,
Biomedical measurement"
BOOST: Base station ON-OFF switching strategy for energy efficient massive MIMO HetNets,"In this paper, we investigate the problem of optimal base station (BS) ON-OFF switching and user association in a heterogeneous network (HetNet) with massive MIMO, with the objective to maximize the system energy efficiency (EE). The joint BS ON-OFF switching and user association problem is formulated as an integer programming problem. We first develop a centralized scheme, in which we relax the integer constraints and employ a series of Lagrangian dual methods that transform the original problem into a standard linear programming (LP) problem. Due to the special structure of the LP, we prove that the optimal solution to the relaxed LP is also feasible and optimal to the original problem. We then propose a distributed scheme by formulating a repeated bidding game for users and BS's, and prove that the game converges to a Nash Equilibrium (NE). Simulation studies demonstrate that the proposed schemes can achieve considerable gains in EE over several benchmark schemes in all the scenarios considered.","MIMO,
Macrocell networks,
Switches,
Power demand,
Linear programming,
Wireless communication,
Games"
Power Allocation for Max-Sum Rate and Max-Min Rate Proportional Fairness in NOMA,"In this letter, we consider proportional fairness scheduling (PFS) for downlink non-orthogonal multiple access (NOMA) with two users. Unlike conventional multiuser diversity systems, the power allocation plays a key role in PFS for NOMA as it can support multiple users simultaneously with positive transmission rates. With different criteria, we find optimal power allocation. Among those, it is shown that the PFS scheme that maximizes the minimum normalized rate can provide not only proportional fairness, but also small variation of transmission rates.","NOMA,
Resource management,
Throughput,
Downlink,
Linear programming,
Multiuser detection,
Indexes"
Plant-Wide Industrial Process Monitoring: A Distributed Modeling Framework,"With the growing complexity of the modern industrial process, monitoring large-scale plant-wide processes has become quite popular. Unlike traditional processes, the measured data in the plant-wide process pose great challenges to information capture, data management, and storage. More importantly, it is difficult to efficiently interpret the information hidden within those data. In this paper, the road map of a distributed modeling framework for plant-wide process monitoring is introduced. Based on this framework, the whole plant-wide process is decomposed into different blocks, and statistical data models are constructed in those blocks. For online monitoring, the results obtained from different blocks are integrated through the decision fusion algorithm. A detailed case study is carried out for performance evaluation of the plant-wide monitoring method. Research challenges and perspectives are discussed and highlighted for future work.","Monitoring,
Data models,
Decentralized control,
Feature extraction,
Analytical models,
Principal component analysis,
Informatics"
Adaptive On/Off Delay-Compensated Active Rectifiers for Wireless Power Transfer Systems,"An adaptive on/off delay-compensation technique is proposed to improve the performance of CMOS active rectifiers for wireless power transfer (WPT) systems. The effects of the on/off delays on the performance of the active rectifiers with either a parallel-resonant or a series-resonant circuit at the secondary coil are studied, which include power conversion efficiency (PCE), voltage conversion ratio (VCR) and output voltage ripple. By adding two feedback loops to the active diodes to generate the switched-offset currents for the comparators adaptively, both onand off-delays are compensated for accurately against PVT variations and mismatches. As a design example, a fully integrated active rectifier for biomedical applications with a parallel-resonant secondary was fabricated in a standard 0.35 μm CMOS process. With an AC input that ranges from 1.8 to 3.6 V, the measured VCR is higher than 90% and the measured PCE is higher than 89.1% for a load resistor of 500 Ω. In particular, the PCE is increased by 9% compared to the active rectifier without using the proposed technique.","rectifiers,
CMOS integrated circuits,
inductive power transmission,
power conversion"
Sparse and Low-Rank Graph for Discriminant Analysis of Hyperspectral Imagery,"Recently, sparse graph-based discriminant analysis (SGDA) has been developed for the dimensionality reduction and classification of hyperspectral imagery. In SGDA, a graph is constructed by ℓ1-norm optimization based on available labeled samples. Different from traditional methods (e.g., k-nearest neighbor with Euclidean distance), weights in an ℓ1-graph derived via a sparse representation can automatically select more discriminative neighbors in the feature space. However, the sparsity-based graph represents each sample individually, lacking a global constraint on each specific solution. As a consequence, SGDA may be ineffective in capturing the global structures of data. To overcome this drawback, a sparse and low-rank graph-based discriminant analysis (SLGDA) is proposed. Low-rank representation has been proved to be capable of preserving global data structures, although it may result in a dense graph. In SLGDA, a more informative graph is constructed by combining both sparsity and low rankness to maintain global and local structures simultaneously. Experimental results on several different multiple-class hyperspectral-classification tasks demonstrate that the proposed SLGDA significantly outperforms the state-of-the-art SGDA.","Hyperspectral imaging,
Sparse matrices,
Dictionaries,
Principal component analysis,
Kernel,
Eigenvalues and eigenfunctions"
On the Parallelization of Spectrum Defragmentation Reconfigurations in Elastic Optical Networks,"Flexible-grid elastic optical networks (EONs) have attracted intensive research interests for the agile spectrum management in the optical layer. Meanwhile, due to the relatively small spectrum allocation granularity, spectrum fragmentation has been commonly recognized as one of the key factors that can deteriorate the performance of EONs. To alleviate spectrum fragmentation, various defragmentation (DF) schemes have been considered to consolidate spectrum utilization in EONs through connection reconfigurations. However, most of the previous approaches operate in the sequential manner (Seq-DF), i.e., involving a sequence of reconfigurations to progressively migrate highly fragmented spectrum utilization to consolidated state. In this paper, we propose to perform the DF operations in a parallel manner (Par-DF), i.e., conducting all the DF-related connection reconfigurations simultaneously. We first provide a detailed analysis on the latency and disruption of Seq-DF and Par-DF in EONs, and highlight the benefits of Par-DF. Then, we study two types of Par-DF approaches in EONs, i.e., reactive Par-DF (re-Par-DF) and proactive Par-DF (pro-Par-DF). We perform hardness analysis on them, and prove that the problem of re-Par-DF is NP-hard in the strong sense while pro-Par-DF is an APX-hard problem. Next, we focus on pro-Par-DF and propose a Lagrangian-relaxation (LR) based heuristic to solve it time-efficiently. The proposed algorithm decomposes the original problem into several independent subproblems and ensures that each of them can be solved efficiently. The LR based approach informs us the proximity of current feasible solution to the optimal one constantly, and offers a near-optimal performance (relative dual gap 5%) within 500 iterations in most simulations. Extensive simulations also verify that the proposed pro-Par-DF approach outperforms Seq-DF in terms of the DF Latency, Disruption and Cost.","Optical fiber networks,
Optical switches,
Bandwidth,
Algorithm design and analysis,
SONET,
Routing,
WDM networks"
Sound Localization Sensors for Search and Rescue Biobots,"Recent advances in neural engineering have enabled direct control of insect locomotion through neural and muscular stimulation. The resulting insect biobots, with a natural ability to crawl through small spaces, offer unique advantages over traditional synthetic robots. A cyberphysical network of such biobots could prove useful for search and rescue applications in uncertain disaster environments. We present a vision-based automated system for an objective assessment of biobotic navigation capability on Madagascar hissing cockroaches. We report the most precise control results obtained with insect biobots so far both manually and autonomously. We also demonstrate autonomous control capability where a low-power insect-mounted array of microphones was used to localize a sound source and guide the biobot toward it. Forming a wireless mobile sensor network with directional and omnidirectional microphones distributed within the structure of a rubble pile could be useful for both environmental mapping and localization of trapped survivors under the rubble.","Insects,
Microphones,
Electrodes,
Robots,
Arrays,
Biosensors"
Investigation of Electrical Characteristics in Al/CdS-PVA/p-Si (MPS) Structures Using Impedance Spectroscopy Method,"The cadmium sulfide (CdS) nanopowders have been prepared by ball-milling method, and CdS-polyvinyl alcohol (PVA) nanocompound in the form of film has been deposited on a p-Si wafer as an interfacial layer by spin-coating method. The impedance characteristics of the fabricated Al/CdS-PVA/ p-Si (metal-polymer-semiconductor)-type structures were studied in the frequency and voltage range of 5 kHz-5 MHz and ±1 V, respectively, by considering interface states (Dit), series resistance (Rs), and interfacial layer effects at 300 K. While the voltage and frequency dependence profiles of Dit were evaluated from the low-high frequency capacitance (CLF-CHF) and Hill-Coleman methods, Rs profiles were evaluated from the Nicollian and Brews method. Doping concentration atoms (NA) and barrier height [ΦB(capacitance-voltage (C-V))] values were also obtained from the reverse bias C-2 versus V plots for each frequency. While Dit and Rs values decrease with increasing frequency almost exponentially, ΦB(C-V) increases linearly. Therefore, both the measured capacitance (Cm) and conductance (Gm/w) values were corrected to eliminate the Rs effect. The experimental results show that Rs value is more effective on the impedance measurements at high frequencies in the accumulation region, but Dit is effective at low frequencies in the depletion region.","Frequency measurement,
Voltage measurement,
Capacitance,
Surface impedance,
Impedance measurement,
Absorption,
Nanostructures"
Near-Optimal Velocity Control for Mobile Charging in Wireless Rechargeable Sensor Networks,"Limited energy in each node is the major design constraint in wireless sensor networks (WSNs). To overcome this limit, wireless rechargeable sensor networks (WRSNs) have been proposed and studied extensively over the last few years. In a typical WRSN, batteries in sensor nodes can be replenished by a mobile charger that periodically travels along a certain trajectory in the sensing area. To maximize the charged energy in sensor nodes, one fundamental question is how to control the traveling velocity of the charger. In this paper, we first identify the optimal velocity control as a key design objective of mobile wireless charging in WRSNs. We then formulate the optimal charger velocity control problem on arbitrarily-shaped irregular trajectories in a 2D space. The problem is proved to be NP-hard, and hence a heuristic solution with a provable upper bound is developed using novel spatial and temporal discretization. We also derive the optimal velocity control for moving the charger along a linear (1D) trajectory commonly seen in many WSN applications. Extensive simulations show that the network lifetime can be extended by 2.5× with the proposed velocity control mechanisms.","Trajectory,
Mobile communication,
Mobile computing,
Velocity control,
Wireless sensor networks,
Acceleration,
Inductive charging"
Weakly Supervised Large Scale Object Localization with Multiple Instance Learning and Bag Splitting,"Localizing objects of interest in images when provided with only image-level labels is a challenging visual recognition task. Previous efforts have required carefully designed features and have difficulty in handling images with cluttered backgrounds. Up-scaling to large datasets also poses a challenge to applying these methods to real applications. In this paper, we propose an efficient and effective learning framework called MILinear, which is able to learn an object localization model from large-scale data without using bounding box annotations. We integrate rich general prior knowledge into a learning model using a large pre-trained convolutional network. Moreover, to reduce ambiguity in positive images, we present a bag-splitting algorithm that iteratively generates new negative bags from positive ones. We evaluate the proposed approach on the challenging Pascal VOC 2007 dataset, and our method outperforms other state-of-the-art methods by a large margin; some results are even comparable to fully supervised models trained with bounding box annotations. To further demonstrate scalability, we also present detection results on the ILSVRC 2013 detection dataset, and our method outperforms supervised deformable part-based model without using box annotations.","Support vector machines,
Feature extraction,
Training,
Visualization,
Computational modeling,
Bismuth,
Proposals"
"Analysis, Design, and Implementation of a Quasi-Proportional-Resonant Controller for a Multifunctional Capacitive-Coupling Grid-Connected Inverter","The capacitive-coupling grid-connected inverter (CGCI) is coupled to the point of common coupling via a second-order LC branch. Its operational voltage is much lower than that of a conventional inductive-coupling grid-connected inverter (IGCI) when it serves as a multifunctional inverter to compensate reactive power and transfer active power simultaneously. It is a promising solution for microgrid and building-integrated distributed generator systems. A quasi-proportional-resonant (quasi-PR) controller is applied to reduce the steady-state current tracking errors of the CGCI in this paper. The quasi-PR controller generates the voltage reference for use of carrier-based pulse-width modulation, which can effectively reduce output current ripples. The second-order coupling impedance of the CGCI causes its modeling and controller design to differ from that of the conventional IGCI. A comprehensive design method for the quasi-PR controller in a CGCI is developed. The quasi-PR controller is also compared with a proportional-integration current controller. Simulation results are provided to verify the effectiveness of the quasi-PR controller and its design method in a CGCI. The current tracking errors are greatly reduced when the quasi-PR controller rather than the proportional-integration controller is applied. Experimental results are also provided to validate the CGCI as a multifunctional grid-connected inverter.","Inverters,
Pulse width modulation,
Couplings,
Reactive power,
Impedance,
Integrated circuits,
Voltage control"
User Association and Interference Management in Massive MIMO HetNets,"Two key traits of 5G cellular networks are much higher base station (BS) densities-especially in the case of low-power BSs-and the use of massive MIMO at these BSs. This paper explores how massive MIMO can be used to jointly maximize the offloading gains and minimize the interference challenges arising from adding small cells. We consider two interference management approaches: joint transmission (JT) with local precoding, where users are served simultaneously by multiple BSs without requiring channel state information exchanges among cooperating BSs, and resource blanking, where some macro BS resources are left blank to reduce the interference in the small cell downlink. A key advantage offered by massive MIMO is channel hardening, which enables to predict instantaneous rates a priori. This allows us to develop a unified framework, where resource allocation is cast as a network utility maximization (NUM) problem, and to demonstrate large gains in cell-edge rates based on the NUM solution. We propose an efficient dual subgradient based algorithm, which converges towards the NUM solution. A scheduling scheme is also proposed to approach the NUM solution. Simulations illustrate more than 2x rate gain for 10th percentile users vs. an optimal association without interference management.","Interference,
MIMO,
Resource management,
Blanking,
Load management,
Optimization,
Scheduling"
Stochastic Optimization of Sub-Hourly Economic Dispatch With Wind Energy,"We present a stochastic programming framework for a multiple timescale economic dispatch problem to address integration of renewable energy resources into power systems. This framework allows certain slow-response energy resources to be controlled at an hourly timescale, while fast-response resources, including renewable resources, and related network decisions can be controlled at a sub-hourly timescale. To this end, we study two models motivated by actual scheduling practices of system operators. Using an external simulator as driver for sub-hourly wind generation, we optimize these economic dispatch models using stochastic decomposition, a sample-based approach for stochastic programming. Computational experiments, conducted on the IEEE-RTS96 system and the Illinois system, reveal that optimization with sub-hourly dispatch not only results in lower expected operational costs, but also predicts these costs with far greater accuracy than with models allowing only hourly dispatch. Our results also demonstrate that when compared with standard approaches using the extensive formulation of stochastic programming, the sequential sampling approach of stochastic decomposition provides better predictions with much less computational time.","Stochastic processes,
Optimization,
Biological system modeling,
Generators,
Computational modeling,
Economics,
Approximation methods"
Low-Loss Spoof Surface Plasmon Slow-Wave Transmission Lines With Compact Transition and High Isolation,"The symmetric spoof surface plasmon (SSP)-based slow-wave transmission line (SW-TL) with compact transition, low ohmic loss, and low crosstalk between SW-TLs is proposed and investigated. First, the SSP cells are modeled by equivalent circuit elements. The proposed equivalent circuit model is appealing for the integration of SW-TLs with other microwave circuits. With the symmetricity, the SW-TLs are readily realized by a compact mode converter providing gradual impedance, momentum, and polarization matching from guided waves to spoof microwave plasmons. Then, simulation studies and experiments verify that the proposed SSP SW-TL features as low as half the ohmic loss of the traditional counterparts. After that, the low mutual coupling between the proposed SSP SW-TLs is numerically and experimentally substantiated and showed to be up to 10 dB lower than that between conventional microstrip TLs. The proposed low loss, highly isolated and compact SW-TL along with the reliable circuit model enables the further exploitation of promising spoof plasmon modes in microwave technology.","Microstrip,
Microwave circuits,
Dispersion,
Plasmons,
Cutoff frequency"
Large-Scale Aerial Image Categorization Using a Multitask Topological Codebook,"Fast and accurately categorizing the millions of aerial images on Google Maps is a useful technique in pattern recognition. Existing methods cannot handle this task successfully due to two reasons: 1) the aerial images' topologies are the key feature to distinguish their categories, but they cannot be effectively encoded by a conventional visual codebook and 2) it is challenging to build a realtime image categorization system, as some geo-aware Apps update over 20 aerial images per second. To solve these problems, we propose an efficient aerial image categorization algorithm. It focuses on learning a discriminative topological codebook of aerial images under a multitask learning framework. The pipeline can be summarized as follows. We first construct a region adjacency graph (RAG) that describes the topology of each aerial image. Naturally, aerial image categorization can be formulated as RAG-to-RAG matching. According to graph theory, RAG-to-RAG matching is conducted by enumeratively comparing all their respective graphlets (i.e., small subgraphs). To alleviate the high time consumption, we propose to learn a codebook containing topologies jointly discriminative to multiple categories. The learned topological codebook guides the extraction of the discriminative graphlets. Finally, these graphlets are integrated into an AdaBoost model for predicting aerial image categories. Experimental results show that our approach is competitive to several existing recognition models. Furthermore, over 24 aerial images are processed per second, demonstrating that our approach is ready for real-world applications.",
Flexible Fault-Tolerant Topology for Switched Reluctance Motor Drives,"Switched reluctance motor (SRM) drives are one competitive technology for traction motor drives. This paper proposes a novel and flexible SRM fault-tolerant topology with fault diagnosis, fault tolerance, and advanced control functions. The converter is composed of a single-phase bridge and a relay network, based on the traditional asymmetrical half-bridge driving topology. When the SRM-driving system is subjected to fault conditions including open-circuit and short-circuit faults, the proposed converter starts its fault-diagnosis procedure to locate the fault. Based on the relay network, the faulty part can be bypassed by the single-phase bridge arm, while the single-phase bridge arm and the healthy part of the converter can form a fault-tolerant topology to sustain the driving operation. A fault-tolerant control strategy is developed to decrease the influence of the fault. Furthermore, the proposed fault-tolerant strategy can be applied to three-phase 12/8 SRM and four-phase 8/6 SRM. Simulation results in MATLAB/Simulink and experiments on a three-phase 12/8 SRM and a four-phase 8/6 SRM validate the effectiveness of the proposed strategy, which may have significant economic implications in traction drive systems.",
Optimal Reliability in Energy Harvesting Industrial Wireless Sensor Networks,"For industrial wireless sensor networks, it is essential to reliably sense and deliver the environmental data on time to avoid system malfunction. While energy harvesting is a promising technique to extend the lifetime of sensor nodes, it also brings new challenges for system reliability due to the stochastic nature of the harvested energy. In this paper, we investigate the optimal energy management policy to minimize the weighted packet loss rate under the delay constraint, where the packet loss rate considers the lost packets, both during the sensing and delivering processes. We show that the above-mentioned energy management problem can be modeled as an infinite horizon average reward constraint Markov decision problem. In order to address the well-known curse of dimensionality problem and facilitate distributed implementation, we use the linear value approximation technique. Moreover, we apply stochastic online learning with a post-decision state to deal with the lack of the knowledge of the underlying stochastic processes. A distributed energy allocation algorithm with a water-filling structure and a scheduling algorithm by an auction mechanism are obtained. Experimental results show that the proposed algorithm achieves nearly the same performance as the optimal offline value iteration algorithm while requiring much less computation complexity and signaling overhead, and outperforms various existing baseline algorithms.",
Standby-Power-Free Integrated Circuits Using MTJ-Based VLSI Computing,"Nonvolatile spintronic devices have potential advantages, such as fast read/write and high endurance together with back-end-of-the-line compatibility, which offers the possibility of constructing not only stand-alone RAMs and embedded RAMs that can be used in conventional VLSI circuits and systems but also standby-power-free high-performance nonvolatile CMOS logic employing logic-in-memory architecture. The advantages of employing spintronic devices, especially magnetic tunnel junction (MTJ) devices with CMOS circuits, are discussed, and the current status of the MTJ-based VLSI computing paradigm is presented along with its prospects and remaining challenges.","Magnetic tunneling,
Nonvolatile memory,
Very large scale integration,
Magnetoelectronics,
Random access memory,
Computer architecture,
Performance evaluation,
Spintronics"
Arbitrary Power-Conserving Field Transformations With Passive Lossless Omega-Type Bianisotropic Metasurfaces,"We present a general theory for designing realistic omega-type bianisotropic metasurfaces (O-BMSs), unlocking their full potential for molding electromagnetic fields. These metasurfaces, characterized by electric surface impedance, magnetic surface admittance, and magnetoelectric coupling coefficient, were previously considered for wavefront manipulation. However, previous reports mainly considered plane-wave excitations, and implementations included cumbersome metallic features. In this paper, we prove that any field transformation that locally conserves real power can be implemented via passive and lossless meta-atoms characterized by closed-form expressions; this allows rigorous incorporation of arbitrary source and scattering configurations. Subsequently, we show that O-BMS meta-atoms can be implemented using an asymmetric stack of three impedance sheets, an appealing structure for printed circuit board fabrication. Our formulation reveals that, as opposed to Huygens' metasurfaces, which exhibit negligible magnetoelectric coupling, O-BMSs are not limited to controlling the phase of transmitted fields, but can rather achieve a high level of control over the amplitude and phase of reflected fields. This is demonstrated by designing O-BMSs for reflectionless wide-angle refraction, independent surface-wave guiding, and a highly directive low-profile antenna, verified with full-wave simulations. This straightforward methodology facilitates the development of O-BMS-based devices for controlling the near and far fields of arbitrary sources in complex scattering configurations.","Magnetoelectric effects,
Surface impedance,
Impedance,
Magnetic resonance,
Surface waves,
Antennas"
A Novel Simple and Compact Microstrip-Fed Circularly Polarized Wide Slot Antenna With Wide Axial Ratio Bandwidth for C-Band Applications,"This communication presents a design of a new compact circularly polarized (CP) slot antenna fed by a microstrip feedline. The 3-dB axial ratio band can be achieved by simply protruding a horizontal stub from the ground plane toward the center of the wide slot (WS) and then feeding the WS with a microstrip feedline positioned to the side of the WS, underneath the protruded stub. The feedline and metallic stub are perpendicular to each other, and they resemble a T shape when viewed from the top. The proposed antenna is fabricated with an area of 25 × 25 mm2. Measurement results show that the antenna attains an S11 ≤ -10 dB impedance matching bandwidth of 90.2%, from 3.5 to 9.25 GHz, and a broadband 3 dB-AR bandwidth of 40%, ranging from 4.6 to 6.9 GHz. A peak gain of 0.8-4.5 dBi is achieved within the AR band. The proposed antenna is suitable for circular polarization applications in C band.","Bandwidth,
Slot antennas,
Microstrip antennas,
Antenna measurements,
Microstrip,
Impedance"
Semi-Blind Pilot Decontamination for Massive MIMO Systems,"In multicell multiuser massive multi-input multi-output (MIMO) systems, pilot contamination degrades the uplink (UL) channel estimation performance. To mitigate the effect of pilot contamination, we propose a semiblind channel estimation method that does not require cell cooperation or statistical information of the channels. In the proposed method, we first sequentially estimate the UL data from different users in the target cell. To do that, for each user, we solve a constrained minimization problem to obtain an extracting vector and then use it to extract the desired data source from the observed mixture signal. An efficient algorithm is presented to solve the optimization problem. After the ambiguities in the extracted source are corrected with the aid of the pilot sequence, the estimates of the user UL data can be obtained. Based on the demodulated UL data of all users in the target cell, we finally obtain the least squares (LS) estimate of the channel. The pilot contamination effect is shown to be reduced as the UL data length grows. Simulation results demonstrate that the proposed method significantly outperforms some existing channel estimation methods that do not require cell cooperation or channel statistics.","Channel estimation,
Contamination,
MIMO,
Data mining,
Robustness,
Wireless communication,
Antennas"
Green Full-Duplex Self-Backhaul and Energy Harvesting Small Cell Networks With Massive MIMO,"With the dense deployment of small cell networks, the powering and backhaul problem of small cell base stations (SBSs) has attracted great attention, and energy harvesting technology and self-backhaul technology have been proposed as promising solutions. Although some excellent works have been done on energy harvesting and self-backhaul in small cell networks, most existing works do not consider them jointly. In this paper, we aim at green small cell networks by jointly achieving self-backhaul and energy harvesting. In addition, full-duplex and massive multiple-input and multiple-output technologies are also exploited to enhance the system performance. In order to improve the energy efficiency (EE) further, a novel precoding scheme is designed to eliminate both the inter-tier and multi-user interference. Based on the proposed precoding scheme, we formulate the cell association and power allocation problem as an optimization problem to optimize the system EE performance, with the energy arrival rate and remaining battery energy in SBSs involved. The formulated optimization problem implies a sleep mechanism to control the ON/OFF of SBSs, which will further reduce the energy consumption of small cell networks. In addition, to reduce the computation complexity to solve this non-convex problem, we propose to transform the original problem into a difference of convex program, which can be efficiently solved via a constrained concave convex procedure-based algorithm. Extensive simulation results are presented to justify the effectiveness of the proposed scheme with different system configurations.","MIMO,
Energy harvesting,
Computer architecture,
Interference,
Microprocessors,
Resource management,
Antenna arrays,
Green communications,
Energy efficiency"
Video Super-Resolution With Convolutional Neural Networks,"Convolutional neural networks (CNN) are a special type of deep neural networks (DNN). They have so far been successfully applied to image super-resolution (SR) as well as other image restoration tasks. In this paper, we consider the problem of video super-resolution. We propose a CNN that is trained on both the spatial and the temporal dimensions of videos to enhance their spatial resolution. Consecutive frames are motion compensated and used as input to a CNN that provides super-resolved video frames as output. We investigate different options of combining the video frames within one CNN architecture. While large image databases are available to train deep neural networks, it is more challenging to create a large video database of sufficient quality to train neural nets for video restoration. We show that by using images to pretrain our model, a relatively small video database is sufficient for the training of our model to achieve and even improve upon the current state-of-the-art. We compare our proposed approach to current video as well as image SR algorithms.","Dictionaries,
Image reconstruction,
Training,
Neural networks,
Spatial resolution,
Computer architecture"
The Capacity of Private Information Retrieval,"In the private information retrieval (PIR) problem a user wishes to retrieve, as efficiently as possible, one out of K messages from N non-communicating databases (each holds all K messages) while revealing nothing about the identity of the desired message index to any individual database. The information theoretic capacity of PIR is the maximum number of bits of desired information that can be privately retrieved per bit of downloaded information. For K messages and N databases, we show that the PIR capacity is (1 + 1/N + 1/N2 + ⋯+1/NK-1)-1. A remarkable feature of the capacity achieving scheme is that if it is projected onto any subset of messages by eliminating the remaining messages, it also achieves the PIR capacity for that subset of messages.","Indexes,
Information retrieval,
Privacy,
Encoding,
Computer science"
AutoElastic: Automatic Resource Elasticity for High Performance Applications in the Cloud,"Elasticity is undoubtedly one of the most striking characteristics of cloud computing. Especially in the area of high performance computing (HPC), elasticity can be used to execute irregular and CPU-intensive applications. However, the on- the-fly increase/decrease in resources is more widespread in Web systems, which have their own IaaS-level load balancer. Considering the HPC area, current approaches usually focus on batch jobs or assumptions such as previous knowledge of application phases, source code rewriting or the stop-reconfigure-and-go approach for elasticity. In this context, this article presents AutoElastic, a PaaS-level elasticity model for HPC in the cloud. Its differential approach consists of providing elasticity for high performance applications without user intervention or source code modification. The scientific contributions of AutoElastic are twofold: (i) an Aging-based approach to resource allocation and deallocation actions to avoid unnecessary virtual machine (VM) reconfigurations (thrashing) and (ii) asynchronism in creating and terminating VMs in such a way that the application does not need to wait for completing these procedures. The prototype evaluation using OpenNebula middleware showed performance gains of up to 26 percent in the execution time of an application with the AutoElastic manager. Moreover, we obtained low intrusiveness for AutoElastic when reconfigurations do not occur.","Elasticity,
Cloud computing,
Monitoring,
Measurement,
Resource management,
Graphical user interfaces"
Collective Travel Planning in Spatial Networks,"Travel planning and recommendation are important aspects of transportation. We propose and investigate a novel Collective Travel Planning (CTP) query that finds the lowest-cost route connecting multiple sources and a destination, via at most k
meeting points. When multiple travelers target the same destination (e.g., a stadium or a theater), they may want to assemble at meeting points and then go together to the destination by public transport to reduce their global travel cost (e.g., energy, money, or greenhouse-gas emissions). This type of functionality holds the potential to bring significant benefits to society and the environment, such as reducing energy consumption and greenhouse-gas emissions, enabling smarter and greener transportation, and reducing traffic congestions. The CTP query is Max SNP-hard. To compute the query efficiently, we develop two algorithms, including an exact algorithm and an approximation algorithm. The exact algorithm is capable finding the optimal result for small values of k
(e.g., k = 2
) in interactive time, while the approximation algorithm, which has a 5
-approximation ratio, is suitable for other situations. The performance of the CTP query is studied experimentally with real and synthetic spatial data.",
Load Aware Self-Organising User-Centric Dynamic CoMP Clustering for 5G Networks,"Coordinated multi-point (CoMP) is a key feature for mitigating inter-cell interference, improve system throughput, and cell edge performance. However, CoMP implementation requires complex beamforming/scheduling design, increased backhaul bandwidth, additional pilot overhead, and precise synchronization. Cooperation needs to be limited to a few cells only due to this imposed overhead and complexity. Hence, small CoMP clusters will need to be formed in the network. In this paper, we first present a self-organizing, user-centric CoMP clustering algorithm in a control/data plane separation architecture, proposed for 5G to maximize spectral efficiency (SE) for a given maximum cluster size. We further utilize this clustering algorithm and introduce a novel two-stage re-clustering algorithm to reduce high load on cells in hotspot areas and improve user satisfaction. Stage-1 of the algorithm utilizes maximum cluster size metric to introduce additional capacity in the system. A novel re-clustering algorithm is introduced in stage-2 to distribute load from highly loaded cells to neighboring cells with less load for multi-user joint transmission CoMP case. We show that unsatisfied users due to high load can be significantly reduced with minimal impact on SE.","Computer architecture,
Microprocessors,
Clustering algorithms,
ALgorithm design and analysis,
Bandwidth allocation,
Inter-cell Interference,
Throughput,
Load management"
Toward Distributed Data Processing on Intelligent Leak-Points Prediction in Petrochemical Industries,"Focusing on the leak-points in petrochemical industries, this paper discusses the key factors (i.e., equipment temperature, gas pressure, and diffusion rate) in petrochemical industries. Data from sensors of petrochemical industries need to be timely operated because of time sensitivity and it is hard to achieve associated information from sensors located in production sites. To this end, we propose a three-level framework based on improved back propagation (TLBP). The real-time data streams are processed according to the arriving time in input layer. At the same time, a neuron-optimizing solution is introduced in learning process to deal with redundant and invalid neurons, thereby accelerating the response speed of learning and reducing the prediction time. Finally, we propose an improved mechanism of the multidimensional learning factor to lower the learning error and higher convergence rate. Meanwhile, to fulfill the distributed prediction on leak-points, we see one three-level data-processing unit as a logic machine with multiple operators. Using the assignment scheduling, the general scheduling problem is split into the common subproblem of every operator and the system overhead is reduced. With the processed data we can obtain the relative location or diffusion radius of leak-points, as well as the area of leak-points. Simulation results show that the TLBP performs better than related algorithms in different metrics. Besides, the adaptability of TLBP is verified in leak-points prediction of petrochemical equipment from the processed data.","Neurons,
Data processing,
Petrochemicals,
Prediction algorithms,
Sensors,
Convergence,
Joining processes"
Learning a Combined Model of Visual Saliency for Fixation Prediction,"A large number of saliency models, each based on a different hypothesis, have been proposed over the past 20 years. In practice, while subscribing to one hypothesis or computational principle makes a model that performs well on some types of images, it hinders the general performance of a model on arbitrary images and large-scale data sets. One natural approach to improve overall saliency detection accuracy would then be fusing different types of models. In this paper, inspired by the success of late-fusion strategies in semantic analysis and multi-modal biometrics, we propose to fuse the state-of-the-art saliency models at the score level in a para-boosting learning fashion. First, saliency maps generated by several models are used as confidence scores. Then, these scores are fed into our para-boosting learner (i.e., support vector machine, adaptive boosting, or probability density estimator) to generate the final saliency map. In order to explore the strength of para-boosting learners, traditional transformation-based fusion strategies, such as Sum, Min, and Max, are also explored and compared in this paper. To further reduce the computation cost of fusing too many models, only a few of them are considered in the next step. Experimental results show that score-level fusion outperforms each individual model and can further reduce the performance gap between the current models and the human inter-observer model.","Computational modeling,
Predictive models,
Biological system modeling,
Visualization,
Feature extraction,
Support vector machines,
Semantics"
Planar Ultrawideband Antennas With Improved Realized Gain Performance,"The design nuances and associated performance characteristics of two printed planar ultrawideband (UWB) antennas are reported. The designs achieve improved broadside-realized gains, particularly at the high-frequency side of the UWB band. An arc-shaped slot is etched into the radiating patch of a standard compact elliptically shaped UWB monopole antenna. The resulting parasitic element is engineered to produce its fundamental resonant mode in such a manner that a more compact overall design is realized and the broadside-realized gain in the upper UWB frequency range is improved while maintaining impedance matching without any significant changes to the original design parameters. In agreement with simulations, a 61.7% reduction in size from previous designs is demonstrated with more than a 6 dB increase in the realized gain near 10 GHz. To further improve its high-frequency characteristics, a multimode-resonator filter consisting of a single-wing element is combined with the slot-modified UWB antenna. The filter is first designed, fabricated, and measured to demonstrate that it produces the predicted appropriate transmission characteristics throughout the UWB band. The design integration of this compact filter is then presented and the resulting performance characteristics of the overall antenna system illustrate its advantages. The simulated and measured results are in good agreement. They indicate that the integrated design possesses sharp frequency cutoffs at both edges of the UWB passband, as well as strong upper stop-band attenuation. As a consequence, a 2.12 dB further increase of the broadside-realized gain values is demonstrated near 10 GHz.",
A 3-D Riesz-Covariance Texture Model for Prediction of Nodule Recurrence in Lung CT,"This paper proposes a novel imaging biomarker of lung cancer relapse from 3-D texture analysis of CT images. Three-dimensional morphological nodular tissue properties are described in terms of 3-D Riesz-wavelets. The responses of the latter are aggregated within nodular regions by means of feature covariances, which leverage rich intra- and inter-variations of the feature space dimensions. When compared to the classical use of the average for feature aggregation, feature covariances preserve spatial co-variations between features. The obtained Riesz-covariance descriptors lie on a manifold governed by Riemannian geometry allowing geodesic measurements and differentiations. The latter property is incorporated both into a kernel for support vector machines (SVM) and a manifold-aware sparse regularized classifier. The effectiveness of the presented models is evaluated on a dataset of 110 patients with non-small cell lung carcinoma (NSCLC) and cancer recurrence information. Disease recurrence within a timeframe of 12 months could be predicted with an accuracy of 81.3-82.7%. The anatomical location of recurrence could be discriminated between local, regional and distant failure with an accuracy of 78.3-93.3%. The obtained results open novel research perspectives by revealing the importance of the nodular regions used to build the predictive models.","Computed tomography,
Cancer,
Biomedical imaging,
Lungs,
Solids,
Tumors"
Very Deep Convolutional Neural Networks for Noise Robust Speech Recognition,"Although great progress has been made in automatic speech recognition, significant performance degradation still exists in noisy environments. Recently, very deep convolutional neural networks (CNNs) have been successfully applied to computer vision and speech recognition tasks. Based on our previous work on very deep CNNs, in this paper this architecture is further developed to improve recognition accuracy for noise robust speech recognition. In the proposed very deep CNN architecture, we study the best configuration for the sizes of filters, pooling, and input feature maps: the sizes of filters and poolings are reduced and dimensions of input features are extended to allow for adding more convolutional layers. Then the appropriate pooling, padding, and input feature map selection strategies are investigated and applied to the very deep CNN to make it more robust for speech recognition. In addition, an in-depth analysis of the architecture reveals key characteristics, such as compact model scale, fast convergence speed, and noise robustness. The proposed new model is evaluated on two tasks: Aurora4 task with multiple additive noise types and channel mismatch, and the AMI meeting transcription task with significant reverberation. Experiments on both tasks show that the proposed very deep CNNs can significantly reduce word error rate (WER) for noise robust speech recognition. The best architecture obtains a 10.0% relative reduction over the traditional CNN on AMI, competitive with the long short-term memory recurrent neural networks (LSTM-RNN) acoustic model. On Aurora4, even without feature enhancement, model adaptation, and sequence training, it achieves a WER of 8.81%, a 17.0% relative improvement over the LSTM-RNN. To our knowledge, this is the best published result on Aurora4.","Speech recognition,
Convolution,
Neural networks,
Noise measurement,
Noise robustness"
Caching and operator cooperation policies for layered video content delivery,"Distributed caching architectures have been proposed for bringing content close to requesters and the key problem is to design caching algorithms for reducing content delivery delay. The problem obtains an interesting new twist with the advent of advanced layered-video encoding techniques such as Scalable Video Coding (SVC). We show that the problem of finding the caching configuration of video encoding layers that minimizes average delay for a network operator is NP-Hard, and we establish a pseudopolynomial-time optimal solution using a connection with the multiple-choice knapsack problem. We also design caching algorithms for multiple operators that cooperate by pooling together their co-located caches, in an effort to aid each other, so as to avoid large delays due to downloading content from distant servers. We derive an approximate solution to this cooperative caching problem using a technique that partitions the cache capacity into amounts dedicated to own and others' caching needs. Numerical results based on real traces of SVC-encoded videos demonstrate up to 25% reduction in delay over existing (layer-agnostic) caching schemes, with increasing gains as the video popularity distribution gets steeper, and cache capacity increases.","Streaming media,
Delays,
Servers,
Static VAr compensators,
Approximation algorithms,
Encoding,
Video recording"
Opportunistic WiFi Offloading in Vehicular Environment: A Game-Theory Approach,"In this paper, we study opportunistic traffic offloading in a vehicular environment, where the cellular traffic of vehicular users (VUs) is offloaded through carrier-WiFi networks deployed by the mobile network operator (MNO). By jointly considering users' satisfaction, the offloading performance, and the MNO's revenue, two WiFi offloading mechanisms are proposed: auction game-based offloading (AGO) and congestion game-based offloading (CGO). Moreover, we introduce an approach to predict WiFi offloading potential and access cost and incorporate it in the offloading mechanisms. Specifically, with the AGO mechanism, the MNO employs auctions to sell WiFi access opportunities; VUs decide whether to bid according to their utilities and are capable of using WiFi if the auction is won. With the CGO mechanism, a VU calculates utility considering other VUs' strategies and makes offloading decisions accordingly. We show that the AGO mechanism can maximize social welfare and increase the MNO's revenue, whereas the CGO mechanism can achieve a better performance of average VU utility and fairness. Additionally, both AGO and CGO mechanisms can improve the overall WiFi offloading performance. Through simulations, we demonstrate that both AGO and CGO mechanisms can achieve higher average utility of VUs and lower average service delay and offload much more cellular traffic compared with existing offloading mechanisms.","IEEE 802.11 Standard,
Mobile communication,
Vehicles,
Delays,
Mobile computing,
Internet,
Quality of service"
A Branching-Process-Based Method to Check Soundness of Workflow Systems,"Workflow nets (WF-nets) as a class of Petri nets are widely used to model and analyze workflow systems. Soundness is an important property of WF-nets, which guarantees that the systems are deadlock- and livelock-free and each task has a chance to be performed. Van der Aalst has proven that the soundness problem is decidable for WF-nets and we have also shown that it is PSPACE-complete for bounded ones. Since the definition of soundness is based on reachability and Van der Aalst has proven that a sound WF-net must be bounded, the soundness detection can be carried out via the reachability graph analysis. However, the state explosion problem is a big obstacle to this technique. The unfolding technique of Petri nets can effectively avoid/alleviate this problem. This paper proposes an algorithm to generate a finite prefix of the unfolding of a WF-net, called basic unfolding. Furthermore, a necessary and sufficient condition is proposed to decide soundness based on basic unfolding. In addition, some examples illustrate that the unfolding technique can save the storage space effectively.","Petri nets,
Business process model,
Branching proces,
Analytical models,
Algorithm design and analysis,
Sufficient conditions"
"Biomedical and Catalytic Applications of Gold and Silver-Gold Alloy Nanoparticles Biosynthesized Using Cell-Free Extract of Bacillus Safensis LAU 13: Antifungal, Dye Degradation, Anti-Coagulant and Thrombolytic Activities","This study investigated the green biosynthesis of gold (Au) and silver-gold alloy (Ag-Au) nanoparticles using cell-free extract of Bacillus safensis LAU 13 strain (GenBank accession No: KJ461434). The biosynthesized AuNPs and Ag-AuNPs were characterized using UV-Vis spectroscopy, Fourier-transform infrared spectroscopy, and transmission electron microscopy. Evaluation of the antifungal activities, degradation of malachite green, anti-coagulation of blood, and thrombolysis of human blood clot by the biosynthesized nanoparticles were investigated. The AuNPs and Ag-AuNPs had maximum absorbance at 561 and 545 nm, respectively. The FTIR peaks at 3318, 2378, 2114, 1998, 1636, 1287, 446, 421 cm-1 for AuNPs; and 3310, 2345, 2203, 2033, 1636, 1273, 502, 453, 424 cm-1 for Ag-AuNPs indicated that proteins were the capping and stabilization molecules in the biosynthesized nanoparticles. The particles were fairly spherical in shape with size of 10-45 nm for AuNPs and 13-80 nm for Ag-AuNPs. Moreover, energy dispersive X-ray analysis of AuNPs revealed gold as the most prominent metal in the AuNPs solution, while silver and gold were the most prominent in the case of Ag-AuNPs. Selected area electron diffraction showed the biosynthesized nanoparticles as crystal structures with ring shape pattern. AuNPs and Ag-AuNPs displayed growth inhibitions of 66.67-90.78% against strains of Aspergillus fumigatus and A. niger at concentration of 200 μg/ml, and remarkable degradation (> 90%) of malachite green after 48 h. Furthermore, the nanoparticles prevented coagulation of blood, and also completely dissolved blood clots, indicating the biomedical potential of AuNPs and Ag-AuNPs in the management of blood coagulation disorders. This is the first report of the synthesis of AuNPs and Ag-AuNPs using a strain of B. safensis for biomedical and catalytic applications.","Nanoparticles,
Gold,
Coagulation,
Nanobioscience,
Anti-fungal,
Degradation"
Circulating Current Suppression of the Modular Multilevel Converter in a Double-Frequency Rotating Reference Frame,"The modular multilevel converter (MMC) has attracted significant interest for medium-/high-power energy conversion applications due to its modularity, scalability, and excellent harmonic performance. One of the technical challenges associated with the operation of the MMC is the circulation of double-frequency harmonic currents within its phase legs. This paper proposes a circulating current control strategy in a double-frequency rotating reference frame, which, contrary to the existing solutions that are based on approximate/inaccurate models, relies on an experimentally identified nonparametric model of circulating currents to determine the coefficients of the controller. Minimizing the squared second norm of the error between the open-loop transfer function of the system and a desired one, the coefficients of the controller are determined. To guarantee the stability of the closed-loop system, the minimization problem is subjected to a few constraints. The validity and effectiveness of the proposed control strategy is confirmed, and its dynamic performance is compared with that of an existing solution by experimental results.",
A Novel Reconfigurable Feeding Network for Quad-Polarization-Agile Antenna Design,"In this communication, a reconfigurable feeding network is proposed for the design of a quad-polarization-agile antenna. By switching the PIN diodes, the four transmission modes with selected phase differences can be electrically tuned at two output ports. For each mode, the measured insertion loss of the feeding network is less than 0.8 dB at the operating frequency. Because of its compact size, the proposed feeding network can be further integrated with a dual-polarized aperture-coupled antenna, which can exhibit two orthogonal linear polarizations and two orthogonal circular polarizations. Measured results of the polarization-agile antenna are shown in detail, which verify its performance.","Antenna measurements,
Ports (Computers),
Antenna feeds,
Switches,
Patch antennas,
Antenna radiation patterns"
Crowdsourced Data Management: A Survey,"Any important data management and analytics tasks cannot be completely addressed by automated processes. These tasks, such as entity resolution, sentiment analysis, and image recognition can be enhanced through the use of human cognitive ability. Crowdsouring platforms are an effective way to harness the capabilities of people (i.e., the crowd) to apply human computation for such tasks. Thus, crowdsourced data management has become an area of increasing interest in research and industry. We identify three important problems in crowdsourced data management. (1) Quality Control: Workers may return noisy or incorrect results so effective techniques are required to achieve high quality; (2) Cost Control: The crowd is not free, and cost control aims to reduce the monetary cost; (3) Latency Control: The human workers can be slow, particularly compared to automated computing time scales, so latency-control techniques are required. There has been significant work addressing these three factors for designing crowdsourced tasks, developing crowdsourced data manipulation operators, and optimizing plans consisting of multiple operators. In this paper, we survey and synthesize a wide spectrum of existing studies on crowdsourced data management. Based on this analysis we then outline key factors that need to be considered to improve crowdsourced data management.","Crowdsourcing,
Quality control,
Pricing,
Predictive models,
Electronic mail,
Data models,
Computational modeling"
Truthful Scheduling Mechanisms for Powering Mobile Crowdsensing,"Mobile crowdsensing leverages mobile devices (e.g., smart phones) and human mobility for pervasive information exploration and collection; it has been deemed as a promising paradigm that will revolutionize various research and application domains. Unfortunately, the practicality of mobile crowdsensing can be crippled due to the lack of incentive mechanisms that stimulate human participation. In this paper, we study incentive mechanisms for a novel Mobile Crowdsensing Scheduling (MCS) problem, where a mobile crowdsensing application owner announces a set of sensing tasks, then human users (carrying mobile devices) compete for the tasks based on their respective sensing costs and available time periods, and finally the owner schedules as well as pays the users to maximize its own sensing revenue under a certain budget. We prove that the MCS problem is NP-hard and propose polynomial-time approximation mechanisms for it. We also show that our approximation mechanisms (including both offline and online versions) achieve desirable game-theoretic properties, namely truthfulness and individual rationality, as well as O(1) performance ratios. Finally, we conduct extensive simulations to demonstrate the correctness and effectiveness of our approach.","Sensors,
Mobile communication,
Schedules,
Approximation algorithms,
Algorithm design and analysis,
Approximation methods,
Mobile handsets"
Coarse-to-Fine Description for Fine-Grained Visual Categorization,"Recent years have witnessed the significant advance in fine-grained visual categorization, which targets to classify the objects belonging to the same species. To capture enough subtle visual differences and build discriminative visual description, most of the existing methods heavily rely on the artificial part annotations, which are expensive to collect in real applications. Motivated to conquer this issue, this paper proposes a multi-level coarse-to-fine object description. This novel description only requires the original image as input, but could automatically generate visual descriptions discriminative enough for fine-grained visual categorization. This description is extracted from five sources representing coarse-to-fine visual clues: 1) original image is used as the source of global visual clue; 2) object bounding boxes are generated using convolutional neural network (CNN); 3) with the generated bounding box, foreground is segmented using the proposed k nearest neighbour-based co-segmentation algorithm; and 4) two types of part segmentations are generated by dividing the foreground with an unsupervised part learning strategy. The final description is generated by feeding these sources into CNN models and concatenating their outputs. Experiments on two public benchmark data sets show the impressive performance of this coarse-to-fine description, i.e., classification accuracy achieves 82.5% on CUB-200-2011, and 86.9% on fine-grained visual categorization-Aircraft, respectively, which outperform many recent works.","Visualization,
Image segmentation,
Testing,
Object detection,
Electronic mail,
Training,
Neural networks"
Real-Time Indoor Carbon Dioxide Monitoring Through Cognitive Wireless Sensor Networks,"In recent years, indoor air quality has become an important health and safety concern, as more energy efficient and air tight buildings are built and the existing buildings age. Clean air is essential for good health, and this is especially true when it comes to indoor air. However, many work environments lack proper detection mechanisms to identify health risks for occupants. Wireless ad hoc sensor networks have the potential to alleviate this problem. This paper presents a real-time cognitive wireless sensor network system for carbon dioxide monitoring at a complex indoor environment. The system aims to monitor and detect the concentration of carbon dioxide in a real-time basis and provide overall air quality alerts in a timely manner. Moreover, the system coexists with minimum interference with other systems in the monitoring area. A prototype is designed to show the enhanced real-time data transmission. Experiments are conducted to validate and support the development of the system for real-time monitoring and alerting.",
"Characteristic Mode Analysis of a Class of Empirical Design Techniques for Probe-Fed, U-Slot Microstrip Patch Antennas","In this paper, characteristic mode analysis (CMA) of three empirical design techniques for the probe-fed, symmetrically located, U-slot microstrip patch antenna, on a single-layer grounded substrate, is presented with supporting experimental data. The first method, resonant frequency (ResF), utilizes the existence of the four distinct ResFs, while the second one, dimensional invariance (DI), relies on the property of DI, for the design of the U-slot microstrip patch. In both these methods, the optimization of the probe location is necessary for further enhancement of the 10-dB return loss bandwidth. The third method, dimensionally invariant ResF, that optimally combines the features of the previous two is developed here and shown to yield better bandwidth performance with minimal or no probe location optimization, and hence is superior to the other two for rapid prototyping. CMA is carried out for critical parameters, such as substrate electrical thickness, slot width, probe radius, and feed location variations, to assess their dominant influence on the characteristics of the U-slot microstrip patch antenna.","Substrates,
Bandwidth,
Resonant frequency,
Patch antennas,
Microstrip,
Design methodology"
Semantic-Security Capacity for Wiretap Channels of Type II,"The secrecy capacity of the type II wiretap channel (WTC II) with a noisy main channel is currently an open problem. Herein its secrecy-capacity is derived and shown to be equal to its semantic-security (SS) capacity. In this setting, the legitimate users communicate via a discrete-memoryless (DM) channel in the presence of an eavesdropper that has perfect access to a subset of its choosing of the transmitted symbols, constrained to a fixed fraction of the blocklength. The secrecy criterion is achieved simultaneously for all possible eavesdropper subset choices. The SS criterion demands negligible mutual information between the message and the eavesdropper's observations even when maximized over all message distributions. A key tool for the achievability proof is a novel and stronger version of Wyner's soft covering lemma. Specifically, a random codebook is shown to achieve the soft-covering phenomenon with high probability. The probability of failure is doubly exponentially small in the blocklength. Since the combined number of messages and subsets grows only exponentially with the blocklength, SS for the WTC II is established by using the union bound and invoking the stronger soft-covering lemma. The direct proof shows that rates up to the weak-secrecy capacity of the classic WTC with a DM erasure channel (EC) to the eavesdropper are achievable. The converse follows by establishing the capacity of this DM wiretap EC as an upper bound for the WTC II. From a broader perspective, the stronger soft-covering lemma constitutes a tool for showing the existence of codebooks that satisfy exponentially many constraints, a beneficial ability for many other applications in information theoretic security.","Security,
Random variables,
Error probability,
Noise measurement,
Mutual information,
Encoding"
"Design and Implementation of a GaN-Based, 100-kHz, 102-W/in3 Single-Phase Inverter","High power density is a desirable feature of power electronics design, which prompts economic incentives for industrial applications. In this paper, a gallium nitride (GaN)-based 2-kVA single-phase inverter design was developed for the Google Little Box Challenge, which achieves a 102-W/in3 power density. First, the static and dynamic temperature-dependent characteristics of multiple SiC and enhancement-mode GaN FETs are investigated and compared. Based on the device testing results, several topologies of the inverter stage and different power decoupling solutions are compared with respect to the device volume, efficiency, and thermal requirements. Moreover, some design approaches for magnetic devices and the implementation of gate drives for GaN devices are discussed in this paper, which enable a compact and robust system. Finally, a dc notch filter and a hard switching full-bridge converter are combined as the proposed design for the prototype. A 2-kVA prototype is demonstrated, which meets the volume, efficiency, and thermal requirements. The performance of the prototype is verified by the experimental results.","Inverters,
Density measurement,
Power system measurements,
Gallium nitride,
Prototypes,
Switches,
Switching frequency"
Energy Efficiency and Contact Opportunities Tradeoff in Opportunistic Mobile Networks,"To discover neighbor nodes, nodes in opportunistic mobile networks (OppNets) have to probe their environment continuously. This can be an extremely energy-consuming process. If nodes probe very frequently, a lot of energy will be consumed in the contact probing process and might be inefficient. On the other hand, infrequent contact probing might cause nodes to miss many of their contacts. Therefore, there exists a tradeoff between energy efficiency and contact opportunities in OppNets. To investigate this tradeoff, we first propose a model to investigate the contact probing process based on the random-waypoint model and obtain the expressions of the single detecting probability and the double detecting probability. Moreover, we also demonstrate that among all contact probing strategies with the same average probing interval, which do not have preknowledge of the contact process, the strategy that probes at a constant interval performs better than any arbitrary probing strategy in expectation in the single contact probing process. Then, extensive simulations are conducted to validate the correctness of our proposed model. Finally, based on the proposed model, we analyze the tradeoff between energy efficiency and the total number of effective contacts in the single and double contact probing processes. Our results show that the total number of effective contacts in the single and double contact probing processes has a lower bound and an upper bound, and the good tradeoff points are obviously different when the speed of nodes is different.","Probes,
Analytical models,
Mobile communication,
Mobile computing,
Peer-to-peer computing,
Energy consumption,
Stochastic processes"
LTE-V: A TD-LTE-Based V2X Solution for Future Vehicular Network,"Diverse applications in vehicular network present specific requirements and challenges on wireless access technology. Although considered as the first standard, IEEE 802.11p shows the obvious drawbacks and is still in the field-trial stage. In this paper, we propose long-term evolution (LTE)-V as a systematic and integrated V2X solution based on time-division LTE (TD-LTE) 4G. LTE-V includes two modes: 1) LTE-V-direct and 2) LTE-V-cell. Comparing to IEEE 802.11p, LTE-V-direct is a new decentralized architecture which modifies TD-LTE physical layer and try to keep commonality as possible to provide short range direct communication, low latency, and high reliability improvements. By leveraging the centralized architecture with native features of TD-LTE, LTE-V-cell optimizes radio resource management for better supporting V2I. LTE-V-direct and LTE-V-cell coordinate with each other to provide an integrated V2X solution. Performance simulations based on sufficient scenarios and the prototype system with typical cases are presented. Finally, future works of LTE-V are envisioned.","Vehicular ad hoc networks,
Wireless communication,
Internet of things,
Long Term Evolution,
Road safety,
Delays,
Ad hoc networks"
Chip to Facility Ramifications of Containment Solution on IT Airflow and Uptime,"We developed a generalized testing methodology in which IT fans' internal and external impedance effects are collapsed into a single curve (i.e., flow curve). Such curves can give accurate flow rate predictions of the IT equipment based on RPM logging. Flow curves cover the three possible airflow regions for IT in a contained environment. The experimental procedure is introduced to rank IT equipment based on its air systems, and the flow regions are correlated with the CPU performance. The strength of the IT air system is characterized by the free delivery and the critical pressure points. In addition, the experimentally obtained active flow curves can be used as a numerical boundary condition in various containment designs. Accordingly, for the first time in the literature, the aerodynamic interaction of IT with different air systems in the containment (i.e., BladeCenters, servers, and switches) can numerically be investigated. It is found that stacking IT in a contained environment with no physical consideration can lead to radical reliability problems. The region of reverse flow is discovered to be very possible upon events in the data center. In such a case, the weak IT (e.g., 1U switch) behaves as an open leakage into the sealed containment. On the other hand, at the critical pressure point, minimum forced convection occurs in the weak IT, leading to CPU overheating.","Servers,
Atmospheric modeling,
Cooling,
Computational modeling,
Numerical models,
Impedance,
Temperature measurement"
CMOS Vertical Hall Magnetic Sensors on Flexible Substrate,This paper presents the realization of different vertical Hall sensors (VHSs) implemented using a 0.18-μm CMOS technology and mounted on flexible substrates. Various geometries of VHS have been studied to obtain the optimum sensor device dimension and shape. COMSOL multiphysics simulation results are validated with respect to the electrical behaviour of an eight-resistor Verilog-A model implemented in Cadence environment. Simulation and measurement results are in good agreement. The use of polymeric foils and current spinning technique compensate for the effects caused by mechanical stress and possible fabrication imperfections. Measurement results for a low-offset basic VHS in planar state show a sensitivity of 59 ± 1 V(AT)-1 in voltage mode and of 8 ± 0.1 %T-1 in current mode.,
THz Backward-Wave Oscillators for Plasma Diagnostic in Nuclear Fusion,"Understanding of the anomalous transport attributed to short-scale length microturbulence through collective scattering diagnostics is key to the development of nuclear fusion energy. Signals in the subterahertz (THz) range (0.1-0.8 THz) with adequate power are required to map wider wavenumber regions. The progress of a joint international effort devoted to the design and realization of novel backward-wave oscillators at 0.346 THz and above with output power in the 1 W range is reported herein. The novel sources possess desirable characteristics to replace the bulky, high maintenance, optically pumped far-infrared lasers so far utilized in this plasma collective scattering diagnostic. The formidable fabrication challenges are described. The future availability of the THz source here reported will have a significant impact in the field of THz applications both for scientific and industrial applications, to provide the output power at THz so far not available.",
Greener and Smarter Phones for Future Cities: Characterizing the Impact of GPS Signal Strength on Power Consumption,"Smart cities appear as the next stage of urbanization aiming to not only exploit physical and digital infrastructure for urban development but also the intellectual and social capital as its core ingredient for urbanization. Smart cities harness the power of data from sensors in order to understand and manage city systems. The most important of these sensing devices are smartphones as they provide the most important means to connect the smart city systems with its citizens, allowing personalization n and cocreation. The battery lifetime of smartphones is one of the most important parameters in achieving good user experience for the device. Therefore, the management and the optimization of handheld device applications in relation to their power consumption are an important area of research. This paper investigates the relationship between the energy consumption of a localization application and the strength of the global positioning system (GPS) signal. This is an important focus, because location-based applications are among the top power-hungry applications. We conduct experiments on two android location-based applications, one developed by us, and the other one, off the shelf. We use the results from the measurements of the two applications to derive a mathematical model that describes the power consumption in smartphones in terms of SNR and the time to first fix. The results from this study show that higher SNR values of GPS signals do consume less energy, while low GPS signals causing faster battery drain (38% as compared with 13%). To the best of our knowledge, this is the first study that provides a quantitative understanding of how the poor strength (SNR) of satellite signals will cause relatively higher power drain from a smartphone's battery.","Green design,
Mobile communication,
Energy efficiency,
Smart cities,
Smart phones,
Signal to noise ratio,
Digital systems,
Urban area,
Batteries,
Power demand,
Global Positioning System"
ChaLearn Joint Contest on Multimedia Challenges Beyond Visual Analysis: An overview,"This paper provides an overview of the Joint Contest on Multimedia Challenges Beyond Visual Analysis. We organized an academic competition that focused on four problems that require effective processing of multimodal information in order to be solved. Two tracks were devoted to gesture spotting and recognition from RGB-D video, two fundamental problems for human computer interaction. Another track was devoted to a second round of the first impressions challenge of which the goal was to develop methods to recognize personality traits from short video clips. For this second round we adopted a novel collaborative-competitive (i.e., coopetition) setting. The fourth track was dedicated to the problem of video recommendation for improving user experience. The challenge was open for about 45 days, and received outstanding participation: almost 200 participants registered to the contest, and 20 teams sent predictions in the final stage. The main goals of the challenge were fulfilled: the state of the art was advanced considerably in the four tracks, with novel solutions to the proposed problems (mostly relying on deep learning). However, further research is still required. The data of the four tracks will be available to allow researchers to keep making progress in the four tracks.",
Virtualization of 5G Cellular Networks as a Hierarchical Combinatorial Auction,"Virtualization has been seen as one of the main evolution trends in the forthcoming fifth generation (5G) cellular networks which enables the decoupling of infrastructure from the services it provides. In this case, the roles of infrastructure providers (InPs) and mobile virtual network operators (MVNOs) can be logically separated and the resources (e.g., subchannels, power, and antennas) of a base station owned by an InP can be transparently shared by multiple MVNOs, while each MVNO virtually owns the entire BS. Naturally, the issue of resource allocation arises. In particular, the InP is required to abstract the physical resources into isolated slices for each MVNO who then allocates the resources within the slice to its subscribed users. In this paper, we aim to address this two-level hierarchical resource allocation problem while satisfying the requirements of efficient resource allocation, strict inter-slice isolation, and the ability of intra-slice customization. To this end, we design a hierarchical combinatorial auction mechanism, based on which a truthful and sub-efficient resource allocation framework is provided. Specifically, winner determination problems (WDPs) are formulated for the InP and MVNOs, and computationally tractable algorithms are proposed to solve these WDPs. Also, pricing schemes are designed to ensure incentive compatibility. The designed mechanism can achieve social efficiency in each level even if each party involved acts selfishly. Numerical results show the effectiveness of the proposed scheme.","Resource management,
Indium phosphide,
III-V semiconductor materials,
Virtualization,
Wireless communication,
MIMO,
Mobile computing"
A Quality-Based Nonlinear Fault Diagnosis Framework Focusing on Industrial Multimode Batch Processes,"This paper proposes a framework for quality-based fault detection and diagnosis for nonlinear batch processes with multimode operating environment. The framework seeks to address 1) the mode partition problem using a kernel fuzzy C-clustering method, and the optimal cluster number will be guaranteed by a between-within proportion index; 2) the diagnosis problem using a contribution rate method based on an improved kernel partial least squares (PLS) model, by which better detection and diagnosis performances are provided; and 3) the classification of online measurements using a hybrid kernel PLS regression and the Bayes inference theory, where the new coming measurement can be correctly assigned to its constituent mode. The whole framework is developed for batch processes, and applied to the hot strip mill rolling process. It is shown using the real industrial data that for faults affecting the thickness and flatness of the strip steel in this process, the detection and diagnosis abilities of the present methods are better compared with the existing methods.",
Optimized Graph Learning Using Partial Tags and Multiple Features for Image and Video Annotation,"In multimedia annotation, due to the time constraints and the tediousness of manual tagging, it is quite common to utilize both tagged and untagged data to improve the performance of supervised learning when only limited tagged training data are available. This is often done by adding a geometry-based regularization term in the objective function of a supervised learning model. In this case, a similarity graph is indispensable to exploit the geometrical relationships among the training data points, and the graph construction scheme essentially determines the performance of these graph-based learning algorithms. However, most of the existing works construct the graph empirically and are usually based on a single feature without using the label information. In this paper, we propose a semi-supervised annotation approach by learning an optimized graph (OGL) from multi-cues (i.e., partial tags and multiple features), which can more accurately embed the relationships among the data points. Since OGL is a transductive method and cannot deal with novel data points, we further extend our model to address the out-of-sample issue. Extensive experiments on image and video annotation show the consistent superiority of OGL over the state-of-the-art methods.",
Big Data for Remote Sensing: Challenges and Opportunities,"Every day a large number of Earth observation (EO) spaceborne and airborne sensors from many different countries provide a massive amount of remotely sensed data. Those data are used for different applications, such as natural hazard monitoring, global climate change, urban planning, etc. The applications are data driven and mostly interdisciplinary. Based on this it can truly be stated that we are now living in the age of big remote sensing data. Furthermore, these data are becoming an economic asset and a new important resource in many applications. In this paper, we specifically analyze the challenges and opportunities that big data bring in the context of remote sensing applications. Our focus is to analyze what exactly does big data mean in remote sensing applications and how can big data provide added value in this context. Furthermore, this paper describes the most challenging issues in managing, processing, and efficient exploitation of big data for remote sensing problems. In order to illustrate the aforementioned aspects, two case studies discussing the use of big data in remote sensing are demonstrated. In the first test case, big data are used to automatically detect marine oil spills using a large archive of remote sensing data. In the second test case, content-based information retrieval is performed using high-performance computing (HPC) to extract information from a large database of remote sensing images, collected after the terrorist attack to the World Trade Center in New York City. Both cases are used to illustrate the significant challenges and opportunities brought by the use of big data in remote sensing applications.","Big data,
Remote sensing,
Sensors,
Context modeling,
Information retrieval,
Computer applications,
Terrorism,
High performance computing"
A Game Theoretic Approach to Risk-Based Optimal Bidding Strategies for Electric Vehicle Aggregators in Electricity Markets With Variable Wind Energy Resources,"This paper proposes a stochastic optimization model for optimal bidding strategies of electric vehicle (EV) aggregators in day-ahead energy and ancillary services markets with variable wind energy. The forecast errors of EV fleet characteristics, hourly loads, and wind energy as well as random outages of generating units and transmission lines are considered as potential uncertainties, which are represented by scenarios in the Monte Carlo Simulation (MCS). The conditional value at risk (CVaR) index is utilized for measuring EV aggregators risks caused by the uncertainties. The EV aggregators optimal bidding strategy is formulated as a mathematical programming with equilibrium constraints (MPEC), in which the upper level problem is the aggregators CVaR maximization while the lower level problem corresponds to the system operation cost minimization. The bi-level problem is transformed into a single-level mixed integer linear programming (MILP) problem using the prime-dual formulation with linearized constraints. The progressive hedging algorithm (PHA) is utilized to solve the resulting single-level MILP problem. A game theoretic approach is developed for analyzing the competition among the EV aggregators. Numerical cases are studied for a modified 6-bus system and the IEEE 118-bus system. The results show the validity of the proposed approach and the impact of the aggregators bidding strategies on the stochastic electricity market operation.","Indexes,
Uncertainty,
Wind energy,
Stochastic processes,
Generators,
Electricity supply industry,
Renewable energy sources"
Secure Multiplex Coding With Dependent and Non-Uniform Multiple Messages,"The secure multiplex coding (SMC) is a technique to remove rate loss in the coding for wire-tap channels and broadcast channels with confidential messages caused by the inclusion of random bits into transmitted signals. SMC replaces the random bits by other meaningful secret messages, and a collection of secret messages serves as the random bits to hide the rest of messages. In the previous studies, multiple secret messages were assumed to have independent and uniform distributions, which is difficult to be ensured in practice. We remove this restrictive assumption by a generalization of the channel resolvability technique. We also give practical construction techniques for SMC by using an arbitrary given error-correcting code as an ingredient, and channel-universal coding of SMC. By using the same principle as the channel-universal SMC, we give coding for the broadcast channel with confidential messages universal to both channel and source distributions.",
Wireless NoC for VFI-Enabled Multicore Chip Design: Performance Evaluation and Design Trade-Offs,"Multiple Voltage Frequency Island (VFI)-based designs can reduce the energy dissipation in multicore chips. Indeed, by tailoring the voltages and frequencies of each VFI domain, we can achieve significant energy savings subject to specific performance constraints. The achievable performance of VFI-based multicore platforms depends on the overall communication backbone, which relies predominantly on Networks-on-Chip (NoCs). Traditionally mesh-based NoCs have been used in VFI-based systems. However, the mesh-based NoCs have large latency and energy overheads due to their inherently long multihop paths. Emerging paradigms such as the millimeter (mm)-wave small-world wireless Networks-on-Chip (mSWNoCs) have lately been observed to help reduce the impact of the communication backbone on the performance of the multicore chips. In this work, we demonstrate that not only do mSWNoC-enabled VFI designs mitigate some of the full-system performance degradation inherent in VFI-partitioned multicore designs, but they also help in eliminating it entirely for certain applications. We also demonstrate that the VFI-partitioned designs used in conjunction with a novel NoC architecture like mSWNoC can achieve significant energy savings while minimizing the impact on the performance for each application under consideration.","Wireless communication,
Multicore processing,
Benchmark testing,
Ports (Computers),
Energy efficiency,
Optimization"
Control of Single-Phase Grid-Connected Converters With LCL Filters Using Recurrent Neural Network and Conventional Control Methods,"Single-phase grid-connected inverters are widely used to connect small-scale distributed renewable resources to the grid. However, unlike a three-phase system, control for a single-phase inverter is more challenging, especially when the inverter is used with an LCL filter. This paper proposes a novel recurrent neural network-based vector control method for a single-phase inverter with an LCL filter. The neural network is trained based on adaptive dynamic programming principle, and the objective of the training is to approximate optimal control. The Levenberg-Marquardt plus forward accumulation through time algorithm is developed for training the proposed recurrent neural network controller. The neural network vector control approach is compared with the conventional control methods, including the conventional PI-based vector control method and the PR-based control technique for single-phase inverters. Both the simulations and hardware experiments demonstrate the great advantages of the proposed neural network vector control over the conventional control methods. Compared with conventional control methods, the neural network control allows for low sampling rate and low switching frequency, while maintaining high performance in controlling a single-phase inverter. In addition, no specific damping policy is required to implement the proposed neural network vector control for an LCL-filter based single-phase inverter. The study shows that the neural network vector control is a robust control method, and can provide better control performance even when facing system parameter changes, while under this case, both the conventional PI-based vector control and the PR-based control failed to yield the acceptable results.","Inverters,
Artificial neural networks,
Control systems,
Training,
Recurrent neural networks,
Voltage control"
Nonconvex Nonsmooth Low Rank Minimization via Iteratively Reweighted Nuclear Norm,"The nuclear norm is widely used as a convex surrogate of the rank function in compressive sensing for low rank matrix recovery with its applications in image recovery and signal processing. However, solving the nuclear norm-based relaxed convex problem usually leads to a suboptimal solution of the original rank minimization problem. In this paper, we propose to use a family of nonconvex surrogates of L0-norm on the singular values of a matrix to approximate the rank function. This leads to a nonconvex nonsmooth minimization problem. Then, we propose to solve the problem by an iteratively re-weighted nuclear norm (IRNN) algorithm. IRNN iteratively solves a weighted singular value thresholding problem, which has a closed form solution due to the special properties of the nonconvex surrogate functions. We also extend IRNN to solve the nonconvex problem with two or more blocks of variables. In theory, we prove that the IRNN decreases the objective function value monotonically, and any limit point is a stationary point. Extensive experiments on both synthesized data and real images demonstrate that IRNN enhances the low rank matrix recovery compared with the state-of-the-art convex algorithms.","Minimization,
Sparse matrices,
Radio frequency,
Approximation methods,
Signal processing algorithms,
Electronic mail,
Compressed sensing"
Denoising of Hyperspectral Images Using Group Low-Rank Representation,"Hyperspectral images (HSIs) have been used in a wide range of fields, such as agriculture, food safety, mineralogy, and environment monitoring, but being corrupted by various kinds of noise limits its efficacy. Low-rank representation (LRR) has proved its effectiveness in the denoising of HSIs. However, it just employs local information for denoising, which results in ineffectiveness when local noise is heavy. In this paper, we propose an approach of group low-rank representation (GLRR) for the HSI denoising. In our GLRR, a corrupted HSI is divided into overlapping patches, the similar patches are combined into a group, and the group is reconstructed as a whole using LRR. The proposed method enables the exploitation of both the local similarity within a patch and the nonlocal similarity across the patches in a group simultaneously. The additional nonlocally similar patches can bring in extra structural information to the corrupted patches, facilitating the detection of noise as outliers. LRR is applied to the group of patches, as the uncorrupted patches enjoy intrinsic low-rank structure. The effectiveness of the proposed GLRR method is demonstrated qualitatively and quantitatively by using both simulated and real-world data in experiments.","Noise reduction,
Image reconstruction,
Hyperspectral imaging,
Correlation,
Matrix decomposition,
Earth"
High-Performance InAlN/GaN MOSHEMTs Enabled by Atomic Layer Epitaxy MgCaO as Gate Dielectric,"We have demonstrated high-performance InAlN/ GaN MOS high-electron-mobility-transistors (MOSHEMTs) with various channel lengths (Lch) of 85-250 nm using atomic-layer-epitaxy (ALE) crystalline Mg0.25Ca0.75O as gate dielectric. With a nearly lattice matched epitaxial oxide, the interface between oxide and barrier is improved. The gate leakage current of MOSHEMT is reduced by six orders of magnitude compared with HEMT. An OFF-state leakage current of 3 × 10-13 A/mm, ON/OFF ratio of 4 × 1012, almost ideal subthreshold swing of 62 mV/decade, low drain current noise with Hooge parameter of 10-4, and negligible current collapse and hysteresis are realized. The 85-nm Lch MOSHEMT also exhibits good ON-state performance with Idmax = 2.25 A/mm, RON = 1.3 Ω · mm, and gmax = 475 mS/mm, showing that ALE MgCaO is a promising gate dielectric for GaN device applications.","Logic gates,
HEMTs,
Epitaxial growth,
Gallium nitride,
MODFETs,
Aluminum oxide,
Capacitance-voltage characteristics"
A Stochastic Geometry Approach to the Modeling of DSRC for Vehicular Safety Communication,"Vehicle-to-vehicle safety communications based on the dedicated short-range communication technology have the potential to enable a set of applications that help avoid traffic accidents. The performance of these applications, largely affected by the reliability of communication links, stringently ties back to the MAC and PHY layer design, which has been standardized as IEEE 802.11p. The link reliabilities depend on the signal-to-interference-plus-noise ratio (SINR), which, in turn, depends on the locations and transmit power values of the transmitting nodes. Hence, an accurate network model needs to take into account the network geometry. For such geometric models, however, there is a lack of mathematical understanding of the characteristics and performance of IEEE 802.11p. Important questions such as the scalability performance of IEEE 802.11p have to be answered by simulations, which can be very time consuming and provide limited insights to future protocol design. In this paper, we investigate the performance of IEEE 802.11p by proposing a novel mathematical model based on queuing theory and stochastic geometry. In particular, we extend the Matérn hard-core type-II process with a discrete and nonuniform distribution, which is used to derive the temporal states of backoff counters. By doing so, concurrent transmissions from nodes within the carrier sensing ranges of each other are taken into account, leading to a more accurate approximation to real network dynamics. A comparison with Network Simulator 2 (ns2) simulations shows that our model achieves a good approximation in networks with different densities.","Radiation detectors,
Geometry,
Mathematical model,
Stochastic processes,
Safety,
Queueing analysis,
Interference"
Binocular Responses for No-Reference 3D Image Quality Assessment,"Perceptual quality assessment of distorted three-dimensional (3D) images has become a fundamental yet challenging issue in the field of 3D imaging. In this paper, we propose a general-purpose blind/no-reference (NR) 3D image quality assessment (IQA) metric that utilizes the complementary local patterns (the local magnitude pattern and the proposed generalized local directional pattern) of binocular energy response (BER) and binocular rivalry response (BRR). The main technical contribution of this research is that binocular visual perception and local structural distribution are considered for NR 3D-IQA. More specifically, the metric simulates the binocular visual perception using BER and BRR. Subsequently, the local patterns of the binocular responses' encoding maps are used to form various binocular quality-predictive features, which will change in the presence of distortions. After feature extraction, we use k-nearest neighbors-based machine learning to drive the overall quality score. We tested our proposed metric against two publicly available 3D databases; these tests confirm that the proposed metric's results consistently align with human subjective judgments.","Three-dimensional displays,
Measurement,
Bit error rate,
Image quality,
Visual perception,
Feature extraction,
Quality assessment"
Sensor Selection for Estimation with Correlated Measurement Noise,"In this paper, we consider the problem of sensor selection for parameter estimation with correlated measurement noise. We seek optimal sensor activations by formulating an optimization problem, in which the estimation error, given by the trace of the inverse of the Bayesian Fisher information matrix, is minimized subject to energy constraints. Fisher information has been widely used as an effective sensor selection criterion. However, existing information-based sensor selection methods are limited to the case of uncorrelated noise or weakly correlated noise due to the use of approximate metrics. By contrast, here we derive the closed form of the Fisher information matrix with respect to sensor selection variables that is valid for any arbitrary noise correlation regime and develop both a convex relaxation approach and a greedy algorithm to find near-optimal solutions. We further extend our framework of sensor selection to solve the problem of sensor scheduling, where a greedy algorithm is proposed to determine non-myopic (multi-time step ahead) sensor schedules. Lastly, numerical results are provided to illustrate the effectiveness of our approach, and to reveal the effect of noise correlation on estimation performance.","Noise measurement,
Covariance matrices,
Estimation error,
Correlation,
Greedy algorithms,
Parameter estimation"
"Bulk Data Dissemination in Wireless Sensor Networks: Analysis, Implications and Improvement","To guarantee reliability, bulk data dissemination relies on the negotiation scheme in which senders and receivers negotiate transmission schedule through a three-way handshake procedure. However, we find negotiation incurs a long dissemination time and seriously defers the network-wide convergence. On the other hand, the flooding approach, which is conventionally considered inefficient and energy-consuming, can facilitate bulk data dissemination if appropriately incorporated. This motivates us to pursue a delicate tradeoff between negotiation and flooding in the bulk data dissemination. We propose SurF (Survival of the Fittest), a bulk data dissemination protocol which adaptively adopts negotiation and leverages flooding opportunistically. SurF incorporates a time-reliability model to estimate the time efficiencies (flooding versus negotiation) and dynamically selects the fittest one to facilitate the dissemination process. We implement SurF in TinyOS 2.1.1 and evaluate its performance with 40 TelosB nodes. The results show that SurF, while retaining the dissemination reliability, reduces the dissemination time by 40 percent in average, compared with the state-of-the-art protocols.",
Secret Key Agreement: General Capacity and Second-Order Asymptotics,"We revisit the problem of secret key agreement using interactive public communication for two parties and propose a new secret key agreement protocol. The protocol attains the secret key capacity for general observations and attains the second-order asymptotic term in the maximum length of a secret key for independent and identically distributed observations. In contrast to the previously suggested secret key agreement protocols, the proposed protocol uses interactive communication. In fact, the standard one-way communication protocol used prior to this paper fails to attain the asymptotic results above. Our converse proofs rely on a recently established upper bound for secret key lengths. Both our lower and upper bounds are derived in a single-shot setup and the asymptotic results are obtained as corollaries.","Protocols,
Zinc,
Reliability,
Standards,
Upper bound,
Markov processes,
Couplings"
A New Approach for Segmentation and Quantification of Cells or Nanoparticles,"With the rapid development of microscopy imaging technology, the requirement for robust segmentation and quantification of cells or nanoparticles increases greatly. It remains challenging due to the diversity of the cell or nanoparticle types, the arbitrary shapes, and the large numbers of cells or nanoparticles. The most existing methods are only capable of segmenting some specific types of cells or nanoparticles. In this paper, we propose a more versatile approach that is capable of segmenting a variety of cells or nanoparticles. It consists of five parts: 1) automatic gradient image formation; 2) automatic threshold selection; 3) manual calibration of the threshold selection method for each specific type of cell or nanoparticle images; 4) manual determination of the segmentation cases for each specific type of cell or nanoparticle images; and 5) automatic quantification by iterative morphological erosion. After the parameter, N is calibrated and the segmentation case is determined manually for each specific type of cell or nanoparticle images with one or several typical images; only parts 1), 2), and 5) are needed for the rest of processing and they are automatic. The proposed approach is tested with different types of cell and nanoparticle images. Experimental results verified its effectiveness.","Nanoparticles,
Image segmentation,
Histograms,
Informatics,
Robustness,
Microscopy,
Shape"
Direct visual-inertial odometry with stereo cameras,"We propose a novel direct visual-inertial odometry method for stereo cameras. Camera pose, velocity and IMU biases are simultaneously estimated by minimizing a combined photometric and inertial energy functional. This allows us to exploit the complementary nature of vision and inertial data. At the same time, and in contrast to all existing visual-inertial methods, our approach is fully direct: geometry is estimated in the form of semi-dense depth maps instead of manually designed sparse keypoints. Depth information is obtained both from static stereo - relating the fixed-baseline images of the stereo camera - and temporal stereo - relating images from the same camera, taken at different points in time. We show that our method outperforms not only vision-only or loosely coupled approaches, but also can achieve more accurate results than state-of-the-art keypoint-based methods on different datasets, including rapid motion and significant illumination changes. In addition, our method provides high-fidelity semi-dense, metric reconstructions of the environment, and runs in real-time on a CPU.","Cameras,
Three-dimensional displays,
Tracking,
Optimization,
Robot vision systems,
Visualization,
Lighting"
Depth Image Based View Synthesis: New Insights and Perspectives on Hole Generation and Filling,"View synthesis with depth-image-based rendering (DIBR) has attracted great interest in that it can provide a virtual image at any arbitrary viewpoint in 3-D video and free-viewpoint TV. An inherent problem in the DIBR view synthesis is occurrence of holes in a synthesized image, which is also known as disocclusion problem. The disoccluded regions need to be handled properly in order to generate a synthesized view of good quality. This paper provides a fundamental examination of hole generation mechanism in the DIBR oriented view synthesis process. A necessary and sufficient condition of hole generation is first shown, and the corresponding hole location and length is obtained analytically. Furthermore, in view that the conventional hole filling algorithms may fail to fill up a hole correctly when lacking (adequate) visible background information, we propose utilizing the occluded (invisible) information to identify and locate the relevant background pixels around a hole. We then make use of the visible and invisible background information together to perform hole filling. Experimental results validate our hole generation model demonstrating agreement to our analytical results, while our proposed hole filling approach shows superior performance in terms of visual quality of synthesized views.","Cameras,
Three-dimensional displays,
Interpolation,
Rendering (computer graphics),
Merging,
Filling,
Joints"
Low Cost Disaggregation of Smart Meter Sensor Data,"This paper proposes a novel load disaggregation algorithm, based on non-intrusive appliance monitoring that provides accurate results without the need of the reactive power component. The proposed technique requires the minimum possible number of sensor meters within the smart meter hardware and reduces the data traffic of the advanced metering infrastructure network, since it processes the only low-frequency smart meter data of the active power component of a residential unit. We propose a three-stage process for energy usage analysis, based on pulse extraction, pulse clustering and classification, and pulse to appliance association. The smart meter data are decomposed into a discrete set of pulses, and each pulse is associated with the operation of the appliances. The outcome of the algorithm is a pulse to appliance association that creates a daily load disaggregation map for the residential unit. In addition, this paper presents an overview and comparison of existing solutions that will help the reader obtain a good overview of the landscape of load disaggregation from smart meter sensor readings.","Home appliances,
Smart meters,
Reactive power,
Power demand,
Hardware,
Intelligent sensors"
Power Line Interference Removal for High-Quality Continuous Biosignal Monitoring With Low-Power Wearable Devices,"Mobile and long-term recording of biomedical signals, such as electrocardiogram (ECG), electromyogram (EMG), and EEG, can improve diagnosis and monitor the evolution of several widespread diseases. However, it requires specific solutions, such as wearable devices, that should be particularly comfortable for patients, while at the same time ensuring medical-grade signal acquisition quality, including power line interference (PLI) removal. This paper focuses on the on-board real-time PLI filtering on a low-power biopotential acquisition wearable system. This paper analyzes in depth basic and advanced PLI filtering techniques and evaluates them in a wearable real-time processing scenario, assessing performance on EMG and ECG signals. Our experiments prove that most PLI removal algorithms are not usable in this challenging context, because they lack robustness or they require offline processing and large amounts of available data. On the other hand, adaptive filtering techniques are robust and well suited for lightweight online processing. We substantiate this finding with offline analysis and comparison, as well as with a complete embedded implementation on our low-power low-cost wearable device.","Biomedical monitoring,
Interference,
Electrocardiography,
Electromyography,
Real-time systems,
Sensors,
Monitoring"
Data and Energy Integrated Communication Networks for Wireless Big Data,"This paper describes a new type of communication network called data and energy integrated communication networks (DEINs), which integrates the traditionally separate two processes, i.e., wireless information transfer (WIT) and wireless energy transfer (WET), fulfilling co-transmission of data and energy. In particular, the energy transmission using radio frequency is for the purpose of energy harvesting (EH) rather than information decoding. One driving force of the advent of DEINs is wireless big data, which comes from wireless sensors that produce a large amount of small piece of data. These sensors are typically powered by battery that drains sooner or later and will have to be taken out and then replaced or recharged. EH has emerged as a technology to wirelessly charge batteries in a contactless way. Recent research work has attempted to combine WET with WIT, typically under the label of simultaneous wireless information and power transfer. Such work in the literature largely focuses on the communication side of the whole wireless networks with particular emphasis on power allocation. The DEIN communication network proposed in this paper regards the convergence of WIT and WET as a full system that considers not only the physical layer but also the higher layers, such as media access control and information routing. After describing the DEIN concept and its high-level architecture/protocol stack, this paper presents two use cases focusing on the lower layer and the higher layer of a DEIN network, respectively. The lower layer use case is about a fair resource allocation algorithm, whereas the high-layer section introduces an efficient data forwarding scheme in combination with EH. The two case studies aim to give a better explanation of the DEIN concept. Some future research directions and challenges are also pointed out.","Wireless communication,
Wireless sensor networks,
Batteries,
Energy harvesting,
Resource management,
Communication networks,
MIMO,
Information analysis,
Communication networks"
Nash Equilibrium Computation in Subnetwork Zero-Sum Games With Switching Communications,"In this paper, we investigate a distributed Nash equilibrium computation problem for a time-varying multi-agent network consisting of two subnetworks, where the two subnetworks share the same objective function. We first propose a subgradient-based distributed algorithm with heterogeneous stepsizes to compute a Nash equilibrium of a zero-sum game. We then prove that the proposed algorithm can achieve a Nash equilibrium under uniformly jointly strongly connected (UJSC) weight-balanced digraphs with homogenous stepsizes. Moreover, we demonstrate that for weighted-unbalanced graphs a Nash equilibrium may not be achieved with homogenous stepsizes unless certain conditions on the objective function hold. We show that there always exist heterogeneous stepsizes for the proposed algorithm to guarantee that a Nash equilibrium can be achieved for UJSC digraphs. Finally, in two standard weight-unbalanced cases, we verify the convergence to a Nash equilibrium by adaptively updating the stepsizes along with the arc weights in the proposed algorithm.","Nash equilibrium,
Optimization,
Yttrium,
Games,
Linear programming,
Switches"
A Three Degree-of-Freedom Weakly Coupled Resonator Sensor With Enhanced Stiffness Sensitivity,"This paper reports a three degree-of-freedom (3DoF) microelectromechanical systems (MEMS) resonant sensing device consisting of three weakly coupled resonators with enhanced sensitivity to stiffness change. If one resonator of the system is perturbed by an external stimulus, mode localization occurs, which can be detected by a change of modal amplitude ratio. The perturbation can be, for example, a change in stiffness of one resonator. A detailed theoretical investigation revealed that a mode aliasing effect, along with the thermal noise floor of the sensor and the associated electrical system ultimately limit the dynamic range of the sensor. The nonlinearity of the 3DoF sensor was also analyzed theoretically. The 3DoF resonator device was fabricated using a silicon on insulator process. Measurement results from a prototype device agreed well with the predictions of the analytical model. A significant, namely 49 times, improvement in sensitivity to stiffness change was evident from the fabricated 3DoF resonator sensor compared with the existing state-of-the-art 2DoF resonator sensors, while the typical nonlinearity was smaller than ±2% for a wide span of stiffness change. In addition, measurements indicate that a dynamic range of at least 39.1 dB is achievable, which could be further extended by decreasing the noise of the device and the interface electronics.",
PIS: A Multi-Dimensional Routing Protocol for Socially-Aware Networking,"Socially-aware networking is an emerging paradigm for intermittently connected networks consisting of mobile users with social relationships and characteristics. In this setting, humans are the main carriers of mobile devices. Hence, their connections, social features, and behaviors can be exploited to improve the performance of data forwarding protocols. In this paper, we first explore the impact of three social features, namely physical proximity, user interests, and social relationship on users' daily routines. Then, we propose a multi-dimensional routing protocol called Proximity-Interest-Social (PIS) protocol in which the three different social dimensions are integrated into a unified distance function in order to select optimal intermediate data carriers. PIS protocol utilizes a time slot management mechanism to discover users' movement similarities in different time periods during a day. We compare the performance of PIS to Epidemic, PROPHET, and SimBet routing protocols using SIGCOMM09 and INFOCOM06 data sets. The experiment results show that PIS outperforms other benchmark routing protocols with the highest data delivery ratio with a low communication overhead.",
Maneuvering Control of Planar Snake Robots Using Virtual Holonomic Constraints,"This paper investigates the problem of maneuvering control for planar snake robots. The control objective is to make the center of mass of the snake robot converge to a desired path and traverse the path with a desired velocity. The proposed feedback control strategy enforces virtual constraints encoding a lateral undulatory gait, parametrized by the states of dynamic compensators used to regulate the orientation and forward speed of the snake robot.","Joints,
Friction,
Robot kinematics,
Mobile robots,
Kinematics,
Control design"
Coexistence of ZigBee-Based WBAN and WiFi for Health Telemonitoring Systems,"The development of telemonitoring via wireless body area networks (WBANs) is an evolving direction in personalized medicine and home-based mobile health. A WBAN consists of small, intelligent medical sensors which collect physiological parameters such as electrocardiogram, electroencephalography, and blood pressure. The recorded physiological signals are sent to a coordinator via wireless technologies, and are then transmitted to a healthcare monitoring center. One of the most widely used wireless technologies in WBANs is ZigBee because it is targeted at applications that require a low data rate and long battery life. However, ZigBee-based WBANs face severe interference problems in the presence of WiFi networks. This problem is caused by the fact that most ZigBee channels overlap with WiFi channels, severely affecting the ability of healthcare monitoring systems to guarantee reliable delivery of physiological signals. To solve this problem, we have developed an algorithm that controls the load in WiFi networks to guarantee the delay requirement for physiological signals, especially for emergency messages, in environments with coexistence of ZigBee-based WBAN and WiFi. Since WiFi applications generate traffic with different delay requirements, we focus only on WiFi traffic that does not have stringent timing requirements. In this paper, therefore, we propose an adaptive load control algorithm for ZigBee-based WBAN/WiFi coexistence environments, with the aim of guaranteeing that the delay experienced by ZigBee sensors does not exceed a maximally tolerable period of time. Simulation results show that our proposed algorithm guarantees the delay performance of ZigBee-based WBANs by mitigating the effects of WiFi interference in various scenarios.","IEEE 802.11 Standards,
Zigbee,
Interference,
Delays,
Sensors,
Biomedical monitoring,
Monitoring"
A Portable Micro Gas Chromatography System for Lung Cancer Associated Volatile Organic Compound Detection,"With the help of micro-electromechanical systems (MEMS) and complementary metal-oxide-semiconductor (CMOS) technology, a portable micro gas chromatography (μGC) system for lung cancer associated volatile organic compounds (VOCs) detection is realized for the first time. The system is composed of an MEMS preconcentrator, an MEMS separation column, and a CMOS system-on-chip (SoC). The preconcentrator provides a concentration ratio of 2170. The separation column can separate more than seven types of lung cancer associated VOCs. The SoC is fabricated by a TSMC 0.35 μm 2P4M process including the CMOS VOCs detector, sensor calibration circuit, low-noise chopper instrumentation amplifier (IA), 10 bit analog to digital converter, and the microcontrol unit (MCU). Experimental results show that the system is able to detect seven types of lung cancer associated VOCs (acetone, 2-butanone, benzene, heptane, toluene, m-xylene, 1,3,5-trimethylbenzene). The concentration linearity is R2 = 0.985 and the detection sensitivity is up to 15 ppb with 1,3,5-trimethylbenzene.","Micromechanical devices,
Calibration,
CMOS integrated circuits,
Cancer,
Detectors,
Heating,
Lungs"
Weakly Supervised Human Fixations Prediction,"Automatically predicting human eye fixations is a useful technique that can facilitate many multimedia applications, e.g., image retrieval, action recognition, and photo retargeting. Conventional approaches are frustrated by two drawbacks. First, psychophysical experiments show that an object-level interpretation of scenes influences eye movements significantly. Most of the existing saliency models rely on object detectors, and therefore, only a few prespecified categories can be discovered. Second, the relative displacement of objects influences their saliency remarkably, but current models cannot describe them explicitly. To solve these problems, this paper proposes weakly supervised fixations prediction, which leverages image labels to improve accuracy of human fixations prediction. The proposed model hierarchically discovers objects as well as their spatial configurations. Starting from the raw image pixels, we sample superpixels in an image, thereby seamless object descriptors termed object-level graphlets (oGLs) are generated by random walking on the superpixel mosaic. Then, a manifold embedding algorithm is proposed to encode image labels into oGLs, and the response map of each prespecified object is computed accordingly. On the basis of the object-level response map, we propose spatial-level graphlets (sGLs) to model the relative positions among objects. Afterward, eye tracking data is employed to integrate these sGLs for predicting human eye fixations. Thorough experiment results demonstrate the advantage of the proposed method over the state-of-the-art.","Computational modeling,
Visualization,
Layout,
Semantics,
Image segmentation,
Manifolds,
Legged locomotion"
Stochastic Ranking Algorithm for Many-Objective Optimization Based on Multiple Indicators,"Traditional multiobjective evolutionary algorithms face a great challenge when dealing with many objectives. This is due to a high proportion of nondominated solutions in the population and low selection pressure toward the Pareto front. In order to tackle this issue, a series of indicator-based algorithms have been proposed to guide the search process toward the Pareto front. However, a single indicator might be biased and lead the population to converge to a subregion of the Pareto front. In this paper, a multi-indicator-based algorithm is proposed for many-objective optimization problems. The proposed algorithm, namely stochastic ranking-based multi-indicator Algorithm (SRA), adopts the stochastic ranking technique to balance the search biases of different indicators. Empirical studies on a large number (39 in total) of problem instances from two well-defined benchmark sets with 5, 10, and 15 objectives demonstrate that SRA performs well in terms of inverted generational distance and hypervolume metrics when compared with state-of-the-art algorithms. Empirical studies also reveal that, in the case a problem requires the algorithm to have strong convergence ability, the performance of SRA can be further improved by incorporating a direction-based archive to store well-converged solutions and maintain diversity.","Sociology,
Statistics,
Optimization,
Convergence,
Algorithm design and analysis,
Evolutionary computation,
Benchmark testing"
"L
1
-Minimization Algorithms for Sparse Signal Reconstruction Based on a Projection Neural Network","This paper presents several L1 -minimization algorithms for sparse signal reconstruction based on a continuous-time projection neural network (PNN). First, a one-layer projection neural network is designed based on a projection operator and a projection matrix. The stability and global convergence of the proposed neural network are proved. Then, based on a discrete-time version of the PNN, several L1 -minimization algorithms for sparse signal reconstruction are developed and analyzed. Experimental results based on random Gaussian sparse signals show the effectiveness and performance of the proposed algorithms. Moreover, experimental results based on two face image databases are presented that reveal the influence of sparsity to the recognition rate. The algorithms are shown to be robust to the amplitude and sparsity level of signals as well as efficient with high convergence rate compared with several existing L1 -minimization algorithms.","Convergence,
Signal reconstruction,
Signal processing algorithms,
Neural networks,
Face recognition,
Algorithm design and analysis,
Optimization"
A Multilevel Index Model to Expedite Web Service Discovery and Composition in Large-Scale Service Repositories,"The number of web services has grown drastically. Then how to manage them efficiently in a service repository is an important issue to address. Given a special field, there often exists an efficient data structure for a class of objects, e.g., the Google' Bigtable is very suitable for webpages' storage and management. Based on the theory of the equivalence relations and quotient sets, this work proposes a multilevel index model for large-scale service repositories, which can be used to reduce the execution time of service discovery and composition. Its novel use of keys as inspired by the key in relational database can effectively remove the redundancy of the commonly-used inverted index. Its four function-based operations are for the first time proposed to manage and maintain services in a repository. The experiments validate that the proposed model is more efficient than the existing structures, i.e., sequential and inverted index ones.","Indexes,
Web services,
Redundancy,
Data structures,
Ontologies,
Cities and towns,
Motion pictures"
Gabor Cube Selection Based Multitask Joint Sparse Representation for Hyperspectral Image Classification,"The large amount of spectral and spatial information contained in hyperspectral imagery has provided great opportunity to effectively characterize and identify the surface materials of interest. As a novel feature extraction technique, a series of Gabor wavelet filters with different scales and frequencies was applied on hyperspectral data to extract spectral-spatial-combined features, which produced impressive performance on pixel-oriented classification. However, the incredibly large number of Gabor features could cause too much burden for onboard computation, limiting the efficiency of the method. To make matters worse, due to the nonhomogeneous spatial distribution of materials as well as the different characteristics of the constructed Gabor filters, some Gabor features could have a smaller or even negative impact on material representation, deteriorating the classification accuracy eventually. In this paper, a Gabor cube selection based multitask joint sparse representation approach, abbreviated as GS-MTJSRC, was proposed for hyperspectral image classification. First, based on the Fisher discrimination criterion, the most representative Gabor cubes for each class were picked out. Next, under multitask joint sparse representation framework, a coefficient vector could be obtained for each test sample with the selected Gabor cube features, which could be directly used for the following residual-based classification. Experimental results on three real hyperspectral data sets with different characteristics and spatial resolutions demonstrated the feasibility and efficiency of the proposed method.","Hyperspectral imaging,
Feature extraction,
Training,
Data mining,
Support vector machines,
Kernel"
Off the Radar: Comparative Evaluation of Radial Visualization Solutions for Composite Indicators,"A composite indicator (CI) is a measuring and benchmark tool used to capture multi-dimensional concepts, such as Information and Communication Technology (ICT) usage. Individual indicators are selected and combined to reflect a phenomena being measured. Visualization of a composite indicator is recommended as a tool to enable interested stakeholders, as well as the public audience, to better understand the indicator components and evolution overtime. However, existing CI visualizations introduce a variety of solutions and there is a lack in CI's visualization guidelines. Radial visualizations are popular among these solutions because of CI's inherent multi-dimensionality. Although in dispute, Radar-charts are often used for CI presentation. However, no empirical evidence on Radar's effectiveness and efficiency for common CI tasks is available. In this paper, we aim to fill this gap by reporting on a controlled experiment that compares the Radar chart technique with two other radial visualization methods: Flowercharts as used in the well-known OECD Betterlife index, and Circle-charts which could be adopted for this purpose. Examples of these charts in the current context are shown in Figure 1. We evaluated these charts, showing the same data with each of the mentioned techniques applying small multiple views for different dimensions of the data. We compared users' performance and preference empirically under a formal task-taxonomy. Results indicate that the Radar chart was the least effective and least liked, while performance of the two other options were mixed and dependent on the task. Results also showed strong preference of participants toward the Flower chart. Summarizing our results, we provide specific design guidelines for composite indicator visualization.","Radar,
Data visualization,
Visualization,
Benchmark testing,
Image color analysis,
Urban areas"
Distributed Multi-Target Tracking and Data Association in Vision Networks,"Distributed algorithms have recently gained immense popularity. With regards to computer vision applications, distributed multi-target tracking in a camera network is a fundamental problem. The goal is for all cameras to have accurate state estimates for all targets. Distributed estimation algorithms work by exchanging information between sensors that are communication neighbors. Vision-based distributed multi-target state estimation has at least two characteristics that distinguishes it from other applications. First, cameras are directional sensors and often neighboring sensors may not be sensing the same targets, i.e., they are naive with respect to that target. Second, in the presence of clutter and multiple targets, each camera must solve a data association problem. This paper presents an information-weighted, consensus-based, distributed multi-target tracking algorithm referred to as the Multi-target Information Consensus (MTIC) algorithm that is designed to address both the naivety and the data association problems. It converges to the centralized minimum mean square error estimate. The proposed MTIC algorithm and its extensions to non-linear camera models, termed as the Extended MTIC (EMTIC), are robust to false measurements and limited resources like power, bandwidth and the real-time operational requirements. Simulation and experimental analysis are provided to support the theoretical results.","Target tracking,
Cameras,
Sensors,
Distributed databases,
State estimation,
Algorithm design and analysis"
Spatial Spectrum Sensing-Based Device-to-Device Cellular Networks,"Ultra-densification is one of the main features of 5G networks. In an ultra-dense network, how to conduct interference management and spectrum allocation is a challenging issue. Spectrum sensing in cognitive radio networks is a distributed and efficient way to resolve this issue in ultra-dense networks. However, most of the studies on spectrum sensing only focus on sensing temporal spectrum opportunities where one or multiple primary users are active, which does not make full use of spectrum opportunities in the spatial location domain. To overcome the shortcomings of conventional temporal spectrum sensing, we study the problem of spatial spectrum sensing, which senses spatial spectrum opportunities in wireless networks. In this paper, the performance of spatial spectrum sensing and its application in sensing-based device-to-device (D2D) cellular networks are analyzed using stochastic geometry. Specifically, by modeling the locations of active transmitters as a Poisson point process, the spatial spectrum sensing problem is formulated using the framework of a detection theory. Closed-form expressions are obtained for the sensing threshold, probabilities of spatial detection, and false alarm. Furthermore, analytical throughput for D2D users and cellular users under both channel inversion and constant power allocation cases are derived. The optimal sensing radius that maximizes the defined network metric is obtained numerically. Finally, the simulation and numerical results are presented to verify our theoretical analysis.","Sensors,
Interference,
Resource management,
Mobile handsets,
Transmitters,
Mobile communication,
Uplink"
Sparse Codes Auto-Extractor for Classification: A Joint Embedding and Dictionary Learning Framework for Representation,"In this paper, we discuss the sparse codes auto-extractor based classification. A joint label consistent embedding and dictionary learning approach is proposed for delivering a linear sparse codes auto-extractor and a multi-class classifier by simultaneously minimizing the sparse reconstruction, discriminative sparse-code, code approximation and classification errors. The auto-extractor is characterized with a projection that bridges signals with sparse codes by learning special features from input signals for characterizing sparse codes. The classifier is trained based on extracted sparse codes directly. In our setting, the performance of the classifier depends on the discriminability of sparse codes, and the representation power of the extractor depends on the discriminability of input sparse codes, so we incorporate label information into the dictionary learning to enhance the discriminability of sparse codes. So, for inductive classification, our model forms an integration process from test signals to sparse codes and finally to assigned labels, which is essentially different from existing sparse coding based approaches that involve an extra sparse reconstruction with the trained dictionary for each test signal. Remarkable results are obtained by our model compared with other state-of-the-arts.",
"The Extra, Restricted Connectivity and Conditional Diagnosability of Split-Star Networks","Connectivity is a classic measure for fault tolerance of a network in the case of vertices failures. Extra connectivity and restricted connectivity are two important indicators of the robustness of a multi-processor system in presence of failing processors. An interconnection network's diagnosability is an important measure of its self-diagnostic capability. The conditional diagnosability is widely accepted as a new measure of diagnosability by assuming that any fault-set cannot contain all neighbors of any node in a multiprocessor system. In this paper, we analyze the combinatorial properties and fault tolerance ability for the Split-Star Network, denoted by Sn2, a well-known interconnection network proposed for multiprocessor systems, establish the g-extra connectivity, where 1 ≤ g ≤ 3. We also determine the h-restricted connectivity (h = 1; 2), and prove that the conditional diagnosability of Sn2 (n ≥ 4) is 6n - 16 under the comparison model, which is about three times of the Sn2's traditional diagnosability. As a product, the strong diagnosability of Sn2 is also obtained.","Program processors,
Fault tolerance,
Fault tolerant systems,
Multiprocessing systems,
Artificial neural networks,
Multiprocessor interconnection,
Network topology"
A Framework for Truthful Online Auctions in Cloud Computing with Heterogeneous User Demands,"Auction-style pricing policies can effectively reflect the underlying trends in demand and supply for the cloud resources, and thereby attracted a research interest recently. In particular, a desirable cloud auction design should be (1) online to timely reflect the fluctuation of supply-demand relations, (2) expressive to support the heterogeneous user demands, and (3) truthful to discourage users from cheating behaviors. Meeting these requirements simultaneously is non-trivial, and most existing auction mechanism designs do not directly apply. To meet these goals, this paper conducts the first work on a framework for truthful online cloud auctions where users with heterogeneous demands could come and leave on the fly. Concretely speaking, we first design a novel bidding language, wherein users' heterogeneous requirement on their desired allocation time, application type, and even how they value among different possible allocations can be flexibly and concisely expressed. Besides, building on top of our bidding language we propose COCA, an incentive-Compatible (truthful) Online Cloud Auction mechanism. To ensure truthfulness with heterogenous and online user demand, the design of COCA is driven by a monotonic payment rule and a utility-maximizing allocation rule. Moreover, our theoretical analysis shows that the worst-case performance of COCA can be well-bounded, and our further discussion shows that COCA performs well when some other important factors in online auction design are taken into consideration. Finally, in simulations the performance of COCA is seen to be comparable to the well-known off-line Vickrey-Clarke-Groves (VCG) mechanism [19].",
Dynamic Modeling of Cascading Failure in Power Systems,"The modeling of cascading failure in power systems is difficult because of the many different mechanisms involved; no single model captures all of these mechanisms. Understanding the relative importance of these different mechanisms is important for choosing which mechanisms need to be modeled for particular applications. This work presents a dynamic simulation model of both power networks and protection systems, which can simulate a wider variety of cascading outage mechanisms relative to existing quasi-steady-state (QSS) models. This paper describes the model and demonstrates how different mechanisms interact. In order to test the model, we simulated a batch of randomly selected N-2 contingencies for several different static load configurations, and found that the distributions of blackout sizes and event lengths from the simulator correlate well with historical trends. The results also show that load models have significant impacts on the cascading risks. Finally, the dynamic model was compared against a simple dc-power-flow based QSS model; we find that the two models tend to agree for the early stages of cascading but produce substantially different results for later stages.","Load modeling,
Mathematical model,
Relays,
Power system dynamics,
Power system protection,
Power system faults,
Computational modeling"
Algebraic Differential Evolution Algorithm for the Permutation Flowshop Scheduling Problem With Total Flowtime Criterion,"This paper introduces an original algebraic approach to differential evolution (DE) algorithms for combinatorial search spaces. An abstract algebraic differential mutation for generic combinatorial spaces is defined by exploiting the concept of a finitely generated group. This operator is specialized for the permutations space by means of an original randomized bubble sort algorithm. Then, a discrete DE algorithm is derived for permutation problems and it is applied to the permutation flowshop scheduling problem with the total flowtime criterion. Other relevant components of the proposed algorithm are: a crossover operator for permutations, a novel biased selection strategy, a heuristic-based initialization, and a memetic restart procedure. Extensive experimental tests have been performed on a widely accepted benchmark suite in order to analyze the dynamics of the proposed approach and to compare it with the state-of-the-art algorithms. The experimental results clearly show that the proposed algorithm reaches state-of-the-art performances and, most remarkably, it is able to find some new best known results. Furthermore, the experimental analysis on the impact of the algorithmic components shows that the two main contributions of this paper, i.e., the discrete differential mutation and the biased selection operator, greatly contribute to the overall performance of the algorithm.","Algorithm design and analysis,
Heuristic algorithms,
Processor scheduling,
Search problems,
Sociology,
Statistics,
Thin film transistors"
Smartwatch-based activity recognition: A machine learning approach,"Smartwatches and smartphones contain accelerometers and gyroscopes that sense a user's movements, and can help identify the activity a user is performing. Research into smartphone-based activity recognition has exploded over the past few years, but research into smartwatch-based activity recognition is still in its infancy. In this paper we compare smartwatch and smartphone-based activity recognition, and smartwatches are shown to be capable of identifying specialized hand-based activities, such as eating activities, which cannot be effectively recognized using a smartphone (e.g., smartwatches can identify the ""drinking"" activity with 93.3% accuracy while smartphones achieve an accuracy of only 77.3%). Smartwatch-based activity recognition can form the basis of new biomedical and health applications, including applications that automatically track a user's eating habits.","Sensors,
Data models,
Smart phones,
Gyroscopes,
Accelerometers,
Training data,
Radio frequency"
Mobile-Edge Computing: Partial Computation Offloading Using Dynamic Voltage Scaling,"The incorporation of dynamic voltage scaling technology into computation offloading offers more flexibilities for mobile edge computing. In this paper, we investigate partial computation offloading by jointly optimizing the computational speed of smart mobile device (SMD), transmit power of SMD, and offloading ratio with two system design objectives: energy consumption of SMD minimization (ECM) and latency of application execution minimization (LM). Considering the case that the SMD is served by a single cloud server, we formulate both the ECM problem and the LM problem as nonconvex problems. To tackle the ECM problem, we recast it as a convex one with the variable substitution technique and obtain its optimal solution. To address the nonconvex and nonsmooth LM problem, we propose a locally optimal algorithm with the univariate search technique. Furthermore, we extend the scenario to a multiple cloud servers system, where the SMD could offload its computation to a set of cloud servers. In this scenario, we obtain the optimal computation distribution among cloud servers in closed form for the ECM and LM problems. Finally, extensive simulations demonstrate that our proposed algorithms can significantly reduce the energy consumption and shorten the latency with respect to the existing offloading schemes.","Voltage control,
Cloud computing,
Energy consumption,
Electronic countermeasures,
Servers,
Computer architecture,
Optimization"
End-to-End Optimization for Geo-Distributed MapReduce,"MapReduce has proven remarkably effective for a wide variety of data-intensive applications, but it was designed to run on large single-site homogeneous clusters. Researchers have begun to explore the extent to which the original MapReduce assumptions can be relaxed, including skewed workloads, iterative applications, and heterogeneous computing environments. This paper continues this exploration by applying MapReduce across geo-distributed data over geo-distributed computation resources. Using Hadoop, we show that network and node heterogeneity and the lack of data locality lead to poor performance, because the interaction of MapReduce phases becomes pronounced in the presence of heterogeneous network behavior. To address these problems, we take a two-pronged approach: We first develop a model-driven optimization that serves as an oracle, providing high-level insights. We then apply these insights to design cross-phase optimization techniques that we implement and demonstrate in a real-world MapReduce implementation. Experimental results in both Amazon EC2 and PlanetLab show the potential of these techniques as performance is improved by 7-18 percent depending on the execution environment and application.","Optimization,
Computational modeling,
Extraterrestrial measurements,
Distributed databases,
Data models,
Cloud computing,
Bandwidth"
A hierarchical edge cloud architecture for mobile computing,"The performance of mobile computing would be significantly improved by leveraging cloud computing and migrating mobile workloads for remote execution at the cloud. In this paper, to efficiently handle the peak load and satisfy the requirements of remote program execution, we propose to deploy cloud servers at the network edge and design the edge cloud as a tree hierarchy of geo-distributed servers, so as to efficiently utilize the cloud resources to serve the peak loads from mobile users. The hierarchical architecture of edge cloud enables aggregation of the peak loads across different tiers of cloud servers to maximize the amount of mobile workloads being served. To ensure efficient utilization of cloud resources, we further propose a workload placement algorithm that decides which edge cloud servers mobile programs are placed on and how much computational capacity is provisioned to execute each program. The performance of our proposed hierarchical edge cloud architecture on serving mobile workloads is evaluated by formal analysis, small-scale system experimentation, and large-scale trace-based simulations.",
Dual-Layered MIMO Transmission for Increased Bandwidth Efficiency,"A dual-layered downlink transmission scheme is proposed for intrinsically amalgamating multiple-input-multiple-output (MIMO) spatial multiplexing (SMX) with spatial modulation (SM). The proposed scheme employs a classic SMX transmission that is known to offer superior bandwidth efficiency (BE) compared with SM. We exploit receive-antenna-based SM (RSM) on top of this transmission as an enhancement of the BE. The RSM here is applied to the combined spatial and power-level domain not by activating and deactivating the RAs but rather by choosing between two power levels {P1, P2} for the received symbols in these antennas. In other words, the combination of symbols received at a power level P1 carries information in the spatial domain in the same manner as the combination of nonzero elements in the receive symbol vector carries information in the RSM transmission. This allows for the coexistence of RSM with SMX, and the results show increased BE for the proposed scheme compared with both SMX and SM. To characterize the proposed scheme, we carry out a mathematical analysis of its performance, and we use this to optimize the ratio between P1 and P2 for attaining the minimum error rates. Our analytical and simulation results demonstrate significant BE gains for the proposed scheme compared with conventional SMX and SM.",
A Self-Calibrating Radar Sensor System for Measuring Vital Signs,"Vital signs (i.e., heartbeat and respiration) are crucial physiological signals that are useful in numerous medical applications. The process of measuring these signals should be simple, reliable, and comfortable for patients. In this paper, a noncontact self-calibrating vital signs monitoring system based on the Doppler radar is presented. The system hardware and software were designed with a four-tiered layer structure. To enable accurate vital signs measurement, baseband signals in the radar sensor were modeled and a framework for signal demodulation was proposed. Specifically, a signal model identification method was formulated into a quadratically constrained l1 minimization problem and solved using the upper bound and linear matrix inequality (LMI) relaxations. The performance of the proposed system was comprehensively evaluated using three experimental sets, and the results indicated that this system can be used to effectively measure human vital signs.","Doppler radar,
Baseband,
Heart beat,
Biomedical measurement,
Demodulation,
Monitoring"
Semi-Supervised Nonnegative Matrix Factorization via Constraint Propagation,"As is well known, nonnegative matrix factorization (NMF) is a popular nonnegative dimensionality reduction method which has been widely used in computer vision, document clustering, and image analysis. However, traditional NMF is an unsupervised learning mode which cannot fully utilize the priori or supervised information. To this end, semi-supervised NMF methods have been proposed by incorporating the given supervised information. Nevertheless, when little supervised information is available, the improved performance will be limited. To effectively utilize the limited supervised information, this paper proposed a novel semi-supervised NMF method (CPSNMF) with pairwise constraints. The method propagates both the must-link and cannot-link constraints from the constrained samples to unconstrained samples, so that we can get the constraint information of the entire data set. Then, this information is reflected to the adjustment of data weight matrix. Finally, the weight matrix is incorporated as a regularization term to the NMF objective function. Therefore, the proposed method can fully utilize the constraint information to keep the geometry of the data distribution. Furthermore, the proposed CPSNMF is explored with two formulations and corresponding update rules are provided to solve the optimization problems. Thorough experiments on standard databases show the superior performance of the proposed method.",
Cooperative Wireless Energy Harvesting and Spectrum Sharing in 5G Networks,"In this paper, we propose a novel best cooperative mechanism (BCM) for wireless energy harvesting and spectrum sharing in 5G networks. Data transfer and energy harvesting are finished in the designed timeslot mode. In the proposed BCM, secondary users (SUs) harvest energy from both ambient signals and primary user's (PU's) signals. In addition, the SU's can act as relay for PUs and harvest energy from PU signals simultaneously. The proposed mechanism allows optimal time duration for data transfer within the timeslot. We formulate an optimization problem based on the proposed BCM with an objective to maximize throughput of PUs and SUs with constraints on data rate and energy harvest save ratios. The effectiveness of the proposed cooperative mechanism is verified by simulations, and it is considered as an important stepping stone for future research in this domain.","Energy harvesting,
Spread spectrum management,
5G mobile communication,
Wireless communication,
Cooperative communication,
Data transfer"
A Game Theoretical Approach to Defend Against Co-Resident Attacks in Cloud Computing: Preventing Co-Residence Using Semi-Supervised Learning,"While cloud computing has facilitated easy and affordable access to IT resources, it has also introduced a wide range of security risks from almost every layer and component of cloud systems. In this paper, we focus on one risk at the virtual machine level and the co-resident attack, where by constructing various types of side channels, malicious users can obtain sensitive information from other virtual machines that co-locate on the same physical server. Most previous work has focused on the elimination of side channels, or more generally speaking, the possible countermeasures after attackers co-locate with their targets. In contrast, we provide a different perspective, and propose a defence mechanism that makes it difficult and expensive for attackers to achieve co-residence in the first place. Specifically, we first identify the potential differences between the behaviors of attackers and legal users. Second, we apply clustering analysis and semi-supervised learning techniques to classify users. Third, we model the problem as a two-player security game, and give a detailed analysis of the optimum strategies for both players. Finally, we demonstrate that the attacker's overall cost is increased dramatically by one-to-two orders of magnitude as a result of our defence mechanism.","Cloud computing,
Servers,
Resource management,
Games,
Security,
Australia,
Electronic mail"
Compressive Sensing-Based Topology Identification for Smart Grids,"Smart grid (SG) technology transforms the traditional power grid from a single-layer physical system to a cyber-physical network that includes a second layer of information. Collecting, transferring, and analyzing the huge amount of data that can be captured from different parameters in the network, together with the uncertainty that is caused by the distributed power generators, challenge the standard methods for security and monitoring in future SGs. Other important issues are the cost and power efficiency of data collection and analysis, which are highlighted in emergency situations such as blackouts. This paper presents an efficient dynamic solution for online SG topology identification (TI) and monitoring by combining concepts from compressive sensing (CS) and graph theory. In particular, the SG is modeled as a huge interconnected graph, and then using a dc power-flow model under the probabilistic optimal power flow (P-OPF), TI is mathematically reformulated as a sparse-recovery problem (SRP). This problem and challenges therein are efficiently solved using modified sparse-recovery algorithms. Network models are generated using the MATPOWER toolbox. Simulation results show that the proposed method represents a promising alternative for real-time monitoring in SGs.","Topology,
Network topology,
Mathematical model,
Load flow,
Sensors,
Phasor measurement units,
Power grids"
Analysis of CSMA/CA Mechanism of IEEE 802.15.6 under Non-Saturation Regime,"We have developed an analytical model for a non-saturated IEEE 802.15.6 wireless body area network (WBAN) operating under an error-prone channel. The most suitable vehicle for improving network performance was found to be the choice of access phase lengths based on traffic loads for different user priorities (UPs). It was also found that the deployment of exclusive access phase (EAP) is not necessary in a typical WBAN; in fact, short exclusive and random access phases (EAP and RAP, respectively) lead to inefficient use of available bandwidth. We have also found that four user priorities (out of the eight available) typically suffice to achieve even the most stringent requirements for WBAN performance.","Markov processes,
Multiaccess communication,
IEEE 802.15 Standards,
Radiation detectors,
Analytical models,
Probability"
Measurement-Based Real-Time Voltage Stability Monitoring for Load Areas,"This paper proposes a measurement-based voltage stability monitoring method for a load area fed by N tie lines. Compared to a traditional Thevenin equivalent based method, the new method adopts an N +1 buses equivalent system so as to model and monitor individual tie lines. For each tie line, the method solves the power transfer limit against voltage instability analytically as a function of all parameters of that equivalent, which are online identified from real-time synchronized measurements on boundary buses of the load area. Thus, this new method can directly calculate the real-time power transfer limit on each tie line. The method is first compared with a Thevenin equivalent based method using a 4-bus test system and then demonstrated by case studies on the Northeast Power Coordinating Council (NPCC) 48-machine, 140-bus power system.","Voltage measurement,
Power system stability,
Monitoring,
Load modeling,
Real-time systems,
Stability criteria"
Empirical data analysis: A new tool for data analytics,"In this paper, a novel empirical data analysis approach (abbreviated as EDA) is introduced which is entirely data-driven and free from restricting assumptions and pre-defined problem- or user-specific parameters and thresholds. It is well known that the traditional probability theory is restricted by strong prior assumptions which are often impractical and do not hold in real problems. Machine learning methods, on the other hand, are closer to the real problems but they usually rely on problem- or user-specific parameters or thresholds making it rather art than science. In this paper we introduce a theoretically sound yet practically unrestricted and widely applicable approach that is based on the density in the data space. Since the data may have exactly the same value multiple times we distinguish between the data points and unique locations in the data space. The number of data points, k is larger or equal to the number of unique locations, l and at least one data point occupies each unique location. The number of different data points that have exactly the same location in the data space (equal value), f can be seen as frequency. Through the combination of the spatial density and the frequency of occurrence of discrete data points, a new concept called multimodal typicality, τMM is proposed in this paper. It offers a closed analytical form that represents ensemble properties derived entirely from the empirical observations of data. Moreover, it is very close (yet different) from the histograms, from the probability density function (pdf) as well as from fuzzy set membership functions. Remarkably, there is no need to perform complicated pre-processing like clustering to get the multimodal representation. Moreover, the closed form for the case of Euclidean, Mahalanobis type of distance as well as some other forms (e.g. cosine-based dissimilarity) can be expressed recursively making it applicable to data streams and online algorithms. Inference/estimation of the typicality of data points that were not present in the data so far can be made. This new concept allows to rethink the very foundations of statistical and machine learning as well as to develop a series of anomaly detection, clustering, classification, prediction, control and other algorithms.",
Observations and opportunities in architecting shared virtual memory for heterogeneous systems,"Computing is becoming increasingly heterogeneous with accelerators like GPUs being tightly integrated with CPUs on the same die. Extending the CPU's virtual addressing mechanism to these accelerators is a key step in making accelerators easily programmable. In this work, we analyze, using real-system measurements, shared virtual memory across the CPU and an integrated GPU. We make several key observations and highlight consequent research opportunities: (1) servicing a TLB miss from the GPU can be an order of magnitude slower than that from the CPU and consequently it is imperative to enable many concurrent TLB misses to hide this larger latency; (2) divergence in memory accesses impacts the GPU's address translation more than the rest of the memory hierarchy, and research in designing address translation mechanisms tolerant to this effect is imperative; and (3) page faults from the GPU are considerably slower than that from the CPU and software-hardware co-design is essential for efficient implementation of page faults from throughput-oriented accelerators like GPUs. We present a detailed measurement study of a commercially available integrated APU that illustrates these effects and motivates future research opportunities.","Graphics processing units,
Hardware,
Memory management,
Prefetching,
Linux"
A Distance-Computation-Free Search Scheme for Binary Code Databases,"Recently, binary codes have been widely used in many multimedia applications to approximate high-dimensional multimedia features for practical similarity search due to the highly compact data representation and efficient distance computation. While the majority of the hashing methods aim at learning more accurate hash codes, only a few of them focus on indexing methods to accelerate the search for binary code databases. Among these indexing methods, most of them suffer from extremely high memory cost or extensive Hamming distance computations. In this paper, we propose a new Hamming distance search scheme for large scale binary code databases, which is free of Hamming distance computations to return the exact results. Without the necessity to compare database binary codes with queries, the search performance can be improved and databases can be externally maintained. More specifically, we adopt the inverted multi-index data structure to index binary codes. Importantly, the Hamming distance information embedded in the structure is utilized in the designed search scheme such that the verification of exact results no longer relies on Hamming distance computations. As a step further, we optimize the performance of the inverted multi-index structure by taking the code distributions among different bits into account for index construction. Empirical results on large-scale binary code databases demonstrate the superiority of our method over existing approaches in terms of both memory usage and search efficiency.","Binary codes,
Hamming distance,
Indexing,
Streaming media,
Search problems"
Robust Adaptive Neural Tracking Control for a Class of Perturbed Uncertain Nonlinear Systems With State Constraints,"In this paper, we deal with the problem of tracking control for a class of uncertain nonlinear systems in strictfeedback form subject to completely unknown system nonlinearities, hard constraints on full states, and unknown time-varying bounded disturbances. Integral barrier Lyapunov functionals are constructed to handle the unknown affine control gains (g(·)) with state constraints simultaneously. This removes the need on the knowledge of control gains for control design and avoids the conservative step of transforming original state constraints into new bounds on tracking errors. Neural networks (NNs) are used to approximate the unknown continuous packaged functions. To enhance the robustness, adapting parameters are developed to compensate the unknown bounds on NNs approximations and external disturbances. Design parameters-dependent feasibility conditions are formulated as sufficient conditions for the existence of feasible design parameters to guarantee the state constraints, and an offline constrained optimization step is proposed to obtain the optimal design parameters prior to the implementation of the proposed control. It is proved that the proposed control can guarantee the semiglobal uniform ultimate boundedness of all signals in closed-loop system, all states are ensured to remain in the predefined constrained state space, and tracking error converges to an adjustable neighborhood of the origin by choosing appropriate design parameters. Simulations are performed to validate the proposed control.","Nonlinear systems,
Artificial neural networks,
Approximation methods,
Control design,
Trajectory,
Adaptive systems"
Super-Resolution Compressed Sensing for Line Spectral Estimation: An Iterative Reweighted Approach,"Conventional compressed sensing theory assumes signals have sparse representations in a known dictionary. Nevertheless, in many practical applications such as line spectral estimation, the sparsifying dictionary is usually characterized by a set of unknown parameters in a continuous domain. To apply the conventional compressed sensing technique to such applications, the continuous parameter space has to be discretized to a finite set of grid points, based on which a “nominal dictionary” is constructed for sparse signal recovery. Discretization, however, inevitably incurs errors since the true parameters do not necessarily lie on the discretized grid. This error, also referred to as grid mismatch, leads to deteriorated recovery performance. In this paper, we consider the line spectral estimation problem and propose an iterative reweighted method which jointly estimates the sparse signals and the unknown parameters associated with the true dictionary. The proposed algorithm is developed by iteratively decreasing a surrogate function majorizing a given log-sum objective function, leading to a gradual and interweaved iterative process to refine the unknown parameters and the sparse signal. A simple yet effective scheme is developed for adaptively updating the regularization parameter that controls the tradeoff between the sparsity of the solution and the data fitting error. Theoretical analysis is conducted to justify the proposed method. Simulation results show that the proposed algorithm achieves super resolution and outperforms other state-of-the-art methods in many cases of practical interest.","Dictionaries,
Compressed sensing,
Estimation,
Signal resolution,
Frequency estimation,
Optimization,
Iterative methods"
Advanced spectrum sharing in 5G cognitive heterogeneous networks,"Spectrum utilization, energy consumption, and cost efficiency are three key performance metrics that should be jointly investigated in developing a sustainable 5G system. Advanced spectrum sharing can enhance both the spectral efficiency and energy efficiency in a cost-effective manner, which is expected to perform much better than conventional networks. In this article, we survey cognitive and cooperative spectrum sharing, and classify a multi-level spectrum exploitation, coordination, and utilization framework from both technical and economic perspectives. We specifically concentrate on spectrum trading and leasing, spectrum mobility, relaying, routing, and harvesting. Finally, a spectrum flowing scheme is proposed for 5G cognitive heterogeneous cellular networks, which improves both spectral and energy efficiency.","5G mobile communication,
Economics,
Energy efficiency,
Cognitive radio,
Mobile computing,
Heterogeneous networks,
Spread spectrum management"
Locality and Availability in Distributed Storage,"This paper studies the problem of information symbol availability in codes: we refer to a systematic code as code with (r, t)-availability if every information (systematic) symbol can be reconstructed from t disjoint groups of other code symbols, each of the sizes at most r. This paper shows that it is possible to construct codes that can support a scaling number of parallel reads while keeping the rate to be an arbitrarily high constant. It further shows that this is possible with the minimum Hamming distance arbitrarily close to the Singleton bound. This paper also presents a bound demonstrating a tradeoff between rate, minimum Hamming distance, and availability parameters. Our codes match the aforementioned bound, and their constructions rely on certain combinatorial structures. Resolvable designs provide one way to realize these required combinatorial structures. The two constructions presented in this paper require field sizes, which are linear and exponential in the code length, respectively. From a practical standpoint, our codes are relevant for distributed storage applications involving hot data, i.e., the information, which is frequently accessed by multiple processes in parallel.","Maintenance engineering,
Systematics,
Hamming distance,
Upper bound,
5G mobile communication,
Indexes"
Very Compact Fully Lumped Decoupling Network for a Coupled Two-Element Array,"Without the need of any transmission line, a very compact decoupling network based on reactive lumped elements is presented for a two-element closely spaced array. The lumped network, consisting of two series and four shunt elements, can be analytically designed using the even-odd mode analysis. In the even mode, the half-circuit of the decoupling network is identical to an L-section matching network, while in the odd mode it is equivalent to a π-section one. The proposed decoupling network can deal with the matching conditions of the even and odd modes independently so as to simultaneously achieve good impedance matching and port isolation of the whole antenna array. The design principle, formulation, and experimental results including the radiation characteristics are introduced.","Arrays,
Antennas,
Ports (Computers),
MIMO,
Joining processes,
Metamaterials"
Total Variation Regularized RPCA for Irregularly Moving Object Detection Under Dynamic Background,"Moving object detection is one of the most fundamental tasks in computer vision. Many classic and contemporary algorithms work well under the assumption that backgrounds are stationary and movements are continuous, but degrade sharply when they are used in a real detection sreal detection systemystem, mainly due to: 1) the dynamic background (e.g., swaying trees, water ripples and fountains in real scenarios, as well as raindrops and snowflakes in bad weather) and 2) the irregular object movement (like lingering objects). This paper presents a unified framework for addressing the difficulties mentioned above, especially the one caused by irregular object movement. This framework separates dynamic background from moving objects using the spatial continuity of foreground, and detects lingering objects using the temporal continuity of foreground. The proposed framework assumes that the dynamic background is sparser than the moving foreground that has smooth boundary and trajectory. We regard the observed video as being made up of the sum of a low-rank static background, a sparse and smooth foreground, and a sparser dynamic background. To deal with this decomposition, i.e., a constrained minimization problem, the augmented Lagrangian multiplier method is employed with the help of the alternating direction minimizing strategy. Extensive experiments on both simulated and real data demonstrate that our method significantly outperforms the state-of-the-art approaches, especially for the cases with dynamic backgrounds and discontinuous movements.","Object detection,
Heuristic algorithms,
Sparse matrices,
Optimization,
Robustness,
Algorithm design and analysis,
Cybernetics"
Control and Bidding Strategy for Virtual Power Plants With Renewable Generation and Inelastic Demand in Electricity Markets,"A virtual power plant (VPP), aggregating the capacities of distributed energy resources (DER) as a single profile, can facilitate cost-efficient integrations of DERs into electricity markets. In this paper, we investigate the control and bidding problem of VPPs, which consist of renewable distributed generators (RDGs) and consumers with inelastic demand. As both renewable generation and inelastic demand cannot be scheduled and accurately forecasted, a novel coordinated strategy on renewable power usage is proposed. To minimize the cost of VPP in the day-ahead and the balancing markets, a stochastic bilevel optimization problem is formulated with decision variables being renewable power usages and day-ahead bids. Due to the unimodality of the objective function, the problem can be greatly simplified and solved by local optimization algorithms. The performance of proposed strategy has been numerically assessed and compared with other commonly used strategies. Results show that our strategy leads to much lower expected costs than others. Moreover, it can be combined with flexible resources to further improve the performance.","Wind power generation,
Wind forecasting,
Optimization,
Standards,
Uncertainty"
Grounded Theory in Software Engineering Research: A Critical Review and Guidelines,"Grounded Theory (GT) has proved an extremely useful research approach in several fields including medical sociology, nursing, education and management theory. However, GT is a complex method based on an inductive paradigm that is fundamentally different from the traditional hypothetico-deductive research model. As there are at least three variants of GT, some ostensibly GT research suffers from method slurring, where researchers adopt an arbitrary subset of GT practices that are not recognizable as GT. In this paper, we describe the variants of GT and identify the core set of GT practices. We then analyze the use of grounded theory in software engineering. We carefully and systematically selected 98 articles that mention GT, of which 52 explicitly claim to use GT, with the other 46 using GT techniques only. Only 16 articles provide detailed accounts of their research procedures. We offer guidelines to improve the quality of both conducting and reporting GT studies. The latter is an important extension since current GT guidelines in software engineering do not cover the reporting process, despite good reporting being necessary for evaluating a study and informing subsequent research.","Software engineering,
Software,
Guidelines,
Computer science,
Interviews,
Encoding,
Sorting"
Towards Multistep Electricity Prices in Smart Grid Electricity Markets,"The multistep electricity price (MEP) policy has been introduced by many countries to promote energy saving, load balancing, and fairness in electricity consumption. Nonetheless, with the development of the smart grid, how to determine the quantity of electricity and at what price in a step-like fashion has not been fully investigated in the past. To address this issue, in this paper, we introduce two types of MEP models: a one-dimensional MEP model and a two-dimensional MEP model, which can be used to formally analyze and determine the desirable quantities of electricity and pricing in multiple steps. Particularly, in the one-dimensional MEP model, the steps are scaled only by the quantity of electricity whereas in the two-dimensional MEP model, the steps are scaled by both the quantity of electricity and the time when the electricity is used. Based on the proposed MEP models, we further investigate the vulnerability of the electricity market operation and investigate false data injection attacks against electricity prices and charges to consumers. Through an extensive simulation study, our data shows that the proposed MEP models can achieve fairness in electricity consumption, balance loads between peak and non-peak times, and improve electricity resource utilization. Our data also indicates that false data injection attacks can only partially compromise prices in our MEP models, leading to a limited impact on users' charges.","Electricity,
Load modeling,
Smart grids,
Energy conservation,
Electricity supply industry,
Load management,
Data models"
A Triaxial Accelerometer-Based Human Activity Recognition via EEMD-Based Features and Game-Theory-Based Feature Selection,"In recent years, sensor-based human activity recognition has attracted lots of studies. This paper presents a single wearable triaxial accelerometer-based human activity recognition system, which can be used in the real life of activity monitoring. The sensor is attached around different parts of the body: waist and left ankle, respectively. In order to improve the accuracy and reduce the computational complexity, the ensemble empirical mode decomposition (EEMD)-based features and the feature selection (FS) method are introduced, respectively. Considering the feature interaction, a game theory-based FS method is proposed to evaluate the features. Relevant and distinguished features that are robust to the placement of sensors are selected. In the experiment, the data acquired from the two different parts of the body, waist and ankle, are utilized to evaluate the proposed FS method. To verify the effectiveness of the proposed method, k-nearst neighbor and support vector machine are used to recognize the human activities from waist and ankle. Experiment results demonstrate the effectiveness of the introduced EEMD-based features for human activity recognition. Compared with the representative FS methods, including Relief-F and minimum-redundancy maximum-relevance, the proposed FS approach selects fewer features and provides higher accuracy. The results also show that the triaxial accelerometer around the waist produces optimal results.","Feature extraction,
Sensors,
Accelerometers,
White noise,
Biomedical monitoring,
Empirical mode decomposition,
Game theory"
Selective Harmonic Elimination With Groebner Bases and Symmetric Polynomials,"Selective harmonic elimination (SHE) technology has been widely used in many medium- and high-power converters which operates at very low switching frequency; however, it is still a challenging work to solve the switching angles from a group of nonlinear transcendental equations, especially for the multilevel converters. Based on the Groebner bases and symmetric polynomial theory, an algebraic method is proposed for SHE. The SHE equations are transformed to an equivalent canonical system which consists of a univariate high-order equations and a group of univariate linear equations, thus the solving procedure is simplified dramatically. In order to solve the final solutions from the definition of the elementary symmetric polynomials, a univariate polynomial equation is constructed according to the intermediate solutions and two criteria are given to check whether the results are true or not. Unlike the commonly used numerical and random searching methods, this method has no requirement on choosing initial values and can find all the solutions. Compared with the existing algebraic methods, such as the resultant elimination method, the calculation efficiency is improved, and the maximum solvable switching angles is nine. Experiments on three-phase two-level and 13-level inverters verify the correctness of the switching angles solved by the proposed method.","Polynomials,
Switches,
Mathematical model,
Modulation,
Harmonic analysis,
Inverters,
Power system harmonics"
Spatiochromatic Context Modeling for Color Saliency Analysis,"Visual saliency is one of the most noteworthy perceptual abilities of human vision. Recent progress in cognitive psychology suggests that: 1) visual saliency analysis is mainly completed by the bottom-up mechanism consisting of feedforward low-level processing in primary visual cortex (area V1) and 2) color interacts with spatial cues and is influenced by the neighborhood context, and thus it plays an important role in a visual saliency analysis. From a computational perspective, the most existing saliency modeling approaches exploit multiple independent visual cues, irrespective of their interactions (or are not computed explicitly), and ignore contextual influences induced by neighboring colors. In addition, the use of color is often underestimated in the visual saliency analysis. In this paper, we propose a simple yet effective color saliency model that considers color as the only visual cue and mimics the color processing in V1. Our approach uses region-/boundary-defined color features with spatiochromatic filtering by considering local color-orientation interactions, therefore captures homogeneous color elements, subtle textures within the object and the overall salient object from the color image. To account for color contextual influences, we present a divisive normalization method for chromatic stimuli through the pooling of contrary/complementary color units. We further define a color perceptual metric over the entire scene to produce saliency maps for color regions and color boundaries individually. These maps are finally globally integrated into a one single saliency map. The final saliency map is produced by Gaussian blurring for robustness. We evaluate the proposed method on both synthetic stimuli and several benchmark saliency data sets from the visual saliency analysis to salient object detection. The experimental results demonstrate that the use of color as a unique visual cue achieves competitive results on par with or better than 12 state-of-the-art approaches.",
Virtual Actuators for Wide-Area Damping Control of Power Systems,"In this paper, a new approach to design fault-tolerant wide-area damping controllers (WADCs) is presented. Use of actuator redundancy to achieve higher reliability has always been an accepted engineering design technique and is used in this study to help ensure power system security. In our proposed method when an actuator fails or is unavailable (e.g., due to loss of communication), the supervisory controller redistributes the control signals to the remaining actuators. The WADC is initially designed to provide satisfactory damping. In the next step, virtual actuators (VAs) are designed to manage actuator failures without the need to redesign the nominal WADC. By inserting this reconfiguration block between the nominal WADC and the new actuator, there is no need to retune the WADC and the performance of the fault-free system can be recovered. Our proposed block is independent of the nominal WADC and does not need any information beyond that an actuator is unavailable. The approach is applied to Kundur's two-area system, and the 39-bus New England system. Numerical results show the effectiveness of the proposed method subjected to different failures.","Actuators,
Damping,
Power system stability,
HVDC transmission,
Generators,
Power system dynamics"
Global Alignment of Protein-Protein Interaction Networks: A Survey,"In this paper, we survey algorithms that perform global alignment of networks or graphs. Global network alignment aligns two or more given networks to find the best mapping from nodes in one network to nodes in other networks. Since graphs are a common method of data representation, graph alignment has become important with many significant applications. Protein-protein interactions can be modeled as networks and aligning these networks of protein interactions has many applications in biological research. In this survey, we review algorithms for global pairwise alignment highlighting various proposed approaches, and classify them based on their methodology. Evaluation metrics that are used to measure the quality of the resulting alignments are also surveyed. We discuss and present a comparison between selected aligners on the same datasets and evaluate using the same evaluation metrics. Finally, a quick overview of the most popular databases of protein interaction networks is presented focusing on datasets that have been used recently.","Proteins,
Measurement,
Computational biology,
Springs,
Bioinformatics"
A Voting-Based Femtocell Downlink Cell-Breathing Control Mechanism,"An overlay macrocell-femtocell system aims to increase the system capacity with a low-cost infrastructure. To construct such an infrastructure, we need to solve some existing problems. First, there is a tradeoff between femtocell coverage and overall system throughput, which we defined as the cell-breathing phenomenon. In light of this, we propose a femtocell downlink cell-breathing control framework to strike a balance between the coverage and data rate. Second, due to the selfish nature of mobile stations, the system information collected from them does not necessarily reflect the true status of the system. Thus, we design FEmtocell Virtual Election Rule (FEVER), a voting-based direct mechanism that only requires users to report their channel quality information to the femtocell base station. Not only is it proved to be truthful and has low implementation complexity, but it also strikes a balance between efficiency and fairness to meet the different needs. The simulation results verify the enhanced system performance under the FEVER mechanism.",
Robust Energy-Efficient MIMO Transmission for Cognitive Vehicular Networks,"This work investigates a robust energy-efficient solution for multiple-input–multiple-output (MIMO) transmissions in cognitive vehicular networks. Our goal is to design an optimal MIMO beamforming for secondary users (SUs), considering imperfect interference channel-state information (CSI). Specifically, we optimize the energy efficiency (EE) of SUs, given that the transmission power constraint, the robust interference power constraint, and the minimum transmission rate are satisfied. To solve the optimization problem, we first characterize the uncertainty of CSI by bounding it in a Frobenius-norm-based region and then equivalently convert the robust interference constraint to a linear matrix inequality (LMI). Furthermore, a feasible ascent direction approach is proposed to reduce the optimization problem into a sequential linearly constrained semidefinite program, which leads to a distributed iterative optimization algorithm for deriving the robust and optimal beamforming. The feasibility and convergence of the proposed algorithm is theoretically validated, and the final experimental results are also supplemented to show the strength of the proposed algorithm over some conventional schemes in terms of the achieved EE performance and robustness.","MIMO,
Robustness,
Optimization,
Vehicles,
Array signal processing,
Interference,
Mathematical model"
Correspondence Driven Saliency Transfer,"In this paper, we show that large annotated data sets have great potential to provide strong priors for saliency estimation rather than merely serving for benchmark evaluations. To this end, we present a novel image saliency detection method called saliency transfer. Given an input image, we first retrieve a support set of best matches from the large database of saliency annotated images. Then, we assign the transitional saliency scores by warping the support set annotations onto the input image according to computed dense correspondences. To incorporate context, we employ two complementary correspondence strategies: a global matching scheme based on scene-level analysis and a local matching scheme based on patch-level inference. We then introduce two refinement measures to further refine the saliency maps and apply the random-walk-with-restart by exploring the global saliency structure to estimate the affinity between foreground and background assignments. Extensive experimental results on four publicly available benchmark data sets demonstrate that the proposed saliency algorithm consistently outperforms the current state-of-the-art methods.","Feature extraction,
Object detection,
Visualization,
Estimation,
Context,
Electronic mail,
Mathematical model"
Secure Routing Based on Social Similarity in Opportunistic Networks,"The lack of pre-existing infrastructure or dynamic topology makes it impossible to establish end-to-end connections in opportunistic networks (OppNets). Instead, a store-and-forward strategy can be employed. However, such loosely knit routing paths depend heavily on the cooperation among participating nodes. Selfish or malicious behaviors of nodes impact greatly on the network performance. In this paper, we design and validate a dynamic trust management model for secure routing optimization. We propose the concept of incorporating social trust into the routing decision process and design a trust routing based on social similarity (TRSS) scheme. TRSS is based on the observation that nodes move around and contact each other according to their common interests or social similarities. A node sharing more social features in social history record with the destination is more likely to travel close to the latter in the near future and should be chosen as the next-hop forwarder. Furthermore, social trust can be established based on an observed node's trustworthiness and its encounter history. Based on direct and recommended trust, those untrustworthy nodes will be detected and purged from the trusted list. Since only trusted nodes' packets will be forwarded, the selfish nodes have the incentives to behave well again. Simulation evaluation demonstrates that TRSS is very effective in detecting selfish or even malicious nodes and achieving better performance.","Routing,
History,
Relays,
Context,
Wireless communication,
Social network services,
Urban areas"
Real-Time Device-Level Transient Electrothermal Model for Modular Multilevel Converter on FPGA,"Real-time simulation of modular multilevel converters (MMCs) is challenging due to their complex structure consisting of a large number of submodules (SMs). In the literature, the computational speed is emphasized for MMC modeling in real-time simulation, while accurate and detailed information of insulated-gate bipolar transistor (IGBT) modules in SMs is sacrificed. A novel datasheet-based device-level electrothermal model for an MMC on the field programmable gate array (FPGA) is presented in this paper for real-time hardware emulation. Conduction and switching power losses, junction temperatures, temperature-dependent electrical parameters, and linearized switching transient waveforms of IGBT modules are adequately captured in the proposed model. Simultaneously the system-level behavior of the MMC is accurately modeled. Five-level and nine-level MMC systems are emulated in the hardware with the time step of 10 μs and 10 ns for system-level and device-level computations, respectively. The paralleled and pipelined hardware design using IEEE 32-bit floating point number precision runs on Xilinx Virtex-7 XC7VX485T device. The emulated real-time results by an oscilloscope have been validated by offline simulation on SaberRD software.","Insulated gate bipolar transistors,
Computational modeling,
Hardware,
Real-time systems,
Field programmable gate arrays,
Emulation,
Capacitors"
Successive Convex Quadratic Programming for Quality-of-Service Management in Full-Duplex MU-MIMO Multicell Networks,"This paper designs jointly optimal linear precoders for both base stations (BSs) and users in a multiuser multi-input multi-output (MU-MIMO) multicell network. The BSs are full-duplexing transceivers while uplink users and downlink users (DLUs) are equipped with multiple antennas. Here, the network quality-of-service (QoS) requirement is expressed in terms of the minimum throughput at the BSs and DLUs. We consider the problems of either QoS-constrained sum throughput maximization or minimum cell throughput maximization. Due to the nonconcavity of the throughput functions, the optimal solutions of these two problems remain unknown in both half-duplexing and full-duplexing networks. The first problem has a nonconcave objective and a nonconvex feasible set, whereas the second problem has a nonconcave and nonsmooth objective. To solve such challenging optimization problems, we develop iterative low-complexity algorithms that only invoke one simple convex quadratic program at each iteration. Since the objective value is proved to iteratively increase, our path-following algorithms converge at least to the local optimum of the original nonconvex problems. Due to their guaranteed convergence, simple implementation, and low complexity, the devised algorithms lend themselves to practical precoder designs for large-scale full-duplex MU-MIMO multicell networks. Numerical results demonstrate the advantages of our successive convex quadratic programming framework over existing solutions.","Throughput,
Uplink,
Downlink,
Interference,
Quality of service,
Optimization,
Antennas"
Secure Multiuser Scheduling in Downlink Dual-Hop Regenerative Relay Networks Over Nakagami- m Fading Channels,"In this paper, we investigate the secrecy performance of multiuser dual-hop relay networks where a base station (BS) communicates with multiple legitimate users through the assistance of a trustful regenerative relay in the presence of multiple eavesdroppers. In particular, the maximal ratio transmission scheme is exploited at the BS and a threshold-based multiuser scheduling scheme is employed over the legitimate users, while concerning the imperfect decoding at the regenerative relay. To evaluate the secrecy performance of the considered system, two practical situations are addressed based on the availability of eavesdropper's channel state information (CSI), i.e., Scenario I, where the eavesdropper's CSI is not available at the relay, and Scenario II, where the eavesdropper's CSI is available at the relay. For both the scenarios, we further consider two eavesdropping modes, i.e., colluding eavesdropping and non-colluding eavesdropping. For Scenario I, new exact and asymptotic closed-form expressions for the secrecy outage probability (SOP) are derived. For Scenario II, we derive new exact and asymptotic closed-form expressions for the ergodic secrecy rate (ESR). The asymptotic SOPs demonstrate that the secrecy diversity order is independent of the number of legitimate users NB and eavesdroppers NE, the number of antennas equipped at eavesdroppers AE, as well as the fading factor of the wiretap channel mE. Furthermore, we also determine the secrecy multiplexing gain and the power cost to explicitly quantify the impact of the legitimate channel and wiretap channel on the ESR. Our findings demonstrate that increasing the switching threshold, the number of antennas at the BS, and the number of legitimate users has a positive impact on secrecy performance.","Wireless communication,
Network security,
Fading channels,
Power outages,
Relay networks (telecommunications),
Jamming,
Privacy"
A New Stray-Load Loss Formula for Small and Medium-Sized Induction Motors,"This paper proposes a new stray-load loss (SLL) formula for small and medium induction motors (IMs) based on tests data of a 182, 60 Hz IMs in the range of 1-500 hp (0.75-375 kW). They are all tested in accordance with IEEE Std 112-Method B. The proposed formula is validated by recalculating the efficiency of the same number of motors by using the proposed formula, as well as the IEEE Std 112 and the IEC 60034-2-1 standards. Another validation was done on testing 17 additional IMs that are independent of the 182-motor data. In both validations, the new formula demonstrates better accuracy. This formula shows the potential to replace the existing SLL estimation formula for this horsepower range.","Induction motors,
Loss measurement,
IEEE Standards,
IEC Standards,
Copper,
Stators"
Nonreciprocal Graphene Devices and Antennas Based on Spatiotemporal Modulation,"A new class of magnet-free nonreciprocal plasmonic devices operating at terahertz (THz) frequencies is introduced based on the spatiotemporal modulation of graphene's conductivity. The proposed components are based on graphene parallel-plate waveguides with double-gated electrodes, which allow independent manipulation of graphene properties in both space and time. We employ this structure for the design of plasmonic isolators and leaky-wave antennas at THz frequencies and study the effect of graphene and modulation parameters on their response. We envision that this technology may pave the way towards silicon-compatible fully planar nonreciprocal plasmonic components and antennas with enhanced functionalities at THz, with important applications in biosensing, imaging, and intra/interchip communications.","Graphene,
Frequency modulation,
Spatiotemporal phenomena,
Plasmons,
Antennas,
Conductivity"
Safe controller optimization for quadrotors with Gaussian processes,"One of the most fundamental problems when designing controllers for dynamic systems is the tuning of the controller parameters. Typically, a model of the system is used to obtain an initial controller, but ultimately the controller parameters must be tuned manually on the real system to achieve the best performance. To avoid this manual tuning step, methods from machine learning, such as Bayesian optimization, have been used. However, as these methods evaluate different controller parameters on the real system, safety-critical system failures may happen. In this paper, we overcome this problem by applying, for the first time, a recently developed safe optimization algorithm, SafeOpt, to the problem of automatic controller parameter tuning. Given an initial, low-performance controller, SafeOpt automatically optimizes the parameters of a control law while guaranteeing safety. It models the underlying performance measure as a Gaussian process and only explores new controller parameters whose performance lies above a safe performance threshold with high probability. Experimental results on a quadrotor vehicle indicate that the proposed method enables fast, automatic, and safe optimization of controller parameters without human intervention.","Optimization,
Bayes methods,
Safety,
Tuning,
Vehicle dynamics,
Noise measurement,
Computational modeling"
Parallel and Distributed Dimensionality Reduction of Hyperspectral Data on Cloud Computing Architectures,"Cloud computing offers the possibility to store and process massive amounts of remotely sensed hyperspectral data in a distributed way. Dimensionality reduction is an important task in hyperspectral imaging, as hyperspectral data often contains redundancy that can be removed prior to analysis of the data in repositories. In this regard, the development of dimensionality reduction techniques in cloud computing environments can provide both efficient storage and preprocessing of the data. In this paper, we develop a parallel and distributed implementation of a widely used technique for hyperspectral dimensionality reduction: principal component analysis (PCA), based on cloud computing architectures. Our implementation utilizes Hadoop's distributed file system (HDFS) to realize distributed storage, uses Apache Spark as the computing engine, and is developed based on the map-reduce parallel model, taking full advantage of the high throughput access and high performance distributed computing capabilities of cloud computing environments. We first optimized the traditional PCA algorithm to be well suited for parallel and distributed computing, and then we implemented it on a real cloud computing architecture. Our experimental results, conducted using several hyperspectral datasets, reveal very high performance for the proposed distributed parallel method.","Hyperspectral imaging,
Principal component analysis,
Cloud computing,
Distributed databases,
Sparks,
Computer architecture"
A Constrained Optimization Approach to Dynamic State Estimation for Power Systems Including PMU and Missing Measurements,"In this brief, a hybrid filter algorithm is developed to deal with the state estimation (SE) problem for power systems by taking into account the impact from the phasor measurement units (PMUs). Our aim is to include PMU measurements when designing the dynamic state estimators for power systems with traditional measurements. Also, as data dropouts inevitably occur in the transmission channels of traditional measurements from the meters to the control center, the missing measurement phenomenon is also tackled in the state estimator design. In the framework of extended Kalman filter (EKF) algorithm, the PMU measurements are treated as inequality constraints on the states with the aid of the statistical criterion, and then the addressed SE problem becomes a constrained optimization one based on the probability-maximization method. The resulting constrained optimization problem is then solved using the particle swarm optimization algorithm together with the penalty function approach. The proposed algorithm is applied to estimate the states of the power systems with both traditional and PMU measurements in the presence of probabilistic data missing phenomenon. Extensive simulations are carried out on the IEEE 14-bus test system and it is shown that the proposed algorithm gives much improved estimation performances over the traditional EKF method.","Phasor measurement units,
Power system dynamics,
Optimization,
Power measurement,
Noise measurement,
Estimation"
Switched by input: Power efficient structure for RRAM-based convolutional neural network,"Convolutional Neural Network (CNN) is a powerful technique widely used in computer vision area, which also demands much more computations and memory resources than traditional solutions. The emerging metal-oxide resistive random-access memory (RRAM) and RRAM crossbar have shown great potential on neuromorphic applications with high energy efficiency. However, the interfaces between analog RRAM crossbars and digital peripheral functions, namely Analog-to-Digital Converters (AD-Cs) and Digital-to-Analog Converters (DACs), consume most of the area and energy of RRAM-based CNN design due to the large amount of intermediate data in CNN. In this paper, we propose an energy efficient structure for RRAM-based CNN. Based on the analysis of data distribution, a quantization method is proposed to transfer the intermediate data into 1 bit and eliminate DACs. An energy efficient structure using input data as selection signals is proposed to reduce the ADC cost for merging results of multiple crossbars. The experimental results show that the proposed method and structure can save 80% area and more than 95% energy while maintaining the same or comparable classification accuracy of CNN on MNIST.","Kernel,
Convolution,
Neural networks,
Quantization (signal),
Merging,
Neurons,
Computer vision"
Trainlets: Dictionary Learning in High Dimensions,"Sparse representation has shown to be a very powerful model for real world signals, and has enabled the development of applications with notable performance. Combined with the ability to learn a dictionary from signal examples, sparsity-inspired algorithms are often achieving state-of-the-art results in a wide variety of tasks. These methods have traditionally been restricted to small dimensions mainly due to the computational constraints that the dictionary learning problem entails. In the context of image processing, this implies handling small image patches. In this work we show how to efficiently handle bigger dimensions and go beyond the small patches in sparsity-based signal and image processing methods. We build our approach based on a new cropped Wavelet decomposition, which enables a multi-scale analysis with virtually no border effects. We then employ this as the base dictionary within a double sparsity model to enable the training of adaptive dictionaries. To cope with the increase of training data, while at the same time improving the training performance, we present an Online Sparse Dictionary Learning (OSDL) algorithm to train this model effectively, enabling it to handle millions of examples. This work shows that dictionary learning can be up-scaled to tackle a new level of signal dimensions, obtaining large adaptable atoms that we call Trainlets.",
AutoDietary: A Wearable Acoustic Sensor System for Food Intake Recognition in Daily Life,"Nutrition-related diseases are nowadays a main threat to human health and pose great challenges to medical care. A crucial step to solve the problems is to monitor the daily food intake of a person precisely and conveniently. For this purpose, we present AutoDietary, a wearable system to monitor and recognize food intakes in daily life. An embedded hardware prototype is developed to collect food intake sensor data, which is highlighted by a high-fidelity microphone worn on the subject's neck to precisely record acoustic signals during eating in a noninvasive manner. The acoustic data are preprocessed and then sent to a smartphone via Bluetooth, where food types are recognized. In particular, we use hidden Markov models to identify chewing or swallowing events, which are then processed to extract their time/frequency-domain and nonlinear features. A lightweight decision-tree-based algorithm is adopted to recognize the type of food. We also developed an application on the smartphone, which aggregates the food intake recognition results in a user-friendly way and provides suggestions on healthier eating, such as better eating habits or nutrition balance. Experiments show that the accuracy of food-type recognition by AutoDietary is 84.9%, and those to classify liquid and solid food intakes are up to 97.6% and 99.7%, respectively. To evaluate real-life user experience, we conducted a survey, which collects rating from 53 participants on wear comfort and functionalities of AutoDietary. Results show that the current design is acceptable to most of the users.",
Secure Relay Beamforming for SWIPT in Amplify-and-Forward Two-Way Relay Networks,"In this paper, we investigate the secure relay beamforming problem for simultaneous wireless information and power transfer (SWIPT) in an amplify-and-forward (AF) two-way relay network. We consider scenarios that the eavesdropper's channel state information (CSI) is and is not available. When the eavesdropper's CSI is available, our objective is to maximize the achievable secrecy sum rate under transmit power constraint and energy harvesting constraint. Since the optimization problem is nonconvex, we derive its performance upper bound, which requires 2-D search, where a semidefinite programming is solved in each step. We also propose an upper bound-based rank-one solution by employing the Gaussian randomization method. To reduce computational complexity, we transform the optimization problem into a difference-of-convex programming and propose a sequential parametric convex approximation (SPCA)-based iterative algorithm to find a locally optimal solution. Furthermore, we also propose a zero-forcing (ZF)-based suboptimal solution. Simulation results demonstrate that the upper bound-based rank-one solution archives the performance almost the same as the upper bound that has high computational complexity. The low-complexity SPCA-based locally optimal solution performs close to the upper bound. The ZF-based suboptimal solution has the lowest computational complexity among the proposed solutions. When the eavesdropper's CSI is not available, we propose an artificial noise-aided secure relay beamforming scheme.","Array signal processing,
Relay networks (telecommunications),
Receivers,
Upper bound,
Wireless communication,
Communication system security"
Accurate Segmentation of CT Male Pelvic Organs via Regression-Based Deformable Models and Multi-Task Random Forests,"Segmenting male pelvic organs from CT images is a prerequisite for prostate cancer radiotherapy. The efficacy of radiation treatment highly depends on segmentation accuracy. However, accurate segmentation of male pelvic organs is challenging due to low tissue contrast of CT images, as well as large variations of shape and appearance of the pelvic organs. Among existing segmentation methods, deformable models are the most popular, as shape prior can be easily incorporated to regularize the segmentation. Nonetheless, the sensitivity to initialization often limits their performance, especially for segmenting organs with large shape variations. In this paper, we propose a novel approach to guide deformable models, thus making them robust against arbitrary initializations. Specifically, we learn a displacement regressor, which predicts 3D displacement from any image voxel to the target organ boundary based on the local patch appearance. This regressor provides a non-local external force for each vertex of deformable model, thus overcoming the initialization problem suffered by the traditional deformable models. To learn a reliable displacement regressor, two strategies are particularly proposed. 1) A multi-task random forest is proposed to learn the displacement regressor jointly with the organ classifier; 2) an auto-context model is used to iteratively enforce structural information during voxel-wise prediction. Extensive experiments on 313 planning CT scans of 313 patients show that our method achieves better results than alternative classification or regression based methods, and also several other existing methods in CT pelvic organ segmentation.","Image segmentation,
Computed tomography,
Deformable models,
Shape,
Bladder,
Planning"
Interactive Control of Coupled Microgrids for Guaranteed System-Wide Small Signal Stability,"This paper proposes an interactive control framework for microgrid interconnections to achieve effective load sharing and guaranteed system-wide small signal stability. In the proposed framework, hierarchical control is performed at three levels operating in different time frames. A model reference control-based scheme is implemented for primary level power sharing, through which the interface inverter of each microgrid is controlled to track a designed reference model. At the secondary level, an interactive droop management scheme is proposed to manage the reference model droop gains based on a distributed stability criterion. At the tertiary level, an ac power flow-based supervisory control strategy is utilized to dispatch the nominal setting to each microgrid central controller (MGCC) for the primary level reference tracking, and broadcast an interaction coefficient to each MGCC so that the droop gains can be managed to guarantee system-wide stability. Numerical analysis of a study system designed based on the IEEE 123-node test feeder demonstrates the effectiveness of the proposed interactive control framework.","Microgrids,
Stability criteria,
Power system stability,
Reactive power,
Frequency synchronization,
Couplings"
Partial Sum Minimization of Singular Values in Robust PCA: Algorithm and Applications,"Robust Principal Component Analysis (RPCA) via rank minimization is a powerful tool for recovering underlying low-rank structure of clean data corrupted with sparse noise/outliers. In many low-level vision problems, not only it is known that the underlying structure of clean data is low-rank, but the exact rank of clean data is also known. Yet, when applying conventional rank minimization for those problems, the objective function is formulated in a way that does not fully utilize a priori target rank information about the problems. This observation motivates us to investigate whether there is a better alternative solution when using rank minimization. In this paper, instead of minimizing the nuclear norm, we propose to minimize the partial sum of singular values, which implicitly encourages the target rank constraint. Our experimental analyses show that, when the number of samples is deficient, our approach leads to a higher success rate than conventional rank minimization, while the solutions obtained by the two approaches are almost identical when the number of samples is more than sufficient. We apply our approach to various low-level vision problems, e.g., high dynamic range imaging, motion edge detection, photometric stereo, image alignment and recovery, and show that our results outperform those obtained by the conventional nuclear norm rank minimization method.","Minimization,
Linear programming,
Robustness,
Principal component analysis,
Approximation methods,
Computer vision,
Noise"
Ambient Backscatter Communication Systems: Detection and Performance Analysis,"Ambient backscatter technology that utilizes the ambient radio frequency signals to enable the communications of battery-free devices has attracted much attention recently. In this paper, we study the problem of signal detection for an ambient backscatter communication system that adopts the differential encoding to eliminate the necessity of channel estimation. Specifically, we formulate a new transmission model, design the data detection algorithm, and derive two closed-form detection thresholds. One threshold is used to approximately achieve the minimum sum bit error rate (BER), while the other yields balanced error probabilities for “0” bit and “1” bit. The corresponding BER expressions are derived to fully characterize the detection performance. In addition, the lower and the upper bounds of BER at high signal-to-noise ratio regions are also examined to simplify a performance analysis. Simulation results are then provided to corroborate the theoretical studies.",
Distributed Energy Spectral Efficiency Optimization for Partial/Full Interference Alignment in Multi-user Multi-relay Multi-cell MIMO Systems,"The energy spectral efficiency maximization (ESEM) problem of a multi-user, multi-relay, multi-cell system is considered, where all the network nodes are equipped with multi-antenna transceivers. To deal with the potentially excessive interference originating from a plethora of geographically distributed transmission sources, a pair of transmission protocols based on interference alignment (IA) are conceived. The first, termed the full-IA, avoids all intra-cell interference (ICI) and other-cell interference by finding the perfect interference-nulling receive beamforming matrices (RxBFMs). The second protocol, termed partial-IA, only attempts to null the ICI. Employing the RxBFMs computed by either of these protocols mathematically decomposes the channel into a multiplicity of non-interfering multiple-input-single-output channels, which we term as spatial multiplexing components (SMCs). The problem of finding the optimal SMCs as well as their power control variables for the ESEM problem considered is formally defined and converted into a convex optimization form with carefully selected variable relaxations and transformations. Thus, the optimal SMCs and power control variables can be distributively computed using both the classic dual decomposition and subgradient methods. Our results indicate that indeed, the ESEM algorithm performs better than the baseline equal power allocation algorithm in terms of its ESE. Furthermore, surprisingly the partial-IA outperforms the full-IA in all cases considered, which is because the partial-IA is less restrictive in terms of the number of available transmit dimensions at the transmitters. Given the typical cell sizes considered in this paper, the path-loss sufficiently attenuates the majority of the interference, and thus the full-IA over-compensates, when trying to avoid all possible sources of interference.","Protocols,
Interference,
Macrocell networks,
Receivers,
Wireless communication,
Transceivers,
Array signal processing"
Joint Relay and Jammer Selection Improves the Physical Layer Security in the Face of CSI Feedback Delays,"We enhance the physical layer security (PLS) of amplify-and-forward (AF) relaying networks with the aid of joint relay and jammer selection (JRJS), despite the deleterious effect of channel state information (CSI) feedback delays. Furthermore, we conceive a new outage-based characterization approach for the JRJS scheme. The traditional best relay selection (TBRS) is also considered as a benchmark. We first derive closed-form expressions of both the connection outage probability (COP) and the secrecy outage probability (SOP) for both the TBRS and JRJS schemes. Then, a reliable and secure connection probability (RSCP) is defined and analyzed for characterizing the effect of the correlation between the COP and the SOP introduced by the corporate source-relay link. The reliability-security ratio (RSR) is introduced for characterizing the relationship between the reliability and the security through asymptotic analysis. Moreover, the concept of effective secrecy throughput is defined as the product of the secrecy rate and of the RSCP for the sake of characterizing the overall efficiency of the system, as determined by the transmit SNR, the secrecy codeword rate, and the power sharing ratio between the relay and the jammer. The impact of the direct source-eavesdropper link and additional performance comparisons with respect to other related selection schemes are also included. Our numerical results show that the JRJS scheme outperforms the TBRS method both in terms of the RSCP and in terms of its effective secrecy throughput, but it is more sensitive to the feedback delays. Increasing the transmit signal-to-noise ratio (SNR) will not always improve the overall throughput. Moreover, the RSR results demonstrate that, upon reducing the CSI feedback delays, the reliability improves more substantially than the security degrades, implying an overall improvement in terms of the security-reliability tradeoff. Additionally, the secrecy throughput loss due to the second-hop feedback delay is more pronounced than that due to the first-hop one.","Relays,
Jamming,
Security,
Reliability,
Signal to noise ratio,
Throughput,
Delays"
Saving Energy in Partially Deployed Software Defined Networks,"As power consumption of the Internet has been growing quickly in recent years, saving energy has become an important problem of networking research, for which the most promising solution is to find the minimum-power network subsets and shut down other unnecessary network devices and links to satisfy changing traffic loads. However, in traditional networks, it is difficult to implement a coordinated strategy among the network devices due to their distributed network control. On the other hand, the new networking paradigm-software defined network (SDN) provides us an efficient way of having a centralized controller with a global network view to control the power states. As an emerging technology, SDNs usually coexist with traditional networks at present. Therefore, we need to investigate how to save energy in partially deployed SDNs. In this paper, we formulate the optimization problem of finding minimum-power network subsets in partially deployed SDNs. After proving the problem is NP-hard, we propose a heuristic solution to approach its exact solution. Through extensive simulations, we demonstrate that our heuristic algorithm has a good performance; that is, on average we can save about 50 percent of total power consumption in the full SDN, having a distance less than 5 percent of the exact solution's power consumption. Moreover, it also achieves good performance in the partially deployed SDN, on average saving about 40 percent of the total power consumption when there are about 60 percent SDN nodes in the network. Meanwhile, it runs significantly faster than a general linear solver of this problem, by reducing the computation time of the network containing hundreds of nodes by 100× at least.",
Adopting Abstract Images for Semantic Scene Understanding,"Relating visual information to its linguistic semantic meaning remains an open and challenging area of research. The semantic meaning of images depends on the presence of objects, their attributes and their relations to other objects. But precisely characterizing this dependence requires extracting complex visual information from an image, which is in general a difficult and yet unsolved problem. In this paper, we propose studying semantic information in abstract images created from collections of clip art. Abstract images provide several advantages over real images. They allow for the direct study of how to infer high-level semantic information, since they remove the reliance on noisy low-level object, attribute and relation detectors, or the tedious hand-labeling of real images. Importantly, abstract images also allow the ability to generate sets of semantically similar scenes. Finding analogous sets of real images that are semantically similar would be nearly impossible. We create 1,002 sets of 10 semantically similar abstract images with corresponding written descriptions. We thoroughly analyze this dataset to discover semantically important features, the relations of words to visual features and methods for measuring semantic similarity. Finally, we study the relation between the saliency and memorability of objects and their semantic importance.","Semantics,
Abstracts,
Visualization,
Art,
Speech,
Mutual information,
Feature extraction"
An Analytical Framework for Evaluating Spectrum/Energy Efficiency of Heterogeneous Cellular Networks,"Achieving high spectrum efficiency (SE) and energy efficiency (EE) is of primary importance for the sustainability of future cellular networks, but a key challenge is on balancing the tradeoff that arises when maximizing both of these performance metrics simultaneously. This paper develops a framework for analyzing the SE and EE of a two-tier heterogeneous cellular network consisting of macrocell and femtocell base stations (BSs) operating under a shared-spectrum scenario. It is shown that both the SE and the EE can be significantly enhanced with the overlaid deployment of the femto tier. However, the performance gain achievable is found to be strongly dependent on the load level and the BS power consumption attributes. A multiobjective optimization problem that maximizes the SE and the EE subject to quality-of-service (QoS) constraints is formulated and solved to give the Pareto-optimal operational regime. The novelty of this work is the quantification of the SE-EE tradeoff as a Lebesgue measure, which is defined by the Pareto-optimal regime. The developed framework is useful for studying the impact of the load on the SE-EE tradeoff, based on a strategy that exploits the varying load conditions to achieve good balance in the SE-EE tradeoff is formulated. Numerical results show that, while the improvement achieved in minimizing the SE-EE performance gap is marginal under high-load conditions, it is feasible to significantly increase the SE and the EE during low-load conditions and satisfy the users' QoS requirements by optimally adapting the density of the femto-tier BSs accessing the shared spectrum.","Throughput,
Interference,
Macrocell networks,
Signal to noise ratio,
Quality of service,
Analytical models,
Measurement"
Distributed Model Predictive Control for Smart Energy Systems,"Integration of a large number of flexible consumers in a smart grid requires a scalable power balancing strategy. We formulate the control problem as an optimization problem to be solved repeatedly by the aggregator in a model predictive control framework. To solve the large-scale control problem in real-time requires decomposition methods. We propose a decomposition method based on Douglas-Rachford splitting to solve this large-scale control problem. The method decomposes the problem into smaller subproblems that can be solved in parallel, e.g., locally by each unit connected to an aggregator. The total power consumption is controlled through a negotiation procedure between all cooperating units and an aggregator that coordinates the overall objective. For large-scale systems, this method is faster than solving the original problem and can be distributed to include an arbitrary number of units. We show how different aggregator objectives are implemented and provide simulations of the controller including the computational performance.","Real-time systems,
Power demand,
Optimization,
Power markets,
Predictive control,
Linear programming,
Heat pumps"
Indistinguishability Obfuscation from DDH-Like Assumptions on Constant-Degree Graded Encodings,"All constructions of general purpose indistinguishability obfuscation (IO) rely on either meta-assumptions that encapsulate an exponential family of assumptions (e.g., Pass, Seth and Telang, CRYPTO 2014 and Lin, EUROCRYPT 2016), or polynomial families of assumptions on graded encoding schemes with a high polynomial degree/multilinearity (e.g., Gentry, Lewko, Sahai and Waters, FOCS 2014). We present a new construction of IO, with a security reduction based on two assumptions: (a) a DDH-like assumption - called the sSXDH assumption - on constant degree graded encodings, and (b) the existence of polynomial-stretch pseudorandom generators (PRG) in NC0. Our assumption on graded encodings is simple, has constant size, and does not require handling composite-order rings. This narrows the gap between the mathematical objects that exist (bilinear maps, from elliptic curve groups) and ones that suffice to construct general purpose indistinguishability obfuscation.","Encoding,
Cryptography,
Generators,
Complexity theory,
Noise measurement,
Electronic mail"
Internet of Drones,"The Internet of Drones (IoD) is a layered network control architecture designed mainly for coordinating the access of unmanned aerial vehicles to controlled airspace, and providing navigation services between locations referred to as nodes. The IoD provides generic services for various drone applications, such as package delivery, traffic surveillance, search and rescue, and more. In this paper, we present a conceptual model of how such an architecture can be organized and we specify the features that an IoD system based on our architecture should implement. For doing so, we extract key concepts from three existing large scale networks, namely the air traffic control network, the cellular network, and the Internet, and explore their connections to our novel architecture for drone traffic management. A simulation platform for IoD is being implemented, which can be accessed from www.IoDnet.org in the future.","Internet of things,
Drones,
Network architecture,
Internet,
Navigation,
Atmospheric modeling,
Surveillance,
Traffic control"
A Survey of Traffic Issues in Machine-to-Machine Communications Over LTE,"Machine-to-machine (M2M) communication, also referred to as Internet of Things (IoT), is a global network of devices such as sensors, actuators, and smart appliances which collect information, and can be controlled and managed in real time over the Internet. Due to their universal coverage, cellular networks and the Internet together offer the most promising foundation for the implementation of M2M communication. With the worldwide deployment of the fourth generation (4G) of cellular networks, the long-term evolution (LTE) and LTE-advanced standards have defined several quality-of-service classes to accommodate the M2M traffic. However, cellular networks are mainly optimized for human-to-human (H2H) communication. The characteristics of M2M traffic are different from the human-generated traffic and consequently create sever problems in both radio access and the core networks (CNs). This survey on M2M communication in LTE/LTE-A explores the issues, solutions, and the remaining challenges to enable and improve M2M communication over cellular networks. We first present an overview of the LTE networks and discuss the issues related to M2M applications on LTE. We investigate the traffic issues of M2M communications and the challenges they impose on both access channel and traffic channel of a radio access network and the congestion problems they create in the CN. We present a comprehensive review of the solutions for these problems which have been proposed in the literature in recent years and discuss the advantages and disadvantages of each method. The remaining challenges are also discussed in detail.","Long Term Evolution,
Uplink,
Downlink,
Radio access networks,
Internet of things,
Telecommunication traffic,
Machine-to-machine communications"
Mobile Biplane X-Ray Imaging System for Measuring 3D Dynamic Joint Motion During Overground Gait,"Most X-ray fluoroscopy systems are stationary and impose restrictions on the measurement of dynamic joint motion; for example, knee-joint kinematics during gait is usually measured with the subject ambulating on a treadmill. We developed a computer-controlled, mobile, biplane, X-ray fluoroscopy system to track human body movement for high-speed imaging of 3D joint motion during overground gait. A robotic gantry mechanism translates the two X-ray units alongside the subject, tracking and imaging the joint of interest as the subject moves. The main aim of the present study was to determine the accuracy with which the mobile imaging system measures 3D knee-joint kinematics during walking. In vitro experiments were performed to measure the relative positions of the tibia and femur in an intact human cadaver knee and of the tibial and femoral components of a total knee arthroplasty (TKA) implant during simulated overground gait. Accuracy was determined by calculating mean, standard deviation and root-mean-squared errors from differences between kinematic measurements obtained using volumetric models of the bones and TKA components and reference measurements obtained from metal beads embedded in the bones. Measurement accuracy was enhanced by the ability to track and image the joint concurrently. Maximum root-mean-squared errors were 0.33 mm and 0.65° for translations and rotations of the TKA knee and 0.78 mm and 0.77° for translations and rotations of the intact knee, which are comparable to results reported for treadmill walking using stationary biplane systems. System capability for in vivo joint motion measurement was also demonstrated for overground gait.","Joints,
X-ray imaging,
Knee,
Legged locomotion,
Bones,
Target tracking"
A Comprehensive Review of Smart Energy Meters in Intelligent Energy Networks,"The significant increase in energy consumption and the rapid development of renewable energy, such as solar power and wind power, have brought huge challenges to energy security and the environment, which, in the meantime, stimulate the development of energy networks toward a more intelligent direction. Smart meters are the most fundamental components in the intelligent energy networks (IENs). In addition to measuring energy flows, smart energy meters can exchange the information on energy consumption and the status of energy networks between utility companies and consumers. Furthermore, smart energy meters can also be used to monitor and control home appliances and other devices according to the individual consumer's instruction. This paper systematically reviews the development and deployment of smart energy meters, including smart electricity meters, smart heat meters, and smart gas meters. By examining various functions and applications of smart energy meters, as well as associated benefits and costs, this paper provides insights and guidelines regarding the future development of smart meters.","Resistance heating,
Smart meters,
Energy consumption,
Smart grids,
DH-HEMTs"
Energy-Aware and Bandwidth-Efficient Hybrid Video Streaming Over Mobile Networks,"Current cellular networks support video streaming over unicast or multicast. However, there exists a tradeoff between utilizing the two: i) unicast leads to higher network load, but lower energy consumption of mobile devices, and ii) multicast results in lower network load, but higher energy consumption. To make the best out of both, we propose to concurrently utilize unicast and multicast for minimizing the energy consumption of mobile devices and minimizing the load on cellular networks. Cellular networks support two multicast schemes: i) independent cell networks and ii) multi-cell single frequency networks, where multiple adjacent base stations operate on the same frequency. We first consider the less-complicated independent cell networks, and then extend our solution to single frequency networks for better performance. We formulate the resource allocation in hybrid multicast -unicast streaming systems as a binary integer programming problem. We describe optimal algorithms for the two multicast schemes. We then propose two efficient, heuristic, algorithms that run faster and provide close to optimal results. While our solution is general, for concreteness, we conduct detailed LTE packet-level simulations using OPNET. Our simulation results show the proposed algorithms i) scale to many more mobile devices than the state-of-the-art unicast-only approaches and ii) result in lower energy consumption than the latest multicast-only approaches. In addition, the algorithms designed for multi-cell single frequency networks outperform the algorithms designed for independent cell networks in all aspects, such as service ratio, spectral efficiency, energy saving, video quality, frame loss rate, initial buffering time, and number of re-buffering events.",
Proposal for an All-Spin Artificial Neural Network: Emulating Neural and Synaptic Functionalities Through Domain Wall Motion in Ferromagnets,"Non-Boolean computing based on emerging postCMOS technologies can potentially pave the way for low-power neural computing platforms. However, existing work on such emerging neuromorphic architectures have either focused on solely mimicking the neuron, or the synapse functionality. While memristive devices have been proposed to emulate biological synapses, spintronic devices have proved to be efficient at performing the thresholding operation of the neuron at ultra-low currents. In this work, we propose an All-Spin Artificial Neural Network where a single spintronic device acts as the basic building block of the system. The device offers a direct mapping to synapse and neuron functionalities in the brain while inter-layer network communication is accomplished via CMOS transistors. To the best of our knowledge, this is the first demonstration of a neural architecture where a single nanoelectronic device is able to mimic both neurons and synapses. The ultra-low voltage operation of low resistance magneto-metallic neurons enables the low-voltage operation of the array of spintronic synapses, thereby leading to ultra-low power neural architectures. Device-level simulations, calibrated to experimental results, was used to drive the circuit and system level simulations of the neural network for a standard pattern recognition problem. Simulation studies indicate energy savings by ~400× in comparison to a corresponding digital/ analog CMOS neuron implementation.","Neuromorphics,
Magnetoelectronics,
Artificial neural networks,
Spintronics,
CMOS integrated circuits,
Magnetic domains"
Cooling-Aware Energy and Workload Management in Data Centers via Stochastic Optimization,"While the quest of end users for fast and convenient Internet services grows steadily, energy-hungry data centers correspondingly expand in both numbers and scale - a fact that raises global warming and climate change concerns. In addition, high penetration of renewables, development of energy-efficient cooling facilities, and flexibility of distributed storage units, all call for a system-wide energy and workload management policy for future sustainable data centers. As implementing offline management policies is practically infeasible due to complexity and the lack of future information, real-time management schemes are considered here under a systematic framework. Leveraging stochastic optimization tools, a unified management approach is proposed allowing data centers to adaptively respond to intermittent availability of renewables, variability of cooling efficiency, information technology (IT) workload shift, and energy price fluctuations under long-term quality-of-service (QoS) requirements. Meanwhile, it is rigorously established that when storage devices have sufficiently high capacity, or, the difference between electricity purchase and selling prices is small, the proposed algorithm yields a feasible and near-optimal management strategy without knowing the distributions of the independently and identically distributed (i.i.d.) workload, renewable, and electricity price processes. Numerical results further demonstrate that the proposed algorithm works well not only for i.i.d. processes, but also in real-data scenarios, where the underlying randomness is highly correlated over time.",
A Two-Body Rigid/Flexible Model of Needle Steering Dynamics in Soft Tissue,"Robotics-assisted needle steering can enhance targeting accuracy in percutaneous interventions. This paper presents a novel dynamical model for robotically controlled needle steering. This is the first model that predicts both needle shape and tip position in soft tissue, and accepts needle insertion velocity, needle 180° axial rotation, and needle base force/torque as inputs. A hybrid formulation of needle steering dynamics in soft tissue is presented, which considers the needle as a two-body rigid/flexible coupled system composed of a moving, discrete, and rigid part attached to a vibrating compliant part that is subject to external excitation forces. The former is the carrier representing the surgeon's hand or the needle inserting robot, while the latter is a beam modeling the continuous deflection of the needle inside tissue. A novel time-delayed tissue model and a fracture mechanics-based model are developed to model the tissue reaction forces and cutting force at the needle tip, respectively. Experiments are performed on synthetic and ex vivo animal tissues to identify the model parameters and validate the needle steering model. The maximum error of the 2-D model in predicting the needle tip position in the insertion plane was 1.59 mm in the case of no axial rotation and 0.74 mm with axial rotation.",
Mining High Utility Patterns in One Phase without Generating Candidates,"Utility mining is a new development of data mining technology. Among utility mining problems, utility mining with the itemset share framework is a hard one as no anti-monotonicity property holds with the interestingness measure. Prior works on this problem all employ a two-phase, candidate generation approach with one exception that is however inefficient and not scalable with large databases. The two-phase approach suffers from scalability issue due to the huge number of candidates. This paper proposes a novel algorithm that finds high utility patterns in a single phase without generating candidates. The novelties lie in a high utility pattern growth approach, a lookahead strategy, and a linear data structure. Concretely, our pattern growth approach is to search a reverse set enumeration tree and to prune search space by utility upper bounding. We also look ahead to identify high utility patterns without enumeration by a closure property and a singleton property. Our linear data structure enables us to compute a tight bound for powerful pruning and to directly identify high utility patterns in an efficient and scalable way, which targets the root cause with prior algorithms. Extensive experiments on sparse and dense, synthetic and real world data suggest that our algorithm is up to 1 to 3 orders of magnitude more efficient and is more scalable than the state-of-the-art algorithms.","Data mining,
Itemsets,
Data structures,
Scalability,
Knowledge engineering,
Data engineering"
Power-Delay Tradeoff With Predictive Scheduling in Integrated Cellular and Wi-Fi Networks,"The explosive growth of global mobile traffic has led to rapid growth in the energy consumption in communication networks. In this paper, we focus on the energy-aware design of the network selection, subchannel, and power allocation in cellular and Wi-Fi networks, while taking into account the traffic delay of mobile users. Based on the two-timescale Lyapunov optimization technique, we first design an online Energy-Aware Network Selection and Resource Allocation (ENSRA) algorithm, which yields a power consumption within O(1/V)bound of the optimal value, and guarantees an O(V) traffic delay for any positive control parameter V. Motivated by the recent advancement in the accurate estimation and prediction of user mobility, channel conditions, and traffic demands, we further develop a novel predictive Lyapunov optimization technique to utilize the predictive information, and propose a Predictive Energy-Aware Network Selection and Resource Allocation (P-ENSRA) algorithm. We characterize the performance bounds of P-ENSRA in terms of the power-delay tradeoff theoretically. To reduce the computational complexity, we finally propose a Greedy Predictive Energy-Aware Network Selection and Resource Allocation (GP-ENSRA) algorithm, where the operator solves the problem in P-ENSRA approximately and iteratively. Numerical results show that GP-ENSRA significantly improves the power-delay performance over ENSRA in the large delay regime. For a wide range of system parameters, GP-ENSRA reduces the traffic delay over ENSRA by 20-30% under the same power consumption.","Resource management,
IEEE 802.11 Standard,
Macrocell networks,
Delays,
Optimization,
Prediction algorithms,
Power demand"
Joint Optimization of Task Scheduling and Image Placement in Fog Computing Supported Software-Defined Embedded System,"Traditional standalone embedded system is limited in their functionality, flexibility, and scalability. Fog computing platform, characterized by pushing the cloud services to the network edge, is a promising solution to support and strengthen traditional embedded system. Resource management is always a critical issue to the system performance. In this paper, we consider a fog computing supported software-defined embedded system, where task images lay in the storage server while computations can be conducted on either embedded device or a computation server. It is significant to design an efficient task scheduling and resource management strategy with minimized task completion time for promoting the user experience. To this end, three issues are investigated in this paper: 1) how to balance the workload on a client device and computation servers, i.e., task scheduling, 2) how to place task images on storage servers, i.e., resource management, and 3) how to balance the I/O interrupt requests among the storage servers. They are jointly considered and formulated as a mixed-integer nonlinear programming problem. To deal with its high computation complexity, a computation-efficient solution is proposed based on our formulation and validated by extensive simulation based studies.","Servers,
Embedded systems,
Processor scheduling,
Image edge detection,
Resource management,
Minimization,
Fog computing"
A Two-Stage Data-Driven-Based Prognostic Approach for Bearing Degradation Problem,"Prognostics of the remaining useful life (RUL) has emerged as a critical technique for ensuring the safety, availability, and efficiency of a complex system. To gain a better prognostic result, degradation information is quite useful because it can reflect the health status of a system. However, due to the lack of accurate information about the plants' degradation, the prognostic model is usually not well established. To solve this problem, this paper proposes a two-stage strategy that is in the context of data-driven modeling to predict the future health status of a bearing, where the degradation information was estimated by calculating the deviation of multiple statistics of vibration signals of a bearing from a known healthy state. Then, a prediction stage based on an enhanced Kalman filter and an expectation-maximization algorithm were used to estimate the RUL of the bearing adaptively. To verify the effectiveness of the proposed approach, a real-bearing degradation problem was implemented.",
Authentication and Authorization Scheme for Various User Roles and Devices in Smart Grid,"The smart grid, as the next generation of the power grid, is characterized by employing many different types of intelligent devices, such as intelligent electronic devices located at substations, smart meters positioned in the home area network, and outdoor field equipment deployed in the fields. In addition, there are various users in the smart grid network, including customers, operators, maintenance personnel, and so on, who use these devices for various purposes. Therefore, a secure and efficient mutual authentication and authorization scheme is needed in the smart grid to prevent various insider and outsider attacks on many different devices. In this paper, we propose an authentication and authorization scheme for mitigating outsider and insider threats in the smart grid by verifying the user authorization and performing the user authentication together whenever a user accesses the devices. The proposed scheme computes each user role dynamically using an attribute-based access control and verifies the identity of the user together with the device. Security and performance analysis show that the proposed scheme resists various insider as well as outsider attacks, and is more efficient in terms of communication and computation costs in comparison with the existing schemes. The correctness of the proposed scheme is also proved using BAN-Logic and Proverif.","Authentication,
Smart grids,
Authorization,
Protocols,
Maintenance engineering,
Substations"
Cryptographic Hierarchical Access Control for Dynamic Structures,"A hierarchical key assignment scheme is a method to assign some private information and encryption keys to a set of classes in a partially ordered hierarchy, in such a way that the private information of a higher class can be used to derive the keys of all classes lower down in the hierarchy. Sometimes, it is necessary to make dynamic updates to the hierarchy, in order to implement an access control policy which evolves with time. All security models for hierarchical key assignment schemes have been designed to cope with static hierarchies and do not consider the issue of performing dynamic updates to the hierarchy. In this paper, we define the concept of hierarchical key assignment schemes supporting dynamic updates, formalizing the relative security model. In particular, we provide the notion of security with respect to key indistinguishability, by considering the dynamic changes to the hierarchy. Moreover, we show how to construct a hierarchical key assignment scheme supporting dynamic updates, by using as a building block a symmetric encryption scheme. The proposed construction is provably secure with respect to key indistinguishability, and provides efficient key derivation and updating procedures, while requiring each user to store only a single private key.","Access control,
Internet of things,
Encryption,
Medical services,
Context,
Sensors"
Profiling Online Social Behaviors for Compromised Account Detection,"Account compromization is a serious threat to users of online social networks (OSNs). While relentless spammers exploit the established trust relationships between account owners and their friends to efficiently spread malicious spam, timely detection of compromised accounts is quite challenging due to the well established trust relationship between the service providers, account owners, and their friends. In this paper, we study the social behaviors of OSN users, i.e., their usage of OSN services, and the application of which in detecting the compromised accounts. In particular, we propose a set of social behavioral features that can effectively characterize the user social activities on OSNs. We validate the efficacy of these behavioral features by collecting and analyzing real user clickstreams to an OSN website. Based on our measurement study, we devise individual user's social behavioral profile by combining its respective behavioral feature metrics. A social behavioral profile accurately reflects a user's OSN activity patterns. While an authentic owner conforms to its account's social behavioral profile involuntarily, it is hard and costly for impostors to feign. We evaluate the capability of the social behavioral profiles in distinguishing different OSN users, and our experimental results show the social behavioral profiles can accurately differentiate individual OSN users and detect compromised accounts.","Facebook,
Feature extraction,
Measurement,
Navigation,
Uniform resource locators,
Browsers,
Accuracy"
On Networking of Internet of Things: Explorations and Challenges,"Internet of Things (IoT), as the trend of future networks, begins to be used in many aspects of daily life. It is of great significance to recognize the networking problem behind developing IoT. In this paper, we first analyze and point out the key problem of IoT from the perspective of networking: how to interconnect large-scale heterogeneous network elements and exchange data efficiently. Combining our on-going works, we present some research progresses on three main aspects: 1) the basic model of IoT architecture; 2) the internetworking model; and 3) the sensor-networking mode. Finally, we discuss two remaining challenges in this area.",
Multi-Armed Bandit Channel Access Scheme With Cognitive Radio Technology in Wireless Sensor Networks for the Internet of Things,"The wireless sensor network (WSN) is one of the key enablers for the Internet of Things (IoT), where WSNs will play an important role in future internet by several application scenarios, such as healthcare, agriculture, environment monitoring, and smart metering. However, today's radio spectrum is very crowded for the rapid increasing popularities of various wireless applications. Hence, WSN utilizing the advantages of cognitive radio technology, namely, cognitive radio-based WSN (CR-WSN), is a promising solution for spectrum scarcity problem of IoT applications. A major challenge in CR-WSN is utilizing spectrum more efficiently. Therefore, a novel channel access scheme is proposed for the problem that how to access the multiple channels with the unknown environment information for cognitive users, so as to maximize system throughput. The problem is modeled as I.I.D. multi-armed bandit model with M cognitive users and N arms (M<;N). In order to solve the competition and the fairness between cognitive users of WSNs, a fair channel-grouping scheme is proposed. The proposed scheme divides these channels into M groups according to the water-filling principle based on the learning algorithm UCB-K index, the number of channels not less than one in each group and then allocate channel group for each cognitive user by using distributed learning algorithm fairly. Finally, the experimental results demonstrate that the proposed scheme cannot only effectively solve the problem of collision between the cognitive users, improve the utilization rate of the idle spectrum, and at the same time reflect the fairness of selecting channels between cognitive users.","Internet of things,
Wireless sensor networks,
Cognitive radio,
Medical services,
Agriculture"
A New Hybrid Boosting Converter for Renewable Energy Applications,"A hybrid boosting converter (HBC) with collective advantages of regulation capability from its boost structure and gain enhancement from its voltage multiplier structure is proposed in this paper. The new converter incorporates a bipolar voltage multiplier, featuring symmetrical configuration, single inductor and single switch, high gain capability with wide regulation range, low component stress, small output ripple and flexible extension, which make it suitable for front-end PV system and some other renewable energy applications. The operation principal, component stress, and voltage ripple are analyzed in this paper. Performance comparison and evaluation with a number of previous single-switch single-inductor converters are provided. A 200-W 35 to 380 V second-order HBC prototype was built with peak efficiency at 95.44%. The experimental results confirms the feasibility of the proposed converter.",
Developing Route Optimization-Based PMIPv6 Testbed for Reliable Packet Transmission,"Proxy Mobile IPv6 (PMIPv6) allows a mobile node to communicate directly to its peers while changing the currently used IP address. This mode of operation is called route optimization (RO). In the RO process, the peer node learns a binding between the home address and its current temporary care-of-address. Many schemes have been proposed to support RO in PMIPv6. However, these schemes do not consider the out-of-sequence problem, which may happen between the existing path and the newly established RO path. In this paper, we propose a scheme to solve the out-of-sequence problem with low cost. In our scheme, we use the additional packet sequence number and the time information when the problem occurs. We then run experiments on a reliable packet transmission (RPT) laboratory testbed to evaluate the performance of the proposed scheme, and compare it with the well-known RO-supported PMIPv6 and the out-of-sequence time period scheme. The experimental results show that for most of the cases, our proposed scheme guarantees RPT by preventing the out-of-sequence problem.","Mobile communication,
Mobile nodes,
Route optimization,
Current estimation,
Sequential analysis"
Spectral Matrix Decomposition-Based Motion Artifacts Removal in Multi-Channel PPG Sensor Signals,"The intelligent wearable heart rate measurement requirement has attracted more and more attention, and the related applications of Internet of Things are emerging. However, under intensive physical exercises, motion artifacts are strong interference sources for wrist-type photoplethysmography (PPG) sensor signals, thus significantly affecting the accurate estimation of heart rate and other physiological parameters. Currently, how to effectively remove the motion artifacts from PPG sensor signals is becoming an active and challenging research realm. In this paper, we propose a multi-channel spectral matrix decomposition (MC-SMD) model to accurately estimate heart rate in the presence of intensive physical activities. Motivated by the observation that the PPG signal spectrum and the acceleration spectrum have almost the same spectral peak positions in the frequency domain, we first model the removal of motion artifacts as a spectral matrix decomposition optimization problem. After removing motion artifacts, we propose a new spectral peak tracking method for estimating heart rate. Experimental results on the well-known PPG data sets recorded from 12 subjects during intensive movements demonstrate that MC-SMD can efficiently remove the motion artifacts and retrieve an accurate heart rate using multi-channel PPG sensor signals.","Heart rate,
Acceleration,
Sparse matrices,
Matrix decomposition,
Estimation,
Tracking"
Performance Enhancement of Black Phosphorus Field-Effect Transistors by Chemical Doping,"In this letter, a new approach to chemically dope black phosphorus (BP) is presented, which significantly enhances the device performance of BP field-effect transistors for an initial period of 18 h, before degrading to previously reported levels. By applying 2,3,5,6-tetrafluoro-7,7,8,8-tetracyanoquinodimethane (F4-TCNQ), low ON-state resistance of 3.2 Ω · mm and high field-effect mobility of 229 cm2/Vs are achieved with a record high drain current of 532 mA/mm at a moderate channel length of 1.5 μm.","Doping,
Resistance,
Field effect transistors,
Contact resistance,
Performance evaluation,
Phosphorus"
Wildcard Rules Caching and Cache Replacement Algorithms in Software-Defined Networking,"In software-defined networking, flow tables of OpenFlow switches are implemented by ternary content addressable memory (TCAM). Although TCAM can process input packets in high speed, it is a scarce and expensive resource providing only a few thousands of rule entries on a network switch. Rules caching is a technique to solve the TCAM capacity problem. However, the rule dependency problem is a challenging issue for wildcard rules caching where packets can mismatch rules. In this paper, we use a cover-set approach to solve the rule dependency problem and cache important rules to TCAM. We also propose a rule cache replacement algorithm considering the temporal and spatial traffic localities. Simulation results show that our algorithms have better cache hit ratio than previous works.","Algorithm design and analysis,
Routing,
Safety,
Bandwidth,
Weaving,
Simulation,
Routing protocols"
Distributed MPC for Efficient Coordination of Storage and Renewable Energy Sources Across Control Areas,"In electric power systems, multiple entities are responsible for ensuring an economic and reliable way of delivering power from producers to consumers. With the increase of variable renewable generation it is becoming increasingly important to take advantage of the individual entities' (and their areas') capabilities for balancing variability. Hence, in this paper, we employ and extend the approximate Newton directions method to optimally coordinate control areas leveraging storage available in one area to balance variable resources in another area with only minimal information exchange among the areas. The problem to be decomposed is a model predictive control problem including generation constraints, energy storage constraints, and AC power flow constraints. Singularity issues encountered when formulating the respective Newton-Raphson steps due to intertemporal constraints are addressed and extensions to the original decomposition method are proposed to improve the convergence rate and required communication of the method.",
SeCoMan: A Semantic-Aware Policy Framework for Developing Privacy-Preserving and Context-Aware Smart Applications,"This paper is intended to provide a solution for developing context-aware smart applications preserving the users' privacy in the Internet of Things (IoT). In this sense, we present a framework called Semantic Web-based Context Management (SeCoMan) aimed at offering a set of predefined queries to provide applications with information about indoor location of users and objects, as well as context-aware services. SeCoMan uses a semantic-oriented IoT vision where semantic technologies play a key role. In fact, SeCoMan uses Semantic Web for modeling description of things, reasoning over data to infer new knowledge, and defining context-aware policies. SeCoMan also defines a layered architecture, including functions related to the management of the users' privacy in a manner that accommodate IoT requirements, in addition to not affecting system performance nor introducing excessive overheads. A thorough discussion on other related works, together with some experiments to measure the throughput and scalability, confirm that SeCoMan is a solution that improves the most relevant proposals existing so far.","Context,
Ontologies,
Privacy,
Semantics,
Authorization,
Middleware,
Shape"
Analog-to-Stochastic Converter Using Magnetic Tunnel Junction Devices for Vision Chips,"This paper introduces an analog-to-stochastic converter using a magnetic tunnel junction (MTJ) device for vision chips based on stochastic computation. Stochastic computation has been recently exploited for area-efficient hardware implementation, such as low-density parity-check decoders and image processors. However, power-and-area hungry two-step (analog-to-digital and digital-to-stochastic) converters are required for the analog to stochastic signal conversion. To realize a one-step conversion, an MTJ device is used as it inherently exhibits a probabilistic switching behavior between two resistance states. Exploiting the device-based probabilistic behavior, analog signals can be directly and area efficiently converted to stochastic signals to mitigate the signal-conversion overhead. The analog-to-stochastic signal conversion is theoretically described and the conversion characteristic is evaluated using device and circuit parameters. In addition, the resistance variability of the MTJ device is considered in order to compensate the variability effect on the signal conversion. Based on the theoretical analysis, the analog-to-stochastic converter is designed in 90-nm CMOS and 100-nm MTJ technologies and is verified using a SPICE simulator (NS-SPICE) that handles both transistors and MTJ devices.","Magnetic tunneling,
Probabilistic logic,
Switches,
Resistance,
Integrated circuits,
Image sensors,
Hardware"
Millimeter Wave Networked Wearables in Dense Indoor Environments,"Supporting high data rate wireless connectivity among wearable devices in a dense indoor environment is challenging. This is primarily due to bandwidth scarcity when many users operate multiple devices simultaneously. The millimeter-wave (mmWave) band has the potential to address this bottleneck, thanks to more spectrum and less interference because of signal blockage at these frequencies. In this paper, we explain the potential and challenges associated with using mmWave for wearable networks. To provide a means for concrete analysis, we present a system model that admits easy analysis of dense, indoor mmWave wearable networks. We evaluate the performance of the system while considering the unique propagation features at mmWave frequencies, such as human body blockages and reflections from walls. One conclusion is that the non-isotropy of the surroundings relative to a reference user causes variations in system performance depending on the user location, body orientation, and density of the network. The impact of using antenna arrays is quantified through analytic closed-form expressions that incorporate antenna gain and directivity. It is shown that using directional antennas, positioning the transceiver devices appropriately, and orienting the human user body in certain directions depending on the user location result in gigabits-per-second achievable ergodic rates for mmWave wearable networks.","Wireless communication,
Wearable computing,
Indoor environments,
Antenna arrays,
Bandwidth allocation,
Analytical models,
Inteference (signal),
Millimeter wave communication"
Flexible and Low-Complexity Encoding and Decoding of Systematic Polar Codes,"In this paper, we present hardware and software implementations of flexible polar systematic encoders and decoders. The proposed implementations operate on polar codes of any length less than a maximum and of any rate. We describe the low-complexity, highly parallel, and flexible systematic-encoding algorithm that we use and prove its correctness. Our hardware implementation results show that the overhead of adding code rate and length flexibility is little, and the impact on operation latency minor compared with code-specific versions. Finally, the flexible software encoder and decoder implementations are also shown to be able to maintain high throughput and low latency.","Systematics,
Encoding,
Decoding,
Software algorithms,
Hardware,
Software,
Throughput"
Low Resolution Face Recognition Across Variations in Pose and Illumination,"We propose a completely automatic approach for recognizing low resolution face images captured in uncontrolled environment. The approach uses multidimensional scaling to learn a common transformation matrix for the entire face which simultaneously transforms the facial features of the low resolution and the high resolution training images such that the distance between them approximates the distance had both the images been captured under the same controlled imaging conditions. Stereo matching cost is used to obtain the similarity of two images in the transformed space. Though this gives very good recognition performance, the time taken for computing the stereo matching cost is significant. To overcome this limitation, we propose a reference-based approach in which each face image is represented by its stereo matching cost from a few reference images. Experimental evaluation on the real world challenging databases and comparison with the state-of-the-art super-resolution, classifier based and cross modal synthesis techniques show the effectiveness of the proposed algorithm.",
Low-Power ECG-Based Processor for Predicting Ventricular Arrhythmia,"This paper presents the design of a fully integrated electrocardiogram (ECG) signal processor (ESP) for the prediction of ventricular arrhythmia using a unique set of ECG features and a naive Bayes classifier. Real-time and adaptive techniques for the detection and the delineation of the P-QRS-T waves were investigated to extract the fiducial points. Those techniques are robust to any variations in the ECG signal with high sensitivity and precision. Two databases of the heart signal recordings from the MIT PhysioNet and the American Heart Association were used as a validation set to evaluate the performance of the processor. Based on application-specified integrated circuit (ASIC) simulation results, the overall classification accuracy was found to be 86% on the out-of-sample validation data with 3-s window size. The architecture of the proposed ESP was implemented using 65-nm CMOS process. It occupied 0.112-mm2 area and consumed 2.78-μW power at an operating frequency of 10 kHz and from an operating voltage of 1 V. It is worth mentioning that the proposed ESP is the first ASIC implementation of an ECG-based processor that is used for the prediction of ventricular arrhythmia up to 3 h before the onset.",
Unified Compact Model Covering Drift-Diffusion to Ballistic Carrier Transport,"In this letter, we present a unified compact model, which accurately captures carrier transport from the drift-diffusion to ballistic regime. This is a single unified model, which accounts for carrier degeneracy effects in ballistic transport. The model is implemented into the industry standard compact models for FinFETs, fully depleted silicon-on-insulator (FDSOI) devices and bulk MOSFETs: 1) Berkeley Spice model for common multi-gate; 2) Berkeley Spice model for independent multi-gate; and 3) BSIM6. The model is validated with experimental data and TCAD simulations for FDSOI devices, FinFETs, and bulk MOSFETs.","Semiconductor device modeling,
Computational modeling,
FinFETs,
Data models"
Spiking Neural Network With Distributed Plasticity Reproduces Cerebellar Learning in Eye Blink Conditioning Paradigms,"Goal: In this study, we defined a realistic cerebellar model through the use of artificial spiking neural networks, testing it in computational simulations that reproduce associative motor tasks in multiple sessions of acquisition and extinction. Methods: By evolutionary algorithms, we tuned the cerebellar microcircuit to find out the near-optimal plasticity mechanism parameters that better reproduced human-like behavior in eye blink classical conditioning, one of the most extensively studied paradigms related to the cerebellum. We used two models: one with only the cortical plasticity and another including two additional plasticity sites at nuclear level. Results: First, both spiking cerebellar models were able to well reproduce the real human behaviors, in terms of both “timing” and “amplitude”, expressing rapid acquisition, stable late acquisition, rapid extinction, and faster reacquisition of an associative motor task. Even though the model with only the cortical plasticity site showed good learning capabilities, the model with distributed plasticity produced faster and more stable acquisition of conditioned responses in the reacquisition phase. This behavior is explained by the effect of the nuclear plasticities, which have slow dynamics and can express memory consolidation and saving. Conclusions: We showed how the spiking dynamics of multiple interactive neural mechanisms implicitly drive multiple essential components of complex learning processes. Significance: This study presents a very advanced computational model, developed together by biomedical engineers, computer scientists, and neuroscientists. Since its realistic features, the proposed model can provide confirmations and suggestions about neurophysiological and pathological hypotheses and can be used in challenging clinical applications.","Computational modeling,
Genetic algorithms,
Brain modeling,
Biological system modeling,
Protocols,
Sociology,
Statistics"
POST: Exploiting Dynamic Sociality for Mobile Advertising in Vehicular Networks,"Mobile advertising in vehicular networks is of great interest with which timely information can be fast spread into the network. Given a limited budget for hiring seed vehicles, how to achieve the maximum advertising coverage within a given period of time is NP-hard. In this paper, we propose an innovative scheme, POST, for mobile advertising in vehicular networks. The POST design is based on two key observations we have found by analyzing three large-scale vehicular traces. First, vehicles demonstrate dynamic sociality in the network; second, such vehicular sociality has strong temporal correlations. With the knowledge, POST uses Markov chains to infer future vehicular sociality and adopts two greedy heuristics to select the most “centric” vehicles as seeds for mobile advertising. Extensive simulations based on three real data sets of taxi and bus traces have been carried out. The results show that POSTcan greatly improve the coverage and the intensity of advertising. For all the three involved data sets, it achieves an average gain of 64 percent comparing with the state-of-art schemes.","Vehicles,
Advertising,
Mobile communication,
Public transportation,
Mobile computing,
Social network services,
Correlation"
Improved Fault-Tolerant Control for Brushless Permanent Magnet Motor Drives With Defective Hall Sensors,"Brushless permanent magnet motor drives based on Hall sensors have received significant attention in recent years. In this area, the faults of Hall sensors become a new concern and several fault-tolerant control (FTC) methods have been proposed. However, most of the state-of-the-art FTC methods require some time to reconstruct the correct Hall sensor signals, which results in significant transient currents and speed dip during fault diagnostic process (FDP). In this paper, a new and improved FTC scheme based on FDP and vector-tracking observer is proposed. A method to identify the duration of FDP is proposed based on the analysis of acceleration estimation and the fault diagnosis results. During FDP, the method defaults to an open-loop observer control, which removes the undesirable current/torque transient. After that, the close-loop observer is re-enabled and the motor operation is restored. The proposed FTC is demonstrated in detailed simulations and experimentally on 120° brushless dc motor drives and sinusoidal PM motor drives. For both types of drives, a significant improvement is achieved in steady state and transient operation with faults of up to two Hall sensors, which has not been possible with available alternative FTC approaches (unless a sensorless control is used).","Fault diagnosis,
Acceleration,
Magnetic sensors,
Permanent magnet motors,
Observers"
"BLISS: Balancing Performance, Fairness and Complexity in Memory Access Scheduling","In a multicore system, applications running on different cores interfere at main memory. This inter-application interference degrades overall system performance and unfairly slows down applications. Prior works have developed application-aware memory request schedulers to tackle this problem. State-of-the-art application-aware memory request schedulers prioritize memory requests of applications that are vulnerable to interference, by ranking individual applications based on their memory access characteristics and enforcing a total rank order. In this paper, we observe that state-of-the-art application-aware memory schedulers have two major shortcomings. First, such schedulers trade off hardware complexity in order to achieve high performance or fairness, since ranking applications individually with a total order based on memory access characteristics leads to high hardware cost and complexity. Such complexity could prevent the scheduler from meeting the stringent timing requirements of state-of-the-art DDR protocols. Second, ranking can unfairly slow down applications that are at the bottom of the ranking stack, thereby sometimes leading to high slowdowns and low overall system performance. To overcome these shortcomings, we propose the Blacklisting Memory Scheduler (BLISS), which achieves high system performance and fairness while incurring low hardware cost and complexity. BLISS design is based on two new observations. First, we find that, to mitigate interference, it is sufficient to separate applications into only two groups, one containing applications that are vulnerable to interference and another containing applications that cause interference, instead of ranking individual applications with a total order. Vulnerable-to-interference group is prioritized over the interference-causing group. Second, we show that this grouping can be efficiently performed by simply counting the number of consecutive requests served from each application. We evaluate BLISS across a wide variety of workloads and system configurations and compare its performance and hardware complexity (via RTL implementations), with five state-of-the-art memory schedulers. Our evaluations show that BLISS achieves 5 percent better system performance and 25 percent better fairness than the best-performing previous memory scheduler while greatly reducing critical path latency and hardware area cost of the memory scheduler (by 79 and 43 percent, respectively), thereby achieving a good trade-off between performance, fairness and hardware complexity.","Interference,
Complexity theory,
Hardware,
System performance,
Multicore processing,
Random access memory,
Scheduling"
Dynamic Demand Control of Electric Vehicles to Support Power Grid With High Penetration Level of Renewable Energy,"Electric vehicles (EVs) have become increasingly popular over the last few years and are considered as an important means to mitigate air pollution problems in big cities around the world. With their onboard batteries, EVs also present an opportunity to serve as a demand response tool in supporting future smart grid where there is usually high penetration level of renewable energy (RE) sources. In this study, a novel dynamic demand control (DDC) has been developed to coordinate the charging and discharging of EVs according to the frequency deviation signal to deal with intermittent RE generation. Furthermore, in our work, customers' requirements and satisfaction are strictly guaranteed through the introduction of a new term called Urgency Index. The merits of this scheme are its simplicity, efficiency, robustness, and readiness for practical applications. The effectiveness of the proposed control scheme is demonstrated by computer simulations of a power system with high penetration level of wind energy.","Vehicles,
Indexes,
Batteries,
Frequency control,
Vehicle dynamics,
Renewable energy sources"
Robust Stability of Switched Nonlinear Systems With Switching Uncertainties,"This technical note focuses on a class of switched nonlinear systems with unstable modes and switching uncertainties. Both prescribed switching instants and switching sequence of the nominal switching signal would change. Two novel indexes named time changing ratios and mode changing ratios are proposed, based on which several conditions that fully utilize the trade-off among stable and unstable modes are established to achieve the robust stability of the switched system. An example of multi-agent systems illustrates the efficiency of the new results.","Switches,
Uncertainty,
Switched systems,
Robust stability,
Upper bound,
Asymptotic stability,
Protocols"
Short-Packet Communications Over Multiple-Antenna Rayleigh-Fading Channels,"Motivated by the current interest in ultra-reliable, low-latency, machine-type communication systems, we investigate the tradeoff between reliability, throughput, and latency in the transmission of information over multiple-antenna Rayleigh block-fading channels. Specifically, we obtain finite-blocklength, finite-SNR upper and lower bounds on the maximum coding rate achievable over such channels for a given constraint on the packet error probability. Numerical evidence suggests that our bounds delimit tightly the maximum coding rate already for short blocklengths (packets of about 100 symbols). Furthermore, our bounds reveal the existence of a tradeoff between the rate gain obtainable by spreading each codeword over all available time-frequency-spatial degrees of freedom, and the rate loss caused by the need of estimating the fading coefficients over these degrees of freedom. In particular, our bounds allow us to determine the optimal number of transmit antennas and the optimal number of time-frequency diversity branches that maximize the rate. Finally, we show that infinite-blocklength performance metrics such as the ergodic capacity and the outage capacity yield inaccurate throughput estimates.","Fading,
Reliability,
Throughput,
Time-frequency analysis,
Mission critical systems,
Receivers,
Multiplexing"
Scalable Adaptive Spintronic Reconfigurable Logic Using Area-Matched MTJ Design,"Spin-transfer torque (STT) random access memory has been researched as a promising alternative for static random access memory in reconfigurable fabrics, particularly in lookup tables (LUTs), due to its nonvolatility, low standby and static power, and high integration density features. In this brief, we leverage physical characteristics of magnetic tunnel junctions (MTJs) to design a unique reference MTJ which has a calibrated resistance matching the STT-based LUT (STT-LUT) circuit requirements to provide optimal reading operation. Results obtained show 42% and 70% power-delay product (PDP) improvement over previous MTJ-based LUT designs. Moreover, a four-input adaptive STT-based LUT (A-LUT) is proposed based on the developed STT-LUT, which is configurable to function in seven independent modes. An n-input A-LUT exhibits PDP which can be a fraction of n-input STT-LUT PDP, when performing two-input to (n-1)-input Boolean logic functions.","Table lookup,
Magnetic tunneling,
Resistance,
Random access memory,
Power demand,
Fabrics,
Switches"
Monetary Cost Optimizations for Hosting Workflow-as-a-Service in IaaS Clouds,"Recently, we have witnessed workflows from science and other data-intensive applications emerging on Infrastructure-as-a-Service (IaaS) clouds, and many workflow service providers offering workflow-as-a-service (WaaS). The major concern of WaaS providers is to minimize the monetary cost of executing workflows in the IaaS clouds. The selection of virtual machines (instances) types significantly affects the monetary cost and performance of running a workflow. Moreover, IaaS cloud environment is dynamic, with high performance dynamics caused by the interference from concurrent executions and price dynamics like spot prices offered by Amazon EC2. Therefore, we argue that WaaS providers should have the notion of offering probabilistic performance guarantees for individual workflows to explicitly expose the performance and cost dynamics of IaaS clouds to users. We develop a scheduling system called Dyna to minimize the expected monetary cost given the user-specified probabilistic deadline guarantees. Dyna includes an A*-based instance configuration method for performance dynamics, and a hybrid instance configuration refinement for using spot instances. Experimental results with three scientific workflow applications on Amazon EC2 and a cloud simulator demonstrate (1) the ability of Dyna on satisfying the probabilistic deadline guarantees required by the users; (2) the effectiveness on reducing monetary cost in comparison with the existing approaches.","Probabilistic logic,
Optimization,
Cloud computing,
Dynamic scheduling,
Quality of service,
Heuristic algorithms,
Interference"
SenSpeed: Sensing Driving Conditions to Estimate Vehicle Speed in Urban Environments,"Acquiring instant vehicle speed is desirable and a corner stone to many important vehicular applications. This paper utilizes smartphone sensors to estimate the vehicle speed, especially when GPS is unavailable or inaccurate in urban environments. In particular, we estimate the vehicle speed by integrating the accelerometer’s readings over time and find the acceleration errors can lead to large deviations between the estimated speed and the real one. Further analysis shows that the changes of acceleration errors are very small over time which can be corrected at some points, called reference points, where the true vehicle speed can be estimated. Recognizing this observation, we propose an accurate vehicle speed estimation system, SenSpeed, which senses natural driving conditions in urban environments including making turns, stopping, and passing through uneven road surfaces, to derive reference points and further eliminates the speed estimation deviations caused by acceleration errors. Extensive experiments demonstrate that SenSpeed is accurate and robust in real driving environments. On average, the real-time speed estimation error on local road is
2.1km/h
, and the offline speed estimation error is as low as
1.21
km/h. Whereas the average error of GPS is
5.0
and
4.5
km/h, respectively.","Vehicles,
Acceleration,
Estimation,
Accelerometers,
Sensors,
Global Positioning System,
Roads"
Secure Transmission in Cooperative Relaying Networks With Multiple Antennas,"We investigate the secrecy performance of dual-hop amplify-and-forward multi-antenna relaying systems over Rayleigh fading channels, considering the direct link between the source and the destination. In order to exploit the available direct link and the multiple antennas for secrecy improvement, different linear processing schemes at the relay and different diversity combining techniques at the destination are proposed, namely: 1) zero-forcing/maximal ratio combining (ZF/MRC); 2) ZF/selection combining (ZF/SC); 3) maximal ratio transmission/MRC (MRT/MRC); and 4) MRT/SC. For all these schemes, we present new closed-form approximations for the secrecy outage probability. Moreover, we investigate a benchmark scheme, i.e., cooperative jamming/ZF (CJ/ZF), where the secrecy outage probability is obtained in exact closed-form. In addition, we present asymptotic secrecy outage expressions for all the proposed schemes in the high signal-to-noise ratio (SNR) regime, in order to characterize key design parameters, such as secrecy diversity order and secrecy array gain. The outcomes of this paper can be summarized as follows: 1) MRT/MRC and MRT/SC achieve a full diversity order of M + 1, ZF/MRC and ZF/SC achieve a diversity order of M, while CJ/ZF only achieves unit diversity order, where M is the number of antennas at the relay; 2) ZF/MRC (ZF/SC) outperforms the corresponding MRT/MRC(MRT/SC) in the low SNR regime, while becomes inferior to the corresponding MRT/MRC (MRT/SC) in the high SNR; and 3) all the proposed schemes tend to outperform the CJ/ZF with moderate number of antennas, and linear processing schemes with MRC attain better performance than those with SC.","Antennas,
Diversity reception,
Relays,
Signal to noise ratio,
Wireless communication,
Security,
Fading channels"
A Graph-Theoretical Approach for Tracing Filamentary Structures in Neuronal and Retinal Images,"The aim of this study is about tracing filamentary structures in both neuronal and retinal images. It is often crucial to identify single neurons in neuronal networks, or separate vessel tree structures in retinal blood vessel networks, in applications such as drug screening for neurological disorders or computer-aided diagnosis of diabetic retinopathy. Both tasks are challenging as the same bottleneck issue of filament crossovers is commonly encountered, which essentially hinders the ability of existing systems to conduct large-scale drug screening or practical clinical usage. To address the filament crossovers' problem, a two-step graph-theoretical approach is proposed in this paper. The first step focuses on segmenting filamentary pixels out of the background. This produces a filament segmentation map used as input for the second step, where they are further separated into disjointed filaments. Key to our approach is the idea that the problem can be reformulated as label propagation over directed graphs, such that the graph is to be partitioned into disjoint sub-graphs, or equivalently, each of the neurons (vessel trees) is separated from the rest of the neuronal (vessel) network. This enables us to make the interesting connection between the tracing problem and the digraph matrix-forest theorem in algebraic graph theory for the first time. Empirical experiments on neuronal and retinal image datasets demonstrate the superior performance of our approach over existing methods.","Image segmentation,
Skeleton,
Junctions,
Neurons,
Retinal vessels,
Biomedical imaging"
Design Structure Matrix Extensions and Innovations: A Survey and New Opportunities,"The design structure matrix (DSM), also called the dependency structure matrix, has become a widely used modeling framework across many areas of research and practice. The DSM brings advantages of simplicity and conciseness in representation, and, supported by appropriate analysis, can also highlight important patterns in system architectures (design structures), such as modules and cycles. A literature review in 2001 cited about 100 DSM papers; there have been over 1000 since. Thus, it is useful to survey the latest DSM extensions and innovations to help consolidate progress and identify promising opportunities for further research. This paper surveys the DSM literature, primarily from archival journals, and organizes the developments pertaining to building, displaying, analyzing, and applying product, process, and organization DSMs. It then addresses DSM applications in other domains, as well as recent developments with domain mapping matrices (DMMs) and multidomain matrices (MDMs). Overall, DSM methods are becoming more mainstream, especially in the areas of engineering design, engineering management, management/organization science, and systems engineering. Despite significant research contributions, however, DSM awareness seems to be spreading more slowly in the realm of project management.",
Multi-Label Dictionary Learning for Image Annotation,"Image annotation has attracted a lot of research interest, and multi-label learning is an effective technique for image annotation. How to effectively exploit the underlying correlation among labels is a crucial task for multi-label learning. Most existing multi-label learning methods exploit the label correlation only in the output label space, leaving the connection between the label and the features of images untouched. Although, recently some methods attempt toward exploiting the label correlation in the input feature space by using the label information, they cannot effectively conduct the learning process in both the spaces simultaneously, and there still exists much room for improvement. In this paper, we propose a novel multi-label learning approach, named multi-label dictionary learning (MLDL) with label consistency regularization and partial-identical label embedding MLDL, which conducts MLDL and partial-identical label embedding simultaneously. In the input feature space, we incorporate the dictionary learning technique into multi-label learning and design the label consistency regularization term to learn the better representation of features. In the output label space, we design the partial-identical label embedding, in which the samples with exactly same label set can cluster together, and the samples with partial-identical label sets can collaboratively represent each other. Experimental results on the three widely used image datasets, including Corel 5K, IAPR TC12, and ESP Game, demonstrate the effectiveness of the proposed approach.","Computational modeling,
Dictionaries,
Correlation,
Visualization,
Semantics,
Image coding,
Training"
Adaptive Neural Network-Based Event-Triggered Control of Single-Input Single-Output Nonlinear Discrete-Time Systems,"This paper presents a novel adaptive neural network (NN) control of single-input and single-output uncertain nonlinear discrete-time systems under event sampled NN inputs. In this control scheme, the feedback signals are transmitted, and the NN weights are tuned in an aperiodic manner at the event sampled instants. After reviewing the NN approximation property with event sampled inputs, an adaptive state estimator (SE), consisting of linearly parameterized NNs, is utilized to approximate the unknown system dynamics in an event sampled context. The SE is viewed as a model and its approximated dynamics and the state vector, during any two events, are utilized for the event-triggered controller design. An adaptive event-trigger condition is derived by using both the estimated NN weights and a dead-zone operator to determine the event sampling instants. This condition both facilitates the NN approximation and reduces the transmission of feedback signals. The ultimate boundedness of both the NN weight estimation error and the system state vector is demonstrated through the Lyapunov approach. As expected, during an initial online learning phase, events are observed more frequently. Over time with the convergence of the NN weights, the inter-event times increase, thereby lowering the number of triggered events. These claims are illustrated through the simulation results.","Artificial neural networks,
Adaptation models,
Function approximation,
Adaptive systems,
System dynamics,
Stability analysis"
Evaluating and Improving the Performance and Scheduling of HPC Applications in Cloud,"Cloud computing is emerging as a promising alternative to supercomputers for some high-performance computing (HPC) applications. With cloud as an additional deployment option, HPC users and providers are faced with the challenges of dealing with highly heterogeneous resources, where the variability spans across a wide range of processor configurations, interconnects, virtualization environments, and pricing models. In this paper, we take a holistic viewpoint to answer the question-why and whoshould choose cloud for HPC, for what applications, and how should cloud be used for HPC? To this end, we perform comprehensive performance and cost evaluation and analysis of running a set of HPC applications on a range of platforms, varying from supercomputers to clouds. Further, we improve performance of HPC applications in cloud by optimizing HPC applications' characteristics for cloud and cloud virtualization mechanisms for HPC. Finally, we present novel heuristics for online application-aware job scheduling in multi-platform environments. Experimental results and simulations using CloudSim show that current clouds cannot substitute supercomputers but can effectively complement them. Significant improvement in average turnaround time (up to 2X)and throughput (up to 6X) can be attained using our intelligent application-aware dynamic scheduling heuristics compared tosingle-platform or application-agnostic scheduling.","Cloud computing,
Clouds,
Supercomputers,
Virtualization,
Benchmark testing,
Jacobian matrices,
Bandwidth"
"Unified Scaling of Polar Codes: Error Exponent, Scaling Exponent, Moderate Deviations, and Error Floors","Consider the transmission of a polar code of block length N and rate R over a binary memoryless symmetric channel W and let Pe be the block error probability under successive cancellation decoding. In this paper, we develop new bounds that characterize the relationship of the parameters R, N, Pe, and the quality of the channel W quantified by its capacity I(W) and its Bhattacharyya parameter Z(W). In previous work, two main regimes were studied. In the error exponent regime, the channel W and the rate R <; I(W) are fixed, and it was proved that the error probability Pe scales roughly as 2-√N. In the scaling exponent approach, the channel W and the error probability Pe are fixed and it was proved that the gap to capacity I(W) - R scales as N-1/μ. Here, μ is called scaling exponent and this scaling exponent depends on the channel W. A heuristic computation for the binary erasure channel (BEC) gives μ = 3.627 and it was shown that, for any channel W, 3.579 ≤ μ ≤ 5.702. Our contributions are as follows. First, we provide the tighter upper bound μ <;≤ 4.714 valid for any W. With the same technique, we obtain the upper bound μ ≤ 3.639 for the case of the BEC; this upper bound approaches very closely the heuristically derived value for the scaling exponent of the erasure channel. Second, we develop a trade-off between the gap to capacity I(W)- R and the error probability Pe as the functions of the block length N. In other words, we neither fix the gap to capacity (error exponent regime) nor the error probability (scaling exponent regime), but we do consider a moderate deviations regime in which we study how fast both quantities, as the functions of the block length N, simultaneously go to 0. Third, we prove that polar codes are not affected by error floors. To do so, we fix a polar code of block length N and rate R. Then, we vary the channel W and study the impact of this variation on the error probability. We show that the error probability Pe scales as the Bhattacharyya parameter Z(W) raised to a power that scales roughly like VN. This agrees with the scaling in the error exponent regime.","Error probability,
Decoding,
Upper bound,
Capacity planning,
Parity check codes,
Encoding,
Performance analysis"
Taming Cross-Technology Interference for Wi-Fi and ZigBee Coexistence Networks,"Recent studies show that Wi-Fi interference has been a major problem for low power urban sensing technology ZigBee networks. Existing approaches for dealing with such interferences often modify either the ZigBee nodes or Wi-Fi nodes. However, massive deployment of ZigBee nodes and uncooperative Wi-Fi users call for innovative cross-technology coexistence without intervening legacy systems. In this work, we investigate the Wi-Fi and ZigBee coexistence when ZigBee is the interested signal. Typically, the duration of transmitting a ZigBee data packet is longer than that of a Wi-Fi packet. Mitigating short duration Wi-Fi interference (called flash) in long duration ZigBee data (called smog) is challenging. To address these challenges, we propose ZIMO: a sink-based MIMO design for harmony coexistence of ZigBee and Wi-Fi networks with the goal of protecting the ZigBee data packets from being interfered by high-power cross-technology signals. The key insight is to properly exploit opportunities resulted from differences between Wi-Fi and ZigBee, and bridge the gap between interested data and cross technology signals. Also, extracting the channel coefficient of Wi-Fi and ZigBee will enhance other coexistence technologies such as TIMO [1] . We implement a prototype in GNURadio-USRP N200, and our extensive evaluations under real wireless conditions show that ZIMO can improve ZigBee network throughput up to 1.9
×
, with 1.5
×
in media, and 1.1
×
to 1.9
×
for Wi-Fi network as byproduct in ZigBee signal recovery.",
Security and Vulnerability Implications of 3D ICs,"Physical limit of transistor miniaturization has driven chip design into the third dimension. 3D integration technology emerges as a viable option to improve chip performance and increase device density in a direction orthogonal to costly device scaling. As 3D integration is becoming a promising technology for next-generation chip design, recent years have seen a huge proliferation of research literature exploiting it from a security perspective. This paper presents a survey on the current state of 3D integration technology from a security perspective and summarizes its security opportunities and challenges. We report current research work on 3D integration based security in three major applications: supply chain attack prevention, side-channel attack mitigation, and trustworthy computing system design. The security advantages and opportunities of 3D integration in these security applications are highlighted. Besides, the paper discusses new vulnerabilities risen by 3D integration that require researchers' attention. Based on the survey result, we summarize the distinct characteristics of 3D ICs and investigate their impacts on security-aware 3D IC designs.","Three-dimensional displays,
Security,
Stacking,
Fabrication,
Integrated circuit interconnections,
Through-silicon vias"
Adaptive and Channel-Aware Detection of Selective Forwarding Attacks in Wireless Sensor Networks,"Wireless sensor networks (WSNs) are vulnerable to selective forwarding attacks that can maliciously drop a subset of forwarding packets to degrade network performance and jeopardize the information integrity. Meanwhile, due to the unstable wireless channel in WSNs, the packet loss rate during the communication of sensor nodes may be high and vary from time to time. It poses a great challenge to distinguish the malicious drop and normal packet loss. In this paper, we propose a channel-aware reputation system with adaptive detection threshold (CRS-A) to detect selective forwarding attacks in WSNs. The CRS-A evaluates the data forwarding behaviors of sensor nodes, according to the deviation of the monitored packet loss and the estimated normal loss. To optimize the detection accuracy of CRS-A, we theoretically derive the optimal threshold for forwarding evaluation, which is adaptive to the time-varied channel condition and the estimated attack probabilities of compromised nodes. Furthermore, an attack-tolerant data forwarding scheme is developed to collaborate with CRS-A for stimulating the forwarding cooperation of compromised nodes and improving the data delivery ratio of the network. Extensive simulation results demonstrate that CRS-A can accurately detect selective forwarding attacks and identify the compromised sensor nodes, while the attack-tolerant data forwarding scheme can significantly improve the data delivery ratio of the network.",
Fuzzy-Based Goal Representation Adaptive Dynamic Programming,"In this paper, a novel nonlinear learning controller called fuzzy-based goal representation adaptive dynamic programming (Fuzzy-GrADP) is proposed. In the proposed GrADP method, a goal representation network is introduced to generate an adaptive internal reinforcement signal to the critic network to help the controller provide a general mapping between the input and output actions. Moreover, in the proposed architecture, the action network in the GrADP is improved by using the fuzzy hyperbolic model, which combines the merits of the fuzzy model and the neural network model. Based on the back-propagation technique, the parameters in the membership functions and the fuzzy rules are all undergo training and online adapting. The proposed controller is tested on two numerical benchmarks, and the simulation results show that the proposed controller outperforms the original adaptive dynamic fuzzy controller and the pure neural network-based GrADP controller. In addition, the proposed controller is further applied on a large multimachine power system for static var compensator damping control, where simulation results demonstrate the effectiveness of the proposed approach on real applications. Furthermore, in order to demonstrate the theoretical guarantee of the proposed method, Lyapunov stability analysis to support the proposed Fuzzy-GrADP approach has also been carried out.","Dynamic programming,
Power system stability,
Adaptive systems,
Adaptation models,
Damping,
Mathematical model,
Nonlinear systems"
Objective Extraction for Many-Objective Optimization Problems: Algorithm and Test Problems,"For many-objective optimization problems (MaOPs), in which the number of objectives is greater than three, the performance of most existing evolutionary multi-objective optimization algorithms generally deteriorates over the number of objectives. As some MaOPs may have redundant or correlated objectives, it is desirable to reduce the number of the objectives in such circumstances. However, the Pareto solution of the reduced MaOP obtained by most of the existing objective reduction methods, based on objective selection, may not be the Pareto solution of the original MaOP. In this paper, we propose an objective extraction method (OEM) for MaOPs. It formulates the reduced objective as a linear combination of the original objectives to maximize the conflict between the reduced objectives. Subsequently, the Pareto solution of the reduced MaOP obtained by the proposed algorithm is that of the original MaOP, and the proposed algorithm can thus preserve the dominance structure as much as possible. Moreover, we propose a novel framework that features both simple and complicated Pareto set shapes for many-objective test problems with an arbitrary number of essential objectives. Within this framework, we can control the importance of essential objectives. As there is no direct performance metric for the objective reduction algorithms on the benchmarks, we present a new metric that features simplicity and usability for the objective reduction algorithms. We compare the proposed OEM with three objective reduction methods, i.e., REDGA, L-PCA, and NL-MVU-PCA, on the proposed test problems and benchmark DTLZ5 with different numbers of objectives and essential objectives. Our numerical studies show the effectiveness and robustness of the proposed approach.","Optimization,
Correlation,
Measurement,
Benchmark testing,
Robustness,
Sociology"
A Multi-Mode Dead Reckoning System for Pedestrian Tracking Using Smartphones,"This paper proposes an approach for pedestrian tracking using dead reckoning enhanced with a mode detection using a standard smartphone. The mode represents a specific state of carrying device, and it is automatically detected while a person is walking. This paper presents a new approach, which extends and enhances previous methods by identifying in real-time three typical modes of carrying the device and using the identified mode to enhance tracking accuracy. The way of carrying the device in all modes is unconstrained to offer reliable person-independent tracking. Based on the identification of modes, a lightweight step-based tracking algorithm is developed with a novel step length estimation model. The tracking system is implemented on a commercial off-the-shelf smartphone equipped with a built-in inertial measurement unit with 3-D accelerometer and gyroscope. It achieves real-time tracking and localization performance with an average position accuracy of 98.91%.","Legged locomotion,
Sensors,
Smart phones,
Acceleration,
Accelerometers,
Gyroscopes,
Real-time systems"
Optimal Placement for Barrier Coverage in Bistatic Radar Sensor Networks,"By taking advantage of active sensing using radio waves, radar sensors can offer several advantages over passive sensors. Although much attention has been given to multistatic and multiple-input-multiple-output (MIMO) radar concepts, little has been paid to understanding radar networks (i.e., multiple individual radars working in concert). In this context, we study the coverage problem of a bistatic radar (BR) sensor network, which is very challenging due to the Cassini oval sensing region of a BR and the coupling of sensing regions across different BRs. In particular, we consider the problem of deploying a network of BRs in a region to maximize the worst-case intrusion detectability, which amounts to minimizing the vulnerability of a barrier. We show that it is optimal to place BRs on the shortest barrier if it is the shortest line segment that connects the left and right boundary of the region. Based on this, we study the optimal placement of BRs on a line segment to minimize its vulnerability, which is a nonconvex optimization problem. By exploiting certain specific structural properties pertaining to the problem (particularly an important structure of detectability), we characterize the optimal placement order and the optimal placement spacing of the BR nodes, both of which present elegant balanced structures. Our findings provide valuable insights into the placement of BRs for barrier coverage. To our best knowledge, this is the first work to explore the barrier coverage of a network of BRs.","Receivers,
Radio transmitters,
Bistatic radar,
Sensors,
Signal to noise ratio"
Optimization-Based Cell Selection Method for Grid-Connected Modular Multilevel Converters,"Modular multilevel converters (MMCs) are widely used in different applications. Due to low-loss operation, compactness, and high modularity, MMC is extremely attractive for high-voltage direct-current (HVDC) transmission systems. The HVDC station loss is highly related to the converter switching pulse pattern, which is generated by modulation algorithm and cell selection methods. This paper formulates the switching pulse pattern generation, as a versatile optimization problem. The problem constraints and objectives are formulated for HVDC applications and compared with similar problems in the field of computer science. To overcome the computational complexity in solving the introduced optimization problem, a heuristic method is proposed for cell selection algorithm. The method utilizes the current level in order to obtain lossless switching at zero-current crossings. The study of the proposed method, in a time-domain simulation platform, shows that the method can reduce the switching converter losses by 60% compared to carrier-based modulation, maintaining the same capacitor voltage ripple. Eventually, the practical functionality of the proposed method is verified in a real-time digital simulator, RTDS, for a 512-level converter in a point to point HVDC link. Although this paper focuses on HVDC, the mathematical model is applicable for any MMC application.","Switches,
Capacitors,
Voltage control,
HVDC transmission,
Tin,
Switching loss,
Switching frequency"
"Multimode
Q
Control in Tapping-Mode AFM: Enabling Imaging on Higher Flexural Eigenmodes","Numerous dynamic atomic force micros- copy (AFM) methods have appeared in recent years, which make use of the excitation and detection of higher order eigenmodes of the microcantilever. The ability to control these modes and their responses to excitation is believed to be the key to unraveling the true potential of these methods. In this paper, we highlight a multimode Q control method that exhibits remarkable damping performance and stability robustness. The experimental results obtained in ambient conditions demonstrate improved imaging stability by damping nondriven resonant modes when scanning is performed at a higher eigenmode of the cantilever. Higher scan speeds are shown to result from a decrease in transient response time.","Force,
Q-factor,
Imaging,
Damping,
Optical variables measurement,
Nickel,
Springs"
Robust Beamforming for Nonorthogonal Multiple-Access Systems in MISO Channels,"Nonorthogonal multiple access (NOMA) is a promising technology in future mobile communication systems. In this paper, considering that the base station knows imperfect channel state information (CSI), we investigate the robust beamforming design problem for NOMA systems in multiple-input-single-output (MISO) channels. Modeling channel uncertainties by the worst-case model, we aim at maximizing the worst-case achievable sum rate subject to the transmit power constraint at the base station. We propose to decouple the nonconvex optimization problem into four optimization problems and employ an alternating optimization algorithm to solve the problem. Simulation results demonstrate that our proposed robust beamforming scheme outperforms the orthogonal multiple-access scheme.","Base stations,
Array signal processing,
Optimization,
Robustness,
Uncertainty,
Downlink"
Short-Term Wind Speed or Power Forecasting With Heteroscedastic Support Vector Regression,"Wind speed or wind power forecasting plays an important role in large-scale wind power penetration due to their uncertainty. Support vector regression, widely used in wind speed or wind power forecasting, aims at discovering natural structures of wind variation hidden in historical data. Most current regression algorithms, including least squares support vector regression (SVR), assume that the noise of the data is Gaussian with zero mean and the same variance. However, it is discovered that the uncertainty of short-term wind speed satisfies Gaussian distribution with zero mean and heteroscedasticity in this work. This kind of task is called heteroscedastic regression. In order to deal with this problem, we derive an optimal loss function for heteroscedastic regression and develop a new framework of v-SVR for learning tasks of Gaussian noise (GN) with heteroscedasticity. In addition, we introduce the stochastic gradient descent (SGD) method to solve the proposed model, which leads the models to be trained online. Finally, we reveal the uncertainty properties of wind speed with two real-world datasets and test the proposed algorithms on these data. The experimental results confirm the effectiveness of the proposed model.","Wind speed,
Wind power generation,
Forecasting,
Support vector machines,
Uncertainty,
Gaussian distribution,
Computer science"
Secure and Robust Multi-Constrained QoS Aware Routing Algorithm for VANETs,"Secure QoS routing algorithms are a fundamental part of wireless networks that aim to provide services with QoS and security guarantees. In vehicular ad hoc networks (VANETs), vehicles perform routing functions, and at the same time act as end-systems thus routing control messages are transmitted unprotected over wireless channels. The QoS of the entire network could be degraded by an attack on the routing process, and manipulation of the routing control messages. In this paper, we propose a novel secure and reliable multi-constrained QoS aware routing algorithm for VANETs. We employ the ant colony optimisation (ACO) technique to compute feasible routes in VANETs subject to multiple QoS constraints determined by the data traffic type. Moreover, we extend the VANET-oriented evolving graph (VoEG) model to perform plausibility checks on the routing control messages exchanged among vehicles. Simulation results show that the QoS can be guaranteed while applying security mechanisms to ensure a reliable and robust routing service.","Routing,
Quality of service,
Vehicles,
Reliability,
Security,
Ad hoc networks,
Delays"
A Novel Differential-Fed Patch Antenna on Stepped-Impedance Resonator With Enhanced Bandwidth Under Dual-Resonance,"A novel design concept to enhance the bandwidth of a differential-fed patch antenna using the dual-resonant radiation of a stepped-impedance resonator (SIR) is proposed. The SIR is composed of two distinctive portions: the radiating patch and a pair of open stubs. Initially, based on the transmission line model, the first and second odd-order radiative resonant modes, i.e., TM10 and TM30, of this SIR-typed patch antenna are extensively investigated. It is demonstrated that the frequency ratio between the dual-resonant modes can be fully controlled by the electrical length and the impedance ratios between the open stub and radiating patch. After that, the SIR-typed patch antenna is reshaped with stepped ground plane in order to increase the impedance ratio as highly required for wideband radiation. With this arrangement, these two radiative modes are merged with each other, resulting in a wide impedance bandwidth with a stable radiation pattern under dual-resonant radiation. Finally, the proposed antenna is designed, fabricated, and measured. It is verified in experiment that the impedance bandwidth (|Sdd11| <; -10 dB) of the proposed antenna has gained tremendous increment up to 10% (0.85-0.94 GHz) with two attenuation poles. Most importantly, the antenna has achieved a stable gain varying from 7.4 to 8.5 dB within the whole operating band, while keeping low-cross polarization.","Patch antennas,
Impedance,
Bandwidth,
Resonant frequency,
Antenna radiation patterns,
Antenna measurements"
Spectrum Management for Proactive Video Caching in Information-Centric Cognitive Radio Networks,"To deal with the rapid growth of mobile data traffic and the user interest shift from peer-to-peer communications to content dissemination-based services, such as video streaming, information-centric networking has emerged as a promising architecture and has been increasingly used for wireless and mobile networks. In this paper, we focus on video dissemination in information-centric cognitive radio networks (IC-CRNs) and investigate the use of harvested bands for proactively caching video contents at the locations close to the interested users to improve the performance of video distribution. With consideration of the dynamic and unobservable nature of some parameters, we formulate the allocation of harvested bands as a Markov decision process with hidden and dynamic parameters and transform it into a partially observable Markov decision process and a multi-armed bandit formulation. Based on them, we develop a new spectrum management mechanism, which maximizes the benefit of proactive video caching as well as the efficiency of spectrum utilization in the IC-CRNs. Extensive simulation results demonstrate the significant performance improvement of the proposed scheme for video streaming.","Streaming media,
Cognitive radio,
Mobile communication,
Mobile computing,
Radio spectrum management,
Dynamic scheduling,
Resource management"
How the Brain Formulates Memory: A Spatio-Temporal Model Research Frontier,"Memory is a complex process across different brain regions and a fundamental function for many cognitive behaviors. Emerging experimental results suggest that memories are represented by populations of neurons and organized in a categorical and hierarchical manner. However, it is still not clear how the neural mechanisms are emulated in computational models. In this paper, we present a spatio-temporal memory (STM) model using spiking neurons to explore the memory formulation and organization in the brain. Unlike previous approaches, this model employs temporal population codes as the neural representation of information and spiketiming-based learning methods to formulate the memory structure. It explicitly demonstrates that the complex spatio-temporal patterns are the internal neural representations of memory items. Two types of memory processes are analyzed and emulated: associative memory, i.e., spatio-temporal patterns driven by intra-assembly connections, and episodic memory, i.e., temporally separated spatio-temporal patterns linked by inter-assembly connections. Our model will provide a computational substrate based on lowlevel neural circuits for developing neuromorphic cognitive systems with wide applications.","Neurons,
Encoding,
Spatio-temporal models,
Statistics,
Learning systems,
Computational modeling,
Memory"
Energy Efficient Resource Allocation in D2D-Assisted Heterogeneous Networks with Relays,"Heterogeneous networks (HetNets) supported with relays and device to device communication can be considered as a promising solution to realize the ambitious targets of the future fifth generation networks in terms of energy efficiency and capacity. HetNets necessitate optimal power allocation, spectrum resource allocation, and cell selection to meet the quality of service requirements. In this paper, we formulate energy efficiency maximization problem in terms of resource allocation and cell selection for HetNets, where objective is to maximize the network throughput per unit network power consumption. Formulated optimization problem is non-linear fractional programming problem. We use Charnes-Cooper transformation to convert proposed fractional programming problem into concave optimization problem. We propose outer approximation algorithm (OAA) to solve the converted concave optimization problem. The proposed algorithm is evaluated by extensive simulation work. The performance of ε-optimal solution obtained by OAA method is shown for different network parameters, such as number of users, required date rate, and capacity of network.","Resource management,
Quality of service,
Programming,
Approximation algorithms,
Heterogeneous networks,
Device-to-device communication"
Visual Encodings of Temporal Uncertainty: A Comparative User Study,"A number of studies have investigated different ways of visualizing uncertainty. However, in the temporal dimension, it is still an open question how to best represent uncertainty, since the special characteristics of time require special visual encodings and may provoke different interpretations. Thus, we have conducted a comprehensive study comparing alternative visual encodings of intervals with uncertain start and end times: gradient plots, violin plots, accumulated probability plots, error bars, centered error bars, and ambiguation. Our results reveal significant differences in error rates and completion time for these different visualization types and different tasks. We recommend using ambiguation - using a lighter color value to represent uncertain regions - or error bars for judging durations and temporal bounds, and gradient plots - using fading color or transparency - for judging probability values.","Uncertainty,
Visualization,
Bars,
Encoding,
Image color analysis,
Data visualization"
An Efficient Privacy-Preserving Ranked Keyword Search Method,"Cloud data owners prefer to outsource documents in an encrypted form for the purpose of privacy preserving. Therefore it is essential to develop efficient and reliable ciphertext search techniques. One challenge is that the relationship between documents will be normally concealed in the process of encryption, which will lead to significant search accuracy performance degradation. Also the volume of data in data centers has experienced a dramatic growth. This will make it even more challenging to design ciphertext search schemes that can provide efficient and reliable online information retrieval on large volume of encrypted data. In this paper, a hierarchical clustering method is proposed to support more search semantics and also to meet the demand for fast ciphertext search within a big data environment. The proposed hierarchical approach clusters the documents based on the minimum relevance threshold, and then partitions the resulting clusters into sub-clusters until the constraint on the maximum size of cluster is reached. In the search phase, this approach can reach a linear computational complexity against an exponential size increase of document collection. In order to verify the authenticity of search results, a structure called minimum hash sub-tree is designed in this paper. Experiments have been conducted using the collection set built from the IEEE Xplore. The results show that with a sharp increase of documents in the dataset the search time of the proposed method increases linearly whereas the search time of the traditional method increases exponentially. Furthermore, the proposed method has an advantage over the traditional method in the rank privacy and relevance of retrieved documents.","Servers,
Indexes,
Privacy,
Computer architecture,
Encryption"
Robust Kernel Low-Rank Representation,"Recently, low-rank representation (LRR) has shown promising performance in many real-world applications such as face clustering. However, LRR may not achieve satisfactory results when dealing with the data from nonlinear subspaces, since it is originally designed to handle the data from linear subspaces in the input space. Meanwhile, the kernel-based methods deal with the nonlinear data by mapping it from the original input space to a new feature space through a kernel-induced mapping. To effectively cope with the nonlinear data, we first propose the kernelized version of LRR in the clean data case. We also present a closed-form solution for the resultant optimization problem. Moreover, to handle corrupted data, we propose the robust kernel LRR (RKLRR) approach, and develop an efficient optimization algorithm to solve it based on the alternating direction method. In particular, we show that both the subproblems in our optimization algorithm can be efficiently and exactly solved, and it is guaranteed to obtain a globally optimal solution. Besides, our proposed algorithm can also solve the original LRR problem, which is a special case of our RKLRR when using the linear kernel. In addition, based on our new optimization technique, the kernelization of some variants of LRR can be similarly achieved. Comprehensive experiments on synthetic data sets and real-world data sets clearly demonstrate the efficiency of our algorithm, as well as the effectiveness of RKLRR and the kernelization of two variants of LRR.",
Structure-Preserving Color Normalization and Sparse Stain Separation for Histological Images,"Staining and scanning of tissue samples for microscopic examination is fraught with undesirable color variations arising from differences in raw materials and manufacturing techniques of stain vendors, staining protocols of labs, and color responses of digital scanners. When comparing tissue samples, color normalization and stain separation of the tissue images can be helpful for both pathologists and software. Techniques that are used for natural images fail to utilize structural properties of stained tissue samples and produce undesirable color distortions. The stain concentration cannot be negative. Tissue samples are stained with only a few stains and most tissue regions are characterized by at most one effective stain. We model these physical phenomena that define the tissue structure by first decomposing images in an unsupervised manner into stain density maps that are sparse and non-negative. For a given image, we combine its stain density maps with stain color basis of a pathologist-preferred target image, thus altering only its color while preserving its structure described by the maps. Stain density correlation with ground truth and preference by pathologists were higher for images normalized using our method when compared to other alternatives. We also propose a computationally faster extension of this technique for large whole-slide images that selects an appropriate patch sample instead of using the entire image to compute the stain color basis.","Image color analysis,
Biology,
Pathology,
Estimation,
Histograms,
Software,
Sparse matrices"
Node Localization in Robotic Sensor Networks for Pipeline Inspection,"Robotic sensor networks provide an effective approach for underground pipeline inspection. Such networks are comprised of sensor nodes (SNs) and relay nodes (RNs) carried by robots for information sensing and communication, and are able to perform accurate and realtime inspection, especially in adverse environments. SN localization is critical in such networks because localization results can be used not only for locating and pinpointing leaks, but also for maneuvering mobile SNs in a pipeline of complex configuration. However, both the underground operational environment and the limited resources of the SNs pose significant challenges for SN localization. This paper presents algorithms for SN localization in robotic sensor networks for underground pipeline inspection. Specifically, self-localization of underground in-pipe SNs were investigated by taking into account SN movement dynamics, and using the measurements of the SN's velocity and the received signal strength (RSS) of the radio signal from aboveground RNs. Depending on the availability of the RSS at the SN, different localization algorithms based on the Kalman filter are proposed for different scenarios. Simulation results show the efficacy of the proposed algorithms. The framework also provides insight into the design of robotic sensor networks for the inspection and maintenance of other types of pipeline systems, such as oil and gas pipelines.","Tin,
Robot sensing systems,
Velocity measurement,
Pipelines,
Inspection,
Position measurement"
Association Between Changes in Mammographic Image Features and Risk for Near-Term Breast Cancer Development,"The purpose of this study is to develop and test a new computerized model for predicting near-term breast cancer risk based on quantitative assessment of bilateral mammographic image feature variations in a series of negative full-field digital mammography (FFDM) images. The retrospective dataset included series of four sequential FFDM examinations of 335 women. The last examination in each series (“current”) and the three most recent “prior” examinations were obtained. All “prior” examinations were interpreted as negative during the original clinical image reading, while in the “current” examinations 159 cancers were detected and pathologically verified and 176 cases remained cancer-free. From each image, we initially computed 158 mammographic density, structural similarity, and texture based image features. The absolute subtraction value between the left and right breasts was selected to represent each feature. We then built three support vector machine (SVM) based risk models, which were trained and tested using a leave-one-case-out based cross-validation method. The actual features used in each SVM model were selected using a nested stepwise regression analysis method. The computed areas under receiver operating characteristic curves monotonically increased from 0.666 ± 0.029 to 0.730 ± 0.027 as the time-lag between the “prior” (3 to 1) and “current” examinations decreases. The maximum adjusted odds ratios were 5.63, 7.43, and 11.1 for the three “prior” (3 to 1) sets of examinations, respectively. This study demonstrated a positive association between the risk scores generated by a bilateral mammographic feature difference based risk model and an increasing trend of the near-term risk for having mammography-detected breast cancer.","Indexes,
Breast cancer,
Feature extraction,
Solid modeling,
Computational modeling"
Visualization and Analysis of Tradeoffs in Many-Objective Optimization: A Case Study on the Interior Permanent Magnet Motor Design,"The presentation and visualization of tradeoff solutions in many-objective optimization problems are difficult due to the large number of solutions in a hyperdimensional objective space. A recently proposed tool, known as aggregation tree (AT), can be used to analyze the degree of conflict between groups of objectives in a many-objective problem. In this paper, we present a case study on the internal permanent magnet motor design with seven objectives. The results show that the AT provides useful information about objective relationships (in accordance with the common knowledge of physics) as well as guidance in the reduction of objectives.","Optimization,
Visualization,
Torque,
Permanent magnet motors,
Linear programming,
Search problems,
MATLAB"
A Parallel Decomposition Method for Nonconvex Stochastic Multi-Agent Optimization Problems,"This paper considers the problem of minimizing the expected value of a (possibly nonconvex) cost function parameterized by a random (vector) variable, when the expectation cannot be computed accurately (e.g., because the statistics of the random variables are unknown and/or the computational complexity is prohibitive). Classical stochastic gradient methods for solving this problem may suffer from slow convergence. In this paper, we propose a stochastic parallel Successive Convex Approximation-based (best-response) algorithm for general nonconvex stochastic sum-utility optimization problems, which arise naturally in the design of multi-agent networks. The proposed novel decomposition approach enables all users to update their optimization variables in parallel by solving a sequence of strongly convex subproblems, one for each user. Almost sure convergence to stationary points is proved. We then customize the algorithmic framework to solve the stochastic sum rate maximization problem over single-input-single-output (SISO) frequency-selective interference channels, multiple-input-multiple-output (MIMO) interference channels, and MIMO multiple-access channels. Numerical results corroborate that the proposed algorithms can converge faster than state-of-the-art stochastic gradient schemes while achieving the same (or better) sum-rates.",
Multimodal Multipart Learning for Action Recognition in Depth Videos,"The articulated and complex nature of human actions makes the task of action recognition difficult. One approach to handle this complexity is dividing it to the kinetics of body parts and analyzing the actions based on these partial descriptors. We propose a joint sparse regression based learning method which utilizes the structured sparsity to model each action as a combination of multimodal features from a sparse set of body parts. To represent dynamics and appearance of parts, we employ a heterogeneous set of depth and skeleton based features. The proper structure of multimodal multipart features are formulated into the learning framework via the proposed hierarchical mixed norm, to regularize the structured features of each part and to apply sparsity between them, in favor of a group feature selection. Our experimental results expose the effectiveness of the proposed learning method in which it outperforms other methods in all three tested datasets while saturating one of them by achieving perfect accuracy.","Feature extraction,
Joints,
Histograms,
Three-dimensional displays,
Videos,
Learning systems"
Wireless Neighborhood Area Networks With QoS Support for Demand Response in Smart Grid,"In order to support various innovative demand response programs, smart grid needs a wireless communication network with quality-of-service (QoS) support. This paper studies the issue of providing QoS in terms of packet delay, packet error probability, and outage probability to a large number of sensors and smart meters in a neighborhood area network of a densely populated urban area. We assume the network is based on the IEEE 802.15.4g Standard. Given that bandwidth is limited, we propose to divide smart meters into groups and each group will take a turn to access a shared wireless channel in a time-division-multiplexing manner. Within each allocated time duration, a group of smart meters will compete for channel access using a simple slotted Aloha protocol. We have developed an analytical model to quantify the QoS metrics. Through the analytical model, we can determine the minimum concentrator density that is required to support a given smart meter density. We have verified the analytical model through simulations. The results show that we need less than ten concentrators per km
2
to support a node density of 500 units per km
2
, while making sure that packet delay does not exceed 1.0 s, packet error probability is below 0.005 and outage probability is lower than 0.01.",
Multi-Server Coded Caching,"In this paper, we consider multiple cache-enabled clients connected to multiple servers through an intermediate network. We design several topology-aware coding strategies for such networks. Based on the topology richness of the intermediate network, and types of coding operations at internal nodes, we define three classes of networks, namely, dedicated, flexible, and linear networks. For each class, we propose an achievable coding scheme, analyze its coding delay, and also compare it with an information theoretic lower bound. For flexible networks, we show that our scheme is order-optimal in terms of coding delay and, interestingly, the optimal memory-delay curve is achieved in certain regimes. In general, our results suggest that, in the case of networks with multiple servers, type of network topology can be exploited to reduce service delay.","Servers,
Delays,
Encoding,
Network topology,
Topology,
Routing,
Ports (Computers)"
Graph-based Dequantization of Block-Compressed Piecewise Smooth Images,"Block-based image or video coding standards (e.g. JPEG) compress an image lossily by quantizing transform coefficients of non-overlapping pixel blocks. If the chosen quantization parameters (QP) are large, then hard decoding of a compressed image-using indexed quantization bin centers as reconstructed transform coefficients-can lead to unpleasant blocking artifacts. Leveraging on recent advances in graph signal processing (GSP), we propose a dequantization scheme specifically for piecewise smooth (PWS) images: images with sharp object boundaries and smooth interior surfaces. We first mathematically define a PWS image as a low-frequency signal with respect to an inter-pixel similarity graph with edges of weights 1 or 0. Using quantization bin boundaries as constraints, we then jointly optimize the desired graph-signal and the similarity graph in a unified framework. A generalization to consider generalized piecewise smooth (GPWS) images-where sharp object boundaries are replaced by transition regions-is also proposed. Experimental results show that our proposed scheme outperforms a state-of-the-art dequantization method by 1 dB on average in PSNR.",
Robust Visual Tracking via Exclusive Context Modeling,"In this paper, we formulate particle filter-based object tracking as an exclusive sparse learning problem that exploits contextual information. To achieve this goal, we propose the context-aware exclusive sparse tracker (CEST) to model particle appearances as linear combinations of dictionary templates that are updated dynamically. Learning the representation of each particle is formulated as an exclusive sparse representation problem, where the overall dictionary is composed of multiple group dictionaries that can contain contextual information. With context, CEST is less prone to tracker drift. Interestingly, we show that the popular L1 tracker [1] is a special case of our CEST formulation. The proposed learning problem is efficiently solved using an accelerated proximal gradient method that yields a sequence of closed form updates. To make the tracker much faster, we reduce the number of learning problems to be solved by using the dual problem to quickly and systematically rank and prune particles in each frame. We test our CEST tracker on challenging benchmark sequences that involve heavy occlusion, drastic illumination changes, and large pose variations. Experimental results show that CEST consistently outperforms state-of-the-art trackers.","Target tracking,
Context modeling,
Robustness,
Visualization,
Object tracking"
Energy-Efficient Resource Allocation and User Scheduling for Collaborative Mobile Clouds With Hybrid Receivers,"In this paper, we study the resource allocation and user scheduling algorithm for minimizing the energy cost of data transmission in the context of orthogonal frequency-division multiple-access (OFDMA) collaborative mobile clouds (CMCs) with simultaneous wireless information and power transfer receivers. The CMC, which consists of several collaborating mobile terminals, offers one potential solution for downlink content distribution and for energy consumption (EC) reduction. Previous work on the design of the CMC system mainly focused on cloud formulation or energy efficiency (EE) investigation, whereas how to allocate the radio resource and schedule user transmission has not gotten much attention. With the objective of minimizing system EC, an optimization problem that jointly considers subchannel assignment, power allocation, and user scheduling has been presented. We propose different algorithms to address the formulated problem based on the convex optimization technique. Simulation results demonstrate that the proposed user scheduling and resource allocation algorithms can achieve significant EE performance.","Resource management,
Receivers,
Energy consumption,
Mobile communication,
Scheduling,
Cloud computing,
Wireless communication"
Discriminant Correlation Analysis: Real-Time Feature Level Fusion for Multimodal Biometric Recognition,"Information fusion is a key step in multimodal biometric systems. The fusion of information can occur at different levels of a recognition system, i.e., at the feature level, matching-score level, or decision level. However, feature level fusion is believed to be more effective owing to the fact that a feature set contains richer information about the input biometric data than the matching score or the output decision of a classifier. The goal of feature fusion for recognition is to combine relevant information from two or more feature vectors into a single one with more discriminative power than any of the input feature vectors. In pattern recognition problems, we are also interested in separating the classes. In this paper, we present discriminant correlation analysis (DCA), a feature level fusion technique that incorporates the class associations into the correlation analysis of the feature sets. DCA performs an effective feature fusion by maximizing the pairwise correlations across the two feature sets and, at the same time, eliminating the between-class correlations and restricting the correlations to be within the classes. Our proposed method can be used in pattern recognition applications for fusing the features extracted from multiple modalities or combining different feature vectors extracted from a single modality. It is noteworthy that DCA is the first technique that considers class structure in feature fusion. Moreover, it has a very low computational complexity and it can be employed in real-time applications. Multiple sets of experiments performed on various biometric databases and using different feature extraction techniques, show the effectiveness of our proposed method, which outperforms other state-of-the-art approaches.","Correlation,
Feature extraction,
Covariance matrices,
Biometrics (access control),
Training,
Eigenvalues and eigenfunctions,
Pattern recognition"
Deep spatial autoencoders for visuomotor learning,"Reinforcement learning provides a powerful and flexible framework for automated acquisition of robotic motion skills. However, applying reinforcement learning requires a sufficiently detailed representation of the state, including the configuration of task-relevant objects. We present an approach that automates state-space construction by learning a state representation directly from camera images. Our method uses a deep spatial autoencoder to acquire a set of feature points that describe the environment for the current task, such as the positions of objects, and then learns a motion skill with these feature points using an efficient reinforcement learning method based on local linear models. The resulting controller reacts continuously to the learned feature points, allowing the robot to dynamically manipulate objects in the world with closed-loop control. We demonstrate our method with a PR2 robot on tasks that include pushing a free-standing toy block, picking up a bag of rice using a spatula, and hanging a loop of rope on a hook at various positions. In each task, our method automatically learns to track task-relevant objects and manipulate their configuration with the robot's arm.","Visualization,
Learning (artificial intelligence),
Robot sensing systems,
Robot kinematics,
Cameras,
Unsupervised learning"
A Dynamic Graph-Based Scheduling and Interference Coordination Approach in Heterogeneous Cellular Networks,"To meet the demand of increasing mobile data traffic and provide better user experience, heterogeneous cellular networks (HCNs) have become a promising solution to improve both the system capacity and coverage. However, due to dense self-deployment of small cells in a limited area, serious interference from nearby base stations may occur, which results in severe performance degradation. To mitigate downlink interference and utilize spectrum resources more efficiently, we present a novel graph-based resource allocation and interference management approach in this paper. First, we divide small cells into cell clusters, considering their neighborhood relationships in the scenario. Then, we develop another graph clustering scheme to group user equipment (UE) in each cell cluster into UE clusters with minimum intracluster interference. Finally, we utilize a proportional fairness scheduling scheme to assign subchannels to each UE cluster and allocate power using water-filling method. To show the efficacy and effectiveness of our proposed approach, we propose a dual-based approach to search for optimal solutions as the baseline for comparisons. Furthermore, we compare the graph-based approach with the state of the art and a distributed approach without interference coordination. The simulation results show that our graph-based approach reaches more than 90% of the optimal performance and achieves a significant improvement in spectral efficiency compared with the state of the art and the distributed approach both under cochannel and orthogonal deployments. Moreover, the proposed graph-based approach has low computation complexity, making it feasible for real-time implementation.","Interference,
Signal to noise ratio,
Resource management,
Macrocell networks,
Downlink,
Measurement,
OFDM"
Delay-Aware Scheduling and Resource Optimization With Network Function Virtualization,"To accelerate the implementation of network functions/middle boxes and reduce the deployment cost, recently, the concept of network function virtualization (NFV) has emerged and become a topic of much interest attracting the attention of researchers from both industry and academia. Unlike the traditional implementation of network functions, a software-oriented approach for virtual network functions (VNFs) creates more flexible and dynamic network services to meet a more diversified demand. Software-oriented network functions bring along a series of research challenges, such as VNF management and orchestration, service chaining, VNF scheduling for low latency and efficient virtual network resource allocation with NFV infrastructure, among others. In this paper, we study the VNF scheduling problem and the corresponding resource optimization solutions. Here, the VNF scheduling problem is defined as a series of scheduling decisions for network services on network functions and activating the various VNFs to process the arriving traffic. We consider VNF transmission and processing delays and formulate the joint problem of VNF scheduling and traffic steering as a mixed integer linear program. Our objective is to minimize the makespan/latency of the overall VNFs' schedule. Reducing the scheduling latency enables cloud operators to service (and admit) more customers, and cater to services with stringent delay requirements, thereby increasing operators' revenues. Owing to the complexity of the problem, we develop a genetic algorithm-based method for solving the problem efficiently. Finally, the effectiveness of our heuristic algorithm is verified through numerical evaluation. We show that dynamically adjusting the bandwidths on virtual links connecting virtual machines, hosting the network functions, reduces the schedule makespan by 15%-20% in the simulated scenarios.","Delays,
Optimal scheduling,
Bandwidth,
Job shop scheduling,
Channel allocation"
Energy-Efficient Multimedia Data Dissemination in Vehicular Clouds: Stochastic-Reward-Nets-Based Coalition Game Approach,"In this paper, we investigate an energy efficiency issue for multimedia applications in a vehicular cloud environment. The problem of energy efficiency is formulated as a stochastic reward nets (SRNs)-based coalition game, in which vehicles are assumed as the players that formulate the coalition among themselves using a predefined criteria based on the demand generated and the available resources at the nearest cloudlet. A demand- and supply-based payoff value function is formulated for each player in the game. The processes and actions of the players are represented as SRNs in which each player should have a finite number of tokens to fire its actions. To reduce the delay, each vehicle accesses resources such as memory, processing power, and storage from the nearest cloudlet that may be either at the road side units deployed near the road or on the vehicles. The actions of the players are associated with a cardinality that represents the number of rewards and actions they have taken in a unit interval of time after interacting with an environment that is stochastic in this paper. For each action performed by the players, they may get feedback in the form of a reward or a penalty, according to which each player updates its action probability vector that helps them take the next actions in the game. An energy-efficient algorithm for frame scheduling using the nearest cloudlet is also proposed. The performance of the proposed algorithm is found to be satisfactory with respect to various evaluation metrics. In particular, there is an increment of 10%-15% in profit generation, with 20%-25% reduction in the delay, and an increment of 20% in the packet delivery ratio.",
A Hierarchical Energy Management System Based on Hierarchical Optimization for Microgrid Community Economic Operation,"In view of the merits and promising applications of microgrid community (MGC), this paper presents a two-level hierarchical optimization method for MGC's energy management system in smart grid environment. The lower level focuses on an individual microgrid (MG), and the upper level is responsible for managing the MGs and MG community level devices (MCLDs). It is executed consecutively from lower level to upper level in order to minimize operational costs. First, the lower level optimizes the power output of MGs generators, the charge/discharge power of energy storage system, and the exchanged power with upstream grid. The results of the lower level are transferred to the upper level as its constraints. Second, the upper level makes decisions about MCLDs' powers and the exchanged power between distribution networks based on results from the lower level while ignoring any internal constituents of MG. The model is built in ways that nonlinearity is removed by linearization approximation and nonconvexity is removed by adding implicit logic constraints. A case study based on a real system in South China's Guangxi Province is analyzed. The results demonstrate the effectiveness of the method. Of the four scenarios tested, two are proved cost-effective and are recommended for MGC operation.","Energy management,
Silicon,
Generators,
Computer architecture,
Microgrids,
Schedules,
Optimization"
Opportunistic Downlink Scheduling With Resource-Based Fairness and Feedback Reduction in Distributed Antenna Systems,"Despite increasing interest in distributed antenna systems (DASs), how to guarantee resource-based fairness in multiuser DASs remains largely unexplored. In this paper, we propose a novel cumulative distribution function (CDF)-based scheduling (CS) with flexible beam transmissions (CSFB) to guarantee resource-based fairness in DASs. With CSFB, to increase the probability that each remote antenna unit (RAU) can contribute to the throughput of users located near it, the probabilities of each user being selected for different RAUs and the number of beams for transmission are jointly adapted to the geographical distribution of RAUs. Thus, CSFB can efficiently exploit multiuser diversity realized by independent fading channels, as well as spatial multiplexing by effectively utilizing the distributed RAUs. To realize CSFB in practice, a one-bit-feedback scheme, i.e., CSFB-OB, is further proposed to reduce feedback overhead for user selection. We prove that both CSFB and CSFB-OB can satisfy resource-based fairness and derive the upper bound for the feedback overhead with CSFB-OB. Simulation results show that CSFB and CSFB-OB with a suitable feedback threshold achieve a better throughput performance than CS with all-beam and single-beam transmissions and the existing fair scheduling schemes.","Throughput,
Fading,
Signal to noise ratio,
Interference,
Multiplexing,
Antenna arrays"
Optimal Bidding Strategy and Intramarket Mechanism of Microgrid Aggregator in Real-Time Balancing Market,"Microgrid (MG) system with multienergy resources has a wide and dispatchable generation range and shows instant response, therefore, constituting a potentially suitable real-time power balancing resource. In this paper, we introduce the concept of MG aggregator to involve small-scale MGs in real-time balancing market bidding via a hierarchical market framework. At the upper real-time market level, the bidding strategy of aggregator is optimized by a risk-constrained mean-variance model to depress the effects of renewable energy sources (RES) uncertainty; at the lower intramarket level, an event-driven mechanism is presented to reach the cleared quantity of the upper market while realizing maximum economy. Furthermore, the above-centralized self-scheduling problem of MG aggregator is decomposed into individual MG optimization problems to achieve an optimal solution with fast convergence. Simulation results verify that the proposed market framework and the bidding strategy for MG aggregator are of high applicability in real market environment.","Microgrids,
Real-time systems,
Batteries,
Electricity supply industry,
Wind turbines,
Informatics"
Systematic Shape Optimization of Symmetric MIMO Antennas Using Characteristic Modes,"We introduce a systematic approach to the shape optimization of compact, single-aperture MIMO antennas. Because the characteristic modes of a radiator represent its complete set of possible responses to an excitation, any port on the antenna must display the properties of a combination of one or more of these characteristic modes. By restricting our consideration to a class of symmetric antennas, the lowest order characteristic modes of a structure can be separated with practical decoupling networks, studied, and excited independently. We show that the quality factor of each characteristic mode effectively bounds the performance of any individual port excitation, and can be used to evaluate the fitness of the antenna for multiport excitation. Under this framework, we apply a genetic algorithm (GA) to synthesize low Q MIMO antennas while minimizing conductor area. Feed locations are specified on the optimized shape based on the weighted excitation strength of the desired modes, and a two-port MIMO antenna is implemented and measured, verifying the proposed theory.","MIMO,
Optimization,
Ports (Computers),
Shape,
Antenna feeds"
Two-Dimensional DoA Estimation for Multipath Propagation Characterization Using the Array Response of PN-Sequences,"Multipath propagation and power arrival profiles in three-dimensional (3-D) space determine the performance of the full-dimensional MIMO (FD-MIMO) systems. Field channel measurements are crucial in characterizing wireless channel properties. Nevertheless, in spatial channel measurements, estimating the direction-of-arrivals (DoAs) of multipath components (MPCs) is a challenging issue, because of the large number of propagation paths and the correlation among the multipath signals. The number of incidence angles and estimation precision in traditional methods is limited by the sensor array size and signal correlation. In this paper, we propose a scheme for measuring and estimating the 2-D DoAs of propagation paths called multipath angular estimation using the array response of PN-sequences (MAPS). By using a receiving planar antenna array (PAA), MAPS first extracts the complex path array response vector (PARV) for each propagation path and then estimates the DoAs of the paths individually and independently. The subspace-decomposition theory for MAPS is proved and extensive simulations are conducted to compare MAPS with other algorithms. Furthermore, a channel sounder using two PAAs and the probing signal of 2.6 GHz carrier modulated by PN-sequences has been developed. The simulation and field tests show that MAPS can estimate arbitrary number of resolved MPCs in a channel snapshot and effectively suppress the multipath interference.","Direction-of-arrival estimation,
Arrays,
Estimation,
Antenna measurements,
Antenna arrays,
Correlation,
Spatial resolution"
Sparse Channel Estimation and Equalization for OFDM-Based Underwater Cooperative Systems With Amplify-and-Forward Relaying,"This paper is concerned with a challenging problem of channel estimation and equalization for amplify-and-forward cooperative relay based orthogonal frequency division multiplexing (OFDM) systems in sparse underwater acoustic (UWA) channels. The sparseness of the channel impulse response and prior information for the non-Gaussian channel gains, modeled by an exact continuous Gaussian mixture (CGM), are exploited to improve the performance of the channel estimation algorithm. The resulting novel algorithm initially estimates the overall sparse complex-valued channel taps from the source to the destination as well as their locations using the matching pursuit (MP) approach. The effective time-domain non-Gaussian noise is approximated well as a Gaussian noise in the frequency-domain, where the estimation takes place. An efficient and low complexity algorithm is developed based on a combination of the MP and the maximum a posteriori probability (MAP) based space-alternating generalized expectation-maximization technique, to improve the estimates of the channel taps and their locations in an iterative manner. Computer simulations show that the UWA channel is estimated very effectively and the proposed algorithm exhibits excellent symbol error rate and channel estimation performance.","Channel estimation,
OFDM,
Matching pursuit algorithms,
Relays,
Signal processing algorithms,
Doppler effect,
Receivers"
Simultaneous Multikernel GPU: Multi-tasking throughput processors via fine-grained sharing,"Studies show that non-graphics programs can be less optimized for the GPU hardware, leading to significant resource under-utilization. Sharing the GPU among multiple programs can effectively improve utilization, which is particularly attractive to systems where many applications require access to the GPU (e.g., cloud computing). However, current GPUs lack proper architecture features to support sharing. Initial attempts are preliminary: They either provide only static sharing, which requires recompilation or code transformation, or they do not effectively improve GPU resource utilization. We propose Simultaneous Multikernel (SMK), a fine-grain dynamic sharing mechanism, that fully utilizes resources within a streaming multiprocessor by exploiting heterogeneity of different kernels. We propose several resource allocation strategies to improve system throughput while maintaining fairness. Our evaluation shows that for shared workloads with complementary resource occupancy, SMK improves GPU throughput by 52% over non-shared execution and 17% over a state-of-the-art design.",
Quality-Aware Sensing Coverage in Budget-Constrained Mobile Crowdsensing Networks,"Mobile crowdsensing has shown elegant capacity in data collection and has given rise to numerous applications. In the sense of coverage quality, marginal works have considered the efficient (less cost) and effective (considerable coverage) design for mobile crowdsensing networks. We investigate the optimal quality-aware coverage in mobile crowdsensing networks. The difference between ours and the conventional coverage problem is that we only select a subset of mobile users so that the coverage quality is maximized with constrained budget. To address this new problem, which is proved to be NP-hard, we first prove that the set function of coverage quality is nondecreasing submodular. By leveraging the favorable property in submodular optimization, we then propose an (1 - (1/e)) approximation algorithm with O(nk+2) time complexity, where k is an integer that is greater than or equal to 3. Finally, we conduct extensive simulations for the proposed scheme, and the results demonstrate that ours outperforms the random selection scheme and one of the state of the art in terms of total coverage quality by, at most, 2.4× and 1.5× and by, on average, 1.4× and 1.3×, respectively. Additionally, ours achieves a near-optimal solution, compared with the brute-force search results.","Mobile communication,
Sensors,
Approximation algorithms,
Mobile computing,
Approximation methods,
Trajectory,
Optimization"
Probing Projections: Interaction Techniques for Interpreting Arrangements and Errors of Dimensionality Reductions,"We introduce a set of integrated interaction techniques to interpret and interrogate dimensionality-reduced data. Projection techniques generally aim to make a high-dimensional information space visible in form of a planar layout. However, the meaning of the resulting data projections can be hard to grasp. It is seldom clear why elements are placed far apart or close together and the inevitable approximation errors of any projection technique are not exposed to the viewer. Previous research on dimensionality reduction focuses on the efficient generation of data projections, interactive customisation of the model, and comparison of different projection techniques. There has been only little research on how the visualization resulting from data projection is interacted with. We contribute the concept of probing as an integrated approach to interpreting the meaning and quality of visualizations and propose a set of interactive methods to examine dimensionality-reduced data as well as the projection itself. The methods let viewers see approximation errors, question the positioning of elements, compare them to each other, and visualize the influence of data dimensions on the projection space. We created a web-based system implementing these methods, and report on findings from an evaluation with data analysts using the prototype to examine multidimensional datasets.","Data visualization,
Visualization,
Distortion,
Heating,
Approximation error,
Stress,
Prototypes"
Long-Term QoS-Aware Cloud Service Composition Using Multivariate Time Series Analysis,"We propose a cloud service composition framework that selects the optimal composition based on an end user's long-term Quality of Service (QoS) requirements. In a typical cloud environment, existing solutions are not suitable when service providers fail to provide the long-term QoS provision advertisements. The proposed framework uses a new multivariate QoS analysis to predict the long-term QoS provisions from service providers' historical QoS data and short-term advertisements represented using Time Series. The quality of the QoS prediction is improved by incorporating QoS attributes' intra correlations into the multivariate analysis. To select the optimal service composition, the proposed framework uses QoS time series' inter correlations and performs a novel time series group similarity approach on the predicted QoS values. Experiments are conducted on real QoS dataset and results prove the efficiency of the proposed approach.","Quality of service,
Time series analysis,
Predictive models,
Correlation,
History,
Mathematical model,
Hidden Markov models"
"Design and Testing of Simple, Electrically Small, Low-Profile, Huygens Source Antennas With Broadside Radiation Performance","The efficacy of a simple, electrically small, low-profile, Huygens source antenna that radiates in its broadside direction is demonstrated numerically and experimentally. First, two types of electrically small, near-field resonant parasitic (NFRP) antennas are introduced and their individual radiation performance characteristics are discussed. The electric one is based on a modified Egyptian axe dipole NFRP element; the magnetic one is based on a capacitively loaded loop NFRP element. In both cases, the driven element is a simple coax-fed dipole antenna, and there is no ground plane. By organically combining these two elements, Huygens source antennas are obtained. A forward propagating demonstrator version was fabricated and tested. The experimental results are in good agreement with their analytical and simulated values. This low profile, ~0.05λ0, and electrically small, ka = 0.645, prototype yielded a peak realized gain of 2.03 dBi in the broadside direction with a front-to-back ratio of 16.92 dB. A backward radiating version is also obtained; its simulated current distribution behavior is compared with that of the forward version to illustrate the design principles.",
Graph Signal Denoising via Trilateral Filter on Graph Spectral Domain,"This paper presents a graph signal denoising method with the trilateral filter defined in the graph spectral domain. The original trilateral filter (TF) is a data-dependent filter that is widely used as an edge-preserving smoothing method for image processing. However, because of the data-dependency, one cannot provide its frequency domain representation. To overcome this problem, we establish the graph spectral domain representation of the data-dependent filter, i.e., a spectral graph TF (SGTF). This representation enables us to design an effective graph signal denoising filter with a Tikhonov regularization. Moreover, for the proposed graph denoising filter, we provide a parameter optimization technique to search for a regularization parameter that approximately minimizes the mean squared error w.r.t. the unknown graph signal of interest. Comprehensive experimental results validate our graph signal processing-based approach for images and graph signals.",
CSI Phase Fingerprinting for Indoor Localization With a Deep Learning Approach,"With the increasing demand of location-based services, indoor localization based on fingerprinting has become an increasingly important technique due to its high accuracy and low hardware requirement. In this paper, we propose PhaseFi, a fingerprinting system for indoor localization with calibrated channel state information (CSI) phase information. In PhaseFi, the raw phase information is first extracted from the multiple antennas and multiple subcarriers of the IEEE 802.11n network interface card by accessing the modified device driver. Then a linear transformation is applied to extract the calibrated phase information, which we prove to have a bounded variance. For the offline stage, we design a deep network with three hidden layers to train the calibrated phase data, and employ the weights of the deep network to represent fingerprints. A greedy learning algorithm is incorporated to train the weights layer-by-layer to reduce computational complexity, where a subnetwork between two consecutive layers forms a restricted Boltzmann machine. In the online stage, we use a probabilistic method based on the radial basis function for online location estimation. The proposed PhaseFi scheme is implemented and validated with extensive experiments in two representation indoor environments. It is shown to outperform three benchmark schemes based on CSI or received signal strength in both scenarios.",
Fundamentals of the Downlink Green Coverage and Energy Efficiency in Heterogeneous Networks,"This paper studies the proposed green (energy-efficient) coverage probability, link and network energy efficiencies in the downlink of a heterogeneous cellular network (HetNet) consisting of K independent Poisson point processes of base stations (BSs). The important statistical properties of the universal (general) cell association functions are first studied, and the cell load statistics for power-law cell association functions, which can characterize the accurate void cell probability of a BS in every tier, are also derived. A simple and feasible green channel-aware cell association (GCA) scheme is proposed and the green coverage probability is also proposed for any particular cell association scheme, such as the maximum received power association (MRPA) and the nearest BS association (NBA) schemes. Then, the link and network energy efficiencies are proposed to characterize the mean spectrum efficiency per unit power consumption for a BS and the mean area spectrum efficiency for the HetNet, respectively. All the tight bounds on the green coverage probability, link, and network energy efficiencies for the GCA, MRPA, and NBA schemes are found. They are theoretically shown to pose the fundamental maximum limits on the link and network energy efficiencies achieved by any other cell association schemes, and such a fact is validated by numerical results as well.","Power demand,
Base stations,
Probability,
Downlink,
Heterogeneous networks,
Load modeling,
Green communications,
Energy efficiency"
Curricular design based in bodies of knowledge: Engineering education for the innovation and the industry,"Bodies of Knowledge (BOK), contain the relevant knowledge for a disciplines as example Software Engineering (SE), System Information (SI), Information Technology (IT), Computer Science (CS), Medicine, Economics, and others areas of knowledge. BOK describes relevant knowledge for a discipline, and will need show the consensus in the Knowledge Areas (KA), and related disciplines. The development of this consensus is a prerequisite to the adoption of coherent skills development in the education context, and continuing professional programs both in public and private organizations. In this context a systematic mapping study (SMS), it was performed to evaluate quantity and types of primary studies in an area of interest. SMS will be used as the research method within this research. The research method proposed will allow to sort and classify the information referent to the topics of this research. This paper is an attempt to analyze existing proposals on BOK contents, structure, and make a proposal what the kind of contents it should have, and how it should be structured so that this consensus among all parties can be described and best achieved. In the same way the relevance, and useful of the BOK in the curricular design for the innovation, and the industry context is present.","Context,
Software engineering,
Knowledge engineering,
Data mining,
Systematics,
Industries,
Software"
Wasserstein Continuity of Entropy and Outer Bounds for Interference Channels,"It is shown that under suitable regularity conditions, differential entropy is O(√n)-Lipschitz as a function of probability distributions on Ilin with respect to the quadratic Wasserstein distance. Under similar conditions, (discrete) Shannon entropy is shown to be O(n)-Lipschitz in distributions over the product space with respect to Ornstein's d̅-distance (Wasserstein distance corresponding to the Hamming distance). These results together with Talagrand's and Marton's transportation-information inequalities allow one to replace the unknown multi-user interference with its independent identically distributed approximations. As an application, a new outer bound for the two-user Gaussian interference channel is proved, which, in particular, settles the missing corner point problem of Costa (1985).","Entropy,
Interference channels,
Couplings,
Hamming distance,
Euclidean distance"
Battery-less Tri-band-Radio Neuro-monitor and Responsive Neurostimulator for Diagnostics and Treatment of Neurological Disorders,"A 0.13 μm CMOS system on a chip (SoC) for 64 channel neuroelectrical monitoring and responsive neurostimulation is presented. The direct-coupled chopper-stabilized neural recording front end rejects up to ±50 mV input dc offset using an in-channel digitally assisted feedback loop. It yields a compact 0.018 mm2 integration area and 4.2 μVrms integrated input-referred noise over 1 Hz to 1 kHz frequency range. A multiplying specific absorption rate (SAR) ADC in each channel calibrates channel-to-channel gain mismatch. A multicore low-power DSP performs synchrony-based neurological event detection and triggers a subset of 64 programmable current-mode stimulators for subsequent neuromodulation. Triple-band FSK/ultra-wideband (UWB) wireless transmitters communicate to receivers located at 10 cm to 10 m distance from the SoC with data rates from 1.2 to 45 Mbps. An inductive link that operates at 1.5 MHz, provides power and is also used to communicate commands to an on-chip ASK receiver. The chip occupies 16 mm2 while consuming 2.17 and 5.8 mW with UWB and FSK transmitters, respectively. Efficacy of the SoC is assessed using a rat model of temporal lobe epilepsy characterized by spontaneous seizures. It exhibits an average seizure detection sensitivity and specificity of 87% and 95%, respectively, with over 78% of all seizures aborted.",
Reduced Daily Recalibration of Myoelectric Prosthesis Classifiers Based on Domain Adaptation,"Control scheme design based on surface electromyography (sEMG) pattern recognition has been the focus of much research on a myoelectric prosthesis (MP) technology. Due to inherent nonstationarity in sEMG signals, prosthesis systems may need to be recalibrated day after day in daily use applications; thereby, hindering MP usability. In order to reduce the recalibration time in the subsequent days following the initial training, we propose a domain adaptation (DA) framework, which automatically reuses the models trained in earlier days as input for two baseline classifiers: a polynomial classifier (PC) and a linear discriminant analysis (LDA). Two novel algorithms of DA are introduced, one for PC and the other one for LDA. Five intact-limbed subjects and two transradial-amputee subjects participated in an experiment lasting ten days, to simulate the application of a MP over multiple days. The experiment results of four methods were compared: PC-DA (PC with DA), PC-BL (baseline PC), LDA-DA (LDA with DA), and LDA-BL (baseline LDA). In a new day, the DA methods reuse nine pretrained models, which were calibrated by 40 s training data per class in nine previous days. We show that the proposed DA methods significantly outperform nonadaptive baseline methods. The improvement in classification accuracy ranges from 5.49% to 28.48%, when the recording time per class is 2 s. For example, the average classification rates of PC-BL and PC-DA are 83.70% and 92.99%, respectively, for intact-limbed subjects with a nine-motions classification task. These results indicate that DA has the potential to improve the usability of MPs based on pattern recognition, by reducing the calibration time.","Training,
Vectors,
Adaptation models,
Polynomials,
Data models,
Feature extraction,
Pattern recognition"
Big Data Meet Green Challenges: Big Data Toward Green Applications,"Big data are widely recognized as being one of the most powerful drivers to promote productivity, improve efficiency, and support innovation. It is highly expected to explore the power of big data and turn big data into big values. To answer the interesting question whether there are inherent correlations between the two tendencies of big data and green challenges, a recent study has investigated the issues on greening the whole life cycle of big data systems. This paper would like to discover the relations between the trend of big data era and that of the new generation green revolution through a comprehensive and panoramic literature survey in big data technologies toward various green objectives and a discussion on relevant challenges and future directions.",
Downlink Power Control in Self-Organizing Dense Small Cells Underlaying Macrocells: A Mean Field Game,"A novel distributed power control paradigm is proposed for dense small cell networks co-existing with a traditional macrocellular network. The power control problem is first modeled as a stochastic game and the existence of the Nash Equilibrium is proven. Then, we extend the formulated stochastic game to a mean field game (MFG) considering a highly dense network. An MFG is a special type of differential game which is ideal for modeling the interactions among a large number of entities. We analyze the performance of two different cost functions for the mean field game formulation. Both of these cost functions are designed using stochastic geometry analysis in such a way that the cost functions are valid for the MFG setting. A finite difference algorithm is then developed based on the Lax-Friedrichs scheme and Lagrange relaxation to solve the corresponding MFG. Each small cell base station can independently execute the proposed algorithm offline, i.e., prior to data transmission. The output of the algorithm shows how each small cell base station should adjust its transmit power in order to minimize the cost over a predefined period of time. Moreover, sufficient conditions for the uniqueness of the mean field equilibrium for a generic cost function are also given. The effectiveness of the proposed algorithm is demonstrated via numerical results.","Games,
Scattering,
Equations,
Mathematical model,
Power control,
Cost function,
Base stations"
SmartScanner: Know More in Walls with Your Smartphone!,"Seeing through walls and knowing clearly what exist inside just like a superman are not only fantastic wishes for humans, but also of much practical significance. For example, you would like to know whether there are pipes, or rebars inside a wall before drilling into it. Moreover, knowing how pipes are configured in a wall before attempting to fix defects would definitely prevent unnecessary damages. Existing methods that intend to address this issue are either costly due to the use of high-end technology, or restrictive for reasons of some strong assumptions. However, in this paper, we present a novel system, SmartScanner, which is based on off-the-shelf sensors embedded in a smartphone. SmartScanner makes full use of in-built sensors, namely, the accelerometer, gyroscope, and magnetometer to achieve this goal inexpensively and conveniently. Specifically, by combining these sensors, we are able to clearly distinguish certain objects inside a wall and map out the layout of an in-wall pipeline system. We implement SmartScanner on two smartphone platforms, namely iPhone 4 and Xiaomi Mi2S, and conduct extensive experiments to evaluate its performance. Experiments show that SmartScanner can achieve high accuracies in distinguishing objects in various scenarios. Meanwhile, as for layout mapping, 90 percent of length errors are limited to several centimeters for horizontal and vertical pipeline segments, respectively. Also, SmartScanner can achieve centimeter-level position errors of turning points in horizontal and vertical directions in the testbed.",
An area-efficient consolidated configurable error correction for approximate hardware accelerators,"Approximate adders are widely being advocated for developing hardware accelerators to perform complex arithmetic operations. Most of the state-of-the-art accuracy configurable approximate adders utilize some integrated Error Detection and Correction (EDC) circuitry. Consequently, the accumulated area overhead due to the EDC (integrated within individual adders) is significant. In this paper, we propose a low-cost Consolidated Error Correction (CEC) unit, that essentially corrects the accumulated error at the accelerator output. The proposed CEC is based on a mathematical model of approximation error. We integrate our CEC unit in approximate hardware accelerators deployed in different applications to demonstrate its area savings and speed enhancement compared to state-of-the-art.","Adders,
Gears,
Error correction,
Hardware,
Electrical engineering,
Approximation error,
Clocks"
Online Volt-Var Control for Distribution Systems With Solid-State Transformers,"In distribution power systems, feeder voltages can be very sensitive to changes in load and/or distributed generation. This paper introduces a solid-state-transformer-based local voltage-control strategy to reduce variability distribution system bus voltages. An online dynamic volt-var control (VVC) algorithm is proposed to regulate bus voltages by injecting or absorbing reactive power through a solid-state transformer (SST). The proposed algorithm does not require any communication between the SST and the substation and makes control decisions locally. The main goal of the voltage-control algorithm is to enforce strict voltage constraints on the system voltages. The proposed control algorithm is validated in a radial and meshed distribution system using PSCAD.",
Analytical and Numerical Methods to Model Anchor Losses in 65-MHz AlN Contour Mode Resonators,"This paper presents and experimentally validates two different approaches to describe the quality factor (Q) due to anchor losses in 65-MHz aluminum nitride (AlN) contour mode resonators (CMRs). The first method is an approach that can be considered qualitative in nature, as it consists of a simplified analytical model that assumes quasi-static anchor conditions and a semi-infinite substrate. Despite its simplicity, it effectively provides designers with some guidelines on how to layout resonator anchors. The second approach is quantitative and consists of a numerical technique that can be considered as an alternative to the use of perfectly matched layers (PMLs). The new finite-element method imposes fixed-constraint (FC) boundary conditions at the edges of the released regions, and the Q is calculated as the ratio of strain energy in both resonator and anchors and the total acoustic energy transferred to the substrate. The two approaches (analytical and numerical) are experimentally validated through measurements of 216 AlN CMRs operating at their fundamental resonance frequency (around 65 MHz). The proposed numerical approach is also compared with the results obtained using PML. This comparison shows that the FC technique has a similar accuracy to PML in predicting Q, but it is superior to the latter when reflections from the clamped boundaries become relevant.","Substrates,
Aluminum nitride,
III-V semiconductor materials,
Acoustics,
Stress,
Vibrations,
Analytical models"
Optimum High-k Oxide for the Best Performance of Ultra-Scaled Double-Gate MOSFETs,"A widely used technique to mitigate gate leakage in ultrascaled metal oxide semiconductor field effect transistors ( mosfets) is the use of high-k dielectrics, which provide the same equivalent oxide thickness (EOT) as SiO2, but thicker physical layers. However, using a thicker physical dielectric for the same EOT has a negative effect on the device performance due to the degradation of 2D electrostatics. In this paper, the effects of high-k oxides on double-gate (DG) mosfet with gate length under 20 nm are studied. All the devices are modeled using an effective mass quantum transport approach based on the quantum transmitting boundary method, where only ballistic transport is considered. We find that there is an optimum physical oxide thickness (TOX) to achieve the best performance in terms of on-current for each gate stack, including SiO2 interface layer and one high-k material. For the same EOT, Al2O3 (k = 9) over 3-Å SiO2 provides the best performance, while for HfO2 (k = 22) and La2O3 (k = 30), SiO2 thicknesses should be 5 Å and 7 Å, respectively. The effects of using high-k oxides and gate stacks on the performance of ultrascaled mosfets are analyzed. While thin oxide thickness increases the gate leakage, the thick oxide layer reduces the gate control on the channel. Therefore, the physical thicknesses of gate stack should be optimized to achieve the best performance.",
Big Data-Driven Service Composition Using Parallel Clustered Particle Swarm Optimization in Mobile Environment,"The proliferation of mobile computing and smartphone technologies has resulted in an increasing number and range of services from myriad service providers. These mobile service providers support numerous emerging services with differing quality metrics but similar functionality. Facilitating an automated service workflow requires fast selection and composition of services from the services pool. The mobile environment is ambient and dynamic in nature, requiring more efficient techniques to deliver the required service composition promptly to users. Selecting the optimum required services in a minimal time from the numerous sets of dynamic services is a challenge. This work addresses the challenge as an optimization problem. An algorithm is developed by combining particle swarm optimization and k-means clustering. It runs in parallel using MapReduce in the Hadoop platform. By using parallel processing, the optimum service composition is obtained in significantly less time than alternative algorithms. This is essential for handling large amounts of heterogeneous data and services from various sources in the mobile environment. The suitability of this proposed approach for big data-driven service composition is validated through modeling and simulation.",
Progress in the Characterizations and Understanding of Conducting Filaments in Resistive Switching Devices,"Characterizations of resistive switching (RS) devices, especially through direct, in situ methodologies, provide valuable information that could lead to improved insights into the device switching mechanism and device design and optimization. Here, we discuss the characterization efforts on resistive switching devices to date, with emphasis on direct transmission electron microscopy observations on conducting filament formation and growth dynamics. Other characterization techniques used in filament analysis such as spectroscopic and topographic characterizations will also be covered. In the end, we will discuss challenges to be addressed and advances that are needed to further our understanding of dynamic ionic, electronic, and structural effects involved in the RS process.",
Hadoop Performance Modeling for Job Estimation and Resource Provisioning,"MapReduce has become a major computing model for data intensive applications. Hadoop, an open source implementation of MapReduce, has been adopted by an increasingly growing user community. Cloud computing service providers such as Amazon EC2 Cloud offer the opportunities for Hadoop users to lease a certain amount of resources and pay for their use. However, a key challenge is that cloud service providers do not have a resource provisioning mechanism to satisfy user jobs with deadline requirements. Currently, it is solely the user's responsibility to estimate the required amount of resources for running a job in the cloud. This paper presents a Hadoop job performance model that accurately estimates job completion time and further provisions the required amount of resources for a job to be completed within a deadline. The proposed model builds on historical job execution records and employs Locally Weighted Linear Regression (LWLR) technique to estimate the execution time of a job. Furthermore, it employs Lagrange Multipliers technique for resource provisioning to satisfy jobs with deadline requirements. The proposed model is initially evaluated on an in-house Hadoop cluster and subsequently evaluated in the Amazon EC2 Cloud. Experimental results show that the accuracy of the proposed model in job execution estimation is in the range of 94.97 and 95.51 percent, and jobs are completed within the required deadlines following on the resource provisioning scheme of the proposed model.","Mathematical model,
Computational modeling,
Estimation,
Upper bound,
Cloud computing,
Data models,
Educational institutions"
Heuristics for Provisioning Services to Workflows in XaaS Clouds,"In XaaS clouds, resources as services (e.g., infrastructure, platform and software as a service) are sold to applications such as scientific and big data analysis workflows. Candidate services with various configurations (CPU type, memory size, number of machines and so on) for the same task may have different execution time and cost. Further, some services are priced rented by intervals that be shared among tasks of the same workflow to save service rental cost. Establishing a task-mode (service) mapping (to get a balance between time and cost) and tabling tasks on rented service instances are crucial for minimizing the client-oriented cost to rent services for the whole workflow. In this paper, a multiple complete critical-path based heuristic (CPIS) is developed for the task-mode mapping problem. A list based heuristic (LHCM) concerning the task processing cost and task-slot matching is developed for tabling tasks on service instances based on the result of task-mode mapping. Then, the effectiveness of the proposed CPIS is compared with that of the previously proposed CPIL, the existing state-of-the-art heuristics including PCP, SC-PCP ( an extension to PCP), DET, and CPLEX. The effectiveness of the proposed LHCM is evaluated with its use with different task-mode mapping algorithms. Experimental results show that the proposed heuristics can reduce 24 percent of the service renting cost than the compared algorithms on the test benchmarks at most for non-shareable services. In addition, half of the service renting cost could be saved when LHCM is applied to consolidate tasks on rented service instances.",
Toward Unconstrained Fingerprint Recognition: A Fully Touchless 3-D System Based on Two Views on the Move,"Touchless fingerprint recognition systems do not require contact of the finger with any acquisition surface and thus provide an increased level of hygiene, usability, and user acceptability of fingerprint-based biometric technologies. The most accurate touchless approaches compute 3-D models of the fingertip. However, a relevant drawback of these systems is that they usually require constrained and highly cooperative acquisition methods. We present a novel, fully touchless fingerprint recognition system based on the computation of 3-D models. It adopts an innovative and less-constrained acquisition setup compared with other previously reported 3-D systems, does not require contact with any surface or a finger placement guide, and simultaneously captures multiple images while the finger is moving. To compensate for possible differences in finger placement, we propose novel algorithms for computing 3-D models of the shape of a finger. Moreover, we present a new matching strategy based on the computation of multiple touch-compatible images. We evaluated different aspects of the biometric system: acceptability, usability, recognition performance, robustness to environmental conditions and finger misplacements, and compatibility and interoperability with touch-based technologies. The proposed system proved to be more acceptable and usable than touch-based techniques. Moreover, the system displayed satisfactory accuracy, achieving an equal error rate of 0.06% on a dataset of 2368 samples acquired in a single session and 0.22% on a dataset of 2368 samples acquired over the course of one year. The system was also robust to environmental conditions and to a wide range of finger rotations. The compatibility and interoperability with touch-based technologies was greater or comparable to those reported in public tests using commercial touchless devices.","Solid modeling,
Shape,
Computational modeling,
Biometrics (access control),
Cameras,
Biological system modeling,
Accuracy"
Deep learning for tactile understanding from visual and haptic data,"Robots which interact with the physical world will benefit from a fine-grained tactile understanding of objects and surfaces. Additionally, for certain tasks, robots may need to know the haptic properties of an object before touching it. To enable better tactile understanding for robots, we propose a method of classifying surfaces with haptic adjectives (e.g., compressible or smooth) from both visual and physical interaction data. Humans typically combine visual predictions and feedback from physical interactions to accurately predict haptic properties and interact with the world. Inspired by this cognitive pattern, we propose and explore a purely visual haptic prediction model. Purely visual models enable a robot to “feel” without physical interaction. Furthermore, we demonstrate that using both visual and physical interaction signals together yields more accurate haptic classification. Our models take advantage of recent advances in deep neural networks by employing a unified approach to learning features for physical interaction and visual observations. Even though we employ little domain specific knowledge, our model still achieves better results than methods based on hand-designed features.","Haptic interfaces,
Visualization,
Robots,
Training,
Neural networks,
Convolution,
Data models"
A Provably Efficient Online Collaborative Caching Algorithm for Multicell-Coordinated Systems,"Caching at the base stations brings the contents closer to the users, reduces the traffic through the backhaul links, and reduces the delay experienced by the cellular users. The cellular network operator may charge the content providers for caching their contents. Moreover, content providers may lose their users if the users are not getting their desired quality of service, such as maximum tolerable delay in Video on Demand services. In this paper, we study the collaborative caching problem for a multicell-coordinated system from the point of view of minimizing the total cost paid by the content providers. We formulate the problem as an Integer Linear Program and prove its NP-completeness. We also provide an online caching algorithm that does not require any knowledge about the contents popularities. We prove that the online algorithm achieves a competitive ratio of O(log (n)), and we show that the best competitive ratio that any online algorithm can achieve is Ω (log (n) / log log (n)). Therefore, our proposed caching algorithm is provably efficient. Through simulations, we show that our online algorithm performs very close to the optimal offline collaborative scheme, and can outperform it when contents popularities are not properly estimated.",
Weakly Supervised Metric Learning for Traffic Sign Recognition in a LIDAR-Equipped Vehicle,"We address the problem of traffic sign recognition in a light detection and ranging (LIDAR)-equipped vehicle. With the help of 3-D LIDAR points, the 2-D multiview sign images will be easily detected from the captured images of street signs. After detection, the sign recognition problem is formulated as a multiview object recognition task. We develop a metric-learning-based template matching approach for this task and learn a distance metric between the captured images and the corresponding sign templates. For each sign, recognition is done via soft voting by the recognition results of its corresponding multiview images. We propose a latent structural support vector machine (SVM)-based weakly supervised metric learning (WSMLR) method to learn the metric and a reliability classifier. The reliability classifier is used to determine each image's reliability, which serves as each image's weight in both the learning and soft voting procedure. We evaluate the proposed method for multiview traffic sign recognition on a multiview traffic sign data set with 112 categories and observe very encouraging results compared with other state-of-the-art methods. In addition, the method can be customized to solve the single-view sign recognition. The performance of our method for single-view sign recognition is tested on two public data sets, showing that our method is comparable with other competitive ones.",
Mobility-Enabled Service Selection for Composite Services,"Mobile business is becoming a reality due to ubiquitous Internet connectivity, popular mobile devices, and widely available cloud services. However, characteristics of the mobile environment, such as mobility, unpredictability, and variation of mobile network's signal strength, present challenges in selecting optimal services for composition. Traditional QoS-aware methods that select individual services with the best QoS may not always result in the best composite service because constant mobility makes the performance of service invocation unpredictable and location-based. This paper discusses the challenges of this problem and defines it in a formal way. To solve this new research problem, we propose a mobility model, a mobility-aware QoS computation rule, and a mobility-enabled selection algorithm with teaching-learning-based optimization. The experimental simulation results demonstrate that our approach can obtain better solutions than current standard composition methods in mobile environments. The approach can obtain near-optimal solutions and has a nearly linear algorithmic complexity with respect to the problem size.",
Energy-Efficient Mobile Association in Heterogeneous Networks With Device-to-Device Communications,"With device-to-device (D2D) communications, a user terminal can be used as a relay node to support multi-hop transmission, so that cell-edge or deeply faded users can obtain a better connective experience. In this paper, we investigate energy-efficient mobile association in D2D-enabled heterogeneous networks. We consider joint access point selection, mode switching, D2D relay node (DRN) selection, and power control to maximize the energy efficiency (EE) of uplink transmission while guaranteeing the quality-of-service requirement of users. The optimization problem can be decomposed into three subproblems: access point selection, power control, and joint mode switching and DRN selection. The joint mode switching and DRN selection problem is a 0-1 integer optimization problem, whose optimal solution can be found by the brute-force searching method that is complexity-prohibitive when the number of DRNs is large. To reduce the complexity involved in computation, channel estimation, and feedback, we develop a distance-based mobile association (DMA) algorithm, which only operates based on the location information of users and DRNs. Simulation results demonstrate that the proposed DMA algorithm can achieve a good tradeoff between the EE and the complexity.",
Mixed Mode Transmission and Resource Allocation for D2D Communication,"In cellular communication systems with optional device-to-device (D2D) links, user equipments (UEs) can operate in either D2D mode or cellular mode for data transport. This work introduces mixed-mode D2D communication in which D2D links can operate in multiple modes through resource multiplexing. Within this framework, we study the problem of maximizing weighted D2D sum rate under cellular rate constraints by optimizing mixed-mode allocation and resource allocation in term of transmit power and subchannel assignment. Due to nonconvex cellular rate constraints and binary constraints of subchannel allocation, this problem is a nonconvex mixed-integer problem that is generally difficult to solve. We propose a two-step approach by introducing energy-splitting variables such that mixed-mode allocation and resource allocation can be decoupled and optimized independently. The resulting algorithm can be distributive, requires little signaling overhead, and has low computational complexity. We present extensive numerical results to demonstrate the practicality of our proposed algorithm with regard to various network parameters.",
Efficient Scheduling of Multiple Mobile Chargers for Wireless Sensor Networks,"In this paper, we study the deployment of multiple mobile charging vehicles to charge sensors in a large-scale wireless sensor network for a given monitoring period so that none of the sensors will run out of energy, where sensors can be charged by the charging vehicles with wireless energy transfer. To minimize the network operational cost, we first formulate a charging scheduling problem of dispatching multiple mobile charging vehicles to collaboratively charge sensors such that the sum of travelling distance (referred to as the service cost) of these vehicles for this monitoring period is minimized, subject to that none of the sensors will run out of energy. Due to NP-hardness of the problem, we then propose a novel approximation algorithm with a guaranteed approximation ratio, assuming that the energy consumption rate of each sensor does not change for the given monitoring period. Otherwise, we devise a heuristic algorithm through modifications to the approximation algorithm. We finally evaluate the performance of the proposed algorithms via experimental simulations. Simulation results show that the proposed algorithms are very promising, which can reduce the service cost by up to 20% in comparison with the service costs delivered by existing ones.","Sensors,
Mobile communication,
Wireless sensor networks,
Approximation algorithms,
Monitoring,
Vehicles,
Energy consumption"
Fourier Spectral Filter Array for Optimal Multispectral Imaging,"Limitations to existing multispectral imaging modalities include speed, cost, range, spatial resolution, and application-specific system designs that lack versatility of the hyperspectral imaging modalities. In this paper, we propose a novel general-purpose single-shot passive multispectral imaging modality. Central to this design is a new type of spectral filter array (SFA) based not on the notion of spatially multiplexing narrowband filters, but instead aimed at enabling single-shot Fourier transform spectroscopy. We refer to this new SFA pattern as Fourier SFA, and we prove that this design solves the problem of optimally sampling the hyperspectral image data.","Hyperspectral imaging,
Detectors,
Multispectral imaging,
Spatial resolution,
Optical variables measurement"
A Wideband Balanced-to-Unbalanced Coupled-Line Power Divider,"A compact wideband balanced-to-unbalanced (BTU) out-of-phase power divider (PD) is proposed in this letter. This novel circuit essentially consists of three pairs of cascaded coupled lines and a grounded resistor for output isolation. By using the even- (odd-) mode method analysis and the traditional transmission-line theory, closed-form design equations for equal power division with out of phase from one differential input to two unbalanced outputs, high output isolation and good common-mode suppression are obtained, simultaneously. In addition, an experimental PD is designed and fabricated. The good performance and the consistency between the simulated and measured results verify our design theory.","Power dividers,
Resistors,
Impedance,
Wideband,
Scattering parameters,
Wireless communication"
A Hybrid-STATCOM With Wide Compensation Range and Low DC-Link Voltage,"This paper proposes a hybrid static synchronous compensator (hybrid-STATCOM) in a three-phase power transmission system that has a wide compensation range and low dc-link voltage. Because of these prominent characteristics, the system costs can be greatly reduced. In this paper, the circuit configuration of hybrid-STATCOM is introduced first. Its V-I characteristic is then analyzed, discussed, and compared with traditional STATCOM and capacitive-coupled STATCOM (C-STATCOM). The system parameter design is then proposed on the basis of consideration of the reactive power compensation range and avoidance of the potential resonance problem. After that, a control strategy for hybrid-STATCOM is proposed to allow operation under different voltage and current conditions, such as unbalanced current, voltage dip, and voltage fault. Finally, simulation and experimental results are provided to verify the wide compensation range and low dc-link voltage characteristics and the good dynamic performance of the proposed hybrid-STATCOM.","Automatic voltage control,
Inverters,
Reactive power,
Loading,
Couplings,
Firing"
Wireless-Powered Cooperative Communications: Power-Splitting Relaying With Energy Accumulation,"A harvest-use-store power splitting (PS) relaying strategy with distributed beamforming is proposed for wireless-powered multi-relay cooperative networks in this paper. Different from the conventional battery-free PS relaying strategy, harvested energy is prioritized to power information relaying while the remainder is accumulated and stored for future usage with the help of a battery in the proposed strategy, which supports an efficient utilization of harvested energy. However, PS affects throughput at subsequent time slots due to the battery operations including the charging and discharging. To this end, PS and battery operations are coupled with distributed beamforming. A throughput optimization problem to incorporate these coupled operations is formulated though it is intractable. To address the intractability of the optimization, a layered optimization method is proposed to achieve the optimal joint PS and battery operation design with non-causal channel state information (CSI), in which the PS and the battery operation can be analyzed in a decomposed manner. Then, a general case with causal CSI is considered, where the proposed layered optimization method is extended by utilizing the statistical properties of CSI. To reach a better tradeoff between performance and complexity, a greedy method that requires no information about subsequent time slots is proposed. Simulation results reveal the upper and lower bound on performance of the proposed strategy, which are reached by the layered optimization method with non-causal CSI and the greedy method, respectively. Moreover, the proposed strategy outperforms the conventional PS-based relaying without energy accumulation and time switching-based relaying strategy.","Batteries,
Relays,
Energy harvesting,
Switches,
Optimization,
RF signals,
Array signal processing"
The Feedback Capacity of the Binary Erasure Channel With a No-Consecutive-Ones Input Constraint,"The input-constrained erasure channel with feedback is considered, where the binary input sequence contains no consecutive ones, i.e., it satisfies the (1, ∞)-RLL constraint. We derive the capacity for this setting, which can be expressed as Cε = max0≤ p≤0.5 ((1-ε)Hb(p))/(1+(1-ε)p) , where ε is the erasure probability and Hb(·) is the binary entropy function. Moreover, we prove that a priori knowledge of the erasure at the encoder does not increase the feedback capacity. The feedback capacity was calculated using an equivalent dynamic programming (DP) formulation with an optimal average-reward that is equal to the capacity. Furthermore, we obtained an optimal encoding procedure from the solution of the DP, leading to a capacity-achieving, zero-error coding scheme for our setting. DP is, thus, shown to be a tool not only for solving optimization problems, such as capacity calculation, but also for constructing optimal coding schemes. The derived capacity expression also serves as the only non-trivial upper bound known on the capacity of the input-constrained erasure channel without feedback, a problem that is still open.","Memoryless systems,
Mathematical model,
Channel coding,
Entropy,
Dynamic programming"
Smokey: Ubiquitous smoking detection with commercial WiFi infrastructures,"Even though indoor smoking ban is being put into practice in civilized countries, existing vision or sensor-based smoking detection methods cannot provide ubiquitous smoking detection. In this paper, we take the first attempt to build a ubiquitous passive smoking detection system, which leverages the patterns smoking leaves on WiFi signals to identify the smoking activity even in the non-line-of-sight and through-wall environments. We study the behaviors of smokers and leverage the common features to recognize the series of motions during smoking, avoiding the target-dependent training set to achieve the high accuracy. We design a foreground detection based motion acquisition method to extract the meaningful information from multiple noisy subcarriers even influenced by posture changes. Without requirements of target's compliance, we leverage the rhythmical patterns of smoking to reduce the detection false positives. We prototype Smokey with the commodity WiFi infrastructure and evaluate its performance in real environments. Experimental results show Smokey is accurate and robust in various scenarios.","IEEE 802.11 Standard,
Wireless communication,
Mouth,
Gesture recognition,
Monitoring,
Sensors,
Training"
Wearable AMC Backed Near-Endfire Antenna for On-Body Communications on Latex Substrate,"A near-endfire, artificial magnetic conductor (AMC) backed wearable antenna is proposed in this paper for wireless body area networks operating in the 2.4-GHz industrial, scientific and medical (ISM) radio band. The latex substrate permittivity has accurately been characterized for realizing a flexible planar Yagi-Uda antenna printed on it using a large-area screenprinting process. The bidirectional-endfire radiation of Yagi- Uda antenna is changed to an off-axis near-endfire radiation using an AMC reflector also printed on latex. The antenna is separated from the upper AMC surface using flexible Styrofoam of thickness 0.044λ0 at 2.4 GHz for the best compromise between keeping the antenna structure low profile and achieving an off-axis beam-tilt radiation of ~74° toward the endfire direction. The 0° reflection phase single-layered AMC and double-layered AMC (D-AMC) surfaces are proposed to reduce the body-absorbed radiation and, consequently, minimize the peak specific absorption rate (SAR) level for 2.4-GHz frequency band. Antenna performance in terms of return loss, radiation efficiency, extent of frequency detuning, gain, and SAR level is studied for free space as well as the CST MWS tissue-equivalent voxel model for all the proposed antenna designs. Antenna deformation bending study when placed on the human body is also performed in this paper. The antenna design is first optimized and fabricated on printed circuit board to verify the concept and then designed over the latex for actual human on-body all-flexible configuration. The Yagi-Uda antenna backed with D-AMC reflector demonstrates the measured return loss bandwidth of 45 MHz (2.425-2.47 GHz) and the gain of 0.12 dBi in the endfire direction with an improved on-body (chest) radiation efficiency of 78.97% and a reduced peak SAR level of 0.714 W/kg (average over 10-g tissue) for the compact overall flexible latex antenna volume of 0.4λ0×0.4λ0×0.076λ0 at 2.4 GHz. To the best of our knowledge, this is the first latex-based endfire antenna for on-body 2.4-GHz wireless communications backed with an AMC periodic metamaterial surface.",
Fast Direct Methods for Gaussian Processes,"A number of problems in probability and statistics can be addressed using the multivariate normal (Gaussian) distribution. In the one-dimensional case, computing the probability for a given mean and variance simply requires the evaluation of the corresponding Gaussian density. In the n-dimensional setting, however, it requires the inversion of an n x n covariance matrix, C, as well as the evaluation of its determinant, det(C). In many cases, such as regression using Gaussian processes, the covariance matrix is of the form C = σ2I + K, where K is computed using a specified covariance kernel which depends on the data and additional parameters (hyperparameters). The matrix C is typically dense, causing standard direct methods for inversion and determinant evaluation to require O(n3) work. This cost is prohibitive for large-scale modeling. Here, we show that for the most commonly used covariance functions, the matrix C can be hierarchically factored into a product of block low-rank updates of the identity matrix, yielding an O(n log2 n) algorithm for inversion. More importantly, we show that this factorization enables the evaluation of the determinant det(C), permitting the direct calculation of probabilities in high dimensions under fairly broad assumptions on the kernel defining K. Our fast algorithm brings many problems in marginalization and the adaptation of hyperparameters within practical reach using a single CPU core. The combination of nearly optimal scaling in terms of problem size with high-performance computing resources will permit the modeling of previously intractable problems. We illustrate the performance of the scheme on standard covariance kernels.","Covariance matrices,
Gaussian processes,
Approximation methods,
Kernel,
Acceleration,
Symmetric matrices,
Matrix decomposition"
A Diffusion and Clustering-Based Approach for Finding Coherent Motions and Understanding Crowd Scenes,"This paper addresses the problem of detecting coherent motions in crowd scenes and presents its two applications in crowd scene understanding: semantic region detection and recurrent activity mining. It processes input motion fields (e.g., optical flow fields) and produces a coherent motion field named thermal energy field. The thermal energy field is able to capture both motion correlation among particles and the motion trends of individual particles, which are helpful to discover coherency among them. We further introduce a two-step clustering process to construct stable semantic regions from the extracted time-varying coherent motions. These semantic regions can be used to recognize pre-defined activities in crowd scenes. Finally, we introduce a cluster-and-merge process, which automatically discovers recurrent activities in crowd scenes by clustering and merging the extracted coherent motions. Experiments on various videos demonstrate the effectiveness of our approach.","Semantics,
Correlation,
Feature extraction,
Trajectory,
Motion detection,
Hidden Markov models,
Thermal energy"
A Truncated Nuclear Norm Regularization Method Based on Weighted Residual Error for Matrix Completion,"Low-rank matrix completion aims to recover a matrix from a small subset of its entries and has received much attention in the field of computer vision. Most existing methods formulate the task as a low-rank matrix approximation problem. A truncated nuclear norm has recently been proposed as a better approximation to the rank of matrix than a nuclear norm. The corresponding optimization method, truncated nuclear norm regularization (TNNR), converges better than the nuclear norm minimization-based methods. However, it is not robust to the number of subtracted singular values and requires a large number of iterations to converge. In this paper, a TNNR method based on weighted residual error (TNNR-WRE) for matrix completion and its extension model (ETNNR-WRE) are proposed. TNNR-WRE assigns different weights to the rows of the residual error matrix in an augmented Lagrange function to accelerate the convergence of the TNNR method. The ETNNR-WRE is much more robust to the number of subtracted singular values than the TNNR-WRE, TNNR alternating direction method of multipliers, and TNNR accelerated proximal gradient with Line search methods. Experimental results using both synthetic and real visual data sets show that the proposed TNNR-WRE and ETNNR-WRE methods perform better than TNNR and Iteratively Reweighted Nuclear Norm (IRNN) methods.","Integrated circuits,
Minimization,
Convergence,
Approximation methods,
Robustness,
Acceleration,
Accuracy"
Stability Evaluation of Interconnected Multi-Inverter Microgrids Through Critical Clusters,"This paper proposes the notion of “critical cluster” in inverter based droop controlled microgrids, thus representing the neighborhood of the distributed generation units that determines the small signal stability margin of the entire system. The clustering starts from the lowest impedance electrical connection between distributed generators, termed as “critical line”. At first, the systematic study of few similar microgrids by means of the eigenvalue analysis of their small signal models reveals the correlation between the location of their dominant low frequency modes and the individual connections between neighboring inverters. Second, the sensitivity analysis of active power droop gain with respect to network parameters confirms the previous findings and shows the dominating effect of the critical line's impedance. Simulations and small signal analysis studies assess the impact of the choice of various interconnection points when two individual droop controlled islanded microgrids are connected to form a single microgrid. At the same time, simplified models on the basis of critical clusters allow the effective approximation of the stability margin corresponding to the original systems. The results reveal that different interconnection points lead to strong variations in the performance of the coupled microgrid both in terms of transient response and small signal stability.",
"Visualization, Selection, and Analysis of Traffic Flows","Visualization of the trajectories of moving objects leads to dense and cluttered images, which hinders exploration and understanding. It also hinders adding additional visual information, such as direction, and makes it difficult to interactively extract traffic flows, i.e., subsets of trajectories. In this paper we present our approach to visualize traffic flows and provide interaction tools to support their exploration. We show an overview of the traffic using a density map. The directions of traffic flows are visualized using a particle system on top of the density map. The user can extract traffic flows using a novel selection widget that allows for the intuitive selection of an area, and filtering on a range of directions and any additional attributes. Using simple, visual set expressions, the user can construct more complicated selections. The dynamic behaviors of selected flows may then be shown in annotation windows in which they can be interactively explored and compared. We validate our approach through use cases where we explore and analyze the temporal behavior of aircraft and vessel trajectories, e.g., landing and takeoff sequences, or the evolution of flight route density. The aircraft use cases have been developed and validated in collaboration with domain experts.","Trajectory,
Visualization,
Aircraft,
Data visualization,
Image color analysis,
Color,
Data mining"
A Novel Approach to Extracting Non-Negative Latent Factors From Non-Negative Big Sparse Matrices,"An inherently non-negative latent factor model is proposed to extract non-negative latent factors from non-negative big sparse matrices efficiently and effectively. A single-element-dependent sigmoid function connects output latent factors with decision variables, such that non-negativity constraints on the output latent factors are always fulfilled and thus successfully separated from the training process with respect to the decision variables. Consequently, the proposed model can be easily and fast built with excellent prediction accuracy. Experimental results on an industrial size sparse matrix are given to verify its outstanding performance and suitability for industrial applications.",
Multi-Path Link Embedding for Survivability in Virtual Networks,"Internet applications are deployed on the same network infrastructure, yet they have diverse performance and functional requirements. The Internet was not originally designed to support the diversity of current applications. Network virtualization enables heterogeneous applications and network architectures to coexist without interference on the same infrastructure. Embedding a virtual network (VN) into a physical network is a fundamental problem in network virtualization. A VN embedding that aims to survive physical (e.g., link) failures is known as the survivable VN embedding (SVNE). A key challenge in the SVNE problem is to ensure VN survivability with minimal resource redundancy. To address this challenge, we propose survivability in multi-path link embedding (SiMPLE). By exploiting path diversity in the physical network, SiMPLE provides guaranteed VN survivability against single link failure while incurring minimal resource redundancy. In case of multiple arbitrary link failures, SiMPLE provides maximal survivability to the VNs. We formulate this problem as an integer linear program and implement it using GNU linear programming kit. We propose a greedy proactive approach to solve larger instances of the problem in case of single link failures. In presence of more than one link failures, we propose a greedy reactive algorithm as an extension to the previous one, which opportunistically recovers the lost bandwidth in the VNs. Simulation results show that SiMPLE outperforms full backup and shared backup schemes for SVNE, and produces near-optimal results.","Substrates,
Bandwidth,
Indium phosphide,
III-V semiconductor materials,
Redundancy,
Internet,
Simulation"
Standardized Evaluation System for Left Ventricular Segmentation Algorithms in 3D Echocardiography,"Real-time 3D Echocardiography (RT3DE) has been proven to be an accurate tool for left ventricular (LV) volume assessment. However, identification of the LV endocardium remains a challenging task, mainly because of the low tissue/blood contrast of the images combined with typical artifacts. Several semi and fully automatic algorithms have been proposed for segmenting the endocardium in RT3DE data in order to extract relevant clinical indices, but a systematic and fair comparison between such methods has so far been impossible due to the lack of a publicly available common database. Here, we introduce a standardized evaluation framework to reliably evaluate and compare the performance of the algorithms developed to segment the LV border in RT3DE. A database consisting of 45 multivendor cardiac ultrasound recordings acquired at different centers with corresponding reference measurements from three experts are made available. The algorithms from nine research groups were quantitatively evaluated and compared using the proposed online platform. The results showed that the best methods produce promising results with respect to the experts' measurements for the extraction of clinical indices, and that they offer good segmentation precision in terms of mean distance error in the context of the experts' variability range. The platform remains open for new submissions.","Image segmentation,
Three-dimensional displays,
Echocardiography,
Ultrasonic imaging,
Hospitals,
Databases"
Tag-Based Image Search by Social Re-ranking,"Social media sharing websites like Flickr allow users to annotate images with free tags, which significantly contribute to the development of the web image retrieval and organization. Tag-based image search is an important method to find images contributed by social users in such social websites. However, how to make the top ranked result relevant and, with diversity, is challenging. In this paper, we propose a social re-ranking system for tag-based image retrieval with the consideration of an image's relevance and diversity. We aim at re-ranking images according to their visual information, semantic information, and social clues. The initial results include images contributed by different social users. Usually each user contributes several images. First, we sort these images by inter-user re-ranking. Users that have higher contribution to the given query rank higher. Then we sequentially implement intra-user re-ranking on the ranked user's image set, and only the most relevant image from each user's image set is selected. These selected images compose the final retrieved results. We build an inverted index structure for the social image dataset to accelerate the searching process. Experimental results on a Flickr dataset show that our social re-ranking method is effective and efficient.","Image retrieval,
Visualization,
Semantics,
Cultural differences,
Flickr,
Media,
Tagging"
Design of a High-Performance System for Secure Image Communication in the Internet of Things,"Image or video exchange over the Internet of Things (IoT) is a requirement in diverse applications, including smart health care, smart structures, and smart transportations. This paper presents a modular and extensible quadrotor architecture and its specific prototyping for automatic tracking applications. The architecture is extensible and based on off-the-shelf components for easy system prototyping. A target tracking and acquisition application is presented in detail to demonstrate the power and flexibility of the proposed design. Complete design details of the platform are also presented. The designed module implements the basic proportional-integral-derivative control and a custom target acquisition algorithm. Details of the sliding-window-based algorithm are also presented. This algorithm performs
20×
faster than comparable approaches in OpenCV with equal accuracy. Additional modules can be integrated for more complex applications, such as search-and-rescue, automatic object tracking, and traffic congestion analysis. A hardware architecture for the newly introduced Better Portable Graphics (BPG) compression algorithm is also introduced in the framework of the extensible quadrotor architecture. Since its introduction in 1987, the Joint Photographic Experts Group (JPEG) graphics format has been the de facto choice for image compression. However, the new compression technique BPG outperforms the JPEG in terms of compression quality and size of the compressed file. The objective is to present a hardware architecture for enhanced real-time compression of the image. Finally, a prototyping platform of a hardware architecture for a secure digital camera (SDC) integrated with the secure BPG (SBPG) compression algorithm is presented. The proposed architecture is suitable for high-performance imaging in the IoT and is prototyped in Simulink. To the best of our knowledge, this is the first ever proposed hardware architecture for SBPG compression integrated with an SDC.","Internet of Things,
Object detection,
Image compression,
Video communication,
Image coding,
Algorithm design and analysis,
Target tracking,
Compression algorithms,
Transform coding,
Smart devices"
Efficient FPGA acceleration of Convolutional Neural Networks using logical-3D compute array,"Convolutional Deep Neural Networks (DNNs) are reported to show outstanding recognition performance in many image-related machine learning tasks. DNNs have a very high computational requirement, making accelerators a very attractive option. These DNNs have many convolutional layers with different parameters in terms of input/output/kernel sizes as well as input stride. Design constraints usually require a single design for all layers of a given DNN. Thus a key challenge is how to design a common architecture that can perform well for all convolutional layers of a DNN, which can be quite diverse and complex. In this paper we present a flexible yet highly efficient 3D neuron array architecture that is a natural fit for convolutional layers. We also present our technique to optimize its parameters including on-chip buffer sizes for a given set of resource constraint for modern FPGAs. Our experimental results targeting a Virtex-7 FPGA demonstrate that our proposed technique can generate DNN accelerators that can outperform the state-of-the-art solutions, by 22% for 32-bit floating-point MAC implementations, and are far more scalable in terms of compute resources and DNN size.",
Formal Verification With Confidence Intervals to Establish Quality of Service Properties of Software Systems,"Formal verification is used to establish the compliance of software and hardware systems with important classes of requirements. System compliance with functional requirements is frequently analyzed using techniques such as model checking, and theorem proving. In addition, a technique called quantitative verification supports the analysis of the reliability, performance, and other quality-of-service (QoS) properties of systems that exhibit stochastic behavior. In this paper, we extend the applicability of quantitative verification to the common scenario when the probabilities of transition between some or all states of the Markov models analyzed by the technique are unknown, but observations of these transitions are available. To this end, we introduce a theoretical framework, and a tool chain that establish confidence intervals for the QoS properties of a software system modelled as a Markov chain with uncertain transition probabilities. We use two case studies from different application domains to assess the effectiveness of the new quantitative verification technique. Our experiments show that disregarding the above source of uncertainty may significantly affect the accuracy of the verification results, leading to wrong decisions, and low-quality software systems.","Markov processes,
Quality of service,
Probabilistic logic,
Software systems,
Model checking,
Analytical models"
Self-Sustainable Communications With RF Energy Harvesting: Ginibre Point Process Modeling and Analysis,"RF-enabled wireless power transfer and energy harvesting has recently emerged as a promising technique to provision perpetual energy replenishment for low-power wireless networks. The network devices are replenished by the RF energy harvested from the transmission of ambient RF transmitters, which offers a practical and promising solution to enable self-sustainable communications. This paper adopts a stochastic geometry framework based on the Ginibre model to analyze the performance of self-sustainable communications over cellular networks with general fading channels. Specifically, we consider the point-to-point downlink transmission between an access point and a battery-free device in the cellular networks, where the ambient RF transmitters are randomly distributed following a repulsive point process, called Ginibre α-determinantal point process (DPP). Two practical RF energy harvesting receiver architectures, namely time-switching and power-splitting, are investigated. We perform an analytical study on the RF-powered device and derive the expectation of the RF energy harvesting rate, the energy outage probability and the transmission outage probability over Nakagami-m fading channels. These are expressed in terms of so-called Fredholm determinants, which we compute efficiently with modern techniques from numerical analysis. Our analytical results are corroborated by the numerical simulations, and the efficiency of our approximations is demonstrated. In practice, the accurate simulation of any of the Fredholm determinant appearing in the manuscript is a matter of seconds. An interesting finding is that a smaller value of α (corresponding to larger repulsion) yields a better transmission outage performance when the density of the ambient RF transmitters is small. However, it yields a lower transmission outage probability when the density of the ambient RF transmitters is large. We also show analytically that the power-splitting architecture outperforms the time-switching architecture in terms of transmission outage performances. Lastly, our analysis provides guidelines for setting the time-switching and power-splitting coefficients at their optimal values.","Radio frequency,
Energy harvesting,
Wireless communication,
Transmitters,
Wireless sensor networks,
Performance evaluation,
Relays"
"Comparative Study and Analysis Among ATGP, VCA, and SGA for Finding Endmembers in Hyperspectral Imagery","Endmember finding has become increasingly important in hyperspectral data exploitation because endmembers can be used to specify unknown particular spectral classes. Pixel purity index (PPI) and N-finder algorithm (N-FINDR) are probably the two most widely used techniques for this purpose where many currently available endmember finding algorithms are indeed derived from these two algorithms and can be considered as their variants. Among them are three well-known algorithms derived from imposing different abundance constraints, that is, abundance-unconstrained automatic target generation process (ATGP), abundance nonnegativity constrained vertex component analysis (VCA), and fully abundance constrained simplex growing algorithm (SGA). This paper explores relationships among these three algorithms and further shows that theoretically they are essentially the same algorithms in the sense of design rationale. The reason that these three algorithms perform differently is not because they are different algorithms, but rather because they use different preprocessing steps, such as initial conditions and dimensionality reduction transforms.","Indexes,
Hyperspectral imaging,
Algorithm design and analysis,
Transforms,
Computer science,
Iterative methods"
Design of Fuzzy Cognitive Maps for Modeling Time Series,"This study elaborates on a comprehensive design methodology of fuzzy cognitive maps (FCMs). Here, the maps are regarded as a modeling vehicle of time series. It is apparent that whereas time series are predominantly numeric, FCMs are abstract constructs operating at the level of abstract entities referred to as concepts and represented by the individual nodes of the map. We introduce a mechanism to represent a numeric time series in terms of information granules constructed in the space of amplitude and change of amplitude of the time series, which, in turn, gives rise to a collection of concepts forming the corresponding nodes of the FCMs. Each information granule is mapped onto a node (concept) of the map. We identify two fundamental design phases of FCMs, namely 1) formation of information granules mapping numeric data (time series) into activation levels of information granules (viz., the nodes of the map), and 2) optimization of information granules at the parametric level, viz., learning (estimating) the weights between the nodes of the map. The learning is typically realized in a supervised mode on a basis of some experimental data. A construction of information granules is realized with the aid of fuzzy clustering, namely fuzzy C-means. The optimization is realized with the use of particle swarm optimization. The proposed approach is illustrated in detail by a series of experiments using a collection of publicly available data.","Time series analysis,
Numerical models,
Optimization,
Data models,
Fuzzy sets,
Performance analysis,
Algorithm design and analysis"
An Efficient Implementation of the Bellman-Ford Algorithm for Kepler GPU Architectures,"Finding the shortest paths from a single source to all other vertices is a common problem in graph analysis. The Bellman-Ford's algorithm is the solution that solves such a single-source shortest path (SSSP) problem and better applies to be parallelized for many-core architectures. Nevertheless, the high degree of parallelism is guaranteed at the cost of low work efficiency, which, compared to similar algorithms in literature (e.g., Dijkstra's) involves much more redundant work and a consequent waste of power consumption. This article presents a parallel implementation of the Bellman-Ford algorithm that exploits the architectural characteristics of recent GPU architectures (i.e., NVIDIA Kepler, Maxwell) to improve both performance and work efficiency. The article presents different optimizations to the implementation, which are oriented both to the algorithm and to the architecture. The experimental results show that the proposed implementation provides an average speedup of
5×
higher than the existing most efficient parallel implementations for SSSP, that it works on graphs where those implementations cannot work or are inefficient (e.g., graphs with negative weight edges, sparse graphs), and that it sensibly reduces the redundant work caused by the parallelization process.","Graphics processing units,
Instruction sets,
Parallel processing,
Heuristic algorithms,
Computer architecture,
Optimization,
Kernel"
Spectral Multimodal Hashing and Its Application to Multimedia Retrieval,"In recent years, multimedia retrieval has sparked much research interest in the multimedia, pattern recognition, and data mining communities. Although some attempts have been made along this direction, performing fast multimodal search at very large scale still remains a major challenge in the area. While hashing-based methods have recently achieved promising successes in speeding-up large-scale similarity search, most existing methods are only designed for uni-modal data, making them unsuitable for multimodal multimedia retrieval. In this paper, we propose a new hashing-based method for fast multimodal multimedia retrieval. The method is based on spectral analysis of the correlation matrix of different modalities. We also develop an efficient algorithm that learns some parameters from the data distribution for obtaining the binary codes. We empirically compare our method with some state-of-the-art methods on two real-world multimedia data sets.","Multimedia communication,
Kernel,
Eigenvalues and eigenfunctions,
Binary codes,
Laplace equations,
Data models,
Algorithm design and analysis"
RBoost: Label Noise-Robust Boosting Algorithm Based on a Nonconvex Loss Function and the Numerically Stable Base Learners,"AdaBoost has attracted much attention in the machine learning community because of its excellent performance in combining weak classifiers into strong classifiers. However, AdaBoost tends to overfit to the noisy data in many applications. Accordingly, improving the antinoise ability of AdaBoost plays an important role in many applications. The sensitiveness to the noisy data of AdaBoost stems from the exponential loss function, which puts unrestricted penalties to the misclassified samples with very large margins. In this paper, we propose two boosting algorithms, referred to as RBoost1 and RBoost2, which are more robust to the noisy data compared with AdaBoost. RBoost1 and RBoost2 optimize a nonconvex loss function of the classification margin. Because the penalties to the misclassified samples are restricted to an amount less than one, RBoost1 and RBoost2 do not overfocus on the samples that are always misclassified by the previous base learners. Besides the loss function, at each boosting iteration, RBoost1 and RBoost2 use numerically stable ways to compute the base learners. These two improvements contribute to the robustness of the proposed algorithms to the noisy training and testing samples. Experimental results on the synthetic Gaussian data set, the UCI data sets, and a real malware behavior data set illustrate that the proposed RBoost1 and RBoost2 algorithms perform better when the training data sets contain noisy data.","Boosting,
Robustness,
Algorithm design and analysis,
Noise measurement,
Noise,
Training,
Estimation"
A Virtual Space Vector Modulation Technique for the Reduction of Common-Mode Voltages in Both Magnitude and Third-Order Component,"A virtual space vector modulation technique reducing both magnitude and third-order harmonic component of the common-mode voltage (CMV) in a two-level voltage-source inverter (VSI) is proposed in this paper. The presented method employs a set of virtual space vectors constructed from original stationary space vectors to conduct modulation. Since the created virtual vectors have the lowest instantaneous and zero average CMVs, both the magnitude and third-order harmonic component of the generated CMV are reduced, contributing to better overall CMV performance and common-mode filter design in VSI applications. Three variants of the proposed modulation method using different virtual space vector combinations are presented. The concept of the virtual space vector modulation technique demonstrated with two-level inverter in this paper can also be extended to multilevel inverters. Simulation and experimental results, as well as comparisons with existing methods are provided to verify the proposed technique.","Vectors,
Modulation,
Switches,
Harmonic analysis,
Power harmonic filters,
Inverters,
Support vector machines"
Minimax Rates of Entropy Estimation on Large Alphabets via Best Polynomial Approximation,"Consider the problem of estimating the Shannon entropy of a distribution over k elements from n independent samples. We show that the minimax mean-square error is within the universal multiplicative constant factors of (k/n log k)2 t log2 k/n if n exceeds a constant factor of (k/log k); otherwise, there exists no consistent estimator. This refines the recent result of Valiant and Valiant that the minimal sample size for consistent entropy estimation scales according to Θ(k/log k). The apparatus of the best polynomial approximation plays a key role in both the construction of optimal estimators and, by a duality argument, the minimax lower bound.",
Design Considerations and Performance Evaluation of 1200-V 100-A SiC MOSFET-Based Two-Level Voltage Source Converter,"Silicon carbide (SiC) MOSFET is capable of achieving better efficiency and better power density of power converters due to its low on-state resistance and lower switching losses compared to silicon (Si) Insulated Gate Bipolar Transistor. Operation of power converters at higher switching frequency using SiC devices allows reduction in filter size and hence improves the power to weight ratio of the converter. This paper presents switching characterization of 1200-V 100-A SiC MOSFET module and compares the efficiency of a two-level voltage source converter (2L-VSC) using SiC MOSFETs and Si IGBTs. Also, various design considerations of the 1200-V 100-A SiC MOSFET-based 2L-VSC including gate drive design, bus bar packaging, and thermal management have been elaborated. The designed and developed 2L-VSC is operated to supply 35 kVA load at 20-kHz switching frequency with dc bus voltage of 800 V and the corresponding experimental results are presented.","Silicon carbide,
MOSFET,
Logic gates,
Switches,
Temperature measurement,
Schottky diodes,
Inductance"
Popularity-driven content caching,"This paper presents a novel cache replacement method - Popularity-Driven Content Caching (PopCaching). PopCaching learns the popularity of content and uses it to determine which content it should store and which it should evict from the cache. Popularity is learned in an online fashion, requires no training phase and hence, it is more responsive to continuously changing trends of content popularity. We prove that the learning regret of PopCaching (i.e., the gap between the hit rate achieved by PopCaching and that by the optimal caching policy with hindsight) is sublinear in the number of content requests. Therefore, PopCaching converges fast and asymptotically achieves the optimal cache hit rate. We further demonstrate the effectiveness of PopCaching by applying it to a movie.douban.com dataset that contains over 38 million requests. Our results show significant cache hit rate lift compared to existing algorithms, and the improvements can exceed 40% when the cache capacity is limited. In addition, PopCaching has low complexity.",
Contextual Sentiment Topic Model for Adaptive Social Emotion Classification,"Social emotion classification is important for numerous applications, such as public opinion measurement, corporate reputation estimation, and customer preference analysis. However, topics that evoke a certain emotion in the general public are often context-sensitive, making it difficult to train a universal classifier for all collections. A multilabeled sentiment topic model, namely, the contextual sentiment topic model (CSTM), can be used for adaptive social emotion classification. The CSTM distinguishes context-independent topics from both a background theme, which characterizes nondiscriminative information, and a contextual theme, which characterizes context-dependent information across different collections. Experimental results demonstrated the effectiveness of this model for the adaptive classification of social emotions.","Adaptation models,
Context modeling,
Sentiment analysis,
Intelligent systems,
Emotion recognition,
Economics"
Radio-Over-Fiber Technologies for Emerging Wireless Systems,"This paper describes some recently developed novel radio-over-fiber technologies that can support the implementation of future advanced wireless networks incorporating fiber optic distribution networks. Some of the technologies that are actively being explored and have the potential to significantly impact next generation converged networks include active antenna systems, centralized BBU architectures, and 60 GHz small cells. A major challenge in the successful realization of the optical distribution network for future wireless fronthaul will be the very large bit rates per cell site that must be supported between the RRH and BBU. We also describe how bandpass ampling could help to reduce the link data rates and discuss how analog optical distribution networks may offer a viable alternative to conventional digital fiber optic links for next generation integrated optical/wireless networks.","Optical fibers,
Wireless communication,
Optical fiber networks,
Computer architecture,
Antennas"
Fundamental Limits of Communication With Low Probability of Detection,"This paper considers the problem of communication over a discrete memoryless channel (DMC) or an additive white Gaussian noise (AWGN) channel subject to the constraint that the probability that an adversary who observes the channel outputs can detect the communication is low. In particular, the relative entropy between the output distributions when a codeword is transmitted and when no input is provided to the channel must be sufficiently small. For a DMC whose output distribution induced by the “off” input symbol is not a mixture of the output distributions induced by other input symbols, it is shown that the maximum amount of information that can be transmitted under this criterion scales like the square root of the blocklength. The same is true for the AWGN channel. Exact expressions for the scaling constant are also derived.",
A Real-Time Electrically Controlled Active Matching Circuit Utilizing Genetic Algorithms for Wireless Power Transfer to Biomedical Implants,"This paper discusses the feasibility of a real-time active matching circuit (MC) for wireless power transfer applications, especially for biomedical systems. One prototype of low-cost real-time automatic MC, utilizing a variable circuit topology, including discrete passives and p-i-n diodes, has been implemented and the principle has been verified by measurements. One genetic algorithm was introduced to optimize the design over a wide range of impedances to match. As a result of preliminary operation verification tests, the proposed real-time MC system results in improving the transfer coefficient in the range of 10-16-cm coil separation distance a maximum of 3.2 dB automatically in about 64 ms. Similar performance improvement results were observed in additional tests under misaligned conditions, as well as for nonsymmetrical Tx-Rx coil configurations further verifying the potential applicability of the proposed system to practical biomedical devices.",
V2V QoS Guaranteed Channel Access in IEEE 802.11p VANETs,"IEEE 802.11p Wireless Access in the Vehicular Environment (WAVE) has been serving as the de facto wireless protocol for a Vehicular Ad hoc Network (VANET) with the explosive growth of vehicular applications. These applications require guaranteed Quality-of-Service (QoS). However, the fundamental channel access mechanism of WAVE, Enhanced Distributed Channel Access (EDCA), is not able to provide guaranteed QoS due to the unpredictable random access. To remedy this problem, we propose a novel channel access scheme, called Earliest Deadline First based Carrier Sense Multiple Access (EDF-CSMA). EDF-CSMA based on EDCA dynamically adjusts the priority of real-time streaming to avoid collision and introduces an admission control policy according to time constraints to provide guaranteed QoS in multi-channel environments. An analytical model is carried out to study and compare the channel utilization of EDF-CSMA and QoS-aware Hybrid Coordination Function (HCF) controlled channel access (HCCA) method. The result shows that 60 percent of channel utilization is improved by EDF-CSMA. Additionally, real video-based simulations are conducted to evaluate the performance of EDF-CSMA and the existing EDCA method. The results show that EDF-CSMA reaches better QoS support than EDCA while maintaining efficient channel utilization.","Quality of service,
Delays,
Multiaccess communication,
Data communication,
Switches,
Wireless communication,
Vehicles"
A Novel Transformer-less Interleaved Four-Phase Step-Down DC Converter With Low Switch Voltage Stress and Automatic Uniform Current-Sharing Characteristics,"In this paper, we propose a novel transformer-less direct current (dc) converter that features low switch voltage stress and automatic uniform current sharing. An interleaved four-phase voltage divider operating from a 400 V dc bus is used to achieve a high step-down conversion ratio with a moderate duty ratio. Based on the capacitive voltage division, the proposed converter achieves two major objectives, i.e., increased voltage conversion ratio, due to energy storage in the blocking capacitors, and reduced voltage stress of active switches and diodes. As a result, the proposed converter permits the use of lower voltage rating MOSFETs to reduce both switching and conduction losses, thereby improving the overall efficiency. In addition, due to the charge balance of the capacitors, the proposed converter enables automatic uniform current sharing of the interleaved phases without adding extra circuitry or complex control methods. The operation principles and performance analyses of the proposed converter are presented, and its effectiveness is verified by a 500 W output power prototype circuit that converts 400 V input voltage into 24 V output voltage.",
Multi-View Clustering Based on Belief Propagation,"The availability of many heterogeneous but related views of data has arisen in numerous clustering problems. Different views encode distinct representations of the same data, which often admit the same underlying cluster structure. The goal of multi-view clustering is to properly combine information from multiple views so as to generate high quality clustering results that are consistent across different views. Based on max-product belief propagation, we propose a novel multi-view clustering algorithm termed multi-view affinity propagation (MVAP). The basic idea is to establish a multi-view clustering model consisting of two components, which measure the within-view clustering quality and the explicit clustering consistency across different views, respectively. Solving this model is NP-hard, and a multi-view affinity propagation is proposed, which works by passing messages both within individual views and across different views. However, the exemplar consistency constraint makes the optimization almost impossible. To this end, by using some previously designed mathematical techniques, the messages as well as the cluster assignment vector computations are simplified to get simple yet functionally equivalent computations. Experimental results on several real-world multi-view datasets show that MVAP outperforms existing multi-view clustering algorithms. It is especially suitable for clustering more than two views.",
EB Scheme-Based Hybrid SE-FE DGTD Method for Multiscale EM Simulations,"This communication presents an EB scheme subdomain-level discontinuous Galerkin time domain (DGTD) method for multiscale simulations. It is an extension of the previous subdomain-level DGTD research by combining the degree of freedom efficiency of spectral element time domain method and the mesh flexibility of the finite element time domain method. Thus, the multiscale problems can be solved efficiently by separating the geometrically fine and coarse parts and meshing them with hexahedrons and tetrahedrons, respectively, via a nonconformal mesh. The implicit-explicit Runge-Kutta method is applied to the EB scheme DGTD method to obtain an efficient time integration approach.",
Dynamic Facial Expression Recognition With Atlas Construction and Sparse Representation,"In this paper, a new dynamic facial expression recognition method is proposed. Dynamic facial expression recognition is formulated as a longitudinal groupwise registration problem. The main contributions of this method lie in the following aspects: 1) subject-specific facial feature movements of different expressions are described by a diffeomorphic growth model; 2) salient longitudinal facial expression atlas is built for each expression by a sparse groupwise image registration method, which can describe the overall facial feature changes among the whole population and can suppress the bias due to large intersubject facial variations; and 3) both the image appearance information in spatial domain and topological evolution information in temporal domain are used to guide recognition by a sparse representation method. The proposed framework has been extensively evaluated on five databases for different applications: the extended Cohn-Kanade, MMI, FERA, and AFEW databases for dynamic facial expression recognition, and UNBC-McMaster database for spontaneous pain expression monitoring. This framework is also compared with several state-of-the-art dynamic facial expression recognition methods. The experimental results demonstrate that the recognition rates of the new method are consistently higher than other methods under comparison.",
Cost-Effective Survivable Virtual Optical Network Mapping in Flexible Bandwidth Optical Networks,"This paper addresses the minimum network cost problem for survivable virtual optical network mapping in flexible bandwidth optical networks. For each virtual link, we provide dedicated-path protection, i.e., primary path and backup path, to guarantee high survivability on the physical network. To simplify the virtual links mapping, an extended auxiliary graph is constructed by coordinating the virtual optical network and the physical network. We develop an integer linear program (ILP) model, the LBSD (the largest bandwidth requirement (LB) of virtual links versus the shortest distance (SD)) mapping approach, the LCSD (the largest computing (LC) resources requirement versus the shortest distance) mapping approach to minimize the network cost for a given set of VONs. For comparison, we also introduce one baseline mapping approach, named LCLC (the largest computing resources requirement versus the largest computing resources (LC) provisioning), and the lower bound. Simulation results show that, comparing to the LCLC mapping approach, the ILP model, the LBSD and LCSD mapping approaches not only solve the problem of minimizing the total network cost but also guarantee that the spectrum usage and the number of regenerators are minimum. The ILP model and the LBSD mapping approach are greatly close to a lower bound of network cost and perform the same results as a lower bound of spectrum usage in both the 6-node network and the 14-node network. As a result, our proposed LBSD mapping approach can efficiently reduce the network cost, spectrum usage, and the number of regenerators, which is near the optimal solutions of the ILP model.","Optical fiber networks,
Bandwidth,
Computational modeling,
Repeaters,
Cloud computing,
Virtualization,
Computer architecture"
Solar Power Prediction Assisted Intra-task Scheduling for Nonvolatile Sensor Nodes,"With the advent of the era of trillion sensors, solar-powered sensor nodes are widely used as they do not require battery charging or replacement. However, the limited and intermittent solar energy supply seriously affects deadline miss rate (DMR) of tasks. Furthermore, traditional solar-powered sensor nodes also suffer from energy loss of battery charging and voltage conversion. Recently, a storage-less and converter-less power supply architecture has been proposed to achieve higher energy efficiency by removing the leaky energy storage and dc voltage conversion. Without energy storages, a node using inter-task scheduling is more sensitive to solar variations, which results in high DMRs. This paper proposes an intra-task scheduling scheme for the storage-less and converter-less solar-powered sensor nodes, whose features include power prediction based on classified solar profiles, a trigger mechanism to select scheduling points, an artificial neural network to calculate task priorities and a fine-grained task selection algorithm. Experimental results show that the proposed algorithm reduces DMR by up to 30% and improves energy utilization efficiency by 20% with trivial energy overheads.",
A Simple and Accurate TDOA-AOA Localization Method Using Two Stations,"This letter focuses on locating passively a point source in the three-dimensional (3D) space, using the hybrid measurements of time difference of arrival (TDOA) and angle of arrival (AOA) observed at two stations. We propose a simple closed-form solution method by constructing new relationships between the hybrid measurements and the unknown source position. The mean-square error (MSE) matrix of the proposed solution is derived under the small error condition. Theoretical analysis discloses that the performance of the proposed solution can attain the Cramér-Rao bound (CRB) for Gaussian noise over the small error region where the bias compared to variance is small to be ignored. The proposed solution can be extended directly to more than two observing stations with CRB performance maintained theoretically. Simulations validate the performance of the proposed method.","Three-dimensional displays,
Sea measurements,
Position measurement,
Closed-form solutions,
Cramer-Rao bounds,
Maximum likelihood estimation,
Azimuth"
BiSet: Semantic Edge Bundling with Biclusters for Sensemaking,"Identifying coordinated relationships is an important task in data analytics. For example, an intelligence analyst might want to discover three suspicious people who all visited the same four cities. Existing techniques that display individual relationships, such as between lists of entities, require repetitious manual selection and significant mental aggregation in cluttered visualizations to find coordinated relationships. In this paper, we present BiSet, a visual analytics technique to support interactive exploration of coordinated relationships. In BiSet, we model coordinated relationships as biclusters and algorithmically mine them from a dataset. Then, we visualize the biclusters in context as bundled edges between sets of related entities. Thus, bundles enable analysts to infer task-oriented semantic insights about potentially coordinated activities. We make bundles as first class objects and add a new layer, “in-between”, to contain these bundle objects. Based on this, bundles serve to organize entities represented in lists and visually reveal their membership. Users can interact with edge bundles to organize related entities, and vice versa, for sensemaking purposes. With a usage scenario, we demonstrate how BiSet supports the exploration of coordinated relationships in text analytics.","Visualization,
Semantics,
Image edge detection,
Data analytics,
Encoding"
Pareto Dominance-Based Multiobjective Optimization Method for Distribution Network Reconfiguration,"With ever increasing deployment of automation and communication systems in smart grids, distribution network reconfiguration is becoming a viable solution for improving the operation of power grids. A novel hybrid optimization algorithm is proposed in this paper that determines Pareto frontiers, as the candidate solutions, for multiobjective distribution network reconfiguration problem. The proposed hybrid optimization algorithm combines the concept of fuzzy Pareto dominance with shuffled frog leaping algorithm (SFLA) to recognize optimal nondominated solutions identified by SFLA. The local search step of SFLA is also customized for power systems application so that it automatically creates and analyzes only the feasible and radial configurations in its optimization procedure, which significantly increases the convergence speed of the algorithm. Moreover, an adaptive reliability-based frog encoding is introduced that supervises the algorithm to concentrate on more reliable network topologies. The performance of the proposed method is demonstrated on a 136-bus electricity distribution network.","Switches,
Voltage fluctuations,
Optimization,
Reliability,
Power system reliability,
Linear programming,
Encoding"
High Performance Optical Modulator Based on Electro-Optic Polymer Filled Silicon Slot Photonic Crystal Waveguide,"Silicon-organic hybrid integrated devices have emerging applications ranging from high-speed optical interconnects to photonic electromagnetic-field sensors. Silicon slot photonic crystal waveguides (PCWs) filled with electro-optic (EO) polymers combine the slow-light effect in PCWs with the high polarizability of EO polymers, which promises the realization of high-performance optical modulators. In this paper, a high-speed, power-efficient, low-dispersion, and compact optical modulator based on an EO polymer filled silicon slot PCW is presented. Lattice-shifted PCWs are utilized to engineer the photonic band diagram and thus enable an 8 nm-wide low-dispersion spectrum range, which is over an order of magnitude wider than that in modulators based on non-band-engineered PCWs and ring-resonators. A small voltage-length product of Vπ × L = 0.282 V × mm measured at 100 KHz is achieved by slow-light enhancement, corresponding to an unprecedented record-high effective in-device EO coefficient (r33) of 1230 pm/V among silicon-organic hybrid modulators. Excluding the slow-light effect, the actual in-device r33 is estimated to be 98 pm/V. By engineering the RC time constant via silicon doping and also utilizing a backside gate technique, the 3-dB modulation bandwidth of the device is measured to be 15 GHz. In addition, the RF power consumption of the modulator is estimated to be 24 mW at 10 GHz, and the estimated energy consumption for potential digital modulations is approximately 94.4 fJ/bit at 10 Gb/s.","Silicon,
Electrooptic modulators,
Polymers,
Electrooptical waveguides,
Frequency modulation,
Radio frequency"
TelCoVis: Visual Exploration of Co-occurrence in Urban Human Mobility Based on Telco Data,"Understanding co-occurrence in urban human mobility (i.e. people from two regions visit an urban place during the same time span) is of great value in a variety of applications, such as urban planning, business intelligence, social behavior analysis, as well as containing contagious diseases. In recent years, the widespread use of mobile phones brings an unprecedented opportunity to capture large-scale and fine-grained data to study co-occurrence in human mobility. However, due to the lack of systematic and efficient methods, it is challenging for analysts to carry out in-depth analyses and extract valuable information. In this paper, we present TelCoVis, an interactive visual analytics system, which helps analysts leverage their domain knowledge to gain insight into the co-occurrence in urban human mobility based on telco data. Our system integrates visualization techniques with new designs and combines them in a novel way to enhance analysts' perception for a comprehensive exploration. In addition, we propose to study the correlations in co-occurrence (i.e. people from multiple regions visit different places during the same time span) by means of biclustering techniques that allow analysts to better explore coordinated relationships among different regions and identify interesting patterns. The case studies based on a real-world dataset and interviews with domain experts have demonstrated the effectiveness of our system in gaining insights into co-occurrence and facilitating various analytical tasks.",
Hyperspectral Anomaly Detection by Graph Pixel Selection,"Hyperspectral anomaly detection (AD) is an important problem in remote sensing field. It can make full use of the spectral differences to discover certain potential interesting regions without any target priors. Traditional Mahalanobis-distance-based anomaly detectors assume the background spectrum distribution conforms to a Gaussian distribution. However, this and other similar distributions may not be satisfied for the real hyperspectral images. Moreover, the background statistics are susceptible to contamination of anomaly targets which will lead to a high false-positive rate. To address these intrinsic problems, this paper proposes a novel AD method based on the graph theory. We first construct a vertex- and edge-weighted graph and then utilize a pixel selection process to locate the anomaly targets. Two contributions are claimed in this paper: 1) no background distributions are required which makes the method more adaptive and 2) both the vertex and edge weights are considered which enables a more accurate detection performance and better robustness to noise. Intensive experiments on the simulated and real hyperspectral images demonstrate that the proposed method outperforms other benchmark competitors. In addition, the robustness of the proposed method has been validated by using various window sizes. This experimental result also demonstrates the valuable characteristic of less computational complexity and less parameter tuning for real applications.","Hyperspectral imaging,
Detectors,
Manifolds,
Kernel,
Image edge detection,
Robustness"
Wireless Communications under Broadband Reactive Jamming Attacks,"A reactive jammer jams wireless channels only when target devices are transmitting; Compared to constant jamming, reactive jamming is harder to track and compensate against [2], [38]. Frequency hopping spread spectrum (FHSS) and direct sequence spread spectrum (DSSS) have been widely used as countermeasures against jamming attacks. However, both will fail if the jammer jams all frequency channels or has high transmit power. In this paper, we propose an anti-jamming communication system that allows communication in the presence of a broadband and high power reactive jammer. The proposed system transmits messages by harnessing the reaction time of a reactive jammer. It does not assume a reactive jammer with limited spectrum coverage and transmit power, and thus can be used in scenarios where traditional approaches fail. We develop a prototype of the proposed system using GNURadio. Our experimental evaluation shows that when a powerful reactive jammer is present, the prototype still keeps communication, whereas other schemes such as 802.11 DSSS fail completely.","Jamming,
Receivers,
Constellation diagram,
Wireless communication,
Synchronization,
Spread spectrum communication"
Strategy Configurations of Multiple Users Competition for Cloud Service Reservation,"In this paper, we focus on strategy configurations of multiple users to make cloud service reservation. We consider the problem from a game theoretic perspective and formulate it into a non-cooperative game among the multiple cloud users, in which each user is informed with incomplete information of other users. For each user, we design a utility function which combines the net profit with time efficiency and try to maximize its value. We solve the problem by employing variational inequality (VI) theory and prove that there exists a Nash equilibrium solution set for the formulated game. Then, we propose an iterative proximal algorithm (IPA), which is designed to compute a Nash equilibrium solution. The convergence of the IPA algorithm is also analyzed and we find that it converges to a Nash equilibrium if several conditions are satisfied. Finally, we conduct some numerical calculations to verify our theoretical analysis. The experimental results show that our proposed IPA algorithm converges to a stable state very quickly and improves the utilities of all users to certain extent by configuring a proper request strategy.","Games,
Servers,
Nash equilibrium,
Pricing,
Algorithm design and analysis,
Time factors"
Robust Transceiver Design for MISO Interference Channel With Energy Harvesting,"In this paper, we consider the multiuser multiple-input single-output (MISO) interference channel where the received signal is divided into two parts for information decoding and energy harvesting (EH), respectively. The transmit beamforming vectors and receive power splitting (PS) ratios are jointly designed in order to minimize the total transmission power subject to both signal-to-interference-plus-noise ratio (SINR) and EH constraints. Most joint beamforming and power splitting (JBPS) designs assume that perfect channel state information (CSI) is available; however CSI errors are inevitable in practice. To overcome this limitation, we study the robust JBPS design problem assuming a norm-bounded error (NBE) model for the CSI. Three different solution approaches are proposed for the robust JBPS problem, each one leading to a different computational algorithm. Firstly, an efficient semidefinite relaxation (SDR)-based approach is presented to solve the highly non-convex JBPS problem, where the latter can be formulated as a semidefinite programming (SDP) problem. A rank-one recovery method is provided to recover a robust feasible solution to the original problem. Secondly, based on second order cone programming (SOCP) relaxation, we propose a low complexity approach with the aid of a closed-form robust solution recovery method. Thirdly, a new iterative method is also provided which can achieve near-optimal performance when the SDR-based algorithm results in a higher-rank solution. We prove that this iterative algorithm monotonically converges to a Karush-Kuhn-Tucker (KKT) solution of the robust JBPS problem. Finally, simulation results are presented to validate the robustness and efficiency of the proposed algorithms.","Receivers,
Robustness,
Interference channels,
Array signal processing,
Signal to noise ratio,
Transmitters"
Anti-Eavesdropping Schemes for Interference Alignment (IA)-Based Wireless Networks,"In interference alignment (IA)-based networks, interferences are constrained into certain subspaces at the unintended receivers, and the desired signal can be recovered free of interference. Due to the superposition of signals from legitimate users at the eavesdropper, the IA-based network seems to be more secure than conventional wireless networks. Nevertheless, when adequate antennas are equipped, the legitimate information can still be eavesdropped. In this paper, we analyze the performance of the external eavesdropper, and propose two anti-eavesdropping schemes for IA-based networks. When the channel state information (CSI) of eavesdropper is available, zero-forcing scheme can be utilized, in which the transmitted signals are zero-forced at the eavesdropper through the precoding of transmitters in IA-based networks. Furthermore, a more generalized artificial noise (AN) scheme is proposed for IA-based networks without the knowledge of eavesdropper's CSI. In this scheme, a single-stream AN is generated by each user, which will disrupt the eavesdropping without introducing any additional interference to the legitimate transmission of IA-based networks. In addition, the feasibility conditions, transmission rate, and eavesdropping rate are analyzed in detail, and an iterative algorithm to achieve the scheme is also designed. Extensive simulation results are provided to verify our analysis results and show the effectiveness of the proposed anti-eavesdropping schemes for IA-based networks.","Interference,
Wireless networks,
Receivers,
Transmitters,
Security,
Covariance matrices"
Novel Location-Constrained Virtual Network Embedding LC-VNE Algorithms Towards Integrated Node and Link Mapping,"This paper tries to solve the location-constrained virtual network embedding (LC-VNE) problem efficiently. We first investigate the complexity of LC-VNE, and by leveraging the graph bisection problem, we provide the first formal proof of the NP-completeness and inapproximability result of LC-VNE. Then, we propose two novel LC-VNE algorithms based on a compatibility graph (CG) to achieve integrated node and link mapping. In particular, in the CG, each node represents a candidate substrate path for a virtual link, and each link indicates the compatible relation between its two endnodes. Our theoretical analysis proves that the maximal clique in the CG is also the maximum one when the substrate network has sufficient resources. With CG, we reduce LC-VNE to the minimumcost maximum clique problem, which inspires us to propose two efficient LC-VNE heuristics. Extensive numerical simulations demonstrate that compared with the existing ones, our proposed LC-VNE algorithms have significantly reduced time complexity and can provide smaller gaps to the optimal solutions, lower blocking probabilities, and higher time-average revenue as well.",
Evolutionary undersampling for extremely imbalanced big data classification under apache spark,"The classification of datasets with a skewed class distribution is an important problem in data mining. Evolutionary undersampling of the majority class has proved to be a successful approach to tackle this issue. Such a challenging task may become even more difficult when the number of the majority class examples is very big. In this scenario, the use of the evolutionary model becomes unpractical due to the memory and time constrictions. Divide-and-conquer approaches based on the MapReduce paradigm have already been proposed to handle this type of problems by dividing data into multiple subsets. However, in extremely imbalanced cases, these models may suffer from a lack of density from the minority class in the subsets considered. Aiming at addressing this problem, in this contribution we provide a new big data scheme based on the new emerging technology Apache Spark to tackle highly imbalanced datasets. We take advantage of its in-memory operations to diminish the effect of the small sample size. The key point of this proposal lies in the independent management of majority and minority class examples, allowing us to keep a higher number of minority class examples in each subset. In our experiments, we analyze the proposed model with several data sets with up to 17 million instances. The results show the goodness of this evolutionary undersampling model for extremely imbalanced big data classification.","Big data,
Sparks,
Data mining,
Data models,
Biological cells,
Proposals,
Standards"
Mobile Data Offloading Through Caching in Residential 802.11 Wireless Networks,"As the ever growing mobile data traffic challenges the economic viability and performance of cellular networks, innovative solutions that harvest idle user-owned network resources are gaining increasing interest. In this work, we propose leasing wireless bandwidth and cache space of residential 802.11 (WiFi) access points (APs) for offloading mobile data. This solution not only reduces cellular network congestion, but, due to caching, improves also the user-perceived network performance without overloading the backhaul links of the APs. To encourage residential users to contribute their bandwidth and cache resources, we design monetary incentive (reimbursement) schemes. The offered reimbursements directly determine the amounts of available bandwidth and cache space in every AP, which in turn affect the caching policy (where to cache each content file) and the routing policy (where to route each mobile data request). In order to reduce operator's total cost for serving mobile data requests and leasing resources, we introduce a framework for the joint optimization of incentive, caching, and routing policies. Using a novel WiFi usage dataset collected from 167 residences, we show that in densely populated areas with relatively costly network capacity upgrades, our proposal can halve operator's total cost, while reimbursing up to 9€ per month each residential user.","IEEE 802.11 Standard,
Mobile communication,
Bandwidth,
Mobile computing,
Routing,
Wireless networks"
CCR: Clustering and Collaborative Representation for Fast Single Image Super-Resolution,"Clustering and collaborative representation (CCR) have recently been used in fast single image super-resolution (SR). In this paper, we propose an effective and fast single image super-resolution (SR) algorithm by combining clustering and collaborative representation. In particular, we first cluster the feature space of low-resolution (LR) images into multiple LR feature subspaces and group the corresponding high-resolution (HR) feature subspaces. The local geometry property learned from the clustering process is used to collect numerous neighbor LR and HR feature subsets from the whole feature spaces for each cluster center. Multiple projection matrices are then computed via collaborative representation to map LR feature subspaces to HR subspaces. For an arbitrary input LR feature, the desired HR output can be estimated according to the projection matrix, whose corresponding LR cluster center is nearest to the input. Moreover, by learning statistical priors from the clustering process, our clustering-based SR algorithm would further decrease the computational time in the reconstruction phase. Extensive experimental results on commonly used datasets indicate that our proposed SR algorithm obtains compelling SR images quantitatively and qualitatively against many state-of-the-art methods.","Clustering algorithms,
Feature extraction,
Dictionaries,
Image reconstruction,
Collaboration,
Image resolution,
Geometry"
Silicon-Based Floating-Body Synaptic Transistor With Frequency-Dependent Short- and Long-Term Memories,A new synaptic transistor was fabricated with two separated gates based on a FinFET structure in order to mimic short- and long-term memories in a biological synapse and connect with a postsynaptic neuron circuit directly. The transition between short- and long-term memories occurred after applying repetitive input pulses and strongly depended upon intervals between input pulses. These findings indicate that it has very similar learning characteristics with a biological synapse and the possibility as a synaptic device in neuromorphic systems.,
Faster-Than-Nyquist Broadcasting in Gaussian Channels: Achievable Rate Regions and Coding,"We consider the concept of faster-than-Nyquist rate (FTN) broadcasting, which nonorthogonally multiplexes more than one user message in the continuous-time domain for transmission over broadcast channels. Two FTN broadcasting approaches, namely, sub-FTN and full-FTN, are considered for broadcasting of K independent messages over K-user continuous time Gaussian broadcast channel. The derived achievable rate regions of the two approaches are shown to be, in general, greater than the capacity region of the optimally coded Nyquist-rate broadcasting using a same modulating pulse. The full-FTN broadcasting provides larger degrees of freedom (capacity pre-log factor) to each user of the broadcast channel while the sub-FTN improves signal-to-interference-plus-noise-ratios of the individual link. The amount of capacity gains in high SNR regime is linearly proportional to excess bandwidth in the modulating pulse used and dependent on FTN signaling rates, channel SNRs, and number of users in the broadcast channel. The simulated sub-FTN and full-FTN broadcast transceivers outperform coded Nyquist-rate systems both in BER performances and in capacity.","Broadcasting,
Receivers,
Encoding,
Signal to noise ratio,
Equalizers,
Multiplexing,
Indexes"
A Hybrid Evolutionary Immune Algorithm for Multiobjective Optimization Problems,"In recent years, multiobjective immune algorithms (MOIAs) have shown promising performance in solving multiobjective optimization problems (MOPs). However, basic MOIAs only use a single hypermutation operation to evolve individuals, which may induce some difficulties in tackling complicated MOPs. In this paper, we propose a novel hybrid evolutionary framework for MOIAs, in which the cloned individuals are divided into several subpopulations and then evolved using different evolutionary strategies. An example of this hybrid framework is implemented, in which simulated binary crossover and differential evolution with polynomial mutation are adopted. A fine-grained selection mechanism and a novel elitism sharing strategy are also adopted for performance enhancement. Various comparative experiments are conducted on 28 test MOPs and our empirical results validate the effectiveness and competitiveness of our proposed algorithm in solving MOPs of different types.","Optimization,
Sociology,
Statistics,
Cloning,
Immune system,
Convergence,
Computer science"
Image Registration Based on Autocorrelation of Local Structure,"Registration of images in the presence of intra-image signal fluctuations is a challenging task. The definition of an appropriate objective function measuring the similarity between the images is crucial for accurate registration. This paper introduces an objective function that embeds local phase features derived from the monogenic signal in the modality independent neighborhood descriptor (MIND). The image similarity relies on the autocorrelation of local structure (ALOST) which has two important properties: 1) low sensitivity to space-variant intensity distortions (e.g., differences in contrast enhancement in MRI); 2) high distinctiveness for `salient' image features such as edges. The ALOST method is quantitatively compared to the MIND approach based on three different datasets: thoracic CT images, synthetic and real abdominal MR images. The proposed method outperformed the NMI and MIND similarity measures on these three datasets. The registration of dynamic contrast enhanced and post-contrast MR images of patients with Crohn's disease led to relative contrast enhancement measures with the highest correlation (r=0.56) to the Crohn's disease endoscopic index of severity.","Band-pass filters,
Linear programming,
Correlation,
Image registration,
Noise,
Distortion,
Transforms"
A Four-Port MIMO Antenna Using Concentric Square-Ring Patches Loaded With CSRR for High Isolation,A novel four-port multiple-input-multiple-output (MIMO) antenna system is designed using concentric square-ring patch antennas. All four ports are made to resonate at 2.4 GHz ISM band with an overall system dimension of 60×60×1.6 mm3. This design uses complementary split-ring resonator (CSRR) loaded on its ground plane for enhanced isolation of - 22 dB between patch antenna elements. CSRR reduces mutual coupling by about 6.5 dB. The antenna operates with a 2:1 VSWR bandwidth of 75 MHz centered at 2.45 GHz. This collocated antenna system satisfies MIMO diversity performance with low envelope correlation between its waveforms. The effectiveness of concentric rings in MIMO design along with proposed isolation enhancement technique is validated using measurements from a prototype.,"MIMO,
Ports (Computers),
Couplings,
Bandwidth,
Antenna radiation patterns,
Wireless communication"
A Joint Training Framework for Robust Automatic Speech Recognition,"Robustness against noise and reverberation is critical for ASR systems deployed in real-world environments. In robust ASR, corrupted speech is normally enhanced using speech separation or enhancement algorithms before recognition. This paper presents a novel joint training framework for speech separation and recognition. The key idea is to concatenate a deep neural network (DNN) based speech separation frontend and a DNN-based acoustic model to build a larger neural network, and jointly adjust the weights in each module. This way, the separation frontend is able to provide enhanced speech desired by the acoustic model and the acoustic model can guide the separation frontend to produce more discriminative enhancement. In addition, we apply sequence training to the jointly trained DNN so that the linguistic information contained in the acoustic and language models can be back-propagated to influence the separation frontend at the training stage. To further improve the robustness, we add more noise- and reverberation-robust features for acoustic modeling. At the test stage, utterance-level unsupervised adaptation is performed to adapt the jointly trained network by learning a linear transformation of the input of the separation frontend. The resulting sequence-discriminative jointly-trained multistream system with run-time adaptation achieves 10.63% average word error rate (WER) on the test set of the reverberant and noisy CHiME-2 dataset (task-2), which represents the best performance on this dataset and a 22.75% error reduction over the best existing method.",
On Cloud Service Reliability Enhancement with Optimal Resource Usage,"An increasing number of companies are beginning to deploy services/applications in the cloud computing environment. Enhancing the reliability of cloud service has become a critical and challenging research problem. In the cloud computing environment, all resources are commercialized. Therefore, a reliability enhancement approach should not consume too much resource. However, existing approaches cannot achieve the optimal effect because of checkpoint image-sharing neglect, and checkpoint image inaccessibility caused by node crashing. To address this problem, we propose a cloud service reliability enhancement approach for minimizing network and storage resource usage in a cloud data center. In our proposed approach, the identical parts of all virtual machines that provide the same service are checkpointed once as the service checkpoint image, which can be shared by those virtual machines to reduce the storage resource consumption. Then, the remaining checkpoint images only save the modified page. To persistently store the checkpoint image, the checkpoint image storage problem is modeled as an optimization problem. Finally, we present an efficient heuristic algorithm to solve the problem. The algorithm exploits the data center network architecture characteristics and the node failure predicator to minimize network resource usage. To verify the effectiveness of the proposed approach, we extend the renowned cloud simulator Cloudsim and conduct experiments on it. Experimental results based on the extended Cloudsim show that the proposed approach not only guarantees cloud service reliability, but also consumes fewer network and storage resources than other approaches.","Service level agreements,
Optimization,
Cloud computing,
Image storage,
Checkpointing,
Data centers,
Computer crashes"
Finite-Time Connectivity-Preserving Consensus of Networked Nonlinear Agents With Unknown Lipschitz Terms,"This technical note studies finite-time consensus problem for a team of networked nonlinear agents with unknown Lipschitz terms under communication constraints, where each agent has a limited sensing range. Because the induced interaction graph is typically state-dependent and dynamic, we propose a distributed nonlinear consensus algorithm that is capable of preserving the initial interaction patterns. By using tools from nonsmooth analysis, sufficient conditions are obtained such that finite-time consensus can be reached. An upper bound of the convergence time is derived via a two-step analysis. The validity of the theoretical result is shown by one simulation example.","Convergence,
Symmetric matrices,
Laplace equations,
Algorithm design and analysis,
Nonlinear dynamical systems,
Eigenvalues and eigenfunctions,
Sensors"
Central-Tapped Node Linked Modular Fault-Tolerance Topology for SRM Applications,"Electric vehicles (EVs) and hybrid electric vehicles (HEVs) can reduce greenhouse gas emissions while switched reluctance motor (SRM) is one of the promising motor for such applications. This paper presents a novel SRM fault-diagnosis and fault-tolerance operation solution. Based on the traditional asymmetric half-bridge topology for the SRM driving, the central tapped winding of the SRM in modular half-bridge configuration are introduced to provide fault-diagnosis and fault-tolerance functions, which are set idle in normal conditions. The fault diagnosis can be achieved by detecting the characteristic of the excitation and demagnetization currents. An SRM fault-tolerance operation strategy is also realized by the proposed topology, which compensates for the missing phase torque under the open-circuit fault, and reduces the unbalanced phase current under the short-circuit fault due to the uncontrolled faulty phase. Furthermore, the current sensor placement strategy is also discussed to give two placement methods for low cost or modular structure. Simulation results in MATLAB/Simulink and experiments on a 750-W SRM validate the effectiveness of the proposed strategy, which may have significant implications and improve the reliability of EVs/HEVs.","Circuit faults,
Fault tolerance,
Fault tolerant systems,
Topology,
Reluctance motors,
Windings,
Fault diagnosis"
Online Supercapacitor Diagnosis for Electric Vehicle Applications,"This paper presents an online diagnosis method for the supercapacitors' aging problem. State-of-health (SoH) estimation is an important feature since aging introduces degradation in the supercapacitors' performance, which might eventually lead to their failure. SoH is usually measured by electrochemical impedance spectroscopy. However, this has to be performed offline and requires interruption of the system's operation. Unlike this method, this paper presents an online diagnosis technique for supercapacitors using an extended Kalman observer as a well-known tool for its particularities and performances to study nonlinear parameter estimation. The main objective of this paper is the online SoH diagnosis based on the supercapacitors' aging indicator estimation. Moreover, the proposed online estimation strategy requires only voltage and current measurements, which reduces the number of sensors with respect to other methods. The effectiveness of the proposed online observer is shown through experimental results, and robustness to noise is also studied.","Supercapacitors,
Aging,
Capacitance,
Resistance,
Kalman filters,
Observers"
Skin Temperature Prediction in Lower Limb Prostheses,"Increased temperature and perspiration within a prosthetic socket is a common complaint of many amputees. The heat dissipation in prosthetic sockets is greatly influenced by the thermal conductive properties of the socket and interface liner materials. These materials influence the body's temperature regulation mechanism and might be the reason for thermal discomfort in prosthetic sockets. Monitoring interface temperature at skin level is notoriously complicated. The problem might be considered notorious because embedding wires and sensors in an elastomer eventually results in elastomer failures because of the high strain induced when donning a liner (amputees roll the liners onto their limbs). Another reason is because placing sensors and wires directly against the skin could cause irritation and chaffing over just a short period of time. We describe a route wherein if the thermal properties of the socket and liner materials are known, the in-socket residual limb temperature could be accurately predicted by monitoring the temperature between socket and liner rather than skin and liner using the Gaussian process technique.","Skin,
Sockets,
Temperature,
Prosthetics,
Training,
Materials,
Legged locomotion"
A Wearable Microwave Antenna Array for Time-Domain Breast Tumor Screening,"In this work, we present a clinical prototype with a wearable patient interface for microwave breast cancer detection. The long-term aim of the prototype is a breast health monitoring application. The system operates using multistatic time-domain pulsed radar, with 16 flexible antennas embedded into a bra. Unlike the previously reported, table-based prototype with a rigid cup-like holder, the wearable one requires no immersion medium and enables simple localization of breast surface. In comparison with the table-based prototype, the wearable one is also significantly more cost-effective and has a smaller footprint. To demonstrate the improved functionality of the wearable prototype, we here report the outcome of daily testing of the new, wearable prototype on a healthy volunteer over a 28-day period. The resulting data (both signals and reconstructed images) is compared to that obtained with our table-based prototype. We show that the use of the wearable prototype has improved the quality of collected volunteer data by every investigated measure. This work demonstrates the proof-of-concept for a wearable breast health monitoring array, which can be further optimized in the future for use with patients with various breast sizes and tissue densities.","Prototypes,
Breast,
Arrays,
Microwave imaging,
Antenna measurements,
Antenna arrays,
Microwave theory and techniques"
A Tunable Majority Gate-Based Full Adder Using Current-Induced Domain Wall Nanomagnets,"Domain wall nanomagnet (DWNM)-based devices have been extensively studied as a promising alternative to the conventional CMOS technology in both the memory and logic implementations due to their non-volatility, near-zero standby power, and high integration density characteristics. In this paper, we leverage a physics-based model of a DWNM device to design a highly scalable current-mode majority gate to achieve a novel one bit full-adder (FA) circuit. The modeled DWNM specifications are calibrated with the experimentally measured data. The functionality of the proposed DWNM-based FA (DWNM-FA) is verified using a SPICE circuit simulator. The detailed analysis and the calculations have been performed to realize the proposed DWNM-FA delay and power consumption corresponding to the various induced input currents at different operating temperatures. The power-delay product of DWNM-FA is examined to tune the operation within the optimum induced input current region to obtain desired power-delay requirements over a range of 200 μA to 1 mA at temperatures from 298 to 378 K. Finally, the comparison results exhibit 52% and 49% area improvement as well as 41% and 31% improvement in device count complexity over CMOS-based and magnetic tunnel junction-based FA designs, respectively.","Magnetic tunneling,
Logic gates,
Integrated circuit modeling,
Magnetic domains,
Nanoscale devices,
Magnetic domain walls,
CMOS integrated circuits"
Auction Mechanisms Toward Efficient Resource Sharing for Cloudlets in Mobile Cloud Computing,"Mobile cloud computing offers an appealing paradigm to relieve the pressure of soaring data demands and augment energy efficiency for future green networks. Cloudlets can provide available resources to nearby mobile devices with lower access overhead and energy consumption. To stimulate service provisioning by cloudlets and improve resource utilization, a feasible and efficient incentive mechanism is required to charge mobile users and reward cloudlets. Although auction has been considered as a promising form for incentive, it is challenging to design an auction mechanism that holds certain desirable properties for the cloudlet scenario. Truthfulness and system efficiency are two crucial properties in addition to computational efficiency, individual rationality and budget balance. In this paper, we first propose a feasible and truthful incentive mechanism (TIM), to coordinate the resource auction between mobile devices as service users (buyers) and cloudlets as service providers (sellers). Further, TIM is extended to a more efficient design of auction (EDA). TIM guarantees strong truthfulness for both buyers and sellers, while EDA achieves a fairly high system efficiency but only satisfies strong truthfulness for sellers. We also show the difficulties for the buyers to manipulate the resource auction in EDA and the high expected utility with truthful bidding.","Mobile communication,
Cost accounting,
Mobile handsets,
Resource management,
Mechanical factors,
Cloud computing,
Mobile computing"
On the Capacity of the Intensity-Modulation Direct-Detection Optical Broadcast Channel,"The capacity of the intensity-modulation direct-detection optical broadcast channel (OBC) is investigated, under both average and peak intensity constraints. An outer bound on the capacity region is derived by adapting Bergmans' approach to the OBC. Inner bounds are derived by using superposition coding with either truncated-Gaussian (TG) distributions or discrete distributions. While the discrete distribution achieves higher rates, the TG distribution leads to a simpler representation of the achievable rate region. At high signal-to-noise ratio (SNR), it is shown that the TG distribution is nearly optimal. It achieves the symmetric-capacity within a constant gap (independent of SNR), which approaches half a bit as the number of users grows. It also achieves the capacity region within a constant gap. At low SNR, it is shown that on-off keying (OOK) with time-division multiple-access (TDMA) is optimal. This is interesting in practice since both OOK and TDMA have low complexity. At moderate SNR (typically [0,8] dB), a discrete distribution with a small alphabet size achieves fairly good performance.","Signal to noise ratio,
Channel capacity,
Wireless communication,
Upper bound,
Time division multiple access,
Encoding,
Optical transmitters"
Privacy Preserving Ranked Multi-Keyword Search for Multiple Data Owners in Cloud Computing,"With the advent of cloud computing, it has become increasingly popular for data owners to outsource their data to public cloud servers while allowing data users to retrieve this data. For privacy concerns, secure searches over encrypted cloud data has motivated several research works under the single owner model. However, most cloud servers in practice do not just serve one owner; instead, they support multiple owners to share the benefits brought by cloud computing. In this paper, we propose schemes to deal with privacy preserving ranked multi-keyword search in a multi-owner model (PRMSM). To enable cloud servers to perform secure search without knowing the actual data of both keywords and trapdoors, we systematically construct a novel secure search protocol. To rank the search results and preserve the privacy of relevance scores between keywords and files, we propose a novel additive order and privacy preserving function family. To prevent the attackers from eavesdropping secret keys and pretending to be legal data users submitting searches, we propose a novel dynamic secret key generation protocol and a new data user authentication protocol. Furthermore, PRMSM supports efficient data user revocation. Extensive experiments on real-world datasets confirm the efficacy and efficiency of PRMSM.","Servers,
Cryptography,
Authentication,
Protocols,
Data privacy,
Law"
Joint User-Association and Resource-Allocation in Virtualized Wireless Networks,"In this paper, we consider the down-link dynamic resource allocation in multi-cell virtualized wireless networks (VWNs) to support the users of different service providers (slices) within a specific region by a set of base stations (BSs) through orthogonal frequency division multiple access (OFDMA). In particular, we develop a joint BS assignment, sub-carrier, and power allocation algorithm to maximize the network sum rate, while satisfying the minimum required rate of each slice. Under the assumption that each user at each transmission instance can connect to no more than one BS, we introduce the user-association factor to represent the joint sub-carrier and BS assignment as the optimization variable vector in the problem formulation. Sub-carrier reuse is allowed in different cells, but not within one cell. As the proposed optimization problem is inherently non-convex and NP-hard, by applying the successive convex approximation (SCA) and complementary geometric programming (CGP), we develop an efficient two-step iterative approach with low computational complexity to solve the proposed problem. For a given problem, Step 1 derives the optimum user-association and subsequently, and for an obtained user-association, Step 2 finds the optimum power allocation. Simulation results demonstrate that the proposed iterative algorithm outperforms the traditional approach in which each user is assigned to the BS with the largest average value of signal strength, and then, joint sub-carrier and power allocation is obtained for the assigned users of each cell. Simulation results reveal a coverage improvement, offered by the proposed approach, of 57% and 71% for uniform and non-uniform users distribution, respectively, leading to higher spectrum efficiency for VWN.","Convex programming,
Wireless networks,
Optimization,
Quality of service,
Iterative methods,
Approximation methods,
Programming,
Resource management"
Short-Term Traffic Prediction Based on Dynamic Tensor Completion,"Short-term traffic prediction plays a critical role in many important applications of intelligent transportation systems such as traffic congestion control and smart routing, and numerous methods have been proposed to address this issue in the literature. However, most, if not all, of them suffer from the inability to fully use the rich information in traffic data. In this paper, we present a novel short-term traffic flow prediction approach based on dynamic tensor completion (DTC), in which the traffic data are represented as a dynamic tensor pattern, which is able capture more information of traffic flow than traditional methods, namely, temporal variabilities, spatial characteristics, and multimode periodicity. A DTC algorithm is designed to use the multimode information to forecast traffic flow with a low-rank constraint. The proposed method is evaluated on real-world data sets and compared with other state-of-the-art methods, and the efficacy of the proposed approach is validated on the experiments of traffic flow prediction, particularly when dealing with incomplete traffic data.","Tensile stress,
Predictive models,
Data models,
Time series analysis,
Heuristic algorithms,
Intelligent transportation systems"
Transfer Prototype-Based Fuzzy Clustering,"Traditional prototype-based clustering methods, such as the well-known fuzzy c-means (FCM) algorithm, usually need sufficient data to find a good clustering partition. If available data are limited or scarce, most of them are no longer effective. While the data for the current clustering task may be scarce, there is usually some useful knowledge available in the related scenes/domains. In this study, the concept of transfer learning is applied to prototype-based fuzzy clustering (PFC). Specifically, the idea of leveraging knowledge from the source domain is exploited to develop a set of transfer PFC algorithms. First, two representative PFC algorithms, namely, FCM and fuzzy subspace clustering, have been chosen to incorporate with knowledge leveraging mechanisms to develop the corresponding transfer clustering algorithms based on an assumption that there are the same number of clusters between the target domain (current scene) and the source domain (related scene). Furthermore, two extended versions are also proposed to implement the transfer learning for the situation that there are different numbers of clusters between two domains. The novel objective functions are proposed to integrate the knowledge from the source domain with the data in the target domain for the clustering in the target domain. The proposed algorithms have been validated on different synthetic and real-world datasets. Experimental results demonstrate their effectiveness in comparison with both the original PFC algorithms and the related clustering algorithms like multitask clustering and coclustering.","Clustering algorithms,
Clustering methods,
Linear programming,
Prototypes,
Power capacitors,
Partitioning algorithms,
Phase change materials"
The Impacts of Distributed Energy Sources on Distribution Network Reconfiguration,"Thanks to the recent improvements in renewable energy technologies throughout the world, distributed energy sources are now playing an undeniable role in supplying the electricity in distribution networks. This paper studies the impacts of utilizing distributed generation units on the task of network reconfiguration in distribution systems. Considering the importance of reducing voltage drops and voltage sags in distribution systems, network reconfiguration is formulated as a multiobjective optimization problem in this study to minimize these two objective functions. A Pareto-based metaheuristic optimization algorithm is proposed to identify a Pareto frontier representing the alternative high-quality suboptimal configurations. The proposed optimization method is tested on a 69-bus distribution system to demonstrate the performance of the algorithm.","Voltage fluctuations,
Optimization,
Linear programming,
Power quality,
Encoding,
Genetic algorithms,
Topology"
A Regression Approach to Single-Channel Speech Separation Via High-Resolution Deep Neural Networks,"We propose a novel data-driven approach to single-channel speech separation based on deep neural networks (DNNs) to directly model the highly nonlinear relationship between speech features of a mixed signal containing a target speaker and other interfering speakers. We focus our discussion on a semisupervised mode to separate speech of the target speaker from an unknown interfering speaker, which is more flexible than the conventional supervised mode with known information of both the target and interfering speakers. Two key issues are investigated. First, we propose a DNN architecture with dual outputs of the features of both the target and interfering speakers, which is shown to achieve a better generalization capability than that with output features of only the target speaker. Second, we propose using a set of multiple DNNs, each intending to be signal-noise-dependent (SND), to cope with the difficulty that one single general DNN could not well accommodate all the speaker mixing variabilities at different signal-to-noise ratio (SNR) levels. Experimental results on the speech separation challenge (SSC) data demonstrate that our proposed framework achieves better separation results than other conventional approaches in a supervised or semisupervised mode. SND-DNNs could also yield significant performance improvements over a general DNN for speech separation in low SNR cases. Furthermore, for automatic speech recognition (ASR) following speech separation, this purely front-end processing with a single set of speaker-independent ASR acoustic models, achieves a relative word error rate (WER) reduction of 11.6% over a state-of-the-art separation and recognition system where a complicated joint back-end decoding framework with multiple sets of speaker-dependent ASR acoustic models needs to be implemented. When speaker-adaptive ASR acoustic models for the target speakers are adopted for the enhanced signals, another 12.1% WER reduction over our best speaker-independent ASR system is achieved.",
A Design of 3-dB Wideband Microstrip Power Divider With an Ultra-Wide Isolated Frequency Band,"A 3-dB planar wideband power divider with an ultra-wide stopband and isolated frequency band is proposed. In order to extend the passband, the quasi-coupled lines are adopted. Moreover, the open and shorted stubs added at the input and output ports, respectively, can increase the bandwidths of the passband and stopband. Furthermore, in order to broaden the isolated frequency band, the impedance Ziso with the series connected resister and capacitor on the right side of the middle coupled line is adopted. The detailed derivation is proposed as well. In addition, this power divider is fabricated on the substrate Rogers RO4003C with a compact size of 15.19 mm × 11.4 mm.","Power dividers,
Passband,
Impedance,
Frequency conversion,
Wideband,
Ports (Computers),
Resistors"
"Detecting, Tracing, and Monitoring Architectural Tactics in Code","Software architectures are often constructed through a series of design decisions. In particular, architectural tactics are selected to satisfy specific quality concerns such as reliability, performance, and security. However, the knowledge of these tactical decisions is often lost, resulting in a gradual degradation of architectural quality as developers modify the code without fully understanding the underlying architectural decisions. In this paper we present a machine learning approach for discovering and visualizing architectural tactics in code, mapping these code segments to tactic traceability patterns, and monitoring sensitive areas of the code for modification events in order to provide users with up-to-date information about underlying architectural concerns. Our approach utilizes a customized classifier which is trained using code extracted from fifty performance-centric and safety-critical open source software systems. Its performance is compared against seven off-the-shelf classifiers. In a controlled experiment all classifiers performed well; however our tactic detector outperformed the other classifiers when used within the larger context of the Hadoop Distributed File System. We further demonstrate the viability of our approach for using the automatically detected tactics to generate viable and informative messages in a simulation of maintenance events mined from Hadoop's change management system.",
A Reliability-Augmented Particle Filter for Magnetic Fingerprinting Based Indoor Localization on Smartphone,"Using magnetic field data as fingerprints for smartphone indoor positioning has become popular in recent years. Particle filter is often used to improve accuracy. However, most of existing particle filter based approaches either are heavily affected by motion estimation errors, which result in unreliable systems, or impose strong restrictions on smartphone such as fixed phone orientation, which are not practical for real-life use. In this paper, we present a novel indoor positioning system for smartphones, which is built on our proposed reliability-augmented particle filter. We create several innovations on the motion model, the measurement model, and the resampling model to enhance the basic particle filter. To minimize errors in motion estimation and improve the robustness of the basic particle filter, we propose a dynamic step length estimation algorithm and a heuristic particle resampling algorithm. We use a hybrid measurement model, combining a new magnetic fingerprinting model and the existing magnitude fingerprinting model, to improve system performance, and importantly avoid calibrating magnetometers for different smartphones. In addition, we propose an adaptive sampling algorithm to reduce computation overhead, which in turn improves overall usability tremendously. Finally, we also analyze the “Kidnapped Robot Problem” and present a practical solution. We conduct comprehensive experimental studies, and the results show that our system achieves an accuracy of 1~2 m on average in a large building.",
Planning the Coordination of Directional Overcurrent Relays for Distribution Systems Considering DG,"Introduction of distributed generation (DG) to the power system may lead to nonselective protection actions. For every future DG installation, the relay settings need to be modified to guarantee protection coordination that can lead to numerous changes in relay settings. This paper presents a novel approach to plan relay protection coordination considering future DG installations. Thus, this paper aims at proposing a method capable of optimally identifying one set of relay settings valid for all possible future DG planning scenarios. The proposed algorithm is formulated as a linear programming problem and the simplex algorithm is utilized to solve it. The proposed approach is tested on the distribution part of the modified meshed IEEE 14-bus system and the IEEE 13-bus radial test system. Comparative studies have been conducted to highlight the advantages of the proposed approach under various planning scenarios considering application of fault current limiters.",
Discriminative Dictionary Learning With Common Label Alignment for Cross-Modal Retrieval,"Cross-modal retrieval has attracted much attention in recent years due to its widespread applications. In this area, how to capture and correlate heterogeneous features originating from different modalities remains a challenge. However, most existing methods dealing with cross-modal learning only focus on learning relevant features shared by two distinct feature spaces, therefore overlooking discriminative feature information of them. To remedy this issue and explicitly capture discriminative feature information, we propose a novel cross-modal retrieval approach based on discriminative dictionary learning that is augmented with common label alignment. Concretely, a discriminative dictionary is first learned to account for each modality, which boosts not only the discriminating capability of intra-modality data from different classes but also the relevance of inter-modality data in the same class. Subsequently, all the resulting sparse codes are simultaneously mapped to a common label space, where the cross-modal data samples are characterized and associated. Also in the label space, the discriminativeness and relevance of the considered cross-modal data can be further strengthened by enforcing a common label alignment. Finally, cross-modal retrieval is performed over the common label space. Experiments conducted on two public cross-modal datasets show that the proposed approach outperforms several state-of-the-art methods in term of retrieval accuracy.","Correlation,
Data models,
Resource management,
Search problems,
Videos"
Utility-Optimal Resource Management and Allocation Algorithm for Energy Harvesting Cognitive Radio Sensor Networks,"In this paper, we study resource management and allocation for energy harvesting cognitive radio sensor networks (EHCRSNs). In these networks, energy harvesting supplies the network with a continual source of energy to facilitate the self-sustainability of the power-limited sensors. Furthermore, cognitive radio enables access to the underutilized licensed spectrum to mitigate the spectrum-scarcity problem in the unlicensed band. We develop an aggregate network utility optimization framework for the design of an online energy management, spectrum management, and resource allocation algorithm based on Lyapunov optimization. The framework captures three stochastic processes: energy harvesting dynamics, inaccuracy of channel occupancy information, and channel fading. However, a priori knowledge of any of these processes statistics is not required. Based on the framework, we propose an online algorithm to achieve two major goals: first, balancing sensors' energy consumption and energy harvesting while stabilizing their data and energy queues; second, optimizing the utilization of the licensed spectrum while maintaining a tolerable collision rate between the licensed subscriber and unlicensed sensors. The performance analysis shows that the proposed algorithm achieves a close-to-optimal aggregate network utility while guaranteeing bounded data and energy queue occupancy. The extensive simulations are conducted to verify the effectiveness of the proposed algorithm and the impact of various network parameters on its performance.",
Sentiment Embeddings with Applications to Sentiment Analysis,"We propose learning sentiment-specific word embeddings dubbed sentiment embeddings in this paper. Existing word embedding learning algorithms typically only use the contexts of words but ignore the sentiment of texts. It is problematic for sentiment analysis because the words with similar contexts but opposite sentiment polarity, such as good and bad, are mapped to neighboring word vectors. We address this issue by encoding sentiment information of texts (e.g., sentences and words) together with contexts of words in sentiment embeddings. By combining context and sentiment level evidences, the nearest neighbors in sentiment embedding space are semantically similar and it favors words with the same sentiment polarity. In order to learn sentiment embeddings effectively, we develop a number of neural networks with tailoring loss functions, and collect massive texts automatically with sentiment signals like emoticons as the training data. Sentiment embeddings can be naturally used as word features for a variety of sentiment analysis tasks without feature engineering. We apply sentiment embeddings to word-level sentiment analysis, sentence level sentiment classification, and building sentiment lexicons. Experimental results show that sentiment embeddings consistently outperform context-based embeddings on several benchmark datasets of these tasks. This work provides insights on the design of neural networks for learning task-specific word embeddings in other natural language processing tasks.",
Quaternionic Local Ranking Binary Pattern: A Local Descriptor of Color Images,"This paper proposes a local descriptor called quaternionic local ranking binary pattern (QLRBP) for color images. Different from traditional descriptors that are extracted from each color channel separately or from vector representations, QLRBP works on the quaternionic representation (QR) of the color image that encodes a color pixel using a quaternion. QLRBP is able to handle all color channels directly in the quaternionic domain and include their relations simultaneously. Applying a Clifford translation to QR of the color image, QLRBP uses a reference quaternion to rank QRs of two color pixels, and performs a local binary coding on the phase of the transformed result to generate local descriptors of the color image. Experiments demonstrate that the QLRBP outperforms several state-of-the-art methods.","Quaternions,
Color,
Image color analysis,
Feature extraction,
Robustness,
Image coding,
Face recognition"
Full-Range Soft-Switching-Isolated Buck-Boost Converters With Integrated Interleaved Boost Converter and Phase-Shifted Control,"A new method for deriving isolated buck-boost (IBB) converter with single-stage power conversion is proposed in this paper and novel IBB converters based on high-frequency bridgeless-interleaved boost rectifiers are presented. The semiconductors, conduction losses, and switching losses are reduced significantly by integrating the interleaved boost converters into the full-bridge diode-rectifier. Various high-frequency bridgeless boost rectifiers are harvested based on different types of interleaved boost converters, including the conventional boost converter and high step-up boost converters with voltage multiplier and coupled inductor. The full-bridge IBB converter with voltage multiplier is analyzed in detail. The voltage multiplier helps to enhance the voltage gain and reduce the voltage stresses of the semiconductors in the rectification circuit. Hence, a transformer with reduced turns ratio and parasitic parameters, and low-voltage rated MOSFETs and diodes with better switching and conduction performances can be applied to improve the efficiency. Moreover, optimized phase-shift modulation strategy is applied to the full-bridge IBB converter to achieve isolated buck and boost conversion. What's more, soft-switching performance of all of the active switches and diodes within the whole operating range is achieved. A 380-V output prototype is fabricated to verify the effectiveness of the proposed IBB converters and its control strategies.","Rectifiers,
Inductors,
Semiconductor diodes,
Topology,
Power conversion,
Switches,
Computer architecture"
Active Fault-Tolerant Control for an Internet-Based Networked Three-Tank System,"This brief is concerned with the active fault-tolerant control (FTC) problem for an Internet-based networked three-tank system (INTTS) serving as a benchmark system for evaluating networked FTC algorithms. The INTTS has two parts located at Tsinghua University in China and at the University of South Wales in the U.K., respectively, which are connected via the Internet. With the INTTS as an experimental platform, the active FTC problem is investigated for a class of nonlinear networked systems subject to partial actuator failures. Once a specific actuator failure is detected and confirmed by a fault diagnosis unit, the control law is then reconfigured based on the information of the detected fault. Both the stability and the acThis brief is concerned with the active faulttolerant control (FTC) problem for an Internet-based networked three-tank system (INTTS) serving as a benchmark system for evaluating networked FTC algorithms. The INTTS has two parts located at Tsinghua University in China and at the University of South Wales in the U.K., respectively, which are connected via the Internet. With the INTTS as an experimental platform, the active FTC problem is investigated for a class of nonlinear networked systems subject to partial actuator failures. Once a specific actuator failure is detected and confirmed by a fault diagnosis unit, the control law is then reconfigured based on the information of the detected fault. Both the stability and the acceptable H∞ disturbance attenuation level are guaranteed for the closed-loop system using the remaining reliable actuators. Extensive experiments are carried out on the active FTC problem of the INTTS with partial actuator failures, and the effectiveness of the proposed scheme is illustrated.ceptable H∞ disturbance attenuation level are guaranteed for the closed-loop system using the remaining reliable actuators. Extensive experiments are carried out on the active FTC problem of the INTTS with partial actuator failures, and the effectiveness of the proposed scheme is illustrated.","Actuators,
Symmetric matrices,
Fault tolerance,
Fault tolerant systems,
Fault diagnosis,
Benchmark testing,
Mathematical model"
Eco-Aware Online Power Management and Load Scheduling for Green Cloud Datacenters,"Many of today's cloud datacenters are powered by electricity generated from brown energy (e.g., fuel fossil and oil), which directly translates into severe harm to the environment. To reduce the carbon footprint and the operating cost of datacenters, there is a clear trend to migrate to green datacenters, which are entirely (or partially) powered by renewable energy. However, given a portfolio with multiple off- and on-site power supplies (such as power grid, renewables, and batteries), it is challenging for datacenter operators to conduct efficient power management and thus meet the highly dynamic user demand. In this paper, we proposed an online algorithm, which is called EcoPower, to perform eco-aware power management and load scheduling jointly for geographically distributed cloud datacenters. Our objective is to minimize the time-average eco-aware power cost of cloud datacenters while still ensuring the quality-of-experience (QoE) constraint of user requests. To this end, we formulated the problem into a constrained stochastic optimization problem and apply the Lyapunov optimization theory to design an online control algorithm, which approaches the optimality with explicitly provable upper bounds. We also conducted extensive trace-driven simulations, and our results show that our proposed EcoPower algorithm can achieve a good balance between power cost savings, environment protection, and the user QoE, with the eco-aware power cost being cut down by over 20%. We found that wind dominant, solar complementary is a better strategy for cloud datacenters to integrate renewables into their power supply.","Batteries,
Electricity,
Green products,
Power supplies,
Power grids,
Renewable energy sources,
Algorithm design and analysis"
Pricing and Repurchasing for Big Data Processing in Multi-Clouds,"Processing streaming big data becomes critical as new diver Internet of Thing applications begin to emerge. The existing cloud pricing strategy is unfriendly for processing streaming big data with varying loads. Multiple cloud environments are a potential solution with an efficient pay-on-demand pricing strategy for processing streaming big data. In this paper, we propose an intermediary framework with multiple cloud environments to provide streaming big data computing service with lower cost per load, in which a cloud service intermediary rents the cloud service from multiple cloud providers and provides streaming processing service to the users with multiple service interfaces. In this framework, we also propose a pricing strategy to maximize the revenue of the multiple cloud intermediaries. With extensive simulations, our pricing strategy brings higher revenue than other pricing methods.","Cloud computing,
Big data,
Pricing,
Computational modeling,
Computers,
Games,
Real-time systems"
Improper Gaussian signaling in full-duplex relay channels with residual self-interference,"We study the potential employment of improper Gaussian signaling (IGS) in full-duplex cooperative settings with residual self-interference (RSI). IGS is recently shown to outperform traditional proper Gaussian signaling (PGS) in several interference-limited channel settings. In this work, IGS is employed in an attempt to alleviate the RSI adverse effect in full-duplex relaying (FDR). To this end, we derive a tight upper bound expression for the end-to-end outage probability in terms of the relay signal parameters represented in its power and circularity coefficient. We further show that the derived upper bound is either monotonic or unimodal in the relay's circularity coefficient. This result allows for easily locating the global optimal point using known numerical methods. Based on the analysis, IGS allows FDR systems to operate even with high RSI. It is shown that, while the communication totally fails with PGS as the RSI increases, the IGS outage probability approaches a fixed value that depends on the channel statistics and target rate. The obtained results show that IGS can leverage higher relay power budgets than PGS to improve the performance, meanwhile it relieves its RSI impact via tuning the signal impropriety.",
Fingerprint liveness detection based on multi-scale LPQ and PCA,"Fingerprint authentication system is used to verify users' identification according to the characteristics of their fingerprints. However, this system has some security and privacy problems. For example, some artificial fingerprints can trick the fingerprint authentication system and access information using real users' identification. Therefore, a fingerprint liveness detection algorithm needs to be designed to prevent illegal users from accessing privacy information. In this paper, a new software-based liveness detection approach using multi-scale local phase quantity (LPQ) and principal component analysis (PCA) is proposed. The feature vectors of a fingerprint are constructed through multi-scale LPQ. PCA technology is also introduced to reduce the dimensionality of the feature vectors and gain more effective features. Finally, a training model is gained using support vector machine classifier, and the liveness of a fingerprint is detected on the basis of the training model. Experimental results demonstrate that our proposed method can detect the liveness of users' fingerprints and achieve high recognition accuracy. This study also confirms that multi-resolution analysis is a useful method for texture feature extraction during fingerprint liveness detection.",
Multi-User Massive MIMO Communication Systems Based on Irregular Antenna Arrays,"In practical mobile communication engineering applications, surfaces of antenna array deployment regions are usually uneven. Therefore, massive multi-input-multi-output (MIMO) communication systems usually transmit wireless signals by irregular antenna arrays. To evaluate the performance of irregular antenna arrays, the matrix correlation coefficient and the ergodic received gain are defined for massive MIMO communication systems with mutual coupling effects. Furthermore, the lower bound of the ergodic achievable rate, symbol error rate, and average outage probability is first derived for multi-user massive MIMO communication systems using irregular antenna arrays. Asymptotic results are also derived when the number of antennae approaches infinity. Numerical results indicate that there exists a maximum achievable rate when the number of antennae keeps increasing in massive MIMO communication systems using irregular antenna arrays. Moreover, the irregular antenna array outperforms the regular antenna array in the achievable rate of massive MIMO communication systems when the number of antennae is larger than or equal to a given threshold.","Antenna arrays,
MIMO,
Mutual coupling,
Wireless communication,
Correlation"
Visual Object Tracking Performance Measures Revisited,"The problem of visual tracking evaluation is sporting a large variety of performance measures, and largely suffers from lack of consensus about which measures should be used in experiments. This makes the cross-paper tracker comparison difficult. Furthermore, as some measures may be less effective than others, the tracking results may be skewed or biased toward particular tracking aspects. In this paper, we revisit the popular performance measures and tracker performance visualizations and analyze them theoretically and experimentally. We show that several measures are equivalent from the point of information they provide for tracker comparison and, crucially, that some are more brittle than the others. Based on our analysis, we narrow down the set of potential measures to only two complementary ones, describing accuracy and robustness, thus pushing toward homogenization of the tracker evaluation methodology. These two measures can be intuitively interpreted and visualized and have been employed by the recent visual object tracking challenges as the foundation for the evaluation methodology.","Target tracking,
Visualization,
Performance evaluation,
Object tracking,
Current measurement,
Robustness"
Secure and Efficient Data Communication Protocol for Wireless Body Area Networks,"Wireless Body Area Networks (WBANs) are expected to play a major role in the field of patient-health monitoring in the near future, which gains tremendous attention amongst researchers in recent years. One of the challenges is to establish a secure communication architecture between sensors and users, whilst addressing the prevalent security and privacy concerns. In this paper, we propose a communication architecture for BANs, and design a scheme to secure the data communications between implanted/wearable sensors and the data sink/data consumers (doctors or nurse) by employing Ciphertext-Policy Attribute Based Encryption (CP_ABE) [1] and signature to store the data in ciphertext format at the data sink, hence ensuring data security. Our scheme achieves a role-based access control by employing an access control tree defined by the attributes of the data. We also design two protocols to securely retrieve the sensitive data from a BAN and instruct the sensors in a BAN. We analyze the proposed scheme, and argue that it provides message authenticity and collusion resistance, and is efficient and feasible. We also evaluate its performance in terms of energy consumption and communication/computation overhead.","Sensors,
Medical services,
Encryption,
Access control,
Wireless communication"
Motion-based detection and tracking in 3D LiDAR scans,"Robots are expected to operate autonomously in increasingly complex scenarios such as crowded streets or heavy traffic situations. Perceiving the dynamics of moving objects in the environment is crucial for safe and smart navigation and therefore a key enabler for autonomous driving. In this paper we present a novel model-free approach for detecting and tracking dynamic objects in 3D LiDAR scans obtained by a moving sensor. Our method only relies on motion cues and does not require any prior information about the objects. We sequentially detect multiple motions in the scene and segment objects using a Bayesian approach. For robustly tracking objects, we utilize their estimated motion models. We present extensive quantitative results based on publicly available datasets and show that our approach outperforms the state of the art.","Dynamics,
Tracking,
Laser radar,
Bayes methods,
Three-dimensional displays,
Robot sensing systems"
Compressed Sensing Improves the Performance of Subcarrier Index-Modulation-Assisted OFDM,"In orthogonal frequency division multiplexing relying on subcarrier index modulation (OFDM-SIM), the information is conveyed by both the indices of the activated subcarriers and the conventional amplitude-phase modulated (APM) symbols. It has been shown that OFDM-SIM is capable of striking a tradeoff between the attainable spectral efficiency (SE) and energy efficiency (EE). In order to further increase the EE of the OFDM-SIM system, while potentially increasing its SE, we propose a compressed sensing (CS)-assisted signaling strategy for the family of OFDM-SIM systems. Correspondingly, we first consider the joint maximum likelihood detection of the CS-assisted index-modulated (CSIM) and of the classic APM symbols, despite its high complexity. Then, we propose a low complexity detection algorithm, which is termed as the iterative residual check (IRC)-based detector. This is based on the greedy pursuit concept of CS, which makes locally optimal choices at each step. Finally, both analytical and simulation results are provided for characterizing the attainable system performance of our proposed OFDM-CSIM system. We demonstrate that in comparison to the conventional OFDM-SIM system, the proposed OFDM-CSIM arrangement is capable of achieving both a higher SE as well as an increased EE. We also show that the diversity gain provided by the OFDM-CSIM system is much higher than that of the OFDM-SIM system. Furthermore, our investigation of the detection performance shows that the proposed IRC detector is capable of providing an attractive detection performance at a low complexity.",
Variability Mitigation in Nanometer CMOS Integrated Systems: A Survey of Techniques From Circuits to Software,"Variation in performance and power across manufactured parts and their operating conditions is an accepted reality in modern microelectronic manufacturing processes with geometries in nanometer scales. This article surveys challenges and opportunities in identifying variations, their effects and methods to combat these variations for improved microelectronic devices. We focus on computing devices and their design at various levels to combat variability. First, we provide a review of key concepts with particular emphasis on timing errors caused by various variability sources. We consider methods to predict and prevent, detect and correct, and finally conditions under which such errors can be accepted; we also consider their implications on cost, performance and quality. We provide a comparative evaluation of methods for deployment across various layers of the system from circuits, architecture, to application software. These can be combined in various ways to achieve specific goals related to observability and controllability of the variability effects, providing means to achieve cross-layer or hybrid resilience. We then provide examples of real world resilient single-core and parallel architectures. We find that parallel architectures and parallelism in general provide the best means to combat and exploit variability to design resilient and efficient systems. Using programmable accelerator architectures such as clustered processing elements and GP-GPUs, we show how system designers can coordinate propagation of timing error information and its effects along with new techniques for memoization (i.e., spatial or temporal reuse of computation). This discussion naturally leads to use of these techniques into emerging area of “approximate computing,” and how these can be used in building resilient and efficient computing systems. We conclude with an outlook for the emerging field.",
Secure and Privacy-Aware Cloud-Assisted Video Reporting Service in 5G-Enabled Vehicular Networks,"Vehicular networks are one of the main technologies that will be leveraged by the arrival of future fifth-generation (5G) mobile cellular networks. While scalability and latency are the major drawbacks of IEEE 802.11p and fourth-generation (4G) Long-Term Evolution (LTE)-enabled vehicular communications, respectively, the 5G technology is a promising solution to empower the real-time services offered by vehicular networks. However, the security and privacy of such services in 5G-enabled vehicular networks need to be addressed first. In this paper, we propose a novel system model for a 5G-enabled vehicular network that facilitates a reliable, secure, and privacy-aware real-time video reporting service. This service is designed for participating vehicles to instantly report the videos of traffic accidents to guarantee a timely response from official vehicles and/or ambulances toward accidents. While it provides strong security and privacy guarantees for the participating vehicle's identity and the video contents, the proposed service ensures traceability of misbehaving participants through a cooperation scheme among different authorities. We show the feasibility and the fulfillment of the proposed reporting service in 5G-enabled vehicular networks in terms of security, privacy, and efficiency.",
Computational Snapshot Multispectral Cameras: Toward dynamic capture of the spectral world,"Multispectral cameras collect image data with a greater number of spectral channels than traditional trichromatic sensors, thus providing spectral information at a higher level of detail. Such data are useful in various fields, such as remote sensing, materials science, biophotonics, and environmental monitoring. The massive scale of multispectral data-at high resolutions in the spectral, spatial, and temporal dimensions-has long presented a major challenge in spectrometer design. With recent developments in sampling theory, this problem has become more manageable through use of undersampling and constrained reconstruction techniques. This article presents an overview of these state-of-the-art multispectral acquisition systems, with a particular focus on snapshot multispectral capture, from a signal processing perspective. We propose that undersampling-based multispectral cameras can be understood and compared by examining the efficiency of their sampling schemes, which we formulate as the spectral sensing coherence information between their sensing matrices and spectrum-specific bases learned from a large-scale multispectral image database. We analyze existing snapshot multispectral cameras in this manner, and additionally discuss their optical performance in terms of light throughput and system complexity.","Cameras,
Sensors,
Modulation,
Spatial resolution,
Apertures,
Spectral analysis,
Digital imaging"
Assessing Short-Term Voltage Stability of Electric Power Systems by a Hierarchical Intelligent System,"In the smart grid paradigm, growing integration of large-scale intermittent renewable energies has introduced significant uncertainties to the operations of an electric power system. This makes real-time dynamic security assessment (DSA) a necessity to enable enhanced situational-awareness against the risk of blackouts. Conventional DSA methods are mainly based on the time-domain simulation, which are insufficiently fast and knowledge-poor. In recent years, the intelligent system (IS) strategy has been identified as a promising approach to facilitate real-time DSA. While previous works mainly concentrate on the rotor angle stability, this paper focuses on another yet increasingly important dynamic insecurity phenomenon-the short-term voltage instability, which involves fast and complex load dynamics. The problem is modeled as a classification subproblem for transient voltage collapse and a prediction subproblem for unacceptable dynamic voltage deviation. A hierarchical IS is developed to address the two subproblems sequentially. The IS is based on ensemble learning of random-weights neural networks and is implemented in an offline training, a real-time application, and an online updating pattern. The simulation results on the New England 39-bus system verify its superiority in both learning speed and accuracy over some state-of-the-art learning algorithms.",
A new converse bound for coded caching,"An information-theoretic lower bound is developed for the caching system studied by Maddah-Ali and Niesen. By comparing the proposed lower bound with the decentralized coded caching scheme of Maddah-Ali and Niesen, the optimal memory-rate tradeoff is characterized to within a multiplicative gap of 4.7 for the worst case, improving the previous analytical gap of 12. Furthermore, for the case when users' requests follow the uniform distribution, the multiplicative gap is tightened to 4.7, improving the previous analytical gap of 72. As an independent result of interest, for the single-user average case in which the user requests multiple files, it is proved that caching the most requested files is optimal.",
Self-Curable Gate-All-Around MOSFETs Using Electrical Annealing to Repair Degradation Induced From Hot-Carrier Injection,Device degradation induced by hot-carrier injection was repaired by electrical annealing using Joule heat through a built-in heater in a gate. The concentrated high temperature anneals the gate oxide locally and the degraded device parameters are recovered or further enhanced within a short time of 1 ms. Selecting a proper range of repair voltage is very important to maximize the annealing effects and minimize the extra damages caused by excessive high temperature. The repairing voltage is related to the resistance of the poly-Si gate according to the device scaling.,
Fusing Heterogeneous Features From Stacked Sparse Autoencoder for Histopathological Image Analysis,"In the analysis of histopathological images, both holistic (e.g., architecture features) and local appearance features demonstrate excellent performance, while their accuracy may vary dramatically when providing different inputs. This motivates us to investigate how to fuse results from these features to enhance the accuracy. Particularly, we employ content-based image retrieval approaches to discover morphologically relevant images for image-guided diagnosis, using holistic and local features, both of which are generated from the cell detection results by a stacked sparse autoencoder. Because of the dramatically different characteristics and representations of these heterogeneous features (i.e., holistic and local), their results may not agree with each other, causing difficulties for traditional fusion methods. In this paper, we employ a graph-based query-specific fusion approach where multiple retrieval results (i.e., rank lists) are integrated and reordered based on a fused graph. The proposed method is capable of combining the strengths of local or holistic features adaptively for different inputs. We evaluate our method on a challenging clinical problem, i.e., histopathological image-guided diagnosis of intraductal breast lesions, and it achieves 91.67% classification accuracy on 120 breast tissue images from 40 patients.","Feature extraction,
Image analysis,
Accuracy,
Computer architecture,
Image retrieval,
Biomedical imaging,
Fuses"
Prefetching-Based Data Dissemination in Vehicular Cloud Systems,"In the last decade, vehicular ad hoc networks (VANETs) have been widely studied as an effective method for providing wireless communication connectivity in vehicular transportation systems. In particular, vehicular cloud systems (VCSs) have received abundant interest for the ability to offer a variety of vehicle information services. We consider the data dissemination problem of providing reliable data delivery services from a cloud data center to vehicles through roadside wireless access points (APs) with local data storage. Due to intermittent wireless connectivity and the limited data storage size of roadside wireless APs, the question of how to use the limited resources of the wireless APs is one of the most pressing issues affecting data dissemination efficiency in VCSs. In this paper, we devise a vehicle route-based data prefetching scheme, which maximizes data dissemination success probability in an average sense when the size of local data storage is limited and wireless connectivity is stochastically unknown. We propose a greedy algorithm and an online learning algorithm for deterministic and stochastic cases, respectively, to decide how to prefetch a set of data of interest from a data center to roadside wireless APs. Experiment results indicate that the proposed algorithms can achieve efficient data dissemination in a variety of vehicular scenarios.",
"Light-Weight, Inter-Procedural and Callback-Aware Resource Leak Detection for Android Apps","Android devices include many embedded resources such as Camera, Media Player and Sensors. These resources require programmers to explicitly request and release them. Missing release operations might cause serious problems such as performance degradation or system crash. This kind of defects is called resource leak. Despite a large body of existing works on testing and analyzing Android apps, there still remain several challenging problems. In this work, we present Relda2, a light-weight and precise static resource leak detection tool. We first systematically collected a resource table, which includes the resources that the Android reference requires developers release manually. Based on this table, we designed a general approach to automatically detect resource leaks. To make a more precise inter-procedural analysis, we construct a Function Call Graph for each Android application, which handles function calls of user-defined methods and the callbacks invoked by the Android framework at the same time. To evaluate Relda2's effectiveness and practical applicability, we downloaded 103 apps from popular app stores and an open source community, and found 67 real resource leaks, which we have confirmed manually.","Androids,
Humanoid robots,
Smart phones,
Java,
Testing,
Leak detection,
Computer bugs"
Secure Degrees of Freedom Regions of Multiple Access and Interference Channels: The Polytope Structure,"In this paper, we determine the entire secure degrees of freedom (s.d.o.f.) regions of the K-user Gaussian multiple access (MAC) wiretap channel and the K-user interference channel (IC) with secrecy constraints. For the IC, we consider three secrecy constraints: K-user IC with an external eavesdropper (ICEE), K-user IC with confidential messages (IC-CM), and their combination Kuser IC with confidential messages and external eavesdropper (IC-CM-EE). The converse for the IC includes constraints both due to secrecy as well as due to interference. For the IC, although the portion of the region close to the optimum sum s.d.o.f. point is governed by the upper bounds due to secrecy constraints, the other portions of the region are governed by the upper bounds due to interference constraints. Different from the existing literature, in order to fully understand the characterization of the s.d.o.f. region of the IC, one has to study the four-user case, i.e., the twoor three-user cases do not illustrate the full generality of the problem. In order to prove the achievability, we use the polytope structure of the converse region. In both MAC and IC cases, we develop explicit schemes that achieve the extreme points of the polytope region given by the converse. In particular, the extreme points of the MAC region are achieved by an m-user MAC wiretap channel with K - m helpers, i.e., by setting K - m users' secure rates to zero and utilizing them as pure (structured) cooperative jammers. The extreme points of the IC region are achieved by a (K - m)-user IC with confidential messages, m helpers, and N external eavesdroppers, for m ≥ 1 and a finite N. A byproduct of our results in this paper is that the sum s.d.o.f. is achieved only at one extreme point of the s.d.o.f. region, which is the symmetric-rate extreme point, for both MAC and IC channel models.","Integrated circuits,
Receivers,
Upper bound,
Transmitters,
Interference channels,
Jamming"
Low-Rank Decomposition-Based Restoration of Compressed Images via Adaptive Noise Estimation,"Images coded at low bit rates in real-world applications usually suffer from significant compression noise, which significantly degrades the visual quality. Traditional denoising methods are not suitable for the content-dependent compression noise, which usually assume that noise is independent and with identical distribution. In this paper, we propose a unified framework of content-adaptive estimation and reduction for compression noise via low-rank decomposition of similar image patches. We first formulate the framework of compression noise reduction based upon low-rank decomposition. Compression noises are removed by soft thresholding the singular values in singular value decomposition of every group of similar image patches. For each group of similar patches, the thresholds are adaptively determined according to compression noise levels and singular values. We analyze the relationship of image statistical characteristics in spatial and transform domains, and estimate compression noise level for every group of similar patches from statistics in both domains jointly with quantization steps. Finally, quantization constraint is applied to estimated images to avoid over-smoothing. Extensive experimental results show that the proposed method not only improves the quality of compressed images obviously for post-processing, but are also helpful for computer vision tasks as a pre-processing method.",
Crowdsourcing in ITS: The State of the Work and the Networking,"In the last decade, crowdsourcing has emerged as a novel mechanism for accomplishing temporal and spatial critical tasks in transportation with the collective intelligence of individuals and organizations. This paper presents a timely literature review of crowdsourcing and its applications in intelligent transportation systems (ITS). We investigate the ITS services enabled by crowdsourcing, the keyword co-occurrence and coauthorship networks formed by ITS publications, and identify the problems and challenges that need further research. Finally, we briefly introduce our future works focusing on using geospatial tagged data to analyze real-time traffic conditions and the management of traffic flow in urban environment. This review aims to help ITS practitioners and researchers build a state-of-the-art understanding of crowdsourcing in ITS, as well as to call for more research on the application of crowdsourcing in transportation systems.","Crowdsourcing,
Transportation,
Social network services,
Artificial intelligence,
Real-time systems,
Sensors"
Information Theory and the IrisCode,"Iris recognition has legendary resistance to false matches, and the tools of information theory can help to explain why. The concept of entropy is fundamental to understanding biometric collision avoidance. This paper analyses the bit sequences of IrisCodes computed both from real iris images and from synthetic white noise iris images, whose pixel values are random and uncorrelated. The capacity of the IrisCode as a channel is found to be 0.566 bits per bit encoded, of which 0.469 bits of entropy per bit is encoded from natural iris images. The difference between these two rates reflects the existence of anatomical correlations within a natural iris, and the remaining gap from one full bit of entropy per bit encoded reflects the correlations in both phase and amplitude introduced by the Gabor wavelets underlying the IrisCode. A simple two-state hidden Markov model is shown to emulate exactly the statistics of bit sequences generated both from natural and white noise iris images, including their imposter distributions, and may be useful for generating large synthetic IrisCode databases.","Entropy,
Iris recognition,
Random variables,
Uncertainty,
Mutual information,
Image coding"
Benchmarking the Effect of Flow Exporters and Protocol Filters on Botnet Traffic Classification,"Botnets represent one of the most aggressive threats against cyber security. Different techniques using different feature sets have been proposed for botnet traffic analysis and classification. However, no work has been performed to study the effect of such differences. In this paper, we perform a study on the effect of (if any) the feature sets of network traffic flow exporters. To this end, we explore five different traffic flow exporters (each with a different set of flow features) using two different protocol filters [Hypertext Transfer Protocol (HTTP) and Domain Name System (DNS)] and five different classifiers. We evaluate all these on eight different botnet traffic data sets. Our results indicate that the use of a flow exporter and a protocol filter indeed has an effect on the performance of botnet traffic classification. Experimental results show that the best performance is achieved using Tranalyzer flow exporter and HTTP filter with the C4.5 classifier.","Protocols,
Feature extraction,
Servers,
IP networks,
Topology,
Malware,
Decision trees"
Optimization of Full versus Incremental Periodic Backup Policy,"This paper models repairable computing systems performing a mission that is successful if the system can accomplish a specified amount of work within the allowed mission time or deadline. During the mission the system is subject to a sequence of full and incremental data backup procedures to facilitate an effective system recovery and avoid repeating the entire mission work from the very beginning when a system failure happens. The repair time is fixed while the system time-to-failure can follow any arbitrary type of distributions. This paper makes novel contributions by first developing a new numerical algorithm to evaluate mission success probability and expected completion time of the considered repairable real-time computing systems subject to mixed full and incremental backups. Correctness of the proposed evaluation algorithm is verified using Monte Carlo simulations. We make another new contribution by formulating and solving the backup schedule optimization problem that finds the full and incremental backup frequencies maximizing the mission success probability. Through illustrative examples, effects of different parameters (including the system time-to-failure distribution parameter, maximum allowed mission time, data backup and retrieval times, storage availability, repair time and efficiency) on the mission success probability and expected completion time as well as on the optimal backup schedule solution are investigated.","Maintenance engineering,
Optimization,
Scheduling,
Computational modeling,
Real-time systems,
Probability density function,
Memory management"
The Data Context Map: Fusing Data and Attributes into a Unified Display,"Numerous methods have been described that allow the visualization of the data matrix. But all suffer from a common problem - observing the data points in the context of the attributes is either impossible or inaccurate. We describe a method that allows these types of comprehensive layouts. We achieve it by combining two similarity matrices typically used in isolation - the matrix encoding the similarity of the attributes and the matrix encoding the similarity of the data points. This combined matrix yields two of the four submatrices needed for a full multi-dimensional scaling type layout. The remaining two submatrices are obtained by creating a fused similarity matrix - one that measures the similarity of the data points with respect to the attributes, and vice versa. The resulting layout places the data objects in direct context of the attributes and hence we call it the data context map. It allows users to simultaneously appreciate (1) the similarity of data objects, (2) the similarity of attributes in the specific scope of the collection of data objects, and (3) the relationships of data objects with attributes and vice versa. The contextual layout also allows data regions to be segmented and labeled based on the locations of the attributes. This enables, for example, the map's application in selection tasks where users seek to identify one or more data objects that best fit a certain configuration of factors, using the map to visually balance the tradeoffs.",
Collaborative Recognition of Queuing Behavior on Mobile Phones,"Nowadays people spend a substantial amount of time waiting in different places such as supermarkets and amusement parks. Detecting the status of queuing may benefit both users and business. In this paper, we present QueueSense, a queuing recognition system to assist in a queue management system. QueueSense consists of clients on smartphones that provide automatic, energy-efficient, and accurate queuing recognition, and a server in the cloud that collects data, identifies multi-queue lines, and provides waiting time estimation. In order to be useful, QueueSense should be able to recognize queuing behavior in various queuing scenarios without greatly decreasing the battery life of mobile phones. We present features of queuing and build the classifier on smartphones to automatically recognize queue classifier without human input. We investigate the complicated nature of energy consumption for queue recognition on phones and design an effective algorithm to maximize energy savings while guaranteeing accuracy of queue recognition. We evaluate QueueSense performance using the data set from real world queuing scenarios collected over a three-month period. Empirical results show that QueueSense is adaptive to various queuing scenarios with both high recognition accuracy and energy efficiency. We further implemented a prototype of QueueSense, the first queue detection system using smartphones. We conducted real-world experiments in a dining hall and a supermarket near a university campus. Through implementation and evaluation, we demonstrate that QueueSense is capable of detecting waiting lines that occur in our daily lives.",
A Fast Fault-Tolerant Architecture for Sauvola Local Image Thresholding Algorithm Using Stochastic Computing,"Binarization plays an important role in document image processing, particularly in degraded document images. Among all local image thresholding algorithms, Sauvola has excellent binarization performance for degraded document images. However, this algorithm is computationally intensive and sensitive to the noises from the internal computational circuits. In this paper, we present a stochastic implementation of Sauvola algorithm. Our experimental results show that the stochastic implementation of Sauvola needs much less time and area and can tolerate more faults, while consuming less power in comparison with its conventional implementation.","Streaming media,
Computer architecture,
Fault tolerance,
Fault tolerant systems,
Standards,
Logic gates,
Hardware"
Adaptive Multi-Resource Allocation for Cloudlet-Based Mobile Cloud Computing System,"Mobile cloud computing utilizing cloudlet is an emerging technology to improve the quality of mobile services. In this paper, to better overcome the main bottlenecks of the computation capability of cloudlet and the wireless bandwidth between mobile devices and cloudlet, we consider the multi-resource allocation problem for the cloudlet environment with resource-intensive and latency-sensitive mobile applications. The proposed multi-resource allocation strategy enhances the quality of mobile cloud service, in terms of the system throughput (the number of admitted mobile applications) and the service latency. We formulate the resource allocation model as a semi-Markov decision process under the average cost criterion, and solve the optimization problem using linear programming technology. Through maximizing the long-term reward while meeting the system requirements of the request blocking probability and service time latency, an optimal resource allocation policy is calculated. From simulation result, it is indicated that the system adaptively adjusts the allocation policy about how much resource to allocate and whether to utilize the distant cloud according to the traffic of mobile service requests and the availability of the resource in the system. Our algorithm outperforms greedy admission control over a broad range of environments.","Cloud computing,
Mobile communication,
Resource management,
Wireless communication,
Bandwidth,
Mobile applications,
Mobile handsets"
Neyman-Pearson-Based Early Mode Decision for HEVC Encoding,"The high efficiency video coding (HEVC) standard has highly improved the coding efficiency by adopting hierarchical structures of coding unit (CU), prediction unit (PU), and transform unit (TU). However, enormous computational complexity is introduced due to the recursive rate-distortion optimization (RDO) process on all CUs, PUs and TUs. In this paper, we propose a fast and efficient mode decision algorithm based on the Neyman-Pearson rule, which consists of early SKIP mode decision and fast CU size decision. First, the early mode decision is modeled as a binary classification problem of SKIP/non-SKIP or split/unsplit. The Neyman-Pearson-based rule is employed to balance the rate-distortion (RD) performance loss and the complexity reduction by minimizing the missed detection with a constrained incorrect decision rate. A nonparametric density estimation scheme is also developed to calculate the likelihood function of the statistical parameters. Furthermore, an online training scheme is employed to periodically update the probability density distributions for different quantization parameters (QPs) and CU depth levels. The experimental results show that the proposed overall algorithm can save 65% and 58% computational complexity on average with a 1.29% and 1.08% Bjontegaard Delta bitrate (BDBR) increase for various test sequences under random access and low delay P conditions, respectively. The proposed overall scheme also has the advantage that it can make the trade-off between the RD performance and time saving by setting different values for the incorrect decision rate.","Encoding,
Computational complexity,
Prediction algorithms,
Algorithm design and analysis,
Partitioning algorithms,
Estimation"
A Linear Kalman Filter for MARG Orientation Estimation Using the Algebraic Quaternion Algorithm,"Real-time orientation estimation using low-cost inertial sensors is essential for all the applications where size and power consumption are critical constraints. Such applications include robotics, human motion analysis, and mobile devices. This paper presents a linear Kalman filter for magnetic angular rate and gravity sensors that processes angular rate, acceleration, and magnetic field data to obtain an estimation of the orientation in quaternion representation. Acceleration and magnetic field observations are preprocessed through a novel external algorithm, which computes the quaternion orientation as the composition of two algebraic quaternions. The decoupled nature of the two quaternions makes the roll and pitch components of the orientation immune to magnetic disturbances. The external algorithm reduces the complexity of the filter, making the measurement equations linear. Real-time implementation and the test results of the Kalman filter are presented and compared against a typical quaternion-based extended Kalman filter and a constant gain filter based on the gradient-descent algorithm.","Quaternions,
Kalman filters,
Magnetometers,
Estimation,
Acceleration,
Magnetic sensors"
Internet of Things Based Energy Aware Smart Home Control System,"The concept of smart home is widely favored, as it enhances the lifestyle of the residents involving multiple disciplines, i.e., lighting, security, and much more. As the smart home networks continue to grow in size and complexity, it is essential to address a handful among the myriads of challenges related to data loss due to the interference and efficient energy management. In this paper, we propose a smart home control system using a coordinator-based ZigBee networking. The working of the proposed system is three fold: smart interference control system controls the interference caused due to the co-existence of IEEE 802.11x-based wireless local area networks and wireless sensor networks; smart energy control system is developed to integrate sunlight with light source and optimizes the energy consumption of the household appliances by controlling the unnecessary energy demands; and smart management control system to efficiently control the operating time of the electronic appliances. The performance of the proposed smart home is testified through computer simulation. Simulation results show that the proposed smart home system is less affected by the interference and efficient in reducing the energy consumption of the appliances used in a smart home.","Smart homes,
Home automation,
Energy management,
Internet of things,
ZigBee,
Interference,
Wireless LAN,
IEEE 802.11x Standard"
Fronthaul Compression and Transmit Beamforming Optimization for Multi-Antenna Uplink C-RAN,"This paper considers the joint fronthaul compression and transmit beamforming design for the uplink cloud radio access network (C-RAN), in which multi-antenna users communicate with a cloud-computing based centralized processor (CP) through multi-antenna base-stations (BSs) serving as relay nodes. A compress-and-forward relaying strategy, named the virtual multiple-access channel (VMAC) scheme, is employed, in which the BSs can either perform single-user compression or Wyner-Ziv coding to quantize the received signals and send the quantization bits to the CP via capacity-limited fronthaul links; the CP performs successive decoding with either successive interference cancellation (SIC) receiver or linear minimum-mean square-error (MMSE) receiver. Under this setup, this paper investigates the joint optimization of the transmit beamformers and the quantization noise covariance matrices for maximizing the network utility. A novel weighted minimum-mean-square-error successive convex approximation (WMMSE-SCA) algorithm is first proposed for maximizing the weighted sum rate under the user transmit power and fronthaul capacity constraints with single-user compression. Assuming a heuristic decompression order, the proposed algorithm is then adapted for optimizing the transmit beamforming and fronthaul compression under Wyner-Ziv coding. This paper also proposes a low-complexity separate design consisting of optimizing transmit beamformers for the Gaussian vector multiple-access channel along with per-antenna quantizers with uniform quantization noise levels across the antennas at each BS. Numerical results show that majority of the performance gain brought by C-RAN comes from the implementation of SIC at the CP. Furthermore, the low complexity separate design already performs very close to the optimized joint design in regime of practical interest.","Array signal processing,
Receivers,
Encoding,
Quantization (signal),
Uplink,
Silicon carbide,
Decoding"
Increasing the Reliability of Crowdsourcing Evaluations Using Online Quality Assessment,"Manual annotations and transcriptions have an ever-increasing importance in areas such as behavioral signal processing, image processing, computer vision, and speech signal processing. Conventionally, this metadata has been collected through manual annotations by experts. With the advent of crowdsourcing services, the scientific community has begun to crowdsource many tasks that researchers deem tedious, but can be easily completed by many human annotators. While crowdsourcing is a cheaper and more efficient approach, the quality of the annotations becomes a limitation in many cases. This paper investigates the use of reference sets with predetermined ground-truth to monitor annotators' accuracy and fatigue, all in real-time. The reference set includes evaluations that are identical in form to the relevant questions that are collected, so annotators are blind to whether or not they are being graded on performance on a specific question. We explore these ideas on the emotional annotation of the MSP-IMPROV database. We present promising results which suggest that our system is suitable for collecting accurate annotations.",
Generalized Code Index Modulation Technique for High-Data-Rate Communication Systems,"In this paper, we propose a generalized code index modulation (CIM) technique for direct-sequence spread spectrum (DSSS) communication. In particular, at the transmitter, the bit stream is divided into blocks in which each block is divided into two subblocks: mapped and modulated subblocks. Thereafter, the bits within the mapped subblock are used to select one of the predefined spreading codes, which is then used to spread the modulated bits of the second subblock. In this design, using the spreading code index as an information-bearing unit increases the overall spectral efficiency of this system. At the receiver side, the spreading code index is first estimated, thus resulting in a direct estimation of mapped subblock bits. Consequently, the corresponding spreading code to this estimated index is used to despread the modulated symbol of the modulated subblock. Subsequently, mathematical expressions for bit error rate (BER), symbol error rate (SER), throughput, energy efficiency, and the system complexity are derived to analyze the system performance. Finally, simulation results show that the proposed modulation scheme can achieve a higher data rate than the conventional DSSS system, with lower energy consumption and complexity.",
In-Band Full Duplex Broadband Power Line Communications,"In this paper, we introduce in-band full duplexing (IBFD) for broadband power line communication (BB-PLC) systems. Inspired by the use of IBFD in digital subscriber lines, Ethernet, cable communication, and recently in wireless communication, we investigate the constraints and requirements for a successful IBFD implementation in BB-PLC. We propose a two-stage IBFD structure consisting of an initial analog isolation using an active hybrid circuit, and a simplified mixed-domain digital echo cancellation procedure to suppress the self-interference. Furthermore, we enhance the digital cancellation filter to better adapt to linear periodically time-varying channel conditions, commonly encountered in PLC scenarios. We evaluate our solution under diverse power line channel and noise conditions to examine the overall data rate gains that can be achieved. Last, we extend IBFD to multiple-input multiple-output BB-PLC systems that enable faster and/or more robust data transmission.",
Using crowdsourced data in location-based social networks to explore influence maximization,"Online social networks have gained significant popularity recently. The problem of influence maximization in online social networks has been extensively studied. However, in prior works, influence propagation in the physical world, which is also an indispensable factor, is not considered. The Location-Based Social Networks (LBSNs) are a special kind of online social networks in which people can share location-embedded information. In this paper, we make use of mobile crowdsourced data obtained from location-based social network services to study influence maximization in LBSNs. A novel network model and an influence propagation model taking influence propagation in both online social networks and the physical world into consideration are proposed. An event activation position selection problem is formalized and a corresponding solution is provided. The experimental results indicate that the proposed influence propagation model is meaningful and the activation position selection algorithm has high performance.","Trajectory,
Computer science,
Electronic mail,
Mobile computing,
Mobile communication,
Facebook"
A Big Data Clustering Algorithm for Mitigating the Risk of Customer Churn,"As market competition intensifies, customer churn management is increasingly becoming an important means of competitive advantage for companies. However, when dealing with big data in the industry, existing churn prediction models cannot work very well. In addition, decision makers are always faced with imprecise operations management. In response to these difficulties, a new clustering algorithm called semantic-driven subtractive clustering method (SDSCM) is proposed. Experimental results indicate that SDSCM has stronger clustering semantic strength than subtractive clustering method (SCM) and fuzzy c-means (FCM). Then, a parallel SDSCM algorithm is implemented through a Hadoop MapReduce framework. In the case study, the proposed parallel SDSCM algorithm enjoys a fast running speed when compared with the other methods. Furthermore, we provide some marketing strategies in accordance with the clustering results and a simplified marketing activity is simulated to ensure profit maximization.",
Secure and Scalable Data Collection With Time Minimization in the Smart Grid,"Deployment of data generation devices such as sensors and smart meters have been accelerating toward the vision of smart grid. The volume of data to be collected increases tremendously. Secure, efficient, and scalable data collection becomes a challenging task. In this paper, we present a secure and scalable data communications protocol for smart grid data collection. Under a hierarchical architecture, relay nodes [also known as data collectors (DCs)] collect and convey the data securely from measurement devices to the power operator. While the DCs can verify the integrity, they are not given access to the content, which may pave the way for third party providers to deliver value-added services or even the data collection itself. We further present optimization solutions for minimizing the total data collection time.","Data collection,
Protocols,
Smart grids,
DH-HEMTs,
Public key"
Conditional Identity-Based Broadcast Proxy Re-Encryption and Its Application to Cloud Email,"Recently, a number of extended Proxy Re-Encryptions (PRE), e.g. Conditional (CPRE), identity-based PRE (IPRE) and broadcast PRE (BPRE), have been proposed for flexible applications. By incorporating CPRE, IPRE and BPRE, this paper proposes a versatile primitive referred to as conditional identity-based broadcast PRE (CIBPRE) and formalizes its semantic security. CIBPRE allows a sender to encrypt a message to multiple receivers by specifying these receivers' identities, and the sender can delegate a re-encryption key to a proxy so that he can convert the initial ciphertext into a new one to a new set of intended receivers. Moreover, the re-encryption key can be associated with a condition such that only the matching ciphertexts can be re-encrypted, which allows the original sender to enforce access control over his remote ciphertexts in a fine-grained manner. We propose an efficient CIBPRE scheme with provable security. In the instantiated scheme, the initial ciphertext, the re-encrypted ciphertext and the re-encryption key are all in constant size, and the parameters to generate a re-encryption key are independent of the original receivers of any initial ciphertext. Finally, we show an application of our CIBPRE to secure cloud email system advantageous over existing secure email systems based on Pretty Good Privacy protocol or identity-based encryption.","Receivers,
Electronic mail,
Encryption,
Public key,
Games"
Capacitance Modeling in Dual Field-Plate Power GaN HEMT for Accurate Switching Behavior,"In this paper, a surface-potential-based compact model is proposed for the capacitance of an AlGaN/GaN high-electron mobility transistor (HEMT) dual field-plate (FP) structure, i.e., with gate and source FPs. FP incorporation in a HEMT gives an improvement in terms of enhanced breakdown voltage, reduced gate leakage, and so on, but it affects the capacitive nature of the device, particularly by bringing into existence in a subthreshold region of operation, a feedback miller capacitance between the gate and the drain, and also a capacitance between the drain and the source, therefore, affecting switching characteristics. Here, we model the bias dependence of the terminal capacitances, wherein the expressions developed for intrinsic charges required for capacitance derivation are analytical and physics-based in nature and valid for all regions of device operation. The proposed model, implemented in Verilog-A, is in excellent agreement with the measured data for different temperatures.","Capacitance,
Logic gates,
HEMTs,
Aluminum gallium nitride,
Wide band gap semiconductors,
Mathematical model"
Single-Image Super-Resolution Using Active-Sampling Gaussian Process Regression,"As well known, Gaussian process regression (GPR) has been successfully applied to example learning-based image super-resolution (SR). Despite its effectiveness, the applicability of a GPR model is limited by its remarkably computational cost when a large number of examples are available to a learning task. For this purpose, we alleviate this problem of the GPR-based SR and propose a novel example learning-based SR method, called active-sampling GPR (AGPR). The newly proposed approach employs an active learning strategy to heuristically select more informative samples for training the regression parameters of the GPR model, which shows significant improvement on computational efficiency while keeping higher quality of reconstructed image. Finally, we suggest an accelerating scheme to further reduce the time complexity of the proposed AGPR-based SR by using a pre-learned projection matrix. We objectively and subjectively demonstrate that the proposed method is superior to other competitors for producing much sharper edges and finer details.",
Shaped Gaussian Dictionaries for Quantized Networked Control Systems With Correlated Dropouts,"This paper studies fixed rate vector quantisation for noisy networked control systems (NCSs) with correlated packet dropouts. In particular, a discrete-time linear time invariant system is to be controlled over an error-prone digital channel. The controller uses (quantized) packetized predictive control to reduce the impact of packet losses. The proposed vector quantizer is based on sparse regression codes (SPARC), which have recently been shown to be efficient in open-loop systems when coding white Gaussian sources. The dictionaries in existing design of SPARCs consist of independent and identically distributed (i.i.d.) Gaussian entries. However, we show that a significant gain can be achieved by using Gaussian dictionaries that are shaped according to the second-order statistics of the NCS in question. Furthermore, to avoid training of the dictionaries, we provide closed-form expressions for the required second-order statistics in the absence of quantization.","Actuators,
Stability analysis,
Predictive control,
Networked control systems,
Encoding,
Vector quantization"
A survey on security in network functions virtualization,"Network functions virtualization (NFV) is an emerging network technology. Instead of deploying hardware equipments for each network functions, virtualized network functions in NFV are realized through virtual machines (VMs) running various software on top of industry standard high volume servers or cloud computing infrastructure. NFV decreases hardware equipment costs and energy consumption, improves operational efficiency and optimizes network configuration. However, potential security issues is a major concern of NFV. In this paper, we survey the challenges and opportunities in NFV security. We describe the NFV architecture design and some potential NFV security issues and challenges. We also present existing NFV security solutions and products. We also survey NFV security use cases and explore promising research directions in this area.","Security,
Cloud computing,
Computer architecture,
Virtualization,
Virtual machine monitors,
Hardware"
Proportionate Adaptive Filtering for Block-Sparse System Identification,"In this paper, a new family of proportionate normalized least mean square (PNLMS) adaptive algorithms that improve the performance of identifying block-sparse systems is proposed. The main proposed algorithm, called block-sparse PNLMS (BS-PNLMS), is based on the optimization of a mixed l2,1 norm of the adaptive filter's coefficients. It is demonstrated that both the NLMS and the traditional PNLMS are special cases of BS-PNLMS. Meanwhile, a block-sparse improved PNLMS (BS-IPNLMS) is also derived for both sparse and dispersive impulse responses. Simulation results demonstrate that the proposed BS-PNLMS and BS-IPNLMS algorithms outperformed the NLMS, PNLMS and IPNLMS algorithms with only a modest increase in computational complexity.",
Recent Advances in Energy-Efficient Routing Protocols for Wireless Sensor Networks: A Review,"Due to a battery constraint in wireless sensor networks (WSNs), prolonging their lifetime is important. Energy-efficient routing techniques for WSNs play a great role in doing so. In this paper, we articulate this problem and classify current routing protocols for WSNs into two categories according to their orientation toward either homogeneous or heterogeneous WSNs. They are further classified into static and mobile ones. We give an overview of these protocols in each category by summarizing their characteristics, limitations, and applications. Finally, some open issues in energy-efficient routing protocol design for WSNs are indicated.",
Hardware design and optimal ADC resolution for uplink massive MIMO systems,"This work focuses on the hardware design for the efficient operation of Massive multiple-input multiple-output (MIMO) systems. A closed-form uplink achievable data rate expression is derived considering imperfect channel state information (CSI) and hardware impairments. We formulate an optimization problem to maximize the sum data rate subject to a constraint on the total power consumption. A general power consumption model accounting for the level of hardware impairments is utilized. The optimization variables are the number of base station (BS) antennas and the level of impairments per BS antenna. The resolution of the analog-to-digital converter (ADC) is a primary source of such impairments. The results show the trade-off between the number of BS antennas and the level of hardware impairments, which is important for practical hardware design. Moreover, the maximum power consumption can be tuned to achieve maximum energy efficiency (EE). Numerical results suggest that the optimal level of hardware impairments yields ADCs of 4 to 5 quantization bits.","Hardware,
Power demand,
Antennas,
MIMO,
Channel estimation,
Quantization (signal),
Distortion"
Radio Resource Allocation for Device-to-Device Underlay Communication Using Hypergraph Theory,"Device-to-device (D2D) communication has been recognized as a promising technique to offload the traffic for the evolved Node B (eNB). However, D2D transmission as an underlay causes severe interference to both the cellular and other D2D links, which imposes a great technical challenge to radio resource allocation. Conventional graph based resource allocation methods typically consider the interference between two user equipments (UEs), but they cannot model the interference from multiple UEs to completely characterize the interference. In this paper, we study channel allocation using hypergraph theory to coordinate the interference between D2D pairs and cellular UEs, where an arbitrary number of D2D pairs are allowed to share the uplink channels with the cellular UEs. Hypergraph coloring is used to model the cumulative interference from multiple D2D pairs, and thus, eliminate the mutual interference. Simulation results show that the system capacity is significantly improved using the proposed hypergraph method in comparison to the conventional graph based one.","Interference,
Resource management,
Channel allocation,
Receivers,
Color,
Wireless communication,
Uplink"
A Digital PWM Current Controller for Switched Reluctance Motor Drives,"In this paper, a PWM current controller for the switched reluctance motor drives is proposed and digitally implemented. Parameter adaption is employed to guarantee both fast dynamics and robustness of the proposed current controller. The relationship between the proposed controller and the conventional controllers including PI and dead-beat controller is also presented. An improved sampling method is designed to avoid PWM delay in the control loop. Simulation and experimental results show that the proposed controller keeps similar dynamic response and accuracy as hysteresis controller under various testing conditions. However, compared with the hysteresis controller, the proposed current controller needs much lower sampling rate and has a constant switching frequency.",
Hyperspectral Image Classification by Fusing Collaborative and Sparse Representations,"This paper proposes to combine collaborative representation (CR) and sparse representation (SR) for hyperspectral image classification. SR may select too few samples that cannot well reflect within-class variations, while CR generates nonsparse code using all the atoms that may unfortunately include between-class interference. To alleviate these problems, two methods fusing CR and SR are proposed, i.e., a fused representation-based classification (FRC) method and an elastic net representation-based classification (ENRC) method. FRC attempts to achieve the balance between CR and SR in the residual domain, while ENRC uses a convex combination of ℓ1 and ℓ2 penalties. Experimental results on two hyperspectral data demonstrate that the proposed methods outperform the original counterparts, i.e., CR-based classification (CRC) and SR-based classification (SRC).","Testing,
Hyperspectral imaging,
Training,
Collaboration,
Earth"
Deep background subtraction with scene-specific convolutional neural networks,"Background subtraction is usually based on low-level or hand-crafted features such as raw color components, gradients, or local binary patterns. As an improvement, we present a background subtraction algorithm based on spatial features learned with convolutional neural networks (ConvNets). Our algorithm uses a background model reduced to a single background image and a scene-specific training dataset to feed ConvNets that prove able to learn how to subtract the background from an input image patch. Experiments led on 2014 ChangeDetection.net dataset show that our ConvNet based algorithm at least reproduces the performance of state-of-the-art methods, and that it even outperforms them significantly when scene-specific knowledge is considered.","Neural networks,
Training,
Gray-scale,
Convolutional codes,
Cameras,
Computational modeling,
Video sequences"
L-SHADE with competing strategies applied to CEC2015 learning-based test suite,"Successful adaptive variant of differential evolution, the Success-history based parameter adaptation of Differential Evolution using linear population size reduction algorithm (L-SHADE), was improved. Adaptive mechanisms used in the algorithm were joined with adaptive mechanism proposed for competitive differential evolution algorithm. Four strategies, including the original one and strategies with exponential crossover, compete in the new LSHADE44 algorithm. The proposed algorithm is applied to the benchmark set defined for Learning-based case of Special Session and Competitions on Real-Parameter Single Objective Optimization on CEC2016. According to preliminary experiments, the proposed algorithm with competing strategies outperformed the original L-SHADE in the most of the test problems.","Sociology,
Statistics,
Optimization,
Electronic mail,
Benchmark testing,
Linear programming,
Computers"
An Integrated Simulation Framework to Model Electric Vehicle Operations and Services,"At present, battery-charging operations constitute one of the most critical obstacles toward a large-scale uptake of electric mobility (EM), due to performance issues and implementation complexities. Although several solutions based on the utilization of information and communication technologies and on mobile applications have been investigated to assist electric vehicle (EV) drivers and to coordinate charging operations, there is still the problem of how to evaluate and validate such solutions on realistic scenarios, due to the lack of accurate simulators integrating vehicular mobility, wireless communication, and battery charging/discharging models. In this paper, we attempt to fill this gap by proposing a novel EV simulation platform that can assist in the predeployment of charging infrastructures and services on realistic large-scale EM scenarios. The simulation platform, which is realized within the ARTEMIS EU project “Internet of Energy for Electric Mobility,” supports two utilization modes, i.e., evaluation of EM scenarios and immersive emulation of EM-related mobile applications, due to a semantic architecture through which virtual and real components can be integrated in a seamless way. We provide three major contributions with respect to the state of the art. First, we extend the existing cosimulation platform composed of SUMO (a vehicular traffic simulator) and OMNET++ (a network simulator) with realistic models of EVs, electric vehicle supply equipment, and ontology-based communication protocols that enable the deployment of city-wide mobile services (e.g., charging reservation). Second, we validate the battery model against the consumptions data of target EVs, and we evaluate the operations of EVs on a large-scale scenario (the city of Bologna, Italy), by analyzing the effectiveness of the charging reservation process and the resulting impact to the smart grid. Finally, we introduce the Mobile Application Zoo, which is a sandbox through which EM-related mobile applications can be seamlessly integrated within the simulation platform to be validated on virtual environments before their deployment on real scenarios, and we describe the implementation of an Android application for battery monitoring and charging reservation.","Vehicles,
Batteries,
Smart grids,
Mobile communication,
Load modeling,
Mathematical model,
Data models"
Replication-Based Load Balancing,"Load balancing of large distributed server systems is a complex optimization problem of critical importance in cloud systems and data centers. Existing schedulers often incur a high communication overhead when collecting the data required to make scheduling decisions, hence delaying job requests on their way to the executing servers. We propose a novel scheme that incurs no communication overhead between the users and the servers upon job arrival, thus removing any scheduling overhead from the job's critical path. Our approach is based on creating several replicas of each job and sending each replica to a different server. Upon the arrival of a replica to the head of the queue at its server, the latter signals the servers holding replicas of that job, so as to remove them from their queues. We show, through analysis and simulations, that this scheme significantly improves the expected queuing overhead over traditional schemes under various load conditions and different job length distributions. In addition, we show that our scheme remains efficient even when the inter-server signal propagation delay is significant (relative to the job's execution time). We provide a heuristic solution to the performance degradation that occurs in such cases and show, by simulations, that it efficiently mitigates the detrimental effect of propagation delays.","Servers,
Load modeling,
Delays,
Load management,
Propagation delay,
Mathematical model,
Vectors"
Analysis and Augmented Spatial Processing for Uplink OFDMA MU-MIMO Receiver With Transceiver I/Q Imbalance and External Interference,"This paper addresses receiver (RX) signal processing in multiuser multiple-input multiple-output (MU-MIMO) systems. We focus on uplink orthogonal frequency-division multiple access (OFDMA)-based MU-MIMO communications under in-phase/quadrature (I/Q) imbalance in the associated radio frequency electronics. It is shown in the existing literature that transceiver I/Q imbalances cause cross-talk of mirror-subcarriers in OFDM systems. As opposed to typically reported single-user studies, we extend the studies to OFDMA-based MU-MIMO communications, with simultaneous user multiplexing in both frequency and spatial domains, and incorporate also external interference from multiple sources at RX input, for modeling challenging conditions in increasingly popular heterogeneous networks. In the signal processing developments, we exploit the augmented subcarrier processing, which processes each subcarrier jointly with its counterpart at the image subcarrier, and jointly across all RX antennas. Furthermore, we derive an optimal augmented linear RX in terms of minimizing the mean-squared error. The novel approach integrates the I/Q imbalance mitigation, external interference suppression, and data stream separation of multiple UEs into a single processing stage, thus avoiding separate transceiver calibration. Extensive analysis and numerical results show the signal-to-interference-plus-noise ratio (SINR) and symbol-error rate (SER) behavior of an arbitrary data stream after RX spatial processing as a function of different system and impairment parameters. Based on the results, the performance of the conventional per-subcarrier processing is heavily limited under transceiver I/Q imbalances, and is particularly sensitive to external interferers, whereas the proposed augmented subcarrier processing provides a high-performance signal processing solution being able to detect the signals of different users as well as suppress the external interference efficiently. Finally, we also extend the studies to massive MIMO framework, with very large antenna systems. It is shown that, despite the huge number of RX antennas, the conventional linear processing methods still suffer heavily from I/Q imbalances while the augmented approach does not have such limitations.",
"Anti-Spoofing for Text-Independent Speaker Verification: An Initial Database, Comparison of Countermeasures, and Human Performance","In this paper, we present a systematic study of the vulnerability of automatic speaker verification to a diverse range of spoofing attacks. We start with a thorough analysis of the spoofing effects of five speech synthesis and eight voice conversion systems, and the vulnerability of three speaker verification systems under those attacks. We then introduce a number of countermeasures to prevent spoofing attacks from both known and unknown attackers. Known attackers are spoofing systems whose output was used to train the countermeasures, while an unknown attacker is a spoofing system whose output was not available to the countermeasures during training. Finally, we benchmark automatic systems against human performance on both speaker verification and spoofing detection tasks.",
VoteTrust: Leveraging Friend Invitation Graph to Defend against Social Network Sybils,"Online social networks (OSNs) suffer from the creation of fake accounts that introduce fake product reviews, malware and spam. Existing defenses focus on using the social graph structure to isolate fakes. However, our work shows that Sybils could befriend a large number of real users, invalidating the assumption behind social-graph-based detection. In this paper, we present VoteTrust, a scalable defense system that further leverages user-level activities. VoteTrust models the friend invitation interactions among users as a directed, signed graph, and uses two key mechanisms to detect Sybils over the graph: a voting-based Sybil detection to find Sybils that users vote to reject, and a Sybil community detection to find other colluding Sybils around identified Sybils. Through evaluating on Renren social network, we show that VoteTrust is able to prevent Sybils from generating many unsolicited friend requests. We also deploy VoteTrust in Renen, and our real experience demonstrates that VoteTrust can detect large-scale collusion among Sybils.",
Identifiability in Blind Deconvolution With Subspace or Sparsity Constraints,"Blind deconvolution (BD), the resolution of a signal and a filter given their convolution, arises in many applications. Without further constraints, BD is ill-posed. In practice, subspace or sparsity constraints have been imposed to reduce the search space, and have shown some empirical success. However, the existing theoretical analysis on uniqueness in BD is rather limited. In an effort to address the still open question, we derive sufficient conditions under which two vectors can be uniquely identified from their circular convolution, subject to subspace or sparsity constraints. These sufficient conditions provide the first algebraic sample complexities for BD. We first derive a sufficient condition that applies to almost all bases or frames. For BD of vectors in ℂn, with two subspace constraints of dimensions m1 and m2, the required sample complexity is n ≥ m1m2. Then, we impose a sub-band structure on one basis, and derive a sufficient condition that involves a relaxed sample complexity n≥ m1+m2-1, which we show to be optimal. We present the extensions of these results to BD with sparsity constraints or mixed constraints, with the sparsity level replacing the subspace dimension. The cost for the unknown support in this case is an extra factor of 2 in the sample complexity.","Deconvolution,
Convolution,
Complexity theory,
Dictionaries,
Subspace constraints,
Sparse matrices"
"Multi-Sensor Scheduling for State Estimation With Event-Based, Stochastic Triggers","In networked systems, state estimation is hampered by communication limits. Past approaches, which consider scheduling sensors through deterministic event-triggers, reduce communication and maintain estimation quality. However, these approaches destroy the Gaussian property of the state, making it computationally intractable to obtain an exact minimum mean squared error estimate. We propose a stochastic event-triggered sensor schedule for state estimation which preserves the Gaussianity of the system, extending previous results from the single-sensor to the multi-sensor case.",
Green Wireless Power Transfer Networks,"A wireless power transfer network (WPTN) aims to support devices with cable-less energy on-demand. Unfortunately, wireless power transfer itself-especially through radio frequency radiation rectification-is fairly inefficient due to decaying power with distance, antenna polarization, etc. Consequently, idle charging needs to be minimized to reduce the already large costs of providing energy to the receivers. In turn, energy saving in a WPTN can be boosted by simply switching off the energy transmitter when the received energy is too weak for rectification. Therefore in this paper we propose, and experimentally evaluate, two “green” protocols for the control plane of static charger/mobile receiver WPTN aimed at optimizing the charger workflow to make the WPTN reduce idle time of transmitters. Those protocols are: “beaconing,” where receivers advertise their presence to the WPTN, and “probing” exploiting the receiver feedback from the WPTN on the level of received energy. We demonstrate that both protocols reduce the unnecessary WPTN uptime, however trading it for the reduced energy provision, compared to the base case of “WPTN charger always on.” For example, our system (in our experiments) saves at most ≈80 % of energy at the charger with only ≈17% less energy possibly harvested.",
Reducing Friction in Software Development,"Software is being produced so fast that its growth hinders its sustainability. Technical debt, which encompasses internal software quality, evolution and maintenance, reengineering, and economics, is growing such that its management is becoming the dominant driver of software engineering progress. It spans the software engineering life cycle, and its management capitalizes on recent advances in fields such as source code analysis, quality measurement, and project management. Managing technical debt will become an investment activity applying economic theories. It will effectively address the architecture level and will offer specific processes and tools employing data science and analytics to support decision making. It will also be an essential part of the software engineering curriculum. Getting ahead of the software quality and innovation curve will inevitably involve establishing technical-debt management as a core software engineering practice. This article is part of a special issue on the Future of Software Engineering.",
Spectrally Efficient CSI Acquisition for Power Line Communications: A Bayesian Compressive Sensing Perspective,"Power line communication (PLC) techniques present a no extra wire solution for the communication purpose in a smart grid due to the ubiquity and low cost. Moreover, the through-the-grid property of PLC has naturally extended its possible applications, including but not limited to the automatic meter reading, line quality monitoring, online diagnostics, and network tomography. To guarantee the performance of communications as well as other applications in PLC systems, accurate channel state information (CSI) acquisition should be performed regularly. However, the conventional pilot-based CSI acquisition approaches in PLC systems have not made full use of the channel characteristics and hence suffer from a low spectral efficiency. In this paper, by exploiting the parametric sparsity and discretizing the electrical length in the well-known PLC channel model, we formulate the non-sparse (either time domain or frequency domain) PLC channel into a compressive sensing (CS) applicable problem. Furthermore, we propose a spectrally efficient CSI acquisition scheme under the framework of Bayesian CS and extend it to the multiple-input multiple-output PLC by investigating the channel spatial correlation. Compared with the existing sparse CSI acquisition schemes for PLC, such as the annihilating filter-based and the estimating signal parameters via rotational invariance technique-based ones, the proposed scheme has better mean square error performance and noise robustness.","MIMO,
Ports (Computers),
Correlation,
Bayes methods,
Transmission line matrix methods,
Frequency response,
Compressed sensing"
Received Signal Strength-Based Robust Cooperative Localization With Dynamic Path Loss Model,"Robust received signal strength (RSS)-based cooperative wireless localization using a linear least squares (LLS) method is proposed. We first extend the LLS methods to the cooperative case. To make the proposed algorithm robust, dynamic path loss models are utilized to describe the changing environments; the path loss constants are updated based on the estimated positions of the client nodes. Furthermore, anchor nodes (reference nodes) calibration is considered to deal with the anchor node position errors. The simulation results are given for the proposed methods. Compared with the RSS-based non-cooperative LLS type methods, robust and better performance are obtained.",
A Hierarchical Approach to Three-Dimensional Segmentation of LiDAR Data at Single-Tree Level in a Multilayered Forest,"Small-footprint high-density LiDAR data provide information on both the dominant and the subdominant layers of the forest. However, tree detection is usually carried out in the Canopy Height Model (CHM) image domain, where not all the dominant trees are distinguishable and the understory vegetation is not visible. To address these issues, we propose a novel method that integrates the analysis of the CHM with that of the point cloud space (PCS) to 1) improve the accuracy in the detection and delineation of the dominant trees and 2) identify and delineate the subdominant trees. By means of a derivative analysis of the horizontal profile of the forest, the method detects the missed crowns and delineates the crown boundaries directly in the PCS. Then, for each segmented crown, the vertical profile is analyzed to identify the presence of subcanopies and extract them. The proposed method does not require any prior knowledge on the stand properties (e.g., crown size and forest density). Experimental results obtained on two LiDAR data sets characterized by different laser point density show that the proposed method always improved the detection rate compared to other state-of-the-art techniques. It correctly detected 97% and 92% of the dominant trees measured in situ in high- and low-density LiDAR data, respectively. Moreover, it automatically identified 77% of the subdominant trees manually extracted by an expert operator in the high-density LiDAR data.","Vegetation,
Laser radar,
Three-dimensional displays,
Vegetation mapping,
Spatial resolution,
Clustering algorithms,
Data mining"
Path-Following Algorithms for Beamforming and Signal Splitting in RF Energy Harvesting Networks,"We consider the joint design of transmit beamforming and receive signal-splitting ratios in the downlink of a wireless network with simultaneous radio frequency information and energy transfer. Under constraints on the signal-to-interference-plus-noise ratio at each user and the total transmit power at the base station, the design objective is to maximize either the sum harvested energy or the minimum harvested energy. We develop a computationally efficient path-following method to solve these challenging nonconvex optimization problems. We mathematically show that the proposed algorithms iteratively progress and converge to locally optimal solutions. Simulation results further show that these locally optimal solutions are the same as the globally optimal solutions for the considered practical network settings.",
Extremely High-Frequency Flexible Graphene Thin-Film Transistors,"We have achieved 140-nm channel length graphene thin-film transistors (TFTs) on flexible glass with a 95-GHz intrinsic cutoff frequency and greater than 30-GHz intrinsic power frequency after standard de-embedding. The flexible glass substrate offers subnanometer surface smoothness as well as high thermal conductivity, 1 W/m · K, which can prevent thermomechanical failure, which is a limitation of plastic and rubber substrates. In addition, we developed a flexible 60-nm polyimide thin film as gate dielectric with low surface roughness less than 0.35 nm for optimal carrier transport and facilitate edge-injection contacts for low contact resistance. The maximum electron (hole) mobility is 4540 (1100) cm2/V · s, and the extracted contact resistance in the electron (hole) branch is 1140 (720) Ω · μm. The intrinsic cutoff frequency is 196% higher than our previous results on polymeric substrates. Importantly, the experimental saturation velocity of the graphene TFT is the highest for any flexible transistor on any material system reported so far.",
Synergistic policy and virtual machine consolidation in cloud data centers,"In modern Cloud Data Centers (DC)s, correct implementation of network policies is crucial to provide secure, efficient and high performance services for tenants. It is reported that the inefficient management of network policies accounts for 78% of DC downtime, challenged by the dynamically changing network characteristics and by the effects of dynamic Virtual Machine (VM) consolidation. While there has been significant research in policy and VM management, they have so far been treated as disjoint research problems. In this paper, we explore the simultaneous, dynamic VM and policy consolidation, and formulate the Policy-VM Consolidation (PVC) problem, which is shown to be NP-Hard. We then propose Sync, an efficient and synergistic scheme to jointly consolidate network policies and virtual machines. Extensive evaluation results and a testbed implementation of our controller show that policy and VM migration under Sync significantly reduces flow end-to-end delay by nearly 40%, and network-wide communication cost by 50% within few seconds, while adhering strictly to the requirements of network policies.",
D2D Fogging: An Energy-Efficient and Incentive-Aware Task Offloading Framework via Network-assisted D2D Collaboration,"In this paper, we propose device-to-device (D2D) Fogging, a novel mobile task offloading framework based on network-assisted D2D collaboration, where mobile users can dynamically and beneficially share the computation and communication resources among each other via the control assistance by the network operators. The purpose of D2D Fogging is to achieve energy efficient task executions for network wide users. To this end, we propose an optimization problem formulation that aims at minimizing the time-average energy consumption for task executions of all users, meanwhile taking into account the incentive constraints of preventing the over-exploiting and free-riding behaviors which harm user's motivation for collaboration. To overcome the challenge that future system information such as user resource availability is difficult to predict, we develop an online task offloading algorithm, which leverages Lyapunov optimization methods and utilizes the current system information only. As the critical building block, we devise corresponding efficient task scheduling policies in terms of three kinds of system settings in a time frame. Extensive simulation results demonstrate that the proposed online algorithm not only achieves superior performance (e.g., it reduces approximately 30% ~ 40% energy consumption compared with user local execution), but also adapts to various situations in terms of task type, user amount, and task frequency.","Device-to-device communication,
Mobile communication,
Collaboration,
Mobile computing,
Base stations,
Mobile handsets,
Green communications,
Energy efficiency"
The Effect of FRT Behavior of VSC-HVDC-Connected Offshore Wind Power Plants on AC/DC System Dynamics,"Future power systems will contain more converter-based generation, among which are the voltage-source converter-high-voltage direct-current (VSC-HVDC)-connected offshore wind power plants (WPP). Their interaction with the onshore system influences power system dynamics in the transient stability timeframe. The respective protection and control methods which cause this interaction must be taken into account in grid-integration studies performed today. This paper gives insight into the effect of typically required fault ride through (FRT) and post-FRT measures of VSC-HVDC-connected offshore WPPs on the combined ac and HVDC system dynamics. Several important sensitivities are addressed, among which are: 1) FRT implementation, 2) the postfault active power-recovery rates, 3) the ac network dynamic characteristics, and 4) the HVDC topology. The analysis is first performed as a proof of concept on a small benchmark system, and subsequently generalized to a realistic dynamic model of the future Northwestern European power system. The results of this paper can be used as a reference for understanding the effects of large-scale VSC-HVDC-connected offshore WPPs on the stability of the onshore interconnected power systems.","Power conversion,
Power system dynamics,
Power system stability,
Stability analysis,
HVDC transmission,
Mathematical model"
Turing Patterns in Memristive Cellular Nonlinear Networks,"The formation of ordered structures, in particular Turing patterns, in complex spatially extended systems has been observed in many different contexts, spanning from natural sciences (chemistry, physics, and biology) to technology (mechanics and electronics). In this paper, it is shown that the use of memristors in a simple cell of a spatially-extended circuit architecture allows us to design systems able to generate Turing patterns. In addition, the memristor parameters play a key role in the selection of the type and characteristics of the emerging pattern, which is also influenced by the initial conditions. The problem of finding the regions of parameters where Turing patterns may emerge in the proposed cellular architecture is solved in an analytic way, and numerical results are shown to illustrate the system behavior with respect to its parameters.",
Metal Artifact Reduction for Polychromatic X-ray CT Based on a Beam-Hardening Corrector,"This paper proposes a new method to correct beam hardening artifacts caused by the presence of metal in polychromatic X-ray computed tomography (CT) without degrading the intact anatomical images. Metal artifacts due to beam-hardening, which are a consequence of X-ray beam polychromaticity, are becoming an increasingly important issue affecting CT scanning as medical implants become more common in a generally aging population. The associated higher-order beam-hardening factors can be corrected via analysis of the mismatch between measured sinogram data and the ideal forward projectors in CT reconstruction by considering the known geometry of high-attenuation objects. Without prior knowledge of the spectrum parameters or energy-dependent attenuation coefficients, the proposed correction allows the background CT image (i.e., the image before its corruption by metal artifacts) to be extracted from the uncorrected CT image. Computer simulations and phantom experiments demonstrate the effectiveness of the proposed method to alleviate beam hardening artifacts.","Computed tomography,
Metals,
Attenuation,
Phantoms,
X-ray imaging,
Geometry,
Approximation methods"
Fabrication of Textile Antennas and Circuits With 0.1 mm Precision,"We present a new selection of E-fibers (also referred to as E-threads) and associated embroidery process. The new E-threads and process achieve a geometrical precision down to 0.1 mm. Thus, for the first time, accuracy of typical printed circuit board (PCB) prototypes can be achieved directly on textiles. Compared to our latest embroidery approach, the proposed process achieves: 1) 3 × higher geometrical precision; 2) 24 × lower fabrication cost; 3) 50% less fabrication time; and 4) equally good RF performance. This improvement was achieved by employing a new class of very thin, 7-filament, Elektrisola E-threads ( diameter ≈ 0.12 mm, almost 2 × thinner than before). To validate our approach, we “printed” and tested a textile spiral antenna operating between 1-5 GHz. Measurement results were in good agreement with simulations. We envision this textile spiral to be integrated within a cap and unobtrusively acquire neuropotentials from wireless fully-passive brain implants. Overall, the proposed embroidery approach brings forward new possibilities for a wide range of applications.",
Landing of a Quadrotor on a Moving Target Using Dynamic Image-Based Visual Servo Control,"This paper addresses the landing problem of a vertical take-off and landing vehicle, exemplified by a quadrotor, on a moving platform using image-based visual servo control. Observable features on a flat and textured target plane are exploited to derive a suitable control law. The target plane may be moving with bounded linear acceleration in any direction. For control purposes, the image of the centroid for a collection of landmarks is used as position measurement, whereas the translational optical flow is used as velocity measurement. The proposed control law guarantees convergence to the desired landing spot on the target plane, without estimating any parameter related to the unknown height, which is also guaranteed to remain strictly positive. Moreover, convergence is guaranteed even in the presence of bounded and possibly time-varying disturbances, resulting, for example, from the motion of the target plane, measurement errors, or wind-induced force disturbances. To improve performance, an estimator for unknown constant force disturbances is also included in the control law. Simulation and experimental results are provided to illustrate and assess the performance of the proposed controller.","Servosystems,
Vehicle dynamics,
Adaptive optics,
Optical imaging,
Optical feedback,
Position control"
CAVER: Algorithms for Analyzing Dynamics of Tunnels in Macromolecules,"The biological function of a macromolecule often requires that a small molecule or ion is transported through its structure. The transport pathway often leads through void spaces in the structure. The properties of transport pathways change significantly in time; therefore, the analysis of a trajectory from molecular dynamics rather than of a single static structure is needed for understanding the function of pathways. The identification and analysis of transport pathways are challenging because of the high complexity and diversity of macromolecular shapes, the thermal motion of their atoms, and the large amount of conformations needed to properly describe conformational space of protein structure. In this paper, we describe the principles of the CAVER 3.0 algorithms for the identification and analysis of properties of transport pathways both in static and dynamic structures. Moreover, we introduce the improved clustering solution for finding tunnels in macromolecules, which is included in the latest CAVER 3.02 version. Voronoi diagrams are used to identify potential pathways in each snapshot of a molecular dynamics trajectory and clustering is then used to find the correspondence between tunnels from different snapshots. Furthermore, the geometrical properties of pathways and their evolution in time are computed and visualized.",
A Spintronic Memristor-Based Neural Network With Radial Basis Function for Robotic Manipulator Control Implementation,"A radial basis function (RBF) neural network control algorithm can effectively improve the robotic manipulators' performance against a large amount of uncertainty. The adaptive law can be derived by using the Lyapunov method so that the stability of robotic manipulator control system and the weight self-adaptive convergence of RBF neural networks will be guaranteed. Meanwhile, system fluctuations and even overshot phenomenon under every start-up process, which are caused by the system's convergence from the given nonoptimal initial weight value to the optimal weight value, can be avoided by using memristors to remember the optimal weight after the system's first operation. According to the above analysis, this correspondence paper designs a kind of RBF neural network control algorithm based on spintronic memristors, and then analyzes its theoretical derivation process and core design idea. Finally, the system simulation model, which uses a two-link robotic manipulator as control object, is built to prove the algorithm's validity and feasibility. Simulation results show that the proposed algorithm can satisfy the effect of presupposition.","Magnetoelectronics,
Memristors,
Neural networks,
Manipulators,
Arrays,
Robot kinematics"
Fingerprint and Assistant Nodes Based Wi-Fi Localization in Complex Indoor Environment,"With the extensive development of Wi-Fi, indoor location services based on received signal strength (RSS) fingerprints have attracted increasing attention from researchers. In complex indoor environments, multipath and non-line-of-sight (NLOS) conditions would lead to large errors in measured values, thereby reducing indoor positioning accuracy. In this paper, we propose a Wi-Fi indoor localization method based on collaboration of fingerprint and assistant nodes. First, appropriate assistant nodes based on the similarity of RSS sequences are elaborately selected around the unknown node and distances between them are used as auxiliary information to improve the positioning accuracy. Furthermore, in the complex indoor circumstances that result in NLOS error, an adaptive Kalman filter with colored noise is used to mitigate the time-of-flight ranging error. Experiments demonstrate that in complex indoor environments, our system can outperform its counterparts with robust performance and low localization estimation error.",
Predicting Protein Function via Semantic Integration of Multiple Networks,"Determining the biological functions of proteins is one of the key challenges in the post-genomic era. The rapidly accumulated large volumes of proteomic and genomic data drives to develop computational models for automatically predicting protein function in large scale. Recent approaches focus on integrating multiple heterogeneous data sources and they often get better results than methods that use single data source alone. In this paper, we investigate how to integrate multiple biological data sources with the biological knowledge, i.e., Gene Ontology (GO), for protein function prediction. We propose a method, called SimNet, to Semantically integrate multiple functional association Networks derived from heterogenous data sources. SimNet firstly utilizes GO annotations of proteins to capture the semantic similarity between proteins and introduces a semantic kernel based on the similarity. Next, SimNet constructs a composite network, obtained as a weighted summation of individual networks, and aligns the network with the kernel to get the weights assigned to individual networks. Then, it applies a network-based classifier on the composite network to predict protein function. Experiment results on heterogenous proteomic data sources of Yeast, Human, Mouse, and Fly show that, SimNet not only achieves better (or comparable) results than other related competitive approaches, but also takes much less time. The Matlab codes of SimNet are available at https://sites.google.com/site/guoxian85/simnet.","Proteins,
Mice,
Semantics,
Bioinformatics,
Measurement,
Estimation"
Learning RAT Selection Game in 5G Heterogeneous Networks,"In this letter, we consider the problem of RAT selection in a heterogeneous cellular network where each user chooses among multiple access technologies. The competition of the users is modeled as an incomplete information game where players are not aware other players' actions. A RAT selection strategy is proposed and is shown that it converges to the Nash equilibrium of the game. Moreover, we consider a more practical case in which the users have no information about other users. For this case, we propose a Q-learning-based algorithm, which converges to the Nash equilibrium of the first problem.","Games,
Nash equilibrium,
Throughput,
Learning (artificial intelligence),
Convergence,
Rats,
Heterogeneous networks"
Robust Energy-Constrained Frequency Reserves From Aggregations of Commercial Buildings,"It has been shown that the heating, ventilation, and air conditioning (HVAC) systems of commercial buildings can offer ancillary services to power systems without loss of comfort. In this paper, we propose a new control framework for reliable scheduling and provision of frequency reserves by aggregations of commercial buildings. The framework incorporates energy-constrained frequency signals, which are adopted by several transmission system operators for loads and storage devices. We use a hierarchical approach with three levels: 1) reserve capacities are allocated among buildings (e.g., on a daily basis) using techniques from robust optimization; 2) a robust model predictive controller optimizes the HVAC system consumption typically every 30 minutes; and 3) a feedback controller adjusts the consumption to provide reserves in real time. We demonstrate how the framework can be used to estimate the reserve capacities in simulations with typical Swiss office buildings and different reserve product characteristics. Our results show that an aggregation of approximately 100 buildings suffices to meet the 5-MW minimum bid size of the Swiss reserve market.",
Unit Commitment Model in Smart Grid Environment Considering Carbon Emissions Trading,"With the development of smart grid, demand-side resources (DSR) will play an increasingly important role in the power balance of supply and demand. In addition, the requirement of a low-carbon smart grid means some policy backgrounds, such as carbon emissions trading (CET), should not be ignored. Under these circumstances, it is a good idea to construct a novel unit commitment (UC) model. This paper proposes a model that not only takes advantage of various resources on the demand side, such as electric vehicles, demand response, and distributed generation, but also reflects the effects of CET on generation schedule. Then, an improved particle swarm optimization (IPSO) algorithm is applied to solve the problem. In numerical studies, we analyze the impacts of DSR and CET on the results of UC, respectively. In addition, two meaningful experiments are conducted to study the approaches to allocate emission quotas and the effects of price transmission mechanism.",
Multiview Uncorrelated Discriminant Analysis,"Multiview learning is more robust than single-view learning in many real applications. Canonical correlation analysis (CCA) is a popular technique to utilize information stemming from multiple feature sets. However, it does not exploit label information effectively. Later multiview linear discriminant analysis (MLDA) was proposed through combining CCA and linear discriminant analysis (LDA). Due to the successful application of uncorrelated LDA (ULDA), which seeks optimal discriminant features with minimum redundancy, we propose a new supervised learning method called multiview ULDA (MULDA) in this paper. This method combines the theory of ULDA with CCA. Then we adapt discriminant CCA (DCCA) instead of the CCA in MLDA and MULDA, and discuss about the effect of this modification. Furthermore, we generalize these methods to the nonlinear case by kernel-based learning techniques. The new method is called kernel multiview uncorrelated discriminant analysis (KMUDA). Then we modify kernel multiview discriminant analysis and KMUDA by replacing Kernel CCA with Kernel DCCA. Our methods are tested on different real datasets and compared with other state-of-the-art methods. Experimental results validate the effectiveness of our methods.","Feature extraction,
Kernel,
Correlation,
Yttrium,
Optimization,
Eigenvalues and eigenfunctions,
Sun"
Fully-Reconfigurable Bandpass/Bandstop Filters and Their Coupling-Matrix Representation,"A new type of a tunable microwave filtering device with reconfigurable bandpass-filter (BPF) and bandstop-filter (BSF) operational modes is reported. It consists of series-cascaded BPF/BSF stages which are formed by two resonating nodes, one non-resonating node (NRN), and two impedance inverters. Each BPF/BSF stage results in two transmission zeros (TZs) that are generated at the natural frequencies of the constituent resonators, whose spectral locations can be reconfigured by tuning the resonating elements. Thus, multi-TZ BPF/BSF responses can be synthesized in the overall circuit which features fully-controllable performances by means of TZ reallocation. The coupling-matrix representation of the proposed frequency-agile BPF/BSF scheme is demonstrated. Moreover, an S-band two-stage prototype based on frequency-reconfigurable evanescent-mode cavity resonators is fabricated to experimentally validate the predicted behavior.","Resonant frequency,
Band-pass filters,
Prototypes,
Cavity resonators,
Passband,
Bandwidth,
Transfer functions"
Fully 3-D Integrated Pixel Detectors for X-Rays,"The vertically integrated photon imaging chip (VIPIC1) pixel detector is a stack consisting of a 500-μm-thick silicon sensor, a two-tier 34-μm-thick integrated circuit, and a host printed circuit board (PCB). The integrated circuit tiers were bonded using the direct bonding technology with copper, and each tier features 1-μm-diameter throughsilicon vias that were used for connections to the sensor on one side, and to the host PCB on the other side. The 80-μm-pixel-pitch sensor was the direct bonding technology with nickel bonded to the integrated circuit. The stack was mounted on the board using Sn-Pb balls placed on a 320-μm pitch, yielding an entirely wire-bond-less structure. The analog front-end features a pulse response peaking at below 250 ns, and the power consumption per pixel is 25 μW. A successful completion of the 3-D integration is reported. In addition, all pixels in the matrix of 64 x 64 pixels were responding on well-bonded devices. Correct operation of the sparsified readout, allowing a single 153-ns bunch timing resolution, was confirmed in the tests on a synchrotron beam of 10-keV X-rays. An equivalent noise charge of 36.2 e- rms and a conversion gain of 69.5 μV/e with 2.6 e- rms and 2.7 μV/e rms pixel-to-pixel variations, respectively, were measured.","Detectors,
Bonding,
Photonics,
X-rays,
Silicon,
Through-silicon vias,
Nickel"
Analysis of Decorrelation Transform Gain for Uncoded Wireless Image and Video Communication,"An uncoded transmission scheme called SoftCast has recently shown great potential for wireless video transmission. Unlike conventional approaches, SoftCast processes input images only by a series of transformations and modulates the coefficients directly to a dense constellation for transmission. The transmission is uncoded and lossy in nature, with its noise level commensurate with the channel condition. This paper presents a theoretical analysis for an uncoded visual communication, focusing on developing a quantitative measurements for the efficiency of decorrelation transform in a generalized uncoded transmission framework. Our analysis reveals that the energy distribution among signal elements is critical for the efficiency of uncoded transmission. A decorrelation transform can potentially bring a significant performance gain by boosting the energy diversity in signal representation. Numerical results on Markov random process and real image and video signals are reported to evaluate the performance gain of using different transforms in uncoded transmission. The analysis presented in this paper is verified by simulated SoftCast transmissions. This provide guidelines for designing efficient uncoded video transmission schemes.",
Real-Time Lexicon-Free Scene Text Localization and Recognition,"An end-to-end real-time text localization and recognition method is presented. Its real-time performance is achieved by posing the character detection and segmentation problem as an efficient sequential selection from the set of Extremal Regions. The ER detector is robust against blur, low contrast and illumination, color and texture variation. In the first stage, the probability of each ER being a character is estimated using features calculated by a novel algorithm in constant time and only ERs with locally maximal probability are selected for the second stage, where the classification accuracy is improved using computationally more expensive features. A highly efficient clustering algorithm then groups ERs into text lines and an OCR classifier trained on synthetic fonts is exploited to label character regions. The most probable character sequence is selected in the last stage when the context of each character is known. The method was evaluated on three public datasets. On the ICDAR 2013 dataset the method achieves state-of-the-art results in text localization; on the more challenging SVT dataset, the proposed method significantly outperforms the state-of-the-art methods and demonstrates that the proposed pipeline can incorporate additional prior knowledge about the detected text. The proposed method was exploited as the baseline in the ICDAR 2015 Robust Reading competition, where it compares favourably to the state-of-the art.","Text recognition,
Erbium,
Robustness,
Optical character recognition software,
Complexity theory,
Real-time systems,
Image edge detection"
A Modified Frequency Domain Algorithm Based on Optimal Azimuth Quadratic Factor Compensation for Geosynchronous SAR Imaging,"The Doppler rate of geosynchronous synthetic aperture radar (GEO SAR) may be positive, negative, or even zero at different orbital positions. When the Doppler rate is zero or near zero at some special positions, the range cell migration cannot be corrected in the range Doppler (RD) domain by traditional frequency domain algorithms. To solve this problem, a modified frequency domain algorithm based on optimal quadratic factor compensation, including phase and envelope compensation, is proposed in this paper. First, the quadratic factor compensation in the two-dimensional (2-D) time domain is introduced to expand the folded azimuth spectrum and transform the nonlinear frequency versus time relationship into a linear relationship. Moreover, an analytical method for obtaining the optimal compensation factor is proposed to reduce the variance of the azimuth phase and increase the azimuth size of a well-focused image. Using the proposed algorithm, a 400 km × 200 km (groundrange × azimuth) image is obtained at the orbit position with a zero Doppler rate. The proposed algorithm is also suitable for positions where the Doppler rate is nonzero, and the maximum azimuth size of well-focused images is greater than that of conventional imaging algorithms. Finally, the validity of the proposed algorithm is verified by computer simulations.","Azimuth,
Doppler effect,
Synthetic aperture radar,
Time-frequency analysis,
Earth,
Radar imaging"
Time-Domain Attribute-Based Access Control for Cloud-Based Video Content Sharing: A Cryptographic Approach,"With the ever-increasing demands on multimedia applications, cloud computing, due to its economical but powerful resources, is becoming a natural platform to process, store, and share multimedia contents. However, the employment of cloud computing also brings new security and privacy issues as few public cloud servers can be fully trusted by users. In this paper, we focus on how to securely share video contents to a certain group of people during a particular time period in cloud-based multimedia systems, and propose a cryptographic approach, a provably secure time-domain attribute-based access control (TAAC) scheme, to secure the cloud-based video content sharing. Specifically, we first propose a provably secure time-domain attribute-based encryption scheme by embedding the time into both the ciphertexts and the keys, such that only users who hold sufficient attributes in a specific time slot can decrypt the video contents. We also propose an efficient attribute updating method to achieve the dynamic change of users' attributes, including granting new attributes, revoking previous attributes, and regranting previously revoked attributes. We further discuss on how to control those video contents that can be commonly accessed in multiple time slots and how to make special queries on video contents generated in previous time slots. The security analysis and performance evaluation show that TAAC is provably secure in generic group model and efficient in practice.","Streaming media,
Access control,
Time-domain analysis,
Encryption,
Cloud computing"
Trust-Distortion Resistant Trust Management Frameworks on Mobile Ad Hoc Networks: A Survey,"Trust management is a promising approach to conduct nodes' transactions and establish management interactions in distributed mobile ad hoc networks (MANETs) in which nodes' collaboration is critical to achieve system goals. Lack of centralized management, severe resource constraints (e.g., computing power, energy, and bandwidth), and important network dynamics (e.g., topology changes, node mobility, node failure, and propagation channel conditions) make trust management a challenging task in such a network. Mainly, some trust management basis may be exploited to fulfill new attacks. In this work, we present a holistic view on various trust management frameworks geared for MANETs, capable to handle main existing attacks deceiving trustworthiness computation to mislead trust-based network operations, referred to as trust-distortion attacks. Besides, we propose a taxonomy of main identified trust-distortion attacks based on how the trustworthiness estimation of a node about another node is distorted. Moreover, we provide a holistic classification of main evaluation metrics, which can be used to evaluate and compare such frameworks. For each framework, a unified approach is used to describe the trust model, taking each component required for trust management as a guideline. Moreover, each framework is analyzed regarding its resistance against different trust-distortion attacks, the framework unique features, merits, demerits, and findings. Finally, we compare different trust-distortion resistant frameworks and outline the open issues and future research directions.","Monitoring,
Mobile computing,
Resistance,
Peer-to-peer computing,
Mobile ad hoc networks,
Face"
Leveraged Neighborhood Restructuring in Cultural Algorithms for Solving Real-World Numerical Optimization Problems,"Many researchers have developed population-based techniques to solve numerical optimization problems. Almost none of these techniques demonstrate consistent performance over a wide range of problems as these problems differ substantially in their characteristics. In the state-of-the-art cultural algorithms (CAs), problem solving is facilitated by the exchange of knowledge between a network of active knowledge sources in the belief space and networks of individuals in the population space. To enhance the performance of CAs, we restructure the social fabric interconnections to facilitate flexible communication among problem solvers in the population space. Several social network reconfiguration mechanisms and types of communications are examined. This extended CA is compared with other variants of CAs and other well-known state-of-the-art algorithms on a set of challenging real-world problems. The numerical results show that the injection of neighborhoods with flexible subnetworks enhances performance on a diverse landscape of numerical optimization problems.",
Electrically Small Folded Dipole Antenna for HF and Low-VHF Bands,"A novel, highly miniaturized, lightweight antenna operating at the low-VHF band is presented. Earlier studies on an extremely short HF monopole antenna consisting of two in-phase vertical elements face an inevitable issue regarding an unbalanced coaxial cable feed due to the very small ground plane . To resolve this problem, as well as to achieve higher bandwidth, we introduce an electrically small folded dipole version of the same antenna having a fully balanced structure. The overall dimension and total mass of the proposed antenna are 10 ×10 ×15 cm3. ( 0.013λ0 ×0.013λ0 ×0.02λ0 at 40 MHz) and 98 g, respectively. The gain and pattern of the fabricated antenna are measured in an elevated range that is in nearly free-space conditions. Measurements are shown to be in good agreement with the design predictions from simulation.","Antenna measurements,
Dipole antennas,
Antenna radiation patterns,
Antenna feeds,
Coils"
Control Strategies of Three-Phase Distributed Generation Inverters for Grid Unbalanced Voltage Compensation,"The high penetration level of power electronics interfaced distributed generation (DG) systems creates great ancillary services potential through the DG interfacing converters, such as the grid unbalanced voltage compensation. However, the unbalanced voltage compensation may cause adverse effects on the DGs' operation, such as output active power oscillation and dc-link voltage variations. Moreover, since the compensation is realized through the available rating of DGs' interfacing converters, it is equally important to consider the effectiveness of control strategy for unbalanced voltage compensation. Considering these challenging issues, two grid unbalanced voltage compensation strategies for three-phase power electronics interfaced DG systems are proposed in this paper. Especially, the first control strategy aims at minimizing the DG's active power oscillation and reducing the adverse effects of unbalanced voltage compensation on DG's operation. The second control strategy focuses on the effectiveness of unbalanced voltage compensation by controlling DG's negative sequence current to be inphase with the grid negative sequence current. Performances of the two proposed control strategies under different grid conditions and DG operating conditions are studied, and recommendations for appropriate control strategy utilization under various conditions are provided. Finally, validity of the proposed strategies is verified by both simulations and experimental results.","Voltage control,
Oscillators,
Reactive power,
Impedance,
Power electronics,
Power quality,
Minimization"
Energy Storage System for a Port Crane Hybrid Power-Train,"Marine networks are experiencing an expanding role in the global transportation of goods and are demanding an increasing energy resource while being a contributor to climate change-related emissions. This paper investigates the potential of hybrid energy source systems (HESS) that employ energy storage devices and peak power devices in a combination that is capable of providing average energy while recovering and managing the electrical power system transients. Moreover, the contribution of the energy storage device, or power buffer, may result in reduced rating for the main energy source, reducing system mass and volume while improving energy conversion efficiency. Crane system power flow is analyzed and energy saving calculated for a representative load cycle. Experimentally validated powertrain models are presented, control strategies developed, and alternative energy/power storage devices in single and HESS configurations analyzed. While many papers discuss similar concepts for road vehicles, the application to port cranes has not been reported previously. Similarly, detailed design encompassing system losses, thermal management, component mass, volume, and system dynamic operation have not been reported previously. This paper develops procedures for the design of battery alone and battery-supercapacitor HESS that are shown to be different and independent of the optimization method chosen.",
Data Collection and Wireless Communication in Internet of Things (IoT) Using Economic Analysis and Pricing Models: A Survey,"This paper provides a state-of-the-art literature review on economic analysis and pricing models for data collection and wireless communication in Internet of Things (IoT). Wireless sensor networks (WSNs) are the main components of IoT which collect data from the environment and transmit the data to the sink nodes. For long service time and low maintenance cost, WSNs require adaptive and robust designs to address many issues, e.g., data collection, topology formation, packet forwarding, resource and power optimization, coverage optimization, efficient task allocation, and security. For these issues, sensors have to make optimal decisions from current capabilities and available strategies to achieve desirable goals. This paper reviews numerous applications of the economic and pricing models, known as intelligent rational decision-making methods, to develop adaptive algorithms and protocols for WSNs. Besides, we survey a variety of pricing strategies in providing incentives for phone users in crowdsensing applications to contribute their sensing data. Furthermore, we consider the use of some pricing models in machine-to-machine (M2M) communication. Finally, we highlight some important open research issues as well as future research directions of applying economic and pricing models to IoT.","Internet of things,
Machine-to-machine communications,
Biological system modeling,
Pricing,
Economics,
Data models,
Wireless sensor networks,
Crowdsensing,
Internet of things"
Bayesian Factorization and Learning for Monaural Source Separation,"This paper presents a new Bayesian nonnegative matrix factorization (NMF) for monaural source separation. Using this approach, the reconstruction error based on NMF is represented by a Poisson distribution, and the NMF parameters, consisting of the basis and weight matrices, are characterized by the exponential priors. A variational Bayesian inference procedure is developed to learn variational parameters and model parameters. The randomness in separation process is faithfully represented so that the system robustness to model variations in heterogeneous environments could be achieved. Importantly, the exponential prior parameters are used to impose sparseness in basis representation. The variational lower bound of log marginal likelihood is adopted as the objective to control model complexity. The dependencies of variational objective on model parameters are fully characterized in the derived closed-form solution. A clustering algorithm is performed to find the groups of bases for unsupervised source separation. The experiments on speech/music separation and singing voice separation show that the proposed Bayesian NMF (BNMF) with adaptive basis representation outperforms the NMF with fixed number of bases and the other BNMFs in terms of signal-to-distortion ratio and the global normalized source to distortion ratio.",
Optimal Throughput for Two-Way Relaying: Energy Harvesting and Energy Co-Operation,"For a two-way relay network (TWRN) with three nodes, we discuss the performance optimization of digital network coding (DNC) and physical network coding (PNC) schemes under the energy harvesting (EH) constraints and peak power constraints. We also consider the energy transfer between nodes, which is referred to as energy co-operation. To find the maximal achievable performance, we first consider the case of offline scheduling, formulate the corresponding optimization problems, find the optimal solutions, as well as present some useful theoretical properties on optimality. Then we move to the online scheduling, and propose both dynamic programming and some intuitive policies to approach the performance of its offline counterpart. Numerical results show that PNC outperforms DNC due to the higher spectrum efficiency and the intrinsic coding gains, under the same conditions. Furthermore, it is observed that if the relay harvests much more energy and shares it with the two source nodes, DNC with energy co-operation scheme has the potential to perform comparable to or even better than PNC without energy co-operation scheme, which validates the importance of energy co-operation in contemporary communication systems.",
Dense and Sparse Reconstruction Error Based Saliency Descriptor,"In this paper, we propose a visual saliency detection algorithm from the perspective of reconstruction error. The image boundaries are first extracted via superpixels as likely cues for background templates, from which dense and sparse appearance models are constructed. First, we compute dense and sparse reconstruction errors on the background templates for each image region. Second, the reconstruction errors are propagated based on the contexts obtained from K-means clustering. Third, the pixel-level reconstruction error is computed by the integration of multi-scale reconstruction errors. Both the pixellevel dense and sparse reconstruction errors are then weighted by image compactness, which could more accurately detect saliency. In addition, we introduce a novel Bayesian integration method to combine saliency maps, which is applied to integrate the two saliency measures based on dense and sparse reconstruction errors. Experimental results show that the proposed algorithm performs favorably against 24 state-of-the-art methods in terms of precision, recall, and F-measure on three public standard salient object detection databases.","Image reconstruction,
Feature extraction,
Image segmentation,
Bayes methods,
Visualization,
Measurement uncertainty,
Image color analysis"
Sum-Rate Maximization for Multiuser MIMO Wireless Powered Communication Networks,"This paper investigates multiuser multiple-input-multiple-output (MIMO) wireless powered communication networks where a multiantenna hybrid access point (H-AP) transfers wireless energy to multiantenna users in a downlink phase, and the users utilize the harvested energy for their information transmission to the H-AP in an uplink phase. By employing space-division multiple-access techniques, we propose an optimal algorithm that jointly computes the downlink energy precoding matrices, the uplink information precoding matrices, and time allocation between the downlink and the uplink phases for maximizing the uplink sum-rate performance. To this end, we first obtain the optimal energy and information transmit covariance matrices with given time allocation. Then, the optimal time allocation can be efficiently identified by a simple line search method. Simulation results verify that the proposed joint optimal algorithm significantly improves the average sum-rate performance, compared with a conventional scheme that determines time allocation and precoding matrices separately.","Covariance matrices,
Uplink,
Downlink,
Resource management,
Wireless communication,
MIMO"
A Cloud-Based Architecture for the Internet of Spectrum Devices Over Future Wireless Networks,"The dramatic increase in data rates in wireless networks has caused radio spectrum usage to be an essential and critical issue. Spectrum sharing is widely recognized as an affordable, near-term method to address this issue. This paper first characterizes the new features of spectrum sharing in future wireless networks, including heterogeneity in sharing bands, diversity in sharing patterns, crowd intelligence in sharing devices, and hyperdensification in sharing networks. Then, to harness the benefits of these unique features and promote a vision of spectrum without bounds and networks without borders, this paper introduces a new concept of the Internet of spectrum devices (IoSDs) and develops a cloud-based architecture for IoSD over future wireless networks, with the prime aim of building a bridging network among various spectrum monitoring devices and massive spectrum utilization devices, and enabling a highly efficient spectrum sharing and management paradigm for future wireless networks. Furthermore, this paper presents a systematic tutorial on the key enabling techniques of the IoSD, including big spectrum data analytics, hierarchal spectrum resource optimization, and quality of experience-oriented spectrum service evaluation. In addition, the unresolved research issues are also presented.",
Fast and Accurate Mining the Community Structure: Integrating Center Locating and Membership Optimization,"Mining communities or clusters in networks is valuable in analyzing, designing, and optimizing many natural and engineering complex systems, e.g., protein networks, power grid, and transportation systems. Most of the existing techniques view the community mining problem as an optimization problem based on a given quality function(e.g., modularity), however none of them are grounded with a systematic theory to identify the central nodes in the network. Moreover, how to reconcile the mining efficiency and the community quality still remains an open problem. In this paper, we attempt to address the above challenges by introducing a novel algorithm. First, a kernel function with a tunable influence factor is proposed to measure the leadership of each node, those nodes with highest local leadership can be viewed as the candidate central nodes. Then, we use a discrete-time dynamical system to describe the dynamical assignment of community membership; and formulate the serval conditions to guarantee the convergence of each node's dynamic trajectory, by which the hierarchical community structure of the network can be revealed. The proposed dynamical system is independent of the quality function used, so could also be applied in other community mining models. Our algorithm is highly efficient: the computational complexity analysis shows that the execution time is nearly linearly dependent on the number of nodes in sparse networks. We finally give demonstrative applications of the algorithm to a set of synthetic benchmark networks and also real-world networks to verify the algorithmic performance.","Heuristic algorithms,
Optimization,
Algorithm design and analysis,
Complex networks,
Proteins,
Kernel,
Trajectory"
Subspace Based Network Community Detection Using Sparse Linear Coding,"Information mining from networks by identifying communities is an important problem across a number of research fields including social science, biology, physics, and medicine. Most existing community detection algorithms are graph theoretic and lack the ability to detect accurate community boundaries if the ratio of intra-community to inter-community links is low. Also, algorithms based on modularity maximization may fail to resolve communities smaller than a specific size if the community size varies significantly. In this paper, we present a fundamentally different community detection algorithm based on the fact that each network community spans a different subspace in the geodesic space. Therefore, each node can only be efficiently represented as a linear combination of nodes spanning the same subspace. To make the process of community detection more robust, we use sparse linear coding with l1 norm constraint. In order to find a community label for each node, sparse spectral clustering algorithm is used. The proposed community detection technique is compared with more than 10 state of the art methods on two benchmark networks (with known clusters) using normalized mutual information criterion. Our proposed algorithm outperformed existing algorithms with a significant margin on both benchmark networks. The proposed algorithm has also shown excellent performance on three real-world networks.",
Traffic engineering in software-defined networking: Measurement and management,"As the next generation network architecture, software-defined networking (SDN) has exciting application prospects. Its core idea is to separate the forwarding layer and control layer of network system, where network operators can program packet forwarding behavior to significantly improve the innovation capability of network applications. Traffic engineering (TE) is an important network application, which studies measurement and management of network traffic, and designs reasonable routing mechanisms to guide network traffic to improve utilization of network resources, and better meet requirements of the network quality of service (QoS). Compared with the traditional networks, the SDN has many advantages to support TE due to its distinguish characteristics, such as isolation of control and forwarding, global centralized control, and programmability of network behavior. This paper focuses on the traffic engineering technology based on the SDN. First, we propose a reference framework for TE in the SDN, which consists of two parts, traffic measurement and traffic management. Traffic measurement is responsible for monitoring and analyzing real-time network traffic, as a prerequisite for traffic management. In the proposed framework, technologies related to traffic measurement include network parameters measurement, a general measurement framework, and traffic analysis and prediction; technologies related to traffic management include traffic load balancing, QoS-guarantee scheduling, energy-saving scheduling, and traffic management for the hybrid IP/SDN. Current existing technologies are discussed in detail, and our insights into future development of TE in the SDN are offered.","Software defined networks,
Telecommunication traffic,
Telecommunication network management,
Network monitoring,
Quality of service,
Current measurement,
Energy measurement,
Next generatoin networking,
Resource management"
sEMG-Based Identification of Hand Motion Commands Using Wavelet Neural Network Combined With Discrete Wavelet Transform,"Surface electromyogram (sEMG) signals can be applied in medical, rehabilitation, robotic, and industrial fields. As a typical application, a myoelectric prosthetic hand is controlled by the sEMG signals of the amputee's residual muscles. To improve the dexterity of the myoelectric prosthetic hand, additional hand motion commands need to be classified. The more sEMG sensors are used, the more hand motion commands can be classified. However, the amputee's residual muscles are limited. In order to improve the practicability of the myoelectric prosthetic hand, it is critical to investigate the effective pattern recognition algorithms to deal with the sEMG signals detected by fewer sensors, while identifying as many hand motion commands as possible. Current pattern recognition algorithms for sEMG signals are challenged by limited recognition patterns and unsteady classification accuracy rates. To solve these dilemmas, we employed discrete wavelet transform (DWT) and wavelet neural network (WNN) algorithms to improve the pattern recognition effects of sEMG signals. In addition, the back propagation and gradient descent algorithms were utilized to train WNN. In this work, we only used three sEMG sensors to classify and recognize six kinds of hand motion commands. The maximum identification accuracy rate is 100%, and an average classification accuracy rate of the proposed WNN is 94.67%, which is substantially better than the artificial neural network (ANN) algorithm.","Sensors,
Feature extraction,
Discrete wavelet transforms,
Accuracy,
Prosthetic hand,
Muscles,
Wrist"
VLSI Implementation of Fully Parallel LTE Turbo Decoders,"Turbo codes facilitate near-capacity transmission throughputs by achieving a reliable iterative forward error correction. However, owing to the serial data dependence imposed by the logarithmic Bahl-Cocke-Jelinek-Raviv algorithm, the limited processing throughputs of the conventional turbo decoder implementations impose a severe bottleneck upon the overall throughputs of real-time communication schemes. Motivated by this, we recently proposed a floating-point fully parallel turbo decoder (FPTD) algorithm, which eliminates the serial data dependence, allowing parallel processing and hence significantly reducing the number of clock cycles required. In this paper, we conceive a technique for reducing the critical datapath of the FPTD, and we propose a novel fixed-point version as well as its very large scale integration (VLSI) implementation. We also propose a novel technique, which allows the FPTD to also decode shorter frames employing compatible interleaver patterns. We strike beneficial tradeoffs amongst the latency, core area, and energy consumption by investigating the minimum bit widths and techniques for message log-likelihood ratio scaling and state metric normalization. Accordingly, the design flow and design tradeoffs considered in this paper are also applicable to other fixed-point implementations of error correction decoders. We demonstrate that upon using Taiwan Semiconductor Manufacturing Company (TSMC) 65-nm low-power technology for decoding the longest long-term evolution frames (6144 b) received over an additive white Gaussian noise channel having Eb/N0 = 1 dB, the proposed fixed-point FPTD VLSI achieves a processing throughput of 21.9 Gb/s and a processing latency of 0.28 μs. These results are 17.1 times superior to those of the state-of-the-art benchmarker. Furthermore, the proposed fixed-point FPTD VLSI achieves an energy consumption of 2.69 μJ/frame and a normalized core area of 5 mm2/Gb/s, which are 34% and 23% lower than those of the benchmarker, respectively.","Decoding,
Throughput,
Very large scale integration,
Hardware,
Error correction,
Algorithm design and analysis,
Benchmark testing"
Delay Minimization for Data Dissemination in Large-Scale VANETs with Buses and Taxis,"Minimizing the end-to-end delay for data dissemination in a large-scale VANET with both buses of fixed schedules and taxis of random schedules is a challenging issue, due to the scalability, high-mobility, and network heterogeneity concerns. Particularly, the mix of random taxis and fixed-scheduled buses makes the delay components along a path dependent and hard to estimate. In this paper, to address the scalability and high-mobility issues, we introduce a store-and-forward framework for VANETs with extra storage using “drop boxes”, which function similar to network routers. Next, we propose an optimal link strategy which is independent of the message arrival time and can be executed in a distributed manner. Then, we derive the expected path delay, considering the dependence of the delay components along the path, and propose the optimal routing strategy to minimize the expected path delay. Trace-driven simulations have been used to validate the rigorous analysis, and demonstrate the superior performance of the proposed strategies, which result in a substantial delay reduction and a much higher delivery ratio when compared with the state-of-the-art solutions without drop boxes. The strategies can further improve the delay performance when compared with the over-simplified routing solutions which ignore the dependence of the delay components.","Delays,
Vehicles,
Public transportation,
Routing,
Vehicular ad hoc networks,
Scalability,
Schedules"
Connected Component Model for Multi-Object Tracking,"In multi-object tracking, it is critical to explore the data associations by exploiting the temporal information from a sequence of frames rather than the information from the adjacent two frames. Since straightforwardly obtaining data associations from multi-frames is an NP-hard multi-dimensional assignment (MDA) problem, most existing methods solve this MDA problem by either developing complicated approximate algorithms, or simplifying MDA as a 2D assignment problem based upon the information extracted only from adjacent frames. In this paper, we show that the relation between associations of two observations is the equivalence relation in the data association problem, based on the spatial–temporal constraint that the trajectories of different objects must be disjoint. Therefore, the MDA problem can be equivalently divided into independent subproblems by equivalence partitioning. In contrast to existing works for solving the MDA problem, we develop a connected component model (CCM) by exploiting the constraints of the data association and the equivalence relation on the constraints. Based upon CCM, we can efficiently obtain the global solution of the MDA problem for multi-object tracking by optimizing a sequence of independent data association subproblems. Experiments on challenging public data sets demonstrate that our algorithm outperforms the state-of-the-art approaches.",
CPS Oriented Control Design for Networked Surveillance Robots With Multiple Physical Constraints,"Networked robotics are a typical cyber-physical system (CPS). This paper presents the cyber physical interaction model to perform formation control and tracking in the presence of other robots and static obstacles. It discusses how such a model can be effectively utilized to deal with kinodynamic and operation range constraints. The cyber system is also responsible for feasible trajectory generation based upon regional path segments and to ensure that all the robots maneuver through obstacles in a safe manner. The introduction of virtual robot restructures the formation control problem into a tracking control problem between virtual reference robot and follower robots. A novel obstacle avoidance approach is proposed based upon the scaling of whole (partial) formation corresponding to centralized (distributed) framework. The involved CPS has network structure preserving properties that are key to effective distributed decision making. The novel formation control, obstacle avoidance, and trajectory tracking approaches facilitate networked robots to be effectively controlled through the cyber system. We also discuss efficient and optimal implementation of the proposed trajectory generator using computer-aided design for CPSs. Evaluation of the proposed approach is provided that demonstrate the formation control, trajectory tracking, and obstacle avoidance for multirobots using the proposed scheme.","Trajectory,
Collision avoidance,
Robot kinematics,
Robot sensing systems,
Symmetric matrices,
Integrated circuit modeling"
F2C: Enabling Fair and Fine-Grained Resource Sharing in Multi-Tenant IaaS Clouds,"This paper presents F2C, a cooperative resource management system for Infrastructure-as-a-Service (IaaS) clouds. Inspired by group-buying mechanisms in real product and service markets, F2C advocates a group of cloud tenants (called tenant coalition) to buy resource capacity in bulk and share the resource pool in the form of virtual machines (VMs). Tenant coalitions leads to vast opportunities for fine-grained resource sharing among multiple tenants. However, resource sharing, especially for multiple resource types, poses several challenging problems in pay-as-you-use cloud environments, such as sharing incentive, free-riding, lying and economic fairness. To address those problems, we propose Reciprocal Resource Fairness (RRF) , a novel resource allocation mechanism to enable fair sharing on multiple resource types within a tenant coalition. RRF is implemented in two complementary and hierarchical mechanisms: inter-tenant resource trading and intra-tenant weight adjustment. RRF satisfies several highly desirable properties to ensure fairness. We implement F2C in Xen platform. The experimental results show F2C is promising for both cloud providers and tenants. For cloud providers, F2C improves VM density and cloud providers' revenue by 2.2X compared to the current IaaS cloud models. For tenants, F2C improves application performance by 45 percent and guarantees 95 percent economic fairness among multiple tenants.","Resource management,
Cloud computing,
Indexes,
Biological system modeling,
Random access memory,
Economics,
Memory management"
Where does AlphaGo go: from church-turing thesis to AlphaGo thesis and beyond,"An investigation on the impact and significance of the AlphaGo vs. Lee Sedol Go match is conducted, and concludes with a conjecture of the AlphaGo Thesis and its extension in accordance with the Church-Turing Thesis in the history of computing. It is postulated that the architecture and method utilized by the AlphaGo program provide an engineering solution for tackling issues in complexity and intelligence. Specifically, the AlphaGo Thesis implies that any effective procedure for hard decision problems such as NP-hard can be implemented with AlphaGo-like approach. Deep rule-based networks are proposed in attempt to establish an understandable structure for deep neural networks in deep learning. The success of AlphaGo and corresponding thesis ensure the technical soundness of the parallel intelligence approach for intelligent control and management of complex systems and knowledge automation.","Complexity theory,
Games,
Neural networks,
Computers,
Machine learning,
Decision making"
Explicit Path Control in Commodity Data Centers: Design and Applications,"Many data center network (DCN) applications require explicit routing path control over the underlying topologies. In this paper, we present XPath, a simple, practical and readily-deployable way to implement explicit path control, using existing commodity switches. At its core, XPath explicitly identifies an end-to-end path with a path ID and leverages a two-step compression algorithm to pre-install all the desired paths into IP TCAM tables of commodity switches. Our evaluation and implementation show that XPath scales to large DCNs and is readily-deployable. Furthermore, on our testbed, we integrate XPath into four applications to showcase its utility.","Routing,
IP networks,
Bandwidth,
Ports (Computers),
Topology,
Servers,
Network topology"
Methodology for 3-D Substrate Network Extraction for SPICE Simulation of Parasitic Currents in Smart Power ICs,"A 3-D simulation of substrate currents is crucial to analyze parasitic coupling effects due to minority carrier injection in smart power ICs. In this paper, a substrate parasitic extraction methodology is introduced by dividing the IC layout into elementary elements to solve the continuity equation for minority carriers in the volume based on the finite-difference method. A substrate parasitic network is derived from the mesh generated through the existing mixed-signal design flow. The induced substrate model is included in circuit simulators such as SPICE to predict the effects of substrate couplings during the design phase. Furthermore, this analysis enables optimization of layout with minimal parasitic effects. By linking the substrate model to the active components, the couplings between the integrated circuit with the substrate parasitic currents can be analyzed during circuit simulations. Simulations and measurements on an high voltage driver reveal consistent results and therefore confirm the validity of the method. Therefore, the approach developed herein is effective to predict parasitic couplings due the injection of minority carriers.","Substrates,
Integrated circuit modeling,
Layout,
Couplings,
Solid modeling,
Automotive engineering"
Statistical Multiplexing Gain Analysis of Heterogeneous Virtual Base Station Pools in Cloud Radio Access Networks,"Cloud radio access network (C-RAN) was proposed recently to reduce network cost, enable cooperative communications, and increase system flexibility through centralized baseband processing. By pooling multiple virtual base stations (VBSs) and consolidating their stochastic computational tasks, the overall computational resource can be reduced, achieving the so-called statistical multiplexing gain. In this paper, we evaluate the statistical multiplexing gain of VBS pools using a multi-dimensional Markov model, which captures the session-level dynamics and the constraints imposed by both radio and computational resources. Based on this model, we derive a recursive formula for the blocking probability and also a closed-form approximation for it in large pools. These formulas are then used to derive the session-level statistical multiplexing gain of both real-time and delay-tolerant traffic. Numerical results show that VBS pools can achieve more than 75% of the maximum pooling gain with 50 VBSs, but further convergence to the upper bound (large-pool limit) is slow because of the quickly diminishing marginal pooling gain, which is inversely proportional to a factor between the one-half and three-fourth power of the pool size. We also find that the pooling gain is more evident under light traffic load and stringent quality of service requirement.","Computational modeling,
Multiplexing,
Numerical models,
Quality of service,
Computer architecture,
Wireless communication,
Base stations"
Compressed CSI Acquisition in FDD Massive MIMO: How Much Training is Needed?,"Massive multiple-input-multiple-output (MIMO) is a promising technique for providing unprecedented spectral efficiency. However, it has been well recognized that the excessive training overhead required for obtaining the channel side information is a major handicap in frequency-division duplexing (FDD) massive MIMO. Several attempts have been made to reduce this training overhead by exploiting the sparsity structures of massive MIMO channels. So far, however, there has been little discussion about how to exploit the partial support information of these channels to achieve further overhead reductions. Such information, which is a set of indices of the significant elements of a channel vector, can be acquired in advance and hence is an important option to explore. In this paper, we examine the impact on the required training overhead when this information is applied within a weighted ℓ1 minimization framework, and analytically show that a sharp estimate of the reduced overhead size can be successfully obtained. Furthermore, we examine how the accuracy of the partial support information impacts the achievable overhead reduction. Numerical results for a wide range of sparsity and partial support information reliability levels are presented to quantify our findings and main conclusions.","Training,
MIMO,
Channel estimation,
Minimization,
Antennas,
Antenna measurements,
Compressed sensing"
Towards Information Diffusion in Mobile Social Networks,"The emerging of mobile social networks opens opportunities for viral marketing. However, before fully utilizing mobile social networks as a platform for viral marketing, many challenges have to be addressed. In this paper, we address the problem of identifying a small number of individuals through whom the information can be diffused to the network as soon as possible, referred to as the diffusion minimization problem. Diffusion minimization under the probabilistic diffusion model can be formulated as an asymmetric k
-center problem which is NP-hard, and the best known approximation algorithm for the asymmetric k
-center problem has approximation ratio of \log ^*n
and time complexity O(n^5)
. Clearly, the performance and the time complexity of the approximation algorithm are not satisfiable in large-scale mobile social networks. To deal with this problem, we propose a community based algorithm and a distributed set-cover algorithm. The performance of the proposed algorithms is evaluated by extensive experiments on both synthetic networks and a real trace. The results show that the community based algorithm has the best performance in both synthetic networks and the real trace compared to existing algorithms, and the distributed set-cover algorithm outperforms the approximation algorithm in the real trace in terms of diffusion time.","Communities,
Social network services,
Mobile computing,
Mobile communication,
Approximation algorithms,
Algorithm design and analysis,
Approximation methods"
Caching and delivery via interference elimination,"We propose a new caching scheme where linear combinations of the file segments are cached at the users, for the scenarios where the number of files is no greater than the number of users. When a user requests a certain file in the delivery phase, the other file segments in the cached linear combinations can be viewed as interferences. The proposed scheme combines rank metric codes and maximum distance separable codes to facilitate the decoding and elimination of these interferences, and also to simultaneously deliver useful contents to the intended users. The performance of the proposed scheme can be explicitly evaluated, and we show that the new scheme can strictly improve existing tradeoff inner bounds in the literature; for certain cases, the new tradeoff points are in fact optimal.","Measurement,
Encoding,
Servers,
Systematics,
Interference elimination"
Low-Complexity Algorithms for Low Rank Clutter Parameters Estimation in Radar Systems,"This paper addresses the problem of the clutter subspace projector estimation in the context of a disturbance composed of a low rank heterogeneous (Compound Gaussian) clutter and white Gaussian noise. In such a context, adaptive processing based on an estimated orthogonal projector onto the clutter subspace (instead of an estimated covariance matrix) requires less samples than classical methods. The clutter subspace estimate is usually derived from the eigenvalue decomposition of a covariance matrix estimate. However, it has been previously shown that a direct maximum likelihood estimator of the clutter subspace projector can be obtained for the considered context. In this paper, we derive two algorithms based on the block majorization-minimization framework to reach this estimator. These algorithms are shown to be computationally faster than the state of the art, with guaranteed convergence. Finally, the performance of the related estimators is illustrated on realistic Space Time Adaptive Processing for airborne radar simulations.","Clutter,
Compounds,
Covariance matrices,
Maximum likelihood estimation,
Signal processing algorithms,
Eigenvalues and eigenfunctions"
An Efficient Algorithm for Optimally Solving a Shortest Vector Problem in Compute-and-Forward Design,"We consider the problem of finding the optimal coefficient vector that maximizes the computation rate at a relay in the compute-and-forward scheme. Based on the idea of sphere decoding, we propose a highly efficient algorithm that finds the optimal coefficient vector. First, we derive a novel algorithm to transform the original quadratic form optimization problem into a shortest vector problem (SVP) using the Cholesky factorization. Instead of computing the Cholesky factor explicitly, the proposed algorithm realizes the Cholesky factorization with only O(n) flops by taking advantage of the structure of the Gram matrix in the quadratic form. Then, we propose some conditions that can be checked with O(n) flops, under which a unit vector is the optimal coefficient vector. Finally, by considering some useful properties of the optimal coefficient vector, we modify the Schnorr-Euchner search algorithm to solve the SVP. We show that the estimated average complexity of our new algorithm is O(n1.5p0.5) flops for independent identically distributed (i.i.d.) Gaussian channel entries with SNR P based on the Gaussian heuristic. Simulations show that our algorithm is not only much more efficient than the existing ones that give the optimal solution, but also faster than some best known suboptimal methods. Besides, we show that our algorithm can be readily adapted to output a list of L best candidate vectors for use in the compute-and-forward design. The estimated average complexity of the resultant list-output algorithm is O(n2.5p0.5 + n1.5p0.5 log(L) + nL) flops for i.i.d. Gaussian channel entries.","Relays,
Algorithm design and analysis,
Complexity theory,
Wireless communication,
Optimization,
Signal to noise ratio,
Transforms"
Graph Regularized Feature Selection with Data Reconstruction,"Feature selection is a challenging problem for high dimensional data processing, which arises in many real applications such as data mining, information retrieval, and pattern recognition. In this paper, we study the problem of unsupervised feature selection. The problem is challenging due to the lack of label information to guide feature selection. We formulate the problem of unsupervised feature selection from the viewpoint of graph regularized data reconstruction. The underlying idea is that the selected features not only preserve the local structure of the original data space via graph regularization, but also approximately reconstruct each data point via linear combination. Therefore, the graph regularized data reconstruction error becomes a natural criterion for measuring the quality of the selected features. By minimizing the reconstruction error, we are able to select the features that best preserve both the similarity and discriminant information in the original data. We then develop an efficient gradient algorithm to solve the corresponding optimization problem. We evaluate the performance of our proposed algorithm on text clustering. The extensive experiments demonstrate the effectiveness of our proposed approach.",
Hypergraph-Regularized Sparse NMF for Hyperspectral Unmixing,"Hyperspectral image (HSI) unmixing has attracted increasing research interests in recent decades. The major difficulty of it lies in that the endmembers and the associated abundances need to be separated from highly mixed observation data with few a priori information. Recently, sparsity-constrained nonnegative matrix factorization (NMF) algorithms have been proved effective for hyperspectral unmixing (HU) since they can sufficiently utilize the sparsity property of HSIs. In order to improve the performance of NMF-based unmixing approaches, spectral and spatial constrains have been added into the unmixing model, but spectral-spatial joint structure is required to be more accurately estimated. To exploit the property that similar pixels within a small spatial neighborhood have higher possibility to share similar abundances, hypergraph structure is employed to capture the similarity relationship among the spatial nearby pixels. In the construction of a hypergraph, each pixel is taken as a vertex of the hypergraph, and each vertex with its k nearest spatial neighboring pixels form a hyperedge. Using the hypergraph, the pixels with similar abundances can be accurately found, which enables the unmixing algorithm to obtain promising results. Experiments on synthetic data and real HSIs are conducted to investigate the performance of the proposed algorithm. The superiority of the proposed algorithm is demonstrated by comparing it with some state-of-the-art methods.","Hyperspectral imaging,
Computer science,
Hypergraph learning,
Sparse matrices"
A Fully Integrated Wireless Compressed Sensing Neural Signal Acquisition System for Chronic Recording and Brain Machine Interface,"Reliable, multi-channel neural recording is critical to the neuroscience research and clinical treatment. However, most hardware development of fully integrated, multi-channel wireless neural recorders to-date, is still in the proof-of-concept stage. To be ready for practical use, the trade-offs between performance, power consumption, device size, robustness, and compatibility need to be carefully taken into account. This paper presents an optimized wireless compressed sensing neural signal recording system. The system takes advantages of both custom integrated circuits and universal compatible wireless solutions. The proposed system includes an implantable wireless system-on-chip (SoC) and an external wireless relay. The SoC integrates 16-channel low-noise neural amplifiers, programmable filters and gain stages, a SAR ADC, a real-time compressed sensing module, and a near field wireless power and data transmission link. The external relay integrates a 32 bit low-power microcontroller with Bluetooth 4.0 wireless module, a programming interface, and an inductive charging unit. The SoC achieves high signal recording quality with minimized power consumption, while reducing the risk of infection from through-skin connectors. The external relay maximizes the compatibility and programmability. The proposed compressed sensing module is highly configurable, featuring a SNDR of 9.78 dB with a compression ratio of 8×. The SoC has been fabricated in a 180 nm standard CMOS technology, occupying 2.1 mm × 0.6 mm silicon area. A pre-implantable system has been assembled to demonstrate the proposed paradigm. The developed system has been successfully used for long-term wireless neural recording in freely behaving rhesus monkey.","bioelectric potentials,
biomedical telemetry,
Bluetooth,
brain-computer interfaces,
compressed sensing,
lab-on-a-chip,
low noise amplifiers,
medical signal detection,
medical signal processing,
neurophysiology,
skin,
telemedicine"
Photovoltaic Inverter Controllers Seeking AC Optimal Power Flow Solutions,"This paper considers future distribution networks featuring inverter-interfaced photovoltaic (PV) systems, and addresses the synthesis of feedback controllers that seek real- and reactive-power inverter setpoints corresponding to AC optimal power flow (OPF) solutions. The objective is to bridge the temporal gap between long-term system optimization and real-time inverter control, and enable seamless PV-owner participation without compromising system efficiency and stability. The design of the controllers is grounded on a dual ε-subgradient method, while semidefinite programming relaxations are advocated to bypass the non-convexity of AC OPF formulations. Global convergence of inverter output powers is analytically established for diminishing stepsize rules for cases where: i) computational limits dictate asynchronous updates of the controller signals, and ii) inverter reference inputs may be updated at a faster rate than the power-output settling time.","Inverters,
Reactive power,
Steady-state,
Optimization,
Adaptive control,
Photovoltaic systems"
A Study on the Programming Structures for RRAM-Based FPGA Architectures,"Field Programmable Gate Arrays (FPGAs) can benefit non-volatility and high-performance by exploiting Resistive Random Access Memories (RRAMs). In RRAM-based FPGAs, the memories do not only replace the SRAMs and store configurations, but they can also replace the transmission gates and propagate datapath signals. The high-performance achievable by RRAM-based FPGAs comes from the fact that the on-resistance of the memory devices RLRS is smaller than the equivalent resistance of a transmission gate. Efficient programming structures for RRAMs should provide high current density with a small area footprint, to obtain a low RLRS. In this paper, we first examine the efficiency of the widely-used 2Transistor/1RRAM (2T1R) programming structure and identify four major limitations of the 2T1R structure. To overcome these limitations, we propose a 2Transmission-Gates/1RRAM (2TG1R) and a 4Transistor/ 1RRAM (4T1R) programming structures. We perform both theoretical analysis and electrical simulations on the evaluated programming structures. 4T1R programming structure is the best in terms of current density with 1.4 x and 1.1 x as compared to 2T1R and 2TG1R counterparts, respectively. We also investigate the effect of boosting the programming voltage Vprog of the programming structures. Experimental results show that boosting Vprog for all the programming structures improves driving current of the evaluated programming structures by 3 x and area efficiency by 1.7 x on average.","Programming,
Field programmable gate arrays,
Switches,
Logic gates,
Transistors,
Computer architecture,
Metals"
Online Energy Harvesting Prediction in Environmentally Powered Wireless Sensor Networks,"The increasing popularity of micro-scale power-scavenging techniques for wireless sensor networks (WSNs) is paving the way to energy-autonomous sensing systems. To sustain perpetual operations, however, environmentally powered devices must adapt their workload to the stochastic nature of ambient sources. Energy prediction models, which estimate the future expected energy intake, are effective tools to support the development of proactive power management strategies. In this paper, we present profile energy prediction model (Pro-Energy), an energy prediction model for multi-source energy-harvesting WSNs that leverages past energy observations to forecast future energy availability. We then propose Pro-Energy with variable-length timeslots (Pro-Energy-VLT), an extension of Pro-Energy that combines our energy predictor with timeslots of variable lengths to adapt to the dynamics of the power source. To assess the performance of our proposed solutions, we use real-life solar and wind traces, as well as publicly available traces of solar irradiance and wind speed. A comparative performance evaluation shows that Pro-Energy significantly outperforms the state-of-the-art energy predictors, by improving the prediction accuracy of up to 67%. Moreover, by adapting the granularity of the prediction timeslots to the dynamics of the energy source, Pro-Energy-VLT further improves the prediction accuracy, while reducing the memory footprint and the energy overhead of energy forecasting.","Wireless sensor networks,
Predictive models,
Sensors,
Adaptation models,
Wind forecasting,
Forecasting"
RF Modeling of FDSOI Transistors Using Industry Standard BSIM-IMG Model,"In this paper, RF modeling and step-by-step parameter extraction methodology of the BSIM-IMG model are discussed with experimental data. BSIM-IMG is the latest industry standard surface potential based model for fully depleted silicon-on-insulator (FDSOI) transistors. The impact of gate, substrate, and thermal networks is demonstrated with S-parameter data, which enable the BSIM-IMG model to capture RF behavior of the FDSOI transistor. The model is validated over a wide range of biases and frequencies and excellent agreement with the experimental data is obtained.","Substrates,
Logic gates,
Radio frequency,
Data models,
Transistors,
Resistance,
Capacitance"
Discrete Wavelet Transform-Based Feature Extraction of Experimental Voltage Signal for Li-Ion Cell Consistency,"The difference in electrochemical characteristics among Li-ion cells in the battery pack inevitably result in voltage and state-of-charge (SOC) imbalances caused by cell-to-cell variation. Therefore, in this approach, with lower requirements of active and passive balancing circuits, a novel approach based on the discrete wavelet transform (DWT) that are well suitable for analyzing and evaluating an experimental charging/discharging voltage signal (ECDVS) is newly introduced to minimize the aforementioned problem. The ECDVS can be applied as source data in the DWT-based analysis because of its great ability to extract variable information of electrochemical characteristics from the nonstationary and transient phenomena simultaneously in both the time and frequency domains. By using the wavelet decomposition implementing the multiresolution analysis (MRA), it is possible to discriminate Li-ion cells that have similar electrochemical characteristics corresponding to information extracted from the ECDVS over wide frequency ranges. Consequently, experimental results showed the clearness of the proposed DWT-based approach for cell discrimination very well.",
Intelligent Traffic Light Controlling Algorithms Using Vehicular Networks,"In this paper, we propose an intelligent traffic light controlling (ITLC) algorithm. ITLC is intended to schedule the phases of each isolated traffic light efficiently. This algorithm considers the real-time traffic characteristics of the competing traffic flows at the signalized road intersection. Moreover, we have adopted the ITLC algorithm to design a traffic scheduling algorithm for an arterial street scenario; we have thus proposed an arterial traffic light (ATL) controlling algorithm. In the ATL controlling algorithm, the intelligent traffic lights installed at each road intersection coordinate with each other to generate an efficient traffic schedule for the entire road network. We report on the performance of ITLC and ATL algorithms for several scenarios using NS-2. From the experimental results, we infer that the ITLC algorithm reduces, at each isolated traffic light, the queuing delay and increases the traffic fluency by 30% compared with the online algorithm (OAF) traffic light scheduling algorithm. The latter algorithm achieved the best performance when compared with the OAF traffic light scheduling algorithm. On the other hand, the ATL controlling algorithm increases the traffic fluency of traveling vehicles at arterial street coordinations by 70% more than the random and separate traffic light scheduling system. Furthermore, compared with the previously introduced traffic scheduling ART-SYS, the ATL controlling algorithm decreases the average delay at each traffic light by 10%.","Roads,
Vehicles,
Schedules,
Algorithm design and analysis,
Timing,
Real-time systems,
Scheduling algorithms"
Hierarchical Decomposition Based Consensus Tracking for Uncertain Interconnected Systems via Distributed Adaptive Output Feedback Control,"In this note, distributed adaptive controllers are developed for output consensus tracking of multiple linear systems with unknown parameters, uncertain subsystem interconnections and external disturbances. The subsystems are allowed to have non-identical dynamics and the same yet arbitrary order. It is assumed that only part of subsystems can have direct access to the time-varying trajectory information and the subsystem states are unmeasurable for local feedback control. In our design, the directed graph representing the information transmission status among subsystems is preprocessed by splitting it into a hierarchical structure. Then local adaptive controllers of subsystems in different layers can be computed in a sequential order and the difficulty on deriving mutually dependent local controls in previous consensus works are successfully overcome. In each subsystem, additional estimates are introduced to account for the unknown parameters and states in its neighbors' dynamics. Besides, only the information of local outputs and inputs need be collected from the neighboring subsystems. Certain robust terms are added in distributed adaptive laws to mitigate the effects of uncertain subsystem interactions and disturbances. It is proved that with our scheme, all closed-loop signals can be ensured bounded when the strengths of uncertain subsystem interconnections are sufficiently weak. The tracking errors for the entire group of subsystems will converge to a compact set and the transient tracking error performance can be adjusted by appropriately choosing design parameters.","Information processing,
Trajectory,
Power system dynamics,
Adaptive control,
Algorithm design and analysis,
Couplings,
Output feedback"
Robust Ensemble Clustering Using Probability Trajectories,"Although many successful ensemble clustering approaches have been developed in recent years, there are still two limitations to most of the existing approaches. First, they mostly overlook the issue of uncertain links, which may mislead the overall consensus process. Second, they generally lack the ability to incorporate global information to refine the local links. To address these two limitations, in this paper, we propose a novel ensemble clustering approach based on sparse graph representation and probability trajectory analysis. In particular, we present the elite neighbor selection strategy to identify the uncertain links by locally adaptive thresholds and build a sparse graph with a small number of probably reliable links. We argue that a small number of probably reliable links can lead to significantly better consensus results than using all graph links regardless of their reliability. The random walk process driven by a new transition probability matrix is utilized to explore the global information in the graph. We derive a novel and dense similarity measure from the sparse graph by analyzing the probability trajectories of the random walkers, based on which two consensus functions are further proposed. Experimental results on multiple real-world datasets demonstrate the effectiveness and efficiency of our approach.","Trajectory,
Robustness,
Sparse matrices,
Sun,
Information science,
Accuracy"
A Port and Frequency Reconfigurable MIMO Slot Antenna for WLAN Applications,"A novel compact four-port reconfigurable multiple-input multiple-output (MIMO) antenna design for IEEE 802.11 applications is proposed. In one configuration, the antenna provides four ports operating from 4.9 to 5.725 GHz with isolation between antennas greater than 14 dB. In the second configuration, it provides a two-port antenna operating at 2.4-2.5 GHz together with another two-port antenna operating at 4.9-5.725 GHz all with isolations greater than 18 dB. The structure consists of four-slot antennas, and two of the slots are made reconfigurable by including MEMS switches in the slots. The overall antenna size is compact and occupies 46×20×1.6 mm3 and is printed on FR-4 printed-circuit-board. The proposed antenna is investigated by simulation and measurement, and results include radiation patterns, S-parameters, and signal correlations and branch power ratio (BPR) between ports. These show that in typical wireless environments' envelope, cross correlations of less than 0.2 between the ports are obtained. The effect of the RF MEMS switches on the antenna performance is also addressed.","Slot antennas,
MIMO,
Ports (Computers),
Wireless LAN,
Microswitches,
Radio frequency"
Virtual Resource Allocation in Software-Defined Information-Centric Cellular Networks With Device-to-Device Communications and Imperfect CSI,"In this paper, we propose an architecture of software-defined information-centric network virtualization with device-to-device (D2D) communications, which facilitates dynamic virtual resource allocation and content caching via a software-defined networking (SDN) controller with a global view of the system. In our proposed framework, substrate physical resources can be virtualized and shared among multiple mobile virtual network operators (MVNOs). Meanwhile, by means of integrating D2D communications into information-centric wireless networks, content caching is enabled not only in the air but in mobile devices as well. In addition, taking into consideration inaccurate channel estimation and measurement, we formulate the virtual resource allocation and caching optimization as a discrete stochastic optimization problem in which imperfect channel state information is incorporated. Because the formulated virtual resource allocation problem is a large-scale combinational optimization problem, we exploit discrete stochastic approximation approaches to cope with it. Finally, extensive simulations are conducted to demonstrate the effectiveness of the proposed scheme with different system parameters. Simulation results show that MVNOs can benefit from not only the sharing of physical infrastructure but from the caching functionality that exists in both the air and mobile devices as well.","Virtualization,
Resource management,
Mobile handsets,
Wireless networks,
Protocols,
Computer architecture,
Vehicle dynamics"
Stabilization of Cascaded DC/DC Converters via Adaptive Series-Virtual-Impedance Control of the Load Converter,"It has been shown recently that a cascaded dc/dc converter system can be stabilized via amplitude compensation (SAC) or phase compensation (SPC) for the input impedance of the load converter. In this letter, it is shown that the cascaded system when adopting the SAC is unconditionally stable but conditionally stable when adopting the SPC, that is, SAC is more stable than SPC. Then, the comparison is carried out for the parallel-virtual-impedance (PVI) and series-virtual-impedance (SVI) control strategies that are adopted to implement the SAC, and it is found that only the SVI control strategy can achieve the SAC for the whole load and input voltage range of the load converter without limitation. Therefore, SVI is in general better than PVI when realizing SAC. Following on this, an adaptive mechanism is introduced to improve the traditional SVI control strategy so that the load converter can be stably connected to different source converters such as LC input filters and traditional dc/dc converters. Finally, a load converter cascaded with three different source converters is fabricated to validate the effectiveness of the proposed adaptive SVI control strategy.","Impedance,
Voltage control,
Adaptive systems,
Frequency conversion,
Shape,
Feedback control"
Routing and Spectrum Assignment in Elastic Filterless Optical Networks,"Elastic optical networking is considered a promising candidate to improve the spectral efficiency of optical networks. One of the most important planning challenges of elastic optical networks is the NP-hard routing and spectrum assignment (RSA) problem. In this paper, we investigate offline RSA in elastic filterless optical networks, which use a passive broadcast-and-select architecture to offer network agility. Here, an elastic optical network is referred to as the optical network that can adapt the channel bandwidth, data rate, and transmission format for each traffic demand in order to offer maximum throughput. In elastic filterless networks, the presence of unfiltered signals resulting from the drop-and-continue node architecture must be considered as an additional constraint in the RSA problem. In this paper, first, the RSA problem in elastic filterless networks is formulated by using an integer linear program to obtain optimal solutions for small networks. Due to the problem complexity, two efficient RSA heuristics are also proposed to achieve suboptimal solutions for larger networks in reasonable time. Simulation results show that significant bandwidth savings in elastic filterless networks can be achieved compared with the fixed-grid filterless solutions. The proposed approach is further tested in multi-period traffic scenarios and combined with periodical spectrum defragmentation, leading to additional improvement in spectrum utilization of elastic filterless optical networks.",
A Novel Grain-Oriented Lamination Rotor Core Assembly for a Synchronous Reluctance Traction Motor With a Reduced Torque Ripple Algorithm,"High torque density and low torque ripple are crucial for traction applications, which allow electrified powertrains to perform properly during start-up, acceleration, and cruising. High-quality anisotropic magnetic materials such as cold-rolled grain-oriented electrical steels can be used for achieving higher efficiency, torque density, and compactness in synchronous reluctance motors equipped with transverse laminated rotors. However, the rotor cylindrical geometry makes utilization of these materials with pole numbers higher than two more difficult. From a reduced torque ripple viewpoint, particular attention to the rotor slot pitch angle design can lead to improvements. This paper presents an innovative rotor lamination design and assembly using cold-rolled grain-oriented electrical steel to achieve higher torque density along with an algorithm for rotor slot pitch angle design for reduced torque ripple. The design methods and prototyping process are discussed, finite-element analyses and experimental examinations are carried out, and the results are compared to verify and validate the proposed methods.","Rotors,
Lamination,
Torque,
Steel,
Magnetic flux,
Magnetic cores,
Geometry"
Crowdlet: Optimal worker recruitment for self-organized mobile crowdsourcing,"In this paper, we advocate Crowdlet, a novel self-organized mobile crowdsourcing paradigm, in which a mobile task requester can proactively exploit a massive crowd of encountered mobile workers at real-time for quick and high-quality results. We present a comprehensive system model of Crowdlet that defines task, worker arrival and worker ability models. Further, we introduce a service quality concept to indicate the expected service gain that a requester can enjoy when he recruits an encountered worker, by jointly taking into account worker ability, real-timeness and task reward. Based on the models, we formulate an online worker recruitment problem to maximize the expected sum of service quality. We derive an optimal worker recruitment policy through the dynamic programming principle, and show that it exhibits a nice threshold based structure. We conduct extensive performance evaluation based on real traces, and numerical results demonstrate that our policy can achieve superior performance and improve more than 30% performance gain over classic policies. Besides, our Android prototype shows that Crowdlet is cost-efficient, requiring less than 7 seconds and 6 Joule in terms of time and energy cost for policy computation in most cases.","Mobile communication,
Crowdsourcing,
Recruitment,
Real-time systems,
Computational modeling,
Exponential distribution"
On Conformal Divergences and Their Population Minimizers,"Total Bregman divergences are a recent tweak of ordinary Bregman divergences originally motivated by applications that required invariance by rotations. They have displayed superior results compared with ordinary Bregman divergences on several clustering, computer vision, medical imaging, and machine learning tasks. These preliminary results raise two important problems. First, report a complete characterization of the left and right population minimizers for this class of total Bregman divergences. Second, characterize a principled superset of total and ordinary Bregman divergences with good clustering properties, from which one could tailor the choice of a divergence to a particular application. In this paper, we provide and study one such superset with interesting geometric features, that we call conformal divergences, and focus on their left and right population minimizers. Our results are obtained in a recently coined (u, v) -geometric structure that is a generalization of the dually flat affine connections in information geometry. We characterize both analytically and geometrically the population minimizers. We prove that conformal divergences (resp. total Bregman divergences) are essentially exhaustive for their left (resp. right) population minimizers. We further report new results and extend previous results on the robustness to outliers of the left and right population minimizers, and discuss the role of the (u, v) -geometric structure in clustering. Additional results are also given.","Sociology,
Statistics,
Information geometry,
Robustness,
Distortion,
Context"
Suspecting Less and Doing Better: New Insights on Palmprint Identification for Faster and More Accurate Matching,"This paper introduces a generalized palmprint identification framework to unify several state-of-art 2D and 3D palmprint methods. Through this framework, we argue that the methods employing one-to-one matching strategy and binary representation for feature are more effective for palmprint identification. The analysis for the first argument is based on a statistical matching model and is supported by outperforming results on several publicly available 2D palmprpint databases. These two arguments are further evaluated for 3D palmprint matching and used to introduce a new method for encoding 3D palmprint feature. The proposed 3D feature is binary and more efficiently computed. It encodes the 3D shape of palmprint to either convex or concave. The experimental results on two publicly available, from contactless and contact-base 3D palmprint database of 177 and 200 subjects, respectively, outperform the state-of-the-art methods. This paper also provides our palmprint matching algorithm(s) in public domain, unlike the previous work in this area, which will help to further advance research efforts in this area.","Biometrics (access control),
Feature extraction,
Three-dimensional displays,
Encoding,
Databases,
Probes,
Image coding"
Efficient Algorithms for the Data Exchange Problem,"In this paper, we study the data exchange problem, where a set of users is interested in gaining access to a common file, but where each has only partial knowledge about it as side-information. Assuming that the file is broken into packets, the side-information considered is in the form of linear combinations of the file packets. Given that the collective information of all the users is sufficient to allow recovery of the entire file, the goal is for each user to gain access to the file, while minimizing some communication cost. We assume that the users can communicate over a noiseless broadcast channel, and that the communication cost is a sum of each user's cost function over the number of bits it transmits. For instance, the communication cost could simply be the total number of bits that needs to be transmitted. In the most general case studied in this paper, each user can have any arbitrary convex cost function. We provide deterministic, polynomial-time algorithms (in the number of users and packets), which find an optimal communication scheme that minimizes the communication cost. To further lower the complexity, we also propose a simple randomized algorithm inspired by our deterministic algorithm, which is based on a random linear network-coding scheme.","Base stations,
Complexity theory,
Network coding,
Wireless communication,
Mobile handsets,
Electronic mail,
Optimization"
Similarity Constraints-Based Structured Output Regression Machine: An Approach to Image Super-Resolution,"For regression-based single-image super-resolution (SR) problem, the key is to establish a mapping relation between high-resolution (HR) and low-resolution (LR) image patches for obtaining a visually pleasing quality image. Most existing approaches typically solve it by dividing the model into several single-output regression problems, which obviously ignores the circumstance that a pixel within an HR patch affects other spatially adjacent pixels during the training process, and thus tends to generate serious ringing artifacts in resultant HR image as well as increase computational burden. To alleviate these problems, we propose to use structured output regression machine (SORM) to simultaneously model the inherent spatial relations between the HR and LR patches, which is propitious to preserve sharp edges. In addition, to further improve the quality of reconstructed HR images, a nonlocal (NL) self-similarity prior in natural images is introduced to formulate as a regularization term to further enhance the SORM-based SR results. To offer a computation-effective SORM method, we use a relative small nonsupport vector samples to establish the accurate regression model and an accelerating algorithm for NL self-similarity calculation. Extensive SR experiments on various images indicate that the proposed method can achieve more promising performance than the other state-of-the-art SR methods in terms of both visual quality and computational cost.",
CoDe4D: Color-Depth Local Spatio-Temporal Features for Human Activity Recognition From RGB-D Videos,"Human activity recognition has a variety of important real-world applications, such as video analysis, surveillance, and human-robot interaction. As a promising video representation method, local spatio-temporal (LST) features have received increasing attention from computer vision, machine learning, and robotics communities. However, approaches based on traditional LST features only use color information, which face several challenges, such as illumination changes and dynamic backgrounds. The recent availability of commercial color-depth cameras makes it much cheaper, faster, and easier to acquire depth information, which provides a potential to implement more discriminative and robust LST features. In this paper, we introduce the new 4-D color-depth (CoDe4D) LST feature that incorporates both intensity and depth information acquired from RGB-D cameras. Our feature detector constructs a saliency map through applying independent filters in xyzt dimension to represent texture, shape and pose variations, and selects its local maxima as interest points. Our multichannel orientation histogram descriptor applies a 4-D support region, which is adaptive to linear perspective view changes, on each interest point. Then, image gradients of color-depth patches within the support region are computed and quantized using a spherical coordinate-based method to form a final feature vector. We build a complete activity recognition system by combining our features with bag-of-features representations and support vector machines. To evaluate the performance of our CoDe4D LST features and the complete system, we conduct experiments using four benchmark color-depth human activity data sets, including UTK Action3-D, Berkeley MHAD, ACT42, and MSR daily activity 3-D data sets. Experimental results demonstrate the promising representative power of our CoDe4D features, which obtain the state-of-the-art performance on activity recognition from RGB-D visual data.","Feature extraction,
Three-dimensional displays,
Image color analysis,
Visualization,
Detectors,
Videos,
Cameras"
Successive Omniscience,"Because the exchange of information among all the users in a large network can take a long time, a successive omniscience protocol is proposed. Namely, subgroups of users first recover the information of other users in the same subgroup at an earlier stage called local omniscience. Then, the users recover the information of all other users at a later stage called global omniscience. To facilitate the information exchange, a distributed storage system is used, so that users can conveniently upload and download messages through some reliable central servers. The minimum upload bandwidth is characterized and a bandwidth-storage trade-off is discovered. The results reveal the new connections to the problem of secret key agreement and, consequently, provide meaningful interpretations of a recently proposed multivariate mutual information measure that was inspired by the secret key agreement problem.","Zinc,
Servers,
Bandwidth,
Mutual information,
Network coding,
Random variables,
Decoding"
Frequency-domain equalization aided iterative detection of faster-than-Nyquist signaling with noise whitening,"In this paper, we propose a serially concatenated turbo-encoded faster-than-Nyquist signaling (FTNS) transceiver that takes into account FTNS-specific colored noise effects. The proposed low-complexity receiver carries out soft-decision frequency-domain equalization with the aid of the minimum-mean square error criterion while whitening the colored noise. Simulation results demonstrate that the proposed multi-stage-concatenated FTNS system achieves a better error-ratio performance than previous systems that do not consider colored noise effects in the high-symbol-packing FTNS regime. Furthermore, as an explicit benefit of the proposed iterative decoder, near-capacity performance is achieved with practical decoding complexity.",
Numerical Simulation of Rock Breakage Modes under Confining Pressures in Deep Mining: An Experimental Investigation,"The cutting efficiency in underground excavations relies on the optimum parameters of the cutting tool and the cutting process. However, the optimization of the cutting tool design and the cutting process is a challenge and requires knowledge about the tool-rock interaction. This paper aims to investigate the tool-rock interaction using a rock cutting mathematical model. The confining pressure was considered in the rock cutting model with conical cutters and the discrete element method was adopted to calculate the dynamics of the rock breakage of this model. Graded particle assemblies were created, calibrated, and compressed in the horizontal direction with a certain confining pressure. Afterwards, the initiation and propagation of cracks during the rock cutting processes were recorded. A series of small-scale rock cutting tests were also carried out to verify the numerical model. The analysis results demonstrate that: 1) the confining pressure induced larger cutting force than that in the unconfined condition; 2) with increase of the confining pressure, the rock failure mode experienced predominantly brittle to predominantly ductile failure; and 3) there was a critical confining pressure/compressive strength ratio of 0.53 when the transition of failure mode occurred.","Rocks,
Mathematical model,
Finite element analysis,
Cutting tools,
Numerical models,
Coal,
Numerical simulation,
Mining industry"
"Software Calibration of a Frequency-Diverse, Multistatic, Computational Imaging System","We demonstrate a technique for calibrating a frequency-diverse, multistatic, computational imaging system. A frequency-diverse aperture enables an image to be reconstructed primarily from a set of scattered field measurements taken over a band of frequencies, avoiding mechanical scanning and active components. Since computational imaging systems crucially rely on the accuracy of a forward model that relates the measured and transmitted fields, deviations of the actual system from that model will rapidly degrade imaging performance. Here, we study the performance of a computational imaging system at microwave frequencies based on a set of frequency-diverse aperture antennas, or panels. We propose a calibration scheme that compares the measured versus simulated scattered field from a cylinder and calculates a compensating phase difference to be applied at each of the panels comprising the system. The calibration of the entire system needs be performed only once, avoiding a more laborious manual calibration step for each transmitting and receiving path. Imaging measurements performed using the system confirm the efficacy and importance of the calibration step.","Image processing,
Calibration,
Frequency measurement,
Computational modeling,
Antenna measurements,
Image reconstruction,
Near field communication,
Software development"
Patient status monitoring for smart home healthcare,"We propose smart home health care system for the realization of smart cities to fulfill the needs of elderly people in order to have continued care. An elderly person should be monitored constantly, specifically if he or she is diagnosed for health-related problems before. In the proposed system, a patient's condition is monitored by using multimodal inputs, specifically, speech and video. Video cameras and microphones are installed in the smart homes; these sensors constantly capture video and speech of the patient, and transmit them to a dedicated cloud. In the cloud, the data are processed, and a classification score on the patient's condition, whether he is normal, tensed, or in pain, is produced. Depending on the condition of the person, the doctors prescribe the person via audio, video or message services, or the caregivers rush to the location for emergency. For data processing in the server, we extract robust and low-dimensional discriminating features from voice and video frames. Experimental results show that the combined modality achieves better accuracy than that using a single modality to correctly classify the patient's condition.","Smart cities,
Speech,
Smart homes,
Pain,
Monitoring,
Intelligent sensors"
Demand-Aware Network Function Placement,"Network function virtualization is an emerging network resource utilization approach which decouples network functions from proprietary hardware and enables adaptive services to end-user requests. To accommodate the network function requests, network function instances are created and deployed at runtime. In this paper, we study a network virtualization scheme to orchestrate and manage networking and network function services. We propose an integrated design for network function instance allocation and end-to-end demand realization sharing the same physical substrate network and demonstrate that the corresponding network design problem is NP complete. A mixed-integer programming formulation is proposed first to find its optimal solution, followed by a two-player pure-strategy game model which captures the competition on physical resources between network function instance allocation and routing. We then design an algorithm based on iterative weakly dominated elimination in Game Theory. Computational results demonstrate the value of the integrated approach and its ability to allocate network function instances supporting end-to-end requests with limited physical resources in optical networks.","Optical fiber networks,
Routing,
Resource management,
Cloud computing,
Virtualization,
Substrates"
The Cybersecurity Landscape in Industrial Control Systems,"Industrial control systems (ICSs) are transitioning from legacy-electromechanical-based systems to modern information and communication technology (ICT)-based systems creating a close coupling between cyber and physical components. In this paper, we explore the ICS cybersecurity landscape including: 1) the key principles and unique aspects of ICS operation; 2) a brief history of cyberattacks on ICS; 3) an overview of ICS security assessment; 4) a survey of “uniquely-ICS” testbeds that capture the interactions between the various layers of an ICS; and 5) current trends in ICS attacks and defenses.","Computer security,
Process control,
Production facilities,
Computer crime,
Cyber-physical systems,
SCADA systems,
Industrial plants"
A Kalman Filter for Amplitude Estimation in High-Speed Dynamic Mode Atomic Force Microscopy,"A fundamental challenge in dynamic mode atomic force microscopy (AFM) is the estimation of the cantilever oscillation amplitude from the deflection signal, which might be distorted by noise and/or high-frequency components. When the cantilever is excited at resonance, its deflection is typically obtained via narrow-band demodulation using a lock-in amplifier (LIA). However, the bandwidth of this measurement technique is ultimately bounded by the low-pass filter, which must be employed after demodulation to attenuate the component at twice the carrier frequency. Furthermore, to measure the amplitude of multiple frequency components, such as higher eigenmodes and/or higher harmonics in multifrequency AFM, multiple LIAs must be employed. In this paper, the authors propose the estimation of amplitude and phase using a linear time-varying Kalman filter that is easily extended to multiple frequencies. Experimental results are obtained using square-modulated sine waves and closed-loop AFM scans, verifying the performance of the proposed Kalman filter.",
Knowledge-Based Adaptive Detection: Joint Exploitation of Clutter and System Symmetry Properties,"We address adaptive radar detection of targets embedded in clutter characterized by a symmetrically structublack power spectral density (PSD) and persymmetric covariance matrix. At the design stage, such properties are jointly exploited to come up with decision schemes capable of guaranteeing superior detection performances with respect to architectures which incorporate either persymmetry or clutter PSD symmetry. The performance analysis, both on simulated and on real radar data, confirms the superiority of the newly proposed architectures over their natural counterparts which do not take advantage of both the sources of a priori information.",
A Secure Anonymous Authentication Protocol for Mobile Services on Elliptic Curve Cryptography,"Mobile user authentication is an essential topic to consider in the current communications technology due to greater deployment of handheld devices and advanced technologies. Memon et al. recently proposed an efficient and secure two-factor authentication protocol for location-based services using asymmetric key cryptography. Unlike their claims, the vigilant analysis of this paper substantiates that Memon et al.'s protocol has quite a few limitations such as vulnerability to key compromised impersonation attack, insecure password changing phase, imperfect mutual authentication, and vulnerability to insider attack. Furthermore, this paper proposes an enhanced secure authentication protocol for roaming services on elliptic curve cryptography. The proposed protocol is also a two-factor authentication protocol and is suitable for practical applications due to the composition of light-weight operations. The proposed protocol's formal security is verified using Automated Validation of Internet Security Protocols and Applications tool to certify that the proposed protocol is free from security threats. The informal and formal security analyses along with the performance analysis sections determine that the proposed protocol performs better than Memon et al.'s protocol and other related protocols in terms of security and efficiency.","Protocols,
Authentication,
Mobile communication,
Elliptic curve cryptography,
Mobile handsets"
Fabrication of Fully Inkjet-Printed Vias and SIW Structures on Thick Polymer Substrates,"In this paper, a novel fully inkjet-printed via fabrication technology and various inkjet-printed substrate-integrated waveguide (SIW) structures on thick polymer substrates are presented. The electrical properties of polymethyl methacrylate (PMMA) are thoroughly studied up to 8 GHz utilizing the T-resonator method, and inkjet-printable silver nanoparticle ink on PMMA is characterized. A long via fabrication process up to 1 mm utilizing inkjet-printing technology is demonstrated, and its characteristics are presented for the first time. The inkjet-printed vias on 0.8-mm-thick substrate have a resistance of ~0.2. An equivalent circuit model of the inkjet-printed stepped vias is also discussed. An inkjet-printed microstrip-to-SIW interconnect and an SIW cavity resonator utilizing the proposed inkjet-printed via fabrication process are also presented. The design of the components and the fabrication steps are discussed, and the measured performances over the microwave frequency range of the prototypes are presented.","Substrates,
Silver,
Fabrication,
Conductivity,
Ink,
Nanoparticles,
Printing"
Ghost-in-ZigBee: Energy Depletion Attack on ZigBee-Based Wireless Networks,"ZigBee has been widely recognized as an important enabling technique for Internet of Things (IoT). However, the ZigBee nodes are normally resource-limited, making the network susceptible to a variety of security threats. This paper closely investigates a severe attack on ZigBee networks termed as ghost, which leverages the underlying vulnerabilities of the IEEE 802.15.4 security suites to deplete the energy of the nodes. We show that the impact of ghost is very large and that it can facilitate a variety of threats including denial of service and replay attacks. We highlight that merely deploying a standard suite of advanced security techniques does not necessarily guarantee improved security, but instead might be leveraged by adversaries to cause severe disruption in the network. We propose several recommendations on how to localize and withstand the ghost and other related attacks in ZigBee networks. Extensive simulations are provided to show the impact of the ghost and the performance of the proposed recommendations. Moreover, physical experiments also have been conducted and the observations confirm the severity of the impact by the ghost attack. We believe that the presented work will aid the researchers to improve the security of ZigBee further.",
Three-Dimensional Beamforming for Large-Scale FD-MIMO Systems Exploiting Statistical Channel State Information,"In this paper, we provide a practical downlink transmission approach for single-cell full-dimension multiple-input-multiple-output (FD-MIMO) systems with large-scale uniform planar antenna array at the base station (BS). Under the assumption of only statistical channel state information (CSI) at the BS, we derive the optimal beamforming vector of each user by maximizing a lower bound on the average signal-to-leakage-plus-noise ratio. Some main guidelines for user scheduling are also derived under this criterion. Based on these results, a low-complexity 3-D beamforming space-division multiple-access (SDMA) transmission algorithm exploiting only the statistical CSI of each user is proposed. Furthermore, the ergodic sum rate of the proposed algorithm is analyzed, and a closed-form expression, as well as a low signal-to-noise ratio (SNR) approximation and a high-SNR approximation, are derived. Simulation results show that the proposed algorithm performs well in terms of achievable sum rate, and the analytical results on its achievable sum rate are validated.",
Blind quality assessment of compressed images via pseudo structural similarity,"Block-based compression causes severe pseudo structures. We find that the pseudo structures of images compressed by different levels show some degree of similarity. So we propose to evaluate the quality of compressed images via the similarity between pseudo structures of two images. To obtain a “reference” image, we introduce the most distorted image (MDI), which is derived from the distorted image and suffers from the highest degree of compression. The proposed pseudo structural similarity (PSS) model calculates the similarity between pseudo structures of the distorted image and MDI. Pseudo structures of the distorted image become similar to the MDI's under the condition of severe compression. Via comparative tests, the proposed PSS model, on one hand, is shown to be comparable to state-of-the-art competitors, and on the other hand, it is not only good at assessing natural scene images but also performs the best in the hotly-researched screen content image (SCI) database. It deserves to mention that PSS is able to boost the performance of mainstream general-purpose no-reference (NR) quality measures.","Image coding,
Distortion measurement,
Transform coding,
Databases,
Distortion,
Image quality"
Power Allocation and Performance of Multiuser Mixed RF/FSO Relay Networks With Opportunistic Scheduling and Outdated Channel Information,"This paper studies the performance of a multiuser mixed radio frequency (RF)/free space optical (FSO) relay network with transmit opportunistic scheduling. The outdated channel information (OCI) on the first relaying hop and its effect on the system performance is also studied in this paper. Furthermore, a power allocation scheme is proposed for optimizing the overall system performance. The considered system includes K sources (users), one amplify-and-froward relay and one destination. The users are connected with the relay node through RF links and the relay is connected with the destination through an FSO link. In the analysis, the first hop channels are assumed to follow Rayleigh fading model and the second hop channel is assumed to follow Gamma-Gamma fading model with considering the effect of pointing errors. Closed-form expressions are derived for the outage probability, average symbol error probability, and ergodic channel capacity. Furthermore, the system performance is studied at high signal-to-noise ratio regime, where the diversity order and coding gain are derived and analyzed. Using the asymptotic results, the power of users and relay are determined to minimize the system outage probability under a total power constraint. Monte-Carlo simulations are provided to validate the achieved exact and asymptotic results. Main results show that under weak atmospheric turbulence conditions, the system performance is dominated by the RF channels and a diversity order of K is achieved by the system, whereas under severe atmospheric turbulence conditions, the system is dominated by the FSO channel and the diversity order is determined by the minimum value of the turbulence fading and pointing error parameters.","Relay networks (telecommunications),
Fading channels,
Radio frequency,
Closed-form solutions,
Error probability,
Atmospheric modeling"
Wearable band for hand gesture recognition based on strain sensors,"A novel fully wearable system based on a smart wristband equipped with stretchable strain gauge sensors and readout electronics have been assembled and tested to detect a set of movements of a hand crucial in rehabilitation procedures. The high sensitivity of the active devices embedded on the wristband do not need a direct contact with the skin, thus maximizing the comfort on the arm of the tester. The gestures done with the device have been auto-labeled by comparing the signals detected in real-time by the sensors with a commercial infrared device (Leap motion). Finally, the system has been evaluated with two machine-learning algorithms Linear Discriminant Analysis (LDA) and Support Vector Machine (SVM), reaching a reproducibility of 98% and 94%, respectively.","Thumb,
Support vector machines,
Biomedical monitoring,
Sensor systems,
Skin"
Joint Spectrum Sensing and Resource Allocation Scheme in Cognitive Radio Networks with Spectrum Sensing Data Falsification Attack,"Spectrum sensing and spectrum sharing are two fundamental issues in a cognitive radio network (CRN). The spectrum sensing data falsification (SSDF) attack imposes bad effects on both spectrum sensing and spectrum sharing. To deal with SSDF attacks and to incentivize secondary users (SUs) to behave well, a joint spectrum sensing and resource allocation (JSSRA) scheme in a CRN is proposed in this paper. The JSSRA problem is formulated as a weighted-proportional-fairness-based resource-allocation optimization problem under the constraint that the primary user (PU) network is sufficiently protected. The problem is decomposed into two subproblems, namely, the resource allocation subproblem and cooperative SU number decision subproblem, which are solved by the Lagrangian dual algorithm and the brute-force algorithm, respectively. Moreover, a user-selection method based on reinforcement learning is presented to select reliable SUs for cooperative spectrum sensing (CSS). In addition, the SU's trust degree is updated according to its behavior in CSS and is used in the sensed resource-allocation process. The key point of our proposed scheme is to make SUs improve the sensing reliability and prevent SUs from behaving maliciously by an incentive mechanism. Comprehensive performance evaluation is conducted by computer simulation. It is shown that the proposed JSSRA scheme deals with the SSDF attack well in cooperative sensing process to improve system robustness and achieves a significant system utility gain in resource allocation.","Sensors,
Resource management,
Cascading style sheets,
Reliability,
Optimization,
Interference,
Data communication"
Design of a Network of Digital Sensor Macros for Extracting Power Supply Noise Profile in SoCs,"Increased functional density with shrinking technology could result in escalating power supply noise (PSN)-induced failures in the field. Furthermore, the low correlation between system-level functional test and production test is making it difficult to better screen parts that would fail in the field due to PSN. To address these issues, in this paper, we present a fully digital on-chip distributed sensor network to continuously monitor the PSN profile across the chip and generate a trace for diagnosis of any noise-induced failure at silicon validation, structural test, system test, and functional operation phases of system on chips (SoCs). The sensors capture PSN at a fine granularity and store the SoC's critical status bits. The sensor offers easy access and control with the aid of scan chains. The sensor network has been designed in the 28-nm standard cell library, and its performance is demonstrated in the physical design of OpenSPARCT1 multicore processor SoC.",
A Robust Scheme for Feature-Preserving Mesh Denoising,"In recent years researchers have made noticeable progresses in mesh denoising, that is, recovering high-quality 3D models from meshes corrupted with noise (raw or synthetic). Nevertheless, these state of the art approaches still fall short for robustly handling various noisy 3D models. The main technical challenge of robust mesh denoising is to remove noise while maximally preserving geometric features. In particular, this issue becomes more difficult for models with considerable amount of noise. In this paperwe present a novel scheme for robust feature-preserving mesh denoising. Given a noisy mesh input, our method first estimates an initial mesh, then performs feature detection, identification and connection, and finally, iteratively updates vertex positions based on the constructed feature edges. Through many experiments, we show that our approach can robustly and effectively denoise various input mesh models with synthetic noise or raw scanned noise. The qualitative and quantitative comparisons between our method and the selected state of the art methods also show that our approach can noticeably outperform them in terms of both quality and robustness.","Noise reduction,
Feature extraction,
Noise measurement,
Robustness,
Estimation,
Face,
Three-dimensional displays"
A General Privacy-Preserving Auction Mechanism for Secondary Spectrum Markets,"Auctions are among the best-known market-based tools to solve the problem of dynamic spectrum redistribution. In recent years, a good number of strategy-proof auction mechanisms have been proposed to improve spectrum utilization and to prevent market manipulation. However, the issue of privacy preservation in spectrum auctions remains open. On the one hand, truthful bidding reveals bidders' private valuations of the spectrum. On the other hand, coverage/interference areas of the bidders may be revealed to determine conflicts. In this paper, we present PISA, which is a PrIvacy preserving and Strategy-proof Auction mechanism for spectrum allocation. PISA provides protection for both bid privacy and coverage/interference area privacy leveraging a privacy-preserving integer comparison protocol, which is well applicable in other contexts. We not only theoretically prove the privacy-preserving properties of PISA, but also extensively evaluate its performance. Evaluation results show that PISA achieves good spectrum allocation efficiency with light computation and communication overheads.","Privacy,
Cryptography,
Resource management,
Interference,
Protocols,
Cost accounting,
IEEE transactions"
Droiddetector: android malware characterization and detection using deep learning,"Smartphones and mobile tablets are rapidly becoming indispensable in daily life. Android has been the most popular mobile operating system since 2012. However, owing to the open nature of Android, countless malwares are hidden in a large number of benign apps in Android markets that seriously threaten Android security. Deep learning is a new area of machine learning research that has gained increasing attention in artificial intelligence. In this study, we propose to associate the features from the static analysis with features from dynamic analysis of Android apps and characterize malware using deep learning techniques. We implement an online deep-learning-based Android malware detection engine (DroidDetector) that can automatically detect whether an app is a malware or not. With thousands of Android apps, we thoroughly test DroidDetector and perform an indepth analysis on the features that deep learning essentially exploits to characterize malware. The results show that deep learning is suitable for characterizing Android malware and especially effective with the availability of more training data. DroidDetector can achieve 96.76% detection accuracy, which outperforms traditional machine learning techniques. An evaluation of ten popular anti-virus softwares demonstrates the urgency of advancing our capabilities in Android malware detection.",
Energy-Efficient Hybrid Analog/Digital Approximate Computation in Continuous Time,"We present a unit that performs continuous-time hybrid approximate computation, in which both analog and digital signals are functions of continuous time. Our 65 nm CMOS prototype system is capable of solving nonlinear differential equations up to 4th order, and is scalable to higher orders. Nonlinear functions are generated by a programmable, clockless, continuoustime 8-bit hybrid architecture (ADC + SRAM + DAC). Digitally assisted calibration is used in all analog/mixed-signal blocks. Compared to the prior art, our chip makes possible arbitrary nonlinearities and achieves 16× lower power dissipation, thanks to technology scaling and extensive use of class-AB analog blocks. Typically, the unit achieves a computational accuracy of about 0.5% to 5% RMS, solution times from a fraction of 1 μs to several hundred μs, and total computational energy from a fraction of 1 nJ to hundreds of nJ, depending on equation details. Very significant advantages are observed in computational speed and energy (over two orders of magnitude and over one order of magnitude, respectively) compared to those obtained with a modern microcontroller for the same RMS error.",
Designing reconfigurable large-scale deep learning systems using stochastic computing,"Deep Learning, as an important branch of machine learning and neural network, is playing an increasingly important role in a number of fields like computer vision, natural language processing, etc. However, large-scale deep learning systems mainly operate in high-performance server clusters, thus restricting the application extensions to personal or mobile devices. The solution proposed in this paper is taking advantage of the fantastic features of stochastic computing methods. Stochastic computing is a type of data representation and processing technique, which uses a binary bit stream to represent a probability number (by counting the number of ones in this bit stream). In the stochastic computing area, some key arithmetic operations such as additions or multiplications can be implemented with very simple components like AND gates or multiplexers, respectively. Thus it provides an immense design space for integrating a large amount of neurons and enabling fully parallel and scalable hardware implementations of large-scale deep learning systems. In this paper, we present a reconfigurable large-scale deep learning system based on stochastic computing technologies, including the design of the neuron, the convolution function, the back-propagation function and some other basic operations. And the network-on-chip technique is also proposed in this paper to achieve the goal of implementing a large-scale hardware system. Our experiments validate the functionality of reconfigurable deep learning systems using stochastic computing, and demonstrate that when the bit streams are set to be 8192 bits, classification of MNIST digits by stochastic computing can perform as low error rate as that by normal arithmetic operations.","Machine learning,
Neurons,
Hardware,
Stochastic processes,
Biological neural networks,
Encoding"
Trust-Aware Consensus-Inspired Distributed Cooperative Spectrum Sensing for Cognitive Radio Ad Hoc Networks,"Cooperation among cognitive radios for spectrum sensing is deemed essential for environments with deep shadows. In this paper, we study cooperative spectrum sensing for cognitive radio ad hoc networks where there is no fusion center to aggregate the information from various secondary users. We propose a novel consensus-inspired cooperative sensing scheme based on linear iterations that is fully distributed and low-cost. In addition, the tradeoffs on the number of consensus iterations are explored for scenarios with different shadow fading characteristics. Furthermore, we model insistent spectrum sensing data falsification (ISSDF) attack aimed at consensus-based iterative schemes and show its destructive effect on the cooperation performance which accordingly results in reduced spectrum efficiency and increased interference with primary users. We propose a trust management scheme to mitigate these attacks and evaluate the performance improvement through extensive Monte Carlo simulations for large-scale cognitive radio ad hoc networks in TV white space. Our proposed trust management reduces the harm of a set of collusive ISSDF attackers up to two orders of magnitude in terms of missed-detection and false alarm error rates. Moreover, in a hostile environment, integration of trust management into cooperative schemes considerably relaxes the sensitivity requirements on the cognitive radio devices.","Sensors,
Cognitive radio,
Ad hoc networks,
Fading channels,
Network topology,
Protocols,
Peer-to-peer computing"
Robust Backstepping Sliding-Mode Control and Observer-Based Fault Estimation for a Quadrotor UAV,"This study gives the mathematic model of a quadrotor unmanned aerial vehicle (UAV) and then proposes a robust nonlinear controller which combines the sliding-mode control technique and the backstepping control technique. To achieve Cartesian position trajectory tracking capability, the construction of the controller can be divided into two stages: a regular SMC controller for attitude subsystem (inner loop) is first developed to guarantee fast convergence rapidity of Euler angles and the backstepping technique is applied to the position loop until desired attitudes are obtained and then the ultimate control laws. The stability of the closed-loop system is guaranteed by stabilizing each of the subsystems step by step and the robustness of the controller against model uncertainty and external disturbances is investigated. In addition, an adaptive observer-based fault estimation scheme is also considered for taking off mode. Simulations are conducted to demonstrate the effectiveness of the designed robust nonlinear controller and the fault estimation scheme.","Robustness,
Attitude control,
Mathematical model,
Backstepping,
Rotors,
Estimation"
Lower Bounds on the LTE-A Average Random Access Delay Under Massive M2M Arrivals,"Rapid growth of machine-to-machine (M2M) communications necessitates the reevaluation of the Long Term Evolution-Advanced (LTE-A) performance, since the current standard is not optimized for intensive M2M traffic. A serious issue is that massive M2M arrivals can overload the LTE-A random access channel, resulting in a significant access delay. There have been a number of proposals to control this overload; however, there are no studies on the mathematical characterization of delay bounds to the best of our knowledge. Here, we derive lower bounds for the LTE-A average random access delay for both a regular traffic pattern (uniformly distributed arrivals) and for a traffic pattern, indicating a serious congestion (beta-distributed arrivals). The proposed delay bounds, which predict the minimum delay with less than 6% error, present the fundamental limits of delay that can be achieved by a practical load-balancing algorithm. This paper is also one of the first attempts toward the mathematical analysis of beta-distributed arrivals. We also analyze the effect of estimation accuracy, frequency of random access opportunities, and the number of preambles on the access delay. We show that it is possible to reduce the access delay by several orders of magnitude using an appropriate configuration of these system parameters.",
Jump over ASLR: Attacking branch predictors to bypass ASLR,"Address Space Layout Randomization (ASLR) is a widely-used technique that protects systems against a range of attacks. ASLR works by randomizing the offset of key program segments in virtual memory, making it difficult for an attacker to derive the addresses of specific code objects and consequently redirect the control flow to this code. In this paper, we develop an attack to derive kernel and user-level ASLR offset using a side-channel attack on the branch target buffer (BTB). Our attack exploits the observation that an adversary can create BTB collisions between the branch instructions of the attacker process and either the user-level victim process or on the kernel executing on its behalf. These collisions, in turn, can impact the timing of the attacker's code, allowing the attacker to identify the locations of known branch instructions in the address space of the victim process or the kernel. We demonstrate that our attack can reliably recover kernel ASLR in about 60 milliseconds when performed on a real Haswell processor running a recent version of Linux. Finally, we describe several possible protection mechanisms, both in software and in hardware.",
Evaluation of the IEEE 802.11ah Restricted Access Window mechanism for dense IoT networks,"IEEE 802.11ah is a new Wi-Fi draft for sub-1Ghz communications, aiming to address the major challenges of the Internet of Things (IoT): connectivity among a large number of power-constrained stations deployed over a wide area. The new Restricted Access Window (RAW) mechanism promises to increase throughput and energy efficiency by dividing stations into different RAW groups. Only the stations in the same group can access the channel simultaneously, which reduces collision probability in dense scenarios. However, the draft does not specify any RAW grouping algorithms, while the grouping strategy is expected to severely impact RAW performance. To study the impact of parameters such as traffic load, number of stations and RAW group duration on optimal number of RAW groups, we implemented a sub-1Ghz PHY model and the 802.11ah MAC protocol in ns-3 to evaluate its transmission range, throughput, latency and energy efficiency in dense IoT network scenarios. The simulation shows that, with appropriate grouping, the RAW mechanism substantially improves throughput, latency and energy efficiency. Furthermore, the results suggest that the optimal grouping strategy depends on many parameters, and intelligent RAW group adaptation is necessary to maximize performance under dynamic conditions. This paper provides a major leap towards such a strategy.",
Cross-Domain Sentiment Classification Using Sentiment Sensitive Embeddings,"Unsupervised Cross-domain Sentiment Classification is the task of adapting a sentiment classifier trained on a particular domain (source domain), to a different domain (target domain), without requiring any labeled data for the target domain. By adapting an existing sentiment classifier to previously unseen target domains, we can avoid the cost for manual data annotation for the target domain. We model this problem as embedding learning, and construct three objective functions that capture: (a) distributional properties of pivots (i.e., common features that appear in both source and target domains), (b) label constraints in the source domain documents, and (c) geometric properties in the unlabeled documents in both source and target domains. Unlike prior proposals that first learn a lower-dimensional embedding independent of the source domain sentiment labels, and next a sentiment classifier in this embedding, our joint optimisation method learns embeddings that are sensitive to sentiment classification. Experimental results on a benchmark dataset show that by jointly optimising the three objectives we can obtain better performances in comparison to optimising each objective function separately, thereby demonstrating the importance of task-specific embedding learning for cross-domain sentiment classification. Among the individual objective functions, the best performance is obtained by (c). Moreover, the proposed method reports cross-domain sentiment classification accuracies that are statistically comparable to the current state-of-the-art embedding learning methods for cross-domain sentiment classification.","Training,
Linear programming,
Feature extraction,
Logistics,
Frequency-domain analysis,
Joints,
Learning systems"
Using Viewing Statistics to Control Energy and Traffic Overhead in Mobile Video Streaming,"Video streaming can drain a smartphone battery quickly. A large part of the energy consumed goes to wireless communication. In this article, we first study the energy efficiency of different video content delivery strategies used by service providers and identify a number of sources of energy inefficiency. Specifically, we find a fundamental tradeoff in energy waste between prefetching small and large chunks of video content: small chunks are bad because each download causes a fixed tail energy to be spent regardless of the amount of content downloaded, whereas large chunks increase the risk of downloading data that user will never view because of abandoning the video. Hence, the key to optimal strategy lies in the ability to predict when the user might abandon viewing prematurely. We then propose an algorithm called eSchedule that uses viewing statistics to predict viewer behavior and computes an energy optimal download strategy for a given mobile client. The algorithm also includes a mechanism for explicit control of traffic overhead, i.e., unnecessary download of content that the user will never watch. Our evaluation results suggest that the algorithm can cut the energy waste down to less than half compared to other strategies. We also present and experiment with an Android prototype that integrates eSchedule into a YouTube downloader.","Streaming media,
Mobile communication,
Schedules,
YouTube,
Watches,
IEEE 802.11 Standards,
Optimal scheduling"
Forecasting-Aided Imperfect False Data Injection Attacks Against Power System Nonlinear State Estimation,"This letter proposes an imperfect false data injection attack model and its corresponding forecasting-aided implementation method against the nonlinear power system state estimation by introducing an attack vector relaxing error. The upper bound of the relaxing error within the method is presented through theoretical analysis. Simulation experiments on the IEEE 30-bus system show that the proposed method works well both to the nonlinear model and to the dc model. In this letter, both single and multiple state variables attacks are considered.",
Anomalous Diffusion in Cardiac Tissue as an Index of Myocardial Microstructure,"Diffusion in biological tissues is known to be hindered by the structural complexity of the underlying medium. In the heart, improved characterisation on how this complexity influences acquired diffusion weighted signals is key to advancing our interpretation of diffusion magnetic resonance imaging, as well as to propose novel biomarkers to further characterise myocardial microstructure. In this work, we propose stretched Mittag-Leffler signal decay models for the quantification of the anomalous decay observed in acquired diffusion weighted signals. Our results, analysed in ex vivo healthy, fixed rat ventricles, indicate that such a representation suffices to capture the anomalous signal decay observed in the myocardial syncytium. The subdiffusive order of signal decay is shown to encode independent information to that encapsulated by standard diffusion tensor metrics, and thus may provide additional information on tissue microstructure. Moreover, subdiffusion gradients are shown to be indicative of the total structural heterogeneity spanning the left ventricular wall, which includes progressive myolaminae branching and spatially varying densities of perimysial collagen, microvasculature and adipose tissue. The proposed approach may therefore have important implications for the characterisation of tissue microstructure, both in cardiac and other tissue types.",
Design and Implementation of an Anthropomorphic Hand for Replicating Human Grasping Functions,"How to design an anthropomorphic hand with a few actuators to replicate the grasping functions of the human hand is still a challenging problem. This paper aims to develop a general theory for designing the anthropomorphic hand and endowing the designed hand with natural grasping functions. A grasping experimental paradigm was set up for analyzing the grasping mechanism of the human hand in daily living. The movement relationship among joints in a digit, among digits in the human hand, and the postural synergic characteristic of the fingers were studied during the grasping. The design principle of the anthropomorphic mechanical digit that can reproduce the digit grasping movement of the human hand was developed. The design theory of the kinematic transmission mechanism that can be embedded into the palm of the anthropomorphic hand to reproduce the postural synergic characteristic of the fingers by using a limited number of actuators is proposed. The design method of the anthropomorphic hand for replicating human grasping functions was formulated. Grasping experiments are given to verify the effectiveness of the proposed design method of the anthropomorphic hand.",
Pricing Mobile Data Offloading: A Distributed Market Framework,"Mobile data offloading is an emerging technology to avoid congestion in cellular networks and improve the level of user satisfaction. In this paper, we develop a distributed market framework to price the offloading service, and conduct a detailed analysis of the incentives for offloading service providers and conflicts arising from the interactions of different participators. Specifically, we formulate a multileader multifollower Stackelberg game (MLMF-SG) to model the interactions between the offloading service providers and the offloading service consumers in the considered market framework, and investigate the cases where the offloading capacity of APs is unlimited and limited, respectively. For the case without capacity limit, we decompose the followers' game of the MLMF-SG (FG-MLMF-SG) into a number of simple follower games (FGs), and prove the existence and uniqueness of the equilibrium of the FGs from which the existence and uniqueness of the FG-MLMF-SG also follows. For the leaders' game of the MLMF-SG, we also prove the existence and uniqueness of the equilibrium. For the case with capacity limit, by considering a symmetric strategy profile, we establish the existence and uniqueness of the equilibrium of the corresponding MLMF-SG, and present a distributed algorithm that allows the leaders to achieve the equilibrium. Finally, extensive numerical experiments demonstrate that the Stackelberg equilibrium is very close to the corresponding social optimum for both considered cases.","Games,
Mobile communication,
IEEE 802.11 Standard,
Radio frequency,
Pricing,
Mobile computing,
Femtocells"
Iterative Time-Frequency Filtering of Sinusoidal Signals With Updated Frequency Estimation,"In this letter, a sinusoidal time-frequency distribution based filtering (STFD-F) algorithm is proposed and analysed for estimating mono-component stationary sinusoidal signals embedded in strong noise. An initial frequency estimation of the sinusoidal signal is required in the STFD-F algorithm. We theoretically derive the closed-form expressions of the variance and the bias of the estimated signal using the STFD-F, and show that the performance of the STFD-F is dependent on the frequency estimation accuracy, which can be gradually refined by performing an iterative STFD-F procedure. Computer simulations on synthetic sinusoidal signals are presented to corroborate the theoretical analysis.","Frequency modulation,
Signal processing algorithms,
Time-frequency analysis,
Frequency estimation,
Algorithm design and analysis,
Kernel,
Filtering"
A Practical Large-Capacity Three-Stage Buffered Clos-Network Switch Architecture,"This paper proposes a three-stage buffered Clos-network switch (TSBCS) architecture along with a novel batch scheduling (BS) mechanism. We found that TSBCS/BS can be mapped to a “fat” combined input-crosspoint queued (CICQ) switch. Consequently, the well-studied CICQ scheduling algorithms can be directly applied in TSBCS. Moreover, BS drastically reduces the time complexity of TSBCS scheduling when compared with ordinary CICQ switches of the same number of switch ports, which enables us to build a larger-capacity switch with reasonable scheduling complexity. We further show that TSBCS/BS can achieve 100 percent throughput under any admissible traffic if a stable CICQ scheduling algorithm is used. Direct cell forwarding schemes are proposed to overcome the performance drawback of BS under light traffic loads. With extensive simulations, we show that the performance of TSBCS/BS is comparable to that of output-queued switches and the latter are usually considered as theoretical optimal.","Switches,
Computer architecture,
Microprocessors,
Ports (Computers),
Out of order,
Radiation detectors,
Throughput"
A Game-Theoretic Resource Allocation Approach for Intercell Device-to-Device Communications in Cellular Networks,"Device-to-device (D2D) communication is a recently emerged disruptive technology for enhancing the performance of current cellular systems. To successfully implement D2D communications underlaying cellular networks, resource allocation to D2D links is a critical issue, which is far from trivial due to the mutual interference between D2D users and cellular users. Most of the existing resource allocation research for D2D communications has primarily focused on the intracell scenario while leaving the intercell settings not considered. In this paper, we investigate the resource allocation issue for intercell scenarios where a D2D link is located in the overlapping area of two neighboring cells. Furthermore, we present three intercell D2D scenarios regarding the resource allocation problem. To address the problem, we develop a repeated game model under these scenarios. Distinct from existing works, we characterize the communication infrastructure, namely, base stations, as players competing resource allocation quota from D2D demand, and we define the utility of each player as the payoff from both cellular and D2D communications using radio resources. We also propose a resource allocation algorithm and protocol based on the Nash equilibrium derivations. Numerical results indicate that the developed model not only significantly enhances the system performance, including sum rate and sum rate gain, but also shed lights on resource configurations for intercell D2D scenarios.",
A Configurable Energy-Efficient Compressed Sensing Architecture With Its Application on Body Sensor Networks,"The past decades have witnessed a rapid surge in new sensing and monitoring devices for well-being and healthcare. One key representative in this field is body sensor networks (BSNs). However, with advances in sensing technologies and embedded systems, wireless communication has gradually become one of the dominant energy-consuming sectors in BSN applications. Recently, compressed sensing (CS) has attracted increasing attention in solving this problem due to its enabled sub-Nyquest sampling rate. In this paper, we investigate the quantization effect in CS architecture and argue that the quantization configuration is a critical factor of the energy efficiency for the entire CS architecture. To this end, we present a novel configurable quantized compressed sensing (QCS) architecture, in which the sampling rate and quantization are jointly explored for better energy efficiency. Furthermore, to combat the computational complexity of the configuration procedure, we propose a rapid configuration algorithm, called RapQCS. According to the experiments involving several categories of real biosignals, the proposed configurable QCS architecture can gain more than 66% performance-energy tradeoff than the fixed QCS architecture. Moreover, our proposed RapQCS algorithm can achieve over 150× speedup on average, while decreasing the reconstructed signal fidelity by only 2.32%.",
Postprocessing of Compressed Images via Sequential Denoising,"In this paper, we propose a novel postprocessing technique for compression-artifact reduction. Our approach is based on posing this task as an inverse problem, with a regularization that leverages on existing state-of-the-art image denoising algorithms. We rely on the recently proposed Plug-and-Play Prior framework, suggesting the solution of general inverse problems via alternating direction method of multipliers, leading to a sequence of Gaussian denoising steps. A key feature in our scheme is a linearization of the compression-decompression process, so as to get a formulation that can be optimized. In addition, we supply a thorough analysis of this linear approximation for several basic compression procedures. The proposed method is suitable for diverse compression techniques that rely on transform coding. In particular, we demonstrate impressive gains in image quality for several leading compression methods-JPEG, JPEG2000, and HEVC.","Image coding,
Transform coding,
Noise reduction,
Image reconstruction,
Image restoration,
Jacobian matrices,
Standards"
A Linear Programming Approach to Expansion Co-Planning in Gas and Electricity Markets,"In a carbon-constrained world, the continuing and rapid growth of gas-fired power generation (GPG) will lead to the increasing demand for natural gas. The reliable and affordable gas supply hence becomes an important factor to consider in power system planning. Meanwhile, the installation of GPG units should take into account not only the fuel supply constraints but also the capability of sending out the generated power. In this paper, a novel expansion co-planning (ECP) model is proposed, aiming to minimize the overall capital and operational costs for the coupled gas and power systems. Moreover, linear formulations are introduced to deal with the nonlinear nature of the objective functions and constraints. Furthermore, the physical and economic interactions between the two systems are simulated by an iterative process. The proposed linear co-planning approach is tested on a simple six-bus power system with a seven-node gas system and a modified IEEE 118-bus system with a 14-node gas system. Numerical results have demonstrated that our co-planning approach can allow systematic investigations on supporting cost-effective operating and planning decisions for power systems.","Contracts,
Planning,
Power generation,
Reliability,
Power systems,
Pipelines,
Electricity supply industry"
Joint acoustic factor learning for robust deep neural network based automatic speech recognition,"Deep neural networks (DNNs) for acoustic modeling have been shown to provide impressive results on many state-of-the-art automatic speech recognition (ASR) applications. However, DNN performance degrades due to mismatches in training and testing conditions and thus adaptation is necessary. In this paper, we explore the use of discriminative auxiliary input features obtained using joint acoustic factor learning for DNN adaptation. These features are derived from a bottleneck (BN) layer of a DNN and are referred to as BN vectors. To derive these BN vectors, we explore the use of two types of joint acoustic factor learning which capture speaker and auxiliary information such as noise, phone and articulatory information of speech. In this paper, we show that these BN vectors can be used for adaptation and thereby improve the performance of an ASR system. We also show that the performance can be further improved on augmenting these BN vectors to conventional i-vectors. In this paper, experiments are performed on Aurora-4, REVERB challenge and AMI databases.","Acoustics,
Speech,
Training,
Hidden Markov models,
Neural networks,
Adaptation models,
Databases"
Electricity-Natural Gas Operation Planning With Hourly Demand Response for Deployment of Flexible Ramp,"This paper proposes an integrated stochastic day-ahead scheduling model to dispatch hourly generation and load resources and deploy flexible ramping for managing the variability of renewable energy system. A comprehensive framework for the natural gas transportation network is considered to address the dispatchability of a fleet of fuel-constrained natural gas-fired units. System uncertainties include the day-ahead load and renewable generation forecast errors. Illustrative examples demonstrate that the real-time natural gas delivery can directly impact the hourly dispatch, flexible ramp deployment, and power system operation cost. Meanwhile, the demand side participation can mitigate the dependency of electricity on natural gas by providing a viable option for flexible ramp when the natural gas system is constrained.",
Adapting to User Interest Drift for POI Recommendation,"Point-of-Interest recommendation is an essential means to help people discover attractive locations, especially when people travel out of town or to unfamiliar regions. While a growing line of research has focused on modeling user geographical preferences for POI recommendation, they ignore the phenomenon of user interest drift across geographical regions, i.e., users tend to have different interests when they travel in different regions, which discounts the recommendation quality of existing methods, especially for out-of-town users. In this paper, we propose a latent class probabilistic generative model Spatial-Temporal LDA (ST-LDA) to learn region-dependent personal interests according to the contents of their checked-in POIs at each region. As the users' check-in records left in the out-of-town regions are extremely sparse, ST-LDA incorporates the crowd's preferences by considering the public's visiting behaviors at the target region. To further alleviate the issue of data sparsity, a social-spatial collective inference framework is built on ST-LDA to enhance the inference of region-dependent personal interests by effectively exploiting the social and spatial correlation information. Besides, based on ST-LDA, we design an effective attribute pruning (AP) algorithm to overcome the curse of dimensionality and support fast online recommendation for large-scale POI data. Extensive experiments have been conducted to evaluate the performance of our ST-LDA model on two real-world and large-scale datasets. The experimental results demonstrate the superiority of ST-LDA and AP, compared with the state-of-the-art competing methods, by making more effective and efficient mobile recommendations.","Urban areas,
Correlation,
Gold,
Real-time systems,
Probabilistic logic,
Algorithm design and analysis,
Mobile communication"
A Systematic Study of ESD Protection Co-Design With High-Speed and High-Frequency ICs in 28 nm CMOS,"This paper discusses a systematic study of electrostatic discharge (ESD) protection circuit co-design and analysis technique for high-frequency and high-speed ICs in 28 nm CMOS. The comprehensive ESD-IC co-design flow includes ESD device optimization and characterization, ESD behavioral modeling, backend interconnect characterization, parasitic ESD parameter extraction, ESD failure analysis and ESD co-design evaluation for ICs operating at up to 15 GHz and 40 Gbps. Ring oscillator, dummy I/O buffer and current mode logic (CML) circuits were used to demonstrate the co-design method. This practical ESD-IC co-design technique can be applied to high-performance, high-frequency and high-speed ICs.","Electrostatic discharges,
Integrated circuit modeling,
Semiconductor device modeling,
Logic gates,
Transient analysis,
Thyristors"
Leveraging Strategic Detection Techniques for Smart Home Pricing Cyberattacks,"In this work, the vulnerability of the electricity pricing model in the smart home system is assessed. Two closely related pricing cyberattacks which manipulate the guideline electricity prices received at smart meters are considered and they aim at reducing the expense of the cyberattacker and increasing the peak energy usage in the local community. A single event detection technique which uses support vector regression and impact difference for detecting anomaly pricing is proposed. The detection capability of such a technique is still limited since it does not model the long term impact of pricing cyberattacks. This motivates us to develop a partially observable Markov decision process based detection algorithm, which has the ingredients such as reward expectation and policy transfer graph to account for the cumulative impact and the potential future impact due to pricing cyberattacks. Our simulation results demonstrate that the pricing cyberattack can reduce the cyberattacker's bill by 34.3 percent at cost of the increase of others' bill by 7.9 percent, and increase the peak to average ratio (PAR) by 35.7 percent. Furthermore, the proposed long term detection technique has the detection accuracy of more than 97 percent with significant reduction in PAR and bill compared to repeatedly using the single event detection technique.","Pricing,
Guidelines,
Computer crime,
Smart homes,
Smart meters,
Energy consumption,
Communities"
GaAs-InGaAs-GaAs Fin-Array Tunnel Diodes on (001) Si Substrates With Room-Temperature Peak-to-Valley Current Ratio of 5.4,"In this letter, we report the selective area growth of GaAs, In0.2Ga0.8As, and GaAs/In0.2Ga0.8As/GaAs quantum-well fins of 65-nm width on exactly orientated (001) Si substrates. By exploiting high aspect ratio trenches formed by patterned SiO2 on Si and a V-grooved Si (111) surface in the aspect ratio trapping process, we are able to achieve good material quality and structural properties, as evidenced by x-ray diffraction, scanning electron microscopy, and transmission electron microscopy. The fabricated GaAs-In0.2Ga0.8As-GaAs fin-array tunnel diodes exhibit a maximum room-temperature peak-to-valley current ratio of 5.4, and negative differential resistance characteristics up to 200 °C.","Silicon,
Gallium arsenide,
Substrates,
Indium gallium arsenide,
Charge carrier processes,
Light emitting diodes"
On the Asymptotic Capacity of Dual-Aperture FSO Systems With Generalized Pointing Error Model,"Free-space optical (FSO) communication systems are negatively affected by two physical phenomenon, namely, scintillation due to atmospheric turbulence and pointing errors. To quantify the effect of these two factors on FSO system performance, we need an effective mathematical model for them. In this paper, we propose and study a generalized pointing error model based on the Beckmann distribution. We then derive a generic expression of the asymptotic capacity of FSO systems under the joint impact of turbulence and generalized pointing error impairments. Finally, the asymptotic channel capacity formula is extended to quantify the FSO systems performance with selection and switched-and-stay diversity.","Laser beams,
Adaptive optics,
Optical refraction,
Atmospheric modeling,
Optical transmitters,
Optical variables control,
Signal to noise ratio"
Online Ensemble Learning of Data Streams with Gradually Evolved Classes,"Class evolution, the phenomenon of class emergence and disappearance, is an important research topic for data stream mining. All previous studies implicitly regard class evolution as a transient change, which is not true for many real-world problems. This paper concerns the scenario where classes emerge or disappear gradually. A class-based ensemble approach, namely Class-Based ensemble for Class Evolution (CBCE), is proposed. By maintaining a base learner for each class and dynamically updating the base learners with new data, CBCE can rapidly adjust to class evolution. A novel under-sampling method for the base learners is also proposed to handle the dynamic class-imbalance problem caused by the gradual evolution of classes. Empirical studies demonstrate the effectiveness of CBCE in various class evolution scenarios in comparison to existing class evolution adaptation methods.","Data mining,
Adaptation models,
Data models,
Transient analysis,
Sun,
Probability distribution,
Computer science"
Migration Towards Cloud-Assisted Live Media Streaming,"Live media streaming has become one of the most popular applications over the Internet. We have witnessed the successful deployment of commercial systems with content delivery network (CDN)- or peer-to-peer-based engines. While each being effective in certain aspects, having an all-round scalable, reliable, responsive, and cost-effective solution remains an illusive goal. Moreover, today's live streaming services have become highly globalized, with subscribers from all over the world. Such a globalization makes user behaviors and demands even more diverse and dynamic, further challenging state-of-the-art system designs. The emergence of cloud computing, however, sheds new light into this dilemma. Leveraging the elastic resource provisioning from the cloud, we present Cloud-Assisted Live Media Streaming (CALMS), a generic framework that facilitates a migration to the cloud. CALMS adaptively leases and adjusts cloud server resources in a fine granularity to accommodate temporal and spatial dynamics of demands from live streaming users. We present optimal solutions to deal with cloud servers with diverse capacities and lease prices, as well as the potential latencies in initiating and terminating leases in real-world cloud platforms. Our solution well accommodates location heterogeneity, mitigating the impact from user globalization. It also enables seamless migration for existing streaming systems, e.g., peer-to-peer, and fully explores their potentials. Simulations with data traces from both cloud service providers (Amazon EC2 and SpotCloud) and a live streaming service provider (PPTV) demonstrate that CALMS effectively mitigates the overall system deployment costs and yet provides users with satisfactory streaming latency and rate.","Servers,
Streaming media,
Schedules,
Organizations,
Bandwidth,
Peer-to-peer computing,
Educational institutions"
The Capacity of String-Duplication Systems,"It is known that the majority of the human genome consists of duplicated sequences. Furthermore, it is believed that a significant part of the rest of the genome also originated from duplicated sequences and has mutated to its current form. In this paper, we investigate the possibility of constructing an exponentially large number of sequences from a short initial sequence using simple duplication rules, including those resembling genomic-duplication processes. In other words, our goal is to find the capacity, or the expressive power, of these string-duplication systems. Our results include exact capacities, and bounds on the capacities, of four fundamental string-duplication systems. The study of these fundamental biologically inspired systems is an important step toward modeling and analyzing more complex biological processes.","Genomics,
Bioinformatics,
DNA,
Biological information theory,
Formal languages,
Context modeling,
Electronic mail"
An Energy-Efficient Region-Based RPL Routing Protocol for Low-Power and Lossy Networks,"Routing plays an important role in the overall architecture of the Internet of Things. IETF has standardized the RPL routing protocol to provide the interoperability for low-power and lossy networks (LLNs). LLNs cover a wide scope of applications, such as building automation, industrial control, healthcare, and so on. LLNs applications require reliable and energy-efficient routing support. Point-to-point (P2P) communication is a fundamental requirement of many LLNs applications. However, traditional routing protocols usually propagate throughout the whole network to discover a reliable P2P route, which requires large amount energy consumption. Again, it is challenging to achieve both reliability and energy-efficiency simultaneously, especially for LLNs. In this paper, we propose a novel energy-efficient region-based routing protocol (ER-RPL), which achieves energy-efficient data delivery without compromising reliability. In contrast of traditional routing protocols where all nodes are required for route discovery, the proposed scheme only requires a subset of nodes to do the job, which is the key of energy saving. Our theoretical analysis and extensive simulation studies demonstrate that ER-RPL has a great performance superiority over two conventional benchmark protocols, i.e., RPL and P2P-RPL.",
"A Unified Evolutionary Optimization Procedure for Single, Multiple, and Many Objectives","Traditionally, evolutionary algorithms (EAs) have been systematically developed to solve mono-, multi-, and many-objective optimization problems, in this order. Despite some efforts in unifying different types of mono-objective evolutionary and non-EAs, researchers are not interested enough in unifying all three types of optimization problems together. Such a unified algorithm will allow users to work with a single software enabling one-time implementation of solution representation, operators, objectives, and constraints formulations across several objective dimensions. For the first time, we propose a unified evolutionary optimization algorithm for solving all three classes of problems specified above, based on the recently proposed elitist, guided nondominated sorting procedure, developed for solving many-objectives problems. Using a new niching-based selection procedure, our proposed unified algorithm automatically degenerates to an efficient equivalent population-based algorithm for each class. No extra parameters are needed. Extensive simulations are performed on unconstrained and constrained test problems having single-, two-, multi-, and many-objectives and on two engineering optimization design problems. Performance of the unified approach is compared to suitable population-based counterparts at each dimensional level. Results amply demonstrate the merit of our proposed unified approach and motivate similar studies for a richer understanding of the development of optimization algorithms.","Optimization,
Sociology,
Statistics,
Software algorithms,
Software,
Algorithm design and analysis,
Heuristic algorithms"
Community-Based Weighted Graph Model for Valence-Arousal Prediction of Affective Words,"Compared to the categorical approach that represents affective states as several discrete classes (e.g., positive and negative), the dimensional approach represents affective states as continuous numerical values in multiple dimensions, such as the valence-arousal (VA) space, thus allowing for more fine-grained sentiment analysis. In building dimensional sentiment applications, affective lexicons with VA ratings are useful resources but are still very rare. Several semi-supervised methods such as the kernel method, linear regression, and the pagerank algorithm have been investigated to automatically determine the VA ratings of affective words from a set of semantically similar seed words. These methods suffer from two major limitations. First, they apply an equal weight to all seeds similar to an unseen word in predicting its VA ratings. Second, even similar seeds may have quite different ratings (or an inverse polarity) of valence/arousal to the unseen word, thus reducing prediction performance. To overcome these limitations, this study proposes a community-based weighted graph model that can select seeds which are both similar to and have similar ratings (or the same polarity) with each unseen word to form a community (subgraph) so that its VA ratings can be estimated from such high-quality seeds using a weighted propagation scheme. That is, seeds more similar to unseen words contribute more to the estimation process. Experimental results show that the proposed method yields better prediction performance for both English and Chinese datasets.","Sentiment analysis,
Linear regression,
IEEE transactions,
Speech,
Speech processing,
Kernel,
Noise measurement"
Emergence of Consensus in a Multi-Robot Network: From Abstract Models to Empirical Validation,"Consensus dynamics in decentralised multiagent systems are subject to intense studies, and several different models have been proposed and analyzed. Among these, the naming game stands out for its simplicity and applicability to a wide range of phenomena and applications, from semiotics to engineering. Despite the wide range of studies available, the implementation of theoretical models in real distributed systems is not always straightforward, as the physical platform imposes several constraints that may have a bearing on the consensus dynamics. In this letter, we investigate the effects of an implementation of the naming game for the kilobot robotic platform, in which we consider concurrent execution of games and physical interferences. Consensus dynamics are analyzed in the light of the continuously evolving communication network created by the robots, highlighting how the different regimes crucially depend on the robot density and on their ability to spread widely in the experimental arena. We find that physical interferences reduce the benefits resulting from robot mobility in terms of consensus time, but also result in lower cognitive load for individual agents.",
Outdoor FSO Communications Under Fog: Attenuation Modeling and Performance Evaluation,"Free space optics (FSO) is a candidate technology for backhauling next generation 5G/6G networks. Fog strongly deteriorates the performance of FSO channels. However its modeling is still in its infancy. We contribute to the development of accurate deterministic and statistical channel models for fog attenuation prediction. The system performance is investigated as a function of the visibility range, BER, and channel capacity.","Attenuation,
Channel capacity,
Bit error rate,
Predictive models,
Wavelength measurement,
Data models"
Design and Implementation of a GPON-Based Virtual OpenFlow-Enabled SDN Switch,"Passive optical networks (PON) have become a promising solution for accessing networks because of the advantages they offer, such as high efficiency, security, and cost reduction. However, network management in PON is not yet automated and needs network operator intervention. In recent years, software-defined networking (SDN) has become an emerging technology. Through the separation of control and data plane in SDN switches, SDN provides dynamically fine-grained traffic control that enhances total network controllability and manageability. In this paper, we leverage the benefits of gigabit-capable passive optical network (GPON), while enhancing its capabilities on traffic management to the same level as an SDN switch. More specifically, we abstract the underlying physical GPON into an OpenFlow-enabled virtual SDN switch. The virtual switch can be used to connect multiple sites in widespread geographic locations. Similar to a real OpenFlow switch, a GPON virtual switch can be controlled by a standard OpenFlow controller. In our design, an embedded OpenFlow agent resides in the optical line termination (OLT) of the underlying GPON. The agent communicates with the external OpenFlow controller and simultaneously uses optical network unit management and control interface inside the OLT to manage ONUs. We created a prototype system based on a commodity GPON network. In the virtual switch, we implemented all the OpenFlow functions, including packet forwarding, bandwidth metering, statistical data collection, and status reporting. The experimental results show that the GPON virtual switch can correctly perform all the functions defined in the OpenFlow 1.3 specification. Its performance on flow entry modification time, dynamic bandwidth control, and switch status monitoring are comparable to the performance of a real OpenFlow switch.","Optical switches,
Optical network units,
Passive optical networks,
Ports (Computers),
Bandwidth"
Energy-Efficient In-Memory Paging for Smartphones,"Smartphones are becoming increasingly energy-hungry to support feature-rich applications, posing a lot of pressure on battery lifetime and making energy consumption a non-negligible issue. In particular, dynamic random access memory (DRAM)-based main memory subsystem is a major contributor to the energy consumption of mobile devices. In this paper, we propose direct read (DR). Swap, an energy-efficient in-memory paging design to reduce energy consumption in smartphones. In DR. Swap, we adopt emerging energy-efficient nonvolatile memory (NVM) and use it as the swap area. Utilizing NVMs byte-addressability, we propose DR which guarantees zero memory copy for read-only requests when accessing a page in swap area. To better understand the energy consumption of swapping, we build an energy model to analyze the energy consumption of different paging architectures. We evaluate DR. Swap based on the Google Nexus 5 smartphone, experimental results show that our technique can reduce more than 50% energy consumption compared to DRAM backed swapping.","Smart phones,
Nonvolatile memory,
Random access memory,
Energy consumption,
Ash,
Memory management,
Phase change materials"
Diagnosis Code Assignment Using Sparsity-Based Disease Correlation Embedding,"With the latest developments in database technologies, it becomes easier to store the medical records of hospital patients from their first day of admission than was previously possible. In Intensive Care Units (ICU), modern medical information systems can record patient events in relational databases every second. Knowledge mining from these huge volumes of medical data is beneficial to both caregivers and patients. Given a set of electronic patient records, a system that effectively assigns the disease labels can facilitate medical database management and also benefit other researchers, e.g., pathologists. In this paper, we have proposed a framework to achieve that goal. Medical chart and note data of a patient are used to extract distinctive features. To encode patient features, we apply a Bag-of-Words encoding method for both chart and note data. We also propose a model that takes into account both global information and local correlations between diseases. Correlated diseases are characterized by a graph structure that is embedded in our sparsity-based framework. Our algorithm captures the disease relevance when labeling disease codes rather than making individual decision with respect to a specific disease. At the same time, the global optimal values are guaranteed by our proposed convex objective function. Extensive experiments have been conducted on a real-world large-scale ICU database. The evaluation results demonstrate that our method improves multi-label classification results by successfully incorporating disease correlations.",
On Secure Wireless Communications for IoT Under Eavesdropper Collusion,"Wireless communication is one of the key technologies that actualize the Internet of Things (IoT) concept into the real world. Understanding the security performance of wireless communications lays the foundation for the security management of IoT. Eavesdropper collusion represents a significant threat to wireless communication security, while physical-layer security serves as a promising approach to providing a strong form of security guarantee. This paper studies the important secrecy outage performance of wireless communications under eavesdropper collusion, where the physical layer security is adopted to counteract such attack. Based on the classical Probability Theory, we first conduct analysis on the secrecy outage of the simple noncolluding case in which eavesdroppers do not collude and operate independently. For the secrecy outage analysis of the more hazardous M-colluding scenario, where any M eavesdroppers can combine their observations to decode the message, the techniques of Laplace transform, keyhole contour integral, and Cauchy Integral Theorem are jointly adopted to work around the highly cumbersome multifold convolution problem involved in such analysis, such that the related signal-to-interference ratio modeling for all colluding eavesdroppers can be conducted and thus the corresponding secrecy outage probability can be analytically determined. Finally, simulation and numerical results are provided to illustrate our theoretical achievements. An interesting observation suggests that the SOP increases first superlinearly and then sublinearly with M.","Security,
Wireless communication,
Wireless sensor networks,
Communication system security,
Data collection,
Relays,
Sensors"
Rapid Multiobjective Antenna Design Using Point-By-Point Pareto Set Identification and Local Surrogate Models,"Antenna design is inherently a multicriterial problem. Determination of the best possible tradeoffs between conflicting objectives (a so-called Pareto front), such as reflection response, gain, and antenna size, is indispensable from the designer's point of view, yet challenging when high-fidelity electromagnetic (EM) simulations are utilized for performance evaluation. Here, a novel and computationally efficient methodology for multiobjective optimization of antenna structures is presented. In our approach, the tradeoff designs are obtained by moving along the Pareto front and identifying the subsequent Pareto-optimal solutions using surrogate-based optimization techniques. Computational efficiency of the process is achieved by employing coarse-discretization EM simulations and local response surface approximation (RSA) models. The proposed approach is demonstrated using a compact ultrawideband (UWB) monopole antenna with a representation of the Pareto front obtained at the cost corresponding to just a few dozen of evaluations of the high-fidelity EM antenna model. Experimental validation is also provided.","Optimization,
Computational modeling,
Reflection,
Reflector antennas,
Algorithm design and analysis,
Solid modeling"
Blind Image Deconvolution by Automatic Gradient Activation,"Blind image deconvolution is an ill-posed inverse problem which is often addressed through the application of appropriate prior. Although some priors are informative in general, many images do not strictly conform to this, leading to degraded performance in the kernel estimation. More critically, real images may be contaminated by nonuniform noise such as saturation and outliers. Methods for removing specific image areas based on some priors have been proposed, but they operate either manually or by defining fixed criteria. We show here that a subset of the image gradients are adequate to estimate the blur kernel robustly, no matter the gradient image is sparse or not. We thus introduce a gradient activation method to automatically select a subset of gradients of the latent image in a cutting-plane-based optimization scheme for kernel estimation. No extra assumption is used in our model, which greatly improves the accuracy and flexibility. More importantly, the proposed method affords great convenience for handling noise and outliers. Experiments on both synthetic data and real-world images demonstrate the effectiveness and robustness of the proposed method in comparison with the state-of-the-art methods.","Kernel,
Estimation,
Image edge detection,
Convolution,
Deconvolution,
Computer science,
Robustness"
Printable hydraulics: A method for fabricating robots by 3D co-printing solids and liquids,"This paper introduces a novel technique for fabricating functional robots using 3D printers. Simultaneously depositing photopolymers and a non-curing liquid allows complex, pre-filled fluidic channels to be fabricated. This new printing capability enables complex hydraulically actuated robots and robotic components to be automatically built, with no assembly required. The technique is showcased by printing linear bellows actuators, gear pumps, soft grippers and a hexapod robot, using a commercially-available 3D printer. We detail the steps required to modify the printer and describe the design constraints imposed by this new fabrication approach.","Liquids,
Robots,
Printers,
Solid modeling,
Solids"
Isosurface Visualization of Data with Nonparametric Models for Uncertainty,"The problem of isosurface extraction in uncertain data is an important research problem and may be approached in two ways. One can extract statistics (e.g., mean) from uncertain data points and visualize the extracted field. Alternatively, data uncertainty, characterized by probability distributions, can be propagated through the isosurface extraction process. We analyze the impact of data uncertainty on topology and geometry extraction algorithms. A novel, edge-crossing probability based approach is proposed to predict underlying isosurface topology for uncertain data. We derive a probabilistic version of the midpoint decider that resolves ambiguities that arise in identifying topological configurations. Moreover, the probability density function characterizing positional uncertainty in isosurfaces is derived analytically for a broad class of nonparametric distributions. This analytic characterization can be used for efficient closed-form computation of the expected value and variation in geometry. Our experiments show the computational advantages of our analytic approach over Monte-Carlo sampling for characterizing positional uncertainty. We also show the advantage of modeling underlying error densities in a nonparametric statistical framework as opposed to a parametric statistical framework through our experiments on ensemble datasets and uncertain scalar fields.","Uncertainty,
Kernel,
Isosurfaces,
Random variables,
Joints,
Polynomials"
SecureFind: Secure and Privacy-Preserving Object Finding via Mobile Crowdsourcing,"The plummeting cost of Bluetooth tags and the ubiquity of mobile devices are revolutionizing the traditional lost-and-found service. This paper presents SecureFind, a secure and privacy-preserving object-finding system via mobile crowdsourcing. In SecureFind, a unique Bluetooth tag is attached to every valuable object, and the owner of a lost object submits an object-finding request to many mobile users via the SecureFind service provider. Each mobile user involved searches his vicinity for the lost object on behalf of the object owner who can infer the location of his lost object based on the responses from mobile users. SecureFind is designed to ensure strong object security such that only the object owner can discover the location of his lost object as well as offering location privacy to mobile users involved. The high efficacy and efficiency of SecureFind are confirmed by extensive simulations.","Detectors,
Mobile communication,
Bluetooth,
Privacy,
Crowdsourcing,
Security,
Mobile handsets"
Dual-Polarized Filtering Antenna With High Selectivity and Low Cross Polarization,"This paper presents a dual-polarized patch antenna with quasi-elliptic bandpass responses. The proposed antenna is mainly composed of a feeding network, a driven patch, and a stacked patch, with its entire height being 0.09λ. The feeding network consists of two orthogonal H-shaped lines that coupled to the driven patch, each for one polarization. The elaborately designed feeding lines not only ensure a sharp roll-off rate at the lower band edge, but also help to achieve low cross polarization and high isolation between two feeding ports. On the other hand, the upper stacked patch provides improved suppression levels at the upper stopband and also an enhanced gain within passband. Consequently, a compact dual-polarized antenna with satisfying filtering performance is obtained, without using extra filtering circuits. For demonstration, an antenna is designed to fit the specification of LTE band (2.49-2.69 GHz). The implemented antenna achieves an average a gain of 9 dBi, a cross-polarization ratio of 29 dB, an isolation of 35 dB within LTE band. The out-of-band suppression level is more than 40 dB within the 2G and 3G frequency bands from 1.71-2.17 GHz. It can be used as the antenna elements in multiband base station antenna arrays to reduce the mutual coupling.",
Global Stability Analysis Using the Eigenfunctions of the Koopman Operator,"We propose a novel operator-theoretic framework to study global stability of nonlinear systems. Based on the spectral properties of the so-called Koopman operator, our approach can be regarded as a natural extension of classic linear stability analysis to nonlinear systems. The main results establish the (necessary and sufficient) relationship between the existence of specific eigenfunctions of the Koopman operator and the global stability property of hyperbolic fixed points and limit cycles. These results are complemented with numerical methods which are used to estimate the region of attraction of the fixed point or to prove in a systematic way global stability of the attractor within a given region of the state space.","Stability analysis,
Numerical stability,
Asymptotic stability,
Eigenvalues and eigenfunctions,
Nonlinear systems,
Trajectory,
Limit-cycles"
Global Coverage Maximization in PTZ-Camera Networks Based on Visual Quality Assessment,"In this paper, we propose a novel method to automatically configure a pan-tilt-zoom camera network in order to maximize coverage and visual quality in complex indoor environments. Based on a suitable modeling of cameras and environment, the optimization procedure determines the most appropriate camera position and settings to fulfill a given coverage objective. To achieve this goal, we use a particle swarm optimizer with an appropriate fitness function that takes into account a number of concurrent metrics and constraints. Furthermore, the solution is found working into a simulated environment obtained with the ray-tracing software. The proposed solution has been tested in various synthetic and real environments, taking into account the presence of obstacles and other constraints. We also simulated dynamic situations, such as cameras failures, to test the capability of fast camera network reconfiguration. For the performance evaluation, and in addition to the simulation in virtual scenes, we have also conducted a validation phase in real-world scenarios, where we assessed how the introduction on the optimal configuration improves the solution of some typical computer vision tasks.",
A Dielectric Rod Antenna for Picosecond Pulse Stimulation of Neurological Tissue,"A dielectrically loaded wideband rod antenna has been studied as a pulse delivery system to subcutaneous tissues. Simulation results applying 100-ps electrical pulse show that it allows us to generate a critical electric field for biological effects, such as brain stimulation, in the range of several centimeters. In order to reach the critical electric field for biological effects, which is ~20 kV/cm, at a depth of 2 cm, the input voltage needs to be 175 kV. The electric field spot size in the brain at this position is ~1 cm2. Experimental studies in free space with a conical antenna (part of the antenna system) with aluminum nitride as the dielectric have confirmed the accuracy of the simulation. These results set the foundation for high-voltage in situ experiments on the complete antenna system and the delivery of pulses to a biological tissue.","Dielectrics,
Electromagnetic waveguides,
Loaded antennas,
Wideband,
Biology,
Aluminum nitride"
Privacy-Preserving and Regular Language Search Over Encrypted Cloud Data,"Using cloud-based storage service, users can remotely store their data to clouds but also enjoy the high quality data retrieval services, without the tedious and cumbersome local data storage and maintenance. However, the sole storage service cannot satisfy all desirable requirements of users. Over the last decade, privacy-preserving search over encrypted cloud data has been a meaningful and practical research topic for outsourced data security. The fact of remote cloud storage service that users cannot have full physical possession of their data makes the privacy data search a formidable mission. A naive solution is to delegate a trusted party to access the stored data and fulfill a search task. This, nevertheless, does not scale well in practice as the fully data access may easily yield harm for user privacy. To securely introduce an effective solution, we should guarantee the privacy of search contents, i.e., what a user wants to search, and return results, i.e., what a server returns to the user. Furthermore, we also need to guarantee privacy for the outsourced data, and bring no additional local search burden to user. In this paper, we design a novel privacy-preserving functional encryption-based search mechanism over encrypted cloud data. A major advantage of our new primitive compared with the existing public key based search systems is that it supports an extreme expressive search mode, regular language search. Our security and performance analysis show that the proposed system is provably secure and more efficient than some searchable systems with high expressiveness.","Servers,
Encryption,
Cloud computing,
Keyword search,
Indexes,
Receivers"
One Integrated Energy Efficiency Proposal for 5G IoT Communications,"To further enhance the energy efficiency (EE) performance of fifth generation (5G) Internet of Things systems, an integrated structure is proposed in this paper. That is, other than prior studies that separately study the wireless and wired parts, the wireless and wired parts are holistically combined together to comprehensively optimize the EE of the whole system. The integrated system structure is introduced beforehand with the proposed unified control center components for better deployment of the select-and-sleep mechanism. In addition, in the wireless part, one cellular partition zooming (CPZ) mechanism is proposed. In contrast, in the wired part, a precaching mechanism is introduced. With these proposals, the proposed system EE performance is investigated. Comprehensive computer-based simulation results demonstrate that the proposed schemes display better EE performance. This is due to the fact that system power consumption is further reduced with these schemes as compared to the prior work.",
Bandwidth-Efficient Packet Scheduling for Live Streaming With Network Coding,"Network coding (NC) brings substantial improvements in terms of throughput and delay in collaborative media streaming applications. A key aspect of NC-driven live peer-to-peer streaming is the packet scheduling policy. Indeed, lack of synchronization among peers usually results in significantly redundant packet transmission, which in turn leads to severe bandwidth inefficiencies. In this paper, we address the problem of finding a suitable asynchronous packet scheduling policy that greatly helps to overcome this critical redundant transmission problem. We propose a bandwidth cost minimization technique under a full video packet recovery constraint. In order to add scalability and improved performance, we also further derive a distributed packet scheduling algorithm. Both implementation and analytical considerations of the proposed approaches are described in this paper. Experimental results confirm that the proposed algorithms deliver higher bandwidth efficiency with reduced redundancy and communication overhead rate and, consequently, better quality-of-service in terms of improved video quality and delivery ratio.","Peer-to-peer computing,
Bandwidth,
Scheduling algorithms,
Streaming media,
Network coding,
Receivers,
Delays"
Power-Efficient Protection With Directed p -Cycles for Asymmetric Traffic in Elastic Optical Networks,"In this paper, we investigate power-efficient directed preconfigured cycles (p-Cycles) for asymmetric traffic protection in elastic optical networks (EONs) against single link failure. Owing to the advantage of distinguishing traffic amount in two directions, directed p-cycles consume low power by allocating different spectrum slots and modulation formats for each direction. A mixed integer linear programming (MILP) model is formulated to minimize total power consumption, which takes into account directed cycle generation, spectrum allocation, modulation adaptation, and protection capacity. To increase the scalability, the MILP model is decomposed, and a two-step approach is proposed: improved cycle enumeration and a simplified integer linear programming model. Extensive simulations are performed to study the power consumption of p-cycles under different traffic patterns in terms of traffic asymmetry (TASY), anycast ratio (AR), and the number of data centers (DCs). The results strongly demonstrate that directed p-cycles obtain significant power savings for protecting asymmetric traffic in EONs. The power savings rise up to 46.91% and 36.38% compared with undirected p-cycles as the TASY and AR increase, respectively. Moreover, the directed p-cycles achieve valuable power savings (up to 46.1%) with the introduction of DCs while the amount of power savings does not depend on the number of DCs.","Adaptation models,
Optical fiber networks,
Resource management,
Modulation,
Power demand,
Routing"
A Mobile Data Gathering Framework for Wireless Rechargeable Sensor Networks with Vehicle Movement Costs and Capacity Constraints,"Several recent works have studied mobile vehicle scheduling to recharge sensor nodes via wireless energy transfer technologies. Unfortunately, most of them overlooked important factors of the vehicles' moving energy consumption and limited recharging capacity, which may lead to problematic schedules or even stranded vehicles. In this paper, we consider the recharge scheduling problem under such important constraints. To balance energy consumption and latency, we employ one dedicated data gathering vehicle and multiple charging vehicles. We first organize sensors into clusters for easy data collection, and obtain theoretical bounds on latency. Then we establish a mathematical model for the relationship between energy consumption and replenishment, and obtain the minimum number of charging vehicles needed. We formulate the scheduling into a Profitable Traveling Salesmen Problem that maximizes profit - the amount of replenished energy less the cost of vehicle movements, and prove it is NP-hard. We devise and compare two algorithms: a greedy one that maximizes the profit at each step; an adaptive one that partitions the network and forms Capacitated Minimum Spanning Trees per partition. Through extensive evaluations, we find that the adaptive algorithm can keep the number of nonfunctional nodes at zero. It also reduces transient energy depletion by 30-50 percent and saves 10-20 percent energy. Comparisons with other common data gathering methods show that we can save 30 percent energy and reduce latency by two orders of magnitude.","Vehicles,
Batteries,
Mobile communication,
Energy consumption,
Base stations,
Sensors,
Inductive charging"
Multiactuator Haptic Feedback on the Wrist for Needle Steering Guidance in Brachytherapy,"Brachytherapy is a cancer treatment procedure where long needles are inserted toward an inner body target in order to deliver radioactive seeds that treat the cancer cells. Controlling the trajectory of the needle is very challenging as it deviates from a straight path during insertion. In this letter, we present the pilot study of usefulness of a wristband with haptic feedback designed to help surgeons guide the needle toward a desired destination. The wristband embeds eight miniature actuators distributed around the wrist. The actuators are controlled to generate different haptic stimuli, each of which informs the user about a necessary needle steering manoeuvre. We describe the design of the wristband and its evaluation in two distinct user studies. In the first study, we evaluate how accurately users can identify the vibration patterns. In the second study, we focus on how the user responds to these patterns while performing needle insertion into tissue in an environment with high cognitive visual load. The reported average success rate in identifying the haptic pattern and the success rate in performing the correct action during needle insertion are 86% and 72%, respectively. These results suggest that the device could work in tandem with a needle steering algorithm to help surgeons achieve high quality implants and develop needle steering skills.","Needles,
Surgery,
Haptic interfaces,
Brachytherapy,
Visualization,
Actuators,
Wrist"
Downlink Traffic Scheduling for LTE-A Small Cell Networks With Dual Connectivity Enhancement,"Small cells are a promising solution to increase the network capacity and to offload network traffic for LTE-A networks. In an LTE-A small cell network, there is one macro eNB (MeNB) and several slave eNBs (SeNBs). Recently, the dual connectivity technology is proposed for enhancing LTE-A small cell networks. For a user equipment (UE) that has dual connectivity, the MeNB can split the UE's downlink traffic and enable this UE to receive its downlink data from the MeNB and an SeNB simultaneously. In this work, we propose a downlink traffic scheduling (DTS) scheme for the MeNB to arrange the data rate of downlink traffic splitting to SeNBs for UEs that have dual connectivity. Simulation results indicate that the proposed scheme can effectively increase the network throughput for LTE-A small cell networks with dual connectivity enhancement.",
Daytime Preceding Vehicle Brake Light Detection Using Monocular Vision,"Advanced vehicle safety is a recently emerging issue appealed from the explosive population of car owners. Increasing driver assistance systems have been developed for warning drivers of potential hazards by analyzing the surroundings with sensors and/or cameras. Issuing vehicle deceleration and potential collision, brake lights are particularly important warning signals, allowing of no neglect. In this paper, we propose a vision-based daytime brake light detection system using a driving video recorder, which tends to be widespread used. At daytime, visual features, motions, and appearances of vehicles are highly visible. However, brake lights, on the contrary, are hard to notice due to low contrast between the brakes lights and environments. Without the significant characteristic of light scattering as at night, the proposed system extracts preceding vehicles with taillight symmetry verification, and then integrates both luminance and radial symmetry features to detect brake lights. A detection refinement process using temporal information is also employed for miss recovery. Experiments are conducted on a test data set collected by front-mounted driving video recorders, and the results verify that the proposed system can effectively detect brake lights at daytime, showing its good feasibility in real-world environments.","Vehicles,
Image color analysis,
Feature extraction,
Shape,
Sensors,
Light scattering"
Software Defined Networking With Pseudonym Systems for Secure Vehicular Clouds,"The vehicular cloud is a promising new paradigm, where vehicular networking and mobile cloud computing are elaborately integrated to enhance the quality of vehicular information services. Pseudonym is a resource for vehicles to protect their location privacy, which should be efficiently utilized to secure vehicular clouds. However, only a few existing architectures of pseudonym systems take flexibility and efficiency into consideration, thus leading to potential threats to location privacy. In this paper, we exploit software-defined networking technology to significantly extend the flexibility and programmability for pseudonym management in vehicular clouds. We propose a software-defined pseudonym system, where the distributed pseudonym pools are promptly scheduled and elastically managed in a hierarchical manner. In order to decrease the system overhead due to the cost of inter-pool communications, we leverage the two-sided matching theory to formulate and solve the pseudonym resource scheduling. We conducted extensive simulations based on the real map of San Francisco. Numerical results indicate that the proposed software-defined pseudonym system significantly improves the pseudonym resource utilization, and meanwhile, effectively enhances the vehicles' location privacy by raising their entropy.","Cloud computing,
Privacy,
Delays,
Resource management,
Vehicular ad hoc networks,
Cryptography,
Computer security,
Intelligent vehicles"
The Voltage Boost Enabled by Luminescence Extraction in Solar Cells,"Over the past few years, the application of the physical principle, i.e., “luminescence extraction,” has produced record voltages and efficiencies in photovoltaic cells. Luminescence extraction is the use of optical design, such as a back mirror or textured surfaces, to help internal photons escape out of the front surface of a solar cell. The principle of luminescence extraction is exemplified by the mantra “a good solar cell should also be a good LED.” Basic thermodynamics says that the voltage boost should be related to concentration ratio C of a resource by ΔV = (kT/q) ln{C }. In light trapping (i.e., when the solar cell is textured and has a perfect back mirror), the concentration ratio of photons C = {4n2}; therefore, one would expect a voltage boost of ΔV = (kT/q) ln{4n2 } over a solar cell with no texture and zero back reflectivity, where n is the refractive index. Nevertheless, there has been ambiguity over the voltage benefit to be expected from perfect luminescence extraction. Do we gain an open-circuit voltage boost of ΔV = (kT/q ) ln{n2}, ΔV = (kT/q) ln{2 n2}, or ΔV = (kT/q) ln{4 n2}? What is responsible for this voltage ambiguity ΔV = (kT/q) ln{4}≍36 mV? We show that different results come about, depending on whether the photovoltaic cell is optically thin or thick to its internal luminescence. In realistic intermediate cases of optical thickness, the voltage boost falls in between: ln{n2 } < (qΔV/kT) < ln{4n 2}.",
Broadband High-Gain SIW Cavity-Backed Circular-Polarized Array Antenna,"A circularly polarized (CP) 4 × 4 array antenna based on substrate integrated waveguide (SIW) technology is presented. Circular polarization is achieved by applying the sequential rotation technique (SRT) with a well-designed sequential feed network and linear-polarized array elements. The proposed 4 × 4 array has a wide axial ratio (AR) bandwidth of 14% from 18.3 to 21.1 GHz with gain >13 dBic. Then, the array is expanded to achieve higher gains. A 16 × 16-element array is designed, fabricated, and tested. Test results show that the 16 × 16 array has an AR bandwidth of 13.8% from 18.5 to 21.25 GHz and a peak gain of 25.9 dBic at 20.5 GHz.",
Enabling Privacy-Preserving Incentives for Mobile Crowd Sensing Systems,"Recent years have witnessed the proliferation of mobile crowd sensing (MCS) systems that leverage the public crowd equipped with various mobile devices (e.g., smartphones, smartglasses, smartwatches) for large scale sensing tasks. Because of the importance of incentivizing worker participation in such MCS systems, several auction-based incentive mechanisms have been proposed in past literature. However, these mechanisms fail to consider the preservation of workers' bid privacy. Therefore, different from prior work, we propose a differentially private incentive mechanism that preserves the privacy of each worker's bid against the other honest-but-curious workers. The motivation of this design comes from the concern that a worker's bid usually contains her private information that should not be disclosed. We design our incentive mechanism based on the single-minded reverse combinatorial auction. Specifically, we design a differentially private, approximately truthful, individual rational, and computationally efficient mechanism that approximately minimizes the platform's total payment with a guaranteed approximation ratio. The advantageous properties of the proposed mechanism are justified through not only rigorous theoretical analysis but also extensive simulations.","Privacy,
Mobile communication,
Mobile handsets,
Sensor systems,
Aggregates,
Computer science"
Fusion of Multispectral and Panchromatic Images Based on Morphological Operators,"Nonlinear decomposition schemes constitute an alternative to classical approaches for facing the problem of data fusion. In this paper, we discuss the application of this methodology to a popular remote sensing application called pansharpening, which consists in the fusion of a low resolution multispectral image and a high-resolution panchromatic image. We design a complete pansharpening scheme based on the use of morphological half gradient operators and demonstrate the suitability of this algorithm through the comparison with the state-of-the-art approaches. Four data sets acquired by the Pleiades, Worldview-2, Ikonos, and Geoeye-1 satellites are employed for the performance assessment, testifying the effectiveness of the proposed approach in producing top-class images with a setting independent of the specific sensor.","Spatial resolution,
Data integration,
Satellites,
Rendering (computer graphics),
Remote sensing,
Algorithm design and analysis"
"FinFET With High- \kappa
Spacers for Improved Drive Current","We demonstrate p-channel gate-source/drain underlapped silicon FinFET with HfO2 high-κ spacer and compare it with its counterpart having SiO2 low-κ spacer. The HfO2 spacer structure reduces series resistance in the underlap regions due to the large capacitive coupling between the gate and the underlap regions. Both drain current and transconductance of p-channel FinFET are higher than those of the SiO2 spacer device by about 3× when biased in the saturation region, and about 1.6× and 2×, respectively, when biased in the linear region. Subthreshold swing and drain-induced barrier lowering are also improved by incorporating the HfO2 spacer.","Logic gates,
FinFETs,
Hafnium compounds,
Transconductance,
Capacitance,
Silicon,
Performance evaluation"
Mobile Phone Computing and the Internet of Things: A Survey,"As the Internet of Things (IoT) and the Web of Things (WoT) are becoming a reality, their interconnection with mobile phone computing is increasing. Mobile phone integrated sensors offer advanced services, which when combined with Web-enabled real-world devices located near the mobile user (e.g., body area networks, radio-frequency identification tags, energy monitors, environmental sensors, etc.), have the potential of enhancing the overall user knowledge, perception and experience, encouraging more informed choices and better decisions. This paper serves as a survey of the most significant work performed in the area of mobile phone computing combined with the IoT/WoT. A selection of over 100 papers is presented, which constitute the most significant work in the field up to date, categorizing these papers into ten different domains, according to the area of application (i.e., health, sports, gaming, transportation, and agriculture), the nature of interaction (i.e., participatory sensing, eco-feedback, actuation, and control), or the communicating actors involved (i.e., things and people). Open issues and research challenges are identified, analyzed and discussed.","Sensors,
Mobile handsets,
Internet of things,
Mobile communication,
Mobile computing,
Mobile applications,
Monitoring"
Three-Phase Time-Multiplexed Planar Power Transmission to Distributed Implants,"A platform has been presented for wireless powering of receivers (Rx's) that are arbitrarily distributed over a large area. A potential application could be powering of small Rx implants, distributed over large areas of the brain. The transmitter (Tx) consists of three overlapping layers of hexagonal planar spiral coils (hex-PSC) that are horizontally shifted to provide the strongest and most homogeneous electromagnetic flux coverage. The three-layer hex-PSC array is driven by a three-phase time-division-multiplexed power Tx that takes the advantage of the carrier phase shift, coil geometries, and Rx time constant to homogeneously power the arbitrarily distributed Rx's regardless of their misalignments. The functionality of the proposed three-phase power transmission concept has been verified in a detailed scaled-up high-frequency structure simulator Advanced Design System simulation model and measurement setup, and compared with a conventional Tx. The new Tx delivers 5.4 mW to each Rx and achieves, on average, 5.8% power transfer efficiency to the Rx at the worst case 90° angular misalignment, compared with 1.4% by the conventional Tx.","Coils,
Arrays,
Time division multiplexing,
Magnetic fields,
Implants,
Receivers,
Wireless communication"
A Comparative Error Analysis of Current Time-of-Flight Sensors,"Time-of-flight (ToF) cameras suffer from systematic errors, which can be an issue in many application scenarios. In this paper, we investigate the error characteristics of eight different ToF cameras. Our survey covers both well established and recent cameras including the Microsoft Kinect V2. We present up to six experiments for each camera to quantify different types of errors. For each experiment, we outline the basic setup, present comparable data for each camera, and discuss the respective results. The results discussed in this paper enable the community to make appropriate decisions in choosing the best matching camera for a certain application. This work also lays the foundation for a framework to benchmark future ToF cameras. Furthermore, our results demonstrate the necessity for correcting characteristic measurement errors. We believe that the presented findings will allow 1) the development of novel correction methods for specific errors and 2) the development of general data processing algorithms that are able to robustly operate on a wider range of cameras and scenes.","Cameras,
Scattering,
Sensor phenomena and characterization,
Systematics,
Time measurement"
Impact on Power System Flexibility by Electric Vehicle Participation in Ramp Market,"This paper investigates electric vehicle (EV) participation in the flexible ramp market. We take into account EV stochastic mobility, and evaluate impact on power system reliability and flexibility. Based on dynamic programming, the model deals with uncertainties and variations of net load, as well as EV charging requirements. Markov process is utilized in estimating the aggregated power capacity of EVs. Two participation modes are analyzed: 1) EV direct provision of the ramp product; and 2) EV cooperation with the conventional generator. Moreover, we propose new indices to evaluate power system flexibility. Finally, numerical experiments are conducted to validate the proposed approach and illustrate how EV involvement into the ramp market can improve power system reliability and flexibility.","Generators,
Vehicles,
Power systems,
Batteries,
Mathematical model,
Markov processes"
Z-Impedance Compensation for Wireless Power Transfer Based on Electric Field,"Capacitive power transfer (CPT) has been investigated as an alternative wireless power transfer technology based on electric field coupling. The coupling interface of CPT is formed by a pair of “capacitors” in series with the power source and load. The effective capacitance ranges from tens to a few hundreds of picofarads, yielding high impedance. Therefore, in most CPT systems, a tuning inductor is connected in series with the coupling interface for circuit compensation and power transfer capability enhancement. However, this compensation method suffers from high voltage spikes from the inductor if the secondary side load is removed suddenly causing electrical and health hazards. To address the issue, this paper proposes a CPT system based on a Z-impedance compensation network with inherent open-circuit and short-circuit immunity. It also has the voltage boost capability as a Z-source inverter. Its operating principle is described and a set of design equations are given. Both simulations and experimental results from a 5 W low power design have demonstrated that the proposed compensation method using the Z-impedance matching network exhibited open-circuit and short-circuit immunity, could boost up the output voltage by 50% with power efficiency exceeding 80%.",
An Improved Capacitor Voltage-Balancing Method for Five-Level Diode-Clamped Converters With High Modulation Index and High Power Factor,"The capacitor voltage imbalance is a critical issue of five-level diode-clamped converters (5L-DCC). To address this issue, an inner-hexagon-vector-decomposition-based space-vector modulation (VDSVM-H1) approach is provided in the literature, which obtains the capacitor voltage balancing with high modulation index and high power factor, but renders some drawbacks. To overcome these shortcomings, a novel capacitor voltage balancing method is proposed here. First, the previous VDSVM-H1 approach is modified by introducing six new vector sequences to each triangle and applying a new vector selection rule such that the converter will not violate the 5L-DCC switching mechanism in all operating conditions. Second, the variation of the line-to-line voltage output in one sampling period is restricted to one- or two-level in the optimized region, instead of the three-level in the previous VDSVM-H1 approach, which means less harmonics generating in the ac-side outputs. Finally, the simulation and experimental results show that the proposed method can improve the VDSVM-H1 with convincing results.","Capacitors,
Switches,
Modulation,
Reactive power,
Discharges (electric),
Voltage control,
Indexes"
General Video Game for 2 players: Framework and competition,"This paper presents a new track of the General Video Game AI competition for generic Artificial Intelligence agents, which features both competitive and cooperative real time stochastic two player games. The aim of the competition is to directly test agents against each other in more complex and dynamic environments, where there is an extra uncertainty in a game, consisting of the behaviour of the other player. The framework, server functionality and general competition setup are analysed and the results of the experiments with several sample controllers are presented. The results indicate that currently Open Loop Monte Carlo Tree Search is the overall leading algorithm on this set of games.","Games,
Artificial intelligence,
Avatars,
Servers,
Computer science,
Real-time systems,
Training"
Compact and Bandwidth-Enhanced Asymmetric Coplanar Waveguide (ACPW) Antenna Using CRLH-TL and Modified Ground Plane,"A novel compact and broadband asymmetric coplanar wave guide (ACPW) antenna is presented. A method to extend the bandwidth of a metamaterial-inspired antenna based on a composite right/left-handed transmission line (CRLH-TL) and a modified ground plane is proposed. The ACPW antenna has a broadband characteristic by placing the zeroth-order resonance (ZOR), first-positive-order resonance (FPOR) of short-ended CRLH-TL and the modified ground plane's two resonances, which are half and one lambda resonances, at all different frequencies with proper frequency intervals. The prototype of the proposed antenna has been implemented and measured. The measured -10-dB fractional bandwidth is 109.1% (from 2.69 to 9.15 GHz) with high efficiency of over 65% and a low profile of 0.32λ0 × 0.19λ0 (where λ0 is the free-space wavelength at the first resonant frequency).","Resonant frequency,
Antenna measurements,
Bandwidth,
Broadband antennas,
Dispersion,
Coplanar waveguides"
Feedback Linearization for Nonlinear Systems With Time-Varying Input and Output Delays by Using High-Gain Predictors,"This note addresses the problem of feedback linearization for nonlinear systems with time-varying input and output delays. To solve the realization issue of future states, a high-gain-observer is constructed as a predictor. Then, the output feedback predictive control is presented. The stability of the closed-loop system is analyzed by using a Lyapunov-Krasovskii functional. It is demonstrated that by designing the observer gain high enough, the closed-loop system recovers the performance of state feedback control with no time delay. However, the gain of the observer is limited by the time delay. Finally, numerical simulations are given to illustrate the effectiveness of the proposed control.","Closed loop systems,
Observers,
Trajectory,
Delays,
Output feedback,
Nonlinear systems,
State feedback"
A Novel Approach to Multiple Sequence Alignment Using Multiobjective Evolutionary Algorithm Based on Decomposition,"Multiple sequence alignment (MSA) is a fundamental and key step for implementing other tasks in bioinformatics, such as phylogenetic analyses, identification of conserved motifs and domains, structure prediction, etc. Despite the fact that there are many methods to implement MSA, biologically perfect alignment approaches are not found hitherto. This paper proposes a novel idea to perform MSA, where MSA is treated as a multiobjective optimization problem. A famous multiobjective evolutionary algorithm framework based on decomposition is applied for solving MSA, named MOMSA. In the MOMSA algorithm, we develop a new population initialization method and a novel mutation operator. We compare the performance of MOMSA with several alignment methods based on evolutionary algorithms, including VDGA, GAPAM, and IMSA, and also with state-of-the-art progressive alignment approaches, such as MSAprobs, Probalign, MAFFT, Procons, Clustal omega, T-Coffee, Kalign2, MUSCLE, FSA, Dialign, PRANK, and CLUSTALW. These alignment algorithms are tested on benchmark datasets BAliBASE 2.0 and BAliBASE 3.0. Experimental results show that MOMSA can obtain the significantly better alignments than VDGA, GAPAM on the most of test cases by statistical analyses, produce better alignments than IMSA in terms of TC scores, and also indicate that MOMSA is comparable with the leading progressive alignment approaches in terms of quality of alignments.",
TMACS: A Robust and Verifiable Threshold Multi-Authority Access Control System in Public Cloud Storage,"Attribute-based Encryption (ABE) is regarded as a promising cryptographic conducting tool to guarantee data owners’ direct control over their data in public cloud storage. The earlier ABE schemes involve only one authority to maintain the whole attribute set, which can bring a single-point bottleneck on both security and performance. Subsequently, some multi-authority schemes are proposed, in which multiple authorities separately maintain disjoint attribute subsets. However, the single-point bottleneck problem remains unsolved. In this paper, from another perspective, we conduct a threshold multi-authority CP-ABE access control scheme for public cloud storage, named TMACS, in which multiple authorities jointly manage a uniform attribute set. In TMACS, taking advantage of (
t,n
) threshold secret sharing, the master key can be shared among multiple authorities, and a legal user can generate his/her secret key by interacting with any
t
authorities. Security and performance analysis results show that TMACS is not only verifiable secure when less than
t
authorities are compromised, but also robust when no less than
t
authorities are alive in the system. Furthermore, by efficiently combining the traditional multi-authority scheme with TMACS, we construct a hybrid one, which satisfies the scenario of attributes coming from different authorities as well as achieving security and system-level robustness.",
Modelling and design of a synergy-based actuator for a tendon-driven soft robotic glove,"The need for a means of assistance in human grasping, to compensate for weakness or to augment performance, is well documented. An appealing new way of doing so is through soft, wearable robots that work in parallel with the human muscles. In this paper we present the design and modelling of a tendon-driving unit that empowers a wearable, soft glove. Being portability one of our main objectives, we use only 1 motor to move 8 degrees of freedom of the hand. To achieve this we use an underactuation strategy based on the human hand's first postural synergy, which explains alone ≈60% of activities of daily living. The constrains imposed by the underactuation strategy are softened, to allow adaptability during grasping, by placing elastic elements in series with the tendons. A simulation of the dynamic behaviour of the glove on a human hand allows us to quantify the magnitude and distribution of the forces involved during usage. These results are used to guide design choices such as the power of the motor and the stiffness of the springs. The designed tendon-driving unit comprises a DC motor which drives an array of spools dimensioned according to the first postural synergy, an electromechanical clutch to hold the hand in position during static posture and a feeder mechanism to avoid slacking of the tendons around the spool. Finally, the tendon-driving unit is tested to verify that it satisfies motion and force characteristics required to assist its wearer in activities of daily living.","Tendons,
Force,
Actuators,
Grasping,
Couplings,
Torque,
Robots"
SALSA: A Novel Dataset for Multimodal Group Behavior Analysis,"Studying free-standing conversational groups (FCGs) in unstructured social settings (e.g., cocktail party) is gratifying due to the wealth of information available at the group (mining social networks) and individual (recognizing native behavioral and personality traits) levels. However, analyzing social scenes involving FCGs is also highly challenging due to the difficulty in extracting behavioral cues such as target locations, their speaking activity and head/body pose due to crowdedness and presence of extreme occlusions. To this end, we propose SALSA, a novel dataset facilitating multimodal and Synergetic sociAL Scene Analysis, and make two main contributions to research on automated social interaction analysis: (1) SALSA records social interactions among 18 participants in a natural, indoor environment for over 60 minutes, under the poster presentation and cocktail party contexts presenting difficulties in the form of low-resolution images, lighting variations, numerous occlusions, reverberations and interfering sound sources; (2) To alleviate these problems we facilitate multimodal analysis by recording the social interplay using four static surveillance cameras and sociometric badges worn by each participant, comprising the microphone, accelerometer, bluetooth and infrared sensors. In addition to raw data, we also provide annotations concerning individuals' personality as well as their position, head, body orientation and F-formation information over the entire event duration. Through extensive experiments with state-of-the-art approaches, we show (a) the limitations of current methods and (b) how the recorded multiple cues synergetically aid automatic analysis of social interactions. SALSA is available at http://tev.fbk.eu/salsa.",
Modular Multilevel Converter-Based Bipolar High-Voltage Pulse Generator With Sensorless Capacitor Voltage Balancing Technique,"In order to generate bipolar high-voltage (HV) pulses across certain load from HV dc (HVdc) power supply, a voltage source inverter (VSI) stage should be inserted between the load and the supply. In order to meet the required HV level, series connection of semiconductor devices should be employed with dynamic voltage sharing between the involved devices. Modular multilevel converter (MMC) can be used instead of the conventional two-level VSI to alleviate the complexity introduced by the deployment of series-connected devices. The voltage level of the HVdc power supply and the voltage rating of the available semiconductor devices determine the suitable number of MMC voltage levels (N). Capacitor voltage balancing is a vital issue for proper operation of the MMC. In general, conventional sensor-based balancing techniques require a significant amount of measurements, which increases the complexity of the system. In addition, the high dv/dt during switching times causes electromagnetic interference, which may adversely affect the accuracy of the measurements. In this paper, a sensorless voltage balancing technique is proposed for the MMC-based bipolar HV pulse generator that reduces the system sensitivity, cost, and complexity. A detailed illustration of the proposed approach is presented in this paper. The simulation and experimental results are used to validate the proposed concept.","Pulse generation,
Capacitors,
Complexity theory,
Switches,
HVDC transmission,
Semiconductor devices,
Electromagnetic interference"
On the Use of Knitted Antennas and Inductively Coupled RFID Tags for Wearable Applications,"Recent advancements in conductive yarns and fabrication technologies offer exciting opportunities to design and knit seamless garments equipped with sensors for biomedical applications. In this paper, we discuss the design and application of a wearable strain sensor, which can be used for biomedical monitoring such as contraction, respiration, or limb movements. The system takes advantage of the intensity variations of the backscattered power (RSSI) from an inductively-coupled RFID tag under physical stretching. First, we describe the antenna design along with the modeling of the sheet impedance, which characterizes the conductive textile. Experimental results with custom fabricated prototypes showed good agreement with the numerical simulation of input impedance and radiation pattern. Finally, the wearable sensor has been applied for infant breathing monitoring using a medical programmable mannequin. A machine learning technique has been developed and applied to post-process the RSSI data, and the results show that breathing and non-breathing patterns can be successfully classified.","Radiofrequency identification,
Biomedical monitoring,
Antennas,
RFID tags,
Textile technology,
Wearable sensors,
Biomedical communication"
Timed Consistent Network Updates in Software-Defined Networks,"Network updates, such as policy and routing changes, occur frequently in software-defined networks (SDNs). Updates should be performed consistently, preventing temporary disruptions, and should require as little overhead as possible. Scalability is increasingly becoming an essential requirement in SDNs. In this paper, we propose to use time-triggered network updates to achieve consistent updates. Our proposed solution requires lower overhead than the existing update approaches, without compromising the consistency during the update. We demonstrate that accurate time enables far more scalable consistent updates in the SDN than previously available. In addition, it provides the SDN programmer with fine-grained control over the tradeoff between consistency and scalability.",
Principle and Modeling of a Novel Moving Coil Linear-Rotary Electromagnetic Actuator,"This paper presents a novel electromagnetic actuator that adopts an air-core coil mover to deliver decoupled linear and rotary motions. It uses light-weight moving coil to achieve high speed and dynamic response, and single-phase Lorentz-force driving scheme to realize direct and noncommutation actuation. To overcome the low thrust force of such driving scheme, unique magnetic circuits are used to enhance the thrust force and torque of the proposed actuator. Closed-form analytical solutions for modeling the magnetic field within the coil operating regions of these unique magnetic circuits are presented together with the complete thermal analyses. A prototype was developed and it delivers 10 mm stroke and 90° angular displacement. Using commercially available drivers, it achieved a high throughput of 8000 units/h with 20 μm, and 0.66° tracking accuracy.","Magnetic circuits,
Magnetic separation,
Actuators,
Magnetization,
Force,
Magnetic noise,
Magnetic shielding"
Symbolic Models for Networks of Control Systems,"In this note, we propose symbolic models for networks of discrete-time nonlinear control systems. If each subsystem composing the network admits an incremental input-to-state stable Lyapunov function and if some small gain theorem-type conditions are satisfied, a network of symbolic models, each one associated with each subsystem composing the network, is proposed and shown to be approximately bisimilar to the original network with any desired accuracy.","Control systems,
Measurement,
Lyapunov methods,
Linear systems,
Complexity theory,
Linear matrix inequalities"
Decision Tree and SVM-Based Data Analytics for Theft Detection in Smart Grid,"Nontechnical losses, particularly due to electrical theft, have been a major concern in power system industries for a long time. Large-scale consumption of electricity in a fraudulent manner may imbalance the demand-supply gap to a great extent. Thus, there arises the need to develop a scheme that can detect these thefts precisely in the complex power networks. So, keeping focus on these points, this paper proposes a comprehensive top-down scheme based on decision tree (DT) and support vector machine (SVM). Unlike existing schemes, the proposed scheme is capable enough to precisely detect and locate real-time electricity theft at every level in power transmission and distribution (T&D). The proposed scheme is based on the combination of DT and SVM classifiers for rigorous analysis of gathered electricity consumption data. In other words, the proposed scheme can be viewed as a two-level data processing and analysis approach, since the data processed by DT are fed as an input to the SVM classifier. Furthermore, the obtained results indicate that the proposed scheme reduces false positives to a great extent and is practical enough to be implemented in real-time scenarios.","Support vector machines,
Real-time systems,
Inspection,
Security,
Smart meters,
Servers"
Distributed Maximal Clique Computation and Management,"Maximal cliques are elementary substructures in a graph and instrumental in graph analysis such as the structural analysis of many complex networks, graph clustering and community detection, network hierarchy detection, emerging pattern mining, vertex importance measures, etc. However, the number of maximal cliques is also notoriously large even for many small real world graphs. This size problem gives rise to challenges in both computing and managing the set of maximal cliques. Many algorithms for computing maximal cliques have been proposed in the literature; however, most of them are sequential algorithms that cannot scale due to the high complexity of the problem, while existing parallel algorithms for computing maximal cliques are mostly immature and especially suffer from skewed workload. As for managing the set of maximal cliques, which is essential due to its large size, there is barely any efficient method for querying or updating the set of maximal cliques. In this paper, we first propose a distributed algorithm built on a share-nothing architecture for computing the set of maximal cliques. We effectively address the problem of skewed workload distribution due to high-degree vertices, which also leads to drastically reduced worst-case time complexity for computing maximal cliques in common real-world graphs. Then, we propose a set of fundamental query operations and efficient algorithms to process the queries, to aid more efficient and effective analysis of the set of maximal cliques. Finally, we also devise algorithms to support efficient update maintenance of the set of maximal cliques when the underlying graph is updated. We verify the efficiency of our algorithms for computing, querying, and updating the set of maximal cliques with a range of real-world graphs from different application domains.",
Mixed-ADC Massive MIMO Uplink in Frequency-Selective Channels,"The aim of this paper is to investigate the recently developed mixed-analog-to-digital converter (ADC) architecture for frequency-selective channels. Multi-carrier techniques, such as orthogonal frequency division multiplexing, are employed to handle inter-symbol interference. A frequency-domain equalizer is designed for mitigating the inter-carrier interference introduced by the nonlinearity of one-bit quantization. For static single-input-multiple-output (SIMO) channels, a closed-form expression of the generalized mutual information (GMI) is derived, and based on which the linear frequency-domain equalizer is optimized. The analysis is then extended to ergodic time-varying SIMO channels with estimated channel state information, where numerically tight lower and upper bounds of the GMI are derived. The analytical framework is naturally applicable to the multi-user scenario, for both static and time-varying channels. Extensive numerical studies reveal that the mixed-ADC architecture with a small proportion of high-resolution ADCs does achieve a dominant portion of the achievable rate of ideal conventional architecture, and that it remarkably improves the performance as compared with one-bit massive multiple-input-multiple-output.","MIMO,
OFDM,
Computer architecture,
Channel estimation,
Frequency-domain analysis,
Quantization (signal),
Antennas"
Node Scheduling Control Inspired by Epidemic Theory for Data Dissemination in Wireless Sensor-Actuator Networks With Delay Constraints,"Wireless sensor-actuator networks (WSANs) enhance the existing wireless sensor networks (WSNs) by equipping sensor nodes with actuators. The actuators work with the sensor nodes to perform application-specific operations. The WSAN systems have several applications such as disaster relief, intelligent building management, military surveillance, health monitoring, and infrastructure security. These applications require the capability of fast data dissemination in order to act responsively to events. However, due to strict resource constraints of the nodes, WSANs pose significant challenges in network protocol design to support applications with delay requirements. Biologically inspired modeling techniques have received considerable attention for achieving robustness, scalability, and adaptability, while retaining individual simplicity. Specifically, data dissemination, packet routing, and broadcasting protocols for wireless networks have been modeled by epidemic theory. However, existing bio-inspired algorithms are mostly based on predefined heuristics and fixed parameters, and thus it is difficult for them to achieve the desired level of performance under dynamic environments. In order to solve this problem, we propose an epidemic-inspired algorithm for data dissemination in WSANs which automatically controls node states to meet the delay requirements while minimizing energy consumption. Through mathematical analysis, behavior of the algorithm in terms of converge time and steady state can be predicted. Also, the analysis shows that the system achieves stability, and derives parameter conditions for achieving the stability. Finally, extensive simulation results indicate that the proposed scheme outperforms existing protocols in achieving delay requirements and conserving energy.","Protocols,
Wireless sensor networks,
Delays,
Actuators,
Adaptation models,
Wireless networks"
"Modeling, Analysis, and Parameters Design of LC-Filter-Integrated Quasi-Z -Source Indirect Matrix Converter","Through coupling the impedance network between the grid and the conventional indirect matrix converter (IMC), the LC-filter-integrated quasi-Z-source (qZS) IMC overcomes the 0.866 voltage gain limitation of the conventional IMC and also avoids the input filter that is required to mitigate current harmonics of the conventional qZS matrix converters. This paper further investigates the voltage boosting and LC filtering function of the LC-filter-integrated qZS IMC. The voltage gain, the filtering function, and qZS network parameters design are presented using a small-signal model and circuit analysis. Simulation and experimental results validate the built model, the voltage gain analysis, and the parameters design of this type of qZS IMC. The input current of the LC-filter-integrated qZS network is compared to the conventional Z-source and qZS IMCs to investigate the integrated LC filtering capability. The experimental results verify that the LC-filter-integrated qZS network provides the necessary filtering function. Thus, the traditional input filter can be eliminated, which reduces the cost, power loss, volume, and weight for the overall system, when compared with the other conventional topologies that require the input filter, even those with impedance-source networks.",
A Low-Jitter and Fractional-Resolution Injection-Locked Clock Multiplier Using a DLL-Based Real-Time PVT Calibrator With Replica-Delay Cells,"A low-jitter and fractional-resolution injection-locked clock multiplier (ILCM) with a delay-locked-loop (DLL)-based process-voltage-temperature (PVT)-calibrator is proposed. The ring-type voltage-controlled oscillator (VCO) and the voltage-controlled delay line (VCDL) of the DLL consist of identical delay cells, and they share the same control voltage. Thus, by changing the ratio between the numbers of stages of the VCDL and the VCO, the frequency of the VCO can be calibrated at any target frequencies, noninteger times the reference frequency. As the amount of the unit delay is adjusted continuously by the DLL, the VCO can overcome real-time frequency drifts as well as static process variations; thus, excellent jitter performance can be sustained during any environmental variations. The proposed ILCM, designed in the 65 nm CMOS process, generated output frequencies that range from 1.2 to 2.0 GHz with a frequency resolution of 40 MHz and a 400 MHz reference clock. When injection locked, the integrated jitter from 1 kHz to 40 MHz of the 1.6 GHz signal was 440 fs. The proposed real-time PVT calibrator restricted the degradations of phase noise and jitter over the temperature and the supply variations to less than 0.7 dB and 20%, respectively. The active area was 0.32 mm2 and the power consumption was 3.6 mW.","delay lock loops,
injection locked oscillators,
phase noise,
timing jitter,
voltage-controlled oscillators"
A Novel Wavefront-Based High Parallel Solution for HEVC Encoding,"With a lot of enhanced coding tools introduced, High Efficiency Video Coding (HEVC) achieves significant improvement in coding efficiency at the cost of increased computational complexity. To efficiently reduce the encoding time of HEVC, a wavefront-based high parallel (WHP) solution integrating novel data-level and task-level methods is proposed in this paper. On data level, optimal single-instruction-multiple-data algorithms are designed for the enhanced coding tools, i.e., replacing the multiplication in motion compensation by add and shift operations with reduced instruction cycles, removing the transpose in transform via realignment of coefficients, and minimizing the memory access in sum of absolute difference/sum of squared differences calculation by fully reusing the registers. On task level, a novel inter-frame wavefront (IFW) method is developed by effectively decreasing the dependence of wavefront parallel processing (WPP). In addition, a coding tree block level parallelism analysis method is presented to prove the superior of IFW method compared with other HEVC representative parallel methods. Besides, a three-level thread management scheme is proposed to best exploit the parallelism of IFW method and achieve corresponding encoding speedup. Extensive experimental results show that, the overall WHP solution can bring up to
57.65×
,
65.55×
, and
88.17×
speedup for HEVC encoding of Wide Video Graphics Array, 720p and 1080p standard test sequences, while maintaining the same coding performance as with WPP. The proposed solution is also applied in several leading video companies in China, providing HEVC video service for more than 1.3 million users everyday.","Encoding,
Transforms,
Parallel processing,
Interpolation,
Video coding,
Decoding,
Standards"
Automatic Source Code Summarization of Context for Java Methods,"Source code summarization is the task of creating readable summaries that describe the functionality of software. Source code summarization is a critical component of documentation generation, for example as Javadocs formed from short paragraphs attached to each method in a Java program. At present, a majority of source code summarization is manual, in that the paragraphs are written by human experts. However, new automated technologies are becoming feasible. These automated techniques have been shown to be effective in select situations, though a key weakness is that they do not explain the source code's context. That is, they can describe the behavior of a Java method, but not why the method exists or what role it plays in the software. In this paper, we propose a source code summarization technique that writes English descriptions of Java methods by analyzing how those methods are invoked. We then performed two user studies to evaluate our approach. First, we compared our generated summaries to summaries written manually by experts. Then, we compared our summaries to summaries written by a state-of-the-art automatic summarization tool. We found that while our approach does not reach the quality of human-written summaries, we do improve over the state-of-the-art summarization tool in several dimensions by a statistically-significant margin.","Context,
Documentation,
Java,
Natural languages,
Software,
Generators,
XML"
Map-Based Probabilistic Visual Self-Localization,"Accurate and efficient self-localization is a critical problem for autonomous systems. This paper describes an affordable solution to vehicle self-localization which uses odometry computed from two video cameras and road maps as the sole inputs. The core of the method is a probabilistic model for which an efficient approximate inference algorithm is derived. The inference algorithm is able to utilize distributed computation in order to meet the real-time requirements of autonomous systems in some instances. Because of the probabilistic nature of the model the method is capable of coping with various sources of uncertainty including noise in the visual odometry and inherent ambiguities in the map (e.g., in a Manhattan world). By exploiting freely available, community developed maps and visual odometry measurements, the proposed method is able to localize a vehicle to 4 m on average after 52 seconds of driving on maps which contain more than 2,150 km of drivable roads.",
Learning a Mahalanobis Distance-Based Dynamic Time Warping Measure for Multivariate Time Series Classification,"Multivariate time series (MTS) datasets broadly exist in numerous fields, including health care, multimedia, finance, and biometrics. How to classify MTS accurately has become a hot research topic since it is an important element in many computer vision and pattern recognition applications. In this paper, we propose a Mahalanobis distance-based dynamic time warping (DTW) measure for MTS classification. The Mahalanobis distance builds an accurate relationship between each variable and its corresponding category. It is utilized to calculate the local distance between vectors in MTS. Then we use DTW to align those MTS which are out of synchronization or with different lengths. After that, how to learn an accurate Mahalanobis distance function becomes another key problem. This paper establishes a LogDet divergence-based metric learning with triplet constraint model which can learn Mahalanobis matrix with high precision and robustness. Furthermore, the proposed method is applied on nine MTS datasets selected from the University of California, Irvine machine learning repository and Robert T. Olszewski's homepage, and the results demonstrate the improved performance of the proposed approach.","Time series analysis,
Time measurement,
Feature extraction,
Pollution measurement,
Euclidean distance,
Matrix decomposition"
IQ Imbalance in Multiuser Systems: Channel Estimation and Compensation,"In this paper, we consider the uplink of a single-cell multi-user single-input multiple-output (MU-SIMO) system with in-phase and quadrature-phase imbalance (IQI). In particular, we investigate the effect of receive (RX) IQI on the performance of MU-SIMO systems with large antenna arrays employing maximum-ratio combining receivers. In order to study how IQI affects channel estimation, we derive a new channel estimator for the IQI-impaired model and show that the higher the value of signal-to-noise ratio, the higher the impact of IQI on the spectral efficiency (SE). Moreover, a novel pilot-based joint estimator of the augmented multiple-input multiple-output (MIMO) channel matrix and IQI coefficients is described, and then, a low-complexity IQI compensation scheme is proposed, which is based on the IQI coefficients' estimation and it is independent of the channel gain. The performance of the proposed compensation scheme is analytically evaluated by deriving a tractable approximation of the ergodic SE assuming transmission over Rayleigh fading channels with large-scale fading. Furthermore, we investigate how many mobile stations should be scheduled in massive MIMO systems with IQI and show that the highest SE loss occurs at the optimal operating point. Finally, by deriving asymptotic power scaling laws and proving that the SE loss due to IQI is asymptotically independent of the number of BS antennas, we show that massive MIMO is resilient to the effect of RX IQI.","Channel estimation,
MIMO,
Receivers,
Antennas,
Radio frequency,
Fading channels,
Uplink"
A Proximal Dual Consensus ADMM Method for Multi-Agent Constrained Optimization,"This paper considers a convex optimization problem with a globally coupled linear equality constraint and local polyhedron constraints and develops efficient distributed optimization methods. The considered problem has many engineering applications. Due to the polyhedron constraints, agents in the existing methods have to deal with polyhedron constrained subproblems at each iteration. One of the key challenges is that projection onto a polyhedron set is not trivial, which prohibits the agents from solving these subproblems efficiently. In this paper, based on the alternating direction method of multipliers (ADMM), we propose a new distributed optimization method, called proximal dual consensus ADMM (PDC-ADMM). The PDC-ADMM transforms the polyhedron constraints as quadratic penalty terms in the subproblems, making the subproblems efficiently solvable and consequently reducing the overall computational overhead of the agents. In addition, we propose a randomized PDC-ADMM which can deal with time-varying networks with randomly ON/OFF agents and communication errors, and an inexact (randomized) PDC-ADMM for low-complexity computations. We show that the proposed distributed methods converge to the optimal solution set almost surely and have a O (1/k) ergodic convergence rate in the mean. Numerical results show that the proposed methods offer significantly lower computation time than the existing distributed ADMM method in solving a linearly constrained LASSO problem.","Convergence,
Optimization methods,
Handheld computers,
Silicon,
Standards,
Algorithm design and analysis"
Securing Massive MIMO Via Power Scaling,"In this work, we study how fast we are able to scale down the power for both training and data transmission while guaranteeing security in a massive MIMO network without the help of artificial noise. We consider a multicell network with a large number of base station (BS) and eavesdropper antennas, but limited number of cells and mobile users. By offering an achievable lower bound on secrecy rate for both uplink and downlink, we observe that we can always find a power scaling approach for security as long as the ratio of the number of eavesdropper antennas to the number of BS antennas is smaller than a threshold. In particular, we find that when the eavesdropper and its targeting receiver share the same distance to the information source, the threshold is exactly the total pilot power received at the BS for uplink training.","MIMO,
Uplink,
Downlink,
Antenna arrays,
Training,
Contamination"
Transmit Antenna Selection for Multiple-Input Multiple-Output Spatial Modulation Systems,"The benefits of transmit antenna selection (TAS) invoked for spatial modulation (SM) aided multiple-input multiple-output (MIMO) systems are investigated. Specifically, we commence with a brief review of the existing TAS algorithms and focus on the recently proposed Euclidean distance-based TAS (ED-TAS) schemes due to their high diversity gain. Then, a pair of novel ED-TAS algorithms, termed as the improved QR decomposition (QRD)-based TAS (QRD-TAS) and the error-vector magnitude-based TAS (EVM-TAS) are proposed, which exhibit an attractive system performance at low complexity. Moreover, the proposed ED-TAS algorithms are amalgamated with the low-complexity yet efficient power allocation (PA) technique, termed as TAS-PA, for the sake of further improving the system's performance. Our simulation results show that the proposed TAS-PA algorithms achieve signal-to-noise ratio (SNR) gains of up to 9 dB over the conventional TAS algorithms and up to 6 dB over the TAS-PA algorithm designed for spatial multiplexing systems.","Complexity theory,
MIMO,
Algorithm design and analysis,
Bit error rate,
Transmitting antennas,
Modulation,
Signal to noise ratio"
"Mobility-Aware Modeling and Analysis of Dense Cellular Networks With
C
-Plane/
U
-Plane Split Architecture","The unrelenting increase in the population of mobile users and their traffic demands drive cellular network operators to densify their network infrastructure. Network densification shrinks the footprint of base stations (BSs) and reduces the number of users associated with each BS, leading to an improved spatial frequency reuse and spectral efficiency, and thus, higher network capacity. However, the densification gain comes at the expense of higher handover rates and network control overhead. Hence, user's mobility can diminish or even nullifies the foreseen densification gain. In this context, splitting the control plane (C-plane) and user plane (U-plane) is proposed as a potential solution to harvest densification gain with reduced cost in terms of handover rate and network control overhead. In this paper, we use stochastic geometry to develop a tractable mobility-aware model for a two-tier downlink cellular network with ultradense small cells and C-plane/U-plane split architecture. The developed model is then used to quantify the effect of mobility on the foreseen densification gain with and without C-plane/ U-plane split. To this end, we shed light on the handover problem in dense cellular environments, show scenarios where the network fails to support certain mobility profiles, and obtain network design insights.","Handover,
Computer architecture,
Interference,
Signal to noise ratio,
Delays,
Stochastic processes"
Aggressive quadrotor flight through cluttered environments using mixed integer programming,"Quadrotor flight has typically been limited to sparse environments due to numerical complications that arise when dealing with large numbers of obstacles. We hypothesized that it would be possible to plan and robustly execute trajectories in obstacle-dense environments using the novel Iterative Regional Inflation by Semidefinite programming algorithm (IRIS), mixed-integer semidefinite programs (MISDP), and model-based control. Unlike sampling-based approaches, the planning algorithm first introduced by Deits theoretically guarantees non-penetration of the trajectories even with small obstacles such as strings. We present experimental validation of this claim by aggressively flying a small quadrotor (34g, 92mm rotor to rotor) in a series of indoor environments including a cubic meter volume containing 20 interwoven strings, and present the control architecture we developed to do so.","Trajectory,
Iris,
Planning,
Computational modeling,
Mathematical model,
Optimization,
Propellers"
A Gaussian Model-Based Probabilistic Approach for Pulse Transit Time Estimation,"In this paper, we propose a new probabilistic approach to pulse transit time (PTT) estimation using a Gaussian distribution model. It is motivated basically by the hypothesis that PTTs normalized by RR intervals follow the Gaussian distribution. To verify the hypothesis, we demonstrate the effects of arterial compliance on the normalized PTTs using the Moens-Korteweg equation. Furthermore, we observe a Gaussian distribution of the normalized PTTs on real data. In order to estimate the PTT using the hypothesis, we first assumed that R-waves in the electrocardiogram (ECG) can be correctly identified. The R-waves limit searching ranges to detect pulse peaks in the photoplethysmogram (PPG) and to synchronize the results with cardiac beats-i.e., the peaks of the PPG are extracted within the corresponding RR interval of the ECG as pulse peak candidates. Their probabilities of being the actual pulse peak are then calculated using a Gaussian probability function. The parameters of the Gaussian function are automatically updated when a new pulse peak is identified. This update makes the probability function adaptive to variations of cardiac cycles. Finally, the pulse peak is identified as the candidate with the highest probability. The proposed approach is tested on a database where ECG and PPG waveforms are collected simultaneously during the submaximal bicycle ergometer exercise test. The results are promising, suggesting that the method provides a simple but more accurate PTT estimation in real applications.","Electrocardiography,
Estimation,
Mathematical model,
Gaussian distribution,
Equations,
Indexes,
Biomedical measurement"
Development and Evaluation of an Active Learning Support System for Context-Aware Ubiquitous Learning,"Situating students to learn from the real world has been recognized as an important and challenging issue. However, in a real-world learning environment, there are usually many physical constraints that affect the learning performance of students, such as the total learning time, the limitation of the number of students who can visit a learning target, and the time needed for moving from one learning location to another. It is essential to guide the students along an efficient learning path to maximize their learning performance according to the current situation. In this paper, an active learning support system (ALESS) for context-aware ubiquitous learning environments is designed and developed. ALESS can provide learning guidance when conducting ubiquitous learning activities. A great deal of context information is used in ALESS, including the location, the current capacity of the learning object, the time available, etc. ALESS is able to actively provide the required learning support to individual students when they approach the corresponding real-world learning targets. To evaluate the performance of ALESS, an experiment was conducted in the National Science Museum of Taiwan. The experimental results showed that, with the help of ALESS, the students learned more efficiently, and achieved better learning performance.",
Robust Power Flow Control of Grid-Connected Inverters,"In this paper, an uncertainty and disturbance estimator (UDE)-based robust power flow control is developed for grid-connected inverters to achieve accurate power delivery to the grid. The model of power delivering with both frequency dynamics and voltage dynamics is derived at first. The UDE method is introduced into the controller design to deal with model uncertainties (e.g., output impedance and power angle), coupling effects, and external disturbances (e.g., the fluctuation of the dc-link voltage, the variation of output impedance/line impedance, and the variations of both frequency and amplitude in the grid voltage). Also, this controller does not need a voltage regulator or a current regulator and is easy for the implementation and parameter tuning through the design of the desired tracking error dynamics and the UDE filters. Experimental results are provided to show the effectiveness of the proposed method for different disturbance rejection scenarios, the low-voltage fault-ride through capability, and the weak grid operation capability. The good robustness of the UDE-based control is also demonstrated through the comparison with two other controllers: the proportional-integral controller and the active disturbance rejection controller.",
Study of Senone-Based Deep Neural Network Approaches for Spoken Language Recognition,"This paper compares different approaches for using deep neural networks (DNNs) trained to predict senone posteriors for the task of spoken language recognition (SLR). These approaches have recently been found to outperform various baseline systems on different datasets, but they have not yet been compared to each other or to a common baseline. Two of these approaches use the DNNs to generate feature vectors which are then processed in different ways to predict the score of each language given a test sample. The features are extracted either from a bottleneck layer in the DNN or from the output layer. In the third approach, the standard i-vector extraction procedure is modified to use the senones as classes and the DNN to predict the zeroth order statistics. We compare these three approaches and conclude that the approach based on bottleneck features followed by i-vector modeling outperform the other two approaches. We also show that score-level fusion of some of these approaches leads to gains over using a single approach for short-duration test samples. Finally, we demonstrate that fusing systems that use DNNs trained with several languages leads to improvements in performance over the best single system, and we propose an adaptation procedure for DNNs trained with languages with less available data. Overall, we show improvements between 40% and 70% relative to a state-of-the-art Gaussian mixture model (GMM) i-vector system on test durations from 3 seconds to 120 seconds on two significantly different tasks: the NIST 2009 language recognition evaluation task and the DARPA RATS language identification task.","Feature extraction,
Standards,
Speech,
Rats,
Mathematical model,
Neural networks,
Training"
Optimum Transmission Policies for Energy Harvesting Sensor Networks Powered by a Mobile Control Center,"Wireless energy transfer, namely, radio frequency (RF)-based energy harvesting, is a potential way to prolong the lifetime of energy-constrained devices, especially in wireless sensor networks. However, due to huge propagation attenuation, its energy efficiency is regarded as the biggest bottleneck to wide applications. It is critical to find appropriate transmission policies to improve the global energy efficiency in this kind of system. To this end, this paper focuses on the sensor networks scenario, where a mobile control center powers the sensors by RF signal and also collects information from them. Two related schemes, called harvest-and-use scheme and harvest-store-use scheme, are investigated. In the harvest-and-use scheme, as a benchmark, both constant and adaptive transmission modes from sensors are discussed. In the harvest-store-use scheme, we propose a new concept, the best opportunity for wireless energy transfer, and use it to derive an explicit closed-form expression of optimal transmission policy. It is shown by simulation that a considerable improvement in terms of energy efficiency can be obtained with the help of the transmission policies developed in this paper. Furthermore, the transmission policies are also discussed under the constraint of fixed information rate. The minimal required power, the performance loss from the new constraint, and the effect of fading are then presented.","Wireless communication,
Wireless sensor networks,
Energy harvesting,
Mobile communication,
Energy exchange,
Fading channels,
Mobile computing"
"Design of a Wideband, Tunable Four-Port MIMO Antenna System With High Isolation Based on the Theory of Characteristic Modes","Cognitive radio (CR) systems, which are intended for opportunistic spectrum access over a large portion of the mobile radio spectrum, require highly isolated and wideband multiport antennas. The subject of this paper is an approach for mapping characteristic modes (CMs) to radiation modes (RMs) to build a multiple-input multiple-output (MIMO) antenna system meeting the requirements of isolation and bandwidth (BW). A set of mutually orthogonal RMs of the antenna system is constructed from superpositions of CMs of the chassis of the device. By exploitation of orthogonality properties and permutation relations between the couplers due to symmetry, the complexity of the matching network (MN) and the number of tunable reactances are reduced. The approach is applied to the design of a four-port antenna system for a femto-cell form factor device operating in the [470, 790] MHz range. We proceed to the computation of the CMs of the device, the selection of most efficient ones, and their excitation with couplers whose locations respect the symmetry of the structure and of the current density distributions of the chosen modes. Theoretical considerations and simulations are compared against measured results for our hardware prototype.",
Carrier Aggregation Between Operators in Next Generation Cellular Networks: A Stable Roommate Market,"This paper studies carrier aggregation between multiple mobile network operators (MNOs), referred to as interoperator carrier aggregation (IO-CA). In IO-CA, each MNO can transmit on its own licensed spectrum and aggregate the spectrum licensed to other MNOs. We focus on the case that MNOs are partitioned and distributed into small groups, called IO-CA pairs, each of which consists of two MNOs that mutually agree to share their spectrum with each other. We model the IO-CA pairing problem between MNOs as a stable roommate market and derive a condition for which a stable matching structure among all MNOs exist. We propose an algorithm that achieves a stable matching if it exists. Otherwise, the algorithm results in a stable partition. For each IO-CA pair, we derive the optimal transmit power for each spectrum aggregator and establish a Stackelberg game model to analyze the interaction between the licensed subscribers and aggregators in the spectrum of each MNO. We derive the Stackelberg equilibrium of our proposed game and then develop a joint optimization algorithm that achieves the stable matching structure among MNOs as well as the optimal transmit powers for the aggregators and prices for the subscribers of each MNO.",
Assistive Control System for Upper Limb Rehabilitation Robot,"This paper presents an assistive control system with a special kinematic structure of an upper limb rehabilitation robot embedded with force/torque sensors. A dynamic human model integrated with sensing torque is used to simulate human interaction under three rehabilitation modes: active mode, assistive mode, and passive mode. The hereby proposed rehabilitation robot, called NTUH-ARM, provides 7 degree-of- freedom (DOF) motion and runs subject to an inherent mapping between the 7 DOFs of the robot arm and the 4 DOFs of the human arm. The Lyapunov theory is used to analyze the stability of the proposed controller design. Clinical trials have been conducted with six patients, one of which acts as a control. The results of these experiments are positive and STREAM assessment by physical therapists also reveals promising results.",
A Class-Information-Based Sparse Component Analysis Method to Identify Differentially Expressed Genes on RNA-Seq Data,"With the development of deep sequencing technologies, many RNA-Seq data have been generated. Researchers have proposed many methods based on the sparse theory to identify the differentially expressed genes from these data. In order to improve the performance of sparse principal component analysis, in this paper, we propose a novel class-information-based sparse component analysis (CISCA) method which introduces the class information via a total scatter matrix. First, CISCA normalizes the RNA-Seq data by using a Poisson model to obtain their differential sections. Second, the total scatter matrix is gotten by combining the between-class and within-class scatter matrices. Third, we decompose the total scatter matrix by using singular value decomposition and construct a new data matrix by using singular values and left singular vectors. Then, aiming at obtaining sparse components, CISCA decomposes the constructed data matrix by solving an optimization problem with sparse constraints on loading vectors. Finally, the differentially expressed genes are identified by using the sparse loading vectors. The results on simulation and real RNA-Seq data demonstrate that our method is effective and suitable for analyzing these data.","Accuracy,
Matrix decomposition,
Sparse matrices,
Principal component analysis,
Bioinformatics,
Optimization,
Data models"
Towards sophisticated learning from EHRs: Increasing prediction specificity and accuracy using clinically meaningful risk criteria,"Computer based analysis of Electronic Health Records (EHRs) has the potential to provide major novel insights of benefit both to specific individuals in the context of personalized medicine, as well as on the level of population-wide health care and policy. The present paper introduces a novel algorithm that uses machine learning for the discovery of longitudinal patterns in the diagnoses of diseases. Two key technical novelties are introduced: one in the form of a novel learning paradigm which enables greater learning specificity, and another in the form of a risk driven identification of confounding diagnoses. We present a series of experiments which demonstrate the effectiveness of the proposed techniques, and which reveal novel insights regarding the most promising future research directions.",
A Power-Efficient Multichannel Neural Stimulator Using High-Frequency Pulsed Excitation From an Unfiltered Dynamic Supply,"This paper presents a neural stimulator system that employs a fundamentally different way of stimulating neural tissue compared to classical constant current stimulation. A stimulation pulse is composed of a sequence of current pulses injected at a frequency of 1 MHz for which the duty cycle is used to control the stimulation intensity. The system features 8 independent channels that connect to any of the 16 electrodes at the output. A sophisticated control system allows for individual control of each channel's stimulation and timing parameters. This flexibility makes the system suitable for complex electrode configurations and current steering applications. Simultaneous multichannel stimulation is implemented using a high frequency alternating technique, which reduces the amount of electrode switches by a factor 8. The system has the advantage of requiring a single inductor as its only external component. Furthermore it offers a high power efficiency, which is nearly independent on both the voltage over the load as well as on the number of simultaneously operated channels. Measurements confirm this: in multichannel mode the power efficiency can be increased for specific cases to 40% compared to 20% that is achieved by state-of-the-art classical constant current stimulators with adaptive power supply.",
An Effective Nonlinear Multivariable HMPC for USC Power Plant Incorporating NFN-Based Modeling,"The ultra-supercritical (USC) unit is an advanced power generation technology with high plant efficiency, high coal utilization, and low emission. However, it is difficult to realize a coordinate control for the USC unit to achieve fast and stable dynamic response during load tracking and grid frequency disturbances, because it is complex, nonlinear, and large scale. This paper presents a nonlinear hierarchical model predictive control (HMPC) to incorporate both the plant-wide economic process optimization and the regulatory process control into a hierarchical control structure, in which the model predictive control (MPC) technology is utilized to solve the multilayer optimization problem. While the nonlinear HMPC optimization problems can be nonconvex, the neuro-fuzzy network (NFN) modeling on USC is incorporated to facilitate the convex quadratic program (QP) routine. Detailed analysis on load tracking and grid frequency disturbances via simulations has been addressed to demonstrate the effectiveness of the proposed nonlinear HMPC.",
Fault-tolerant IP routing flow-based model,"In this paper the fault-tolerant IP routing flow-based model presented. In solving the technological problem of fault-tolerant IP routing it is necessary during minimization of object function to solve either linear programming problem or Boolean programming problem with limitations defined. Proposed model also provides the support of traffic balancing functions on the virtual router interfaces, which also has a positive impact on the availability and productivity of telecommunication system as a whole.","Design automation,
Decision support systems,
Telecommunications,
Computer science"
Close Human Interaction Recognition Using Patch-Aware Models,"This paper addresses the problem of recognizing human interactions with close physical contact from videos. Due to ambiguities in feature-to-person assignments and frequent occlusions in close interactions, it is difficult to accurately extract the interacting people. This degrades the recognition performance. We, therefore, propose a hierarchical model, which recognizes close interactions and infers supporting regions for each interacting individual simultaneously. Our model associates a set of hidden variables with spatiotemporal patches and discriminatively infers their states, which indicate the person that the patches belong to. This patch-aware representation explicitly models and accounts for discriminative supporting regions for individuals, and thus overcomes the problem of ambiguities in feature assignments. Moreover, we incorporate the prior for the patches to deal with frequent occlusions during interactions. Using the discriminative supporting regions, our model builds cleaner features for individual action recognition and interaction recognition. Extensive experiments are performed on the BIT-Interaction data set and the UT-Interaction data set set #1 and set #2, and validate the effectiveness of our approach.",
Online Sensorless Position Estimation for Switched Reluctance Motors Using One Current Sensor,"This paper proposes an online sensorless rotor position estimation technique for switched reluctance motors (SRMs) using just one current sensor. It is achieved by first decoupling the excitation current from the bus current. Two phase-shifted pulse width modulation signals are injected into the relevant lower transistors in the asymmetrical half-bridge converter for short intervals during each current fundamental cycle. Analog-to-digital converters are triggered in the pause middles of the dual pulse to separate the bus current for excitation current recognition. Next, the rotor position is estimated from the excitation current, by a current-rise-time method in the current-chopping-control mode in a low-speed operation and a current-gradient method in the voltage-pulse-control mode in a high-speed operation. The proposed scheme requires only a bus current sensor and a minor change to the converter circuit, without a need for individual phase current sensors or additional detection devices, achieving a more compact and cost-effective drive. The performance of the sensorless SRM drive is fully investigated. The simulation and experiments on a 750-W three-phase 12/8-pole SRM are carried out to verify the effectiveness of the proposed scheme.",
Enabling New Computation Paradigms with HyperFET - An Emerging Device,"High power consumption has significantly increased the cooling cost in high-performance computation stations and limited the operation time in portable systems powered by batteries. Traditional power reduction mechanisms have limited traction in the post-Dennard Scaling landscape. Emerging research on new computation devices and associated architectures has shown three trends with the potential to greatly mitigate current power limitations. The first is to employ steep-slope transistors to enable fundamentally more efficient operation at reduced supply voltage in conventional Boolean logic, reducing dynamic power. The second is to employ brain-inspired computation paradigms, directly embodying computation mechanisms inspired by the brains, which have shown potential in extremely efficient, if approximate, processing with silicon-neuron networks. The third is “let physics do the computation”, which focuses on using the intrinsic operation mechanism of devices (such as coupled oscillators) to do the approximate computation, instead of building complex circuits to carry out the same function. This paper first describes these three trends, and then proposes the use of the hybrid-phase-transition-FET (Hyper-FET), a device that could be configured as a steep-slope transistor, a spiking neuron cell, or an oscillator, as the device of choice for carrying these three trends forward. We discuss how a single class of device can be configured for these multiple use cases, and provide in-depth examination and analysis for a case study of building coupled-oscillator systems using Hyper-FETs for image processing. Performance benchmarking highlights the potential of significantly higher energy efficiency than dedicated CMOS accelerators at the same technology node.","Oscillators,
Computer architecture,
MOSFET,
Neurons,
CMOS integrated circuits,
Hysteresis,
Integrated circuit modeling"
Beamforming and Interference Cancellation for D2D Communication Underlaying Cellular Networks,"This paper presents an analytical performance investigation of both beamforming (BF) and interference cancellation (IC) strategies for a device-to-device (D2D) communication system underlaying a cellular network with an M-antenna base station (BS). We first derive new closed-form expressions for the ergodic achievable rate for BF and IC precoding strategies with quantized channel state information (CSI), as well as, perfect CSI. Then, novel lower and upper bounds are derived which apply for an arbitrary number of antennas and are shown to be sufficiently tight to the Monte-Carlo results. Based on these results, we examine in detail three important special cases including: high signal-to-noise ratio (SNR), weak interference between cellular link and D2D link, and BS equipped with a large number of antennas. We also derive asymptotic expressions for the ergodic achievable rate for these scenarios. Based on these results, we obtain valuable insights into the impact of the system parameters, such as the number of antennas, SNR and the interference for each link. In particular, we show that an irreducible saturation point exists in the high SNR regime, while the ergodic rate under IC strategy is verified to be always better than that under BF strategy. We also reveal that the ergodic achievable rate under perfect CSI scales as log2M, whilst it reaches a ceiling with quantized CSI.",
Recent Activities in Earth Data Science [Technical Committees],"Recent trends on big Earth-observing (EO) data lead to some questions that the Earth science community needs to address. Are we experiencing a paradigm shift in Earth science research now? How can we better utilize the explosion of technology maturation to create new forms of EO data processing? Can we summarize the existing methodologies and technologies scaling to big EO data as a new field named earth data science? Big data technologies are being widely practiced in Earth sciences and remote sensing communities to support EO data access, processing, and knowledge discovery. The data-intensive scientific discovery, named the fourth paradigm, leads to data science in the big data era [1]. According to the definition by the U.S. National Institute of Standards and Technology, the data science paradigm is the ""extraction of actionable knowledge directly from data through a process of discovery, hypothesis, and hypothesis testing"" [2]. Earth data science is the art and science of applying the data science paradigm to EO data.","Remote sensing,
Geospatial analysis,
Big data,
Data processing,
Earth observing data"
Radiation Hardening by Process of CBRAM Resistance Switching Cells,"Non-volatile memory (NVM) technology highly resistant to ionizing dose and radiation effects in general continues to be a challenge for space missions. Novel NVM nano-ionic technologies known as conductive bridging random access memory (CBRAM), a resistive circuit technology, exhibits great promise for both high density memory and high total ionizing dose resilience. In this work, it is discovered that CBRAM can be sensitive to high TID levels. However, this novel technology can be radiation-hardened by process, which is demonstrated in this paper.","capacitor switching,
ionisation chambers,
radiation hardening (electronics),
random processes"
Orchestrating Tree-Type VNF Forwarding Graphs in Inter-DC Elastic Optical Networks,"It is known that by incorporating network function virtualization (NFV) in inter-datacenter (inter-DC) networks, service providers can use their network resources more efficiently and adaptively and expedite the deployment of new services. This paper studies the provisioning algorithms to realize tree-type virtual network function forwarding graphs (VNF-FGs), i.e., multicast NFV trees (M-NFV-Ts), in inter-DC elastic optical networks (IDC-EONs) cost-effectively. Specifically, we try to optimize the VNF placement and multicast routing and spectrum assignment jointly for orchestrating M-NFV-Ts in an IDC-EON with the lowest cost. Our study addresses both static network planning and dynamic network provisioning. For network planning, we first formulate a mixed integer linear programming (MILP) model to solve the problem exactly, and then propose three heuristic algorithms, namely, auxiliary frequency slot matrix (AFM)-MILP, AFM-GS, and RB. Extensive simulations show that AFM-MILP and AFM-GS can approximate the MILP's performance on low-cost M-NFV-T provisioning with much shorter running time. For network provisioning, we design two additional online algorithms based on AFM-GS and RB to serve M-NFV-Ts in a dynamic IDC-EON, with the consideration of spectrum fragmentation.","Optical fiber networks,
Algorithm design and analysis,
Planning,
Heuristic algorithms,
Resource management,
Bandwidth"
Quantized Consensus by the ADMM: Probabilistic Versus Deterministic Quantizers,"This paper develops efficient algorithms for distributed average consensus with quantized communication using the alternating direction method of multipliers (ADMM). We first study the effects of probabilistic and deterministic quantizations on a distributed ADMM algorithm. With probabilistic quantization, this algorithm yields linear convergence to the desired average in the mean sense with a bounded variance. When deterministic quantization is employed, the distributed ADMM converges to a consensus within 3+⌈log1+δΩ⌉ iterations where δ > 0 depends on the network topology and Ω is a polynomial fraction depending on the quantization resolution, the agents' data, and the network topology. A tight upper bound on the consensus error is also obtained, which depends only on the quantization resolution and the average degree of the graph. This bound is much preferred in large scale networks over existing algorithms whose consensus errors are increasing in the range of agents' data, the quantization resolution, and the number of agents. We finally propose our algorithm which combines both probabilistic and deterministic quantizations. Simulations show that the consensus error of our algorithm is typically less than one quantization resolution for all connected networks where agents' data can be of arbitrary magnitudes.",
Detection of the characters from the license plates by cascade classifiers method,"This article describes the detection of the characters of the license plate through of computer vision techniques: such as cascade of classifiers based in sobel algorithm, analysis of peaks and valleys, and support vector machines; the search for the region of the plate begins by detecting vehicles, then character segmentation and concludes with the recognition of these. The system was tested in different scenarios such as: different lighting provided by the day or night and weather changes. The average time to execute these phases it was 434 ms.","Vehicles,
Biological cells,
Licenses,
Character recognition,
Image edge detection,
Support vector machines,
Feature extraction"
A Survey of FPGA-Based LDPC Decoders,"Low-density parity check (LDPC) error correction decoders have become popular in communications systems, as a benefit of their strong error correction performance and their suitability to parallel hardware implementation. A great deal of research effort has been invested into LDPC decoder designs that exploit the flexibility, the high processing speed, and the parallelism of field-programmable gate array (FPGA) devices. FPGAs are ideal for design prototyping and for the manufacturing of small-production-run devices, where their in-system programmability makes them far more cost-effective than application-specific integrated circuits (ASICs). However, the FPGA-based LDPC decoder designs published in the open literature vary greatly in terms of design choices and performance criteria, making them a challenge to compare. This paper explores the key factors involved in FPGA-based LDPC decoder design and presents an extensive review of the current literature. In-depth comparisons are drawn amongst 140 published designs (both academic and industrial) and the associated performance tradeoffs are characterized, discussed, and illustrated. Seven key performance characteristics are described, namely, their processing throughput, processing latency, hardware resource requirements, error correction capability, processing energy efficiency, bandwidth efficiency, and flexibility. We offer recommendations that will facilitate fairer comparisons of future designs, as well as opportunities for improving the design of FPGA-based LDPC decoders.","Parity check codes,
Decoding,
Field programmable gate arrays,
Tutorials,
Forward error correction,
Modulation,
Encoding"
On Alternate Relaying With Improper Gaussian Signaling,"In this letter, we investigate the potential benefits of adopting improper Gaussian signaling (IGS) in a two-hop alternate relaying (AR) system. Given the known benefits of using IGS in interference-limited networks, we propose to use IGS to relieve the inter-relay interference (IRI) impact on the AR system assuming no channel state information is available at the source. In this regard, we assume that the two relays use IGS and the source uses proper Gaussian signaling (PGS). Then, we optimize the degree of impropriety of the relays signal, measured by the circularity coefficient, to maximize the total achievable rate. Simulation results show that using IGS yields a significant performance improvement over PGS, especially when the first hop is a bottleneck due to weak source-relay channel gains and/or strong IRI.","Relays,
Interference,
Optimization,
Mathematical model,
Channel state information,
Indexes,
Electronic mail"
Authentication of Smartphone Users Using Behavioral Biometrics,"Smartphones and tablets have become ubiquitous in our daily lives. Smartphones, in particular, have become more than personal assistants. These devices have provided new avenues for consumers to play, work, and socialize whenever and wherever they want. Smartphones are small in size, so they are easy to handle and to stow and carry in users' pockets or purses. However, mobile devices are also susceptible to various problems. One of the greatest concerns is the possibility of breach in security and privacy if the device is seized by an outside party. It is possible that threats can come from friends as well as strangers. Due to the size of smart devices, they can be easily lost and may expose details of users' private lives. In addition, this might enable pervasive observation or imitation of one's movements and activities, such as sending messages to contacts, accessing private communication, shopping with a credit card, and relaying information about where one has been. This paper highlights the potential risks that occur when smartphones are stolen or seized, discusses the concept of continuous authentication, and analyzes current approaches and mechanisms of behavioral biometrics with respect to methodology, associated datasets and evaluation approaches.","Authentication,
Biometrics (access control),
Tutorials,
Privacy,
Biomedical monitoring,
Mobile handsets"
Real-Time Detection of False Data Injection in Smart Grid Networks: An Adaptive CUSUM Method and Analysis,"A smart grid is delay sensitive and requires the techniques that can identify and react on the abnormal changes (i.e., system fault, attacker, shortcut, etc.) in a timely manner. In this paper, we propose a real-time detection scheme against false data injection attack in smart grid networks. Unlike the classical detection test, the proposed algorithm is able to tackle the unknown parameters with low complexity and process multiple measurements at once, leading to a shorter decision time and a better detection accuracy. The objective is to detect the adversary as quickly as possible while satisfying certain detection error constraints. A Markov-chain-based analytical model is constructed to systematically analyze the proposed scheme. With the analytical model, we are able to configure the system parameters for guaranteed performance in terms of false alarm rate, average detection delay, and missed detection ratio under a detection delay constraint. The simulations are conducted with MATPOWER 4.0 package for different IEEE test systems.","Smart grids,
Analytical models,
Delays,
State estimation,
Real-time systems,
Tin,
Power measurement"
Bird detection in audio: A survey and a challenge,"Many biological monitoring projects rely on acoustic detection of birds. Despite increasingly large datasets, this detection is often manual or semi-automatic, requiring manual tuning/postprocessing. We review the state of the art in automatic bird sound detection, and identify a widespread need for tuning-free and species-agnostic approaches. We introduce new datasets and an IEEE research challenge to address this need, to make possible the development of fully automatic algorithms for bird sound detection.",
A Helping Hand: Soft Orthosis with Integrated Optical Strain Sensors and EMG Control,"Human fingers and hands are frequently injured because they are delicate, complex, and used constantly. More than 3 million people in the United States suffer from hand or forearm disabilities [1], and, worldwide, hand injuries account for one-third of all work injuries [2]. Due to the importance of hands and the prevalence of hand issues, there is an increasing effort toward developing hand orthotics. These efforts have resulted in active hand orthoses that have been used for rehabilitation training and restoring partial hand function [3]. To ensure safety and to reduce control complexity, some orthoses use mechanical compliances [4], [5] such as underactuated linkages [6] or low-stiffness materials and structures (e.g., rubbers and flexible wires) [7], [8]-[11]. The orthoses made of elastomeric materials tend to be more comfortable, perhaps because their low elastic modulus (10 kPa <; G' <; 1 MPa) [12] is similar to that of human skin (~100 kPa) [13].",
A Hybrid Electrical Magnetic Power Quality Compensation System With Minimum Active Compensation Capacity for V/V Cophase Railway Power Supply System,"To solve the power quality problem in a V/V cophase railway power supply system, a hybrid electrical magnetic power quality compensator (HEMPQC) based on magnetic static var compensator (MSVC) and hybrid power quality compensator (HPQC) is proposed in this paper. Compared with conventional HPQC, the proposed HEMPQC could keep the active compensation capacity minimum to any load condition. The output current of MSVC is conducted to make the active compensation capacity minimum. The coupling branch impedance optimum design procedures are deduced. Based on the instantaneous current detecting and reactive current distribution method, the collaboration control strategy is proposed for HEMPQC to achieve the dynamic tracking of the reference signals. Finally, simulation and experimental results have verified the proposed hybrid compensation system and compensation method effectively.","Harmonic analysis,
Reactive power,
Couplings,
Power harmonic filters,
Power conversion,
Power quality"
Privacy-Preserving Transportation Traffic Measurement in Intelligent Cyber-physical Road Systems,"Traffic measurement is a critical function in transportation engineering. We consider privacy-preserving point-to-point traffic measurement in this paper. We measure the number of vehicles traveling from one geographical location to another by taking advantage of capabilities provided by the intelligent cyberphysical road systems (CPRSs) that enable automatic collection of traffic data. The challenge is to allow the collection of aggregate point-to-point data while preserving the privacy of individual vehicles. We propose a novel measurement scheme, which utilizes bit arrays to collect “masked” data and adopts maximum-likelihood estimation (MLE) to obtain the measurement result. Both mathematical proof and simulation demonstrate the practicality and scalability of our scheme.","Vehicles,
Privacy,
Maximum likelihood estimation,
Size measurement,
Roads,
Accuracy"
Building Trustworthy Systems Using Untrusted Components: A High-Level Synthesis Approach,"Trustworthiness of system-on-chip designs is undermined by malicious logic (Trojans) in third-party intellectual properties (3PIPs). In this paper, duplication, diversity, and isolation principles have been extended to detect build trustworthy systems using untrusted, potentially Trojan-infected 3PIPs. We use a diverse set of vendors to prevent collusions between the 3PIPs from the same vendor. We identify design constraints for Trojan detection to achieving detection, collusion prevention, and isolating the Trojan-infected 3PIP, and incorporate them during high-level synthesis. In addition, we develop techniques to reduce the number of vendors. The effectiveness of the proposed techniques is validated using the high-level synthesis benchmarks.","Trojan horses,
Logic gates,
IP networks,
Security,
Registers,
DH-HEMTs,
Hardware"
Secure Face Unlock: Spoof Detection on Smartphones,"With the wide deployment of the face recognition systems in applications from deduplication to mobile device unlocking, security against the face spoofing attacks requires increased attention; such attacks can be easily launched via printed photos, video replays, and 3D masks of a face. We address the problem of face spoof detection against the print (photo) and replay (photo or video) attacks based on the analysis of image distortion (e.g., surface reflection, moiré pattern, color distortion, and shape deformation) in spoof face images (or video frames). The application domain of interest is smartphone unlock, given that the growing number of smartphones have the face unlock and mobile payment capabilities. We build an unconstrained smartphone spoof attack database (MSU USSA) containing more than 1000 subjects. Both the print and replay attacks are captured using the front and rear cameras of a Nexus 5 smartphone. We analyze the image distortion of the print and replay attacks using different: 1) intensity channels (R, G, B, and grayscale); 2) image regions (entire image, detected face, and facial component between nose and chin); and 3) feature descriptors. We develop an efficient face spoof detection system on an Android smartphone. Experimental results on the public-domain Idiap Replay-Attack, CASIA FASD, and MSU-MFSD databases, and the MSU USSA database show that the proposed approach is effective in face spoof detection for both the cross-database and intra-database testing scenarios. User studies of our Android face spoof detection system involving 20 participants show that the proposed approach works very well in real application scenarios.",
On Reverse Engineering-Based Hardware Trojan Detection,"Due to design and fabrication outsourcing to foundries, the problem of malicious modifications to integrated circuits (ICs), also known as hardware Trojans (HTs), has attracted attention in academia as well as industry. To reduce the risks associated with Trojans, researchers have proposed different approaches to detect them. Among these approaches, test-time detection approaches have drawn the greatest attention. Many test-time approaches assume the existence of a Trojan-free (TF) chip/model also known as “golden model.” Prior works suggest using reverse engineering (RE) to identify such TF ICs for the golden model. However, they did not state how to do this efficiently. In fact, RE is a very costly process which consumes lots of time and intensive manual effort. It is also very error prone. In this paper, we propose an innovative and robust RE scheme to identify the TF ICs. We reformulate the Trojan-detection problem as clustering problem. We then adapt a widely used machine learning method,
K
-means clustering, to solve our problem. Simulation results using state-of-the-art tools on several publicly available circuits show that the proposed approach can detect HTs with high accuracy rate. A comparison of this approach with our previously proposed approach [1] is also conducted. Both the limitations and application scenarios of the two methods are discussed in detail.","Trojan horses,
Layout,
Integrated circuits,
Support vector machines,
Feature extraction,
Hardware,
Fabrication"
Proposal of a GaN/SiC Hybrid Field-Effect Transistor for Power Switching Applications,"A GaN/SiC hybrid field-effect transistor (HyFET) is proposed as a high-voltage power device that provides a high-mobility lateral AlGaN/GaN channel to reduce the channel resistance and a vertical SiC drift region to sustain the high OFF-state voltage. The performance of the HyFET is evaluated by numerical device simulations. Compared with the conventional SiC MOSFET, the HyFET exhibits a greatly reduced RON together with a low CGD and low gate charges. The figures of merit QG × RON and QGD × RON of the HyFET are dramatically improved.",
Memetic Music Composition,"Computers and artificial intelligence play a key role in the production of artwork through the designing of synthetic agents that are able to reproduce the capabilities of human artists in assembling high-quality artefacts such as paintings and sculptures. In this context, music composition represents one of the art disciplines that can greatly benefit from the appropriate use of computational intelligence, as witnessed by the large number of research activities performed in this field over the recent years. Nevertheless, the automatic composition of music is far from being completely and precisely perfected due to the intrinsic virtuosity that characterizes human musicians' capabilities. This paper reduces this gap with the proposal of an intelligent scheme for the efficient composition of melodies based on a musical method that is inspired by and strongly characterized by human virtuosity: the unfigured bass technique. In particular, we formulate this music composition technique as an optimization problem and solve it with an adaptive multiagent memetic approach comprising diverse metaheuristics, the composer agents that cooperate to create high-quality four-voice pieces of music starting from a bass line as input. A collection of experimental studies on the famous Bach's four-voice chorales showed that the cooperation among different optimization strategies yields improved performance over the solutions obtained by conventional and hybrid evolutionary algorithms.","Optimization,
Memetics,
Computers,
Genetic algorithms,
Art,
Music,
Space exploration"
A standards-based approach for domain specific modelling of smart grid system architectures,"The ongoing integration of decentralized, renewable energies is a major challenge for today's power system. In order to control the volatile behaviour of these Distributed Energy Resources (DER), the electricity system has to evolve towards a Smart Grid. The development of this critical and complex System-of-Systems involves different stakeholder from different disciplines. Thus, domain specific engineering concepts on system level are needed. To foster the interdisciplinary development, the proposed approach presents a standards-based architecture framework, implemented as Domain Specific Language (DSL). Moreover, the DSL is used to develop a reference architecture on basis of the NIST Logical Reference Model. To evaluate the applicability of the reference architecture model it is used for instantiation of a particular system solution.","Smart grids,
Unified modeling language,
NIST,
DSL,
Computer architecture,
Security"
A Real-Time Information Based Demand-Side Management System in Smart Grid,"In this paper, we study a real-time information based demand-side management (DSM) system with advanced communication networks in smart grid. DSM can smooth peak-to-average ratio (PAR) of power usage in the grid, which in turn reduces the waste of fuel and the emission of greenhouse gas. We first target to minimize PAR with a centralized scheme. To motivate power suppliers, we further propose another centralized scheme targeting minimum power generation cost. However, customers may not be motivated by a centralized scheme since such a scheme requires total control and privacy from them. A centralized scheme also requires too much real-time data exchange for frequent DSM deployment. To tackle these issues, we propose game theoretical approaches so that most of the computation is performed locally. In the proposed game, all the customers are motivated by extra savings if participating. Moreover, we prove that all parties benefit from the DSM system to the same level because both the centralized schemes and the game theoretical approach minimize global PAR. Such an analysis is further demonstrated by the simulation results and discussions. Additionally, we evaluate the performance of several (partially) distributed approaches in order to find the best way to deploy DSM system.","Home appliances,
Games,
Generators,
Energy consumption,
Schedules,
Peak to average power ratio,
Power grids"
A novel approach for estimating Truck Factors,"Truck Factor (TF) is a metric proposed by the agile community as a tool to identify concentration of knowledge in software development environments. It states the minimal number of developers that have to be hit by a truck (or quit) before a project is incapacitated. In other words, TF helps to measure how prepared is a project to deal with developer turnover. Despite its clear relevance, few studies explore this metric. Altogether there is no consensus about how to calculate it, and no supporting evidence backing estimates for systems in the wild. To mitigate both issues, we propose a novel (and automated) approach for estimating TF-values, which we execute against a corpus of 133 popular project in GitHub. We later survey developers as a means to assess the reliability of our results. Among others, we find that the majority of our target systems (65%) have TF ≤ 2. Surveying developers from 67 target systems provides confidence towards our estimates; in 84% of the valid answers we collect, developers agree or partially agree that the TF's authors are the main authors of their systems; in 53% we receive a positive or partially positive answer regarding our estimated truck factors.","History,
Electronic mail,
Reliability,
Estimation,
Personnel,
Delays"
From high-level deep neural models to FPGAs,"Deep Neural Networks (DNNs) are compute-intensive learning models with growing applicability in a wide range of domains. FPGAs are an attractive choice for DNNs since they offer a programmable substrate for acceleration and are becoming available across different market segments. However, obtaining both performance and energy efficiency with FPGAs is a laborious task even for expert hardware designers. Furthermore, the large memory footprint of DNNs, coupled with the FPGAs' limited on-chip storage makes DNN acceleration using FPGAs more challenging. This work tackles these challenges by devising DnnWeaver, a framework that automatically generates a synthesizable accelerator for a given (DNN, FPGA) pair from a high-level specification in Caffe [1]. To achieve large benefits while preserving automation, DNNWEAVER generates accelerators using hand-optimized design templates. First, DnnWeaver translates a given high-level DNN specification to its novel ISA that represents a macro dataflow graph of the DNN. The DnnWeaver compiler is equipped with our optimization algorithm that tiles, schedules, and batches DNN operations to maximize data reuse and best utilize target FPGA's memory and other resources. The final result is a custom synthesizable accelerator that best matches the needs of the DNN while providing high performance and efficiency gains for the target FPGA. We use DnnWeaver to generate accelerators for a set of eight different DNN models and three different FPGAs, Xilinx Zynq, Altera Stratix V, and Altera Arria 10. We use hardware measurements to compare the generated accelerators to both multicore CPUs (ARM Cortex A15 and Xeon E3) and many-core GPUs (Tegra K1, GTX 650Ti, and Tesla K40). In comparison, the generated accelerators deliver superior performance and efficiency without requiring the programmers to participate in the arduous task of hardware design.",
Common-Mode Resonance Suppression in Transformerless PWM Current-Source Drive,"Among high-power pulsewidth modulation (PWM) current-source motor drives, the transformerless structure using the integrated dc choke has been widely acknowledged with superior advantages. A typical challenge faced by such transformerless PWM current-source drive systems is the potential common-mode resonance excited by the common-mode voltage (CMV). Since the implementation of power factor compensation (PFC) at low motor speeds may increase the CMV in such drives, the common-mode resonance could be serious and further aggravate the CMV stress on the system. In this paper, the critical factors on the common-mode resonance are thoroughly investigated. Based on the investigation, a solution based on average-value-reduction (AVR) space-vector modulation (SVM) is proposed to suppress the common-mode resonance while maintaining the PFC function. The investigation of common-mode resonance and the effectiveness of the proposed resonance suppression solution are verified through experiments on a transformerless PWM current-source drive system.","Pulse width modulation,
Support vector machines,
Inductors,
Power transformer insulation,
Reactive power,
Stress"
Local-Gravity-Face (LG-face) for Illumination-Invariant and Heterogeneous Face Recognition,"This paper proposes a novel method called local-gravity-face (LG-face) for illumination-invariant and heterogeneous face recognition (HFR). LG-face employs a concept called the local gravitational force angle (LGFA). The LGFA is the direction of the gravitational force that the center pixel exerts on the other pixels within a local neighborhood. A theoretical analysis shows that the LGFA is an illumination-invariant feature, considering only the reflectance part of the local texture effect of the neighboring pixels. It also preserves edge information. Rank 1 recognition rates of 97.78% on the CMU-PIE database and 97.31% on the Extended Yale B database are achieved under varying illumination, demonstrating that LG-face is an effective method of illumination-invariant face recognition. For HFR, when faces appear in different modalities, LG-face produces a common feature representation. Rank 1 recognition rates of 99.96% on the CUFS database, 98.67% on the CUFSF database, and 99.78% on the CASIA-HFB database show that the LG-face is also an effective method for HFR. The proposed method also performs consistently in the presence of complicated variations and noise.","Lighting,
Face,
Face recognition,
Databases,
Gravity,
Visualization,
Solid modeling"
Quantifying and evaluating the technical debt on mobile cloud-based service level,"As network bandwidth and coverage continue to increase, the adoption rates of mobile devices are growing over time and the mobile technology is becoming increasingly industrialized. In mobile cloud marketplaces, the cloud-supported mobile services can be leased off. However, the mobile service selection may introduce technical debt (TD), which is essential to be predicted and quantified. In this context, this paper examines the incurrence of technical debt in the future when leasing cloud-based mobile services by proposing a novel quantitative model, which adopts a linear and symmetric approach as a linear growth in the number of users is predicted. The formulation of the problem is based on a cost-benefit analysis, elaborating on the potential profit that could be obtained if the number of users would be equal to the maximum value. The probability of overutilization of the selected service in the long run is also researched. Finally, a quantification tool has been developed as a proof of concept (PoC), which initiates the technical debt analysis and optimization on mobile cloud-based service level and aims to provide insights into the overutilization or underutilization of a web service when a linear increase in the number of users occurs.","Decision support systems,
Quality of service,
Reliability"
Learning Contextual Dependence With Convolutional Hierarchical Recurrent Neural Networks,"Deep convolutional neural networks (CNNs) have shown their great success on image classification. CNNs mainly consist of convolutional and pooling layers, both of which are performed on local image areas without considering the dependence among different image regions. However, such dependence is very important for generating explicit image representation. In contrast, recurrent neural networks (RNNs) are well known for their ability of encoding contextual information in sequential data, and they only require a limited number of network parameters. Thus, we proposed the hierarchical RNNs (HRNNs) to encode the contextual dependence in image representation. In HRNNs, each RNN layer focuses on modeling spatial dependence among image regions from the same scale but different locations. While the cross RNN scale connections target on modeling scale dependencies among regions from the same location but different scales. Specifically, we propose two RNN models: 1) hierarchical simple recurrent network (HSRN), which is fast and has low computational cost and 2) hierarchical long-short term memory recurrent network, which performs better than HSRN with the price of higher computational cost. In this paper, we integrate CNNs with HRNNs, and develop end-to-end convolutional hierarchical RNNs (C-HRNNs) for image classification. C-HRNNs not only utilize the discriminative representation power of CNNs, but also utilize the contextual dependence learning ability of our HRNNs. On four of the most challenging object/scene image classification benchmarks, our C-HRNNs achieve the state-of-the-art results on Places 205, SUN 397, and MIT indoor, and the competitive results on ILSVRC 2012.","Recurrent neural networks,
Context modeling,
Natural language processing,
Logic gates,
Image representation,
Computer vision"
Integrated Servo-Mechanical Design of a Fine Stage for a Coarse/Fine Dual-Stage Positioning System,"Traditionally, the coarse and fine mechanical stages within a dual-stage positioning system are designed separately without consideration about their control performance in dual-stage integration. In this paper, a flexure-based Lorentz motor fine stage is designed concurrently with a simple PID controller to perform the dual-stage positioning, based on the existing coarse stage. The design of fine stage is carried out using a proposed integrated servo-mechanical design approach, where various specifications are considered and formulated as constraints in an optimization problem. Through the approach, both the plant modal parameters and controller parameters of fine stage are concurrently solved. It demonstrates that through suitable mechanical plant design, the fine stage can fulfill various control specifications by only using a simple PID controller, e.g., to compensate sensitivity peak, maintain stability, etc. Meanwhile, the proposed design approach also ensures certain open-loop positioning performance and the decoupling property of coarse/fine stages. The prototype of designed fine stage is fabricated, and experimental investigation indicates that the sensitivity peak is effectively reduced from 14.5 dB of coarse stage to 7.1 dB in the dual-stage system, and the fine stage is able to achieve submicrometer accuracy. The maximal tracking error is also reduced significantly from about 20 μm via the coarse stage to less than 2 μm through dual-stage positioning.","Sensitivity,
Transfer functions,
Mechatronics,
IEEE transactions,
Frequency measurement,
Optimization,
Permanent magnet motors"
Generic and Efficient Constructions of Attribute-Based Encryption with Verifiable Outsourced Decryption,"Attribute-based encryption (ABE) provides a mechanism for complex access control over encrypted data. However in most ABE systems, the ciphertext size and the decryption overhead, which grow with the complexity of the access policy, are becoming critical barriers in applications running on resource-limited devices. Outsourcing decryption of ABE ciphertexts to a powerful third party is a reasonable manner to solve this problem. Since the third party is usually believed to be untrusted, the security requirements of ABE with outsourced decryption should include privacy and verifiability. Namely, any adversary including the third party should learn nothing about the encrypted message, and the correctness of the outsourced decryption is supposed to be verified efficiently. We propose generic constructions of CPA-secure and RCCA-secure ABE systems with verifiable outsourced decryption from CPA-secure ABE with outsourced decryption, respectively. We also instantiate our CPA-secure construction in the standard model and then show an implementation of this instantiation. The experimental results show that, compared with the existing scheme, our CPA-secure construction has more compact ciphertext and less computational costs. Moreover, the techniques involved in the RCCA-secure construction can be applied in generally constructing CCA-secure ABE, which we believe to be of independent interest.","Encapsulation,
Encryption,
Outsourcing,
Standards,
Computational modeling"
Inherent Structure-Based Multiview Learning With Multitemplate Feature Representation for Alzheimer's Disease Diagnosis,"Multitemplate-based brain morphometric pattern analysis using magnetic resonance imaging has been recently proposed for automatic diagnosis of Alzheimer's disease (AD) and its prodromal stage (i.e., mild cognitive impairment or MCI). In such methods, multiview morphological patterns generated from multiple templates are used as feature representation for brain images. However, existing multitemplate-based methods often simply assume that each class is represented by a specific type of data distribution (i.e., a single cluster), while in reality, the underlying data distribution is actually not preknown. In this paper, we propose an inherent structure-based multiview leaning method using multiple templates for AD/MCI classification. Specifically, we first extract multiview feature representations for subjects using multiple selected templates and then cluster subjects within a specific class into several subclasses (i.e., clusters) in each view space. Then, we encode those subclasses with unique codes by considering both their original class information and their own distribution information, followed by a multitask feature selection model. Finally, we learn an ensemble of view-specific support vector machine classifiers based on their, respectively, selected features in each view and fuse their results to draw the final decision. Experimental results on the Alzheimer's Disease Neuroimaging Initiative database demonstrate that our method achieves promising results for AD/MCI classification, compared to the state-of-the-art multitemplate-based methods.","Feature extraction,
Brain,
Clustering algorithms,
Encoding,
Alzheimer's disease,
Support vector machines"
Robust Collaborative Nonnegative Matrix Factorization for Hyperspectral Unmixing,"Spectral unmixing is an important technique for remotely sensed hyperspectral data exploitation. It amounts to identifying a set of pure spectral signatures, which are called endmembers, and their corresponding fractional, draftrulesabun-dances in each pixel of the hyperspectral image. Over the last years, different algorithms have been developed for each of the three main steps of the spectral unmixing chain: 1) estimation of the number of endmembers in a scene; 2) identification of the spectral signatures of the endmembers; and 3) estimation of the fractional abundance of each endmember in each pixel of the scene. However, few algorithms can perform all the stages involved in the hyperspectral unmixing process. Such algorithms are highly desirable to avoid the propagation of errors within the chain. In this paper, we develop a new algorithm, which is termed robust collaborative nonnegative matrix factorization (R-CoNMF), that can perform the three steps of the hyperspectral unmixing chain. In comparison with other conventional methods, R-CoNMF starts with an overestimated number of endmembers and removes the redundant endmembers by means of collaborative regularization. Our experimental results indicate that the proposed method provides better or competitive performance when compared with other widely used methods.","Hyperspectral imaging,
Estimation,
Collaboration,
Robustness,
Geography,
Approximation algorithms"
TSentiment: On gamifying Twitter sentiment analysis,"Social media platforms contain interesting information that can be used to directly measure people' feelings and, thanks to the use of communication technologies, also to geographically locate these feelings. Unfortunately, the understanding is not as easy as one may think. Indeed, the large volume of data makes the manual approach impractical and the diversity of language combined with the brevity of the texts makes the automatic approach quite complicated. In this paper, we consider the gamification approach to sentimentally classify tweets and we propose TSentiment, a game with a purpose that uses human beings to classify the polarity of tweets (e.g., positive, negative, neutral) and their sentiment (e.g., joy, surprise, sadness, etc.). We created a dataset of more than 65,000 tweets, we developed a Web-based game and we asked students to play the game. Obtained results showed that the game approach was well accepted and thus it can be useful in scenarios where the identification of people' feelings may bring benefits to decision making processes.","Games,
Twitter,
Media,
Sentiment analysis,
Engines,
Conferences,
Urban areas"
Low-loss and Broadband G-Band Dielectric Interconnect for Chip-to-Chip Communication,"This paper presents a novel dielectric waveguide based G-band interconnect. By using a new transition of microstrip line to dielectric waveguide, the interconnect achieves low insertion loss and wide bandwidth. The measured minimum insertion loss is 4.9 dB with 9.7 GHz 1-dB bandwidth. Besides, the structure is based on standard micromachined processing and easy to integrate with conventional packaging.","Integrated circuit interconnections,
Optical waveguides,
Substrates,
Bandwidth,
Impedance,
Insertion loss,
Silicon"
A Bi-Projection Neural Network for Solving Constrained Quadratic Optimization Problems,"In this paper, a bi-projection neural network for solving a class of constrained quadratic optimization problems is proposed. It is proved that the proposed neural network is globally stable in the sense of Lyapunov, and the output trajectory of the proposed neural network will converge globally to an optimal solution. Compared with existing projection neural networks (PNNs), the proposed neural network has a very small model size owing to its bi-projection structure. Furthermore, an application to data fusion shows that the proposed neural network is very effective. Numerical results demonstrate that the proposed neural network is much faster than the existing PNNs.","Optimization,
Mathematical model,
Convergence,
Biological neural networks,
Recurrent neural networks,
Trajectory"
Multi-body Motion Estimation from Monocular Vehicle-Mounted Cameras,"This paper addresses the problem of simultaneous estimation of a vehicle's ego motion and motions of multiple moving objects in the scene-called eoru motions-through a monocular vehicle-mounted camera. Localization of multiple moving objects and estimation of their motions is crucial for autonomous vehicles. Conventional localization and mapping techniques (e.g., visual odometry and simultaneous localization and mapping) can only estimate the ego motion of the vehicle. The capability of a robot localization pipeline to deal with multiple motions has not been widely investigated in the literature. We present a theoretical framework for robust estimation of multiple relative motions in addition to the camera ego motion. First, the framework for general unconstrained motion is introduced and then it is adapted to exploit the vehicle kinematic constraints to increase efficiency. The method is based on projective factorization of the multiple-trajectory matrix. First, the ego motion is segmented and then several hypotheses are generated for the eoru motions. All the hypotheses are evaluated and the one with the smallest reprojection error is selected. The proposed framework does not need any a priori knowledge of the number of motions and is robust to noisy image measurements. The method with a constrained motion model is evaluated on a popular street-level image dataset collected in urban environments (the KITTI dataset), including several relative ego-motion and eoru-motion scenarios. A benchmark dataset (Hopkins 155) is used to evaluate this method with a general motion model. The results are compared with those of the state-of-the-art methods considering a similar problem, referred to as multibody structure from motion in the computer vision community.","Cameras,
Motion segmentation,
Vehicles,
Estimation,
Image segmentation,
Computer vision,
Tracking"
OpenPNM: A Pore Network Modeling Package,"Pore network modeling is a widely used technique for simulating multiphase transport in porous materials, but there are very few software options available. This work outlines the OpenPNM package that was jointly developed by several porous media research groups to help address this gap. OpenPNM is written in Python using NumPy and SciPy for most mathematical operations, thus combining Python's ease of use with the performance necessary to perform large simulations. The package assists the user with managing and interacting with all the topological, geometrical, and thermophysical data. It also includes a suite of commonly used algorithms for simulating percolation and performing transport calculations on pore networks. Most importantly, it was designed to be highly flexible to suit any application and be easily customized to include user-specified pore-scale physics models. The framework is fast, powerful, and concise. An illustrative example is included that determines the effective diffusivity through a partially water-saturated porous material with just 29 lines of code.","Computational modeling,
Mathematical model,
Object recognition,
Modeling,
Open source software,
Network topology"
Specific Emitter Identification Based on Nonlinear Dynamical Characteristics,"Specific emitter identification (SEI) designates the unique transmitter of a given signal, using only external feature measurements called the RF fingerprints of the signal. SEI is often used in military and civilian spectrum-management operations. The SEI technique has also been applied to enhance the security of wireless network, such as VHF radio networks, Wi-Fi networks, cognitive radios, and cellular networks. A novel SEI method based on nonlinear dynamical characteristics is proposed in this paper. The method works based on the actual signal's inherent nonlinear dynamical characteristics. The permutation entropy is extracted as the signal's RF fingerprint to identify the unique transmitter. The quadrature phase-shift keying (QPSK) signals from four wireless network cards and differential quadrature phase-shift keying (DQPSK) signals from three digital radios are utilized to evaluate the performance of the method. Experimental results demonstrate that the proposed method is effective. On the other hand, the proposed method is convenient to implement in a PC.","Entropy,
Transient analysis,
Radio frequency,
Time series analysis,
Radio transmitters,
Wireless networks,
Phase shift keying"
Simultaneous template optimization and mask assignment for DSA with multiple patterning,"Block Copolymer Directed Self-Assembly (DSA) is a promising technique to print contacts/vias for the 10nm technology node and beyond. By using hybrid lithography that cooperates DSA with multiple patterning, multiple masks are used to print the DSA templates and then the templates can be used to guide the self-assembly of the block copolymer. In this paper, we propose approaches to solve the simultaneous template optimization and mask assignment problem for DSA with multiple patterning. We verified in experiments that our approaches remarkably outperform the state of the art work in reducing the manufacturing cost.","Layout,
Self-assembly,
Lithography,
Optimization,
Heuristic algorithms,
Pattern matching"
An Islanding Detection Method for Inverter-Based Distributed Generators Based on the Reactive Power Disturbance,"In this paper, an islanding detection method for inverter-based distributed generators (DGs) is presented, which is based on perturbing reactive power output. Two sets of disturbances are configured in this method, which have different amplitudes and duration time. The first set of reactive power disturbance (FSORPD) is periodic with small amplitudes to break the reactive power balance during islanding, whereas the magnitude of the second set of reactive power disturbance (SSORPD) is sufficient to force the frequency to deviate outside its threshold limits. Considering all the possible frequency variation characteristics with the FSORPD after islanding, three criterions are designed for switching the disturbance from the FSORPD to the SSORPD. Since DGs located at different positions have the same frequency variation characteristics, the SSORPDs can be added on different DGs at the same time without the need of communication. Therefore, synchronization of the SSORPDs can be guaranteed for the system with multiple DGs and the method can detect islanding with a zero nondetection zone property. Moreover, the method can be applied to the DG either operating at unity power factor or supplying reactive power as well for its local load. According to the antiislanding test system recommended in IEEE Std.929-2000 and IEEE Std.1547-2003, the effectiveness of the method has been validated with several case studies in the power systems computer-aided design/Electro magnetic transient in DC system environment.",
"A Spatial Mashup Service for Efficient Evaluation of Concurrent k
-NN Queries","Although the travel time is the most important information in road networks, many spatial queries, e.g.,
k
-nearest-neighbor (
k
-NN) and range queries, for location-based services (LBS) are only based on the network distance. This is because it is costly for an LBS provider to collect real-time traffic data from vehicles or roadside sensors to compute the travel time between two locations. With the advance of web mapping services, e.g., Google Maps, Microsoft Bing Maps, and MapQuest Maps, there is an invaluable opportunity for using such services for processing spatial queries based on the travel time. In this paper, we propose a server-side Spatial M ashup Service (SMS) that enables the LBS provider to efficiently evaluate
k
-NN queries in road networks using the route information and travel time retrieved from an external web mapping service. Due to the high cost of retrieving such external information, the usage limits of web mapping services, and the large number of spatial queries, we optimize the SMS for a large number of
k
-NN queries. We first discuss how the SMS processes a single
k
-NN query using two optimizations, namely, direction sharing and parallel requesting. Then, we extend them to process multiple concurrent
k
-NN queries and design a performance tuning tool to provide a trade-off between the query response time and the number of external requests and more importantly, to prevent a starvation problem in the parallel requesting optimization for concurrent queries. We evaluate the performance of the proposed SMS using MapQuest Maps, a real road network, real and synthetic data sets. Experimental results show the efficiency and scalability of our optimizations designed for the SMS.",
TimeSpan: Using Visualization to Explore Temporal Multi-dimensional Data of Stroke Patients,"We present TimeSpan, an exploratory visualization tool designed to gain a better understanding of the temporal aspects of the stroke treatment process. Working with stroke experts, we seek to provide a tool to help improve outcomes for stroke victims. Time is of critical importance in the treatment of acute ischemic stroke patients. Every minute that the artery stays blocked, an estimated 1.9 million neurons and 12 km of myelinated axons are destroyed. Consequently, there is a critical need for efficiency of stroke treatment processes. Optimizing time to treatment requires a deep understanding of interval times. Stroke health care professionals must analyze the impact of procedures, events, and patient attributes on time-ultimately, to save lives and improve quality of life after stroke. First, we interviewed eight domain experts, and closely collaborated with two of them to inform the design of TimeSpan. We classify the analytical tasks which a visualization tool should support and extract design goals from the interviews and field observations. Based on these tasks and the understanding gained from the collaboration, we designed TimeSpan, a web-based tool for exploring multi-dimensional and temporal stroke data. We describe how TimeSpan incorporates factors from stacked bar graphs, line charts, histograms, and a matrix visualization to create an interactive hybrid view of temporal data. From feedback collected from domain experts in a focus group session, we reflect on the lessons we learned from abstracting the tasks and iteratively designing TimeSpan.",
Incentive Mechanism Design for Heterogeneous Crowdsourcing Using All-Pay Contests,"Many crowdsourcing scenarios are heterogeneous in the sense that, not only the workers' types (e.g., abilities or costs) are different, but the beliefs (probabilistic knowledge) about their respective types are also different. In this paper, we design an incentive mechanism for such scenarios using an asymmetric all-pay contest (or auction) model. Our design objective is an optimal mechanism, i.e., one that maximizes the crowdsourcing revenue minus cost. To achieve this, we furnish the contest with a prize tuple which is an array of reward functions each for a potential winner. We prove and characterize the unique equilibrium of this contest, and solve the optimal prize tuple. In addition, this study discovers a counter-intuitive property, called strategy autonomy (SA), which means that heterogeneous workers behave independently of one another as if they were in a homogeneous setting. In game-theoretical terms, it says that an asymmetric auction admits a symmetric equilibrium. Not only theoretically interesting, but SA also has important practical implications on mechanism complexity, energy efficiency, crowdsourcing revenue, and system scalability. By scrutinizing seven mechanisms, our extensive performance evaluation demonstrates the superior performance of our mechanism as well as offers insights into the SA property.","Crowdsourcing,
Sensors,
Mobile computing,
Probabilistic logic,
Mechanical factors,
Mobile communication,
Bayes methods"
Channel-Access-Aware User Association With Interference Coordination in Two-Tier Downlink Cellular Networks,"The diverse transmit power levels of base stations (BSs) in a multitier cellular network, on the one hand, lead to an uneven distribution of traffic loads among different BSs when received signal power (RSP)-based user association is used. This causes underutilization of resources at low-power BSs. On the other hand, strong interference from high-power BSs affects downlink transmissions to the users associated with low-power BSs. In this context, this paper proposes a channel-access-aware (CAA) user association scheme that can simultaneously enhance the spectral efficiency (SE) of downlink transmission and achieve traffic load balancing among different BSs. The CAA scheme is a network-assisted user association scheme that requires traffic load information from different BSs, in addition to channel quality indicators. We develop a tractable mathematical model to derive the SE of the network and the SE of downlink transmission to a user who associates with a BS using the proposed CAA scheme considering almost blank subframe (ABS)-based interference coordination at a macro BS. The framework can model and analyze the individual traffic load distributions of different BSs in a two-tier network. The derived expressions provide approximate solutions of reasonable accuracy, compared with the results obtained from Monte Carlo simulations. Numerical results comparatively analyze the gains of the CAA scheme over conventional-RSP-based association and biased-RSP-based association. Based on this, important insights are extracted, which are related to the selection of the proportion of an ABS in various traffic load scenarios.","Interference,
Fading,
Downlink,
Shadow mapping,
Macrocell networks,
Load modeling,
Load management"
Simulations of a Vibrissa Slipping along a Straight Edge and an Analysis of Frictional Effects during Whisking,"During tactile exploration, rats sweep their whiskers against objects in a motion called whisking. Here, we investigate how a whisker slips along an object's edge and how friction affects the resulting tactile signals. First, a frictionless model is developed to simulate whisker slip along a straight edge and compared with a previous model that incorporates friction but cannot simulate slip. Results of both models are compared to behavioral data obtained as a rat whisked against a smooth, stainless steel peg. As expected, the frictionless model predicts larger magnitudes of vertical slip than observed experimentally. The frictionless model also predicts forces and moments at the whisker base that are smaller and have a different direction than those predicted by the model with friction. Estimates for the friction coefficient yielded values near 0.48 (whisker/stainless steel). The present work provides the first assessments of the effects of friction on the mechanical signals received by the follicle during active whisking. It also demonstrates a proof-of-principle approach for reducing whisker tracking requirements during experiments and demonstrates the feasibility of simulating a full array of vibrissae whisking against a peg.","Friction,
Force,
Mathematical model,
Three-dimensional displays,
Shape,
Predictive models,
Kinematics"
Situation Analytics: A Foundation for a New Software Engineering Paradigm,Advances in cognitive science along with modern-day smart technologies and software services that take into account our mental state will enable a software industry that is poised to meet customers' needs on the fly in new and truly individualized ways.,"Cognition,
Context awareness,
Machine learning,
Services computing,
Software engineering"
A Dual-Polarity Graphene NEMS Switch ESD Protection Structure,"Conventional on-chip electrostatic discharge (ESD) protection structures for integrated circuits (ICs) rely on in-Si p-n-junction-based devices, which have many inherent disadvantages unsuitable for ICs at nanonodes. This letter reports a novel above-IC graphene-based nanoelectromechanical system (gNEMS) transient switch ESD protection mechanism and structure. Transmission line pulse testing shows dual-polarity transient ESD switching effect with a response time down to 200 ps. This gNEMS switch is a potential ESD protection solution to realize the above-Si ESD protection designs through 3-D integration in IC back end of line.","Electrostatic discharges,
Switches,
Graphene,
Transient analysis,
Integrated circuits,
Fabrication,
Switching circuits"
Cloudlet load balancing in wireless metropolitan area networks,"With advances in wireless communication technology, more and more people depend heavily on portable mobile devices for businesses, entertainments and social interactions. Although such portable mobile devices can offer various promising applications, their computing resources remain limited due to their portable size. This however can be overcome by remotely executing computation-intensive tasks on clusters of near by computers known as cloudlets. As increasing numbers of people access the Internet via mobile devices, it is reasonable to envision in the near future that cloudlet services will be available for the public through easily accessible public wireless metropolitan area networks (WMANs). However, the outdated notion of treating cloudlets as isolated data-centers-in-a-box must be discarded as there are clear benefits to connecting multiple cloudlets together to form a network. In this paper we investigate how to balance the workload between multiple cloudlets in a network to optimize mobile application performance. We first introduce a system model to capture the response times of offloaded tasks, and formulate a novel optimization problem, that is to find an optimal redirection of tasks between cloudlets such that the maximum of the average response times of tasks at cloudlets is minimized. We then propose a fast, scalable algorithm for the problem. We finally evaluate the performance of the proposed algorithm through experimental simulations. The experimental results demonstrate the significant potential of the proposed algorithm in reducing the response times of tasks.","Cloud computing,
Time factors,
Mobile handsets,
Delays,
Mobile communication,
Computers,
Load management"
Review on the State-of-the-Art Technologies for Acquisition and Display of Digital Holograms,"Optical holography for recording three-dimensional (3-D) scenes can be traced back to the early sixties. Since then, the art of holography has been applied in many areas, primarily as a tool for 3-D imaging, processing, and display. Extension of optical holography to other disciplines, such as optical computing and encryption, has been explored, but the scope of development is relatively limited. However, with the rapid advancements in electronics, computing, and material science technologies, most of the optical processes can be substituted with numerical or digital hardware means, thus leading to the emergence of digital holography. A typical digital holography framework can be encapsulated into three major stages, namely the input, processing, and output stages. The input and output stages are gatekeepers connecting the optical and digital worlds, without which the study on digital holography could only be restricted to theoretical and numerical analysis. In the past few decades, numerous research works have been conducted on these two important areas. In this paper, we shall provide a review on the recent development in these two important areas of digital holography. Selected pieces of important and popular works on the acquisition and display of digital holograms will be reported.","Holography,
Holographic optical components,
Optical imaging,
Laser beams,
Optical recording,
Optical reflection,
Optical scattering"
All PM Fiber Laser Mode Locked With a Compact Phase Biased Amplifier Loop Mirror,"An Yb-doped, all-polarization-maintaining fiber laser oscillator with a nonlinear amplifying loop mirror is presented in this letter. A new compact non-reciprocal phase shifter biased fiber loop mirror was engaged inside the fiber laser, which results in a low threshold and stable mode locking. With a 2.8-nm filter inside the cavity, the mode locked output power is 4.1 mW with the repetition rate of 31.35 MHz at the pump power of 80 mW. The spectral bandwidth of the pulse is 3.1 nm. The pulsewidth of the direct output and the dechirped pulse are 2.13 ps and 538 fs, respectively. The filter bandwidth plays a significant role in the spectrum bandwidth and the direct output pulse width.",
Design and Demonstration of 820-GHz Array Using Diode-Connected NMOS Transistors in 130-nm CMOS for Active Imaging,"An 820-GHz 8 × 8 diode-connected NMOS transistor active imaging array with an on-chip pixel selection circuit was demonstrated in a 130-nm CMOS technology. The noise performance of this architecture is comparable to the state-of-the-art MOSFET and Schottky diode detector arrays. The imaging array consists of a row and column selector, an array of diode-connected NMOS transistor passive pixels, an analog multiplexer, and a low-noise amplifier bank. At 823 GHz, it achieves 2.56 kV/W of measured mean responsivity with a standard deviation of 18% and 36.2 pW/Hz1/2 of measured mean noise equivalent power (NEP) at 1-MHz modulation frequency with a standard deviation of 67%. The mean responsivity is greater than ~ 2 kV/W between 815 to 835 GHz. The minimum NEP of 12.6 pW/Hz1/2 is the lowest for CMOS based detectors at ~ 1 THz. The 8 × 8 imaging array occupies 2.0 × 1.7 mm2 and consumes 9.6 mW of power. Reducing device sizes to support the increase of operating frequency is expected to increase the variability and mitigation approaches will be required. The measured access time for the pixel is ~ 40 nS. The number of elements that can be connected in a row is determined by the modulation frequency and can be more than 1000 elements while supporting a frame rate greater than 1000 per second. Lastly, the expressions of responsivity and NEP including 1/f noise that can be used for the detector optimization are derived and presented .","Arrays,
Imaging,
Detectors,
MOSFET,
Computational modeling,
Integrated circuit modeling,
Schottky diodes"
Achieving Exact Cluster Recovery Threshold via Semidefinite Programming,"The binary symmetric stochastic block model deals with a random graph of n vertices partitioned into two equal-sized clusters, such that each pair of vertices is independently connected with probability p within clusters and q across clusters. In the asymptotic regime of p = a log n/n and q = b log n/n for fixed a, b, and n → ∞, we show that the semidefinite programming relaxation of the maximum likelihood estimator achieves the optimal threshold for exactly recovering the partition from the graph with probability tending to one, resolving a conjecture of Abbe et al. Furthermore, we show that the semidefinite programming relaxation also achieves the optimal recovery threshold in the planted dense subgraph model containing a single cluster of size proportional to n.","Stochastic processes,
Maximum likelihood estimation,
Programming,
Symmetric matrices,
Linear matrix inequalities,
Maximum likelihood detection,
Clustering algorithms"
Authentication Scheme for Flexible Charging and Discharging of Mobile Vehicles in the V2G Networks,"Navigating security and privacy challenges is one of the crucial requirements in the vehicle-to-grid (V2G) network. Since electric vehicles (EVs) need to provide their private information to aggregators/servers when charging/discharging at different charging stations, privacy of the vehicle owners can be compromised if the information is misused, traced, or revealed. In a wide V2G network, where vehicles can move outside of their home network to visiting networks, security and privacy become even more challenging due to untrusted entities in the visiting networks. Although some privacy-preserving solutions were proposed in the literature to tackle this problem, they do not protect against well-known security attacks and generate a huge overhead. Therefore, we propose a mutual authentication scheme to preserve privacy of the EV's information from aggregators/servers in the home as well as distributed visiting V2G networks. Our scheme, based on a bilinear pairing technique with an accumulator performing batch verification, yields higher system efficiency, defeats various security attacks, and maintains untraceability, forward privacy, and identity anonymity. A performance analysis shows that our scheme, in comparison with the existing solutions, significantly generates lower communication and computation overheads in the home and centralized V2G networks, and comparable overheads in the distributed visiting V2G networks.",
Least Cost Influence Maximization Across Multiple Social Networks,"Recently, in online social networks (OSNs), the least cost influence (LCI) problem has become one of the central research topics. It aims at identifying a minimum number of seed users who can trigger a wide cascade of information propagation. Most of existing literature investigated the LCI problem only based on an individual network. However, nowadays users often join several OSNs such that information could be spread across different networks simultaneously. Therefore, in order to obtain the best set of seed users, it is crucial to consider the role of overlapping users under this circumstances. In this article, we propose a unified framework to represent and analyze the influence diffusion in multiplex networks. More specifically, we tackle the LCI problem by mapping a set of networks into a single one via lossless and lossy coupling schemes. The lossless coupling scheme preserves all properties of original networks to achieve high-quality solutions, while the lossy coupling scheme offers an attractive alternative when the running time and memory consumption are of primary concern. Various experiments conducted on both real and synthesized datasets have validated the effectiveness of the coupling schemes, which also provide some interesting insights into the process of influence propagation in multiplex networks.","Social network services,
Multiplexing,
Optimization,
Synchronization,
Propagation losses,
Facebook"
Reliable Decentralized Fault Prognosis of Discrete-Event Systems,"We investigate the problem of reliable decentralized fault prognosis of partially-observed discrete-event systems. In this problem, n local prognosers are deployed to send their local prognostic decisions to a coordinator that calculates the final prognostic decision. However, only k (1≤ k ≤ n) local prognostic decisions are guaranteed to be available to the coordinator due to possible failures or communication losses of at most n - k local prognosers. We propose the notion of k-reliable decentralized prognoser in order to address this reliability issue. A necessary and sufficient condition for the existence of a k-reliable decentralized prognoser, which predicts faults prior to their occurrences, is presented. This condition is termed as k-reliable coprognosability. A polynomial-time algorithm for the verification of k-reliable coprognosability is presented. We also demonstrate how to compute the k-reliable reactive bound prior to any occurrence of faults.","Prognostics and health management,
Automata,
Cybernetics,
Discrete-event systems,
Software reliability,
Robustness"
Single-Feed Quad-Beam Transmitarray Antenna Design,"We present a design methodology for single-feed multibeam transmitarray antennas through case studies of quad-beam designs. Different far-field pattern masks and fitness functions are studied for multibeam designs, and the particle swarm optimization (PSO) technique is implemented for aperture phase synthesis. A quad-layer configuration of double square loops is used for the transmitarray elements, and a quad-beam transmitarray prototype is fabricated and tested. The effects of various approximations in unit-cell analysis are also investigated in detail. The Ku-band prototype generates four symmetric beams with 50° elevation separation between the beams and gains around 23 dB.","Transmitting antennas,
Antenna radiation patterns,
Gain,
Arrays,
Aperture antennas,
Prototypes"
The Internet of Molecular Things Based on FRET,"Molecular devices, which consist of single or a few molecules, are envisioned to perform advanced tasks such as molecular information processing and collaborative sensing/actuating if they are operated in a cooperative manner. To connect these nanoscopic primitive devices with each other and with macroscale networks, and thus, to realize the internet of molecular devices, requires fundamentally different and novel approaches, other than the molecular or electromagnetic nanocommunications. Recently, we proposed and studied the use of Förster resonance energy transfer (FRET), which is a short-range nonradiative energy transfer process between fluorophores, as a high-rate and reliable wireless communication mechanism to connect fluorophore-based photoactive molecular devices. In this paper, we provide an in-depth architectural view of this new communication paradigm with a focus on its peculiarities, fundamental principles, and design requirements by comprehensively surveying the theoretical and experimental positions and ideas. We give an overview of networking opportunities offered by the intrinsic capabilities of fluorophores under the novel concept of Internet of Molecular Things. We present some prospective applications, theoretical modeling approaches, and experimental opportunities, and finally discuss the implementation challenges.","Excitons,
Optical transmitters,
Receivers,
Optical switches,
Relays,
Absorption,
Nanoscale devices"
Spatio-Temporal Kronecker Compressive Sensing for Traffic Matrix Recovery,"A traffic matrix is generally used by several network management tasks in a data center network, such as traffic engineering and anomaly detection. It gives a flow-level view of the network traffic volume. Despite the explicit importance of the traffic matrix, it is significantly difficult to implement a large-scale measurement to build an absolute traffic matrix. Generally, the traffic matrix obtained by the operators is imperfect, i.e., some traffic data may be lost. Hence, we focus on the problems of recovering these missing traffic data in this paper. To recover these missing traffic data, we propose the spatio-temporal Kronecker compressive sensing method, which draws on Kronecker compressive sensing. In our method, we account for the spatial and temporal properties of the traffic matrix to construct a sparsifying basis that can sparsely represent the traffic matrix. Simultaneously, we consider the low-rank property of the traffic matrix and propose a novel recovery model. We finally assess the estimation error of the proposed method by recovering real traffic.","Telecommunication traffic,
Compressed sensing,
Estimation error,
Telecommunication network management,
Sensor systems"
Evaluation Framework for User Experience in 5G Systems: On Systematic Rateless-Coded Transmissions,"This paper investigates the system performance evaluation framework of systematic rateless-coded (SRCed) transmissions for user experience in future 5G systems. To this end, we define the application-layer information loss ratio (AILR), i.e., the ratio of the number of unsuccessfully decoded messages to that of the total transmitted messages, as a system performance index from the perspective over network application layer, which can be used as an evaluation framework on the users' experience in the viewpoint of 5G transmission systems. By using the integer partition theory, we analytically derive some theoretical results and then obtain an exact expression of the AILR for SRCed transmissions. Simulation and numerical results are provided to demonstrate the validness of our analytical results, which also show that the SRCed transmission achieves much better system performance than existing coded transmission methods in terms of AILR. Moreover, by using our presented AILR expression, the proper system configuration can be easily determined without a heavy burden of Monte Carlo simulations. It also illustrates some inherent relationships between system parameters by using SRCed transmission on application layer, which can be easily carried out to achieve a better performance in the viewpoint of users' experiences. First, for a given channel condition, the larger the message length is, the smaller the ratio of the message length to the source symbol length should be selected. Second, for a given message length, the better the channel condition is, the larger the ratio of the message length to the source symbol length should be selected.",
Optimal Deployment of Distributed Generation Using a Reliability Criterion,"This paper presents an optimal planning approach toward the design of cost-efficient and reliable microgrids. The proposed approach uses simulated annealing (SA) to determine the optimal size and location of a mix of distributed generation (DG) candidate technologies to achieve stipulated reliability criteria. The deployment plan consists of adding suitable quantities of DG at appropriate locations, and is optimal in that the cost of expansion is minimized. The paper develops the models and the approach, and describes an SA-based implementation. The method is demonstrated on a standard test system, and the application of the method as a planning tool is illustrated by means of two case studies: 1) optimal expansion of an existing distribution system into a microgrid and 2) evaluation of the impact of projected prices on the deployment strategy. Relative penetration of different DG technologies is also analyzed.",
A Probabilistic Approach to Determine Optimal Capacity and Location of Electric Vehicles Parking Lots in Distribution Networks,"In this paper, a probabilistic approach based on the point estimate method is presented to determine the optimal capacity and location of electric vehicles (EVs) parking lots in distribution networks. For this purpose, uncertain parameters in driving patterns of vehicle owners are considered, and the effects of these uncertainties on determination of optimal capacity and profit from the construction of parking lots have been investigated. The proposed approach has considered both technical and economical aspects simultaneously. Additionally, because of the necessity of optimal schedule and the determination of EV charging and discharging time intervals to calculate the benefits of the amount of parking lot power exchange with a distribution network and EVs, a new approach is proposed to charge schedule of EVs. This method runtime, in addition to simple mechanism and global optimal responses, is very short. Finally, the presented probabilistic method is performed on two test distribution networks and obtained results are discussed.","Discharges (electric),
System-on-chip,
Vehicles,
Schedules,
Mathematical model,
Probabilistic logic,
Uncertainty"
Probabilistic Deep Spiking Neural Systems Enabled by Magnetic Tunnel Junction,"Deep spiking neural networks are becoming increasingly powerful tools for cognitive computing platforms. However, most of the existing studies on such computing models are developed with limited insights on the underlying hardware implementation, resulting in area and power expensive designs. Although several neuromimetic devices emulating neural operations have been proposed recently, their functionality has been limited to very simple neural models that may prove to be inefficient at complex recognition tasks. In this paper, we venture into the relatively unexplored area of utilizing the inherent device stochasticity of such neuromimetic devices to model complex neural functionalities in a probabilistic framework in the time domain. We consider the implementation of a deep spiking neural network capable of performing high-accuracy and lowlatency classification tasks, where the neural computing unit is enabled by the stochastic switching behavior of a magnetic tunnel junction. The simulation studies indicate an energy improvement of 20× over a baseline CMOS design in 45-nm technology.","Artificial neural networks,
Neurons,
Switches,
Magnetic tunneling,
Computational modeling,
Probabilistic logic"
Joint Feature Selection and Subspace Learning for Cross-Modal Retrieval,"Cross-modal retrieval has recently drawn much attention due to the widespread existence of multimodal data. It takes one type of data as the query to retrieve relevant data objects of another type, and generally involves two basic problems: the measure of relevance and coupled feature selection. Most previous methods just focus on solving the first problem. In this paper, we aim to deal with both problems in a novel joint learning framework. To address the first problem, we learn projection matrices to map multimodal data into a common subspace, in which the similarity between different modalities of data can be measured. In the learning procedure, the ℓ2-norm penalties are imposed on the projection matrices separately to solve the second problem, which selects relevant and discriminative features from different feature spaces simultaneously. A multimodal graph regularization term is further imposed on the projected data,which preserves the inter-modality and intra-modality similarity relationships.An iterative algorithm is presented to solve the proposed joint learning problem, along with its convergence analysis. Experimental results on cross-modal retrieval tasks demonstrate that the proposed method outperforms the state-of-the-art subspace approaches.","Terrorism,
Meteorology,
Buildings,
Sun,
Iterative methods,
Correlation,
Ice"
Social Friend Recommendation Based on Multiple Network Correlation,"Friend recommendation is an important recommender application in social media. Major social websites such as Twitter and Facebook are all capable of recommending friends to individuals. However, most of these websites use simple friend recommendation algorithms such as similarity, popularity, or “friend's friends are friends,” which are intuitive but consider few of the characteristics of the social network. In this paper we investigate the structure of social networks and develop an algorithm for network correlation-based social friend recommendation (NC-based SFR). To accomplish this goal, we correlate different “social role” networks, find their relationships and make friend recommendations. NC-based SFR is characterized by two key components: 1) related networks are aligned by selecting important features from each network, and 2) the network structure should be maximally preserved before and after network alignment. After important feature selection has been made, we recommend friends based on these features. We conduct experiments on the Flickr network, which contains more than ten thousand nodes and over 30 thousand tags covering half a million photos, to show that the proposed algorithm recommends friends more precisely than reference methods.","Correlation,
Network topology,
Media,
Topology,
Twitter"
Efficient Algorithms for Capacitated Cloudlet Placements,"Mobile cloud computing is emerging as a main ubiquitous computing platform to provide rich cloud resources for various applications of mobile devices. Although most existing studies in mobile cloud computing focus on energy savings of mobile devices by offloading computing-intensive jobs from mobile devices to remote clouds, the access delays between mobile users and remote clouds usually are long and sometimes unbearable. Cloudlet as a new technology is capable to bridge this gap, and can enhance the performance of mobile devices significantly while meeting the crisp response time requirements of mobile users. In this paper, we study the cloudlet placement problem in a large-scale Wireless Metropolitan Area Network (WMAN) consisting of many wireless Access Points (APs). We first formulate the problem as a novel capacitated cloudlet placement problem that places K
cloudlets to some strategic locations in the WMAN with the objective to minimize the average access delay between mobile users and the cloudlets serving the users. We then propose an exact solution to the problem by formulating it as an Integer Linear Programming (ILP). Due to the poor scalability of the ILP, we instead propose an efficient heuristic for the problem. For a special case of the problem where all cloudlets have identical computing capacities, we devise novel approximation algorithms with guaranteed approximation ratios. We also devise an online algorithm for dynamically allocating user requests to different cloudlets, if the K
cloudlets have already been placed. We finally evaluate the performance of the proposed algorithms through experimental simulations. Simulation results demonstrate that the proposed algorithms are promising and scalable.","Cloud computing,
Mobile communication,
Delays,
Approximation algorithms,
Mobile handsets,
Approximation methods,
Heuristic algorithms"
Multivariate Discretization Based on Evolutionary Cut Points Selection for Classification,"Discretization is one of the most relevant techniques for data preprocessing. The main goal of discretization is to transform numerical attributes into discrete ones to help the experts to understand the data more easily, and it also provides the possibility to use some learning algorithms which require discrete data as input, such as Bayesian or rule learning. We focus our attention on handling multivariate classification problems, where high interactions among multiple attributes exist. In this paper, we propose the use of evolutionary algorithms to select a subset of cut points that defines the best possible discretization scheme of a data set using a wrapper fitness function. We also incorporate a reduction mechanism to successfully manage the multivariate approach on large data sets. Our method has been compared with the best state-of-the-art discretizers on 45 real datasets. The experiments show that our proposed algorithm overcomes the rest of the methods producing competitive discretization schemes in terms of accuracy, for C4.5, Naive Bayes, PART, and PrUning and BuiLding Integrated in Classification classifiers; and obtained far simpler solutions.","Sociology,
Statistics,
Biological cells,
Genetic algorithms,
Evolutionary computation,
Accuracy,
Proposals"
Real-Time Classification of Hand Motions Using Ultrasound Imaging of Forearm Muscles,"Surface electromyography (sEMG) has been the predominant method for sensing electrical activity for a number of applications involving muscle-computer interfaces, including myoelectric control of prostheses and rehabilitation robots. Ultrasound imaging for sensing mechanical deformation of functional muscle compartments can overcome several limitations of sEMG, including the inability to differentiate between deep contiguous muscle compartments, low signal-to-noise ratio, and lack of a robust graded signal. The objective of this study was to evaluate the feasibility of real-time graded control using a computationally efficient method to differentiate between complex hand motions based on ultrasound imaging of forearm muscles. Dynamic ultrasound images of the forearm muscles were obtained from six able-bodied volunteers and analyzed to map muscle activity based on the deformation of the contracting muscles during different hand motions. Each participant performed 15 different hand motions, including digit flexion, different grips (i.e., power grasp and pinch grip), and grips in combination with wrist pronation. During the training phase, we generated a database of activity patterns corresponding to different hand motions for each participant. During the testing phase, novel activity patterns were classified using a nearest neighbor classification algorithm based on that database. The average classification accuracy was 91%. Real-time image-based control of a virtual hand showed an average classification accuracy of 92%. Our results demonstrate the feasibility of using ultrasound imaging as a robust muscle-computer interface. Potential clinical applications include control of multiarticulated prosthetic hands, stroke rehabilitation, and fundamental investigations of motor control and biomechanics.",
Quantitative Evaluation of Wind Turbine Faults Under Variable Operational Conditions,"Wind turbines have been widely used for clean and renewable electricity generation. The maintenance costs of wind turbines constitute a significant portion of the total cost of the generated electricity. Thus, health management systems are increasingly needed to reduce the maintenance costs and improve the reliability of wind turbines. This paper proposes a novel framework for the quantitative evaluation of faults and health conditions of wind turbines using generator current signals. A synchronous resampling algorithm is designed to handle nonstationary current signals for fault feature extraction. The extracted fault features are used to reconstruct new signals, whose correlation dimensions are then calculated by using the Grassberger-Procaccia (G-P) algorithm for fault and health condition evaluation of the wind turbines. Experimental studies are carried out for a direct-drive wind turbine equipped with a permanent-magnet synchronous generator (PMSG) in the healthy condition and two faulty conditions. Results show that the proposed framework can not only detect the faults but also quantify different health conditions for the wind turbine.","Wind turbines,
Correlation,
Feature extraction,
Algorithm design and analysis,
Condition monitoring,
Vibrations"
"Strong Data Processing Inequalities and \Phi
-Sobolev Inequalities for Discrete Channels","The noisiness of a channel can be measured by comparing suitable functionals of the input and output distributions. For instance, the worst case ratio of output relative entropy to input relative entropy for all possible pairs of input distributions is bounded from above by unity, by the data processing theorem. However, for a fixed reference input distribution, this quantity may be strictly smaller than one, giving the so-called strong data processing inequalities (SDPIs). The same considerations apply to an arbitrary Φ-divergence. This paper presents a systematic study of optimal constants in the SDPIs for discrete channels, including their variational characterizations, upper and lower bounds, structural results for channels on product probability spaces, and the relationship between the SDPIs and the so-called Φ-Sobolev inequalities (another class of inequalities that can be used to quantify the noisiness of a channel by controlling entropy-like functionals of the input distribution by suitable measures of input-output correlation). Several applications to information theory, discrete probability, and statistical physics are discussed.","Data processing,
Markov processes,
Entropy,
Probability distribution,
Correlation,
Information theory,
Kernel"
An Analysis of the Inertia Weight Parameter for Binary Particle Swarm Optimization,"In particle swarm optimization (PSO), the inertia weight is an important parameter for controlling its search capability. There have been intensive studies of the inertia weight in continuous optimization, but little attention has been paid to the binary case. This paper comprehensively investigates the effect of the inertia weight on the performance of binary PSO (BPSO), from both theoretical and empirical perspectives. A mathematical model is proposed to analyze the behavior of BPSO, based on which several lemmas and theorems on the effect of the inertia weight are derived. Our research findings suggest that in the binary case, a smaller inertia weight enhances the exploration capability while a larger inertia weight encourages exploitation. Consequently, this paper proposes a new adaptive inertia weight scheme for BPSO. This scheme allows the search process to start first with exploration and gradually move toward exploitation by linearly increasing the inertia weight. The experimental results on 0/1 knapsack problems show that the BPSO with the new increasing inertia weight scheme performs significantly better than that with the conventional decreasing and constant inertia weight schemes. This paper verifies the efficacy of increasing inertia weight in BPSO.","Particle swarm optimization,
Acceleration,
Standards,
Optimization,
Electronic mail,
Sociology,
Statistics"
Long-Term Renewable Energy Planning Model for Remote Communities,"This paper presents a novel long-term renewable energy (RE) planning model for remote communities (RCs), considering the characteristics of diesel-based RCs in Canada and other parts of the world such as Alaska and northern Chile. Over the past few years, there has been a significant increase in assessing and deploying RE projects in northern remote locations. The model proposed in this paper adds to such efforts by creating a multiple-year community planning tool that can be used to determine economic and technically feasible RE solutions, considering the current operating structures, electricity pricing systems, subsidy frameworks, and project funding alternatives under which RE can be deployed in RCs. The proposed model is implemented in a case study for the Kasabonika Lake First Nation community in northern Ontario. The case study shows that RE projects can be feasible under current operating conditions, for a set of funding alternatives that share the economic risks.","Planning,
Mathematical model,
Economics,
Microgrids,
Wind forecasting,
Wind speed,
Fuels"
An FPGA-Based Instrument for En-Masse RRAM Characterization With ns Pulsing Resolution,"An FPGA-based instrument with capabilities of on-board oscilloscope and nanoscale pulsing (70 ns @ ±10 V) is presented, thus allowing exploration of the nano-scale switching of RRAM devices. The system possesses less than 1% read-out error for resistance range between 1 kΩ to 1 MΩ, and demonstrated its functionality on characterizing solid-state prototype RRAM devices on wafer; devices exhibiting gradual switching behavior under pulsing with duration spanning between 30 ns to 100 μs. The data conversion error-induced degradation on read-out accuracy is studied extensively and verified by standard linear resistor measurements. The integrated oscilloscope capability extends the versatility of our instrument, rendering a powerful tool for processing development of emerging memory technologies but also for testing theoretical hypotheses arising in the new field of memristors.","Resistance,
Memristors,
Switches,
Arrays,
Oscilloscopes"
A Millimeter-Wave Filtering Monopulse Antenna Array Based on Substrate Integrated Waveguide Technology,"A millimeter-wave filtering monopulse antenna array based on substrate integrated waveguide (SIW) technology is proposed, manufactured, and tested in this communication. The proposed antenna array consists of a filter, a monopulse comparator, a feed network, and four antennas. A square dual-mode SIW cavity is designed to realize the monopulse comparator, in which internal coupling slots are located at its diagonal lines for the purpose of meeting the internal coupling coefficiencies in both sum and difference channels. Then, a four-output filter including the monopulse comparator is synthesized efficiently by modifying the coupling matrix of a single-ended filter. Finally, each SIW resonator coupled with those four outputs of the filter is replaced by a cavity-backed slot antenna so as to form the proposed filtering antenna array. A prototype is demonstrated at Ka band with a center frequency of 29.25 GHz and fractional bandwidth of 1.2%. Our measurement shows that, for the H-plane, the sidelobe levels of the sum pattern are less than -15 dB and the null depths of the difference pattern are less than -28 dB. The maximum measured gain of the sum beam at the center operating frequency is 8.1 dBi.","Antenna arrays,
Arrays,
Resonator filters,
Antenna measurements,
Cavity resonators,
Couplings"
How to Generate a Good Word Embedding,"The authors analyze three critical components in training word embeddings: model, corpus, and training parameters. They systematize existing neural-network-based word embedding methods and experimentally compare them using the same corpus. They then evaluate each word embedding in three ways: analyzing its semantic properties, using it as a feature for supervised tasks, and using it to initialize neural networks. They also provide several simple guidelines for training good word embeddings.","Object recognition,
Neural networks,
Embedded systems,
Distributed processing,
Training,
Analytical models,
Semantics"
Learning And-Or Model to Represent Context and Occlusion for Car Detection and Viewpoint Estimation,"This paper presents a method for learning an And-Or model to represent context and occlusion for car detection and viewpoint estimation. The learned And-Or model represents car-to-car context and occlusion configurations at three levels: (i) spatially-aligned cars, (ii) single car under different occlusion configurations, and (iii) a small number of parts. The And-Or model embeds a grammar for representing large structural and appearance variations in a reconfigurable hierarchy. The learning process consists of two stages in a weakly supervised way (i.e., only bounding boxes of single cars are annotated). First, the structure of the And-Or model is learned with three components: (a) mining multi-car contextual patterns based on layouts of annotated single car bounding boxes, (b) mining occlusion configurations between single cars, and (c) learning different combinations of part visibility based on CAD simulations. The And-Or model is organized in a directed and acyclic graph which can be inferred by Dynamic Programming. Second, the model parameters (for appearance, deformation and bias) are jointly trained using Weak-Label Structural SVM. In experiments, we test our model on four car detection datasets-the KITTI dataset [1] , the PASCAL VOC2007 car dataset [2] , and two self-collected car datasets, namely the Street-Parking car dataset and the Parking-Lot car dataset, and three datasets for car viewpoint estimation-the PASCAL VOC2006 car dataset [2] , the 3D car dataset [3] , and the PASCAL3D+ car dataset [4] . Compared with state-of-the-art variants of deformable part-based models and other methods, our model achieves significant improvement consistently on the four detection datasets, and comparable performance on car viewpoint estimation.",
Face-Based Heart Rate Signal Decomposition and Evaluation Using Multiple Linear Regression,"Contact measurements of the cardiac pulse using the conventional electrocardiogram equipment requires patients to wear adhesive gel patches or chest straps that can cause skin irritation and discomfort. Commercially available pulse oximetry sensors that attach to the fingertips or earlobes also cause inconvenience for patients and the spring-loaded clips can be painful to use. Therefore, a novel robust non-contact technique is developed for the evaluation of heart rate variation. According to the periodic variation of reflectance strength resulting from changes to hemoglobin absorptivity across the visible light spectrum as heartbeats cause changes to blood volume in the blood vessels in the face, a reflectance signal is decomposed from consecutive frames of the green channel of the facial region. Furthermore, ensemble empirical mode decomposition of the Hilbert-Huang transform (HHT) is used to acquire the primary heart rate signal while reducing the effect of ambient light changes. The effective instantaneous frequencies from intrinsic mode functions decomposed by HHT are implemented by the multiple-linear regression model to evaluate heart rates before the frequencies were rectified by maximum likelihood method assuming Poisson distribution, and the minimum elapse time for heart rate evaluation is also evaluated in the estimate process. Experimental results show that our proposed approach provides a convenient non-contact method to evaluate heart rate and outperforms the current state-of-the-art method with higher accuracy and smaller variance.","Reflectivity,
Heart rate,
Face,
Sensors,
Lighting,
Blood,
Empirical mode decomposition"
Software Development in Startup Companies: The Greenfield Startup Model,"Software startups are newly created companies with no operating history and oriented towards producing cutting-edge products. However, despite the increasing importance of startups in the economy, few scientific studies attempt to address software engineering issues, especially for early-stage startups. If anything, startups need engineering practices of the same level or better than those of larger companies, as their time and resources are more scarce, and one failed project can put them out of business. In this study we aim to improve understanding of the software development strategies employed by startups. We performed this state-of-practice investigation using a grounded theory approach. We packaged the results in the Greenfield Startup Model (GSM), which explains the priority of startups to release the product as quickly as possible. This strategy allows startups to verify product and market fit, and to adjust the product trajectory according to early collected user feedback. The need to shorten time-to-market, by speeding up the development through low-precision engineering activities, is counterbalanced by the need to restructure the product before targeting further growth. The resulting implications of the GSM outline challenges and gaps, pointing out opportunities for future research to develop and validate engineering practices in the startup context.","Software,
Companies,
GSM,
Context,
Software engineering,
History"
Automatic Web Service Composition Based on Uncertainty Execution Effects,"By arranging multiple existing web services into workflows to create value-added services, automatic web service composition has received much attention in service-oriented computing. A large number of methods have been proposed for it although most of them are merely based on the matching of input-output parameters of services. Besides these parameters, some other elements can affect the execution of services and their composition, such as the preconditions and service execution results. In particular, the execution effects of some services are often uncertain because of the complex and dynamically changing application environments in the real world, and this can cause the emergence of nondeterministic choices in the workflows of composite services. However, the previous methods for automatic service composition mainly rely on sequential structures, which make them difficult to take into account uncertain effects during service composition. In this paper, Graphplan is employed and extended to tackle this problem. In order to model services with uncertain effects, we first extend the original form of Graphplan. Then, we propose a novel approach that can introduce branch structures into composite solutions to cope with such uncertainty in the service composition process. Extensive experiments are performed to evaluate and analyze the proposed methodology.","Planning,
Web services,
Libraries,
Uncertainty,
Standards,
Educational institutions,
Business"
Online Metric-Weighted Linear Representations for Robust Visual Tracking,"In this paper, we propose a visual tracker based on a metric-weighted linear representation of appearance. In order to capture the interdependence of different feature dimensions, we develop two online distance metric learning methods using proximity comparison information and structured output learning. The learned metric is then incorporated into a linear representation of appearance. We show that online distance metric learning significantly improves the robustness of the tracker, especially on those sequences exhibiting drastic appearance changes. In order to bound growth in the number of training samples, we design a time-weighted reservoir sampling method. Moreover, we enable our tracker to automatically perform object identification during the process of object tracking, by introducing a collection of static template samples belonging to several object classes of interest. Object identification results for an entire video sequence are achieved by systematically combining the tracking information and visual recognition at each frame. Experimental results on challenging video sequences demonstrate the effectiveness of the method for both inter-frame tracking and object identification.","Visualization,
Reservoirs,
Robustness,
Tracking,
Correlation,
Optimization"
Effective Multimodality Fusion Framework for Cross-Media Topic Detection,"Due to the prevalence of We-Media, information is quickly published and received in various forms anywhere and anytime through the Internet. The rich cross-media information carried by the multimodal data in multiple media has a wide audience, deeply reflects the social realities, and brings about much greater social impact than any single media information. Therefore, automatically detecting topics from cross media is of great benefit for the organizations (i.e., advertising agencies and governments) that care about the social opinions. However, cross-media topic detection is challenging from the following aspects: 1) the multimodal data from different media often involve distinct characteristics and 2) topics are presented in an arbitrary manner among the noisy web data. In this paper, we propose a multimodality fusion framework and a topic recovery (TR) approach to effectively detect topics from cross-media data. The multimodality fusion framework flexibly incorporates the heterogeneous multimodal data into a multimodality graph, which takes full advantage from the rich cross-media information to effectively detect topic candidates (T.C.). The TR approach solidly improves the entirety and purity of detected topics by: 1) merging the T.C. that are highly relevant themes of the same real topic and 2) filtering out the less-relevant noise data in the merged T.C. Extensive experiments on both single-media and cross-media data sets demonstrate the promising flexibility and effectiveness of our method in detecting topics from cross media.","Media,
Noise level,
Feature extraction,
Visualization,
Robustness,
Fuses,
Complexity theory"
A Framework of Price Bidding Configurations for Resource Usage in Cloud Computing,"In this paper, we focus on price bidding strategies of multiple users competition for resource usage in cloud computing. We consider the problem from a game theoretic perspective and formulate it into a non-cooperative game among the multiple cloud users, in which each cloud user is informed with incomplete information of other users. For each user, we design a utility function which combines the net profit with time efficiency and try to maximize its value. We design a mechanism for the multiple users to evaluate their utilities and decide whether to use the cloud service. Furthermore, we propose a framework for each cloud user to compute an appropriate bidding price. At the beginning, by relaxing the condition that the allocated number of servers can be fractional, we prove the existence of Nash equilibrium solution set for the formulated game. Then, we propose an iterative algorithm (

), which is designed to compute a Nash equilibrium solution. The convergency of the proposed algorithm is also analyzed and we find that it converges to a Nash equilibrium if several conditions are satisfied. Finally, we revise the obtained solution and propose a near-equilibrium price bidding algorithm (

) to characterize the whole process of our proposed framework. The experimental results show that the obtained near-equilibrium solution is close to the equilibrium one.",
Crowdsourced POI labelling: Location-aware result inference and Task Assignment,"Identifying the labels of points of interest (POIs), aka POI labelling, provides significant benefits in location-based services. However, the quality of raw labels manually added by users or generated by artificial algorithms cannot be guaranteed. Such low-quality labels decrease the usability and result in bad user experiences. In this paper, by observing that crowdsourcing is a best-fit for computer-hard tasks, we leverage crowdsourcing to improve the quality of POI labelling. To our best knowledge, this is the first work on crowdsourced POI labelling tasks. In particular, there are two sub-problems: (1) how to infer the correct labels for each POI based on workers' answers, and (2) how to effectively assign proper tasks to workers in order to make more accurate inference for next available workers. To address these two problems, we propose a framework consisting of an inference model and an online task assigner. The inference model measures the quality of a worker on a POI by elaborately exploiting (i) worker's inherent quality, (ii) the spatial distance between the worker and the POI, and (iii) the POI influence, which can provide reliable inference results once a worker submits an answer. As workers are dynamically coming, the online task assigner judiciously assigns proper tasks to them so as to benefit the inference. The inference model and task assigner work alternately to continuously improve the overall quality. We conduct extensive experiments on a real crowdsourcing platform, and the results on two real datasets show that our method significantly outperforms state-of-the-art approaches.","Labeling,
Crowdsourcing,
Computational modeling,
Random variables,
Computer science,
Mobile radio mobility management,
Reliability"
Group-Based Authentication and Key Agreement With Dynamic Policy Updating for MTC in LTE-A Networks,"Machine type communication (MTC) is an important mobile communication approach in the long-term evaluation-advanced (LTE-A) networks. To meet the MTC security requirements, the access authentication processing of MTC devices needs to follow the evolved packet system-authentication and key agreement (EPS-AKA), a protocol defined in the third generation partnership project (3GPP) standard. However, in the emergence of group-based communication scenarios, an independent authentication processing for each MTC device will cause signal congestion in the networks. In addition, the access-policy updating has always been an issue when constructing authentication schemes. In this paper, we propose a group-based AKA (GR-AKA) protocol with dynamic policy updating. Specifically, we choose an asynchronous secret share scheme combining with Diffie-Hellman key exchange scheme to implement distributed authentication and session key establishment in the LTE-A networks, and to achieve dynamic MTC-device access authority updating. Compared with other authentication protocols in the LTE-A networks, our method could not only authenticate several MTC devices simultaneously but also dynamically update the access-policy to control the access authority of MTC devices. Extensive analysis and experiment results have shown the efficiency and efficacy of proposed protocol.",
"Weighted Schatten p
-Norm Minimization for Image Denoising and Background Subtraction","Low rank matrix approximation (LRMA), which aims to recover the underlying low rank matrix from its degraded observation, has a wide range of applications in computer vision. The latest LRMA methods resort to using the nuclear norm minimization (NNM) as a convex relaxation of the nonconvex rank minimization. However, NNM tends to over-shrink the rank components and treats the different rank components equally, limiting its flexibility in practical applications. We propose a more flexible model, namely, the weighted Schatten p-norm minimization (WSNM), to generalize the NNM to the Schatten p-norm minimization with weights assigned to different singular values. The proposed WSNM not only gives better approximation to the original low-rank assumption, but also considers the importance of different rank components. We analyze the solution of WSNM and prove that, under certain weights permutation, WSNM can be equivalently transformed into independent non-convex lp-norm subproblems, whose global optimum can be efficiently solved by generalized iterated shrinkage algorithm. We apply WSNM to typical low-level vision problems, e.g., image denoising and background subtraction. Extensive experimental results show, both qualitatively and quantitatively, that the proposed WSNM can more effectively remove noise, and model the complex and dynamic scenes compared with state-of-the-art methods.","Wireless sensor networks,
Minimization,
Optimization,
Electronic mail,
Sparse matrices,
Image denoising,
Computational modeling"
Architectures for Recursive Digital Filters Using Stochastic Computing,"This paper addresses implementation of digital IIR filters using stochastic computing. Stochastic computing requires fewer logic gates and is inherently fault-tolerant. Thus, these structures are well suited for nanoscale CMOS technologies. While it is easy to realize FIR filters using stochastic computing, implementation of IIR digital filters is non-trivial. Stochastic logic assumes independence of input signals; however, feedback in IIR digital filters leads to correlation of input signals, and the independence assumption is violated. This paper demonstrates that, despite feedback in IIR filters, these filters can be implemented using stochastic logic. The key to stochastic implementation is selection of an IIR filter structure where the states are orthogonal and are, therefore, uncorrelated. Two categories of architectures are presented for stochastic IIR digital filters. One category is based on the basic lattice filter representation where the states are orthogonal, and the other is based on the normalized lattice filter representation where states are orthonormal . For each category, three stochastic implementations are introduced. The first is based on a state-space description of the IIR filter derived from the lattice filter structure. The second is based on transforming the lattice IIR digital filter into an equivalent form that can exploit the novel scaling approach developed for inner product computations. The third is optimized stochastic implementation with reduced number of binary multipliers. Simulation results demonstrate high signal-to-error ratio and fault tolerance in these structures. Furthermore, hardware synthesis results show that these filter structures require lower hardware area and power compared to two's complement realizations.","Lattices,
Finite impulse response filters,
Covariance matrices,
Fault tolerance,
Fault tolerant systems,
Correlation,
Logic gates"
Power Management for Cooperative Localization: A Game Theoretical Approach,"Network cooperation among agents can significantly increase their position accuracy at the cost of power consumption. Current power management techniques aim at minimizing the total position estimation errors over all the agents subject to the power budgets. There are two main drawbacks for these approaches. First, the performance of a single agent may be sacrificed for the benefit of the whole network, and second, full power budget may be used for only marginal performance improvement on the position accuracy. This paper proposes a new type of power management strategies where each agent individually minimizes its square position error bound penalized by its power cost. The strategies are obtained as solutions to two power management games that are formulated under the knowledge of local information and global information, respectively. We show that agents are more likely to cooperate when global information is available or the channel quality is good. Analytical and numerical results show that the proposed strategies significantly reduce the energy consumption with only marginal performance loss in position accuracy.","Games,
Resource management,
Distance measurement,
Power measurement,
Optimization,
Synchronization,
Mathematical model"
Stochastic Optimal Control for Wireless Powered Communication Networks,"In this paper, we propose a stochastic optimal control algorithm for the wireless powered communication networks (WPCNs), in which the access point (AP) supplies energy to wireless nodes by means of the RF energy transfer technology. The energy beamforming is used to enhance the RF energy transfer efficiency by concentrating the radiated power on target nodes. Each wireless node is equipped with an energy queue and a data queue. We propose an algorithm that minimizes the expected energy transmission power from the AP while stabilizing the data queues of all nodes. The proposed algorithm is an online algorithm that adaptively decides the beamforming vector, the data scheduling, and the data transmission power, only based on the current state of the energy and the data queues. The proposed algorithm dynamically steers the energy beam to nodes that currently have low energy in the energy queue. We apply the Lyapunov optimization technique to design such an algorithm. We mathematically prove that the proposed algorithm achieves the optimal performance.","Data communication,
Radio frequency,
Array signal processing,
Optimization,
Wireless communication,
Energy exchange,
Energy harvesting"
Transmit Power Minimization for Wireless Networks With Energy Harvesting Relays,"Energy harvesting (EH) has recently emerged as a key technology for green communications as it can power wireless networks with renewable energy sources. However, directly replacing the conventional non-EH transmitters by EH nodes will be a challenge. In this paper, we propose to deploy extra EH nodes as relays over an existing non-EH network. Specifically, the considered non-EH network consists of multiple source-destination (S-D) pairs. The deployed EH relays will take turns to assist each S-D pair, and energy diversity can be achieved to combat the low-EH rate of each EH relay. To make the best of these EH relays, with the source transmit power minimization as the design objective, we formulate a joint power assignment and relay selection problem, which, however, is NP-hard. We thus propose a general framework to develop efficient suboptimal algorithms, which is mainly based on a sufficient condition for the feasibility of the optimization problem. This condition yields useful design insights and also reveals an energy hardening effect, which provides the possibility to exempt the requirement of noncausal EH information. Simulation results will show that the proposed co-operation strategy can achieve near-optimal performance and provide significant power savings. Compared to the greedy co-operation method that only optimizes the performance of the current transmission block, the proposed strategy can achieve the same performance with much fewer relays, and the performance gap increases with the number of S-D pairs.","Relays,
Wireless networks,
Optimization,
Energy harvesting,
Algorithm design and analysis,
Protocols,
Minimization"
Comprehensive Parameterization of Solar Cell: Improved Accuracy With Simulation Efficiency,"Simulating photovoltaic (PV) power systems becomes important when studying integration issues of the intermittent solar energy into electric grids. The accuracy of the maximum power point (MPP) in PV output model is a concern since it represents the capacity of power generation. This paper proposes a comprehensive approach to identify PV cell parameters and avoid model errors of the MPP based on standard and simplified equivalent circuits. The estimation accuracy has been improved while maintaining the computational simplicity. This paper begins with the definition of the performance index used to quantify the model accuracy at the MPP. Based on the availability of information from the manufacturer's datasheets, the accuracy and complexity of different equivalent circuits are discussed and investigated. The proposed approach has been successfully tested for solar cells made of mono and multi crystalline material.","Mathematical model,
Accuracy,
Computational modeling,
Integrated circuit modeling,
Resistance,
Short-circuit currents,
Equivalent circuits"
Nonnegative-Matrix-Factorization-Based Hyperspectral Unmixing With Partially Known Endmembers,"Hyperspectral unmixing is an important technique for estimating fractions of various materials from remote sensing imagery. Most unmixing methods make the assumption that no prior knowledge of endmembers is available before the estimation. This is, however, not true for some unmixing tasks for which part of the endmember signatures may be known in advance. In this paper, we address the hyperspectral unmixing problem with partially known endmembers. We extend nonnegative-matrix-factorization-based unmixing algorithms to incorporate prior information into their models. The proposed approach uses the spectral signature of known endmembers as a constraint, among others, in the unmixing model, and propagates the knowledge by an optimization process which minimizes the difference between the image data and the prior knowledge. Results on both synthetic and real data have validated the effectiveness of the proposed method and have shown that it has outperformed several state-of-the-art methods that use or do not use prior knowledge of endmembers.","Hyperspectral imaging,
Libraries,
Dictionaries,
Estimation,
Linear programming"
3D Mapping for Visualization of Rigid Structures: A Review and Comparative Study,"In this review, we discuss state-of-the-art developments in 3D models for small and rigid structures. This includes the pros and cons of cutting-edge range cameras used as active 3D scanners, while also considering passive image reconstruction schemes by means of the well-known structure-from-motion (SfM) algorithms. Furthermore, we discuss the issue of how data fusion algorithms can be used to optimally fuse 2D contour information onto 3D models for several different applications. Considering the benefits of 3D range sensors, we also review current trends in optimum data fusion of point clouds from 3D range sensors. We present the benefits and the limitations of each algorithm against various design considerations. To highlight the pros and cons, we also perform a comparative study of the performance of a 3D range sensor, represented by an iPad structure sensor, with respect to the well-known SfM software packages, namely, Bundler, Microsoft PhotoSynth, Agisoft PhotoScan, and Smart3DCapture. Last, we highlight several research opportunities and potential research challenges associated with each technique.","Three-dimensional displays,
Sensors,
Cameras,
Laser radar,
Solid modeling,
Tablet computers,
Accuracy"
Identification and Punishment Policies for Spectrum Sensing Data Falsification Attackers Using Delivery-Based Assessment,"Spectrum sensing data falsification (SSDF) attacks represent a major challenge for cooperative spectrum sensing (CSS) in cognitive radio (CR) networks. In an SSDF attack, a malicious user or many malicious users send false sensing results to the fusion center (FC) to mislead the global decision about spectrum occupancy. Thus, an SSDF attack degrades the achievable detection accuracy, throughput, and energy efficiency of CR networks (CRNs). In this paper, a novel attacker-identification algorithm is proposed that is able to skillfully detect attackers and reject their reported results. Moreover, we provide a novel attacker-punishment algorithm that aims at punishing attackers by lowering their individual energy efficiency, motivating them either to quit sending false results or leave the network. Both algorithms are based on a novel assessment strategy of the sensing performance of each user. The proposed strategy is called delivery-based assessment, which relies on the delivery of the transmitted data to evaluate the made global decision and the individual reports. Mathematical analysis and simulation results show promising performance of both algorithms compared with previous works, particularly when then the number of attackers is very large.","Sensors,
Cascading style sheets,
Data communication,
Cognitive radio,
Algorithm design and analysis,
Simulation,
Reliability"
An Efficient Data-Driven Clustering Technique to Detect Attacks in SCADA Systems,"Supervisory control and data acquisition (SCADA) systems have become a salient part in controlling critical infrastructures, such as power plants, energy grids, and water distribution systems. In the past decades, these systems were isolated and use proprietary software, operating systems, and protocols. In recent years, SCADA systems have been interfaced with enterprise systems, which therefore exposed them to the vulnerabilities of the Internet and the security threats. Traditional security solutions (e.g., firewalls, antivirus software, and intrusion detection systems) cannot fully protect SCADA systems, because they have different requirements. This paper presents an innovative intrusion detection approach to detect SCADA tailored attacks. This is based on a data-driven clustering technique of process parameters, which automatically identifies the normal and critical states of a given system. Later, it extracts proximity-based detection rules from the identified states for monitoring purposes. The effectiveness of the proposed approach is tested by conducting experiments on eight data sets that consist of process parameters' values. The empirical results demonstrated an average accuracy of 98% in automatically identifying the critical states, while facilitating the monitoring of the SCADA system.","Monitoring,
SCADA systems,
Servers,
Security,
Computer science,
Water resources"
Epileptic Seizure Detection Based on Partial Directed Coherence Analysis,"Long-term video EEG epilepsy monitoring can help doctors diagnose and cure epilepsy. The workload of doctors to read the EEG signals of epilepsy patients can be effectively reduced by automatic seizure detection. The application of partial directed coherence (PDC) analysis as mechanism for feature extraction in the scalp EEG recordings for seizure detection could reflect the physiological changes of brain activity before and after seizure onsets. In this study, a new approach on the basis of PDC was proposed to detect the seizure intervals of epilepsy patients. First of all, the multivariate autoregressive model was established for a moving window and the direction and intensity of information flow based on PDC analysis was calculated. Then, the outflow information related to certain EEG channel could be obtained by summing up the intensity of information flow propagated to other EEG channels in order to reduce the feature dimensionality. At last, according to the pathological features of epileptic seizures, the outflow information was regarded as the input vectors to a support vector machine classifier for discriminating interictal periods and ictal periods of EEG signals. The proposed method had achieved a good performance with the correct rate of 98.3%, the selectivity rate of 67.88%, the sensitivity rate of 91.44%, the specificity rate of 99.34%, and the average detection rate of 95.39%, which demonstrated that this method was suitable for detecting the seizure intervals of epilepsy patients. By comparing with other existing techniques, the proposed method based on PDC analysis achieved significant improvement in terms of seizure detection.","Electroencephalography,
Epilepsy,
Support vector machines,
Feature extraction,
Brain modeling,
Scalp"
Multieigenvalue Communication,"In the most general case, all three components-the discrete eigenvalues, the discrete spectral amplitudes, and the continuous spectrum-of the nonlinear Fourier transform of a signal can be independently modulated. This paper examines information transmission using only the discrete eigenvalues, and presents heuristic designs for multisoliton signal sets with spectral efficiencies greater than 3 b/s/Hz. The first design, called multieigenvalue position encoding, is based on an exhaustive search followed by pruning of the signal set to remove high pulsewidth or high bandwidth outliers. The second design, called trellis encoding, achieves comparable efficiencies to the fist method at much lower complexity. These multisoliton signals do not undergo any pulse broadening, but are significantly limited by bandwidth expansion if the system length is not much smaller than the dispersion length parameter. This limitation suggests that modulating the eigenvalues alone cannot address the problem of nonlinearity in commercial fiber transmission systems, and that our proposed methods are only meaningful when dispersion is very small and dominated by nonlinearity, e.g., close to the zero-dispersion wavelength at 1300 nm.",
Recurrent Fuzzy Neural Cerebellar Model Articulation Network Fault-Tolerant Control of Six-Phase Permanent Magnet Synchronous Motor Position Servo Drive,"A recurrent fuzzy neural cerebellar model articulation network (RFNCMAN) fault-tolerant control of a six-phase permanent magnet synchronous motor (PMSM) position servo drive is proposed in this study. First, the fault detection and operating decision method of the six-phase PMSM position servo drive is developed. Then, an ideal computed torque controller is designed for the tracking of the rotor position reference command. In general, it is impossible to design an ideal computed control law owing to the uncertainties of the six-phase PMSM position servo drive, which are difficult to know in advance for practical applications. Therefore, the RFNCMAN, which combined the merits of a recurrent fuzzy cerebellar model articulation network and a recurrent fuzzy neural network, is proposed to estimate a nonlinear equation included in the ideal computed control law with a robust compensator designed to compensate the minimum reconstructed error. Furthermore, the adaptive learning algorithm for the online training of the RFNCMAN is derived using the Lyapunov stability to guarantee the closed-loop stability. Finally, the proposed RFNCMAN fault-tolerant control system is implemented in a 32-bit floating-point DSP. The effectiveness of the six-phase PMSM position servo drive using the proposed intelligent fault-tolerant control system is verified by some experimental results.","Windings,
Torque,
Fault tolerance,
Fault tolerant systems,
Servomotors,
Uncertainty"
Wireless Physical-Layer Identification: Modeling and Validation,"The wireless physical-layer identification (WPLI) techniques utilize the unique features of the physical waveforms of wireless signals to identify and classify authorized devices. As the inherent physical-layer features are difficult to forge, WPLI is deemed as a promising technique for wireless security solutions. However, as of today, it still remains unclear whether the existing WPLI techniques can be applied under real-world requirements and constraints. In this paper, through both theoretical modeling and experiment validation, the reliability and the differentiability of the WPLI techniques are rigorously evaluated, especially under the constraints of the state-of-the-art wireless devices, real operation environments, as well as wireless protocols and regulations. In particular, a theoretical model is first established to systematically describe the complete procedure of the WPLI. More importantly, the proposed model is then implemented to thoroughly characterize the various WPLI techniques that utilize the spectrum features coming from the nonlinear RF front-end, under the influences from different transmitters, receivers, and wireless channels. Subsequently, the limitations of the existing WPLI techniques are revealed and evaluated in details using both the developed theoretical model and the in-lab experiments. The real-world requirements and constraints are characterized along each step in WPLI, including: 1) the signal processing at the transmitter (device to be identified); 2) the various physical-layer features that originate from circuits, antenna, and environments; 3) the signal propagation in various wireless channels; 4) the signal reception and processing at the receiver (the identifier); and 5) the fingerprint extraction and classification at the receiver.","Wireless communication,
Communication system security,
Receivers,
Wireless sensor networks,
Transmitters,
Reliability,
Feature extraction"
Negative Capacitance Behavior in a Leaky Ferroelectric,"We present a simulation study of the negative capacitance effect incorporating leakage through the ferroelectric (FE) negative capacitor. The dynamics of the FE is modeled using the Landau-Khalatnikov equation. When an FE and a dielectric are simply connected in series without a metal contact between them, the stabilization of negative capacitance remains unchanged irrespective of leakage. However, when a metal is used, any finite leakage through the FE makes it impossible to stabilize negative capacitance at the steady state. Nonetheless, when a voltage is applied, the series configuration enters the negative capacitance state and as long as the gate voltage is cycled faster than the time needed by the leakage current to discharge all the capacitors, the transistor shows improved subthreshold swing. These results are expected to provide insight into understanding and analyzing recent experimental results on negative capacitance.","Iron,
Capacitors,
Capacitance,
Logic gates,
Mathematical model,
Radio frequency"
Integrated adaptation with multi-factor joint-learning for far-field speech recognition,"Although great progress has been made in automatic speech recognition (ASR), significant performance degradation still exists in distant talking scenarios due to significantly lower signal power. In this paper, a novel adaptation framework, named integrated adaptation with multi-factor joint-learning, is proposed to improve the recognition accuracy for distant speech recognition. We explore and extract speaker, phone and environment factor representations using deep neural networks (DNNs), which are integrated into the main ASR DNN to improve classification accuracy. In addition, the hidden activations in the main ASR DNN are used to improve the factor extraction, which in turn helps the ASR DNN. All the model parameters, including those in the ASR DNN and factor extractor DNNs, are jointly optimized under the multi-task learning framework. Further more, unlike prior techniques, our novel approach requires no explicit separate stages for factor extraction and adaptation. Experiments on the AMI single distant microphone (SDM) task show that the proposed architecture can significantly reduce word error rate (WER) and additional improvement can be achieved by combining it with the i-vector adaptation. Our best configuration obtained more than 15% and 10% relative reduction on WER over the baselines using the SDM and close-talk data generated alignments, respectively.","Feature extraction,
Speech recognition,
Training,
Speech,
Adaptation models,
Data mining,
Hidden Markov models"
A Survey of Vision-Based Traffic Monitoring of Road Intersections,"Visual surveillance of dynamic objects, particularly vehicles on the road, has been, over the past decade, an active research topic in computer vision and intelligent transportation systems communities. In the context of traffic monitoring, important advances have been achieved in environment modeling, vehicle detection, tracking, and behavior analysis. This paper is a survey that addresses particularly the issues related to vehicle monitoring with cameras at road intersections. In fact, the latter has variable architectures and represents a critical area in traffic. Accidents at intersections are extremely dangerous, and most of them are caused by drivers' errors. Several projects have been carried out to enhance the safety of drivers in the special context of intersections. In this paper, we provide an overview of vehicle perception systems at road intersections and representative related data sets. The reader is then given an introductory overview of general vision-based vehicle monitoring approaches. Subsequently and above all, we present a review of studies related to vehicle detection and tracking in intersection-like scenarios. Regarding intersection monitoring, we distinguish and compare roadside (pole-mounted, stationary) and in-vehicle (mobile platforms) systems. Then, we focus on camera-based roadside monitoring systems, with special attention to omnidirectional setups. Finally, we present possible research directions that are likely to improve the performance of vehicle detection and tracking at intersections.",
Stability Analysis and Control of Rigid-Body Systems With Impacts and Friction,"Many critical tasks in robotics, such as locomotion or manipulation, involve collisions between a rigid body and the environment or between multiple bodies. Methods based on sums-of-squares (SOS) for numerical computation of Lyapunov certificates are a powerful tool for analyzing the stability of continuous nonlinear systems, and can additionally be used to automatically synthesize stabilizing feedback controllers. Here, we present a method for applying sums-of-squares verification to rigid bodies with Coulomb friction undergoing discontinuous, inelastic impact events. The proposed algorithm explicitly generates Lyapunov certificates for stability, positive invariance, and safety over admissible (non-penetrating) states and contact forces. We leverage the complementarity formulation of contact, which naturally generates the semialgebraic constraints that define this admissible region. The approach is demonstrated on multiple robotics examples, including simple models of a walking robot, a perching aircraft, and control design of a balancing robot.","Friction,
Stability analysis,
Mathematical model,
Robots,
Numerical stability,
Polynomials,
Dynamics"
DeyPoS: Deduplicatable Dynamic Proof of Storage for Multi-User Environments,"Dynamic Proof of Storage (PoS) is a useful cryptographic primitive that enables a user to check the integrity of outsourced files and to efficiently update the files in a cloud server. Although researchers have proposed many dynamic PoS schemes in singleuser environments, the problem in multi-user environments has not been investigated sufficiently. A practical multi-user cloud storage system needs the secure client-side cross-user deduplication technique, which allows a user to skip the uploading process and obtain the ownership of the files immediately, when other owners of the same files have uploaded them to the cloud server. To the best of our knowledge, none of the existing dynamic PoSs can support this technique. In this paper, we introduce the concept of deduplicatable dynamic proof of storage and propose an efficient construction called DeyPoS, to achieve dynamic PoS and secure cross-user deduplication, simultaneously. Considering the challenges of structure diversity and private tag generation, we exploit a novel tool called Homomorphic Authenticated Tree (HAT). We prove the security of our construction, and the theoretical analysis and experimental results show that our construction is efficient in practice.","Servers,
Cloud computing,
Cryptography,
Outsourcing,
Computers"
Design and Real-Time Controller Implementation for a Battery-Ultracapacitor Hybrid Energy Storage System,"In this study, two real-time energy management strategies have been investigated for optimal current split between batteries and ultracapacitors (UCs) in electric vehicle applications. In the first strategy, an optimization problem is formulated and solved using Karush-Kuhn-Tucker conditions to obtain the real-time operation points of current split for the hybrid energy storage system (HESS). In the second strategy, a neural network-based strategy is implemented as an intelligent controller for the proposed system. To evaluate the performance of these two real-time strategies, a performance metric based on the battery state-of-health (SoH) is developed to reveal the relative impact of instantaneous battery currents on the battery degradation. A 38 V-385 Wh battery and a 32 V-4.12 Wh UC HESS hardware prototype has been developed and a real-time experimental platform has been built for energy management controller validation, using xPC Target and National Instrument data acquisition system. Both the simulation and real-time experiment results have successfully validated the real-time implementation feasibility and effectiveness of the two real-time controller designs. It is shown that under a high speed, high acceleration, aggressive drive cycle US06, the two real-time energy management strategies can greatly reduce the battery peak current and consequently decreases the battery SoH reduction by 31% and 38% in comparison to a battery-only energy storage system.","Batteries,
Real-time systems,
Energy management,
DC-DC power converters,
Integrated circuit modeling,
Optimization"
Parallel Processing Systems for Big Data: A Survey,"The volume, variety, and velocity properties of big data and the valuable information it contains have motivated the investigation of many new parallel data processing systems in addition to the approaches using traditional database management systems (DBMSs). MapReduce pioneered this paradigm change and rapidly became the primary big data processing system for its simplicity, scalability, and fine-grain fault tolerance. However, compared with DBMSs, MapReduce also arouses controversy in processing efficiency, low-level abstraction, and rigid dataflow. Inspired by MapReduce, nowadays the big data systems are blooming. Some of them follow MapReduce's idea, but with more flexible models for general-purpose usage. Some absorb the advantages of DBMSs with higher abstraction. There are also specific systems for certain applications, such as machine learning and stream data processing. To explore new research opportunities and assist users in selecting suitable processing systems for specific applications, this survey paper will give a high-level overview of the existing parallel data processing systems categorized by the data input as batch processing, stream processing, graph processing, and machine learning processing and introduce representative projects in each category. As the pioneer, the original MapReduce system, as well as its active variants and extensions on dataflow, data access, parameter tuning, communication, and energy optimizations will be discussed at first. System benchmarks and open issues for big data processing will also be studied in this survey.","Big data,
Computer applications,
Programming,
Parallel processing,
Data models,
Benchmark testing,
Machine learning,
Structured Query Language"
A Traffic Adaptive Multi-Channel MAC Protocol with Dynamic Slot Allocation for WSNs,"Using low duty-cycle is the most common technique to extend the system lifetime in WSNs. However, it also implies limited throughput and long delay and the penalty is even higher under variable traffic patterns. In this paper, we present iQueue-MAC, a hybrid CSMA/TDMA MAC that adapts to variable/bursty traffic. With light load, iQueue-MAC uses a contention-based CSMA mechanism that provides low delay with scattered transmissions. When traffic increases, detected by a forming backlog in the sender, iQueue-MAC changes to a contention-free TDMA mechanism allocating transmission slots. Thus, iQueue-MAC mitigates packet buffering and reduces packet delay, combining the best of TDMA and CSMA. In this paper we also show how iQueue-MAC can operate in both single and multi channel modes. We implemented it on SIM32W108 chips together with other reference WSN protocols for comparison. iQueue-MAC exhibits similar figures during light traffic. However, with bursty traffic its throughput can be five times that of CoSenS and Ri-MAC-MC and its delay 20 times lower. Finally, iQueue-MAC is able to effectively use multiple channels, duplicating its throughput when compared to single channel operation.","Time division multiple access,
Wireless sensor networks,
Routing protocols,
Media Access Protocol,
Resource management"
A High Throughput List Decoder Architecture for Polar Codes,"While long polar codes can achieve the capacity of arbitrary binary-input discrete memoryless channels when decoded by a low complexity successive-cancellation (SC) algorithm, the error performance of the SC algorithm is inferior for polar codes with finite block lengths. The cyclic redundancy check (CRC)-aided SC list (SCL) decoding algorithm has better error performance than the SC algorithm. However, current CRC-aided SCL decoders still suffer from long decoding latency and limited throughput. In this paper, a reduced latency list decoding (RLLD) algorithm for polar codes is proposed. Our RLLD algorithm performs the list decoding on a binary tree, whose leaves correspond to the bits of a polar code. In existing SCL decoding algorithms, all the nodes in the tree are traversed, and all possibilities of the information bits are considered. Instead, our RLLD algorithm visits much fewer nodes in the tree and considers fewer possibilities of the information bits. When configured properly, our RLLD algorithm significantly reduces the decoding latency and, hence, improves throughput, while introducing little performance degradation. Based on our RLLD algorithm, we also propose a high throughput list decoder architecture, which is suitable for larger block lengths due to its scalable partial sum computation unit. Our decoder architecture has been implemented for different block lengths and list sizes using the TSMC 90-nm CMOS technology. The implementation results demonstrate that our decoders achieve significant latency reduction and area efficiency improvement compared with the other list polar decoders in the literature.","Throughput,
Binary trees,
Maximum likelihood decoding,
Hardware,
Reliability"
Towards the evaluation of a big data-as-a-service model: A decision theoretic approach,"The rise of large data centers has created new business models, where businesses can lease storage and computing capacity and pay only for the storage they actually use, rather than making the large capital investments needed to construct and provision large-scale computer installations. In this context, investments in big-data computing are rapidly gaining ground, having extraordinary near-term and long-term benefits. The mobile cloud can be considered as a marketplace, where the storage and computing capabilities of the mobile cloud-based system architectures can be leased off. However, cloud storage is not less expensive, only that it incurs operating rather than capital expenses. This paper elaborates on a novel cost analysis model, adopting a non-linear and asymmetric approach. The proposed modelling aims to evaluate the adoption of a big data-as-a-service business model against the traditional high-performance data warehouse appliances that exist in the market in order to inform effective and strategic decision making. The lease of cloud storage is investigated, when developing the mathematical formulas, and the research approach is examined with respect to the cost that derives from the unused storage. Possible upgradation of the storage and the risk of entering into new and accumulated costs in the future are also considered in this study. A quantification tool has been also developed as a proof of concept (PoC), implementing the proposed quantitative model and intending to shed light on the adoption of big data-as-a-service business models.",
CrowdSensing for smart mobility through a service-oriented architecture,"Crowdsensing is a powerful approach to build representations of specific aspects of reality which are of interest for citizens in smart cities, and in particular for people with special needs. In this work, we present an application of the microservice paradigm to create a mobility services platform. By exposing each part of the process as a microservice, we achieve the ability of developing applications as orchestration of available components. Moreover, we leverage the possibility of sharing data between different applications in a controlled environment.","Sensors,
Quality management,
Conferences,
Reliability,
Smart cities,
Biological system modeling,
Prototypes"
Cross-Layer Protocol Design for CSMA/CD in Full-Duplex WiFi Networks,"The device in conventional half-duplex (HD) WiFi networks cannot perform carrier sensing while in data transmission, thus it suffers from long collision duration. To mitigate this problem, this letter presents a new WiFi cross-layer protocol design based on CSMA/CD, which facilitates simultaneous carrier sensing and data transmission by using the full-duplex (FD) technology. As the FD technology introduces the residual self-interference (RSI), we study two types of errors caused by the RSI against the FD-WiFi sensing (i.e., false alarm and miss detection). Meanwhile, we derive the normalized throughput when considering the sensing performance in the proposed FD-WiFi CSMA/CD protocol. Both analytical and simulated results show that sensing threshold should be properly designed to balance the two types of sensing errors, and our proposed cross-layer protocol can achieve significant throughput improvement.","Sensors,
IEEE 802.11 Standard,
Throughput,
Data communication,
High definition video,
Media Access Protocol"
Comparable features and same cryptography key generation using biometric fingerprint image,"To enforce the privacy of data, it is important that attacker should not get an access of the resources. Several mechanisms have been reported to ensure this. All these mechanisms use a private key such as password or cryptographic key to encrypt data. The problem with this technique is that owner should remember the key or store cryptography key in a database, which, in fact, make the system under threat. In this paper, we have addressed this concern and propose biometric-based data encryption strategy to secure user's own data. We capture a biometric data for a user from which it extracts statistical features. These feature vectors are then used to generate a cryptography key. We encrypt users' data with this cryptographic key. Similar procedure is followed to decrypt the data. We have carried out number of experiments with our approach using standard fingerprint image databases. The experimental results substantiate that on the average 97.25% users have generated same and irrevocable cryptographic key. The advantages of our approach are that it generate unique and dynamic biometric-based cryptography key, the storage of neither templates nor keys are required and it is faster and accurate in terms of key generation.","Feature extraction,
Encryption,
Fingerprint recognition,
Biomedical imaging,
Databases"
QoE-Based Flow Admission Control in Small Cell Networks,"An important requirement on 5G mobile systems is to accommodate massive numbers of wireless devices and users. Heterogeneous networks are expected to play a crucial role in meeting this requirement. In this vein, small cells are expected to become an integral part of these heterogeneous networks. However, their success would not last longer unless they offer services at a quality similar to that currently ensured by the macro cellular networks. Mitigating congestion of the backhaul links to small cell networks is a crucial factor. With this regard, this paper proposes an admission control that makes decisions to redirect IP flows, fully or partially, to the macro or small cell networks, or to reject the incoming flows. The decision mechanism is based on predictions of users' Quality of Experience (QoE). It is modeled as a Markov decision process (MDP), whereby the aim is to derive the optimal policy (i.e. reject or accept flows in the macro or the small cell) that maximizes users' QoE. Through computer simulations, we evaluate the performance of the proposed admission control and compare it against a random policy decision. We also numerically illustrate its optimal policies in different scenarios under different traffic load conditions.","Admission control,
Mobile communication,
Mobile computing,
Computer architecture,
Microprocessors,
Wireless communication"
Industry 4.1 for Wheel Machining Automation,"Industry 4.0 is set to be one of the new manufacturing objectives. The technologies involved to achieve Industry 4.0 are Internet of Things (IoT), cyber physical systems (CPS), and cloud manufacturing (CM). However, the current objectives defined by Industry 4.0 do not include zero defects; it only keeps the faith of achieving nearly zero-defects state. The purpose of this paper is to propose a platform denoted advanced manufacturing cloud of things (AMCoT) to not only achieve the objectives of Industry 4.0 but also accomplish the goal of zero defects by applying the technology of automatic virtual metrology (AVM). As such, by applying Industry 4.0 together with AVM to achieve the goal of zero defects, the era of Industry 4.1 is taking place. The application of wheel machining automation is adopted in this letter to illustrate how AMCoT and Industry 4.1 work.","Industries,
Machining,
Wheels,
Metrology,
Inspection"
"Joint Admission Control, Mode Selection, and Power Allocation in D2D Communication Systems","Device-to-device (D2D) communications can help in achieving the higher data rate targets in emerging wireless networks. The use of D2D communication imposes certain challenges such as interference with the cellular and D2D users. A well-designed joint admission control, network mode selection, and power allocation technique in a cellular network with D2D capability can improve overall throughput. The proposed technique jointly maximizes the total throughput and number of admitted users in cellular networks under quality-of-service (QoS) and interference constraints. The joint admission control, mode selection, and power allocation problem (JACMSPA) falls into a class of mixed-integer nonlinear constraint optimization problems that are generally NP-hard. Due to the combinatorial nature of the problem, its optimal solution needs exhaustive search of integer variables whose complexity increases exponentially with the number of user pairs. In this paper, we invoke outer approximation approach (OAA)-based linearization technique to solve the JACMSPA. The proposed method gives guaranteed ε-optimal solution with reasonable computational complexity. Simulation results verify the effectiveness of the proposed approach method.","Resource management,
Admission control,
Interference,
Throughput,
Joints,
Optimization"
Self-Calibration of Accelerometer Arrays,"A gyroscope-free inertial measurement unit employs solely accelerometers to capture the motion of a body in the form of its linear and angular acceleration as well as its angular velocity. For that, multiple transducers are fixed at distinct locations of the body that together form an accelerometer array. To accurately estimate the motion, the poses of the sensors, i.e., their positions and orientations, must be known precisely. Unfortunately, these parameters are typically hard to assess. Current state-of-the-art calibration methods are able to reconstruct the geometrical sensor configuration based on a set of motion data and corresponding acceleration measurements. However, to impose a reference motion on the sensor array and to capture that motion with the necessary accuracy requires sophisticated laboratory equipment. In this paper, we present a method to estimate the transducer poses using only their own measurements without depending on reference motion data. It is based on an iterative graph optimization that considers both the sensor poses and the motion as target variables. Initially, this results in infinitely many solutions. We reduce the solutions to only one global optimum by explicitly modeling the used triple-axis accelerometers as sensor triads and furthermore taking the temporal dependence of the acceleration samples into account. We compare our method to the conventional calibration using reference data in terms of its estimation accuracy. Furthermore, we analyze the convergence properties of our method by evaluating its tolerance to initial pose deviations. For both, we use synthetic and experimental data recorded on a 3-D rotation table.",
A Survey of General-Purpose Crowdsourcing Techniques,"Since Jeff Howe introduced the term Crowdsourcing in 2006, this human-powered problem-solving paradigm has gained a lot of attention and has been a hot research topic in the field of computer science. Even though a lot of work has been conducted on this topic, so far we do not have a comprehensive survey on most relevant work done in the crowdsourcing field. In this paper, we aim to offer an overall picture of the current state of the art techniques in general-purpose crowdsourcing. According to their focus, we divide this work into three parts, which are: incentive design, task assignment, and quality control. For each part, we start with different problems faced in that area followed by a brief description of existing work and a discussion of pros and cons. In addition, we also present a real scenario on how the different techniques are used in implementing a location-based crowdsourcing platform, gMission. Finally, we highlight the limitations of the current general-purpose crowdsourcing techniques and present some open problems in this area.","Crowdsourcing,
Problem-solving,
Computer science,
Quality control,
Encyclopedias"
Protecting virtual networks with DRONE,"Network virtualization is enabling infrastructure providers (InPs) to offer new services to higher level service providers (SPs). InPs are usually bound by Service Level Agreements (SLAs) to ensure various levels of resource availability for different SPs' virtual networks (VNs). They provision redundant backup resources while embedding an SP's VN request to conform to the SLAs during physical failures in the infrastructure. An extreme of this backup resource provisioning is to reserve a dedicated backup of each element in an SP's VN request. Such dedicated protection scheme can enable an InP to ensure fast VN recovery, thus, providing high uptime guarantee to the SPs. In this paper, we study the 1 + 1-Protected Virtual Network Embedding (1 + 1-ProViNE) problem. We propose Dedicated Protection for Virtual Network Embedding (DRONE), a suite of solutions to the 1 + 1-ProViNE. DRONE includes an Integer Linear Programming (ILP) formulation for optimal solution (OPT-DRONE) and a heuristic (FAST-DRONE) to tackle the computational complexity in computing the optimal solution. Trace driven simulations show that FAST-DRONE allocates only 14.3% extra backup resources on average compared to the optimal solution, while executing 200-12000x faster.","Indium phosphide,
III-V semiconductor materials,
Bandwidth,
Virtualization,
Optical fiber networks,
Computational complexity,
Computational modeling"
Toward Simulation-Free Estimation of Critical Clearing Time,"Contingency screening for transient stability of large-scale, strongly nonlinear, interconnected power systems is one of the most computationally challenging parts of Dynamic Security Assessment and requires huge resources to perform time-domain simulations-based assessment. To reduce computational cost of time-domain simulations, direct energy methods have been extensively developed. However, these methods, as well as other existing methods, still rely on time-consuming numerical integration of the fault-on dynamics. This task is computationally hard, since possibly thousands of contingencies need to be scanned and thousands of accompanied fault-on dynamics simulations need to be performed and stored on a regular basis. In this paper, we introduce a novel framework to eliminate the need for fault-on dynamics simulations in contingency screening. This simulation-free framework is based on bounding the fault-on dynamics and extending the recently introduced Lyapunov Function Family approach for transient stability analysis of structure-preserving model. In turn, a lower bound of the critical clearing time is obtained by solving convex optimization problems without relying on any time-domain simulations. A comprehensive analysis is carried out to validate this novel technique on a number of IEEE test cases.",
A Compact Parylene-Coated WLAN Flexible Antenna for Implantable Electronics,"This letter presents a compact planar flexible antenna designed for wireless local area network (WLAN) using simple microfabrication techniques that are compatible with existing state-of-the-art flexible electronic devices. The antenna is fully insulated with biocompatible Parylene C film, which shows a cost-effective and highly feasible approach to making flexible antennas for implantable applications. Coating of ultrathin Parylene C film has shown negligible effects on the return loss and the radiation patterns of the antennas. The characteristics of the proposed antenna have also shown negligible change under different bending conditions. The original WLAN antenna working in air was successfully tuned to operate under implanted condition at 2.4 GHz by tuning the length of the radiator. The measured results showed that the tuned implantable antenna is suitable for integration with flexible and implantable electronics.",
Using Memetic Algorithm for Instance Coreference Resolution,"Instance coreference resolution is an essential problem in studying semantic web, and it is also critical for the implementation of web of data and future integration and application of semantic data. In this paper, we propose to use Memetic Algorithm (MA) to solve this instance coreference problem in a sequential stage, i.e., the instance-level matching is carried out with the result of schema-level matching. We first give the optimization model for schema-level matching and instance-level matching. Then, we, respectively, present profile similarity measures and the rough evaluation metrics with the assumption that the golden alignment for both schema-level matching and instance-level matching is one-to-one. Furthermore, we give the details of the MA. Finally, the experiments of comparing our approach with the state-of-the-art systems on OAEI benchmarks and real-world datasets are conducted and the results demonstrate that our approach is effective.",
Just Noticeable Difference Estimation for Screen Content Images,"We propose a novel just noticeable difference (JND) model for a screen content image (SCI). The distinct properties of the SCI result in different behaviors of the human visual system when viewing the textual content, which motivate us to employ a local parametric edge model with an adaptive representation of the edge profile in JND modeling. In particular, we decompose each edge profile into its luminance, contrast, and structure, and then evaluate the visibility threshold in different ways. The edge luminance adaptation, contrast masking, and structural distortion sensitivity are studied in subjective experiments, and the final JND model is established based on the edge profile reconstruction with tolerable variations. Extensive experiments are conducted to verify the proposed JND model, which confirm that it is accurate in predicting the JND profile, and outperforms the state-of-the-art schemes in terms of the distortion masking ability. Furthermore, we explore the applicability of the proposed JND model in the scenario of perceptually lossless SCI compression, and experimental results show that the proposed scheme can outperform the conventional JND guided compression schemes by providing better visual quality at the same coding bits.","Image edge detection,
Adaptation models,
Image coding,
Discrete cosine transforms"
AmphiHex-I: Locomotory Performance in Amphibious Environments With Specially Designed Transformable Flipper Legs,"An amphibious robot can locomote in amphibious environments, including walking on rough terrains, maneuvering underwater, and passing through soft muddy or sandy substrates in the littoral area between land and water. However, developing an amphibious robot is challenging, especially when it requires a high locomotory performance in soft substrates and a combination of different propulsion methods. To tackle such a challenge, an amphibious robot, known as AmphiHex-I, with novel transformable flipper-leg composite propulsion mechanisms has been proposed and developed. In this paper, locomotory performance of the flipper legs in amphibious environments, especially in the muddy terrain, is extensively studied with a walking platform in terms of structural parameters, kinematic parameters, and environmental properties. The results indicate that there exist an optimal rotation speed of the flipper legs with various shapes for a higher locomotion speed of the walking model in muddy terrain, which guides the design and the control of the transformable flipper legs. Through the versatile gaits of AmphiHex-I in amphibious environments, outdoor locomotion experiments validate the platform study and demonstrate that the robot's transformable flipper-leg propulsion mechanisms make it highly adaptive to a littoral environment such as the muddy terrain. Locomotion ability of AmphiHex-I endows its broad applications in the areas of resource exploration, disaster rescue, and reconnaissance in complex environments.",
Non-Volatile Nano-Electro-Mechanical Memory for Energy-Efficient Data Searching,"A compact non-volatile nano-electro-mechanical memory (NV-NEMory) cell design together with a novel memory array architecture and operating scheme is proposed for real-time data searching applications. Performance characteristics of a vertically oriented NV-NEMory cell with a small layout area of 8F2, where F is the minimum half-pitch, are investigated by static and transient device simulations. Data searching can be achieved directly in the memory by a two-step read operation, dramatically improving the latency and energy cost of each search query.","Contacts,
Nonvolatile memory,
Microprocessors,
Arrays,
Switches,
Delays"
Performance Limits and Geometric Properties of Array Localization,"Location-aware networks are of great importance and interest in both civil and military applications. This paper determines the localization accuracy of an agent, which is equipped with an antenna array and localizes itself using wireless measurements with anchor nodes, in a far-field environment. In view of the Cramér-Rao bound, we first derive the localization information for static scenarios and demonstrate that such information is a weighed sum of Fisher information matrices from each anchor-antenna measurement pair. Each matrix can be further decomposed into two parts: 1) a distance part with intensity proportional to the squared baseband effective bandwidth of the transmitted signal and 2) a direction part with intensity associated with the normalized anchor-antenna visual angle. Moreover, in dynamic scenarios, we show that the Doppler shift contributes additional direction information, with intensity determined by the agent velocity and the root mean squared time duration of the transmitted signal. In addition, two measures are proposed to evaluate the localization performance of wireless networks with different anchor-agent and array-antenna geometries, and both formulae and simulations are provided for typical anchor deployments and antenna arrays.","Antenna arrays,
Arrays,
Antenna measurements,
Doppler shift,
Geometry,
Directive antennas"
Wireless Communication in Data Centers: A Survey,"Data centers (DCs) is becoming increasingly an integral part of the computing infrastructures of most enterprises. Therefore, the concept of DC networks (DCNs) is receiving an increased attention in the network research community. Most DCNs deployed today can be classified as wired DCNs as copper and optical fiber cables are used for intra- and inter-rack connections in the network. Despite recent advances, wired DCNs face two inevitable problems; cabling complexity and hotspots. To address these problems, recent research works suggest the incorporation of wireless communication technology into DCNs. Wireless links can be used to either augment conventional wired DCNs, or to realize a pure wireless DCN. As the design spectrum of DCs broadens, so does the need for a clear classification to differentiate various design options. In this paper, we analyze the free space optical (FSO) communication and the 60 GHz radio frequency (RF), the two key candidate technologies for implementing wireless links in DCNs. We present a generic classification scheme that can be used to classify current and future DCNs based on the communication technology used in the network. The proposed classification is then used to review and summarize major research in this area. We also discuss open questions and future research directions in the area of wireless DCs.",
Evaluating Belief Structure Satisfaction to Uncertain Target Values,"We describe the basic properties of the Dempster-Shafer belief structure and introduce the associated measures of plausibility and belief. We look at the role of these structures for providing a model of imprecise probabilistic information. We next consider the problem of calculating the satisfaction of target values by a variable V whose value is expressed by a belief structure. We first look at the simplest case when the target is expressed as subset of the domain of V. We then look at the situation when the target is expressed by more complex uncertain structures. Among those considered are a probability distribution, another belief structure, measure, and possibility distribution. At a formal level this paper involves the extension of the concepts of plausibility and belief associated with D-S structures from being mappings of subsets of the underlying domain of V into unit interval to be mappings of these more complex structures into the unit interval.","Probability distribution,
Q measurement,
Bayes methods,
Cybernetics,
Measurement uncertainty,
Fuzzy sets,
Computers"
Histogram of Oriented Principal Components for Cross-View Action Recognition,"Existing techniques for 3D action recognition are sensitive to viewpoint variations because they extract features from depth images which are viewpoint dependent. In contrast, we directly process point clouds for cross-view action recognition from unknown and unseen views. We propose the histogram of oriented principal components (HOPC) descriptor that is robust to noise, viewpoint, scale and action speed variations. At a 3D point, HOPC is computed by projecting the three scaled eigenvectors of the pointcloud within its local spatio-temporal support volume onto the vertices of a regular dodecahedron. HOPC is also used for the detection of spatiotemporal keypoints (STK) in 3D pointcloud sequences so that view-invariant STK descriptors (or Local HOPC descriptors) at these key locations only are used for action recognition. We also propose a global descriptor computed from the normalized spatio-temporal distribution of STKs in 4-D, which we refer to as STK-D. We have evaluated the performance of our proposed descriptors against nine existing techniques on two cross-view and three single-view human action recognition datasets. The experimental results show that our techniques provide significant improvement over state-of-the-art methods.",
Binary Linear Locally Repairable Codes,"Locally repairable codes (LRCs) are a class of codes designed for the local correction of erasures. They have received considerable attention in recent years due to their applications in distributed storage. Most existing results on LRCs do not explicitly take into consideration the field size q, i.e., the size of the code alphabet. In particular, for the binary case, only a few results are known. In this paper, we present an upper bound on the minimum distance d of linear LRCs with availability, based on the work of Cadambe and Mazumdar. The bound takes into account the code length n, dimension k, locality r, availability t, and field size q. Then, we study the binary linear LRCs in three aspects. First, we focus on analyzing the locality of some classical codes, i.e., cyclic codes and Reed-Muller codes, and their modified versions, which are obtained by applying the operations of extend, shorten, expurgate, augment, and lengthen. Next, we construct LRCs using phantom parity-check symbols and multi-level tensor product structure, respectively. Compared with other previous constructions of binary LRCs with fixed locality or minimum distance, our construction is much more flexible in terms of code parameters, and gives various families of high-rate LRCs, some of which are shown to be optimal with respect to their minimum distance. Finally, the availability of LRCs is studied. We investigate the locality and availability properties of several classes of one-step majority-logic decodable codes, including cyclic simplex codes, cyclic difference-set codes, and 4-cycle free regular low-density parity-check codes. We also show the construction of a long LRC with availability from a short one-step majority-logic decodable code.","Tensile stress,
Upper bound,
Linear codes,
Maintenance engineering,
Product codes,
Phantoms,
Electronic mail"
Sparse Coding for Alpha Matting,"Existing color sampling-based alpha matting methods use the compositing equation to estimate alpha at a pixel from the pairs of foreground (F) and background (B) samples. The quality of the matte depends on the selected (F,B) pairs. In this paper, the matting problem is reinterpreted as a sparse coding of pixel features, wherein the sum of the codes gives the estimate of the alpha matte from a set of unpaired F and B samples. A non-parametric probabilistic segmentation provides a certainty measure on the pixel belonging to foreground or background, based on which a dictionary is formed for use in sparse coding. By removing the restriction to conform to (F,B) pairs, this method allows for better alpha estimation from multiple F and B samples. The same framework is extended to videos, where the requirement of temporal coherence is handled effectively. Here, the dictionary is formed by samples from multiple frames. A multi-frame graph model, as opposed to a single image as for image matting, is proposed that can be solved efficiently in closed form. Quantitative and qualitative evaluations on a benchmark dataset are provided to show that the proposed method outperforms the current stateoftheart in image and video matting.","Image color analysis,
Image coding,
Videos,
Dictionaries,
Estimation,
Coherence,
Optimization"
Doubly Sparse Relevance Vector Machine for Continuous Facial Behavior Estimation,"Certain inner feelings and physiological states like pain are subjective states that cannot be directly measured, but can be estimated from spontaneous facial expressions. Since they are typically characterized by subtle movements of facial parts, analysis of the facial details is required. To this end, we formulate a new regression method for continuous estimation of the intensity of facial behavior interpretation, called Doubly Sparse Relevance Vector Machine (DSRVM). DSRVM enforces double sparsity by jointly selecting the most relevant training examples (a.k.a. relevance vectors) and the most important kernels associated with facial parts relevant for interpretation of observed facial expressions. This advances prior work on multi-kernel learning, where sparsity of relevant kernels is typically ignored. Empirical evaluation on challenging Shoulder Pain videos, and the benchmark DISFA and SEMAINE datasets demonstrate that DSRVM outperforms competing approaches with a multi-fold reduction of running times in training and testing.","Pain,
Estimation,
Kernel,
Support vector machines,
Videos,
Face,
Training"
Efficient and Robust Learning for Sustainable and Reacquisition-Enabled Hand Tracking,"The use of machine learning approaches for long-term hand tracking poses some major challenges such as attaining robustness to inconsistencies in lighting, scale and object appearances, background clutter, and total object occlusion/disappearance. To address these issues in this paper, we present a robust machine learning approach based on enhanced particle filter trackers. The inherent drawbacks associated with the particle filter approach, i.e., sample degeneration and sample impoverishment, are minimized by infusing the particle filter with the mean shift approach. Moreover, to instill our tracker with reacquisition ability, we propose a rotation invariant and efficient detection framework named beta histograms of oriented gradients. Our robust appearance model operates on the red, green, blue color histogram and our newly proposed rotation invariant noise compensated local binary patterns descriptor, which is a noise compensated, rotation invariant version of the local binary patterns descriptor. Through our experiments, we demonstrate that our proposed hand tracker performs favorably against state-of-the-art algorithms on numerous challenging video sequences of hand postures, and overcomes the largely unsolved problem of redetecting hands after they vanish and reappear into the frame.",
A Machine Learning Approach to Meter Placement for Power Quality Estimation in Smart Grid,"Due to the high-measuring cost, the monitoring of power quality (PQ) is nontrivial. This paper is aimed at reducing the cost of PQ monitoring in power network. Using a real-world PQ dataset, this paper adopts a learn-from-data approach to obtain a device latent feature model, which captures the device behavior as a PQ transition function. With the latent feature model, the power network could be modeled, in analogy, as a data-driven network, which presents the opportunity to use the well-investigated network monitoring and data estimation algorithms to solve the network quality monitoring problem in power grid. Based on this network model, algorithms are proposed to intelligently place measurement devices on suitable power links to reduce the uncertainty of PQ estimation on unmonitored power links. The meter placement algorithms use entropy-based measurements and Bayesian network models to identify the most suitable power links for PQ meter placement. Evaluation results on various simulated networks including IEEE distribution test feeder system show that the meter placement solution is efficient, and has the potential to significantly reduce the uncertainty of PQ values on unmonitored power links.","Monitoring,
Estimation,
Reliability,
Voltage fluctuations,
Power grids,
Phasor measurement units,
Power quality"
Distributed network flows solving linear algebraic equations,"We study distributed network flows as solvers in continuous time for the linear algebraic equation z = Hy. Each node i holds a row hiT of the matrix H and the corresponding entry zi in the vector z. The first “consensus + projection” flow under investigation consists of two terms, one from standard consensus dynamics and the other contributing to projection onto each affine subspace specified by the hi and zi. The second “projection consensus” flow on the other hand simply replaces the relative state feedback in consensus dynamics with projected relative state feedback. Without dwell-time assumption on switching graphs as well as without positively lower bounded assumption on arc weights, we prove that all node states converge to a common solution of the linear algebraic equation, if there is any. The convergence is global for the “consensus + projection” flow while local for the “projection consensus” flow in the sense that the initial values must lie on the affine subspaces. If the linear equation has no exact solutions, we show that the node states can converge to a ball around the least squares solution whose radius can be made arbitrarily small through selecting a sufficiently large gain for the “consensus + projection” flow under fixed bidirectional graphs. Semi-global convergence to approximate least squares solutions is demonstrated for general switching directed graphs under suitable conditions.",
A Modified Ant Colony Optimization Algorithm for Network Coding Resource Minimization,"This paper presents a modified ant colony optimization (ACO) approach for the network coding resource minimization problem. It is featured with several attractive mechanisms specially devised for solving the concerned problem: 1) a multidimensional pheromone maintenance mechanism is put forward to address the issue of pheromone overlapping; 2) problem-specific heuristic information is employed to enhance the capability of heuristic search (neighboring area search); 3) a tabu-table-based path construction method is devised to facilitate the construction of feasible (link-disjoint) paths from the source to each receiver; 4) a local pheromone updating rule is developed to guide ants to construct appropriate promising paths; and 5) a solution reconstruction method is presented, with the aim of avoiding prematurity and improving the global search efficiency of proposed algorithm. Due to the way it works, the ACO can well exploit the global and local information of routing-related problems during the solution construction phase. The simulation results on benchmark instances demonstrate that with the integrated five extended mechanisms, our algorithm outperforms a number of existing algorithms with respect to the best solutions obtained and the computational time.","Encoding,
Receivers,
Optimization,
Network coding,
Merging,
Search problems,
Cities and towns"
Durability of silicon pin-joints for microrobotics,"This work presents the initial characterization of planar silicon pin-joints for use in linkages for walking microrobot legs. A major goal in walking microrobotics is the creation of robust leg structures driven by low-power motors capable of lifting a 20mg mass and propelling it forward. Hinged joint structures, rather than stiff flexures, are ideal for this task. However, since joints are not fully rigid structures, the possibility of pull-out failure is important to take into account. The joints we use are fabricated in a silicon-on-insulator (SOI) process. They have demonstrated pull-out forces ranging from 1mN to 29mN, well over the strength of our motor designs and capable of handling the intended mass of the robot. Additionally, the frictional coefficient during pull-out was found to be dependent on the load from the joint holder.",
Biologically Inspired Control System for 3-D Locomotion of a Humanoid Biped Robot,"This paper proposes the control system for 3-D locomotion of a humanoid biped robot based on a biological approach. The muscular system in the human body and the neural oscillator for generating locomotion signals are adapted in this paper. We extend the neuro-locomotion system for modeling a multiple neuron system, where motoric neurons represent the muscular system and sensoric neurons represent the sensor system inside the human body. The output signals from coupled neurons representing the angle joint level are controlled by gain neurons that represent the energy burst for driving the joint in each motor. The direction and the length of step in robot locomotion can be adjusted by command neurons. In order to form the locomotion pattern, we apply multiobjective evolutionary computation to solve the multiobjective problem when optimizing synapse weights between the motoric neurons. We use recurrent neural network (RNN) for the stabilization system required for supporting locomotion. RNN generates a dynamic weight synapse value between the sensoric neuron and the motoric neuron. The effectiveness of our system is demonstrated in open dynamic engine computer simulation and in a real robot application that has 12 degrees of freedom (DoFs) in legs and four DoFs in hands.","Neurons,
Robot sensing systems,
Oscillators,
Legged locomotion,
Humanoid robots,
Mathematical model"
Representation Learning of Temporal Dynamics for Skeleton-Based Action Recognition,"Motion characteristics of human actions can be represented by the position variation of skeleton joints. Traditional approaches generally extract the spatial-temporal representation of the skeleton sequences with well-designed hand-crafted features. In this paper, in order to recognize actions according to the relative motion between the limbs and the trunk, we propose an end-to-end hierarchical RNN for skeleton-based action recognition. We divide human skeleton into five main parts in terms of the human physical structure, and then feed them to five independent subnets for local feature extraction. After the following hierarchical feature fusion and extraction from local to global, dimensions of the final temporal dynamics representations are reduced to the same number of action categories in the corresponding data set through a single-layer perceptron. In addition, the output of the perceptron is temporally accumulated as the input of a softmax layer for classification. Random scale and rotation transformations are employed to improve the robustness during training. We compare with five other deep RNN variants derived from our model in order to verify the effectiveness of the proposed network. In addition, we compare with several other methods on motion capture and Kinect data sets. Furthermore, we evaluate the robustness of our model trained with random scale and rotation transformations for a multiview problem. Experimental results demonstrate that our model achieves the state-of-the-art performance with high computational efficiency.","Skeleton,
Hidden Markov models,
Recurrent neural networks,
Feature extraction,
Robustness,
Training,
Computational modeling"
Joint Rate and Power Adaptation for Amplify-and-Forward Two-Way Relaying Relying on Analog Network Coding,"Analog network coding (ANC) is a promising technique of improving the throughput of relaying, especially when combined with both rate- and power-adaptation in the context of amplify-and-forward two-way relaying (AF-TWR ). In particular, the adaptation is employed both during the multiple access stage, when a pair of terminals transmit simultaneously to a relay, and during the broadcast stage, where the relay transmits to both terminals. Based on our bit-error-rate (BER) bounds, we formulate the explicit relationship amongst the data rates, transmit powers, and BERs. Then, we conceive a rate- and power-adaptation scheme, operating both under specific average power constraints and BER constraints both at the relay node and at the two terminals. We observe that the transmit power of nodes does affect the data rate and hence using a fixed transmit power is not always optimal. We then derive a closed-form solution for continuous-rate ANC aided quadrature amplitude modulation/phase shift keying (ANC-QAM/PSK) using the classic Karush-Kuhn-Tucker method and conceive discrete-rate ANC-QAM/PSK regimes for practical wireless systems. The performance of the proposed scheme is evaluated through extensive simulations. Our performance results confirm that the proposed ANC-QAM/PSK outperforms its counterpart operating without power adaptation in a broad range of scenarios.","Relays,
Throughput,
Network coding,
Analog networks,
Context modeling,
Closed-form solutions,
Quadrature amplitude modulation,
Cooperative communications,
Fading channes,
Bit error rate"
Visual Tracking Under Motion Blur,"Most existing tracking algorithms do not explicitly consider the motion blur contained in video sequences, which degrades their performance in real-world applications where motion blur often occurs. In this paper, we propose to solve the motion blur problem in visual tracking in a unified framework. Specifically, a joint blur state estimation and multi-task reverse sparse learning framework are presented, where the closed-form solution of blur kernel and sparse code matrix is obtained simultaneously. The reverse process considers the blurry candidates as dictionary elements, and sparsely represents blurred templates with the candidates. By utilizing the information contained in the sparse code matrix, an efficient likelihood model is further developed, which quickly excludes irrelevant candidates and narrows the particle scale down. Experimental results on the challenging benchmarks show that our method performs well against the state-of-the-art trackers.","Kernel,
Visualization,
Target tracking,
Estimation,
Sparse matrices,
Dictionaries"
"Second and Third-Order Noise Shaping Digital Quantizers for Low Phase Noise and Nonlinearity-Induced Spurious Tones in Fractional-
N
PLLs","Noise shaping digital quantizers, most commonly digital delta-sigma (ΔΣ) modulators, are used in fractional-N phase-locked loops (PLLs) to enable fractional frequency tuning. Unfortunately, their quantization noise is subjected to nonlinear distortion because of the PLL's inevitable non-ideal analog circuit behavior, which induces spurious tones in the PLL's phase error. Successive requantizers have been proposed as ΔΣ modulator replacements with the advantage that they reduce the power of these spurious tones. However, the quantization noise from previously published successive requantizers is only first-order highpass shaped, so it usually causes more PLL phase noise than that from the second-order and third-order ΔΣ modulators commonly used in PLLs. This paper presents second-order and third-order successive requantizers to address this limitation. Additionally, successive requantizer design options are presented that result in either lower-power spurious tones or lower phase noise compared to ΔΣ modulators when used in PLLs.","Phase locked loops,
Quantization (signal),
Generators,
Phase noise,
Noise shaping,
Phase modulation"
Model Predictive Direct Power Control for Active Power Decoupled Single-Phase Quasi-Z -Source Inverter,"The active power filter (APF) that consists of a half-bridge leg and an ac capacitor is integrated in the single-phase quasi-Z-source inverter (qZSI) in this paper to avoid the second harmonic power flowing into the dc side. The capacitor of APF buffers the second harmonic power of the load, and the ac capacitor allows highly pulsating ac voltage, so that the capacitances of both dc and ac sides can be small. A model predictive direct power control (DPC) is further proposed to achieve the purpose of this new topology through predicting the capacitor voltage of APF at each sampling period and ensuring the APF power to track the second harmonic power of single-phase qZSI. Simulation and experimental results verify the model predictive DPC for the APF-integrated single-phase qZSI.",
Emerging smart meters in electrical distribution systems: Opportunities and challenges,"High penetration of variable and non-programmable distributed generation has brought new challenges to the power system operation and is highlighting the need of a smarter grid. One of the key requirements in this regard is developing and deploying smart metering systems in distribution networks. In this paper we present the actual situation in the Italian distribution networks and we discuss the opportunities and challenges of applying new metering systems and introducing a flexible, multi-utility, multi-service metering architecture. Some off-the-shelf or prototype smart meters, selected to be tested in an ongoing European project, named FLEXMETER, are presented.","Smart meters,
Substations,
Circuit faults,
Smart grids,
Monitoring,
Current measurement,
Real-time systems"
Robust Detection of Non-Regular Interferometric Fringes From a Self-Mixing Displacement Sensor Using Bi-Wavelet Transform,"An innovative signal processing method based on custom-made wavelet transform (WT) is presented for robust detection of fringes contained in the interferometric signal of self-mixing (SM) laser diode sensors. It enables the measurement of arbitrarily-shaped vibrations even in the corruptive presence of speckle. Our algorithm is based on the pattern recognition capability of bespoke WTs for detecting SM fringes. Once the fringes have been correctly detected, phase unwrapping methods can be applied to retrieve the complete instantaneous phase of the SM signals. Here, the novelty consists in using two distinct mother wavelets Ψr(t) and Ψd(t) specifically designed to distinguish SM patterns as well as the displacement direction. The peaks, i.e. the maxima modulus of WT, then allow the detection of the fringes.","Sensors,
Wavelet transforms,
Optical feedback,
Robustness,
Optical interferometry,
Speckle"
A Tractable Approach to Uplink Spectral Efficiency of Two-Tier Massive MIMO Cellular HetNets,"This letter investigates the uplink spectral efficiency (SE) of a two-tier cellular network, where massive multiple-input multiple-output macro base stations are overlaid with dense small cells. Macro user equipments (MUEs) and small cells with single user equipment uniformly scattered are modeled as two independent homogeneous Poisson point processes. By applying stochastic geometry, we analyze the multiuser uplink SE at a macro base station that employs a zero-forcing detector and we obtain a novel lower bound as well as its approximation. According to the simple and near-exact analytical expression, we observe that the ideal way to improve the SE is by increasing the MUE density and the base station antennas synchronously rather than increasing them individually. Furthermore, a large value of path loss exponent has a positive effect on the SE due to the reduced aggregated interference.","Aggregates,
Interference,
MIMO,
Approximation methods,
Antennas,
Uplink,
Base stations"
A Cyber-Enabled Stabilizing Control Scheme for Resilient Smart Grid Systems,"A parametric controller is proposed for transient stability of synchronous generators after the occurrence of a disturbance in the power grid. The proposed controller based on feedback linearization control theory relies on receiving timely phasor measurement unit (PMU) information from selected parts of the power grid to employ fast acting flywheels that are situated near synchronous generators. The local storage devices aim to balance a swing equation model of the synchronous generator to drive the associated rotor speed to stability. The advantages of the proposed controller include that it is tunable and integrates well with existing governor controls in contrast to other forms of PMU-based control. Further, a comparison is drawn between the proposed controller and recently proposed nonlinear controllers for transient stabilization. Numerical results show the effectiveness and robustness of the proposed controller when applied to the 39-bus 10-generator New England power system.",
Locating Intra-Body Capsule Object by Three-Magnet Sensing System,"Magnetic localization is an appropriate method for tracing an intra-body capsule object because of its satisfactory accuracy and efficiency. In this method, the capsule is enclosed in a ring magnet, which establishes a magnetic field around the human body. By using a sensor array system with a number of triaxial magnetic sensors, the magnetic flux densities can be measured, and the magnet can be localized by an appropriate algorithm. However, a problem for such a system is that the movements of the human body have interferences on the localization. Therefore, in order to compensate the interferences, we propose a three-magnet localization method. Here, in addition to the capsule object magnet, two other magnets are fixed on the surface of the human body to serve as reference objects. The position and orientation parameters of all the three magnets are determined by applying the optimal algorithm on the sensing data from the sensor array. Then, a reference coordinate system is built based on the two reference objects, and the capsule magnet is relatively tracked with respect to this reference system in human body. The experimental results show that the average localization error caused by the body movement interference is reduced from 30.1 mm (in the original coordinate system) to 3.82 mm (in reference coordinate system) and the average direction error reduced from 17.7° to 2.2°.","Magnetic resonance imaging,
Magnetic flux,
Magnetic sensors,
Sensor arrays,
Sensor systems,
Magnetic field measurement"
Energy Management for Joint Operation of CHP and PV Prosumers Inside a Grid-Connected Microgrid: A Game Theoretic Approach,"This paper mainly focuses on the energy management of microgrids (MGs) consisting of combined heat and power (CHP) and photovoltaic (PV) prosumers. A multiparty energy management framework is proposed for joint operation of CHP and PV prosumers with the internal price-based demand response. In particular, an optimization model based on Stackelberg game is designed, where the microgrid operator (MGO) acts as the leader and PV prosumers are the followers. The properties of the game are studied and it is proved that the game possesses a unique Stackelberg equilibrium. The heuristic algorithm based on differential evolution is proposed that can be adopted by the MGO, and nonlinear constrained programing can be adopted by each prosumer to reach the Stackelberg equilibrium. Finally, via a practical example, the effectiveness of the model is verified in terms of determining MGO's prices and optimizing net load characteristic, etc.","Energy management,
Optimization,
Cogeneration,
Games,
Power grids"
Bending Properties of Anisotropic Conductive Films Assembled Chip-in-Flex Packages for Wearable Electronics Applications,"In this paper, a chip-in-flex (CIF) assembly that has an excellent bending performance, including a minimum bending radius without a chip fracture and the capacity to withstand dynamic bending, is developed. Chip-on-flex (COF) and CIF assemblies are fabricated using anisotropic conductive films (ACFs) as interconnection materials. The COF package is composed of 40-μm-thin silicon chips, ACF, and flexible substrates. The CIF package is fabricated by attaching a cover adhesive film and a polyimide film on the COF package to encapsulate the silicon chip. Through static bending tests, the optimal thickness of the cover adhesive film is established. The optimized CIF assembly allows a minimum bending radius of 4 mm without a chip fracture, while the chip in the COF assembly fractures at a bending radius of 10 mm. A finite-element analysis of the static bending test is performed to understand the internal stress state of the assemblies. A bending reliability test of the CIF package is also conducted at a bending radius of 7.5 mm for 160k cycles, by measuring the daisy-chain resistance during the test. The effect of the elastic modulus of the ACF resin on the fatigue endurance is investigated through the bending fatigue test. The higher modulus of the ACF resin resulted in excellent fatigue reliability with stable ACF joints showing neither delamination nor resin crazing after 160k cycles of bending.","Assembly,
Silicon,
Substrates,
Resins,
Fatigue,
Wearable computers,
Polyimides"
Calibration and Unwrapping of the Normalized Scattering Cross Section for the Cyclone Global Navigation Satellite System,"This paper develops and characterizes the algorithms used to generate the Level 1 (L1) science data products of the Cyclone Global Navigation Satellite System (CYGNSS) mission. The L1 calibration consists of two parts: the Level 1a (L1a) calibration converts the raw Level 0 delay-Doppler maps (DDMs) of processed counts into received power in units of watts. The L1a DDMs are then converted to Level 1b DDMs of bistatic radar cross section values by unwrapping the forward scattering model and generating two additional DDMs: one of unnormalized bistatic radar cross section values (in units of square meters) and a second of bin-by-bin effective scattering areas. The L1 data products are generated in such a way as to allow for flexible processing of variable areas of the DDM (which correspond to different regions on the surface). The application of the L1 data products to the generation of input observables for the CYGNSS Level 2 (L2) wind retrievals is also presented. This includes a demonstration of using only near-specular DDM bins to calculate a normalized bistatic radar cross section (unitless, i.e., m2/m2) over a subset of DDM pixels, or DDM area. Additionally, an extensive term-by-term error analysis has been performed using this example extent of the DDM to help quantify the sensitivity of the L1 calibration as a function of key internal instrument and external parameters in the near-specular region.",
Biometric Authentication Using Noisy Electrocardiograms Acquired by Mobile Sensors,"Electrocardiogram (ECG) signals from mobile sensors are expected to increase the availability of authentication in the emerging wearable device industry. However, mobile sensors provide a relatively lower quality signal than the conventional medical devices. This paper proposes a practical authentication procedure for ECG signals that collected via one-chip-solution mobile sensors. We designed a cascading bandpass filter for noise cancellation and suggest eight fiducial features. For classification-based authentication, we use the radial basis function kernel-based support vector machine showing the best performance among nine classifiers through experimental comparisons. In spite of noisy ECG signals in mobile sensors, we achieved 4.61% of the equal error rate (EER) on a single heartbeat, and 1.87% of EER on 15 s testing time on 175 subjects, which is a reasonable result and supports the usability of low-cost ECGs for biometric authentication.",
A Three-Level Dodecagonal Space Vector-Based Harmonic Suppression Scheme for Open-End Winding IM Drives With Single-DC Supply,"This paper presents a harmonic elimination technique based on a three-level dodecagonal space vector structure for open-end winding induction motor (IM) drives with a single-dc supply. Advantages of dodecagonal space vector switching and multilevel inverters are achieved with a single-dc supply. A dc supply-fed three-level flying capacitor (FC) inverter feeds active power to one end of the IM winding terminals and H-bridge connected capacitors eliminate fifth- and seventh-order harmonics from the other end. A pulsewidth modulation (PWM) technique is developed to switch the three-level dodecagonal space vectors and simultaneously control the H-bridge capacitors at 0.1445Vdc. The fifthand seventh-order harmonics are eliminated for the full modulation range of the three-level FC inverter, including the extreme 6-step operation. An increase in the linear modulation range has been achieved, resulting in improved dc bus utilization. Harmonic elimination is achieved by increasing switching frequency of the low-voltage capacitor connected H-bridge inverter; thus, switching frequency for the high-voltage dc supply-fed FC inverter is not increased. Using the proposed scheme, the instantaneous phase voltage never exceeds 2/3Vdc (maximum phase voltage applied for hexagonal space vector structure) for which the machine windings are rated. Additionally, the proposed inverter has also been shown to operate for field oriented control of the open-end winding IM drive.","Inverters,
Capacitors,
Harmonic analysis,
Windings,
Switches,
Modulation,
Aerospace electronics"
Incorporation of Optimal Computing Budget Allocation for Ordinal Optimization Into Learning Automata,"A learning automaton (LA) is a powerful tool for reinforcement learning. Its action probability vector plays two roles: 1) deciding when it converges, i.e., total computing budget it has used, and 2) allocating computing budget among actions to identify the optimal one. These two intertwined roles lead to a problem: the computing budget mostly goes to the currently estimated optimal action due to its high action probability regardless whether such budget allocation can help identify the true optimal one or not. This work proposes a new class of LA that avoids the use of its action probability vector for computing budget allocation. Instead we use such vector only to determine if it converges and then employ optimal computing budget allocation to accomplish the allocation of computing budget in a way that maximizes the probability of identifying the true optimal actions. ε-optimality is proven. Simulations verify its advantages over existing algorithms. A learning automaton (LA) represents an important leaning mechanism with applications in automated system design, biological systems, computer vision, and transportation. It updates its action probability vector in accordance with the inputs received from the environment to improve its performance. It acts as an adaptive controller in modeling a process as well as generating appropriate control signals. The existing LAs simply employ heuristics to update their action probability vectors and then use the vectors for ordinal optimization and determining the computing budget size. This work separates ordinal optimization from the action probability vector and introduces optimal computing budget allocation to maximize the probability of selecting the true optimal action. Compared with the state-of-the-art methods in five popular environments, the proposed LA speeds up the learning efficiency ranging from 10.93% to 65.94%.",
Data transformation and migration in polystores,"Ever increasing data size and new requirements in data processing has fostered the development of many new database systems. The result is that many data-intensive applications are underpinned by different engines. To enable data mobility there is a need to transfer data between systems easily and efficiently. We analyze the state-of-the-art of data migration and outline research opportunities for a rapid data transfer. Our experiments explore data migration between a diverse set of databases, including PostgreSQL, SciDB, S-Store and Accumulo. Each of the systems excels at specific application requirements, such as transactional processing, numerical computation, streaming data, and large scale text processing. Providing an efficient data migration tool is essential to take advantage of superior processing from that specialized databases. Our goal is to build such a data migration framework that will take advantage of recent advancement in hardware and software.","Engines,
Distributed databases,
Arrays,
Data mining,
Relational databases,
Transforms"
A 0.52/1 V Fast Lock-in ADPLL for Supporting Dynamic Voltage and Frequency Scaling,"In energy-efficient processing platforms, such as wearable sensors and implantable medical devices, dynamic voltage and frequency scaling allows optimizing the energy efficiency under various modes of operation. The clock generator used in these platforms should be capable of achieving a faster settling time and has a wider operating voltage range. In this brief, a fast lock-in all-digital phase-locked loop (ADPLL) with two operation modes (0.52/1 V) is presented. The proposed ADPLL can quickly compute the desired digitally controlled oscillator control code with high accuracy. Therefore, the proposed ADPLL can achieve a fast setting time with frequency errors <;5% within four clock cycles. The proposed ADPLL is implemented using a standard performance 90-nm CMOS process. The output frequency of the ADPLL ranges from 60 to 600 MHz at 1 V, and from 30 to 120 MHz at 0.52 V. The power consumption of the proposed ADPLL is 0.92 mW at (1 V, 600 MHz), and 37 μW at (0.52 V, 120 MHz).","Phase locked loops,
Phase frequency detector,
Frequency conversion,
Jitter,
Solid state circuits,
Frequency estimation"
FPGA-Based Web Services -- Infinite Potential or a Road to Nowhere?,"Field-programmable gate array (FPGA) technology could have significant potential in the construction of Web services, but it generates multiple issues that software and hardware designers must overcome first. As a Web service hardware platform, the FPGA could be an experimental yet interesting and powerful alternative to standard solutions based on microprocessors and microcontrollers. Here, the authors share their thoughts about the possibility of using FPGA chips to implement environment-aware embedded Web services.","Field-programmable gate arrays,
Internet,
Web services,
Economics,
Distributed processing,
Ubiquitous computing,
Internet of things"
Energy Management Strategy of Multiple Supercapacitors in a DC Microgrid Using Adaptive Virtual Impedance,"Supercapacitors (SCs) are increasingly used in energy storage system to tackle the fast power transients. They can be used individually or together with other energy storage units like batteries. In a microgrid, multiple SCs could be installed at different locations without communications among them. This paper focuses on the energy management strategy (EMS) of multiple SCs in a dc microgrid, where the distributed generation units and energy storage units are controlled with the plug-and-play feature. A novel EMS is proposed, which uses the state-of-charge-based adaptive virtual impedance to facilitate the transient power sharing among the parallel SCs without physical communications. The detailed analysis and design procedure are explained based on an example microgrid system with two SCs and one battery energy storage connected in parallel through the dc/dc converters. The effectiveness of the proposed method is verified by both simulation and experimental results.","Batteries,
Microgrids,
Impedance,
Energy management,
State of charge,
Power conversion"
Query Expansion Based on Crowd Knowledge for Code Search,"As code search is a frequent developer activity in software development practices, improving the performance of code search is a critical task. In the text retrieval based search techniques employed in the code search, the term mismatch problem is a critical language issue for retrieval effectiveness. By reformulating the queries, query expansion provides effective ways to solve the term mismatch problem. In this paper, we propose Query Expansion based on Crowd Knowledge (QECK), a novel technique to improve the performance of code search algorithms. QECK identifies software-specific expansion words from the high quality pseudo relevance feedback question and answer pairs on Stack Overflow to automatically generate the expansion queries. Furthermore, we incorporate QECK in the classic Rocchio's model, and propose QECK based code search method QECKRocchio. We conduct three experiments to evaluate our QECK technique and investigate QECKRocchio in a large-scale corpus containing real-world code snippets and a question and answer pair collection. The results show that QECK improves the performance of three code search algorithms by up to 64 percent in Precision, and 35 percent in NDCG. Meanwhile, compared with the state-of-the-art query expansion method, the improvement of QECK Rocchio is 22 percent in Precision, and 16 percent in NDCG.","Software,
Software engineering,
Search problems,
Search engines,
Thesauri"
Common radio resource management model for heterogeneous cellular networks,"This article is dedicated to exploring new management algorithms required for heterogeneous mobile networks, taking advantage of their coverage superposition and management integration of different technology, enabling operators the opportunity to reduce installation and operational costs while offering high quality services to end subscribers. Modified analytical models are proposed to evaluate heterogeneous integrated scenarios where the shared radio resource management policies performance are analyzed.",
Low-Loss 3-D Multilayer Transmission Lines and Interconnects Fabricated by Additive Manufacturing Technologies,This paper presents low-loss 3-D transmission lines and vertical interconnects fabricated by aerosol jet printing (AJP) which is an additive manufacturing technology. AJP stacks up multiple layers with minimum feature size as small as 20 μm in the xy-direction and 0.7 μm in the z-direction. It also solves the problem of fabricating vias to realize the vertical transition by 3-D printing. The loss of the stripline is measured to be 0.53 dB/mm at 40 GHz. The vertical transition achieves a broadband bandwidth from 0.1 to 40 GHz. The results of this paper demonstrate the feasibility of utilizing 3-D printing for low-cost multilayer system-on-package RF/millimeter-wave front-ends.,"Printing,
Silver,
Ink,
Integrated circuit interconnections,
Nonhomogeneous media,
Polyimides,
Fabrication"
Optimal Industrial Load Control in Smart Grid,"In this paper, we investigate optimal load control in industrial sector, which involves several new and distinct research problems. For example, while most residential appliances operate independently, industrial units are highly interdependent and must follow certain operational sequences. Also, unlike residential appliances, the operation of industrial units may span across multiple days and involve multiple batch cycles. Furthermore, in industries with process control, energy management is often coupled with material flow management. The design in this paper is comprehensive and addresses industrial load control under various smart electricity pricing scenarios, including day-ahead pricing, time-of-use pricing, peak pricing (PP), inclining block rates, and critical PP. The use of behind-the-meter renewable generator and energy storage is also considered. The formulated optimization problem is a tractable mixed-integer linear program. Different case studies are presented based on a practical energy-extensive steel mill industry model.","Pricing,
Load modeling,
Load flow control,
Industries,
Batteries,
Batch production systems,
Job shop scheduling"
Signal Recovery on Graphs: Fundamental Limits of Sampling Strategies,"This paper builds theoretical foundations for the recovery of a newly proposed class of smooth graph signals, approximately bandlimited graph signals, under three sampling strategies: uniform sampling, experimentally designed sampling, and active sampling. We then state minimax lower bounds on the maximum risk for the approximately bandlimited class under these three sampling strategies and show that active sampling cannot fundamentally outperform experimentally designed sampling. We propose a recovery strategy to compare uniform sampling with experimentally designed sampling. As the proposed recovery strategy lends itself well to statistical analysis, we derive the exact mean square error for each sampling strategy. To study convergence rates, we introduce two types of graphs and find that 1) the proposed recovery strategy achieves the optimal rates; and 2) the experimentally designed sampling fundamentally outperforms uniform sampling for Type-2 class of graphs. To validate our proposed recovery strategy, we test it on five specific graphs: a ring graph with k nearest neighbors, an Erdos-Rényi graph, a random geometric graph, a small-world graph, and a power-law graph and find that experimental results match the proposed theory well. This paper also presents a comprehensive explanation for when and why sampling for semi-supervised learning with graphs works.",
QoE Evaluation of Multimedia Services Based on Audiovisual Quality and User Interest,"Quality of experience (QoE) has significant influence on whether or not a user will choose a service or product in the competitive era. For multimedia services, there are various factors in a communication ecosystem working together on users, which stimulate their different senses inducing multidimensional perceptions of the services, and inevitably increase the difficulty in measurement and estimation of the user's QoE. In this paper, a user-centric objective QoE evaluation model (QAVIC model for short) is proposed to estimate the user's overall QoE for audiovisual services, which takes account of perceptual audiovisual quality (QAV) and user interest in audiovisual content (IC) amongst influencing factors on QoE such as technology, content, context, and user in the communication ecosystem. To predict the user interest, a number of general viewing behaviors are considered to formulate the IC evaluation model. Subjective tests have been conducted for training and validation of the QAVIC model. The experimental results show that the proposed QAVIC model can estimate the user's QoE reasonably accurately using a 5-point scale absolute category rating scheme.","Multimedia communication,
Integrated circuit modeling,
Ecosystems,
Context,
Predictive models,
Streaming media,
Measurement"
Secrecy-Based Energy-Efficient Data Offloading via Dual Connectivity Over Unlicensed Spectrums,"Offloading cellular mobile users' (MUs') data traffic to small-cell networks is a cost-effective approach to relieve congestion in macrocell cellular networks. However, as many small-cell networks operate in the unlicensed bands, the data offloading might suffer from a security issue, i.e., some eavesdropper could overhear the offloaded data over unlicensed spectrums. This motivates us to investigate a secrecy-based energy-efficient uplink data offloading scheme. Specifically, we consider the recent paradigm of traffic offloading via dual connectivity, which enables an MU to simultaneously deliver traffic to a macro base station (mBS) over the licensed channel and a small-cell access point (sAP) over the unlicensed channel. We formulate an MU's joint optimization of traffic scheduling and power allocation problem, with the objective of minimizing the total power consumption while meeting both the MU's traffic demand and secrecy requirement. Despite the non-convex nature of the joint optimization problem, we propose an efficient algorithm to compute the optimal offloading solution. By evaluating the impact of the MU's secrecy requirement and the eavesdropper's channel condition, we quantify the conditions under which the optimal offloading solution corresponds to the full-offloading and zero-offloading, respectively. Numerical results validate the optimal performance of our proposed algorithm, and show that the optimal offloading can significantly reduce the total power consumption compared with some fixed offloading schemes. Based on the optimal offloading solution for each MU, we further analyze the scenario of multiple MUs and sAPs, and investigate how to optimally exploit the sAPs' total offloading capacity to serve the MUs while accounting for the MUs' corresponding power consumptions for offloading data. To this end, we formulate a total network-benefit maximization problem that accounts for the reward for serving the MUs successfully, the mBS's bandwidth usage, and the MUs' power consumptions. Numerical results show that the optimal solution can improve the total network benefit compared with some heuristic sAP-selection scheme.","Security,
Uplink,
Power demand,
Mobile communication,
Resource management,
Bandwidth,
Base stations,
Green communications,
Energy efficiency"
FiDoop: Parallel Mining of Frequent Itemsets Using MapReduce,"Existing parallel mining algorithms for frequent itemsets lack a mechanism that enables automatic parallelization, load balancing, data distribution, and fault tolerance on large clusters. As a solution to this problem, we design a parallel frequent itemsets mining algorithm called FiDoop using the MapReduce programming model. To achieve compressed storage and avoid building conditional pattern bases, FiDoop incorporates the frequent items ultrametric tree, rather than conventional FP trees. In FiDoop, three MapReduce jobs are implemented to complete the mining task. In the crucial third MapReduce job, the mappers independently decompose itemsets, the reducers perform combination operations by constructing small ultrametric trees, and the actual mining of these trees separately. We implement FiDoop on our in-house Hadoop cluster. We show that FiDoop on the cluster is sensitive to data distribution and dimensions, because itemsets with different lengths have different decomposition and construction costs. To improve FiDoop's performance, we develop a workload balance metric to measure load balance across the cluster's computing nodes. We develop FiDoop-HD, an extension of FiDoop, to speed up the mining performance for high-dimensional data analysis. Extensive experiments using real-world celestial spectral data demonstrate that our proposed solution is efficient and scalable.","Itemsets,
Data mining,
Clustering algorithms,
Algorithm design and analysis,
Load management,
Load modeling"
Context-aware wireless mobile autonomic computing and communications: research trends and emerging applications,"Growing attention has recently been devoted to context-aware computing and communication systems, in particular concerning their evolution toward the new paradigm of context-aware autonomic computing and communications. Indeed, context awareness and autonomicity appear to be the indispensable glue technologies to accomplish efficient integration of modern software-intensive cyber-physical systems, operating in open and non-deterministic environments, and to master their complexity. This article provides an update on the latest developments in this field. Proposed methodologies and techniques are discussed and framed in the overall research problem. Moreover, future trends and research challenges are outlined by relating the basic concepts of context-aware autonomic computing and communications to the emerging paradigm of the self-aware Internet of Things, applications of which appear to be very promising examples of next-generation computing and communication systems.","Context-aware services,
Monitoring,
Adaptation models,
Market research,
Performance evaluation,
Autonomic systems"
A Colored Petri Net Based Frequency Support Scheme Using Fleet of Electric Vehicles in Smart Grid Environment,"The ever-growing dependency of modern life on electricity may impose huge burden on smart grids (SGs). This dependency affects the demand-supply gap and may lead to undesirable frequency fluctuations. In the worst case, these fluctuations may result in blackouts. In this direction, fleet of electric vehicles (EVs) may play a crucial role in reducing these fluctuations to a great extent. So, this paper proposes a novel scheme for efficient frequency support in SG environment by utilizing fleet of EVs. These EVs act as controllable loads and work in close coordination with aggregators and charging stations. Aggregators play a crucial role in regulating charging and discharging rates of EVs while meeting their energy requirements with the help of the proposed colored petri net based controller. The proposed scheme has been evaluated with respect to publicly available frequency regulation data acquired from PJM and ERCOT. In addition to this, the scheme has also been compared with an existing approach and results clearly depict that the proposed scheme is more scalable in comparison to the existing schemes in V2G environment.",
Performance Recovery of Voltage Source Converters With Application to Grid-Connected Fuel Cell DGs,"Most common types of distributed generation systems utilize power electronic interfaces and, in particular, three-phase voltage source converters (VSCs) which are mainly used to regulate active and reactive power delivered to the grid. The main drawbacks of VSCs originate from their nonlinearities, control strategies, and lack of robustness against uncertainties. In this paper, two time-scale separation redesign technique is proposed to improve the overall robustness of VSCs and address the issues of uncertainties. The proposed controller is applied to a grid-connected solid oxide fuel cell distributed generation system to recover the trajectories of the nominal system despite the presence of uncertainties. Abrupt changes in the input dc voltage, grid-side voltage, line impedance and PWM malfunctions are just a few uncertainties considered in our evaluations. Simulation results based on detailed model indicate that the redesigned system with lower filter gain (ε) achieves more reliable performance in compare to the conventional current control scheme. The results also verified that the redesigned controller is quite successful in improving the startup and tracking responses along with enhancing the overall robustness of the system.","Power conversion,
Fuel cells,
Uncertainty,
Robustness,
Mathematical model,
Distributed power generation"
Measuring the Influence of Perceived Cybercrime Risk on Online Service Avoidance,"Cybercrime is a pervasive threat for today's Internet-dependent society. While the real extent and economic impact is hard to quantify, scientists and officials agree that cybercrime is a huge and still growing problem. A substantial fraction of cybercrime's overall costs to society can be traced to indirect opportunity costs, resulting from unused online services. This paper presents a parsimonious model that builds on technology acceptance research and insights from criminology to identify factors that reduce Internet users' intention to use online services. We hypothesize that avoidance of online banking, online shopping and online social networking is increased by cybercrime victimization and media reports. The effects are mediated by the perceived risk of cybercrime and moderated by the user's confidence online. We test our hypotheses using a structural equation modeling analysis of a representative pan-European sample. Our empirical results confirm the negative impact of perceived risk of cybercrime on the use of all three online service categories and support the role of cybercrime experience as an antecedent of perceived risk of cybercrime. We further show that more confident Internet users perceive less cybercriminal risk and are more likely to use online banking and online shopping, which highlights the importance of consumer education.","Computer crime,
Bismuth,
Internet,
Media,
Online banking,
Mathematical model,
Privacy"
Robust Face Sketch Style Synthesis,"Heterogeneous image conversion is a critical issue in many computer vision tasks, among which example-based face sketch style synthesis provides a convenient way to make artistic effects for photos. However, existing face sketch style synthesis methods generate stylistic sketches depending on many photo-sketch pairs. This requirement limits the generalization ability of these methods to produce arbitrarily stylistic sketches. To handle such a drawback, we propose a robust face sketch style synthesis method, which can convert photos to arbitrarily stylistic sketches based on only one corresponding template sketch. In the proposed method, a sparse representation-based greedy search strategy is first applied to estimate an initial sketch. Then, multi-scale features and Euclidean distance are employed to select candidate image patches from the initial estimated sketch and the template sketch. In order to further refine the obtained candidate image patches, a multi-feature-based optimization model is introduced. Finally, by assembling the refined candidate image patches, the completed face sketch is obtained. To further enhance the quality of synthesized sketches, a cascaded regression strategy is adopted. Compared with the state-of-the-art face sketch synthesis methods, experimental results on several commonly used face sketch databases and celebrity photos demonstrate the effectiveness of the proposed method.","Face recognition,
Training,
Dictionaries,
Optimization,
Hidden Markov models,
Heterogeneous image conversion,
Databases"
Continuous Blood Pressure Measurement From Invasive to Unobtrusive: Celebration of 200th Birth Anniversary of Carl Ludwig,"The year 2016 marks the 200th birth anniversary of Carl Friedrich Wilhelm Ludwig (1816-1895). As one of the most remarkable scientists, Ludwig invented the kymograph, which for the first time enabled the recording of continuous blood pressure (BP), opening the door to the modern study of physiology. Almost a century later, intraarterial BP monitoring through an arterial line has been used clinically. Subsequently, arterial tonometry and volume clamp method were developed and applied in continuous BP measurement in a noninvasive way. In the last two decades, additional efforts have been made to transform the method of unobtrusive continuous BP monitoring without the use of a cuff. This review summarizes the key milestones in continuous BP measurement; that is, kymograph, intraarterial BP monitoring, arterial tonometry, volume clamp method, and cuffless BP technologies. Our emphasis is on recent studies of unobtrusive BP measurements as well as on challenges and future directions.","Arteries,
Blood pressure,
Biomedical monitoring,
Hypertension,
Pressure measurement"
Toward a Blind Deep Quality Evaluator for Stereoscopic Images Based on Monocular and Binocular Interactions,"During recent years, blind image quality assessment (BIQA) has been intensively studied with different machine learning tools. Existing BIQA metrics, however, do not design for stereoscopic images. We believe this problem can be resolved by separating 3D images and capturing the essential attributes of images via deep neural network. In this paper, we propose a blind deep quality evaluator (DQE) for stereoscopic images (denoted by 3D-DQE) based on monocular and binocular interactions. The key technical steps in the proposed 3D-DQE are to train two separate 2D deep neural networks (2D-DNNs) from 2D monocular images and cyclopean images to model the process of monocular and binocular quality predictions, and combine the measured 2D monocular and cyclopean quality scores using different weighting schemes. Experimental results on four public 3D image quality assessment databases demonstrate that in comparison with the existing methods, the devised algorithm achieves high consistent alignment with subjective assessment.","Three-dimensional displays,
Image quality,
Stereo image processing,
Predictive models,
Training,
Neural networks,
Distortion"
Bifurcation Analysis in Weakly-Coupled Inductive Power Transfer Systems,"This work reveals and analyzes an unfamiliar bifurcation in weakly-coupled inductive wireless power transfer systems (IWPT) employing diode rectifier. This paper firstly provides a local analysis calculating the required RF source power, based on the rectifier ac-dc conversion gain and the two-port analysis of the coupled coils. The local analysis is supported by measured results on silicon. Successively, we demonstrate that if the secondary coil and the diode rectifier have a high quality factor, the rectifier diode varactor can create a turning-point bifurcation in the solution curve of the output dc voltage versus the RF source power. With the bifurcation, the local analysis becomes invalid and a higher source power is required. Bifurcation analysis based on large-signal capacitor modeling and conversion matrix analysis are provided, substantiating the results. The introduced bifurcation analysis is verified by three IWPT examples on PCB. A proposed design with an auxiliary nonlinear varactor is proposed to mitigate the bifurcation with improved performance.","Coils,
Bifurcation,
Radio frequency,
Capacitors,
Couplings,
Receivers,
Impedance matching"
Collaborative Wireless Freeview Video Streaming With Network Coding,"Free viewpoint video (FVV) offers compelling interactive experience by allowing users to switch to any viewing angle at any time. An FVV is composed of a large number of camera-captured anchor views, with virtual views (not captured by any camera) rendered from their nearby anchors using techniques such as depth-image-based rendering (DIBR). We consider a group of wireless users who may interact with an FVV by independently switching views. We study a novel live FVV streaming network where each user pulls a subset of anchors from the server via a primary channel. To enhance anchor availability at each user, a user generates network-coded (NC) packets using some of its anchors and broadcasts them to its direct neighbors via a secondary channel. Given limited primary and secondary channel bandwidths at the devices, we seek to maximize the received video quality (i.e., minimize distortion) by jointly optimizing the set of anchors each device pulls and the anchor combination to generate NC packets. To our best knowledge, this is among the first body of work addressing such joint optimization problem for wireless live FVV streaming with NC-based collaboration. We first formulate the problem and show that it is NP-hard. We then propose a scalable and effective algorithm called PAFV (Peer-Assisted Freeview Video). In PAFV, each node collaboratively and distributedly decides on the anchors to pull and NC packets to share so as to minimize video distortion in its neighborhood. Extensive simulation studies show that PAFV outperforms other algorithms, achieving substantially lower video distortion (often by more than 20-50%) with significantly less redundancy (by as much as 70%). Our Android-based video experiment further confirms the effectiveness of PAFV over comparison schemes.","Streaming media,
Wireless communication,
Distortion,
Servers,
Bandwidth,
Network coding,
Switches"
Three-Dimensional Needle Shape Estimation in TRUS-Guided Prostate Brachytherapy Using 2-D Ultrasound Images,"In this paper, we propose an automated method to reconstruct the three-dimensional (3-D) needle shape during needle insertion procedures using only 2-D transverse ultrasound (US) images. Using a set of transverse US images, image processing and random sample consensus are used to locate the needle within each image and estimate the needle shape. The method is validated with an in vitro needle insertion setup and a transparent tissue phantom, where two orthogonal cameras are used to capture the true 3-D needle shape for verification. Results showed that the use of at least three images obtained at 75% of the maximum insertion depth or greater allows for maximum needle shape estimation errors of less than 2 mm. In addition, the needle shape can be calculated consistently as long as the needle can be identified in 30% of the transverse US images obtained. Application to permanent prostate brachytherapy is also presented, where the estimated needle shape is compared to manual segmentation and sagittal US images. Our method is intended to help to assess needle placement during manual or robot-assisted needle insertion procedures after the needle has been inserted.","Needles,
Brachytherapy,
Three-dimensional displays,
Biomedical image processing,
Image segmentation,
Acoustic applications"
Asymmetric Silicon Slot-Waveguide-Assisted Polarizing Beam Splitter,"A silicon polarizing beam splitter is designed and fabricated based on an asymmetric slot waveguide structure without adopting additional strip-slot waveguide mode converters. The asymmetric slot waveguide consists of a 150-nm-wide and a 350-nm-wide nanowires with a slot of 100 nm, which can realize a transverse magnetic light cross-coupling with a 392-nm-wide strip waveguide, while little transverse electric light coupling can happen. The fabricated device has a coupling length of ~18 μm with a coupling gap spacing of 450 nm, which can achieve a polarization extinction ratio (PER) of ~14 and 25 dB at the bar and cross ports, respectively. Low insertion loss is realized, while more than 10-dB PER can be obtained over the wavelength range of 1520-1576 nm. The device performance could be further improved with the fine optimization of device structure parameters and fabrication process.","Optical waveguides,
Couplings,
Optical device fabrication,
Strips,
Optical polarization,
Optical refraction"
cNV SRAM: CMOS Technology Compatible Non-Volatile SRAM Based Ultra-Low Leakage Energy Hybrid Memory System,"A CMOS technology compatible non-volatile SRAM (cNV SRAM) is proposed in this paper to achieve energy efficient on-chip memory. cNV SRAM works as conventional 8T SRAM to keep high speed in work mode; in sleep mode, it backs up the data in its NV component and switches off the power supply, thereby minimizing the leakage energy without data loss. The circuit- and architectural- level implementation schemes of cNV SRAM are developed considering multiple key performance parameters including energy dissipation, access time, write time, noise margin, layout area, restoration time, and injection charges. Simulation results on SPEC 2000 benchmark suite demonstrate that cNV SRAM realizes 86 percent energy savings on average with negligible performance impact and small hardware overhead as compared to conventional SRAM. Finally, the impact of the sleep time and memory size on the effectiveness of cNV SRAM is analyzed in detail and it shows that cNV SRAM is particularly effective to implement large on-chip memories with long idle time.","Registers,
SRAM cells,
Charge pumps,
Phasor measurement units,
Microprocessors,
Power supplies"
AmbiguityVis: Visualization of Ambiguity in Graph Layouts,"Node-link diagrams provide an intuitive way to explore networks and have inspired a large number of automated graph layout strategies that optimize aesthetic criteria. However, any particular drawing approach cannot fully satisfy all these criteria simultaneously, producing drawings with visual ambiguities that can impede the understanding of network structure. To bring attention to these potentially problematic areas present in the drawing, this paper presents a technique that highlights common types of visual ambiguities: ambiguous spatial relationships between nodes and edges, visual overlap between community structures, and ambiguity in edge bundling and metanodes. Metrics, including newly proposed metrics for abnormal edge lengths, visual overlap in community structures and node/edge aggregation, are proposed to quantify areas of ambiguity in the drawing. These metrics and others are then displayed using a heatmap-based visualization that provides visual feedback to developers of graph drawing and visualization approaches, allowing them to quickly identify misleading areas. The novel metrics and the heatmap-based visualization allow a user to explore ambiguities in graph layouts from multiple perspectives in order to make reasonable graph layout choices. The effectiveness of the technique is demonstrated through case studies and expert reviews.","Visualization,
Measurement,
Layout,
Heating,
Image edge detection,
Entropy,
Readability metrics"
FCUDA-NoC: A Scalable and Efficient Network-on-Chip Implementation for the CUDA-to-FPGA Flow,"High-level synthesis (HLS) of data-parallel input languages, such as the Compute Unified Device Architecture (CUDA), enables efficient description and implementation of independent computation cores. HLS tools can effectively translate the many threads of computation present in the parallel descriptions into independent, optimized cores. The generated hardware cores often heavily share input data and produce outputs independently. As the number of instantiated cores grows, the off-chip memory bandwidth may be insufficient to meet the demand. Hence, a scalable system architecture and a data-sharing mechanism become necessary for improving system performance. The network-on-chip (NoC) paradigm for intrachip communication has proved to be an efficient alternative to a hierarchical bus or crossbar interconnect, since it can reduce wire routing congestion, and has higher operating frequencies and better scalability for adding new nodes. In this paper, we present a customizable NoC architecture along with a directory-based data-sharing mechanism for an existing CUDA-to-FPGA (FCUDA) flow to enable scalability of our system and improve overall system performance. We build a fully automated FCUDA-NoC generator that takes in CUDA code and custom network parameters as inputs and produces synthesizable register transfer level (RTL) code for the entire NoC system. We implement the NoC system on a VC709 Xilinx evaluation board and evaluate our architecture with a set of benchmarks. The results demonstrate that our FCUDA-NoC design is scalable and efficient and we improve the system execution time by up to 63× and reduce external memory reads by up to 81% compared with a single hardware core implementation.","Graphics processing units,
Bandwidth,
Kernel,
Ports (Computers),
Field programmable gate arrays,
Hardware,
Parallel processing"
Compressive Sampling-Based Image Coding for Resource-Deficient Visual Communication,"In this paper, a new compressive sampling-based image coding scheme is developed to achieve competitive coding efficiency at lower encoder computational complexity, while supporting error resilience. This technique is particularly suitable for visual communication with resource-deficient devices. At the encoder, compact image representation is produced, which is a polyphase down-sampled version of the input image; but the conventional low-pass filter prior to down-sampling is replaced by a local random binary convolution kernel. The pixels of the resulting down-sampled pre-filtered image are local random measurements and placed in the original spatial configuration. The advantages of the local random measurements are two folds: 1) preserve high-frequency image features that are otherwise discarded by low-pass filtering and 2) remain a conventional image and can therefore be coded by any standardized codec to remove the statistical redundancy of larger scales. Moreover, measurements generated by different kernels can be considered as the multiple descriptions of the original image and therefore the proposed scheme has the advantage of multiple description coding. At the decoder, a unified sparsity-based soft-decoding technique is developed to recover the original image from received measurements in a framework of compressive sensing. Experimental results demonstrate that the proposed scheme is competitive compared with existing methods, with a unique strength of recovering fine details and sharp edges at low bit-rates.","Image coding,
Decoding,
Visualization,
Codecs,
Image reconstruction,
Kernel,
Wireless sensor networks"
Energy Aware and Adaptive Cross-Layer Scheme for Video Transmission Over Wireless Sensor Networks,"Wireless multimedia sensor networks (WMSNs), is an ad hoc network of wirelessly connected sensor nodes that allow retrieving video and audio streams, still images, and scalar sensor data but such sensors are limited in energy, memory, communication, and computational power. Multimedia transmission over wireless sensor network (WSN) is a challenging task due to quality-of-service(QoS) guarantees such as huge amount of bandwidth, strict delay, and lower loss ratio. Recently, cross-layer approach adopted by WMSNs shows a promising approach that improves quality of multimedia transmitted over WSNs under different wireless conditions. In this paper, an energy aware and adaptive cross layer scheme to transmit multimedia content over WSNs is presented. It provides packet, queue, and path scheduling, so that it selects optimal video encoding parameters at application layer according to current wireless channel state, and schedules packets according to its type through an adaptive priority video queue so that less important packets are dropped in case of network congestion. Finally, path scheduling is introduced so that different packets types/priority are routed through different paths with different QoSs considering network lifetime. Simulation results show that new scheme transmits video over WSNs efficiently and meets QoS requirements and uses energy wisely to prolongs network lifetime.","Wireless sensor networks,
Streaming media,
Multimedia communication,
Sensors,
Wireless communication,
Scheduling,
Cross layer design"
Incentivizing crowdsourcing systems with network effects,"In a crowdsourcing system, it is important for the crowdsourcer to engineer extrinsic rewards to incentivize the participants. With mobile social networking, a user enjoys an intrinsic benefit when she aligns her behavior with the behavior of others. Referred to as network effects, such an intrinsic benefit becomes more significant as the number of users grows in the crowdsourcing system. But should a crowdsourcer design her extrinsic rewards differently when such network effects are taken into account? In this paper, we, for the first time, consider network effects as a contributing factor to intrinsic rewards, and study its influence on the design of extrinsic rewards. Rather than assuming a fixed participant population, we show that the number of participating users evolves to a steady equilibrium, thanks to subtle interactions between intrinsic rewards due to network effects and extrinsic rewards offered by the crowdsourcer. Taken network effects into consideration, we design progressively more sophisticated extrinsic reward mechanisms, and propose new and optimal strategies for a crowdsourcer to obtain a higher utility. Via extensive simulations, we demonstrate that with our new strategies, a crowdsourcer is able to attract more participants with higher contributed efforts; and participants gain higher utilities from both intrinsic and extrinsic rewards.",
Automated Bug Report Field Reassignment and Refinement Prediction,"Bug fixing is one of the most important activities in software development and maintenance. Bugs are reported, recorded, and managed in bug tracking systems such as Bugzilla. In general, a bug report contains many fields, such as product, component, severity, priority, fixer, operating system (OS), and platform, which provide important information for the bug triaging and fixing process. Our previous study finds that approximately 80% of bug reports have their fields reassigned and refined at least once, and bugs with reassigned and refined fields take more time to fix than bugs with no reassigned and refined fields. Thus, automatically predicting which bug report fields get reassigned and refined could help developers to save bug fixing time. Considering that a bug report could have multiple field reassignments and refinements (e.g., the product, component, fixer, and other fields of a bug report can get reassigned and refined), in this paper, we propose a multi-label learning algorithm to predict which bug report fields might be reassigned and refined. We note that the number of bug reports with some types of reassignment and refinement (e.g., bugs whose severity fields gets reassigned and refined) is a small proportion of the whole bug report collection, indicating the class imbalance problem. Thus, we propose imbalanced ML.KNN (Im-ML.KNN), which extends ML.KNN, one of the state-of-the-art multi-label learning algorithms, to achieve better performance. Im-ML.KNN is a composite model that combines 3 multi-label classifiers built using different types of features (i.e., meta, textual, and mixed features). We evaluate our solution on 4 large bug report datasets including OpenOffice, Netbeans, Eclipse, and Mozilla containing a total of 190,558 bug reports. We show that Im-ML.KNN can achieve an average F-measure score of 0.56-0.62. We also compare Im-ML.KNN with other state-of-art methods, such as the method proposed by Lamkanfi , ML.KNN, and HOMER-NB. The results show that Im-ML.KNN, on average, improves the average F-measure scores of Lamkanfi 's method, ML.KNN, and HOMER-NB by 119.69%, 9.11%, and 161.08%, respectively.","Feature extraction,
Computer bugs,
Training,
Prediction algorithms,
Software,
Buildings,
Data mining"
Comparing Oversampling Techniques to Handle the Class Imbalance Problem: A Customer Churn Prediction Case Study,"Customer retention is a major issue for various service-based organizations particularly telecom industry, wherein predictive models for observing the behavior of customers are one of the great instruments in customer retention process and inferring the future behavior of the customers. However, the performances of predictive models are greatly affected when the real-world data set is highly imbalanced. A data set is called imbalanced if the samples size from one class is very much smaller or larger than the other classes. The most commonly used technique is over/under sampling for handling the class-imbalance problem (CIP) in various domains. In this paper, we survey six well-known sampling techniques and compare the performances of these key techniques, i.e., mega-trend diffusion function (MTDF), synthetic minority oversampling technique, adaptive synthetic sampling approach, couples top-N reverse k-nearest neighbor, majority weighted minority oversampling technique, and immune centroids oversampling technique. Moreover, this paper also reveals the evaluation of four rules-generation algorithms (the learning from example module, version 2 (LEM2), covering, exhaustive, and genetic algorithms) using publicly available data sets. The empirical results demonstrate that the overall predictive performance of MTDF and rules-generation based on genetic algorithms performed the best as compared with the rest of the evaluated oversampling methods and rule-generation algorithms.","Predictive models,
Prediction algorithms,
Genetic algorithms,
Sampling methods,
Customer retention,
Learning systems,
Customer satisfaction,
Customer profiles"
Modeling and Optimization of High Frame Rate Video Transmission Over Wireless Networks,"High frame rate (HFR) video is emerging as a new paradigm in popular multimedia applications (e.g., cloud gaming) to achieve smooth viewing experience perceived by end-users. In the context of HFR streaming video, end-to-end distortion and sending frame rate are equally important to the perceptual quality. This study presents a modeling-based approach to optimizing the HFR video transmission over wireless networks. First, we develop an analytical model dubbed FRIED (Frame Rate versus vIdEo Distortion) to characterize the tradeoff between sending frame rate and end-to-end video distortion. Second, we propose a Joint frAme Selection and FEC (Forward Error Correction) cOding (JASCO) approach based on the FRIED model to optimize the transmission performance. The efficacy of the proposed JASCO is evaluated through extensive semi-physical emulations in Exata involving H.264 video streaming. Experimental results show that JASCO outperforms the reference approaches in improving video peak signal-to-noise ratio (PSNR) at the same frame rate. Or conversely, JASCO is able to achieve higher received frame rate while guaranteeing the same video PSNR.","Streaming media,
Distortion,
Encoding,
Delays,
Forward error correction,
Wireless networks"
Optimal and Suboptimal Joint Relay and Antenna Selection for Two-Way Amplify-and-Forward Relaying,"This paper investigates joint relay and antenna selection schemes for two-way amplify-and-forward (AF) relaying system, where a multiantenna source exchanges information with a single-antenna source by exploiting a group of single-antenna relays. In view of performance and complexity tradeoffs, two optimal and one suboptimal joint selection schemes are proposed and compared. In contrast to the optimal selection schemes, the suboptimal counterpart is characterized by its low overhead and implementation complexity. The performance of these selection strategies has been investigated by deriving the outage probability approximations in closed form. Moreover, the achievable diversity orders and the corresponding coding gains are derived through high signal-to-noise ratio (SNR) approximations of the outage probability. Our theoretical and simulation results show that the performance gap between the optimal and suboptimal schemes disappears for specific scenarios, which provides useful design guidelines for practical two-way relaying system.","Relays,
Antennas,
Joints,
Complexity theory,
Signal to noise ratio,
Resource management,
Wireless communication"
Poisson Matrix Recovery and Completion,"We extend the theory of low-rank matrix recovery and completion to the case when Poisson observations for a linear combination or a subset of the entries of a matrix are available, which arises in various applications with count data. We consider the usual matrix recovery formulation through maximum likelihood with proper constraints on the matrix M of size d1-by-d2, and establish theoretical upper and lower bounds on the recovery error. Our bounds for matrix completion are nearly optimal up to a factor on the order of O(log(d1d2)). These bounds are obtained by combining techniques for recovering sparse vectors with compressed measurements in Poisson noise, those for analyzing low-rank matrices, as well as those for one-bit matrix completion [Davenport , “1-bit Matrix Completion, Information and Inference,” Information and Inference, vol. 3, no. 3, pp. 189-223, Sep. 2014] (although these two problems are different in nature). The adaptation requires new techniques exploiting properties of the Poisson likelihood function and tackling the difficulties posed by the locally sub-Gaussian characteristic of the Poisson distribution. Our results highlight a few important distinctions of the Poisson case compared to the prior work including having to impose a minimum signal-to-noise requirement on each observed entry and a gap in the upper and lower bounds. We also develop a set of efficient iterative algorithms and demonstrate their good performance on synthetic examples and real data.","Sparse matrices,
Upper bound,
Signal to noise ratio,
Approximation algorithms,
Noise measurement,
Compressed sensing,
Random variables"
Subspace Polynomials and Cyclic Subspace Codes,"Subspace codes have received an increasing interest recently due to their application in error correction for random network coding. In particular, cyclic subspace codes are possible candidates for large codes with efficient encoding and decoding algorithms. In this paper, we consider such cyclic codes and provide constructions of optimal codes for which their codewords do not have full orbits. We further introduce a new way to represent subspace codes by a class of polynomials called subspace polynomials. We present some constructions of such codes, which are cyclic and analyze their parameters.","Orbits,
Space vehicles,
Encoding,
Network coding,
Decoding,
Indexes"
Multiple Stage Residual Model for Image Classification and Vector Compression,"Feature coding is a fundamental issue with many vision tasks, such as image classification, image retrieval and image segmentation, etc. There is no doubt that the encoding procedure leads to information loss, due to the existence of quantization error. The residual vector, defined as the difference between the feature and its corresponding visual word, is the chief culprit to be responsible for the quantization error. Many previous algorithms consider it as a coding issue, and focus on reducing the quantization error by reconstructing the feature with more than one visual word, or by the so-called soft-assignment strategy. In this paper, we consider the problem from a different point of view, and propose an effective and efficient model called multiple stage residual model (MSRM). It makes full use of the residual vector to generate a multiple stage code. MSRM is a hierarchical structure, with the bottom stage producing the coarsest quantization, and the top stage producing the finest quantization. Moreover, our proposed model is a generic framework, which can be built upon many coding algorithms. The interplay of such a coarse-to-fine quantization procedure with a discriminative classifier (e.g., SVM) can improve the classification accuracy of the baseline algorithms significantly. As a special case of MSRM, multiple stage vector quantization (MSVQ) can be directly used for vector compression and approximate nearest neighbor search, and achieves competitive performances with high efficiency.","Encoding,
Quantization (signal),
Image coding,
Visualization,
Approximation algorithms,
Algorithm design and analysis,
Kernel"
Energy-Efficient Infrastructure Sensor Network for Ad Hoc Cognitive Radio Network,"We propose an energy-efficient network architecture that consists of ad hoc (mobile) cognitive radios (CRs) and infrastructure wireless sensor nodes. The sensor nodes within communications range of each CR are grouped into a cluster, and the clusters of CRs are regularly updated according to the random mobility of the CRs. We reduce the energy consumption and the end-to-end delay of the sensor network by dividing each cluster into disjoint subsets with overlapped sensing coverage of primary user (PU) activity. Respective subset of a CR provides target detection and false alarm probabilities. Substantial energy efficiency is achieved by activating only one subset of the cluster, while putting the rest of the subsets in the cluster into sleep mode. Additional gain in energy efficiency is obtained by two promising propositions: selecting nodes from the active subset for actual sensing and switching the active subset to sleep mode by scheduling. The sensor nodes for actual spectrum sensing are chosen considering their respective time durations for sensing. Even the only active subset is switched to sleep mode for a certain number of time slots, utilizing the history of PU activity. We compare the proposed CR network with existing approaches to demonstrate the network performance in terms of the energy consumption and the end-to-end delay.",
"A Dual-Band, Inductively Coupled Miniaturized-Element Frequency Selective Surface With Higher Order Bandpass Response","We present a new approach for designing dual-band miniaturized-element frequency selective surfaces (MEFSSs) with independent control of the frequencies of operation of each band. The proposed device is composed of 2-D periodic arrays of subwavelength inductive wire grids and capacitive patches separated by dielectric substrates. The structure is built on an inductively coupled MEFSS that uses capacitively loaded dielectric spacers as its main resonators. The two operating bands of this MEFSS correspond to the first and second resonant frequencies of its constituting resonators. By judiciously choosing the locations where the resonators are loaded and the load values, the frequencies of the first and second resonances can be controlled individually. In this way, a dual-band MEFSS with independent frequency bands of operation can be obtained. Using the equivalent circuit model of this MEFSS, a synthesis procedure is developed that can be used to synthesize the dual-band MEFSS from its system-level performance indicators. A prototype of the proposed dual-band MEFSS with second-order bandpass response at each band is designed, fabricated, and experimentally characterized. The measurement results of this device show a stable frequency response with respect to the angle of incidence up to ±45° for both the TE and TM polarizations of incidence.","Resonant frequency,
Frequency selective surfaces,
Dual band,
Capacitors,
Integrated circuit modeling,
Dielectric substrates,
Equivalent circuits"
Toward real-time and cooperative mobile visual sensing and sharing,"Mobile social media enables people to record ongoing physical events they witness and share them instantaneously online. However, since these event pictures are often individually provided, they are typically fragmented and possess high redundancy. Though there have been studies about visual event summarization, they pay little attention to collaborative sensing, subevent detection, and event summary. In this paper, we present several building blocks for a cooperative visual sensing and sharing system. We create a virtual opportunistic community associated with an event, where members collaborate to cover different aspects of the event. More specifically, a crowd-powered approach is first used to localize the event. We then propose three subevent segmentation methods based on crowd-event interaction patterns. Based on the segmentation results, we summarize the event at two levels: multi-facet subevent summary and crowd-behavior-based highlights. Experiments over 21 online datasets and two real world datasets demonstrate the effectiveness of our approaches.",
Belief & Evidence in Empirical Software Engineering,"Empirical software engineering has produced a steady stream of evidence-based results concerning the factors that affect important outcomes such as cost, quality, and interval. However, programmers often also have strongly-held a priori opinions about these issues. These opinions are important, since developers are highlytrained professionals whose beliefs would doubtless affect their practice. As in evidence-based medicine, disseminating empirical findings to developers is a key step in ensuring that the findings impact practice. In this paper, we describe a case study, on the prior beliefs of developers at Microsoft, and the relationship of these beliefs to actual empirical data on the projects in which these developers work. Our findings are that a) programmers do indeed have very strong beliefs on certain topics b) their beliefs are primarily formed based on personal experience, rather than on findings in empirical research and c) beliefs can vary with each project, but do not necessarily correspond with actual evidence in that project. Our findings suggest that more effort should be taken to disseminate empirical findings to developers and that more in-depth study the interplay of belief and evidence in software practice is needed.","Bayes methods,
Software engineering,
Software,
Media,
Computer science,
Immune system"
Revisiting virtual L1 caches: A practical design using dynamic synonym remapping,"Virtual caches have potentially lower access latency and energy consumption than physical caches because they do not consult the TLB prior to cache access. However, they have not been popular in commercial designs. The crux of the problem is the possibility of synonyms. This paper makes several empirical observations about the temporal characteristics of synonyms, especially in caches of sizes that are typical of L1 caches. By leveraging these observations, the paper proposes a practical design of an L1 virtual cache that (1) dynamically decides a unique virtual page number for all the synonymous virtual pages that map to the same physical page and (2) uses this unique page number to place and look up data in the virtual caches. Accesses to this unique page number proceed without any intervention. Accesses to other synonymous pages are dynamically detected, and remapped to the corresponding unique virtual page number to correctly access data in the cache. Such remapping operations are rare, due to the temporal properties of synonyms, allowing a Virtual Cache with Dynamic Synonym Remapping (VC-DSR) to achieve most of the benefits of virtual caches but without software involvement. Experimental results based on real world applications show that VC-DSR can achieve about 92% of the dynamic energy savings for TLB lookups, and 99.4% of the latency benefits of ideal (but impractical) virtual caches for the configurations considered.","Computers,
Software,
Organizations,
Energy consumption,
Microarchitecture,
Hardware,
Coherence"
Requirements: The Key to Sustainability,Software's critical role in society demands a paradigm shift in the software engineering mind-set. This shift's focus begins in requirements engineering. This article is part of a special issue on the Future of Software Engineering.,"Stakeholders,
Economics,
Procurement,
Software systems,
Software engineering,
Requirements engineering,
Sustainability"
Designing Fuzzy Sets With the Use of the Parametric Principle of Justifiable Granularity,"This study is concerned with a design of membership functions of fuzzy sets. The membership functions are formed in such a way that they are experimentally justifiable and exhibit a sound semantics. These two requirements are articulated through the principle of justifiable granularity. The parametric version of the principle is discussed in detail. We show linkages with type-2 fuzzy sets, which are constructed on a basis of type-1 fuzzy sets. Several experimental studies are reported, which illustrate a behavior of the introduced method.","Fuzzy sets,
Marine vehicles,
Buildings,
Optimization,
Numerical models,
Semantics,
Systematics"
Stacked Patch Antenna With Dual-Polarization and Low Mutual Coupling for Massive MIMO,"Massive multiple input and multiple output (MIMO) has attracted significant interests in both academia and industry. It has been considered as one of most promising technologies for 5G wireless systems. The large-scale antenna array for base stations naturally becomes the key to deploy the Massive MIMO technologies. In this communication, we present a dual-polarized antenna array with 144 ports for Massive MIMO operating at 3.7 GHz. The proposed array consists of 18 low profile subarrays. Each subarray consists of four single units. Each single antenna unit consists of one vertically polarized port and one horizontally polarized port connected to power splitters, which serve as a feeding network. A stacked patch design is used to construct the single unit with the feeding network, which gives higher gain and lower mutual coupling within the size of a conversional dual-port patch antenna. Simulation results of the proposed single antenna unit, sub-array, and Massive MIMO array are verified by measurement.","Couplings,
Antenna arrays,
Antenna measurements,
Ports (Computers),
Mutual coupling,
MIMO"
Cost-Efficient Sensory Data Transmission in Heterogeneous Software-Defined Vehicular Networks,"Sensing and networking have been regarded as key enabling technologies of future smart vehicles. Sensing allows vehicles to be context awareness, while networking empowers context sharing among ambients. Existing vehicular communication solutions mainly rely on homogeneous network, or heterogeneous network via data offloading. However, today's vehicular network implementations are highly heterogeneous. Therefore, conventional homogeneous communication and data offloading may not be able to satisfy the requirement of the emerging vehicular networking applications. In this paper, we apply the software-defined network (SDN) to the heterogeneous vehicular networks to bridge the gaps. With SDN, heterogeneous network resources can be managed with a unified abstraction. Moreover, we propose an SDN-based wireless communication solution, which can schedule different network resources to minimize communication cost. We investigate the problems in both single and multiple hop cases. We also evaluate the proposed approaches using traffic traces. The effectiveness and the efficiency are validated by the results.","Vehicles,
Sensors,
Software,
Mathematical model,
Ad hoc networks,
Wireless networks"
Intuitive Exploration of Volumetric Data Using Dynamic Galleries,"In this work we present a volume exploration method designed to be used by novice users and visitors to science centers and museums. The volumetric digitalization of artifacts in museums is of rapidly increasing interest as enhanced user experience through interactive data visualization can be achieved. This is, however, a challenging task since the vast majority of visitors are not familiar with the concepts commonly used in data exploration, such as mapping of visual properties from values in the data domain using transfer functions. Interacting in the data domain is an effective way to filter away undesired information but it is difficult to predict where the values lie in the spatial domain. In this work we make extensive use of dynamic previews instantly generated as the user explores the data domain. The previews allow the user to predict what effect changes in the data domain will have on the rendered image without being aware that visual parameters are set in the data domain. Each preview represents a subrange of the data domain where overview and details are given on demand through zooming and panning. The method has been designed with touch interfaces as the target platform for interaction. We provide a qualitative evaluation performed with visitors to a science center to show the utility of the approach.","Image color analysis,
Data visualization,
Transfer functions,
Rendering (computer graphics),
Color,
Cameras,
Navigation"
Performance Analysis of Carrier-Based Discontinuous PWM Method for Vienna Rectifiers With Neutral-Point Voltage Balance,"The nongenerative-boost type rectifier, which is called the Vienna rectifier, is advantageous in terms of efficiency and current total harmonic distortion. Therefore, the Vienna rectifier is used in grid-connected applications such as telecommunication systems and wind turbine systems. Owing to the structural characteristics of the Vienna rectifier, various switching methods exist. Among these methods, a carrier-based discontinuous pulse-width modulation (CB-DPWM) method guarantees high efficiency compared to continuous pulse-width modulation methods; moreover, it is simple compared to a DPWM method based on space vectors. In this paper, the performance of the CB-DPWM method, its applicable region depending on the power factor and modulation index (Ma), and its efficiency are analyzed in detail. Then, based on the analysis, a neutral-point voltage balancing method for the CB-DPWM method is proposed. The effectiveness and performance of the proposed neutral-point voltage balancing method are verified by simulation and experiment.","Rectifiers,
Switches,
Reactive power,
Pulse width modulation,
Voltage control,
Topology"
Energy management of Renewable Energy Sources in a microgrid using Cuckoo Search Algorithm,"In this paper, the Renewable Energy Resources (RES) are used in a specific small area which is known as microgrid. Microgrid consists of microsources, battery storage and loads. In this paper the research is focused on the islanded mode microgrid. In the microgrid, the energy management system having a problem of Economic Load Dispatch (ELD) and it is optimized by meta-heuristic techniques. The newly introduced Cuckoo Search Algorithm (CSA) is implemented for the solution of ELD problem in the MATLAB environment. The minimization of total cost is obtained for four different scenarios like all sources included, all sources without solar energy, all sources without wind energy and all sources without solar and wind energy. In both scenarios, the result shows the comparison of CSA with the Reduced Gradient Method (RGM) for the ELD problem solution. The results are calculated for different power demand of 24 hours. The results obtained with CSA gives better cost reduction in less iterations as compared to RGM which shows the effectiveness of the suggested algorithm.","Microgrids,
Generators,
Batteries,
Wind energy,
Wind energy generation,
Wind power generation,
Solar energy"
Performance and Energy Aware Inhomogeneous 3D Networks-on-Chip Architecture Generation,"Recently, Through-Silicon-Via (TSV) has been more popular to provide faster inter-layer communication in three-dimensional Networks-on-Chip (3D NoCs). However, the area overhead of TSVs reduces wafer utilization and yield which impact design of 3D architectures using a large number of TSVs such as homogeneous 3D NoCs topologies. Also, 3D routers require more memory and thus they are more power hungry than conventional 2D routers. Alternatively, hybrid 3D NoCs combine both the area and performance benefits of 2D and 3D router architectures by using a limited number of TSVs. Existing hybrid architectures suffer from higher packet delays as they do not consider the dynamic communication patterns of different application and their NoC resource usage. We propose a novel algorithm to systematically generate hybrid 3D NoC topologies for a given application such that the vertical connections are minimized while the NoC performance is not sacrificed. The proposed algorithm analyses the target application and generates hybrid architectures by efficiently redistributing the vertical links and buffer spaces based on their utilizations. Furthermore, the algorithm has been evaluated with synthetic and various real-world traffic patterns. Experimental results show that the proposed algorithm generates optimized architectures with lower energy consumption and a significant reduction in packet delay compared to the existing solutions.",
Patient Flow Scheduling and Capacity Planning in a Smart Hospital Environment,"Improving patient flow is a way to refine health services. An efficient patient flow can improve the quality of services and the utilization of resources. A smart environment could facilitate the experience of individuals within a physical space, such as a hospital. Meanwhile, a smart healthcare environment could improve patient flow through an efficient scheduling policy and the utilization of healthcare resources by an optimized capacity plan. This paper, first, explores a dynamic scheduling policy to improve the patient flow, and an efficient capacity scheme based on the varying patient flow. This scheduling policy and the capacity scheme can be built in a smart hospital environment through wireless sensor networks and smart healthcare systems. The research applies a formal modeling approach that can provide a quantitative analysis of systems. This approach, performance evaluation process algebra, can give strict definitions for the patient flow in order to model the dynamic scheduling policy and the capacity scheme; moreover, it provides a scalable performance analysis by the fluid flow approximation. Finally, this paper is concerned with how formal method might be used to model and analyze the scheduling policy and the capacity plan on improving the healthcare service before deployment.","Hospitals,
Analytical models,
Dynamic scheduling,
Capacity planning,
Quality of service,
Patient monitoring,
Smart buildings,
Medical services"
Using Frequency Coupling Matrix Techniques for the Analysis of Harmonic Interactions,"This paper develops a simplified phasor model for predicting harmonics present at the point of common coupling between a voltage-source power converter and the utility network. It employs the frequency coupling matrix (FCM) modeling technique. The FCM is experimentally determined without requiring access to converter internal details, such as control and output filter parameters, which are generally not available for converters used in distributed generation systems. Experimental measurements are conducted on a commercially available two-stage, three phase, grid-tied photovoltaic inverter to assess the accuracy of experimentally determined FCMs to predict the harmonic behavior of grid-connected converters. This paper considers two grid conditions for the experimental analysis: 1) when the grid is stiff and contains only background voltage harmonics and 2) when the grid contains harmonic grid impedances as well as background voltage harmonics. In all cases, a close match between the results predicted by the FCM approach and experimental measurements is achieved, thus demonstrating the practical viability of using experimentally determined FCM models for harmonic predictions.","Harmonic analysis,
Couplings,
Switches,
Power harmonic filters,
Current measurement,
Voltage measurement"
On Predicting Visual Comfort of Stereoscopic Images: A Learning to Rank Based Approach,"Predicting the degree of experienced visual comfort in the context of stereoscopic 3-D (S3D) viewing is particularly challenging. In this letter, a simple yet effective visual comfort assessment (VCA) approach for stereoscopic images is proposed from the perspective of learning to rank (L2R). The proposed L2R-based VCA (L2R-VCA) approach is inspired by the traditional absolute categorical rating (ACR) methodology in subjective study and is to characterize the qualitative description behavior of human subjective study. Experimental results on our recently built database confirm the promising performance of the proposed L2R-VCA approach, yielding higher consistency with human subject judgment results.",
Security Tradeoffs in Cyber Physical Systems: A Case Study Survey on Implantable Medical Devices,"The new culture of networked systems that offer everywhere accessible services has given rise to various types of security tradeoffs. In fact, with the evolution of physical systems that keep getting integrated with cyber frameworks, cyber threats have far more critical effects as they get reflected on the physical environment. As a result, the issue of security of cyber physical systems requires a special holistic treatment. In this paper, we study the tradeoff between security, safety, and availability in such systems and demonstrate these concepts on implantable medical devices as a case study. We discuss the challenges and constraints associated with securing such systems and focus on the tradeoff between security measures required for blocking unauthorized access to the device and the safety of the patient in emergency situations where such measures must be dropped to allow access. We analyze the up to date proposed solutions and discuss their strengths and limitations.","Access control,
Physical layer,
Medical devices,
Computer security,
Safety,
Implants,
Cyber-physical systems"
Error Rate and Power Allocation Analysis of Regenerative Networks Over Generalized Fading Channels,"Cooperative communication has been shown to provide significant increase of transmission reliability and network capacity while expanding coverage in cellular networks. The present work is devoted to the investigation of the end-to-end performance and power allocation of a maximum-ratio-combining based regenerative multi-relay cooperative network over non-homogeneous scattering environment, which is the realistic case in many practical wireless communication scenarios. Novel analytic expressions are derived for the end-to-end symbol-error-rate of both M-ary phase-shift keying and M-ary quadrature amplitude modulation over independent and non-identically distributed generalized fading channels are given by exact analytic expressions that involve the Lauricella function and can be readily evaluated with the aid of a proposed computing algorithm. Simple analytic expressions are also derived for the corresponding symbol-error-rate at asymptotically high signal-to-noise ratios. The derived expressions are corroborated with respective results from computer simulations and are subsequently employed in formulating a sum-power optimization problem that enhances the system performance under total sum-power constraint within the multi-relay cooperative system. It is also shown that asymptotically optimum power allocation provides substantial performance gains over the corresponding equal power allocation, particularly, when the source-relay and relay-destination paths are highly unbalanced.","Fading,
Relays,
Resource management,
Phase shift keying,
Quadrature amplitude modulation,
Cooperative systems,
Wireless communication"
Compact models of negative-capacitance FinFETs: Lumped and distributed charge models,"This work presents insights into the device physics and behaviors of ferroelectric based negative capacitance FinFETs (NC-FinFETs) by proposing lumped and distributed compact models for its simulation. NC-FinFET may have a floating metal between ferroelectric (FE) and the dielectric layers and the lumped charge model represents such a device. For a NC-FinFET without a floating metal, the distributed charge model should be used and at each point in the channel the ferroelectric layer will impact the local channel charge. This distributed effect has important implications on device characteristics as shown in this paper. The proposed compact models have been implemented in circuit simulators for exploring circuits based on NC-FinFET technology.","Iron,
Integrated circuit modeling,
Logic gates,
Mathematical model,
Capacitance,
FinFETs"
A Compact 60-GHz Wireless Power Transfer System,"The first reported full-system 60-GHz wireless power transfer (WPT) solution that can power batteryless and charge coil-free compact WPT devices is presented. The system is fabricated in a 40-nm digital CMOS process and an inexpensive packaging material. In the rectenna (RX), a grid antenna is integrated with a complementary cross-coupled oscillator-like rectifier. At a 4-cm spacing from the transmitter (TX), the RX harvests energy at a rate of 1.22 mW with a 32.8% efficiency, which is significantly higher than the prior state of the art. A novel theoretical analysis of the rectifier operation is presented that formulates all key specifications. The TX is equipped with a quad-core PA that produces a saturated output power (Psat) of 24.6 dBm, which is the highest power delivery in digital CMOS at millimeter-wave bands. The TX peak power-added efficiency is 9.4%. In the TX, a 4 × 8-way differential power combining and a binary-tree architecture are implemented. The designed 2 × 2 grid array antenna helps the TX produce 35.3-dBm peak equivalent isotropically radiated power. The results of the performance characterizations of the full-system and all individually fabricated blocks are reported. The quadcore PA supports power control and beam steering. A four-port TX antenna is designed that shows a 70° steering range in simulations.","Antenna arrays,
Power generation,
Couplings,
Batteries,
Couplers"
Secrecy and Energy Efficiency in Massive MIMO Aided Heterogeneous C-RAN: A New Look at Interference,"In this paper, we investigate the potential benefits of the massive multiple-input multiple-output (MIMO) enabled heterogeneous cloud radio access network (C-RAN) in terms of the secrecy and energy efficiency (EE). In this network, both remote radio heads (RRHs) and massive MIMO macrocell base stations are deployed and soft fractional frequency reuse is adopted to mitigate the intertier interference. We first examine the physical layer security by deriving the area ergodic secrecy rate and secrecy outage probability. Our results reveal that the use of massive MIMO and C-RAN can greatly improve the secrecy performance. For C-RAN, a large number of RRHs achieves high area ergodic secrecy rate and low-secrecy outage probability, due to its powerful interference management. We find that for massive MIMO aided macrocells, having more antennas and serving more users improves secrecy performance. Then, we derive the EE of the heterogeneous C-RAN, illustrating that increasing the number of RRHs significantly enhances the network EE. Furthermore, it is indicated that allocating more radio resources to the RRHs can linearly increase the EE of RRH tier and improve the network EE without affecting the EE of the macrocells.","MIMO,
Interference,
Physical layer,
Network security,
Antenna arrays,
Fading channels,
Macrocell networks,
Energy efficiency,
Radio access networks"
Traffic-Load-Adaptive Medium Access Control for Fully Connected Mobile Ad Hoc Networks,"In this paper, we propose an adaptive medium access control (MAC) solution for a fully connected mobile ad hoc network (MANET), supporting homogeneous best-effort data traffic. The MAC scheme achieves consistently high network performance by adapting to the ever-varying network traffic load. Based on the detection of a current network load condition, nodes can make a switching decision between IEEE 802.11 distributed coordination function (DCF) and dynamic time-division multiple access (D-TDMA), when the network traffic load reaches a threshold, referred to as MAC switching point. The adaptive MAC solution determines the MAC switching point to maximize network performance. Approximate and closed-form performance analytical models for both MAC protocols are established, which facilitate the computation of MAC switching point in a tractable way. Extensive analytical and simulation results demonstrate that the adaptive MAC solution provides consistently maximal network performance in the presence of traffic load dynamics.","Media Access Protocol,
IEEE 802.11 Standard,
Switches,
Time division multiple access,
Mobile ad hoc networks,
Adaptive systems,
Delays"
Resource Allocation for an OFDMA Cloud-RAN of Small Cells Underlaying a Macrocell,"We present a joint resource allocation (RA) and admission control (AC) framework for an orthogonal frequency-division multiple access (OFDMA)-based downlink cellular network composed of a macrocell underlaid by a cloud radio access network (C-RAN) of small cells. In this framework, the RA problems for both the macrocell and small cells are formulated as optimization problems. In particular, the macrocell, being aware of the existence of the small cells, maximizes the sum of the interference levels it can tolerate subject to the macrocell power budget and the quality-of-service (QoS) constraints of macrocell user equipments (MUEs). On the other hand, the small cells minimize the total downlink transmit power subject to their power budget, QoS requirements of small cell UEs (SUEs), interference thresholds for MUEs, and fronthaul constraints. Moreover, AC is considered in the resource allocation problem for the small cells to account for the case where it is not possible to support all SUEs. Besides, to allow for the existence of other network tiers, small cells have a constraint on the number of sub-channels that can be allocated. Both optimization problems are shown to be mixed integer nonlinear problems (MINLPs) for which, lower complexity algorithms are proposed that are based on the framework of successive convex approximation (SCA). Numerical results demonstrate the importance of the careful selection of the resource allocation policy at the macrocell and its impact on the performance of small cells. Moreover, we investigate the effect of the different parameters of the RA problem for the C-RAN of small cells on the overall performance of small cells.",
Image Deblurring via Enhanced Low-Rank Prior,"Low-rank matrix approximation has been successfully applied to numerous vision problems in recent years. In this paper, we propose a novel low-rank prior for blind image deblurring. Our key observation is that directly applying a simple low-rank model to a blurry input image significantly reduces the blur even without using any kernel information, while preserving important edge information. The same model can be used to reduce blur in the gradient map of a blurry input. Based on these properties, we introduce an enhanced prior for image deblurring by combining the low rank prior of similar patches from both the blurry image and its gradient map. We employ a weighted nuclear norm minimization method to further enhance the effectiveness of low-rank prior for image deblurring, by retaining the dominant edges and eliminating fine texture and slight edges in intermediate images, allowing for better kernel estimation. In addition, we evaluate the proposed enhanced low-rank prior for both the uniform and the non-uniform deblurring. Quantitative and qualitative experimental evaluations demonstrate that the proposed algorithm performs favorably against the state-of-the-art deblurring methods.","Kernel,
Image restoration,
Image edge detection,
Estimation,
Minimization,
Cameras,
Approximation algorithms"
Turning a denoiser into a super-resolver using plug and play priors,"Denoising and Super-Resolution are two inverse problems that have been extensively studied. Over the years, these two tasks were treated as two distinct problems that deserve a different algorithmic solution. In this paper we wish to exploit the recently introduced Plug-and-Play Prior (PPP) approach to connect between the two. Using the PPP, we turn leading denoisers into super-resolution solvers. As a case-study we demonstrate this on the NCSR algorithm, which has two variants: one for denoising and one for superresolution. We show that by using the NCSR denoiser, one can get equal or even better results when compared with the NCSR super-resolution.","Mathematical model,
Image resolution,
Noise reduction,
Noise measurement,
Estimation,
Inverse problems,
Degradation"
Dynamic Positioning With Model Predictive Control,"Marine vessels with dynamic positioning (DP) capability are typically equipped with sufficient number of thrusters to make them overactuated and with satellite navigation and other sensors to determine their position, heading, and velocity. An automatic control system is tasked with coordinating the thrusters to move the vessel in any desired direction and to counteract the environmental forces. The design of this control system is usually separated into several levels. First, a DP control algorithm calculates the total force and moment of force that the thruster system should produce. Then, a thrust allocation (TA) algorithm coordinates the thrusters so that the resultant force they produce matches the request from the DP control algorithm. Unless significant heuristic modifications are made, the DP control algorithm has limited information about the thruster effects such as saturations and limited rate of rotation of variable-direction thrusters, as well as systemic effects such as singular thruster configurations. The control output produced with this control architecture is therefore not always optimal, and may result in a position loss that would not have occurred with a more sophisticated control algorithm. Recent advances in computer hardware and algorithms make it possible to consider a model-predictive control (MPC) algorithm that combines positioning control and TA into a single algorithm, which should theoretically yield a near-optimal controller output. This paper explores the advantages and disadvantages of using MPC compared with the traditional algorithms.","Heuristic algorithms,
Marine vehicles,
Force,
Motion control,
Computer architecture,
Computational modeling,
Predictive control"
Analysis and Design Considerations of Integrated 3-Level Buck Converters,"This paper presents a systematic analysis of integrated 3-level buck converters under both ideal and real conditions as a guidance for designing robust and fast 3-level buck converters. Under ideal conditions, the voltage conversion ratio, the output voltage ripple and, in particular, the system's loop-gain function are derived. Design considerations for real circuitry implementations of an integrated 3-level converter, such as the implementation of the flying capacitor, the impacts of the parasitic capacitors of the flying capacitor and the 4 power switches, and the time mismatch between the 2 duty-cycle signals are thoroughly discussed. Under these conditions, the voltage conversion ratio, the voltage across the flying capacitor and the power efficiency are analyzed and verified with Cadence simulation results. The loop-gain function of an integrated 3-level buck converter with parasitic capacitors and time mismatch is derived with the state-space averaging method. The derived loop-gain functions are verified with time-domain small signal injection simulation and measurement, with a good match between the analytical and experimental results.","Capacitors,
Inductors,
Integrated circuit modeling,
Switches,
Standards,
Topology,
Modulation"
Optimizing Unlicensed Spectrum Sharing for LTE-U and WiFi Network Coexistence,"Long-term evolution in unlicensed spectrum (LTE-U) is an emerging technology for expanding cellular network capacity without additional spectrum cost. This paper investigates effective spectrum sharing for coexisting Wi-Fi and LTE-U services. Based on a novel hyper access point (HAP) we introduced for effectively embedding LTE-U in unlicensed Wi-Fi band, LTE-U can directly take advantage of the Wi-Fi point coordination function protocol. To facilitate the coexistence, our HAP dedicates a contention-free period to LTE-U users and allows a contention period (CP) for traditional Wi-Fi users. We investigate the optimization of joint user association and resource allocation to further improve system throughput and user fairness. We formulate a network utility maximization problem based on the Nash bargaining solution (NBS), for which we derive a closed-form expression for the optimal CP length under a given user association. We analyze this NBS-based utility maximization and the performance of the proposed algorithm under log-normal fading, Rayleigh fading, and Rician fading channel models, respectively. Our numerical results corroborate our analysis and demonstrate effective improvement of the system performance by the proposed HAP algorithm against traditional LTE-U deployment.","IEEE 802.11 Standard,
Resource management,
Interference,
Throughput,
Rayleigh channels,
Media Access Protocol"
Chip-Level RAID with Flexible Stripe Size and Parity Placement for Enhanced SSD Reliability,"The move from SLC to MLC/TLC flash memory technology is increasing SSD capacity at lower cost, but at the cost of sacrificing reliability. An approach to remedy this loss is to employ the RAID architecture with the chips that comprise SSDs. However, using the traditional RAID approach may result in negative effects as the total number of writes is increased due to the parity updates. In this paper, we describe Elastic Striping and Anywhere Parity (eSAP)-RAID, a RAID scheme that allows flexible stripe sizes and parity placement. Using performance and lifetime models that we derive of SSDs employing RAID-5 and eSAP-RAID, we show that eSAP-RAID brings about significant performance and reliability benefits by reducing parity writes compared to RAID-5. We also implement these schemes in SSDs using DiskSim with SSD Extension and validate the models using realistic workloads. We also discuss policies such as dynamic stripe sizing and selective data protection that exploits the flexible nature of eSAP. We show that through such policies particular reliability enhancement goals can be met.","Reliability,
Error correction codes,
Ash,
Bit error rate,
Random access memory,
FCC"
One-Class Classification-Based Real-Time Activity Error Detection in Smart Homes,"Caring for individuals with dementia is frequently associated with extreme physical and emotional stress, which often leads to depression. Smart home technology and advances in machine learning techniques can provide innovative solutions to reduce caregiver burden. One key service that caregivers provide is prompting individuals with memory limitations to initiate and complete daily activities. We hypothesize that sensor technologies combined with machine learning techniques can automate the process of providing reminder-based interventions. The first step toward automated interventions is to detect when an individual faces difficulty with activities. We propose machine learning approaches based on one-class classification that learn normal activity patterns. When we apply these classifiers to activity patterns that were not seen before, the classifiers are able to detect activity errors, which represent potential prompt situations. We validate our approaches on smart home sensor data obtained from older adult participants, some of whom faced difficulties performing routine activities and thus committed errors.","Smart homes,
Real-time systems,
Signal processing algorithms,
Streaming media,
Temperature measurement,
Psychology,
Dementia"
A Hybrid Genetic Algorithm for the Minimum Exposure Path Problem of Wireless Sensor Networks Based on a Numerical Functional Extreme Model,"Searching for the minimum exposure path (MEP) is one of the critical issues in wireless sensor networks (WSNs). The exposure corresponding to the MEP is one indicator to measure the coverage quality of a WSN, reflecting how well a mobile target is monitored through the sensing field. The classical methods, such as the grid-based method and the Voronoi-diagram-based method, are not accurate enough to obtain the MEP, are too complex, and are not applicable to networks with heterogeneous sensor nodes, a large number of sensor nodes, or all-sensor field intensity function. To overcome these challenges, a numerical functional extreme (NFE) model is proposed for the MEP problem in this paper. The NFE model is a high-dimensional and nonlinear optimization problem. To efficiently solve this problem, based on the characteristics of the sensor node coverage, a new crossover operator is designed, a new local search scheme is proposed, and an upside-down operator to escape from local optima is developed. Integrating all of these, a hybrid genetic algorithm (HGA) is proposed for the NFE model, and its global convergence with probability one is proven. An extensive collection of experiments were conducted, and the results indicate that the proposed NFE model and the developed HGA can improve the solution accuracy and can be applicable to not only the case with heterogeneous sensors but the case with a large number of sensor nodes and all-sensor field intensity function as well.",
Open-Circuit Fault-Tolerant Control for Outer Switches of Three-Level Rectifiers in Wind Turbine Systems,"A three-level converter is used as the power converters of wind turbine systems because of their advantages such as low-current total harmonic distortion, high efficiency, and low collector-emitter voltage. Interior permanent magnet synchronous generators (IPMSGs) have been chosen as the generator in wind turbine systems owing to their advantages of size and efficiency. In wind turbine systems consisting of the three-level converter and the IPMSG, fault-tolerant controls for an open-circuit fault of switches should be implemented to improve reliability. This paper focuses on the open-circuit fault of outer switches (Sx1 and Sx4) in three-level rectifiers (both neutral-point clamped and T-type) that are connected to the IPMSG. In addition, the effects of Sx1 and Sx4 open-circuit faults are analyzed, and based on this analysis, a tolerant control is proposed. The proposed tolerant control maintains normal operation with sinusoidal currents under the open-circuit fault of outer switches by adding a compensation value to the reference voltages. The effectiveness and performance of the proposed tolerant control are verified by simulation and experiment.","Rectifiers,
Reactive power,
Switches,
Circuit faults,
Topology,
Distortion,
Voltage control"
Equiprobable Subcarrier Activation Method for OFDM With Index Modulation,"Orthogonal frequency division multiplexing with index modulation (OFDM-IM) conveys additional information bits via the indices of active subcarriers. Consequently, the determination of the active subcarriers according to the incoming bits arises as a challenging problem. The existing solution resorts to the lexicographic ordering, which leads to a low implementation complexity but an unequal subcarrier activation probability. This letter proposes a distinct solution that allows the equiprobable activation of all OFDM-IM subcarriers with comparable implementation complexity. The signal-to-noise ratio gain achieved by the proposed solution is also analyzed. Computer simulations reveal the advantages of the proposed solution.","Indexes,
OFDM,
Modulation,
Signal to noise ratio,
Detectors,
Complexity theory,
Computer simulation"
Non-Obtuse Remeshing with Centroidal Voronoi Tessellation,"We present a novel remeshing algorithm that avoids triangles with small (acute) angles and those with large (obtuse) angles. Our solution is based on an extension of Centroidal Voronoi Tesselation (CVT). We augment the original CVT formulation with a penalty term that penalizes short Voronoi edges, while the CVT term helps to avoid small angles. Our results show significant improvements in remeshing quality over the state of the art.","Three-dimensional displays,
Laplace equations,
Surface treatment,
Optimization,
Mesh generation,
Solid modeling,
Face"
Improving Read Performance of NAND Flash SSDs by Exploiting Error Locality,"NAND flash-based solid-state drives (SSDs), which can serve as the caches of hard disk drives, have gained popularity in large-scale, high-performance storage. A type of advanced error correction code for SSDs, low-density parity-check (LDPC), is required to mitigate a considerable number of errors in the raw data of NAND flash. However, LDPC imposes read performanceoverhead due to the complex decoding procedure of LDPC. In this paper, we propose an error-correcting cache (EC-Cache) that exploits “error locality”, a characteristic of NAND flash memory, to improve the read performance of SSDs. We use the term “error locality” to refer to the property that the majority of errors in reads to the same flash page appear at the same positions until thepage is erased. By caching detected errors, we can correct a significant portion of errors in the requested flash page prior to the LDPC decoding process. This design significantly reduces LDPC decoding overhead because the latency of LDPC is correlated with thenumber of errors in the input data. We conduct experiments, including flash characterization, LDPC simulation, and SSD simulation,to evaluate EC-Cache. The experimental results demonstrate that EC-Cache can improve the read performance of LDPC-based SSDs by up to 2.6\times .","Ash,
Decoding,
Random access memory,
Sensors,
Iterative decoding,
Flash memories"
High-performance and tunable stereo reconstruction,"Traditional stereo algorithms have focused their efforts on reconstruction quality and have largely avoided prioritizing for run time performance. Robots, on the other hand, require quick maneuverability and effective computation to observe its immediate environment and perform tasks within it. In this work, we propose a high-performance and tunable stereo disparity estimation method, with a peak frame-rate of 120Hz (VGA resolution, on a single CPU-thread), that can potentially enable robots to quickly reconstruct their immediate surroundings and maneuver at high-speeds. Our key contribution is a disparity estimation algorithm that iteratively approximates the scene depth via a piece-wise planar mesh from stereo imagery, with a fast depth validation step for semi-dense reconstruction. The mesh is initially seeded with sparsely matched keypoints, and is recursively tessellated and refined as needed (via a resampling stage), to provide the desired stereo disparity accuracy. The inherent simplicity and speed of our approach, with the ability to tune it to a desired reconstruction quality and runtime performance makes it a compelling solution for applications in high-speed vehicles.","stereo image processing,
estimation theory,
natural scenes,
robots"
Power-Loss Analysis and Efficiency Maximization of a Silicon-Carbide MOSFET-Based Three-Phase 10-kW Bidirectional EV Charger Using Variable-DC-Bus Control,"It is expected that wide-bandgap devices like silicon-carbide MOSFETs and gallium-nitride HEMTs could replace Si devices in power electronics converters to reach higher system efficiency. This paper adopts the conventional half-bridge LLC topology to realize a 10-kW all-SiC bidirectional charger used in electric vehicles. Though it is a well-known topology for the unidirectional charger, it has not been comprehensively explored for the bidirectional energy flow yet. A double-pulse-test (DPT) platform is utilized to provide accurate power losses. A state-space model is built to obtain accurate switching current waveforms, which is eventually combined with the DPT results to accurately predict the system efficiency. Based on this model, to further enhance the system efficiency, the dc-bus voltage is varied with LLC dc/dc converter running at the resonant frequency through the whole power range. Experimental results validated that the proposed approach could realize the bidirectional power flow. By varying the dc-bus voltage, the V2G and G2V modes reach ~96 % wall-to-battery efficiency.","Switches,
Topology,
MOSFET,
Silicon carbide,
Batteries,
Power electronics,
Bidirectional control"
ANC-ERA: Random Access for Analog Network Coding in Wireless Networks,"Analog network coding (ANC) is effective in improving spectrum efficiency. To coordinate ANC among multiple nodes without relying on complicated scheduling algorithm and network optimization, a new random access MAC protocol, called ANC-ERA, is developed to dynamically form ANC-cooperation groups in an ad hoc network. ANC-ERA includes several key mechanisms to maintain high performance in medium access. First, network allocation vectors (NAV) of control frames are properly set to avoid over-blocking of channel access. Second, a channel occupation frame (COF) is added to protect vulnerable periods during the formation of ANC cooperation. Third, an ACK diversity mechanism is designed to reduce potentially high ACK loss probability in ANC-based wireless networks. Since forming an ANC cooperation relies on bi-directional traffic between the initiator and the cooperator, the throughput gain from ANC drops dramatically if bi-directional traffic is not available. To avoid this issue, the fourth key mechanism, called flow compensation, is designed to form different types of ANC cooperation among neighboring nodes of the initiator and the cooperator. Both theoretical analysis and simulations are conducted to evaluate ANC-ERA. Performance results show that ANC-ERA works effectively in ad hoc networks and significantly outperforms existing random access MAC protocols.","Relays,
Media Access Protocol,
Wireless networks,
Ad hoc networks,
Network coding,
Sensors"
Dynamic Resource Partitioning for Heterogeneous Multi-Core-Based Cloud Computing in Smart Cities,"As the smart cities emerged for more comfortable urban spaces, services, such as health, transportation, and so on, need to be promoted. In addition, the cloud computing provides flexible allocation, migration of services, and better security isolation; therefore, it is the infrastructure for the smart cities. Single instruction-set architecture (ISA) heterogeneous multi-core processors have higher performance per watt than their symmetric counterparts and are popular in current processors. In current cloud computing, which integrates a few fast out-of-order cores, coupled with a large number of simpler, slow cores, all cores expose the same ISA. The best way to leverage the effectiveness of these systems is to accelerate sequential CPU-bound threads using fast cores, and to improve the throughput of parallel memory-bound threads using slow cores. However, shared hardware resources, such as memory, respond to requests from all cores, which interfere with each other, leading to both low speed for fast cores and low throughput for slow cores. In this paper, we propose a dynamic resource partitioning (DRP) method for single-ISA heterogeneous multi-cores, which partitions the shared resources according to both threads' requirements for the shared resources and the performance of their running cores. The key principle is to profile both threads' resource characteristics at run-time and the performance of the cores that the threads are running on to estimate demands for resources. Then, we use the estimation to direct our resource partitioning. Moreover, we integrate our DRP with current memory scheduling policies to improve the system performance further for the two methods being orthogonal.",
A Higher Energy-Efficient Sampling Scheme for Networked Control Systems over IEEE 802.15.4 Wireless Networks,"This paper proposes a higher energy-efficient mixed sampling scheme (MSE) for networked control systems (NCSs) over IEEE 802.15.4 wireless networks. Compared with some existing periodic event-triggered sampling (ETS) schemes with a delayed sampling estimation, this delay is no longer existing in MSE since there is a dynamic adjustable threshold in MSE to compensate for this delay. Compared with some existing self-triggered sampling (STS)/ETS schemes, MSE does not require continuous measurement of the system states and does not suffer from the conservativeness induced by a self-triggered estimation. By using the proposed MSE, one can improve the energy efficiency in energy-constrained wireless NCSs (WiNCSs) by reducing the number of transmitted packets and increasing the idle-listening period of wireless sensor nodes. An inverted pendulum (Feedback 33-005-PCI) controlled over IEEE 802.15.4 wireless networks is given to demonstrate the effectiveness of the proposed method.","Wireless sensor networks,
Informatics,
Upper bound,
Networked control systems,
IEEE 802.15 Standard,
Delays,
Wireless networks"
A Review of Technology Standards and Patent Portfolios for Enabling Cyber-Physical Systems in Advanced Manufacturing,"Cyber-physical systems (CPS) are a collection of transformative technologies for managing interconnected physical and computational capabilities. Recent developments in technology are increasing the availability and affordability of sensors, data acquisition systems, and computer networks. The competitive nature of industry requires manufacturers to implement new methodologies. CPS is a broad area of engineering which supports applications across industries, such as manufacturing, healthcare, electric power grids, agriculture, and transportation. In particular, CPS is the core technology enabling the transition from Industry 3.0 to Industry 4.0 (I 4.0) and is transforming global advanced manufacturing. This paper provides a consolidated review of the latest CPS literature, a complete review of international standards, and a complete analysis of patent portfolios related to the 5C's CPS architecture model by Lee et al. The critical evaluation of international standards and the intellectual property contained in CPS patents is unaddressed by the previous research and will benefit both academic scholars and industry practitioners. The analysis provides a basis for predicting research and development future trends and helps policy makers manage technology changes that will result from CPS in I 4.0. This paper covers the emerging I 4.0 standards from the International Organization for Standardization, the International Electrotechnical Commission, and China's Guobiao standards followed by a patent analysis covering global patents issued in the U.S., Europe, China, and the World Intellectual Property Organization.","Cyber-physical systems,
Patents,
Manufacturing processes,
Intellectual property,
Sensor systems,
Standards development,
International standards"
Synthesis of Human-in-the-Loop Control Protocols for Autonomous Systems,"We propose an approach to synthesize control protocols for autonomous systems that account for uncertainties and imperfections in interactions with human operators. As an illustrative example, we consider a scenario involving road network surveillance by an unmanned aerial vehicle (UAV) that is controlled remotely by a human operator but also has a certain degree of autonomy. Depending on the type (i.e., probabilistic and/or nondeterministic) of knowledge about the uncertainties and imperfections in the human-automation interactions, we use abstractions based on Markov decision processes and augment these models to stochastic two-player games. Our approach enables the synthesis of operator-dependent optimal mission plans for the UAV, highlighting the effects of operator characteristics (e.g., workload, proficiency, and fatigue) on UAV mission performance. It can also provide informative feedback (e.g., Pareto curves showing the tradeoffs between multiple mission objectives), potentially assisting the operator in decision-making. We demonstrate the applicability of our approach via a detailed UAV mission planning case study.","Protocols,
Human factors,
Stochastic processes,
Games,
Fatigue,
Planning,
Roads"
Adaptive Impact-Driven Detection of Silent Data Corruption for HPC Applications,"For exascale HPC applications, silent data corruption (SDC) is one of the most dangerous problems because there is no indication that there are errors during the execution. We propose an adaptive impact-driven method that can detect SDCs dynamically. The key contributions are threefold. (1) We carefully characterize 18 HPC applications/benchmarks and discuss the runtime data features, as well as the impact of the SDCs on their execution results. (2) We propose an impact-driven detection model that does not blindly improve the prediction accuracy, but instead detects only influential SDCs to guarantee user-acceptable execution results. (3) Our solution can adapt to dynamic prediction errors based on local runtime data and can automatically tune detection ranges for guaranteeing low false alarms. Experiments show that our detector can detect 80-99.99 percent of SDCs with a false alarm rate less that 1 percent of iterations for most cases. The memory cost and detection overhead are reduced to 15 and 6.3 percent, respectively, for a large majority of applications.",
Full-Duplex Spectrum Sharing in Cooperative Single Carrier Systems,"We propose cyclic prefix single carrier full-duplex transmission in amplify-and-forward cooperative spectrum sharing networks to achieve multipath diversity and full-duplex spectral efficiency. Integrating full-duplex transmission into cooperative spectrum sharing systems results in two intrinsic problems: 1) the residual loop interference occurs between the transmit and the receive antennas at the secondary relays and 2) the primary users simultaneously suffer interference from the secondary source (SS) and the secondary relays (SRs). Thus, examining the effects of residual loop interference under peak interference power constraint at the primary users and maximum transmit power constraints at the SS and the SRs is a particularly challenging problem in frequency selective fading channels. To do so, we derive and quantitatively compare the lower bounds on the outage probability and the corresponding asymptotic outage probability for max-min relay selection, partial relay selection, and maximum interference relay selection policies in frequency selective fading channels. To facilitate comparison, we provide the corresponding analysis for half-duplex. Our results show two complementary regions, named as the signal-to-noise ratio (SNR) dominant region and the residual loop interference dominant region, where the multipath diversity and spatial diversity can be achievable only in the SNR dominant region, however the diversity gain collapses to zero in the residual loop interference dominant region.","Interference,
Relays,
Fading channels,
Signal to noise ratio,
Diversity methods,
OFDM,
Frequency division multiplexing"
"A 90 nm CMOS, 6\ {\upmu {\text{W}}} Power-Proportional Acoustic Sensing Frontend for Voice Activity Detection","This work presents a sub-6 μW acoustic frontend for speech/non-speech classification in a voice activity detection (VAD) in 90 nm CMOS. Power consumption of the VAD system is minimized by architectural design around a new power-proportional sensing paradigm and the use of machine-learning assisted moderate-precision analog analytics for classification. Power-proportional sensing allows for hierarchical and context-aware scaling of the frontend's power consumption depending on the complexity of the ongoing information extraction, while the use of analog analytics brings increased power efficiency through switching ON/OFF the computation of individual features depending on the features' usefulness in a particular context. The proposed VAD system reduces the power consumption by 10× as compared to state-of-the-art (SotA) systems and yet achieves an 89% average hit rate (HR) for a 12 dB signal-to-acoustic-noise ratio (SANR) in babble context, which is at par with softwarebased VAD systems.","speech recognition,
acoustic signal detection,
acoustic transducers,
CMOS integrated circuits,
low-power electronics,
signal conditioning circuits"
ParticipAct: A Large-Scale Crowdsensing Platform,"In recent years, the widespread availability of sensor-provided smartphones has enabled the possibility of harvesting large quantities of data in urban areas exploiting user devices, so enabling the so-called crowdsensing that allows to realize complex applications impossible without the involvement of the research community. While many efforts have been made to improve specific techniques - spanning from signal processing to the assignment of data collection campaigns to users, and to the entire data processing - to the best of our knowledge, there are no active experiments aimed to explore the challenging issues raised by the management of large-scale crowdsensing campaigns as real-world experiments. This paper presents the ParticipAct platform and its ParticipAct living lab, an ongoing experiment at the University of Bologna that involves 170 students for one year in several crowdsensing campaigns that can access passively smartphone sensors and also prompt for user active collaboration. In this paper, we describe the guidelines behind the design of ParticipAct, its features, its architecture, and report quantitative results that assess and confirm the feasibility, obtained via intelligent coordination and management of crowdsensing campaigns.","Sensors,
Servers,
Smart phones,
Data collection,
Computer architecture,
Urban areas,
Waste materials"
Efficient Compressed Sensing SENSE pMRI Reconstruction With Joint Sparsity Promotion,"The theory and techniques of compressed sensing (CS) have shown their potential as a breakthrough in accelerating k-space data acquisition for parallel magnetic resonance imaging (pMRI). However, the performance of CS reconstruction models in pMRI has not been fully maximized, and CS recovery guarantees for pMRI are largely absent. To improve reconstruction accuracy from parsimonious amounts of k-space data while maintaining flexibility, a new CS SENSitivity Encoding (SENSE) pMRI reconstruction framework promoting joint sparsity (JS) across channels (JS CS SENSE) is proposed in this paper. The recovery guarantee derived for the proposed JS CS SENSE model is demonstrated to be better than that of the conventional CS SENSE model and similar to that of the coil-by-coil CS model. The flexibility of the new model is better than the coil-by-coil CS model and the same as that of CS SENSE. For fast image reconstruction and fair comparisons, all the introduced CS-based constrained optimization problems are solved with split Bregman, variable splitting, and combined-variable splitting techniques. For the JS CS SENSE model in particular, these techniques lead to an efficient algorithm. Numerical experiments show that the reconstruction accuracy is significantly improved by JS CS SENSE compared with the conventional CS SENSE. In addition, an accurate residual-JS regularized sensitivity estimation model is also proposed and extended to calibration-less (CaL) JS CS SENSE. Numerical results show that CaL JS CS SENSE outperforms other state-of-the-art CS-based calibration-less methods in particular for reconstructing non-piecewise constant images.",
Inversion Symmetry of the Euclidean Group: Theory and Application to Robot Kinematics,"Just as the 3-D Euclidean space can be inverted through any of its points, the special Euclidean group SE(3) admits an inversion symmetry through any of its elements and is known to be a symmetric space. In this paper, we show that the symmetric submanifolds of SE(3) can be systematically exploited to study the kinematics of a variety of kinesiological and mechanical systems and, therefore, have many potential applications in robot kinematics. Unlike Lie subgroups of SE(3), symmetric submanifolds inherit distinct geometric properties from inversion symmetry. They can be generated by kinematic chains with symmetric joint twists. The main contribution of this paper is: 1) to give a complete classification of symmetric submanifolds of SE(3); 2) to investigate their geometric properties for robotics applications; and 3) to develop a generic method for synthesizing their kinematic chains.","Couplings,
Manipulators,
Kinematics,
Mirrors,
Robot kinematics,
Systematics"
A Planar Windmill-Like Broadband Antenna Equipped With Artificial Magnetic Conductor for Off-Body Communications,"A broadband antenna inspired by a windmill sail is developed for wireless body area network (WBAN) applications. The antenna consists of a couple of modified dipoles with four crossed symmetrical S-shaped arms printed on a flexible substrate. A 5 ×5 unit structure of artificial magnetic conductor (AMC) is integrated to reduce the backward scattering wave toward the human body, and simultaneously ensures a low profile with a thickness of 5.74 mm and a small size with the area of 46 ×46 mm2. The measured results on the phantom reveal that the AMC-integrated antenna accomplishes an impedance bandwidth of 63.5% (5.7-11.0 GHz) with , a peak gain of 8 dBi, and a front-to-back ratio (FBR) greater than 15 dB. Health safety factors, such as specific absorption rate and temperature, are considered. According to the calculation of link budget in different scenarios, the reliable communication can be guaranteed within 10 m in line-of-sight (LOS) environment. The good performances make the proposed AMC-integrated antenna potential for wireless communication between miniaturized wearable sensors and a localized base station around body.",
Lithography-Aware Analog Layout Retargeting,"Photolithographic defects during manufacture cannot only result in significant yield loss in digital integrated circuits, but are also deemed as an important factor in evaluating the quality of analog layouts. In this paper, we propose a graph-based lithography-aware analog layout retargeting methodology. We build up our fault model based on a classical defect size distribution function, geometrical critical area analysis, and probability of failure (POF). The objective of our algorithm is to minimize POF by intelligent redundant space allocation scheme during layout compaction. The optimizations handle the whole analog layout area by global wire widening, intradevice wire shifting (WS), and interdevice WS, which are achieved by updating the constraint-graph representation of the layout. Moreover, we propose an extra space allocation approach that can further reduce POF by an inconsiderably small chip-area compromise. The yield improvement and superior effectiveness of our algorithm are exhibited by retargeting operational amplifiers and being compared with a traditional linear programming-based layout compaction method and a well-known even wire distribution scheme.",
A Resilient Routing Algorithm with Formal Reliability Analysis for Partially Connected 3D-NoCs,"3D ICs can take advantage of a scalable communication platform, commonly referred to as the Networks-on-Chip (NoC). In the basic form of 3D-NoC, all routers are vertically connected. Partially connected 3D-NoC has emerged because of physical limitations of using vertical links. Routing is of great importance in such partially connected architectures. A high-performance, fault-tolerant and adaptive routing strategy with respect to the communication flow among the cores is crucial while freedom from livelock and deadlock has to be guaranteed. In this paper we introduce a new routing algorithm for partially connected 3D-NoCs. The routing algorithm is adaptive and tolerates the faults on vertical links as compared to the predesigned routing algorithms. Our results show a 40-50\% improvement in the fraction of intact inter-level communications when the fault tolerant algorithm is used. This routing algorithm is light-weight and has only one virtual channel along the Y dimension.","Network-on-chip,
Algorithm design and analysis,
Three-dimensional displays,
Fault tolerance,
System recovery,
Through-silicon vias,
Computer network reliability"
Semantic Concept Co-Occurrence Patterns for Image Annotation and Retrieval,"Describing visual image contents by semantic concepts is an effective and straightforward way to facilitate various high level applications. Inferring semantic concepts from low-level pictorial feature analysis is challenging due to the semantic gap problem, while manually labeling concepts is unwise because of a large number of images in both online and offline collections. In this paper, we present a novel approach to automatically generate intermediate image descriptors by exploiting concept co-occurrence patterns in the pre-labeled training set that renders it possible to depict complex scene images semantically. Our work is motivated by the fact that multiple concepts that frequently co-occur across images form patterns which could provide contextual cues for individual concept inference. We discover the co-occurrence patterns as hierarchical communities by graph modularity maximization in a network with nodes and edges representing concepts and co-occurrence relationships separately. A random walk process working on the inferred concept probabilities with the discovered co-occurrence patterns is applied to acquire the refined concept signature representation. Through experiments in automatic image annotation and semantic image retrieval on several challenging datasets, we demonstrate the effectiveness of the proposed concept co-occurrence patterns as well as the concept signature representation in comparison with state-of-the-art approaches.",
Control and characterization of electromagnetic emissions in wide band gap based converter modules for ungrounded grid-forming applications,"Electromagnetic emissions of a 1.2kV, 120A SiC-based half-bridge switching at 100kHz that includes grounding paths and that can be extended to a 100kVA inverter and, eventually, systems of paralleled and cascaded inverters suitable for shipboard and solar farm applications is studied. This switching pole forms the basis of a test platform specifically designed to discover sensitivities to resonant paths so that design guidelines for peripheral structures and EMI mitigating components can be developed. Ungrounded grid-forming inverters are considered in this work because such systems present a worst case scenario when it comes to the effects of resonances through grounding paths being excited by “near-RF” frequencies associated with Wide Band Gap implementations.","Inverters,
Electromagnetic interference,
Inductors,
Switches,
Logic gates,
Switching frequency"
"Safe Coordinated Maneuvering of Teams of Multirotor Unmanned Aerial Vehicles: A Cooperative Control Framework for Multivehicle, Time-Critical Missions","Multirotor unmanned aerial vehicles (UAVs) have experienced a very fast-paced technological development over the past years. Flight control systems have evolved from simple stability augmentation systems, barely enabling an external pilot to remotely fly a multirotor UAV, to full-fledged command augmentation systems, opening up the possibilities of autonomous operations of multirotors. Due to their small size, low cost, and high agility, multirotors draw a plethora of applications, including multiple vehicles operations, where the vehicles cooperate and jointly execute a mission, in constrained complex environments such as crowd monitoring and utility line inspection.",
Improving the security of wireless sensor networks in an IoT environmental monitoring system,"The Internet of Things (IoT) has become a popular subject in the technology industry and will soon reach the popularity level of smartphones. With the rapid technological advancements of sensors, Wireless Sensor Networks (WSNs) has become the main technology for IoT. We investigated the security of WSNs in an environmental monitoring system with the goal to improve the overall security. We implemented a Secure Temperature Monitoring System (STMS), which served as our investigational environment. Our results revealed a security flaw found in the bootstrap loader (BSL) password used to protect firmware found in the MSP430 MCU. We demonstrated how the BSL password could be brute forced in a matter of days. Furthermore, to our knowledge we illustrated the first sample of how an attacker can reverse engineer firmware and obtain WSN cryptographic keys. Our sample provides a step-by-step procedure on how to reverse engineer MSP430 firmware. We contributed a solution to improve the BSL password and better protect firmware found in the MSP430 chips. The Secure-BSL software we contributed allows the randomization of the BSL password. Our solution guarantees brute force times in a matter of decades. The impractical brute force time assures the security of firmware and prevents future reverse engineering tactics. In addition, our Secure-BSL software supports two-factor authentication, therefore adding another layer of security. The two-factor authentication feature allows developers to specify a user-defined passphrase to further protect the MSP430 MCU. Our research serves as proof that any security implemented in a WSN environment is broken if an attacker has access to firmware found in sensor devices.","Temperature sensors,
Security,
Wireless sensor networks,
Monitoring,
Temperature measurement,
Microprogramming"
Similarity of Properties of Metamaterial Slow-Wave Structures and Metallic Periodic Structures,"A study of the evolution of wave dispersion in systems of all-metallic periodic structures with increasing corrugation depth shows a similarity of the properties of waves in metamaterial slow-wave structures (MSWSs) and traditional metallic SWSs used in high-power microwave sources. We show that the main properties of MSWSs, such as the existence of a lowest order negative dispersion wave below cutoff, also appear in ordinary metallic periodic systems with deep corrugations. Furthermore, we find that the appearance of negative dispersion in all-metallic periodic structures with increasing corrugation depth is accompanied by a hybrid mode being identified as the lowest order negative dispersion mode.",
Wearable Inertial Sensors for Human Motion Analysis: A Review,"This paper reviews the research literature on human motion analysis using inertial sensors with the aim to find out: which configuration of sensors have been used to measure human motion; which algorithms have been implemented to estimate position and orientation of segments and joints of human body; how the performance of the proposed systems has been evaluated; and what is the target population with which the proposed systems have been assessed. These questions were used to revise the current state-of-the-art and suggest future directions in the development of systems to estimate human motion. A search of literature was conducted on eight Internet databases and includes medical literature: PubMed and ScienceDirect; technical literature: IEEE Xplore and ACM Digital Library; and all-science literature: Scopus, Web of Science, Taylor and Francis Online, and Wiley Online Library. A total of 880 studies were reviewed based on the criteria for inclusion/exclusion. After the screening and full review stages, 37 papers were selected for the review analysis. According to the review analysis, most studies focus on calculating the orientation or position of certain joints of the human body, such as elbow or knee. There are only three works that estimate position or orientation of both, upper and lower limbs simultaneously. Regarding the configuration of the experiments, the mean age of the test subjects is 26.2 years (± 3.7), indicating a clear trend to test the systems and methods using mainly young people. Other population groups, such as people with mobility problems, have not been considered in tests so far. Human motion analysis is relevant for obtaining a quantitative assessment of motion parameters of people. This assessment is crucial for, among others, healthcare applications, monitoring of neuromuscular impairments, and activity recognition. There is a growing interest for developing technologies and methods for enabling human motion analysis, ranging from specialized in situ systems to low-cost wearable systems.","Wearable sensors,
Motion measurement,
Sensor systems,
Magnetic sensors,
Sensor phenomena and characterization,
Sensor fusion"
"3S-cart: A Lightweight, Interactive Sensor-Based Cart for Smart Shopping in Supermarkets","Nowadays, shopping has played a key role in our economic activity. It deserves investigation how to provide smart shopping by promptly interacting with customers in supermarkets. This paper proposes a sensor-based smart shopping cart (3S-cart) system by using the context-aware ability of sensors to detect the behavior of customers, and respond to them in real time. A prototype of 3S-cart is implemented by encapsulating modularized sensors in a box to be put on shopping carts. Thus, 3S-cart is lightweight and easy to deploy. We also demonstrate two supermarket applications by 3S-cart. In the sales-promotion application, each cart checks if its customer has interest in some products and shows sales information at once to increase the purchasing desire. In the product-navigation application, a customer asks the system to find an unhindered, shortest path to comfortably obtain the desired product. This paper contributes in exploiting the sensor technology to provide interactive shopping in supermarkets, and addressing the prototyping experience and potential applications of the proposed 3S-cart system.",
Current Injection-Based Online Parameter and VSI Nonlinearity Estimation for PMSM Drives Using Current and Voltage DC Components,"To develop a high-performance and reliable permanent-magnet synchronous machine (PMSM) drive for electric vehicle (EV) applications, accurate knowledge of the PMSM parameters is of significance. This paper investigates online estimation of PMSM parameters and voltage source inverter (VSI) nonlinearity using current injection method in which magnetic saturation is also considered. First, a novel dc component-based current injection model considering VSI nonlinearity is proposed, which employs the dc components of dq-axis currents and voltages for PMSM parameter and VSI-distorted voltage estimation. This method can eliminate the influence of rotor position error on VSI nonlinearity estimation. Second, a simplified linear equation is employed to model the cross- and self-saturation of the dq-axis inductances during current injection, which can facilitate the estimation of the inductance variations induced by magnetic saturation. Third, a novel current compensation strategy is proposed to minimize the torque ripples caused by current injection, which contributes to making our approach applicable to both surface and interior PMSMs. Therefore, the proposed online parameter estimation approach can estimate the winding resistance, rotor flux, VSI-distorted voltage, and the varying dq-axis inductances under different operating conditions. The proposed approach is experimentally validated on a down-scaled laboratory interior PMSM prototyped for direct-drive EV powertrain.","Parameter estimation,
Rotors,
Mathematical model,
Permanent magnet machines,
Magnetic flux,
Saturation magnetization"
Feature Selection Embedded Subspace Clustering,"We propose a new subspace clustering method that integrates feature selection into subspace clustering. Rather than using all features to construct a low-rank representation of the data, we find such a representation using only relevant features, which helps in revealing more accurate data relationships. Two variants are proposed by using both convex and nonconvex rank approximations. Extensive experimental results confirm the effectiveness of the proposed method and models.","Power capacitors,
Face,
Clustering algorithms,
Optimization,
Clustering methods,
Signal processing algorithms,
Closed-form solutions"
CPA-SLAM: Consistent plane-model alignment for direct RGB-D SLAM,"Planes are predominant features of man-made environments which have been exploited in many mapping approaches. In this paper, we propose a real-time capable RGB-D SLAM system that consistently integrates frame-to-keyframe and frame-to-plane alignment. Our method models the environment with a global plane model and - besides direct image alignment - it uses the planes for tracking and global graph optimization. This way, our method makes use of the dense image information available in keyframes for accurate short-term tracking. At the same time it uses a global model to reduce drift. Both components are integrated consistently in an expectation-maximization framework. In experiments, we demonstrate the benefits our approach and its state-of-the-art accuracy on challenging benchmarks.","Simultaneous localization and mapping,
Optimization,
Solid modeling,
Cameras,
Tracking,
Motion segmentation,
Visualization"
Joint Optimization of Quality of Experience and Power Consumption in OFDMA Multicell Networks,"Quality of experience (QoE) and power consumption are two important considerations of OFDMA multicell networks. In this letter, we propose a fair QoE-based radio resource allocation (FQRA) for OFDMA multicell networks. Different from the previous work, the multiuser QoE per power consumption is introduced as the performance metric. A novel utility function, which can characterize the fairness of users' QoE and power consumption jointly, is proposed. Then a multiuser FQRA problem is formulated. Due to the nonconvex form of optimization, a two-step solution is devised in which the subchannel allocation and power allocation are performed iteratively. Simulation results show that our method can significantly improve the QoE per power consumption of cells and outperform the state-of-art schemes.",
Resonant Inductive Coupling-Based Piston Position Sensing Mechanism for Large Vertical Displacement Micromirrors,"This paper serves to demonstrate resonant inductive coupling-based eddy current sensing as a promising piston position sensing mechanism for large vertical displacement micromirrors that exhibit piston scan ranges above 100 μm. The sensor consists of two microfabricated coils packaged underneath the mirror plate of an electrothermally actuated piston scanning micromirror. For this paper, position sensing is achieved through the amplitude detection of the sensor oscillation signal due to the change in inductive coupling between the coils when the mirror plate undergoes its piston scan. Two sensing regions could be obtained: a front slope region that has a larger piston sensing range of 1 mm with a 280-nm resolution and a back slope region that has higher sensitivity over a smaller piston sensing range of ~130 μm with a 20-nm resolution. For demonstration purpose, the sensing coils are designed to oscillate at 9.4 MHz through a regenerative circuit and a readout circuit was used to extract the piston position information, with which the static, dynamic, and frequency response of the micromirror were measured. This paper also presents the fundamental electromagnetic analytical modeling for the sensor performance.","Coils,
Sensors,
Pistons,
Micromirrors,
Couplings,
Transmitters"
Constructions and Decoding of Cyclic Codes Over b -Symbol Read Channels,"Symbol-pair read channels, in which the outputs of the read process are pairs of consecutive symbols, were recently studied by Cassuto and Blaum. This new paradigm is motivated by the limitations of the reading process in high density data storage systems. They studied error correction in this new paradigm, specifically, the relationship between the minimum Hamming distance of an error correcting code and the minimum pair distance, which is the minimum Hamming distance between symbol-pair vectors derived from codewords of the code. It was proved that for a linear cyclic code with minimum Hamming distance dH, the corresponding minimum pair distance is at least dH +3. In this paper, we show that, for a given linear cyclic code with a minimum Hamming distance dH, the minimum pair distance is at least dH + (dH/2). We then describe a decoding algorithm, based upon a bounded distance decoder for the cyclic code, whose symbol-pair error correcting capabilities reflect the larger minimum pair distance. Finally, we consider the case where the read channel output is a larger number, b ≥3, of consecutive symbols, and we provide extensions of several concepts, results, and code constructions to this setting.","Hamming distance,
Decoding,
Measurement,
Electronic mail,
Error correction codes,
Magnetic recording"
Defining and Enabling Resiliency of Electric Distribution Systems With Multiple Microgrids,"This paper presents a method for quantifying and enabling the resiliency of a power distribution system using analytical hierarchical process and percolation theory. Using this metric, quantitative analysis can be done to analyze the impact of possible control decisions to pro-actively enable the resilient operation of distribution system with multiple microgrids and other resources. Developed resiliency metric can also be used in short term distribution system planning. The benefits of being able to quantify resiliency can help distribution system planning engineers and operators to justify control actions, compare different reconfiguration algorithms, and develop proactive control actions to avert power system outage due to impending catastrophic weather situations or other adverse events. Validation of the proposed method is done using modified CERTS microgrids and a modified industrial distribution system. Simulation results show topological and composite metric considering power system characteristics to quantify the resiliency of a distribution system with the proposed methodology, and improvements in resiliency using two-stage reconfiguration algorithm and multiple microgrids.",
A Low-Power Broad-Bandwidth Noise Cancellation VLSI Circuit Design for In-Ear Headphones,"Conventional active noise cancelling (ANC) headphones often perform well in reducing the low-frequency noise and isolating the high-frequency noise by earmuffs passively. The existing ANC systems often use high-speed digital signal processors to cancel out disturbing noise, which results in high power consumption for a commercial ANC headphone. The contribution of this paper can be classified into: 1) proper filter length selection; 2) low-power storage mechanism for convolution operation; and 3) high-throughput pipelining architecture. With these novel techniques, we develop an area-/power-efficient ANC circuit by using the TSMC 90-nm CMOS technology for in-ear headphone applications. The proposed feedforward filtered-x least mean square ANC circuit design provides the features of using lower operating frequency and consuming much less power that facilitate better performance than the conventional ANC headphones. To verify the effectiveness of the proposed design, a series of physical measurements is executed in an anechoic chamber. Measurement results show that the proposed high-performance/low-power circuit design can reduce disturbing noise of various frequency bands very well, and outperforms the existing works. The proposed design can attenuate 15 dB for broadband pink noise between 50 and 1500 Hz when operated at 20-MHz clock frequency at the costs of 84.2 k gates and power consumption of 6.59 mW only. Compared with the existing designs, the proposed work achieves higher noise cancellation performance in terms of 3 dB further and saves 97% power consumption.","Headphones,
Feedforward neural networks,
Noise reduction,
Very large scale integration,
Noise cancellation,
Delays"
Bounds and constructions of codes with multiple localities,"This paper studies bounds and constructions of locally repairable codes (LRCs) with multiple localities so-called multiple-locality LRCs (ML-LRCs). In the simplest case of two localities some code symbols of an ML-LRC have a certain locality while the remaining code symbols have another one. We extend two bounds, the Singleton and the alphabet-dependent upper bound on the dimension of Cadambe-Mazumdar for LRCs, to the case of ML-LRCs with more than two localities. Furthermore, we construct Singleton-optimal ML-LRCs codes.","Hamming distance,
Generators,
Upper bound,
Distributed databases,
Linear codes,
Maintenance engineering"
The Capacity of Wireless CSMA/CA Networks,"Due to a poor understanding of the interactions among transmitters, wireless networks using carrier sense multiple access with collision avoidance (CSMA/CA) have been commonly stigmatized as unpredictable in nature. Even elementary questions regarding the throughput limitations of these networks cannot be answered in general. In this paper, we investigate the behavior of wireless CSMA/CA networks to understand how the transmissions of a particular node affect the medium access, and ultimately the throughput, of other nodes in the network. We introduce a theory which accurately models the behavior of these networks and show that, contrary to popular belief, their performance is predictable and can be described by a system of equations. Using the proposed theory, we provide the analytical expressions necessary to fully characterize the capacity region of any wireless CSMA/CA network. We show that this region is nonconvex in general and agnostic to the probability distributions of all network parameters, depending only on their expected values. Our theory is also shown to extend naturally to time division multiple access (TDMA) networks and to predict how the network responds to infeasible input rates.",
Multi-Way Lossless Outphasing System Based on an All-Transmission-Line Combiner,"A lossless power-combining network comprising cascaded transmission-line segments in a tree structure is introduced for a multi-way outphasing architecture. This architecture addresses the suboptimal loading conditions in Chireix outphasing transmitters while offering a compact and microwave-friendly implementation compared to previous techniques. In the proposed system, four saturated power amplifiers (PAs) interact through an all-TL power-combining network to produce nearly ideal resistive load modulation of the branch PAs over a 10:1 range of output powers. This work focuses on the operation of the combining network, deriving analytical expressions for input-port admittance characteristics and an outphasing control strategy to modulate output power while minimizing reactive loading of the saturated branch amplifiers. A methodology for combiner design is given, along with a combiner design example for compact layout. An experimental four-way outphasing amplifier system operating at 2.14 GHz demonstrates the technique with greater than 60% drain efficiency for an output power range of 6.2 dB. The system demonstrates a W-CDMA modulated signal with a 9.15-dB peak-to-average power ratio with 54.5% average modulated efficiency at 41.1-dBm average output power.","Loading,
Admittance,
Power generation,
Impedance,
Ports (Computers),
Modulation,
Microwave theory and techniques"
Experimental demonstration of outdoor 2.2 Tbps super-channel FSO transmission system,"Free space optic (FSO) is a wireless technology that promises high speed data rate with low deployment cost. Next generation wireless networks require more bandwidth which is not supported by todays wireless techniques. FSO can be a potential candidate for last mile bottle neck in wireless network and for many other applications. In this paper, we experimentally demonstrate a high speed FSO system using super-channel source and multi-format transmitter. The FSO system was installed outdoor on the building roof over 11.5 m distance and built using off-the-shelf components. We designed a comb source capable of generating multi-subcarriers with flexible spacing. Also we designed a multi-format transmitter capable of generating different complex modulation schemes. For single carrier transmission, we were able to transmit a 23 Gbaud 16-QAM signal over FSO link, achieving 320 Gbps with 6 b/s/Hz spectral efficiency. Then using our super-channel system, 12 equal gain subcarriers are generated and modulated by a DP-16QAM signal with different symbol rates. We achieved maximum symbol rate of 23 Gbaud (i.e. 2.2 Tbps) and spectral efficiency of 7.2 b/s/Hz.","Optical transmitters,
Modulation,
Wavelength division multiplexing,
High-speed optical techniques,
Bandwidth,
Lasers,
Radio frequency"
Accurate Localization of Multiple Sources Using Semidefinite Programming Based on Incomplete Range Matrix,"We address the problem of locating multiple sources from the Euclidean distance matrix (EDM), which can be obtained from the received signal strength or time of arrival measurements. In EDM-based localization, EDM is usually corrupted by some inevitable factors, such as non-line-of-sight propagation, hardware failures, and strong interference. Note that EDM is a low-rank matrix but not a positive semidefinitematrix, classical semidefinite programming (SDP)-based algorithms cannot be implemented directly to handle the case. We derive an SDP-based low-rank solution to reconstruct EDM based on the semidefinite embedding lemma. Based on the recovered EDM, unlike some existing conventional non-convex estimators, a semidefinite relaxation method is developed to fix the locations of sources. In particular, we relax the non-convex localization problem into convex one by using square range information. Numerical simulation results demonstrate that the proposed algorithm performs higher accuracy while increasing slightly computational complexity as compared with the other existing approaches.","Sensors,
Wireless sensor networks,
Programming,
Hardware,
Electronic mail,
Matrix decomposition,
Simulation"
1.5 Gbit/s FPGA Implementation of a Fully-Parallel Turbo Decoder Designed for Mission-Critical Machine-Type Communication Applications,"In wireless communication schemes, turbo codes facilitate near-capacity transmission throughputs by achieving reliable forward error correction. However, owing to the serial data dependencies imposed by the underlying logarithmic Bahl-Cocke-Jelinek-Raviv (Log-BCJR) algorithm, the limited processing throughputs of conventional turbo decoder implementations impose a severe bottleneck upon the overall throughputs of real-time wireless communication schemes. Motivated by this, we recently proposed a fully parallel turbo decoder (FPTD) algorithm, which eliminates these serial data dependencies, allowing parallel processing and hence offering a significantly higher processing throughput. In this paper, we propose a novel resource-efficient version of the FPTD algorithm, which reduces its computational resource requirement by 50%, which enhancing its suitability for field-programmable gate array (FPGA) implementations. We propose a model FPGA implementation. When using a Stratix IV FPGA, the proposed FPTD FPGA implementation achieves an average throughput of 1.53 Gb/s and an average latency of 0.56 μs, when decoding frames comprising N = 720 b. These are, respectively, 13.2 times and 11.1 times superior to those of the state-of-the-art FPGA implementation of the Log-BCJR long-term evolution (LTE) turbo decoder, when decoding frames of the same frame length at the same error correction capability. Furthermore, our proposed FPTD FPGA implementation achieves a normalized resource usage of 0.42 (kALUTs/Mb/s), which is 5.2 times superior to that of the benchmarker decoder. Furthermore, when decoding the shortest N = 40-b LTE frames, the proposed FPTD FPGA implementation achieves an average throughput of 442 Mb/s and an average latency of 0.18 μs, which are, respectively, 21.1 times and 10.6 times superior to those of the benchmarker decoder. In this case, the normalized resource usage of 0.08 (kALUTs/Mb/s) is 146.4 times superior to that of the benchmarker decoder.","Decoding,
Field programmable gate arrays,
Throughput,
Benchmark testing,
Wireless communication,
Long Term Evolution,
Turbo codes"
Beyond Low Rank + Sparse: Multiscale Low Rank Matrix Decomposition,"We present a natural generalization of the recent low rank + sparse matrix decomposition and consider the decomposition of matrices into components of multiple scales. Such decomposition is well motivated in practice as data matrices often exhibit local correlations in multiple scales. Concretely, we propose a multiscale low rank modeling that represents a data matrix as a sum of block-wise low rank matrices with increasing scales of block sizes. We then consider the inverse problem of decomposing the data matrix into its multiscale low rank components and approach the problem via a convex formulation. Theoretically, we show that under various incoherence conditions, the convex program recovers the multiscale low rank components either exactly or approximately. Practically, we provide guidance on selecting the regularization parameters and incorporate cycle spinning to reduce blocking artifacts. Experimentally, we show that the multiscale low rank decomposition provides a more intuitive decomposition than conventional low rank methods and demonstrate its effectiveness in four applications, including illumination normalization for face images, motion separation for surveillance videos, multiscale modeling of the dynamic contrast enhanced magnetic resonance imaging, and collaborative filtering exploiting age information.",
Learning How to Communicate in the Internet of Things: Finite Resources and Heterogeneity,"For a seamless deployment of the Internet of Things (IoT), there is a need for self-organizing solutions to overcome key IoT challenges that include data processing, resource management, coexistence with existing wireless networks, and improved IoT-wide event detection. One of the most promising solutions to address these challenges is via the use of innovative learning frameworks that will enable the IoT devices to operate autonomously in a dynamic environment. However, developing learning mechanisms for the IoT requires coping with unique IoT properties in terms of resource constraints, heterogeneity, and strict quality-of-service requirements. In this paper, a number of emerging learning frameworks suitable for IoT applications are presented. In particular, the advantages, limitations, IoT applications, and key results pertaining to machine learning, sequential learning, and reinforcement learning are studied. For each type of learning, the computational complexity, required information, and learning performance are discussed. Then, to handle the heterogeneity of the IoT, a new framework based on the powerful tools of cognitive hierarchy theory is introduced. This framework is shown to efficiently capture the different IoT device types and varying levels of available resources among the IoT devices. In particular, the different resource capabilities of IoT devices are mapped to different levels of rationality in cognitive hierarchy theory, thus enabling the IoT devices to use different learning frameworks depending on their available resources. Finally, key results on the use of cognitive hierarchy theory in the IoT are presented.",
An Energy-Efficient Resource Allocation and Interference Management Scheme in Green Heterogeneous Networks Using Game Theory,"In heterogeneous networks (HetNets), energy-efficient resource allocation and intercell-interference management are important issues. In this paper, we address these issues using a two-level dynamic scheme. First, we assign the MUs with the optimum number of subchannels that achieves an operator's required balance between macro users' satisfaction and maximization of network efficiency. Then, the remaining subchannels are left to be shared by a number of small cells. In the latter step, a transmit power adaptation method using a noncooperative game-theoretic approach is developed to reduce cochannel interference in the whole network. The problem is formulated by allowing multiple neighboring small cells to share each subchannel (i.e., universal frequency reuse in the small cell level). We fully characterize the pricing factor in the penalty part of the utility function. The existence and uniqueness of the Nash equilibrium (NE) are analyzed and proved. Then, a distributed iterative algorithm based on the fixed-point theorem is proposed to attain the equilibrium of the game. Simulation results are presented to show the effectiveness of the proposed scheme in different network topologies.",
Image Denoising via Bandwise Adaptive Modeling and Regularization Exploiting Nonlocal Similarity,"This paper proposes a new image denoising algorithm based on adaptive signal modeling and regularization. It improves the quality of images by regularizing each image patch using bandwise distribution modeling in transform domain. Instead of using a global model for all the patches in an image, it employs content-dependent adaptive models to address the non-stationarity of image signals and also the diversity among different transform bands. The distribution model is adaptively estimated for each patch individually. It varies from one patch location to another and also varies for different bands. In particular, we consider the estimated distribution to have non-zero expectation. To estimate the expectation and variance parameters for every band of a particular patch, we exploit the nonlocal correlation in image to collect a set of highly similar patches as the data samples to form the distribution. Irrelevant patches are excluded so that such adaptively learned model is more accurate than a global one. The image is ultimately restored via bandwise adaptive soft-thresholding, based on a Laplacian approximation of the distribution of similar-patch group transform coefficients. Experimental results demonstrate that the proposed scheme outperforms several state-of-the-art denoising methods in both the objective and the perceptual qualities.",
High-Performance and Dynamically Updatable Packet Classification Engine on FPGA,"High-performance and dynamically updatable hardware architectures for multi-field packet classification have regained much interest in the research community. For example, software defined networking requires 15 fields of the packets to be checked against a predefined rule set. Many algorithmic solutions for packet classification have been studied over the past decade. FPGA-based packet classification engines can achieve very high throughput; however, supporting dynamic updates is yet challenging. In this paper, we present a two-dimensional pipelined architecture for packet classification on FPGA; this architecture achieves high throughput while supporting dynamic updates. In this architecture, modular Processing Elements (PEs) are arranged in a two-dimensional array. Each PE accesses its designated memory locally, and supports prefix match and exact match efficiently. The entire array is both horizontally and vertically pipelined. We exploit striding, clustering, dual-port memory, and power gating techniques to further improve the performance of our architecture. The total memory is proportional to the rule set size. Our architecture sustains high clock rate even if we scale up (1) the length of each packet header, or/and (2) the number of rules in the rule set. The performance of the entire architecture does not depend on rule set features such as the number of unique values in each field. The PEs are also self-reconfigurable; they support dynamic updates of the rule set during run-time with very little throughput degradation. Experimental results show that, for a 1 K 15-tuple rule set, a state-of-the-art FPGA can sustain a throughput of 650 Million Packets Per Second (MPPS) with 1 million updates/second. Compared to TCAM, our architecture demonstrates at least four-fold energy efficiency while achieving two-fold throughput.","Field programmable gate arrays,
Pipelines,
Throughput,
Arrays,
Vectors,
Registers"
Energy Efficient Direction-Based PDORP Routing Protocol for WSN,"Energy consumption is one of the constraints in wireless sensor networks (WSNs). The routing protocols are the hot areas to address quality-of-service (QoS) related issues, viz., energy consumption, network lifetime, network scalability, and packet overhead. The key issue in WSN is that these networks suffer from the packet overhead, which is the root cause of more energy consumption and degrade the QoS in sensor networks. In WSN, there are several routing protocols, which are used to enhance the performance of the network. Out of those protocols, dynamic source routing (DSR) protocol is more suitable in terms of small energy density, but sometimes when the mode of a node changes from active to sleep, the efficiency decreases as the data packets need to wait at the initial point, where the packet has been sent and this increases the waiting time and end-to-end delay of the packets, which leads to increase in energy consumption. Our problem is to identify the dead nodes and to choose another suitable path so that the data transmission becomes smoother and less energy gets conserved. In order to resolve these issues, we propose directional transmission-based energy aware routing protocol named PDORP. The proposed protocol PDORP has the characteristics of both power efficient gathering sensor information system and DSR routing protocols. In addition, hybridization of genetic algorithm and bacterial foraging optimization is applied to proposed routing protocol to identify energy efficient optimal paths. The performance analysis, comparison through a hybridization approach of the proposed routing protocol, gives better result comprising less bit error rate, less delay, less energy consumption, and better throughput, which leads to better QoS and prolong the lifetime of the network. Moreover, the computation model is adopted to evaluate and compare the performance of the both routing protocols using soft computing techniques.","Routing protocols,
Wireless sensor networks,
Routing,
Optimization,
Energy consumption,
Energy efficiency"
Effective Active Skeleton Representation for Low Latency Human Action Recognition,"With the development of depth sensors, low latency 3D human action recognition has become increasingly important in various interaction systems, where response with minimal latency is a critical process. High latency not only significantly degrades the interaction experience of users, but also makes certain interaction systems, e.g., gesture control or electronic gaming, unattractive. In this paper, we propose a novel active skeleton representation towards low latency human action recognition . First, we encode each limb of the human skeleton into a state through a Markov random field. The active skeleton is then represented by aggregating the encoded features of individual limbs. Finally, we propose a multi-channel multiple instance learning with maximum-pattern-margin to further boost the performance of the existing model. Our method is robust in calculating features related to joint positions, and effective in handling the unsegmented sequences. Experiments on the MSR Action3D, the MSR DailyActivity3D, and the Huawei/3DLife-2013 dataset demonstrate the effectiveness of the model with the proposed novel representation, and its superiority over the state-of-the-art low latency recognition approaches.","Skeleton,
Videos,
Feature extraction,
Noise measurement,
Acceleration,
Three-dimensional displays,
Markov random fields"
Experimental Study of Grid Frequency Regulation Ancillary Service of a Variable Speed Heat Pump,"This paper describes an analysis of a variable speed heat pump (VSHP), which responds to direct load control (DLC) signals to provide grid frequency regulation (GFR) ancillary service, while ensuring the comfort of building occupants. A data-driven dynamic model of the VSHP is developed through real-time experimental studies with a time horizon ranging from seconds to hours. The model is simple, yet still sufficiently comprehensive to analyze the operational characteristics of the VSHP. The DLC scheme is then experimentally applied to the VSHP to evaluate its demand response (DR) capability. Two control methods are considered for a practical implementation of the DLC-enabled VSHP and a further improvement of the DR capability, respectively. Additionally, a small-signal analysis is carried out using the aggregated dynamic response of a number of DLC-enabled VSHPs to analyze their contribution to GFR in an isolated power grid. For experimental case studies, a laboratory-scale microgrid is then implemented with generator and load emulators. We show that the DLC-enabled VSHP can effectively reduce grid frequency deviations and required reserve capacities of generators.","Compressors,
Heat pumps,
Buildings,
Frequency control,
Atmospheric modeling,
Power system dynamics,
Heating"
Biologically Inspired Model for Visual Cognition Achieving Unsupervised Episodic and Semantic Feature Learning,"Recently, many biologically inspired visual computational models have been proposed. The design of these models follows the related biological mechanisms and structures, and these models provide new solutions for visual recognition tasks. In this paper, based on the recent biological evidence, we propose a framework to mimic the active and dynamic learning and recognition process of the primate visual cortex. From principle point of view, the main contributions are that the framework can achieve unsupervised learning of episodic features (including key components and their spatial relations) and semantic features (semantic descriptions of the key components), which support higher level cognition of an object. From performance point of view, the advantages of the framework are as follows: 1) learning episodic features without supervision - for a class of objects without a prior knowledge, the key components, their spatial relations and cover regions can be learned automatically through a deep neural network (DNN); 2) learning semantic features based on episodic features - within the cover regions of the key components, the semantic geometrical values of these components can be computed based on contour detection; 3) forming the general knowledge of a class of objects - the general knowledge of a class of objects can be formed, mainly including the key components, their spatial relations and average semantic values, which is a concise description of the class; and 4) achieving higher level cognition and dynamic updating - for a test image, the model can achieve classification and subclass semantic descriptions. And the test samples with high confidence are selected to dynamically update the whole model. Experiments are conducted on face images, and a good performance is achieved in each layer of the DNN and the semantic description learning process. Furthermore, the model can be generalized to recognition tasks of other objects with learning ability.","Semantics,
Face,
Biological system modeling,
Visualization,
Cognition,
Computational modeling"
"An Unified Multiscale Framework for Planar, Surface, and Curve Skeletonization","Computing skeletons of 2D shapes, and medial surface and curve skeletons of 3D shapes, is a challenging task. In particular, there is no unified framework that detects all types of skeletons using a single model, and also produces a multiscale representation which allows to progressively simplify, or regularize, all skeleton types. In this paper, we present such a framework. We model skeleton detection and regularization by a conservative mass transport process from a shape's boundary to its surface skeleton, next to its curve skeleton, and finally to the shape center. The resulting density field can be thresholded to obtain a multiscale representation of progressively simplified surface, or curve, skeletons. We detail a numerical implementation of our framework which is demonstrably stable and has high computational efficiency. We demonstrate our framework on several complex 2D and 3D shapes.",
Data-Driven Surrogate-Assisted Multiobjective Evolutionary Optimization of a Trauma System,"Most existing work on evolutionary optimization assumes that there are analytic functions for evaluating the objectives and constraints. In the real world, however, the objective or constraint values of many optimization problems can be evaluated solely based on data and solving such optimization problems is often known as data-driven optimization. In this paper, we divide data-driven optimization problems into two categories, i.e., offline and online data-driven optimization, and discuss the main challenges involved therein. An evolutionary algorithm is then presented to optimize the design of a trauma system, which is a typical offline data-driven multiobjective optimization problem, where the objectives and constraints can be evaluated using incidents only. As each single function evaluation involves a large amount of patient data, we develop a multifidelity surrogate-management strategy to reduce the computation time of the evolutionary optimization. The main idea is to adaptively tune the approximation fidelity by clustering the original data into different numbers of clusters and a regression model is constructed to estimate the required minimum fidelity. Experimental results show that the proposed algorithm is able to save up to 90% of computation time without much sacrifice of the solution quality.","Optimization,
Computational modeling,
Evolutionary computation,
Computational efficiency,
Data models,
Algorithm design and analysis,
System analysis and design"
A Virtual View PSNR Estimation Method for 3-D Videos,"In three-dimensional videos (3-DVs) with n -view texture videos plus n -view depth maps, virtual views can be synthesized from neighboring texture videos and the associated depth maps. To evaluate the system performance or guide the rate-distortion-optimization process of 3-DV coding, the distortion/PSNR of the virtual view should be calculated by measuring the quality difference between the virtual view synthesized by compressed 3-DVs with one synthesized by uncompressed 3-DVs, which increases the complexity of a 3-DV system. In order to reduce the complexity of 3-DV system, it is better to estimate virtual view distortions/PSNR directly without rendering virtual views. In this paper, the virtual view synthesis procedure and the distortion propagation from existing views to virtual views are analyzed in detail, and then a virtual view distortion/PSNR estimation method is derived. Experimental results demonstrate that the proposed method could estimate PSNRs of virtual views accurately. The squared correlation coefficient and root of mean squared error between the estimated PSNRs by the proposed method and the actual PSNRs are 0.998 and 2.012 on average for all the tested sequences. Since the proposed method is implemented row-by-row independently, it is also friendly for parallel design. The execute time for each row of pictures with 1024 × 768 resolution is only 0.079 s, while for pictures with 1920 × 1088 resolution it is only 0.155 s.",
Video Quality-Based Spectral and Energy Efficient Mobile Association in Heterogeneous Wireless Networks,"The staggering mobile growth is shaping to be the biggest shift in technology since the advent of the Internet, paving the way for unprecedented and yet to be thought of video services and applications. The proliferation of these mobile devices and applications, however, requires new paradigms to satisfy the increasing demands for capacity and energy, and achieve a good video quality. In this paper, we propose a video quality-based framework for spectrum and energy efficient mobile association and resource allocation in heterogeneous wireless networks. The basic tenets of the framework are (1) two novel performance metrics, namely QSE and QEE, to capture spectrum usage and energy consumption from video quality's perspective; and (2) a computationally efficient optimization model to derive mobile association and resource allocation for video connections in heterogeneous wireless networks. To this end, we first study the fundamental tradeoff between QSE and QEE in a PtP Rayleigh fading wireless channel. We then study QSE and QEE at the system level and develop a mobile association and resource allocation scheme that aims to jointly optimize system level QSE and QEE. The problem is formulated as a mixed-integer nonlinear optimization problem. Nonlinear fractional programming approach and dual decomposition method are applied to search the optimal solutions in a computationally efficient way. The simulation results evaluate the performance tradeoff between QSE and QEE, and show that the system performance, including PSNR distribution and maximum QSE/QEE values, greatly depends on bandwidth and power decaying factors.","Mobile communication,
Quality assessment,
Wireless networks,
Video recording,
Mobile computing,
Streaming media,
Measurement"
Polarimetric Analysis of Compact-Polarimetry SAR Architectures for Sea Oil Slick Observation,"In this paper, a theoretical and experimental analysis of polarimetric synthetic aperture radar (SAR) architectures is undertaken for sea oil slick observation purposes. Reference is made to the conventional full-polarimetric (FP) SAR that is here contrasted with new-generation polarimetric SAR architectures, known as compact-polarimetric (CP) SAR. Two CP modes are considered, i.e., the hybrid-polarity and π/4 modes, whose measurements are emulated from actual L- and C-band FP SAR data. Polarimetric sea surface scattering is predicted according to an extended version of the Bragg scattering model (X-Bragg) in order to point out the differences exhibited between FP and CP SAR architectures and among CP SAR modes. Theoretical predictions are then contrasted with experiments undertaken on actual polarimetric SAR data collected over well-known oil slicks and weak-damping surfactants. Results confirm model prediction, showing that differences mainly apply when polarimetric features are estimated over slick-free sea surface using different SAR architectures, with the π/4 mode behaving closer to FP SAR. Although CP SAR architectures measure only a subset of the FP information content, they represent an interesting operational alternative for both detecting oil slicks and discriminating them from weak-damping surfactants.",
Necessary and Sufficient Condition for Stability of Switched Uncertain Linear Systems Under Dwell-Time Constraint,"In this technical note, a necessary and sufficient stability criterion for switched linear systems under dwell-time constraint is proposed by employing a class of time-scheduled homogeneous polynomial Lyapunov functions with a sufficiently large degree. The key feature of this nonconservative condition lies in its convexity in the system matrices, which explicitly facilitates its further extension to uncertain systems. Then, in order to obtain numerically testable condition, a family of LMI conditions are presented with the aid of the idea of dividing the dwell-time interval into a finite number of segments. It is proved that the non-conservativeness can be maintained with a sufficiently large interval dividing parameter. In the end, the result is straightforwardly extended to the uncertain case in virtue of the convexity in the system matrices. Numerical examples are presented to illustrate our findings.","Stability criteria,
Lyapunov methods,
Switches,
Switched systems,
Numerical stability,
Asymptotic stability"
Patch Antennas With Loading of a Pair of Shorting Pins Toward Flexible Impedance Matching and Low Cross Polarization,"Patch antennas with loading of a pair of shorting pins are proposed in this paper toward flexible impedance matching and low cross polarization. The shorting pins are introduced in the centerline of a square patch to strengthen the surface current density near the feeding point at edge. As these paired pins simultaneously move away from the center toward the two radiating edges of patch, the resonant input impedance of the microstrip-edge-fed patch antenna is increasingly reduced due to enlarged current density at the feeding point. Because of symmetric arrangement of these two shorting pins, surface current density on the patch is maintained as the odd-symmetric property with respect to the H-plane, thus tremendously degrading the cross-polarization level. Simulated and measured results are found in good agreement with each other in terms of input impedance and radiation pattern. They further demonstrate that co-polarization to cross-polarization ratio (CTCR) of the paired-pins-loaded patch antenna in H-plane is maintained at least 10 dB higher than that of its single-pin-loaded patch counterpart.",
On the Capacity Gain from Full Duplex Communications in a Large Scale Wireless Network,"Compared to half duplex communications, full duplex communications can significantly improve link capacity. However, in a large scale wireless network such as a wireless mesh network, the capacity gain from full duplex communications has not been fully investigated. To this end, a metric of network capacity called transmission capacity is studied in this paper for a full duplex wireless network. It captures the maximum transmission throughput in a unit area, subject to a certain outage probability. The key challenge of deriving transmission capacity is to characterize the aggregate interference of the typical link in a full duplex wireless network, which is completely different from that in a half duplex wireless network. In this paper, stochastic geometry is employed to model the network topology as a Thomas cluster point process and then the aggregate interference is characterized as a shot-noise process. Based on these models, the transmission capacity is derived. Analytical results show that under the same network density the distribution of aggregate interference in a full duplex wireless network is more dispersed than that in a half duplex wireless network. Comparisons of transmission capacity between a full duplex network and a half duplex network reveal that the capacity gain from full duplex communications is limited due to severe aggregate interference. This result implies that self-interference cancellation alone cannot ensure scalable full duplex wireless networking.",
Learning Transfer-Based Adaptive Energy Minimization in Embedded Systems,"Embedded systems execute applications with varying performance requirements. These applications exercise the hardware differently depending on the computation task, generating varying workloads with time. Energy minimization with such workload and performance variations within (intra) and across (inter) applications is particularly challenging. To address this challenge, we propose an online approach, capable of minimizing energy through adaptation to these variations. At the core of this approach is a reinforcement learning algorithm that suitably selects the appropriate voltage/frequency scaling (VFS) based on workload predictions to meet the applications' performance requirements. The adaptation is then facilitated and expedited through learning transfer, which uses the interaction between the application, runtime, and hardware layers to adjust the VFS. The proposed approach is implemented as a power governor in Linux and extensively validated on an ARM Cortex-A8 running different benchmark applications. We show that with intra- and inter-application variations, our proposed approach can effectively minimize energy consumption by up to 33% compared to the existing approaches. Scaling the approach to multicore systems, we also demonstrate that it can minimize energy by up to 18% with 2× reduction in the learning time when compared with an existing approach.","Minimization,
Runtime,
Hardware,
MPEG 4 Standard,
Energy consumption,
Central Processing Unit,
Browsers"
Efficient Bit Rate Transcoding for High Efficiency Video Coding,"High efficiency video coding (HEVC) shows a significant advance in compression efficiency and is considered to be the successor of H.264/AVC. To incorporate the HEVC standard into real-life network applications and a diversity of other applications, efficient bit rate adaptation (transrating) algorithms are required. A current problem of transrating for HEVC is the high computational complexity associated with the encoder part of such a cascaded pixel domain transcoder. This paper focuses on deriving an optimal strategy for reducing the transcoding complexity with a complexity-scalable scheme. We propose different transcoding techniques which are able to reduce the transcoding complexity in both CU and PU optimization levels. At the CU level, CUs can be evaluated in top-to-bottom or bottom-to-top flows, in which the coding information of the input video stream is utilized to reduce the number of evaluations or to early terminate certain evaluations. At the PU level, the PU candidates are adaptively selected based on the probability of PU sizes and the co-located input PU partitioning. Moreover, with the use of different proposed methods, a complexity-scalable transrating scheme can be achieved. Furthermore, the transcoding complexity can be effectively controlled by the machine learning based approach. Simulations show that the proposed techniques provide a superior transcoding performance compared to the state-of-the-art related works. Additionally, the proposed methods can achieve a range of trade-offs between transrating complexity and coding performance. From the proposed schemes, the fastest approach is able to reduce the complexity by 82% while keeping the bitrate loss below 3%.",
Fundamental limits of secretive coded caching,"Recent work by Maddah-Ali and Niesen introduced coded caching which demonstrated the benefits of joint design of storage and transmission policies in content delivery networks. They studied a setup where a server communicates with a set of users, each equipped with a local cache, over a shared error-free link and proposed an order-optimal caching and delivery scheme. In this paper, we introduce the problem of secretive coded caching where we impose the additional constraint that a user should not be able to learn anything, from either the content stored in its cache or the server transmissions, about a file it did not request. We propose a feasible scheme for this setting and demonstrate its order-optimality with respect to information-theoretic lower bounds.","Servers,
Cache memory,
Random variables,
Information theory,
Content distribution networks,
Radio frequency,
Electronic mail"
Can Scientific Impact Be Predicted?,"A widely used measure of scientific impact is citations. However, due to their heavy-tailed distribution, citations are fundamentally difficult to predict. Instead, to characterize scientific impact, we address two analogous questions asked by many scientific researchers: “How will my h-index evolve over time, and which of my previously or newly published papers will contribute to it?” To answer these questions, we perform two related tasks. First, we develop a model to predict authors' future h-indices based on their current scientific impact. Second, we examine the factors that drive papers-either previously or newly published-to increase their authors' predicted future h-indices. By leveraging relevant factors, we can predict an author's h-index in five years with an R2 value of 0.92 and whether a previously (newly) published paper will contribute to this future h-index with an F1 score of 0.99 (0.77). We find that topical authority and publication venue are crucial to these effective predictions, while topic popularity is surprisingly inconsequential. Further, we develop an online tool that allows users to generate informed h-index predictions. Our work demonstrates the predictability of scientific impact, and can help researchers to effectively leverage their scholarly position of “standing on the shoulders of giants”.","Distortion measurement,
Big data,
Indexes,
Computer science,
Predictive models,
Productivity,
Yttrium"
The Van der Pol's mathematical model of the voltage-controlled oscillator based on a transistor structure with negative resistance,The results of the mathematical modelling for the voltage-controlled oscillator based on a transistor structure with negative resistance are presented in this article. The generated oscillations with and without noise were described with the Van der Pol's model. The research was carried out for relaxation and oscillator modes of the generator.,"Decision support systems,
Cybernetics,
Computers,
Scientific publishing,
Electrical engineering,
Microwave circuits"
Scalable and Reliable IoT Enabled by Dynamic Spectrum Management for M2M in LTE-A,"To underpin the predicted growth of the Internet of Things (IoT), a highly scalable, reliable and available connectivity technology will be required. Whilst numerous technologies are available today, the industry trend suggests that cellular systems will play a central role in ensuring IoT connectivity globally. With spectrum generally a bottleneck for 3GPP technologies, TV white space (TVWS) approaches are a very promising means to handle the billions of connected devices in a highly flexible, reliable and scalable way. To this end, we propose a cognitive radio enabled TD-LET test-bed to realize the dynamic spectrum management over TVWS. In order to reduce the data acquisition and improve the detection performance, we propose a hybrid framework for the dynamic spectrum management of machine-to-machine networks. In the proposed framework, compressed sensing is implemented with the aim to reduce the sampling rates for wideband spectrum sensing. A noniterative reweighed compressive spectrum sensing algorithm is proposed with the weights being constructed by data from geolocation databases. Finally, the proposed hybrid framework is tested by means of simulated as well as real-world data.","Sensors,
Cognitive radio,
Databases,
Radio spectrum management,
Analog TV,
Internet of things,
Machine-to-machine communications"
Folksonomy-Based Visual Ontology Construction and Its Applications,"An ontology hierarchically encodes concepts and concept relationships, and has a variety of applications such as semantic understanding and information retrieval. Previous work for building ontologies has primarily relied on labor-intensive human contributions or focused on text-based extraction. In this paper, we consider the problem of automatically constructing a folksonomy-based visual ontology (FBVO) from the user-generated annotated images. A systematic framework is proposed consisting of three stages as concept discovery, concept relationship extraction, and concept hierarchy construction. The noisy issues of the user-generated tags are carefully addressed to guarantee the quality of derived FBVO. The constructed FBVO finally consists of 139 825 concept nodes and millions of concept relationships by mining more than 2.4 million Flickr images. Experimental evaluations show that the derived FBVO is of high quality and consistent with human perception. We further demonstrate the utility of the derived FBVO in applications of complex visual recognition and exploratory image search.","Visualization,
Ontologies,
Semantics,
Image recognition,
Computational modeling,
Noise measurement"
BIT: Biologically Inspired Tracker,"Visual tracking is challenging due to image variations caused by various factors, such as object deformation, scale change, illumination change, and occlusion. Given the superior tracking performance of human visual system (HVS), an ideal design of biologically inspired model is expected to improve computer visual tracking. This is, however, a difficult task due to the incomplete understanding of neurons' working mechanism in the HVS. This paper aims to address this challenge based on the analysis of visual cognitive mechanism of the ventral stream in the visual cortex, which simulates shallow neurons (S1 units and C1 units) to extract low-level biologically inspired features for the target appearance and imitates an advanced learning mechanism (S2 units and C2 units) to combine generative and discriminative models for target location. In addition, fast Gabor approximation and fast Fourier transform are adopted for real-time learning and detection in this framework. Extensive experiments on large-scale benchmark data sets show that the proposed biologically inspired tracker performs favorably against the state-of-the-art methods in terms of efficiency, accuracy, and robustness. The acceleration technique in particular ensures that biologically inspired tracker maintains a speed of approximately 45 frames/s.",
Optimal Charging of Electric Vehicles for Load Shaping: A Dual-Splitting Framework With Explicit Convergence Bounds,"This paper proposes a tailored distributed optimal charging algorithm for plug-in electric vehicles (PEVs). If controlled properly, large PEV populations can enable high penetration of renewables by balancing loads with intermittent generation. The algorithmic challenges include scalability, computation, uncertainty, and constraints on driver mobility and power-system congestion. This paper addresses computation and communication challenges via a scalable distributed optimal charging algorithm. Specifically, we exploit the mathematical structure of the aggregated charging problem to distribute the optimization program, using duality theory. Explicit bounds of convergence are derived to guide computational requirements. Two variations in the dual-splitting algorithm are also presented, which enable privacy-preserving properties. Constraints on both individual mobility requirements and power-system capacity are also incorporated. We demonstrate the proposed dual-splitting framework on a load-shaping case study for the so-called California “Duck Curve” with mobility data generated from the vehicle-to-grid simulator.",
Integrated Space-Division Multiplexer for Application to Data Center Networks,"The prospect of creating integrated space-division multiplexing (SDM) on a chip, utilizing the orthogonal degrees of freedom of numerous guided spatial modes in a multimode waveguide, promises a substantial reduction in the cost, complexity, and scalability of networking systems by augmenting or replacing the commonly used approach of wavelength-division multiplexing (WDM). As a demonstration of the SDM approach, we introduce and experimentally characterize a periodically nanostructured resonant coupler integrated with a multimode waveguide that selectively transfers energy between arbitrary waveguide modes. Compared to alternative schemes, this device possesses advantages in terms of packing density, control of operating bandwidth, tunability to operate with numerous orthogonal spatial modes, and support of a large number of switching ports.","Optical waveguides,
Optical switches,
Couplers,
Couplings,
Ports (Computers),
Wavelength division multiplexing,
Reflection"
Benchmarking and Validation of Cascading Failure Analysis Tools,"Cascading failure in electric power systems is a complicated problem for which a variety of models, software tools, and analytical tools have been proposed but are difficult to verify. Benchmarking and validation are necessary to understand how closely a particular modeling method corresponds to reality, what engineering conclusions may be drawn from a particular tool, and what improvements need to be made to the tool in order to reach valid conclusions. The community needs to develop the test cases tailored to cascading that are central to practical benchmarking and validation. In this paper, the IEEE PES working group on cascading failure reviews and synthesizes how benchmarking and validation can be done for cascading failure analysis, summarizes and reviews the cascading test cases that are available to the international community, and makes recommendations for improving the state of the art.","Power system faults,
Power system protection,
Benchmark testing,
Failure analysis,
Power system stability,
Analytical models,
Software tools"
Stochastic Analysis of an Adaptive Line Enhancer/Canceler With a Cyclostationary Input,"This paper studies the second moment behavior of the adaptive line enhancer (ALE)/adaptive line canceler (ALC) for a cyclostationary input consisting of a fixed amplitude random phase sine wave plus a white Gaussian process with periodic power variations. Both transient and steady-state results are shown to be in good-to-excellent agreement with Monte Carlo simulations. The main conclusion is that periodic input power variations cause periodic processing gain variations of the ALE/ALC with the same period as the input power. However, these variations do not cause a large degradation in the ALE/ALC performance.","Signal processing algorithms,
Least squares approximations,
Line enhancers,
Steady-state,
Narrowband,
Algorithm design and analysis,
Broadband communication"
Cloud robotics: Current status and open issues,"With the development of cloud computing, big data, and other emerging technologies, the integration of cloud technology and multi-robot systems makes it possible to design multi-robot systems with improved energy efficiency, high real-time performance, and low cost. In order to address the potential of clouds in enhancing robotics for industrial systems, this paper describes the basic concepts and development process of cloud robotics and the overall architecture of these systems. Then, the major driving forces behind the development of cloud robotics are carefully analyzed from the point of view of cloud computing, big data, open source resources, robot cooperative learning, and network connectivity. Subsequently, the key issues and challenges in the current cloud robotic systems are proposed, and some possible solutions are also given. Finally, the potential value of cloud robotic systems in different practical applications is discussed.","Cloud computing,
Big data,
Open source code,
Service robots,
Internet of things,
Multi-robot systems,
Energy efficiency,
Real-time systems"
Kinematically Redundant Spatial Parallel Mechanisms for Singularity Avoidance and Large Orientational Workspace,"This paper introduces a novel architecture of kinematically redundant parallel mechanisms. This family of mechanisms is similar to the well-known Gough-Stewart platform, and it retains its advantages, i.e., the members connecting the base to the moving platform are only subjected to tensile/compressive loads. The proposed architecture exploits kinematic redundancy to avoid singularities and extend the rotational workspace. The novel kinematic architecture is described, and the associated kinematic relationships are developed. Based on the derivation of the Jacobian matrices, it is shown that the singularities of this type of mechanism are governed by the orientation of passive links connecting the redundant legs to the platform. Grassmann geometry is then used to demonstrate that, given some simple geometric assumptions on the architecture, all singularities can be avoided by exploiting the kinematic redundancy. The orientational workspace is then discussed, and a graphical representation is provided for an example architecture comprising nine actuators, whose orientational workspace is shown to be very large. The translational workspace is also studied. Example trajectories are given in order to illustrate the capabilities of the mechanism to produce very large rotation angles without encountering singularities. Computer animations of the trajectories are provided in a multimedia extension of the paper.","Legged locomotion,
Actuators,
Kinematics,
Redundancy,
Computer architecture,
Joining processes,
Mathematical model"
"Modeling of Subsurface Leakage Current in Low
V
TH
Short Channel MOSFET at Accumulation Bias","We present a phenomenological model for subsurface leakage current in MOSFETs biased in accumulation. The subsurface leakage current is mainly caused by source-drain coupling, leading to carriers surmounting the barrier between the source and the drain. The developed model successfully takes drain-to-source voltage (VDS), gate-to-source voltage (VGS), gate length (LG), substrate doping concentration (Nsub), and temperature (T) dependence into account. The presented analytical model is implemented into the BSIM6 bulk MOSFET model and is in good agreement with technology-CAD simulation data.","Leakage currents,
Logic gates,
Semiconductor process modeling,
MOSFET,
Semiconductor device modeling,
Doping,
Junctions"
Incentive mechanism for proximity-based Mobile Crowd Service systems,"We investigate emerging proximity-based Mobile Crowd Service or pMCS systems, in which services are provided and consumed by users carrying smart mobile devices (e.g., smartphones) and in proximity of each other (e.g., within Bluetooth range). Due to limited resources on smartphones, it is crucial to provide a mechanism to incentivize users' participation and ensure fair trading in a pMCS system. In this paper, we design a multi-market dynamic double auction mechanism for a pMCS system, referred to as MobiAuc, and we show that it is truthful, feasible, individual-rational, no-deficit, and computationally efficient. The novelty and significance of MobiAuc is that it addresses and solves the fair trading problem in a multi-market dynamic double auction setting which naturally occurs in a mobile wireless environment. We demonstrate its efficiency via simulations based on generated user patterns (stochastic arrivals and random market clustering of users) and real-world traces. Our preliminary implementation of MobiAuc and experiments on Android platform have demonstrated the feasibility of MobiAuc mechanism in practice.","Smart phones,
Mobile communication,
Heuristic algorithms,
Algorithm design and analysis,
Wireless communication,
Bluetooth,
Electronic mail"
Introducing: The Libflame Library for Dense Matrix Computations,"As part of the FLAME project, we have been dilligently developing new methodologies for analyzing, designing, and implementing linear algebra libraries. While we did not know it when we started, these techniques appear to solve many of the programmability problems that now face us with the advent of multicore and many-core architectures. These efforts have culminated in a new library, libflame, which strives to replace similar libraries that date back to the late 20th century. With this paper, we introduce the scientific computing community to this library.","Libraries,
Linear algebra,
Fires,
Computer architecture,
Scientific computing,
Design methodology,
Multicore processing,
Mathematical programming,
Collaborative tools,
Linear programming"
Practical Approximation of Single-Qubit Unitaries by Single-Qubit Quantum Clifford and T Circuits,"We present an algorithm, along with its implementation that finds T-optimal approximations of single-qubit Z-rotations using quantum circuits consisting of Clifford and T gates. Our algorithm is capable of handling errors in approximation down to size 10-15, resulting in the optimal single-qubit circuit designs required for implementation of scalable quantum algorithms. Our implementation along with the experimental results are available in the public domain.",
QoS-Aware Resource Allocation for Device-to-Device Communications With Channel Uncertainty,"In device-to-device (D2D) communications, channel state information (CSI) is exploited to manage the interference between D2D users and regular cellular users (CUs) and improve system performance. However, obtaining the accurate CSI is usually difficult and causes high overhead, particularly when the links are not connected to the base station (BS), such as the links between regular CUs and D2D receivers (CU-D links). In this paper, we investigate the signaling overhead and performance tradeoff in D2D communications with channel uncertainty. To limit interference to regular CUs, we only allow the resource of a CU to be reused by, at most, one D2D pair. We also assume that only partial CSI of the CU-D links is available at the BS and develop two different strategies to deal with the channel uncertainty, namely, probabilistic and partial feedback schemes. We first derive a probability-based resource-allocation scheme by utilizing channel statistical characteristics to maximize the overall throughput of the CUs and admissible D2D pairs while guaranteeing their quality of service (QoS) in terms of signal-to-interference-plus-noise ratio (SINR) and outage probability, respectively. Then, we propose an efficient feedback scheme to reduce the overhead of CSI feedback while providing near-optimal performance. In addition, we propose a combined scheme to take advantages of both probabilistic and partial feedback schemes. It is shown by simulation that there exists an optimal threshold of the outage probability for probabilistic scheme while the partial feedback scheme is robust to the channel models. Furthermore, the combined scheme outperforms the probabilistic and the partial feedback schemes in terms of overall throughput.","Fading,
Interference,
Resource management,
Probabilistic logic,
Receivers,
Signal to noise ratio,
Throughput"
A Novel Pipeline Approach for Efficient Big Data Broadcasting,"Big-data computing is a new critical challenge for the ICT industry. Engineers and researchers are dealing with data sets of petabyte scale in the cloud computing paradigm. Thus, the demand for building a service stack to distribute, manage, and process massive data sets has risen drastically. In this paper, we investigate the Big Data Broadcasting problem for a single source node to broadcast a big chunk of data to a set of nodes with the objective of minimizing the maximum completion time. These nodes may locate in the same datacenter or across geo-distributed datacenters. This problem is one of the fundamental problems in distributed computing and is known to be NP-hard in heterogeneous environments. We model the Big-data broadcasting problem into a LockStep Broadcast Tree (LSBT) problem. The main idea of the LSBT model is to define a basic unit of upload bandwidth, r, such that a node with capacity c broadcasts data to a set of [c/r] children at the rater. Note that r is a parameter to be optimized as part of the LSBT problem. We further divide the broadcast data into m chunks. These data chunks can then be broadcast down the LSBT in a pipeline manner. In a homogeneous network environment in which each node has the same upload capacity c, we show that the optimal uplink rate r* of LSBT is either c/2 or c/3, whichever gives the smaller maximum completion time. For heterogeneous environments, we present an O(nlog2n) algorithm to select an optimal uplink rater* and to construct an optimal LSBT. Numerical results show that our approach performs well with less maximum completion time and lower computational complexity than other efficient solutions in literature.",
Campaigning in Heterogeneous Social Networks: Optimal Control of SI Information Epidemics,"We study the optimal control problem of maximizing the spread of an information epidemic on a social network. Information propagation is modeled as a susceptible-infected (SI) process, and the campaign budget is fixed. Direct recruitment and word-of-mouth incentives are the two strategies to accelerate information spreading (controls). We allow for multiple controls depending on the degree of the nodes/individuals. The solution optimally allocates the scarce resource over the campaign duration and the degree class groups. We study the impact of the degree distribution of the network on the controls and present results for Erdös-Rényi and scale-free networks. Results show that more resource is allocated to high-degree nodes in the case of scale-free networks, but medium-degree nodes in the case of Erdös-Rényi networks. We study the effects of various model parameters on the optimal strategy and quantify the improvement offered by the optimal strategy over the static and bang-bang control strategies. The effect of the time-varying spreading rate on the controls is explored as the interest level of the population in the subject of the campaign may change over time. We show the existence of a solution to the formulated optimal control problem, which has nonlinear isoperimetric constraints, using novel techniques that is general and can be used in other similar optimal control problems. This work may be of interest to political, social awareness, or crowdfunding campaigners and product marketing managers, and with some modifications may be used for mitigating biological epidemics.","Sociology,
Statistics,
Optimal control,
Social network services,
Silicon,
Recruitment,
Biology"
An Improved MPPT Method for PV System With Fast-Converging Speed and Zero Oscillation,"Maximum power point tracking (MPPT) is essential for photovoltaic (PV) systems to ensure the highest power output of PV arrays under any environmental condition. Comparing to other techniques, the Beta method shows advantages in terms of tracking speed, steady-state performance, and simple implementation. However, the conventional Beta can further be improved by minimizing oscillations around the maximum power point under a steady state and an increasing tracking speed in response to rapid changing of irradiance or temperature. An improved Beta-parameter-based MPPT method is proposed in this paper to achieve the above-mentioned objectives. An adaptive scaling factor is introduced and utilized in the MPPT mechanism, which enhances the tracking speed and is easily applied for any PV power system. Furthermore, the proposed method can identify and maintain the middle point of the three-level perturbations, which eliminate the oscillations at a steady state. The control mechanism is not limited by specific operating conditions and illustrates superior performance over traditional methods with regards to transient response and steady-state performance, which contributes to effective solar power harvesting. Followed by theoretical analysis, the simulation and experimental evaluation validate the claimed advantages of the proposed MPPT solution.","Steady-state,
Oscillators,
Transient analysis,
Maximum power point trackers,
Temperature,
Temperature dependence,
Convergence"
Folding Alternant and Goppa Codes With Non-Trivial Automorphism Groups,"The main practical limitation of the McEliece public-key encryption scheme is probably the size of its key. A famous trend to overcome this issue is to focus on subclasses of alternant/Goppa codes with a non-trivial automorphism group. Such codes display then symmetries allowing compact parity-check or generator matrices. For instance, a key-reduction is obtained by taking quasi-cyclic (QC) or quasi-dyadic (QD) alternant/Goppa codes. We show that the use of such symmetric alternant/Goppa codes in cryptography introduces a fundamental weakness. It is indeed possible to reduce the key-recovery on the original symmetric public-code to the key-recovery on a (much) smaller code that has no symmetry anymore. This result is obtained thanks to an operation on codes called folding that exploits the knowledge of the automorphism group. This operation consists in adding the coordinates of codewords which belong to the same orbit under the action of the automorphism group. The advantage is twofold. The reduction factor can be as large as the size of the orbits, and it preserves a fundamental property: folding the dual of an alternant (respectively, Goppa) code provides the dual of an alternant (respectively, Goppa) code. A key point is to show that all the existing constructions of alternant/Goppa codes with symmetries follow a common principal of taking codes whose support is globally invariant under the action of affine transformations (by building upon prior works of Berger and Dür). This enables not only to present a unified view but also to generalize the construction of QC, QD, and even quasi-monoidic Goppa codes. Finally, our results can be harnessed to boost up any key-recovery attack on McEliece systems based on symmetric alternant or Goppa codes, and in particular algebraic attacks.",
Industrial Control System Network Intrusion Detection by Telemetry Analysis,"Until recently, industrial control systems (ICSs) used “air-gap” security measures, where every node of the ICS network was isolated from other networks, including the Internet, by a physical disconnect. Attaching ICS networks to the Internet benefits companies and engineers who use them. However, as these systems were designed for use in the air-gapped security environment, protocols used by ICSs contain little to no security features and are vulnerable to various attacks. This paper proposes an approach to detect the intrusions into network attached ICSs by measuring and verifying data that is transmitted through the network but is not inherently the data used by the transmission protocol-network telemetry. Using simulated PLC units, the developed IDS was able to achieve 94.3 percent accuracy when differentiating between machines of an attacker and engineer on the same network, and 99.5 percent accuracy when differentiating between attacker and engineer on the Internet.","Telemetry,
Protocols,
SCADA systems,
Security,
Delays,
Internet"
Diminished Reality Based on Image Inpainting Considering Background Geometry,"Diminished reality aims to remove real objects from video images and fill in the missing regions with plausible background textures in realtime. Most conventional methods based on image inpainting achieve diminished reality by assuming that the background around a target object is almost planar. This paper proposes a new diminished reality method that considers background geometries with less constraints than the conventional ones. In this study, we approximate the background geometry by combining local planes, and improve the quality of image inpainting by correcting the perspective distortion of texture and limiting the search area for finding similar textures as exemplars. The temporal coherence of texture is preserved using the geometries and camera pose estimated by visual-simultaneous localization and mapping (SLAM). The mask region that includes a target object is robustly set in each frame by projecting a 3D region, rather than tracking the object in 2D image space. The effectiveness of the proposed method is successfully demonstrated using several experimental environments.","Three-dimensional displays,
Cameras,
Geometry,
Target tracking,
Real-time systems,
Distortion,
Coherence"
"A 7.6 mW, 414 fs RMS-Jitter 10 GHz Phase-Locked Loop for a 40 Gb/s Serial Link Transmitter Based on a Two-Stage Ring Oscillator in 65 nm CMOS","This paper describes the design of a 10 GHz phase-locked loop (PLL) for a 40 Gb/s serial link transmitter (TX). A two-stage ring oscillator is used to provide a four-phase, 10 GHz clock for a quarter-rate TX. Several analyses and verification techniques, ranging from the clocking architectures for a 40 Gb/s TX to oscillation failures in a two-stage ring oscillator, are addressed in this paper. A tri-state-inverter-based frequency-divider and an AC-coupled clock-buffer are used for high-speed operations with minimal power and area overheads. The proposed 10 GHz PLL fabricated in the 65 nm CMOS technology occupies an active area of 0.009 mm2 with an integrated-RMS-jitter of 414 fs from 10 kHz to 100 MHz while consuming 7.6 mW from a 1.2-V supply. The resulting figure-of-merit is -238.8 dB, which surpasses that of the state-of-the-art ring-PLLs by 4 dB.","Ring oscillators,
CMOS integrated circuits,
Clocks,
Phase locked loops,
Inverters,
CMOS technology,
Bandwidth"
Efficient Search of Girth-Optimal QC-LDPC Codes,"In this paper, we study the cycle structure of quasi-cyclic (QC) low-density parity-check (LDPC) codes with the goal of obtaining the shortest code with a given degree distribution and girth. We focus on QC-LDPC codes, whose Tanner graphs are cyclic liftings of fully connected base graphs of size 3 × n, n ≥ 4, and obtain minimal lifting degrees that result in girths 6 and 8. This is performed through an efficient exhaustive search, and as a result, we also find all the possible non-isomorphic codes with the same minimum block length, girth, and degree distribution. The exhaustive search, which is ordinarily a formidable task, is made possible by pruning the search space of many codes that are isomorphic to those previously examined in the search process. Many of the pruning techniques proposed in this paper are also applicable to QC-LDPC codes with base graphs other than the 3 × n fully connected ones discussed here, as well as to codes with a larger girth. To further demonstrate the effectiveness of the pruning techniques, we use them to search for QC-LDPC codes with girths 10 and 12, and find a number of such codes that have a shorter block length compared with the best known similar codes in the literature. In addition, motivated by the exhaustive search results, we tighten the lower bound on the block length of QC-LDPC codes of girth 6 constructed from fully connected 3 × n base graphs, and construct codes that achieve the lower bound for an arbitrary value of n ≥ 4.","Parity check codes,
Bipartite graph,
Indexes,
Computer science,
Computers,
Manganese"
Highly Scalable Digital Silicon Photonic MEMS Switches,"Optical circuit switches with fast switching times can provide rapidly reconfigurable bandwidth in data center networks. Silicon photonic switches are attractive candidates with their fast response times and CMOS process compatibility. In this paper, we report on a 50 × 50 silicon photonic switch with MEMS-actuated vertical adiabatic couplers. The switch is monolithically integrated on a 7.6 × 7.6 mm2 chip. It has an on-chip insertion loss of 8.5 dB. Our switch exhibits a sub-microsecond switching time (0.85 μs), a broad spectral bandwidth (1400-1700 nm), and digital switching characteristic. The switch architecture is highly scalable as light passes through only one switching element irrespective of the switch size.","Optical switches,
Optical waveguides,
Optical losses,
Couplers,
Silicon photonics,
Micromechanical devices"
Infarct Localization From Myocardial Deformation: Prediction and Uncertainty Quantification by Regression From a Low-Dimensional Space,"Diagnosing and localizing myocardial infarct is crucial for early patient management and therapy planning. We propose a new method for predicting the location of myocardial infarct from local wall deformation, which has value for risk stratification from routine examinations such as (3D) echocardiography. The pipeline combines non-linear dimensionality reduction of deformation patterns and two multi-scale kernel regressions. Confidence in the diagnosis is assessed by a map of local uncertainties, which integrates plausible infarct locations generated from the space of reduced dimensionality. These concepts were tested on 500 synthetic cases generated from a realistic cardiac electromechanical model, and 108 pairs of 3D echocardiographic sequences and delayed-enhancement magnetic resonance images from real cases. Infarct prediction is made at a spatial resolution around 4 mm, more than 10 times smaller than the current diagnosis, made regionally. Our method is accurate, and significantly outperforms the clinically-used thresholding of the deformation patterns (on real data: sensitivity/specificity of 0.828/0.804, area under the curve: 0.909 versus 0.742 for the most predictive strain component). Uncertainty adds value to refine the diagnosis and eventually re-examine suspicious cases.","Uncertainty,
Myocardium,
Computational modeling,
Three-dimensional displays,
Pipelines,
Data models,
Training"
A Source-Channel Separation Theorem With Application to the Source Broadcast Problem,"A converse method is developed for the source broadcast problem. Specifically, it is shown that the separation architecture is optimal for a variant of the source broadcast problem, and the associated source-channel separation theorem can be leveraged, via a reduction argument, to establish a necessary condition for the original problem, which unifies several existing results in the literature. Somewhat surprisingly, this method, albeit based on the source-channel separation theorem, can be used to prove the optimality of non-separation-based schemes and determine the performance limits in certain scenarios where the separation architecture is suboptimal.",
Scalable Daily Human Behavioral Pattern Mining from Multivariate Temporal Data,"This work introduces a set of scalable algorithms to identify patterns of human daily behaviors. These patterns are extracted from multivariate temporal data that have been collected from smartphones. We have exploited sensors that are available on these devices, and have identified frequent behavioral patterns with a temporal granularity, which has been inspired by the way individuals segment time into events. These patterns are helpful to both end-users and third parties who provide services based on this information. We have demonstrated our approach on two real-world datasets and showed that our pattern identification algorithms are scalable. This scalability makes analysis on resource constrained and small devices such as smartwatches feasible. Traditional data analysis systems are usually operated in a remote system outside the device. This is largely due to the lack of scalability originating from software and hardware restrictions of mobile/wearable devices. By analyzing the data on the device, the user has the control over the data, i.e., privacy, and the network costs will also be removed.","Sensors,
Data mining,
Scalability,
Mobile communication,
IEEE 802.11 Standard,
Smart phones,
Computer science"
Convergence Analysis and Assurance for Gaussian Message Passing Iterative Detector in Massive MU-MIMO Systems,"This paper considers a low-complexity Gaussian message passing iterative detection (GMPID) algorithm for a massive multiuser multiple-input multiple-output (MU-MIMO) system, in which a base station with M antennas serves K Gaussian sources simultaneously. Both K and M are very large numbers, and we consider the cases that K <; M. The GMPID is a message passing algorithm operating on a fully connected loopy graph, which is well understood to be non-convergent in some cases. As it is hard to analyze the GMPID directly, the large-scale property of the massive MU-MIMO is used to simplify the analysis. First, we prove that the variances of the GMPID definitely converge to the mean square error of minimum mean square error (mmse) detection. Second, we derive two sufficient conditions that make the means of the GMPID converge to those of the mmse detection. However, the means of GMPID may not converge √ when K/M ≥ (√ 2 - 1)2. Therefore, a modified GMPID called scale-and-add GMPID, which converges to the mmse detection in mean and variance for any K <; M, and has a faster convergence speed than the GMPID, but has no higher complexity than the GMPID, is proposed. Finally, numerical results are provided to verify the validity and accuracy of the theoretical results.","Gaussian processes,
Graph theory,
Iterative methods,
Antenna arrays,
Least mean squares methods,
Message passing,
MIMO"
Super-Resolution of Complex Exponentials From Modulations With Unknown Waveforms,"Super-resolution is generally referred to as the task of recovering fine details from coarse information. Motivated by applications, such as single-molecule imaging, radar imaging, etc., we consider parameter estimation of complex exponentials from their modulations with unknown waveforms, allowing for non-stationary blind super-resolution. This problem, however, is ill-posed since both the parameters associated with the complex exponentials and the modulating waveforms are unknown. To alleviate this, we assume that the unknown waveforms live in a common low-dimensional subspace. Using a lifting trick, we recast the blind super-resolution problem as a structured low-rank matrix recovery problem. Atomic norm minimization is then used to enforce the structured low-rankness, and is reformulated as a semidefinite program that is solvable in polynomial time. We show that, up to scaling ambiguities, exact recovery of both of the complex exponential parameters and the unknown waveforms is possible when the waveform subspace is random and the number of measurements is proportional to the number of degrees of freedom in the problem. Numerical simulations support our theoretical findings, showing that non-stationary blind super-resolution using atomic norm minimization is possible.",
Semi-Supervised Text Classification With Universum Learning,"Universum, a collection of nonexamples that do not belong to any class of interest, has become a new research topic in machine learning. This paper devises a semi-supervised learning with Universum algorithm based on boosting technique, and focuses on situations where only a few labeled examples are available. We also show that the training error of AdaBoost with Universum is bounded by the product of normalization factor, and the training error drops exponentially fast when each weak classifier is slightly better than random guessing. Finally, the experiments use four data sets with several combinations. Experimental results indicate that the proposed algorithm can benefit from Universum examples and outperform several alternative methods, particularly when insufficient labeled examples are available. When the number of labeled examples is insufficient to estimate the parameters of classification functions, the Universum can be used to approximate the prior distribution of the classification functions. The experimental results can be explained using the concept of Universum introduced by Vapnik, that is, Universum examples implicitly specify a prior distribution on the set of classification functions.",
Integration of Fractal Biosensor in a Digital Microfluidic Platform,"The digital microfluidic (DMF) platform introduces many applications in biomedical assays. If it is to be commercially available to the public, it needs to have the essential features of smart sensing and a compact size. In this paper, we report on a fractal electrode biosensor that is used for both droplet actuation and sensing C-reactive protein (CRP) concentration levels to assess cardiac disease risk. Our proposed electrode is the first two-terminal electrode design to be integrated into DMF platforms. A simulation of the electrical field distribution shows reduced peak intensities and uniform distribution of the field. When compared with a V-notch square electrode, the fractal electrode shows a superior performance in both aspects, i.e., field uniformity and intensity. These improvements are translated into a successful and responsive actuation of a water droplet with 100 V. Likewise, the effective dielectric strength is improved by a 33% increase in the fractal electrode breakdown voltage. In addition, the capability of the fractal electrode to work as a capacitive biosensor is evaluated with CRP quantification test. Selected fractal electrodes undergo a surface treatment to immobilize anti-CRP antibodies on their surface. The measurement shows a response to the added CRP in capacitance within 3 min. When the untreated electrodes were used for quantification, there was no significant change in capacitance, and this suggested that immobilization was necessary. The electrodes configuration in the fabricated DMF platform allows the fractal electrodes to be selectively used as biosensors, which means that the device could be integrated into point-of-care applications.","Microfluidics,
Capacitance,
Dielectrics,
Biosensors,
Proteins"
A Generalized MPC Framework for the Design and Comparison of VSI Current Controllers,"Model predictive control (MPC) has been widely advocated as a design strategy for many aspects of industrial electronics. The methodology has been strongly promoted by some researchers but has also attracted criticism from others. In this context, the purpose of this paper is twofold. First, we show that many existing and popular control strategies, including finite set MPC and linear controllers [proportional integral, proportional resonant (PR)], can be viewed as special cases of MPC. Second, we show that the predictive control framework allows one to embellish these classical control architectures with novel features and to design new and advanced control architectures to address various challenges posed by power electronics applications. The findings of the paper are supported by a practical example of designing of a novel form of PR controller with superior tracking performance and delay compensation, confirmed via simulation and experiments.","Predictive control,
Switches,
Delays,
Inverters,
Electronic mail,
Load modeling"
Double Bow-Tie Slot Antennas for Wideband Millimeter-Wave and Terahertz Applications,"This paper presents millimeter-wave and terahertz double bow-tie slot antennas on a synthesized elliptical silicon lens. Two different antennas are designed to cover 0.1-0.3 and 0.2-0.6 THz, respectively. The double bow-tie slot antenna results in a wide impedance bandwidth and 78-97% Gaussian coupling efficiency over a 3:1 frequency range. A wideband coplanar-waveguide low-pass filter is designed using slow-wave techniques, and the measured filter response shows an S21 <; -25 dB over a 3:1 frequency range. Absolute gain measurements done at 100-300 GHz and 200-600 GHz confirm the wideband operation of this design. The double bow-tie slot antenna is intended to fill the gap between standard double-slot antennas and log periodic and sinuous antennas, with applications areas in radio astronomy and imaging systems.","Slot antennas,
Impedance,
Lenses,
Wideband,
Antenna measurements,
Broadband antennas"
Energy-Optimal Motion Planning for Multiple Robotic Vehicles With Collision Avoidance,"We propose a numerical algorithm for multiple-vehicle motion planning that explicitly takes into account the vehicle dynamics, temporal and spatial specifications, and energy-related requirements. As a motivating example, we consider the case where a group of vehicles is tasked to reach a number of target points at the same time (simultaneous arrival problem) without colliding among themselves and with obstacles, subject to the requirement that the overall energy required for vehicle motion be minimized. With the theoretical setup adopted, the vehicle dynamics are explicitly taken into account at the planning level. This paper formulates the problem of multiple-vehicle motion planning in a rigorous mathematical setting, describes the optimization algorithm used to solve it, and discusses the key implementation details. The efficacy of the method is illustrated through numerical examples for the simultaneous arrival problem. The initial guess to start the optimization procedure is obtained from simple geometrical considerations, e.g., by joining the desired initial and final positions of the vehicles via straight lines. Even though the initial trajectories thus obtained may result in intervehicle and vehicle/obstacle collisions, we show that the optimization procedure that we employ in this paper will generate collision-free trajectories that also minimize the overall energy spent by each vehicle and meet the required temporal and spatial constraints. The method developed applies to a very general class of vehicles; however, for clarity of exposition, we adopt as an illustrative example the case of wheeled robots.",
A New MI-Based Visualization Aided Validation Index for Mining Big Longitudinal Web Trial Data,"Web-delivered clinical trials generate big complex data. To help untangle the heterogeneity of treatment effects, unsupervised learning methods have been widely applied. However, identifying valid patterns is a priority but challenging issue for these methods. This paper, built upon our previous research on multiple imputation (MI)-based fuzzy clustering and validation, proposes a new MI-based Visualization-aided validation index (MIVOOS) to determine the optimal number of clusters for big incomplete longitudinal Web-trial data with inflated zeros. Different from a recently developed fuzzy clustering validation index, MIVOOS uses a more suitable overlap and separation measures for Web-trial data but does not depend on the choice of fuzzifiers as the widely used Xie and Beni (XB) index. Through optimizing the view angles of 3-D projections using Sammon mapping, the optimal 2-D projection-guided MIVOOS is obtained to better visualize and verify the patterns in conjunction with trajectory patterns. Compared with XB and VOS, our newly proposed MIVOOS shows its robustness in validating big Web-trial data under different missing data mechanisms using real and simulated Web-trial data.","Cluster approximation,
Pattern recognition,
Data visualization,
Web services,
Clinical trials,
Unsupervised learning,
Three-dimensional displays,
Medical trials"
"DC Local Power Distribution: Technology, Deployment, and Pathways to Success","Direct-current (DC) power distribution has been used ever since electric grids were invented, but, for the last century, low-voltage dc has been largely limited to a variety of niche applications such as rail transport, vehicles, telecommunications, and off-grid buildings. Recent years have seen a variety of innovations in dc distribution technology, notably, standards for 380-V dc cabling and connectors and increases in power that can be carried over Ethernet and universal serial bus (USB). There are increasing calls for much more use of dc distribution and dc microgrids in buildings, and there are potential advantages of both. However, open questions remain about the directions this might take, what policy makers could and should do in this area, and technology developments that would be most useful. This article considers potential pathways for increased use of dc and identifies those pathways that seem most beneficial and likely to succeed. We limit the scope of consideration to distribution within (or between) buildings.","DC motors,
Nanoscale devices,
Power distribution,
Connectors,
Universal Serial Bus,
Power grids"
Utilization of Chip-Scale Atomic Clock for Synchrophasor Measurements,"Global positioning system (GPS)-based phasor measurement units (PMUs) are increasingly deployed in the power system in order to monitor the grid status in real time. Nevertheless, GPS receivers inside PMUs tend to lose signal lock when certain uncontrollable and unpredictable factors arise. To address this issue, the chip-scale atomic clock is proposed to be used as a backup solution for time synchronization in this paper. It is the first time ever reporting the utilization of CSAC in the electric power grid. Test results show that CSAC can work as a reliable and accurate backup for GPS timing.","Global Positioning System,
Phasor measurement units,
Synchronization,
Frequency measurement,
Yttrium,
Atomic clocks"
Iris Recognition Based on Human-Interpretable Features,"The iris is a stable biometric trait that has been widely used for human recognition in various applications. However, deployment of iris recognition in forensic applications has not been reported. A primary reason is the lack of human-friendly techniques for iris comparison. To further promote the use of iris recognition in forensics, the similarity between irises should be made visualizable and interpretable. Recently, a human-in-the-loop iris recognition system was developed, based on detecting and matching iris crypts. Building on this framework, we propose a new approach for detecting and matching iris crypts automatically. Our detection method is able to capture iris crypts of various sizes. Our matching scheme is designed to handle potential topological changes in the detection of the same crypt in different images. Our approach outperforms the known visible-feature-based iris recognition method on three different data sets. In particular, our approach achieves over 22% higher rank one hit rate in identification, and over 51% lower equal error rate in verification. In addition, the benefit of our approach on multi-enrollment is experimentally demonstrated.","Iris recognition,
Cryptography,
Feature extraction,
Probes,
Algorithm design and analysis,
Forensics,
Image segmentation"
Estimation of Respiratory Rates Using the Built-in Microphone of a Smartphone or Headset,"This paper proposes accurate respiratory rate estimation using nasal breath sound recordings from a smartphone. Specifically, the proposed method detects nasal airflow using a built-in smartphone microphone or a headset microphone placed underneath the nose. In addition, we also examined if tracheal breath sounds recorded by the built-in microphone of a smartphone placed on the paralaryngeal space can also be used to estimate different respiratory rates ranging from as low as 6 breaths/min to as high as 90 breaths/min. The true breathing rates were measured using inductance plethysmography bands placed around the chest and the abdomen of the subject. Inspiration and expiration were detected by averaging the power of nasal breath sounds. We investigated the suitability of using the smartphone-acquired breath sounds for respiratory rate estimation using two different spectral analyses of the sound envelope signals: The Welch periodogram and the autoregressive spectrum. To evaluate the performance of the proposed methods, data were collected from ten healthy subjects. For the breathing range studied (6-90 breaths/min), experimental results showed that our approach achieves an excellent performance accuracy for the nasal sound as the median errors were less than 1% for all breathing ranges. The tracheal sound, however, resulted in poor estimates of the respiratory rates using either spectral method. For both nasal and tracheal sounds, significant estimation outliers resulted for high breathing rates when subjects had nasal congestion, which often resulted in the doubling of the respiratory rates. Finally, we show that respiratory rates from the nasal sound can be accurately estimated even if a smartphone's microphone is as far as 30 cm away from the nose.","Microphones,
Acoustic applications,
Band-pass filters,
Headphones,
Biomedical measurement,
Respiratory rates,
Informatics"
Next to You: Monitoring Quality of Experience in Cellular Networks From the End-Devices,"A quarter of the world population will be using smartphones to access the Internet in the near future. In this context, understanding the quality of experience (QoE) of popular apps in such devices becomes paramount to cellular network operators, who need to offer high-quality levels to reduce the risks of customers churning for quality dissatisfaction. In this paper, we address the problem of QoE provisioning in smartphones from a double perspective, combining the results obtained from subjective laboratory tests with end-device passive measurements and QoE crowd-sourced feedback obtained in operational cellular networks. The study addresses the impact of both access bandwidth and latency on the QoE of five different services and mobile apps: YouTube, Facebook, Web browsing through Chrome, Google Maps, and WhatsApp. We evaluate the influence of both constant and dynamically changing network access conditions, tackling in particular the case of fluctuating downlink bandwidth, which is typical in cellular networks. As a main contribution, we show that the results obtained in the laboratory are highly applicable in the live scenario, as mappings track the QoE provided by users in real networks. We additionally provide hints and bandwidth thresholds for good QoE levels on such apps, as well as discussion on end-device passive measurements and analysis. The results presented in this paper provide a sound basis to better understand the QoE requirements of popular mobile apps, as well as for monitoring the underlying provisioning network. To the best of our knowledge, this is the first paper providing such a comprehensive analysis of QoE in mobile devices, combining network measurements with users QoE feedback in laboratory tests, and operational networks.","Monitoring,
Bandwidth,
YouTube,
Quality of service,
Smart phones,
Mobile communication"
Similarity Measure Selection for Clustering Time Series Databases,"In the past few years, clustering has become a popular task associated with time series. The choice of a suitable distance measure is crucial to the clustering process and, given the vast number of distance measures for time series available in the literature and their diverse characteristics, this selection is not straightforward. With the objective of simplifying this task, we propose a multi-label classification framework that provides the means to automatically select the most suitable distance measures for clustering a time series database. This classifier is based on a novel collection of characteristics that describe the main features of the time series databases and provide the predictive information necessary to discriminate between a set of distance measures. In order to test the validity of this classifier, we conduct a complete set of experiments using both synthetic and real time series databases and a set of five common distance measures. The positive results obtained by the designed classification framework for various performance measures indicate that the proposed methodology is useful to simplify the process of distance selection in time series clustering tasks.","Time series analysis,
Databases,
Correlation,
Time measurement,
Noise,
Market research,
Standards"
Tunable Single Bandpass Microwave Photonic Filter With an Improved Dynamic Range,"A tunable single bandpass microwave photonic filter (MPF) with an improved spurious free dynamic range (SFDR) using a dual-parallel Mach-Zehnder modulator (DP-MZM) and a phase-shifted fiber Bragg grating (PS-FBG) is proposed and experimentally demonstrated. The DP-MZM is employed to generate an equivalent phase-modulated (EPM) signal with an adjustable optical carrier to sideband ratio. The PS-FBG is used as an optical notch filter to remove one sideband of the EPM signal to convert the EPM signal to a single-sideband intensity-modulated signal. At the output of a photodetector, a microwave signal is detected. The entire operation is equivalent to a single passband MPF. The tunability is achieved by tuning the wavelength the optical carrier. The SFDR of the MPF is improved due to the gain enhancement by a partial suppression of the optical carrier. An experiment is performed. A single bandpass MPF with a passband width of 150 MHz and a frequency-tunable range of ~5.5 GHz with an improved SFDR by 11 dB is demonstrated.","Microwave filters,
Optical fibers,
Optical filters,
Microwave photonics,
Optical reflection"
Coexisting Success Probability and Throughput of Multi-RAT Wireless Networks With Unlicensed Band Access,"In this letter, the coexisting success probability and throughput of a wireless network consisting of multiple subnetworks of different radio access technologies (RATs) are investigated. The coexisting success probability that is defined as the average of all success probabilities of all subnetworks is found in closed-form and it will be shown to have the concavity over the number of channels in the unlicensed band. The optimal deployment densities of all different RATs access points (APs) that maximize the coexisting success probability are shown to exist and can be found under the derived constraint on network parameters. The coexisting throughput is defined as the per-channel sum of all spectrum efficiencies of all subnetworks and numerical results show that it is significantly higher than the throughput of the unlicensed band only accessed by WiFi APs.","Throughput,
IEEE 802.11 Standard,
Wireless networks,
Fading,
Sensors,
Rats"
Spectral Efficiency of Mixed-ADC Receivers for Massive MIMO Systems,"This paper investigates the uplink of multi-user massive multi-input multioutput (MIMO) systems with a mixed analog-to-digital converter (ADC) receiver architecture, in which some antennas are equipped with costly full-resolution ADCs and others with less expensive low-resolution ADCs. A closed-form approximation of the achievable spectral efficiency (SE) with the maximum-ratio combining detector is derived. Based on this approximated result, the effects of the number of base station (BS) antennas, the transmit power, the proportion of full-resolution ADCs in the mixed-ADC structure, and the number of quantization bits of the low-resolution ADCs are revealed. Results show case that the achievable SE increases with the number of BS antennas and quantization bits, and it converges to a saturated value in the high user power regime or the full ADC resolution case. Most important, this work efficiency verifies that for a massive MIMO, the mixed-ADC receiver with a small fraction of full-resolution ADCs can have comparable SE performance with the receiver with all full-resolution ADCs but at a considerably lower hardware cost.","MIMO,
Quantization,
Uplink,
Analog-digital conversion,
Receiving antennas,
Detectors,
Spectral analysis,
Energy efficiency"
Melia: A MapReduce Framework on OpenCL-Based FPGAs,"MapReduce, originally developed by Google for search applications, has recently become a popular programming framework for parallel and distributed environments. This paper presents an energy-efficient architecture design for MapReduce on Field Programmable Gate Arrays (FPGAs). The major goal is to enable users to program FPGAs with simple MapReduce interfaces, and meanwhile to embrace automatic performance optimizations within the MapReduce framework. Compared to other processors like CPUs and GPUs, FPGAs are (re-)programmable hardware and have very low energy consumption. However, the design and implementation of MapReduce on FPGAs can be challenging: firstly, FPGAs are usually programmed with hardware description languages, which hurts the programmability of the MapReduce design to its users; secondly, since MapReduce has irregular access patterns (especially in the reduce phase) and needs to support user-defined functions, careful designs and optimizations are required for efficiency. In this paper, we design, implement and evaluate Melia, a MapReduce framework on FPGAs. Melia takes advantage of the recent OpenCL programming framework developed for Altera FPGAs, and abstracts FPGAs behind the simple and familiar MapReduce interfaces in C. We further develop a series of FPGA-centric optimization techniques to improve the efficiency of Melia, and a costand resource-based approach to automate the parameter settings for those optimizations. We evaluate Melia on a recent Altera Stratix V GX FPGA with a number of commonly used MapReduce benchmarks. Our results demonstrate that 1) the efficiency and effectiveness of our optimizations and automated parameter setting approach, 2) Melia can achieve promising energy efficiency in comparison with its counterparts on CPUs/GPUs on both single-FPGA and cluster settings.","Field programmable gate arrays,
Optimization,
Digital signal processing,
Programming,
Data processing"
Spectrum Sensing of OFDM Signals Over Multipath Fading Channels and Practical Considerations for Cognitive Radios,"Despite the promising role of orthogonal frequency-division multiplexing (OFDM) in communication systems, the spectrum sensing of OFDM signals and its practical considerations for cognitive radios (CRs) remain vital and challenging topics. This paper presents a new scheme for detecting OFDM signals based on the Neyman-Pearson (NP) principle. In contrast to conventional approaches in which additive white Gaussian noise (AWGN) channels are considered or empirical second-order statistics based on correlation coefficients are employed, to improve the detection performance, the proposed approach involves considering multipath fading channels and the classical NP detector. The log-likelihood ratio (LLR) test is formulated without requiring additional pilot symbols by using the redundancy of the cyclic prefix. Analytical results indicate that the LLR of received samples is the sum of the log-likelihood function (LLF) of the samples, which is typically used for estimating unknown parameters, and the LLR of an energy detector (ED). These results provide insight into the NP detector and the relationship between the NP detector, a detector based on the LLF, and the ED.1 Because many unknown parameters must be estimated in the NP detector, two practical generalized log-likelihood ratio test (GLRT) detectors are designed. To develop a channel-independent GLRT, which is crucial for achieving favorable performance over multipath fading channels, the complementary property of the correlation coefficient is employed to derive an estimate independent of multipath channel profiles. Simulation results confirm the advantages of the proposed detector compared with the state-of-the-art detectors.","Detectors,
OFDM,
Correlation,
Multipath channels,
Fading,
AWGN channels"
Robust single-view instance recognition,"Some robots must repeatedly interact with a fixed set of objects in their environment. To operate correctly, it is helpful for the robot to be able to recognize the object instances that it repeatedly encounters. However, current methods for recognizing object instances require that, during training, many pictures are taken of each object from a large number of viewing angles. This procedure is slow and requires much manual effort before the robot can begin to operate in a new environment. We have developed a novel procedure for training a neural network to recognize a set of objects from just a single training image per object. To obtain robustness to changes in viewpoint, we take advantage of a supplementary dataset in which we observe a separate (non-overlapping) set of objects from multiple viewpoints. After pre-training the network in a novel multi-stage fashion, the network can robustly recognize new object instances given just a single training image of each object. If more images of each object are available, the performance improves. We perform a thorough analysis comparing our novel training procedure to traditional neural network pre-training techniques as well as previous state-of-the-art approaches including keypoint-matching, template-matching, and sparse coding, and we demonstrate that our method significantly outperforms these previous approaches. Our method can thus be used to easily teach a robot to recognize a novel set of object instances from unknown viewpoints.","Training,
Robustness,
Robots,
Neural networks,
Image recognition,
Three-dimensional displays,
Databases"
Challenges in Data Crowdsourcing,"Crowdsourcing refers to solving large problems by involving human workers that solve component sub-problems or tasks. In data crowdsourcing, the problem involves data acquisition, management, and analysis. In this paper, we provide an overview of data crowdsourcing, giving examples of problems that the authors have tackled, and presenting the key design steps involved in implementing a crowdsourced solution. We also discuss some of the open challenges that remain to be solved.",
A Frequency Agile Microstrip Patch Phased Array Antenna With Polarization Reconfiguration,"A novel multifunctional 1×4 phased array antenna employing wideband frequency agile microstrip patches with simultaneous polarization reconfiguration has been designed and experimentally verified. Each radiating element consists of a circular microstrip patch connected to an annular microstrip ring via four varactor diodes for achieving frequency agility between 1.5 and 2.4 GHz (frequency agility bandwidth ≈46%, S11 ≤ -10 dB). Employing two feed points per radiator enables switching among four polarization senses (two linear and two circular polarizations) using a polarization feed network (PFN). For realizing beam steering, the optimum amplitude and phase excitation coefficients for each radiating element were calculated using projection matrix method based on active element pattern, which is then applied to each corresponding radiating element using programmable digital phase shifters, low noise amplifiers, and attenuators arranged in a beam forming network. Measurement shows ±52° beam peak steering at 1.5 GHz and ±28° beam peak steering at 2.4 GHz based on 3 dB gain variation criteria for both the linear and circular polarizations. The simulated and measured results agree reasonably well.",
Clustering Data Streams Based on Shared Density between Micro-Clusters,"As more and more applications produce streaming data, clustering data streams has become an important technique for data and knowledge engineering. A typical approach is to summarize the data stream in real-time with an online process into a large number of so called micro-clusters. Micro-clusters represent local density estimates by aggregating the information of many data points in a defined area. On demand, a (modified) conventional clustering algorithm is used in a second offline step to recluster the micro-clusters into larger final clusters. For reclustering, the centers of the micro-clusters are used as pseudo points with the density estimates used as their weights. However, information about density in the area between micro-clusters is not preserved in the online process and reclustering is based on possibly inaccurate assumptions about the distribution of data within and between micro-clusters (e.g., uniform or Gaussian). This paper describes DBSTREAM, the first micro-cluster-based online clustering component that explicitly captures the density between micro-clusters via a shared density graph. The density information in this graph is then exploited for reclustering based on actual density between adjacent micro-clusters. We discuss the space and time complexity of maintaining the shared density graph. Experiments on a wide range of synthetic and real data sets highlight that using shared density improves clustering quality over other popular data stream clustering methods which require the creation of a larger number of smaller micro-clusters to achieve comparable results.","Clustering algorithms,
Knowledge engineering,
Real-time systems,
Clustering methods,
Estimation,
Data structures,
Dispersion"
Exploiting Order Independence for Scalable and Expressive Packet Classification,"Efficient packet classification is a core concern for network services. Traditional multi-field classification approaches, in both software and ternary content-addressable memory (TCAMs), entail tradeoffs between (memory) space and (lookup) time. TCAMs cannot efficiently represent range rules, a common class of classification rules confining values of packet fields to given ranges. The exponential space growth of TCAM entries relative to the number of fields is exacerbated when multiple fields contain ranges. In this work, we present a novel approach which identifies properties of many classifiers which can be implemented in linear space and with worst-case guaranteed logarithmic time and allows the addition of more fields including range constraints without impacting space and time complexities. On real-life classifiers from Cisco Systems and additional classifiers from ClassBench (with real parameters), 90-95% of rules are thus handled, and the other 5-10% of rules can be stored in TCAM to be processed in parallel.","Encoding,
Complexity theory,
Standards,
Memory management,
IEEE transactions,
Visualization,
Quality of service"
Hybrid Deep Learning for Face Verification,"This paper proposes a hybrid convolutional network (ConvNet)-Restricted Boltzmann Machine (RBM) model for face verification. A key contribution of this work is to learn high-level relational visual features with rich identity similarity information. The deep ConvNets in our model start by extracting local relational visual features from two face images in comparison, which are further processed through multiple layers to extract high-level and global relational features. To keep enough discriminative information, we use the last hidden layer neuron activations of the ConvNet as features for face verification instead of those of the output layer. To characterize face similarities from different aspects, we concatenate the features extracted from different face region pairs by different deep ConvNets. The resulting high-dimensional relational features are classified by an RBM for face verification. After pre-training each ConvNet and the RBM separately, the entire hybrid network is jointly optimized to further improve the accuracy. Various aspects of the ConvNet structures, relational features, and face verification classifiers are investigated. Our model achieves the state-of-the-art face verification performance on the challenging LFW dataset under both the unrestricted protocol and the setting when outside data is allowed to be used for training.","Feature extraction,
Face,
Face recognition,
Computational modeling,
Machine learning,
Data models,
Sun"
Current-Aided Order Tracking of Vibration Signals for Bearing Fault Diagnosis of Direct-Drive Wind Turbines,"Vibration monitoring is one of the most popular, effective, and reliable methods for bearing fault diagnosis. A key issue in the vibration monitoring for the bearings used in variable-speed wind turbines is the elimination of the effect of the turbine shaft speed fluctuation in the vibration signals measured under varying-rotating-speed conditions. This paper proposes a new current-aided vibration order tracking method for bearing fault diagnosis of variable-speed direct-drive (i.e., no gearbox) wind turbines. The method explores a new simple and effective approach to acquire the reference signal from a current signal measured from the stator of the generator for vibration order tracking. First, the instantaneous fundamental frequency of the current signal is estimated in the time-frequency domain to obtain the shaft rotating frequency. Then, the shaft phase-time relationship is established. With this information, the envelope of the synchronously recorded vibration signal is subsequently resampled at the equal-phase-increment time points. Finally, bearing fault diagnosis is performed by observing the peaks at bearing characteristic frequencies in the power spectrum of the resampled vibration envelope signal. The proposed method is validated by successful diagnosis of different bearing faults in a direct-drive wind turbine under varying-speed conditions.",
The ADMM Penalized Decoder for LDPC Codes,"Linear programming (LP) decoding for low-density parity-check codes was introduced by Feldman et al. and has been shown to have theoretical guarantees in several regimes. Furthermore, it has been reported in the literature-via simulation and via instanton analysis-that LP decoding displays better error rate performance at high signal-to-noise ratios (SNR) than does belief propagation (BP) decoding. However, at low SNRs, LP decoding is observed to have worse performance than BP. In this paper, we seek to improve LP decoding at low SNRs while maintaining LP decoding's high SNR performance. Our main contribution is a new class of decoders obtained by applying the alternating direction method of multipliers (ADMM) algorithm to a set of non-convex optimization problems. These non-convex problems are constructed by adding a penalty term to the objective of LP decoding. The goal of the penalty is to make pseudocodewords, which are non-integer vertices of the LP relaxation, more costly. We name this class of decoders-ADMM penalized decoders. For low and moderate SNRs, we simulate ADMM penalized decoding with ℓ1 and ℓ2 penalties. We find that these decoders can outperform both BP and LP decoding. For high SNRs, where it is difficult to obtain data via simulation, we use an instanton analysis and find that, asymptotically, ADMM penalized decoding performs better than BP but not as well as LP. Unfortunately, since ADMM penalized decoding is not a convex program, we have not been successful in developing theoretical guarantees. However, the non-convex program can be approximated using a sequence of linear programs; an approach that yields a reweighted LP decoder. We show that a two-round reweighted LP decoder has an improved theoretical recovery threshold when compared with LP decoding. In addition, we find via simulation that reweighted LP decoding significantly attains lower error rates than LP decoding at low SNRs.","Decoding,
Signal to noise ratio,
Iterative decoding,
Message passing,
Error analysis,
Optimization"
A Modular Textile Antenna Design Using Snap-on Buttons for Wearable Applications,"An antenna design concept with detachable radiation elements offering modular geometry reconfigurabilities for wearable applications is presented. By utilizing snap-on buttons, both as the radio-frequency (RF) connection and mechanical holding mechanism, different modularly interchangeable microstrip patches are employed to demonstrate geometry reconfigurabilities in terms of polarization and resonance frequency. The uniqueness of the design arises from the fact that all configurations share one common feed structure which consists of a two-layered substrate including snap-on buttons, a ground plane, and a proximity coupled feed. To show the concept, modular realizations with different functionalities in terms of polarization or resonance frequency are demonstrated in this paper. First, a detachable patch offering interchangeable right-hand circular polarization (RHCP) and left-hand circular polarization (LHCP) at 5 GHz is proposed. Second, a demonstration of a planar inverted-F antenna (PIFA) concept offering interchangeable resonance frequencies for the 2.4- and 5.3-GHz bands of wireless local area networks (WLAN) is given. Finally, a patch module designed for 8-GHz operation is presented to show the versatility in frequency modularity. Experimental results of the fabricated antennas in freeAn antenna design concept with detachable radiation elements offering modular geometry reconfigurabilities for wearable applications is presented. By utilizing snap-on buttons, both as the radio-frequency (RF) connection and mechanical holding mechanism, different modularly interchangeable microstrip patches are employed to demonstrate geometry reconfigurabilities in terms of polarization and resonance frequency. The uniqueness of the design arises from the fact that all configurations share one common feed structure which consists of a two-layered substrate including snap-on buttons, a ground plane, and a proximity coupled feed. To show the concept, modular realizations with different functionalities in terms of polarization or resonance frequency are demonstrated in this paper. First, a detachable patch offering interchangeable right-hand circular polarization (RHCP) and left-hand circular polarization (LHCP) at 5 GHz is proposed. Second, a demonstration of a planar inverted-F antenna (PIFA) concept offering interchangeable resonance frequencies for the 2.4- and 5.3-GHz bands of wireless local area networks (WLAN) is given. Finally, a patch module designed for 8-GHz operation is presented to show the versatility in frequency modularity. Experimental results of the fabricated antennas in free space, worn by a torso phantom and in bending conditions, validate the concept and prove that this type of modular design offers convenient, passive, low cost, and versatile system reconfigurabilities, which can benefit wearable applications. space, worn by a torso phantom and in bending conditions, validate the concept and prove that this type of modular design offers convenient, passive, low cost, and versatile system reconfigurabilities, which can benefit wearable applications.","Substrates,
Resonant frequency,
Feeds,
Biomedical monitoring,
Radio frequency,
Fabrics"
Fault-Tolerant Scheduling for Real-Time Scientific Workflows with Elastic Resource Provisioning in Virtualized Clouds,"Clouds are becoming an important platform for scientific workflow applications. However, with many nodes being deployed in clouds, managing reliability of resources becomes a critical issue, especially for the real-time scientific workflow execution where deadlines should be satisfied. Therefore, fault tolerance in clouds is extremely essential. The PB (primary backup) based scheduling is a popular technique for fault tolerance and has effectively been used in the cluster and grid computing. However, applying this technique for real-time workflows in a virtualized cloud is much more complicated and has rarely been studied. In this paper, we address this problem. We first establish a real-time workflow fault-tolerant model that extends the traditional PB model by incorporating the cloud characteristics. Based on this model, we develop approaches for task allocation and message transmission to ensure faults can be tolerated during the workflow execution. Finally, we propose a dynamic fault-tolerant scheduling algorithm, FASTER, for realtime workflows in the virtualized cloud. FASTER has three key features: 1) it employs a backward shifting method to make full use of the idle resources and incorporates task overlapping and VM migration for high resource utilization, 2) it applies the vertical/horizontal scaling-up technique to quickly provision resources for a burst of workflows, and 3) it uses the vertical scaling-down scheme to avoid unnecessary and ineffective resource changes due to fluctuated workflow requests. We evaluate our FASTER algorithm with synthetic workflows and workflows collected from the real scientific and business applications and compare it with six baseline algorithms. The experimental results demonstrate that FASTER can effectively improve the resource utilization and schedulability even in the presence of node failures in virtualized clouds.",
Security Analysis and Improvements on Two Homomorphic Authentication Schemes for Network Coding,"Recently, based on the homomorphic signatures, the authentication schemes, such as homomorphic subspace signature (HSS) and key predistribution-based tag encoding (KEPTE), have been proposed to resist against pollution attacks in network coding. In this paper, we show that there exists an efficient multi-generation pollution attack on HSS and KEPTE. In particular, we show that using packets and their signatures of different generations, the adversary can create invalid packets and their corresponding signatures that pass the verification of HSS and KEPTE at intermediate the nodes as well as at the destination nodes. After giving a more generic attack, we analyze the cause of the proposed attack. We then propose the improved key distribution schemes for HSS and KEPTE, respectively. Next, we show that the proposed key distribution schemes can combat against the proposed multi-generation pollution attacks. Finally, we analyze the computation and communication costs of the proposed key distribution schemes for HSS and KEPTE, and by implementing experiments, we demonstrate that the proposed schemes add acceptable burden on the system.","Network coding,
Pollution,
Authentication,
Encoding,
Resists,
Routing"
Reversible Data Hiding in JPEG Images,"Among various digital image formats used in daily life, the Joint Photographic Experts Group (JPEG) is the most popular. Therefore, reversible data hiding (RDH) in JPEG images is important and useful for many applications such as archive management and image authentication. However, RDH in JPEG images is considerably more difficult than that in uncompressed images because there is less information redundancy in JPEG images than that in uncompressed images, and any modification in the compressed domain may introduce more distortion in the host image. Furthermore, along with the embedding capacity and fidelity (visual quality), which have to be considered for uncompressed images, the storage size of the marked JPEG file should be considered. In this paper, based on the philosophy behind the JPEG encoder and the statistical properties of discrete cosine transform (DCT) coefficients, we present some basic insights into how to select quantized DCT coefficients for RDH. Then, a new histogram shifting-based RDH scheme for JPEG images is proposed, in which the zero coefficients remain unchanged and only coefficients with values 1 and -1 are expanded to carry message bits. Moreover, a block selection strategy based on the number of zero coefficients in each 8 × 8 block is proposed, which can be utilized to adaptively choose DCT coefficients for data hiding. Experimental results demonstrate that by using the proposed method we can easily realize high embedding capacity and good visual quality. The storage size of the host JPEG file can also be well preserved.","Transform coding,
Histograms,
Discrete cosine transforms,
Image coding,
Visualization,
Quantization (signal),
Distortion"
Singularity-Free Adaptive Speed Tracking Control for Uncertain Permanent Magnet Synchronous Motor,"This paper presents an adaptive speed tracking control scheme for an uncertain surface-mounted permanent magnet synchronous motor (SPMSM) without any knowledge of the SPMSM parameters and the singularity problem; further, even the upper and lower bounds of the parameters are not necessary. The contribution of this study is twofold. The first one is to introduce a coordinate transformation so that the resulting controller does not suffer from a singularity problem caused by the denominator including the parameter estimates. Besides, although the number of the unknown parameters is increased by two times, the number of estimators is the same as the previous result. The second one is to prove that the slightly modified parameter adaptation law contributes in enhancing the closed-loop robustness against the disturbance caused by the time-varying component of the load torque. The effectiveness of the closed-loop performance is shown by performing the experiment using the 3-kW SPMSM without any SPMSM parameter knowledge.",
Concept for Pulse Compression Device Using Structured Spatial Energy Distribution,"We explore a novel concept for pulse compression scheme applicable at RF, microwave, and possibly up to optical frequencies based on structured energy distribution in cavities supporting degenerate band-edge (DBE) modes. We show the high spatial concentration of energy due to DBE modes and proper choice of boundary conditions in coupled transmission lines (TLs) provide the basis for superior performance of the structured cavity when compared to a conventional cavity. We investigate the novel cavity features: larger loaded quality factor of the cavity and stored energy compared to conventional designs, robustness to variations of cavity loading, energy feeding and extraction at the cavity center, and substantial reduction of the cavity size by use of equivalent lumped circuits for low-energy sections of the cavity. Structured energy also allows for controlled pulse shaping via engineered extraction techniques. The presented concepts are general, in terms of equivalent coupled TLs, and can be applied to a variety of realistic guiding structures. Potential applications include microwave pulse compression devices, on-chip millimeter-wave pulse generation, and pulsed laser generation.","Cavity resonators,
Energy storage,
Microwave circuits,
Microwave photonics,
Microwave devices,
Q-factor"
Improved three-phase micro-inverter using dynamic dead time optimization and phase-skipping control techniques,This paper introduces two efficiency improvement techniques for a grid-tied micro-inverter with current mode control zero voltage switching (ZVS) output stages. The first technique is dynamic dead time optimization wherein PWM dead times are dynamically adjusted as a function of load current. The second method is advanced phase-skipping control which distributes power on individual phases depending on the available input power from PV source. Neither of the techniques require any additional components and both can be easily implemented in the digital controller firmware. The two techniques were designed and implemented in a 400W three-phase micro-inverter prototype and the experimental results confirm practical implementation of these techniques and demonstrate that significant efficiency improvement can be achieved.,"MOSFET,
Inverters,
Zero voltage switching,
Inductors,
Switches,
Capacitors,
Optimization"
Discovering Motifs in Biological Sequences Using the Micron Automata Processor,"Finding approximately conserved sequences, called motifs, across multiple DNA or protein sequences is an important problem in computational biology. In this paper, we consider the (l; d) motif search problem of identifying one or more motifs of length l present in at least q of the n given sequences, with each occurrence differing from the motif in at most d substitutions. The problem is known to be NP-complete, and the largest solved instance reported to date is (26;11). We propose a novel algorithm for the (l; d) motif search problem using streaming execution over a large set of non-deterministic finite automata (NFA). This solution is designed to take advantage of the micron automata processor, a new technology close to deployment that can simultaneously execute multiple NFA in parallel. We demonstrate the capability for solving much larger instances of the (l; d) motif search problem using the resources available within a single automata processor board, by estimating run-times for problem instances (39; 18) and (40; 17). The paper serves as a useful guide to solving problems using this new accelerator technology.","Automata,
Search problems,
Algorithm design and analysis,
Silicon,
Hamming distance,
Computational biology,
Finite element analysis"
Online Calibration of Voltage Transformers Using Synchrophasor Measurements,"Uncalibrated instrument transformers present at the inputs of phasor measurement units (PMUs) can significantly degrade their outputs. This also causes problems in downstream applications that use PMU data. This paper presents a method for calibrating voltage transformers online using synchrophasor measurements. The proposed approach aims to find the optimal locations where good quality measurements must be added in order to bring the calibration error of all the measurements below a predefined threshold. The IEEE 118-bus system, the IEEE 300-bus system, and a 2383-bus Polish system have been used as the test systems for this analysis. The advantage of the proposed approach is its effectiveness and robustness.","Phasor measurement units,
Voltage measurement,
Measurement uncertainty,
Calibration,
Instrument transformers,
Current measurement,
Mathematical model"
A Street-Centric Opportunistic Routing Protocol Based on Link Correlation for Urban VANETs,"In urban vehicular ad hoc networks (VANETs), due to the high mobility and uneven distribution of vehicles, how to select an optimal relaying node in an intra-street and how to determine a street selection at the intersection are two challenging issues in designing an efficient routing protocol in complex urban environments. In this paper, we build a link model with a Wiener process to predict the probability of link availability, which considers the stable and unstable vehicle states according to the behavior of vehicles. We introduce a novel concept called the link correlation which represents the influence of different link combinations in network topology to transmit a packet with less network resource consumption and higher goodput. Based on this concept, we design an opportunistic routing metric called the expected transmission cost over a multi-hop path (ETCoP) implemented with our link model as the selection guidance of a relaying node in intra-streets. This metric can also provide assistance for the next street selection at an intersection. Finally, we propose a street-centric opportunistic routing protocol based on ETCoP for VANETs (SRPE). Simulation results show that our proposed SRPE outperforms the conventional protocols in terms of packet delivery ratio, average end-to-end delay, and network yield.","Vehicles,
Routing,
Routing protocols,
Delays,
Mobile computing,
Urban areas"
Optimum Reconfiguration of Droop-Controlled Islanded Microgrids,"This paper proposes a new formulation for the optimum reconfiguration of islanded microgrid (IMG) systems. The reconfiguration problem is casted as a multi-objective optimization problem, in order to: 1) minimize the IMG fuel consumption in the operational planning horizon for which islanded operation is planned; 2) ensure the IMG capability to feed the maximum possible demand by enhancing its voltage instability proximity index taken over all the states at which the islanded system may reside; and 3) minimize the relevant switching operation costs. The proposed problem formulation takes into consideration the system's operational constraints in all operating conditions based on the consideration of the uncertainty associated with renewable resources output power and load variability. Moreover, the proposed formulation accounts for droop controlled IMG special operational characteristics as well as the availability/unavailability of a supervisory microgrid central controller (MGCC). The formulated problem is solved using non-dominated sorting genetic algorithm II (NSGA-II). MATLAB environment has been used to test and validate the proposed problem formulation. The results show that the implementation of appropriate IMG reconfiguration problem formulations will enhance the performance of IMG systems and facilitate a successful integration of the microgrid concept in distribution networks.",
UR-SolarCap: An Open Source Intelligent Auto-Wakeup Solar Energy Harvesting System for Supercapacitor-Based Energy Buffering,"Energy harvesting systems that couple solar panels with supercapacitor buffers offer an attractive option for powering computational systems deployed in field settings, where power infrastructure is inaccessible. Supercapacitors offer a particularly compelling advantage over electrochemical batteries for such settings because of their ability to survive many more charge-discharge cycles. We share UR-SolarCap-a versatile open source design for such a harvesting system that targets embedded system applications requiring power in the 1-10 W range. Our system is designed for high efficiency and controllability and, importantly, supports auto-wakeup from a state of complete energy depletion. This paper summarizes our design methodology, and the rationale behind our design and configuration decisions. Results from the operation and testing of a system realized with our design demonstrate: 1) an achievable harvester efficiency of 85%; 2) the ability to maintain sustained operation over a two week period when the solar panel and buffer are sized appropriately; and 3) a robust auto-wakeup functionality that resumes system operation upon the availability of harvestable energy after a period in which the system has been forced into a dormant state because of a lack of usable energy. To facilitate the use of the system by researchers exploring embedded system applications in environments that lack a power infrastructure, our designs are available for download as an archive containing design schematics, Printed Circuit Board (PCB) files, firmware code, and a component list for assembly of the system. In addition, a limited number of pre-assembled kits are available upon request.","Supercapacitors,
Solar panels,
Bluetooth,
Embedded systems,
Energy harvesting,
Voltage control,
Light emitting diodes"
On Secrecy Metrics for Physical Layer Security Over Quasi-Static Fading Channels,"Theoretical studies on physical layer security often adopt the secrecy outage probability as the performance metric for wireless communications over quasi-static fading channels. The secrecy outage probability has two limitations from a practical point of view: 1) it does not give any insight into the eavesdropper's decodability of confidential messages and 2) it cannot characterize the amount of information leakage to the eavesdropper when an outage occurs. Motivated by the limitations of the secrecy outage probability, we propose three new secrecy metrics for secure transmissions over quasi-static fading channels. The first metric establishes a link between the concept of secrecy outage and the decodability of messages at the eavesdropper. The second metric provides an error-probability-based secrecy metric which is typically used for the practical implementation of secure wireless systems. The third metric characterizes how much or how fast the confidential information is leaked to the eavesdropper. We show that the proposed secrecy metrics collectively give a more comprehensive understanding of physical layer security over fading channels and enable one to appropriately design secure communication systems with different views on how secrecy is measured.","Measurement,
Wireless communication,
Fading channels,
Security,
Error probability,
Communication system security,
Physical layer"
How Geo-Distributed Data Centers Do Demand Response: A Game-Theoretic Approach,"We study the demand response (DR) of geo-distributed data centers (DCs) using smart grid's pricing signals set by local electric utilities. The geo-distributed DCs are suitable candidates for the DR programs due to their huge energy consumption and flexibility to distribute their energy demand across time and location, whereas the price signal is well-known for DR programs to reduce the peak-to-average load ratio. There are two dependencies that make the pricing design difficult: 1) dependency among utilities; and 2) dependency between DCs and their local utilities. Our proposed pricing scheme is constructed based on a two-stage Stackelberg game in which each utility sets a real-time price to maximize its own profit in Stage I and based on these prices, the DCs' service provider minimizes its cost via workload shifting and dynamic server allocation in Stage II. For the first dependency, we show that there exists a unique Nash equilibrium. For the second dependency, we propose an iterative and distributed algorithm that can converge to this equilibrium, where the “right prices” are set for the “right demands.” We also verify our proposal by trace-based simulations, and results show that our pricing scheme significantly outperforms other baseline schemes in terms of flattening the power demand over time and space.","Servers,
Games,
Pricing,
Real-time systems,
Smart grids,
Minimization,
Load management"
Minimum Cost Placement of Bistatic Radar Sensors for Belt Barrier Coverage,"How to construct barrier coverage efficiently is a critical problem for many wireless sensor network applications, such as boundary surveillance and intrusion detection. In this paper, we study the belt barrier coverage in bistatic radar sensor networks. Much different from the disk and sector coverage, the coverage area of bistatic radar is dependent on the distance between a pair of radar transmitter and receiver. To improve coverage quality, we require to construct a belt barrier with the breadth not smaller than a predefined threshold. Furthermore, the unit cost of a radar transmitter may be different from a receiver. The bistatic radar placement problem is to construct a belt barrier with the minimum total placement cost. To solve the minimum cost placement problem, we propose a line-based equipartition placement strategy such that all radars placed on a deployment line can form a barrier with some breadth and one or more such placement lines can form a belt barrier with the required breadth. We first study the barrier property of different placement patterns on one deployment line, and prove the structure property of the optimal placement sequence on one deployment line. When multiple deployment lines are needed for belt barrier construction, we propose algorithms to find out the number of deployment lines and the number of receivers in the optimal placement pattern on each deployment line to minimize the total placement cost. The efficiency of the proposed algorithm is also validated by our simulation results.","Receivers,
Transmitters,
Sensors,
Bistatic radar,
Wireless sensor networks"
Efficient Background Modeling Based on Sparse Representation and Outlier Iterative Removal,"Background modeling is a critical component for various vision-based applications. Most traditional methods tend to be inefficient when solving large-scale problems. In this paper, we introduce sparse representation into the task of large-scale stable-background modeling, and reduce the video size by exploring its discriminative frames. A cyclic iteration process is then proposed to extract the background from the discriminative frame set. The two parts combine to form our sparse outlier iterative removal (SOIR) algorithm. The algorithm operates in tensor space to obey the natural data structure of videos. Experimental results show that a few discriminative frames determine the performance of the background extraction. Furthermore, SOIR can achieve high accuracy and high speed simultaneously when dealing with real video sequences. Thus, SOIR has an advantage in solving large-scale tasks.","Tensile stress,
Video sequences,
Educational institutions,
Mathematical model,
Noise,
Bismuth,
Principal component analysis"
Joint Information and Jamming Beamforming for Secrecy Rate Maximization in Cognitive Radio Networks,"In this paper, we consider the secure beamforming design for an underlay cognitive radio multiple-input single-output broadcast channel in the presence of multiple passive eavesdroppers. Our goal is to design a jamming noise (JN) transmit strategy to maximize the secrecy rate of the secondary system. By utilizing the zero-forcing method to eliminate the interference caused by JN to the secondary user, we study the joint optimization of the information and JN beamforming for secrecy rate maximization of the secondary system while satisfying all the interference power constraints at the primary users, as well as the per-antenna power constraint at the secondary transmitter. For an optimal beamforming design, the original problem is a nonconvex program, which can be reformulated as a convex program by applying the rank relaxation method. To this end, we prove that the rank relaxation is tight and propose a barrier interior-point method to solve the resulting saddle point problem based on a duality result. To find the global optimal solution, we transform the considered problem into an unconstrained optimization problem. We then employ Broyden-Fletcher-Goldfarb-Shanno method to solve the resulting unconstrained problem, which helps reduce the complexity significantly, compared with the conventional methods. Simulation results show the fast convergence of the proposed algorithm and substantial performance improvements over the existing approaches.","Array signal processing,
Interference,
Jamming,
Radio transmitters,
Optimization,
Covariance matrices,
Algorithm design and analysis"
"How Modeling Standards, Software, and Initiatives Support Reproducibility in Systems Biology and Systems Medicine","Objective: Only reproducible results are of significance to science. The lack of suitable standards and appropriate support of standards in software tools has led to numerous publications with irreproducible results. Our objectives are to identify the key challenges of reproducible research and to highlight existing solutions. Results: In this paper, we summarize problems concerning reproducibility in systems biology and systems medicine. We focus on initiatives, standards, and software tools that aim to improve the reproducibility of simulation studies. Conclusions: The long-term success of systems biology and systems medicine depends on trustworthy models and simulations. This requires openness to ensure reusability and transparency to enable reproducibility of results in these fields.","Standards,
Biological system modeling,
Software,
Systems biology,
Computational modeling,
Data models,
Analytical models"
Demonstration of Cladding-Pumped Six-Core Erbium-Doped Fiber Amplifier,"We demonstrate cladding-pumped six-core Erbium-doped fiber amplifiers (EDFAs) using two different pump coupling schemes: edge-coupled and side-coupled pumping, where a single multimode laser diode can be applied to pump all cores. Using two in-line cladding-pumped EDFAs at the input and output of a 31-km coupled-six-core fiber, we realized 465-km space-division multiplexing and wavelength division multiplexing transmission in a recirculating loop and achieved a spectral efficiency of 18 bits/s/Hz. Through side-coupled pumping, the cladding-pumped six-core EDFA produced >18-dBm output power per core and had <;6-dB noise figure across the C-band.","Erbium-doped fiber amplifiers,
Wavelength division multiplexing,
Multicore processing,
Laser excitation,
Gain,
Couplings,
Power generation"
Interference as Noise: Friend or Foe?,"This paper shows that for the two-user Gaussian interference channel (G-IC) treating interference as noise without time sharing (TINnoTS) achieves the closure of the capacity region to within either a constant gap, or to within a gap of the order O(log(ln(min(S, I))/y)) up to a set of Lebesgue measure γ ∈ (0, 1], where S is the largest signal to noise ratio on the direct links and I is the largest interference to noise ratio on the cross links. As a consequence, TINnoTS is optimal from a generalized degrees of freedom (gDoF) perspective for all channel gains except for a subset of zero measure. TINnoTS with Gaussian inputs is known to be optimal within 1/2 bit for a subset of the weak interference regime. Rather surprisingly, this paper shows that TINnoTS is gDoF optimal in all parameter regimes, even in the strong and very strong interference regimes where joint decoding of Gaussian inputs is optimal. For approximate optimality of TINnoTS in all parameter regimes, it is critical to use non-Gaussian inputs. This paper thus proposes to use mixed inputs as channel inputs for the G-IC, where a mixed input is the sum of a discrete and a Gaussian random variable. Interestingly, with reference to the Han-Kobayashi achievable scheme, the discrete part of a mixed input is shown to effectively behave as a common message in the sense that, although treated as noise, its effect on the achievable rate region is as if it were jointly decoded together with the desired messages at a non-intended receiver. The practical implication is that a discrete interfering input is a friend, while an Gaussian interfering input is in general a foe. This paper also discusses other practical implications of the proposed TINnoTS scheme with mixed inputs. Since TINnoTS requires neither explicit joint decoding nor time sharing, the results of this paper are applicable to a variety of oblivious or asynchronous channels, such as the block asynchronous G-IC (which is not an information stable channel) and the G-IC with partial codebook knowledge at one or more receivers.","Receivers,
Interference channels,
Decoding,
Additives,
Tin,
Integrated circuits"
Human-Machine CRFs for Identifying Bottlenecks in Scene Understanding,"Recent trends in image understanding have pushed for scene understanding models that jointly reason about various tasks such as object detection, scene recognition, shape analysis, contextual reasoning, and local appearance based classifiers. In this work, we are interested in understanding the roles of these different tasks in improved scene understanding, in particular semantic segmentation, object detection and scene recognition. Towards this goal, we “plug-in” human subjects for each of the various components in a conditional random field model. Comparisons among various hybrid human-machine CRFs give us indications of how much “head room” there is to improve scene understanding by focusing research efforts on various individual tasks.",
DCT Coefficient Distribution Modeling and Quality Dependency Analysis Based Frame-Level Bit Allocation for HEVC,"A frame-level bit allocation optimization method is proposed to improve the rate-distortion performance for High Efficiency Video Coding. First, to avoid the demerits of the mixture Laplacian distribution model on complexity, a new synthesized Laplacian distribution (SynLD) model is proposed to describe the discrete cosine transform transformed coefficients based on Kullback-Leibler-divergence analysis. Second, quality dependencies among frames are investigated, and a linear relationship between quality dependency factor (QDF) and skipmode percentage is proposed for QDF prediction. Based on the proposed SynLD model and QDF prediction method, a p-domain-based frame-level bit allocation method is proposed. Experimental results show that when compared with the state-of-the-art pixel-based unified rate-quantization (URQ) model and R-λ-model-based algorithms, 1.75- and 0.16-dB BD-peak signalto-noise ratio (PSNR) gains can be achieved by the proposed bit allocation method, respectively. For quality consistency, the average PSNR standard deviation shows 0.16 and 0.02 dB lower than URQ and R-λ-model-based algorithms, respectively. The proposed method also has a much more stable buffer control status and works well for scene change cases.","Encoding,
Distortion,
Bit rate,
Adaptation models,
Discrete cosine transforms,
Numerical models,
Analytical models"
A Multimode Area-Efficient SCL Polar Decoder,"Polar codes are of great interest, since they are the first provably capacity-achieving forward error correction codes. To improve throughput and to reduce decoding latency of polar decoders, maximum likelihood (ML) decoding units are used by successive cancellation list (SCL) decoders as well as SC decoders. This paper proposes an approximate ML (AML) decoding unit for SCL decoders first. In particular, we investigate the distribution of frozen bits of polar codes designed for both the binary erasure and additive white Gaussian noise channels, and take advantage of the distribution to reduce the complexity of the AML decoding unit, improving the throughput-area efficiency of the SCL decoders. Furthermore, a multimode (MM) SCL decoder with variable list sizes and parallelism is proposed. If high throughput or small latency is required, the decoder decodes multiple received words in parallel with a small list size. However, if error performance is of higher priority, the MM-SCL decoder switches to a serial mode with a bigger list size. Therefore, the MM-SCL decoder provides a flexible tradeoff between latency, throughput, and error performance at the expense of small overhead. Hardware implementation and synthesis results show that our polar decoders not only have a better throughput-area efficiency but also easily adapt to different communication channels and applications.","Maximum likelihood decoding,
Throughput,
Complexity theory,
Probability,
Degradation"
Towards Exploring Data-Intensive Scientific Applications at Extreme Scales through Systems and Simulations,"The state-of-the-art storage architecture of high-performance computing systems was designed decades ago, and with today's scale and level of concurrency, it is showing significant limitations. Our recent work proposed a new architecture to address the I/O bottleneck of the conventional wisdom, and the system prototype (FusionFS) demonstrated its effectiveness on up to 16 K nodes-the scale on par with today's largest supercomputers. The main objective of this paper is to investigate FusionFS's scalability towards exascale. Exascale computers are predicted to emerge by 2018, comprising millions of cores and billions of threads. We built an event-driven simulator (FusionSim) according to the FusionFS architecture, and validated it with FusionFS's traces. FusionSim introduced less than 4 percent error between its simulation results and FusionFS traces. With FusionSim we simulated workloads on up to two million nodes and find out almost linear scalability of I/O performance; results justified FusionFS's viability for exascale systems. In addition to the simulation work, this paper extends the FusionFS system prototype in the following perspectives: (1) the fault tolerance of file metadata is supported, (2) the limitations of the current system design is discussed, and (3) a more thorough performance evaluation is conducted, such as N-to-1 metadata write, system efficiency, and more platforms such as Amazon Cloud.",
Content caching at the wireless network edge: A distributed algorithm via belief propagation,"Caching popular contents at the edge of wireless networks has recently emerged as a promising technology to improve the quality of service for mobile users, while balancing the peak-to-average transmissions over backhaul links. In contrast to existing works, where a central coordinator is required to design the cache placement strategy, we consider a distributed caching problem which is highly relevant in dense network settings. In the considered scenario, each Base Station (BS) has a cache storage of finite capacity, and each user will be served by one or multiple BSs depending on the employed transmission scheme. A belief propagation based distributed algorithm is proposed to solve the cache placement problem, where the parallel computations are performed by individual BSs based on limited local information and very few messages passed between neighboring BSs. Thus, no central coordinator is required to collect the information of the whole network, which significantly saves signaling overhead. Simulation results show that the proposed low-complexity distributed algorithm can greatly reduce the average download delay by collaborative caching and transmissions.","Delays,
Wireless networks,
Distributed algorithms,
Belief propagation,
Array signal processing,
Servers,
Mobile communication"
Auction-Based Random Access Load Control for Time-Dependent Machine-to-Machine Communications,"Random access channel (RACH) contention issue has drawn great attention due to the prospering development of machine-to-machine (M2M) and Internet-of-Things (IoT) applications. Since a high preamble transmission rate is the direct cause of RACH contention, in this paper, we propose a two-stage scheme to control preamble transmission in multiple periods. In stage I, we design an auction method to balance and allocate the RACH transmission traffic among periods. In stage II, we propose an RACH attempt estimation method to control the preamble transmission rate decided by stage I. Through the two-stage scheme, we can efficiently handle a great number of random access request coming from diverse M2M applications.","Throughput,
Estimation error,
Base stations,
Silicon,
Resource management,
Internet of things"
Spice: Socially-driven learning-based mobile media prefetching,"Mobile online social networks (OSNs) are emerging as the popular mainstream platform for information and content sharing among people. In order to provide Quality of Experience (QoE) support for mobile OSN services, in this paper we propose a socially-driven learning-based framework, namely Spice, for media content prefetching to reduce the access delay and enhance mobile user's satisfaction. Through a large-scale data-driven analysis over real-life mobile Twitter traces from over 17,000 users during a period of five months, we reveal that the social friendship has a great impact on user's media content click behavior. To capture this effect, we conduct social friendship clustering over the set of user's friends, and then develop a cluster-based Latent Bias Model for socially-driven learning-based prefetching prediction. We then propose a usage-adaptive prefetching scheduling scheme by taking into account that different users may possess heterogeneous patterns in the mobile OSN app usage. We comprehensively evaluate the performance of Spice framework using trace-driven emulations on smartphones. Evaluation results corroborate that the Spice can achieve superior performance, with an average 67.2% access delay reduction at the low cost of cellular data and energy consumption. Furthermore, by enabling users to offload their machine learning procedures to a cloud server, our design can achieve speed-up of a factor of 1000 over the local data training execution on smartphones.","Media,
Prefetching,
Mobile communication,
Twitter,
Mobile handsets,
Servers,
Delays"
Phase transition oxide neuron for spiking neural networks,"Spiking neural networks are expected to play a vital role in realizing ultra-low power hardware for computer vision applications [1]. While the algorithmic efficiency is promising, their solid-state implementation with traditional CMOS transistors lead to area expensive solutions. Transistors are typically designed and optimized to perform as switches and do not naturally exhibit the dynamical properties of neurons. In this work, we harness the abrupt insulator-to-metal transition (IMT) in a prototypical IMT material, vanadium dioxide (VO2) [2], to experimentally demonstrate a compact integrate and fire spiking neuron [3]. Further, we show multiple spiking dynamics of the neuron relevant to implementing `winner take all' max pooling layers employed in image processing pipelines.",
Searchable Encryption over Feature-Rich Data,"Storage services allow data owners to store their huge amount of potentially sensitive data, such as audios, images, and videos, on remote cloud servers in encrypted form. To enable retrieval of encrypted files of interest, many searchable symmetric encryption (SSE) schemes have been proposed. However, most existing SSE solutions construct indexes based on keyword-file pairs and focus on boolean expressions of exact keyword matches. Moreover, most dynamic SSE solutions cannot achieve forward privacy and reveal unnecessary information when updating the encrypted databases. We tackle the challenge of supporting large-scale similarity search over encrypted feature-rich multimedia data, by considering the search criteria as a high-dimensional feature vector instead of a keyword. Our solutions are built on carefully-designed fuzzy Bloom filters which utilize locality sensitive hashing (LSH) to encode an index associating the file identifiers and feature vectors. Our schemes are proven to be secure against adaptively chosen query attack and forward private in the standard model. We have evaluated the performance of our scheme on various real-world high-dimensional datasets, and achieved a search quality of 99% recall with only a few number of hash tables for LSH. This shows that our index is compact and searching is not only efficient but also accurate.",
Hybrid Bit-to-Symbol Mapping for Spatial Modulation,"In spatial modulation (SM), the information bit stream is divided into two different sets: the transmit antenna index bits (TA-bits) and the amplitude and phase modulation bits (APM-bits). However, the conventional bit-to-symbol mapping (BTS-MAP) scheme maps the APM-bits and the TA-bits independently. For exploiting their joint benefits, we propose a new BTS-MAP rule based on the traditional 2-D Gray mapping rule, which increases the Hamming distance (HD) between the symbol pairs detected from the same transmit antenna (TA) and simultaneously reduces the average HD between the symbol pairs gleaned from different TAs. Based on the analysis of the distribution of minimum Euclidean distance (MED) of SM constellations, we propose a criterion for the construction of a meritorious BTS-MAP for a specific SM setup, with no need for additional feedback links or extra computational complexity. Finally, Monte Carlo simulations are conducted for confirming the accuracy of our analysis.","Blogs,
High definition video,
Indexes,
MIMO,
Bit error rate,
Phase modulation"
Collective Personalized Change Classification With Multiobjective Search,"Many change classification techniques have been proposed to identify defect-prone changes. These techniques consider all developers' historical change data to build a global prediction model. In practice, since developers have their own coding preferences and behavioral patterns, which causes different defect patterns, a separate change classification model for each developer can help to improve performance. Jiang, Tan, and Kim refer to this problem as personalized change classification, and they propose PCC+ to solve this problem. A software project has a number of developers; for a developer, building a prediction model not only based on his/her change data, but also on other relevant developers' change data can further improve the performance of change classification. In this paper, we propose a more accurate technique named collective personalized change classification (CPCC), which leverages a multiobjective genetic algorithm. For a project, CPCC first builds a personalized prediction model for each developer based on his/her historical data. Next, for each developer, CPCC combines these models by assigning different weights to these models with the purpose of maximizing two objective functions (i.e., F1-scores and cost effectiveness). To further improve the prediction accuracy, we propose CPCC+ by combining CPCC with PCC proposed by Jiang, Tan, and Kim To evaluate the benefits of CPCC+ and CPCC, we perform experiments on six large software projects from different communities: Eclipse JDT, Jackrabbit, Linux kernel, Lucene, PostgreSQL, and Xorg. The experiment results show that CPCC+ can discover up to 245 more bugs than PCC+ (468 versus 223 for PostgreSQL) if developers inspect the top 20% lines of code that are predicted buggy. In addition, CPCC+ can achieve F1-scores of 0.60-0.75, which are statistically significantly higher than those of PCC+ on all of the six projects.","Data models,
Predictive models,
Software,
Computer bugs,
Genetic algorithms,
Feature extraction,
Buildings"
Demand-Based Coverage and Connectivity-Preserving Routing in Wireless Sensor Networks,"An important issue of research in wireless sensor networks (WSNs) with dense and random deployment of sensors is to minimize the energy consumption while ensuring the desired coverage of the field of interest and connectivity of the network. In this paper, we present a demand-based coverage and connectivity-preserving routing protocol to provide desired coverage and connectivity requirements in WSNs. The protocol reduces the energy consumption by assigning the minimum required sensing range to the sensors and using a scheduling protocol to periodically turn off the communication radios of the sensors in a coordinated manner and a local route optimization with a power control technique. The proposed protocol is fully distributed and does not use any geographical information. Our simulations show that the proposed protocol effectively maintains the desired coverage and connectivity of the network and prolongs the network lifetime.","Sensors,
Wireless sensor networks,
Energy consumption,
Maintenance engineering,
Routing,
Routing protocols"
Clothes Co-Parsing Via Joint Image Segmentation and Labeling With Application to Clothing Retrieval,"This paper aims at developing an integrated system for clothing co-parsing (CCP), in order to jointly parse a set of clothing images (unsegmented but annotated with tags) into semantic configurations. A novel data-driven system consisting of two phases of inference is proposed. The first phase, referred as “image cosegmentation,” iterates to extract consistent regions on images and jointly refines the regions over all images by employing the exemplar-SVM technique [1]. In the second phase (i.e., “region colabeling”), we construct a multiimage graphical model by taking the segmented regions as vertices, and incorporating several contexts of clothing configuration (e.g., item locations and mutual interactions). The joint label assignment can be solved using the efficient Graph Cuts algorithm. In addition to evaluate our framework on the Fashionista dataset [2], we construct a dataset called the SYSU-Clothes dataset consisting of 2098 high-resolution street fashion photos to demonstrate the performance of our system. We achieve 90.29%/88.23% segmentation accuracy and 65.52%/63.89% recognition rate on the Fashionista and the SYSU-Clothes datasets, respectively, which are superior compared with the previous methods. Furthermore, we apply our method on a challenging task, i.e., cross-domain clothing retrieval: given user photo depicting a clothing image, retrieving the same clothing items from online shopping stores based on the fine-grained parsing results.","Clothing,
Image segmentation,
Semantics,
Labeling,
Graphical models,
Context,
Shape"
Router Node Placement With Service Priority in Wireless Mesh Networks Using Simulated Annealing With Momentum Terms,"In wireless mesh networks (WMNs), mesh clients communicate with each other via the gateway and bridging functions of mesh routers. The performance of a WMN is generally affected by its network connectivity and client coverage, both of which are determined by its router node placement (RNP) in the deployment area. For simplicity, previous works considered only the RNP where each mesh client is served as an equal. In practice, however, mesh clients should be served with different priorities owing to factors such as their importance and their different payments for the service access. To fulfil this requirement, by assuming that each mesh client is also associated with a service priority, this paper investigates an RNP problem with a service priority constraint in which the mesh clients with service priorities higher than a threshold must be served. Given that this problem inherited from the complexity of the original RNP problem is computationally intractable in general, this paper also develops a novel simulated annealing (SA) approach that takes into account momentum terms to improve the efficiency and accuracy of annealing schedules and prevent fluctuations in values of the acceptance probability function. Additionally, the time complexity of the proposed SA algorithm is analyzed. Furthermore, evaluation of different-size instances under various parameters and annealing schedules demonstrates the superiority of the proposed approach.","Schedules,
Annealing,
Metals,
Wireless mesh networks,
Simulated annealing,
Time complexity,
Educational institutions"
Convex Relaxations of Optimal Power Flow Problems: An Illustrative Example,"Recently, there has been significant interest in convex relaxations of the optimal power flow (OPF) problem. A semidefinite programming (SDP) relaxation globally solves many OPF problems. However, there exist practical problems for which the SDP relaxation fails to yield the global solution. Conditions for the success or failure of the SDP relaxation are valuable for determining whether the relaxation is appropriate for a given OPF problem. To move beyond existing conditions, which only apply to a limited class of problems, a typical conjecture is that failure of the SDP relaxation can be related to physical characteristics of the system. By presenting an example OPF problem with two equivalent formulations, this paper demonstrates that physically based conditions cannot universally explain algorithm behavior. The SDP relaxation fails for one formulation but succeeds in finding the global solution to the other formulation. Since these formulations represent the same system, success (or otherwise) of the SDP relaxation must involve factors beyond just the network physics. The lack of universal physical conditions for success of the SDP relaxation motivates the development of tighter convex relaxations capable of solving a broader class of problems. Tools from polynomial optimization theory provide a means of developing tighter relaxations. This paper uses the example problem to illustrate relaxations from the Lasserre hierarchy for polynomial optimization and a related “mixed semidefinite/second-order cone programming” hierarchy.","Optimization,
Programming,
Generators,
5G mobile communication,
Load flow,
Physics,
Mathematical model"
An Architecture of Cloud-Assisted Information Dissemination in Vehicular Networks,"Vehicular network technology allows vehicles to exchange real-time information between each other, which plays a vital role in the development of future intelligent transportation systems Existing research on vehicular networks assumes that each vehicle broadcasts collected information to neighboring vehicles, so that information is shared among vehicles. The fundamental problem of what information is delivered with which vehicle(s), however, has not been adequately studied. We propose an innovative cloud-assisted architecture to facilitate intelligent information dissemination among vehicles. Within the novel architecture, virtual social connections between vehicles are created and maintained on the cloud. Vehicles with similar driving histories are considered friends in a vehicular social network (VSN). The closeness of the relation between two vehicles in a VSN is then modeled by the three-valued subjective logic model. Based on the closeness between vehicles, only relevant information will be delivered to vehicles that are likely interested in it. The cloud-assisted architecture coordinates vehicular social connection construction, VSN maintenance, vehicle closeness assessment, and information dissemination.","Intelligent vehicles,
Cloud computing,
Real-time systems,
Social network services,
Maintenance engineering,
Information exchange"
Ground-based image analysis: A tutorial on machine-learning techniques and applications,"Ground-based whole-sky cameras have opened up new opportunities for monitoring the earth's atmosphere. These cameras are an important complement to satellite images by providing geoscientists with cheaper, faster, and more localized data. The images captured by whole-sky imagers (WSI) can have high spatial and temporal resolution, which is an important prerequisite for applications such as solar energy modeling, cloud attenuation analysis, local weather prediction, and more. Extracting the valuable information from the huge amount of image data by detecting and analyzing the various entities in these images is challenging. However, powerful machine-learning techniques have become available to aid with the image analysis. This article provides a detailed explanation of recent developments in these techniques and their applications in ground-based imaging, aiming to bridge the gap between computer vision and remote sensing with the help of illustrative examples. We demonstrate the advantages of using machine-learning techniques in ground-based image analysis via three primary applications: segmentation, classification, and denoising.","Remote sensing,
Feature extraction,
Cameras,
Detectors,
Satellites,
Monitoring,
Spatial resolution,
Tutorials"
DARE: A Deduplication-Aware Resemblance Detection and Elimination Scheme for Data Reduction with Low Overheads,"Data reduction has become increasingly important in storage systems due to the explosive growth of digital data in the world that has ushered in the big data era. One of the main challenges facing large-scale data reduction is how to maximally detect and eliminate redundancy at very low overheads. In this paper, we present DARE, a low-overhead deduplication-aware resemblance detection and elimination scheme that effectively exploits existing duplicate-adjacency information for highly efficient resemblance detection in data deduplication based backup/archiving storage systems. The main idea behind DARE is to employ a scheme, call Duplicate-Adjacency based Resemblance Detection (DupAdj), by considering any two data chunks to be similar (i.e., candidates for delta compression) if their respective adjacent data chunks are duplicate in a deduplication system, and then further enhance the resemblance detection efficiency by an improved super-feature approach. Our experimental results based on real-world and synthetic backup datasets show that DARE only consumes about 1/4 and 1/2 respectively of the computation and indexing overheads required by the traditional super-feature approaches while detecting 2-10 percent more redundancy and achieving a higher throughput, by exploiting existing duplicate-adjacency information for resemblance detection and finding the “sweet spot” for the super-feature approach.","Redundancy,
Indexing,
Feature extraction,
Random access memory,
Data structures,
Throughput"
Forming Opinions via Trusted Friends: Time-Evolving Rating Prediction Using Fluid Dynamics,"Trust-based recommendation systems study how people form opinions via trusted friends, so as to predict unknown ratings based on the ratings expressed by trusted friends. Most of the existing work only considers the ratings at the current time slot. In real life, a user's opinion evolves over time, since he receives the influence of different opinions sequentially. In addition, existing work usually targets a single user at a time; there is a need to predict multiple ratings for multiple connected users. To reach these ends, we propose a novel multiple-rating prediction scheme, FluidRating, which uses fluid dynamics theory to reveal the time-evolving formulation process of human opinions. In this scheme, each user corresponds to a container, and several containers are connected through single directional pipes, corresponding to influence relations. We identify three features of human personality in the opinion formulation and propagation process: “persistency” represents how much one insists on his opinion, “persuasiveness” represents the ability to impact others, and “forgetting” reflects the common truth that people have limited memory. The recommendation (or influence) is modeled as fluid with two dimensions: its temperature is taken as the “opinion/rating,” and its height is deemed as the persistency. When new opinions emerge, each person refines his opinion through a round of fluid exchange with neighbors. Opinions of multiple rounds are aggregated to gain a final prediction. Experimental evaluation in a real data set validates the feasibility and the effectiveness of the proposed model.","Containers,
Temperature measurement,
Fluid dynamics,
Joining processes,
Predictive models,
Heuristic algorithms"
Energy-Efficient Design of Indoor mmWave and Sub-THz Systems With Antenna Arrays,"Emerging millimeter-wave (mmWave) and Terahertz (THz) systems is a promising revolution for next-generation wireless communications. In this paper, we study an indoor multi-user mmWave and sub-THz system with large antenna arrays, where two different types of architecture, the fully-connected structure and the array-of-subarray structure, are investigated. Specifically, the Doherty power amplifier (PA) is adopted to improve the PA efficiency of the system, and the associated nonlinear system power consumption models with insertion power loss are developed. By capturing the characteristics of the mmWave and sub-THz channels, we design different hybrid beamforming schemes for the two structures with low complexity. We further compare the achievable rates of the two structures and show that, with the insertion loss, the achievable rate of the array-of-subarray structure is generally larger than that of the fully-connected structure. Moreover, we propose the optimal power control strategies for both structures to maximize the energy efficiency of the system and demonstrate that the energy efficiency of the array-of-subarray structure outperforms that of the fully-connected structure. Simulation results are provided to compare and validate the performance of the two structures, where the array-of-subarray structure shows a great advantage over the fully-connected structure in both spectral efficiency and energy efficiency.","Antenna arrays,
Array signal processing,
Radio frequency,
Power demand,
Phase shifters,
Complexity theory"
Input-Based Dynamic Reconfiguration of Approximate Arithmetic Units for Video Encoding,"The field of approximate computing has received significant attention from the research community in the past few years, especially in the context of various signal processing applications. Image and video compression algorithms, such as JPEG, MPEG, and so on, are particularly attractive candidates for approximate computing, since they are tolerant of computing imprecision due to human imperceptibility, which can be exploited to realize highly power-efficient implementations of these algorithms. However, existing approximate architectures typically fix the level of hardware approximation statically and are not adaptive to input data. For example, if a fixed approximate hardware configuration is used for an MPEG encoder (i.e., a fixed level of approximation), the output quality varies greatly for different input videos. This paper addresses this issue by proposing a reconfigurable approximate architecture for MPEG encoders that optimizes power consumption with the goal of maintaining a particular Peak Signal-to-Noise Ratio (PSNR) threshold for any video. Toward this end, we design reconfigurable adder/subtractor blocks (RABs), which have the ability to modulate their degree of approximation, and subsequently integrate these blocks in the motion estimation and discrete cosine transform modules of the MPEG encoder. We propose two heuristics for automatically tuning the approximation degree of the RABs in these two modules during runtime based on the characteristics of each individual video. Experimental results show that our approach of dynamically adjusting the degree of hardware approximation based on the input video respects the given quality bound (PSNR degradation of 1%-10%) across different videos while achieving a power saving up to 38% over a conventional nonapproximated MPEG encoder architecture. Note that although the proposed reconfigurable approximate architecture is presented for the specific case of an MPEG encoder, it can be easily extended to other DSP applications.","Approximation methods,
Transform coding,
Adders,
Computer architecture,
Hardware,
Encoding,
Power demand"
Human-Centered Saliency Detection,"We introduce a new concept for detecting the saliency of 3-D shapes, that is, human-centered saliency (HCS) detection on the surface of shapes, whereby a given shape is analyzed not based on geometric or topological features directly obtained from the shape itself, but by studying how a human uses the object. Using virtual agents to simulate the ways in which humans interact with objects helps to understand shapes and detect their salient parts in relation to their functions. HCS detection is less affected by inconsistencies between the geometry or topology of the analyzed 3-D shapes. The potential benefit of the proposed method is that it is adaptable to variable shapes with the same semantics, as well as being robust against a geometrical and topological noise. Given a 3-D shape, its salient part is detected by automatically selecting a corresponding agent and making them interact with each other. Their adaption and alignment depend on an optimization framework and a training process. We demonstrate the detected salient parts for different types of objects together with the stability thereof. The salient parts can be used for important vision tasks, such as 3-D shape retrieval.","Shape,
Solid modeling,
Computational modeling,
Feature extraction,
Training,
Optimization,
Kernel"
Prediction Hybrid Cache: An Energy-Efficient STT-RAM Cache Architecture,"Spin-transfer torque RAM (STT-RAM) has emerged as an energy-efficient and high-density alternative to SRAM for large on-chip caches. However, its high write energy has been considered as a serious drawback. Hybrid caches mitigate this problem by incorporating a small SRAM cache for write-intensive data along with an STT-RAM cache. In such architectures, choosing cache blocks to be placed into the SRAM cache is the key to their energy efficiency. This paper proposes a new hybrid cache architecture called prediction hybrid cache. The key idea is to predict write intensity of cache blocks at the time of cache misses and determine block placement based on the prediction. We design a write intensity predictor that realize the idea by exploiting a correlation between write intensity of blocks and memory access instructions that incur cache misses of those blocks. It includes a mechanism to dynamically adapt the predictor to application characteristics. We also design a hybrid cache architecture in which write-intensive blocks identified by the predictor are placed into the SRAM region. Evaluations show that our scheme reduces energy consumption of hybrid caches by 28 percent (31 percent) on average compared to the existing hybrid cache architecture in a single-core (quad-core) system.",
Adaptive Quasi-Static Modelling of Needle Deflection During Steering in Soft Tissue,"In this letter, we present a model for needle deflection estimation in soft tissue. The needle is modelled as a vibrating compliant cantilever beam that experiences forces applied by the tissue as it is inserted. Each of the assumed vibration modes are associated with a weighting coefficient whose magnitude is calculated using the minimum potential energy method. The model only requires as input the tissue stiffness and needle-tissue cutting force. Contributions of this letter include the estimation of needle-tissue contact forces as a function of the tissue displacement along the needle shaft, while allowing for multiple bends of the needle. The model is combined with partial ultrasound image feedback in order to adaptively calculate the needle-tissue cutting force as the needle is inserted. The image feedback is obtained by an ultrasound probe that follows the needle tip and stops at an appropriate position to avoid further tissue displacement. Images obtained during early stages of the insertion are used to predict the deflection of the needle further along the insertion process. Experimental results in biological and phantom tissue show an average error in predicting needle deflection of 0.36 mm.","Needles,
Force,
Shafts,
Biological system modeling,
Biological tissues,
Ultrasonic imaging,
Deformable models"
Power System Transient Stability Assessment Based on Big Data and the Core Vector Machine,"In this paper, an online power system transient stability assessment (TSA) problem is mapped as a two-class classification problem and a novel data mining algorithm the core vector machine (CVM) is proposed to solve the problem based on phasor measurement units (PMUs) big data. First of all, an offline training, online application framework is proposed, which contained four sub-steps, namely features selection, offline training, online application, and assessment evaluation. First, 24 features are selected to present the system status. Then in the offline training procedure, the PMU big data is generated by time domain simulation, and a CVM model is trained and tested. In the online application procedure, an interface between PMU data center and feature calculation program is set up to collect real time specific PMU big data and the CVM trained is applied to the TSA problem. Last but not least, the evaluation indices are calculated. Compared with other support vector machines, the proposed CVM based assessment algorithm has the higher precision, meanwhile, it has the least time consumption and space complexity. As long as online PMU big data are received, TSA can be done simultaneously. Case studies on the IEEE New England 39-bus system, and real systems in China and the U.S., exhibit the speed and effectiveness of the proposed algorithm.","Phasor measurement units,
Support vector machines,
Big data,
Training,
Real-time systems,
Power system stability,
Kernel"
Day-Ahead Smart Grid Cooperative Distributed Energy Scheduling With Renewable and Storage Integration,"Day-ahead scheduling of generation units and storage devices is essential for the economic and efficient operation of a power system. Conventionally, a control center calculates the dispatch schedule by gathering information from all of the devices. However, this centralized control structure makes the system vulnerable to single point of failure and communication failures, and raises privacy concerns. In this paper, a fully distributed algorithm is proposed to find the optimal dispatch schedule for a smart grid with renewable and energy storage integration. The algorithm considers modified dc power flow constraints, branch energy losses, and energy storage charging and discharging efficiencies. In this algorithm, each bus of the system is modeled as an agent. By solely exchanging information with its neighbors, the optimal dispatch schedule of the conventional generators and energy storage can be achieved in an iterative manner. The effectiveness of the algorithm is demonstrated through several representative case studies.",
Mitigating Denial of Service Attacks in OLSR Protocol Using Fictitious Nodes,"With the main focus of research in routing protocols for Mobile Ad-Hoc Networks (MANET) geared towards routing efficiency, the resulting protocols tend to be vulnerable to various attacks. Over the years, emphasis has also been placed on improving the security of these networks. Different solutions have been proposed for different types of attacks, however, these solutions often compromise routing efficiency or network overload. One major DOS attack against the Optimized Link State Routing protocol (OLSR) known as the node isolation attack occurs when topological knowledge of the network is exploited by an attacker who is able to isolate the victim from the rest of the network and subsequently deny communication services to the victim. In this paper, we suggest a novel solution to defend the OLSR protocol from node isolation attack by employing the same tactics used by the attack itself. Through extensive experimentation, we demonstrate that 1) the proposed protection prevents more than 95 percent of attacks, and 2) the overhead required drastically decreases as the network size increases until it is non-discernable. Last, we suggest that this type of solution can be extended to other similar DOS attacks on OLSR.","Routing,
Network topology,
Mobile ad hoc networks,
Topology,
Computer crime,
Routing protocols"
Efficient Dynamic Virtual Channel Organization and Architecture for NoC Systems,"A growing number of processing cores on a chip require an efficient and scalable communication structure such as network on chip (NoC). The channel buffer organization of NoC uses virtual channels (VCs) to improve data flow and performance of the NoC system. Dynamically allocated multiqueues (DAMQs) are an effective mechanism to achieve VC flow control with maximum buffer utilization. In this model, VCs employ variable number of buffer slots depending on the traffic. Despite the performance merits of DAMQs, it has some limitations. We propose a new input-port microarchitecture to support our efficient dynamic VC (EDVC) approach that is built on DAMQ buffers. To demonstrate the advantages of EDVC, we compare its microarchitecture with that of the conventional dynamic VC (CDVC), which also employs link-list tables for buffer organization. In terms of hardware, EDVC input-port organization consumes on average 61% less power for application-specific integrated circuit design when compared with the CDVC input port. The saving is even better when compared with VC regulator methodology. An EDVC approach can improve NoC latency by 48%-50% and throughput by 100% on average as compared with the CDVC mechanism.",
Diffusion Adaptation over Multi-Agent Networks with Wireless Link Impairments,"We study the performance of diffusion least-mean squares algorithms for distributed parameter estimation in multi-agent networks when nodes exchange information over wireless communication links. Wireless channel impairments, such as fading and path-loss, adversely affect the exchanged data and cause instability and performance degradation if left unattended. To mitigate these effects, we incorporate equalization coefficients into the diffusion combination step and update the combination weights dynamically in the face of randomly changing neighborhoods due to fading conditions. When channel state information (CSI) is unavailable, we determine the equalization factors from pilot-aided channel coefficient estimates. The analysis reveals that by properly monitoring the CSI over the network and choosing sufficiently small adaptation step-sizes, the diffusion strategies are able to deliver satisfactory performance in the presence of fading and path loss.","Fading,
Channel estimation,
Wireless communication,
Estimation,
Signal to noise ratio,
Wireless sensor networks"
Hybrid driving-stepping locomotion with the wheeled-legged robot Momaro,"Locomotion in uneven terrain is important for a wide range of robotic applications, including Search&Rescue operations. Our mobile manipulation robot Momaro features a unique locomotion design consisting of four legs ending in pairs of steerable wheels, allowing the robot to omnidirectionally drive on sufficiently even terrain, step over obstacles, and also to overcome height differences by climbing. We demonstrate the feasibility and usefulness of this design on the example of the DARPA Robotics Challenge, where our team NimbRo Rescue solved seven out of eight tasks in only 34 minutes. We also introduce a method for semi-autonomous execution of weight-shifting and stepping actions based on a 2D heightmap generated from 3D laser data.","Legged locomotion,
Wheels,
Mobile communication,
Robot sensing systems,
Actuators"
Robust Bayesian Inference for Gas Identification in Electronic Nose Applications by Using Random Matrix Theory,"Finding a rapid gas identification algorithm with high accuracy and a closed-form solution that does not require any manual tuning of parameters is the major challenge to overcome in adopting electronic nose technology in daily life applications. Recently, bio-inspired rank-order-based classifiers have been proposed to meet this challenge by transforming multidimensional sensitivity vectors into temporally ordered spike sequences for target gases. The performance of these classifiers, however, is limited when the spike sequences corresponding to all the target gases do not contain sufficient discriminatory information to identify them. Moreover, their identification decision is delayed up to the computation of the sensitivity vectors at steady state, which incurs a long waiting time. In this paper, we adopt a Bayesian parametric method with a normal distribution model as an alternative approach that provides a closed-form solution with only second-order statistics, i.e., mean and covariance. However, for electronic nose applications, a reliable estimation of the covariance matrix is a major challenge with the commonly used maximum likelihood estimate in Bayesian inference because of the limited number of available measurements for each target gas. We exploit random matrix theory principles to reduce randomness in the sample covariance matrix for its reliable estimation. Moreover, transient features are used to accelerate the gas identification. In order to validate the effectiveness of this approach, data of eight gases, namely, C3H8, C6H6, CH2O, CL2, CO, CO2, NO2, and SO2, are acquired in the laboratory. We achieve a 7.73% performance improvement as compared with Bayesian inference using the maximum likelihood estimate, and an overall accuracy rate of 99.40% on the experimental data set.",
Beamforming for Combating Inter-cluster and Intra-cluster Interference in Hybrid NOMA Systems,"In this paper, downlink beamforming (BF) for hybrid non-orthogonal multiple access (NOMA) systems is considered, in order to combat inter and intra cluster interference. First, to minimize the inter- and intra-cluster interference, the projection hybrid NOMA (PH-NOMA) BF algorithm is introduced, by combining conventional zero-forcing BF (ZFBF) and hybrid NOMA (H-NOMA) precoding. Second, to further reduce the overall interference, two user pairing algorithms, termed projection-based pairing algorithm (PBPA) and inversion-based pairing algorithm (IBPA), are also proposed, by adopting the properties of quasi-degradation developed previously. Consequently, the proposed BF algorithm is obtained by combining PH-NOMA and PBPA/IBPA. Moreover, the system performance in terms of outage probability and diversity is analyzed for both the proposed BF algorithms and conventional ZFBF. Finally, computer simulations are conducted to demonstrate the efficiency of the proposed BF algorithms and to validate the correctness of the performance analysis.","NOMA,
Array signal processing,
Interference,
Clustering algorithms,
Algorithm design and analysis,
Downlink,
Precoding"
Image Retargeting by Texture-Aware Synthesis,"Real-world images usually contain vivid contents and rich textural details, which will complicate the manipulation on them. In this paper, we design a new framework based on exampled-based texture synthesis to enhance content-aware image retargeting. By detecting the textural regions in an image, the textural image content can be synthesized rather than simply distorted or cropped. This method enables the manipulation of textural & non-textural regions with different strategies since they have different natures. We propose to retarget the textural regions by example-based synthesis and non-textural regions by fast multi-operator. To achieve practical retargeting applications for general images, we develop an automatic and fast texture detection method that can detect multiple disjoint textural regions. We adjust the saliency of the image according to the features of the textural regions. To validate the proposed method, comparisons with state-of-the-art image retargeting techniques and a user study were conducted. Convincing visual results are shown to demonstrate the effectiveness of the proposed method.","Image color analysis,
Visualization,
Shape,
Benchmark testing,
Reliability,
Image segmentation,
Feature extraction"
Design and Flux-Weakening Control of an Interior Permanent Magnet Synchronous Motor for Electric Vehicles,"Permanent magnet synchronous motors (PMSMs) provide a competitive technology for EV traction drives owing to their high power density and high efficiency. In this paper, three types of interior PMSMs with different PM arrangements are modeled by the finite element method (FEM). For a given amount of permanent magnet materials, the V-shape interior PMSM is found better than the U-shape and the conventional rotor topologies for EV traction drives. Then the V-shape interior PMSM is further analyzed with the effects of stator slot opening and the permanent magnet pole chamfering on cogging torque and output torque performance. A vector-controlled flux-weakening method is developed and simulated in Matlab to expand the motor speed range for EV drive system. The results show good dynamic and steady-state performance with a capability of expanding speed up to four times of the rated. A prototype of the V-shape interior PMSM is also manufactured and tested to validate the numerical models built by the FEM.",
Simultaneous Ranging and Self-Positioning in Unsynchronized Wireless Acoustic Sensor Networks,"Automatic ranging and self-positioning is a very desirable property in wireless acoustic sensor networks, where nodes have at least one microphone and one loudspeaker. However, due to environmental noise, interference, and multipath effects, audio-based ranging is a challenging task. This paper presents a fast ranging and positioning strategy that makes use of the correlation properties of pseudonoise sequences for estimating simultaneously relative time-of-arrivals from multiple acoustic nodes. To this end, a proper test signal design adapted to the acoustic node transducers is proposed. In addition, a novel self-interference reduction method and a peak matching algorithm are introduced, allowing for increased accuracy in indoor environments. Synchronization issues are removed by following a BeepBeep strategy, providing range estimates that are converted to absolute node positions by means of multidimensional scaling. The proposed approach is evaluated both with simulated and real experiments under different acoustical conditions. The results using a real network of smartphones and laptops confirm the validity of the proposed approach, reaching an average ranging accuracy below 1 cm.","Distance measurement,
Loudspeakers,
Calibration,
Microphones,
Acoustics,
Delays,
Wireless sensor networks"
An Active Filter Method to Eliminate DC-Side Low-Frequency Power for a Single-Phase Quasi-Z-Source Inverter,"The second harmonic pulsating power flows through the dc side of a single-phase quasi-Z-source inverter (qZSI), which requires bulky capacitor banks and inductors to suppress low-frequency ripple of dc-link voltage and inductor currents in the passive ripple reduction way. However, the resultant huge qZS network seriously deteriorates the system reliability, efficiency, volume, weight, and cost. This paper proposes an active-filter-integrated single-phase qZSI to transfer low-frequency power ripple directly from ac load to active filter's ac capacitor, so that low-frequency power ripple does not present in dc side anymore and constant inductor currents and constant capacitor voltages are ensured. Thus, much small qZS impedance is employed to only smooth high-frequency ripple and active filter's capacitor supports ac voltage (large ripple allowed) with small capacitance. The operation principle, parameter design method, and modeling and control strategy of the proposed topology are investigated. Comparative evaluation, simulation, and experimental results verify the proposed new topology system.","Capacitors,
Active filters,
Inductors,
Inverters,
Capacitance,
Batteries,
Inductance"
Exact Performance Analysis of Ambient RF Energy Harvesting Wireless Sensor Networks With Ginibre Point Process,"Ambient radio frequency (RF) energy harvesting methods have drawn significant interests due to their ability to provide energy to wireless devices from ambient RF sources. This paper considers ambient RF energy harvesting wireless sensor networks where a sensor node transmits data to a data sink using the energy harvested from the signals transmitted by the ambient RF sources. We analyze the performance of the network, i.e., the mean of the harvested energy, the power outage probability, and the transmission outage probability. In many practical networks, the locations of the ambient RF sources are spatially correlated and the ambient sources exhibit repulsive behaviors. Therefore, we model the spatial distribution of the ambient sources as an α-Ginibre point process (α-GPP), which reflects the repulsion among the RF sources and includes the Poisson point process as a special case. We also assume that the fading channel is Nakagami-m distributed, which also includes Rayleigh fading as a particular case. In this paper, by exploiting the Laplace transform of the α-GPP, we introduce semi-closed-form expressions for the considered performance metrics and provide an upper bound of the power outage probability. The derived expressions are expressed in terms of the Fredholm determinant, which can be computed numerically. In order to reduce the complexity in computing the Fredholm determinant, we provide a simple closed-form expression for the Fredholm determinant, which allows us to evaluate the Fredholm determinant much more efficiently. The accuracy of our analytical results is validated through simulation results.","Radio frequency,
Energy harvesting,
Fading channels,
Power system faults,
Power system restoration,
RF signals,
Wireless sensor networks,
Green communications,
Energy efficiency"
GPU-Accelerated Parallel Sparse LU Factorization Method for Fast Circuit Analysis,"Lower upper (LU) factorization for sparse matrices is the most important computing step for circuit simulation problems. However, parallelizing LU factorization on the graphic processing units (GPUs) turns out to be a difficult problem due to intrinsic data dependence and irregular memory access, which diminish GPU computing power. In this paper, we propose a new sparse LU solver on GPUs for circuit simulation and more general scientific computing. The new method, which is called GPU accelerated LU factorization (GLU) solver (for GPU LU), is based on a hybrid right-looking LU factorization algorithm for sparse matrices. We show that more concurrency can be exploited in the right-looking method than the left-looking method, which is more popular for circuit analysis, on GPU platforms. At the same time, the GLU also preserves the benefit of column-based left-looking LU method, such as symbolic analysis and columnlevel concurrency. We show that the resulting new parallel GPU LU solver allows the parallelization of all three loops in the LU factorization on GPUs. While in contrast, the existing GPU-based left-looking LU factorization approach can only allow parallelization of two loops. Experimental results show that the proposed GLU solver can deliver 5.71χ and 1.46x speedup over the single-threaded and the 16-threaded PARDISO solvers, respectively, 19.56x speedup over the KLU solver, 47.13x over the UMFPACK solver, and 1.47x speedup over a recently proposed GPU-based left-looking LU solver on the set of typical circuit matrices from the University of Florida (UFL) sparse matrix collection. Furthermore, we also compare the proposed GLU solver on a set of general matrices from the UFL, GLU achieves 6.38x and 1.12x speedup over the singlethreaded and the 16-threaded PARDISO solvers, respectively, 39.39x speedup over the KLU solver, 24.04x over the UMFPACK solver, and 2.35x speedup over the same GPU-based left-looking LU solver. In addition, comparison on self-generated RLC mesh networks shows a similar trend, which further validates the advantage of the proposed method over the existing sparse LU solvers.","Graphics processing units,
Sparse matrices,
Instruction sets,
Algorithm design and analysis,
Concurrent computing,
Parallel processing,
Programming"
A Feature-Scaling-Based k-Nearest Neighbor Algorithm for Indoor Positioning Systems,"With the increasing popularity of WLAN infrastructure, WiFi fingerprint-based indoor positioning systems have received considerable attention recently. Much existing work in this aspect adopts classification techniques that match a vector of radio signal strengths (RSSs) reported by a mobile station (MS) to pretrained reference fingerprints sampled from different access points (APs) at different reference points (RPs) with known positions. However, in the calculation of signal distances between different RSS vectors, existing techniques fail to consider the fact that equal RSS differences at different RSS levels may not mean equal differences in geometrical distances in complex indoor environment. To address this issue, in this paper, we propose a feature-scaling-based k-nearest neighbor (FS-kNN) algorithm for achieving improved localization accuracy. In FS-kNN, we build a novel RSS-level-based FS model, which introduces RSS-level-based scaling weights in the computation of effective signal distances between signal vector reported by a MS and reference fingerprints in a radio map. Experimental results show that FS-kNN can achieve an average location error as low as 1.70 m, which is superior to existing work.",
Fractional Order AGC for Distributed Energy Resources Using Robust Optimization,"The applicability of fractional order (FO) automatic generation control (AGC) for power system frequency oscillation damping is investigated in this paper, employing distributed energy generation. The hybrid power system employs various autonomous generation systems like wind turbine, solar photovoltaic, diesel engine, fuel-cell, and aqua electrolyzer, along with other energy storage devices like the battery and flywheel. The controller is placed in a remote location while receiving and sending signals over an unreliable communication network with stochastic delay. The controller parameters are tuned using robust optimization techniques employing different variants of particle swarm optimization and are compared with the corresponding optimal solutions. An archival-based strategy is used for reducing the number of function evaluations for the robust optimization methods. The solutions obtained through the robust optimization are able to handle higher variation in the controller gains and orders without significant decrease in the system performance. This is desirable from the FO controller implementation point of view, as the design is able to accommodate variations in the system parameter, which may result due to the approximation of FO operators using different realization methods and order of accuracy. Also a comparison is made between the FO and the integer order controllers to highlight the merits and demerits of each scheme.","Robustness,
Optimization,
Hybrid power systems,
Frequency control,
Linear programming,
Automatic generation control,
Delays"
Mosaic: A low-cost mobile sensing system for urban air quality monitoring,"Air quality monitoring has attracted a lot of attention from governments, academia and industry, especially for PM2.5 due to its significant impact on our respiratory systems. In this paper, we present the design, implementation, and evaluation of Mosaic, a low cost urban PM2.5 monitoring system based on mobile sensing. In Mosaic, a small number of air quality monitoring nodes are deployed on city buses to measure air quality. Current low-cost particle sensors based on light-scattering, however, are vulnerable to airflow disturbance on moving vehicles. In order to address this problem, we build our air quality monitoring nodes, Mosaic-Nodes, with a novel constructive airflow-disturbance design based on a carefully tuned airflow structure and a GPS-assisted filtering method. Further, the buses used for system deployment are selected by a novel algorithm which achieves both high coverage and low computation overhead. The collected sensor data is also used to calculate the PM2.5 of locations without direct measurements by an existing inference model. We apply the Mosaic system in a testing urban area which includes more than 70 point-of-interests. Results show that the Mosaic system can accurately obtain the urban air quality with high coverage and low cost.",
Vector Attribute Profiles for Hyperspectral Image Classification,"Morphological attribute profiles are among the most prominent spectral-spatial pixel description methods. They are efficient, effective, and highly customizable multiscale tools based on hierarchical representations of a scalar input image. Their application to multivariate images in general and hyperspectral images in particular has been so far conducted using the marginal strategy, i.e., by processing each image band (eventually obtained through a dimension reduction technique) independently. In this paper, we investigate the alternative vector strategy, which consists in processing the available image bands simultaneously. The vector strategy is based on a vector-ordering relation that leads to the computation of a single max and min tree per hyperspectral data set, from which attribute profiles can then be computed as usual. We explore known vector-ordering relations for constructing such max trees and, subsequently, vector attribute profiles and introduce a combination of marginal and vector strategies. We provide an experimental comparison of these approaches in the context of hyperspectral classification with common data sets, where the proposed approach outperforms the widely used marginal strategy.","Hyperspectral imaging,
Context,
Gray-scale,
Morphology,
Vegetation"
Nano-Communication for Biomedical Applications: A Review on the State-of-the-Art From Physical Layers to Novel Networking Concepts,"Nano-communication-based devices have the potential to play a vital role in future healthcare technologies by improving the quality of human life. Its application in medical diagnostics and treatment has a great potential, because of its ability to access small and delicate body sites noninvasively, where conventional medical devices fall short. In this paper, the state of the art in this field is presented to provide a comprehensive understanding of current models, considering various communication paradigms, antenna design issues, radio channel models based on numerical and experimental analysis and network, and system models for such networks. Finally, open research areas are identified for the future directions within the field.","Nanobioscience,
Nanoscale devices,
Biological system modeling,
Monitoring,
Electromagnetics,
Biomedical monitoring,
Medical services"
A GPU parallel implementation of the Local Principal Component Analysis overcomplete method for DW image denoising,"We focus on the Overcomplete Local Principal Component Analysis (OLPCA) method, which is widely adopted as denoising filter. We propose a programming approach resorting to Graphic Processor Units (GPUs), in order to massively parallelize some heavy computational tasks of the method. In our approach, we design and implement a parallel version of the OLPCA, by using a suitable mapping of the tasks on a GPU architecture with the aim to investigate the performance and the denoising features of the algorithm. The experimental results show improvements in terms of GFlops and memory throughput.","Kernel,
Instruction sets,
Covariance matrices,
Graphics processing units,
Principal component analysis,
Three-dimensional displays,
Noise reduction"
Joint Optimal Design and Operation of Hybrid Energy Storage Systems,"The wide range of performance characteristics of storage technologies motivates the use of a hybrid energy storage system (HESS) that combines the best features of multiple technologies. However, HESS design is complex, in that it involves the choice of storage technologies, the sizing of each storage element, and deciding when to charge and discharge each underlying storage element (operating strategy). We formulate the problem of jointly optimizing the sizing and the operating strategy of an HESS that can be used for a large class of applications and storage technologies. Instead of a single set of storage element sizes, our approach determines the Pareto-optimal frontier of the sizes of the storage elements along with the corresponding optimal operating strategy. Thus, as long as the performance objective of a storage application (such as an off-grid microgrid) can be expressed as a linear combination of the underlying storage sizes, the optimal vector of storage sizes falls somewhere on this frontier. We present two case studies to illustrate our approach, demonstrating that a single storage technology is sometimes inadequate to meet application requirements, unlike an HESS designed using our approach. We also find simple, near-optimal, and practical operating strategies for these case studies, which allows us to gain several new engineering insights.",
"Energy Optimization in Commercial FPGAs with Voltage, Frequency and Logic Scaling","This paper investigates the energy reductions possible in commercially available FPGAs configured to support voltage, frequency and logic scalability combined with power gating. Voltage and frequency scaling is based on in-situ detectors that allow the device to detect valid working voltage and frequency pairs at run-time while logic scalability is achieved with partial dynamic reconfiguration. The considered devices are FPGA-processor hybrids with independent power domains fabricated in 28 nm process nodes. The test case is based on a number of operational scenarios in which the FPGA side is loaded with a motion estimation core that can be configured with a variable number of execution units. The results demonstrate that voltage scalability reduces power by up to 60 percent compared with nominal voltage operation at the same frequency. The energy analysis show that the most energy efficiency core configuration depends on the performance requirements. A low performance scenario shows that serial computation is more energy efficient than the parallel configuration while the opposite is true when the performance requirements increase. An algorithm is proposed to combine effectively adaptive voltage/logic scaling and power gating in the proposed system and application.","Field programmable gate arrays,
Voltage control,
Clocks,
Detectors,
Voltage measurement,
Monitoring,
Motion estimation"
Synthesis of approximate coders for on-chip interconnects using reversible logic,"On-chip coding provides a remarkable potential to improve the energy efficiency of on-chip interconnects. However, the logic design of the encoder/decoder faces a main challenge: the area and power overhead should be minimal while, at the same time, decodability has to be guaranteed. To address these problems, we propose the concept of approximate coding, where the coding function is partially specified and the synthesis algorithm has a higher flexibility to simplify the circuit. Since conventional synthesis methods are unsuitable here, we propose an alternative synthesis approach based on reversible logic. Experimental evaluations confirm the benefits of both, the proposed concept of approximate codings as well as the proposed design method.",
Higher-Order Image Co-segmentation,"A novel interactive image cosegmentation algorithm using likelihood estimation and higher order energy optimization is proposed for extracting common foreground objects from a group of related images. Our approach introduces the higher order clique's, energy into the cosegmentation optimization process successfully. A region-based likelihood estimation procedure is first performed to provide the prior knowledge for our higher order energy function. Then, a new cosegmentation energy function using higher order cliques is developed, which can efficiently cosegment the foreground objects with large appearance variations from a group of images in complex scenes. Both the quantitative and qualitative experimental results on representative datasets demonstrate that the accuracy of our cosegmentation results is much higher than the state-of-the-art cosegmentation methods.","Image segmentation,
Estimation,
Optimization,
Image color analysis,
Histograms,
Indexes,
Measurement"
Evaluation of occupational and professional profiles in Ecuadorian context based on guide of Knowledge SWEBOK and ontological model,"Bodies of Knowledge (BOK), contain the relevant knowledge for a discipline, and it is necessary for the development of the science, and application in the professional, and occupational profiles, and the possible incidence in the industry of Ecuador. In this paper, it is shown an evaluation of professional and occupational profiles based on standard Software Engineering Body of Knowledge SWEBOK 2004 (Spanish Version), and the development of ontological model, in order to obtain the necessary information to establish the relationship, and the criteria to evaluate the profiles based on the guide of knowledge.",
A Biologically Inspired Automatic System for Media Quality Assessment,"Photo aesthetic quality evaluation is a challenging task in artificial intelligence systems. In this paper, we propose a biologically inspired aesthetic descriptor that mimicks humans sequentially perceiving visually/semantically salientIn general, visually salient regions are perceived by low-level visual features, such as the high contrast between the foreground and the background objects; while semantically salient regions are perceived by high-level visual features such as human faces.regions in a photo. In particular, a weakly supervised learning paradigm is developed to project the local image descriptors into a low-dimensional semantic space. Then, each graphlet can be described by multiple types of visual features, both in low-level and in high-level. Since humans usually perceive only a few salient regions in a photo, a sparsity-constrained graphlet ranking algorithm is proposed that seamlessly integrates both the low-level and the high-level visual cues. Top-ranked graphlets are those visually/semantically prominent local aesthetic descriptors in a photo. They are sequentially linked into a path that simulates humans actively viewing process. Finally, we learn a probabilistic aesthetic measure based on such actively viewing paths (AVPs) from the training photos. Experimental results show that: 1) the AVPs are 87.65% consistent with real human gaze shifting paths, as verified by the eye-tracking data and 2) our aesthetic measure outperforms many of its competitors.","Videos,
Visualization,
Semantics,
Image color analysis,
Sparse matrices,
Feature extraction,
Biology"
A Cyber-Physical System for Environmental Monitoring,"This paper presents the development of a cyber-physical system that monitors the environmental conditions or the ambient conditions in indoor spaces at remote locations. The communication between the system's components is performed using the existent wireless infrastructure based on the IEEE 802.11 b/g standards. The resulted solution provides the possibility of logging measurements from locations all over the world and of visualizing and analyzing the gathered data from any device connected to the Internet. This work encompasses the complete solution, a cyber-physical system, starting from the physical level, consisting of sensors and the communication protocol, and reaching data management and storage at the cyber level. The experimental results show that the proposed system represents a viable and straightforward solution for environmental and ambient monitoring applications.",
Synthesizing Virtual Oscillators to Control Islanded Inverters,"Virtual oscillator control (VOC) is a decentralized control strategy for islanded microgrids where inverters are regulated to emulate the dynamics of weakly nonlinear oscillators. Compared to droop control, which is only well defined in sinusoidal steady state, VOC is a time-domain controller that enables interconnected inverters to stabilize arbitrary initial conditions to a synchronized sinusoidal limit cycle. However, the nonlinear oscillators that are elemental to VOC cannot be designed with conventional linear-control design methods. We address this challenge by applying averaging- and perturbation-based nonlinear analysis methods to extract the sinusoidal steady-state and harmonic behavior of such oscillators. The averaged models reveal conclusive links between real- and reactive-power outputs and the terminal-voltage dynamics. Similarly, the perturbation methods aid in quantifying higher order harmonics. The resultant models are then leveraged to formulate a design procedure for VOC such that the inverter satisfies standard ac performance specifications related to voltage regulation, frequency regulation, dynamic response, and harmonic content. Experimental results for a single-phase 750 VA, 120 V laboratory prototype demonstrate the validity of the design approach. They also demonstrate that droop laws are, in fact, embedded within the equilibria of the nonlinear-oscillator dynamics. This establishes the backward compatibility of VOC in that, while acting on time-domain waveforms, it subsumes droop control in sinusoidal steady state.","Inverters,
Oscillators,
Harmonic analysis,
Voltage control,
Steady-state,
Nonlinear dynamical systems,
Limit-cycles"
Compressed-Sensed-Domain L1-PCA Video Surveillance,"We consider the problem of foreground and background extraction from compressed-sensed (CS) surveillance videos that are captured by a static CS camera. We propose, for the first time in the literature, a principal component analysis (PCA) approach that computes directly in the CS domain the low-rank subspace of the background scene. Rather than computing the conventional L2-norm-based principal components, which are simply the dominant left singular vectors of the CS-domain data matrix, we compute the principal components under an L1-norm maximization criterion. The background scene is then obtained by projecting the CS measurement vector onto the L1 principal components followed by total-variation (TV) minimization image recovery. The proposed L1-norm procedure directly carries out low-rank background representation without reconstructing the video sequence and, at the same time, exhibits significant robustness against outliers in CS measurements compared to L2-norm PCA. An adaptive CS- L1-PCA method is also developed for low-latency video surveillance. Extensive experimental studies described in this paper illustrate and support the theoretical developments.","Principal component analysis,
Video surveillance,
Robustness,
Minimization,
Streaming media,
Computational complexity"
A privacy-aware Kinect-based system for healthcare professionals,"In this paper, we present a novel system for healthcare professionals to enhance their compliance with best practices and regulations using Microsoft Kinect sensors and smart watches while strictly protecting patient privacy. A core contribution of this study is a registration mechanism for a healthcare professional to explicitly give our system the permission to monitor his or her activities. Our system supports the use of multiple Kinect sensors for improved tracking accuracy and better coverage for large workplaces. Furthermore, we introduce a non-intrusive biometrics-based single sign-on mechanism to allow a user to register once for all Kinect sensors within each session. Finally, our system generates alerts reliably on detection of non-compliant activities and delivers the alerts discreetly to a consented healthcare professional via a designated smart watch according to his/her personal preference.","Medical services,
Biometrics (access control),
Sensor systems,
Intelligent sensors,
Tracking,
Computers"
Online Deformable Object Tracking Based on Structure-Aware Hyper-Graph,"Recent advances in online visual tracking focus on designing part-based model to handle the deformation and occlusion challenges. However, previous methods usually consider only the pairwise structural dependences of target parts in two consecutive frames rather than the higher order constraints in multiple frames, making them less effective in handling large deformation and occlusion challenges. This paper describes a new and efficient method for online deformable object tracking. Different from most existing methods, this paper exploits higher order structural dependences of different parts of the tracking target in multiple consecutive frames. We construct a structure-aware hyper-graph to capture such higher order dependences, and solve the tracking problem by searching dense subgraphs on it. Furthermore, we also describe a new evaluating data set for online deformable object tracking (the Deform-SOT data set), which includes 50 challenging sequences with full annotations that represent realistic tracking challenges, such as large deformations and severe occlusions. The experimental result of the proposed method shows considerable improvement in performance over the state-of-the-art tracking methods.","Target tracking,
Object tracking,
Visualization,
Robustness,
Support vector machines,
Image segmentation"
Original Symbol Phase Rotated Secure Transmission Against Powerful Massive MIMO Eavesdropper,"Massive multiple-input multiple-output (MIMO) has been extensively studied and considered as a key enabling technology for the fifth generation (5G) wireless communication systems, due to its potential to achieve high energy efficiency and spectral efficiency. As the concept of massive MIMO becomes more popular, it is plausible that the eavesdroppers will also employ massive antennas, which may remarkably enhance their ability to intercept the information. In this paper, motivated by the need to protect against the eavesdroppers equipped with powerful large antenna arrays, which has received scarce attention in the literature, a physical layer security approach called original symbol phase rotated (OSPR) secure transmission scheme is proposed to defend against eavesdroppers armed with unlimited antennas. The basic idea of the proposed OSPR scheme is to randomly rotate the phase of original symbols at the base station (BS) before they are transmitted, so that the massive MIMO eavesdropper will be confused by the intercepted signals, which may not represent the true information symbols. However, the legitimate users are able to infer the correct phase rotations and take proper inverse operations to recover the original symbols. We show that when the BS has a large enough, but finite number of antennas, the proposed OSPR scheme can achieve a considerable security performance in that the eavesdropper is unable to recover most of the original symbols, even with unlimited antennas. The process and the security performance of the proposed OSPR scheme are presented in detail. Simulation results are provided to further corroborate that the proposed OSPR scheme is a potential green secure transmission candidate technique for the future wireless networks.","MIMO,
Physical layer,
Security,
Antenna arrays,
Receiving antennas,
Transmitting antennas"
Cooperative In-Home Power Line Communication: Analyses Based on a Measurement Campaign,"This work focuses on analyses of cooperative protocols to enhance the performance of power line communication systems. Based on a measurement campaign and considering a sum power constraint, achievable data rates for amplify-and-forward (AF) and decode-and-forward (DF) protocols are analyzed. Similar investigations are performed for the maximum data rates attained using Hermitian-symmetric orthogonal frequency division multiplexing (HS-OFDM) together with equal gain combining (EGC), selection combining (SC) and maximal ratio combining (MRC) techniques. The influences of optimally and uniformly allocated transmission power and frequency bandwidth are are also analyzed and the efficiency of combination before and after equalization is compared. Results show that the relative distances among source, relay and destination nodes significantly impact system performance. Also, they reveal a range of total transmission power and bandwidth in which benefits can be verified. Among combining techniques, MRC and SC present similar results, but MRC offers a slightly better performance. In relation to computational complexity, SC is the most favorable. Maximum data rate analyses of HS-OFDM with frequency domain equalization based on zero forcing and minimum mean square error criteria show that the former scheme offers almost the same performance as the latter. Furthermore, it is shown that equalization after combination is more advantageous.","Protocols,
Relays,
Signal to noise ratio,
Frequency measurement,
Diversity reception,
Channel estimation,
Additive noise"
Improving Data Governance in Large Organizations through Ontology and Linked Data,"In the past decade, the role of data has increased exponentially from something that is queried or reported on, to becoming a true corporate asset. The same time period has also seen marked growth in corporate structural complexity. This combination has lead to information management challenges, as the data moving across a multitude of systems lends itself to a higher likelihood of impacting dependent processes and systems, should something go wrong or be changed. Many enterprise data projects are faced with low success rates and consequently subject to high amounts of scrutiny as senior leadership struggles to identify return on investment. While there are many tools and methods to increase a companies' ability to govern data, this research is based on the premise that you can not govern what you do not know. This lack of awareness of the corporate data landscape impacts the ability to govern data, which in turn impacts overall data quality within organizations. This paper seeks to propose a tools and techniques for companies to better gain an awareness of the landscape of their data, processes, and organizational attributes through the use of linked data, via the Resource Description Framework (RDF) and ontology. The outcome of adopting such techniques is an increased level of data awareness within the organization, resulting in improved ability to govern corporate data assets, and in turn increased data quality.","Ontologies,
Resource description framework,
Companies,
Data models,
Computer science"
A Lightweight Authenticated Communication Scheme for Smart Grid,"In smart grid, various kinds of sensors have been equipped in smart meters to collect real-time consumption data and execute the instructions from the power management center, which leads to a more robust and customer-friendly grid system. However, a smart grid enables the two-way communication between the electricity supplier and users, which brings security challenges to the smart grid. In this paper, we propose a lightweight authenticated communication scheme for the smart grid, which ensures a secure two-way communication between the smart meters and the neighborhood gateway. Since in the proposed scheme, the smart meters only need to execute the bitwise exclusive-OR operations to encrypt collected usage data, and Lagrange interpolation formula is used to authenticate the sender; the transmitted messages can be real-timely authenticated. On the other side, the storage burden and communication cost of the smart meters can be significantly reduced. The security analysis shows that the messages transmission between the smart meters and the neighborhood gateway can be done in a confidential and authenticated manner. Furthermore, compared with other existing schemes, the performance analysis demonstrates that the proposed scheme has both lower storage and communication cost.","Smart meters,
Smart grids,
Cryptography,
Intelligent sensors,
Real-time systems"
Metaheuristics for the Lifetime of WSN: A Review,"The importance and the possibilities of wireless sensor networks (WSNs) are now quite clear, because they can be found in all kinds of applications, from those in our daily life to those in the military. However, the limited energy of sensors, i.e., the lifetime problems of WSN, has attracted many researchers from different disciplines. Several recent studies showed that metaheuristic algorithms provide promising solutions to the lifetime problems. This paper begins with a brief review of the lifetime problems and the basic ideas of metaheuristic algorithms. Then, the detailed descriptions of metaheuristic algorithms for solving the lifetime problems from the perspectives of problems and algorithms are given. Some simple examples for illustrating how metaheuristic algorithms can be used to solve the lifetime problems and their performance are given. Several important open and possible research issues are discussed to provide the future research trends of this area.","Wireless sensor networks,
Sensors,
Nominations and elections,
Heuristic algorithms,
Market research,
Computer science,
Home appliances"
An Information Fusion Fault Diagnosis Method Based on Dimensionless Indicators With Static Discounting Factor and KNN,"For petrochemical rotating machinery and equipment, the reliability of the diagnostic evidence is affected by uncertain factors, causing conflicts between evidence provided by the various information sources, and thus affecting the validity of the fault diagnosis. This paper presents an information fusion fault diagnosis method that is based on a static discounting factor and combines K-nearest neighbors (KNNs) with dimensionless indicators. The method uses evidence reasoning to process the uncertainty and accuracy of the information through the KNN algorithm and dimensionless indicators to turn petrochemical machinery sensor input signals into the reliability of structure framework, according to the static discount factor, after correction evidence and evidence theory formula was used to fusion and, based on the fusion result, the fault type diagnosis decision-making. Experimental results show that the method can effectively reduce the influence of unreliable factors on the fusion results, thus allowing more accurate decision making.","Indexes,
Fault diagnosis,
Machinery,
Sensors,
Fuses,
Vibrations"
An Active Wideband and Wide-Angle Electromagnetic Absorber at Microwave Frequencies,"Two-dimensional (2-D) metamaterials (MTMs) can be used to create perfect electromagnetic absorbers. In this letter, a novel active MTM absorber with non-Foster loads is proposed. For obliquely incident plane waves with both transverse-electric (TE) and transverse-magnetic (TM) polarizations, its effective circuit model is analytically demonstrated, accounting the material losses. Based on the circuit model, a stability characterization is introduced to give the design principles for the non-Foster elements to achieve a wideband and wide-angle metamaterial absorber (MA). These active elements are achieved by a two-port non-Foster circuit based on the resonant tunneling diodes. For the purpose of verification, a sample active MA design is presented, exhibiting a high electromagnetic absorption rate for wideband and wide-angle incidence for both TE and TM polarizations at microwave frequencies, as compared to its passive counterpart.","Substrates,
Integrated circuit modeling,
Impedance,
Circuit stability,
Stability criteria,
Wideband"
Modeling and Analysis of Wireless Channels via the Mixture of Gaussian Distribution,"In this paper, we consider a unified approach to model wireless channels by the mixture of Gaussian (MoG) distribution. The proposed approach provides an accurate approximation for the envelope and the signal-to-noise ratio (SNR) distributions of wireless fading channels. Simulation results have shown that the proposed model can accurately characterize multipath and composite fading channels. We utilize the well-known expectation-maximization (EM) algorithm to estimate the parameters of the MoG distribution and further utilize the Bayesian information criterion (BIC) to determine the number of mixture components automatically. We employ the Kullback-Leibler (KL) divergence and the mean-square-error (MSE) criteria to demonstrate that the proposed distribution provides both high accuracy and low computational complexity. Additionally, we provide closed-form expressions or approximations for several performance metrics used in wireless communication systems, including the moment generating function (MGF), the raw moments, the amount of fading (AF), the outage probability, the average channel capacity, and the probability of energy detection for cognitive radio (CR). Numerical analysis and Monte Carlo simulation results are presented to corroborate the analytical results.","Fading,
Wireless communication,
Closed-form solutions,
Analytical models,
Signal to noise ratio,
Approximation methods,
Electronic mail"
A New Topology of Higher Order Power Filter for Single-Phase Grid-Tied Voltage-Source Inverters,"In order to reduce the influence of the grid harmonic currents and voltages, harmonic compensation is regularly implemented for a grid-tied inverter. In this study, a new topology of a higher order power filter for single-phase grid-tied voltage-source inverters, named L(LCL)2, is presented. The subscript is added to the name to prevent confusion with the LLCL filter. In the proposed design, the inverter side inductance is divided into three parts, and the grid side inductor is removed. Also, an additional resonant branch at the double of the switching frequency is added to the traditional LLCL filter to attenuate high-frequency harmonics. The overall inductance of the recommended filter is smaller than the LLCL filter. A comparative study and discussions on the subject of the traditional LLCL filter and the proposed L(LCL)2 filter have been conducted and assessed through an experimental hardware implementation on a 700 W, 120 V/60 Hz single-phase grid-tied inverter. Furthermore, a straightforward engineering design benchmark is suggested to discover parameters of the L(LCL)2 filter. Moreover, stability analysis, loss analysis and an optimization of the L(LCL)2 filter parameters have been conducted in this study. The analysis shows that in comparison with the LLCL filter, the L(LCL)2 filter not only has lower voltage drop and less total inductor size, but also has improved performance in decreasing high-order current harmonics.","Inverters,
Harmonic analysis,
Switching frequency,
Power harmonic filters,
Inductors,
Topology"
Fault-tolerance improvement for core and edge of IP network,"The fault-tolerance improvement for the core and edge of the IP network is proposed in the given paper. In solving the technological problem of the fault-tolerant IP routing during minimization of the object function it is necessary to solve either quadratic programming problem or mixed integer nonlinear programming problem with limitations defined. The proposed model also provides the support of load balancing functions on the virtual router interfaces and fault-tolerant routing in the core of the IP network with protection schemes of link, node and path, which has a positive impact on the availability and productivity of communications system as a whole.","Routing,
IP networks,
Fault tolerance,
Fault tolerant systems,
Routing protocols"
Wireless Sensor-Networks Conditions Monitoring and Fault Diagnosis Using Neighborhood Hidden Conditional Random Field,"This paper formulates wireless sensor networks (WSNs) fault diagnosis problem as a pattern-classification problem and introduces a newly developed algorithm, neighborhood hidden conditional random field (NHCRF), for determining hidden states between sensors. The health conditions of WSN are determined by using the NHCRF model to estimate the posterior probability of different faulty scenarios. The NHCRF model can improve the WSN fault diagnosis, because it has relaxed the independence assumption of the hidden Markov model. To enhance the robustness and antinoise ability of the NHCRF, the concept of nearest neighbors is used when estimating dependencies. In this paper, a 200-sensor-node WSN is used to show that the proposed NHCRF method can deliver excellent and effective results for WSN-health diagnosis. Our study also presents thorough results on different types of WSN traffic, the free traffic, light traffic, and heavy traffic. Comparative results indicate that our method can deliver superior classification performance compared with other methods.","Wireless sensor networks,
Hidden Markov models,
Fault diagnosis,
Sensor phenomena and characterization,
Monitoring,
Training"
Automatic Building Detection From High-Resolution Satellite Images Based on Morphology and Internal Gray Variance,"Automatic building extraction remains an open research topic in digital photogrammetry and remote sensing. While many algorithms have been proposed for building extraction, none of them solve the problem completely. This is even a greater challenge in urban areas, due to high-object density and scene complexity. Standard approaches do not achieve satisfactory performance, especially with high-resolution satellite images. This paper presents a novel framework for reliable and accurate building extraction from high-resolution panchromatic images. Proposed framework exploits the domain knowledge (spatial and spectral properties) about the nature of objects in the scene, their optical interactions and their impact on the resulting image. The steps in the approach consist of 1) directional morphological enhancement; 2) multiseed-based clustering technique using internal gray variance (IGV); 3) shadow detection; 4) false alarm reduction using positional information of both building edge and shadow; and 5) adaptive threshold based segmentation technique. We have evaluated the algorithm using a variety of images from IKONOS and QuickBird satellites. The results demonstrate that the proposed algorithm is both accurate and efficient.","Buildings,
Feature extraction,
Satellites,
Image resolution,
Clustering algorithms,
Remote sensing,
Image segmentation"
Data Randomization and Cluster-Based Partitioning for Botnet Intrusion Detection,"Botnets, which consist of remotely controlled compromised machines called bots, provide a distributed platform for several threats against cyber world entities and enterprises. Intrusion detection system (IDS) provides an efficient countermeasure against botnets. It continually monitors and analyzes network traffic for potential vulnerabilities and possible existence of active attacks. A payload-inspection-based IDS (PI-IDS) identifies active intrusion attempts by inspecting transmission control protocol and user datagram protocol packet's payload and comparing it with previously seen attacks signatures. However, the PI-IDS abilities to detect intrusions might be incapacitated by packet encryption. Traffic-based IDS (T-IDS) alleviates the shortcomings of PI-IDS, as it does not inspect packet payload; however, it analyzes packet header to identify intrusions. As the network's traffic grows rapidly, not only the detection-rate is critical, but also the efficiency and the scalability of IDS become more significant. In this paper, we propose a state-of-the-art T-IDS built on a novel randomized data partitioned learning model (RDPLM), relying on a compact network feature set and feature selection techniques, simplified subspacing and a multiple randomized meta-learning technique. The proposed model has achieved 99.984% accuracy and 21.38 s training time on a well-known benchmark botnet dataset. Experiment results demonstrate that the proposed methodology outperforms other well-known machine-learning models used in the same detection task, namely, sequential minimal optimization, deep neural network, C4.5, reduced error pruning tree, and randomTree.","Feature extraction,
Computational modeling,
Accuracy,
Partitioning algorithms,
Clustering algorithms,
Intrusion detection,
Data models"
Framework to Evaluate M-Learning Systems: A Technological and Pedagogical Approach,"This paper presents the analysis of recent research on mobile learning and usability areas, applying a systematic mapping study. The aim is to understand the tendencies and needs in the m-learning field. The results demonstrate that research in the area has grown significantly since 2013, and we identify a necessity when we see that not all the m-learning applications have used usability tests; we also did not find guidelines or frameworks to evaluate them. With these results and tendencies, we propose an evaluation framework for m-learning applications, considering pedagogical usability and user interface usability, to improve the quality of m-learning applications.","Usability,
Mobile communication,
Education,
Context,
Smart phones,
Databases"
Proactive Caching for Mobile Video Streaming in Millimeter Wave 5G Networks,"Mobile video streaming is fundamental to advanced applications in the fifth generation (5G) networks. Millimeter wave (mmWave) communication represents a leading 5G technology, which provides rich bandwidth and, therefore, great potentials for high-quality mobile video streaming. However, mobile video streaming in mmWave 5G networks faces fundamental challenges due to mmWave antenna directivity and high user mobility. As such, users typically have short connection durations and frequent handoffs, making video streaming suffer from long handoff delays and connection latency. In this paper, we tackle the issues by developing a caching-based mmWave framework, which precaches video contents at the base station for handoff users and thus significantly reduces the connection and retrieval delays. As a result, high-mobility users with frequent handoffs can enjoy continuous high-quality video streaming. Specifically, we model the proposed system as a cache management problem and attain optimal video streaming quality by using Markov decision process to dynamically allocate proper cache memory space of each base station to mobile users. A cell-by-cell decomposition method is proposed to solve the dynamic programming problem with significantly reduced computational complexity. Using extensive simulations, we demonstrate that the proposed solution can effectively maintain high-quality mobile video streaming for high-mobility 5G users moving among mmWave small cells with directional antenna.","Streaming media,
Base stations,
5G mobile communication,
Mobile computing,
Cache memory,
Directional antennas"
Design Concepts for a Fluid-Filled Three-Phase Axial-Peg-Style Electrostatic Rotating Machine Utilizing Variable Elastance,"Rotating electric machinery is usually constructed of iron/steel laminations, copper windings, and permanent magnets. This paper investigates fluid-filled, electrostatic rotating machines for the ultimate ambition of transitioning fundamental magnetic materials to dielectrics in order to reduce production costs. The study of the axial-peg-style electrostatic rotating machine focuses on basic geometric and material knowledge and the creation of design tools. An axial-peg machine possesses interdigitated pegs (cylinders) that come into, and out of, radial alignment as the machine rotates causing variable capacitance between the stator and rotor. A prototype with peak torque of 0.7 Nm and gap field strength of 15 kV/mm was constructed. The specific torque density of the machine is 0.101 Nm/kg, comparable to fractional horsepower NEMA class induction machines. This was achieved by filling the machine with a dielectric fluid, whose relative permittivity is 7.1, rather than the ultra-high vacuum typically employed in canonical electrostatics. Experimental measurements presented include angular capacitance, peak torque, and torque-per-volt under stall conditions. Construction techniques are discussed in detail.","Electrostatics,
Magnetic flux,
Rotors,
Stators,
Torque,
Fluids"
Models of Monocular and Binocular Visual Perception in Quality Assessment of Stereoscopic Images,"Assessing quality of experience (QoE) for three-dimensional (3-D) video is challenging. In this paper, we propose a new full-reference stereoscopic image quality metric, by simulating the behaviors of visual perception with simple and complex receptive field properties and constructing the models of monocular and binocular visual perception. To be more specific, the stereoscopic images are first classified into noncorresponding and corresponding regions. Then, monocular energy responses are generated for the noncorresponding region based on stimuli from different spatial frequencies and orientations, and binocular energy responses are generated for the corresponding region based on stimuli from different spatial frequencies, orientations and disparities, respectively. Finally, gradient similarities between the energy responses of the original and distorted stereoscopic images are measured for noncorresponding and corresponding regions, respectively, and all results are fused to get an overall score. Experiments on three 3-D image quality assessment (IQA) databases demonstrate that in comparison with the most related existing methods, the devised algorithm achieves higher agreement with subjective assessment, making it better suited for the evaluation and optimization of stereoscopic image processing algorithms.","Three-dimensional displays,
Stereo image processing,
Visual perception,
Visualization,
Image quality,
Quality assessment,
Measurement"
Encoder-Driven Inpainting Strategy in Multiview Video Compression,"In free viewpoint video systems, a user has the freedom to select a virtual view from which an image of the 3D scene is rendered, and the scene is commonly represented by color and depth images of multiple nearby viewpoints. In such representation, there exists data redundancy across multiple dimensions: 1) a 3D voxel may be represented by pixels in multiple viewpoint images (inter-view redundancy); 2) a pixel patch may recur in a distant spatial region of the same image due to self-similarity (inter-patch redundancy); and 3) pixels in a local spatial region tend to be similar (inter-pixel redundancy). It is important to exploit these redundancies during inter-view prediction toward effective multiview video compression. In this paper, we propose an encoder-driven inpainting strategy for inter-view predictive coding, where explicit instructions are transmitted minimally, and the decoder is left to independently recover remaining missing data via inpainting, resulting in lower coding overhead. In particular, after pixels in a reference view are projected to a target view via depth-image-based rendering at the decoder, the remaining holes in the target view are filled via an inpainting process in a block-by-block manner. First, blocks are ordered in terms of difficulty-to-inpaint by the decoder. Then, explicit instructions are only sent for the reconstruction of the most difficult blocks. In particular, the missing pixels are explicitly coded via a graph Fourier transform or a sparsification procedure using discrete cosine transform, leading to low coding cost. For blocks that are easy to inpaint, the decoder independently completes missing pixels via template-based inpainting. We apply our proposed scheme to frames in a prediction structure defined by JCT-3V where inter-view prediction is dominant, and experimentally we show that our scheme achieves up to 3-dB gain in peak-signal-to-noise-ratio in reconstructed image quality over a comparable 3D-High Efficiency Video Coding implementation using fixed 16
×
16 block size.","Decoding,
Encoding,
Artificial intelligence,
Image coding,
Redundancy,
Image reconstruction,
Video coding"
Performance Analysis of Touch-Interaction Behavior for Active Smartphone Authentication,"The increasing use of touchscreen smartphones to access sensitive and privacy data has given rise to the need of secure and usable authentication technique. Smartphone users have their own unique behavioral characteristics when performing touch operations. These personal characteristics are reflected on different rhythm, strength, and angle preferences of touch-interaction behavior. This paper investigates the reliability and applicability on the usage of users' touch-interaction behavior for active authentication on smartphones. For each common type of touch operations, both static and dynamic features are extracted and analyzed for fine-grained characterization of users' touch behavior. Classification techniques (nearest neighbor, neural network, support vector machine, and random forest) are applied to the feature space for performing the task of active authentication. Analyses are conducted using data from around 134 900 touch operations of 71 participants in real-world scenarios, and the authentication performance is evaluated across various types of touch operations, varying operation lengths, different application tasks, and different application scenarios. The extensive experimental results are included to show that touch-interaction behavior exhibits sufficient discriminability and stability among smartphone users for active authentication, and achieves equal-error rates between 1.72% and 9.01% for different types of touch operations with the operation length of 11; the authentication accuracies improve when having long observation or small timespan between the training and testing phases, and express more reliably and stably in a specific task than in the free task. We also discuss a number of avenues for additional research that we believe are necessary to advance the state-of-the-art in this area.","Authentication,
Feature extraction,
Support vector machines,
Stability analysis,
Sensors,
Accuracy"
Effective Defense Schemes for Phishing Attacks on Mobile Computing Platforms,"Recent years have witnessed the increasing threat of phishing attacks on mobile computing platforms. In fact, mobile phishing is particularly dangerous due to the hardware limitations of mobile devices and the habits of mobile users. In this paper, we did a comprehensive study on the security vulnerabilities caused by mobile phishing attacks, including web page phishing attacks, application phishing attacks, and account registry phishing attacks. Existing schemes designed for web phishing attacks on personal computers (PCs) cannot effectively address the various phishing attacks on mobile devices. Hence, we propose MobiFish, which is a novel automated lightweight antiphishing scheme for mobile platforms. MobiFish verifies the validity of web pages, applications, and persistent accounts by comparing the actual identity to the claimed identity. MobiFish has been implemented on a Nexus 4 smartphone running the Android 4.2 operating system. We experimentally evaluate the performance of MobiFish with 100 phishing URLs and corresponding legitimate URLs, as well as phishing apps. The results show that MobiFish is very effective in detecting phishing attacks on mobile phones.","Mobile communication,
Web pages,
Uniform resource locators,
Browsers,
HTML,
Twitter,
Mobile handsets"
A Balanced Filtering Branch-Line Coupler,"A balanced filtering branch-line coupler is proposed for the first time. The proposed design is realized by coupled microstrip lines and coupled-line-fed coupling structures. Based on this, the proposed design not only exhibits the functions of power dividing and filtering for differential-mode signals, but also can suppress the common-mode noise/signal and be easily connected with other balanced circuits. The dimension of the proposed design is similar to that of the traditional single-ended design. A prototype of the balanced filtering branch-line coupler centered at 1.87 GHz with the size of 0.33 λg × 0.42 λg is fabricated, where λg is the guided wavelength at the center frequency. The measured results exhibit the maximum insertion loss of 1.4 dB with a 3-dB fractional bandwidth of 3.5%.","Couplers,
Couplings,
Microstrip,
Bandwidth,
Power dividers,
Ports (Computers),
Microwave circuits"
DoA Estimation and Capacity Analysis for 3-D Millimeter Wave Massive-MIMO/FD-MIMO OFDM Systems,"With the promise of meeting future capacity demands, 3-D massive-MIMO/full dimension multiple-input-multiple-output (FD-MIMO) systems have gained much interest in recent years. Apart from the huge spectral efficiency gain, 3-D massive-MIMO/FD-MIMO systems can also lead to significant reduction of latency, simplified multiple access layer, and robustness to interference. However, in order to completely extract the benefits of the system, accurate channel state information is critical. In this paper, a channel estimation method based on direction of arrival (DoA) estimation is presented for 3-D millimeter wave massive-MIMO orthogonal frequency division multiplexing (OFDM) systems. To be specific, the DoA is estimated using estimation of signal parameter via rotational invariance technique method, and the root mean square error of the DoA estimation is analytically characterized for the corresponding MIMO-OFDM system. An ergodic capacity analysis of the system in the presence of DoA estimation error is also conducted, and an optimum power allocation algorithm is derived. Furthermore, it is shown that the DoA-based channel estimation achieves a better performance than the traditional linear minimum mean squared error estimation in terms of ergodic throughput and minimum chordal distance between the subspaces of the downlink precoders obtained from the underlying channel and the estimated channel.","MIMO,
Antenna arrays,
Direction-of-arrival estimation,
OFDM,
Channel estimation,
Estimation,
Three-dimensional displays"
Range and Motion Estimation of a Monocular Camera Using Static and Moving Objects,"We propose a method of estimating the motion of a monocular camera looking at moving objects and their range. Unlike the previous studies where the camera and object motion should be constrained in estimating structure and motion (SaM) of moving objects, the proposed method do not require those constraints even though only a monocular camera is used. By first arranging the SaM dynamics in terms of the measurable states, we design robust nonlinear observers in a sequential way for both static (stationary) and dynamic (moving) objects. Through the combination of these estimates obtained by nonlinear observers, the reconstruction of the 3-D structure of the dynamic objects can be achieved using just 2-D images of a monocular camera. Simulations are performed in the case of changing camera and object velocities, such that the advantages of the proposed method can be clearly demonstrated.","Cameras,
Dynamics,
Observers,
Robot vision systems,
Robustness,
Trajectory"
Dynamic Dead-Time Optimization and Phase Skipping Control Techniques for Three-Phase Microinverter Applications,This paper introduces a combination of two proposed efficiency improvement techniques for a microinverter with current mode control zero-voltage switching output stages. The first technique is dynamic dead-time optimization wherein pulse width modulation dead times are dynamically adjusted as a function of load current. The second method is advanced phase skipping control which maximizes inverter efficiency by controlling power on individual phases depending on the available input power from the photovoltaic source. Neither of the techniques requires any additional circuit components and both can be easily implemented in digital controller firmware. The two techniques were designed and implemented in a 400-W three-phase microinverter prototype. The experimental results validate the theoretical analysis of these techniques and demonstrate that a significant efficiency improvement can be achieved by combining the two proposed control techniques.,"Inverters,
MOSFET,
Switches,
Inductors,
Zero voltage switching,
Optimization,
Capacitors"
The Visual Causality Analyst: An Interactive Interface for Causal Reasoning,"Uncovering the causal relations that exist among variables in multivariate datasets is one of the ultimate goals in data analytics. Causation is related to correlation but correlation does not imply causation. While a number of casual discovery algorithms have been devised that eliminate spurious correlations from a network, there are no guarantees that all of the inferred causations are indeed true. Hence, bringing a domain expert into the casual reasoning loop can be of great benefit in identifying erroneous casual relationships suggested by the discovery algorithm. To address this need we present the Visual Causal Analyst - a novel visual causal reasoning framework that allows users to apply their expertise, verify and edit causal links, and collaborate with the causal discovery algorithm to identify a valid causal network. Its interface consists of both an interactive 2D graph view and a numerical presentation of salient statistical parameters, such as regression coefficients, p-values, and others. Both help users in gaining a good understanding of the landscape of causal structures particularly when the number of variables is large. Our framework is also novel in that it can handle both numerical and categorical variables within one unified model and return plausible results. We demonstrate its use via a set of case studies using multiple practical datasets.","Correlation,
Visualization,
Layout,
Linear regression,
Optimization,
Inference algorithms"
Delay-Energy Tradeoff in Multicast Scheduling for Green Cellular Systems,"Multicast transmission based on real-time network state information is a resource-friendly technique to improve the energy efficiency and reduce the traffic burden for cellular systems. This paper evaluates the effectiveness of this technique for downlink transmissions. In particular, a scenario is considered in which multiple mobile users (MUs) asynchronously request to download one common message locally cached at a base station (BS). Due to the randomness of both the channel conditions and the request arrivals from the MUs, the BS may choose to intelligently hold the arrived requests, especially when the channel conditions are bad or the number of requests is small, and then serve them in one shot later via multicasting. Clearly it is of great interest to balance the delay (incurred by holding the requests) and the energy efficiency (EE, defined as the energy cost per request), and this motivates us to quantify the fundamental tradeoff for the proposed “hold-then-serve” scheme. For the scenario with single channel and unit message sizes, it is shown that for a fixed channel bandwidth, the delay-EE tradeoff reduces to judiciously choosing the optimal stopping rule for when to serve all the arrived requests, where the effect of the bandwidth on the achievable delay-EE region is discussed further. By using optimal stopping theory, it is shown that the optimal stopping rule exists for general Markov channel models and request arrival processes. Particularly, for the hard deadline and proportional delay penalty cases, it is shown that the optimal stopping rule exhibits a threshold structure, and the corresponding threshold in the former case is time varying while in the latter case it is a constant. Finally, for the more general scenario with multiple channels and arbitrary message sizes, the optimal scheduling is formulated as a Markov decision process problem, where some efficient suboptimal scheduling algorithms are proposed.","Delays,
Multicast communication,
Bandwidth,
Markov processes,
Optimal scheduling,
Energy consumption,
Scheduling"
Robust Perturbed Output Regulation and Synchronization of Nonlinear Heterogeneous Multiagents,"The conventional robust output regulation problem aims to achieve reference tracking and disturbance rejection in the presence of system uncertainties while the references and disturbances are generated by an autonomous exosystem. When the exosystem is perturbed by an external event, a novel robust perturbed output regulation problem is formulated and solved in this paper. The formulation arises from a class of synchronization problem of multiple agents. With the aid of a new reference model-based control framework, the proposed solution to the robust perturbed output regulation problem leads to a decentralized control algorithm for synchronization of multiple agents of nonlinear heterogeneous dynamics.","Synchronization,
Robustness,
Uncertainty,
Multi-agent systems,
Protocols,
Nonlinear dynamical systems"
Scalable Cache Management for ISP-Operated Content Delivery Services,"Content delivery networks (CDNs) have been the prevalent method for the efficient delivery of content across the Internet. Management operations performed by CDNs are usually applied only based on limited information about Internet Service Provider (ISP) networks, which can have a negative impact on the utilization of ISP resources. To overcome these issues, previous research efforts have been investigating ISP-operated content delivery services, by which an ISP can deploy its own in-network caching infrastructure and implement its own cache management strategies. In this paper, we extend our previous work on ISP-operated content distribution and develop a novel scalable and efficient distributed approach to control the placement of content in the available caching points. The proposed approach relies on parallelizing the decision-making process and the use of network partitioning to cluster the distributed decision-making points, which enables fast reconfiguration and limits the volume of information required to take reconfiguration decisions. We evaluate the performance of our approach based on a wide range of parameters. The results demonstrate that the proposed solution can outperform previous approaches in terms of management overhead and complexity while offering similar network and caching performance.","Servers,
Decision making,
Internet,
Complexity theory,
Distributed management,
Content management,
Content distribution networks"
Development of IoT based smart security and monitoring devices for agriculture,"Agriculture sector being the backbone of the Indian economy deserves security. Security not in terms of resources only but also agricultural products needs security and protection at very initial stage, like protection from attacks of rodents or insects, in fields or grain stores. Such challenges should also be taken into consideration. Security systems which are being used now a days are not smart enough to provide real time notification after sensing the problem. The integration of traditional methodology with latest technologies as Internet of Things and Wireless Sensor Networks can lead to agricultural modernization. Keeping this scenario in our mind we have designed, tested and analyzed an 'Internet of Things' based device which is capable of analyzing the sensed information and then transmitting it to the user. This device can be controlled and monitored from remote location and it can be implemented in agricultural fields, grain stores and cold stores for security purpose. This paper is oriented to accentuate the methods to solve such problems like identification of rodents, threats to crops and delivering real time notification based on information analysis and processing without human intervention. In this device, mentioned sensors and electronic devices are integrated using Python scripts. Based on attempted test cases, we were able to achieve success in 84.8% test cases.","Security,
Sensors,
Internet of things,
Rodents,
Agriculture,
Monitoring,
Cameras"
An 11b 450 MS/s Three-Way Time-Interleaved Subranging Pipelined-SAR ADC in 65 nm CMOS,"This paper presents an 11 bit 450 MS/s three-way time-interleaved (TI) subranging pipelined-successive approximation register (SAR) analog-to-digital converter (ADC). The proposed hybrid architecture combines the design benefits of different ADC structures to achieve a high conversion rate and accuracy with good power efficiency. The design employs multiple offset calibration schemes to compensate the offset mismatches at each stage. The solutions require less calibration efforts, thus allowing the ADC to achieve a compact area. Furthermore, a dynamic SAR controller embedded with error-decision-correction (EDC) logic is proposed to reduce large transition error. Measurement results on a 65 nm CMOS prototype operated at 450 MS/s and 1.2 V supply show 7.4 mW total power consumption with a peak signal-to-noise distortion ratio (SNDR) of 60.8 dB and an FOM of 32 fJ/conv.step at Nyquist.",
Reflectance and Illumination Recovery in the Wild,"The appearance of an object in an image encodes invaluable information about that object and the surrounding scene. Inferring object reflectance and scene illumination from an image would help us decode this information: reflectance can reveal important properties about the materials composing an object; the illumination can tell us, for instance, whether the scene is indoors or outdoors. Recovering reflectance and illumination from a single image in the real world, however, is a difficult task. Real scenes illuminate objects from every visible direction and real objects vary greatly in reflectance behavior. In addition, the image formation process introduces ambiguities, like color constancy, that make reversing the process ill-posed. To address this problem, we propose a Bayesian framework for joint reflectance and illumination inference in the real world. We develop a reflectance model and priors that precisely capture the space of real-world object reflectance and a flexible illumination model that can represent real-world illumination with priors that combat the deleterious effects of image formation. We analyze the performance of our approach on a set of synthetic data and demonstrate results on real-world scenes. These contributions enable reliable reflectance and illumination inference in the real world.","Lighting,
Image color analysis,
Brain modeling,
Computational modeling,
Joints,
Estimation,
Analytical models"
"Improving Bayesian Reasoning: The Effects of Phrasing, Visualization, and Spatial Ability","Decades of research have repeatedly shown that people perform poorly at estimating and understanding conditional probabilities that are inherent in Bayesian reasoning problems. Yet in the medical domain, both physicians and patients make daily, life-critical judgments based on conditional probability. Although there have been a number of attempts to develop more effective ways to facilitate Bayesian reasoning, reports of these findings tend to be inconsistent and sometimes even contradictory. For instance, the reported accuracies for individuals being able to correctly estimate conditional probability range from 6% to 62%. In this work, we show that problem representation can significantly affect accuracies. By controlling the amount of information presented to the user, we demonstrate how text and visualization designs can increase overall accuracies to as high as 77%. Additionally, we found that for users with high spatial ability, our designs can further improve their accuracies to as high as 100%. By and large, our findings provide explanations for the inconsistent reports on accuracy in Bayesian reasoning tasks and show a significant improvement over existing methods. We believe that these findings can have immediate impact on risk communication in health-related fields.","Visualization,
Bayes methods,
Cognition,
Accuracy,
Diseases,
Breast cancer,
Sociology"
Mechanics of Tissue Cutting During Needle Insertion in Biological Tissue,"In percutaneous needle insertions, cutting forces at the needle tip deflect the needle and increases targeting error. Thus, modeling needle-tissue interaction in biological tissue is essential for accurate robotics-assisted needle steering. In this letter, dynamics of needle tip interaction with inhomogeneous biological tissue is described and the effects of insertion velocity, tissue mechanical characteristics, and needle geometry on tissue cutting force are studied. Needle interaction with biological tissue is divided into three distinct events and modeled. 1) Initial tissue puncturing, which starts by soft tissue deformation and continues until a crack is formed in the tissue. Employing a viscoelastic model of fracture initiation we have predicted the maximum puncturing force and force-displacement response of a needle in contact with a tissue. 2) Tissue cutting, which follows the crack propagation in tissue and is predicted using a novel energy-based fracture model. The model takes account of the needle tip geometry and the tissue mechanical characteristics. 3) Friction between tissue and needle shaft is estimated during needle insertion and retraction using a needle-tissue friction model. Using a needle driving robot ex vivo experiments are performed on a porcine tissue sample to identify the model parameters and validate the analytical predictions offered by the models.","Needles,
Force,
Biological tissues,
Biological system modeling,
Predictive models,
Friction,
Shafts"
Dynamic Gate Stress-Induced V_{\text {TH}} Shift and Its Impact on Dynamic R_{\mathrm {ON}} in GaN MIS-HEMTs,"Very fast transients of VTH shift and their impact on RON under dynamic AC (1 k-1 MHz) positive gate stress in depletion-mode (D-mode) metal-insulator-semiconductor high-electron-mobility transistors (MIS-HEMTs) are revealed. We achieve data acquisition within 120 ns right after each stress pulse throughout the entire stress time range from 10-7 up to 103 s, by virtue of a short stress-to-sense delay of ~100 ns and high sampling rate up to 50 MSa/s. Despite the considerable VTH shift, its impact on RON in D-mode MIS-HEMT is modest, if the device is under sufficient gate overdrive. Furthermore, VTH shift and the consequent RON increase under dynamic stress, which are more relevant to high-frequency switching operation, exhibits frequency dependence within 1 k-1 MHz and is always smaller than that under conventionally used static (constant) stress.",
"USE: A Universal, Scalable, and Efficient Clocking Scheme for QCA","Quantum-dot cellular automata (QCA) is an emerging technology, conceived in face of nanoscale limitations of CMOS circuits, with exceptional integration density, impressive switching frequency, and remarkable low-power characteristics. Several of the current challenges toward the progress of QCA technology is related to the automation of the design process and integration into existing design flows. In this regard, this paper proposes the universal, scalable, efficient (USE), and easily manufacturable clocking scheme. It solves one of the most limiting factors of existing clock schemes, the implementation of feedback paths and easy routing of QCA-based circuits. Consequently, USE facilitates considerably the development of standard cell libraries and design tools for this technology, besides avoiding thermodynamics problems. Case studies presented in this paper reveal an area reduction of up to factor 5 and delay decrease by up to factor 3 in comparison with an existing advanced clocking scheme.","Wires,
Computer architecture,
Quantum dots,
Microprocessors,
Automata,
Adders"
Lazy sequentialization for TSO and PSO via shared memory abstractions,"Lazy sequentialization is one of the most effective approaches for the bounded verification of concurrent programs. Existing tools assume sequential consistency (SC), thus the feasibility of lazy sequentializations for weak memory models (WMMs) remains untested. Here, we describe the first lazy sequentialization approach for the total store order (TSO) and partial store order (PSO) memory models. We replace all shared memory accesses with operations on a shared memory abstraction (SMA), an abstract data type that encapsulates the semantics of the underlying WMM and implements it under the simpler SC model. We give efficient SMA implementations for TSO and PSO that are based on temporal circular doubly-linked lists, a new data structure that allows an efficient simulation of the store buffers. We show experimentally, both on the SV-COMP concurrency benchmarks and a real world instance, that this approach works well in combination with lazy sequentialization on top of bounded model checking.","Buffer storage,
Instruction sets,
Concurrent computing,
Semantics,
Memory management,
Clocks,
Testing"
A Compact Broadband Horizontally Polarized Omnidirectional Antenna Using Planar Folded Dipole Elements,"A compact horizontally polarized (HP) omnidirectional antenna with broadband characteristic is presented. The antenna is composed of four planar folded dipole antennas (PFDAs) as radiation elements of a square array and a broadband microstrip feeding structure composed of baluns and matching networks. The folded dipole antennas are chosen in order to achieve wide bandwidth operation within a compact size. The folded dipole elements are modified to compensate for the mutual coupling effects and also to improve the bandwidth and radiation performance of the antenna. The antenna is fabricated and its input impedance and radiation pattern are measured. The measured 10 dB return loss bandwidth is about 53.2% (1.19-2 GHz) and the gain variation in all directions of azimuth plane is less than 2 dB over the frequency band 1.2-1.9 GHz, and is increased to 2.8 dB at 2 GHz. The gain is almost constant over the entire band with a peak gain about 1.2 dB. The co-pol and cross-pol isolation is more than 20 dB for all azimuth directions and frequencies over the entire band.","Dipole antennas,
Broadband antennas,
Bandwidth,
Arrays,
Antenna radiation patterns,
Broadband communication,
Antenna arrays"
Container Port Performance Measurement and Comparison Leveraging Ship GPS Traces and Maritime Open Data,"Container ports are generally measured and compared using performance indicators such as container throughput and facility productivity. Being able to measure the performance of container ports quantitatively is of great importance for researchers to design models for port operation and container logistics. Instead of relying on the manually collected statistical information from different port authorities and shipping companies, we propose to leverage the pervasive ship GPS traces and maritime open data to derive port performance indicators, including ship traffic, container throughput, berth utilization, and terminal productivity. These performance indicators are found to be directly related to the number of container ships arriving at the terminals and the number of containers handled at each ship. Therefore, we propose a framework that takes the ships' container-handling events at terminals as the basis for port performance measurement. With the inferred port performance indicators, we further compare the strengths and weaknesses of different container ports at the terminal level, port level, and region level, which can potentially benefit terminal productivity improvement, liner schedule optimization, and regional economic development planning. In order to evaluate the proposed framework, we conduct extensive studies on large-scale real-world GPS traces of container ships collected from major container ports worldwide through the year, as well as various maritime open data sources concerning ships and ports. Evaluation results confirm that the proposed framework not only can accurately estimate various port performance indicators but also effectively produces port comparison results such as port performance ranking and port region comparison.",
Collaborative High-Accuracy Localization in Mobile Multipath Environments,"We study the problem of high-accuracy localization of mobile nodes in a multipath-rich environment where submeter accuracy values are required. We employ a peer-to-peer framework where nodes can get pairwise multipath-degraded ranging estimates in local neighborhoods, with the multipath noise correlated across time. The challenge is to enable high-accuracy positioning under severe multipath conditions when the fraction of received signals corrupted by multiple paths is significant. Our contributions are twofold. We provide a practical distributed localization algorithm by invoking an analytical graphical model framework based on particle filtering, and we validate its potential for high-accuracy localization through simulations. In a practical dedicated short-range communication (DSRC) mobile simulation setup, we show that the algorithm can achieve errors of <; 1 m 90% of the time, even when the fraction of line-of-sight (LOS) signals is less than 35%. We also address design questions such as “how many anchors and what fraction of LOS measurements are needed to achieve a specified target accuracy?” by showing that the Cramer-Rao lower bound (CRLB) for localization can be expressed as a product of two factors: a scalar function that depends only on the parameters of the noise distribution and a matrix that depends only on the geometry of node locations and the underlying connectivity graph. A simplified expression is obtained that provides an insightful understanding of the bound and that helps deduce the scaling behavior of the estimation error as a function of the number of agents and anchors in the network.","Vehicles,
Noise,
Accuracy,
Graphical models,
Peer-to-peer computing,
Time measurement,
Noise measurement"
"A Hierarchical Correlation Model for Evaluating Reliability, Performance, and Power Consumption of a Cloud Service","Cloud computing is a new emerging technology aimed at large-scale resource sharing and service-oriented computing. To achieve the efficient use of cloud resources for supporting a cloud service, many important factors need to be considered, particularly, reliability, performance, and power consumption of the cloud service. Evaluation of these metrics is essential for further designing rational resource scheduling strategies. However, these metrics are closely related; they do affect one another. The cloud system should consider correlations among the metrics to make more precise evaluation. Most of the existing approaches and models handle these metrics separately, and thus they cannot be used to study the correlations. This paper presents a new hierarchical correlation model for analyzing and evaluating these correlated metrics, which encompasses Markov models, queuing theory, and a Bayesian approach. Various distinctive characteristics of the cloud system are investigated and captured in the model, such as multiple virtual machines (VMs) hosted on the same server, common cause failures of co-located VMs caused by server failures, and logical mapping mechanisms for multicore CPUs. Moreover, for evaluating and balancing the tradeoff between performance and power consumption, a tradeoff parameter and a pure profit optimization model are developed based on the presented correlation model. Numerical examples are provided.","Servers,
Reliability,
Power demand,
Correlation,
Measurement,
Multicore processing,
Computational modeling"
A Discontinuous Galerkin Time-Domain Integral Equation Method for Electromagnetic Scattering From PEC Objects,"A discontinuous Galerkin time-domain integral equation (DG-TDIE) method based on the marching-on-in-time (MOT) scheme is presented to analyze the transient scattering from arbitrarily shaped perfect electrically conducting (PEC) objects. In this paper, the mono-polar Rao-Wilton-Glisson (RWG) functions are chosen as the trial and the test spatial functions, while the triangular basis functions are for the temporal expansion. Therefore, it is flexible and convenient to analyze objects with nonconformal discretization or targets containing more than three surfaces in contact with each other. Numerical results are presented to demonstrate the accuracy and the efficiency of the DG-TDIE method.",
Dual-Band Microstrip Patch Antenna Using Integrated Uniplanar Metamaterial-Based EBGs,"This paper presents a novel dual-band microstrip patch antenna that employs a metamaterial-based electromagnetic bandgap (MTM-EBG) integrated into its radiating edges to support two distinct operating frequencies. The resulting antenna is compact, uniplanar, completely printable, and via-free. Dispersion engineering of the MTM-EBG unit cell through a rigorous multiconductor transmission-line analysis allows simple, systematic design for two or more arbitrary frequencies. Additionally, a novel approach is taken to employ the same MTM-EBG to impedance-match the antenna to an inset microstrip feed at both operating frequencies. A dual-band MTM-EBG antenna designed to radiate at 2.4 and 5.0 GHz is simulated and tested, and experimental results demonstrate radiation performance comparable to the corresponding conventional patch antennas in excellent agreement with simulations, while also affording some degree of miniaturization at lower frequencies.","Dispersion,
Resonant frequency,
Photonic band gap,
Microstrip antennas,
Metamaterials,
Microstrip"
Learning Personalized Models for Facial Expression Analysis and Gesture Recognition,"Facial expression and gesture recognition algorithms are key enabling technologies for human-computer interaction (HCI) systems. State of the art approaches for automatic detection of body movements and analyzing emotions from facial features heavily rely on advanced machine learning algorithms. Most of these methods are designed for the average user, but the assumption “one-size-fits-all” ignores diversity in cultural background, gender, ethnicity, and personal behavior, and limits their applicability in real-world scenarios. A possible solution is to build personalized interfaces, which practically implies learning person-specific classifiers and usually collecting a significant amount of labeled samples for each novel user. As data annotation is a tedious and time-consuming process, in this paper we present a framework for personalizing classification models which does not require labeled target data. Personalization is achieved by devising a novel transfer learning approach. Specifically, we propose a regression framework which exploits auxiliary (source) annotated data to learn the relation between person-specific sample distributions and parameters of the corresponding classifiers. Then, when considering a new target user, the classification model is computed by simply feeding the associated (unlabeled) sample distribution into the learned regression function. We evaluate the proposed approach in different applications: pain recognition and action unit detection using visual data and gestures classification using inertial measurements, demonstrating the generality of our method with respect to different input data types and basic classifiers. We also show the advantages of our approach in terms of accuracy and computational time both with respect to user-independent approaches and to previous personalization techniques.",
Bi-Directional Algorithm for Computing Discrete Spectral Amplitudes in the NFT,"The nonlinear Fourier transform represents a signal in terms of its continuous spectrum, discrete eigenvalues, and the corresponding discrete spectral amplitudes. This paper presents a new bi-directional algorithm for computing the discrete spectral amplitudes, which addresses the significant problem of rounding errors inherent in previously known techniques. We use the proposed method to obtain accurate spectral-domain noise statistics for 2-soliton signals using numerical simulation.","Eigenvalues and eigenfunctions,
Bidirectional control,
Solitons,
Fourier transforms,
Mathematical model,
Numerical models,
Channel models"
Towards Building Forensics Enabled Cloud Through Secure Logging-as-a-Service,"Collection and analysis of various logs (e.g., process logs, network logs) are fundamental activities in computer forensics. Ensuring the security of the activity logs is therefore crucial to ensure reliable forensics investigations. However, because of the black-box nature of clouds and the volatility and co-mingling of cloud data, providing the cloud logs to investigators while preserving users' privacy and the integrity of logs is challenging. The current secure logging schemes, which consider the logger as trusted cannot be applied in clouds since there is a chance that cloud providers (logger) collude with malicious users or investigators to alter the logs. In this paper, we analyze the threats on cloud users' activity logs considering the collusion between cloud users, providers, and investigators. Based on the threat model, we propose Secure-Logging-as-a-Service ( SecLaaS), which preserves various logs generated for the activity of virtual machines running in clouds and ensures the confidentiality and integrity of such logs. Investigators or the court authority can only access these logs by the RESTful APIs provided by SecLaaS, which ensures confidentiality of logs. The integrity of the logs is ensured by hash-chain scheme and proofs of past logs published periodically by the cloud providers. In prior research, we used two accumulator schemes Bloom filter and RSA accumulator to build the proofs of past logs. In this paper, we propose a new accumulator scheme - Bloom-Tree, which performs better than the other two accumulators in terms of time and space requirement.","Cloud computing,
Digital forensics,
Servers,
Computers,
Computer crime"
Investigation of Integrated Charging and Discharging Incorporating Interior Permanent Magnet Machine With Damper Bars for Electric Vehicles,"Integrated charging technology in electric vehicles is expected to reduce the overall cost as well as the weight of the vehicle, while leading to fast charging capability in the vehicle. Understanding the above, this paper puts an effort to exclusively investigate interior permanent magnet synchronous machine (IPMSM) drive incorporating damper bars in rotor for integrated charging application in electric vehicles. First, motivation for the employment of IPMSM with damper bars for integrated charging is provided and justified. Thereafter, a novel parameter determination method based on dq-axis theory to determine the parameters of a laboratory IPMSM with dampers is proposed and experimentally validated. The determined parameters are then employed to design, control, and compare the performance of an integrated charging system incorporating an IPMSM drive with and without damper bars. The developed system is then experimentally tested under both vehicle-to-grid and grid-to-vehicle modes, and results elicited from the investigations are discussed.","Shock absorbers,
Rotors,
Batteries,
Bars,
Vehicles,
Traction motors,
Stators"
Optimal Control of Energy Storage in a Microgrid by Minimizing Conditional Value-at-Risk,"This paper presents two methods for online rolling horizon optimal control of an energy storage unit in a grid-connected microgrid, subject to uncertainty in demand and electricity pricing. The proposed methods are based on the concept of rolling horizon control, where battery charge/discharge activities are determined by repeatedly solving a linear optimization problem over a moving control window. The predicted values of the microgrid net electricity demand and electricity prices over the control horizon are assumed to be uncertain. The first formulation of the control is based on the scenario-based stochastic conditional value at risk (CVaR) optimization, where the cost function includes electricity usage cost, battery operation costs, and grid signal smoothing objectives. Multivariate Gaussian distribution is used to model the variations of electricity prices and net demand power around their predicted nominal values. The second formulation of the control reduces the computations by taking a worst-case CVaR stochastic optimization approach. In this case, the uncertainty in demand is still stochastic but the problem constraints are made robust with respect to price variations in a range. Simulation results under different scenarios are presented to demonstrate the effectiveness of the proposed methods.",
Multi-Wideband Waveform Design for Distance-Adaptive Wireless Communications in the Terahertz Band,"Terahertz band communication is envisioned as a key technology to satisfy the increasing demand for ultra-high-speed wireless links. In this paper, a multi-wideband waveform design for the THz band is proposed, by exploiting the channel peculiarities including the distance-varying spectral windows, the delay spread and the temporal broadening effects. This scheme allows the dynamical variation of the rate and the transmit power on each sub-window and improves the distance. Moreover, the closed-form expressions of the signal-to-interference-plus-the-noise and bit-error-rate for the multi-wideband waveform are derived, by considering the inter-symbol and inter-band interferences. Then, an optimization framework is formulated to solve for the multi-wideband waveform design parameters of the transmit power and the number of frames, with the aim to maximize the communication distance while satisfying the rate and the transmit power constraints. Four sub-optimal solutions are proposed and compared. The results show that the SINR increases with the transmit power and the number of frames, at the cost of the power consumption and the rate decrease. With the transmit power of 10 dBm, the largest distance to support 10 Gbps for the multi-path propagation is 4 m, which is realized via the power allocation scheme to minimize the power/bit on each sub-window and is 10% improvement over the fixed scheme. However, for the directional transmission, this scheme under-exploits the transmit power severely. Instead, the allocation scheme that minimizes the number of frames outperforms the other three schemes. In terms of the maximum distance that achieves 30 Gbps, this scheme reaches 22.5 m.",
Fault Diagnosis and Signal Reconstruction of Hall Sensors in Brushless Permanent Magnet Motor Drives,"Brushless permanent magnet (BLPM) motor drives based on Hall sensors have received extensive attention in the literature and are widely used in many applications. However, most of the available and published controllers assume that the Hall signals are always available, which is not true if any of the sensors are faulted. In this paper, several fault-tolerant control schemes for BLPM motor drives are proposed. The methodology is based on fault diagnosis and its classification, and subsequent signal reconstruction. Simulation and experimental results demonstrate the effectiveness and advantages of the proposed fault-tolerant schemes in restoring the motor operation when failures occur in up to two Hall sensors. The proposed fault-tolerant schemes can be easily and flexibly realized for conventional drive systems, either by adding the code in the existing driver or by adding a simple auxiliary circuit between the Hall sensors and the driver.","Fault diagnosis,
Permanent magnet motors,
Magnetic sensors,
Motor drives,
Circuit faults,
Brushless motors"
On the Co-Existence of TD-LTE and Radar Over 3.5 GHz Band: An Experimental Study,This letter presents a pioneering study based on a series of experiments on the operation of commercial Time-Division Long-Term Evolution (TD-LTE) systems in the presence of pulsed interfering signals in the 3550-3650 MHz band. TD-LTE operations were carried out in channels overlapping and adjacent to the high power SPN-43 radar with various frequency offsets between the two systems to evaluate the susceptibility of LTE to a high power interfering signal. Our results demonstrate that LTE communication using low antenna heights was not adversely affected by the pulsed interfering signal operating on adjacent frequencies irrespective of the distance of interfering transmitter. Performance was degraded only for very close distances (1-2 km) of overlapping frequencies of interfering transmitter.,"Radar antennas,
Antenna measurements,
Radar measurements,
Interference,
Uplink,
Downlink"
A Column-Row-Parallel ASIC Architecture for 3-D Portable Medical Ultrasonic Imaging,"This paper presents a scalable column-row-parallel ASIC architecture for 3-D portable medical ultrasound. Through its programmable row-by-row or column-by-column operations for both transmit and receive beam-formation, linear scaling in interconnection, data acquisition complexity, power dissipation, and programming time is achieved. In addition, its per-element controllers can activate fine granularity aperture definition when more functionality is favored over the linear-scaling power and speed efficiency. This front-end architecture is backward compatible to implement existing widely used array aperture patterns, while supporting new imaging apertures and algorithms. It lends itself very well for the combination with integrated or external digital beamforming circuits. A 16 × 16 proof-of-concept ASIC is fabricated and flip-chip bonded to a 16 × 16 capacitive micromachined ultrasonic transducer (CMUT). Each three-level pulsing transmitter (Tx) is 46% more power efficient than a traditional two-level version, with high-voltage (HV) multiplexers (MUXs) designed for flexible Tx parallelization. Each low-noise receiver (Rx) consumes 1.4 mW active power and 54 μW sleep power, with optimized source follower stages to combine analog outputs for improved SNR. The transceivers are also fault-tolerant to inevitable defects in transducers, greatly enhancing assembly yield. The system demonstrates 3-D plane-wave generation to implement the coherent compounding algorithm for fast volume rate (62.5 volume/s), high-quality 3-D ultrasonic imaging. An interleaved checker board pattern with Iand Q excitations is also demonstrated for ultrasonic harmonic imaging, which reduces transmitted second harmonic distortion (HD2) by over 20 dB.","Arrays,
Application specific integrated circuits,
Multiplexing,
Transceivers,
Transducers,
Ultrasonic imaging,
Apertures"
Toward Reliable Autonomous Robotic Assistants Through Formal Verification: A Case Study,"It is essential for robots working in close proximity to people to be both safe and trustworthy. We present a case study on formal verification for a high-level planner/scheduler for the Care-O-bot, an autonomous personal robotic assistant. We describe how a model of the Care-O-bot and its environment was developed using Brahms, a multiagent workflow language. Formal verification was then carried out by automatically translating this model to the input language of an existing model checker. Four sample properties based on system requirements were verified. We then refined the environment model three times to increase its accuracy and the persuasiveness of the formal verification results. The first refinement uses a user activity log based on real-life experiments, but is deterministic. The second refinement uses the activities from the user activity log nondeterministically. The third refinement uses “conjoined activities” based on an observation that many user activities can overlap. The four samples properties were verified for each refinement of the environment model. Finally, we discuss the approach of environment model refinement with respect to this case study.","Robot sensing systems,
TV,
Software,
Navigation,
Watches"
Hybrid Beamforming in mm-Wave MIMO Systems Having a Finite Input Alphabet,"Recently, there has been significant research effort toward achieving high data rates in the millimeter wave bands by employing large antenna systems. These systems are considered to have only a fraction of the RF chains compared with the total number of antennas and employ analog phase shifters to steer the transmit and receive beams in addition to the conventional beamforming (BF)/combining invoked in the baseband domain. This scheme, which is popularly known as hybrid BF, has been extensively studied in the literature. To the best of our knowledge, all the existing schemes focus on obtaining the BF/combining matrices that maximize the system capacity computed using a Gaussian input alphabet. However, this choice of matrices may be suboptimal for practical systems, since they employ a finite input alphabet, such as quadrature amplitude modulation/phase-shift keying constellations. Hence, in this paper, we consider a hybrid BF/combining system operating with a finite input alphabet and optimize the analog as well as digital BF/combining matrices by maximizing the mutual information (MI). This is achieved by an iterative gradient ascent algorithm that exploits the relationship between the minimum mean-squared error and the MI. Furthermore, an iterative algorithm is proposed for designing a codebook for the analog and digital BF/combining matrices based on a vector quantization approach. Our simulation results demonstrate that the proposed gradient ascent algorithm achieves an ergodic rate improvement of up to 0.4 bits per channel use (bpcu) compared with the Gaussian input scenario. Furthermore, the gain in the ergodic rate achieved by employing the vector quantization-based codebook is about 0.5 bpcu compared with the Gaussian input scenario.",
The data exchange between smart glasses and healthcare information systems using the HL7 FHIR standard,"In this study we evaluated system architecture for the use of smart glasses as a viewer of information, as a source of medical data (vital sign measurements: temperature, pulse rate, and respiration rate), and as a filter of healthcare information. All activities were based on patient/device identification procedures using graphical markers or features based on visual appearance. The architecture and particular use cases were implemented and verified using smart glasses prototypes developed under the eGlasses project and using a reference Health Level 7 Fast Healthcare Interoperability Resources (HL7 FHIR) server. The results show that information about the identified patient can be quickly retrieved from FHIR servers and annotated using voice recognition services. Smart glasses can be used in the measurement of vital signs of the observed patient, providing values of body temperature, pulse rate, and respiration rate by means of non-contact measurements. Such measurements are sufficiently reliable for medical screening and for fast data exchange using HL7 FHIR actions.","Glass,
Temperature measurement,
Object recognition,
Medical services,
Information systems,
Biomedical imaging,
Temperature sensors"
Visual Tracking via Coarse and Fine Structural Local Sparse Appearance Models,"Sparse representation has been successfully applied to visual tracking by finding the best candidate with a minimal reconstruction error using target templates. However, most sparse representation-based tracking methods only consider holistic rather than local appearance to discriminate between target and background regions, and hence may not perform well when target objects are heavily occluded. In this paper, we develop a simple yet robust tracking algorithm based on a coarse and fine structural local sparse appearance model. The proposed method exploits both partial and structural information of a target object based on sparse coding using the dictionary composed of patches from multiple target templates. The likelihood obtained by averaging and pooling operations exploits consistent appearance of object parts, thereby helping not only locate targets accurately but also handle partial occlusion. To update templates more accurately without introducing occluding regions, we introduce an occlusion detection scheme to account for pixels belonging to the target objects. The proposed method is evaluated on a large benchmark data set with three evaluation metrics. Experimental results demonstrate that the proposed tracking algorithm performs favorably against several state-of-the-art methods.","Target tracking,
Dictionaries,
Visualization,
Robustness,
Encoding,
Lighting"
Handover Management in 5G and Beyond: A Topology Aware Skipping Approach,"Network densification is foreseen as a potential solution to fulfill the 5G spectral efficiency requirements. The spectral efficiency is improved by shrinking base stations' (BSs) footprints, thus improving the spatial frequency reuse and reducing the number of users sharing the resources of each BS. However, the foreseen densification gains are achieved at the expense of increasing handover (HO) rates. Hence, HO rate is a key performance limiting factor that should be carefully considered in densification planning. This paper sheds light on the HO problem that appears in dense 5G networks and proposes an effective solution via topology aware HO skipping. Different skipping techniques are considered and compared with the conventional best connected scheme. To this end, the proposed schemes are validated via the average user rate in downlink single-tier and two-tier cellular networks, which are modeled using the Poisson point process and the Poisson cluster process, respectively. The proposed skipping schemes show up to 47% gains in the average throughput, which would maximize the benefit of network densification.","Cellular networks,
Trajectory,
Throughput,
Handover,
Delays,
Computer architecture"
JPEG XT: A Compression Standard for HDR and WCG Images [Standards in a Nutshell],"High bit depth data acquisition and manipulation have been largely studied at the academic level over the last 15 years and are rapidly attracting interest at the industrial level. An example of the increasing interest for high-dynamic range (HDR) imaging is the use of 32-bit floating point data for video and image acquisition and manipulation that allows a variety of visual effects that closely mimic the real-world visual experience of the end user [1] (see Figure 1). At the industrial level, we are witnessing increasing traction toward supporting HDR and wide color gamut (WCG). WCG leverages HDR for each color channel to display a wider range of colors. Consumer cameras are currently available with a 14- or 16-bit analog-to-digital converter. Rendering devices are also appearing with the capability to display HDR images and video with a peak brightness of up to 4,000 nits and to support WCG (ITU-R Rec. BT.2020 [2]) rather than the historical ITU-R Rec. BT.709 [3]. This trend calls for a widely accepted standard for higher bit depth support that can be seamlessly integrated into existing products and applications. While standard formats such as the Joint Photographic Experts Group (JPEG) 2000 [5] and JPEG XR [6] offer support for high bit depth image representations, their adoption requires a nonnegligible investment that may not always be affordable in existing imaging ecosystems, and induces a difficult transition, as they are not backward-compatible with the popular JPEG image format.","Transform coding,
Image coding,
Encoding,
Streaming media,
Image color analysis,
Decoding"
Robust Landing and Sliding Maneuver Hybrid Controller for a Quadrotor Vehicle,"This paper addresses the design and experimental evaluation of a robust controller for a quadrotor landing maneuver comprising the approach to a landing slope and sliding on that slope, before coming to a complete halt. During the critical landing flight phase, the dynamics of the vehicle change with the type of contact with the ground, and a hybrid automaton, whose states reflect the several dynamic behaviors of the quadrotor, is employed to model the vehicle throughout the complete maneuver. The quadrotor landing problem is broken down as separate maneuver generation and robust trajectory tracking problems, which are combined to achieve a successful maneuver that is robust to possible uncertainties. The experimental results are provided to attest to the feasibility of the proposed landing procedure.","Vehicles,
Vehicle dynamics,
Robustness,
Automata,
Trajectory,
Gears"
A Back-Channel-Etched Amorphous InGaZnO Thin-Film Transistor Technology With Al-Doped ZnO as Source/Drain and Pixel Electrodes,"A back-channel-etched fabrication process for amorphous indium-gallium-zinc oxide (a-IGZO) thin-film transistors is proposed, in which an alumium-doped ZnO (AZO) transparent conductive film is used to form both source/drain and pixel electrodes. It is demonstrated that rinsed acetic acid solution has a high etching selectivity over 100:1 between AZO and a-IGZO. In addition, bus and interconnect lines are formed in a separate fabrication step in this process, so that the Cu process could be adopted without bringing contamination issue.","Thin film transistors,
Electrodes,
Resistance,
Fabrication,
Etching,
Logic gates,
Stress"
Real-Time Simulation of Passage-of-Time Encoding in Cerebellum Using a Scalable FPGA-Based System,"The cerebellum plays a critical role for sensorimotor control and learning. However, dysmetria or delays in movements' onsets consequent to damages in cerebellum cannot be cured completely at the moment. Neuroprosthesis is an emerging technology that can potentially substitute such motor control module in the brain. A pre-requisite for this to become practical is the capability to simulate the cerebellum model in real-time, with low timing distortion for proper interfacing with the biological system. In this paper, we present a frame-based network-on-chip (NoC) hardware architecture for implementing a bio-realistic cerebellum model with ~ 100 000 neurons, which has been used for studying timing control or passage-of-time (POT) encoding mediated by the cerebellum. The simulation results verify that our implementation reproduces the POT representation by the cerebellum properly. Furthermore, our field-programmable gate array (FPGA)-based system demonstrates excellent computational speed that it can complete 1sec real world activities within 25.6 ms. It is also highly scalable such that it can maintain approximately the same computational speed even if the neuron number increases by one order of magnitude. Our design is shown to outperform three alternative approaches previously used for implementing spiking neural network model. Finally, we show a hardware electronic setup and illustrate how the silicon cerebellum can be adapted as a potential neuroprosthetic platform for future biological or clinical application.","Computational modeling,
Biological system modeling,
Brain modeling,
Hardware,
Real-time systems,
Computer architecture,
Neurons"
Discriminative Semantic Subspace Analysis for Relevance Feedback,"Content-based image retrieval (CBIR) has attracted much attention during the past decades for its potential practical applications to image database management. A variety of relevance feedback (RF) schemes have been designed to bridge the gap between low-level visual features and high-level semantic concepts for an image retrieval task. In the process of RF, it would be impractical or too expensive to provide explicit class label information for each image. Instead, similar or dissimilar pairwise constraints between two images can be acquired more easily. However, most of the conventional RF approaches can only deal with training images with explicit class label information. In this paper, we propose a novel discriminative semantic subspace analysis (DSSA) method, which can directly learn a semantic subspace from similar and dissimilar pairwise constraints without using any explicit class label information. In particular, DSSA can effectively integrate the local geometry of labeled similar images, the discriminative information between labeled similar and dissimilar images, and the local geometry of labeled and unlabeled images together to learn a reliable subspace. Compared with the popular distance metric analysis approaches, our method can also learn a distance metric but perform more effectively when dealing with high-dimensional images. Extensive experiments on both the synthetic data sets and a real-world image database demonstrate the effectiveness of the proposed scheme in improving the performance of the CBIR.",
Practical Determination of Individual Element Resistive States in Selectorless RRAM Arrays,"Three distinct methods of reading multi-level cross-point resistive states from selector-less RRAM arrays are implemented in a physical system and compared for read-out accuracy. They are: the standard, direct measurement method and two methods that attempt to enhance accuracy by computing cross-point resistance on the basis of multiple measurements. Results indicate that the standard method performs as well as or better than its competitors. SPICE simulations are then performed with controlled amounts of non-idealities introduced in the system in order to test whether any technique offers particular resilience against typical practical imperfections such as crossbar line resistance. We conclude that even though certain non-idealities are shown to be minimized by different circuit-level read-out strategies, line resistance within the crossbar remains an outstanding challenge.","Resistance,
Electrical resistance measurement,
Current measurement,
Voltage measurement,
Accuracy,
Standards,
Instruments"
Exploiting Social Tie Structure for Cooperative Wireless Networking: A Social Group Utility Maximization Framework,"We develop a social group utility maximization (SGUM) framework for cooperative wireless networking that takes into account both social relationships and physical coupling among users. Specifically, instead of maximizing its individual utility or the overall network utility, each user aims to maximize its social group utility that hinges heavily on its social tie structure with other users. We show that this framework provides rich modeling flexibility and spans the continuum between non-cooperative game and network utility maximization (NUM)-two traditionally disjoint paradigms for network optimization. Based on this framework, we study three important applications of SGUM, in database assisted spectrum access, power control, and random access control, respectively. For the case of database assisted spectrum access, we show that the SGUM game is a potential game and always admits a socially-aware Nash equilibrium (SNE). We also develop a distributed spectrum access algorithm that can converge to the SNE and also quantify the trade-off between the performance and convergence time of the algorithm. For the cases of power control and random access control, we show that there exists a unique SNE and the network performance improves as the strength of social ties increase. Numerical results corroborate that the SGUM solutions can achieve superior performance using real social data trace. Furthermore, we show that the SGUM framework can be generalized to take into account both positive and negative social ties among users, which can be a useful tool for studying network security problems.","Games,
Couplings,
Mobile communication,
Social network services,
Wireless communication,
Mobile computing,
Interference"
Implementation of virtual sensors for building a sensor-cloud environment,"There has been a recent attempt by the researchers to leverage the widespread usage of small sensor nodes and integrate them with cloud technology for building an environment for Internet of Things. While some applications have already been developed to transmit the data from physical sensors to cloud environment, we propose to create and include virtual sensors, i.e. abstractions of physical sensors, in cloud that can enable on demand, pervasive, shared access to sensors. The definition and description of virtual sensors have already been presented in our earlier work. This paper presents implementation of virtual sensors at IaaS level. It provides a virtual sensor system architecture for both health and environment sensors and describes virtual sensor operations in four different stages. It provides description of APIs for sensing, processing, communication and storage at IaaS end. The virtual sensors can be used by any user application at PaaS or SaaS levels. Performance of a preliminary implementation of such virtual sensor system is also analyzed in this paper.","Sensor systems,
Cloud computing,
Temperature sensors,
Temperature measurement,
Monitoring,
Ports (Computers)"
Zero-Determinant Strategy for Resource Sharing in Wireless Cooperations,"Cooperation in resource sharing among wireless users and network operators has been widely studied in wireless communication. However, because of the limited coordination capability or cheating strategies, each participant of the cooperation may cease its cooperative behavior or duties unilaterally during the resource sharing, resulting in unsatisfying quality of services (QoSs) for all other participants. In this paper, we model the resource sharing among participants as an iterated game. Specifically, we first define the participant who is responsible for maintaining the social welfare as an administrator of cooperation (AoC), and other selfish participants as the regular participants of cooperation (PoCs). Then we consider three scenarios, i.e., with two-player applying discrete strategy, two-player applying continuous strategy, and multi-player applying continuous strategy, Finally, we investigate the power control problem in each of scenarios, and apply the zero-determinant strategies for the AoC to find the maximum social welfare that the AoC can achieve with existence of PoCs. Simulation results show that the high and stable social welfare can be maintained by the the AoC with the proposed zero-determinant algorithm.","Games,
Wireless communication,
Resource management,
Power control,
Yttrium,
Gold,
Game theory"
Continuously Adaptive Data Fusion and Model Relearning for Particle Filter Tracking With Multiple Features,"This paper presents a new method for object tracking in a camera sensor with particle filters. The method enables multiple target and background models, arbitrarily spanning many features or imaging modalities, to be adaptively fused to provide optimal discriminating ability against changing backgrounds, which may present varying degrees of clutter and camouflage for different kinds of features at different times. Furthermore, we show how to continuously and robustly relearn all models for all feature modalities online during tracking and for targets whose appearance may be continually changing. Both the data fusion weightings and model relearning parameters are robustly adapted at each frame, by extracting contextual information to inform the saliency assessments of each part of each model. In addition, we propose a two-step estimation method for improving robustness, by preventing excessive drifting of particles during tracking past challenging, cluttered background scenes. We demonstrate the method by implementing a version of the tracker, which combines both shape and color models, and testing it on a publicly available benchmark data set. Results suggest that the proposed method outperforms a number of well-known state-of-the-art trackers from the literature.","Target tracking,
Particle filters,
Adaptation models,
Robustness,
Feature extraction,
Image color analysis,
Histograms"
A Local Structural Descriptor for Image Matching via Normalized Graph Laplacian Embedding,"This paper investigates graph spectral approaches to the problem of point pattern matching. Specifically, we concentrate on the issue of how to effectively use graph spectral properties to characterize point patterns in the presence of positional jitter and outliers. A novel local spectral descriptor is proposed to represent the attribute domain of feature points. For a point in a given point-set, weight graphs are constructed on its neighboring points and then their normalized Laplacian matrices are computed. According to the known spectral radius of the normalized Laplacian matrix, the distribution of the eigenvalues of these normalized Laplacian matrices is summarized as a histogram to form a descriptor. The proposed spectral descriptor is finally combined with the approximate distance order for recovering correspondences between point-sets. Extensive experiments demonstrate the effectiveness of the proposed approach and its superiority to the existing methods.","Laplace equations,
Eigenvalues and eigenfunctions,
Matrix decomposition,
Jitter,
Histograms,
Context,
Probabilistic logic"
CPHR: In-Network Caching for Information-Centric Networking With Partitioning and Hash-Routing,"Recently, research on Information-Centric Networking (ICN) has flourished, which attempts to shift from the current host-oriented Internet architecture to an information-oriented one. The built-in caching capability is a typical feature of ICN. In this paper, in order to fully exploit the built-in caching capability of ICN, we propose a collaborative in-network caching scheme with Content-space Partitioning and Hash-Routing, which is named as CPHR. By intelligently partitioning the content space and assigning partitions to caches, CPHR is able to constrain the path stretch incurred by hash-routing. We formulate the problem of assigning partitions to caches into an optimization problem of maximizing the overall hit ratio and propose a heuristic algorithm to solve it. We also formulate the partitioning proportion problem into a min-max linear optimization problem to balance cache workloads. By simulations with both the characteristics of real Internet traffic and traces of peer-to-peer (P2P) traffic, we show the necessity of collaborative caching since the en-route caching mode cannot yield a considerable overall hit ratio with practical cache size. It is shown as well that CPHR can significantly increase the overall hit ratio by up to about 100% with the practical cache policy Least Recently Used (LRU) while the overhead incurred is acceptable in terms of propagation latency and load on links.",
Software-Based Real-Time Acquisition and Processing of PET Detector Raw Data,"In modern positron emission tomography (PET) readout architectures, the position and energy estimation of scintillation events (singles) and the detection of coincident events (coincidences) are typically carried out on highly integrated, programmable printed circuit boards. The implementation of advanced singles and coincidence processing (SCP) algorithms for these architectures is often limited by the strict constraints of hardware-based data processing. In this paper, we present a software-based data acquisition and processing architecture (DAPA) that offers a high degree of flexibility for advanced SCP algorithms through relaxed real-time constraints and an easily extendible data processing framework. The DAPA is designed to acquire detector raw data from independent (but synchronized) detector modules and process the data for singles and coincidences in real-time using a center-of-gravity (COG)-based, a leastsquares (LS)-based, or a maximum-likelihood (ML)-based crystal position and energy estimation approach (CPEEA). To test the DAPA, we adapted it to a preclinical PET detector that outputs detector raw data from 60 independent digital silicon photomultiplier (dSiPM)-based detector stacks and evaluated it with a [18F]fluorodeoxyglucose-filled hot-rod phantom. The DAPA is highly reliable with less than 0.1% of all detector raw data lost or corrupted. For high validation thresholds (37.1 ± 12.8 photons per pixel) of the dSiPM detector tiles, the DAPA is real time capable up to 55 MBq for the COG-based CPEEA, up to 31 MBq for the LS-based CPEEA, and up to 28 MBq for the ML-based CPEEA. Compared to the COG-based CPEEA, the rods in the image reconstruction of the hot-rod phantom are only slightly better separable and less blurred for the LSand ML-based CPEEA. While the coincidence time resolution (~550 ps) and energy resolution (~12.3%) are comparable for all three CPEEA, the system sensitivity is up to 2.5× higher for the LS- and ML-based CPEEA.",
EEF: Exponentially Embedded Families With Class-Specific Features for Classification,"In this paper, we present a novel exponentially embedded families (EEF) based classification method, in which the probability density function (PDF) on raw data is estimated from the PDF on features. With the PDF construction, we show that class-specific features can be used in the proposed classification method, instead of a common feature subset for all classes as used in conventional approaches. We apply the proposed EEF classifier for text categorization as a case study and derive an optimal Bayesian classification rule with class-specific feature selection based on the Information Gain score. The promising performance on real-life data sets demonstrates the effectiveness of the proposed approach and indicates its wide potential applications.",
Fast Weighted Histograms for Bilateral Filtering and Nearest Neighbor Searching,"The locality sensitive histogram (LSH) injects spatial information into the local histogram in an efficient manner, and has been demonstrated to be very effective for visual tracking. In this paper, we explore the application of this efficient histogram in two important problems. We first extend the LSH to linear time bilateral filtering, and then propose a new type of histogram for efficiently computing edge-preserving nearest neighbor fields (NNFs). While the existing histogram-based bilateral filtering methods are the state of the art for efficient grayscale image processing, they are limited to box spatial filter kernels only. In our first application, we address this limitation by expressing the bilateral filter as a simple ratio of linear functions of the LSH, which is able to extend the box spatial kernel to an exponential kernel. The computational complexity of the proposed bilateral filter is linear in the number of image pixels. In our second application, we derive a new bilateral weighted histogram (BWH) for NNF. The new histogram maintains the efficiency of LSH, which allows approximate NNF to be computed independent of patch size. In addition, BWH takes both spatial and color information into account, and thus provides higher accuracy for histogram-based matching, especially around color edges.","Histograms,
Kernel,
Joints,
Image edge detection,
Computational complexity,
Image color analysis,
Image reconstruction"
DCCC-MAC: A Dynamic Common-Control-Channel-Based MAC Protocol for Cellular Cognitive Radio Networks,"We propose a novel dynamic common-control-channel-based medium access control (DCCC-MAC) protocol for cellular (centralized) cognitive radio (CR) networks. Specifically, unlike the traditional dedicated-control-channel-based medium access control (MAC) protocols, the proposed MAC protocol eliminates the requirement of a dedicated channel for control information exchange. During a given transmission frame, the common control channel (CCC) is selected by a cooperating set of secondary users (SUs) by using a support-vector-machine (SVM)-based learning technique. In the DCCC-MAC protocol, the frame duration is divided into four main phases as follows: spectrum sensing, CCC selection, data transmission, and beaconing. The SUs that participate in the CCC selection process are allocated channels for data transmission during a frame interval using a scheduling process, whereas the other SUs have to contend to access the channels. We present an analytical approach to calculate the minimum required number of minislots in the transmission frame for a given number of SUs in the CCC selection process. The saturation throughput of the proposed MAC protocol is analyzed in closed form. To this end, the numerical and simulation results are presented to quantify the performance of the proposed DCCC-MAC protocol. We also compare the performance of the DCCC-MAC protocol with that of two other state-of-the-art CR MAC protocols that use CCCs.","Sensors,
Media Access Protocol,
Data communication,
Support vector machines,
Cognitive radio,
Vehicle dynamics"
A Model Modification Process for Grid-Connected Inverters Used in Islanded Microgrids,"A method of modifying existing grid-connected inverter models for use in droop-controlled microgrids is presented. The modification involves combination with a model of a grid-forming inverter to accurately represent the coupling between complex power, bus voltage, and frequency. The combination is performed after the individual models are linearized, adding little in terms of computational complexity. The method is applicable to any three-phase inverter operating in a grid-supporting capacity and is scalable for any number of parallel inverters at the same point of connection. To examine the modification process and its effect on model performance, a generic grid-tied inverter model is derived and used as a test case. The newly derived model is modified according to the proposed method. The validity of this process is assessed through comparisons of model predictions-both from before and after modification-to results of hardware experiments. A simple design example is given to demonstrate the application of this process in the design of inverters in distributed-generation-based microgrids.","Inverters,
Mathematical model,
Microgrids,
Phase locked loops,
Voltage control,
Couplings"
Silicon Field Emitter Arrays With Current Densities Exceeding 100 A/cm2 at Gate Voltages Below 75 V,"We report silicon field emitter arrays (FEAs) that demonstrate current densities 100 A/cm2 at gate-emitter voltages <;75 V. These are the highest current densities reported for a semiconductor FEA, and approach the current densities of Spindt-type metal cathodes. We achieved these results using a new device structure that employs high-aspect-ratio silicon nanowire current limiters in series with each emitter tip to address the major failure mechanisms in FEAs. These current limiters mitigate emitter tip failure due to joule heating thus allowing for higher reliability. We employed a novel fabrication process to produce small gate apertures (≈350 nm) that are self-aligned to the field emitter tip enabling device operation at >100 A/cm2 with gate-to-emitter voltages that are less than 75 V. These FEAs demonstrate performance that has the potential to enable smaller, more efficient, and high-power vacuum electronics.",
SBVLC: Secure Barcode-Based Visible Light Communication for Smartphones,"2D barcodes have enjoyed a significant penetration rate in mobile applications. This is largely due to the extremely low barrier to adoption-almost every camera-enabled smartphone can scan 2D barcodes. As an alternative to NFC technology, 2D barcodes have been increasingly used for security-sensitive mobile applications including mobile payments and personal identification. However, the security of barcode-based communication in mobile applications has not been systematically studied. Due to the visual nature, 2D barcodes are subject to eavesdropping when they are displayed on the smartphone screens. On the other hand, the fundamental design principles of 2D barcodes make it difficult to add security features. In this paper, we propose SBVLC-a secure system for barcode-based visible light communication (VLC) between smartphones. We formally analyze the security of SBVLC based on geometric models and propose physical security enhancement mechanisms for barcode communication by manipulating screen view angles and leveraging user-induced motions. We then develop three secure data exchange schemes that encode information in barcode streams. These schemes are useful in many security-sensitive mobile applications including private information sharing, secure device pairing, and contactless payment. SBVLC is evaluated through extensive experiments on both Android and iOS smartphones.",
Compression of 3D Point Clouds Using a Region-Adaptive Hierarchical Transform,"In free-viewpoint video, there is a recent trend to represent scene objects as solids rather than using multiple depth maps. Point clouds have been used in computer graphics for a long time, and with the recent possibility of real-time capturing and rendering, point clouds have been favored over meshes in order to save computation. Each point in the cloud is associated with its 3D position and its color. We devise a method to compress the colors in point clouds, which is based on a hierarchical transform and arithmetic coding. The transform is a hierarchical sub-band transform that resembles an adaptive variation of a Haar wavelet. The arithmetic encoding of the coefficients assumes Laplace distributions, one per sub-band. The Laplace parameter for each distribution is transmitted to the decoder using a custom method. The geometry of the point cloud is encoded using the well-established octtree scanning. Results show that the proposed solution performs comparably with the current state-of-the-art, while being much more computationally efficient. We believe this paper represents the state of the art in intra-frame compression of point clouds for real-time 3D video.","Three-dimensional displays,
Transforms,
Image color analysis,
Geometry,
Image coding,
Real-time systems,
Rendering (computer graphics)"
A Survey Of Techniques for Architecting DRAM Caches,"Recent trends of increasing core-count and memory/bandwidth-wall have led to major overhauls in chip architecture. In face of increasing cache capacity demands, researchers have now explored DRAM, which was conventionally considered synonymous to main memory, for designing large last level caches. Efficient integration of DRAM caches in mainstream computing systems, however, also presents several challenges and several recent techniques have been proposed to address them. In this paper, we present a survey of techniques for architecting DRAM caches. Also, by classifying these techniques across several dimensions, we underscore their similarities and differences. We believe that this paper will be very helpful to researchers for gaining insights into the potential, tradeoffs and challenges of DRAM caches.","Random access memory,
Bandwidth,
Three-dimensional displays,
Program processors,
Memory management,
Multicore processing"
Secure key generation and distribution protocol for wearable devices,"Smart wearable devices have enormous applications in today's world and hence their usage is increasing significantly. As these devices communicate using wireless medium, the communication must be protected from eavesdropping by using shared secret keys for data encryption. In many applications, it is essential to use a common secret key for secured communication among multiple devices. In this paper, we present our novel secret key generation and distribution protocol exploiting accelerometer data collected from smart wearable devices. We propose (i) source separation method for processing accelerometer sensor data, and (ii) key distribution protocol based on Fuzzy vault. Our scheme is information theoretically secure and our experimental results show that the maximum key generation rate of our scheme is 50 bps which is suitable for practical applications.","Accelerometers,
Smart phones,
Acceleration,
Protocols,
Legged locomotion,
Australia,
Glass"
Factorized Hidden Layer Adaptation for Deep Neural Network Based Acoustic Modeling,"In this paper, we propose the factorized hidden layer (FHL) approach to adapt the deep neural network (DNN) acoustic models for automatic speech recognition (ASR). FHL aims at modeling speaker dependent (SD) hidden layers by representing an SD affine transformation as a linear combination of bases. The combination weights are low-dimensional speaker parameters that can be initialized using speaker representations like i-vectors and then reliably refined in an unsupervised adaptation fashion. Therefore, our method provides an efficient way to perform both adaptive training and (test-time) adaptation. Experimental results have shown that the FHL adaptation improves the ASR performance significantly, compared to the standard DNN models, as well as other state-of-the-art DNN adaptation approaches, such as training with the speaker-normalized CMLLR features, speaker-aware training using i-vector and learning hidden unit contributions (LHUC). For Aurora 4, FHL achieves 3.8% and 2.3% absolute improvements over the standard DNNs trained on the LDA + STC and CMLLR features, respectively. It also achieves 1.7% absolute performance improvement over a system that combines the i-vector adaptive training with LHUC adaptation. For the AMI dataset, FHL achieved 1.4% and 1.9% absolute improvements over the sequence-trained CMLLR baseline systems, for the IHM and SDM tasks, respectively.","Adaptation models,
Training,
Hidden Markov models,
Acoustics,
Mathematical model,
Standards,
Interpolation"
Efficient Eigen-Analysis for Large Delayed Cyber-Physical Power System Using Explicit Infinitesimal Generator Discretization,"Time delays significantly compromise the performance of wide-area measurement and control system and thus may jeopardize the stability of cyber-physical power systems (CPPS). A delayed CPPS (DCPPS) has a transcendental characteristic equation, leading to an infinite number of eigenvalues basically unsolvable by traditional eigen-analysis methods. In this paper, an explicit infinitesimal generator discretization (EIGD) approach is presented to tackle the traditionally intractable problem. First, the delayed differential equation of DCPPS is transformed to an ordinary differential equation by using an operator called infinitesimal generator. The operator is then optimally discretized, resulting in a highly structured, sparse and explicit approximant matrix. By exploiting the sparsity of the matrix and that of system matrices, the rightmost eigenvalues of the original DCPPS can be accurately computed. The contributions of the EIGD approach lie in the following: 1) it forms a theoretical foundation for accurately obtaining the critical eigenvalues of a CPPS with multiple delays; 2) it constructs a highly structured approximant matrix that enables efficient eigen-analysis of a large DCPPS by making full use of sparsity techniques; and 3) it integrates the shift-invert transformation, Arnoldi algorithm, Newton correction and eigen-sensitivity to form a computational framework for the analysis of large DCPPS. The accuracy, efficiency and scalability of EIGD have been extensively studied and thoroughly validated on the two-area four-machine test system and a practical large transmission grid.","Eigenvalues and eigenfunctions,
Sparse matrices,
Delay effects,
Power system stability,
Generators,
Mathematical model,
Damping"
An Approach Based on Social Network Analysis Applied to a Collaborative Learning Experience,"The Social Network Analysis (SNA) techniques allow modelling and analysing the interaction among individuals based on their attributes and relationships. This approach has been used by several researchers in order to measure the social processes in collaborative learning experiences. But oftentimes such measures were calculated at the final state of experiences, what may be hardly representative of students' behaviours during the learning processes. Therefore, a temporal dimension in SNA metrics may extend and improve the understanding about students' interactions in a collaborative scenario. In this respect, this paper presents a systematic review about SNA metrics used for analysing CSCL scenarios and proposes to trace the behaviour of such metrics during experiences through the inclusion of a temporal dimension. In order to expose this approach, a real collaborative learning experience, supported by a platform called SMLearning System, was analysed. We found that social relationships among students tend to be symmetric, i.e., there was a proportional distribution of efforts and contributions of students, which is an expected condition in a collaborative scenario. Such observations are based on the temporal behaviour of the reciprocity metric and the correlation between in- and out- degree centrality metrics measured in time.","Measurement,
Collaboration,
Collaborative work,
Context,
Social network services,
Analytical models,
Communities"
A Spiking Neural Network System for Robust Sequence Recognition,"This paper proposes a biologically plausible network architecture with spiking neurons for sequence recognition. This architecture is a unified and consistent system with functional parts of sensory encoding, learning, and decoding. This is the first systematic model attempting to reveal the neural mechanisms considering both the upstream and the downstream neurons together. The whole system is a consistent temporal framework, where the precise timing of spikes is employed for information processing and cognitive computing. Experimental results show that the system is competent to perform the sequence recognition, being robust to noisy sensory inputs and invariant to changes in the intervals between input stimuli within a certain range. The classification ability of the temporal learning rule used in the system is investigated through two benchmark tasks that outperform the other two widely used learning rules for classification. The results also demonstrate the computational power of spiking neurons over perceptrons for processing spatiotemporal patterns. In summary, the system provides a general way with spiking neurons to encode external stimuli into spatiotemporal spikes, to learn the encoded spike patterns with temporal learning rules, and to decode the sequence order with downstream neurons. The system structure would be beneficial for developments in both hardware and software.",
"Expanding the Compute-and-Forward Framework: Unequal Powers, Signal Levels, and Multiple Linear Combinations","The compute-and-forward framework permits each receiver in a Gaussian network to directly decode a linear combination of the transmitted messages. The resulting linear combinations can then be employed as an end-to-end communication strategy for relaying, interference alignment, and other applications. Recent efforts have demonstrated the advantages of employing unequal powers at the transmitters and decoding more than one linear combination at each receiver. However, neither of these techniques fit naturally within the original formulation of compute-and-forward. This paper proposes an expanded compute-and-forward framework that incorporates both of these possibilities and permits an intuitive interpretation in terms of signal levels. Within this framework, recent achievability and optimality results are unified and generalized.","Lattices,
Receivers,
Transmitters,
Decoding,
Encoding,
Interference,
Network coding"
Continuous Authentication Using One-Dimensional Multi-Resolution Local Binary Patterns (1DMRLBP) in ECG Biometrics,"The objective of a continuous authentication system is to continuously monitor the identity of subjects using biometric systems. In this paper, we proposed a novel feature extraction and a unique continuous authentication strategy and technique. We proposed One-Dimensional Multi-Resolution Local Binary Patterns (1DMRLBP), an online feature extraction for one-dimensional signals. We also proposed a continuous authentication system, which uses sequential sampling and 1DMRLBP feature extraction. This system adaptively updates decision thresholds and sample size during run-time. Unlike most other local binary patterns variants, 1DMRLBP accounts for observations' temporal changes and has a mechanism to extract one feature vector that represents multiple observations. 1DMRLBP also accounts for quantization error, tolerates noise, and extracts local and global signal morphology. This paper examined electrocardiogram signals. When 1DMRLBP was applied on the University of Toronto database (UofTDB) 1,012 single session subjects database, an equal error rate (EER) of 7.89% was achieved in comparison to 12.30% from a state-of-the-art work. Also, an EER of 10.10% was resulted when 1DMRLBP was applied to UofTDB 82 multiple sessions database. Experiments showed that using 1DMRLBP improved EER by 15% when compared with a biometric system based on raw time-samples. Finally, when 1DMRLBP was implemented with sequential sampling to achieve a continuous authentication system, 0.39% false rejection rate and 1.57% false acceptance rate were achieved.",
A linearithmic time algorithm for a shortest vector problem in compute-and-forward design,"We modify the algorithm proposed by Sahraei et al. in 2015, resulting an algorithm with expected complexity of O(n log n) arithmetic operations to solve a special shortest vector problem arising in computer-and-forward design, where n is the dimension of the channel vector. This algorithm is more efficient than the best known algorithms with proved complexity.","Algorithm design and analysis,
Complexity theory,
Approximation algorithms,
Linear programming,
Information theory,
Electronic mail,
Gaussian distribution"
Signal-to-Noise Enhancement in Optical Detection of Single Viruses With Multispot Excitation,"We present fluorescence detection of single H1N1 viruses with enhanced signal to noise ratio (SNR) achieved by multispot excitation in liquid-core antiresonant reflecting optical waveguides (ARROWs). Solid-core Y-splitting ARROW waveguides are fabricated orthogonal to the liquid-core section of the chip, creating multiple excitation spots for the analyte. We derive expressions for the SNR increase after signal processing, and analyze its dependence on signal levels and spot number. Very good agreement between theoretical calculations and experimental results is found. SNR enhancements up to 5×104 are demonstrated.",
Enabling Accurate and Practical Online Flash Channel Modeling for Modern MLC NAND Flash Memory,"NAND flash memory is a widely used storage medium that can be treated as a noisy channel. Each flash memory cell stores data as the threshold voltage of a floating gate transistor. The threshold voltage can shift as a result of various types of circuit-level noise, introducing errors when data are read from the channel and ultimately reducing flash lifetime. An accurate model of the threshold voltage distribution across flash cells can enable mechanisms within the flash controller that improve channel reliability and device lifetime. Unfortunately, existing threshold voltage distribution models are either not accurate enough or have high computational complexity, which makes them unsuitable for online implementation within the controller. We propose a new low-complexity flash memory model, built upon a modified version of the Student's t-distribution and the power law, which captures the threshold voltage distribution and predicts future distribution shifts as wear increases. Using our experimental characterization of the state-of-the-art 1X-nm (i.e., 15-19 nm) multi-level cell NAND flash chips, we show that our model is highly accurate (with an average modeling error of 0.68%), and also simple to compute within the flash controller (requiring 4.41 times less computation time than the most accurate prior model, with negligible decrease in accuracy). Our model also predicts future threshold voltage distribution shifts with a 2.72% modeling error. We demonstrate several example applications of our model in the flash controller, which improve flash channel reliability significantly, including a new mechanism to predict the remaining lifetime of a flash device. Our evaluations for two of these applications show that our model: 1) helps improve flash memory lifetime by 48.9% and/or (2) enables the flash device to safely sustain 69.9% more write operations than manufacturer specifications. We hope and believe that the analyses and models developed in this paper can inspire other novel approaches to flash memory reliability and modeling.",
Performance Analysis of Plant Monitoring Nanosensor Networks at THz Frequencies,"Future wireless nanosensor networks are envisioned to operate in the THz band, due to the tiny size of the network components. Among the diverse range of applications that such networks promise, high-resolution plant monitoring systems are the categories which can benefit from the size and high sensitivity of nanosensor devices and also the high bandwidth provided by them. However, communications at the THz frequency band, especially within a hybrid channel like plant foliage, undergo peculiar types of attenuation and distortion. These phenomena, which can challenge the feasibility of the aforementioned applications, need to be addressed/modeled precisely. Therefore, in this paper, we propose the first THz path-loss model within a plant environment. In addition, we provide a simplified model of plant structure as well as a model for the probability of successful transmissions between nanosensors and microscale receivers mounted on the plant stem. The introduced models consider the limited capability of THz radiation to propagate through plant leaves, and also the high free-space path-loss as the main sources of signal loss in the network communications. Furthermore, these models can be customized based on the structural characteristics of a plant, e.g., leaves size and distribution, to account for a variety of plant species. Finally, the performance of communications based on the provided models is evaluated for different network scenarios.","Nanoscale devices,
Atmospheric modeling,
Absorption,
Monitoring,
Permittivity,
Scattering,
Attenuation"
A Cloud-Based Seizure Alert System for Epileptic Patients That Uses Higher-Order Statistics,"Epilepsy is a chronic disease that causes seizures. Automatic detection of a seizure before its occurrence could protect patients from accidents and potentially save their lives. This article proposes a framework that automatically predicts seizures by analyzing EEG signals. The wireless sensor technology captures brain signals, and cloud-based services are used to collect and analyze EEG data from a patient's mobile phone. Features from the EEG signal are extracted by using the fast Walsh-Hadamard transform (FWHT), and a higher-order spectral analysis is applied to FWHT coefficients to reduce the feature set relevant to normal, preictal, and ictal states of seizure. The entropy-based features are classified using the Gaussian process classification algorithm. The performance of the proposed model is tested on the Amazon EC2 cloud and assessed in terms of execution time and accuracy.",
Coping With Emerging Mobile Social Media Applications Through Dynamic Service Function Chaining,"User generated content (UGC)-based applications are gaining lots of popularity among the community of mobile internet users. They are populating video platforms and are shared through different online social services, giving rise to the so-called mobile social media applications. These applications are characterized by communication sessions that frequently and dynamically update content, shared with a potential number of mobile users, sharing the same location or being dispersed over a wide geographical area. Since most of UGC content of mobile social media applications are exchanged through mobile devices, it is expected that along with online social applications, these content will cause severe congestion to mobile networks, impacting both their core and radio access networks. In this paper, we address the challenges introduced by these applications devising a complete framework that 1) identifies such applications/sessions and 2) initiates multicast-based delivery (or offload through WiFi) of the relevant content. The proposed framework leverages the network function virtualization (NFV) paradigm to dynamically integrate its functionalities to the operators' service function chaining (SFC) process, allowing fast deployment and lowering both capital and operational expenditures (CAPEX and OPEX) of the mobile operators. The performance of the proposed framework is evaluated through mathematical analysis and computer simulations, taking Twitter-like social applications as an example.","Mobile communication,
Mobile computing,
Streaming media,
Media,
Twitter,
Wireless communication"
Stackelberg Game Approach for Energy-Aware Resource Allocation in Data Centers,"Data centers hosting distributed computing systems consume huge amounts of electrical energy, contributing to high operational costs, whereas the utilization of data centers continues to be very low. Moreover, a data center generally consists of heterogeneous servers with different performance and energy. Failure to fully consider the heterogeneity of servers will lead to both sub-optimal energy saving and performance. In this study, we employ game theoretic approaches to model the problem of minimizing energy consumption as a Stackelberg game. In our model, the system monitor, who plays the role of the leader, can maximize profit by adjusting resource provisioning, whereas scheduler agents, who act as followers, can select resources to obtain optimal performance. In addition, we model the problem of minimizing average response time of tasks as a noncooperative game among decentralized scheduler agents as they compete with one another in the sharing resources. Several algorithms are presented to implement the game models. Simulation results demonstrate that the proposed technique has immense potential to improve energy efficiency under dynamic work scenarios without compromising service level agreements.",
Sojourn Time-Based Velocity Estimation in Small Cell Poisson Networks,"Due to the increasing density of small cells, mobility management in heterogeneous networks has become a challenging task. One key challenge facing the development of advanced mobility management techniques is the accurate estimation of the users' velocity. One simple way to estimate a user's velocity is via the use of sojourn time samples. In this letter, the Cramer-Rao lower bound (CRLB) for the sojourn time-based velocity estimation is analyzed. Stochastic geometry is used for the spatial modeling of small cells, and the CRLB is derived using the tools from estimation theory. An asymptotically unbiased velocity estimator is also derived. Our analysis shows that the sojourn time-based velocity estimation exhibit a lower CRLB compared to the CRLB of classical velocity estimation using handover count.","Estimation,
Handover,
Computer architecture,
Accuracy,
Microprocessors,
Long Term Evolution"
A Round-based Data Replication Strategy,"Data Grid allows many organizations to share data across large geographical area. The idea behind data replication is to store copies of the same file at different locations. Therefore, if a copy at a location is lost or not available, it can be brought from another location. Additionally, data replication results in a reduced time and bandwidth because of bringing the file from a closer location. However, the files that need to be replicated have to be selected wisely. In this paper, a round-based data replication strategy is proposed to select the most appropriate files for replication at the end of each round based on a number of factors. The proposed strategy is based on Popular File Replicate First (PFRF) strategy, and it overcomes the drawbacks of PFRF. The simulation results show that the proposed strategy yields better performance in terms of average file delay per request, average file bandwidth consumption per request, and percentage of files found.","Heuristic algorithms,
Clustering algorithms,
Bandwidth,
Distributed databases,
Servers,
Educational institutions,
Electronic mail"
Empirical Studies of a Two-Stage Data Preprocessing Approach for Software Fault Prediction,"Software fault prediction is a valuable exercise in software quality assurance to best allocate limited testing resources. Classification is one of the effective methods for software fault prediction. The classification models are trained based on the datasets obtained by mining software historical repositories. However, the performance of the models depends on the quality of datasets. In this paper, we propose a novel two-stage data preprocessing approach which incorporates both feature selection and instance reduction. Specifically, in the feature selection stage, we first perform relevance analysis, and then propose a threshold-based clustering method, called novel threshold-based clustering algorithm, to conduct redundancy control. In the instance reduction stage, we apply random under-sampling to keep the balance between the faulty and non-faulty instances. In empirical studies, we chose datasets from real-world software projects, such as Eclipse and NASA. Then we compared our approach with some classical baseline methods, and further investigated the influencing factors in our approach. The final results demonstrate the effectiveness of our approach, and provide a guideline for achieving cost-effective data preprocessing when using our two-stage approach.","Software,
Data preprocessing,
Clustering algorithms,
Measurement uncertainty,
Gain measurement,
Area measurement,
Software measurement"
Enhancement of Synchronizability in Networks with Community Structure through Adding Efficient Inter-Community Links,"In this paper we propose a framework for enhancing synchronizability of networks with community structure through adding efficient inter-community links. Adding new inter-community links to a network with community structure usually improves its synchronizability. However, this is achieved by increasing communication cost in the network. Thus, the links should be designed in a way that adding them results in maximal improvement. Here, we first consider two disjoint communities, and then, propose an algorithm for choosing nodes from each community to create a certain number of inter-community links between them. We propose an efficient rewiring algorithm, which uses a criterion based on eigenvectors corresponding to the largest and second smallest eigenvalues of the Laplacian matrix. The algorithm uses a modified simulated annealing approach for the optimization process. Extensive numerical simulations show that the proposed algorithm can systematically improve the synchronizability of the network as defined by the eigenratio of the Laplacian. We also show that the proposed rewiring algorithm outperforms heuristic methods such as finding the best possible inter-community links between hub nodes, while having much better computational complexity as well. We study the properties of the end-nodes connected to the final optimized inter-community links. We find that in some cases these nodes have much less centrality values (e.g., degree and betweenness) than the hub nodes of the communities, which means that the optimization algorithm finds non-hub nodes to create inter-community connections in between. The optimized networks are also shown to be good structures for phase synchronizability of non-identical oscillators.","Synchronization,
Algorithm design and analysis,
Stability analysis,
Laplace equations,
Optimization,
Manifolds,
Eigenvalues and eigenfunctions"
On the Properties of Non-Media Digital Watermarking: A Review of State of the Art Techniques,"Over the last 25 years, there has been much work on multimedia digital watermarking. In this domain, the primary limitation to watermark strength has been in its visibility. For multimedia watermarks, invisibility is defined in human terms (that is, in terms of human sensory limitations). In this paper, we review recent developments in the non-media applications of data watermarking, which have emerged over the last decade as an exciting new sub-domain. Since by definition, the intended receiver should be able to detect the watermark, we have to redefine invisibility in an acceptable way that is often application-specific and thus cannot be easily generalized. In particular, this is true when the data is not intended to be directly consumed by humans. For example, a loose definition of robustness might be in terms of the resilience of a watermark against normal host data operations, and of invisibility as resilience of the data interpretation against change introduced by the watermark. In this paper, we classify the data in terms of data mining rules on complex types of data such as time-series, symbolic sequences, data streams, and so forth. We emphasize the challenges involved in non-media watermarking in terms of common watermarking properties, including invisibility, capacity, robustness, and security. With the aid of a few examples of watermarking applications, we demonstrate these distinctions and we look at the latest research in this regard to make our argument clear and more meaningful. As the last aim, we look at the new challenges of digital watermarking that have arisen with the evolution of big data.","Watermarking,
Digital watermarking,
Multimedia communication,
Receivers,
Data mining,
Big data,
Information security"
Edge detection in medical ultrasound images using adjusted Canny edge detection algorithm,"Ultrasound medical images are very important component of the diagnostics process. They are widely used since ultrasound is a non-invasive and non-ionizing diagnostics method. As a part of image analysis, edge detection is often used for further segmentation or more precise measurements of elements in the picture. Edges represent high frequency components of an image. Unfortunately, ultrasound images are subject to degradations, especially speckle noise which is also a high frequency component. That poses a problem for edge detection algorithms since filters for noise removal also degrade edges. Canny operator is widely used as an excellent edge detector, however it also includes Gaussian smoothing element that may significantly soften edges. In this paper we propose a modified Canny algorithm where Gaussian smoothing is replaced by modified median filter that successfully removes speckle noise with little degradation of edges followed by weak weighted smoothing filter that in a controlled way removes other noise, again with insignificant damage to the edges. Our proposed algorithm was tested on standard benchmark image and compared to other approaches from literature where it proved to be successful in precisely determining edges of internal organs.",
An integrated jumping-crawling robot using height-adjustable jumping module,"In this paper, we propose a trajectory-adjustable integrated milli-scale jumping-crawling robot with improved ability to overcome obstacles compared to a robot that can only crawl. The robot employs a novel jumping module with enhanced energy storing-capacity and a height-adjustable active trigger. To increase the energy-storing capacity, latex rubber and knee-like joints are employed to utilize large displacement of the elastic material. The active trigger is based on a single DC motor and can release stored energy at any state, enabling the robot to control the take-off speed of jumping. The jumping module is integrated with the lightweight Dash crawler. The integrated jumping-crawling robot weighs 59.4 g and controls its moving trajectory by adjusting both its crawling speed and its jumping take-off speed.",
Scalable graph signal recovery for big data over networks,"We formulate the recovery of a graph signal from noisy samples taken on a subset of graph nodes as a convex optimization problem that balances the empirical error for explaining the observed values and a complexity term quantifying the smoothness of the graph signal. To solve this optimization problem, we propose to combine the alternating direction method of multipliers with a novel denoising method that minimizes total variation. Our algorithm can be efficiently implemented in a distributed manner using message passing and thus is attractive for big data problems over networks.","Noise measurement,
Message passing,
Optimization,
Noise reduction,
TV,
Big data,
Biological system modeling"
Adaptive Lookup of Open WiFi Using Crowdsensing,"Open WiFi access points (APs) are demonstrating that they can provide opportunistic data services to moving vehicles. We present CrowdWiFi, a novel system to look up roadside WiFi APs located outdoors or inside buildings. CrowdWiFi consists of two components: online compressive sensing (CS) and offline crowdsourcing. Online CS presents an efficient framework for the coarse-grained estimation of nearby APs along the driving route, where received signal strength (RSS) values are recorded at runtime, and the number and location of the APs are recovered immediately based on limited RSS readings and adaptive CS operations. Offline crowdsourcing assigns the online CS tasks to crowd-vehicles and aggregates answers on a bipartite graphical model. Crowd-server also iteratively infers the reliability of each crowd-vehicle from the aggregated sensing results, and then refines the estimation of the APs using weighted centroid processing. Extensive simulation results and real testbed experiments confirm that CrowdWiFi can successfully reduce the computation cost and energy consumption of roadside WiFi lookup, while maintaining satisfactory localization accuracy.","IEEE 802.11 Standard,
Vehicles,
Mobile communication,
Crowdsourcing,
Estimation,
Reliability,
Compressed sensing"
Improved Retention Time in Twin Gate 1T DRAM With Tunneling Based Read Mechanism,We report a twin gate tunnel field effect transistor-based capacitorless dynamic memory with improved retention characteristics through well-calibrated simulations. The first front gate of the twin gate architecture regulates the read mechanism based on band-to-band tunneling whereas the second front gate creates and maintains a dedicated volume for the charge storage near the drain region. The profound well along with the optimized bias values aid to attain a retention time (RT) of ~1.5 s at 85°C. Systematic analysis shows that the storage region can be scaled down to 50 nm with further improvement in RT by using an underlap region between drain and second gate. Optimally designed twin gate device exhibits an improved RT at higher temperature (125°C).,"Logic gates,
TFETs,
Random access memory,
Tunneling,
Electric potential,
Computer architecture,
Charge carrier processes"
Miniaturized NFC Antenna Design for a Tablet PC With a Narrow Border and Metal Back-Cover,"A novel structure of the near-field communication (NFC) antenna design for a tablet PC is proposed. This tablet PC has a narrow border and full metallic back-cover. A miniaturized loop antenna design is achieved by attaching ferrite sheets on both sides of the loop antenna. The ferrite sheets may reduce eddy currents induced on the adjacent metallic back-cover by the loop antenna to improve the communication range of the NFC. Only the edge of the tablet PC allows the antenna to radiate due to the full metallic back-cover. Thus, the NFC antenna needs to be narrow to be installed on the edge of the tablet PC. Therefore, we propose a miniaturized NFC antenna with the dimensions of 41.5 (L) × 7.5 (W) × 0.45 (T) mm3 only. Simulated magnetic field distributions are consistent with measured voltage distributions. This design has a good communication range more than 6 cm in front of the touchscreen panel and reaches 2 cm over the other side above the metal back-cover.",
Scalable Temporal Latent Space Inference for Link Prediction in Dynamic Social Networks,"We propose a temporal latent space model for link prediction in dynamic social networks, where the goal is to predict links over time based on a sequence of previous graph snapshots. The model assumes that each user lies in an unobserved latent space, and interactions are more likely to occur between similar users in the latent space representation. In addition, the model allows each user to gradually move its position in the latent space as the network structure evolves over time. We present a global optimization algorithm to effectively infer the temporal latent space. Two alternative optimization algorithms with local and incremental updates are also proposed, allowing the model to scale to larger networks without compromising prediction accuracy. Empirically, we demonstrate that our model, when evaluated on a number of real-world dynamic networks, significantly outperforms existing approaches for temporal link prediction in terms of both scalability and predictive power.","Prediction algorithms,
Social network services,
Predictive models,
Computational modeling,
Heuristic algorithms,
Electronic mail,
Computational efficiency"
Chameleon: Survey-Free Updating of a Fingerprint Database for Indoor Localization,"In fingerprint-based indoor localization, keeping fingerprints current is important for localization accuracy. Because access point (AP) signals can change over time or suddenly, the traditional approach is to survey the site regularly and frequently, which is laborious and costly. The authors propose Chameleon, a novel survey-free approach to localize users and maintain an updated fingerprint database despite fingerprint signal changes. In Chameleon, clients are both location ""queriers"" and unconscious ""surveyors"" (implicit crowdsourcing). Independent of and amenable to any fingerprint-based localization algorithm, Chameleon employs a clustering algorithm to filter out the altered AP signals to achieve high localization accuracy. Using the calculated location and the collected signals of the client, the fingerprint database can be continuously updated without manual intervention. Extensive experimental trials at The Hong Kong University of Science and Technology and at the Hong Kong International Airport confirm that Chameleon can adapt the radio map to the current signal environment and achieve low localization error despite signal changes.","Fingerprint identification,
Indoor communication,
Mobile computing,
Mobile radio mobility management,
Database management"
Wireless Multichannel Neural Recording With a 128-Mbps UWB Transmitter for an Implantable Brain-Machine Interfaces,"Simultaneous recordings of neural activity at large scale, in the long term and under bio-safety conditions, can provide essential data. These data can be used to advance the technology for brain-machine interfaces in clinical applications, and to understand brain function. For this purpose, we present a new multichannel neural recording system that can record up to 4096-channel (ch) electrocorticogram data by multiple connections of customized application-specific integrated circuits (ASICs). The ASIC includes 64-ch low-noise amplifiers, analog time-division multiplexers, and 12-bit successive approximation register ADCs. Recorded data sampled at a rate of 1 kS/s are multiplexed with time division via an integrated multiplex board, and in total 51.2 Mbps of raw data for 4096 ch are generated. This system has an ultra-wideband (UWB) wireless unit for transmitting the recorded neural signals. The ASICs, multiplex boards, and UWB transmitter unit are designed with the aim of implanting them. From preliminary experiments with a human body-equivalent liquid phantom, we confirmed 4096-ch UWB wireless data transmission at 128 Mbps for distances below 20 mm .","Wireless communication,
Application specific integrated circuits,
Multiplexing,
Ultra wideband technology,
Implants,
Brain-computer interfaces"
Clock synchronization and ranging estimation for control and cooperation of multiple UUVs,"This paper presents the initial implementation of an acoustic synchronization and ranging system to enable the control and cooperation of multiple Unmanned Underwater Vehicles (UUVs). Our solution is based on acoustic clock synchronization and one-way ranging. It requires minimum overhead while providing accurate and quick estimation of the relative distances among underwater nodes. The use of one-way ranging allows to scale up to large teams of UUVs and reduces the energy consumption of localization techniques. Our solution has been implemented in SUNSET, leveraging on the accurate timing information and scheduled transmissions provided by SeaModem acoustic modems. Chip Scale Atomic Clocks have been integrated in the SeaModem to overcome the typical drift of real-time clocks thus enabling accurate one-way ranging estimation during long term missions. The performance of the proposed system have been extensively evaluated in two at-sea campaigns considering different testing scenarios. We have shown that our scheme is able to maintain high ranging accuracy over time without requiring the high overhead and energy consumption of two way ranging techniques. We have also shown that the proposed scheme for acoustic synchronization is very effective in synchronizing real-time and atomic clocks of underwater nodes, whenever needed. Our results confirm that the proposed solution for synchronization and one-way ranging allows to enable the control of multiple UUVs keeping at the bay the overhead in the network and the time needed to estimate relative distances.","Synchronization,
Clocks,
Acoustics,
Distance measurement,
Modems,
Estimation,
Protocols"
Mils-Cloud: A Sensor-Cloud-Based Architecture for the Integration of Military Tri-Services Operations and Decision Making,"Spatially distributed sensor nodes in wireless sensor networks (WSNs) can be used to monitor large unmanned areas. However, there are many limitations to WSNs, and the influence and accessibility of the sensors in these networks are limited to localized areas. Another popular technology today is cloud computing (CC). CC can provide a potent and scalable processing and storage infrastructure that can be used to perform the analysis of online as well as offline data streams provided by the sensors. It is possible to virtualize the sensor networks to provide these networks as a utility service. In this paper, we propose “Mils-Cloud,” which is a sensor-cloud architecture utilizing this infrastructure for developing architecture for the integration of military tri-services in a battlefield scenario. We propose a hierarchical architecture of sensor-cloud with users having different levels of priority. The results show that reserving about 20%-25% of resources actually boosts the performance of the system for priority users without compromising the availability for normal users.",
Reconfigurable Planar Capacitive Coupling in Substrate-Integrated Coaxial-Cavity Filters,"This paper expands our previous work on planar tunable capacitive coupling structures in substrate-integrated cavities using lumped components. We demonstrate both frequency and bandwidth tunable filters with adjustable transmission zeros (TZs). By the appropriate choice of the absolute and relative strength of magnetic and electric coupling coefficients, we demonstrate: 1) tunable bandwidth and the ability to maintain either a constant absolute bandwidth or a constant fractional bandwidth; 2) adjustable TZ location at a prescribed bandwidth; and 3) the ability to switch OFF the filter with high isolation. Filter design methodologies based on a dispersive coupling structure are presented using lumped circuit models, coupling matrix, and full-wave simulations. With this planar capacitive coupling, it is also convenient to realize cross-coupling in higher order filters to produce additional TZs for rejecting spurious resonances or interferes. Fabricated two-pole filters with one or two TZs and four-pole filters with three or four TZs validate the filter design. A two-pole filter with tunable center frequency and tunable bandwidth along with a four-pole filter with tunable center frequency and tunable TZs are also demonstrated.",
Dynamic Job Ordering and Slot Configurations for MapReduce Workloads,"MapReduce is a popular parallel computing paradigm for large-scale data processing in clusters and data centers. A MapReduce workload generally contains a set of jobs, each of which consists of multiple map tasks followed by multiple reduce tasks. Due to 1) that map tasks can only run in map slots and reduce tasks can only run in reduce slots, and 2) the general execution constraints that map tasks are executed before reduce tasks, different job execution orders and map/reduce slot configurations for a MapReduce workload have significantly different performance and system utilization. This paper proposes two classes of algorithms to minimize the makespan and the total completion time for an offline MapReduce workload. Our first class of algorithms focuses on the job ordering optimization for a MapReduce workload under a given map/reduce slot configuration. In contrast, our second class of algorithms considers the scenario that we can perform optimization for map/reduce slot configuration for a MapReduce workload. We perform simulations as well as experiments on Amazon EC2 and show that our proposed algorithms produce results that are up to 15 ~ 80 percent better than currently unoptimized Hadoop, leading to significant reductions in running time in practice.","Optimization,
Approximation algorithms,
Computational modeling,
Facebook,
Heuristic algorithms,
Approximation methods,
Algorithm design and analysis"
Traffic sign recognition with convolutional neural network based on max pooling positions,"Recognition of traffic signs is vary important in many applications such as in self-driving car/driverless car, traffic mapping and traffic surveillance. Recently, deep learning models demonstrated prominent representation capacity, and achieved outstanding performance in traffic sign recognition. In this paper, we propose a traffic sign recognition system by applying convolutional neural network (CNN). In comparison with previous methods which usually use CNN as feature extractor and multi-layer perception (MLP) as classifier, we proposed max pooling positions (MPPs) as an effective discriminative feature to predict category labels. Through extensive experiments, MPPs demonstrates the ideal characteristics of small inter-class variance and large intra-class variance. Moreover, with the German Traffic Sign Recognition Benchmark (GTSRB), outstanding performance has been achieved by using MPPs.","Feature extraction,
Training,
Computational modeling,
Biological system modeling,
Convolution,
Neural networks,
Visualization"
DSCNN: Hardware-oriented optimization for Stochastic Computing based Deep Convolutional Neural Networks,"Deep Convolutional Neural Networks (DCNN), a branch of Deep Neural Networks which use the deep graph with multiple processing layers, enables the convolutional model to finely abstract the high-level features behind an image. Large-scale applications using DCNN mainly operate in high-performance server clusters, GPUs or FPGA clusters; it is restricted to extend the applications onto mobile/wearable devices and Internet-of-Things (IoT) entities due to high power/energy consumption. Stochastic Computing is a promising method to overcome this shortcoming used in specific hardware-based systems. Many complex arithmetic operations can be implemented with very simple hardware logic in the SC framework, which alleviates the extensive computation complexity. The exploration of network-wise optimization and the revision of network structure with respect to stochastic computing based hardware design have not been discussed in previous work. In this paper, we investigate Deep Stochastic Convolutional Neural Network (DSCNN) for DCNN using stochastic computing. The essential calculation components using SC are designed and evaluated. We propose a joint optimization method to collaborate components guaranteeing a high calculation accuracy in each stage of the network. The structure of original DSCNN is revised to accommodate SC hardware design's simplicity. Experimental Results show that as opposed to software inspired feature extraction block in DSCNN, an optimized hardware oriented feature extraction block achieves as higher as 59.27% calculation precision. And the optimized DSCNN can achieve only 3.48% network test error rate compared to 27.83% for baseline DSCNN using software inspired feature extraction block.","Feature extraction,
Hardware,
Neurons,
Optimization,
Neural networks,
Stochastic processes,
Software"
Plasma-Enabled Tuning of a Resonant RF Circuit,"A concept of plasma-enabled tuning of radio frequency systems is introduced and experimentally verified in this paper. Specifically, a commercial gas discharge tube (GDT) is employed as a plasma cell integrated in an inductor-capacitor (LC) resonator. The principal factor affecting the characteristics of the LC circuit with the embedded GDT, studied for the first time in this paper, is the decrease in the cathode sheath thickness and thus increase in the capacitance of the plasma cell with increasing current in the abnormal glow discharge regime. The reduction of plasma cell resistance is an additional factor. The sample LC resonator demonstrates frequency tunability by 55% in the range of 240-372 MHz, while the discharge current increases up to 90 mA, at the expense of reduction in quality factor from 62 to 5 as a result of ohmic losses. Theoretical estimates based on the fundamental principles of glow discharges supplemented by circuit simulations show good agreement with measurements. The local minimum in frequency behavior of the resonator's quality factor is shown to be related to frequency-dependent plasma parameters. The results of this paper indicate that plasma tuning techniques could be a viable alternative for emerging applications.","Plasmas,
Discharges (electric),
Radio frequency,
Tuning,
Cathodes,
Resonant frequency"
Support Vector Feature Selection for Early Detection of Anastomosis Leakage From Bag-of-Words in Electronic Health Records,"The free text in electronic health records (EHRs) conveys a huge amount of clinical information about health state and patient history. Despite a rapidly growing literature on the use of machine learning techniques for extracting this information, little effort has been invested toward feature selection and the features' corresponding medical interpretation. In this study, we focus on the task of early detection of anastomosis leakage (AL), a severe complication after elective surgery for colorectal cancer (CRC) surgery, using free text extracted from EHRs. We use a bag-of-words model to investigate the potential for feature selection strategies. The purpose is earlier detection of AL and prediction of AL with data generated in the EHR before the actual complication occur. Due to the high dimensionality of the data, we derive feature selection strategies using the robust support vector machine linear maximum margin classifier, by investigating: 1) a simple statistical criterion (leave-one-out-based test); 2) an intensive-computation statistical criterion (Bootstrap resampling); and 3) an advanced statistical criterion (kernel entropy). Results reveal a discriminatory power for early detection of complications after CRC (sensitivity 100%; specificity 72%). These results can be used to develop prediction models, based on EHR data, that can support surgeons and patients in the preoperative decision making phase.","Support vector machines,
Kernel,
Entropy,
Surgery,
Probability density function,
Feature extraction,
Vectors"
Design of Wavetraps for Isolation Improvement in Compact In-Band Full-Duplex Relay Antennas,"In full-duplex (FDX) multiple-input and multiple-output (MIMO) systems, the self-interference between each transmitting and receiving antenna, caused by finite isolation between antennas, limits the obtainable signal-to-interference ratio of the system and thus the total capacity. In this paper, the design of planar wavetraps for isolation improvement between multiple antennas is introduced, with an emphasis on back-to-back relay structures. General guidelines for the design of planar wavetraps are deduced which could be applied also in isolation improvement of other antenna structures. A prototype back-to-back relay antenna with two dual-polarized patches for FDX MIMO is presented with the frequency of operation of 2.6 GHz. The prototype antenna is manufactured and the simulated results are validated with measurements. The minimum isolation among each antenna pair on the opposite sides of the relay is improved by 20 dB across a 18-MHz bandwidth, while 15-dB improvement can be obtained across 167-MHz bandwidth, yielding total isolation levels of 70 and 65 dB, respectively. The radiation pattern of the relay antenna is measured with and without wavetraps to show that the wavetraps do not have significant effect on the main lobe radiation properties.","Relays,
MIMO,
Receiving antennas,
Ports (Computers),
Antenna radiation patterns,
Couplings"
Performance and analysis of downlink multiuser MIMO systems with regularized zero-forcing precoding in Ricean fading channels,"Analytical expressions to approximate the expected per-user signal-to-interference-plus-noise-ratio (SINR) and ergodic sum-rate of a multiuser multiple-input-multiple-output system are presented. Our analysis assumes uncorrelated Ricean fading channels with regularized zero-forcing precoding on the downlink. The derived expressions are averaged with respect to the previously unknown arbitrary eigenvalue densities of the complex non-central Wishart distributed channel correlation matrix. To aid the derivation of the expected SINR, we derive analytical expressions for the joint density of two arbitrary eigenvalues of the complex non-central Wishart matrix. Unlike previous studies, our model caters to the presence of a unique Rice factor for each user terminal, making it suitable for analysis of modern systems, such as small cells and millimeter-wave. Our findings suggest that while the presence of strong line-of-sight has an adverse effect on the expected SINR and ergodic sum-rates, increasing the variability of Rice factors enhances the peak rate performance of the system. Our analysis can be applied to arbitrary system dimensions and is seen to remain tight across the signal-to-noise-ratio range considered.","Signal to noise ratio,
Interference,
Fading channels,
Precoding,
Eigenvalues and eigenfunctions,
Downlink,
Linear antenna arrays"
An Energy Efficiency Node Scheduling Model for Spatial-Temporal Coverage Optimization in 3D Directional Sensor Networks,"Low-power green communication has become the utmost important and promising research topic for energy efficiency communications. In this paper, we investigated the energy efficiency green communication in 3-D directional sensor networks. Coverage and schedule are two fundamental research issues for energy efficiency in wireless sensor networks. In network lifetime sensitive scenarios, how to consider the network lifetime as the constraint to trade coverage for network lifetime has not been well investigated. Based on the 3-D sensing model of directional sensors, we address this problem of maximizing the spatial-temporal coverage by scheduling sensors' activity after they have been deployed. First, two elementary region generation approaches, grid-based algorithm, and position-based algorithm are proposed. Then, a spatial-temporal coverage optimization scheduling (STCOS) algorithm is designed to obtain the whole network coverage maximized. Finally, a set of simulation experiments are put forward to evaluate the performance of the proposed elementary regions generation schemes and STCOS algorithms. Experimental results show that compared with the grid-based elementary region generation scheme, the position-based scheme significantly reduces the algorithmic complexity and is time consuming while generating elementary regions in network. Further simulation results show that the proposed STCOS scheme effectively enhances the performance of spatial-temporal coverage optimization.",
An EEMD-ICA Approach to Enhancing Artifact Rejection for Noisy Multivariate Neural Data,"As neural data are generally noisy, artifact rejection is crucial for data preprocessing. It has long been a grand research challenge for an approach which is able: 1) to remove the artifacts and 2) to avoid loss or disruption of the structural information at the same time, thus the risk of introducing bias to data interpretation may be minimized. In this study, an approach (namely EEMD-ICA) was proposed to first decompose multivariate neural data that are possibly noisy into intrinsic mode functions (IMFs) using ensemble empirical mode decomposition (EEMD). Independent component analysis (ICA) was then applied to the IMFs to separate the artifactual components. The approach was tested against the classical ICA and the automatic wavelet ICA (AWICA) methods, which were dominant methods for artifact rejection. In order to evaluate the effectiveness of the proposed approach in handling neural data possibly with intensive noises, experiments on artifact removal were performed using semi-simulated data mixed with a variety of noises. Experimental results indicate that the proposed approach continuously outperforms the counterparts in terms of both normalized mean square error (NMSE) and Structure SIMilarity (SSIM). The superiority becomes even greater with the decrease of SNR in all cases, e.g., SSIM of the EEMD-ICA can almost double that of AWICA and triple that of ICA. To further examine the potentials of the approach in sophisticated applications, the approach together with the counterparts were used to preprocess a real-life epileptic EEG with absence seizure. Experiments were carried out with the focus on characterizing the dynamics of the data after artifact rejection, i.e., distinguishing seizure-free, pre-seizure and seizure states. Using multi-scale permutation entropy to extract feature and linear discriminant analysis for classification, the EEMD-ICA performed the best for classifying the states (87.4%, about 4.1% and 8.7% higher than that of AWICA and ICA respectively), which was closest to the results of the manually selected dataset (89.7%).",
Performance-Aware Cloud Resource Allocation via Fitness-Enabled Auction,"Cloud computing is a new computing paradigm which features renting the computation devices instead of buying them. In a typical cloud computing environment, there will always be different kinds of cloud resources and a number of cloud services making use of cloud resources to run on. As we can see, these cloud services usually have different performance traits. Some may be I/O-intensive, like those data querying services, while others might demand more CPU cycles, like 3D image processing services. Meanwhile, cloud resources also have different kinds of capabilities such as data processing, I/O throughput, 3D image rendering, etc. A simple fact is that allocating a suitable resource will greatly improve the performance of the cloud service, and make the cloud resource itself more efficient as well. In this paper, a new cloud resource allocating algorithm via fitness-enabled auction is proposed to guarantee the fitness of performance traits between cloud resources (sellers) and cloud services (buyers). We study the allocating algorithm in terms of economic efficiency and system performance, and experiments show that the allocation is far more efficient in comparison with the continuous double auction in which the idea of fitness is not introduced.","Resource management,
Standards,
Yarn,
Quality of service,
Cloud computing,
Acceleration,
Supply and demand"
High-Performance Reconfigurable Si Nanowire Field-Effect Transistor Based on Simplified Device Design,"Reconfigurable field-effect transistors (RFETs) are of interest as devices for dynamically switching between n- and p-type polarity which enables different logic computations using the same hardware. So far, RFETs have been realized with one or even two additional program gates for accomplishing reconfigurability. This paper presents an RFET design with just one single-gate on a silicon nanowire channel. Based on measured and device simulation data of a double-gate (DG) RFET, it is shown that the proposed simplified single-gate (SG) RFET achieves the same functionality and dc characteristics as the more complex DG-RFET. Besides reducing the wiring for the program gate(s), the SG-RFET has the additional advantage of being scalable to smaller channel length and thus achieving higher operating speed.","Logic gates,
Silicon,
Field effect transistors,
Schottky barriers,
Data models,
Control systems"
Big Data Meet Green Challenges: Greening Big Data,"Nowadays, there are two significant tendencies, how to process the enormous amount of data, big data, and how to deal with the green issues related to sustainability and environmental concerns. An interesting question is whether there are inherent correlations between the two tendencies in general. To answer this question, this paper firstly makes a comprehensive literature survey on how to green big data systems in terms of the whole life cycle of big data processing, and then this paper studies the relevance between big data and green metrics and proposes two new metrics, effective energy efficiency and effective resource efficiency in order to bring new views and potentials of green metrics for the future times of big data.",
Real-Time Multiple Event Detection and Classification Using Moving Window PCA,"This paper proposes a method for the detection and classification of multiple events in an electrical power system in real-time, namely; islanding, high frequency events (loss of load), and low frequency events (loss of generation). This method is based on principal component analysis of frequency measurements and employs a moving window approach to combat the time-varying nature of power systems, thereby increasing overall situational awareness of the power system. Numerical case studies using both real data, collected from the U.K. power system, and simulated case studies, constructed using DigSilent PowerFactory, for islanding events, as well as both loss of load and generation dip events, are used to demonstrate the reliability of the proposed method.","Principal component analysis,
Power systems,
Monitoring,
Real-time systems,
Event detection,
Phasor measurement units,
Time-frequency analysis"
Energy Management System for Stand-Alone Wind-Powered-Desalination Microgrid,"An energy management system for stand-alone microgrid consisting of a wind turbine (WT) generator, a diesel generator, an energy storage system (ESS), and a sea water desalination system is proposed in this paper. The coordinated control of the distributed generations and ESS is researched with two operation modes. Then, a real-time rolling horizon energy management method is presented based on hour-ahead wind speed forecast. The operation mode of the microgrid system and the reference output power of WT generator are determined according to the forecasted wind speed and state of charge of the ESS, which can achieve the goal of maximizing utilization of wind energy and minimizing utilization of diesel generator on the basis of system stable operation. The proposed energy management method has been tested on the real-time digital simulator system. The results clearly verify the effectiveness of the proposed method.",
Info-Clustering: A Mathematical Theory for Data Clustering,"We formulate an info-clustering paradigm based on a multivariate information measure, called multivariate mutual information, that naturally extends Shannon’s mutual information between two random variables to the multivariate case involving more than two random variables. With proper model reductions, we show that the paradigm can be applied to study the human genome and connectome in a more meaningful way than the conventional algorithmic approach. Not only can info-clustering provide justifications and refinements to some existing techniques, but it also inspires new computationally feasible solutions.","Mutual information,
Clustering algorithms,
Random variables,
Bioinformatics,
Genomics,
Biological information theory"
A Framework for Co-Channel Interference and Collision Probability Tradeoff in LTE Licensed-Assisted Access Networks,"Small cell deployment in heterogeneous networks, whereby small cell base stations (SBS) are deployed alongside traditional macro-cell base stations, is a proven solution for enhancing spatial frequency reuse across licensed spectrum in long-term evolution (LTE) networks. In order to mitigate the shortage of licensed spectrum resources, licensed-assisted access (LAA) has been introduced to allow LTE SBSs to share the unlicensed channel with WiFi nodes. As such, a complex yet interesting optimization problem results from the joint utilization of licensed and unlicensed spectrum resources by the SBSs to meet the quality-of-service (QoS) requirements of small cell users (SUEs). In this paper, we highlight the fundamental tradeoff induced by the SBSs between the amount of co-channel interference (CI) resulting from the reuse of licensed spectrum resources and the collision probability (CP) imposed on the co-existing WiFi nodes due to the sharing of unlicensed spectrum resources in such a coexisting LTE LAA-WiFi heterogeneous network deployment. We find that this fundamental tradeoff can be analyzed by developing a power allocation rule with double water-filling lines and the complete set of Pareto optimal solution can be achieved by the weighted Tchebycheff method. Our simulation results show that the proposed joint resource allocation algorithm can achieve a flexible and suitable tradeoff between the licensed spectrum CI and the WiFi CP according to the QoS requirements of SUEs in LTE LAA networks.","IEEE 802.11 Standard,
Resource management,
Interchannel interference,
Long Term Evolution,
Quality of service,
Electronic mail"
Robust All-in-Focus Super-Resolution for Focal Stack Photography,"We present an unconventional image super-resolution algorithm targeting focal stack images. Contrary to previous works, which align multiple images with sub-pixel accuracy for image super-resolution, we analyze the correlation among the differently focused narrow depth-of-field images in a focal stack to infer high-resolution details for image super-resolution. In order to accurately model the defocus kernels at different depths, we use a cubic interpolation to parameterize the projection of defocus kernels, and apply the radon transform to accurately reconstruct the defocus kernels at arbitrary depth. In the image super-resolution, we utilize the multi-image deconvolution method with a l1 -norm regularization to suppress noise and ringing artifacts. We have also extended the depth-of-field of our inputs to produce an all-in-focus super-resolution image. The effectiveness of our algorithm is demonstrated with the quantitative analysis using synthetic examples and the qualitative analysis using real-world examples.",
Leveraging Data Deduplication to Improve the Performance of Primary Storage Systems in the Cloud,"With the explosive growth in data volume, the I/O bottleneck has become an increasingly daunting challenge for big data analytics in the Cloud. Recent studies have shown that moderate to high data redundancy clearly exists in primary storage systems in the Cloud. Our experimental studies reveal that data redundancy exhibits a much higher level of intensity on the I/O path than that on disks due to relatively high temporal access locality associated with small I/O requests to redundant data. Moreover, directly applying data deduplication to primary storage systems in the Cloud will likely cause space contention in memory and data fragmentation on disks. Based on these observations, we propose a performance-oriented I/O deduplication, called POD, rather than a capacity-oriented I/O deduplication, exemplified by iDedup, to improve the I/O performance of primary storage systems in the Cloud without sacrificing capacity savings of the latter. POD takes a two-pronged approach to improving the performance of primary storage systems and minimizing performance overhead of deduplication, namely, a request-based selective deduplication technique, called Select-Dedupe, to alleviate the data fragmentation and an adaptive memory management scheme, called iCache, to ease the memory contention between the bursty read traffic and the bursty write traffic. We have implemented a prototype of POD as a module in the Linux operating system. The experiments conducted on our lightweight prototype implementation of POD show that POD significantly outperforms iDedup in the I/O performance measure by up to 87.9 percent with an average of 58.8 percent. Moreover, our evaluation results also show that POD achieves comparable or better capacity savings than iDedup.","Indexes,
Redundancy,
Memory management,
Performance evaluation,
Cache storage,
Big data,
Prototypes"
Automated Detection of DCIS in Whole-Slide H&E Stained Breast Histopathology Images,"This paper presents and evaluates a fully automatic method for detection of ductal carcinoma in situ (DCIS) in digitized hematoxylin and eosin (H&E) stained histopathological slides of breast tissue. The proposed method applies multi-scale superpixel classification to detect epithelial regions in whole-slide images (WSIs). Subsequently, spatial clustering is utilized to delineate regions representing meaningful structures within the tissue such as ducts and lobules. A region-based classifier employing a large set of features including statistical and structural texture features and architectural features is then trained to discriminate between DCIS and benign/normal structures. The system is evaluated on two datasets containing a total of 205 WSIs of breast tissue. Evaluation was conducted both on the slide and the lesion level using FROC analysis. The results show that to detect at least one true positive in every DCIS containing slide, the system finds 2.6 false positives per WSI. The results of the per-lesion evaluation show that it is possible to detect 80% and 83% of the DCIS lesions in an abnormal slide, at an average of 2.0 and 3.0 false positives per WSI, respectively. Collectively, the result of the experiments demonstrate the efficacy and accuracy of the proposed method as well as its potential for application in routine pathological diagnostics. To the best of our knowledge, this is the first DCIS detection algorithm working fully automatically on WSIs.","Lesions,
Cancer,
Feature extraction,
Clustering algorithms,
Pathology,
Design automation,
Breast tissue"
An Informed Multitask Diffusion Adaptation Approach to Study Tremor in Parkinson's Disease,"In this paper, a network-based approach for studying the relation between the tremor intensity and the brain connectivity of Parkinson's patients is introduced. We propose an adaptive multitask diffusion strategy to estimate the underlying model between the gait information and the electroencephalography signals. Furthermore, the method incorporates an S-transform-based connectivity measure that performs well even on a single-trial basis. The estimated connectivity values are then combined with the combination weights of the multitask diffusion strategy to model the relation between tremor and the brain signals. The outcome is an enhanced brain connectivity measure representing its time-space relation to the tremor. The results show how the differences between the connectivity values of patients with mild and severe hand tremor are most distinguishable when using the proposed method.","Brain modeling,
Adaptation models,
Electroencephalography,
Parkinson's disease,
Estimation"
Virtual Machine Trading in a Federation of Clouds: Individual Profit and Social Welfare Maximization,"By sharing resources among different cloud providers, the paradigm of federated clouds exploits temporal availability of resources and geographical diversity of operational costs for efficient job service. While interoperability issues across different cloud platforms in a cloud federation have been extensively studied, fundamental questions on cloud economics remain: When and how should a cloud trade resources (e.g., virtual machines) with others, such that its net profit is maximized over the long run, while a close-to-optimal social welfare in the entire federation can also be guaranteed? To answer this question, a number of important, interrelated decisions, including job scheduling, server provisioning, and resource pricing, should be dynamically and jointly made, while the long-term profit optimality is pursued. In this work, we design efficient algorithms for intercloud virtual machine (VM) trading and scheduling in a cloud federation. For VM transactions among clouds, we design a double-auction-based mechanism that is strategy-proof, individual-rational, ex-post budget-balanced, and efficient to execute over time. Closely combined with the auction mechanism is a dynamic VM trading and scheduling algorithm, which carefully decides the true valuations of VMs in the auction, optimally schedules stochastic job arrivals with different service level agreements (SLAs) onto the VMs, and judiciously turns on and off servers based on the current electricity prices. Through rigorous analysis, we show that each individual cloud, by carrying out the dynamic algorithm in the online double auction, can achieve a time-averaged profit arbitrarily close to the offline optimum. Asymptotic optimality in social welfare is also achieved under homogeneous cloud settings. We carry out simulations to verify the effectiveness of our algorithms, and examine the achievable social welfare under heterogeneous cloud settings, as driven by the real-world Google cluster usage traces.","Servers,
Heuristic algorithms,
Cloud computing,
Pricing,
Delays,
Dynamic scheduling,
Virtual machining"
An on-line test solution for addressing interconnect shorts in on-chip networks,This paper presents a scalable time optimized online test solution that addresses short faults in interconnects of an on-chip network (NoC) and observes the deep impact of these faults on NoC performance at large traffics.,"Testing,
Wires,
Clocks,
Mathematical model,
Routing,
Simulation"
Tunable Blocker-Tolerant On-Chip Radio-Frequency Front-End Filter With Dual Adaptive Transmission Zeros for Software-Defined Radio Applications,"This paper presents a tunable active bandpass filter (BPF) with adjustable transmission zeros (TZs) close to the passband for software-defined radio (SDR) applications. The RF front-end frequency selectivity is enhanced by the creation of TZs that also improve the out-of-band (OOB) input-referred third-order intercept point (IIP3). The filter is based on two-path signal cancellation and consists of a tunable BPF in parallel with two tunable bandstop filters. This combination ensures the correct amplitude and phase relationships across a wide tuning range to create adjustable TZs without sacrificing the gain of the passband. This paper presents in detail the design considerations and guidelines, as well as analysis of the filter performance in the presence of nonidealities such as parasitics and imperfect clock signal shape. The proposed filter is implemented with high-QN-path filter blocks in a 65-nm CMOS process. The passband of the filter is tunable from 0.1 to 1.4 GHz with a 3-dB bandwidth of 9.8-10.2 MHz, a gain of 21.5-24 dB, a noise figure of 3-4.2 dB, and a total power consumption of 50-73 mW. TZs are created on both sides of the passband with a minimal offset of 25 MHz and are tunable across a 20-MHz range with up to a 60-dB rejection. The measured blocker 1-dB compression point is 8 dBm and the OOB IIP3 is 23 dBm. The reported filter provides a promising on-chip filtering solution for multistandard multifrequency SDR applications with improved interference mitigation capabilities.","Band-pass filters,
Passband,
Radio frequency,
Filtering theory,
Impedance,
Microwave filters"
Nonlinear Directed Interactions Between HRV and EEG Activity in Children With TLE,"Objective: Epileptic seizure activity influences the autonomic nervous system (ANS) in different ways. Heart rate variability (HRV) is used as indicator for alterations of the ANS. It was shown that linear, nondirected interactions between HRV and EEG activity before, during, and after epileptic seizure occur. Accordingly, investigations of directed nonlinear interactions are logical steps to provide, e.g., deeper insight into the development of seizure onsets. Methods: Convergent cross mapping (CCM) investigates nonlinear, directed interactions between time series by using nonlinear state space reconstruction. CCM is applied to simulated and clinically relevant data, i.e., interactions between HRV and specific EEG components of children with temporal lobe epilepsy (TLE). In addition, time-variant multivariate Autoregressive model (AR)-based estimation of partial directed coherence (PDC) was performed for the same data. Results: Influence of estimation parameters and time-varying behavior of CCM estimation could be demonstrated by means of simulated data. AR-based estimation of PDC failed for the investigation of our clinical data. Time-varying interval-based application of CCM on these data revealed directed interactions between HRV and delta-related EEG activity. Interactions between HRV and alpha-related EEG activity were visible but less pronounced. EEG components mainly drive HRV. The interaction pattern and directionality clearly changed with onset of seizure. Statistical relevant interactions were quantified by bootstrapping and surrogate data approach. Conclusion and Significance: In contrast to AR-based estimation of PDC CCM was able to reveal time-courses and frequency-selective views of nonlinear interactions for the further understanding of complex interactions between the epileptic network and the ANS in children with TLE.","Estimation,
Heart rate variability,
Time series analysis,
Electroencephalography,
Libraries,
Epilepsy,
Pediatrics"
The Radon Cumulative Distribution Transform and Its Application to Image Classification,"Invertible image representation methods (transforms) are routinely employed as low-level image processing operations based on which feature extraction and recognition algorithms are developed. Most transforms in current use (e.g., Fourier, wavelet, and so on) are linear transforms and, by themselves, are unable to substantially simplify the representation of image classes for classification. Here, we describe a nonlinear, invertible, low-level image processing transform based on combining the well-known Radon transform for image data, and the 1D cumulative distribution transform proposed earlier. We describe a few of the properties of this new transform, and with both theoretical and experimental results show that it can often render certain problems linearly separable in a transform space.","Radon,
Feature extraction,
Pattern recognition,
Measurement,
Wavelet transforms,
Visualization"
Strategic Power Allocation With Incomplete Information in the Presence of a Jammer,"In this paper, distributed competitive interactions between a secondary user (SU) transmitter-receiver pair and a jammer are investigated using a game-theoretic framework under physical interference restrictions, power budget constraints, and incomplete knowledge of channel gains. In this game, the SU transmitter is expected to choose its power strategy with the objective of satisfying a minimum signal-to-interference plus noise ratio (SINR) at the corresponding receiver. Similarly, the jammer's objective is to strategically allocate its power so that the SINR constraint of the SU is not satisfied. Due to a lack of complete information, this strategic power allocation problem between the two players is modeled as a Bayesian game for which the self-enforcing strategies of the SU transmitter-receiver pair and the jammer are analyzed. Furthermore, probability distributions are employed by the corresponding players to model the incomplete nature of the game. The solution of the game corresponds to Nash equilibria points. Equilibrium analysis is carried out by considering the mixed strategy solution space and numerical examples are presented for illustration.","Jamming,
Games,
Resource management,
Receivers,
Bayes methods,
Transmitters,
Interference"
Process Discovery from Dependence-Complete Event Logs,"Process mining, especially process discovery, has been utilized to extract process models from event logs. One challenge faced by process discovery is to identify concurrency effectively. State-of-the-art approaches employ activity orders in traces to undertake process discovery and they require stringent completeness notions of event logs. Thus, they may fail to extract appropriate processes when event logs cannot meet the completeness criteria. To address this problem, we propose in this paper a novel technique which leverages activity dependences in traces. Based on the observation that activities with no dependencies can be executed in parallel, our technique is in a position to discover processes with concurrencies even if the logs fail to meet the completeness criteria. That is, our technique calls for a weaker notion of completeness. We evaluate our technique through experiments on both real-world and synthetic event logs, and the conformance checking results demonstrate the effectiveness of our technique and its relative advantages compared with state-of-the-art approaches.","Process control,
Routing,
Computational modeling,
Data mining,
Petri nets,
Noise,
Jacobian matrices"
Correlation-Aware Traffic Consolidation for Power Optimization of Data Center Networks,"Power optimization has become a key challenge in the design of large-scale enterprise data centers. Existing research efforts focus mainly on computer servers to lower their energy consumption, while only few studies have tried to address data center networks (DCNs), which can account for 10-20 percent of the total energy consumption of a data center. In this paper, we propose CARPO, a correlation-aware power optimization algorithm that dynamically consolidates traffic flows onto a small set of links and switches in a DCN and then shuts down unused network devices for energy savings. In sharp contrast to existing work, CARPO is designed based on a key observation from the analysis of real DCN traces that the bandwidth demands of different flows do not peak at exactly the same time. As a result, if the correlations among flows are considered in consolidation, more energy savings can be achieved. In addition, CARPO integrates traffic consolidation with link rate adaptation for maximized energy savings. We implement CARPO on a hardware testbed composed of 10 virtual switches configured with a production 48-port OpenFlow switch and 8 servers. Our empirical results with traces from Wikipedia and Yahoo! data centers demonstrate that CARPO can save up to 50 percent of network energy for a DCN, while having only negligible delay increases. CARPO also outperforms two state-of-the-art baselines by 19.6 and 95 percent on energy savings, respectively. Our simulation results with a large-scale DCN also show that CARPO can achieve more energy savings than the baselines for typical DCN topologies, such as fat tree and BCube.","Correlation,
Servers,
Ports (Computers),
Encyclopedias,
Bandwidth,
Electronic publishing"
Ocean One: A Robotic Avatar for Oceanic Discovery,"The promise of oceanic discovery has long intrigued scientists and explorers, whether with the idea of studying underwater ecology and climate change or with the hope of uncovering natural resources and historic secrets buried deep in archaeological sites. This quest to explore the oceans requires skilled human access, yet much of the oceans are inaccessible to human divers; nearly ninetenths of the ocean floor is at 1 km or deeper [1]. Accessing these depths is imperative since factors such as pollution and deep-sea trawling threaten ecology and archaeological sites. While remotely operated vehicles (ROVs) are inadequate for the task, a robotic avatar could go where humans cannot and still embody human intelligence and intentions through immersive interfaces.","Oceans,
Robot kinematics,
Robot sensing systems,
Avatars,
Dynamics,
Meteorology,
Unmanned vehicles"
Image Retargeting for Preserving Robust Local Feature: Application to Mobile Visual Search,"With the sharp increasing of mobile devices, conducting search on mobile devices becomes pervasive, and one of the most popular applications is mobile visual search. To achieve low bit-rate visual search, most of the existing works focus on addressing local descriptor coding and BoW histogram compression . In this paper, we extend the concept of image retargeting and propose a new image resizing approach that is devoted to preserving the robust local features in the query image while resizing it. Based on the extended concept, we introduce a novel mobile-visual-search scheme that conducts the proposed approach to reduce the size of the query image for achieving low bit-rate visual search. Extensive experiments on Oxford 5 K and Flickr 100k datasets show that our approach obtains superior retrieval performance than state-of-the-art image resizing approaches at the similar query size; meanwhile, it is cost effective in terms of processing time.","Visualization,
Mobile handsets,
Image coding,
Histograms,
Mobile communication,
Encoding,
Image retrieval"
Parameter Space for the Architecture of FFT-Based Montgomery Modular Multiplication,"Modular multiplication is the core operation in public-key cryptographic algorithms such as RSA and the Diffie-Hellman algorithm. The efficiency of the modular multiplier plays a crucial role in the performance of these cryptographic methods. In this paper, improvements to FFT-based Montgomery Modular Multiplication (FFTM3) using carry-save arithmetic and pre-computation techniques are presented. Moreover, pseudo-Fermat number transform is used to enrich the supported operand sizes for the FFTM3. The asymptotic complexity of our method is O(l log l log log l), which is the same as the Schonhage-Strassen multiplication algorithm (SSA). A systematic procedure to select suitable parameter set for the FFTM3 is provided. Prototypes of the improved FFTM3 multiplier with appropriate parameter sets are implemented on Xilinx Virtex-6 FPGA. Our method can perform 3,100-bit and 4,124-bit modular multiplications in 6.74 and 7.78 μs, respectively. It offers better computation latency and area-latency product compared to the state-of-the-art methods for operand size of 3,072-bit and above.","Polynomials,
Transforms,
Algorithm design and analysis,
Spectral analysis,
Hardware,
Convolution,
Complexity theory"
Supercapacitor supported DSTATCOM for harmonic reduction and power factor correction,"Distributed Static Compensator (DSTATCOM) is a widely used custom power device in distributed network to perform the power quality improvement tasks like harmonics reduction, power factor correction and maintain reduces constant dc bus voltage. This paper investigates a new topology based on a Distributed Static Compensator (DSTATCOM) coupled with a supercapacitor for power quality enhancement. The proposed topology includes of a voltage source converter (VSC) based DSTATCOM, a DC-DC bidirectional chopper and a supercapacitor. The supercapacitor is used to control the reduced dc-bus voltage. The popular instantaneous symmetrical component theory (ISCT) control strategy is used to generate the switching pulses for controlling the IGBTs of the VSC. Simulations of the proposed system have been carried out in MATLAB/SIMULINK environment to show its effectiveness over traditional DSTATCOM for power quality issues.","Supercapacitors,
Power quality,
Power harmonic filters,
Harmonic analysis,
Topology,
Choppers (circuits)"
A Hybrid Ray-Tracing/Vector Parabolic Equation Method for Propagation Modeling in Train Communication Channels,"In recent years, various techniques have been applied to modeling radio-wave propagation in railway networks, each one presenting its own advantages and limitations. This paper presents a hybrid channel modeling technique, which combines two of these methods, the ray-tracing (RT) and vector parabolic equation (VPE) methods, to enable the modeling of realistic railway scenarios including stations and long guideways within a unified simulation framework. The general-purpose RT method is applied to analyze propagation in complex areas, whereas the VPE method is reserved for long and uniform tunnel as well as open-air sections. By using the advantages of VPE to compensate for the limitations of RT and vice versa, this hybrid model ensures improved accuracy and computational savings. Numerical results are validated with experimental measurements in various railway scenarios, including an actual deployment site of communication-based train control (CBTC) systems.","Mathematical model,
Ray tracing,
Computational modeling,
Rail transportation,
Density measurement,
Power system measurements,
Antennas"
Exploring Latent Preferences for Context-Aware Personalized Recommendation Systems,"Context-aware recommendations offer the potential of exploiting social contents and utilize related tags and rating information to personalize the search for content considering a given context. Recommendation systems tackle the problem of trying to identify relevant resources from the vast number of choices available online. In this study, we propose a new recommendation model that personalizes recommendations and improves the user experience by analyzing the context when a user wishes to access multimedia content. We conducted empirical analysis on a dataset from last.fm to demonstrate the use of latent preferences for ranking items under a given context. Additionally, we use an optimization function to maximize the mean average precision measure of the resulted recommendation. Experimental results show a potential improvement to the quality of the recommendation in terms of accuracy when compared with state-of-the-art algorithms.",
Multiantenna Secure Cognitive Radio Networks With Finite-Alphabet Inputs: A Global Optimization Approach for Precoder Design,"This paper considers the precoder design for multiantenna secure cognitive radio networks. We use finite-alphabet inputs as the signaling and exploit statistical channel state information (CSI) at the transmitter. We maximize the secrecy rate of the secondary user and control the transmit power and the power leakage to the primary receivers that share the same frequency spectrum. The secrecy rate maximization is important for practical systems, but challenging to solve, mainly due to two reasons. First, the secrecy rate with statistical CSI is computationally prohibitive to evaluate. Second, the optimization over the precoder is a nondeterministic polynomial-time hard (NP-hard) problem. We utilize an accurate approximation of the secrecy rate to reduce the computational effort and then propose a global optimization approach based on branch-and-bound method. The idea is to define a simplex and transform the secrecy rate into a concave function. The derived concave function converges to the secrecy rate when the defined simplex shrinks down. Using this feature, we solve a sequence of concave maximization problems over iteratively shrinking simplices and eventually attain the globally optimal solution that maximizes the approximation of the secrecy rate. When the complexity is concerned, a low-complexity variant with limited number of iterations can be used in practice. We demonstrate the performance gains when compared with others through numerical examples.","Cognitive radio,
Erbium,
Optimization,
Receivers,
MIMO,
Antennas"
Bit-Upset Vulnerability Factor for eDRAM Last Level Cache immunity analysis,"Whereas contemporary Last Level Cache (LLC) designs occupy a significant fraction of total die area in chip-multiprocessors (CMPs), approaches to deal with the vulnerability increase of LLC against Single Event Upset (SEU) and Multi-Bit Upsets (MBUs) are sought. In this paper, we focus on reliability assessment of eDRAM LLC to propose a more accurate and application-relevant vulnerability estimation approach compared to conventional LLC SEU analysis methods. In particular, the eDRAM Bit Upset Vulnerability Factor (BUVF) is proposed and an algorithm is developed to assess its behavior for soft errors using experimental benchmark suites. BUVF explicitly targets the vulnerable portion of the eDRAM refresh cycle where the critical charge varies depending on write voltage, storage and bit-line capacitance. Results for the PARSEC benchmark suite indicated that vulnerable sequences account for about 27.2% of data array lifetime in the cache, among which the Read-Read (RR) access sequence contributes about 23.4%. Furthermore, regardless of the size of the vulnerable data set located in an RR sequence over a short interval, the corresponding region of cache is seen to contribute negligible vulnerability to BUVF, which results from spending a small fraction of program execution time undergoing RR sequences. We recast the problem of reliable eDRAM LLC design as a straightforward search for reduced BUVF.","Capacitors,
Transistors,
Reliability,
Junctions,
Benchmark testing,
Arrays,
Silicon"
On the Accuracy of Fault Detection and Separation in Permanent Magnet Synchronous Machines Using MCSA/MVSA and LDA,"In this paper, the motor current/voltage signature analysis and linear discriminant analysis (LDA) are evaluated with respect to the accuracy to detect the status of permanent magnet synchronous machines (PMSMs) whether it is healthy or faulted, determine the type of that fault, and estimate the severity in the case of static eccentricity or turn-to-turn short-circuit fault. Three types of faults are discussed: static eccentricity, turn-to-turn short circuit, and partial demagnetization fault. Two-dimensional finite element analysis (FEA) is used to model and simulate the machine under healthy and faulted conditions. Fast Fourier transform is applied to the phase voltage or current signals to obtain the frequency spectrum. A combination of the amplitude of the harmonics of the stator voltage or current signals are used as detailed features for the classifier for fault detection. LDA is chosen as a classification method for both detecting the fault and estimating its severity. Two different winding types of PMSMs are tested: a concentrated and a distributed winding machine. To validate the simulation results, experiments at different operational points are carried out and the results are compared with the sFEA.","Circuit faults,
Stators,
Rotors,
Fault detection,
Windings,
Harmonic analysis,
Demagnetization"
Convolutional hypercube pyramid for accurate RGB-D object category and instance recognition,"Deep learning based methods have achieved unprecedented success in solving several computer vision problems involving RGB images. However, this level of success is yet to be seen on RGB-D images owing to two major challenges in this domain: training data deficiency and multi-modality input dissimilarity. We present an RGB-D object recognition framework that addresses these two key challenges by effectively embedding depth and point cloud data into the RGB domain. We employ a convolutional neural network (CNN) pre-trained on RGB data as a feature extractor for both color and depth channels and propose a rich coarse-to-fine feature representation scheme, coined Hypercube Pyramid, that is able to capture discriminatory information at different levels of detail. Finally, we present a novel fusion scheme to combine the Hypercube Pyramid features with the activations of fully connected neurons to construct a compact representation prior to classification. By employing Extreme Learning Machines (ELM) as non-linear classifiers, we show that the proposed method outperforms ten state-of-the-art algorithms for several tasks in terms of recognition accuracy on the benchmark Washington RGB-D and 2D3D object datasets by a large margin (upto 50% reduction in error rate).","Feature extraction,
Three-dimensional displays,
Hypercubes,
Training,
Image color analysis,
Robots,
Object recognition"
Statistical QoS Control of Network Coded Multipath Routing in Large Cognitive Machine-to-Machine Networks,"Machine-to-machine (M2M) communication enables many applications such as smart grid, vehicular safety, and health care among many others. To achieve ubiquitous data transportation among objects and the surrounding environment, deploying spectrum sharing M2M communications with existing wireless networks is a must. A general large-scale cognitive M2M network (CM2MN), adopting cognitive radio technology, consists of multiradio systems, the primary system (PS), and secondary system(s) with tremendous cooperative cognitive machines, under heterogeneous wireless architecture. For these CM2MNs, due to dynamic spectrum access (DSA) nature, there exists possibly unidirectional opportunistic wireless fading links and thus traditional flow control mechanisms at link level do not fit anymore. Furthermore, effective end-to-end quality-of-service (QoS) control is still required to provide a reliable transportation for such multihop CM2M communications. Facing the above challenges, we propose a novel statistical QoS control mechanism through cooperative relaying, realizing virtual multiple-input and multiple-output (MIMO) communications at session level. In particular, a probabilistic network coded routing algorithm and the statistical QoS guarantee are first proposed to coordinate and cooperate tremendous machines. Next, based on the proposed guarantee and routing algorithm, the statistical QoS control mechanism is designed to enable MIMO communications for the session traffic. Specifically, the diversity mode is used to deal with PS's opportunistic nature and wireless fading, and the spatial multiplexing mode is employed to obtain the maximum end-to-end throughput. Simulation results confirm that under our control solution, the great improvements of end-to-end delay violation probability are obtained, thus practically facilitating network coded multipath routing in large CM2MNs.","Quality of service,
MIMO,
Routing,
Relays,
Spread spectrum communication,
Delays,
Network coding"
Combining model-based policy search with online model learning for control of physical humanoids,"We present an automatic method for interactive control of physical humanoid robots based on high-level tasks that does not require manual specification of motion trajectories or specially-designed control policies. The method is based on the combination of a model-based policy that is trained off-line in simulation and sends high-level commands to a model-free controller that executes these commands on the physical robot. This low-level controller simultaneously learns and adapts a local model of dynamics on-line and computes optimal controls under the learned model. The high-level policy is trained using a combination of trajectory optimization and neural network learning, while considering physical limitations such as limited sensors and communication delays. The entire system runs in real-time on the robot's computer and uses only on-board sensors. We demonstrate successful policy execution on a range of tasks such as leaning, hand reaching, and robust balancing behaviors atop a tilting base on the physical robot and in simulation.",
Effective ways to use Internet of Things in the field of medical and smart health care,"The recent advancements in technology and the availability of the Internet make it possible to connect various devices that can communicate with each other and share data. The Internet of Things (IoT) is a new concept that allows users to connect various sensors and smart devices to collect real-time data from the environment. However, it has been observed that a comprehensive platform is still missing in the e-Health and m-Health architectures to use smartphone sensors to sense and transmit important data related to a patient's health. In this paper, our contribution is twofold. Firstly, we critically evaluate the existing literature, which discusses the effective ways to deploy IoT in the field of medical and smart health care. Secondly, we propose a new semantic model for patients' e-Health. The proposed model named as `k-Healthcare' makes use of 4 layers; the sensor layer, the network layer, the Internet layer and the services layer. All layers cooperate with each other effectively and efficiently to provide a platform for accessing patients' health data using smart phones.","Medical services,
Radiofrequency identification,
Intelligent sensors,
Internet,
Wireless sensor networks,
Monitoring"
Finite-Time Lyapunov Exponents and Lagrangian Coherent Structures in Uncertain Unsteady Flows,"The objective of this paper is to understand transport behavior in uncertain time-varying flow fields by redefining the finite-time Lyapunov exponent (FTLE) and Lagrangian coherent structure (LCS) as stochastic counterparts of their traditional deterministic definitions. Three new concepts are introduced: the distribution of the FTLE (D-FTLE), the FTLE of distributions (FTLE-D), and uncertain LCS (U-LCS). The D-FTLE is the probability density function of FTLE values for every spatiotemporal location, which can be visualized with different statistical measurements. The FTLE-D extends the deterministic FTLE by measuring the divergence of particle distributions. It gives a statistical overview of how transport behaviors vary in neighborhood locations. The U-LCS, the probabilities of finding LCSs over the domain, can be extracted with stochastic ridge finding and density estimation algorithms. We show that our approach produces better results than existing variance-based methods do. Our experiments also show that the combination of D-FTLE, FTLE-D, and U-LCS can help users understand transport behaviors and find separatrices in ensemble simulations of atmospheric processes.","Uncertainty,
Atmospheric measurements,
Particle measurements,
Data visualization,
Meteorology,
Three-dimensional displays,
Topology"
A Survey on Trajectory Data Mining: Techniques and Applications,"Rapid advance of location acquisition technologies boosts the generation of trajectory data, which track the traces of moving objects. A trajectory is typically represented by a sequence of timestamped geographical locations. A wide spectrum of applications can benefit from the trajectory data mining. Bringing unprecedented opportunities, large-scale trajectory data also pose great challenges. In this paper, we survey various applications of trajectory data mining, e.g., path discovery, location prediction, movement behavior analysis, and so on. Furthermore, this paper reviews an extensive collection of existing trajectory data mining techniques and discusses them in a framework of trajectory data mining. This framework and the survey can be used as a guideline for designing future trajectory data mining solutions.","Data mining,
Trajectory,
Big data,
Data analytics,
Data processing,
Location awareness"
Network-Coding-Assisted Data Dissemination via Cooperative Vehicle-to-Vehicle/-Infrastructure Communications,"Vehicle-to-vehicle/vehicle-to-infrastructure (referred to as V2X) communications have potential to revolutionize current road transportation systems with respect to vehicle safety, transportation efficiency, and travel experience. This paper puts the first effort on applying network coding in cooperative V2X communication environments to improve bandwidth efficiency and enhance data service performance. Specifically, we investigate new arising challenges on network-coding-assisted data dissemination by considering both communication constraints and application requirements in vehicular networks. We present the system model and give an insight into the characteristics of cooperative data dissemination with network coding. On this basis, we formulate the problem and propose a network-coding-assisted scheduling algorithm to enable the hybrid of vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communications and exploit their joint effects on providing efficient data services. We design a cache strategy that allows vehicles to retrieve their unrequested data items. This strategy not only increases the opportunity of data sharing among vehicles but also gives higher probability of packet decoding, which in turn enhances the data service performance. We give an intensive analysis on the scheduling overhead, which shows the scalability of the algorithm. Finally, we build the simulation model and conduct a comprehensive performance evaluation to demonstrate the superiority of the proposed solution.",
A Low-Complexity Power Allocation Strategy to Minimize Sum-Source-Power for Multi-User Single-AF-Relay Networks,"Because of its outstanding performance in extending coverage and reducing transmit power, wireless relay cooperation is deemed as one of the promising techniques to realize green-broadband communication in the future. In such relay cooperative systems, optimal power allocation not only can prolong the lifetime of users, but also is an effective way to reduce radiation in the environment. In this paper, for amplify-and-forward-relay cooperative networks, where multiple communication pairs share a common relay, we propose a novel power allocation scheme, which has considerably lower complexity compared with the existing solution schemes. The objective of this paper is to minimize sum-source-power consumption under the conditions that the transmit power of all nodes in the network is constrained and their predetermined target signal-to-noise ratios are satisfied. By providing sufficient analytical evidence, we study the optimality, convergence, and computational complexity of our proposed scheme. Through numerical simulation, we further justify the effectiveness and efficacy of our scheme compared with the existing works.","Relays,
Resource management,
Silicon,
Optimization,
Signal to noise ratio,
Peer-to-peer computing,
Cooperative systems"
Inference With Collaborative Model for Interactive Tumor Segmentation in Medical Image Sequences,"Segmenting organisms or tumors from medical data (e.g., computed tomography volumetric images, ultrasound, or magnetic resonance imaging images/image sequences) is one of the fundamental tasks in medical image analysis and diagnosis, and has received long-term attentions. This paper studies a novel computational framework of interactive segmentation for extracting liver tumors from image sequences, and it is suitable for different types of medical data. The main contributions are twofold. First, we propose a collaborative model to jointly formulate the tumor segmentation from two aspects: 1) region partition and 2) boundary presence. The two terms are complementary but simultaneously competing: the former extracts the tumor based on its appearance/texture information, while the latter searches for the palpable tumor boundary. Moreover, in order to adapt the data variations, we allow the model to be discriminatively trained based on both the seed pixels traced by the Lucas-Kanade algorithm and the scribbles placed by the user. Second, we present an effective inference algorithm that iterates to: 1) solve tumor segmentation using the augmented Lagrangian method and 2) propagate the segmentation across the image sequence by searching for distinctive matches between images. We keep the collaborative model updated during the inference in order to well capture the tumor variations over time. We have verified our system for segmenting liver tumors from a number of clinical data, and have achieved very promising results. The software developed with this paper can be found at http://vision.sysu.edu.cn/projects/med-interactive-seg/.",
Arbitrarily Varying Wiretap Channels With Type Constrained States,"Determining a single-letter secrecy-capacity formula for the arbitrarily varying wiretap channel (AVWTC) is an open problem largely because of two main challenges. Not only does it capture the difficulty of the compound wiretap channel (another open problem), it also requires that secrecy is ensured with respect to exponentially many possible channel state sequences. By extending the strong soft-covering lemma, recently derived by the authors, to the heterogeneous scenario, this paper accounts for the exponential number of secrecy constraints while only imposing single-letter constraints on the communication rate. Through this approach, we derive a single-letter characterization of the correlated-random (CR)-assisted semantic-security (SS) capacity of an AVWTC with a type constraint on the allowed state sequences. The allowed state sequences are the ones in a typical set around a single constraining type. The stringent SS requirement is established by showing that the mutual information between the message and the eavesdropper's observations is negligible even when maximized over all message distributions, choices of state sequences, and realizations of the CR-code. Both the achievability and the converse proofs of the type-constrained coding theorem rely on stronger claims than actually required. The direct part establishes a novel single-letter lower bound on the CR-assisted SS-capacity of an AVWTC with state sequences constrained by any convex and closed set of state probability mass functions. This bound achieves the best known single-letter secrecy rates for a corresponding compound wiretap channel over the same constraint set. In contrast to other single-letter results in the AVWTC literature, this paper does not assume the existence of a best channel to the eavesdropper. Instead, SS follows by leveraging the heterogeneous version of the strong soft-covering lemma and a CR-code reduction argument. Optimality is a consequence of a max-inf upper bound on the CR-assisted SS-capacity of an AVWTC with state sequences constrained to any collection of type-classes. When adjusted to the aforementioned compound WTC, the upper bound simplifies to a max-min structure, thus strengthening the previously best known single-letter upper bound by Liang et al. that has a min-max form. The proof of the upper bound uses a novel distribution coupling argument. The capacity formula shows that the legitimate users effectively see an averaged main channel, while security must be ensured versus an eavesdropper with perfect channel state information. An example visualizes our single-letter results, and their relation to the past multi-letter secrecy-capacity characterization of the AVWTC is highlighted.","Cryptography,
Measurement,
Compounds,
Upper bound,
Physical layer,
Encoding"
Nonlinear Electrical Impedance Tomography Reconstruction Using Artificial Neural Networks and Particle Swarm Optimization,"Electrical impedance tomography (EIT) is an imaging technology that offers the advantages of being noninvasive, and it does not generate ionizing radiation. The main difficulty in applying EIT is to solve an ill-posed nonlinear inverse problem. Given a set of electrical voltages measured at the surface of a volume conductor, the goal is to identify the materials that are present in the domain by determining their electrical conductivities. However, since EIT is a nonlinear problem, various algorithms proposed in the literature can only approximate real conductivity distributions. Nonlinear algorithms, especially artificial neural networks (ANNs), have been proposed to solve this inverse problem, but these algorithms are usually limited by slow convergence issues during the training phase. In this paper, the particle swarm optimization (PSO) method is used to train an ANN to solve the EIT problem. It has been found that, compared with the back-propagation algorithm, PSO is capable of generating both faster and higher convergence. This paper also shows that the proposed method is capable of dealing with noisy data and the imperfections in the finite-element discretization, an important source of errors in EIT imaging.","Artificial neural networks,
Tomography,
Inverse problems,
Image reconstruction,
Conductivity,
Voltage measurement,
Electrodes"
Asymptotically Optimal CFAR Detectors,"This paper investigates the asymptotic optimality of the Constant False Alarm Rate (CFAR) tests obtained using the Minimal Invariant Group (MIG) reduction. We show that the CFAR tests obtained after MIG reduction using the Wald test is a Separating Function Estimation Test (SFET) and that the Generalized Likelihood Ratio Test (GLRT) and the Rao test are asymptotically SFET using Maximum Likelihood Estimation (MLE) under some mild conditions. Thus, they are asymptotically optimal. In order to find an improved test and motivated by the invariance property of the MLE of induced maximal invariant, we maximize the asymptotic Probability of Detection of the SFET using the MLE after reduction. We propose a systematic method allowing to derive the asymptotically optimal Separating Function (AOSF). This AOSF is obtained as the Euclidean distance of the transformed parameters under two hypotheses such that the gradient of the transformed parameters is the Cholesky decomposition of the Fisher Information Matrix (FIM), i.e., the FIM is transformed into an identity matrix. Interestingly, the AOSF Estimation Test (AOSFET) using MLE simplifies to the Wald-CFAR wherever the FIM does not depend on the unknown parameters. The simulation results show that the proposed AOSFET usually outperforms the GLRT, Wald test and Rao test.","Maximum likelihood estimation,
Probability density function,
Detectors,
Signal detection,
Radar"
Private and Flexible Urban Message Delivery,"With the popularity of intelligent mobile devices, enormous amounts of urban information has been generated and demanded by the public. In response, ShanghaiGrid (SG) aims to provide abundant information services to the public. With a fixed schedule and urbanwide coverage, an appealing service in SG is to provide free message delivery service to the public using buses, which allows mobile device users to send messages to locations of interest via buses. The main challenge in realizing this service is to provide an efficient routing scheme with privacy preservation under a highly dynamic urban traffic condition. In this paper, we present the innovative scheme BusCast to tackle this problem. In BusCast, buses can pick up and forward personal messages to their destination locations in a store-carry-forward fashion. For each message, BusCast conservatively associates a routing graph rather than a fixed routing path with the message to adapt the dynamic of urban traffic. Meanwhile, the privacy information about the user and the message destination is concealed from both intermediate relay buses and outside adversaries. Both rigorous privacy analysis and extensive trace-driven simulations demonstrate the efficacy of the BusCast scheme.",
Strengthening the entropy power inequality,"We tighten the entropy power inequality (EPI) when one of the random summands is Gaussian. Our strengthening is closely related to strong data processing for Gaussian channels and generalizes the (vector extension of) Costa's EPI. This leads to a new reverse EPI and, as a corollary, sharpens Stam's inequality relating entropy power and Fisher information. Applications to network information theory are given, including a short self-contained proof of the converse for the two-encoder quadratic Gaussian source coding problem. The proof of our main result is based on weak convergence and a doubling argument for establishing Gaussian optimality via rotational-invariance.","Entropy,
Random variables,
Interference channels,
Source coding,
Markov processes,
Two dimensional displays"
Hybrid Radio/Free-Space Optical Design for Next Generation Backhaul Systems,"The deluge of date rate in today's networks imposes a cost burden on the backhaul network design. Developing cost-efficient backhaul solutions becomes an exciting, yet challenging, problem. Traditional technologies for backhaul networks, including either radio-frequency (RF) backhauls or optical fibers (OF). While RF is a cost-effective solution as compared with OF, it supports the lower data rate requirements. Another promising backhaul solution is the free-space optics (FSO) as it offers both a high data rate and a relatively low cost. The FSO, however, is sensitive to nature conditions, e.g., rain, fog, and line-of-sight. This paper combines both the RF and FSO advantages and proposes a hybrid RF/FSO backhaul solution. It considers the problem of minimizing the cost of the backhaul network by choosing either OF or hybrid RF/FSO backhaul links between the base stations, so as to satisfy data rate, connectivity, and reliability constraints. It shows that under a specified realistic assumption about the cost of OF and hybrid RF/FSO links, the problem is equivalent to a maximum weight clique problem, which can be solved with moderate complexity. Simulation results show that the proposed solution shows a close-to-optimal performance, especially for reasonable prices of the hybrid RF/FSO links. They further reveal that the hybrid RF/FSO is a cost-efficient solution and a good candidate for upgrading the existing backhaul networks.","Radio frequency,
Reliability,
Next generation networking,
Optical fiber communication,
Copper,
Transceivers,
Optical design"
Social engineering attack modeling with the use of Bayesian networks,"The problem of modeling socio-engineering attacks on the user's machine using a Bayesian belief networks. The system models the complex “information system - personnel - critical documents” presented in the form of Bayesian belief networks, containing a set of psychological characteristics. This approach can significantly improve the performance and productivity of software for the analysis of security of user information system.","Bayes methods,
Computational modeling,
Psychology,
Information security,
Markov random fields"
Online Supplementary ADP Learning Controller Design and Application to Power System Frequency Control With Large-Scale Wind Energy Integration,"The emergence of smart grids has posed great challenges to traditional power system control given the multitude of new risk factors. This paper proposes an online supplementary learning controller (OSLC) design method to compensate the traditional power system controllers for coping with the dynamic power grid. The proposed OSLC is a supplementary controller based on approximate dynamic programming, which works alongside an existing power system controller. By introducing an action-dependent cost function as the optimization objective, the proposed OSLC is a nonidentifier-based method to provide an online optimal control adaptively as measurement data become available. The online learning of the OSLC enjoys the policy-search efficiency during policy iteration and the data efficiency of the least squares method. For the proposed OSLC, the stability of the controlled system during learning, the monotonic nature of the performance measure of the iterative supplementary controller, and the convergence of the iterative supplementary controller are proved. Furthermore, the efficacy of the proposed OSLC is demonstrated in a challenging power system frequency control problem in the presence of high penetration of wind generation.",
A Hybrid Feature Selection With Ensemble Classification for Imbalanced Healthcare Data: A Case Study for Brain Tumor Diagnosis,"Electronic health records (EHRs) are providing increased access to healthcare data that can be made available for advanced data analysis. This can be used by the healthcare professionals to make a more informed decision providing improved quality of care. However, due to the inherent heterogeneous and imbalanced characteristics of medical data from EHRs, data analysis task faces a big challenge. In this paper, we address the challenges of imbalanced medical data about a brain tumor diagnosis problem. Morphometric analysis of histopathological images is rapidly emerging as a valuable diagnostic tool for neuropathology. Oligodendroglioma is one type of brain tumor that has a good response to treatment provided the tumor subtype is recognized accurately. The genetic variant, 1p-/19q-, has recently been found to have high chemosensitivity, and has morphological attributes that may lend it to automated image analysis and histological processing and diagnosis. This paper aims to achieve a fast, affordable, and objective diagnosis of this genetic variant of oligodendroglioma with a novel data mining approach combining a feature selection and ensemble-based classification. In this paper, 63 instances of brain tumor with oligodendroglioma are obtained due to prevalence and incidence of the tumor variant. In order to minimize the effect of an imbalanced healthcare data set, a global optimization-based hybrid wrapper-filter feature selection with ensemble classification is applied. The experiment results show that the proposed approach outperforms the standard techniques used in brain tumor classification problem to overcome the imbalanced characteristics of medical data.","Tumors,
Feature extraction,
Data mining,
Medical diagnostic imaging,
Artificial neural networks"
Factorization Algorithms for Temporal Psychovisual Modulation Display,"Temporal psychovisual modulation (TPVM) is a new information display technology which aims to generate multiple visual percepts for different viewers on a single display simultaneously. In a TPVM system, the viewers wearing different active liquid crystal (LC) glasses with varying transparency levels can see different images (called personal views). The viewers without LC glasses can also see a semantically meaningful image (called shared view). The display frames and weights for the LC glasses in the TPVM system can be computed through nonnegative matrix factorization (NMF) with three additional constrains: the values of images and modulation weights should have upper bound (i.e., limited luminance of the display and transparency level of the LC); the shared view without using viewing devices should be considered (i.e., the sum of all basis images should be a meaningful image); and the sparsity of modulation weights should be considered due to the material property of LC. In this paper, we proposed to solve the constrained NMF problem by a modified version of hierarchical alternating least squares (HALS) algorithms. Through experiments, we analyze the choice of parameters in the setup of TPVM system. This work serves as a guideline for practical implementation of TPVM display system.",
DCloud: Deadline-Aware Resource Allocation for Cloud Computing Jobs,"With the tremendous growth of cloud computing, it is increasingly critical to provide quantifiable performance to tenants and to improve resource utilization for the cloud provider. Though many recent proposals focus on guaranteeing job performance (with a particular note on network bandwidth) in the cloud, they usually lack efficient utilization of cloud resource, or vice versa. In this paper we present DCloud, which leverages the (soft) deadlines of cloud computing jobs to enable flexible and efficient resource utilization in data centers. With the deadline requirement of a job guaranteed, DCloud employs both time sliding (postponing the launching time of a job) and bandwidth scaling (adjusting the bandwidth associated with VMs) in resource allocation, so as to better match the resource allocated to the job with the cloud's residual resource. Extensive simulations and testbed experiments show that DCloud can accept much more jobs than existing solutions, and significantly increase the cloud provider's revenue with less cost for individual tenants.","Bandwidth,
Resource management,
Yttrium,
Servers,
Cloud computing,
Switches,
Clouds"
An FPGA-based infrastructure for fine-grained DVFS analysis in high-performance embedded systems,"Emerging technologies provide SoCs with fine-grained DVFS capabilities both in space (number of domains) and time (transients in the order oftens of nanoseconds). Analyzing these systems requires cycle-accurate accounting of rapidly-changing dynamics and complex interactions among accelerators, interconnect, memory, and OS. We present an FPGA-based infrastructure that facilitates such analyses for high-performance embedded systems. We show how our infrastructure can be used to first generate SoCs with loosely-coupled accelerators, and then perform design-space exploration considering several DVFS policies under full-system workload scenarios, sweeping spatial and temporal domain granularity.","Clocks,
Phase locked loops,
Voltage control,
Regulators,
Hardware,
Switches,
Transient analysis"
Cognitive and Opportunistic Relay for QoS Guarantees in Machine-to-Machine Communications,"Deploying spectrum sharing machine-to-machine (M2M) communications with the existing wireless networks achieves ubiquitous data transportation among objects and the surrounding environment to benefit our daily life. However, the lack of schemes to completely characterize M2M network topology, to efficiently share radio resource, and to provide quality-of-service (QoS) guarantee regarding end-to-end delay creates challenges to practically facilitate M2M communications. Via mathematical derivations, the network connectivity, degree distribution, and average distance are provided for large M2M networks. To achieve reliable communications upon such M2M networks, inspired by cognitive radio technology and cooperative communications, a cognitive and opportunistic relay (COR) scheme is proposed. Specifically, machines with the proposed COR autonomously sense the primary systems' spectrum usage so as to mitigate detractive interference and adopt opportunistic forwarder selection for lower link delay of packet transmissions. Furthermore, by analytical deriving the effective capacity of the COR over connected M2M networks, the throughput under statistical QoS guarantee and the corresponding delay violation probability are proposed to specify the QoS guarantee capability of the networks and thus suggest the conditions of dependable end-to-end transmissions. Simulation results confirm that the proposed COR effectively achieves the delay guarantee performance, to yield a novel framework for facilitating reliable M2M communications in large machine networks.","Quality of service,
Delays,
Relays,
Machine-to-machine communications,
Throughput,
Reliability,
Spread spectrum communication"
Automatic Road Crack Detection Using Random Structured Forests,"Cracks are a growing threat to road conditions and have drawn much attention to the construction of intelligent transportation systems. However, as the key part of an intelligent transportation system, automatic road crack detection has been challenged because of the intense inhomogeneity along the cracks, the topology complexity of cracks, the inference of noises with similar texture to the cracks, and so on. In this paper, we propose CrackForest, a novel road crack detection framework based on random structured forests, to address these issues. Our contributions are shown as follows: 1) apply the integral channel features to redefine the tokens that constitute a crack and get better representation of the cracks with intensity inhomogeneity; 2) introduce random structured forests to generate a high-performance crack detector, which can identify arbitrarily complex cracks; and 3) propose a new crack descriptor to characterize cracks and discern them from noises effectively. In addition, our method is faster and easier to parallel. Experimental results prove the state-of-the-art detection precision of CrackForest compared with competing methods.",
A Compact Printed Filtering Antenna With Good Suppression of Upper Harmonic Band,"In this letter, a printed planar filtering antenna composed of the stepped-impedance dipole (SID), stepped-impedance resonator (SIR), and low-pass filter (LPF) is presented. The SIR is used as a parasitic element in proximity to the SID radiator to improve its upper band-edge selectivity and to widen its operation bandwidth. Our extensive study is at first conducted to exhibit that the upper harmonic band of radiation can be tremendously pushed upward by appropriately replacing the main dipole radiator and the parasitic resonant element with the SID and SIR. Next, a stepped-impedance LPF is employed to further effectively suppress the high-order harmonic band of radiation as quantitatively demonstrated. The measured reflection coefficient has achieved a wide fractional bandwidth up to 27.5%, covering a frequency range of 2.5–3.3 GHz, with \vert{ S}_{11}\vert < {10}~\hbox{dB}
. In particular, its first harmonic band for radiation has been significantly extended from 7.2 GHz beyond 14.0 GHz as confirmed in simulation and experiment.","Filtering,
Dipole antennas,
Power harmonic filters,
Harmonic analysis,
Impedance,
Antenna measurements"
Automatic Craniomaxillofacial Landmark Digitization via Segmentation-Guided Partially-Joint Regression Forest Model and Multiscale Statistical Features,"Objective: The goal of this paper is to automatically digitize craniomaxillofacial (CMF) landmarks efficiently and accurately from cone-beam computed tomography (CBCT) images, by addressing the challenge caused by large morphological variations across patients and image artifacts of CBCT images. Methods: We propose a segmentation-guided partially-joint regression forest (S-PRF) model to automatically digitize CMF landmarks. In this model, a regression voting strategy is first adopted to localize each landmark by aggregating evidences from context locations, thus potentially relieving the problem caused by image artifacts near the landmark. Second, CBCT image segmentation is utilized to remove uninformative voxels caused by morphological variations across patients. Third, a partially-joint model is further proposed to separately localize landmarks based on the coherence of landmark positions to improve the digitization reliability. In addition, we propose a fast vector quantization method to extract high-level multiscale statistical features to describe a voxel's appearance, which has low dimensionality, high efficiency, and is also invariant to the local inhomogeneity caused by artifacts. Results: Mean digitization errors for 15 landmarks, in comparison to the ground truth, are all less than 2
mm. Conclusion: Our model has addressed challenges of both interpatient morphological variations and imaging artifacts. Experiments on a CBCT dataset show that our approach achieves clinically acceptable accuracy for landmark digitalization. Significance: Our automatic landmark digitization method can be used clinically to reduce the labor cost and also improve digitalization consistency.","Image segmentation,
Three-dimensional displays,
Solid modeling,
Feature extraction,
Computational modeling,
Computed tomography,
Reliability"
Hybrid Zero Block Detection for High Efficiency Video Coding,"In this paper we propose an efficient hybrid zero block early detection method for high efficiency video coding (HEVC). Our method detects both genuine zero blocks (GZBs) and pseudo zero blocks (PZBs). For GZB detection, we use a two sum of absolute difference bounds and a one sum of absolute transformed difference threshold to decrease the GZB detection complexity. A fast rate-distortion estimation algorithm for HEVC is proposed to improve the PZB detection rate. Experimental results on the HM platform show that the proposed method saves about 50% of the rate-distortion optimization (RTO) time, with negligible Bjøntegaard delta bit rate loss. Our method is faster than other state-of-the-art ZB detection methods for HEVC by 10%-30%.",
Distributed Charging Control in Broadband Wireless Power Transfer Networks,"Wireless power transfer (WPT) technology provides a cost-effective solution to achieve a sustainable energy supply in wireless networks, where WPT-enabled energy nodes (ENs) can charge wireless devices (WDs) remotely without interruption to the use. However, in a heterogeneous WPT network with distributed ENs and WDs, some WDs may quickly deplete their batteries due to the lack of timely wireless power supply by the ENs, thus resulting in short network operating lifetime. In this paper, we exploit frequency diversity in a broadband WPT network and study the distributed charging control by ENs to maximize network lifetime. In particular, we propose a practical voting-based distributed charging control framework, where each WD simply estimates the broadband channel, casts its votes for some strong sub-channels, and sends to the ENs along with its battery state information, based on which the ENs independently allocate their transmit power over the sub-channels without the need of centralized control. Under this framework, we aim to design lifetime-maximizing power allocation and efficient voting-based feedback methods. Toward this end, we first derive the general expression of the expected lifetime of a WPT network and draw the general design principles for lifetime-maximizing charging control. Based on the analysis, we then propose a distributed charging control protocol with voting-based feedback, where the power allocated to sub-channels at each EN is a function of the weighted sum vote received from all WDs. Besides, the number of votes cast by a WD and the weight of each vote are related to its current battery state. Simulation results show that the proposed distributed charging control protocol could significantly increase the network lifetime under stringent transmit power constraint in a broadband WPT network. Reciprocally, it also consumes lower transmit power to achieve nearly perpetual network operation.","Broadband communication,
Resource management,
Wireless communication,
Batteries,
Wireless sensor networks,
Radio spectrum management,
Radio frequency,
Green communications,
Energy efficiency"
Resource Optimization-Based Interference Management for Hybrid Self-Organized Small-Cell Network,"This paper jointly studies interference management (IM) and self-organization (SO) schemes in a hybrid-SO small-cell network, which is a combination of the centralized and distributed small-cell networks. From the view of downlink transmission, we formulate a resource optimization-based IM (ROIM) problem. In particular, to accommodate to the hybrid architecture, the problem is divided into two subproblems. The first is subchannel allocation, which is investigated with overall network interference alleviation under the assumption of imperfect channel-state information (CSI). The second is power assignment (PA), which aims at constraining the local interference while guaranteeing the network utility. To solve the ROIM problem, we propose a two-step SO-based IM (TSSOIM) scheme. At the first step, the operation and management (O&M) unit adopts an aggressive discrete stochastic approximation (ADSA) algorithm to find the proper channel set for users. At the second step, small cells employ the game-theory-based Kalai-Smorodinsky bargaining solution (KSBS) to assign power to the channels. Simulation results are presented to show the effectiveness of the proposed TSSOIM scheme.","Interference,
Computer architecture,
Microprocessors,
Resource management,
Vectors,
Downlink,
Approximation algorithms"
Learning convolutional action primitives for fine-grained action recognition,"Fine-grained action recognition is important for many applications of human-robot interaction, automated skill assessment, and surveillance. The goal is to segment and classify all actions occurring in a time series sequence. While recent recognition methods have shown strong performance in robotics applications, they often require hand-crafted features, use large amounts of domain knowledge, or employ overly simplistic representations of how objects change throughout an action. In this paper we present the Latent Convolutional Skip Chain Conditional Random Field (LC-SC-CRF). This time series model learns a set of interpretable and composable action primitives from sensor data. We apply our model to cooking tasks using accelerometer data from the University of Dundee 50 Salads dataset and to robotic surgery training tasks using robot kinematic data from the JHU-ISI Gesture and Skill Assessment Working Set (JIGSAWS). Our performance on 50 Salads and JIGSAWS are 18.0% and 5.3% higher than the state of the art, respectively. This model performs well without requiring hand-crafted features or intricate domain knowledge. The code and features have been made public.","Hidden Markov models,
Convolution,
Robot sensing systems,
Accelerometers,
Surgery,
Robot kinematics"
Modeling and Optimization of Memristor and STT-RAM-Based Memory for Low-Power Applications,"Conventional charge-based memory usage in low-power applications is facing major challenges. Some of these challenges are leakage current for static random access memory (SRAM) and dynamic random access memory (DRAM), additional refresh operation for DRAM, and high programming voltage for Flash. In this paper, two emerging resistive random access memory (ReRAM) technologies are investigated, memristor and spin-transfer torque (STT)-RAM, as potential universal memory candidates to replace traditional ones. Both of these nonvolatile memories support zero leakage and low-voltage operation during read access, which makes them ideal for devices with long sleep time. To date, high write energy for both memristor and STT-RAM is one of the major inhibitors for adopting the technologies. The primary contribution of this paper is centered on addressing the high write energy issue by trading off retention time with noise margin. In doing so, the memristor and STT-RAM power has been compared with the traditional six-transistor-SRAM-based memory power and potential application in wireless sensor nodes is explored. This paper uses 45-nm foundry process technology data for SRAM and physics-based mathematical models derived from real devices for memristor and STT-RAM. The simulations are conducted using MATLAB and the results show a potential power savings of 87% and 77% when using memristor and STT-RAM, respectively, at 1% duty cycle.",
A Survey of Caching Policies and Forwarding Mechanisms in Information-Centric Networking,"Information-centric networking (ICN), an alternative to the host-centric model of the current Internet infrastructure, focuses on the distribution and retrieval of content instead of the transfer of information between specific endpoints. In order to achieve this, ICN is based on the paradigm of publish-subscribe and the concepts of naming and in-network caching. Current approaches to ICN employ caches within networks to minimize the latency of information retrieval. Content may be distributed either in caches along the delivery path(s), on-path caching or in any cache within a network, off-path caching. While approaches to off-path caching are comparable to traditional approaches for content replication and Web caching, approaches to on-path caching are specific to the ICN area. The purpose of this paper is to provide a review of the caching problem in ICN, with a focus on on-path caching. To this end, a detailed analysis of the existing caching policies and forwarding mechanisms that complement these policies is given. A number of criteria such as the caching model and level of operation and the evaluation parameters used in the evaluation of the existing caching policies are being employed to derive a taxonomy for on-path caching and highlight the trends and evaluation issues in this area. A discussion driven by the advantages and disadvantages of the existing caching policies and the challenges and open questions in on-path caching is finally being held.","Internet,
Protocols,
Servers,
Publish-subscribe,
Routing,
Peer-to-peer computing,
Tutorials"
Reconstructing Curvilinear Networks Using Path Classifiers and Integer Programming,"We propose a novel approach to automated delineation of curvilinear structures that form complex and potentially loopy networks. By representing the image data as a graph of potential paths, we first show how to weight these paths using discriminatively-trained classifiers that are both robust and generic enough to be applied to very different imaging modalities. We then present an Integer Programming approach to finding the optimal subset of paths, subject to structural and topological constraints that eliminate implausible solutions. Unlike earlier approaches that assume a tree topology for the networks, ours explicitly models the fact that the networks may contain loops, and can reconstruct both cyclic and acyclic ones. We demonstrate the effectiveness of our approach on a variety of challenging datasets including aerial images of road networks and micrographs of neural arbors, and show that it outperforms state-of-the-art techniques.","Linear programming,
Image reconstruction,
Curvilinear structures,
Biomedical imaging,
Electronic mail,
Integer programming,
Path planning,
Classification"
Integrated Low-Rank-Based Discriminative Feature Learning for Recognition,"Feature learning plays a central role in pattern recognition. In recent years, many representation-based feature learning methods have been proposed and have achieved great success in many applications. However, these methods perform feature learning and subsequent classification in two separate steps, which may not be optimal for recognition tasks. In this paper, we present a supervised low-rank-based approach for learning discriminative features. By integrating latent low-rank representation (LatLRR) with a ridge regression-based classifier, our approach combines feature learning with classification, so that the regulated classification error is minimized. In this way, the extracted features are more discriminative for the recognition tasks. Our approach benefits from a recent discovery on the closed-form solutions to noiseless LatLRR. When there is noise, a robust Principal Component Analysis (PCA)-based denoising step can be added as preprocessing. When the scale of a problem is large, we utilize a fast randomized algorithm to speed up the computation of robust PCA. Extensive experimental results demonstrate the effectiveness and robustness of our method.","Principal component analysis,
Learning systems,
Robustness,
Matrix decomposition,
Closed-form solutions,
Algorithm design and analysis"
Modeling and Optimizing the LTE Discontinuous Reception Mechanism Under Self-Similar Traffic,"The discontinuous reception (DRX) mechanism is adopted in Long-Term Evolution (LTE) systems as a core technology to prolong the battery lifetime of user equipment (UE). With the development of mobile Internet, there is an increasingly urgent need to optimize the DRX performance to accommodate the emerging applications. In this paper, to describe the self-similarity exhibited by the applications, a truncated-Pareto-distributed arrival traffic model is introduced into the LTE-DRX modeling framework. With this premise, a DRX analytical model based on a discrete-time semi-Markov process (DTSMP) is established. Using the proposed model, the performance of DRX operations under certain configurations can be evaluated precisely. To deploy it in practical use, we have designed an online power-saving strategy (OPSS) to improve the energy efficiency of the UE. The OPSS is conducted in two phases: estimation and optimization. In the first phase, several derived statistical estimators are deployed to capture the fluctuations of the traffic conditions and DRX operations. It is proved that these estimators could unbiasedly estimate the statistics within just 1 s. In the second phase, the DRX configuration is optimized by considering the trade off between the packet delay and the power-saving performance. Solid simulations are conducted to verify the accuracy of the DRX analytical model and to evaluate the efficiency of the OPSS. The well-matched results demonstrate that the analytical model is correctly derived. Moreover, we have proved that the proposed OPSS could outperform the conventional LTE DRX mechanism in terms of both energy conservation and packet delay.","Analytical models,
Long Term Evolution,
Mobile communication,
Internet,
Multimedia communication,
Mathematical model,
Delays"
Kinect Posture Reconstruction Based on a Local Mixture of Gaussian Process Models,"Depth sensor based 3D human motion estimation hardware such as Kinect has made interactive applications more popular recently. However, it is still challenging to accurately recognize postures from a single depth camera due to the inherently noisy data derived from depth images and self-occluding action performed by the user. In this paper, we propose a new real-time probabilistic framework to enhance the accuracy of live captured postures that belong to one of the action classes in the database. We adopt the Gaussian Process model as a prior to leverage the position data obtained from Kinect and marker-based motion capture system. We also incorporate a temporal consistency term into the optimization framework to constrain the velocity variations between successive frames. To ensure that the reconstructed posture resembles the accurate parts of the observed posture, we embed a set of joint reliability measurements into the optimization framework. A major drawback of Gaussian Process is its cubic learning complexity when dealing with a large database due to the inverse of a covariance matrix. To solve the problem, we propose a new method based on a local mixture of Gaussian Processes, in which Gaussian Processes are defined in local regions of the state space. Due to the significantly decreased sample size in each local Gaussian Process, the learning time is greatly reduced. At the same time, the prediction speed is enhanced as the weighted mean prediction for a given sample is determined by the nearby local models only. Our system also allows incrementally updating a specific local Gaussian Process in real time, which enhances the likelihood of adapting to run-time postures that are different from those in the database. Experimental results demonstrate that our system can generate high quality postures even under severe self-occlusion situations, which is beneficial for real-time applications such as motion-based gaming and sport training.","Gaussian processes,
Databases,
Image reconstruction,
Three-dimensional displays,
Adaptation models,
Real-time systems,
Reliability"
Local Search Yields Approximation Schemes for k-Means and k-Median in Euclidean and Minor-Free Metrics,"We give the first polynomial-time approximation schemes (PTASs) for the following problems: (1) uniform facility location in edge-weighted planar graphs, (2) k-median and k-means in edge-weighted planar graphs, (3) k-means in Euclidean space of bounded dimension. Our first and second results extend to minor-closed families of graphs. All our results extend to cost functions that are the pth power of the shortest-path distance. The algorithm is local search where the local neighborhood of a solution S consists of all solutions obtained from S by removing and adding 1/εO(1) centers.","Approximation algorithms,
Extraterrestrial measurements,
Clustering algorithms,
Cost function,
Algorithm design and analysis,
Linear programming"
Proxies for Shortest Path and Distance Queries,"Computing shortest paths and distances is one of the fundamental problems on graphs, and it remains a challenging task today. This article investigates a light-weight data reduction technique for speeding-up shortest path and distance queries on large graphs. To do this, we propose a notion of routing proxies (or simply proxies), each of which represents a small subgraph, referred to as deterministic routing areas (DRAs). We first show that routing proxies hold good properties for speeding-up shortest path and distance queries. Then, we design a linear-time algorithm to compute routing proxies and their corresponding DRAs. Finally, we experimentally verify that our solution is a general technique for reducing graph sizes and speeding-up shortest path and distance queries, using real-life large graphs.","Routing,
Gold,
Roads,
Algorithm design and analysis,
Social network services,
Indexes,
Data preprocessing"
A Survey on GPU-Based Implementation of Swarm Intelligence Algorithms,"Inspired by the collective behavior of natural swarm, swarm intelligence algorithms (SIAs) have been developed and widely used for solving optimization problems. When applied to complex problems, a large number of fitness function evaluations are needed to obtain an acceptable solution. To tackle this vital issue, graphical processing units (GPUs) have been used to accelerate the optimization procedure of SIAs. Thanks to their inherent parallelism, SIAs are very suitable for parallel implementation under the GPU platform which have achieved a great success in recent years. This paper presents a comprehensive review of GPU-based parallel SIAs in accordance with a newly proposed taxonomy. Critical concerns for the efficient parallel implementation of SIAs are also described in detail. Moreover, novel criteria are also proposed to evaluate and compare the parallel implementation and algorithm performance universally. The rationality and practicability of the proposed optimization methodology and criteria are verified by careful case study. Finally, our opinions and perspectives on the trends and prospects on the relatively new research domain are also presented for future development.","Graphics processing units,
Parallel processing,
Optimization,
Computational modeling,
Taxonomy,
Acceleration,
Silicon"
Semantic Discriminative Metric Learning for Image Similarity Measurement,"Along with the arrival of multimedia time, multimedia data has replaced textual data to transfer information in various fields. As an important form of multimedia data, images have been widely utilized by many applications, such as face recognition and image classification. Therefore, how to accurately annotate each image from a large set of images is of vital importance but challenging. To perform these tasks well, it is crucial to extract suitable features to character the visual contents of images and learn an appropriate distance metric to measure similarities between all images. Unfortunately, existing feature operators, such as histogram of gradient, local binary pattern, and color histogram, care more about the visual character of images and lack the ability to distinguish semantic information. Similarities between those features cannot reflect the real category correlations due to the well-known semantic gap. In order to solve this problem, this paper proposes a regularized distance metric framework called semantic discriminative metric learning (SDML). SDML combines geometric mean with normalized divergences and separates images from different classes simultaneously. The learned distance metric can treat all images from different classes equally. And distinctions between similar classes with entirely different semantic contents are emphasized by SDML. This procedure ensures the consistency between dissimilarities and semantic distinctions and avoids inaccuracy similarities incurred by unbalanced locations of samples. Various experiments on benchmark image datasets show the excellent performance of the novel method.","Semantics,
Euclidean distance,
Coordinate measuring machines,
Visualization,
Image processing,
Roads"
Action Recognition in Still Images With Minimum Annotation Efforts,"We focus on the problem of still image-based human action recognition, which essentially involves making prediction by analyzing human poses and their interaction with objects in the scene. Besides image-level action labels (e.g., riding, phoning), during both training and testing stages, existing works usually require additional input of human bounding boxes to facilitate the characterization of the underlying human-object interactions. We argue that this additional input requirement might severely discourage potential applications and is not very necessary. To this end, a systematic approach was developed in this paper to address this challenging problem of minimum annotation efforts, i.e., to perform recognition in the presence of only image-level action labels in the training stage. Experimental results on three benchmark data sets demonstrate that compared with the state-of-the-art methods that have privileged access to additional human bounding-box annotations, our approach achieves comparable or even superior recognition accuracy using only action annotations in training. Interestingly, as a by-product in many cases, our approach is able to segment out the precise regions of underlying human-object interactions.","Image recognition,
Image segmentation,
Training,
Testing,
Detectors,
Object detection,
Proposals"
Signal detection of ambient backscatter system with differential modulation,"We study the problem of signal detection for the ambient backscatter system (ABS) when data are transmitted with differential modulation. An implementation of the maximum likelihood (ML) detection algorithm is proposed. To reduce the computational complexity, we further design a suboptimal detector and derive its bit error rate (BER) closed-form expression. Moreover, both the upper and the lower bounds of the BER, which can tell more insight of how system parameters affect the detection performance, are obtained. Simulations are then provided to corroborate the studies.","Detectors,
Bit error rate,
Backscatter,
RF signals,
Modulation,
Signal detection,
Lead"
Delay Constrained Energy Harvesting Networks with Limited Energy and Data Storage,"This paper studies energy harvesting transmitters in the single user channel, the two-way channel, and the two-way relay channel with block fading. Each transmitter is equipped with a finite battery to store the harvested energy, and a finite buffer to store the data that arrive during the communication session. We consider delay sensitive applications and maximize throughput while enabling timely delivery of data with delay constraints. We show that the resulting delay limited throughput maximization problem can be solved using alternating maximization of two decoupled problems termed the energy scheduling problem and the data scheduling problem. We solve the energy scheduling problem using a modified directional waterfilling algorithm with right permeable taps, water pumps, and overflow bins and the data scheduling problem with forward induction. Additionally, we identify the online optimum policy for throughput maximization. We provide numerical results to verify our analytical findings and to demonstrate the impact of the finite data buffer capacity and the delay requirements on the throughput. We observe that larger buffer sizes become useful for more lenient delay requirements, and a data buffer size that is comparable to the throughput within one time slot accounts for the majority of the increase in throughput.","Throughput,
Delays,
Energy harvesting,
Batteries,
Transmitters,
Relays,
Receivers"
Efficient RFID Grouping Protocols,"The grouping problem in RFID systems is to efficiently group all tags according to a given partition such that tags in the same group will have the same group ID. Unlike previous research on unicast transmission from a reader to a tag, grouping provides a fundamental mechanism for efficient multicast transmissions and aggregate queries in large RFID-enabled applications. A message can be transmitted to a group of m tags simultaneously in multicast, which improves the efficiency by m times when comparing with unicast. This paper studies this practically important but not yet thoroughly investigated grouping problem in large RFID system. We start with a straightforward solution called the Enhanced Polling Grouping (EPG) protocol. We then propose a time-efficient Filter Grouping (FIG) protocol that uses Bloom filters to remove the costly ID transmissions. We point out the limitation of the Bloom-filter based solution due to its intrinsic false positive problem, which leads to our final ConCurrent Grouping (CCG) protocol. With a drastically different design, CCG is able to outperform FIG by exploiting collisions to inform multiple tags of their group ID simultaneously and by removing any wasteful slots in its frame-based execution. We further enhance CCG to make it perform better with very large groups. Simulation results demonstrate that our best protocol CCG can reduce the execution time by a factor of 11 when comparing with a baseline polling protocol.","Protocols,
Unicast,
RFID tags,
IEEE transactions,
Aggregates,
Simulation"
Low ON-Resistance SiC Trench/Planar MOSFET With Reduced OFF-State Oxide Field and Low Gate Charges,"We propose a SiC trench/planar MOSFET (TP-MOS) which features a trench channel and a planar channel in one half-cell. Numerical simulations with Sentaurus TCAD have been carried out to study the proposed device architecture. Compared with traditional planar MOSFET (P-MOS), the TP-MOS has a much lower RON owing to the increased channel density. Unlike traditional trench MOSFET (T-MOS) which enables a higher channel density at the price of a high bottom-oxide field in the high-voltage OFF-state, the TP-MOS features bottom p-bases as in the P-MOS that protect the gate oxide from high electric field. The OFF-state oxide field in the TP-MOS is found to be even lower than the P-MOS. In addition, the TP-MOS boasts a low feedback capacitance (Crss) and gateto-drain charge (QGD), since the coupling between the gate and the drain is suppressed by the collective effects of the top p-bases and the bottom p-bases. The QG of the TP-MOS is nearly the same as the P-MOS, and is much smaller than the T-MOS. Superior figures of merit (QG×RON and QGD×RON) are achieved in the TP-MOS.","Logic gates,
MOSFET,
Silicon carbide,
Computer architecture,
JFETs,
Resistance,
Capacitance"
Combining Nonlinear Adaptive Filtering and Signal Decomposition for Motion Artifact Removal in Wearable Photoplethysmography,"Heart rate (HR) estimation using photoplethysmography (PPG) has drawn increasing attention in the field of wearable technology due to its advantages with higher degree of usability and lower cost than Electrocardiograph. It has been widely used in wearable devices, such as smart-watches for fitness tracking and vital sign monitoring. However, motion artifact is a strong interference, preventing accurate estimation of HR. Signal decomposition and adaptive filtering are two popular approaches for motion artifact removal, but each of them has inherent drawbacks. In this paper, a hybrid motion artifact removal method is proposed, which combines nonlinear adaptive filtering and signal decomposition, getting the best of both approaches. The method was evaluated on the PPG database used in the 2015 IEEE Signal Processing Cup. The experimental results showed that the method achieved the average absolute error of 1.16 beat per minutes (BPM) on the 12 training data sets, and 2.98 BPM on the ten testing data sets.","Heart rate,
Acceleration,
Sensors,
Signal resolution,
Estimation,
Filtering"
Cupid: Congestion-free consistent data plane update in software defined networks,"With the popular applications of SDN in load balancing and failure recovery, the controller schedules affected flows to redundant paths to avoid network congestions and failures by updating flow tables in data plane. However, inconsistent flow table updating may lead to transient incorrect network behaviors or undesired performance degradation. Therefore, the consistency imposes dependencies among updates, so that the order of updates must be carefully considered to keep the consistency. To update flow tables consistently and efficiently, in this paper, we propose an update ordering approach - Cupid. To avoid high overhead in update ordering, we divide the global dependencies among updates into local restrictions by: 1) partitioning a new routing path into several independent segments, 2) identifying critical nodes controlling traffic shifting between the old path and new path, and 3) constructing a dependency graph among critical nodes for potential congested links. We then design a heuristic algorithm to resolve the dependency graph. To save the flow table space, a switch keeps only one flow entry with multiple ports for a flow during updating. Our simulation shows that Cupid schedules updates at least 2 times faster and has less throughput losses than the state-of-the-art approaches in both fat-tree and mesh networks.",
Three-Phase Series-Connected Modular Multilevel Converter for HVDC Application,"The three-phase series-connected modular multilevel converter (SC-MMC) is presented as one option for high-voltage direct current (HVDC) tap to reduce the cost of an HVDC station. Compared with conventional three-phase parallel-connected MMC, the number of semiconductor switches in SC-MMC is reduced by one-third to withstand the same dc voltage. First, the paper studies the operating principle of SC-MMC, and then presents an interspacing phase-shifted pulsewidth-modulated method which could improve the waveform of the output ac voltage for a given switching frequency. Next, the control strategy based on the identical real power input of each phase is proposed to balance the dc voltage of each phase under an unbalanced grid condition. The current limit of switching devices is also taken into consideration to protect SC-MMC from overcurrent. Furthermore, a universal zero-sequence current controller is developed as one part of the control strategy. In addition, an innovative method to suppress the third harmonics of ac current is presented. With the third harmonic suppression strategy, the SC-MMC can operate with much smaller SM capacitors without deteriorating the ac current, which contributes to the cost reduction further. Finally, simulation results obtained in PSCAD/EMTDC are provided to validate the proposed control strategies.","Switches,
Harmonic analysis,
HVDC transmission,
Capacitors,
Converters,
Voltage control,
Windings"
Wearable Graphene Sensors With Microfluidic Liquid Metal Wiring for Structural Health Monitoring and Human Body Motion Sensing,"This paper reports on all-flexible strain sensors made of graphene, microfluidic liquid metal, and stretchable elastomer. These graphene sensors feature a flexible wiring design, where liquid metal is introduced into microfluidic channels for wiring inside the devices. This design allows enhanced overall structural flexibility and a reduced risk of stress-related mechanical failure of the sensors, at the contact areas between the graphene sensing elements and the metal wires. A unidirectional strain sensor and a multidirectional rosette strain sensor are developed, by encasing patterned graphene and microfluidic liquid metal channels with a stretchable elastomer. We demonstrate the use of the developed unidirectional strain sensor for structural health monitoring of curved concrete structures, and for tracking the angular motion of a human wrist. The multilayer rosette strain sensor is shown to be capable of detecting the amplitude and angle of a primary strain in a multidirectional strain field.","Graphene,
Sensors,
Metals,
Liquids,
Strain,
Wires,
Microfluidics"
Robust Cell Detection of Histopathological Brain Tumor Images Using Sparse Reconstruction and Adaptive Dictionary Selection,"Successful diagnostic and prognostic stratification, treatment outcome prediction, and therapy planning depend on reproducible and accurate pathology analysis. Computer aided diagnosis (CAD) is a useful tool to help doctors make better decisions in cancer diagnosis and treatment. Accurate cell detection is often an essential prerequisite for subsequent cellular analysis. The major challenge of robust brain tumor nuclei/cell detection is to handle significant variations in cell appearance and to split touching cells. In this paper, we present an automatic cell detection framework using sparse reconstruction and adaptive dictionary learning. The main contributions of our method are: 1) A sparse reconstruction based approach to split touching cells; 2) An adaptive dictionary learning method used to handle cell appearance variations. The proposed method has been extensively tested on a data set with more than 2000 cells extracted from 32 whole slide scanned images. The automatic cell detection results are compared with the manually annotated ground truth and other state-of-the-art cell detection algorithms. The proposed method achieves the best cell detection accuracy with a F1 score = 0.96.",
Automatic Differentiation of Normal and Continuous Adventitious Respiratory Sounds Using Ensemble Empirical Mode Decomposition and Instantaneous Frequency,"Differentiating normal from adventitious respiratory sounds (RS) is a major challenge in the diagnosis of pulmonary diseases. Particularly, continuous adventitious sounds (CAS) are of clinical interest because they reflect the severity of certain diseases. This study presents a new classifier that automatically distinguishes normal sounds from CAS. It is based on the multiscale analysis of instantaneous frequency (IF) and envelope (IE) calculated after ensemble empirical mode decomposition (EEMD). These techniques have two major advantages over previous techniques: high temporal resolution is achieved by calculating IF-IE and a priori knowledge of signal characteristics is not required for EEMD. The classifier is based on the fact that the IF dispersion of RS signals markedly decreases when CAS appear in respiratory cycles. Therefore, CAS were detected by using a moving window to calculate the dispersion of IF sequences. The study dataset contained 1494 RS segments extracted from 870 inspiratory cycles recorded from 30 patients with asthma. All cycles and their RS segments were previously classified as containing normal sounds or CAS by a highly experienced physician to obtain a gold standard classification. A support vector machine classifier was trained and tested using an iterative procedure in which the dataset was randomly divided into training (65%) and testing (35%) sets inside a loop. The SVM classifier was also tested on 4592 simulated CAS cycles. High total accuracy was obtained with both recorded (94.6% ± 0.3%) and simulated (92.8% ± 3.6%) signals. We conclude that the proposed method is promising for RS analysis and classification.","Dispersion,
Feature extraction,
Empirical mode decomposition,
Informatics,
Diseases,
Support vector machines"
Radar Parameter Design for Geosynchronous SAR in Squint Mode and Elliptical Orbit,"Low-inclined elliptical orbits are recommended for geosynchronous synthetic aperture radar (GEO SAR) to map the regions of interest at middle latitudes. However, the radius variation of such orbit results in a time-variant nadir interference and slant range of illuminated regions. These factors shorten the available imaging time for a specific pulse repetition interval (PRI), which may be even shorter than the required integration time. Besides, the squint mode widely used in GEO SAR brings in the nonorthogonal and nonuniform ground resolution, which cannot be completely described by the traditional range and azimuth resolutions. To solve these problems, first, the ground resolution area is proved to be an ellipse, and the axis lengths of the resolution ellipse are used to present the worst and the best resolutions along various directions. Conditions for orthogonal and uniform ground resolutions are investigated, and analytical expressions of the resolution-related parameters are derived. Second, effects of the orbit radius variation on data acquisitions are analyzed, and a continuous PRI variation method is proposed to lengthen the available imaging time. By varying the PRI with a constant time interval, the acquisition window and transmit interference are changed with the time-variant illuminated region, which loosens the constraint of the transmit interference. Finally, the proposed ground resolution expressions and continuous PRI variation method are verified by computer simulations.",
Fuzzy Model Based Bilateral Control Design of Nonlinear Tele-Operation System Using Method of State Convergence,"This paper presents the design of a state convergence (SC)-based bilateral controller for a nonlinear teleoperation system, which has been approximated by a Takagi-Sugeno (TS) fuzzy model. The selection of SC is made due to the advantages offered by this scheme both in the modeling and control design stages. The modeling stage considers master/slave systems, which can be represented by the n th order differential equations, while the control design stage offers an easy way to determine the control gains required for assigning desired closed loop dynamics to teleoperation system. After the master/slave systems are represented by TS fuzzy models, a stabilizing fuzzy law is adopted which allows deploying the SC scheme with all its benefits to design the fuzzy bilateral controller. In this way, not only the simplicity of the design scheme is ensured but also the existing SC scheme is able to control a nonlinear teleoperation system based on its TS fuzzy model description. As an additional advantage, the SC-based existing linear bilateral controller can be easily derived from the SC-based proposed fuzzy bilateral controller. Various cases of master/slave systems originally reported in terms of their linear model representation and communication in the absence/presence of time delay are all discussed in the corresponding fuzzy framework. The MATLAB simulations, considering a one-degree-of-freedom teleoperation system, are performed to validate the proposed methodology for controlling a nonlinear teleoperation system.","Mathematical model,
Differential equations,
Delay effects,
Teleoperation systems,
Adaptive control,
Adaptation models,
Control design,
Fuzzy logic"
Personalizing Pedestrian Accessible way-finding with mPASS,"This work presents users evaluation of mPASS (mobile Pervasive Accessibility Social Sensing), a system to provide citizens with personalized accessible way finding. mPASS collects data both from crowdsourcing and from crowdsensing, in order to obtain a detailed georeferenced description of the urban environment accessibility. It combines these data with a user profile, with the aim of tailoring paths and maps to users' preferences and needs. To drive the design of our application, we assessed our first proposal through a preliminary questionnaire, showing mPASS mockups to 60 uses with disability and elderly users. On the basis of the results of such questionnaire, we developed a prototype and we tested it with a small group of pilot users. This paper presents results of both the assessments.","Sensors,
Crowdsourcing,
Urban areas,
Wheelchairs,
Senior citizens,
Routing,
Mobile communication"
An Inductive-Coupling Blocker Rejection Technique for Miniature RFID Tag,"Miniaturization is a promising trend for future RF identification (RFID) in many applications such as the Internet of Things (IoT) and implantable devices. For a small-sized RFID tag using near-field communication, the reader is required to emit a large amount of RF power in order to power up the tag while simultaneously picking up a weak backscattering communication signal. This results in a very small signal-to-blocker ratio (SBR), making the demodulation very difficult for the reader-side receiver (RSR). In this paper, we propose a novel blocker rejection technique based on inductive coupling. Several coupling coils and transmission lines are designed and optimized on the same printed circuit board (PCB) with the main power transmitting (Tx) coil of the reader, which leads to a much higher SBR. As a demonstration vehicle, a 200 μm × 200 μm RFID tag with an on-chip antenna is fabricated using 65-nm CMOS technology with a harvested power of 12 μW, an operating frequency of 2 GHz, and a backscattering data rate of 625 kb/s. Measured result shows the proposed block rejection technique improves the SBR by 44 dB.","Radiofrequency identification,
Antennas,
Coils,
Backscatter,
System-on-chip,
Couplings,
Radio frequency"
Direction Finding With Partly Calibrated Uniform Linear Arrays in Nonuniform Noise,"We recently proposed an ESPRIT-like method for direction finding with partly calibrated uniform linear arrays. It has been shown that the unknown gains/phases and directionof-arrivals (DOAs) can be estimated jointly. However, this approach relies on the assumption of uniform white noise, i.e., all sensor noise powers are identical. Besides, at most M -2 sources can be handled for an M-element array. This motives us to develop enhanced methods for circumventing the limitations above. This paper extends the uniform white noise to nonuniform noise on one hand, and, on the other hand, allows us to estimate up to M - 1 DOAs of uncorrelated signals. More exactly, for uncorrelated signals, the array can be calibrated according to the specific structure of the array covariance matrix, and the nonuniformity of sensor noises can then be simply eliminated by reformulating the calibrated array covariance matrix. For correlated signals, the nonuniformity of sensor noises is mitigated by solving a least squares minimization problem, such that the signal/noise subspace can be properly determined. Thus, our previously developed ESPRIT-like approach can be adopted to determine the DOAs. The effectiveness of the proposed methods is confirmed by numerical examples.","Sensor arrays,
Covariance matrices,
Direction-of-arrival estimation,
White noise,
Maximum likelihood estimation"
A modular lightweight implementation of the Smart-M3 semantic information broker,"Interoperability among heterogeneous devices is one of the main topics investigated nowadays to realize the Ubiquitous Computing vision. Smart-M3 is a software architecture born to provide interoperability through the Semantic Web technologies and reactivity thanks to the publish-subscribe paradigm. In this paper we present a new implementation in Python of the central component of the Smart-M3 architecture: the Semantic Information Broker (SIB). The new component, named pySIB, has been specifically designed for embedded or resource constrained devices. pySIB represents a new open source lightweight and portable SIB implementation, but also introduces new features and interesting performances. JSON has been introduced as the default information encoding notation as it offers the flexibility of XML with minor bandwidth requirements. Memory allocation on disk and at runtime is in the order of Kilobytes i.e. minimal, if compared with the other reference implementations. Performance tests on existing (SP2B) and ad-hoc benchmarks point out possible improvements but also encouraging data such as the best insertion time among the existing SIB implementations.","Semantics,
Resource description framework,
Protocols,
Encoding,
Context,
Software architecture,
Interoperability"
Efficient Execution Methods of Pivoting for Bulk Extraction of Entity-Attribute-Value-Modeled Data,"Entity-attribute-value (EAV) tables are widely used to store data in electronic medical records and clinical study data management systems. Before they can be used by various analytical (e.g., data mining and machine learning) programs, EAV-modeled data usually must be transformed into conventional relational table format through pivot operations. This time-consuming and resource-intensive process is often performed repeatedly on a regular basis, e.g., to provide a daily refresh of the content in a clinical data warehouse. Thus, it would be beneficial to make pivot operations as efficient as possible. In this paper, we present three techniques for improving the efficiency of pivot operations: 1) filtering out EAV tuples related to unneeded clinical parameters early on; 2) supporting pivoting across multiple EAV tables; and 3) conducting multi-query optimization. We demonstrate the effectiveness of our techniques through implementation. We show that our optimized execution method of pivoting using these techniques significantly outperforms the current basic execution method of pivoting. Our techniques can be used to build a data extraction tool to simplify the specification of and improve the efficiency of extracting data from the EAV tables in electronic medical records and clinical study data management systems.","Data mining,
Data warehouses,
Data models,
TV,
Informatics,
Sorting,
Electronic medical records"
Alleviating Hidden and Exposed Nodes in High-Throughput Wireless Mesh Networks,"This paper proposes an opportunistic approach to mitigating the hidden and exposed node problem in a high-throughput mesh network, by exploiting the frame aggregation and block acknowledgment (BACK) capabilities of IEEE 802.11n/ac wireless networking standard. Hidden nodes significantly drop down the throughput of a wireless mesh network by increasing data loss due to collision, whereas exposed nodes cause under-utilization of the achievable network capacity. The problem becomes worse in IEEE 802.11n/ac supported high-throughput mesh networks, due to the large physical layer frame size and prolonged channel reservation from frame aggregation. The proposed approach uses the standard carrier sense multiple access (CSMA) technology along with an opportunistic collision avoidance (OCA) method that blocks the communication for hidden nodes and opportunistically allows exposed nodes to communicate with the peers. The performance of the proposed CSMA/OCA mechanism for high throughput mesh networks is studied using the results from an IEEE 802.11n+s wireless mesh networking testbed, and the scalability of the scheme has been analyzed using simulation results.",
Distributed Frequency Control via Randomized Response of Electric Vehicles in Power Grid,"In this paper, we propose a new distributed frequency control scheme for electric vehicles (EVs) to help restore the power grid frequency upon a contingency of supply-demand imbalance. Under our scheme, each EV independently monitors the grid frequency at discrete times and responds by switching among its charging, idle, and discharging operational modes according to a simple threshold-based switching algorithm. To recover the grid frequency smoothly and prevent an undesired frequency overshoot/undershoot due to simultaneous response of EVs, we design the inter-response times of any EV to follow an exponentially distributed random variable with a certain mean value at each operational mode. To draw insights into the performance of our scheme, we characterize its impacts on the grid frequency in various aspects, including the mean and variance of the resulting grid frequency over time, the mean frequency recovery time, the average number of EV switching their modes, and the probability of frequency overshoot/undershoot. Accordingly, we formulate an optimization problem for the grid operator to minimize the expected cost of implementing our frequency control scheme by designing EVs response rates subject to their requested incentive prices and the given grid performance guarantees. Finally, we validate our analysis via simulations on the IEEE 9-Bus test system and the Ireland power system, where it is observed that our frequency control scheme can be used as a reliable and cost-efficient alternative for the conventional primary reserve service.","Frequency control,
Time-frequency analysis,
Power grids,
Switches,
Optimization,
Power generation"
Social media mediation system for elderly people,"Most of existed elderly people watching services are belonging to the service category of a confirmation of elderly people's safety based on one way communication. Therefore, we propose a Social Media Mediation System which can be used for the interactive communication between elderly people and younger generation via existed social media. This system has been implemented on a single board computer which equips simple I/O devices and network access function so that elderly people can retrieve and transmit information by voice via social media without using smart phones. We confirmed the effectiveness of the proposed system in the viewpoints of performance and user operation through experiments using a prototype system.","Media,
Senior citizens,
Twitter,
Prototypes,
Mediation,
Google,
Speech recognition"
Linear Combining of Nonlinear Preprocessors for OFDM-Based Power-Line Communications,"Nonlinear preprocessors, including conventional clipping, blanking, joint blanking/clipping, and deep clipping, have been employed to mitigate the impulsive noise in orthogonal frequency division multiplexing-based power-line communications. Those nonlinear preprocessors are characterized by one or two thresholds, which are optimized to achieve an optimum output signal-to-noise ratio (SNR). In this paper, we aim to further improve the output SNR by linearly combining two nonlinear preprocessors. Both analytical and simulation results show that the proposed method yields better output SNR and symbol/bit error rate performance than the individual ones.","Signal to noise ratio,
Blanking,
Interference,
OFDM,
Joints,
Australia"
Quantitative evaluation of contrast for a complex image by its histogram,The task of a quantitative evaluation of the generalized contrast for complex subject images has been considered. The method of a quantitative evaluation of the absolute generalized contrast based on the histogram of brightness distribution of the pairs of image elements has been proposed. Results of the conducted experimental research for different definitions of a contrast kernel confirm the effectiveness of the proposed method of evaluation of the generalized contrast for complex subject images.,
Estimating the Power Capability of Li-ion Batteries Using Informationally Partitioned Estimators,"Enforcing constraints on the maximum deliverable power is essential to protect lithium-ion batteries and to maximize resource utilization. This paper describes an algorithm to address the estimation of power capability of battery systems accounting for thermal and electrical constraints. The algorithm is based on model inversion to compute the limiting currents and, hence, power capability. The adequacy of model inversion significantly depends on the accuracy of model states and parameters. Herein, these are estimated by designing cascading estimators whose structure is determined by quantifying the relative estimability of states and parameters. The parameterized battery model and the estimation algorithms are integrated with a power management system in a model of a series hybrid electric vehicle to demonstrate their effectiveness.","Batteries,
Estimation,
Computational modeling,
Vehicle dynamics,
Heating,
Discharges (electric),
Mathematical model"
"Content-Based Guided Image Filtering, Weighted Semi-Global Optimization, and Efficient Disparity Refinement for Fast and Accurate Disparity Estimation","This paper presents a novel approach, which relies on content-based guided image filtering and weighted semi-global optimization for fast and accurate disparity estimation. The approach uses a pixel-based cost term that combines gradient, Gabor-Feature, and color information. The pixel-based matching costs are filtered by applying guided image filtering, which relies on rectangular support windows of two different sizes. In this way, two filtered costs are estimated for each pixel. Among the two filtered costs, the one that will be finally assigned to each pixel depends on the local image content around this pixel. The filtered cost volume is further refined by exploiting weighted semi-global optimization, which improves the disparity estimation accuracy. Finally, the disparity refinement in outlier regions relies on a straightforward and time-efficient outliers handling scheme and on a simple approach which deals with the disparity outliers at depth discontinuities. Experimental results on the Middlebury online stereo evaluation benchmark and 27 additional Middlebury stereo pairs prove that our method is able to generate disparity maps with high accuracy while keeping the computational cost low.","Measurement,
Venus,
Estimation,
Gray-scale,
Kernel,
Image color analysis,
Optimization"
Wireless NoC and Dynamic VFI Codesign: Energy Efficiency Without Performance Penalty,"Multiple voltage frequency island (VFI)-based designs can reduce the energy dissipation in multicore platforms by taking advantage of the varying nature of the application workloads. Indeed, the voltage/frequency (V/F) levels of the VFIs can be dynamically tailored by considering the workload-driven variations in the application. Traditionally, mesh-based networks-on-chip (NoCs) have been used in VFI-based systems; however, they have large latency and energy overheads due to the inherently long multihop paths. Consequently, in this paper, we explore the emerging paradigm of wireless NoC (WiNoC) and demonstrate that by incorporating WiNoC, VFI, and dynamic V/F tuning in a synergistic manner, we can design energy-efficient multicore platforms without introducing noticeable performance penalty. Our experimental results show that for the benchmarks considered, the proposed approach can achieve between 5.7% and 46.6% energy-delay product (EDP) savings over the state-of-the-art system and 26.8% and 60.5% EDP savings over a standard baseline non-VFI mesh-based system. This opens up a new of class of codesign approaches that can make WiNoCs the communication technology of choice for future multicore platforms.","Multicore processing,
Tuning,
Runtime,
System analysis and design,
Distortion measurement,
Wireless communication,
Energy dissipation"
User capacity of wireless physical-layer identification: An information-theoretic perspective,"Wireless Physical Layer Identification (WPLI) system aims at identifying or classifying authorized devices based on the unique Radio Frequency Fingerprints (RFFs) extracted from their radio frequency signals at the physical layer. Current works of WPLI focus on demonstrating system feasibility based on experimental error performance of WPLI with a fixed number of users. While an important question remains to be answered: what's the user number that WPLI can accommodate using different RFFs and receiving equipment. The user capacity of the WPLI can be a major concern for practical system designers and can also be a key metric to evaluate the classification performance of WPLI. In this work, we establish a theoretical understanding on user capacity of WPLI in an information-theoretic perspective. We apply information-theoretic modeling on RFF features of WPLI. An information-theoretic approach is consequently proposed based on mutual information between RFF and user identity to characterize the user capacity of WPLI. Based on this theoretical tool, the achievable user capacity of WPLI is characterized under practical constrains of off-the-shelf receiving devices. Field experiments on classification error performance are conducted for the validation of the information-theoretic user capacity characterization.","Mutual information,
Feature extraction,
Uncertainty,
Entropy,
Electromagnetic interference,
Error analysis,
Physical layer"
Autonomous-Vehicle Public Transportation System: Scheduling and Admission Control,"Technology of autonomous vehicles (AVs) is becoming mature, and many AVs will appear on roads in the near future. AVs become connected with the support of various vehicular communication technologies, and they possess a high degree of control to respond to instantaneous situations cooperatively with high efficiency and flexibility. In this paper, we propose a new public transportation system based on AVs. It manages a fleet of AVs to accommodate transportation requests, offering point-to-point services with ride sharing. We focus on the two major problems of the system: scheduling and admission control. The former is to configure the most economical schedules and routes for the AVs to satisfy the admissible requests, whereas the latter is to determine the set of admissible requests among all requests to produce maximum profit. The scheduling problem is formulated as a mixed-integer linear program, and the admission control problem is cast as a bilevel optimization, which embeds the scheduling problem as the major constraint. By utilizing the analytical properties of the problem, we develop an effective genetic-algorithm-based method to tackle the admission control problem. We validate the performance of the algorithm with real-world transportation service data.","Vehicles,
Public transportation,
Admission control,
Roads,
Scheduling,
Vehicular ad hoc networks"
Recursive Ground Truth Estimator for Social Data Streams,"The paper develops a recursive state estimator for social network data streams that allows exploitation of social networks, such as Twitter, as sensor networks to reliably observe physical events. Recent literature suggested using social networks as sensor networks leveraging the fact that much of the information upload on the former constitutes acts of sensing. A significant challenge identified in that context was that source reliability is often unknown, leading to uncertainty regarding the veracity of reported observations. Multiple truth finding systems were developed to solve this problem, generally geared towards batch analysis of offline datasets. This work complements the present batch approaches by developing an online recursive state estimator that recovers ground truth from streaming data. In this paper, we model physical world state by a set of binary signals (propositions, called assertions, about world state) and the social network as a noisy medium, where distortion, fabrication, omissions, and duplication are introduced. Our recursive state estimator is designed to recover the original binary signal (the true propositions) from the received noisy signal, essentially decoding the unreliable social network output to obtain the best estimate of ground truth in the physical world. Results show that the estimator is both effective and efficient at recovering the original signal with a high degree of accuracy. The estimator gives rise to a novel situation awareness tool that can be used for reliably following unfolding events in real time, using dynamically arriving social network data.","Reliability,
Sensors,
Twitter,
Observers,
Noise measurement,
Computer science"
Self-taught object localization with deep networks,"This paper introduces self-taught object localization, a novel approach that leverages deep convolutional networks trained for whole-image recognition to localize objects in images without additional human supervision, i.e., without using any ground-truth bounding boxes for training. The key idea is to analyze the change in the recognition scores when artificially masking out different regions of the image. The masking out of a region that includes the object typically causes a significant drop in recognition score. This idea is embedded into an agglomerative clustering technique that generates self-taught localization hypotheses. Our object localization scheme outperforms existing proposal methods in both precision and recall for small number of subwindow proposals (e.g., on ILSVRC-2012 it produces a relative gain of 23.4% over the state-of-the-art for top-1 hypothesis). Furthermore, our experiments show that the annotations automatically-generated by our method can be used to train object detectors yielding recognition results remarkably close to those obtained by training on manually-annotated bounding boxes.","Training,
Detectors,
Proposals,
Manuals,
Image recognition,
Visualization,
Object recognition"
Recent Advances in Programmable Photonic-Assisted Ultrabroadband Radio-Frequency Arbitrary Waveform Generation,"Photonic-assisted RF waveform generation has always demonstrated great potentials in accessing high frequencies and broad bandwidths, outside of the reach of electronic generation techniques, with a high degree of programmability, low jitter, compatability with radio-over-fiber technology, and potential for integration. This review paper summarizes the evolution of photonic-assisted radio-frequency arbitrary waveform generation (RF-AWG) over the past couple of decades. These generation schemes are now mature enough to be directly utilized for many RF applications, such as high-resolution ranging and ultrabroadband multipath channel sounding and compensation. Finally, we discuss the current limitations of these schemes and potential future works in integration of the systems and matching RF-photonic receiver technology.","Optical pulse shaping,
Photonics,
High-speed optical techniques,
Radio frequency,
Optical fibers"
Providing Privacy-Aware Incentives in Mobile Sensing Systems,"Mobile sensing relies on data contributed by users through their mobile device (e.g., smart phone) to obtain useful information about people and their surroundings. However, users may not want to contribute due to lack of incentives and concerns on possible privacy leakage. To effectively promote user participation, both incentive and privacy issues should be addressed. Although incentive and privacy have been addressed separately in mobile sensing, it is still an open problem to address them simultaneously. In this paper, we propose two credit-based privacy-aware incentive schemes for mobile sensing systems, where the focus is on privacy protection instead of on the design of incentive mechanisms. Our schemes enable mobile users to earn credits by contributing data without leaking which data they have contributed, and ensure that malicious users cannot abuse the system to earn unlimited credits. Specifically, the first scheme considers scenarios where an online trusted third party (TTP) is available, and relies on the TTP to protect user privacy and prevent abuse attacks. The second scheme considers scenarios where no online TTP is available. It applies blind signature, partially blind signature, and a novel extended Merkle tree technique to protect user privacy and prevent abuse attacks. Security analysis and cost evaluations show that our schemes are secure and efficient.","Sensors,
Privacy,
Mobile communication,
Incentive schemes,
Mobile handsets,
Cryptography,
Mobile computing"
A Survey on Visual Analytics of Social Media Data,"The unprecedented availability of social media data offers substantial opportunities for data owners, system operators, solution providers, and end users to explore and understand social dynamics. However, the exponential growth in the volume, velocity, and variability of social media data prevents people from fully utilizing such data. Visual analytics, which is an emerging research direction, has received considerable attention in recent years. Many visual analytics methods have been proposed across disciplines to understand large-scale structured and unstructured social media data. This objective, however, also poses significant challenges for researchers to obtain a comprehensive picture of the area, understand research challenges, and develop new techniques. In this paper, we present a comprehensive survey to characterize this fast-growing area and summarize the state-of-the-art techniques for analyzing social media data. In particular, we classify existing techniques into two categories: gathering information and understanding user behaviors. We aim to provide a clear overview of the research area through the established taxonomy. We then explore the design space and identify the research trends. Finally, we discuss challenges and open questions for future studies.",
A study of personal information in human-chosen passwords and its security implications,"Though not recommended, Internet users often include parts of personal information in their passwords for easy memorization. However, the use of personal information in passwords and its security implications have not yet been studied systematically in the past. In this paper, we first dissect user passwords from a leaked dataset to investigate how and to what extent user personal information resides in a password. In particular, we extract the most popular password structures expressed by personal information and show the usage of personal information. Then we introduce a new metric called Coverage to quantify the correlation between passwords and personal information. Afterwards, based on our analysis, we extend the Probabilistic Context-Free Grammars (PCFG) method to be semantics-rich and propose Personal-PCFG to crack passwords by generating personalized guesses. Through offline and online attack scenarios, we demonstrate that Personal-PCFG cracks passwords much faster than PCFG and makes online attacks much easier to succeed.","Measurement,
Correlation,
Authentication,
Dictionaries,
Semantics,
Electronic mail"
Achievable Rates of Underlay-Based Cognitive Radio Operating Under Rate Limitation,"A new information-theoretic model is proposed for underlay-based cognitive radio (CR), which imposes rate limitation on the secondary user (SU), whereas the traditional systems impose either interference or transmit power limitations. The channel is modeled as a twin-user interference channel constituted by the primary user (PU) and the SU. The achievable rate of the SU is derived based on the inner bound formulated by Han and Kobayashi, where the PU achieves the maximum attainable rate of the single-user point-to-point link. We show that it is necessary for the SU to allocate its full power for the “public” message that can be decoded both by the SU and by the PU. We also demonstrate that it is optimal for the PU to allocate its full power for the “private” message that can only be decoded by the PU if the level of interference imposed by the PU on the SU is “ergodically strong.” Similarly, it is optimal for the PU to allocate its full power for the public message that can be decoded both by the SU and PU if this interference is “ergodically weak.” These findings suggest that this power allocation is independent of the level of interference imposed by the SU on the PU. Furthermore, the achievable rate is analyzed as a function of the average level of interference. An interesting observation is that if the level of interference imposed by the SU on the PU is “ergodically weak,” the achievable rate becomes a monotonically increasing function of this interference, and it is independent of the level of interference imposed by the PU on the SU. Furthermore, we analyze the realistic imperfect channel estimation scenario and demonstrate that the channel estimation errors will not affect the optimal nature of the SU's power allocation.","Receivers,
Noise,
Decoding,
Cognitive radio,
Fading,
Interference channels"
Stochastic Centralized Dispatch Scheme for AC/DC Hybrid Smart Distribution Systems,"This paper presents a two-stage stochastic centralized dispatch scheme for AC/DC hybrid smart grids. The developed dispatch scheme coordinates the operations of a variety of distributed energy resources (DERs), such as distributed generators (DGs) and energy storage systems (ESSs). It also ensures the coordinated charging of electric vehicles (EVs) and models the degradation of their batteries that occurs due to vehicle-to-grid (V2G). The energy coordination problem has been formulated as a two-stage day-ahead resource scheduling problem, with the intermittent supply; the variable demand, which includes EVs; and the fluctuating real-time energy price modeled as random variables. The first stage produces day-ahead dispatch decisions for the dispatchable DG units. For a set of possible scenarios over the next 24 h, the second stage determines appropriate corrective decisions with respect to the import/export schedule, storage charging/discharging cycles, and EV charging/discharging patterns. The objective is to minimize the expected total operating cost while satisfying operational and technical constraints. The new two-stage stochastic centralized dispatch model has been tested on a 38-bus AC/DC hybrid distribution system. The simulation results demonstrate the effectiveness of the developed scheme for optimally coordinating the various components of future AC/DC hybrid smart grids. To demonstrate the necessity for uncertainty modeling, the value of the stochastic solution (VSS) and the expected value of perfect information (EVPI) have been applied for comparing the stochastic solution obtained and the deterministic one.",
Joint Spectrum and IT Resource Allocation for Efficient VNF Service Chaining in Inter-Datacenter Elastic Optical Networks,"We study how to allocate spectrum and IT resources jointly for realizing efficient virtual network function (VNF) service chaining in inter-datacenter elastic optical networks. We first formulate an integer linear programming model to solve the problem exactly, and then a longest common subsequence-based heuristic is proposed. The simulation results indicate that the proposed algorithms can reuse the deployed VNFs efficiently and arrange the spectrum utilization in a much more load-balanced manner.","Bandwidth,
Optical fiber networks,
Routing,
Resource management,
Indexes,
Planning,
Simulation"
Joint Energy Management Strategy for Geo-Distributed Data Centers and Electric Vehicles in Smart Grid Environment,"According to some forecast models, electric vehicles (EVs) are expected to have a high level of penetration in the coming decades. To support the daily operation of EVs, charging is necessary. Generally, there are three main charging scenes in the future, i.e., charging at workplace, charging at home, and charging at commercial station. For a data center operator, the synchronous EV charging of the employees at the workplace during the working hours would incur an additional large demand charge. To avoid/reduce such demand charge, we investigate a joint energy management problem for geo-distributed data centers and EVs of the employees in this paper. Specifically, we intend to minimize the cost of a data center operator by jointly scheduling data center workload and EV charging under the given power limits, where the cost consists of electricity bill, revenue loss associated with workloads, and battery depreciation cost. We first formulate a total cost minimization problem with the consideration of heterogeneous demands of EVs and the given power limits. Since the formulated problem is a large-scale convex optimization problem with temporally-coupled and spatially-coupled constraints, we propose a distributed algorithm to solve it. Based on the proposed algorithm, we design a joint energy management strategy for geo-distributed data centers and EVs. Simulation results based on real-world traces show that the proposed strategy could reduce the cost for the data center operator by up to 5.324%.",
Low Starting Electron Beam Current in Degenerate Band Edge Oscillators,"We propose a new principle of operation in vacuum electron-beam-based oscillators that leads to a low beam current for starting oscillations. The principle is based on supersynchronous operation of an electron beam interacting with four degenerate electromagnetic modes in a slow-wave structure (SWS). The four-mode supersynchronous regime is associated with a very special degeneracy condition in the dispersion diagram of a cold periodic SWS called degenerate band edge (DBE). This regime features a giant group delay in the finite-length SWS and low starting-oscillation beam current. The starting beam current is at least an order of magnitude smaller compared with a conventional backward-wave oscillator of the same length. As a representative example, we consider an SWS conceived by a periodically loaded metallic waveguide supporting a DBE and investigate starting-oscillation conditions using the Pierce theory generalized to coupled transmission lines. The proposed supersynchronism regime can be straightforwardly adapted to waveguide geometries others than the periodically loaded waveguide considered here since DBE is a general property that can be realized in a variety of structures.","Oscillators,
Dispersion,
Electron beams,
Periodic structures,
Loaded waveguides,
Delays"
PBA: Prediction-Based Authentication for Vehicle-to-Vehicle Communications,"In vehicular networks, broadcast communications are critically important, as many safety-related applications rely on single-hop beacon messages broadcast to neighbor vehicles. However, it becomes a challenging problem to design a broadcast authentication scheme for secure vehicle-to-vehicle communications. Especially when a large number of beacons arrive in a short time, vehicles are vulnerable to computation-based Denial of Service (DoS) attacks that excessive signature verification exhausts their computational resources. In this paper, we propose an efficient broadcast authentication scheme called Prediction-Based Authentication (PBA) to not only defend against computation-based DoS attacks, but also resist packet losses caused by high mobility of vehicles. In contrast to most existing authentication schemes, our PBA is an efficient and lightweight scheme since it is primarily built on symmetric cryptography. To further reduce the verification delay for some emergency applications, PBA is designed to exploit the sender vehicle's ability to predict future beacons in advance. In addition, to prevent memory-based DoS attacks, PBA only stores shortened re-keyed Message Authentication Codes (MACs) of signatures without decreasing security. We analyze the security of our scheme and simulate PBA under varying vehicular network scenarios. The results demonstrate that PBA fast verifies almost 99 percent messages with low storage cost not only in high-density traffic environments but also in lossy wireless environments.","Vehicles,
Receivers,
Authentication,
Computer crime,
Packet loss"
A Stochastic Geometry Model for Multi-Hop Highway Vehicular Communication,"Carrier sense multiple access (CSMA) protocol is standardized for vehicular communication to ensure a distributed and efficient communication between vehicles. However, several vehicular applications require efficient multi-hop information dissemination. This paper exploits stochastic geometry to develop a tractable and accurate modeling framework to characterize the multi-hop transmissions for vehicular networks in a multilane highway setup. In particular, we study the tradeoffs between per-hop packet forward progress, per-hop transmission success probability, and spatial frequency reuse (SFR) efficiency imposed by different packet forwarding schemes, namely, most forward with fixed radius (MFR), the nearest with forward progress (NFP), and the random with forward progress (RFP). We also define a new performance metric, denoted as the aggregate packet progress (APP), which is a dimensionless quantity that captures the aforementioned tradeoffs. To this end, the developed model reveals the interplay between the spectrum sensing threshold (ρth) of the CSMA protocol and the packet forwarding scheme. Our results show that, contrary to ALOHA networks, which always favor NFP, MFR may achieve the highest APP in CSMA networks if ρth is properly chosen.","Multiaccess communication,
Vehicles,
Road transportation,
Protocols,
Sensors,
Spread spectrum communication,
Measurement"
Is every flow on the right track?: Inspect SDN forwarding with RuleScope,"Software-Defined Networking (SDN) promises un-precedentedly flexible network management but it is susceptible to forwarding faults. Such faults originate from data-plane rules with missing faults and priority faults. Yet existing fault detection ignores priority faults because they are not discovered on commercial switches until recently. In this paper, we present RuleScope, a more comprehensive solution for inspecting SDN forwarding. RuleScope offers a series of accurate and efficient algorithms for detecting and troubleshooting rule faults. They inspect forwarding behavior using customized probe packets to exercise data-plane rules. The detection algorithm exposes not only missing faults but also priority faults. Beyond simply detecting rule faults, the troubleshooting algorithms uncover actual data-plane flow tables. They help track real-time forwarding status and benefit reliable network monitoring. We explore various techniques for enhancing algorithm efficiency without sacrificing inspection accuracy. Experiments with our prototype on the Ryu SDN controller and Pica8 P-3297 switch show that RuleScope achieves accurate and efficient forwarding inspection with limited bandwidth and packet-switching overhead.",
Toward Risk Reduction for Mobile Service Composition,"The advances in mobile technologies enable us to consume or even provide services through powerful mobile devices anytime and anywhere. Services running on mobile devices within limited range can be composed to coordinate together through wireless communication technologies and perform complex tasks. However, the mobility of users and devices in mobile environment imposes high risk on the execution of the tasks. This paper targets reducing this risk by constructing a dependable service composition after considering the mobility of both service requesters and providers. It first proposes a risk model and clarifies the risk of mobile service composition; and then proposes a service composition approach by modifying the simulated annealing algorithm. Our objective is to form a service composition by selecting mobile services under the mobility model and to ensure the service composition have the best quality of service and the lowest risk. The experimental results demonstrate that our approach can yield near-optimal solutions and has a nearly linear complexity with respect to a problem size.","Mobile communication,
Quality of service,
Mobile handsets,
Linear programming,
Annealing,
Wireless communication,
Optimization"
Public Integrity Auditing for Shared Dynamic Cloud Data with Group User Revocation,"The advent of the cloud computing makes storage outsourcing become a rising trend, which promotes the secure remote data auditing a hot topic that appeared in the research literature. Recently some research consider the problem of secure and efficient public data integrity auditing for shared dynamic data. However, these schemes are still not secure against the collusion of cloud storage server and revoked group users during user revocation in practical cloud storage system. In this paper, we figure out the collusion attack in the exiting scheme and provide an efficient public integrity auditing scheme with secure group user revocation based on vector commitment and verifier-local revocation group signature. We design a concrete scheme based on the our scheme definition. Our scheme supports the public checking and efficient user revocation and also some nice properties, such as confidently, efficiency, countability and traceability of secure group user revocation. Finally, the security and experimental analysis show that, compared with its relevant schemes our scheme is also secure and efficient.","Cloud computing,
Servers,
Vectors,
Databases,
Generators,
Cryptography"
"Rethinking Memory Management in Modern Operating System: Horizontal, Vertical or Random?","On modern multicore machines, the memory management typically combines address interleaving in hardware and random allocation in the operating system (OS) to improve performance of both memory and cache. The conventional solutions, however, are increasingly strained as a wide variety of workloads run on complicated memory hierarchy and cause contention at multiple levels. We describe a new framework (named HVR) in OS memory management to support a flexible policy space for tackling diverse application needs, integrating vertical partitioning across layers, horizontal partitioning and random-interleaved allocation at a single layer. We exhaustively study the performance of these policies for over 2,000 workloads and correlate performance with application characteristics. Based on this correlation we derive several practical rules of memory allocation that we integrate into the unified HVR framework to guide resource partitioning and sharing for dynamic and diverse workloads. We implement our approach in Linux kernel 2.6.32 as a restructured page indexing system plus a series of kernel modules. Experimental results show that our framework consistently outperforms the unmodified Linux kernel, with up to 21 percent performance gains, and outperforms prior solutions at individual levels of the memory hierarchy.","Memory management,
Resource management,
Random access memory,
Kernel,
Linux,
Color"
A Hybrid Multiobjective Memetic Metaheuristic for Multiple Sequence Alignment,"Over the last 25 years, the multiple sequence alignment (MSA) problem has attracted the attention of biologists because it is one of the major techniques used in several areas of computational biology, such as homology searches, genomic annotation, protein structure prediction, gene regulation networks, or functional genomics. This problem implicates the alignment of more than two biological sequences, and is considered as a nondeterministic polynomial time optimization problem. In this paper, we find a number of different approaches for dealing with this biological sequence alignment problem. Basically, we distinguish six main groups: 1) exact methods; 2) progressive methods; 3) consistency-based methods; 4) iterative methods; 5) evolutionary algorithms; and 6) structure-based methods. In this paper, we propose the use of evolutionary computation and multiobjective optimization for solving this bioinformatics problem. A multiobjective version of a memetic metaheuristic is presented: hybrid multiobjective metaheuristics for MSA. In order to prove the effectiveness of the new proposal, we use three structure-based benchmarks created by using empirical data as input. The results obtained by our method are compared with well-known methods published in this paper, concluding that the new approach presents remarkable accuracy when dealing with sets of sequences with a low sequence similarity, the most frequent ones in real world.","Optimization,
Linear programming,
Memetics,
Genetic algorithms,
Sociology,
Statistics"
Advanced IDD receiver for PDMA uplink system,"The anticipated 1000 fold increase in traffic demand over the next decade and the explosion of new services and applications, such as the internet of things (IoT), pose great challenges for the current 4G mobile network. Pattern division multiple access (PDMA), as a novel non-orthogonal multiple access scheme, has been proposed recently to address these challenges. The performance of PDMA uplink system mainly depends on the receiver algorithm. The conventional message pass algorithm (MPA) cannot fully exploit the benefits of the coded PDMA system. In this paper, we devise an advanced receiver via iterative detection and decoding (IDD) algorithm which fully exploits coding potentials and diversity gains of the PDMA. The simulation results show that IDD based advanced receiver obtains a performance improvement about 1.6 dB at block error rate (BLER) of 0.01 for 300% overload compared with the MPA based approach.","Decision support systems,
Manganese"
Efficient Selection of Trace and Scan Signals for Post-Silicon Debug,"Post-silicon validation is a critical part of integrated circuit design methodology. The primary objective is to detect and eliminate the bugs that have escaped pre-silicon validation phase. One of the key challenges in post-silicon validation is the limited observability of internal signals in manufactured chips. A promising direction to improve observability is to combine trace and scan signals-a small set of trace signals are stored in every cycle, whereas a large set of scan signals are dumped across multiple cycles. Existing techniques are not very effective, since they explore a coarse-grained combination of trace and scan signals. In this paper, we propose a fine-grained architecture that addresses this issue using various scan chains with different dumping periods. We also propose efficient algorithms to select beneficial signals based on this architecture. Our experimental results demonstrate that our approach can improve restoration ratio up to 127% (36% on average) compared with existing trace-only techniques. Our approach also shows up to 125% improvement (61.7% on average) compared with techniques that allow a combination of trace and scan signals with minor (<;1%) area and power overhead.","Hardware,
Observability,
Logic gates,
Algorithm design and analysis,
Partitioning algorithms,
Silicon,
Color"
Joint Power Control and Rate Adaptation for Video Streaming in Wireless Networks With Time-Varying Interference,"This paper considers a cross-layer optimization framework for video streaming in multinode wireless networks with a time-varying interference environment. We develop a distributed joint power control and rate adaptation framework that exploits the time diversity of the wireless channels, satisfies the hard delay constraints associated with video applications, and respects a certain fairness criterion among the nodes. The proposed framework performs power allocation at the physical/media access control layers to achieve a certain target signal-to-interference-plus-noise ratio, such that the difference between the arrival and the departure rates at the queues is very small, and performs video rate adaptation at the video coding layer (upper layer) according to the nodes' demanded video quality, their channel conditions, and a given fairness criterion. A main challenge here is that the adaptation of the video rate and the power control is not performed at the same time scale. We deal with this issue and model the power and rate variations of the nodes as linear stochastic dynamic equations and formulate a risk-sensitive control problem that captures the hard delay constraints of the video services and the fairness criterion for resource utilization. We provide an optimal solution for this control problem and illustrate the performance of our framework through simulations.",
Carotid Artery Wall Segmentation in Multispectral MRI by Coupled Optimal Surface Graph Cuts,"We present a new three-dimensional coupled optimal surface graph-cut algorithm to segment the wall of the carotid artery bifurcation from Magnetic Resonance (MR) images. The method combines the search for both inner and outer borders into a single graph cut and uses cost functions that integrate information from multiple sequences. Our approach requires manual localization of only three seed points indicating the start and end points of the segmentation in the internal, external, and common carotid artery. We performed a quantitative validation using images of 57 carotid arteries. Dice overlap of 0.86 ± 0.06 for the complete vessel and 0.89 ± 0.05 for the lumen compared to manual annotation were obtained. Reproducibility tests were performed in 60 scans acquired with an interval of 15 ± 9 days, showing good agreement between baseline and follow-up segmentations with intraclass correlations of 0.96 and 0.74 for the lumen and complete vessel volumes respectively.","Image segmentation,
Carotid arteries,
Magnetic resonance imaging,
Image edge detection,
Bifurcation,
Deformable models"
Location-Aware Pilot Assignment for Massive MIMO Systems in Heterogeneous Networks,"We investigate the heterogeneous cellular network (HetNet) where the macrocell base stations (MBSs) are equipped with very large antenna arrays. Since such a combined massive multi-input multi-output (MIMO) and HetNet system operates in the co-channel time-division duplex mode, to mitigate the pilot contamination effect to channel estimation, the number of users that can be served simultaneously is limited by the available pilot resources in the conventional designs. We propose a pilot reuse scheme for massive MIMO-HetNet to increase the user capacity. Specifically, location-aware channel estimation is employed at the MBSs to mitigate the severe pilot contamination introduced by pilot reuse, and we propose a novel pilot assignment algorithm to reduce the interference in HetNets. Simulation results demonstrate that our proposed scheme can support more users and increase both the uplink and the downlink sum-rate capacity, in comparison to the conventional scheme, particularly when the antenna number at the MBSs is sufficiently large.",
Wireless Communication in Feedback-Assisted Active Sensors,"A novel wireless high-resolution resonant-based microwave sensor is presented for chemical sensing applications. A combination of antenna with a planar microstrip resonator increases the flexibility, durability, and reliability while extending the application of the sensor to areas with limited access and harsh environments. The main core of this sensor is a passive planar resonator, which operates at 1.41 GHz and is reinforced by a regenerative active feedback circuitry. The regenerative active feedback loop compensates the power loss of the sensor and, as a result, provides an extremely high-quality factors. Four bow-tie slot antennas of the moderate gain of 5 dB, linearly polarized over the frequency span of 1.35-2 GHz is used to communicate in short range. The sensor model is implemented using the finite-element method and a complete set of simulation is presented. The simulation results are confirmed by the measurements for resonant profile variation in material sensing. The initial quality factor of the fabricated sensor, considering the antennas and resonator loss is Q ≈22000, which broadens the range of sensing platforms into classification of low concentrated (0.003125-0.1 g/mL) salt water as well as material detection of common chemicals such as IPA, acetone, ethanol, methanol, and water.","Sensors,
Wireless communication,
Q-factor,
Gain,
Transmitting antennas,
Antenna measurements,
Wireless sensor networks"
Analysis of 7/8-nm Bulk-Si FinFET Technologies for 6T-SRAM Scaling,"The benefits of a super-steep retrograde (SSR) fin doping profile, which can be achieved using the oxygen insertion technology, are quantified via 3-D technology computer-aided design simulations for the 7/8-nm bulk-Si FinFET technology targeting low-power applications. A calibrated compact model is then used to estimate the six-transistor static RAM cell performance and yield. The SSR FinFET technology is projected to provide for up to 100 mV reduction in minimum cell supply voltage, to facilitate voltage scaling to below 0.50 V.","FinFETs,
Doping,
Logic gates,
Solid modeling,
Random access memory,
Leakage currents"
Omnidirectional Square Loop Segmented Antenna,"A square loop antenna of circumference about one free-space wavelength displays an omnidirectional radiation pattern when its conductor is partitioned into five segments that are interconnected by four small capacitances. The optimization process for determining the capacitances values is described in detail. The required four capacitances are created by overlapping the conductor segments on the opposite sides of the substrate. The far field of the antenna resembles the one of an elementary magnetic dipole. At the center frequency of 956 MHz, the measured maximum gain is 2 dBi, and the measured antenna efficiency is 94%.","Antenna radiation patterns,
Capacitance,
Antenna measurements,
Optimization,
Linear programming,
Dipole antennas"
Heterogeneous Energy Storage Optimization for Microgrids,"As microgrids evolve, it is reasonable to expect that a variety of energy storage systems (ESSs) with different operational characteristics will be used simultaneously. Because each storage system has different capabilities and capacities, they will complement each other, and be able to achieve more efficient and reliable results than if only a single type of system were used. However, integrating multiple types of storage comes with several implementation challenges. Existing control techniques used to charge and discharge different technologies are not sufficient to accommodate the electrochemical (or mechanical) differences. In this paper, we propose an interconnection topology and a reinforcement learning-based algorithm to optimize the coordination of different ESSs in a microgrid.","Batteries,
Microgrids,
Optimization,
System-on-chip,
Discharges (electric),
Topology"
Link Regime and Power Savings of Decode-Forward Relaying in Fading Channels,"In this paper, we re-examine the relay channel under the decode-forward (DF) strategy. Contrary to the established belief that block Markov coding is always the rate-optimal DF strategy, under certain channel conditions (a link regime), independent signaling between the source and relay achieves the same transmission rate without requiring coherent channel phase information. Furthermore, this independent signaling regime allows the relay to conserve power. As such, we design a composite DF relaying strategy that achieves the same rate as block Markov DF but with less required relay power. The finding is attractive from the link adaptation perspective to adapt relay coding and relay power according to the link state. We examine this link adaptation in fading under both perfect channel state information (CSI) and practical CSI in which nodes have perfect receive and long-term transmit CSI, and derive the corresponding relay power savings in both cases. We also derive the outage probability of the composite relaying scheme, which adapts the signaling to the link regime. Through simulation, we expose a tradeoff for relay placement showing that the relay conserves the most power when closer to the destination but achieves the most rate gain when closer to the source.","Relays,
Encoding,
Markov processes,
Fading,
Channel models,
Adaptation models,
Wireless communication"
From Rateless to Distanceless: Enabling Sparse Sensor Network Deployment in Large Areas,"This paper presents a distanceless networking approach for wireless sensor networks sparsely deployed in large areas. By leveraging rateless codes, we provide distanceless transmission to expand the communication range of sensor motes and fully exploit network diversity. We address a variety of practical challenges to accommodate rateless coding on resource-constrained sensor motes and devise a communication protocol to efficiently coordinate the distanceless link transmissions. We propose a new metric (expected distanceless transmission time) for routing selection and further adapt the distanceless transmissions to low duty-cycled sensor networks. We implement the proposed scheme in TinyOS on the TinyNode platform and deploy the sensor network in a real-world project, in which 12 wind measurement sensors are installed around a large urban reservoir of 2.5 × 3.0 km 2 to monitor the field wind distribution. Extensive experiments show that our proposed scheme significantly outperforms the state-of-the-art approaches for data collection in sparse sensor networks.","Decoding,
Receivers,
Transmitters,
Bit rate,
Matrices,
Encoding,
Data collection"
A Profit Maximization Approach to Demand Response Management with Customers Behavior Learning in Smart Grid,"In this paper, we propose a profit-maximization-based pricing optimization model for the demand response (DR) management with customer behavior learning in the context of smart grids. By recognizing the different consumption patterns between shiftable and curtailable appliances, two different and distinguished behavior models are proposed. For shiftable appliances whose energy consumption can be shifted from high price periods to low price periods but total energy consumption is fixed, a probabilistic behavior model and its learning algorithm are proposed to model an individual customer's shifting probabilities dependent on different hourly prices. For curtailable appliances whose energy consumption cannot be shifted but total energy consumption can be adjusted, a regression model is proposed to model an individual customer's usage patterns dependent on prices and temperatures. After proposing the learning algorithms to identify these proposed behavior models, this paper further develops a genetic algorithm-based distributed pricing optimization algorithm for DR management with the aim to maximize the retailer's profit. Numerical results indicate the applicability and effectiveness of the proposed models and their benefits to the retailer by improving its profit.","Home appliances,
Energy consumption,
Load modeling,
Pricing,
Smart meters,
Optimization,
Switches"
A 200-Channel Area-Power-Efficient Chemical and Electrical Dual-Mode Acquisition IC for the Study of Neurodegenerative Diseases,"Microelectrode array (MEA) can be used in the study of neurodegenerative diseases by monitoring the chemical neurotransmitter release and the electrical potential simultaneously at the cellular level. Currently, the MEA technology is migrating to more electrodes and higher electrode density, which raises power and area constraints on the design of acquisition IC. In this paper, we report the design of a 200-channel dual-mode acquisition IC with highly efficient usage of power and area. Under the constraints of target noise and fast settling, the current channel design saves power by including a novel current buffer biased in discrete time (DT) before the TIA (transimpedance amplifier). The 200 channels are sampled at 20 kS/s and quantized by column-wise SAR ADCs. The prototype IC was fabricated in a 0.18 μm CMOS process. Silicon measurements show the current channel has 21.6 pArms noise with cyclic voltammetry (CV) and 0.48 pArms noise with constant amperometry (CA) while consuming 12.1 μW. The voltage channel has 4.07 μVrms noise in the bandwidth of 100 kHz and 0.2% nonlinearity while consuming 9.1 μW. Each channel occupies 0.03 mm2 area, which is among the smallest.","Noise,
Electrodes,
Sensors,
Integrated circuits,
Power capacitors,
Chemicals,
Bandwidth"
A Secure Anti-Collusion Data Sharing Scheme for Dynamic Groups in the Cloud,"Benefited from cloud computing, users can achieve an effective and economical approach for data sharing among group members in the cloud with the characters of low maintenance and little management cost. Meanwhile, we must provide security guarantees for the sharing data files since they are outsourced. Unfortunately, because of the frequent change of the membership, sharing data while providing privacy-preserving is still a challenging issue, especially for an untrusted cloud due to the collusion attack. Moreover, for existing schemes, the security of key distribution is based on the secure communication channel, however, to have such channel is a strong assumption and is difficult for practice. In this paper, we propose a secure data sharing scheme for dynamic members. First, we propose a secure way for key distribution without any secure communication channels, and the users can securely obtain their private keys from group manager. Second, our scheme can achieve fine-grained access control, any user in the group can use the source in the cloud and revoked users cannot access the cloud again after they are revoked. Third, we can protect the scheme from collusion attack, which means that revoked users cannot get the original data file even if they conspire with the untrusted cloud. In our approach, by leveraging polynomial function, we can achieve a secure user revocation scheme. Finally, our scheme can achieve fine efficiency, which means previous users need not to update their private keys for the situation either a new user joins in the group or a user is revoked from the group.","Access control,
Cloud computing,
Communication channels,
Encryption,
Educational institutions"
Automated test generation for Debugging arithmetic circuits,"Optimized and custom arithmetic circuits are widely used in embedded systems such as multimedia applications, cryptography systems, signal processing and console games. Debugging of arithmetic circuits is a challenge due to increasing complexity coupled with non-standard implementations. Existing equivalence checking techniques produce a remainder to indicate the presence of a potential bug. However, bug localization remains a major bottleneck. Simulation-based validation using random or constrained-random tests are not effective and can be infeasible for complex arithmetic circuits. In this paper, we present an automated test generation and bug localization technique for debugging arithmetic circuits. This paper makes two important contributions. We propose an automated approach for generating directed tests by suitable assignments of input variables to make the reminder non-zero. The generated tests are guaranteed to activate the unknown bug. We also propose a bug detection and correction technique by utilizing the patterns of remainder terms as well as the intersection of regions activated by the generated tests. Our experimental results demonstrate that the proposed approach can be used for automated debugging of complex arithmetic circuits.","Circuit faults,
Debugging,
Logic gates,
Computer bugs,
Mathematical model,
Generators,
Partitioning algorithms"
Psychological Parameters for Crowd Simulation: From Audiences to Mobs,"In the social psychology literature, crowds are classified as audiences and mobs. Audiences are passive crowds, whereas mobs are active crowds with emotional, irrational and seemingly homogeneous behavior. In this study, we aim to create a system that enables the specification of different crowd types ranging from audiences to mobs. In order to achieve this goal we parametrize the common properties of mobs to create collective misbehavior. Because mobs are characterized by emotionality, we describe a framework that associates psychological components with individual agents comprising a crowd and yields emergent behaviors in the crowd as a whole. To explore the effectiveness of our framework we demonstrate two scenarios simulating the behavior of distinct mob types.","Psychology,
Computational modeling,
Oceans,
Visualization,
Decision making,
Appraisal,
Autonomous agents"
Do code smells hamper novice programming? A controlled experiment on Scratch programs,"Recently, block-based programming languages like Alice, Scratch and Blockly have become popular tools for programming education. There is substantial research showing that block-based languages are suitable for early programming education. But can block-based programs be smelly too? And does that matter to learners? In this paper we explore the code smells metaphor in the context of block-based programming language Scratch. We conduct a controlled experiment with 61 novice Scratch programmers, in which we divided the novices into three groups. One third receive a non-smelly program, while the other groups receive a program suffering from the Duplication or the Long Method smell respectively. All subjects then perform the same comprehension tasks on their program, after which we measure their time and correctness. The results of the experiment show that code smell indeed influence performance: subjects working on the program exhibiting code smells perform significantly worse, but the smells did not affect the time subjects needed. Investigating different types of tasks in more detail, we find that Long Method mainly decreases system understanding, while Duplication decreases the ease with which subjects modify Scratch programs.","Programming profession,
Sprites (computer),
Games,
Computer languages,
Education"
Transforming Unidirectional Edge Waveguide Into Unidirectional Air Waveguide,"A unidirectional waveguide plays the key role in optical communication system. The unidirectional edge modes in two-dimensional magneto-optical photonic crystals have a unique feature because they are robust against imperfections or disruptions along the edge, but they can hardly form an optical beam. In order to obtain a unidirectional air waveguide, we have studied the coupling effect of two unidirectional edge modes basing on band calculations and numerical simulations. With a waveguide width of 1.5a, an ideal unidirectional air waveguide is achieved. The unidirectional air waveguide has great performance because of its broad working bandwidth, high extinction ratio, single-mode feature, and air waveguide configuration. It has an advantage over the unidirectional edge waveguide because it can focus the wave energy and form a one-way beam. An analytical analysis is also given for the results.",
CompoundEyes: Near-duplicate detection in large scale online video systems in the cloud,"At the present time, billions of videos are hosted and shared in the cloud of which a sizable portion consists of near-duplicate video copies. An efficient and accurate content-based online near-duplicate video detection method is a fundamental research goal; as it would benefit applications such as duplication-aware storage, pirate video detection, polluted video tag detection, searching result diversification. Despite the recent progress made in near-duplicate video detection, it remains challenging to develop a practical detection system for large-scale applications that has good efficiency and accuracy performance. In this paper, we shift the focus from feature representation design to system design, and develop a novel system, called CompoundEyes, accordingly. The improvement in accuracy is achieved via well-organized classifiers instead of advanced feature design. Meanwhile, by applying simple features with reduced dimensionality and exploiting the parallelism of the detection architecture, we accelerate the detection speed. Through extensive experiments we demonstrate that the proposed detection system is accurate and fast. It takes approximately 1.45 seconds to process a video clip from a large video dataset, CC_WEB_VIDEO, with a 89% detection accuracy.",
Flexible Epineural Strip Electrode for Recording in Fine Nerves,"This paper demonstrates flexible epineural strip electrodes (FLESE) for recording from small nerves. Small strip-shaped FLESE enables us to easily and closely stick on various sized nerves for less damage in a nerve and optimal recording quality. In addition, in order to enhance the neural interface, the gold electrode contacts were coated with carbon nanotubes, which reduced the impedance of the electrodes. We used the FLESEs to record electrically elicited nerve signals (compound neural action potentials) from the sciatic nerve in rats. Bipolar and differential bipolar configurations for the recording were investigated to optimize the recording configuration of the FLESEs. The successful results from differential bipolar recordings showed that the total length of FLESEs could be further reduced, maintaining the maximum recording ability, which would be beneficial for recording in very fine nerves. Our results demonstrate that new concept of FLESEs could play an important role in electroceuticals in near future.","Electrodes,
Gold,
Impedance,
Coatings,
Polyimides,
Surface impedance,
Strips"
Speeding-Up Robot Exploration by Exploiting Background Information,"The ability to autonomously learn a model of an environment is an important capability of a mobile robot. In this paper, we investigate the problem of exploring a scene given background information in form of a topo-metric graph of the environment. Our method is relevant for several real-world applications in which the rough structure of the environment is known beforehand. We present an approach that exploits such background information and enables a robot to cover the environment with its sensors faster compared to a greedy exploration system without this information. We implemented our exploration system in ROS and evaluated it in different environments. As the experimental results demonstrate, our proposed method significantly reduces the overall trajectory length needed to cover the environment with the robot's sensors and thus yields a more efficient exploration strategy compared to state-of-the-art greedy exploration, if the additional information is available.","Robot kinematics,
Robot sensing systems,
Traveling salesman problems,
Trajectory,
Navigation"
Robust Convex Approximation Methods for TDOA-Based Localization Under NLOS Conditions,"In this paper, we develop a novel robust optimization approach to source localization using time-difference-of-arrival (TDOA) measurements that are collected under non-line-of-sight (NLOS) conditions. A key feature of our approach is that it does not require knowledge of the distribution or statistics of the NLOS errors, which are often difficult to obtain in practice. Instead, it only assumes that the NLOS errors have bounded supports. Based on this assumption, we formulate the TDOA-based source localization problem as a robust least squares (RLS) problem, in which a location estimate that is robust against the NLOS errors is sought. Since the RLS problem is non-convex, we propose two efficiently implementable convex relaxation-based approximation methods to tackle it. We then conduct a thorough theoretical analysis of the approximation quality and computational complexity of these two methods. In particular, we establish conditions under which they will yield a unique localization of the source. Simulation results on both synthetic and real data show that the performance of our approach under various NLOS settings is very stable and is significantly better than that of several existing non-robust approaches.",
Pairwise Latent Semantic Association for Similarity Computation in Medical Imaging,"Retrieving medical images that present similar diseases is an active research area for diagnostics and therapy. However, it can be problematic given the visual variations between anatomical structures. In this paper, we propose a new feature extraction method for similarity computation in medical imaging. Instead of the low-level visual appearance, we design a CCA-PairLDA feature representation method to capture the similarity between images with high-level semantics. First, we extract the PairLDA topics to represent an image as a mixture of latent semantic topics in an image pair context. Second, we generate a CCA-correlation model to represent the semantic association between an image pair for similarity computation. While PairLDA adjusts the latent topics for all image pairs, CCA-correlation helps to associate an individual image pair. In this way, the semantic descriptions of an image pair are closely correlated, and naturally correspond to similarity computation between images. We evaluated our method on two public medical imaging datasets for image retrieval and showed improved performance.","Silicon,
Semantics,
Visualization,
Biomedical imaging,
Feature extraction,
Training,
Context"
III-Nitride-Based Cyan Light-Emitting Diodes With GHz Bandwidth for High-Speed Visible Light Communication,"A large reduction (from 17 to 5 nm) is made in the thickness of the barrier layers in the multiple-quantum-well region of III-nitride-based cyan light-emitting diodes (LEDs) grown on patterned sapphire substrates. This is shown to lead to a simultaneous improvement in the modulation speed, differential quantum efficiency, and maximum output power of the LEDs under both room temperature and 110 °C operation. With our novel device structure, we achieve a moderate output power (1.7 mW) with a record high 3-dB electrical-to-optical (E-O) bandwidth (1 GHz). The over twofold enhancement in the E-O bandwidth (~1 versus ~0.5 GHz) compared with that previously reported visible LEDs can be attributed to the more uniform distribution of injected carriers within the MQW region and the aggressive downscaling of the thickness of the total active layer, which leads to a shortening of the spontaneous recombination time.","Light emitting diodes,
Bandwidth,
Quantum well devices,
Radiative recombination,
Gallium nitride,
Power generation,
Modulation"
"Compact Planar Ultrawideband Antennas With Continuously Tunable, Independent Band-Notched Filters","A compact planar ultrawideband antenna with continuously tunable, independent band notches for cognitive radio applications is presented. The antenna is fabricated using a copper-cladded substrate. A radiating patch with an inverted rectangular T-slot is etched on the top side of the substrate. A straight rectangular strip with a complete gap is embedded into the T-slot. By placing a single varactor diode across this gap, a frequency-agile band-notch function below 5 GHz is realized. On the bottom side of the substrate, a U-shaped parasitic element having an interdigitated-structure is placed beneath the radiating patch. The second narrow band notch is created by inserting a second varactor diode into the gap on one leg of the parasitic element. It has a frequency-agile performance above 5 GHz. The presence of the interdigitated structure suppresses higher order resonant modes and enhances the tunability of the notched bandwidth. Because these antenna structures naturally block dc, a very small number of lumped elements are required. The experimental results, which are in good agreement with their simulated values, demonstrate that both band notches can be independently controlled and the entire frequency-agile fractional bandwidth is as high as 74.5%, demonstrating a very wide notched frequency-agile coverage.",
Direct semi-dense SLAM for rolling shutter cameras,"In this paper, we present a monocular Direct and Semi-dense SLAM (Simultaneous Localization And Mapping) system for rolling shutter cameras. In a rolling shutter camera, the pose is different for each row of each image, and this yields poor pose estimates and poor structure estimates when using a state-of-the-art semi-dense direct method designed for global shutter cameras. To address this issue in tracking, we model the smooth and continuous camera trajectory using a B-spline curve of degree k??1 for poses in the Lie algebra, se(3).We solve for the camera poses at each row-time by a direct optimisation of photometric error as a function of the control points of the spline. Likewise for mapping, we develop generalised epipolar geometry for the rolling shutter case and solve for point depths using photometric error. Although each of these issues has been previously tackled, to the best of our knowledge ours is the first full solution to monocular, direct (feature-less) SLAM. We benchmark our method for pose accuracy and map accuracy against the state-of-the-art semi-dense SLAM system, LSD-SLAM, demonstrating the improved efficacy of our approach when using rolling shutter cameras via synthetic sequences with known ground-truth and real sequences.","Cameras,
Splines (mathematics),
Simultaneous localization and mapping,
Image segmentation,
Trajectory,
Geometry,
Robot vision systems"
A-Optimal Projection for Image Representation,"We consider the problem of image representation from the perspective of statistical design. Recent studies have shown that images are possibly sampled from a low dimensional manifold despite of the fact that the ambient space is usually very high dimensional. Learning low dimensional image representations is crucial for many image processing tasks such as recognition and retrieval. Most of the existing approaches for learning low dimensional representations, such as principal component analysis (PCA) and locality preserving projections (LPP), aim at discovering the geometrical or discriminant structures in the data. In this paper, we take a different perspective from statistical experimental design, and propose a novel dimensionality reduction algorithm called A-Optimal Projection (AOP). AOP is based on a linear regression model. Specifically, AOP finds the optimal basis functions so that the expected prediction error of the regression model can be minimized if the new representations are used for training the model. Experimental results suggest that the proposed approach provides a better representation and achieves higher accuracy in image retrieval.",
Cache size allocation in backhaul limited wireless networks,"Caching popular content at base stations is a powerful supplement to existing limited backhaul links for accommodating the exponentially increasing mobile data traffic. Given the limited cache budget, we investigate the cache size allocation problem in cellular networks to maximize the user success probability (USP), taking wireless channel statistics, backhaul capacities and file popularity distributions into consideration. The USP is defined as the probability that one user can successfully download its requested file either from the local cache or via the backhaul link. We first consider a single-cell scenario and derive a closed-form expression for the USP, which helps reveal the impacts of various parameters, such as the file popularity distribution. More specifically, for a highly concentrated file popularity distribution, the required cache size is independent of the total number of files, while for a less concentrated file popularity distribution, the required cache size is in linear relation to the total number of files. Furthermore, we study the multi-cell scenario, and provide a bisection search algorithm to find the optimal cache size allocation. The optimal cache size allocation is verified by simulations, and it is shown to play a more significant role when the file popularity distribution is less concentrated.","Resource management,
Wireless communication,
Mobile communication,
Downlink,
Base stations,
Probability,
Computer architecture"
A Scheduling Algorithm for MIMO DoF Allocation in Multi-Hop Networks,"Recently, a new MIMO degree-of-freedom (DoF) model was proposed to allocate DoF resources for spatial multiplexing (SM) and interference cancellation (IC) in a multi-hop network. Although this DoF model promises many benefits, it hinges upon a global node ordering to keep track of IC responsibilities among all the nodes. An open question about this model is whether its global ordering property can be achieved among the nodes in the network through distributed operations. In this paper, we explore this question by studying DoF scheduling in a multi-hop MIMO network, with the objective of maximizing the minimum throughput among a set of sessions. We propose an efficient DoF scheduling algorithm to solve it and show that our algorithm only requires local operations. We prove that the resulting DoF scheduling solution is globally feasible and show that there exists a corresponding feasible global node ordering for IC, albeit such global ordering is implicit. Simulation results show that the solution values obtained by our algorithm are relatively close to the upper bound values computed by CPLEX solver, thereby indicating that our algorithm is highly competitive.","Interference,
MIMO,
Throughput,
Integrated circuit modeling,
Spread spectrum communication,
Resource management"
Tilejunction: Mitigating Signal Noise for Fingerprint-Based Indoor Localization,"In indoor localization based on Wi-Fi fingerprinting, a target sends its received signal strength indicator (RSSI) of access points (APs) to a server to estimate its position. Traditionally, the server estimates the target position by matching the RSSI with the fingerprints stored in the database. Due to signal noise in fingerprint collection and target measurement, this often results in a geographically disperse set of reference points (RPs), leading to unsatisfactory estimation accuracy. To mitigate the noise problem, we propose a novel, efficient, and highly accurate localization scheme termed Tilejunction. Based on only the first two moments of the measured signal, Tilejunction maps the target RSSI of each AP to a convex hull termed signal “tile” where the target is likely within. Using a novel comparison metric for random signals, we formulate a linear programming (LP) problem to localize the target at the junction of the tiles. To further improve its computational efficiency, Tilejunction employs an information-theoretic measure to keep only those APs whose signals show sufficient differentiation in the site. It also partitions the site into multiple clusters to substantially reduce the search space in the LP optimization. We have implemented Tilejunction. Our extensive simulation and experimental measurements show that it outperforms other recent state-of-the-art approaches (e.g. RADAR, KL-divergence, etc.) with significantly lower localization error (often by more than 30 percent).","IEEE 802.11 Standard,
Noise measurement,
Mobile computing,
Servers"
VSync: Cloud based video streaming service for mobile devices,"Synchronizing videos over file-hosting services on personal cloud such as Dropbox, Box or Onedrive leads to wastage in bandwidth and storage, which can be critical, while using mobile devices. Users can alternatively download the video on-the-go, but that leads to high latency, depending on network bandwidth and video file size. In contrast, adaptive video streaming allows near-real-time viewing by streaming the best possible quality in a given network condition. This feature is achieved by keeping multiple versions of video in cloud, leading to additional costs in cloud storage. Moreover, current solutions can only support a small set of bitrates, leading to abrupt switches in video resolution especially when the network condition is unstable, as often experienced by mobile users. This paper introduces Vsync, a framework for cloud based video synchronization for mobile devices. A video content is streamed using a cloud-based real-time transcoding and transmission framework to provide smooth video quality. Built over prediction models for video transcoding sessions and a QoE based adaptive video streaming protocol, Vsync is able to obtain the improvements of 37 ~ 80% than other compared schemes. The dataset and evaluation was done on a pool of 220K video clips.","Streaming media,
Transcoding,
Cloud computing,
Mobile handsets,
Bandwidth,
Real-time systems,
Mobile communication"
Big Data Analytics for Emergency Communication Networks: A Survey,"Disaster management is a crucial and urgent research issue. Emergency communication networks (ECNs) provide fundamental functions for disaster management, because communication service is generally unavailable due to large-scale damage and restrictions in communication services. Considering the features of a disaster (e.g., limited resources and dynamic changing of environment), it is always a key problem to use limited resources effectively to provide the best communication services. Big data analytics in the disaster area provides possible solutions to understand the situations happening in disaster areas, so that limited resources can be optimally deployed based on the analysis results. In this paper, we survey existing ECNs and big data analytics from both the content and the spatial points of view. From the content point of view, we survey existing data mining and analysis techniques, and further survey and analyze applications and the possibilities to enhance ECNs. From the spatial point of view, we survey and discuss the most popular methods and further discuss the possibility to enhance ECNs. Finally, we highlight the remaining challenging problems after a systematic survey and studies of the possibilities.","Big data,
Communication networks,
Ad hoc networks,
Routing protocols,
Routing,
Earthquakes,
Mobile computing"
A Bounded Model of the Communication Delay for System Integrity Protection Schemes,"This paper investigates the latency of system integrity protection schemes (SIPSs) and proposes a bounded model of the communication delay. To be specific, SIPSs can be divided into wide-area protection and substation-area protection. For the former, the data buffering of phasor data concentrators and the automatic protection switching of synchronous optical network/synchronous digital hierarchy are utilized to limit the latency of regional and backbone networks, respectively; then, the communication delay is modeled as bounded, instead of average or stochastic in the literature. For the latter, the network calculus theory is used to restrict the latency in switched Ethernet networks, and the communication delay is modeled as bounded. In practice, SIPSs need to preprogram the time delay of protective relays and expect the communication delay as predictable or predetermined. Hence, the proposed bounded model is more realistic than the average or stochastic model. Further, the bounded model suggests the network dynamics and worst-case performances. It can be a useful tool in the relay setting as well as in the planning, design, and assessment of SIPS networks.","Delays,
Phasor measurement units,
Optical switches,
Stochastic processes,
Communication networks,
Optical buffering,
Indexes"
A Survey of Affective Computing for Stress Detection: Evaluating technologies in stress detection for better health,"As we become more aware of the connection between emotional states and physical health, affective computing continues to rise as a field of interest. Affective computing uses both hardware and software technology to detect the affective state of a person. It is an active research area that has seen much growth in technology geared toward affective state analysis. Its origin is credited to Dr. Rosalind Picard of the Massachusetts Institute of Technology (MIT) when she published her 1995 article on affective computing [1]. It has since become a modern branch of computer science for human-computer interfaces [2], [3]. This stem of computer science has two main veins: 1) detection and recognition of emotional information and 2) simulation of emotion in computational devices. The focus of the current survey is the detection and recognition of emotions as affective states.","Affective computing,
Electrocardiography,
Physiology,
Stress measurement,
Electroencephalography,
Heart rate variability"
Discovering Recurrent Copy Number Aberrations in Complex Patterns via Non-Negative Sparse Singular Value Decomposition,"Recurrent copy number aberrations (RCNAs) in multiple cancer samples are strongly associated with tumorigenesis, and RCNA discovery is helpful to cancer research and treatment. Despite the emergence of numerous RCNA discovering methods, most of them are unable to detect RCNAs in complex patterns that are influenced by complicating factors including aberration in partial samples, co-existing of gains and losses and normal-like tumor samples. Here, we propose a novel computational method, called non-negative sparse singular value decomposition (NN-SSVD), to address the RCNA discovering problem in complex patterns. In NN-SSVD, the measurement of RCNA is based on the aberration frequency in a part of samples rather than all samples, which can circumvent the complexity of different RCNA patterns. We evaluate NN-SSVD on synthetic dataset by comparison on detection scores and Receiver Operating Characteristics curves, and the results show that NN-SSVD outperforms existing methods in RCNA discovery and demonstrate more robustness to RCNA complicating factors. Applying our approach on a breast cancer dataset, we successfully identify a number of genomic regions that are strongly correlated with previous studies, which harbor a bunch of known breast cancer associated genes.","Bioinformatics,
Cancer,
Sparse matrices,
Tumors,
Genomics,
Computational biology"
Radio resource allocation for non-orthogonal multiple access (NOMA) relay network using matching game,"In this paper, we study the resource allocation problem for a single-cell non-orthogonal multiple access (NOMA) relay network where an OFDM amplify-and-forward (AF) relay allocates the spectrum and power resources to the source-destination (SD) pairs. We aim to optimize the spectrum and power resource allocation to maximize the total sum-rate. This is a very complicated problem and the optimal approach requires an exhaustive search, leading to a NP hard problem. To solve this problem, we propose an efficient many-to-many two sided SD pair-subchannel matching algorithm in which the SD pairs and sub-channels are considered as two sets of rational and selfish players chasing their own interests. The algorithm converges to a pair-wise stable matching after a limited number of iterations with a low complexity compared with the optimal solution. Simulation results show that the sum-rate of the proposed algorithm approaches the performance of the optimal exhaustive search and significantly outperforms the conventional orthogonal multiple access scheme, in terms of the total sum-rate and number of accessed SD pairs.","Resource management,
NOMA,
Relay networks (telecommunications),
Interference,
Complexity theory,
Silicon carbide"
Similarity Learning with Top-heavy Ranking Loss for Person Re-identification,"Person re-identification is the task of finding a person of interest across a network of cameras. In this paper, we propose a new similarity learning method for person re-identification. Conventional metric learning methods generally learn a linear transformation by employing sparse pairwise or triplet constraints. Since a lot of negative matching pairs or triplets are abandoned, the discriminative information is not fully exploited. Similarity learning methods with AUC loss can utilize all valid triplet constraints. However, the AUC loss has its own limitation by treating all false ranks occured at different positions equally. To address this limitation, we propose to extend the AUC loss to the top-heavy ranking loss by assigning large weights to top positions of the ranking list. Moreover, we introduce an explicit nonlinear transformation function for the original feature space and learn an inner product similarity under the structured output learning framework. Our approach achieves very promising results on the challenging VIPeR, CUHK Campus and PRID 450S datasets.","Measurement,
Learning systems,
Probes,
Gold,
Lighting,
Training,
Robustness"
PHY-Layer Authentication Using Duobinary Signaling for Spectrum Enforcement,"Spectrum security and enforcement is one of the major challenges that need to be addressed before spectrum sharing technologies can be adopted widely. The problem of rogue transmitters is a major threat to the viability of spectrum sharing. One approach for deterring rogue transmissions is to enable receivers to authenticate or uniquely identify transmitters. Although cryptographic mechanisms at the higher layers have been widely used to authenticate transmitters, the ability to authenticate transmitters at the physical (PHY) layer has a number of key advantages over higher layer approaches. In existing schemes, the authentication signal is added to the message signal in such a way that the authentication signal appears as noise to the message signal and vice versa. Hence, existing schemes are constrained by a fundamental tradeoff between the message signal's signal-to-noise ratio (SNR) and the authentication signal's SNR. In this paper, we extend the precoded duobinary signaling (P-DS) technique to devise a new PHY-layer authentication scheme called P-DS for authentication (P-DSA). P-DSA exploits the redundancy introduced by P-DS to embed the authentication signal into the message signal. P-DSA is not constrained by the aforementioned tradeoff between the message and authentication signals. Our results show that P-DSA improves the detection performance compared with the prior art without sacrificing message throughput or increasing transmission power.","Authentication,
Receivers,
Radio transmitters,
Signal to noise ratio,
Privacy,
Interference"
Vision-Guided Aerial Manipulation Using a Multirotor With a Robotic Arm,"This paper presents a vision guidance approach using an image-based visual servo (IBVS) for an aerial manipulator combining a multirotor with a multidegree of freedom robotic arm. To take into account the dynamic characteristics of the combined manipulation platform, the kinematic and dynamic models of the combined system are derived. Based on the combined model, a passivity-based adaptive controller which can be applied on both position and velocity control is designed. The position control is utilized for waypoint tracking such as taking off and landing, and the velocity control is engaged when the platform is guided by visual information. In addition, a guidance law utilizing IBVS is employed with modifications. To secure the view of an object with an eye-in-hand camera, IBVS is utilized with images taken from a fisheye camera. Also, to compensate underactuation of the multirotor, an image adjustment method is developed. With the proposed control and guidance laws, autonomous flight experiments involving grabbing and transporting an object are carried out. Successful experimental results demonstrate that the proposed approaches can be applied in various types of manipulation missions.","Cameras,
Manipulator dynamics,
Robot vision systems,
Mathematical model,
Robot kinematics"
Towards Reconstructing Routing Paths in Large Scale Sensor Networks,"In wireless sensor networks, sensor nodes are usually self-organized, delivering data to a central sink in a multi-hop manner. Reconstructing the per-packet routing path enables fine-grained diagnostic analysis and performance optimizations of the network. The performances of existing path reconstruction approaches, however, degrade rapidly in large scale networks with lossy links. This paper presents Pathfinder, a robust path reconstruction method against packet losses as well as routing dynamics. At the node side, Pathfinder exploits temporal correlation between a set of packet paths and efficiently compresses the path information using path difference. At the sink side, Pathfinder infers packet paths from the compressed information and employs intelligent path speculation to reconstruct the packet paths with high reconstruction ratio. We propose a novel analytical model to analyze the performance of Pathfinder. We further evaluate Pathfinder compared with two most related approaches using traces from a large scale deployment and extensive simulations. Results show that Pathfinder outperforms existing approaches, achieving both high reconstruction ratio and low transmission cost.","Routing,
Containers,
Wireless sensor networks,
Vectors,
Packet loss,
Analytical models"
Dynamic Request Redirection and Resource Provisioning for Cloud-Based Video Services under Heterogeneous Environment,"Cloud computing provides a new opportunity for Video Service Providers (VSP) to running compute-intensive video applications in a cost effective manner. Under this paradigm, a VSP may rent virtual machines (VMs) from multiple geo-distributed datacenters that are close to video requestors to run their services. As user demands are difficult to predict and the prices of the VMs vary in different time and region, optimizing the number of VMs of each type rented from datacenters located in different regions in a given time frame becomes essential to achieve cost effectiveness for VSPs. Meanwhile, it is equally important to guarantee users' Quality of Experience (QoE) with rented VMs. In this paper, we give a systematic method called Dynamical Request Redirection and Resource Provisioning (DYRECEIVE) to address this problem. We formulate the problem as a stochastic optimization problem and design a Lyapunov optimization framework based online algorithm to solve it. Our method is able to minimize the long-term time average cost of renting cloud resources while maintaining the user QoE. Theoretical analysis shows that our online algorithm can produce a solution within an upper bound to the optimal solution achieved through offline computing. Extensive experiments shows that our method is adaptive to request pattern changes along time and outperforms existing algorithms.","Delays,
Optimization,
Resource management,
Servers,
Quality of service,
Heuristic algorithms,
Streaming media"
Collaborative Web Service Quality Prediction via Exploiting Matrix Factorization and Network Map,"Quality of services (QoS) is an important concern in Web service recommendation or selection. Predicting QoS values of Web services based on their historical QoS records is an effective way to acquire Web service QoS, and thus has attracted considerable research interests. Recently, matrix factorization (MF), a well-known model-based collaborative filtering (CF) technique, has been successfully applied to the Web service QoS prediction. It is generally believed that MF can significantly outperform traditional memory-based CF techniques. However, previous work seldom considered the influence of the underlying network on Web service QoS when adopting MF for Web service QoS prediction. Hence, the prediction performance is not good enough. In this paper, we propose a network-aware Web service QoS prediction approach by integrating MF with the network map. By employing the network map, network distances between service users can be measured and neighborhoods of users are identified. Then, the traditional MF model is revamped by incorporating the constraint term that neighbor users are likely to perceive similar QoS of Web services. Experiments conducted on two real-world Web service datasets indicate that our approach outperforms previous MF and CF-based approaches in prediction accuracy.","Quality of service,
Web services,
Time factors,
Collaboration,
Throughput,
Sparse matrices"
ReMAM: Low energy Resistive Multi-stage Associative Memory for energy efficient computing,"The Internet of things (IoT) significantly increases the volume of computations and the number of running applications on processors, from mobiles to servers. Big data computation requires massive parallel processing and acceleration. In parallel processing, associative memories represent a promising solution to improve energy efficiency by eliminating redundant computations. However, the tradeoff between memory size and search energy consumption limits their applications. In this paper, we propose a novel low energy Resistive Multi-stage Associative Memory (ReMAM) architecture, which significantly reduces the search energy consumption by employing selective row activation and in-advance precharging techniques. ReMAM splits the search in the Ternary Content Addressable Memory (TCAM) to a number of shorter searches in consecutive stages. Then, it selectively activates TCAM rows at each stage based on the hits of previous stages, thus enabling energy saving. The proposed in-advance precharging technique mitigates the delay of the sequential TCAM search and limits the number of precharges to two low-cost steps. Our experimental evaluation on AMD Southern Island GPUs shows that ReMAM reduces energy consumption by 38.2% on average, which is 1.62X larger than using GPGPU with conventional single-stage associative memory.","Associative memory,
Computer architecture,
Energy consumption,
Nonvolatile memory,
Delays,
Microprocessors,
Energy efficiency"
QoS-Aware Energy-Efficient Joint Radio Resource Management in Multi-RAT Heterogeneous Networks,"A heterogeneous wireless network (HetNet), which combines multiple cooperating radio access technologies in an overlapping structure, is a communication system that has been recognized as an efficient way to meet the increasing traffic demand in broadband wireless networks. In this paper, we exploit the network cooperation in HetNets to propose two joint radio resource management (JRRM) schemes that improve energy savings while satisfying the system quality-of-service (QoS) performance requirements. First, we present an optimal QoS-aware energy-efficient JRRM scheme, which is formulated as a semi-Markov decision process model, and provide the optimal control policy for the HetNet under analysis. Second, we present an implementation-friendly QoS-aware energy-efficient JRRM scheme that utilizes a threshold on the macrocell radio resource occupancy to trigger the switching-on/off procedure of the base transceiver station resources, as well as a load-balancing procedure to minimize the service disruptions that may occur because of radio resource shortage and to reduce power consumption during the HetNet operation. This JRRM scheme is analyzed by means of a multidimensional continuous-time Markov chain model. Third, we devise an algorithm to determine the threshold setting in the implementation-friendly JRRM scheme according to a desirable power saving level that is prespecified by the mobile network operator. Numerical results show that the proposed schemes achieve substantial energy savings while keeping satisfactory performance levels.","Load management,
Rats,
Macrocell networks,
Quality of service,
Switches,
Power demand"
On the synchronization bottleneck of OpenStack Swift-like cloud storage systems,"As one type of the most popular cloud storage services, OpenStack Swift and its follow-up systems replicate each data object across multiple storage nodes and leverage object sync protocols to achieve high availability and eventual consistency. The performance of object sync protocols heavily relies on two key parameters: r (number of replicas for each object) and η (number of objects hosted by each storage node). In existing tutorials and demos, the configurations are usually r = 3 and n <; 1000 by default, and the object sync process seems to perform well. To deep understand object sync protocols, we first make a lab-scale OpenStack Swift deployment and run experiments with various configurations. We discover that in data-intensive scenarios, e.g., when r > 3 and n ≫ 1000, the object sync process is significantly delayed and produces massive network overhead. This phenomenon is referred to as the sync bottleneck problem. Then, to explore the root cause, we review the source code of OpenStack Swift and find that its object sync protocol utilizes a fairly simple and network-intensive approach to check the consistency among replicas of objects. In particular, each storage node is required to periodically multicast the hash values of all its hosted objects to all the other replica nodes. Thus in a sync round, the number of exchanged hash values per node is Θ(n×r). Further, to tackle the problem, we propose a lightweight object sync protocol called LightSync. It remarkably reduces the sync overhead by using two novel building blocks: 1) Hashing of Hashes, which aggregates all the h hash values of each data partition into a single but representative hash value with the Merkle tree; 2) Circular Hash Checking, which checks the consistency of different partition replicas by only sending the aggregated hash value to the clockwise neighbor. Its design provably reduces the per-node network overhead from Θ(n×r) to Θ(n/h). In addition, we have implemented LightSync as an open-source patch and adopted it to OpenStack Swift, thus reducing sync delay by up to 28.8× and network overhead by up to 14.2×.","Synchronization,
Cloud computing,
Protocols,
Delays,
Servers,
Open source software,
Data models"
An Investigation of Single-Event Effect Modeling Techniques for a SiGe RF Low-Noise Amplifier,"The single-event transient (SET) response of a SiGe-based, L-band low-noise amplifier (LNA) is investigated, with a focus on providing recommendations for radiation event simulation techniques. Pulsed-laser, two-photon absorption experiments show that the SET sensitivity of the SiGe LNA is highly dependent on operating conditions and strike location. Time and frequency-domain analyses raise potential concerns for digital data modulated on RF carrier signals. Device and circuit-level ion-strike TCAD simulations are utilized to compare alternative simulation approaches, highlight the importance of parasitics on SET simulation accuracy, and suggest best practices for modeling radiation-induced transients within RF/mm-wave circuits.","Transient analysis,
Silicon germanium,
Radio frequency,
Integrated circuit modeling,
Heterojunction bipolar transistors,
Numerical models,
L-band"
Distributed In-Memory Processing of All k Nearest Neighbor Queries,"A wide spectrum of Internet-scale mobile applications, ranging from social networking, gaming and entertainment to emergency response and crisis management, all require efficient and scalable All k Nearest Neighbor (AkNN) computations over millions of moving objects every few seconds to be operational. Most traditional techniques for computing AkNN queries are centralized, lacking both scalability and efficiency. Only recently, distributed techniques for shared-nothing cloud infrastructures have been proposed to achieve scalability for large datasets. These batch-oriented algorithms are sub-optimal due to inefficient data space partitioning and data replication among processing units. In this paper, we present Spitfire, a distributed algorithm that provides a scalable and high-performance AkNN processing framework. Our proposed algorithm deploys a fast load-balanced partitioning scheme along with an efficient replication-set selection algorithm, to provide fast main-memory computations of the exact AkNN results in a batch-oriented manner. We evaluate, both analytically and experimentally, how the pruning efficiency of the Spitfire algorithm plays a pivotal role in reducing communication and response time up to an order of magnitude, compared to three other state-of-the-art distributed AkNN algorithms executed in distributed main-memory.","Servers,
Partitioning algorithms,
Scalability,
Distributed algorithms,
Query processing,
Load management,
Social network services"
Generalized Canonical Time Warping,"Temporal alignment of human motion has been of recent interest due to its applications in animation, tele-rehabilitation and activity recognition. This paper presents generalized canonical time warping (GCTW), an extension of dynamic time warping (DTW) and canonical correlation analysis (CCA) for temporally aligning multi-modal sequences from multiple subjects performing similar activities. GCTW extends previous work on DTW and CCA in several ways: (1) it combines CCA with DTW to align multi-modal data (e.g., video and motion capture data); (2) it extends DTW by using a linear combination of monotonic functions to represent the warping path, providing a more flexible temporal warp. Unlike exact DTW, which has quadratic complexity, we propose a linear time algorithm to minimize GCTW. (3) GCTW allows simultaneous alignment of multiple sequences. Experimental results on aligning multi-modal data, facial expressions, motion capture data and video illustrate the benefits of GCTW. The code is available athttp://humansensing.cs.cmu.edu/ctw.","Time series analysis,
Correlation,
Computer vision,
Complexity theory,
Computer graphics,
Optimization,
Manifolds"
Learning from Uncertainty for Big Data: Future Analytical Challenges and Strategies,"This article will focus on the fourth V, the veracity, to demonstrate the essential impact of modeling uncertainty on learning performance improvement. Low veracity corresponds to the changed uncertainty and the large-scale missing values of big data. Sometimes, along with the growing size of datasets, the uncertainty of data itself often changes sharply, which definitely makes the traditional processing tools unavailable. Except for the changed uncertainty of data itself, the uncertainty in data modeling and data processing are also changing very notably.",
On User-Centric Modular QoE Prediction for VoIP Based on Machine-Learning Algorithms,"The impact of the network performance on the quality of experience (QoE) for various services is not well-understood. Assessing the impact of different network and channel conditions on the user experience is important for improving the telecommunication services. The QoE for various wireless services including VoIP, video streaming, and web browsing, has been in the epicenter of recent networking activities. The majority of such efforts aim to characterize the user experience, analyzing various types of measurements often in an aggregate manner. This paper proposes the MLQoE, a modular algorithm for user-centric QoE prediction. The MLQoE employs multiple machine learning (ML) algorithms, namely, Artificial Neural Networks, Support Vector Regression machines, Decision Trees, and Gaussian Naive Bayes classifiers, and tunes their hyper-parameters. It uses the Nested Cross Validation (nested CV) protocol for selecting the best classifier and the corresponding best hyper-parameter values and estimates the performance of the final model. The MLQoE is conservative in the performance estimation despite multiple induction of models. The MLQoE is modular, in that, it can be easily extended to include other ML algorithms. The MLQoE selects the ML algorithm that exhibits the best performance and its parameters automatically given the dataset used as input. It uses empirical measurements based on network metrics (e.g., packet loss, delay, and packet interarrival) and subjective opinion scores reported by actual users. This paper extensively evaluates the MLQoE using three unidirectional datasets containing VoIP calls over wireless networks under various network conditions and feedback from subjects (collected in field studies). Moreover, it performs a preliminary analysis to assess the generality of our methodology using bidirectional VoIP and video traces. The MLQoE outperforms several state-of-the-art algorithms, resulting in fairly accurate predictions.",
Adaptive Multicell 3-D Beamforming in Multiantenna Cellular Networks,"We consider a cellular network with multiantenna base stations (BSs) and single-antenna users, multicell cooperation, imperfect channel state information (CSI), and directional antennas, each with a vertically adjustable beam. We investigate the impact of the elevation angle of the BS antenna pattern, which is denoted as tilt, on the performance of the considered network when employing either a traditional single-cell transmission or a fully cooperative multicell transmission. Using the results of this investigation, we propose a novel hybrid multicell cooperation technique in which the intercell interference is controlled via either cooperative beamforming in the horizontal plane or coordinated beamforming in the vertical plane of the wireless channel, which is denoted as adaptive multicell 3-D beamforming. The main idea is to divide the coverage area into two disjoint vertical regions and adapt the multicell cooperation strategy at the BSs when serving each region. A fair scheduler is used to share the time slots between the vertical regions. It is shown that the proposed technique can achieve performance comparable with that of a fully cooperative transmission but with significantly lower complexity and signaling requirements. To facilitate computationally efficient simulation and design space exploration, accurate approximations of the user ergodic rate are proposed for different transmission strategies under imperfect CSI.",
Local Community Mining on Distributed and Dynamic Networks From a Multiagent Perspective,"Distributed and dynamic networks are ubiquitous in many real-world applications. Due to the huge-scale, decentralized, and dynamic characteristics, the global topological view is either too hard to obtain or even not available. So, most existing community detection methods working on the global view fail to handle such decentralized and dynamic large networks. In this paper, we propose a novel autonomy-oriented computing-based method for community mining (AOCCM) from the multiagent perspective in the distributed environment. In particular, AOCCM utilizes reactive agents to pick the neighborhood node with the largest structural similarity as the candidate node, and thus determine whether it should be added into local community based on the modularity gain. We further improve AOCCM to a more efficient incremental version named AOCCM-i for mining communities from dynamic networks. AOCCM and AOCCM-i can be easily expanded to detect both nonoverlapping and overlapping global community structures. Experimental results on real-life networks demonstrate that the proposed methods can reduce the computational cost by avoiding repeated structural similarity calculation and can still obtain the high-quality communities.","Communities,
Heuristic algorithms,
Clocks,
Computational modeling,
Cybernetics,
Computer science"
Two-Dimensional Structured-Compressed-Sensing-Based NBI Cancelation Exploiting Spatial and Temporal Correlations in MIMO Systems,"Narrowband interference (NBI) caused by narrowband licensed or unlicensed services is a major concern that constrains the performance of multiple-input multiple-output (MIMO) systems. In this paper, the new and powerful signal processing theory of structured compressed sensing (SCS) is introduced to solve this problem. Exploiting the 2-D spatial and temporal correlations of NBI in MIMO systems, a novel NBI recovery method, i.e., the spatial multiple differential measuring method, is proposed in the framework of 2-D SCS. At each receive antenna, a differential measurement vector is acquired from the repeated training sequences in the IEEE 802.11 series preamble. Then, multiple measurement vectors from all receive antennas are utilized to recover and cancel NBI using the proposed SCS greedy algorithm of structured sparsity adaptive matching pursuit. Simulation results indicate that the proposed scheme outperforms the conventional schemes over the wireless MIMO channel.",
Deleting Secret Data with Public Verifiability,"Existing software-based data erasure programs can be summarized as following the same one-bit-return protocol: the deletion program performs data erasure and returns either success or failure. However, such a one-bit-return protocol turns the data deletion system into a black box-the user has to trust the outcome but cannot easily verify it. This is especially problematic when the deletion program is encapsulated within a Trusted Platform Module (TPM), and the user has no access to the code inside. In this paper, we present a cryptographic solution that aims to make the data deletion process more transparent and verifiable. In contrast to the conventional black/white assumptions about TPM (i.e., either completely trust or distrust), we introduce a third assumption that sits in between: namely, “trust-but-verify”. Our solution enables a user to verify the correct implementation of two important operations inside a TPM without accessing its source code: i.e., the correct encryption of data and the faithful deletion of the key. Finally, we present a proof-of-concept implementation of the SSE system on a resource-constrained Java card to demonstrate its practical feasibility. To our knowledge, this is the first systematic solution to the secure data deletion problem based on a “trust-but-verify” paradigm, together with a concrete prototype implementation.","Protocols,
Encryption,
Public key,
Data storage,
Detection algorithms,
Data security"
Experimental results for 3D bipedal robot walking based on systematic optimization of virtual constraints,"Feedback control laws which create asymptotically stable periodic orbits for hybrid systems are an effective means for realizing dynamic legged locomotion in bipedal robots. To address the challenge of designing such control laws, we recently introduced a method to systematically select a stabilizing feedback control law from a parameterized family of feedback laws by solving an offline optimization problem. The method has been used elsewhere to design a stable gait based on virtual constraints, and its potential effectiveness was illustrated via simulation results. In this paper, we present the first experimental demonstration of a controller designed using this new offline optimization method. The new controller is compared with a nominal controller in experiments on MARLO, a 3D point-foot bipedal robot. Compared to the nominal controller, the optimized controller leads to improved lateral control and longer sustained walking.","Legged locomotion,
Optimization,
Robot kinematics,
Orbits,
Three-dimensional displays,
Manifolds"
A Novel Planar Endfire Circularly Polarized Antenna With Wide Axial-Ratio Beamwidth and Wide Impedance Bandwidth,"A novel wideband planar endfire circularly polarized (CP) antenna with wide 3 dB axial ratio (AR) beamwidth is presented. The operation principle of the proposed CP antenna is described at first through the combination of a planar magnetic dipole and a V-shape open loop. Then, it is demonstrated how its AR beamwidth can be precisely controlled with resorting to the shape and thickness of the open loop element. Finally, the theoretical design approach is numerically verified, and the results are then experimentally validated. It is observed that a 3 dB AR beamwidth is achieved in an extremely wide angular region up to 250° within the principal elevation plane over a frequency range of 2.41-2.51 GHz. The proposed antenna has exhibited a wide impedance bandwidth of 22.23% in fraction, a 3 dB AR bandwidth of no less than 8.00% in fraction, and a simple planar profile in geometry. In addition, its endfire beam is in parallel with its plane.","Dipole antennas,
Antenna radiation patterns,
Directive antennas,
Broadband antennas,
Aperture antennas,
Shape"
On the Construction of Data Aggregation Tree with Minimum Energy Cost in Wireless Sensor Networks: NP-Completeness and Approximation Algorithms,"In many applications, it is a basic operation for the sink to periodically collect reports from all sensors. Since the data gathering process usually proceeds for many rounds, it is important to collect these data efficiently, that is, to reduce the energy cost of data transmission. Under such applications, a tree is usually adopted as the routing structure to save the computation costs for maintaining the routing tables of sensors. In this paper, we work on the problem of constructing a data aggregation tree that minimizes the total energy cost of data transmission in a wireless sensor network. In addition, we also address such a problem in the wireless sensor network where relay nodes exist and consider the cases where the link quality is not perfect. We show that these problems are NP-complete and propose
O(1)
-approximation algorithms for each of them. Simulations show that the proposed algorithms have good performance in terms of energy cost.",
Energy Applications for an Energy Box,"Changes in the electric utility will necessitate new needs and opportunities for monitoring and controlling electric power consumption and generation. Technical solutions exploiting these opportunities and answering these needs would ideally preserve best practices like reliability, privacy, efficiency, and flexibility. A nonintrusive load monitor (NILM) can serve as an ideal platform for constructing an “energy box” capable of sophisticated monitoring and control. This paper introduces a data processing and analysis framework, NILM manager. NILM manager creates a business model for handling power data by minimizing network bandwidth and placing intelligence and feature expansion in easily transmitted “energy apps.”","Monitoring,
Bandwidth,
Data visualization,
Virtual private networks,
Internet of things,
Software,
Computers"
Elucidating the Hemodynamic Origin of Ballistocardiographic Forces: Toward Improved Monitoring of Cardiovascular Health at Home,"The ballistocardiogram (BCG), a signal describing the reaction forces of the body to cardiac ejection of blood, has recently gained interest in the research community as a potential tool for monitoring the mechanical aspects of cardiovascular health for patients at home and during normal activities of daily living. An important limitation in the field of BCG research is that while the BCG signal measures the forces of the body, the information desired (and understood) by clinicians and caregivers, regarding mechanical health of the cardiovascular system, is typically expressed as blood pressure or flow. This paper aims to explore, using system identification tools, the mathematical relationship between the BCG signal and the better-understood impedance cardiography (ICG) and arterial blood pressure (ABP) waveforms, with a series of human subject studies designed to asynchronously modulate cardiac output and blood pressure and with different magnitudes. With this approach, we demonstrate for 19 healthy subjects that the BCG waveform more closely maps to the ICG (flow) waveform as compared with the finger-cuff-based ABP (pressure) waveform, and that the BCG can provide a more accurate estimate of stroke volume (r=0.73, p <; 0.05) as compared with pulse pressure changes (r = 0.26). We also examined, as a feasibility study, for one subject, the ability to calibrate the BCG measurement tool with an ICG measurement on the first day, and then track changes in stroke volume on subsequent days. Accordingly, we conclude that the BCG is a signal more closely related to blood flow than pressures, and that a key health parameter for titrating care-stroke volume-can potentially be accurately measured with BCG signals at home using unobtrusive and inexpensive hardware, such as a modified weighing scale, as compared with the state-of-the-art ICG and ABP devices, which are expensive and obtrusive for use at home.","Feature extraction,
Biomedical monitoring,
Heart beat,
Blood pressure,
Monitoring,
Electrocardiography,
Pressure measurement"
"Joint Caching, Routing, and Channel Assignment for Collaborative Small-Cell Cellular Networks","We consider joint caching, routing, and channel assignment for video delivery over coordinated small-cell cellular systems of the future Internet. We formulate the problem of maximizing the throughput of the system as a linear program, in which the number of variables is very large. To address channel interference, our formulation incorporates the conflict graph that arises when wireless links interfere with each other due to simultaneous transmission. We utilize the column generation method to solve the problem by breaking it into a restricted master subproblem that involves a select subset of variables and a collection of pricing subproblems that select the new variable to be introduced into the restricted master problem, if that leads to a better objective function value. To control the complexity of the column generation optimization further, due to the exponential number of independent sets that arise from the conflict graph, we introduce an approximation algorithm that computes a solution that is within ϵ to optimality, at much lower complexity. Our framework demonstrates considerable gains in average transmission rate at which the video data can be delivered to the users, over the state-of-the-art Femtocaching system, of up to 46%. These operational gains in system performance map to analogous gains in video application quality, thereby enhancing the user experience considerably.","Base stations,
Interference,
Routing,
Channel allocation,
Wireless communication,
Receivers,
Collaboration"
Semi-Supervised Bi-Dictionary Learning for Image Classification With Smooth Representation-Based Label Propagation,"In this paper, we propose semi-supervised bi-dictionary learning for image classification with smooth representation-based label propagation (SRLP). Natural images contain complex contents of multiple objects with complicated background, clutter, and occlusions, which prevents image features from belonging to a specific category. Therefore, we employ reconstruction-based classification to implement discriminative dictionary learning in a probabilistic manner. We jointly learn a discriminative dictionary called anchor in the feature space and its corresponding soft label called anchor label in the label space, where the combination of anchor and anchor label is referred to as bi-dictionary. The learnt bi-dictionary is utilized to bridge the semantic gap in image classification. First, SRLP constructs smoothed reconstruction problems for bi-dictionary learning. Then, SRLP produces the reconstruction coefficients in the feature space over the anchor to infer soft labels of samples in the label space. Experimental results demonstrate that the proposed method is capable of learning a pair of discriminative dictionaries for image classification in the feature and label spaces and outperforms the-state-of-the-art reconstruction-based classification ones.",
3D MCRLB Evaluation of a UMTS-Based Passive Multistatic Radar Operating in a Line-of-Sight Environment,"In this paper, the performance of a universal mobile telecommunication system (UMTS)-based passive multistatic radar in a line-of-sight (LoS) environment is studied. The presence of LoS component from the target considerably alters the received signal model, therefore, its characterization is necessary and is the main subject of this work where the transceivers and a target are localized in a three-dimensional Euclidean space. The probability density function (PDF) of the received signal in the presence of LoS is derived and the closed-form expressions of the modified Cramér-Rao lower bounds (MCRLBs) on the Euclidean coordinates of target's position and velocity are found. It is shown that modified Fisher information matrix (MFIM) is a combination of MFIMs due to non-LoS (NLoS) components and LoS component. With the aid of numerical examples, it is verified that by exploiting LoS, the target radar cross section (RCS) increases, which improves the accuracy of target's detection and parameter estimation. In addition, it is also shown that by exploiting LoS component, the performance limits of a waveform can be determined for a generalized radar cross section model (GRCSM), which provides the characterization of a waveform for a broader range of radar applications.",
Control of a Class of Industrial Processes With Time Delay Based on a Modified Uncertainty and Disturbance Estimator,"The control algorithm based on the uncertainty and disturbance estimator (UDE) is considered as an efficient control strategy that has attracted much attention recently. However, it cannot be directly applied to the widely existing industrial processes with time delay. To extend its applicability, the UDE control algorithm is modified so that it can be applied to stable, integrating, and unstable processes with time delay. The stability condition of the modified UDE (MUDE) is established. It is shown that the design of tracking and regulation can be separated. The tradeoff between the performance and robustness is achieved by parameter tuning. Compared with the recent strategies evolving from the Smith predictor, simulation, and laboratory experimental results are presented to show that the MUDE-based control gives significant improvement in (1) robustness; (2) control for unstable systems; (3) eliminating steady-state error; and (4) structure simplicity, which makes it easy to configure in industrial distributed control systems. Finally, the promising prospect of the proposed strategy in industry is exemplified via a field test in an in-service 1000-MW power plant.","Delay effects,
Process control,
Delays,
Uncertainty,
Stability analysis,
Robustness,
Algorithm design and analysis"
Beyond layers: A 3D-aware toolpath algorithm for fused filament fabrication,"Fused filament fabrication (FFF) is gaining traction for rapid prototyping and custom fabrication. Existing toolpath generation methods for FFF printers take as input a three-dimensional model of the target object and construct a layered toolpath that will fabricate the object in 2D slices of a chosen thickness. While this approach is computationally straightforward, it can produce toolpaths that can contain significant, yet unnecessary, extrusionless travel. In this paper we propose a novel 3D toolpath generation paradigm that leverages local feature independence in the target object. In contrast to existing FFF slicing methods which print an object layer by layer, our algorithm provides a means to print local features of an object without being constrained to a single layer. The key benefit of our approach is a tremendous reduction in “extrusionless travel,” in which the printer must move between features without performing any extrusion. We show on a benchmark of 409 objects that our method can yield substantial savings in extrusionless travel, 34% on average, that can directly translate to a reduction in total manufacturing time.","Motion segmentation,
Printers,
Solid modeling,
Field-flow fractionation,
Computational modeling,
Printing,
Fabrication"
Retention Trimming for Lifetime Improvement of Flash Memory Storage Systems,"NAND flash memory has been widely deployed in embedded systems, personal computers, and data centers. While recent technology scaling and density improvement have reduced its price, they have also significantly shortened its endurance. In this paper, with the understanding of the relationship between data retention time and flash wearing, a retention trimming approach, which trims data retention time based on the data lifetime, is proposed to reduce the wearing of flash memory, and hence improve the endurance of flash memory. Extensive experimental results show that the proposed technique achieves significant endurance improvements.",
A Method for Automatic and Objective Scoring of Bradykinesia Using Orientation Sensors and Classification Algorithms,"Correct assessment of bradykinesia is a key element in the diagnosis and monitoring of Parkinson's disease. Its evaluation is based on a careful assessment of symptoms and it is quantified using rating scales, where the Movement Disorders Society-Sponsored Revision of the Unified Parkinson's Disease Rating Scale (MDS-UPDRS) is the gold standard. Regardless of their importance, the bradykinesia-related items show low agreement between different evaluators. In this study, we design an applicable tool that provides an objective quantification of bradykinesia and that evaluates all characteristics described in the MDS-UPDRS. Twenty-five patients with Parkinson's disease performed three of the five bradykinesia-related items of the MDS-UPDRS. Their movements were assessed by four evaluators and were recorded with a nine degrees-of-freedom sensor. Sensor fusion was employed to obtain a 3-D representation of movements. Based on the resulting signals, a set of features related to the characteristics described in the MDS-UPDRS was defined. Feature selection methods were employed to determine the most important features to quantify bradykinesia. The features selected were used to train support vector machine classifiers to obtain an automatic score of the movements of each patient. The best results were obtained when seven features were included in the classifiers. The classification errors for finger tapping, diadochokinesis and toe tapping were 15-16.5%, 9.3-9.8%, and 18.2-20.2% smaller than the average interrater scoring error, respectively. The introduction of objective scoring in the assessment of bradykinesia might eliminate inconsistencies within evaluators and interrater assessment disagreements and might improve the monitoring of movement disorders.","Magnetic sensors,
Fingers,
Standards,
Support vector machines,
Classification algorithms,
Sensor fusion"
Finite Volume Time Domain Room Acoustics Simulation under General Impedance Boundary Conditions,"In room acoustics simulation and virtualization applications, accurate wall termination is a perceptually crucial feature. It is particularly important in the setting of wave-based modeling of 3D spaces, using methods such as the finite difference time domain method or finite volume time domain method. In this paper, general locally reactive impedance boundary conditions are incorporated into a 3D finite volume time domain formulation, which may be specialized to the various types of finite difference time domain method under fitted boundary termination. Energy methods are used to determine stability conditions for general room geometries, under a large family of nontrivial wall impedances, for finite volume methods over unstructured grids. Simulation results are presented, highlighting in particular the need for unstructured or fitted cells at the room boundary in the case of the accurate simulation of frequency-dependent room mode decay times.",
Robust camera motion estimation using direct edge alignment and sub-gradient method,"There has been a paradigm shifting trend towards feature-less methods due to their elegant formulation, accuracy and ever increasing computational power. In this work, we present a direct edge alignment approach for 6-DOF tracking. We argue that photo-consistency based methods are plagued by a much smaller convergence basin and are extremely sensitive to noise, changing illumination and fast motion. We propose to use the Distance Transform in the energy formulation which can significantly extend the influence of the edges for tracking. We address the problem of non-differentiability of our cost function and of the previous methods by use of a sub-gradient method. Through extensive experiments we show that the proposed method gives comparable performance to the previous method under nominal conditions and is able to run at 30 Hz in single threaded mode. In addition, under large motion we demonstrate our method outperforms previous methods using the same runtime configuration for our method.","Image edge detection,
Transforms,
Three-dimensional displays,
Cameras,
Cost function,
Feature extraction"
Recommender System and Web 2.0 Tools to Enhance a Blended Learning Model,"Blended learning models that combine face-to-face and online learning are of great importance in modern higher education. However, their development should be in line with the recent changes in e-learning that emphasize a student-centered approach and use tools available on the Web to support the learning process. This paper presents research on implementing a contemporary blended learning model within the e-course “Hypermedia Supported Education”. The blended model developed combines a learning management system (LMS), a set of Web 2.0 tools and the E-Learning Activities Recommender System (ELARS) to enhance personalized online learning. As well as incorporating various technologies, the model combines a number of pedagogical approaches, focusing on collaborative and problem-based learning, to ensure the achievement of the course learning outcomes. The results of the comparative study show the effectiveness of the proposed model in that students who performed personalized collaborative e-learning activities achieved better course results. These findings encourage the further application of the model to other computer science courses.","Electronic learning,
Web 2.0,
Least squares approximations,
Recommender systems,
Computational modeling,
Collaboration"
Modelling Multi-Operator Base Station Deployment Patterns in Cellular Networks,"Stochastic models of base station infrastructure deployment by multiple mobile operators can be an invaluable tool for deriving fundamental results about wireless network sharing. In this paper, we study stochastic geometry models for a shared cellular network consisting of base stations deployed by multiple mobile operators, based on real cellular network data coming from three European countries. Relying on a statistical approach as well as the evaluation of wireless network performance metrics, we show that the log-Gaussian Cox process provides the most compelling fitness results with real multi-operator base station deployment patterns and a model that offers some degree of analytical tractability. The model captures the fact that, in urban areas, there is strong correlation between the locations where the base stations of different operators are deployed. In contrast to that, in rural areas we observe some repulsion between antenna locations of different operators. Moreover, we observe that the behavior which can be modelled with the help of these processes occurs over and over again for similar areas in different countries, which suggests universality of the proposed models.",
3-D Ultrasonic Fingerprint Sensor-on-a-Chip,"A fully integrated 3-D ultrasonic fingerprint sensor-on-a-chip is presented. The device consists of a 110× 56 piezoelectric micromachined ultrasonic transducer (PMUT) array bonded at the wafer level to custom readout electronics fabricated in a 180-nm CMOS process with a HV (24 V) transistor option. With the 24 V driving signal strength, the sensor consumes 280 μJ to image a 4.73 mm × 3.24 mm section of a fingerprint at a rate of 380 fps. A wakeup mode that detects the presence of a finger at 4 fps and dissipates 10 μW allows the proposed sensor to double as a power switch. The sensor is capable of imaging both the surface epidermal and subsurface dermal fingerprints and is insensitive to contaminations, including perspiration or oil. The 3-D imaging capability combined with the sensor's sensitivity to the acoustic properties of the tissue translates into excellent robustness against spoofing attacks.",
Stability Analysis of Grid-Interfacing Inverter Control in Distribution Systems With Multiple Photovoltaic-Based Distributed Generators,"A stability-enhancement inverter controller is proposed and its impact on the small-signal stability of distribution systems with multiple photovoltaic-based distributed generators (PV-DGs) is investigated. In specific, the random variation of the power output from multiple PV-DGs is considered. Being different from a single grid-connected PV system, the spatial correlation between PV-DGs and the system stability sensitivity with respect to different PV-DGs among the feeder are also taken into account. The small-signal stability analysis of the distribution system is performed using a probabilistic approach. As the PV-DG power output is randomly variable, the distribution system is not operating in a fixed mode. Consequently, the critical eigenvalues of the system move randomly. Through the Gram-Charlier expansion method, the probability density function of the critical eigenvalues of the distribution system is approximated and the probabilities of the system stability and instability are calculated. Taking the probability of the system instability as the performance metric, the effects of different system parameter settings of the grid-interfacing inverter controller on the distribution system are analyzed. The verification of the analytical results is carried out through Monte-Carlo time-domain simulations of the distribution system. The results suggest several methods to reduce the probability of system instability, including installation of the proposed inverter controller, choosing a large substation capacitor and/or choosing large capacity load and substation transformers.","Power system stability,
Inverters,
Thermal stability,
Stability criteria,
Generators,
Reactive power"
Layout Decomposition Co-Optimization for Hybrid E-Beam and Multiple Patterning Lithography,"As the feature size keeps scaling down and the circuit complexity increases rapidly, a more advanced hybrid lithography, which combines multiple patterning and electron-beam lithography (EBL), is promising to further enhance the pattern resolution. In this paper, we formulate the layout decomposition problem for this hybrid lithography as a minimum vertex deletion
K
-partition problem, where
K
is the number of masks in multiple patterning. Stitch minimization and EBL throughput are considered uniformly by adding a virtual vertex between two feature vertices for each stitch candidate during the conflict graph construction phase. For
K=2
, we propose a primal-dual (PD) method for solving the underlying minimum odd-cycle cover problem efficiently. In addition, a chain decomposition algorithm is employed for removing all “noncyclable” edges. Furthermore, we investigate two versions of the PD method, one with planarization and one without. For
K>2
, we propose a random-initialized local search method that iteratively applies the PD solver. Experimental results show that compared with a two-stage method, our proposed methods reduce the EBL usage by 65.5% with double patterning and 38.7% with triple patterning on average for the benchmarks.","Lithography,
Layout,
Throughput,
Planarization,
Ultraviolet sources,
Search methods,
Writing"
Privacy-Preserving Public Auditing Protocol for Low-Performance End Devices in Cloud,"Cloud storage provides tremendous storage resources for both individual and enterprise users. In a cloud storage system, the data owned by a user are no longer possessed locally. Hence, it is not competent to ensure the integrity of the outsourced data using traditional data integrity checking methods. A privacy-preserving public auditing protocol allows a third party auditor to check the integrity of the outsourced data on behalf of the users without violating the privacy of the data. However, existing privacy-preserving public auditing protocols assume that the end devices of users are powerful enough to compute all costly operations in real time when the data to be outsourced are given. In fact, the end devices may also be those with low computation capabilities. In this paper, we propose two lightweight privacy-preserving public auditing protocols. Our protocols are based on online/offline signatures, by which an end device only needs to perform lightweight computations when a file to be outsourced is available. Besides, our proposals support batch auditing and data dynamics. Experiments show that our protocols are hundreds of times more efficient than a recent proposal regarding to the computational overhead on user side.","Protocols,
Cloud computing,
Performance evaluation,
Data privacy,
Security,
Proposals,
Systems architecture"
P-LEACH: Energy efficient routing protocol for Wireless Sensor Networks,"Wireless Sensor Network (WSN) are of paramount significance since they are responsible for maintaining the routes in the network, data forwarding, and ensuring reliable multi-hop communication. The main requirement of a wireless sensor network is to prolong network energy efficiency and lifetime. Researchers have developed protocols Low Energy Adaptive Clustering Hierarchy (LEACH) and Power-Efficient Gathering in Sensor Information Systems (PEGASIS) for reducing energy consumption in the network. However, the existing routing protocols experience many shortcomings with respect to energy and power consumption. LEACH features the dynamicity but has limitations due to its cluster-based architecture, while PEGASIS overcomes the limitations of LEACH but lacks dynamicity. In this paper, we introduce PEGASIS-LEACH (P-LEACH), a near optimal cluster-based chain protocol that is an improvement over PEGASIS and LEACH both. This protocol uses an energy-efficient routing algorithm to transfer the data in WSN. To validate the energy effectiveness of P-LEACH, we simulate the performance using Network Simulator (NS2) and MATLAB.","Wireless sensor networks,
Base stations,
Energy efficiency,
Routing protocols,
Clustering algorithms,
Algorithm design and analysis"
A High Power Density Dynamic Voltage Scaling Enabling a Single-Inductor Four-Output Regulator Using a Power-Weighted CCM Controller and a Floating Capacitor-Based Output Filter,"This paper presents a dynamic voltage scaling (DVS) compatible single-inductor multiple-output (SIMO) voltage regulation module that enables smaller passives for a given output power, while maintaining power quality (low output ripple), suppressing cross regulation, and improving efficiency at high switching frequency. First, continuous-conduction mode (CCM) operation is utilized to deliver higher output power for a smaller inductance; the cross-regulation in CCM operation is suppressed using a novel power-weighted CCM controller. Second, a modified power stage filter is presented using floating capacitors that utilize the Miller effect to reduce the switching frequency of the output, while maintaining the power quality. The operating principles, stability, and circuit level design of the proposed SIMO VR are presented. The design is demonstrated through a 130-nm CMOS test chip that generates four outputs, each ranging from 200 to 600 mV, from a 1.2-V input. The measurements demonstrate a 20-MHz operation, the pulse width modulation signal of the power stage with 500-nH inductor, and 1-μF total load capacitance, while delivering a output power density of 150 mW/μH·μF. The test chip demonstrates DVS speed of 120 mV/μs, 73% peak efficiency at a load of 40 mA, and as high as 40% efficiency improvement using the modified power filer.","Inductors,
Switching frequency,
Capacitors,
Capacitance,
Voltage control,
Regulators,
Power generation"
Study of a New Planar-Type Balun Topology for Application in the Design of Balun Bandpass Filters,"A comprehensive study of a new planar-type balun prototype is presented in this paper for application in the design of balun bandpass filters (BPFs) with widely used open-type resonators. The proposed balun is in general composed of two identical back-to-back quarter-wavelength (λ/4) coupled line sections. The design concept originates from the analysis of the standing wave pattern on a half-wavelength (λ/2) open-circuited transmission line. After an intuitive illustration is given, its working principle is presented to validate the feasibility of the proposed balun. Afterward, two types of the coupled line prototypes are analyzed to implement the proposed balun with filtering response, whereas a basic rule is given to realize the transmission zeros. To further demonstrate the validity of the proposed balun prototype, two practical balun BPFs with common dual-mode resonators are designed and fabricated. As expected, transmission zeros are generated near the desired passband of our presented balun filters, thereby improving their frequency selectivity. Both simulated and measured results exhibit good filtering and balun performance.",
Efficient deep models for monocular road segmentation,"This paper addresses the problem of road scene segmentation in conventional RGB images by exploiting recent advances in semantic segmentation via convolutional neural networks (CNNs). Segmentation networks are very large and do not currently run at interactive frame rates. To make this technique applicable to robotics we propose several architecture refinements that provide the best trade-off between segmentation quality and runtime. This is achieved by a new mapping between classes and filters at the expansion side of the network. The network is trained end-to-end and yields precise road/lane predictions at the original input resolution in roughly 50ms. Compared to the state of the art, the network achieves top accuracies on the KITTI dataset for road and lane segmentation while providing a 20× speed-up. We demonstrate that the improved efficiency is not due to the road segmentation task. Also on segmentation datasets with larger scene complexity, the accuracy does not suffer from the large speed-up.","Roads,
Image segmentation,
Computer architecture,
Training,
Semantics,
Robots,
Runtime"
Distributed Control for Charging Multiple Electric Vehicles with Overload Limitation,"Severe pollution induced by traditional fossil fuels arouses great attention on the usage of plug-in electric vehicles (PEVs) and renewable energy. However, large-scale penetration of PEVs combined with other kinds of appliances tends to cause excessive or even disastrous burden on the power grid, especially during peak hours. This paper focuses on the scheduling of PEVs charging process among different charging stations and each station can be supplied by both renewable energy generators and a distribution network. The distribution network also powers some uncontrollable loads. In order to minimize the on-grid energy cost with local renewable energy and non-ideal storage while avoiding the overload risk of the distribution network, an online algorithm consisting of scheduling the charging of PEVs and energy management of charging stations is developed based on Lyapunov optimization and Lagrange dual decomposition techniques. The algorithm can satisfy the random charging requests from PEVs with provable performance. Simulation results with real data demonstrate that the proposed algorithm can decrease the time-average cost of stations while avoiding overload in the distribution network in the presence of random uncontrollable loads.","Renewable energy sources,
Charging stations,
Power grids,
Energy storage,
Electric vehicles,
Smart grids,
Lyapunov methods,
Fossil fuels,
Power distribution planning"
A Data-Driven Approach for Estimating the Power Generation of Invisible Solar Sites,"Roof-top solar photovoltaic systems are normally invisible to system operators, meaning that their generated power is not monitored. If a significant number of systems are installed, invisible solar power could significantly alter the net load in power systems. In this paper, a data-driven methodology is proposed to estimate the power generation of invisible solar power sites by using the measured values from a small number of representative sites. The proposed methodology is composed of a data dimension reduction engine and a mapping function. A number of established methods for reducing the dimension of large-scale data is investigated, and a hybrid method based on k -means clustering and principal component analysis is proposed. The output of this block provides a small subset of sites whose measured data are used in the mapping function. We have implemented several mapping functions to estimate the total generation power of all sites based on the measured output of the selected subset of sites. Numerical results based on data from California's power system are presented.","Solar power generation,
Principal component analysis,
Power systems,
Power measurement,
Monitoring,
Estimation"
Ship Classification Based on Superstructure Scattering Features in SAR Images,"This letter presents a novel method for ship classification that uses synthetic-aperture-radar images to distinguish ships based on superstructure scattering features. The ratio of dimensions, which combines the 2-D and 3-D properties of scattering, is explored as an effective and credible means to describe the scattering features of ships. The proposed method consists of three main stages: 1) ship isolation from the sea; 2) parametric vector (F) estimation; and 3) categorization using a support vector machine (SVM) classifier. To depict ship features more accurately and reduce feature redundancy, we propose employing peak extraction to divide a ship into bow, middle, and stern instead of into three equal parts. The classification method is tested with RadarSat-2 images, and ground-truth information is supplied by an automatic identification system. The experimental results show that the proposed method can achieve satisfactory ship-classification performance compared with existing methods, with an overall accuracy exceeding 80%.","Marine vehicles,
Synthetic aperture radar,
Scattering,
Containers,
Backscatter,
Feature extraction,
Sensors"
Efficient Real-Time Train Operation Algorithms With Uncertain Passenger Demands,"The majority of existing studies in subway train operations focus on timetable optimization and vehicle tracking methods, which may be infeasible with disturbances in actual operations. To deal with uncertain passenger demands and realize real-time train operations (RTOs) satisfying multiobjectives, including overspeed protection, punctuality, riding comfort, and energy consumption, this paper proposes two RTO algorithms via expert knowledge and an online learning approach. The first RTO algorithm is developed by a knowledge-based system to ensure the multiple objectives with a constant timetable. Then, by considering uncertain passenger demand at each station and random running time errors, we convert the train operation problem into a Markov decision process with nondeterministic state transition probabilities in which the aim is to minimize the reward for both the total time delay and energy consumption in a subway line. After designing policy, reward, and transition probability, we develop an integrated train operation (ITO) algorithm based on Q-learning to realize RTOs with online adjusting the timetable. Finally, we present some numerical examples to test the proposed algorithms with real detected data in the Yizhuang Line of Beijing Subway. The results indicate that, taking the multiple objectives into account, the RTO algorithm outperforms both manual driving and automatic train operations. In addition, the ITO algorithm is capable of dealing with uncertain disturbances, keeping the total time delay within 2 s and reducing the energy consumption.",
"Asymptotically Near-Optimal RRT for Fast, High-Quality Motion Planning","We present lower bound tree-RRT (LBT-RRT), a single-query sampling-based motion-planning algorithm that is asymptotically near-optimal. Namely, the solution extracted from LBT-RRT converges to a solution that is within an approximation factor of 1 + ε of the optimal solution. Our algorithm allows for a continuous interpolation between the fast RRT algorithm and the asymptotically optimal RRT* and RRG algorithms when the cost function is the path length. When the approximation factor is 1 (i.e., no approximation is allowed), LBT-RRT behaves like RRG. When the approximation factor is unbounded, LBT-RRT behaves like RRT. In between, LBT-RRT is shown to produce paths that have higher quality than RRT would produce and run faster than RRT* would run. This is done by maintaining a tree that is a subgraph of the RRG roadmap and a second, auxiliary graph, which we call the lower-bound graph. The combination of the two roadmaps, which is faster to maintain than the roadmap maintained by RRT*, efficiently guarantees asymptotic near-optimality. We suggest to use LBT-RRT for high-quality anytime motion planning. We demonstrate the performance of the algorithm for scenarios ranging from 3 to 12 degrees of freedom and show that even for small approximation factors, the algorithm produces high-quality solutions (comparable with RRG and RRT*) with little running-time overhead when compared with RRT.","Approximation algorithms,
Planning,
Robots,
Heuristic algorithms,
Algorithm design and analysis,
Data structures,
Convergence"
Smart Insole: A Wearable Sensor Device for Unobtrusive Gait Monitoring in Daily Life,"Gait analysis is an important medical diagnostic process and has many applications in healthcare, rehabilitation, therapy, and exercise training. However, typical gait analysis has to be performed in a gait laboratory, which is inaccessible for a large population and cannot provide natural gait measures. In this paper, we present a novel sensor device, namely, Smart Insole, to tackle the challenge of efficient gait monitoring in real life. An array of electronic textile (eTextile)-based pressure sensors are integrated in the insole to fully measure the plantar pressure. Smart Insole is also equipped with a low-cost inertial measurement unit including a three-axis accelerometer, a three-axis gyroscope, and a three-axis magnetometer to capture the gait characteristics in motion. Smart Insole can offer precise acquisition of gait information. Meanwhile, it is lightweight, thin, and comfortable to wear, providing an unobtrusive way to perform the gait monitoring. Furthermore, a smartphone graphic user interface is developed to display the sensor data in real-time via Bluetooth low energy. We perform a set of experiments in four real-life scenes including hallway walking, ascending/descending stairs, and slope walking, where gait parameters and features are extracted. Finally, the limitation and improvement, wearability and usability, further work, and healthcare-related potential applications are discussed.","Monitoring,
Sensor arrays,
Pressure sensors,
Accelerometers,
Legged locomotion,
Wireless sensor networks,
Wireless communication"
Detection and Classification of Power Quality Disturbances Using Double Resolution S-Transform and DAG-SVMs,"The accurate detection and classification of power quality (PQ) disturbances in power systems is a key step to determine the causes of these events before any proper countermeasure could be taken. This paper presents a new algorithm for detection and classification of PQ disturbances based on the combination of double-resolution S-transform (DRST) and directed acyclic graph support vector machines (DAG-SVMs). The proposed method first employs DRST for an effective feature extraction from power signals. Then, the DAG-SVMs are used to predict the classes of PQ disturbances. The DRST not only has better time-frequency localization and stronger robustness but also reduces the computational complexity without losing the useful information of the original signal in comparison with the traditional S-transform. Through the combined use of DRST and DAG-SVMs, the algorithm can be easily implemented in embedded real-time applications. Finally, the implementation of the proposed algorithm in a digital signal processor + advanced reduced instruction set computing machine-based hardware test platform is introduced. The effectiveness of the proposed method is demonstrated by means of computer simulations and practical experiments with single and combined PQ disturbances.","Feature extraction,
Signal processing algorithms,
Harmonic analysis,
Power system harmonics,
Artificial neural networks,
White noise"
Radio Frequency Beamforming Based on a Complex Domain Frontend,"The state-of-the-art phased array-based digital beamforming systems suffer from disadvantages of high power consumption, high cost, and system complexity due to the massive use of transmitter/receiver (T/R) modules and high-speed digital and digital-analog mixed devices. In this paper, we point out that by proposing a new concept “complex domain” radio frequency (RF) frontend, the relatively slowly changed waveform delay information required to accomplish adaptive beamforming can be separated from wideband RF signals, based on which a self-contained beamforming system can be implemented with a low-speed baseband. By introducing vector RF multipliers in the proposed frontend, the amplitude and phase of RF signals can be simultaneously controlled by the real and imaginary parts of complex numbers, such that beamforming algorithms derived in complex domain can be directly applied without any form of transformation. By doing so, the massive use of conventional T/R modules and high-speed baseband devices can be avoided. Theoretical analysis and experimental demonstration based on commercial components have validated the proposed approach. Our method is able to significantly simplify the realization and decrease the cost of wideband digital beamforming systems, and can be widely used in low cost, power efficient beamforming applications.","Array signal processing,
Radio frequency,
Delays,
RF signals,
Wideband,
Arrays,
Baseband"
Application-aware traffic scheduling for workload offloading in mobile clouds,"Mobile Cloud Computing (MCC) bridges the gap between limited capabilities of mobile devices and the increasing complexity of mobile applications, by offloading the computational workloads from local devices to the cloud. Current research supports workload offloading through appropriate application partitioning and remote method execution, but generally ignores the impact of wireless network characteristics on such offloading. Wireless data transmissions incurred by remote method execution consume a large amount of additional energy during transmission intervals when the network interface stays in the high-power state, and deferring these transmissions increases the response delay of mobile applications. In this paper, we adaptively balance the tradeoff between energy efficiency and responsiveness of mobile applications by developing application-aware wireless transmission scheduling algorithms. We take both causality and run-time dynamics of application method executions into account when deferring wireless transmissions, so as to minimize the wireless energy cost and satisfy the application delay constraint with respect to the practical system contexts. Systematic evaluations show that our scheme significantly improves the energy efficiency of workload offloading over realistic smartphone applications.",
Energy-Efficient User Association and Resource Allocation for Multistream Carrier Aggregation,"Multistream carrier aggregation (MSCA) is a promising technique to boost data rates by enabling users to connect with multiple base stations (BSs) simultaneously. In this paper, we investigate joint user association and resource allocation for MSCA systems to achieve energy efficiency (EE) balance among different BSs. We aim at maximizing the weighted summation of EE values for different BSs, which is modeled as a nonconvex combinatorial sum-of-ratios optimization problem. To develop an upper bound algorithm, we first relax the combinatorial variables and then transform the problem into a series of convex optimization problems by the successive convex approximation (SCA) method. We also propose a low-complexity suboptimal algorithm, which divides the original optimization problem into two steps: user association and channel allocation, as well as power allocation. Numerical results show that the proposed algorithms can achieve flexible EE tradeoff among BSs, and the EE can be significantly improved with MSCA.","Resource management,
Optimization,
Linear programming,
Transforms,
Approximation methods,
Joints,
Convex functions"
Efficient Data Placement for Improving Data Access Performance on Domain-Wall Memory,"A domain-wall memory (DWM) is becoming an attractive candidate to replace the traditional memories for its high density, low-power leakage, and low access latency. Accessing data on DWM is accomplished by shift operations that move data located on nanowires to read/write ports. Due to this kind of construction, data accesses on DWM exhibit varying access latencies. Therefore, data placement (DP) strategy has a significant impact on the performance of data accesses on DWM. In this paper, we prove the nondeterministic polynomial time (NP)-completeness of the DP problem on DWM. For the DWMs organized in single DWM block cluster (DBC), we present integer linear programming formulations to solve the problem optimally. We also propose an efficient single DBC placement (S-DBC-P) algorithm to exploit the benefits of multiple read/write ports and data locality. Compared with the sequential DP strategy, S-DBC-P reduces 76.9% shift operations on average for eight-port DWMs. Furthermore, for DP problem on the DWMs organized in multiple DBCs, we develop an efficient multiple DBC placement (M-DBC-P) algorithm to utilize the parallelism of DBCs. The experimental results show that the M-DBC-P achieves 90% performance improvement over the sequential DP strategy.","Nanowires,
Magnetic domains,
Magnetic domain walls,
Silicon,
Magnetic separation,
Magnetic tunneling,
Algorithm design and analysis"
Distributed Monitoring of Voltage Collapse Sensitivity Indices,"The assessment of voltage stability margins is a promising direction for wide-area monitoring systems. Accurate monitoring architectures for long-term voltage instability are typically centralized and lack scalability, while completely decentralized approaches relying on local measurements tend toward inaccuracy. Here we present distributed linear algorithms for the online computation of voltage collapse sensitivity indices. The computations are collectively performed by processors embedded at each bus in the smart grid, using synchronized phasor measurements and communication of voltage phasors between neighboring buses. Our algorithms provably converge to the proper index values as would be calculated using centralized information, but do not require any central decision maker for coordination. Modifications of the algorithms to account for generator reactive power limits are discussed. We illustrate the effectiveness of our designs with a case study of the New England 39 bus system.","Monitoring,
Voltage measurement,
Sensitivity,
Computer architecture,
Smart grids,
Power system stability,
Phasor measurement units"
Dynamic Gain-Tuning Control (DGTC) Approach for AGC With Effects of Wind Power,"Variable wind power output introduces new challenges to power system frequency regulation and control, such as automatic generation control (AGC) which is very important to regulate power system frequency. The existing methods to design control gains for proportional-integral (PI) controllers in AGC are either time consuming or easily affected by the designer's experience. Further, the control gains are usually designed with fixed values for specific scenarios in the studied power system. The desired response may not be achieved when variable wind power is integrated into power systems. To address these challenges, a dynamic gain tuning control (DGTC) method for AGC is proposed in this paper. By the proposed control method, PI control gains can be dynamically adjusted to reach the desired performance. The proposed method is tested in a modified IEEE 39 bus system with actual wind data, and compared with conventional control approach with well-tuned fixed gains in the simulation. The simulation results show that the proposed control method provides better AGC response with less deviation of system frequency and tie-line flow under variable wind power.","Wind power generation,
Wind speed,
Power systems,
Pi control,
Gain control,
Automatic generation control,
Frequency control"
Packet Fragmentation and Reassembly in Molecular Communication,"This paper describes packet fragmentation and reassembly to achieve reliable molecular communication among bionanomachines. In the molecular communication described in this paper, a sender bionanomachine performs packet fragmentation, dividing a large molecular message into smaller pieces and embedding into smaller molecular packets, so that molecular packets have higher diffusivity to reach the receiver bionanomachine. The receiver bionanomachine then performs packet reassembly to retrieve the original molecular message from a set of molecular packets that it receives. To examine the effect of packet fragmentation and reassembly, we develop analytical models and conduct numerical experiments. Numerical results show that packet fragmentation and reassembly can improve the message delivery performance. Numerical results also indicate that packet fragmentation and reassembly may degrade the performance in the presence of drift in the environment.","Receivers,
Molecular communication,
Nanobioscience,
DNA,
Electron mobility,
Analytical models,
Performance evaluation"
Heterogeneous Warm Standby Multi-Phase Systems With Variable Mission Time,"While the majority of existing works on modeling and optimizing standby systems focus on single-phased missions, only a few works consider standby systems with phased-mission requirements, and these works are only applicable to restricted cold-standby configurations with assumptions of negligible replacement times and fixed phase durations. This paper makes new theoretical contributions by suggesting a general model of heterogeneous 1-out-of- N: G warm standby phased-mission systems (PMS) with dynamic phase durations. The model takes into account diverse, phase-dependent performances and time-to-failure distributions of system elements. It also considers non-zero replacement times specific for activated elements, and for the mission phase when the replacement occurs. Both cold and hot standby PMSs are special cases of the proposed model. An algorithm for evaluating the mission reliability and expected completion time is first presented. The algorithm is applicable to any type of time-to-failure distribution for system elements. The heterogeneous standby PMS can demonstrate non-coherent behavior where the reduction of reliability of some elements can cause the increase of the entire mission reliability. Then it is demonstrated that the sequence of the element activation affects the mission reliability and its expected completion time. Hence the element sequence optimization problem is further formulated and solved for the heterogeneous warm standby PMS. Illustrative examples of mission reliability and expected completion time analysis and optimization are presented.","Stress,
Acceleration,
Optimization,
Genetic algorithms,
Redundancy,
Joints"
Ensuring Cloud Data Reliability with Minimum Replication by Proactive Replica Checking,"Data reliability and storage costs are two primary concerns for current Cloud storage systems. To ensure data reliability, the widely used multi-replica (typically three) replication strategy in current Clouds incurs a huge extra storage consumption, resulting in a huge storage cost for data-intensive applications in the Cloud in particular. In order to reduce the Cloud storage consumption while meeting the data reliability requirement, in this paper we present a cost-effective data reliability management mechanism named PRCR based on a generalized data reliability model. By using a proactive replica checking approach, while the running overhead for PRCR is negligible, PRCR ensures reliability of the massive Cloud data with the minimum replication, which can also serve as a cost effectiveness benchmark for replication based approaches. Our simulation indicates that, compared with the conventional three-replica strategy, PRCR can reduce from one-third to two-thirds of the Cloud storage space consumption, hence significantly lowering the storage cost in a Cloud.","Cloud computing,
Memory,
Data models,
Reliability theory,
Distributed databases,
Encoding"
Enhancing Hyperspectral Endmember Extraction Using Clustering and Oversegmentation-Based Preprocessing,"Spectral mixture analysis (SMA) is an effective tool in recognition of unique spectral signatures of materials called endmembers and estimating their percentage of existence (abundance fractions). Most approaches designed in endmember extraction process are established by applying the spectral information of the dataset and, thus, tend to neglect the existing spatial correlation between adjacent pixels. Although several preprocessing modules have been developed by incorporating both spatial and spectral properties prior to spectral-based endmember extraction algorithms (EEs), they still encounter several challenges. Hence, in this paper, we propose an appropriate clustering and oversegmentation-based preprocessing (COPP) by greatly benefiting from the integration of spatial and spectral information. Moreover, a novel top-down oversegmentation (TDOS) algorithm is developed which can recognize small oversegments with high spatial correlation. Our scheme removes oversegments located at spatial border of cluster regions. Average spectral vectors of determined spatially homogenous oversegments are considered so that their spectral purity scores are calculated. COPP identifies spatially homogenous zones with the greatest spectral purity scores. Pixels of these regions are more likely to be adopted as endmembers by means of subsequent EEs. COPP can take advantage of degrading local spectral variability and noise power. The main contribution of this paper is the enhanced computational performance of EE as well as the precise reconstruction of the original hyperspectral scene besides its appropriate recognition of endmembers' spectral signatures. The effectiveness of our design and its validation are appraised with the state-of-the-art strategies on a synthetic and AVIRIS real hyperspectral datasets.","Hyperspectral imaging,
Clustering algorithms,
Algorithm design and analysis,
Indexes,
Correlation"
Combining MIC feature selection and feature-based MSPCA for network traffic anomaly detection,"In this paper, we propose a network anomaly detection system which consists of a Maximal Information Coefficient based feature selection algorithm and a feature-based MSPCA detection algorithm, which can separate the anomalous information more efficiently. Maximal Information Coefficient can provide a good information measurement of any dependency between two random variables. MSPCA combines the benefit of PCA and wavelet analysis to reduce the effect of normal subspace contamination, which is the main challenge of PCA-based anomaly detection algorithm. We utilize multiple network flow features to describe the network traffic instead of using only volumes. To evaluate our proposed system, we test it on the DARPA 1999 dataset. The results indicate a large improvement when using our method compared to PCA-based anomaly detection algorithms.","Feature extraction,
Microwave integrated circuits,
Principal component analysis,
Wavelet transforms,
Matrix decomposition,
Detection algorithms,
Mutual information"
A Decomposition Approach to Quality-Driven Multiuser Video Streaming in Cellular Cognitive Radio Networks,"We tackle the challenging problem of streaming multiuser videos over the downlink of a cellular cognitive radio network (CRN), where each cognitive user (CU) can sense and access multiple channels at a time. Spectrum sensing, channel assignment, and power allocation strategies are jointly optimized to maximize the quality of service (QoS) for the CUs. We show that the formulated mixed integer nonlinear programming (MINLP) problem can be decomposed into two subproblems: 1) SP1 for the optimal spectrum sensing strategy and 2) SP2 for the optimal channel assignment and power allocation, without sacrificing optimality. We show that SP1 can be optimally solved if there is no restriction on the sensing capability for each CU, and develop a column generation (CG)-based algorithm to solve SP2 iteratively in a distributed manner. We also develop a heuristic algorithm for spectrum sensing with greatly reduced requirement on CU hardware, while still achieving a highly competitive sensing performance. We analyze the proposed algorithms with respect to complexity and time efficiency, and derive a performance upper bound. The proposed algorithms are validated with simulations.","Sensors,
Streaming media,
Wireless communication,
Resource management,
Quality of service,
Wireless sensor networks,
Heuristic algorithms"
Localization for Drifting Restricted Floating Ocean Sensor Networks,"Deploying wireless sensor networks in the ocean poses many challenges due to the harsh conditions of the ocean and the nonnegligible node mobility. In this paper, we propose hybrid ocean sensor networks called drifting restricted floating ocean sensor networks (DR-OSNs) for long-term maritime surveillance monitoring tasks, which combines both the advantages of wireless sensor networks and underwater wireless acoustic sensor networks. We present a localization scheme termed localization for double-head maritime sensor networks (LDSN) for DR-OSNs, which leverages the unique characteristics of DR-OSNs to establish the whole localization system after the network is deployed from a plane or a ship, and it does not need the presence of designated anchor nodes deployed underwater. The whole localization process consists of three steps with algorithms self-moored node localization (SML), underwater sensor localization (USD), and floating-node localization algorithm (FLA). The first step is for the super group nodes to localize their underwater moored nodes via an SML algorithm by leveraging the free-drifting movement of their surface nodes. Once the moored nodes in the super group nodes have localized themselves, they turn into anchor nodes underwater. Thus, in the second step, with the help of these new anchor nodes, the unlocalized underwater moored nodes use the USD algorithm to localize their positions. In the last step, when the free-drifting floating nodes without a Global Positioning System (GPS) module need to know their instant position, they apply the FLA to figure out their position. We conduct extensive simulations to evaluate the scheme, with the results indicating that LDSN achieves high localization accuracy and is an effective localization scheme for DR-OSNs.","Sea surface,
Surveillance,
Global Positioning System,
Wireless sensor networks,
Marine vehicles,
Tides"
Exploiting Mobility in Proportional Fair Cellular Scheduling: Measurements and Algorithms,"Proportional Fair (PF) scheduling algorithms are the de facto standard in cellular networks. They exploit the users' channel state diversity (induced by fast-fading) and are optimal for stationary channel state distributions and an infinite time-horizon. However, mobile users experience a nonstationary channel, due to slow-fading (on the order of seconds), and are associated with base stations for short periods. Hence, we develop the Predictive Finite-horizon PF Scheduling ((PF)2S) Framework that exploits mobility. We present extensive channel measurement results from a 3G network and characterize mobility-induced channel state trends. We show that a user's channel state is highly reproducible and leverage that to develop a data rate prediction mechanism. We then present a few channel allocation estimation algorithms that exploit the prediction mechanism. Our trace-based simulations consider instances of the (PF)2S Framework composed of combinations of prediction and channel allocation estimation algorithms. They indicate that the framework can increase the throughput by 15%-55% compared to traditional PF schedulers, while improving fairness.",
Exploiting Device-to-Device Communications to Enhance Spatial Reuse for Popular Content Downloading in Directional mmWave Small Cells,"With the explosive growth of mobile demand, small cells in millimeter-wave (mmWave) bands underlying macrocell networks have attracted intense interest from both academia and industry. MmWave communications in the 60-GHz band are able to utilize the huge unlicensed bandwidth to provide multiple Gb/s transmission rates. In this case, device-to-device (D2D) communications in mmWave bands should be fully exploited because there is no interference with the macrocell networks and higher achievable transmission rates. In addition, because there is less interference by directional transmission, multiple links including D2D links can be scheduled for concurrent transmissions (spatial reuse). With the popularity of content-based mobile applications, popular content downloading in the small cells needs to be optimized to improve network performance and enhance user experience. In this paper, we develop an efficient scheduling scheme for popular content downloading in mmWave small cells called popular content downloading scheduling (PCDS), where both D2D communications in close proximity and concurrent transmissions are exploited to improve transmission efficiency. In PCDS, a transmission path selection algorithm is designed to establish multihop transmission paths for users, aiming at better utilization of D2D communications and concurrent transmissions. After transmission path selection, a concurrent transmission scheduling algorithm is designed to maximize the spatial reuse gain. Through extensive simulations under various traffic patterns, we demonstrate that PCDS achieves near-optimal performance in terms of delay and throughput, as well as superior performance, compared with other existing protocols, particularly under heavy load. The impact of the maximum number of hops of transmission paths on its performance is also analyzed for a better understanding of the role of D2D communications.","Interference,
Schedules,
Lead,
Media Access Protocol,
Receivers,
Propagation losses,
Signal to noise ratio"
Projection Pursuit: A General Methodology of Wide-Area Coherency Detection in Bulk Power Grid,"This paper presents a general approach for coherency detection in bulk power systems using the projection pursuit (PP) theory. Supported by the concept of center of inertia (COI) in power systems, the PP theory is employed to model the wide-area coherency detection as an optimization problem. In the proposed method, the optimal projection direction in high dimensional orthogonal space is explored in order to detect the coherent groups via the data from synchronous phasor measurement units (PMUs). Two quantitative indices constructed with projection assessment index (PI), the objective of the optimization model, are then defined in order to determine the critical coherent group and the dominant coherent groups. The coherency detection criterion and the implementation framework for the proposed approach are also presented. Simulation data from the 16-machine 68-bus test system and China Southern power Grid (CSG), along with actual field-measurement data retrieved from WAMS database in the CSG, are employed to demonstrate the effectiveness and applicability of the proposed algorithm under different disturbances. It is shown that the proposed methodology successfully detects the dominant coherent groups of generators and buses in bulk power system via the wide-area field-measurement data.","Generators,
Rotors,
Oscillators,
Optimization,
Power system stability,
Principal component analysis"
Power Electronic Circuits for Magnetic Energy Harvesters,"Compared to many other energy harvesting schemes, harvesting energy from magnetic fields offers potential advantages for energy extraction and sensing. A magnetic energy harvester provides great flexibility for sensors and monitoring applications for condition-based monitoring of electromagnetic actuators, including vibration and thermal monitoring. A core must be managed or operated with carefully timed saturation to ensure maximum power extraction, a complex problem given the nonlinear saturation characteristics of a magnetic core [1]. This paper presents a simulator-friendly “circuit model” for a magnetic core, and uses this model to design and demonstrate several power electronic circuit solutions for harvesting energy. The circuit model has an excellent accuracy to represent the core regardless of the level of saturation. The design techniques to enhance power harvest are proposed, and verified through simulation and experiments, substantially boosting the amount of power harvest.","Integrated circuit modeling,
Transformer cores,
Load modeling,
Capacitors,
Saturation magnetization,
IP networks"
Energy-Efficient Distributed Topology Control Algorithm for Low-Power IoT Communication Networks,"Topology control is one of the significant research topics in traditional wireless networks. The primary purpose of topology control ensures the connectivity of wireless nodes participated in the network. Low-power Internet of Things communication networks look like wireless network environments in which the main communication devices are wireless devices with limited energy like battery. In this paper, we propose a distributed topology control algorithm by merging the combinatorial block design from a design theory with the multiples of 2. The proposed technique especially focuses on asynchronous and asymmetric neighbor discovery. The concept of block design is used to generate the neighbor discovery schedule when a target duty cycle is given. In addition, the multiples of 2 are applied to overcome the challenge of the block design and support asymmetric operation. We analyze the worst case discovery latency and energy consumption numerically by calculating the total number of slots and wake-up slots based on the given duty cycle. It shows that our proposed method has the smallest total number of slots and wake-up slots among existing representative neighbor discovery protocols. The numerical analysis represents the proposed technique find neighbors quickly with minimum battery power compared with other protocols for distributed topology control. For future research direction, we could perform a simulation study or real experiment to investigate the best parameter for choosing the multiple of a certain number.","Energy efficiency,
Internet of things,
Machine-to-machine communication,
Low power electronics,
Information retrieval,
Wireless networks,
Asymmetric neighbor discovery"
Traffic scheduling and power allocations for mobile data offloading via dual-connectivity,"In this paper, we investigate how the mobile users (MUs) can effectively offload traffic by taking advantage of the capability of dual-connectivity, which enables an MU to simultaneously communicate with a macro base station (BS) and a small-cell access point (AP) via two radio-interfaces. We formulate an optimization problem that jointly determines each MU's traffic schedule (between the BS and AP) and power allocations (between two radio-interfaces), with the objective to minimize all MUs' total cost. We first propose an effective scheme to characterize the feasibility of the joint optimization problem. Then, by exploiting the layered structure, we propose an efficient layered scheme to solve it. Numerical results are provided to validate the proposed schemes and show the performance gain via properly offloading MUs' traffic via dual-connectivity.","Optimization,
Resource management,
Mobile communication,
Schedules,
Uplink,
Noise measurement,
Performance gain"
Energy Efficient Visible Light Communications Relying on Amorphous Cells,"In this paper, we design an energy efficient indoor visible light communications (VLC) system from a radically new perspective based on an amorphous user-to-network association structure. Explicitly, this intriguing problem is approached from three inter-linked perspectives, considering the cell formation, link-level transmission and system-level optimisation, critically appraising the related optical constraints. To elaborate, apart from proposing hitherto unexplored amorphous cells (A-Cells), we employ a powerful amalgam of asymmetrically clipped optical orthogonal frequency division multiplexing (ACO-OFDM) and transmitter pre-coding aided multi-input single-output (MISO) transmission. As far as the overall system-level optimisation is concerned, we propose a low-complexity solution dispensing with the classic Dinkelbach's algorithmic structure. Our numerical study compares a range of different cell formation strategies and investigates diverse design aspects of the proposed A-Cells. Specifically, our results show that the A-Cells proposed are capable of achieving a much higher energy efficiency per user compared to that of the conventional cell formation for a range of practical field of views (FoVs) angles.",
Polarimetric SAR Image Classification Using Deep Convolutional Neural Networks,"Deep convolutional neural networks have achieved great success in computer vision and many other areas. They automatically extract translational-invariant spatial features and integrate with neural network-based classifier. This letter investigates the suitability and potential of deep convolutional neural network in supervised classification of polarimetric synthetic aperture radar (POLSAR) images. The multilooked POLSAR data in the format of coherency or covariance matrix is first converted into a normalized 6-D real feature vector. The six-channel real image is then fed into a four-layer convolutional neural network tailored for POLSAR classification. With two cascaded convolutional layers, the designed deep neural network can automatically learn hierarchical polarimetric spatial features from the data. Two experiments are presented using the AIRSAR data of San Francisco, CA, and Flevoland, The Netherlands. Classification result of the San Francisco case shows that slant built-up areas, which are conventionally mixed with vegetated area in polarimetric feature space, can now be successfully distinguished after taking into account spatial features. Quantitative analysis with respect to ground truth information available for the Flevoland test site shows that the proposed method achieves an accuracy of 92.46% in classifying the considered 15 classes. Such results are comparable with the state of the art.",
Flow-based computing on nanoscale crossbars: Design and implementation of full adders,We present the design and implementation of a full adder circuit that exploits the natural flow of current through nanowires and More-than-Moore nano-devices in two dimensional crossbars. We evaluate the speed and energy efficiency of our design and compare it to equivalent one-bit adder designs using CMOS and nanoscale memristors. Our memristive full adder circuit has been shown to be an order of magnitude faster and more energy-efficient than equivalent CMOS designs. Our circuit is an order of magnitude more compact that equivalent CMOS designs. We also argue that our design occupies less area and is faster than competing memristor designs.,"Adders,
Memristors,
CMOS integrated circuits,
Nanoscale devices,
Energy efficiency,
Switches,
Performance evaluation"
Interference Mitigation in D2D Communication Underlaying LTE-A Network,"The mobile data traffic has risen exponentially in recent days due to the emergence of data intensive applications, such as online gaming and video sharing. It is driving the telecommunication industry as well as the research community to come up with new paradigms that will support such high data rate requirements within the existing wireless access network, in an efficient and effective manner. To respond to this challenge, device-to-device (D2D) communication in cellular networks is viewed as a promising solution, which is expected to operate, either within the coverage area of the existing eNB and under the same cellular spectrum (in-band) or separate spectrum (out-band). D2D provides the opportunity for users located in close proximity of each other to communicate directly, without traversing data traffic through the eNB. It results in several transmission gains, such as improved throughput, energy gain, hop gain, and reuse gain. However, integration of D2D communication in cellular systems at the same time introduces new technical challenges that need to be addressed. Containment of the interference among D2D nodes and cellular users is one of the major problems. D2D transmission radiates in all directions, generating undesirable interference to primary cellular users and other D2D users sharing the same radio resources resulting in severe performance degradation. Efficient interference mitigation schemes are a principal requirement in order to optimize the system performance. This paper presents a comprehensive review of the existing interference mitigation schemes present in the open literature. Based on the subjective and objective analysis of the work available to date, it is also envisaged that adopting a multi-antenna beamforming mechanism with power control, such that the transmit power is maximized toward the direction of the intended D2D receiver node and limited in all other directions will minimize the interference in the network. This could maximize the sum throughput and hence, guarantees the reliability of both the D2D and cellular connections.","Telecommunications traffic,
Interference (signal),
Data communications,
Mobile communication,
Mobile computing,
Device-to-device communication,
Video sharing,
Multimedia communication,
Wireless communication"
Performance Analysis of MIMO MRC Systems With Feedback Delay and Channel Estimation Error,"In this paper, we investigate the performance of a multiple-input-multiple-output (MIMO) maximal ratio combining (MRC) system with feedback delay and channel estimation error. By taking these practical imperfect factors into account, we first formulate the system model and derive the moment-generating function of the output signal-to-noise ratio (SNR), which serves as the basis for further system performance analysis. Then, we compute the probability density function (pdf) and the cumulative distribution function (cdf) of the output SNR. Furthermore, we derive the analytical expressions of the exact and approximate average symbol error rates (SERs) of the MIMO MRC system, which are used to investigate the performance loss in terms of the array gain and diversity order. Finally, computer simulations are conducted to show the efficacy of the analytical results and the effect of feedback delay and channel estimation error on the system performance.","MIMO,
Signal to noise ratio,
Channel estimation,
Delays,
Receivers,
Transmitters,
Educational institutions"
Person Re-identification by Exploiting Spatio-Temporal Cues and Multi-view Metric Learning,"In this letter, we introduce a new spatio-temporal feature, namely optical flow energy image (OFEI), for video-based person re-identification. OFEI aims to exploit spatio-temporally stable regions across frames, which can capture discriminative cues such as human body parts and carry-on stuffs. Furthermore, we propose a novel matching method, denoted by multi-view relevance metric learning with list-wise constraints (mvRMLLC), to integrate the spatio-temporal (i.e., OFEI) and appearance features. Unlike previous works, mvRMLLC assumes that multiple features are generated from different views with distinct data distributions, while their similarities should be globally consistent. Multiple similarity metrics are then learned and fused by maximizing their global consistency and simultaneously allowing local discrepancies. Extensive experiments on two benchmarks demonstrate that OFEI outperforms the state-of-the-art spatio-temporal features, and mvRMLLC could further enhance the overall performance significantly.","Feature extraction,
Measurement,
Optical imaging,
Robustness,
Wireless application protocol,
Optical signal processing,
Image motion analysis"
Multimodal emotion recognition using deep learning architectures,"Emotion analysis and recognition has become an interesting topic of research among the computer vision research community. In this paper, we first present the emoF-BVP database of multimodal (face, body gesture, voice and physiological signals) recordings of actors enacting various expressions of emotions. The database consists of audio and video sequences of actors displaying three different intensities of expressions of 23 different emotions along with facial feature tracking, skeletal tracking and the corresponding physiological data. Next, we describe four deep belief network (DBN) models and show that these models generate robust multimodal features for emotion classification in an unsupervised manner. Our experimental results show that the DBN models perform better than the state of the art methods for emotion recognition. Finally, we propose convolutional deep belief network (CDBN) models that learn salient multimodal features of expressions of emotions. Our CDBN models give better recognition accuracies when recognizing low intensity or subtle expressions of emotions when compared to state of the art methods.","Databases,
Emotion recognition,
Face,
Physiology,
Three-dimensional displays,
Machine learning,
Facial features"
A Novel Power Consumption Model for Effective Energy Efficiency in Wireless Networks,"Designing energy-efficient delay-aware communication networks have become an inevitable trend in 5G wireless networks. In this letter, we present an energy-efficient and delay-aware cross-layer resource allocation in SISO wireless systems. To achieve this goal, we apply the notion of effective energy efficiency (EEE), defined as the ratio of the system effective capacity (EC) over the total power consumption. Unlike previous works, we introduce a new average power consumption model which accounts for the data link layer, allowing for the probability of emptying the buffer during the transmission timeframe. This leads to a new definition of EEE, which results in better performance in terms of both EEE and EC.","Power demand,
Delays,
Lead,
Resource management,
Quality of service,
Wireless networks,
5G mobile communication"
Cloud-Assisted Data Fusion and Sensor Selection for Internet of Things,"The Internet of Things (IoT) is connecting people and smart devices on a scale that was once unimaginable. One major challenge for the IoT is to handle vast amount of sensing data generated from the smart devices that are resource-limited and subject to missing data due to link or node failures. By exploring cloud computing with the IoT, we present a cloud-based solution that takes into account the link quality and spatio-temporal correlation of data to minimize energy consumption by selecting sensors for sampling and relaying data. We propose a multiphase adaptive sensing algorithm with belief propagation (BP) protocol (ASBP), which can provide high data quality and reduce energy consumption by turning on only a small number of nodes in the network. We formulate the sensor selection problem and solve it using both constraint programming (CP) and greedy search. We then use our message passing algorithm (BP) for performing inference to reconstruct the missing sensing data. ASBP is evaluated based on the data collected from real sensors. The results show that while maintaining a satisfactory level of data quality and prediction accuracy, ASBP can provide load balancing among sensors successfully and preserves 80% more energy compared with the case where all sensor nodes are actively involved.",
Never skip leg day: A novel wearable approach to monitoring gym leg exercises,"We present a wearable textile sensor system for monitoring muscle activity, leveraging surface pressure changes between the skin and an elastic sport support band. The sensor is based on an 8×16 element fabric resistive pressure sensing matrix of 1cm spatial resolution, which can be read out with 50fps refresh rate. We evaluate the system by monitoring leg muscles during leg workouts in a gym out of the lab. The sensor covers the lower part of quadriceps of the user. The shape and movement of the two major muscles (vastus lateralis and medialis) are visible from the data during various exercises. The system registers the activity of the user for every second, including which machine he/she is using, walking, relaxing and adjusting the machines; it also counts the repetitions from each set and evaluate the force consistency which is related to the workout quality. 6 people participated in the experiment of overall 24 leg workout sessions. Each session includes cross-trainer warm-up and cool-down, 3 different leg machines, 4 sets on each machine. Plus relaxing, adjusting machines, and walking, we perform activity recognition and quality evaluation through 2-dimensional mapping and the time sequence of the average force. We have reached 81.7% average recognition accuracy on a 2s sliding window basis, 93.3% on an event basis, and 85.6% spotting F1-score. We further demonstrate how to evaluate the workout quality through counting, force pattern variation and consistency.","Muscles,
Robot sensing systems,
Force,
Electrodes,
Biomedical monitoring,
Monitoring,
Hardware"
Local Search Yields a PTAS for k-Means in Doubling Metrics,"The most well known and ubiquitous clustering problem encountered in nearly every branch of science is undoubtedly k-MEANS: given a set of data points and a parameter k, select k centres and partition the data points into k clusters around these centres so that the sum of squares of distances of the points to their cluster centre is minimized. Typically these data points lie in Euclidean space Rd for some d ≥ 2. k-MEANS and the first algorithms for it were introduced in the 1950's. Over the last six decades, hundreds of papers have studied this problem and different algorithms have been proposed for it. The most commonly used algorithm in practice is known as Lloyd-Forgy, which is also referred to as ""the"" k-MEANS algorithm, and various extensions of it often work very well in practice. However, they may produce solutions whose cost is arbitrarily large compared to the optimum solution. Kanungo et al. [2004] analyzed a very simple local search heuristic to get a polynomial-time algorithm with approximation ratio 9 + ε for any fixed ε > 0 for k-Umeans in Euclidean space. Finding an algorithm with a better worst-case approximation guarantee has remained one of the biggest open questions in this area, in particular whether one can get a true PTAS for fixed dimension Euclidean space. We settle this problem by showing that a simple local search algorithm provides a PTAS for k-MEANS for Rd for any fixed d. More precisely, for any error parameter ε > 0, the local search algorithm that considers swaps of up to ρ = dO(d) · ε-O(d/ε) centres at a time will produce a solution using exactly k centres whose cost is at most a (1+ε)-factor greater than the optimum solution. Our analysis extends very easily to the more general settings where we want to minimize the sum of q'th powers of the distances between data points and their cluster centres (instead of sum of squares of distances as in k-MEANS) for any fixed q ≥ 1 and where the metric may not be Euclidean but still has fixed doubling dimension.","Clustering algorithms,
Approximation algorithms,
Algorithm design and analysis,
Search problems,
Heuristic algorithms,
Euclidean distance"
Sketch-Based Image Retrieval by Salient Contour Reinforcement,"The paper presents a sketch-based image retrieval algorithm. One of the main challenges in sketch-based image retrieval (SBIR) is to measure the similarity between a sketch and an image. To tackle this problem, we propose an SBIR-based approach by salient contour reinforcement. In our approach, we divide the image contour into two types. The first is the global contour map. The second, called the salient contour map, is helpful to find out the object in images similar to the query. In addition, based on the two contour maps, we propose a new descriptor, namely an angular radial orientation partitioning (AROP) feature. It fully utilizes the edge pixels' orientation information in contour maps to identify the spatial relationships. Our AROP feature based on the two candidate contour maps is both efficient and effective to discover false matches of local features between sketches and images, and can greatly improve the retrieval performance. The application of the retrieval system based on this algorithm is established. The experiments on the image dataset with 0.3 million images show the effectiveness of the proposed method and comparisons with other algorithms are also given. Compared to baseline performance, the proposed method achieves 10% higher precision in top 5.",
Decentralized Monitoring of Dynamic Processes Based on Dynamic Feature Selection and Informative Fault Pattern Dissimilarity,"Although decentralized modeling has been widely employed in monitoring large-scale processes, the dynamic property in process data is rarely investigated. Meanwhile, fault diagnosis in a way similar to pattern recognition is still challenging. To handle these issues, a dynamic decentralized fault detection and diagnosis framework based on dynamic feature selection and informative fault pattern (IFP) dissimilarity is presented. The proposed method accounts explicitly for the dynamic property in process data, while handling the challenging fault diagnosis task at the same time. First, a dynamic feature selection method is proposed to interpret the dynamic relations through characterizing the auto- and cross-correlation for each variable individually. As a consequence, multiblocks are derived for decentralized modeling and monitoring purposes. Second, a novel classification-based fault diagnosis approach on the basis of the dissimilarity analysis and filtered monitoring statistics (termed as IFP) is formulated. This sort of method can be feasible even in a condition that the training samples for each reference fault class are insufficient and also overlapped with each other. Finally, the salient performance in terms of fault detection and recognition capabilities that can be achieved is validated by two simulated examples. The comparisons clearly demonstrate the superiority and feasibility of the proposed monitoring scheme.","Monitoring,
Principal component analysis,
Fault diagnosis,
Data models,
Fault detection,
Loading,
Analytical models"
"Application-Level Optimization of Big Data Transfers through Pipelining, Parallelism and Concurrency","In end-to-end data transfers, there are several factors affecting the data transfer throughput, such as the network characteristics (e.g., network bandwidth, round-trip-time, background traffic); end-system characteristics (e.g., NIC capacity, number of CPU cores and their clock rate, number of disk drives and their I/O rate); and the dataset characteristics (e.g., average file size, dataset size, file size distribution). Optimization of big data transfers over inter-cloud and intra-cloud networks is a challenging task that requires joint-consideration of all of these parameters. This optimization task becomes even more challenging when transferring datasets comprised of heterogeneous file sizes (i.e., large files and small files mixed). Previous work in this area only focuses on the end-system and network characteristics however does not provide models regarding the dataset characteristics. In this study, we analyze the effects of the three most important transfer parameters that are used to enhance data transfer throughput: pipelining,parallelism and concurrency. We provide models and guidelines to set the best values for these parameters and present two different transfer optimization algorithms that use the models developed. The tests conducted over high-speed networking and cloud testbeds show that our algorithms outperform the most popular data transfer tools like Globus Online and UDT in majority of the cases.","Pipeline processing,
Throughput,
Concurrent computing,
Optimization,
Data transfer,
Bandwidth"
Compressive Spatio-Temporal Forecasting of Meteorological Quantities and Photovoltaic Power,"This paper presents a solar power forecasting scheme, which uses spatial and temporal time series data along with a photovoltaic (PV) power conversion model. The PV conversion model uses the forecast of three different variables, namely, irradiance on the tilted plane, ambient temperature, and wind speed, in order to estimate the power produced by a PV plant at the grid connection terminals. The forecast values are obtained using a spatio-temporal method that uses the data recorded from a target meteorological station as well as data of its surrounding stations. The proposed forecasting method exploits the sparsity of correlations between time series data in a collection of stations. The performance of both the PV conversion model and the spatio-temporal algorithm is evaluated using high-resolution real data recorded in various locations in Italy. Comparison with other benchmark methods illustrates that the proposed method significantly improves the solar power forecasts, particularly over short-term horizons.","Forecasting,
Wind forecasting,
Predictive models,
Rain,
Time series analysis,
Wind speed"
CAWSAC: Cost-Aware Workload Scheduling and Admission Control for Distributed Cloud Data Centers,"Multiple heterogeneous applications concurrently run in distributed cloud data centers (CDCs) for better performance and lower cost. There is a highly challenging problem of how to minimize the total cost of a CDCs provider in a market where the bandwidth and energy cost show geographical diversity. To solve the problem, this paper first proposes a revenue-based workload admission control method to judiciously admit requests by considering factors including priority, revenue and the expected response time. Then, this paper presents a cost-aware workload scheduling method to jointly optimize the number of active servers in each CDC, and the selection of Internet service providers for the CDCs provider. Finally, trace-driven simulation results demonstrate that the proposed methods can greatly reduce the total cost and increase the throughput of the CDCs provider in comparison to existing methods. Note to Practitioners-A cloud provider deploys its applications in geographically distributed CDCs to improve stability and reliability. For cost and performance, each CDC provides services through multiple ISPs that deliver traffic between millions of users and the CDCs provider. The geographical diversity of the bandwidth and energy cost brings the CDCs provider a big challenge of how to minimize the bandwidth and energy cost of the CDCs provider. This paper first proposes a revenue-based workload admission control method to selectively admit requests. Then, this paper proposes a cost-aware workload scheduling method to allocate requests among multiple available Internet service providers connecting to distributed CDCs. The scheduling strategy can intelligently dispatch requests, and achieve lower cost and higher throughput for the CDCs provider.","Servers,
Admission control,
Bandwidth,
Time factors,
Heuristic algorithms,
Scheduling,
Distributed databases"
Experimental Demonstration of an IFFT/FFT Size Efficient DFT-Spread OFDM for Short Reach Optical Transmission Systems,"We experimentally demonstrate an IFFT/FFT size efficient discrete Fourier transform (DFT)-spread orthogonal frequency-division multiplexing (OFDM) based on complex-valued IFFT/FFT operations without Hermitian symmetry constraint at the input, for short-reach intensity-modulated and directly-detected optical fiber transmission systems. The only complex-valued IFFT-based OFDM has the similar peak-to-average power ratio (PAPR) and bit error rate (BER) performance, but with only half of the IFFT/FFT size as the conventional real IFFT-based OFDM. In this paper, the complex IFFT-based OFDM combined with DFT-spread technique is proposed and applied to reduce PAPR and IFFT/FFT size, and improve BER performance at the same time. The experimental results show that, with the help of PAPR reduction enabled by DFT-spread, more than 2-dB improvement in receiver sensitivity has been achieved after 20.62 km of single mode fiber transmission at a BER of 3.8 × 10-3 (7% hard-decision forward error correction threshold). In addition, by using the DFT-spread technique, the BER performance comparison between complex IFFT-based OFDM and real IFFT-based OFDM is also performed. The results show that, the BER performance of the former is slightly worse than the latter, but has lower hardware complexity and less power consumption due to the reduced IFFT/FFT size.","Peak to average power ratio,
Optical fibers,
Bit error rate,
High-speed optical techniques,
Optical receivers"
An Adaptive SPWM Technique for Cascaded Multilevel Converters With Time-Variant DC Sources,An adaptive sinusoidal pulse-width modulation (SPWM) technique for cascaded H-bridge (CHB) multilevel converters is presented in this paper. The proposed technique enables the CHB topology to provide a symmetrical ac voltage from a set of asymmetrical time-variant input dc-source voltages. A sensor-per-source (SPS) algorithm and a sensor-per-leg (SPL) algorithm are described as alternatives for implementing the adaptive SPWM technique. Software simulations and experimental results are presented to demonstrate the efficacy of the presented SPS and SPL algorithms.,
An Improved Model Predictive Control Scheme for the PWM Rectifier-Inverter System Based on Power-Balancing Mechanism,"The dc-link voltage fluctuation caused by the change of working state of the load motor has been one of the key issues in the pulse width modulation rectifier-inverter system. In this study, an improved model predictive control (MPC) scheme is proposed to address this problem. The MPC is applied to both the rectifier stage and the inverter stage in the system. Direct power control is used in the rectifier stage and the direct torque control is employed in the inverter stage, with the key novelty of the active power reference values being defined by both real-time and periodic compensation power based on the system-level power-balance model. Meanwhile, an MPC algorithm based on a two-step prediction is introduced to compensate for the delay of a digital controller. Comparison has been conducted between the proposed scheme and three other methods. Simulation and experimental results show that the proposed control scheme exhibits good performance in both the rectifier stage and the inverter stage with improved dynamic response and suppressed voltage fluctuation of the dc-link voltage.",
Analysis on Program Disturbance in Channel-Stacked NAND Flash Memory With Layer Selection by Multilevel Operation,"Program disturbance is analyzed in a simplified channel-stacked array with layer selection by multilevel operation after setting the threshold voltages (Vth) of string select transistors (SSTs)/dummy SSTs. There are additional unselected cells that should be inhibited in different ways, and they have the worse disturbance characteristics compared with conventional NAND arrays. Technology computer-aided design simulations and measurements are performed to investigate the disturbance mechanism of the additional cases. It is found that initially nonprecharged channel and large leakage current flowing from channel to bitline degrade the disturbance. New program method is proposed along with low gate bias of dummy wordline. As a result, program disturbance is significantly improved and reliability is also enhanced by reducing the potential difference between the SST gate and the channel.",
Reliability Assessment of the Switched Reluctance Motor Drive Under Single Switch Chopping Strategy,"In this paper, a detailed set of reliability prediction methodology for switched reluctance motor drive (SRD) considering system specific control strategy and component fault classification is elaborated from component level to system level. At component level, introduction to SRD and its single switch chopping strategy is presented to capture characteristics of SRD reliability under a certain control strategy. The unique fault modes classification and summary methods which are tailored to SRD are applied for identification of system dominant fault modes. Then at system level, binary models (reliability block diagram and part-count model) and multivariate model (Markov model) are adopted to build systematic SRD reliability model, respectively. Especially in the Markov model, state transition diagram and state probability matrix P(t) are built in detailed description to constitute the graphical and numerical Markov reliability model. Conclusions can be drawn that compared with RBD, Markov model can capture the effect of specific control strategy on system reliability, and further demonstrates the stronger consistency with SRD practical operation. Fault simulation and experiments are conducted to illustrate the influence on system operation state caused by a control strategy. Also, the results verify the state assessment of system performance after component-level fault occurs.","Reliability,
Circuit faults,
Markov processes,
Power system reliability,
Switches,
Numerical models"
Indoor Global Positioning System with Centimeter Accuracy Using Wi-Fi [Applications Corner],"In this column, we present a time-reversal method for indoor localization that achieves centimeter accuracy with a single pair of off-the-shelf Wi-Fi devices. The high accuracy for localization is maintained under strong NLOS scenarios. With the exploitation of the inherent frequency and spatial diversities in Wi-Fi systems, it is capable of creating a large effective bandwidth to enable centimeter accuracy. Extensive experiment results in a typical office environment show that the centimeter accuracy as well as robustness against dynamics can be simultaneously achieved with a large effective bandwidth. The global GPS can achieve 3-15 m of accuracy by mapping the world into latitude and longitude coordinates. The presented “indoor GPS” can achieve 1-2 cm accuracy when an indoor environment is fingerprinted and mapped.","IEEE 802.11 Standard,
Bandwidth,
Fingerprint recognition,
Frequency diversity,
Spatial diversity,
Performance evaluation,
Global Positioning System"
"A Mixed-Decimation MDF Architecture for Radix-
2
k
Parallel FFT","This paper presents a mixed-decimation multipath delay feedback (M2 DF) approach for the radix-2k fast Fourier transform. We employ the principle of folding transformation to derive the proposed architecture, which activates the idle period of arithmetic modules in multipath delay feedback (MDF) architectures by integrating the decimation-in-time operations into the decimation-in-frequency-operated computing units. Furthermore, we compare the proposed design with other efficient schemes, namely, the MDF and the multipath delay commutator (MDC) scheme theoretically and experimentally. Relying on the obtained expressions and statistics, it can be concluded that the M2DF design serves as an efficient alternative to the MDF scheme, since it achieves improved efficiency in the utilization of arithmetic resources without deteriorating the superiorities of feedback structures. In addition, the recommended design performs better in memory requirement and computing delay compared with the MDC approach.",
Simultaneous Electromagnetic Tracking and Calibration for Dynamic Field Distortion Compensation,"Electromagnetic (EM) tracking systems are highly susceptible to field distortion. The interference can cause measurement errors up to a few centimeters in clinical environments, which limits the reliability of these systems. Unless corrected for, this measurement error imperils the success of clinical procedures. It is therefore fundamental to dynamically calibrate EM tracking systems and compensate for measurement error caused by field distorting objects commonly present in clinical environments. We propose to combine a motion model with observations of redundant EM sensors and compensate for field distortions in real time. We employ a simultaneous localization and mapping technique to accurately estimate the pose of the tracked instrument while creating the field distortion map. We conducted experiments with six degrees-of-freedom motions in the presence of field distorting objects in research and clinical environments. We applied our approach to improve the EM tracking accuracy and compared our results to a conventional sensor fusion technique. Using our approach, the maximum tracking error was reduced by 67% for position measurements and by 64% for orientation measurements. Currently, clinical applications of EM trackers are hampered by the adverse distortion effects. Our approach introduces a novel method for dynamic field distortion compensation, independent from preoperative calibrations or external tracking devices, and enables reliable EM navigation for potential applications.","Distortion,
Sensors,
Distortion measurement,
Instruments,
Magnetic field measurement,
Tracking,
Image analysis"
Multiple Scattering Effects With Cyclical Correction in Active Remote Sensing of Vegetated Surface Using Vector Radiative Transfer Theory,"The energy transport in a vegetated (corn) surface layer is examined by solving the vector radiative transfer equation using a numerical iterative approach. This approach allows a higher order that includes the multiple scattering effects. Multiple scattering effects are important when the optical thickness and scattering albedo of the vegetation layer are large. When both the albedo and the optical thickness exceed 0.4, higher orders contribute significantly (e.g., vertical polarization at L-band). The approach is applied to vegetated surfaces using typical crop structure for backscattering from L-band to Ku-band. For corn fields at L-band, multiple scattering effects are more important for vertical scattered wave with vertical incidence (VV). For example, when vegetation water content (VWC) is 3kg/m2, the deviation between first order and multiple scattering for corn field for VV could be 3.5 dB while 0.7 dB for horizontal scattered wave with horizontal incidence (HH). The iterative approach also allows the separation of the contribution to backscattering from each scattering order and scattering mechanism. Each scattering mechanism is associated with a unique scattering path. By examining the duality of the paths, we are able to identify the cyclical terms with existence of a reflective boundary. The cyclical correction to the backscattering accounts for backscattering enhancement effects on the copolarization by a factor of two. The approach is validated against the SMAPVEX12 L-band corn dataset over the entire crop growth and large soil moisture variations. The model prediction matches the observation with 1.93 and 1.46 dB root-mean-square error (RMSE) for VV and HH, respectively, while correlations are 0.67 and 0.88, respectively. Time-series retrieval is also applied successfully for both soil moisture and VWC with 0.06 cm3/cm3 and 0.44 kg/m2 RMSE, respectively, while correlations are 0.7 and 0.92, respectively. For large VWC, this approach corrects the underestimated backscatters in the single scattering caused by large attenuation.","Scattering,
Backscatter,
Remote sensing,
Soil moisture,
Vegetation mapping,
L-band,
Optical surface waves"
Optimal Energy Management for Stable Operation of an Islanded Microgrid,"This paper presents a methodology on the design of an optimal predictive control scheme applied to an islanded microgrid. The controller manages the batteries energy and performs a centralized load shedding strategy to balance the load and generation within the microgrid, and to keep the stability of the voltage magnitude. A nonlinear model predictive control (NMPC) algorithm is used for processing a data set composed of the batteries state of charge, the distributed energy resources (DERs) active power generation, and the forecasted load. The NMPC identifies upcoming active power unbalances and initiates automated load shedding over noncritical loads. The control strategy is tested in a medium voltage distribution system with DERs. This control strategy is assisted by a distribution monitoring system, which performs real-time monitoring of the active power generated by the DERs and the current load demand at each node of the microgrid. Significant performance improvement is achieved with the use of this control strategy over tested cases without its use. The balance between the power generated by the DERs and the load demand is maintained, while the voltage magnitude is kept within the maximum variation margin of ±5% recommended by the standard ANSI C84.1-1989.","Microgrids,
Load modeling,
Power generation,
Voltage control,
Benchmark testing,
Energy management,
Informatics"
Wearable Heart Rate Sensor Systems for Wireless Canine Health Monitoring,"There is an increasing interest from dog handlers and veterinarians in an ability to continuously monitor dogs' vital signs (heart rate, heart rate variability, and respiratory rate) outside laboratory environments, with the aim of identifying physiological correlations to stress, distress, excitement, and other emotional states. We present a non-invasive wearable sensor system combining electrocardiogram (ECG), photoplethysmogram (PPG), and inertial measurement units (IMU) to remotely and continuously monitor the vital signs of dogs. To overcome the limitations imposed by the efficiently insulated skin and dense hair layers of dogs, we investigated the use of various styles of ECG electrodes and the enhancements of these by conductive polymer coatings. We also studied the incorporation of light guides and optical fibers for an efficient optical coupling of PPG sensors to the skin. Combined with our parallel efforts to use IMUs to identify dog behaviors, these physiological sensors will contribute to a canine-body area network to wirelessly and continuously collect data during canine activities with a long-term goal of effectively capturing and interpreting dogs' behavioral responses to environmental stimuli that may yield measurable benefits to handlers' interactions with their dogs.","Electrodes,
Electrocardiography,
Impedance,
Sensors,
Pins,
Dogs,
Biomedical monitoring"
A Stochastic Analysis of Network MIMO Systems,"This paper quantifies the benefits and limitations of cooperative communications by providing a statistical analysis of the downlink in network multiple-input multiple-output (MIMO) systems. We consider an idealized model where the multiple-antenna base-stations (BSs) are distributed according to a homogeneous Poisson point process and cooperate by forming disjoint clusters. We assume that perfect channel state information is available at the cooperating BSs without any overhead. Multiple single-antenna users are served using zero-forcing beamforming with equal power allocation across the beams. For such a system, we obtain tractable, but accurate, approximations of the signal power and inter-cluster interference power distributions and derive a computationally efficient expression for the achievable per-BS ergodic sum rate using tools from stochastic geometry. This expression allows us to obtain the optimal loading factor, i.e., the ratio between the number of scheduled users and the number of BS antennas, that maximizes the per-BS ergodic sum rate. Further, it allows us to quantify the performance improvement of network MIMO systems as a function of the cooperating cluster size. We show that to perform zero-forcing across the distributed set of BSs within the cluster, the network MIMO system introduces a penalty in received signal power. Along with the inevitable out-of-cluster interference, we show that the per-BS ergodic sum rate of a network MIMO system does not approach that of an isolated cell even at unrealistically large cluster sizes. Nevertheless, network MIMO does provide significant rate improvement as compared to uncoordinated single-cell processing even at relatively modest cluster sizes.","MIMO,
Interference,
Loading,
Geometry,
Stochastic processes,
Array signal processing,
Downlink"
Increasing web service availability by detecting application-layer DDoS attacks in encrypted traffic,"Nowadays, zero-day Denial-of-Service (DoS) attacks become frighteningly common in high-speed networks due to constantly increasing number of vulnerabilities. Moreover, these attacks become more sophisticated, and, therefore, they are hard to detect before they damage several networks and hosts. Due to these reasons, real-time monitoring, processing and network anomaly detection must be among key features of a modern DoS prevention system. In this paper, we present a method which allows us to timely detect various denial-of-service attacks against a computer or a network system. We focus on detection of application-layer DoS attacks that utilize encrypted protocols by applying an anomaly-detection-based approach to statistics extracted from network packets. Since network traffic decryption can violate ethical norms and regulations on privacy, the detection scheme proposed analyzes network traffic without its decryption. The scheme includes the analysis of conversations between a web server and its clients, the construction of a model of normal user behavior by dividing these conversations into clusters and the examination of distribution of these conversations among the resulting clusters with the help of the stacked auto-encoder which belongs to a class of deep learning algorithms. Conversations of clients that deviate from those normal patterns are classified as anomalous. The proposed technique is tested on the data obtained with the help of a realistic cyber environment.","Computer crime,
Feature extraction,
Clustering algorithms,
Protocols,
Cryptography,
Web servers"
Intelligent Marketing in Smart Cities: Crowdsourced Data for Geo-Conquesting,"The authors' approach to intelligent marketing in smart cities uses large-scale crowdsourcing based on mobile user behavior for market planning. Unlike most work, which focuses on the client side, the proposed method is intended for market planning from a marketer perspective. The proposed system tracks and examines user trails via mobile devices. To support distributed analysis for big data, computer clusters project user trajectories onto blocks in a layout map of an actual geo-location. The trajectory falling into a block is independently handled by a distributed computer that detects crowd flows. Because traffic flows are highly relevant to geo-conquesting marketing, two methods are proposed: local longest common subsequence-based (LLCS-based) clustering, and the computation of transition flows and heat maps. Both help marketers analyze crowd flows for geo-conquesting. Simulation of the proposed methods revealed that the system facilitated computation of large-scale crowdsourced data.","Trajectory,
Smart cities,
Mobile communication,
Advertising,
Computational modeling,
Crowdsourcing,
Mathematical model,
Marketing and sales,
Distributed processing,
Pervasive computing"
Robust Consensus of Nonlinear Multiagent Systems With Switching Topology and Bounded Noises,"Consensus of multiagent systems (MASs) is an intriguing topic in recent years due to its widely used application in robotics, biology, computer, and social science. In the real world, the evolution of MAS is inevitably involved in dynamical environments and the recent development of MAS calls for novel tools for the analysis of MAS with dynamic topology. In addition, the interactions between agents are generally nonlinear and environmental noises are ubiquitous in the communication channels between agents. However, the existing investigation on MAS places little attention on nonlinear models and the inner relationship between external disturbance and consensus is still unclear. Facing these problems, this paper considers an MAS in which the interactions between agents are nonlinear and the communication between agents are infected by environmental noises. By using a novel method of nonsmooth Lyapunov candidate, it has been demonstrated that such an MAS can realize robust consensus under the conditions of jointly (sequentially) connected topology and bounded noises. Finally, simulation results validate the effectiveness of these criteria.","Topology,
Robustness,
Noise,
Switches,
Protocols,
Delays,
Lyapunov methods"
Regularized Filters for L1-Norm-Based Common Spatial Patterns,"The ℓ1-norm-based common spatial patterns (CSP-L1) approach is a recently developed technique for optimizing spatial filters in the field of electroencephalogram (EEG)-based brain computer interfaces. The ℓ1-norm-based expression of dispersion in CSP-L1 alleviates the negative impact of outliers. In this paper, we further improve the robustness of CSP-L1 by taking into account noise which does not necessarily have as large a deviation as with outliers. The noise modelling is formulated by using the waveform length of the EEG time course. With the noise modelling, we then regularize the objective function of CSP-L1, in which the ℓ1-norm is used in two folds: one is the dispersion and the other is the waveform length. An iterative algorithm is designed to resolve the optimization problem of the regularized objective function. A toy illustration and the experiments of classification on real EEG data sets show the effectiveness of the proposed method.","Noise,
Brain models,
Electroencephalography,
Dispersion,
Linear programming,
Robustness"
Handover Count Based Velocity Estimation and Mobility State Detection in Dense HetNets,"In wireless cellular networks with densely deployed base stations, knowing the velocities of mobile devices is key to avoiding call drops and improving the quality of service to the user equipments (UEs). A simple and efficient way to estimate a UE's velocity is by counting the number of handovers made by the UE during a predefined time window. Indeed, handover-count based mobility state detection has been standardized since long term evolution (LTE) Release-8 specifications. The increasing density of small cells in wireless networks can help in accurate estimation of velocity and mobility state of a UE. In this paper, we model densely deployed small cells using stochastic geometry, and then analyze the statistics of the number of handovers as a function of UE velocity, small-cell density, and handover count measurement time window. Using these statistics, we derive approximations to the Cramer-Rao lower bound (CRLB) for the velocity estimate of a UE. Also, we determine a minimum variance unbiased (MVU) velocity estimator whose variance tightly matches with the CRLB. Using this velocity estimator, we formulate the problem of detecting the mobility state of a UE as low, medium, or high-mobility, as in LTE specifications. Subsequently, we derive the probability of correctly detecting the mobility state of a UE. Finally, we evaluate the accuracy of the velocity estimator under more realistic scenarios such as clustered deployment of small cells, random way point (RWP) mobility model for UEs, and variable UE velocity. Our analysis shows that the accuracy of velocity estimation and mobility state detection increases with increasing small cell density and with increasing handover count measurement time window.","Handover,
Estimation,
Long Term Evolution,
Wireless communication,
Geometry,
Stochastic processes"
"One Handshake Can Achieve More: An Energy-Efficient, Practical Pipelined Data Collection for Duty-Cycled Sensor Networks","To alleviate long sleep latency due to duty-cycled radio operations, existing collection protocols adopted pipelined scheduling techniques, which stagger the sleep-wakeup schedules of nodes along forwarding paths, requiring accurate time synchronization as underlying support. They either ignored the synchronization issue or just assumed that a local synchronization scheme over non-duty-cycled radios could meet the requirement, however, which may lead to a significant synchronization issue in practice. In this paper, we propose a practical pipelined data collection (PDC) protocol for duty-cycled sensor networks. PDC adopts an inter-layer incorporation of network and media access control layers. It only relies on an RTS/CTS-like handshake with a set of the proposed algorithms, not only for data transmission as commonly utilized, but also for pipelined scheduling and schedule synchronization, data-gathering tree establishment, and network topology control and maintenance, all of which are naturally and seamlessly incorporated together and able to support each other. PDC has been implemented in the Contiki operating system. The testbed evaluations based on two hardware platforms (Z1 and MicaZ) and the compared results with a de facto standard for data collection based on the fully emulated Z1 in Cooja have demonstrated its practicality and efficacy.","Synchronization,
Schedules,
Sensors,
Protocols,
Data collection,
Hardware,
Wireless sensor networks"
On the Construction of Data Aggregation Tree With Maximizing Lifetime in Large-Scale Wireless Sensor Networks,"Data aggregation protocols are generally utilized to extend the lifetime of sensor networks by reducing the communication cost. Traditionally, tree-based structured approaches that are a basic operation for the sink to periodically collect reports from all sensors were concerned about many applications. Since the data aggregation process usually proceeds for many rounds, it is important to collect these data efficiently, that is, to reduce the energy cost of data transmission. Under such applications, a tree is usually adopted as the routing structure to save the computation costs when maintaining the routing tables of sensors. In our previous work, we have demonstrated that multiple trees, as well as split trees, can provide additional lifetime extensions when certain nodes are deployed in a wireless sensor network. In this paper, we explore how the number of the family-set of trees influences the lifetime gain, and we work on the problem of constructing data aggregation trees that minimizes the total energy cost of data transmission under diverse set of scenarios and network query region. Through dividing query area, the sensory and aggregation data have been returned through a number of different forwarding trees within each sub query area, which reduces the network hot spots. To evaluate the performance of the proposed approach, we have compared and analyzed an angular division routing algorithm and query region division routing with LEACH. Theoretical and experimental results illustrate that the query region division algorithm based on angle leads to lower energy cost in comparison with the models reported in the literature.","Sensors,
Routing,
Wireless sensor networks,
Monitoring,
Periodic structures,
Aggregates"
Compressive Sequential Learning for Action Similarity Labeling,"Human action recognition in videos has been extensively studied in recent years due to its wide range of applications. Instead of classifying video sequences into a number of action categories, in this paper, we focus on a particular problem of action similarity labeling (ASLAN), which aims at verifying whether a pair of videos contain the same type of action or not. To address this challenge, a novel approach called compressive sequential learning (CSL) is proposed by leveraging the compressive sensing theory and sequential learning. We first project data points to a low-dimensional space by effectively exploring an important property in compressive sensing: the restricted isometry property. In particular, a very sparse measurement matrix is adopted to reduce the dimensionality efficiently. We then learn an ensemble classifier for measuring similarities between pairwise videos by iteratively minimizing its empirical risk with the AdaBoost strategy on the training set. Unlike conventional AdaBoost, the weak learner for each iteration is not explicitly defined and its parameters are learned through greedy optimization. Furthermore, an alternative of CSL named compressive sequential encoding is developed as an encoding technique and followed by a linear classifier to address the similarity-labeling problem. Our method has been systematically evaluated on four action data sets: ASLAN, KTH, HMDB51, and Hollywood2, and the results show the effectiveness and superiority of our method for ASLAN.","Videos,
Labeling,
Image coding,
Feature extraction,
Measurement,
Boosting,
Video sequences"
High-level synthesis of accelerators in embedded scalable platforms,"Embedded scalable platforms combine a flexible socketed architecture for heterogeneous system-on-chip (SoC) design and a companion system-level design methodology. The architecture supports the rapid integration of processor cores with many specialized hardware accelerators. The methodology simplifies the design, integration, and programming of the heterogeneous components in the SoC. In particular, it raises the level of abstraction in the design process and guides designers in the application of high-level synthesis (HLS) tools. HLS enables a more efficient design of accelerators with a focus on their algorithmic properties, a broader exploration of their design space, and a more productive reuse across many different SoC projects.",
Tracking angles of departure and arrival in a mobile millimeter wave channel,"Millimeter wave provides a promising approach for meeting the ever-growing traffic demand in next generation wireless networks. It is crucial to obtain the channel state information in order to perform beamforming and combining to compensate for severe path loss in this band. In contrast to lower frequencies, a typical millimeter wave channel consists of a few dominant paths. Thus it is generally sufficient to estimate the path gains, angles of departure (AoDs), and angles of arrival (AoAs) of those paths. Proposed in this paper is a dual timescale model to characterize abrupt channel changes (e.g., blockage) and slow variations of AoDs and AoAs. This work focuses on tracking the slow variations and detecting abrupt changes. A Kalman filter based tracking algorithm and an abrupt change detection method are proposed. The tracking algorithm is compared with the adaptive algorithm due to Alkhateeb, Ayach, Leus and Heath (2014) in the case with a single radio frequency chain. Simulation results show that to achieve the same tracking performance, the proposed algorithm requires much lower signal-to-noise ratio (SNR) and much fewer pilots than the other algorithm. Moreover, the change detection method can always detect abrupt changes with moderate number of pilots and SNR.","Array signal processing,
Receivers,
Channel estimation,
Kalman filters,
Transmitters,
Millimeter wave technology,
Change detection algorithms"
Subblock-Constrained Codes for Real-Time Simultaneous Energy and Information Transfer,"Consider an energy-harvesting receiver that uses the same received signal both for decoding information and for harvesting energy, which is employed to power its circuitry. In the scenario where the receiver has limited battery size, a signal with bursty energy content may cause power outage at the receiver, since the battery will drain during intervals with low signal energy. In this paper, we analyze subblock energy-constrained codes (SECCs), which ensure that sufficient energy is carried within every subblock duration. We consider discrete memoryless channels and characterize the SECC capacity and the SECC error exponent, and provide useful bounds for these values. We also study constant subblock-composition codes (CSCCs), which are a subclass of SECCs where all the subblocks in every codeword have the same fixed composition, and this subblock composition is chosen to maximize the rate of information transfer while meeting the energy requirement. Compared with constant composition codes (CCCs), we show that CSCCs incur a rate loss and that the error exponent for CSCCs is also related to the error exponent for CCCs by the same rate loss term. We exploit the symmetry in CSCCs to obtain a necessary and sufficient condition on the subblock length for avoiding power outage at the receiver. Furthermore, for CSCC sequences, we present a tight lower bound on the average energy per symbol within a sliding time window. We provide numerical examples highlighting the tradeoff between the delivery of sufficient energy to the receiver and achieving high information transfer rates. It is observed that the ability to use energy in real-time imposes less of penalty compared with the ability to use information in real-time.",
