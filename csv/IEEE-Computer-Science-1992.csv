Title,Abstract,Keywords
"Fuzzy basis functions, universal approximation, and orthogonal least-squares learning","Fuzzy systems are represented as series expansions of fuzzy basis functions which are algebraic superpositions of fuzzy membership functions. Using the Stone-Weierstrass theorem, it is proved that linear combinations of the fuzzy basis functions are capable of uniformly approximating any real continuous function on a compact set to arbitrary accuracy. Based on the fuzzy basis function representations, an orthogonal least-squares (OLS) learning algorithm is developed for designing fuzzy systems based on given input-output pairs; then, the OLS algorithm is used to select significant fuzzy basis functions which are used to construct the final fuzzy system. The fuzzy basis function expansion is used to approximate a controller for the nonlinear ball and beam system, and the simulation results show that the control performance is improved by incorporating some common-sense fuzzy control rules.",
Numerical potential field techniques for robot path planning,"An approach to robot path planning that consists of incrementally building a graph connecting the local minima of a potential field defined in the robot's configuration space and concurrently searching this graph until a goal configuration is attained is proposed. Unlike the so-called global path planning methods, this approach does not require an expensive computation step before the search for a path can actually start, and it searches a graph that is usually much smaller than the graph searched by the so-called local methods. A collection of effective techniques to implement this approach is described. They are based on the use of multiscale pyramids of bitmap arrays for representing both the robot's workspace and configuration space. This distributed representation makes it possible to construct potential fields numerically, rather than analytically. A path planner based on these techniques has been implemented. Experiments with this planner show that it is both very fast and capable of handling many degrees of freedom.",
Active Messages: A Mechanism for Integrated Communication and Computation,"The design challenge for large-scale multiprocessors is (1) to minimize communication overhead, (2) allow communication to overlap computation, and (3) coordinate the two without sacrificing processor cost/performance. We show that existing message passing multiprocessors have unnecessarily high communication costs. Research prototypes of message driven machines demonstrate low communication overhead, but poor processor cost/performance. We introduce a simple communication mechanism, Active Messages, show that it is intrinsic to both architectures, allows cost effective use of the hardware, and offers tremendous flexibility. Implementations on nCUBE/2 and CM-5 are described and evaluated using a split-phase shared-memory extension to C, Split-C. We further show that active messages are sufficient to implement the dynamically scheduled languages for which message driven machines were designed. With this mechanism, latency tolerance becomes a programming/compiling concern. Hardware support for active messages is desirable and we outline a range of enhancements to mainstream processors.",
Planning optimal grasps,The authors address the problem of planning optimal grasps. Two general optimality criteria that consider the total finger force and the maximum finger force are introduced and discussed. Their formalization using various metrics on a space of generalized forces is detailed. The geometric interpretation of the two criteria leads to an efficient planning algorithm. An example of its use in a robotic environment equipped with two-jaw and three-jaw is described.,"Grippers,
Robots,
Fingers,
Extraterrestrial measurements,
Orbital robotics,
Actuators,
Manipulators,
Grasping,
Assembly systems,
Computer science"
Relative neighborhood graphs and their relatives,"Results of neighborhood graphs are surveyed. Properties, bounds on the size, algorithms, and variants of the neighborhood graphs are discussed. Numerous applications including computational morphology, spatial analysis, pattern classification, and databases for computer vision are described.",
Spawn: a distributed computational economy,"The authors have designed and implemented an open, market-based computational system called Spawn. The Spawn system utilizes idle computational resources in a distributed network of heterogeneous computer workstations. It supports both coarse-grain concurrent applications and the remote execution of many independent tasks. Using concurrent Monte Carlo simulations as prototypical applications, the authors explore issues of fairness in resource distribution, currency as a form of priority, price equilibria, the dynamics of transients, and scaling to large systems. In addition to serving the practical goal of harnessing idle processor time in a computer network, Spawn has proven to be a valuable experimental workbench for studying computational markets and their dynamics.",
The detection of fault-prone programs,"The use of the statistical technique of discriminant analysis as a tool for the detection of fault-prone programs is explored. A principal-components procedure was employed to reduce simple multicollinear complexity metrics to uncorrelated measures on orthogonal complexity domains. These uncorrelated measures were then used to classify programs into alternate groups, depending on the metric values of the program. The criterion variable for group determination was a quality measure of faults or changes made to the programs. The discriminant analysis was conducted on two distinct data sets from large commercial systems. The basic discriminant model was constructed from deliberately biased data to magnify differences in metric values between the discriminant groups. The technique was successful in classifying programs with a relatively low error rate. While the use of linear regression models has produced models of limited value, this procedure shows great promise for use in the detection of program modules with potential for faults.",
Designing an on-demand multimedia service,"A quantitative study of techniques for designing a high-performance multiuser multimedia on-demand information service is presented. The problem of maintaining continuity of playback of each media stream in the presence of multiple subscriber requests is formulated, and admission control algorithms that permit a multimedia server to satisfy the maximum number of subscribers simultaneously are presented. A feedback technique in which a multimedia service uses lightweight messages called feedback units that are transmitted back to it by subscribers' mediaphones to detect asynchrony among them and steer them back to synchrony thereafter is presented. The feedback technique guarantees synchronous playback of media streams transmitted by the multimedia server to subscribers over metropolitan-area networks.",
An updating algorithm for subspace tracking,"In certain signal processing applications it is required to compute the null space of a matrix whose rows are samples of a signal with p components. The usual tool for doing this is the singular value decomposition. However, the singular value decomposition has the drawback that it requires O(p/sup 3/) operations to recompute when a new sample arrives. It is shown that a different decomposition, called the URV decomposition, is equally effective in exhibiting the null space and can be updated in O(p/sup 2/) time. The updating technique can be run on a linear array of p processors in O(p) time.",
Augmented reality: an application of heads-up display technology to manual manufacturing processes,"The authors describe the design and prototyping steps they have taken toward the implementation of a heads-up, see-through, head-mounted display (HUDset). Combined with head position sensing and a real world registration system, this technology allows a computer-produced diagram to be superimposed and stabilized on a specific position on a real-world object. Successful development of the HUDset technology will enable cost reductions and efficiency improvements in many of the human-involved operations in aircraft manufacturing, by eliminating templates, formboard diagrams, and other masking devices.",
Lazy Release Consistency for Software Distributed Shared Memory,"Relaxed memory consistency models, such as release consistency, were introduced in order to reduce the impact of re mote memory access latency in both software and hardware distributed shared memory (DSM). However, in a software DSM, it is also important to reduce the number of messages and the amount of data exchanged for remote memory access. Lazy release consistency is a new algorithm for implementing release consistency that lazily pulls modifications across the interconnect only when necessary. Trace- driven simulation using the SPLASH benchmarks indicates that lazy release consistency reduces both the number of messages and the amount of data transferred between processors. These reductions are especially significant for pro- grams that exhibit false sharing and make extensive use of locks.",
Performance of optical flow techniques,"The performance of six optical flow techniques is compared, emphasizing measurement accuracy. The most accurate methods are found to be the local differential approaches, where nu is computed explicitly in terms of a locally constant or linear model. Techniques using global smoothness constraints appear to produce visually attractive flow fields, but in general seem to be accurate enough for qualitative use only and insufficient as precursors to the computations of egomotion and 3D structures. It is found that some form of confidence measure/threshold is crucial for all techniques in order to separate the inaccurate from the accurate. Drawbacks of the six techniques are discussed.",
Main memory database systems: an overview,"Main memory database systems (MMDBs) store their data in main physical memory and provide very high-speed access. Conventional database systems are optimized for the particular characteristics of disk storage mechanisms. Memory resident systems, on the other hand, use different optimizations to structure and organize data, as well as to make it reliable. The authors survey the major memory residence optimizations and briefly discuss some of the MMDBs that have been designed or implemented.",
The performance of consistent checkpointing,"Consistent checkpointing provides transparent fault tolerance for long-running distributed applications. Performance measurements of an implementation of consistent checkpointing are described. The measurements show that consistent checkpointing performs remarkably well. Eight computation-intensive distributed applications were executed on a network of 16 diskless Sun-3/60 workstations, and the performance without checkpointing was compared to the performance with consistent checkpoints taken at two-minute intervals. For six of the eight applications, the running time increased by less than 1% as a result of the checkpointing. The highest overhead measured was 5.8%. Incremental checkpointing and copy-on write checkpointing were the most effective techniques in lowering the running time overhead. It is argued that these measurements show that consistent checkpointing is an efficient way to provide fault tolerance for long-running distributed applications.",
"Manetho: transparent roll back-recovery with low overhead, limited rollback, and fast output commit","Manetho is a new transparent rollback-recovery protocol for long-running distributed computations. It uses a novel combination of antecedence graph maintenance, uncoordinated checkpointing, and sender-based message logging. Manetho simultaneously achieves the advantages of pessimistic message logging, namely limited rollback and, fast output commit, and the advantage of optimistic message logging, namely low failure-free overhead. These advantages come at the expense of a complex recovery scheme.",
Proof verification and hardness of approximation problems,"The class PCP(f(n),g(n)) consists of all languages L for which there exists a polynomial-time probabilistic oracle machine that used O(f(n)) random bits, queries O(g(n)) bits of its oracle and behaves as follows: If x in L then there exists an oracle y such that the machine accepts for all random choices but if x not in L then for every oracle y the machine rejects with high probability. Arora and Safra (1992) characterized NP as PCP(log n, (loglogn)/sup O(1)/). The authors improve on their result by showing that NP=PCP(logn, 1). The result has the following consequences: (1) MAXSNP-hard problems (e.g. metric TSP, MAX-SAT, MAX-CUT) do not have polynomial time approximation schemes unless P=NP; and (2) for some epsilon >0 the size of the maximal clique in a graph cannot be approximated within a factor of n/sup epsilon / unless P=NP.",
Estimating the probability of failure when testing reveals no failures,"Formulas for estimating the probability of failure when testing reveals no errors are introduced. These formulas incorporate random testing results, information about the input distribution; and prior assumptions about the probability of failure of the software. The formulas are not restricted to equally likely input distributions, and the probability of failure estimate can be adjusted when assumptions about the input distribution change. The formulas are based on a discrete sample space statistical model of software and include Bayesian prior assumptions. Reusable software and software in life-critical applications are particularly appropriate candidates for this type of analysis.",
DDM-a cache-only memory architecture,"The Data Diffusion Machine (DDM), a cache-only memory architecture (COMA) that relies on a hierarchical network structure, is described. The key ideas behind DDM are introduced by describing a small machine, which could be a COMA on its own or a subsystem of a larger COMA, and its protocol. A large machine with hundreds of processors is also described. The DDM prototype project is discussed, and simulated performance results are presented.",
3-D surface description from binocular stereo,"A stereo vision system that attempts to achieve robustness with respect to scene characteristics, from textured outdoor scenes to environments composed of highly regular man-made objects is presented. It integrates area-based and feature-based primitives. The area-based processing provides a dense disparity map, and the feature-based processing provides an accurate location of discontinuities. An area-based cross correlation, an ordering constraint, and a weak surface smoothness assumption are used to produce an initial disparity map. This disparity map is only a blurred version of the true one because of the smoothing introduced by the cross correlation. The problem can be reduced by introducing edge information. The disparity map is smoothed and the unsupported points removed. This method gives an active role to edgels parallel to the epipolar lines, whereas they are discarded in most feature-based systems. Very good results have been obtained on complex scenes in different domains.",
Noniterative subspace tracking,"A rank-one spherical subspace update that is appropriate for subspace-based methods like MUSIC and minimum norm is introduced. This noniterative, highly parallel, numerically stabilized, subspace update is closely related to rank-one eigenstructure updating. However, a rank-one subspace update involves less computation than simple rank-one correlation accumulation. Moreover. The frequency tracking capabilities of the noniterative subspace update are virtually identical to and in some case more robust than the more computationally expensive eigen-based methods.",
Motion estimation from tagged MR image sequences,"A method for reconstructing motion from sequences of tagged magnetic resonance (MR) images is presented. MR tagging is used to create a spatial pattern of varying magnetization so that objects which may otherwise have constant intensity are textured, which reduces the motion ambiguity associated with the aperture problem in computer vision. To compensate for the decay of the tag pattern, a new optical flow algorithm is developed and implemented. The resulting estimated velocity field is then used to recursively update the implied motion reference map over time, thereby tracking the motion of individual particles. If a segmentation of the object is known at the time the tag pattern is created, then an object may be selectively tracked, using the estimated reference map to update the object's position as time progresses. Results are shown for both simulated and actual MR phantom data.",
Optimization neural networks for the segmentation of magnetic resonance images,The application of the Hopfield neural network for the multispectral unsupervised classification of MR images is reported. Winner-take-all neurons were used to obtain a crisp classification map using proton density-weighted and T/sub 2/-weighted images in the head. The preliminary studies indicate that the number of iterations needed to reach 'good' solutions was nearly constant with the number of clusters chosen for the problem.,
Structural testing of concurrent programs,"Although structural testing techniques are among the weakest available with regard to developing confidence in sequential programs, they are not without merit. The authors extend the notion of structural testing criteria to concurrent programs and propose a hierarchy of supporting structural testing techniques. Coverage criteria described include concurrency state coverage, state transition coverage and synchronization coverage. Requisite support tools include a static concurrency analyzer and either a program transformation system or a powerful run-time monitor. Also helpful is a controllable run-time scheduler. The techniques proposed are suitable for Ada or CSP-like languages. Best results are obtained for programs having only static naming of tasking objects.",
Alias-free generalized discrete-time time-frequency distributions,"A definition of generalized discrete-time time-frequency distribution that utilizes all of the outer product terms from a data sequence, so that one can avoid aliasing, is introduced. The new approach provides (1) proper implementation of the discrete-time spectrogram, (2) correct evaluation of the instantaneous frequency of the underlying continuous-time signal, and (3) correct frequency marginal. The formulation provides a unified framework for implementing members of Cohen's class, which was formulated in the continuous-time domain. Some requirements for the discrete-time kernel in the new approach are discussed in association with desirable distribution properties. Some experimental results are provided to illustrate the features of the proposed method.",
Managing bandwidth in ATM networks with bursty traffic,"Three approaches to the bandwidth management problem that have been proposed and studied by various groups are reviewed to illustrate three distinctly different approaches and identify their strengths and weaknesses. Based on these approaches, a bandwidth management and congestion control scheme for asynchronous transfer mode (ATM) networks that supports both point-to-point and one-to-many multicast virtual circuits is proposed. It is shown that the method can handle fully heterogeneous traffic and can be effectively implemented. The algorithm for making virtual circuit acceptance decisions is straightforward and fast, and the hardware mechanisms needed to implement buffer allocation and traffic monitoring at the user-network interface have acceptable complexities. It is also shown, through numerical examples, that the approach can achieve reasonable link efficiencies even in the presence of very bursty traffic. No advance reservation required, simplifying the interface between the network and the user and avoiding an initial network round trip delay before data can be transmitted.","Bandwidth,
Intelligent networks,
Telecommunication traffic,
Traffic control,
Circuits,
Asynchronous transfer mode,
Computer network management,
Computer science,
National electric code,
Resource management"
Symbolic model checking for real-time systems,"Finite-state programs over real-numbered time in a guarded-command language with real-valued clocks are described. Model checking answers the question of which states of a real-time program satisfy a branching-time specification. An algorithm that computes this set of states symbolically as a fixpoint of a functional on state predicates, without constructing the state space, is given.",
The grid protocol: a high performance scheme for maintaining replicated data,"A new protocol for maintaining replicated data that can provide both high data availability and low response time is presented. In the protocol, the nodes are organized in a logical grid. Existing protocols are designed primarily to achieve high availability by updating a large fraction of the copies, which provides some (although not significant) load sharing. In the new protocol, transaction processing is shared effectively among nodes storing copies of the data, and both the response time experienced by transactions and the system throughput are improved significantly. The authors analyze the availability of the new protocol and use simulation to study the effect of load sharing on the response time of transactions. They also compare the new protocol with a voting-based scheme.",
A cognitive-map-based approach to the coordination of distributed cooperative agents,"A partial taxonomy for cognitive maps is provided. The notions of NPN (negative-positive-neural) logic, NPN relations, coupled-type neurons, and coupled-type neural networks are introduced and used as a framework for cognitive map modeling. D-POOL a cognitive-map-based architecture for the coordination of distributed cooperative agents, is presented. D-POOL consists of a collection of distributed nodes. Each node is a cognitive-map-based metalevel system coupled with a local expert/database system (or agent). To solve a problem, a local node first pools cognitive maps from relevant agents in an NPN relation that retains both negative and positive assertions. New cognitive maps are then derived and focuses of attentions are generated. With the focuses, a solution is proposed by the local node and passed to the remote systems. The remote systems respond to the proposal, and D-POOL strives for a cooperative or compromised solution through coherent communication and perspective sharing. The utility of D-POOL is demonstrated using two examples in distributed group decision support.",
A portable multimedia terminal,"A personal communications system (PCS) that centers on integration of services to provide access to data and communications using a specialized, wireless multimedia terminal is described. The possible applications and support systems for such a terminal are outlined. Several of the major design issues behind portable multimedia terminals, including spectrally efficient picocellular networking, low-power digital design, video data compression, and integrated wireless RF transceivers, are discussed. It is argued that optimizing performance in each of these areas is crucial in meeting the performance requirements of the overall system and providing a small, lightweight terminal for personal communications.",
Construction of asymptotically good low-rate error-correcting codes through pseudo-random graphs,"A novel technique, based on the pseudo-random properties of certain graphs known as expanders, is used to obtain novel simple explicit constructions of asymptotically good codes. In one of the constructions, the expanders are used to enhance Justesen codes by replicating, shuffling, and then regrouping the code coordinates. For any fixed (small) rate, and for a sufficiently large alphabet, the codes thus obtained lie above the Zyablov bound. Using these codes as outer codes in a concatenated scheme, a second asymptotic good construction is obtained which applies to small alphabets (say, GF(2)) as well. Although these concatenated codes lie below the Zyablov bound, they are still superior to previously known explicit constructions in the zero-rate neighborhood.<>","Error correction codes,
Concatenated codes,
Graph theory,
Information theory,
Mathematics,
Computer science,
Encoding,
Reed-Solomon codes"
Global optimization of a neural network-hidden Markov model hybrid,"The integration of multilayered and recurrent artificial neural networks (ANNs) with hidden Markov models (HMMs) is addressed. ANNs are suitable for approximating functions that compute new acoustic parameters, whereas HMMs have been proven successful at modeling the temporal structure of the speech signal. In the approach described, the ANN outputs constitute the sequence of observation vectors for the HMM. An algorithm is proposed for global optimization of all the parameters. Results on speaker-independent recognition experiments using this integrated ANN-HMM system on the TIMIT continuous speech database are reported.","Neural networks,
Hidden Markov models,
Artificial neural networks,
Computer science,
Speech analysis,
Automatic speech recognition,
Intelligent robots,
Parameter estimation,
Speech recognition,
Multi-layer neural network"
T: A Multithreaded Massively Parallel Architecture,"What should the architecture of each node in a general purpose, massively parallel architecture (MPA) be? We frame the question in concrete terms by describing two fundamental problems that must be solved well in any general purpose MPA. From this, we systematically develop the required logical organization of an MPA node, and present some details of *T (pronounced Start), a concrete architecture designed to these requirements. *T is a direct descendant of dynamic dataflow architectures, and unifies them with von Neumann architectures. We discuss a hand-compiled example and some compilation issues.",
An approach to regression testing using slicing,"The authors present a novel approach to data-flow-based regression testing that uses slicing type algorithms to explicitly detect definition-use pairs that are affected by a program change. An important benefit of the slicing technique is that, unlike previous techniques, no data flow history is needed nor is the recomputation of data flow for the entire program required to detect affected definition-use pairs. The program changes drive the recomputation of the required partial data flow through slicing. Another advantage is that the proposed technique achieves the same testing coverage as a complete retest of the program without the need for maintaining and updating a test suite.",
Communicating real-time state machines,"Communicating real-time state machines (CRSMs), a complete and executable notation for specifying concurrent real-time systems including the monitored and controlled physical environment, are introduced. They are essentially state machines that communicate synchronously in a manner much like the input-output in Hoare's CSP. In addition, CRSMs have a novel and small set of facilities for describing timing properties and accessing real time. The author defines the CRSM language, gives many examples of its use in requirements specification, outlines an algorithm for executing or simulating CRSMs, introduces some techniques for reasoning about the specifications, and discusses some open problems and issues.",
On updating signal subspaces,"The authors develop an algorithm for adaptively estimating the noise subspace of a data matrix, as is required in signal processing applications employing the 'signal subspace' approach. The noise subspace is estimated using a rank-revealing QR factorization instead of the more expensive singular value or eigenvalue decompositions. Using incremental condition estimation to monitor the smallest singular values of triangular matrices, the authors can update the rank-revealing triangular factorization inexpensively when new rows are added and old rows are deleted. Experiments demonstrate that the new approach usually requires O(n/sup 2/) work to update an n*n matrix, and that it accurately tracks the noise subspace.",
Fuzzy Kohonen clustering networks,"The authors propose a fuzzy Kohonen clustering network which integrates the fuzzy c-means (FCM) model into the learning rate and updating strategies of the Kohonen network. This yields an optimization problem related to FCM, and the numerical results show improved convergence as well as reduced labeling errors. It is proved that the proposed scheme is equivalent to the c-means algorithms. The new method can be viewed as a Kohonen type of FCM, but it is self-organizing, since the size of the update neighborhood and the learning rate in the competitive layer are automatically adjusted during learning. Anderson's IRIS data were used to illustrate this method. The results are compared with the standard Kohonen approach.","Convergence of numerical methods,
Labeling,
Iris"
Characteristics of spontaneous electrical discharging of various insulators in space radiations,"Sixteen samples of standard insulating materials with electrodes were exposed to the full variety of the earth's space radiation belts on the CRRES (Combined Release and Radiation Effects Satellite) for 14 months. Spontaneous discharges were recorded for each sample and were compared to the radiation levels, which were simultaneously monitored. Samples with the most exposed insulator surface (not metallized) pulsed most frequently. Most of the pulses were less than 50 V on 50 Omega . Pulsing correlated weakly with electron flux, but no correlation with proton flux could be discerned. The pulse rate per unit electron flux was initially small, rose continuously for seven months, and then fell slightly during the last seven months. The pulsing rate decayed when the satellite left the electron belts. The decay became more rapid after seven months. There seem to be two kinds of pulses which exhibit differing statistics. One kind dominated during the first seven months, the other during the last seven months. This may be related to the fact that it took several months for electric fields in the samples to approach steady-state levels. A computer simulation predicts the temporal charging of the insulators by the high-energy electron flux.","Electrons,
Insulation,
Belts,
Satellites,
Electrodes,
Earth,
Radiation effects,
Radiation monitoring,
Surface discharges,
Metallization"
Multicasting for multimedia applications,"The authors investigate multicast routing for high-bandwidth delay-sensitive applications in a point-to-point network as an optimization problem. They associate an edge cost and an edge delay with each edge in the network. The problem is to construct a tree spanning the destination nodes, such that it has the least cost, and so that the delay on the path from the source to each destination is bounded. Since the problem is computationally intractable, the authors present an efficient approximation algorithm. Experimental results through simulations show that the performance of the heuristic is near optimal.",
An efficient implementation of Boolean functions as self-timed circuits,"The authors propose a general synthesis method for efficiently implementing any family of Boolean functions over a set of variables, as a self-timed logic module. Interval temporal logic is used to express the constraints that are formulated for the self-timed logic module. A method is provided for proving the correct behavior of the designed circuit, by showing that it obeys all the functional constraints. The resulting circuit is compared with alternative proposed self-timed methodologies. This approach is shown to require less gates than other methods. The proposed method is appropriate for automatic synthesis of self-timed systems. A formal proof of correctness is provided.",
Learning with limited numerical precision using the cascade-correlation algorithm,"A key question in the design of specialized hardware for simulation of neural networks is whether fixed-point arithmetic of limited numerical precision can be used with existing learning algorithms. An empirical study of the effects of limited precision in cascade-correlation networks on three different learning problems is presented. It is shown that learning can fail abruptly as the precision of network weights or weight-update calculations is reduced below a certain level, typically about 13 bits including the sign. Techniques for dynamic rescaling and probabilistic rounding that allow reliable convergence down to 7 bits of precision or less, with only a small and gradual reduction in the quality of the solutions, are introduced.","Neural networks,
Algorithm design and analysis,
Neural network hardware,
Computational modeling,
Computer networks,
Predictive models,
Computer science,
Arithmetic,
Computer architecture,
Computer simulation"
Derivation of phase statistics from the Mueller matrix,"To answer the question of what radar polarimetry has to offer to the remote sensing of random media, statistics of the phase difference of the scattering matrix elements must be studied. Recent polarimetric measurements of rough surfaces have indicated that the statistical parameters of the phase difference (mean, standard deviation, etc.) are very sensitive to some of the physical parameters. In this paper the probability density function of the phase differences is derived from the Mueller matrix, assuming that the elements of the scattering matrix are jointly Gaussian. It is shown that the probability density functions of the copolarized and cross-polarized phase differences are similar in form, and each can be determined by two parameters (α and ζ) completely. The expressions for the probability density functions are verified by comparing the histograms, the mean, and the standard deviations of phase differences derived directly from polarimetric measurements of a variety of rough surfaces to the probability density function, its mean, and standard deviation derived from the Mueller matrices of the same data. The expressions for the probability density functions are of special interest for noncoherent polarimetric radars and noncoherent polarimetric models for random media such as vector radiative transfer.","Covariance matrices,
Phase measurement,
Radar scattering,
Soil measurements,
Radar polarimetry,
Radar measurements"
Probabilistic checking of proofs; a new characterization of NP,"The authors give a new characterization of NP: the class NP contains exactly those languages L for which membership proofs (a proof that an input x is in L) can be verified probabilistically in polynomial time using logarithmic number of random bits and sub-logarithmic number of queries to the proof. This is a non-relativizing characterization of NP. They discuss implications of this characterization; specifically, they show that approximating clique (or independent set) is NP-hard.",
Specification-based test oracles for reactive systems,"The testing process is typically systematic in test data se- lection and test execution. For the most part, however, the effective use of test oracles has been neglected, even though they are a critical component of the testing process. Test or- acles prescribe acceptable behavior for test execution. In the absence of judging test results with formal oracles, testing does not achieve its goal of revealing failures or assuring cor- rect behavior in a practical manner; manual result checking is neither reliable nor cost-effective. We argue that test oracles should be derived from specifications in conjunction with testing criteria, represented in a common form, and their use made integral to the test- ing process. For complex, reactive systems, oracles must reflect the multiparadigm nature of the required behavior. Such systems are often specified using multiple languages, each selected for its utility specifying in a particular computational paradigm. Thus, we are developing an approach for deriving and using oracles based on multiparadigm and multilingual specifications to enable the verification of test results for reactive systems as well as less complex systems.",
Some defects in finite-difference edge finders,"This work illustrates and explains various artifacts in the output of five finite difference edge finders, those of J.F. Canny (1983, 1986), R.A. Boie et al. (1986) and R.A. Boie and I.J. Cox (1987), and three variations on that of D. Marr and E.C. Hildreth (1980), reimplemented with a common output format and method of noise suppression. These artifacts include gaps in boundaries, spurious boundaries, and deformation of region shape.","Finite difference methods,
Topology,
Shape,
Laplace equations,
Noise shaping,
Algorithm design and analysis,
Petroleum,
Computer science,
Cities and towns,
Uncertainty"
Distributed constraint satisfaction for formalizing distributed problem solving,"Viewing cooperative distributed problem solving (CDPS) as distributed constraint satisfaction provides a useful formalism for characterizing CDPS techniques. This formalism and algorithms for solving distributed constraint satisfaction problems (DCSPs) are compared. A technique called asynchronous backtracking that allows agents to act asynchronously and concurrently, in contrast to the traditional sequential backtracking techniques used in constraint satisfaction problems, is presented. Experimental results show that solving DCSPs in a distributed fashion is worthwhile when the problems solved by individual agents are loosely coupled.",
The power test for data dependence,"A data dependence decision algorithm called the power test is introduced. The power test is a combination of the extended GCD algorithm and the Fourier-Motzkin method to eliminate variables in a system of inequalities. This is the first test that can generate the information needed for some advanced transformations, and that can handle complex simultaneous loop limits. Previous work in data dependence decision algorithms is reviewed. Some examples which motivated the development of this test are examined, including those which demonstrate the additional power of the power test. Although it may be too expensive for use as a general-purpose dependence test in a compiler, the power test has proved useful in an interactive program restructuring environment.",
Protocol conformance testing using multiple UIO sequences,"Automatic generation of conformance test sequences for communication protocols by means of unique input/output (UIO) sequences is addressed. It is shown that if multiple minimum-length UIO sequences are computed for each state of the finite-state-machine (FSM) specification, then the length of the resulting test sequence is significantly reduced without an appreciable increase in the time needed to compute the sequence. An algorithm for assignment of the multiple UIO sequences is given. This algorithm, which is based on network flow, is polynomial in the number of states and transitions of the FSM and is effective in reducing the overall length of the test sequence.",
Correction of distortion in endoscope images,"Images formed with endoscopes suffer from a spatial distortion due to the wide-angle nature of the endoscope's objective lens. This change in the size of objects with position precludes quantitative measurement of the area of the objects, which is important in endoscopy for accurately measuring ulcer and lesion sizes over time. A method for correcting the distortion characteristic of endoscope images is presented. A polynomial correction formula was developed for the endoscope lens and validated by comparing quantitative test areas before and after the distortion correction. The distortion correction has been incorporated into a computer program that could readily be applied to electronic images obtained at endoscopy using a desk-top computer. The research presented here is a key step towards the quantitative determination of the area of regions of interest in endoscopy.",
Partitioned Register Files For VLIWs: A Preliminary Analysis Of Tradeoffs,,
Optimal synchronous capacity allocation for hard real-time communications with the timed token protocol,"The authors study the problem of transmitting synchronous messages before their deadlines in communication networks where the timed token medium access control protocol is employed. Synchronous capacity, defined as the maximum time for which a node can transmit its synchronous message every time it receives the token, is a key parameter in the control of synchronous message transmission. To ensure the transmission of synchronous messages before their deadlines, synchronous capacities must be property allocated to individual nodes. The authors develop and analyze an optimal synchronous capacity allocation scheme. An optimal scheme can allocate the synchronous capacities in such a way that the synchronous message deadlines are guaranteed if there exists any allocation scheme that can do so. The optimality of the allocation scheme proposed here is formally proved, and the bounds for its worst case achievable utilization are derived.",
"GENOA - A Customizable, Language- And Front-end Independent Code Analyzer","Programmers working on large software systems spend a great deal of time examining code and trying to understand it. Code Analysis tools (e.g., cross referencing tools such as CIA and Cscope) can be very helpful in this process. In this paper we describe GENOA, an application generator that can produce a whole range of useful code analysis tools. GENOA is designed to be language- and front-end independent; it can be interfaced to any front-end for any language that produces an attributed parse tree, simply by writing an interface spec- ification. While GENOA programs can perform arbitrary analyses on the parse tree, the GENOA language has special, compact iteration operators that are tuned for expressing simple, polynomial time analysis programs; in fact, there is a useful sublanguage of GENOA that can express precisely all (and only) polynomial time (PTIME) analysis prograrns on parse-trees. Thus, we argue that GENOA is a convenient ""little language"" to implement simple, fast analysis tools. We describe the system, provide several practical examples, and present complexity and expressivity results for the abovementioned sublanguage of GENOA.","Programming profession,
Performance analysis,
Computer languages,
Costs,
Software systems,
Data mining,
Writing,
Polynomials,
Information systems,
Computer science"
Simplifying Neural Networks by Soft Weight-Sharing,"One way of simplifying neural networks so they generalize better is to add an extra term to the error function that will penalize complexity. Simple versions of this approach include penalizing the sum of the squares of the weights or penalizing the number of nonzero weights. We propose a more complicated penalty term in which the distribution of weight values is modeled as a mixture of multiple gaussians. A set of weights is simple if the weights have high probability density under the mixture model. This can be achieved by clustering the weights into subsets with the weights in each cluster having very similar values. Since we do not know the appropriate means or variances of the clusters in advance, we allow the parameters of the mixture model to adapt at the same time as the network learns. Simulations on two different problems demonstrate that this complexity term is more effective than previous complexity terms.",
An efficient algorithm for finding all solutions of piecewise-linear resistive circuits,"An efficient algorithm for finding all solutions of piecewise-linear resistive circuits is presented. First, a technique that substantially reduces the number of function evaluations needed in the piecewise-linear modeling process is proposed. Then a simple and efficient sign test is proposed that remarkably reduces the number of linear simultaneous equations to be solved for finding all solutions. An effective technique that makes the sign test even more efficient is introduced. All of the techniques exploit the separability of nonlinear mappings. Some numerical examples are given, and it is shown that all solutions are computed rapidly. The algorithm is simple and efficient, and can be easily programmed.",
Scheduling distance-constrained real-time tasks,"A novel model of real-time task systems with temporal distance constraints is presented. In such systems, the distance between any two consecutive finishing times of the same task must be less than or equal to a given value. Using the periodic task model for such tasks may not provide an efficient solution. The authors discuss the scheduling approaches for this distance-constrained task model and propose several scheduling algorithms. They also study the schedulability conditions for these algorithms.",
Now the learning curve affects CASE tool adoption,"Part of adopting an industrial process is to go through a learning curve that measures the rate at which the average unit cost of production decreases as the cumulative amount produced increases. It is argued that organizations buy integrated CASE tools only to leave them on the shelf because they misinterpret the learning curve and its effect on productivity. It is shown that learning-curve models can quantitatively document the productivity effect of integrated CASE tools by factoring out the learning costs so that managers can use model results to estimate future projects with greater accuracy. Without this depth of understanding, managers are likely to make less-than-optimal decisions about integrated CASE and may abandon the technology too soon. The influence of learning curves on CASE tools and the adaptation of learning-curve models to integrate CASE are discussed. The three biggest tasks in the implementation of learning-curves in integrated CASE settings, locating a suitable data site, collecting the data, and validating the results, are also discussed.",
Specification partitioning for system design,"The authors focus on the goal of partitioning a behavior to satisfy chip-capacity constraints while considering system-performance constraints. A hardware implementation is assumed with a uniform chip technology. A new approach is introduced which partitions entire computations of a behavioral specification, such as processes and procedures, into chip behavioral specifications. The usefulness of the approach was demonstrated. The results of partitioning several examples using the specification partitioning tool being developed are provided.",
Performance evaluation of scene registration and stereo matching for cartographic feature extraction,"Three major areas in the development of competent 3-D scene interpretation system are discussed. First, the importance of accurate automatic scene registration and the difficulty in automated extraction and matching of scene reference points are described. Second, the authors describe two stereo matching algorithms, S1, which is an area-based matcher previously used in the SPAM system, and S2, which is a feature-based matching algorithm based on hierarchical waveform matching. Third, the authors introduce several performance evaluation metrics that made it possible to measure the quality of the overall scene recovery, the building disparity estimate, and the quality and sharpness of the building delineations. Such manually generated scene reference models are critical for understanding strengths and weaknesses of various matching algorithms and in the incremental development of improvements to existing algorithms. Experiments were performed on difficult examples of aerial imagery.",
A sequential algorithm for the universal coding of finite memory sources,"The estimation and universal compression of discrete sources are considered, and a sequential algorithm for the universal coding of finite memory sources, attaining asymptotically minimum redundancy, is presented. The algorithm performs an online estimation of the source states and uses an arithmetic code.",
General schedulers for the pinwheel problem based on double-integer reduction,"The pinwheel is a hard-real-time scheduling problem for scheduling satellite ground stations to service a number of satellites without data loss. Given a multiset of positive integers (instance) A=(a/sub 1/, . . . a/sub n/), the problem is to find an infinite sequence (schedule) of symbols from (1,2, . . . n) such that there is at least one symbol i within any interval of a/sub i/ symbols (slots). Not all instances A can be scheduled; for example, no 'successful' schedule exists for instances whose density is larger than 1. It has been shown that any instance whose density is less than 2/3 can always be scheduled. Two new schedulers are proposed which improve this 2/3 result to a new 0.7 density threshold. These two schedulers can be viewed as a generalization of the previously known schedulers, i.e. they can handle a larger class of pinwheel instances including all instances schedulable by the previously known techniques.",
Training recurrent networks using the extended Kalman filter,"The author describes some relationships between the extended Kalman filter (EKF) as applied to recurrent net learning and some simpler techniques that are more widely used. In particular, making certain simplifications to the EKF gives rise to an algorithm essentially identical to the real-time recurrent learning (RTRL) algorithm. Since the EKF involves adjusting unit activity in the network, it also provides a principled generalization of the teacher forcing technique. Preliminary simulation experiments on simple finite-state Boolean tasks indicated that the EKF can provide substantial speed-up in number of time steps required for training on such problems when compared with simpler online gradient algorithms. The computational requirements of the EKF are steep, but scale with network size at the same rate as RTRL.",
Incremental Testing Of Object-Oriented Class Structures/spl dagger/,"Although there is much interest in creating libraries of well-designed, thoroughly-tested classes that can be confi- dently reused for many applications, few class testing techniques have been developed. In this paper, we present a class testing technique that exploits the hierarchical nature of the inheritance relation to test related groups of classes by reusing the testing information for a parent class to guide the testing of a subclass. We initially test base classes having no parents by designing a test suite that tests each memberfunction individually and also tests the interactions among member functions. To design a test suite for a subclass, our algorithm incrementally updates the history of its parent to reflect both the modified, inherited attributes and the subclass's newly defined attributes. Only those new attributes or affected, inherited attributes are tested and the parent class test suites are reused, if possible, for the testing. Inherited attributes are retested in their new context in a subclass by testing their interactions with the subclass's newly defined attributes. We have incorporated a data flow tester into Free Software Foundation, Inc's C++ compiler and are using it for our experimentation.",
Predictive modeling techniques of software quality from software measures,"The objective in the construction of models of software quality is to use measures that may be obtained relatively early in the software development life cycle to provide reasonable initial estimates of the quality of an evolving software system. Measures of software quality and software complexity to be used in this modeling process exhibit systematic departures of the normality assumptions of regression modeling. Two new estimation procedures are introduced, and their performances in the modeling of software quality from software complexity in terms of the predictive quality and the quality of fit are compared with those of the more traditional least squares and least absolute value estimation techniques. The two new estimation techniques did produce regression models with better quality of fit and predictive quality when applied to data obtained from two software development projects.",
Algorithms for interface timing verification,"Algorithms for analyzing systems of inequalities with min/max constraints that arise in interface timing specifications are examined. A general form of the inequality is shown to be NP-complete, but some interesting special cases can be solved efficiently. A branch-and-bound solution to the general case is developed and applied to a previously published example.",
A comparison of software defects in database management systems and operating systems,"An analysis of software defects reported at customer sites in two large IBM database management products, DB2 and IMS, is presented. The analysis considers several different error classification systems and compares the results to those of an earlier study of field defects in IBM's MVS operating system. The authors compare the error type, defect type, and error trigger distributions of the DB2, IMS, and MVS products; show that there may exist an asymptotic behavior in the error type distribution as a function of a defect type; and discuss the undefined state errors that dominate the error type distribution.",
"Adiabatic Switching, Low Energy Computing, And The Physics Of Storing And Erasing Information",,
Adaptive boundary detection using 'live-wire' two-dimensional dynamic programming,"An adaptive boundary detection algorithm that uses two-dimensional dynamic programming (DP) is presented. The algorithm is less constrained than previous one-dimensional dynamic programming algorithms and allows the user to interactively determine the mathematically optimal boundary between a user-selected seed point and any other dynamically selected free point in the image. Interactive movement of the free point by the cursor causes the boundary to behave like a live wire as it adapts to the new minimum cost path between the seed point and the currently selected free point. The algorithm can also be adapted or customized to learn boundary-defining features for a particular class of images. Adaptive 2-D DP performs well on a variety of images. It accurately detects the boundaries of low contrast objects, which occur with intravenous injections, as well as those found in noisy, low SNR images.",
Identifiability of hidden Markov information sources and their minimum degrees of freedom,"If only a function of the state in a finite-state Markov chain is observed, then the stochastic process is no longer Markovian in general. This type of information source is found widely and the basic problem of its identifiability remains open, that is, the problem of showing when two different Markov chains generate the same stochastic process. The identifiability problem is completely solved by linear algebra, where a block structure of a Markov transition matrix plays a fundamental role, and from which the minimum degree of freedom for a source is revealed.<>",
Fundamentals of deductive program synthesis,"An informal tutorial for program synthesis is presented, with an emphasis on deductive methods. According to this approach, to construct a program meeting a given specification, the authors prove the existence of an object meeting the specified conditions. The proof is restricted to be sufficiently constructive, in the sense that, in establishing the existence of the desired output, the proof is forced to indicate a computational method for finding it. That method becomes the basis for a program that can be extracted from the proof. The exposition is based on the deductive-tableau system, a theorem-proving framework particularly suitable for program synthesis. The system includes a nonclausal resolution rule, facilities for reasoning about equality, and a well-founded induction rule.",
Efficient two-dimensional compressed matching,"Digitized images are known to be extremely space consuming. However, regularities in the images can often be exploited to reduce the necessary storage area. Thus, many systems store images in a compressed form. The authors propose that compression be used as a time saving tool, in addition to its traditional role of space saving. They introduce a new pattern matching paradigm, compressed matching. A text array T and pattern array P are given in compressed forms c(T) and c(P). They seek all appearances of P in T, without decompressing T. This achieves a search time that is sublinear in the size of the uncompressed text mod T mod . They show that for the two-dimensional run-length compression there is a O( mod c(T) mod log mod P mod + mod P mod ), or almost optimal algorithm. The algorithm uses a novel multidimensional pattern matching technique, two-dimensional periodicity analysis.",
Synthetic traces for trace-driven simulation of cache memories,"Two techniques for producing synthetic address traces that produce good emulations of the locality of reference of real programs are presented. The first algorithm generates synthetic addresses by simulating a random walk in an infinite address-space with references governed by a hyperbolic probability law. The second algorithm is a refinement of the first in which the address space has a given finite size. The basic model for the random walk has two parameters that correspond to the working set size and the locality of reference. By comparing synthetic traces with real traces of identical locality parameters, it is demonstrated that synthetic traces exhibit miss ratios and lifetime functions that compare well with those of the real traces they mimic, both in fully associative and in set-associative memories.",
Robust detection of facial features by generalized symmetry,Locating facial features is crucial for various face recognition schemes. The authors suggest a robust facial feature detector based on a generalized symmetry interest operator. No special tuning is required if the face occupies 15-60% of the image. The operator was tested on a large face data base with a success rate of over 95%.,
"Adaptive meshes and shells: irregular triangulation, discontinuities, and hierarchical subdivision",The adaptive mesh model is extended in several ways. Open adaptive meshes and closed adaptive shells based on triangular and rectangular elements are developed. A discontinuity detection and preservation algorithm suitable for the model is proposed. Techniques for adaptive hierarchical subdivision of adaptive meshes and shells are also developed. The extended model is applied to image and 3D surface data.,
Consensus diagnosis: a simulation study,"Consensus diagnoses arise when several experts contribute their opinions about the relative merits of a series of competing hypothesis, and a single decision maker combines their responses and makes a decision without further discussion among the contributors. Consensus diagnoses were simulated by allowing an oracle to generate 'opinions' based on universal background knowledge and all available information about the specific problem being diagnosed. Contributors' opinions were generated by perturbing the oracle's opinion; the size of the perturbation depended on the contributor's degree of expertise. Several different aggregation functions were then used to reclaim the oracle's opinion from those of the contributors. The performance of these functions was compared as panel size and hypothesis-set size varied from two to ten. Comparative and individual analyses indicated that for panels assembled under circumstances similar to those of this study, small, simple methods work best.",
Posing polygonal objects in the plane by pushing,"The authors study the use of pushing actions with a fence to orient and translate objects in the plane. They describe a planner which a guaranteed to construct a sequence of pushing actions to move any polygonal object from any initial configuration to any final configuration. This planner, which utilizes an analysis of the mechanics of pushing an object, generates open-loop plans which do not require feedback sensing. These plans are guaranteed to succeed provided certain physical assumptions are met. Results of experiments conducted to demonstrate the generated plans are presented.","Grippers,
Stability analysis,
Robots,
Feedback loop,
Testing,
Computer science"
Discretized estimator learning automata,"The improvements gained by rendering the various estimator learning algorithms discrete are investigated. This is done by restricting the probability of selecting an action to a finite discrete subset of (0, 1). This modification is proven to be epsilon -optimal in all stationary environments. Various discretized estimator algorithms (DEAs) are constructed. Subsequently, members of the family of DEAs are shown to be epsilon -optimal by deriving two sufficient conditions required for the epsilon -optimality-the properties of monotonicity and moderation. A conjecture about the necessity of these conditions for epsilon -optimality is presented. Experimental results indicate that the discrete modifications improve the performance of the algorithms so that the automata constitute fast-converging and accurate learning automata.","Learning automata,
Stochastic processes,
Feedback,
Computer science,
Cybernetics,
Councils,
Drives,
Biological system modeling,
Probability distribution"
Associative processors and memories: a survey,"The functional structure of a classical content-addressable memory (CAM) and its realization at the transistor level are described. Some unorthodox CAM approaches are briefly examined. Associative processor systems are discussed, and application-specific CAM architectures to support artificial intelligence features are surveyed. Limitations of associative processing and ways to circumvent them are addressed. The use of parallel cellular logic is considered.",
An application of functional dependencies to the topological analysis of protection schemes,"The concept of functional dependency is applied to the problem of relay coordination in protection systems. An algorithm is developed for the identification of a minimal break point set (BPS) of relays of a protection topology. This algorithm is an improvement over existing algorithms in that it identifies a minimal BPS within a time period that is a polynomial function of the number of relays, while the earlier algorithms had exponential time behavior. In the case of large protection schemes, the saving in computation costs is considerable. An algorithm is developed for the selection of a relative sequence matrix; this algorithm also has polynomial time complexity. The functional dependency approach is seen to be more flexible and more powerful than the graph theoretic schemes, and holds out much promise for the development of efficient computer-aided design tools for the protection engineer.",
Using skeletons for nonholonomic path planning among obstacles,"The authors describe a practical path planner for nonholonomic robots in environments with obstacles. The planner is based on building a one-dimensional, maximal clearance skeleton through the configuration space of the robot. Rather than using the Euclidean metric to determine clearance, a special metric which captures information about the nonholonomy of the robot is used. The robot navigates from start to goal states by loosely following the skeleton. The resulting paths taken by the robot are of low complexity. Much of the computation can be done offline for a given robot, making for an efficient planner. The focus is on path planning for mobile robots, particularly the planar two-axle car, but the underlying ideas may be applied to planners for other nonholonomic robots.",
Scheduling sporadic tasks with shared resources in hard-real-time systems,"The problem of scheduling a set of sporadic tasks that share a set of serially reusable, single unit software resources on a single processor is considered. The correctness conditions are that: each invocation of each task completes execution at or before a well-defined deadline; and a resource is never accessed by more than one task simultaneously. An optimal online algorithm for scheduling a set of sporadic tasks is presented. The algorithm results from the integration of a synchronization scheme for access to shared resources with the earliest deadline first algorithm. A set of relations on task parameters that are necessary and sufficient for a set of tasks to be schedulable is also derived. The proposed model for the analysis of processor scheduling policies is novel in that it incorporates minimum as well as maximum processing time requirements of tasks. The scheduling algorithm and the sporadic tasking model have been incorporated into an operating system kernel and used to implement several real-time systems.",
Advanced control rooms and crew performance issues: implications for human reliability,"Recent trends in advanced control room (ACR) design are considered with respect to their impact on operating crew performance and human reliability. Related to ACR evolution is the wide range of technological approaches to human-system interfaces (HSI). Precursors are considered with respect to the ACR trends identified which are automation and KSI design. While ACR design may impact human performance and human error, the effect of human error on plant safety must be evaluated. The difficulties of quantifying this relationship are addressed. Several issues impacting the conduct of human reliability analysis for advanced reactors are considered.","Humans,
Computer displays,
Large screen displays,
Control systems,
Computer graphics,
Lighting control,
Industrial control,
Automatic control,
Application software,
Artificial intelligence"
Design and analysis of a scalable cache coherence scheme based on clocks and timestamps,"A timestamp-based software-assisted cache coherence scheme that does not require any global communication to enforce the coherence of multiple private caches is proposed. It is intended for shared memory multiprocessors. The scheme is based on a compile-time marking of references and a hardware-based local incoherence detection scheme. The possible incoherence of a cache entry is detected and the associated entry is implicitly invalidated by comparing a clock (related to program flow) and a timestamp (related to the time of update in the cache). Results of a performance comparison, which is based on a trace-driven simulation using actual traces. between the proposed timestamp-based scheme and other software-assisted schemes indicate that the proposed scheme performs significantly better than previous software-assisted schemes, especially when the processors are carefully scheduled so as to maximize the reuse of cache contents. This scheme requires neither a shared resource nor global communication and is, therefore, scalable up to a large number of processors.",
MCP: a protocol for coordination and temporal synchronization in multimedia collaborative applications,"The multiflow conversation protocol (MCP), which provides two communication abstractions is discussed. MCP provides a token-based mechanism for concurrency control among participants of a multipoint connection and includes a communication abstraction called a multiflow conversation. A conversation may consist of one or more connections, and MCP enforces temporal synchronization in the delivery of traffic over participant connections. Delivery of traffic in a conversation is also based on a notion of causality that takes into account the delay constraints associated with real-time traffic.",
Identification of program modifications and its applications in software maintenance,"It is pointed out that a major problem in software maintenance is the revalidation of a modified code. It is economically desirable to restrict that process only to those parts of the program that are affected by the modifications. Towards that goal, a formal method is needed to identify the modifications in an automatic way. Such a method is proposed in the present work. The modifications are localized within clusters in the flow graphs of the original and modified programs. Both flow graphs are transformed into reduced flow graphs, between which an isomorphic correspondence is established. Cluster-nodes in the reduced graphs encapsulate modifications to the original program. An algorithm to derive the reduced flow graphs has been implemented as an extension to the recently developed system for testing and debugging (STAD 1.0) and early experiments with the algorithm are reported. Potential applications in regression testing and reasoning about the program are discussed.",
Optimal tracing and replay for debugging message-passing parallel programs,"A techinque for tracing and replaying message-passing programs for debugging is presented. The technique is optimal in the common case and has good performance in the worst case. By making runtime tracing decisions, only a fraction of the total number of messages is traced, gaining two orders of magnitude reduction over traditional techniques which trace every message. Experiments indicate that only 1% of the messages often need to be traced. These traces are sufficient to provide replay, allowing an execution to be reproduced any number of times for debugging. This work is novel in that runtime decisions are used to detect and trace only those messages that introduce nondeterminacy. With the proposed strategy, large reductions in trace size allow long-running programs to be replayed that were previously unmanageable. In addition, the reduced tracing experiments alleviate tracing bottlenecks, allowing executions to be debugged with substantially lower execution-time overhead.",
A cone-beam filtered backprojection reconstruction algorithm for cardiac single photon emission computed tomography,"A filtered backprojection reconstruction algorithm was developed for cardiac single photon emission computed tomography with cone-beam geometry. The algorithm reconstructs cone-beam projections collected from 'short scan' acquisitions of a detector traversing a noncircular planar orbit. Since the algorithm does not correct for photon attenuation, it is designed to reconstruct data collected over an angular range of slightly more than 180 degrees with the assumption that the range of angles is oriented so as not to acquire the highly attenuated posterior projections of emissions from cardiac radiopharmaceuticals. This sampling scheme is performed to minimize the attenuation artifacts that result from reconstructing posterior projections. From computer simulations, it is found that reconstruction of attenuated projections has a greater effect upon quantitation and image quality than any potential cone-beam reconstruction artifacts resulting from insufficient sampling of cone-beam projections. With nonattenuated projection data, cone beam reconstruction errors in the heart are shown to be small (errors of at most 2%).",
Image-based homing,"A system that allows a robot to use a model of its environment to navigate is reported. The system maps the environment as a set of snapshots of the world taken at target locations. The robot uses an image-based local homing algorithm to navigate between neighboring and target locations. The approach has an imaging system that acquires a compact, 360 degrees representation of the environment as an intensity waveform, and an image-based, qualitative homing algorithm that allows the robot to navigate without explicitly inferring three-dimensional structure from the image. The result of an experiment in a typical indoor environment are reported. They show that image-based navigation is a feasible alternative to approaches using 3-D models and more complex model-based vision algorithms.",
A Quantitative Test For Form Closure Grasps,,
Mick gets some (the odds are on his side) (satisfiability),"Consider a randomly generated boolean formula F (in the conjunctive normal form) with m clauses of size k over n variables; k is fixed at any value greater than 1, but n tends to infinity and m = (1 + o(1))cn for some c depending only on k. It is easy to see that F is unsatisfiable with probability 1-o(1) whenever c>(ln 2)2/sup k/; the authors complement this observation by proving that F is satisfiable with probability 1-o(1) whenever c<(0.25)2/sup k//k; in fact, they present a linear-time algorithm that satisfies F with probability 1-o(1). In addition, they establish a threshold for 2-SAT: if k = 2 then F is satisfiable with probability 1-o(1) whenever c<1 and unsatisfiable with probability 1-o(1) whenever c>1.",
The integration of rule systems and database systems,The integration of rule systems into database management systems is explored. Research activities in this area over the past decade are surveyed. The focus is on prototype systems that have been completely specified and the implementation issues encountered. A research agenda which should be addressed by the research community over the next few years is presented.,
Multi-area unit commitment,The authors present a thermal unit commitment method for interconnected multiarea power systems. The method is a natural extension of the commitment utilization factor (CUF)-based single-area unit commitment method. CUF is extended to reflect the impact of multiarea transmission interconnection constraints on the utilization efficiency of committing a candidate unit at a given priority position. The multiarea CUF is used in conjunction with the average full load cost. (AFLC) to efficiently determine the optimal or a near-optimal multiarea priority commitment order. This priority order is then used to generate the multiarea unit commitment schedule. The excellent quality of the results of the CUF-based multiarea method is consistent with that of the previously reported single-area method.,"Spinning,
Costs,
Power system interconnection,
Power system simulation,
Power generation economics,
Equations,
Computer science,
Thermal engineering,
Thermal factors,
Position measurement"
On-line scheduling of real-time tasks,"An optimal on-line scheduler is given for a set of real-time tasks with one common deadline on m processors. It is shown that no optimal scheduler can exist for tasks with two distinct deadlines. Finally, an optimal on-line scheduler is given for situations where processors can go down unexpectedly.",
Performance measurement intrusion and perturbation analysis,"The authors study the instrumentation perturbations of software event tracing on the Alliant FX/80 vector multiprocessor in sequential, vector, concurrent, and vector-concurrent modes. Based on experimental data, they derive a perturbation model that can approximate true performance from instrumented execution. They analyze the effects of instrumentation coverage, (i.e., the ratio of instrumented to executed statements), source level instrumentation, and hardware interactions. The results show that perturbations in execution times for complete trace instrumentations can exceed three orders of magnitude. With appropriate models of performance perturbation, these perturbations in execution time can be reduced to less than 20% while retaining the additional information from detailed traces. In general, it is concluded that it is possible to characterize perturbations through simple models. This permits more detailed, accurate instrumentation than traditionally believed possible.",
Highly-available services using the primary-backup approach,The authors derive lower bounds and the corresponding optimal protocols for three parameters for synchronous primary-backup systems. They compare their results with similar results for active replication in order to determine whether the common folklore on the virtues of the two approaches can be shown formally. They also extend some of their results to asynchronous primary-backup systems. They implement an important subclass of primary-backup protocols that they call 0-blocking. These protocols are interesting because they introduce no additional protocol related delay into a failure-free service request. Through implementing these protocols the authors hope to determine the appropriateness of their theoretical system model and uncover other practical advantages or limitations of the primary-backup approach.,
Guaranteeing synchronous message deadlines with the timed token protocol,"The problem of guaranteeing synchronous message deadlines in token ring networks in which the timed token medium access control protocol is used is discussed. Synchronous capacity, defined as the maximum time for which a node can transmit its synchronous messages every time it receives the token, is a key parameter in the control of synchronous message transmission. To ensure the transmission of synchronous messages before their deadlines, synchronous capacities must be properly allocated to individual nodes. Several synchronous capacity allocation schemes are analyzed in terms of their ability to satisfy deadline constraints of synchronous messages. It is shown that an inappropriate allocation of the synchronous capacities could cause message deadlines to be missed, even if the synchronous traffic is extremely low. The normalized proportional allocation scheme, which can guarantee the synchronous message deadlines for synchronous traffic of up to 33% of available utilization is proposed.",
Two's complement quantization in two-dimensional state-space digital filters,"Two-dimensional (2-D) state-space digital filters are investigated for stability with and without quantization. A sufficient condition is obtained for the stability of the linear Fornasini-Marchesini (1976) state-space model. The same model is then studied for stability when implemented using two's complement truncation quantization, and a sufficient condition for asymptotic stability of the nonlinear filter is obtained. In the process, a theorem is proved which gives a sufficient condition for the stability of a one-dimensional (1-D) state-space digital filter under the same type of quantization.",
Lund control program combines theory with hands-on experience,"The control laboratory and curriculum at Lund Institute of Technology in Sweden are described. Their major goal is to give students a strong background in control theory and an engineering ability to make control systems that work. This is accomplished with a coordinated course structure that is applicable to undergraduates, graduates, and continuing education. The program's control laboratory utilizes a variety of software packages that cover simulation, identification, control design, and online computer control.",
"Toward objective, systematic design-method comparisons","Software design methodologies (SDMs) suggest ways to improve productivity and quality. They are collections of complementary design methods and rules for applying them. A base framework and modeling formalism to help designers compare SDMs and define what design issues different SDMs address, which of their components address similar design issues, and ways to integrate the best characteristics of each to make a cleaner, more comprehensive and flexible SDM are presented. The use of formalism and framework and the evaluation of objectivity and completeness using the type and function frameworks are described.",
Multimedia communications for users,"Research on next-generation multimedia communications services and technologies within a highly interdisciplinary research program that encompasses behavioral science, computer science, and electrical engineering is discussed. The authors state that they have taken an approach to their research that allows the needs of users and the demands of end-to-end applications to shape the future of the multimedia communications network. They use several examples to show how such a perspective affects the development of practical, advanced communications services. These examples span a wide range, including: empirical studies of people's use of technology to communicate in collaborative work settings; the design of software supporting the real-time network delivery of interactive multimedia documents for casual information users in the home; and the creation of next-generation prototypes that support the transmission and viewing of multimedia information in homes, offices and classrooms.",
A radix-4 modular multiplication hardware algorithm for modular exponentiation,"A fast radix-4 modular multiplication hardware algorithm is proposed. It is efficient for modular exponentiation with a large modulus, used in public-key cryptosystems such as the RSA cryptosystem. The operands and the result of multiplication which are intermediate results in modular exponentiation are represented in a redundant representation. The computation proceeds in serial-parallel fashion. Each subtraction for the division for residue calculation is embedded in the repeated multiply-add. Each intermediate result is represented in a more redundant representation than that for the operands and the result, so that the number of the required addition/subtractions is reduced. All addition/subtraction are carried out without carry propagation. A serial-parallel modular multiplier based on the algorithm has a regular cellular array structure with a bit slice feature and is suitable for VLSI implementation.",
On the generalized Hamming weights of several classes of cyclic cods,"The generalized Hamming weights of a linear code are fundamental code parameters related to the minimal overlap structures of the subcodes. They were introduced by V.K. Wei (1991) and shown to characterize the performance of the linear code in certain cryptographical applications. Results are presented on the generalized Hamming weights of several classes of binary cyclic codes, including primitive double-error-correcting and triple-error-correcting BCH codes, certain reversible cyclic codes, and some extended binary Goppa codes. In particular, the second generalized Hamming weight of primitive double-error-correcting BCH codes is determined and upper and lower bounds are obtained for the generalized Hamming weights for the codes studied. These bounds are compared to results from other methods.",
End-to-end scheduling to meet deadlines in distributed systems,"Algorithms for scheduling a class of systems in which all the tasks execute on different processors in turn in the same order are described. This end-to-end scheduling problem is known as the flow-shop problem. Two cases in which the problem is tractable are presented, and a heuristic for the NP-hard general case is evaluated. The traditional flow-shop model is generalized in two directions. First, an algorithm for scheduling flow shops in which tasks can be serviced more than once by some processors is presented. Second, a heuristic algorithm for scheduling flow shops with periodic tasks is described. Scheduling systems with more than one flow shop are considered.","Processor scheduling,
Job shop scheduling,
Time factors,
Scheduling algorithm,
Communication networks,
Timing,
Distributed computing,
Intelligent networks,
Computer science,
Heuristic algorithms"
Analysis of a fluid approximation to flow control dynamics,"The authors consider a flow control mechanism that dynamically regulates the rate of data flow into a network based on feedback information about the network state. Such mechanisms have been introduced in a variety of networks, and have been advocated for future high-speed networks. The authors first model the flow control mechanism by a discrete-space stochastic process and define appropriate performance measures for transient and steady-state regimes. However, the model does not appear to be analytically tractable, and the authors study it through simulation. They then simplify it to a continuous-space deterministic (or fluid) model for which closed-form solutions can be derived easily. It is found that the analytical results for the fluid model agree well with the simulation results obtained using the discrete-space model. Both models explicitly consider delay of the feedback information, thus making them relevant for high-speed networks.",
Applying case-based reasoning to autoclave loading,"Clavier, a case-based reasoning system that determines the placement of parts made of composite materials in an autoclave, is described. The heating rate of all parts put in an autoclave must be controlled carefully, but their number, shape, and placement can cause significant nonlocal variations. Clavier provides interactive support, using cases to propose load configurations and multiload plans. One of its advantages is that it learns, becoming more competent as it acquires new cases. Clavier's structure and results from evaluations of Clavier as an application and as a case-based reasoning research tool are discussed.",
Current-mode analog fuzzy hardware with voltage input interface and normalization locked loop,"A voltage-input current-output membership function circuit (MFC) and a normalization locked loop (NLL) are proposed. They are useful building blocks for current-mode analog fuzzy hardware. The voltage-input current-output MFC consists of two-source-coupled-type operational transconductance amplifiers (OTAs). The MFC is used in the input parts of the analog fuzzy hardware system. The fuzzy hardware system can execute the singleton fuzzy control algorithm. In the algorithm, the weighted average operation is processed. When the weighted average operation is directly realized by analog circuits, a divider must be implemented. The NLL circuit, which can process the weighted average operation without the divider, is implemented using a one-source-coupled OTA. The proposed circuits were designed by using 2- mu m CMOS design rules and their operations were confirmed using SPICE simulations.",
Environment evolution: the Prism model of changes,"A software development environment supports a complex network of items of at least the following major types: people, policies, laws, resources, processes and results. Such items may need to be changed on an on-going basis. The authors have designed in the Prism project a model of changes and two supporting change-related environment infrastructures with the following key features: separation of changes to the described items from the changes to the environmental facilities encapsulating these items; a facility, called the dependency structure, for describing various items and their interdependencies, and for identifying the items affected by a given change; a facility, called the change structure for classifying, recording, and analyzing change-related data and for making qualitative judgments of the consequences of a change; identification of the many distinct properties of a change; and a built-in mechanism for providing feedback. The author's approach to the problem of change and its rationale is described.",
Penetration state transition analysis: A rule-based intrusion detection approach,"A new approach to representing computer penetrations is introduced called penetration state transition analysis. This approach models penetrations as a series of state transitions described in terms of signature actions and state descriptions. State transition diagrams are written to correspond to the states of an actual computer system, and these diagrams form the basis of a rule-based expert system for detecting penetrations, referred to as STAT.",
Some Problems In Perspective System Theory And Its Application To Machine Vision,,
What's in a set of points? (straight line fitting),"The problem of fitting a straight line to a planar set of points is reconsidered. A parameter space computational approach capable of fitting one or more lines to a set of points is presented. The suggested algorithm handles errors in both coordinates of the data points, even when the error variances vary between coordinates and among points and can be readily made robust to outliers. The algorithm is quite general and allows line fitting according to several useful optimality criteria to be performed within a single computational framework. It is observed that certain extensions of the Hough transform can be turned to be equivalent to well-known M estimators, thus allowing computationally efficient approximate M estimation.",
Building the business case for group support technology,"As groupwork gains recognition, emerging group support technologies raise questions about the merits of these systems relative to group performance and return on investment. Business case variables of efficiency, quality, effectiveness, customer satisfaction and decision-making are useful in measuring the potential contribution that group support technologies offer. The author presents findings from a recent field study that used business case concepts as its design approach. He explores the infrastructure development requirements for building a business case study. Such a framework is useful to business decision-makers and researchers interested in the deployment of these technologies in complex business environments.",
Adaptive routing in mesh-connected networks,"It is shown that wormhole routing in mesh-connected networks can be deadlock free and adaptive without the addition of channels to the basic topology. Several partially adaptive routing algorithms for 2-D and 3-D meshes are described and simulated for a variety of conditions. Simulations of policies for selecting input channels show that transmitting extra information in the header flits can reduce communication latencies at high network throughputs. Simulations of policies for selecting output channels show that avoiding turns reduces latencies at high throughputs. Unrestricted nonminimal routing is found to reduce latencies slightly at low throughputs but increase latencies significantly at high throughputs. For nonuniform traffic patterns, a partially adaptive routing algorithm performs better than a nonadaptive one.",
Learning rate schedules for faster stochastic gradient search,"The authors propose a new methodology for creating the first automatically adapting learning rates that achieve the optimal rate of convergence for stochastic gradient descent. Empirical tests agree with theoretical expectations that drift can be used to determine whether the crucial parameter c is large enough. Using this statistic, it will be possible to produce the first adaptive learning rates which converge at optimal speed.",
An algebraic approach to feature interactions,"The various approaches proposed to provide communication between CAD systems and process planning systems share the major problem that, due to geometric interactions among features, there may be several equally valid sets of manufacturable features describing the same part, and different sets of features may differ in their manufacturability. Thus, to produce a good process plan-or, in some cases, any plan at ll-it may be necessary to interpret the part as a different set of features than the one initially obtained from the CAD model. This is addressed using an algebra of features. Given a set of features describing a machinable part, other equally valid interpretations of the part can be produced by performing operations in the algebra. This will enable automated process planning systems to examine these interpretations in order to see which one is most appropriate for use in manufacturing. The feature algebra has been implemented for a restricted domain and integrated with the Protosolid solid modeling system and the EFHA process planning system.","Process planning,
Feature extraction,
Concurrent engineering,
Algebra,
Manufacturing processes,
Design automation,
Manufacturing automation,
Solid modeling,
Computer science,
Fixtures"
Designing application-specific neural networks using the structured genetic algorithm,"Presents a different type of genetic algorithm called the structured genetic algorithm (SGA) for the design of application-specific neural networks. The novelty of this new genetic approach is that it can determine the network structures and their weights solely by an evolutionary process. This is made possible for the SGA primarily due to its redundant genetic material and a gene activation mechanism which in combination provide a multi-layered structure to the chromosome. The authors focus on the use of this learning algorithm for automatic generation of a complete application specific neural network. With this approach, no a priori assumptions about topology are needed and the only information required is the input and output characteristics of the task. The empirical studies show that the SGA can efficiently determine the network size and topology along with the optimal set of connection weights appropriate for desired tasks, without using backpropagation or any other learning algorithm.","Algorithm design and analysis,
Neural networks,
Genetic algorithms,
Biological cells,
Network topology,
Backpropagation algorithms,
Biological system modeling,
Computer science,
Design optimization,
Biological processes"
A defuzzification strategy for a fuzzy logic controller employing prohibitive information in command formulation,"A defuzzification strategy is presented that can handle the possibility of conflicting control commands during the defuzzification process while still producing smooth transitions. The strategy, which is the centroid of the largest area, has parameters that can be chosen to make it behave like both the centroid strategy and the mean of the maximum membership strategy. The strategy addresses the problem of prohibitive information in fuzzy control command formulation. This strategy was applied to a mobile robot path execution system and it was shown that this strategy overcomes some of the deficiencies of other strategies. This strategy not only makes the best choice when several are given, but also avoids abrupt transitions in the control command.",
Design of delay insensitive circuits using multi-ring structures,"The design and VLSI implementation of a delay insensitive circuit that computes the inner product of two vec.tors is described. The circuit is based on an iterative serial-parallel multiplication algorithm. The design is based on a data flow approach using pipelines and rings that are combined into larger multi ring structures by the joining and forking of signals. The implementation is based on a small set of building blocks (latches, combinational circuits and switches) that are composed of C-elements and simple gates. By following this approach, delay insensitive circuits with nontrivial functionality and reasonable performance are readily designed.",
Direct method for reconstructing shape from shading,"An approach to shape-from-shading that is based on a connection with a calculus of variations/optimal control problem is proposed. An explicit representation corresponding to a shaded image is given for the surface; uniqueness of the surface (under suitable conditions) is an immediate consequence. The approach leads naturally to an algorithm for shape reconstruction that is simple, fast, provably convergent (in many cases, provably convergent to the correct solution), and does not require regularization. Given a continuous image, the algorithm can be proved to converge to the continuous surface solution as the image sampling frequency is taken to infinity. Experimental results are presented for synthetic and real images.",
"AUV path planning: an A* approach to path planning with consideration of variable vehicle speeds and multiple, overlapping, time-dependent exclusion zones","The authors describe an implementation of a path planner suitable for an autonomous underwater vehicle (AUV). The path planning unit is capable of maintaining a quadtree database of depth information, obstacles, and exclusion zones: verifying a previously planned path; generating a new path between successive goal points; and generating a path to the nearest point of a safe region. If a path does not exist within the given constraints, the path planner returns a reason for the failure. The path planner attempts to find a 3D corridor that does not intersect any nonentry zones. An A* algorithm is used to generate path corridors along great circle routes. The path planner's real-time performance in open, constricted, and real-world situations is discussed. Additional factors affecting performance such as the number of different vehicle speeds, the quadtree resolution, and the number of nonentry zones blocking the goal are considered.",
Using processor affinity in loop scheduling on shared-memory multiprocessors,"The authors consider a new dimension to the problem of loop scheduling on shared-memory multiprocessors: communication overhead caused by accesses to nonlocal data. It is shown that traditional algorithms for loop scheduling, which ignore the location of data when assigning iterations to processors, incur a significant performance penalty on modern shared-memory multiprocessors. The authors propose a loop scheduling algorithm that attempts to simultaneously balance the workload, minimize synchronization, and colocate loop iterations with the necessary data. They compare the performance of this algorithm to that of other known algorithm using four representative applications on a Silicon Graphics multiprocessor workstation, a BBN Butterfly, and a Sequent Symmetry, and they show that the algorithm offers substantial performance improvements, up to a factor of 3 in some cases. They conclude that loop scheduling algorithms for shared-memory multiprocessors cannot afford to ignore the location of data, particularly in light of the increasing disparity between processor and memory speeds.",
Solar wind-magnetosphere interaction as simulated by a 3-D EM particle code,"Results are presented for simulating the solar-wind-magnetosphere interaction with a new three-dimensional electromagnetic particle code. Previously, such global simulations were done with MHD codes while lower-dimensional particle or hybrid codes served to account for microscopic processes and such transport parameters as have to be introduced ad hoc in MHD. The kinetic model presented attempts to combine the macroscopic and microscopic tasks. It relies only on the Maxwell curl equations and the Lorentz equation for particles, which are ideally suited for computers. The preliminary results shown are for an unmagnetized solar-wind plasma streaming past a dipolar magnetic field. The results show the formation of a bow shock and a magnetotail, the penetration of energetic particles into cusp and radiation belt regions, and dawn-dusk asymmetries.",
Vector-extrapolated fast maximum likelihood estimation algorithms for emission tomography,"A new class of fast maximum-likelihood estimation (MLE) algorithms for emission computed tomography (ECT) is developed. In these cyclic iterative algorithms, vector extrapolation techniques are integrated with the iterations in gradient-based MLE algorithms, with the objective of accelerating the convergence of the base iterations. This results in a substantial reduction in the effective number of base iterations required for obtaining an emission density estimate of specified quality. The mathematical theory behind the minimal polynomial and reduced rank vector extrapolation techniques, in the context of emission tomography, is presented. These extrapolation techniques are implemented in a positron emission tomography system. The new algorithms are evaluated using computer experiments, with measurements taken from simulated phantoms. It is shown that, with minimal additional computations, the proposed approach results in substantial improvement in reconstruction.",
On-the-fly rounding (computing arithmetic),"In implementations of operations based on digit-recurrence algorithms such as division, left-to-right multiplication and square root, the result is obtained in digit-serial form, from most significant digit to least significant. To reduce the complexity of the result-digit selection and allow the use of redundant addition, the result-digit has values from a signed-digit set. As a consequence, the result has to be converted to conventional representation, which can be done on-the-fly as the digits are produced, without the use of a carry-propagate adder. The authors describe three ways to modify this conversion process so that the result is rounded. The resulting operation is fast because no carry-propagate addition is needed. The schemes described apply also to online arithmetic operations.",
Measured performance of a wireless LAN,"The performance of a high-speed commercial spread-spectrum wireless LAN that uses the CSMA/CA multiple-access strategy was studied. Using synthetic workloads, packet capture success rather than signal propagation characteristics was measured. Specifically throughput, packet loss rates, range, and patterns of errors within packets were measured. It is concluded that CSMA/CA is quite successful in allocating bandwidth under stress, but that packet capture rate degrades very quickly once the LAN's effective range is exceeded. Hence, network maintainers should plan the layout of wireless networks at least as carefully as they plan wired networks.",
Color segmentation using perceptual attributes,"A general approach for achieving color image segmentation using uniform-chromaticity-scale perceptual color attributes is proposed. At first chromatic and achromatic areas in a perceptual IHS color space are defined. Then the image is separated into chromatic and achromatic regions according to the region locations in the color space. 1-D histogram thresholding for each color attribute is performed to split the chromatic and achromatic regions, respectively. Finally the region growing is used to solve the oversegmentation problem. In an experiment the power of the proposed approach is demonstrated.",
Orienting generalized polygonal parts,"K.Y. Goldberg (1990) described an algorithm for orienting planar polygonal parts using a modified parallel-jaw gripper. The authors extend this algorithm to handle parts with curved edges. They define a generalized polygon as a planar figure made up of piecewise linear and circular edges, and a generalized polygonal part as one of constant cross section, the convex hull of which is a generalized polygon. For this class of parts a complete algorithm for determining an optimal parts-orienting strategy is presented.",
On the validity of the slow and moderate fading models for matched filter detection of Rayleigh fading signals,"Published analyses of data transmission on flat fading channels often assume that the pulses arrive without distortion, and that random amplitude and phase are applied on a per-pulse basis. In reality, however, multiplicative distortion in the channel operates over each pulse. If the receiver uses a matched filter, an error floor results even for isolated pulse transmission. The author examines the effect systematically. By obtaining the error floor as a function of fade rate and pulse roll-off, he defines the limits, or `safe zone,' of the distortion-free approximation, which is here termed the moderate fading model. The results should be of interest to those working in modelling and analysis of fast fading channels.",
"PRISMA/DB: a parallel, main memory relational DBMS","PRISMA/DB, a full-fledged parallel, main memory relational database management system (DBMS) is described. PRISMA/DB's high performance is obtained by the use of parallelism for query processing and main memory storage of the entire database. A flexible architecture for experimenting with functionality and performance is obtained using a modular implementation of the system in an object-oriented programming language. The design and implementation of PRISMA/DB are described in detail. A performance evaluation of the system shows that the system is comparable to other state-of-the-art database machines. The prototype implementation of the system runs on a 100-node parallel multiprocessor.",
Processor Coupling: Integrating Compile Time and Runtime Scheduling for Parallelism,"The technology to implement a single-chip node composed of 4 high-performance floating-point ALUs will be available by 1995. This paper presents processor coupling, a mechanism for controlling multiple ALUs to exploit both instruction-level and inter- thread parallelism, by using compile time and runtime scheduling. The compiler statically schedules individual threads to discover available inter-thread instruction-level parallelism. The runtime scheduling mechanism interleaves threads, exploiting inter-thread parallelism to maintain high ALU utilization. ALUs are assigned to threads on a cycle by cycle basis, and several threads can be active concurrently. We provide simulation results demonstrating that, on four simple numerical benchmarks, processor coupling achieves better performance than purely statically scheduled or multi-processor machine organizations. We examine how performance is affected by restricted communication between ALUs and by long memory latencies. We also present an implementation and feasibility study of a processor coupled node.",
Efficient diagnosis of multiprocessor systems under probabilistic models,"The problem of fault diagnosis in multiprocessor systems is considered under a probabilistic fault model. The focus is on minimizing the number of tests that must be conducted to correctly diagnose the state of every processor in the system with high probability. A diagnosis algorithm that can correctly diagnose these states with probability approaching one in a class of systems performing slightly greater than a linear number of tests is presented. A nearly matching lower bound on the number of tests required to achieve correct diagnosis in arbitrary systems is proved. Lower and upper bounds on the number of tests required for regular systems are presented. A class of regular systems which includes hypercubes is shown to be correctly diagnosable with high probability. In all cases, the number of tests required under this probabilistic model is shown to be significantly less than under a bounded-size fault set model. These results represent a very great improvement in the performance of system-level diagnosis techniques.",
The software engineering laboratory - an operational software experience factory,"For 15 years, the Software Engineering Laboratory (SEL) has been carrying out studies and experiments for the purpose of understand- ing, assessing, and improving software and software processes within a production software development environment at the National Aeronautics and Space Administration/Goddard Space Flight Center (NASA/GSFC). The SEL comprises three major organizations: NASA/GSFC, Flight Dynamics Division University of Maryland, Department of Computer Science Computer Sciences Corporation, Flight Dynamics Technology Group - These organizations have jointly carried out several hundred software studies, producing hundreds of reports, papers, and documents, all of which de scribe some aspect of the software engineering technology that has been analyzed in the flight dynamics environment at NASA. The studies range from small, controlled experiments (such as analyzing the effectiveness of code readingversus that of functional testing) tolarge, multiple- project studies (such as assessing the impacts of Ada on a production environment). The organization's driving goal is to improve the software process continually, so that sustained improvement may be observed in the resulting products. This paper discusses the SEL as a functioning example of an operational software experience factory and summarizes the characteristics of and major lessons learned from 15 years of SEL operations.","Software engineering,
Laboratories,
Production facilities,
Packaging,
Feedback,
Particle measurements,
Software measurement,
Software quality,
Character recognition,
Process planning"
Efficient tridiagonal solvers on multicomputers,"Three parallel algorithms, namely, the parallel partition LU (PPT) algorithm, the parallel partition hybrid (PPH) algorithm, and the parallel diagonal dominant (PDD) algorithm, are proposed for solving tridiagonal linear systems on multicomputers. These algorithms are based on the divide-and-conquer parallel computation model. The PPT and PPH algorithms support both pivoting and nonpivoting. The PPT algorithm is good when the number of processors is small; otherwise, the PPH algorithm is better. When the system is diagonal dominant, the PDD algorithm is highly parallel and provides an approximate solution which equals the exact solution within machine accuracy. Computation and communication complexities of the three algorithms are presented. All three methods have been implemented on a 64-node nCUBE-1 multicomputer. The analytic results closely match the results measured from the nCUBE-1 machine.",
Optimal ring embedding in hypercubes with faulty links,"The authors show that in an n-dimensional hypercube (Q/sub n/), up to n-2 links can fail before destroying all available Hamiltonian cycles. They present an efficient algorithm which identifies a characterization of a Hamiltonian cycle in Q/sub n/, with as many as n-2 faulty links, in O(n/sup 2/) time. Generating a fault-free Hamiltonian cycle from this characterization can be easily done in linear time. An important application of this work is in optimal simulation of ring-based multiprocessors or multicomputer systems by hypercubes. Compared with the existing fault-tolerant embeddings based on link-disjoint Hamiltonian cycles, the algorithm specifies such a cycle that tolerates twice as many faulty links.",
Analysis of individual packet loss in a finite buffer queue with heterogeneous Markov modulated arrival processes: a study of traffic burstiness and priority packet discarding,"The authors consider a queuing system with a finite buffer and multiple heterogeneous arrival streams. They focus on Markov modulated arrival processes with different burstings and investigate the loss of individual arrival streams when the parameters of the heterogeneous arrival streams are varied. The analysis includes both continuous-time and discrete-time treatments of multiplexed heterogeneous Markov modulated arrivals. Loss probabilities are derived for a priority packet discarding scheme. A new characterization of an arrival stream is introduced, referred to as a self-loss, and it is used to qualitatively predict the effects of multiplexing bursty streams with nonbursty streams. The effectiveness of priority packet discarding is also investigated through numerical examples.",
Global convergence of the recursive kernel regression estimates with applications in classification and nonlinear system estimation,"An improved exponential bound on the L/sub 1/ error for the recursive kernel regression estimates is derived. It is shown, using the martingale device, that weak, strong and complete L/sub 1/ consistencies are equivalent. Consequently the conditions on a certain smoothing sequence are necessary and sufficient for strong L/sub 1/ consistency of the recursive kernel regression estimate. The rates of global convergence are also given. Obtained results are applied to recursive classification rules and to nonlinear time series estimation.",
Delay optimization of carry-skip adders and block carry-lookahead adders using multidimensional dynamic programming,"The worst-case carry propagation delays in carry-skip adders and block carry-lookahead adders depend on how the full adders are grouped structurally together into blocks as well as the number of levels. The authors report on a multidimensional dynamic programming paradigm for configuring these two adders to attain minimum latency. Previous methods are applicable only to very limited delay models that do not guarantee a minimum latency configuration. Under the delay model, critical path delay is calculated not only taking into account the intrinsic gate delays, but also the fanin and fanout contributions.",
Imprecise and uncertain information in databases: an evidential approach,"A novel approach for representing imprecise and uncertain data and evaluating queries in the framework of an extended relational database model based on the Dempster-Shafer theory of evidence is proposed. Because of the ability to combine evidences from different sources, the semantics of the update operation of imprecise or uncertain data is reconsidered. By including an undefined value in a domain, three different cases of a null value are presented: unknown, inapplicable, and unknown or inapplicable. In this model, two levels of uncertainty in the database are supported: one is for the attribute value level and the other is for the tuple level.",
An example of modeling and evaluation of a concurrent program using colored stochastic Petri nets: Lamport's fast mutual exclusion algorithm,"A colored generalized stochastic Petri net (CGSPN) model was used to study the correctness and performance of the Lamport concurrent algorithm to solve the mutual exclusion problem on machines lacking an atomic test and set instruction. In particular, a parametric formal proof of liveness is developed based on the structure and initial state of the model. The performance evaluation is based on a Markovian analysis that exploits the symmetries of the model to reduce the cost of the numerical solution. Both kinds of analysis are supported by efficient algorithms. The potential of the GSPN modeling technique is illustrated on an academic but nontrivial example of an application from distributed systems.",
"High-power, high efficiency, injection-locked, secondary-emission magnetron","A 60-MW, 60% efficient, 35 J/pulse secondary-emission magnetron at S-band is described and experimental results from this moderate voltage (<120 kV), repetitively pulsed (10 Hz), injection locked (14-15 dB gain) device are reported. Efforts to minimize high-voltage and RF breakdown at high power are described. Results from particle-in-cell code computer simulations compare very well with the experiment when space-charge-limited emission is assumed. Several factors which can limit the power and pulse length from this magnetron, including RF and high-voltage breakdown, cathode emission, and transport heating, are discussed. By increasing the voltage, the drive power, and the magnetron length and by using a tungsten alloy anode, 120 MW should be achievable for approximately 4- mu s pulses at 130 kV, with the pulse length limited by transient heating of the anode.",
A retargetable technique for predicting execution time,"A novel technique for predicting point-to-point execution times on contemporary microprocessors is presented. It uses machine-description rules, similar to those that have proven useful for code generation and peephole optimization, to translate compiled object code into a sequence of very low-level instructions. The stream of micro-instructions is then analyzed for tuning, via a three-level pattern matching scheme. The timing tool is currently predicting execution time of code segments targeted for the Motorola 68020 and Intel 80386 processor. The timing tool has been integrated with a version of the vpo C compiler and the ease environment. A prototype has been built and preliminary tests are very promising.","Timing,
Processor scheduling,
Hardware,
Pattern matching,
Prototypes,
Real time systems,
Information systems,
Computer science,
Microprocessors,
Pattern analysis"
Picosecond charge-collection dynamics in GaAs MESFETs (for space application),Ion and picosecond laser induced charge-collection measurements performed as a function of temperature and device bias conditions reveal the significant changes that occur in the charge collection transients as a function of these parameters. The temperature-dependent results provide new evidence that above-bandgap picosecond laser excitation can reproduce the primary features of the ion induced charge-collection transients measured for GaAs MESFETs. Bias dependence results reveal clearly the sensitive role of the device operating point in determining both the shape and the total integrated intensity of the measured charge-collection transients. Preliminary two-dimensional computer simulation results are presented which suggest carrier-induced channel modulation as the primary mechanism for enhanced charge collection in GaAs MESFETs.,
Fuzzy logic and the calculus of fuzzy if-then rules,Summary form only given. Fuzzy logic and the calculus of fuzzy if-then rules are reviewed. The agenda of the calculus of fuzzy if-then rules is set forth briefly. Their importance is discussed.<>,
A cautionary note on image downgrading,"The results of an experiment that shows that it is very simple to contaminate digital images with information that can later be extracted are presented. This contamination cannot be detected when the image is displayed on a good quality graphics workstation. Based on these results, it is recommended that image downgrading based on visual display of the image to be downgraded not be performed if there is any threat of image contamination by Trojan horse programs. Potential Trojan horse programs may include untrusted image processing software.",
Learning reactive admittance control,"A peg-in-hole insertion task is used as an example to illustrate the utility of direct associative reinforcement learning methods for learning control under real-world conditions of uncertainty and noise. An associative reinforcement learning system has to learn appropriate actions in various situations through a search guided by evaluative performance feedback The authors used such a learning system, implemented as a connectionist network, to learn active compliant control for peg-in-hole insertion. The results indicated that direct reinforcement learning can be used to learn a reactive control strategy that works well even in the presence of a high degree of noise and uncertainty.",
System clock estimation based on clock slack minimization,"When estimating a hardware implementation from behavioral descriptions, an important decision is the selection of a clock cycle to schedule the datapath operations into control steps. Traditional high-level synthesis systems require the designer to specify the clock cycle explicitly or express operator delays in terms of multiples of a clock cycle. The authors present an algorithm for clock estimation from dataflow graphs, based on clock slack minimization. This will provide both designers and synthesis tools with a realistic estimate of the clock cycle that can be used to implement a design. By using real life components and examples, it is shown that the clock estimates produced by this method yield faster execution times for the designs, as compared to the maximum operator delay methods. It is observed that the designs scheduled with the clock cycle estimates have faster execution times regardless of the components finally allocated for implementing the design during synthesis.",
Numerical convergence and interpretation of the fuzzy c-shells clustering algorithm,R. N. Dave's (1990) version of fuzzy c-shells is an iterative clustering algorithm which requires the application of Newton's method or a similar general optimization technique at each half step in any sequence of iterates for minimizing the associated objective function. An important computational question concerns the accuracy of the solution required at each half step within the overall iteration. The general convergence theory for grouped coordination minimization is applied to this question to show that numerically exact solution of the half-step subproblems in Dave's algorithm is not necessary. One iteration of Newton's method in each coordinate minimization half step yields a sequence obtained using the fuzzy c-shells algorithm with numerically exact coordinate minimization at each half step. It is shown that fuzzy c-shells generates hyperspherical prototypes to the clusters it finds for certain special cases of the measure of dissimilarity used.,
A case-study in timed refinement: a mine pump,"A specification and top-level refinement of a simple mine pump control system, as well as a proof of correctness of the refinement, are presented as an example of the application of a formal method for the development of time-based systems. The overall approach makes use of a refinement calculus for timed systems, similar to the refinement calculi for sequential programs. The specification makes use of topologically continuous functions of time to describe both analog and discrete properties of both the system and its refinements. The basic building block of specifications is a specification statement that gives a clear separation between the specification of the assumptions that the system may make about the environment in which it is to be placed, and the effect the system is guaranteed to achieve if placed in such an environment. The top-level refinement of the system is developed by application of refinement laws that allow design decisions to be made, local state to be introduced, and the decomposition of systems into pipelined and/or parallel processes.",
Procedure cloning,Procedure cloning is an interprocedural optimization where the compiler creates specialized copies of procedure bodies. The authors examine the problem of procedure cloning and describe an experiment where cloning was required to make other transformations possible. They present a three-phase algorithm for deciding how to clone a program and analyze the algorithm's complexity. The algorithm finds potential improvements in forward interprocedural data-flow solutions and clones those procedures that lead to sharper information. A set of assumptions that bound both the running time of the algorithm and the expansion in code size is presented.,
On a class of rearrangeable networks,"Benes networks are nonblocking rearrangeable networks that can realize arbitrary permutations without conflict. A class of 2 log/sub b/ N stage networks which are equivalent to the Benes networks is introduced. Networks in this class can be either symmetric or asymmetric in their structure, regular or irregular in their interstage connections, and even, 2 log/sub b/ N or 2 log/sub b/ N-1 stages. All networks in this class are nonblocking rearrangeable. A switch labeling scheme is proposed to provide testing of the topological and functional equivalency for this class of networks. This switch labeling scheme can also provide a novel matrix representation for network configuration. This representation introduces a portability concept for the routing scheme on this class of networks. With this representation, a general routing scheme is also developed. This routing scheme can realize arbitrary permutation for the whole class of 2 log/sub b/ N stage networks.",
Working with persistent objects: to swizzle or not to swizzle,"Pointer swizzling is the conversion of database objects between an external form (object identifiers) and an internal form (direct memory pointers). Swizzling is used in some object-oriented databases, persistent object stores, and persistent and database programming language implementations to speed manipulation of memory resident data. The author describes a simplifying model of application behavior, revealing those aspects where swizzling is most relevant in both benefits and costs. The model has a number of parameters, which the authors have measured for a particular instance of the Mneme persistent object store, varying the swizzling technique used. The results confirm most of the intuitive, qualitative tradeoffs, with the quantitative data showing that some performance differences between schemes are smaller than might be expected. However, there are some interesting effects that run counter to naive intuition, most of which are explained using deeper analysis of the algorithms and data structures.",
Compiler blockability of numerical algorithms,"An attempt was made to determine whether a compiler can automatically restructure computations well enough to avoid the need for hand blocking. To that end, programs in LAPACK were studied for which it was possible to examine both the block version and the corresponding point algorithm. For each of these programs, it was determined whether a plausible compiler technology could succeed in obtaining the block version from the point algorithm. The results are encouraging: one can block triangular and trapezoidal loops, and many of the problems introduced by complex dependence patterns can be overcome by the use of the transformation known as index-set splitting. In addition, it was shown that knowledge about which operations commute can enable a compiler to succeed in blocking codes that could not be blocked by any compiler based strictly on dependence analysis.","Program processors,
Programming profession,
Optimizing compilers,
Microprocessors,
Algorithm design and analysis,
Computer science,
Design optimization,
High performance computing,
Delay,
History"
Net partitions yield better module partitions,"The authors demonstrate that the dual intersection graph of the netlist strongly captures circuit properties relevant to partitioning. The main contribution of the analysis highlights advantages to using the dual representation of the logic design, and confirming that net structure and interrelationships, rather than module adjacencies, should constitute the primary descriptors of a circuit. In particular, the dual intersection graph representation of the netlist hypergraph yields much more natural circuit partitioning formulations, since it inherently emphasizes relationships between signal nets. The intersection graph yields a sparser circuit representation than traditional net models. An efficient algorithm, called IG-Match, is proposed for completing the net partition. The IG-Match method yielded significant performance improvements over previous ratio-cut partitioning methods.",
Detection of edges from projections,"In a number of applications of computerized tomography, the ultimate goal is to detect and characterize objects within a cross section. Detection of edges of different contrast regions yields the required information. The problem of detecting edges from projection data is addressed. It is shown that the class of linear edge detection operators used on images can be used for detection of edges directly from projection data. This not only reduces the computational burden but also avoids the difficulties of postprocessing a reconstructed image. This is accomplished by a convolution backprojection operation. For example, with the Marr-Hildreth edge detection operator, the filtering function that is to be used on the projection data is the Radon transform of the Laplacian of the 2-D Gaussian function which is combined with the reconstruction filter. Simulation results showing the efficacy of the proposed method and a comparison with edges detected from the reconstructed image are presented.",
Surface reconstruction using deformable models with interior and boundary constraints,"The authors introduce a technique for 3D surface reconstruction using elastic deformable-models. The model used is an imaginary elastic grid, which is made of membranous, thin-plate-type material. The elastic grid can bent, twisted, compressed, and stretched into any desired 3D shape, which is specified by the shape constraints derived automatically from images of a real 3D object. Shape reconstruction is guided by a set of imaginary springs that enforce the consistency in the position, orientation, and/or curvature measurements of the elastic grid and the desired shape. The dynamics of a surface reconstruction process is regulated by Hamilton's principle or the principle of the least action. Furthermore, a 1D deformable template that borders the elastic grid may be used. This companion boundary template is attracted/repelled by image forces to conform with the silhouette of the imaged object. Implementation results using simple analytic shapes and images of real objects are presented.","Surface reconstruction,
Deformable models,
Image reconstruction,
Shape measurement,
Image analysis,
Springs,
Position measurement,
Surface structures,
Wire,
Computer science"
Active object recognition,"The concept of active object recognition is introduced, and a proposal for its solution is described. The camera is mounted on the end of a robot arm on a mobile base. The system exploits the mobility of the camera by using low-level image data to drive the camera to a standard viewpoint with respect to an unknown object. From such a viewpoint, the object recognition task is reduced to a two-dimensional pattern recognition problem. The system uses an efficient tree-based, probabilistic indexing scheme to find the model object that is likely to have generated the observed data, and for line tracking uses a modification of the token-based tracking scheme of J.L. Crowley et al. (1988). The system has been successfully tested on a set of origami objects. Given sufficiently accurate low-level data, recognition time is expected to grow only logarithmically with the number of objects stored.",
Constructing word-based text compression algorithms,"Text compression algorithms are normally defined in terms of a source alphabet Sigma of 8-bit ASCII codes. The authors consider choosing Sigma to be an alphabet whose symbols are the words of English or, in general, alternate maximal strings of alphanumeric characters and nonalphanumeric characters. The compression algorithm would be able to take advantage of longer-range correlations between words and thus achieve better compression. The large size of Sigma leads to some implementation problems, but these are overcome to construct word-based LZW, word-based adaptive Huffman, and word-based context modelling compression algorithms.","Compression algorithms,
Computer science,
Context modeling,
Encoding"
Subphonetic modeling with Markov states-Senone,"There will never be sufficient training data to model all the various acoustic-phonetic phenomena. How to capture important clues and estimate those needed parameters reliably is one of the central issues in speech recognition. Successful examples include subword models, fenones and many other smoothing techniques. In comparison with subword models, subphonetic modeling may provide a finer level of details. The authors propose to model subphonetic events with Markov states and treat the state in phonetic hidden Markov models as the basic subphonetic unit-senone. Senones generalize fenones in several ways. A word model is a concatenation of senones and senones can be shared across different word models. Senone models not only allow parameter sharing, but also enable pronunciation optimization. The authors report preliminary senone modeling results, which have significantly reduced the word error rate for speaker-independent continuous speech recognition.",
CDNN: a context dependent neural network for continuous speech recognition,"A series of theoretical and experimental results have suggested that multilayer perceptrons (MLPs) are an effective family of algorithms for the smooth estimate of highly dimensioned probability density functions that are useful in continuous speech recognition. All of these systems have exclusively used context-independent phonetic models, in the sense that the probabilities or costs are estimated for simple speech units such as phonemes or words, rather than biphones or triphones. Numerous conventional systems based on hidden Markov models (HMMs) have been reported that use triphone or triphone like context-dependent models. In one case the outputs of many context-dependent MLPs (one per context class) were used to help choose the best sentence from the N best sentences as determined by a context-dependent HMM system. It is shown how, without any simplifying assumptions, one can estimate likelihoods for context-dependent phonetic models with nets that are not substantially larger than context-independent MLPs.",
On optimal population size of genetic algorithms,"A description is given of the results of experiments to find the optimum population size for genetic algorithms as a function of problem complexity. It seems that for moderate problem complexity the optimal population size for problems coded as bitstrings is approximately the length of the string in bits for sequential machines. This result is also consistent with earlier experimentation. In parallel architectures the optimal population size is larger than in the corresponding sequential cases, but the exact figures seem to be sensitive to implementation details.",
Well-behaved dataflow programs for DSP computation,"Accumulation of tokens on the arcs of a dataflow program operating on potentially infinite streams in a DSP computation leads to unbounded storage requirement. Compile-time techniques to determine the storage requirement are essential for efficient scheduling. A class of program graphs called regular stream flow graphs is studied. Restricting the construction to a set of construction rules facilitates compile-time predictability of storage requirement. Compared to existing methods, the model has a stronger verifiability, which is due to the structure of the well-constructed graphs.","Digital signal processing,
Switches,
Flow graphs,
Concurrent computing,
Computer science,
Processor scheduling,
Batteries,
Testing"
Cognitive fit: an empirical study of recursion and iteration,"A laboratory experiment was conducted to assess the basic theory and extensions to the theory for recursive tasks across programming languages. The experiment used 34 LISP and 48 PASCAL computer science students in two repeated measures designs. Findings of the study are reported and analyzed. The results strongly suggest that investigation of programming constructs should take place in the context of specific programming languages. Since a number of languages provide similar kinds of programming constructs, it is difficult for programmers to choose those implementations that best suit their needs. One way of encouraging the use of desirable constructs would be to develop languages adapted to certain types of tasks. Such an approach would inherently lead to cognitive fit and the attendant performance benefits would be realized.",
Experiments in dual-arm manipulation planning,The problem of dual-arm manipulation planning is to plan the path of two cooperating robot arms to carry a moveable object from a given initial configuration to a given goal configuration amidst obstacles. The authors survey previous work in manipulation planning and relate it to this analysis. A formal configuration space presentation of the problem is given. Three implemented planners are described. These three planners operated in a two-dimensional workspace and addressed increasingly difficult versions of the dual-arm manipulation problem. They were implemented in the C language. Execution times given were obtained by running them on a DEC 5000 workstation.,"Arm,
Path planning,
Robots,
Kinematics,
Motion planning,
Orbital robotics,
Manipulators,
Robotic assembly,
Laboratories,
Computer science"
"Learning Complex, Extended Sequences Using the Principle of History Compression","Previous neural network learning algorithms for sequence processing are computationally expensive and perform poorly when it comes to long time lags. This paper first introduces a simple principle for reducing the descriptions of event sequences without loss of information. A consequence of this principle is that only unexpected inputs can be relevant. This insight leads to the construction of neural architectures that learn to “divide and conquer” by recursively decomposing sequences. I describe two architectures. The first functions as a self-organizing multilevel hierarchy of recurrent networks. The second, involving only two recurrent networks, tries to collapse a multilevel predictor hierarchy into a single recurrent net. Experiments show that the system can require less computation per time step and many fewer training sequences than conventional training algorithms for recurrent nets.",
Issues and experiences designing and implementing two group drawing tools,"Groupware designers are developing multi-user equivalents of popular paint and draw applications. Their job is not an easy one. First, human factors issues peculiar to group interaction appear that, if ignored, seriously limit the usability of the group tool. Second, implementation is fraught with considerable hurdles. The authors describe the issues and experiences they have met and handled in the design of two systems supporting remote real time group interaction: GroupSketch, a multi-user sketchpad; and GroupDraw, an object-based multi-user draw package. On the human factors side, they summarize empirically-derived design principles that are critical to building useful and usable collaborative drawing tools. On the implementation side, they describe experiences with replicated versus centralized architectures, schemes for participant registration, multiple cursors, network requirements, and the structure of the drawing primitives.",
Replication and mobility,"Mobility of users and services and its impact on data replication and migration will be one of the main technical problems to be resolved. In fact, the authors view mobility as probably the most challenging new issue facing distributed systems of the future. The distinct new element which mobility brings into the issues of data replication is system's uncertainty about its own state (meaning primarily location). Thus the cost of communication between two mobile users is dependent not only on the distance between them but also on the cost of search necessary to determine the exact value of location. The authors address some of the questions, by proposing an adaptive replication scheme for mobile data.",
Improved Multithreading Techniques for Hiding Communication Latency in Multiprocessors,"Shared memory multiprocessors are considered among the easiest parallel computers to program. However building shared memory machines with thousands of processors has proved difficult because of the inevitably long memory latencies. Much previous research has focused on cache coherency techniques, but it remains unclear if caches can obtain sufficiently high hit rates. In this paper we present improved multithreading techniques that can easily tolerate latencies of hundreds of cycles, and yet only require a small number of threads per processor. High performance is achieved by introducing an explicit context switch instruction that can be used by a simple optimizing compiler to group together several shared accesses. This grouping of shared accesses dramatically reduces the frequency of context switches compared to simpler multithreading models. The combination of our techniques achieves efficiencies of 80% or higher on a broad set of applications.",
Applying features of IEEE 754 to sign/logarithm arithmetic,"Various features found in standard floating point arithmetic (IEEE 754) are examined in light of their appropriateness for sign/logarithm arithmetic. The emphasis is on a 32-b word size comparable to IEEE 754 single precision, although other word sizes are possible. A multilayer sign/logarithm format is considered. The lowest layer, similar to previous implementations, would provide only normalized representations but would not provide representations for zero, denormalized values, infinities, and NaNs. The highest layer would provide most of the features found in IEEE 754, including zeros, denormalized values, infinities, and NaNs. Novel algorithms for implementing logarithmic denormalized arithmetic are presented. Simulation results show that the error characteristics of the proposed logarithmic denormalized arithmetic algorithms are similar to those of the denormalized floating point arithmetic in IEEE 754.",
Primarily disconnected operation: experiences with Ficus,"Ficus is a flexible replication facility with optimistic concurrency control designed to span a wide range of scales and network environments. Support for partitioned operation is fundamental to the Ficus design but was not widely exercised in early Ficus use. This paper reports recent experiences using Ficus in settings where some replicas are only occasionally connected to a network, and hence partitioned operation is the rule rather than the exception. The authors conclude that with some tuning, Ficus adapted quite well to primarily disconnected operation.","File systems,
Portable computers,
IP networks,
Computer science,
Design optimization,
Concurrency control,
Delay,
Contracts,
Scholarships,
Electronic mail"
"Disjoint difference sets, difference triangle sets, and related codes","Disjoint difference sets (DDS), difference triangle sets (DTS), and related codes are discussed and a recursive construction for DDS is given. With this construction and the relationship between DDS and DTS, many new upper bounds for DTS and some better orthogonal codes are obtained.<>",
Representation and recovery of road geometry in YARF,"YARF, like several other road following systems, models the road as features which form concentric circular arcs lying in a flat ground plane. Two approximations are made in order to use a linear estimation technique to determine the spine parameters. The paper demonstrates that errors due to these approximations are reduced substantially by estimating the spine parameters in a data-dependent coordinate system rather than in a vehicle-centered coordinate system. It discusses the problem of estimating the spine parameters in the presence of outlying data. Using standard least squares estimation can result in the vehicle drifting off the road due to errors in the parameter estimates caused by such contaminants in the data. The use of least median squares estimation to overcome these problems is discussed.","Geometry,
Least squares approximation,
Parameter estimation,
Image segmentation,
Computational efficiency,
Data mining,
Robust stability,
Computer science,
Road vehicles,
Noise robustness"
Fast algorithms for routing around faults in multibutterflies and randomly-wired splitter networks,"Simple deterministic O(log N)-step algorithms for routing permutations of packets in multibutterflies and randomly wired splitter networks are described. The algorithms are robust against faults (even in the worst case), and are efficient from a practical point of view. As a consequence, it is found that the multibutterfly is an excellent candidate for a high-bandwidth low-diameter switching network underlying a shared-memory machine.",
How people write together (groupware),"Builders of groupware writing technologies need a better understanding of collaborative writing if their systems are to adequately address user needs. The authors present a taxonomy of joint writing based on an analysis of interviews with authors who have written documents together. The taxonomy describes joint writing in terms of four components: roles played in the collaboration, activities performed in the writing process, document control methods used, and writing strategies employed. The authors conclude by outlining a set of design requirements for collaborative writing that are suggested by the interviews and the taxonomy, and by evaluating six existing systems with respect to these requirements.",
ELM-a fast addition algorithm discovered by a program,"A new addition algorithm, ELM, is presented. This algorithm makes use of a tree of simple processors and requires O(log n) time, where n is the number of bits in the augend and addend. The sum itself is computed in one pass through the tree. This algorithm was discovered by a VLSI CAD tool, FACTOR, developed for use in synthesizing CMOS VLSI circuits.",
Rollback recovery in distributed systems using loosely synchronized clocks,"A rollback recovery scheme for distributed systems is proposed. The state-save synchronization among processes is implemented by bounding clock drifts such that no state-save synchronization messages are required. Since the clocks are only loosely synchronized, the synchronization overhead can be negligible in many applications. An interprocess communication protocol which encodes state-save progress information within message frames is introduced to checkpoint consistent system states. A rollback recovery algorithm that will force a minimum number of nodes to roll back after failures is developed.",
A model of workloads and its use in miss-rate prediction for fully associative caches,"A mathematical model for the behavior of programs or workloads is presented and from it is extracted the miss ratio of a finite, fully associative cache (or other first-level memory) using least-recently-used replacement under those workloads. To obtain miss ratios, the function u(t, L), defined to be the number of unique lines of size L referenced before time t, is modeled. Empirical observations show that this function appears to have the form u(t, L)=(W L/sup a/t/sup b/) (d/sup log/ /sup L log t/) where W, a, b, d are constants that are related, respectively, to the working set size, locality of references to nearby addresses (spatial locality), temporal locality (locality in time not attributable to spatial locality), and interactions between spatial locality and temporal locality. The miss ratio of a finite fully associative cache can be approximated as the time derivative of u(t, L) evaluated where the function has a value equal to the size of the cache. When the miss ratios from this model are compared to measured miss ratios for a representative trace, the accuracy is high for large caches. For smaller caches, the model is close but not highly precise.",
A Distributed Neural Network Architecture for Hexapod Robot Locomotion,"We present fully distributed neural network architecture for controlling the locomotion of a hexapod robot. The design of this network is directly based on work on the neuroethology of insect locomotion. Previously, we demonstrated in simulation that this controller could generate a continuous range of statically stable insect-like gaits as the activity of a single command neuron was varied and that it was robust to a variety of lesions. We now report that the controller can be utilized to direct the locomotion of an actual six-legged robot, and that it exhibits a range of gaits and degree of robustness in the real world that is quite similar to that observed in simulation.",
Point correspondence recovery in non-rigid motion,"A method for the estimation of point correspondences on a surface undergoing nonrigid motion, based on changes in Gaussian curvature, is described. An approach for estimating the point correspondences and stretching of a surface undergoing conformal motion with constant (homothetic), linear, or polynomial stretching is proposed. Small motion assumption is utilized to hypothesize all possible point correspondences. Curvature changes are then computed for each hypothesis. The difference between computed curvature changes and the one predicted by the conformal motion assumption is calculated. The hypothesis with the smallest error gives point correspondences between consecutive time frames. Simulations performed on ellipsoidal data illustrate the performance and accuracy of derived algorithms. The algorithm is applied to volumetric CT data of the left ventricle of a dog's heart.",
Monitoring timing constraints in distributed real-time systems,"A run-time environment for monitoring distributed real-time systems is described. In particular, the authors focus on the problem of detecting violations of timing assertions in an environment in which the real-time tasks run on multiple processors, and timing constraints can be either interprocessor or intraprocessor constraints. Constraint violations are detected at the earliest possible time by deriving and checking intermediate constraints. If the violations must be detected as early as possible, then the problem of minimizing the number of messages to be exchanged between the processors becomes intractable. The authors characterize a subclass of timing constraints that occur commonly in distributed real-time systems and whose message requirements can be minimized. They also take into account the drift among the various processor clocks when detecting a violation of a timing assertion. Finally, an implementation of a distributed run-time monitor is described.",
Chaotic Binary Sequences by Chebyshev Maps and Their Correlation Properties,,
Robust focus ranging,"Depth maps obtained from focus ranging can have numerous errors and distortions due to edge bleeding, feature shifts, image noise, and field curvature. An improved algorithm that examines an initial high depth-of-field image of the scene to identify regions susceptible to edge bleeding and image noise is given. Focus evaluation windows are adapted to local image content and optimize the tradeoff between spatial resolution and noise sensitivity. An elliptical paraboloid field curvature model is used to reduce range distortion in peripheral image areas. Spatio-temporal tracking compensates for image feature shifts. The result is a sparse but reliable depth map.",
Discrete wavelet transforms in VLSI,"Three architectures, based on linear systolic arrays, for computing the discrete wavelet transform, are described. The AT/sup 2/ lower bound for computing the DWT in a systolic model is derived and shown to be AT/sup 2/= Omega (N/sup 2/N/sub w/k). Two of the architectures are within a factor of log N from optimal, but they are of practical importance due to their regular structure, scalability and limited I/O needs. The third architecture is optimal, but it requires complex control.","Discrete wavelet transforms,
Very large scale integration,
Computer architecture,
Frequency,
Filters,
Convolution,
Computer science,
Systolic arrays,
Scalability,
Optimal control"
Evaluation of the WM Architecture,"This report describes the results of studies of the WM architecture- its performance, the values of some of its key architectural parameters, the difficulty of compiling for it, and hardware implementation complexity. The studies confirm that, with comparable chip area and without heroic compiler technology, WM is capable of outperforming traditional scalar architectures by factors of 2-9. They also underscore the need to devise higher bandwidth memory systems.",
Exact analysis of hot-potato routing,"The authors consider a form of packet routing known as hot potato routing or deflection routing. Its striking feature is that there are no buffers at intermediate nodes. Thus packets are always moving (possibly in the 'wrong' direction), giving rise to the term 'hot potato'. They give a simple deterministic algorithm that on a n*n torus will route a random instance in 2n+O(log n) steps with high probability. They add random delays to this algorithm so that it solves the permutation routing problem on the torus in 9n steps with high probability, on every instance. On a hypercube with N=2/sup n/ nodes, they give a simple deterministic algorithm that will route a random instance in O(n) steps with high probability. Various other results are discussed.",
Optimization of fuzzy logic inference architecture,"A fuzzy logic controller architecture that is efficient in both performance and cost is proposed. Optimization of the fuzzy logic circuits is discussed. To speed up the inference process, the defuzzification operation is precomputed, and partial results are stored for runtime uses. Thus, larger memory is traded for better performance. The proposed architecture is less general than previous implementations, but offers better performance and cost.",
On-line load balancing,"The setup for the authors' problem consists of n servers that must complete a set of tasks. Each task can be handled only by a subset of the servers, requires a different level of service, and once assigned can not be re-assigned. They make the natural assumption that the level of service is known at arrival time, but that the duration of service is not. The on-line load balancing problem is to assign each task to an appropriate server in such a way that the maximum load on the servers is minimized. The authors derive matching upper and lower bounds for the competitive ratio of the on-line greedy algorithm for this problem, namely /sup (3n)2/3///sub 2/(1+o(1)), and derive a lower bound, Omega ( square root n), for any other deterministic or randomized on-line algorithm.",
Developments with maximum likelihood X-ray computed tomography,"An approach to the maximum-likelihood estimation of attenuation coefficients in transmission tomography is presented as an extension of earlier theoretical work by K. Lange and R. Carson (J. Comput. Assist. Tomography, vol.8, p.306-16, 1984). The reconstruction algorithm is based on the expectation-maximization (EM) algorithm. Several simplifying approximations are introduced which make the maximization step of the algorithm available. Computer simulations are presented using noise-free and Poisson randomized projections. The images obtained with the EM-type method are compared to those reconstructed with the EM method of Lange and Carson and with filtered backprojection. Preliminary results show that there are potential advantages in using the maximum likelihood approaches in situations where a high-contrast object, such as bone, is embedded in low-contrast soft tissue.",
Evaluation and improvement of fault coverage of conformance testing by UIO sequences,"The fault coverage of testing protocols using unique input/output (UIO) sequences is analyzed. UIO sequences can be efficiently employed in checking the conformance specifications of protocols by using transition testing. The test sequence is found using the rural Chinese postman tour algorithm. A comprehensive fault model is developed, and analytical expressions are given for the fault coverage. The conditions for undetectability are analyzed, and a new algorithm is proposed. Simulation results and illustrative examples are presented. Overhead issues are discussed, and significant improvements are shown for achieving 100% fault coverage. The major advantage of the proposed approach is that it provides the theoretical basis for fault coverage evaluation of protocol testing using UIO sequences.",
A processor-time-minimal systolic array for transitive closure,"Using a directed acyclic graph (DAG) model of algorithms, the authors focus on processor-time-minimal multiprocessor schedules: time-minimal multiprocessor schedules that use as few processors as possible. The Kung, Lo, and Lewis (KLL) algorithm for computing the transitive closure of a relation over a set of n elements requires at least 5n-4 parallel steps. As originally reported. their systolic array comprises n/sup 2/ processing elements. It is shown that any time-minimal multiprocessor schedule of the KLL algorithm's dag needs at least n/sup 2//3 processing elements. Then a processor-time-minimal systolic array realizing the KLL dag is constructed. Its processing elements are organized as a cylindrically connected 2-D mesh, when n=0 mod 3. When n not=0 mod 3, the 2-D mesh is connected as a torus.",
Increased memory performance during vector accesses through the use of linear address transformations,"A technique to analyze transformation matrices is presented. This technique is based on decomposing complex transformations into elementary transformations. When combined with a factorization of the access stride into two components, one a power of 2 and the other relatively prime to 2, the technique leads to an algorithmic synthesis of a CF (conflict free) storage scheme. Additionally, because the address to storage location mapping arithmetic is performed modulo 2, the time required to transform an address to its corresponding storage location is smaller and the hardware cost is lower than if schemes based on row rotation were used.",
Real time inverse kinematics for general 6R manipulators,"The authors present a real-time algorithm for the inverse kinematics of general 6R robot manipulators. The algorithm involves symbolic preprocessing, matrix computation and a variety of numerical techniques. The numerical accuracy of these operations is well understood and for most cases it is possible to compute accurate solutions using 64-b IEEE floating point arithmetic available on most workstations. The average running time of the algorithm, for most cases, is 11 ms on an IBM RS/6000 workstation.",
"Charge generation by heavy ions in power MOSFETs, burnout space predictions and dynamic SEB sensitivity","The transport, energy loss, and charge production of heavy ions in the sensitive regions of IRF 150 power MOSFETs are described. The dependence and variation of transport parameters with ion type and energy relative to the requirements for single event burnout in this part type are discussed. Test data taken with this power MOSFET are used together with analyses by means of a computer code of the ion energy loss and charge production in the device to establish criteria for burnout and parameters for space predictions. These parameters are then used in an application to predict burnout rates in a geostationary orbit for power converters operating in a dynamic mode. Comparisons of rates for different geometries in simulating SEU (single event upset) sensitive volumes are presented.",
Improving the visualization of hierarchies with treemaps: design issues and experimentation,"Controlled experiments with novice treemap users and real data highlight the strengths of treemaps and provide direction for improvement. Issues discussed include experimental results, layout algorithms, nesting offsets, labeling, animation, and small multiple displays. Treemaps prove to be a potent tool for hierarchy display. The principles discussed are applicable to many information visualization situations.",
"Is layering, harmful? (remote procedure call)",Remote procedure call (RPC) mechanisms over the US Department of Defense transmission control protocol. (TCP) can produce behavior analogous to the silly window syndrome because of a mismatched interface between the socket and the TCP modules. The detection and diagnosis of the problem are addressed. Some pointers to a design approach that could avoid the problems of mismatched communication layers are provided.,
From negotiation to negotiation support systems: a theoretical perspective,"An overview is given of the existing negotiation literature under the headings of game theory, economic models, political models, and sociological models. Inferring from the review the need for computer support for negotiation, the authors then propose a theory for understanding the effects due to a support system in a two-party, monolithic, and multiple-issue setting. The theory conceptualizes a negotiation support system as consisting of individual decision support systems interconnected with an electronic communication channel; accordingly, it postulates two sets of effects, one owing to the decision aid and the other to the communication support.",
Details of simulated annealing algorithm to estimate parameters of multiple current dipoles using biomagnetic data,"The details of the simulated annealing algorithm proposed to estimate the parameters of multiple current dipoles using biomagnetic data are described. The effects of the choices of such numerical conditions as the amount of estimate transitions, the equilibrium criterion, and the temperature decrement on the algorithm's performance are discussed. Incorrect results from the computer simulation obtained with inappropriate choices of such conditions are presented. The verification of a near-optimum convergence by reheating and reannealing is demonstrated. A modification of this algorithm is proposed for implementation by parallel computer, and the validity of this parallel algorithm is demonstrated by computer simulation.",
Safe and effective determinant evaluation,"The problem of evaluating the sign of the determinant of a small matrix aries in many geometric algorithms. Given an n*n matrix A with integer entries, whose columns are all smaller than M in Euclidean norm, the algorithm given evaluates the sign of the determinant det A exactly. The algorithm requires an arithmetic precision of less than 1.5n+2lgM bits. The number of arithmetic operations needed is O(n/sup 3/)+O(n/sup 2/) log OD(A)/ beta , where OD(A) mod det A mod is the product of the lengths of the columns of A, and beta is the number of 'extra' bits of precision, min(lg(1/u)-1.1n-2lgn-2,lgN-lgM-1.5n-1), where u is the roundoff error in approximate arithmetic, and N is the largest representable integer. Since OD(A)",
Neural fuzzy logic programming,"A foundational development of propositional fuzzy logic programs is presented. Fuzzy logic programs are structured knowledge bases including uncertainties in rules and facts. The precise specifications of uncertainties have a great influence on the performance of the knowledge base. It is shown how fuzzy logic programs can be transformed to neural networks, where adaptations of uncertainties in the knowledge base increase the reliability of the program and are carried out automatically.",
An accurate analytical BiCMOS delay expression and its application to optimizing high-speed BiCMOS circuits,"A scheme for optimizing the overall delay of BiCMOS driver circuits is proposed in this paper. Using this optimization scheme, it is found that the delay is minimized when the maximum collector current of the bipolar transistors is equal to the onset of high current effects. Using this assumption, an accurate BiCMOS delay expression is derived in terms of the bipolar and MOS device parameters. The critical device parameters are then identified and their influence on the circuit speed discussed. An overall circuit delay expression for optimizing BiCMOS buffers is derived and a comparison made with CMOS buffers. It is shown that BiCMOS circuits have a speed advantage of 1.7 or an area advantage of about 5 for 2- mu m feature sizes. In order to predict the future performance of BiCMOS circuits, a figure of merit is derived from the delay expression. Using the figure-of-merit expression, it is seen that future BiCMOS circuits can keep the speed advantage over CMOS circuits down to submicrometer dimensions under constant load capacitance assumption.",
Adaptive State Space Quantisation For Reinforcement Learning Of collision-free navigation,,
Subprogram inlining: a study of its effects on program execution time,"Equations representing the execution time performance of noninlined and inlined versions of a program have been developed. The accuracy of the equations' description of inlined program execution time behavior was demonstrated on four computer systems. Using the equations, understanding of how certain factors influence the speed of inlined code was gained. Contrary to a number of published reports in the literature, the increased size of inlined code was not found to affect its execution time performance on demand-paged virtual memory machines. On such systems, neither the use of an inlining algorithm that includes program size constraints nor the substitution of interprocedural data flow analysis for inlining is warranted. A modest improvement in the caching and paging behavior of test programs' inlined versions was also observed.","Equations,
Lifting equipment,
Data analysis,
Algorithm design and analysis,
Program processors,
Motion control,
Registers,
Computer science,
System testing,
Programming profession"
A micro-grained VLSI signal processor,"A very-fine-grain, VLSI processor is described. Very-fine-grain VLSI processors are especially suited for problems with a high degree of parallelism. However, to maintain their fine grainness (i.e., small size) most fine grain processors are relatively inflexible. Attempts to increase flexibility usually increase processor complexity and, thereby, decreases grainness. The two-dimensional, micrograined processor maintains both a high degree of flexibility and fine grainness by reducing each processing cell to a small RAM and several multiplexers. For even greater speed, arithmetic operations are based on a redundant number representation. Algorithms for single-instruction multiple-data (SIMD), mesh architectures can be easily adapted for the micrograined processor. This is particularly true for algorithms for certain two-dimensional signal and image processing problems.",
Markov paging,"This paper considers the problem of paging under the assumption that the sequence of pages accessed is generated by a Markov chain. The authors use this model to study the fault-rate of paging algorithms, a quantity of interest to practitioners. They first draw on the theory of Markov decision processes to characterize the paging algorithm that achieves optimal fault-rate on any Markov chain. They address the problem of efficiently devising a paging strategy with low fault-rate for a given Markov chain. They show that a number of intuitively good approaches fail. Their main result is an efficient procedure that, on any Markov chain, will give a paging algorithm with fault-rate at most a constant times optimal. Their techniques also show that some algorithms that do poorly in practice fail in the Markov setting, despite known (good) performance guarantees when the requests are generated independently from a probability distribution.",
Slot allocation strategies for TDMA protocols in multihop packet radio networks,"The authors derive an upper bound of the minimum time division multiple access (TDMA) frame length of any collision-free node assignment protocol in a packet radio network in which a node has multiple reception capacity. They also derive the optimum TDMA frame length for any fully connected network with large reception capacity. When the total number of nodes in the network is unknown, a heuristics to generate a TDMA protocol with frame length within some upper bound is presented for any network with large reception capacity.",
The decoupling of generalized state-space systems via state feedback,"The input-output decoupling problem of generalized state-space systems (GSS) via proportional state feedback is studied. The following three major issues are resolved: the necessary and sufficient conditions for the problem to have a solution, the general analytical expressions of the controller matrices, and the general analytical expressions of the diagonal elements of the closed-loop system. It is concluded that the approach presented seems to be a quite powerful tool for solving several feedback design problems for GSS systems. Using this method, problems such as decoupling and simultaneous pole assignment and decoupling via output feedback are successfully studied.",
On the fault tolerance of some popular bounded-degree networks,"The authors analyze the fault-tolerance properties of several bounded-degree networks that are commonly used for parallel computation. Among other things, they show that an N-node butterfly containing N/sup 1- epsilon / worst-case faults (for any constant epsilon >0) can emulate a fault-free butterfly of the same size with only constant slowdown. Similar results are proved for the shuffle-exchange graph. Hence, these networks become the first connected bounded-degree networks known to be able to sustain more than a constant number of worst-case faults without suffering more than a constant-factor slowdown in performance. They also show that an N-node butterfly whose nodes fail with some constant probability p can emulate a fault-free version of itself with a slowdown of 2/sup O(log* N)/, which is a very slowly increasing function of N. The proofs of these results combine the technique of redundant computation with new algorithms for routing packets around faults in hypercubic networks. Techniques for reconfiguring hypercubic networks around faults that do not rely on redundant computation are also presented. These techniques tolerate fewer faults but are more widely applicable since they can be used with other networks such as binary trees and meshes of trees.",
Communication on noisy channels: a coding theorem for computation,"Communication is critical to distributed computing, parallel computing, or any situation in which automata interact-hence its significance as a resource in computation. In view of the likelihood of errors occurring in a lengthy interaction, it is desirable to incorporate this possibility in the model of communication. The author relates the noisy channel and the standard (noise less channel) complexities of a communication problem by establishing a 'two-way' or interactive analogue of Shanon's coding theorem: every noiseless channel protocol can be simulated by a private-coin noisy channel protocol whose time bound is proportional to the original (noiseless) time bound and inversely proportional to the capacity of the channel, while the protocol errs with vanishing probability. The method involves simulating the original protocol while implementing a hierarchical system of progress checks which ensure that errors of any magnitude in the simulation are, with high probability, rapidly eliminated.",
Fuzzy neural controller,"The authors consider a fuzzy controller that processes fuzzy information. They discuss the model of the fuzzy controller, with fuzzy inputs for error and change in error, using a max-min neural network. A new learning algorithm, a modified delta rule, is derived. The generalization property of the neural net can be used to find a controller output for new fuzzy values of error and change in error. An example is presented showing the applicability of the fuzzy neural controller.",
Connectionist probability estimation in the DECIPHER speech recognition system,"The authors have previously demonstrated that feedforward networks can be used to estimate local output probabilities in hidden Markov model (HMM) speech recognition systems (Renals et al., 1991). These connectionist techniques are integrated into the DECIPHER system, with experiments being performed using the speaker-independent DARPA RM database. The results indicate that: connectionist probability estimation can improve performance of a context-independent maximum-likelihood-trained HMM system; performance of the connectionist system is close to what can be achieved using (context-dependent) HMM systems of much higher complexity; and mixing connectionist and maximum-likelihood estimates can improve the performance of the state-of-the-art context-independent HMM system.",
Towards An Assembly Plan From Observation: Part II: Correction Of Motion parameters Based On Fact Contact Constraints,,
Benchmarking the CM-5 multicomputer,"The authors study the performance of the CM-5 multiprocessor. They provide a number of benchmarks for its communication and computation performance. Many of the operations, like scans and global reduction, can be performed using special hardware available on the CM-5. These operations have been benchmarked. The authors also describe how to embed a mesh and a hypercube on a CM-5 architecture and provide timings for some mesh and hypercube communication primitives on the CM-5.","Communication system control,
Hardware,
Communication networks,
Network interfaces,
Computer science,
Computer architecture,
Timing,
Hypercubes,
Broadcasting,
Fault diagnosis"
Robust parsing for spoken language systems,"A recent extension to the MIT ATIS (Air Travel Information Service) system, which allows it to answer a question when a full linguistic analysis fails is described. Robust parsing is applied only after a full analysis has failed, and it involves the two stages of (1) parsing a set of phrases and clauses, and (2) gluing them together to obtain a single semantic frame encoding the full meaning of the sentence. In a recent evaluation, less than two-thirds of the sentences analyzed yielded a full parse, but the overwhelming majority of the remaining sentences were analyzed correctly by the robust parsing scheme. When text input was replaced by recognizer outputs, even though the recognizer produced greater than 50% sentence error rate, the drop in score (%correct-%incorrect) was only 10 percentage points. This indicates that most of the recognizer errors are harmless in terms of meaning analysis, as long as a robust mechanism for accounting for the parsable phrases is in place.",
Progress in neural network-based vision for autonomous robot driving,"This paper describes recent improvements to the ALVINN system (Autonomous Land Vehicle In a Neural Network) for neural network based autonomous driving. The authors perviously (1991, 1992) reported a technique which allows an an artificial neural network to quickly learn to steer by watching a person drive. But the faster the network is trained, the less exposure it receives to novel or infrequent scenarios. For instance, during a typical four minute training run, the network sees few if any examples of passing cars. When a rare situation like this occurs during testing, its lack of coverage in the training set canresult in erratic driving. By modeling the appearance of infrequent scenarios and then using the model to augment the training set, one can teach the network to generalize to situations not explicitly represented in the live training data. Using this technique, a network trained over a two mile stretch of highway was able to drive autonomously for 21.2 miles at speeds of up to 55 miles/hour.",
Competitive analysis of financial games,"In the unidirectional conversion problem an on-line player is given the task of converting dollars to yen over some period of time. Each day, a new exchange rate is announced and the player must decide how many dollars to convert. His goal is to minimize the competitive ratio. defined as sup/sub E/ (P/sub OPT/(E)/P/sub X/E) where E ranges over exchange rate sequences. P/sub OPT/(E) is the number of yen obtained by an optimal off-line algorithm, and Px(E) is the number of yen obtained by the on-line algorithm X. The authors also consider a continuous version of the problem. in which the exchange rate varies over a continuous time interval. The on-line line players a priori information about the fluctuation of exchange rates distinguishes different variants of the problem. For three variants they show that a simple threat-based strategy is optimal for the on-line player and determine its competitive ratio. They also derive and analyze an optimal policy for the on-line player when he knows the probability distribution of the maximum value that the exchange rate will reach. Finally, they consider a bidirectional conversion problem, which the player may trade dollars for yen or yen for dollars.","Exchange rates,
Portfolios,
Cost function,
Loans and mortgages,
Probability distribution,
Algorithm design and analysis,
Decision making,
Investments,
Stock markets,
History"
Computing curvilinear structure by token-based grouping,"A computational framework for computing curvilinear structure on the edge data of images is presented. The method is symbolic, operating on geometric entities/tokens. It is also constructive, hierarchical, parallel, and locally distributed. Computation proceeds independently at each token and at each stage interleaves the discovery of structure with its careful description. The process yields a hierarchy of descriptions at multiple scales. These multiscale descriptions provide efficient feature indexing both for the grouping process itself as well as for subsequent recognition processes. Experimental results are presented to demonstrate the effectiveness of the approach with respect to curvilinear structure, and its application to more general grouping problems is discussed.",
Improving the software development process using testability research,"Software testability is the tendency of code to reveal existing faults during random testing. This paper proposes to take software testability predictions into account throughout the development process. These predictions can be made from formal specifications, design documents, and the code itself. The insight provided by software testability is valuable during design, coding, testing and quality assurance. The authors believe that software testability analysis can play a crucial role in quantifying the likelihood that faults are not hiding, after the testing does not result in any failures for the current version.","Programming,
Software testing,
Software quality,
Quality assurance,
Fault detection,
Formal specifications,
Failure analysis,
Error correction,
Computer science,
Educational institutions"
Load balancing for distributed branch & bound algorithms,"The authors present a new load balancing strategy and its application to distributed branch & bound algorithms and demonstrate its efficiency by solving some NP-complete problems on a network of up to 256 transputers. The parallelization of their branch & bound algorithm is fully distributed. Every processor performs the same algorithm but each on a different part of the solution tree. In this case it is necessary to distribute subproblems among the processors to achieve a well balanced workload. Their load balancing method overcomes the problem of search overhead and idle times by an appropriate load model and avoids trashing effects by a feedback control method. Using this strategy they were able to achieve a speedup of up to 237.32 on a 256 processor network for very short parallel computation times, compared to an efficient sequential algorithm.","Load management,
Space technology,
Mathematics,
Computer science,
Electronic mail,
Application software,
Load modeling,
Feedback control,
Artificial intelligence,
Parallel processing"
An Electroid Switching Model For Reversible Computer Architectures,,
Generalized key-equation of remainder decoding algorithm for Reed-Solomon codes,A key equation of the remainder decoding algorithm is presented. It is noted that the key equation presents a general relationship between the errors on the received codeword and the coefficients of the remainder polynomial. It is shown that several key equations proposed by L. Welch and E.R. Berlekamp (1983) and others can be derived from the proposed key equation. Useful properties of the key equations in fast decoding of Reed-Solomon codes are given.,
A genetic approach to the truck backer upper problem and the inter-twined spiral problem,"The author describes a biologically motivated paradigm, genetic programming, which can solve a variety of problems. When genetic programming solves a problem, it produces a computer program that takes the state variables of the system as input and produces the actions required to solve the problem as output. Genetic programming is explained and applied to two well-known benchmark problems from the field of neural networks. The truck backer upper problem is a multidimensional control problem and the inter-twined spirals problem is a challenging classification problem.",
Optimal control of admission to a multiserver queue with two arrival streams,"The problem of finding an optimal admission policy to an M/M/c queue with one controlled and one uncontrolled arrival stream is addressed There are two streams of customers that are generated according to independent Poisson processes with constant arrival rates. The service time probability distribution is exponential and does not depend on the class of the customers. Upon arrival a class 1 customer may be admitted or rejected, while incoming class 2 customers are always admitted. A state-dependent reward is earned each time a new class 1 customer enters the system. When the discount factor is small, there exists a stationary admission policy of a threshold type that maximizes the expected total discounted reward over an infinite horizon. A similar result is also obtained when considering the long-run average reward criterion. The proof relies on a new device that consists of a partial construction of the solution of the dynamic programming equation. Applications arising from teletraffic analysis are proposed.",
Dynamic analysis of planar manipulation tasks,"The author presents two algorithms that construct a set of initial configurations from which a given action will reliably accomplish a planar manipulation task. The first algorithm applies energy arguments to construct a conservative set of successful initial configurations, while the second algorithm performs numerical integration to construct a set that is much less conservative. The algorithms may be applied to a variety of tasks, including pushing, placing-by-dropping, and force-controlled assembly tasks. Both algorithms consider the task geometry and mechanics, and allow uncertainty in every task parameter except for the object shapes. Experimental results which demonstrate the validity of the algorithms output for two example manipulation tasks are presented.","Manipulator dynamics,
Robotic assembly,
Uncertainty,
Geometry,
Shape,
Fixtures,
Laboratories,
End effectors,
Nonlinear equations,
Computer science"
On the bit extraction problem,"Consider a coloring of the n-dimensional Boolean cube with c=2/sup s/ colors in such a way that every k-dimensional subcube is equicolored, i.e. each color occurs the same number of times. The author shows that for such a coloring one necessarily has (k-1)/n>or= theta /sub c/=(c/2-1)/(c-1). This resolves the 'bit extraction' or 't-resilient functions' problem (also a special case of the privacy amplification problem) in many cases, such as c-1/n, proving that XOR type colorings are optimal, and always resolves this question to within c/4 in determining the optimal value of k (for any fixed n and c). He also studies the problem of finding almost equicolored colorings when (k-1)/n< theta /sub c/, and of classifying all optimal colorings.",
Multicriterion maximum entropy image reconstruction from projections,"A solution algorithm for the image reconstruction problem with three criteria, maximum entropy, minimum nonuniformity and peakedness, and least square error between the original projection data and projection due to reconstruction is presented. Theoretical results of precedence properties which are respected by all noninferior solutions are first derived. These precedence properties are then incorporated into a multiple-criteria optimization framework to improve the computational efficiency. Comparisons of the new algorithm to the MART and MENT algorithms are carried out using computer-generated noise-free and Gaussian noisy projections. Results of the computational experiment and the efficiency of the multiobjective entropy optimization algorithm (MEOA) are reported.","Entropy,
Image reconstruction,
Gaussian noise,
Biomedical engineering,
Noise generators,
Pixel,
Noise measurement,
Least squares methods,
Computational efficiency,
Biomedical imaging"
Sparsification-a technique for speeding up dynamic graph algorithms,"The authors provide data structures that maintain a graph as edges are inserted and deleted, and keep track of the following properties: minimum spanning forests, best swap, graph connectivity, and graph 2-edge-connectivity, in time O(n/sup 1/2/log(m/n)) per change; 3-edge-connectivity, in time O(n/sup 2/3/) per change; 4-edge-connectivity, in time O(n alpha (n)) per change; k-edge-connectivity, in time O(n log n) per change; bipartiteness, 2-vertex-connectivity, and 3-vertex-connectivity, in time O(n log(m/n)) per change; and 4-vertex-connectivity, in time O(n log(m/n)+n alpha (n)) per change. Further results speed up the insertion times to match the bounds of known partially dynamic algorithms. The algorithms are based on a technique that transforms algorithms for sparse graphs into ones that work on any graph, which they call sparsification.",
ComPaSS: efficient communication services for scalable architectures,"The authors describe the initial implementation of the ComPaSS communication library to support scalable software development in massively parallel processors. ComPaSS provides high-level global communication operations for both data manipulation and process control, many of which are based on a small set of low-level communication primitives. The ComPaSS library is unique in that these low-level operations are provably optimal for a class of architectures representative of many commercial scalable systems-in particular, those using wormhole routing and n-dimensional mesh network topologies. The authors concentrate on the multicast component of the ComPaSS library, which is useful in several data parallel operations. The design of the multicast primitive is described, and an example of its use in a data parallel application is given. Improvements in performance resulting from use of the library on a 64-node nCUBE-2 are presented.","Computer architecture,
Concurrent computing,
Software libraries,
Process control,
Parallel architectures,
Bandwidth,
Computer science,
Programming,
Global communication,
Routing"
Capability evaluation of a sinogram error detection and correction method in computed tomography,An iterative method for detecting and correcting errors in sinograms is described and its capability evaluated. The method is based on the use of a reconstruction-reprojection procedure to check the consistency of a sinogram. Adjustments of the sinogram are made iteratively to satisfy gradually the consistency requirement. The effectiveness of the method for detecting and correcting errors due to scanner detector problems is demonstrated with computer simulated data and with real data from position emission tomography. The potential usefulness of the method for quality control of scanners is discussed.,
In search of gigabit applications,"Applications in existing specialized, metacomputer environments and those yet to be developed for services such as telecommunications, distributed data, and image transfer that will require networks which can handle volumes of data on the order of gigabits per second are discussed. Specific examples are presented from the fields of computational science, data navigation, and collaborative environments and instrument control. It is concluded that distributed computing and collaborative environments that support the interaction of multiple computers, as well as the interaction of computers with humans, are the paradigms that will characterize gigabit applications.",
On The Limits Of Program Parallelism And Its Smoothability,,
A new representation for collision avoidance and detection,"By combining the simplicity of the sphere and the power of the motion of hierarchy of detail, a novel model is proposed with applications to collision avoidance and detection in 3D. The model is based on a double spherical representation for solid bodies. First, each element making up the robot and the obstacles is approximated by a set of exterior spheres which are automatically defined. Second, another set composed of interior spheres is generated. These representations define a hierarchy, since they can be redefined as many times as necessary; starting with two spheres per element, the approximation may be improved until it contains hundreds of spheres. Moreover, they converge to a zero-error representation. The proposed models leads to a simple treatment for the problem of collision detection, and it is further applied to collision-free path planning for manipulators in 3D.",
Hyper Petersen network: yet another hypercube-like topology,"The authors propose and analyze a new hypercubelike topology, called the hyper-Petersen (HP) network, which is constructed from the Cartesian product of a binary hypercube and the Petersen graph. The properties of HP topology include regularity, a high degree of symmetry and connectivity, and a small diameter. For example, it is shown that an n-dimensional HP network with N=1.25*2/sup n/ nodes covers 2.5 times more nodes than the binary hypercube at the cost of increasing the degree by one. Furthermore, with the same degree and connectivity, the diameter of the HP network is one less than that of a hypercube, yet it has a 1.25 times higher packing density. The authors also discuss the embedding of various other topologies such as meshes, trees, and twisted hypercubes on the HP, thereby emphasizing its rich interconnection structure with a simple routing scheme for message communication. A ring of odd length can be embedded in an HP network, which is a limitation of a binary hypercube.",
On the existence and design of the best stack filter based associative memory,"The associative memory of a stack filter is defined as the set of root signals of that filter. In a class of stack filters in which each filter's root set contains a desired set of patterns, those filters whose root sets have the smallest cardinality are said to be minimal among all filters in that class for that set of patterns. A partial ordering is defined on the set of stack filters via the set inclusion operation. Under this partial ordering, stack filters are found that are upper and lower bounds for the set of minimal stack filters that are furthest from the sets of decreasing and increasing stack filters. Knowledge of this configuration leads to an algorithm that can produce a near-minimal filter for any desired set of patterns. This method of constructing associative memories does not require the desired set of patterns to be independent, and it can construct a better filter.",
Design rationale for software engineering: a survey,"The authors provide an introduction to design rationale and why it is important in software engineering. They look at the recent history of argumentation methods. They survey a number of the major systems developed for the support of design rationale, comparing their features and discussing their differences. They look at advantages and disadvantages of the various approaches to design rationale with special attention paid to how they can be used in the process software engineering. They conclude with a discussion of some open issues which are important for the inclusion of design rationale systems in the software engineering process.",
On the delay-sensitivity of gate networks,"In classical switching theory, asynchronous sequential circuits are operated in the fundamental mode. In this mode, a circuit is started in a stable state, and then the inputs are changed to cause a transition to another stable state. The inputs are not allowed to change again until the entire circuit has stabilized. In contrast to this, delay-insensitive circuits-the correctness of which is insensitive to delays in their components and wires-use the input-output mode. In this case, it is assumed that inputs may change again, in response to an output change, even before the entire circuit has stabilized. It is shown that such commonly used behaviors as those of the set-reset latch and Muller's C-ELEMENT do not have delay-insensitive realizations, if gates are used as the basic components. It is proved that no nontrivial sequential behavior with one binary input possesses a delay-insensitive realization using gates only. The proof makes use of the equivalence between ternary simulation and the general-multiple-winner model of circuit behavior.",
Small diameter symmetric networks from linear groups,A report is presented on a collection of constructions of symmetric networks that provide the largest known values for the number of nodes that can be placed in a network of a given degree and diameter. Some of the constructions are in the range of current potential engineering significance. The constructions are Cayley graphs of linear groups obtained by experimental computation.,"Parallel processing,
Concurrent computing,
Mathematics,
Computer science,
Multiprocessor interconnection networks,
Cryptographic protocols,
Local area networks,
Routing,
Laboratories,
Organizing"
Scatter correction in maximum-likelihood reconstruction of PET data,"To obtain quantitative PET (positron emission tomography) images with the ML (maximum likelihood) reconstruction algorithm, the authors investigated the inclusion of a correction for scatter. They implemented the spatially variant convolution method of M. Bergstrom et al. (J. Comput. Assist. Tomogr., vol.7, p.42-50, 1983) which assumes that scatter is independent of depth and collapses the problem to a projection-by-projection scatter model. The model was implemented in three ways: subtraction of scatter estimated from measured projections prior to reconstruction; inclusion of a scatter estimate from the measured projection data in the iteration loop; and inclusion of a scatter estimate in the iteration loop, based on the previous iteration's estimate of trues from the image. The reconstructions were performed on an Intel iPSC/860 hypercube computer. Analysis of the convergence, bias, and noise properties of the three methods of scatter correction demonstrated only slight differences between the methods for real phantom data taken on the Scanditronix PC2048-15B brain PET scanner. The structure of this ML algorithm permits direct extension to a more comprehensive model of scatter.","Scattering,
Positron emission tomography,
Image reconstruction,
Kernel,
Maximum likelihood estimation,
Reconstruction algorithms,
Convergence,
Convolution,
Imaging phantoms,
Attenuation"
A case study of CES: a distributed collaborative editing system implemented in Argus,"Experience implementing CES, a distributed collaborative editing system, is described. CES was written in Argus, a language that was designed to support the construction of reliable distributed programs, and exhibits a number of requirements typical of distributed applications. The authors' experience illustrates numerous areas in which the support provided by Argus for meeting those requirements was quite helpful, but also identifies several areas in which the support provided by Argus was inadequate. Some of the problems arise because of the distinction in Argus (and in other systems) between locally and remotely accessible data and the mechanisms provided for implementing each. Others arise because of limitations of the mechanisms for building user-defined data types. The authors discuss the problems they encountered, including the implications for other systems. They also suggest solutions to the problems, or in some cases further research directed at finding solutions.","Computer aided software engineering,
Collaboration,
Collaborative work,
Computer science,
Writing,
Intelligent networks,
Collaborative tools,
Books,
Computerized monitoring,
Application software"
A longitudinal experiment on relational tone in computer-mediated and face to face interaction,"Prior experiments on computer-mediated communication have suggested depersonalizing effects of the medium, while field studies report warmer personal relations. Past research is criticized for failing to incorporate temporal and developmental perspectives on social information processing and relational development, and for omitting nonverbal cues in comparisons between conditions. 192 coders evaluated relational communication of 16 computer-mediated and 16 traditional groups over time. Mediated groups exhibited greater intimacy and social-orientation than did face-to-face groups. Boundaries on previous theories of computer-mediated communication are recommended, and research using temporal and nonverbal variables is suggested.","Computer mediated communication,
Design methodology,
Information processing,
Computer peripherals,
Marine vehicles,
Problem-solving,
Decision making,
Context,
Data analysis,
Time measurement"
Measurement of creativity of IS products,"While the literature on creativity/innovation in IS is sparse, the literature on measurement of creativity in IS products/services is non-existent. The paper provides a review of the literature on measurement of creativity, then concentrates on a discussion of the measurement of software products. Six software products are evaluated for their degree of creativity using a two-criterion approach: novelty and utility.",
Dexterous rotations of polyhedra,"Studies a strategy for dexterous manipulation, called finger tracking. It is shown that the paradigm of finger tracking may be used to control the fingers of a robot hand to generate rotational motions of the grasped object. The notion of manipulation refers to the reorientation of an object by a mechanical hand by some degrees, about some axis. The reorientation is accomplished by fine finger motions, and the hand never drops the object in the process. The hand can maintain planar rotational motions. This provides for a simple primitive for high-level, task-directed algorithms, toward relieving users from the complexity of low-level manipulation control.",
Virtual reality and education,"Five components of the virtual reality (VR) concept are analytically defined: 3-D perspective, dynamic rendering, closed loop interaction, inside-out perspective, and enhanced sensory feedback. It is argued on the basis of empirical data from a variety of sources that those components that improve performance by reducing effort may actually inhibit learning or long term retention. Closed loop interaction in contrast, while not reducing effort, appears to have a beneficial effect on retention. The importance for learning of directing users attention to the link between the VR perspective and a more artificial perspective is also highlighted.","Virtual reality,
Computer science education,
Computer graphics,
Navigation,
Cameras,
Laboratories,
Books,
Logic,
Neural networks,
Signal analysis"
Diffraction of nonaxisymmetric waves in cylindrically layered media by horizontal discontinuities,"In this paper a numerically efficient algorithm is developed for solving the problem of nonaxisymmetric wave propagation in cylindrically layered media with horizontal discontinuities. For an off-axis source in cylindrically layered media, because the nonaxisymmetry of the waves gives rise to the vectorial coupling between TE and TM waves, the modeling of the wave propagation becomes much more difficult than for a centered (axisymmetric) source. However, the numerical mode-matching method proposed here calculates very efficiently the electromagnetic fields in cylindrically layered media with horizontal discontinuities. Several numerical examples are given to verify the numerical method and to illustrate the applications of this method in the calculation of the field generated by a magnetic dipole source.",
Understanding diagrams in technical documents,"The development of a knowledge base of biological research papers that supports the Scientist's Assistant, an intelligent system that will provide a scientist with interactive access to the research results, methods, and reasoning in a collection of scientific papers, is discussed. The document understanding system uses graphics constraint grammars for describing and analyzing diagrams, spatial indexing in diagram analysis and understanding, and extension of natural-language processing techniques to complex scientific text. The graphics constraint grammars of the diagram-understanding system are described in detail. Example diagrams and grammars are presented.",
Inserting rules into recurrent neural networks,"The authors present a method that incorporates a priori knowledge in the training of recurrent neural networks. This a priori knowledge can be interpreted as hints about the problem to be learned and these hints are encoded as rules which are then inserted into the neural network. The authors demonstrate the approach by training recurrent neural networks with inserted rules to learn to recognize regular languages from grammatical string examples. Because the recurrent networks have second-order connections, rule-insertion is a straightforward mapping of rules into weights and neurons. Simulations show that training recurrent networks with different amounts of partial knowledge to recognize simple grammers improves the training times by orders of magnitude, even when only a small fraction of all transitions are inserted as rules. In addition, there appears to be no loss in generalization performance.",
"Dynamic half-space reporting, geometric optimization, and minimum spanning trees","The authors describe dynamic data structures for half-space range reporting and for maintaining the minima of a decomposable function. Using these data structures, they obtain efficient dynamic algorithms for a number of geometric problems, including closest/farthest neighbor searching, fixed dimension linear programming, bi-chromatic closest pair, diameter, and Euclidean minimum spanning tree.","Tree data structures,
Heuristic algorithms,
Computer science,
Data structures,
Tree graphs,
Application software,
Computer graphics,
Very large scale integration,
Mathematics"
Recognizing 3D objects from 2D images: an error analysis,"Object recognition systems that use a small number of pairings of data and model features to compute the 3D transformation from model to sensor coordinates are considered. The effects of 2D sensor uncertainty on such computations are examined. The uncertainty in transformation parameters is bounded, and the effect of this uncertainty on false positive recognition rates is analyzed.",
Function Optimization Based On Advanced Simulated Annealing,,"Simulated annealing,
Temperature,
Optimization methods,
Computational modeling,
Mathematics,
Computer science,
Statistics,
Cost function,
Area measurement,
Length measurement"
Domain-oriented design environments,"It is argued that domain-oriented design environments (DODEs) provide a complementary goal for the future of software engineering to the approaches pursued with knowledge-based software assistant systems (KBSAs). The DODE extends the KBSA framework by emphasizing a human-centered and domain-oriented approach facilitating communication about evolving systems among all stakeholders. The author briefly discusses the major challenges for software systems, develops a conceptual framework to address these problems, and illustrates the contributions of the KBSA and DODE approaches towards solving these problems.",
The Impact of Communication Locality on Large-Scale Multiprocessor Performance,"As multiprocessor sizes scale and computer architects turn to interconnection networks with non-uniform communication latencies, the lure of exploiting communication locality to increase performance becomes inevitable. Models that accurately quantify locality effects provide invaluable insight into the importance of exploiting locality as machine sizes and features change. This paper presents a framework for modeling the impact of communication locality on system performance. The framework provides a means for combining simple models of application, processor, and network behavior to obtain a combined model that accurately reflects feedback effects between processors and networks. We introduce a model that characterizes application behavior with three parameters that capture computation grain, sensitivity to communication latency, and amount of locality present at execution time. The combined model is validated with measurements taken from a detailed simulator for a complete multiprocessor system. Using the combined model, we show that exploiting communication locality provides gains which are at most linear in the factor by which average communication distance is reduced when the number of outstanding communication transactions per processor is bounded. The combined model is also used to obtain rough upper bounds on the performance improvement from exploiting locality to minimize communication distance.",
Reconfiguration strategies for VLSI processor arrays and trees using a modified Diogenes approach,"The authors deal with reconfiguration of a rectangular array of processors arranged as an N*N mesh, and a complete binary tree of N processors. They present new reconfiguration techniques that are modifications of the Diogenes approach proposed earlier by A.L. Rosenberg et al. (1983). These techniques reduce the overheads incurred in the earlier Diogenes schemes. Some of the previous approaches to the problem are summarized. Two schemes are presented for reconfiguring rectangular arrays and a scheme for reconfiguring trees. For the analysis of the different schemes presented, it is assumed that a processor has a square layout. These schemes are analyzed and their performance results are presented.",
Linear scheduling is close to optimality,"This paper deals with the problem of finding optimal schedulings for uniform dependence algorithms. Given a convex domain, let T/sub f/ be the total time needed to execute all computations using the free (greedy) schedule and let T/sub l/ be the total time needed to execute all computations using the optimal linear schedule. The authors' main result is to bound T/sub l//T/sub f/ and T/sub l/-T/sub f/ for sufficiently 'fat' domains.",
Computation of certain measures of proximity between convex polytopes: a complexity viewpoint,"The quantification of proximity between a pair of objects whose point descriptions are given is considered. Four problems of proximity between two convex polytopes in R/sup 3/ are considered. The convex polytopes are represented as convex hulls of finite sets of points. The authors discuss the complexity of solving the four problems. They analyze algorithms for the four problems in terms of two complexity types. Let the total number of points in the two finite sets be n. It is shown that three of the proximity problems, checking intersection, checking whether the polytopes are just touching, and finding the distance between them, can be solved in O(n) time for fixed s and in polynomial time for varying s. It is also shown that the fourth proximity problem of finding the intensity of collision for varying s is NP-complete.",
"Implementation, investigation, and improvement of a novel cone-beam reconstruction method (SPECT)","A three-dimensional reconstruction method which uses cone-beam data was implemented. Issues concerning implementation are investigated and discussed in detail. Computer simulations were used to determine the amount of image degradation occurring in each of the three steps that comprise the reconstruction method. In addition, computer simulations were used to investigate issues concerning sampling. Improvements in the implementation were made. Additionally, suggestions for future efforts to improve the implementation are made.",
Why tanh: choosing a sigmoidal function,"As hardware implementations of backpropagation and related training algorithms are anticipated, the choice of a sigmoidal function should be carefully justified. Attention should focus on choosing an activation function in a neural unit that exhibits the best properties for training. The author argues for the use of the hyperbolic tangent. While the exact shape of the sigmoidal makes little difference once the network is trained, it is shown that it possesses particular properties that make it appealing for use while training. By paying attention to scaling it is illustrated that tanh (1.5*) has the additional advantage of equalizing training over layers. This result can easily generalize to several standard sigmoidal functions commonly in use.","Kalman filters,
Intelligent systems,
Computer science,
Shape,
Feedforward systems,
Neural networks,
Feedforward neural networks,
Logistics,
Hardware,
Telephony"
Data-parallel programming on a network of heterogeneous workstations,"The authors describe a compiler and run-time system that allows data-parallel programs to execute on a network of heterogeneous UNIX workstations. The programming language supported is Dataparallel C, a SIMD language with virtual processors and a global name space. This parallel programming environment allows the user to take advantage of the power of multiple workstations without adding any message-passing calls to the source program. Because the performance of individual workstations in a multi-user environment may change during the execution of a Dataparallel C program, the run-time system automatically performs dynamic load balancing. The authors present experimental results that demonstrate the usefulness of dynamic load balancing in a multi-user environment.",
A fast multilayer general area router for MCM designs,"The authors report on the development of an efficient multilayer general area router as an alternative to the three-dimensional (3-D) maze router for solving the multilayer multichip module (MCM) routing problem. The router, named SLICE, is independent of net ordering, requires much shorter computation time, and uses fewer vias. A key step in the router is to compute a maximum non-crossing bipartite matching, which is solved optimally in O(n log n) time where n is the number of possible connections. The router was tested on a number of examples, including two MCM designs. Compared to a 3-D maze router, SLICE is four times faster and uses 28% fewer vias. SLICE can successfully produce solutions for large MCM routing examples where 3-D maze routers fail due to insufficient memory.",
Behavior of faulty single BJT BiCMOS logic gates,"The logic behavior of single BJT BiCMOS devices under transistor level shorts and opens is examined. In addition to delay faults, faults that cause the gate to exhibit sequential behavior were observed. Several faults can be detected only by monitoring the current. The faulty behaviour of bipolar (TTL) and CMOS logic families is compared with BiCMOS. Effects of bridging faults in BiCMOS devices has been examined for both hard short as well as bridging with a significant resistance.","BiCMOS integrated circuits,
Logic gates,
Circuit faults,
CMOS technology,
Logic devices,
CMOS logic circuits,
Logic testing,
Very large scale integration,
Computer science,
Added delay"
A minimum entropy approach to rule learning from examples,"Learning from examples uses specific instances (examples and counterexamples) to produce general rules. It is a convenient learning scheme in cases where the process of interviewing human experts and analyzing and formalizing their decision is very difficult or time consuming. The system proposed is capable of obtaining the rules that fit a set of examples and counterexamples based on the minimal entropy (ME) criterion. The system proposed can also set various parameters of the rule (e.g., thresholds) in such a way that entropy is minimized. The system can also handle incremental learning from examples. Applications of the proposed system to seismic image analysis are included.",
Shortest path segmentation: a method for training a neural network to recognize character strings,"The authors describe a method which combines dynamic programming and a neural network recognizer for segmenting and recognizing character strings. The method selects the optimal consistent combination of cuts from a set of candidate cuts generated using heuristics. The optimal segmentation is found by representing the image, the candidate segments, and their scores as a graph in which the shortest path corresponds to the optimal interpretation. The scores are given by neural net outputs for each segment. A significant advantage of the method is that the labor required to segment images manually is eliminated. The system was trained on approximately 7000 unsegmented handwritten zip codes provided by the United States Postal Service. The system has achieved a per-zip-code raw recognition rate of 81% on a 2368 handwritten zip-code test set.",
On-line scheduling of imprecise computations to minimize error,"Three algorithms for scheduling preemptive, imprecise tasks on a processor to minimize the total error are described. Each imprecise task consists of a mandatory task followed by an optional task. Some of the tasks are online; they arrive after the processor begins execution. The algorithms assume that when each new online task arrives, its mandatory task and the portions of all the mandatory tasks yet to be completed at the time can be feasibly scheduled to be computed by their deadlines. The algorithms produce for such tasks feasible schedules whose total errors are as small as possible. The three algorithms are designed for three types of task systems: (1) when every task is online and is ready upon its arrival; (2) when every task is online and is ready upon arrival but there are also offline tasks with arbitrary ready times; and (3) when online tasks have arbitrary ready times. Their running times are O(n log n), O(n log n), and O(n log/sup 2/ n), respectively.",
Replicated distributed processes in Manetho,"The authors present the process-replication protocol of Manetho, a system whose goal is to provide efficient, application-transparent fault tolerance to long-running distributed computations. Manetho uses a novel negative-acknowledgment multicast protocol to enforce the same receipt order of application messages among all replicas of a process. The protocol depends on a combination of antecedence graph maintenance, a form of sender-based message logging, and the fact that the receivers of each multicast execute the same deterministic program. This combination allows the protocol to void the delay in application message delivery that is common in existing negative-acknowledgment multicast protocols, without giving up the advantage of requiring only a small number of control messages.","Multicast protocols,
Fault tolerant systems,
Distributed computing,
Delay,
Computer science,
Application software,
Availability,
Stress,
Sections"
The recovery and understanding of a line drawing from indoor scenes,"A general procedure for the understanding of a class of indoor scenes is proposed. The suggested algorithm makes use of an extensive 2-D processing of the image that provides a faithful line drawing of the viewed scene. It also uses procedures adequate for the understanding of the 3-D structure and for the recognition of several items in the scene. The approach is specific for indoor scenes, such as corridors, offices, and laboratory rooms, where long straight edges are predominant and vanishing points can be detected.","Layout,
Image edge detection,
Image recognition,
Image segmentation,
TV,
Computer vision,
Machine vision,
Vehicles,
Robots"
On parallel processing systems: Amdahl's law generalized and some results on optimal design,"The authors model a job in a parallel processing system as a sequence of stages, each of which requires a certain integral number of processors for a certain interval of time. They derive the speedup of the system for two cases: systems with no arrivals, and systems with arrivals. In the case with no arrivals, their speedup result is a generalization of Amdahl's law (G.M. Amdahl, 1967). They extend the notion of power as previously applied to general queuing and computer-communication systems to their case of parallel processing systems. They find the optimal job input and the optimal number of processors to use so that power is maximized. Many of the results for the case of arrivals are the same as for the case of no arrivals. It is found that the average number of jobs in the system with arrivals equals unity when power is maximized. They also model a job in such a way that the number of processors required continuously varies over time. The same performance indices and parameters studied in the discrete model are evaluated for this continuous model.",
Performance analysis of a generalized class of m-level hierarchical multiprocessor systems,"The performance of the m-level hierarchical multiprocessor system is analyzed in terms of the system bandwidth for both hierarchically nonuniform reference and uniform reference models. The results show that for a higher rate of local requests (requests to memory modules within the same cluster) the m-level system performs fairly close to the crossbar system and outperforms a typical multiple-bus system (with the number of buses equal to half the number of processors). The bandwidth of the m-level system is evaluated for different numbers of levels, and the results are compared with those of a crossbar system (m=1).",
A Fixed Size Storage O(n3) Time Complexity Learning Algorithm for Fully Recurrent Continually Running Networks,"The real-time recurrent learning (RTRL) algorithm (Robinson and Fallside 1987; Williams and Zipser 1989) requires O(n4) computations per time step, where n is the number of noninput units. I describe a method suited for on-line learning that computes exactly the same gradient and requires fixed-size storage of the same order but has an average time complexity per time step of O(n3).",
Linear logic without boxes,"J.-Y. Girard's original definition of proof nets for linear logic involves boxes. The box is the unit for erasing and duplicating fragments of proof nets. It imposes synchronization, limits sharing, and impedes a completely local view of computation. The authors describe an implementation of proof nets without boxes. Proof nets are translated into graphs of the sort used in optimal lambda -calculus implementations; computation is performed by simple graph rewriting. This graph implementation helps in understanding optimal reductions in the lambda -calculus and in the various programming languages inspired by linear logic.",
Fixpoint logic vs. infinitary logic in finite-model theory,"The relationship between fixpoint logic and the infinitary logic L/sub infinity omega //sup omega / with a finite number of variables is studied. It is observed that the equivalence of two finite structures with respect to L/sub infinity omega //sup omega / is expressible in fixpoint logic. As a first application of this, a normal-form theorem for L infinity /sub omega //sup omega / on finite structures is obtained. The relative expressive power of first-order logic, fixpoint logic, and L/sub infinity omega //sup omega / on arbitrary classes of finite structures is examined. A characterization of when L/sub infinity omega //sup omega / collapses to first-order logic on an arbitrary class of finite structures is given.","Logic,
Power generation,
Game theory,
Computer science,
Combinatorial mathematics,
Application software,
Spatial databases,
Complexity theory"
Improving the performance of message-passing applications by multithreading,"Achieving maximum performance in message-passing programs requires that calculation and communication be overlapped. However, the program transformations required to achieve this overlap are error-prone and add significant complexity to the application program. The authors argue that calculation/communication overlap can be achieved easily and consistently by executing multiple threads of control on each processor, and that this approach is practical on message-passing architectures without any special hardware support. They present timing data for a typical message-passing application, to demonstrate the advantages of the scheme.","Multithreading,
Yarn,
Application software,
Hardware,
Process control,
Programming profession,
Processor scheduling,
Computer science,
Computer errors,
Communication system control"
A pseudo-relaxation learning algorithm for bidirectional associative memory,"A fast iterative learning algorithm for the bidirectional associative memory (BAM) called PRLAB is introduced. PRLAB utilizes the pseudo-relaxation method adapted from the relaxation method for solving systems of linear inequalities. PRLAB is very fast, is well suited for a neural network implementation, guarantees the recall of all training patterns, is highly insensitive to learning parameters, and offers high scalability for large applications. PRLAB exploits the maximum storage capacity of the BAM and guarantees perfect recall of all trained pairs. For guaranteed storage, no special form of encoding or preprocessing is necessary.",
Fuzzy logic approach to placement problem,"The authors apply fuzzy reasoning to the placement of sea-of-gate arrays. Fuzzy logic is used to optimize a process of decision making in physical design. Multiple objectives such as utilization of area, routability, and timing were considered simultaneously and balanced by fuzzy logic algorithms. The experiments demonstrated that solutions obtained by fuzzy logic were of much better quality than those achieved by standard techniques.",
The classification and associative memory capability of stack filters,"The notion of the on-set of a positive Boolean function is used to classify stack filters into three different types, called decreasing, increasing, and mixed. The associative memory capability of each of these three types of stack filters is then investigated. The associative memory of a stack filter is defined to be the set of root signals of that filter. In a class of stack filters in which each filter's root set contains a desired set of patterns, those filters whose root sets have the smallest cardinality are said to be minimal among all filters in that class for that set of patterns. Some learning schemes are proposed to find minimal decreasing and increasing stack filters. It is also shown that, for any specified set of patterns, there is always a mixed stack filter which is minimal when one considers all stack filters which preserve those patterns. In this sense, mixed stack filters are always at least as good as decreasing or increasing stack filters.","Associative memory,
Stacking,
Filtering,
Nonlinear filters,
Boolean functions,
Computer science,
Signal synthesis,
Design methodology,
Signal design,
Morphology"
Four-dimensional views of 3D scalar fields,"Scalar functions of three variables, w=f(x, y, z), are common in many types of scientific and medical applications. Such 3D scalar fields can be understood as elevation maps in four dimensions, with three independent variables (x, y, z) and a fourth, dependent, variable w that corresponds to the elevations. It is shown how techniques developed originally for the display of 3-manifolds in 4D Euclidean space can be adapted to visualize 3D scalar fields in a variety of ways.",
Visual tools for generating iconic programming environments,"The authors present VAMPIRE a visual system for rapid generation of iconic programming systems. VAMPIRE uses a graphical class editor to construct a hierarchy describing an iconic language's structure. Each node in the hierarchy represents an abstraction of a group of language elements; each leaf represents an icon which can be placed into a program. Attributes are added to each 'class' in the tree to represent aspects of the language elements, including 'icons' which describe the graphical visualization of the elements and 'rules' which describe the semantics of the element. The semantics of the language are defined using attributed graphical rule. VAMPIRE has been designed so that it can create iconic systems similar to all of the major classes which have appeared to date in the literature.",
Performance analysis of nonblocking packet switch with input and output buffers,The performance of nonblocking packet switches such as the knockout switch and Batcher banyan switch for high-speed communication networks can be improved as the switching capacity L per output increases; the switching capacity per output refers to the maximum number of packets transferred to an output during a slot. The N*N switch with L=N was shown to attain the best possible performance by M.J. Karol et al. (1987). Here a N*N nonblocking packet switch with input and output buffers is analyzed for an arbitrary number of L such that 1,
A neural network based image compression system,"It is proposed that vector quantization be implemented for image compression based on neural networks. Separate codebooks for edge and background blocks are designed using Kohonen (1984) self-organizing feature maps to preserve edge integrity and improve the efficiency of codebook design. A system architecture is proposed, and satisfactory performance is achieved.",
A fast linear shape from shading,"A method for computing depth from a single shaded image is presented. Discrete approximations for p and q using finite differences are used, and the reflectance in Z/sub ij/ is linearized. The method is faster, since each operation is purely local. In addition, it gives good results for spherical surfaces, in contrast to other linear methods.",
Improved Gilbert-Varshamov bound for constrained systems,"Nonconstructive existence results are obtained for block error-correcting codes whose codewords lie in a given constrained system. Each such system is defined as a set of words obtained by reading the labels of a finite directed labeled graph. For a prescribed constrained system and relative minimum distance delta , the new lower bounds on the rate of such codes improve on those derived recently by V.D. Kolesnik and V.Y. Krachkovsky (1991). The better bounds are achieved by considering a special subclass of sequences in the constrained system, namely, those having certain empirical statistics determined by delta .",
How the checklist paradigm elucidates the semantics of fuzzy inference,"The authors present some results on a theoretical semantic device called the checklist paradigm which gives the theoretical bounds on the performance of particular many-valued implication operators and other connectives. In its most general form, the checklist paradigm pairs the distinct connectives of the same logical type to provide the bounds for interval-valued approximate inference. The global structure imposed on the many-valued connectives by the certain type of checklist paradigm contracting measures is shown to be the S/sub 2*2*2/ group.",
Solving systems of set constraints,"It is shown that systems of set constraints that use all the standard set operations, especially unrestricted union and complement, can be solved. The centerpiece of the development is an algorithm that incrementally transforms a system of constraints while preserving the set of solutions. Eventually, either the system is shown to be inconsistent or all solutions can be exhibited. Most of the work is in proving that if this algorithm does not discover an inconsistency, then the system has a solution. This is done by showing that the system of constraints generated by the algorithm can be transformed into an equivalent set of equations that are guaranteed to have a solution. These equations are essentially tree automata.",
Error modeling for hierarchical lossless image compression,"The authors present a new method for error modeling applicable to the multi-level progressive (MLP) algorithm for hierarchical lossless image compression. This method, based on a concept called the variability index, provides accurate models for pixel prediction errors without requiring explicit transmission of the models. They also use the variability index to show that prediction errors do not always follow the Laplace distribution, as is commonly assumed; replacing the Laplace distribution with a more general distribution further improves compression. They describe a new compression measurement called compression gain, and give experimental results showing that the using variability index gives significantly better compression than other methods in the literature.",
The role of long and short paths in circuit performance optimization,"The authors consider the problem of determining the smallest clock period for a combinational circuit by considering both the long and short paths. To develop the timing of the circuit, they use a new class of paths called the shortest destabilizing paths as well as the longest sensitizable paths. The bounds on the clock period can alternatively be viewed as optimization objectives. At the physical level, the problem is that of applying transistor sizing and delay buffer insertion to achieve specified upper bounds on clock period and latency. Experimental results are presented that reflect the complexity of the optimization problem. The clock period determination can also be extended to circuits with feedbacks.",
On the complexity of distance-2 coloring,"The authors study the problem of distance-2 colorings of the vertices of undirected graphs. In such a coloring, vertices separated by a distance of less than or equal to two must receive different colors. This problem has direct application to the problem of broadcast scheduling in multihop radio networks. The authors show that even when restricted to planar graphs, finding a minimum such coloring is NP-complete. They then describe a good (constant times optimal) approximation algorithm for the distance-2 coloring of planar graphs. They also extend this analysis of the algorithm to deal with general graphs. They show that the performance of the algorithm has a worst-case bound that is proportional to the product of the graph arboricity and the maximum vertex degree. Previous algorithms could only guarantee a bound proportional to the square of the maximum degree.",
Vector register allocation,"The problem of allocating vector registers on supercomputers is addressed in the context of compiling vector languages. Two subproblems must be solved to achieve good vector register allocation. First, the vector operations in the source program must be subdivided into sections that fit the hardware of the target machine. Second, the locality of reference of the vector operations must be improved via aggressive program transformations. Solutions to both of these problems, based on the use of novel aspects of data dependence, are presented. The techniques described extend naturally to scalar machines by observing that a scalar register is simply a vector register of length one.","Registers,
Supercomputers,
Optimizing compilers,
Computer science,
High performance computing,
Hardware,
Memory architecture,
Costs,
Computer aided instruction,
Runtime"
How Tight Are the Vapnik-Chervonenkis Bounds?,"We describe a series of numerical experiments that measure the average generalization capability of neural networks trained on a variety of simple functions. These experiments are designed to test the relationship between average generalization performance and the worst-case bounds obtained from formal learning theory using the Vapnik-Chervonenkis (VC) dimension (Blumer et al. 1989; Haussler et al. 1990). Recent statistical learning theories (Tishby et al. 1989; Schwartz et al. 1990) suggest that surpassing these bounds might be possible if the spectrum of possible generalizations has a “gap” near perfect performance. We indeed find that, in some cases, the average generalization is significantly better than the VC bound: the approach to perfect performance is exponential in the number of examples m, rather than the 1/m result of the bound. However, in these cases, we have not found evidence of the gap predicted by the above statistical theories. In other cases, we do find the 1/m behavior of the VC bound, and in these cases, the numerical prefactor is closely related to the prefactor contained in the bound.",
LAN/MAN interconnection to ATM: a simulation study,"The authors compare three strategies, namely, reservation, on-the-fly, and hybrid, for the support of connectionless internet traffic on asynchronous transfer mode (ATM). The comparison is based on a simulation experiment in which a mix of virtual paths (some carrying connectionless traffic, some carrying connection-oriented traffic) are multiplexed on a 150 Mb/s trunk, called the bottleneck trunk. Results based on a variety of measures (cell and burst loss rates, cell delay, and burst delay) show that the on-the-fly approach, which aggressively exploits unused bandwidth, is superior to the reservation scheme, which is handicapped by the renegotiation overhead and the conservative usage of bandwidth. The hybrid scheme exhibits a performance behavior between the other two. This is a bit disappointing, considering the fact that the hybrid scheme is expected to be consistently better than both schemes. Still the hybrid scheme offers some interesting features (e.g. lower delays for the background traffic) which should be further explored by a more extensive examination of the working parameters.","Local area networks,
LAN interconnection,
Asynchronous transfer mode,
Bandwidth,
Computational modeling,
Computer science,
Intserv networks,
Switches,
Computer simulation,
Process control"
A theory of wormhole routing in parallel computers,"Virtually all theoretical work on message routing in parallel computers has dwelt on packet routing: messages are conveyed as packets, an entire packet can reside at a node of the network, and a packet is sent from the queue of one node to the queue of another node until its reaches its destination. The current trend in multicomputer architecture, however, is to use wormhole routing. In wormhole routing a message is transmitted as a contiguous stream of bits, physically occupying a sequence of nodes/edges in the network. Thus, a message resembles a worm burrowing through the network. The authors give theoretical analyses of simple wormhole routing algorithms, showing them to be nearly optimal for butterfly and mesh connected networks. The analysis requires initial random delays in injecting messages to the network. They report simulation results suggesting that the idea of random initial delays is not only useful for theoretical analysis but may actually improve the performance of wormhole routing algorithms.",
Fixed-parameter intractability,"The authors consider the complexity behavior of parametrized problems that they term fixed-parameter tractability: for each fixed parameter value y the problem is solvable in time O(n/sup c/), where c is a constant independent of the parameter y. They introduce a structure theory with which to address the apparent intractability of some parameterized problems, and they obtain completeness, density, and separation/collapse results. The greatest appeal of the theory is in the wide range of natural problems to which it can be applied, and in the practical significance of fixed-parameter problem complexities. Technical aspects are also interesting.",
Wavelet localization of the Radon transform in even dimensions,"One of the phenomena associated with the Radon transform is the following: in odd dimensions, local values of a function f:R/sup n/ to R can be determined by local measurements of the integrals of f over (n-1)-dimensional hyperplanes; in even dimensions, local values are globally dependent on the integrals over hyperplanes. The wavelet transform is used to essentially localize the Radon transform in even dimensions. It is believed that this will be significant in the field of medical imaging.",
Adaptive-size physically-based models for nonrigid motion analysis,Adaptive-size physically based models suitable for nonrigid motion analysis are presented. The mesh size increases or decreases dynamically during the surface reconstruction process to locate nodes near surface areas of interests (like high curvature points) and to optimize the fitting error. A priori information about nonrigidity can be included so that the surface model deforms to fit moving data points while preserving some basic nonrigid constraints (e.g. isometry or conformality). Implementation of the proposed algorithm with and without isometric/conformal constraints is presented. Performance and accuracy of derived algorithms are demonstrated on data simulating deforming ellipsoidal and bending planar shapes. The algorithm is applied to the real range data for bending paper and to volumetric temporal left ventricular data.,
Adjustable Block Size Coherent Caches,"Several studies have shown that the performance of coherent caches depends on the relationship between the granularity of sharing and locality exhibited by the program and the cache block size. Large cache blocks exploit processor and spatial locality, but may cause unnecessary cache invalidations due to false sharing. Small cache blocks can reduce the number of cache invalidations, but increase the number of bus or network transactions required to load data into the cache. In this paper we describe a cache organization that dynamically adjusts the cache block size according to recently observed reference behavior. Cache blocks are split across cache lines when false sharing occurs, and merged back into a single cache line to exploit spatial locality. To evaluate this cache organization, we simulate a scalable multiprocessor with coherent caches, using a suite of memory reference traces to model program behavior. We show that for every fixed block size, some program suffers a 33% in- crease in the average waiting time per reference, and a factor of 2 increase in the average number of words transferred per reference, when compared against the performance of an adjustable block size cache. In the few cases where adjusting the block size does not provide superior performance, it comes within 7% of the best fixed block size alternative. We conclude that an adjustable block size cache offers significantly better performance than every fixed block size cache, especially when there is variability in the granularity of sharing exhibited by applications.",
Fuzzy prediction of time series,"An approach to time series extrapolation based on fuzzy control is described. The standard exponential averaging scheme is inflexible in that it gives a fixed weight to past history, thus ignoring transient phases in system dynamics. A modification to the scheme where the control parameter of the averaging scheme is dynamically adjusted by a simple fuzzy logic controller is presented. The design of the controller is described. The scheme was evaluated by simulation on test workloads and by application to the real-world problem of flow control in communication networks. The sensitivity of the system to its descriptive parameters is outlined.",
Character segmentation techniques for handwritten text-a survey,"The paper is a survey of techniques for segmenting images of handwritten text into individual characters. The topic is broken into two categories: segmentation and segmentation-recognition techniques. Several approaches to each are outlined, and each is analyzed for its relevance to printed, cursive, on-line and off-line input data.",
Some representation properties of stack filters,"Stack filters, a class of nonlinear filters which are based on positive Boolean functions as the window operators, are considered. The representations of these window operations are presented via the structures of on-set and off-set of the positive Boolean functions, which can be expressed as a Boolean expression containing no complements of the input variables. A fast algorithm for finding the representation of stack filters is designed. This algorithm can be easily extended to find the representation of morphological filters mentioned by P. Maragos (1989).",
An approach to symbolic timing verification,Symbolic timing verification is a critical tool in the development of higher-level synthesis tools. The authors present an approach to symbolic timing verification using constraint logic programming techniques. The techniques are quite powerful in that they not only yield simple bounds on delays but also relate the delays in linear inequalities so that tradeoffs are apparent. They model circuits as communicating processes and the current implementation can verify a large class of mixed synchronous and asynchronous specifications. The utility of the approach is illustrated with some examples.,
Partitioning An Assembly For Infinitesimal Motions In Translation And Rotation,,
Speaker normalization for speech recognition,"A codeword-dependent neural network (CDNN) is presented for the study of speaker adaptation. The CDNN is used as a nonlinear mapping function to transform speech data between two speakers. The mapping function is characterized by a number of important properties. First, the assembly of mapping functions enhances overall mapping quality. Second, multiple input vectors are used simultaneously in the transformation. This not only makes full use of dynamic information but also alleviates possible errors in the supervision data. Finally, the mapping function is derived from training data, with the quality dependent on the available amount of training data. Based on speaker-dependent models, performance evaluation showed that speaker normalization significantly reduced the error rate from 41.9% to 5.0%.","Speech recognition,
Training data,
Loudspeakers,
Neural networks,
Assembly,
Error analysis,
Databases,
Management training,
Computer science,
Speech synthesis"
A novel electric power laboratory for power quality and energy studies: training aspects,"The laboratory described can examine issues in power quality (PQ) with regard to both stand-alone devices and their behavior in the power system. A project justification which identifies PQ problem areas is presented. Historical backgrounds of both PQ and laboratories in general are provided, to give a brief educational tutorial in the area, and to set the stage for bringing into creation a lab which addresses correctly the needs of industry and students. Development aspects of the lab are presented. This is followed by a description of the testing capabilities of the laboratory that are needed to address the PQ problem areas, along with the laboratory's presentation of results and training/educational capabilities. Aspects of how the laboratory is used cooperating with other facilities are examined so that broader PQ problems can be studied.",
Effect of fault tolerance on response time-analysis of the primary site approach,"The effect of the primary site approach for fault tolerance on the response time is studied. In the primary site approach, the service to be made fault tolerant is replicated at many nodes, one of which is designated as primary and the others as backups. All the requests for operations on the data object are sent to the primary site. The primary fails, one of the backups takes over as primary. The primary site periodically checkpoints its state on the backups. An analytical model for studying the average response time of the primary site system and analyzing the effects of the checkpointing frequency and the degree of replication on the response time is presented. This model is used to compare the response time of the system to that of a system without any fault tolerance.","Fault tolerance,
Delay,
Fault tolerant systems,
Checkpointing,
Frequency,
Availability,
Analytical models,
Real time systems,
Computer science,
Maintenance engineering"
On primitive factorizations for 3-D polynomial matrices,"A criterion for the existence of primitive factorizations for a class of 3-D polynomial matrices is presented. The criterion can also be used to construct a primitive factorization, when it exists, for a 3-D polynomial matrix in this class. Two examples are also included.",
Hyperflow: a visual programming language for pen computers,"The design philosophy of the Hyperflow visual programming language and an overview of its semantic model are presented. The concept of visually interactive process, vip, is introduced as the fundamental element of the semantics. Vips communicate with each other through exchange of signals, either discrete or continuous. Each vip communicates with the user through its own interface box by displaying on the box information about the vip and by receiving information pen-scribed on the box. There are four different communication modes: mailing, posting, channeling, and broadcasting. Mailing and posting are for discrete signals and channeling and broadcasting are for continuous signals. Simple Hyperflow programs are given including a specification for the Line-Clock device driver.",
On piecewise-linear approximation of nonlinear mappings containing Gummel-Poon models or Schichman-Hodges models,An effective technique for the piecewise-linear approximation of nonlinear mappings containing Gummel-Poon models or Shichman-Hodges models is presented. The basic idea is to exploit the pairwise-separability of the nonlinear mappings containing these nonseparable models. The proposed approximation is much more effective than the conventional piecewise-linear approximation using a simplicial subdivision.,
A comparative study of load sharing in heterogeneous multicomputer systems,"The effective use of a heterogeneous multicomputer system depends on the scheduling policy used. Often the scheduling algorithms used are those that were intended for homogeneous systems. On the other hand, most scheduling algorithms designed with heterogeneity in mind were developed under unrealistic assumptions. To enhance the performance of a multicomputer system, load sharing can be used during scheduling to distribute the workload evenly among the constituent nodes. This paper presents a comprehensive evaluation of load sharing algorithms in heterogeneous multicomputer systems. The simulation results suggest that load sharing policies that perform well in homogeneous systems fail to achieve good performance in heterogeneous systems. The authors also show that the distribution of service time and the communication overhead have significant impact on system performance. They conclude by providing guidelines for selecting load sharing policies suitable for different heterogeneous environments.",
A data acquisition system based on a personal computer,"A versatile and flexible data acquisition system KODAQ (Kakuken Online Data AcQuisition system) has been developed. The system runs with CAMAC and the NEC PC9801, which is similar to the IBM PC/AT. The system is designed to set up a data acquisition system for various kinds of nuclear physics experiments. For small-scale experiments, the system should be adequate in processing capacity. It has a good cost performance.",
Methods for improved update performance of disk arrays,"A disk array is a set of disk drives (and controller) which can automatically recover data when one (or more) disk drives in the set fails. One method used by disk arrays to achieve high availability at lower cost than mirroring is a parity technique. The main drawback of such arrays are that they need four disk accesses to update a data block-two to read old data and parity, and two to write new data and parity. The authors describe four new methods to improve the update performance of disk arrays that use the parity technique from four accesses to three and, in some cases, to two. All the schemes sacrifice disk storage efficiency for improved update performance by relaxing the requirement that the modified data and parity blocks be written back into their original locations. The best technique, called 'floating parity track', achieves much improved update performance while using only 1% more disk space than traditional arrays.",
Unfolding and retiming data-flow DSP programs for RISC multiprocessor scheduling,"Retiming and unfolding are two useful techniques which have been effectively applied in many fields. These two techniques are combined to solve the problem of rate-optimal scheduling for unit-time data flow graphs (DFGs). A rate-optimal retimeable graph is a DFG such that after a legal retiming a rate-optimal schedule can be obtained. For the case of unit-time DFG, which is applicable to RISC multiprocessors, the best known upper-bound for an unfolding factor which produces a rate-optimal retimeable DFG is improved, and it is shown that the result is the minimum possible unfolding factor for rate-optimal schedules. Moreover, for any unfolding factor, the corresponding minimum rate is given by a simple criterion. Since it is proved that the order of retiming and unfolding is irrelevant, efficient polynomial-time retiming algorithms are obtained.",
Shared memory vs. message passing in shared-memory multiprocessors,"It is argued that the choice between the shared-memory and message-passing models depends on two factors: the relative cost of communication and computation as implemented by the hardware, and the degree of load imbalance inherent in the application. Two representative applications are used to illustrate the performance advantages of each programming model on several different shared-memory machines, including the BBN Butterfly, Sequent Symmetry, Encore Multimax and Silicon Graphics Iris multiprocessors. It is shown that applications implemented in the shared-memory model perform better on the previous generation of multiprocessors, while applications implemented in the message-passing model perform better on modern multiprocessors. It is argued that both models have performance advantages, and that the factors that influence the choice of model may not be known at compile-time. As a compromise solution, the authors propose an alternative programming model, which has the load balancing properties of the shared-memory model and the locality properties of the message-passing model, and show that this new model performs better than the other two alternatives.","Message passing,
Hardware,
Samarium,
Computer science,
Costs,
Switches,
Computational modeling,
Concurrent computing,
Application software,
Processor scheduling"
A parallel execution method for minimizing distributed query response time,"Performance studies show that traditional semi-join processing methods are sometimes inefficient because of the storage and processing overhead. To remedy this problem, a new semi-join processing method, called one-shot semi-join execution is proposed. This method allows parallel generation of all the semi-join projections, parallel transmission of all the semi-join projections, and parallel execution of all the semi-joins. The authors apply this method to optimize the response time for processing distributed queries. A response time model is established, which considers both data transmission time and local processing time. Based on this model, an efficient query processing algorithm is developed and analyzed.",
Using visualization tools to understand concurrency,"A visualization tool that provides an aggregate view of execution through a graph of events called the causality graph, which is suitable for systems with hundreds or thousands of processors, coarse-grained parallelism, and for a language that makes communication and synchronization explicit, is discussed. The methods for computing causality graphs and stepping through an execution with causality graphs are described. The properties of the abstraction algorithms and super nodes, the subgraphs in causality graphs, are also discussed.",
Active tactile sensing by robotic fingers based on minimum-external-sensor-realization,"The authors discuss active tactile sensing for detecting a contact point between a multifingered robot hand and an unknown object. They define the concept of actively sensible meaning that an active sensing motion can be planned for a sensing event. Assuming more than two sensing events, conditional-minimum-external-sensor-realization is defined, where it is shown that it is possible to reduce the number of external sensors with a well-planned sensing algorithm. Based on these definitions, an active sensing algorithm for detecting the contact point with minimum-external-sensor-realization is proposed. This approach remedies several disadvantages found in conventional approaches. The approach was tested through experiments using a single-finger model with a fingertip tactile sensor.",
"A document segmentation, classification and recognition system","A discussion is given on a document segmentation, classification and recognition system for automatically reading daily-received office documents that have complex layout structures, such as multiple columns and mixed-mode contents of texts, graphics and half-tone pictures. First, the block segmentation employs a two-step run-length smoothing algorithm for decomposing any document into single-mode blocks. Next, based on clustering rules the block classification classifies each block into one of text, horizontal or vertical lines, graphics, and pictures. The text block is separated into isolated characters using projection profiles, and which are translated into ASCII codes through a font- and size-independent character recognition subsystem. Logo pictures discriminated from half-tone pictures are identified and converted into symbolic words. The experimental results show that the proposed system is capable of correctly reading different styles of mixed-mode printed documents.","Image segmentation,
Computer graphics,
Character recognition,
Smoothing methods,
Facsimile,
Image coding,
Image processing,
Computer vision,
Information science,
Text recognition"
Fundamental data movement algorithms for reconfigurable meshes,A number of data movement algorithms for the two-dimensional reconfigurable mesh are presented. These include computing the prefix sum of a binary sequence and computing the prefix maxima of a sequence of real numbers. These algorithms lead to a fast algorithm to sort a sequence of n reals in O(log n/log m) time on a reconfigurable mesh of size mn*n with 3,
Fuzzy semantics and fuzzy constraint networks,"After reviewing the notion of crisp constraint networks and their relationship to semantics in classical logic, the authors define fuzzy constraint networks and their relationship to fuzzy logic. Then they introduce Khayyam, a fuzzy constrained-based programming language which implements much of Zadeh's PRUF formalism. In Khayyam, any sentence in the first-order fuzzy predicate calculus is a well-formed constrained statement. Finally, using Khayyam to address an equipment selection application, the expressive power of constraint-based languages is illustrated.",
A novel approach to integrate computer exercises into teaching of utility-related applications of power electronics,"The author presents a novel approach to integrating computer exercises into the teaching of utility-related applications of power electronics. First, it is argued that the various emerging high-power applications of power electronics should be included in the power engineering curriculum. Based on a survey of available software packages, two royalty-free programs which are best suited for this purpose are compared. By means of a detailed example of a computer exercise, it is shown how the use of computer simulation in homework problems, laboratory exercises, and group projects can make the education of these important topics more effective and exciting for both the students and the instructor.",
Adaptive fuel allocation using pseudo fuel prices,"The authors outline a practical adaptive fuel allocation approach. The approach uses pseudo fuel prices as decision variables. As a result, the fuel allocation decision can be conveniently implemented in system operation by using the pseudo fuel prices to dispatch generation. A lower pseudo price usually results in higher fuel consumption and a higher pseudo price usually results in lower fuel consumption. In the proposed approach, the systematic criterion for adaptively identifying the need for reschedulings is based on the absolute change in each pseudo fuel price. Various aspects of the proposed approach are discussed, and its application to a midwestern utility system is illustrated.",
A theoretical framework for the analysis and design of size-limited multirate filter banks,"A theoretical framework for analyzing and designing maximally decimated, size-limited filter banks for finite-length input signals is presented. This flexible framework allows for the analysis of many different methods which have recently been proposed to handle the special issues which arise when processing finite extent input signals. Size-limited filter banks are viewed as linear transformations which can be implemented using filter banks composed of linear, time-varying filters and resamplers. The framework is convenient for designing exact-reconstruction, size-limited filter banks which combine almost any signal extension and analysis filter pair.",
One-dimensional least-squares model-based halftoning,"A least-squares model-based approach to digital halftoning is proposed. It exploits both a printer model and a model for visual perception. It obtains an optimal halftoned reproduction by minimizing the squared error between the response of the cascade of the printer and visual models to the binary image and the response of the visual model to the original gray-scale image. Least-squares model-based halftoning uses explicit eye models and relies on printer models that predict distortions and exploit them to increase, rather than decrease, both spatial and gray-scale resolution. The authors examine the one-dimensional case, in which each row or column of the image is halftoned independently. One-dimensional least-squares halftoning is implemented, in closed form, with the Viterbi algorithm. Experiments show that it produces better spatial and gray-scale resolution than conventional one-dimensional techniques and eliminates the problems associated with the modified (to account for printer distortions) error diffusion algorithm.",
A combined-transform coding (CTC) scheme for medical images,"A combined-transform coding (CTC) scheme is proposed to reduce the blocking artifact of conventional block transform coding and hence to improve the subjective performance. The proposed CTC scheme is described and its information-theoretic properties are investigated. Computer simulation results for a class of chest X-ray images are presented. A comparison between the CTC scheme and the conventional discrete cosine transform (DCT) and discrete Walsh-Hadamard transform (DWHT) demonstrates the performance improvement of the proposed scheme. In addition, combined coding can also be used in noiseless coding, yielding a slight improvement in the compression performance if it is used properly.",
Deciding to correct distributed query processing,"Most algorithms for determining query processing strategies in distributed databases are static in nature; that is, the strategy is completely determined on the basis of a priori estimates of the size of intermediate results, and it remains unchanged throughout its execution. The static approach may be far from optimal because it denies the opportunity to reschedule operations if size estimates are found to be inaccurate. Adaptive query execution may be used to alleviate this problem. A low overhead delay method is proposed to decide when to correct a strategy. Sampling is used to estimate the size of relations, and alternative heuristic strategies prepared in a background mode are used to decide when to correct. Evaluation using a model of a distributed database indicates that the heuristic strategies are near optimal. Moreover, it also suggests that it is usually correct to abort creation of an intermediate relation which is much larger than predicted.",
Reconstructing algebraic functions from mixed data,"The authors consider the task of reconstructing algebraic functions given by black boxes. Unlike traditional settings, they are interested in black boxes which represent several algebraic functions-f/sub 1/, . . ., f/sub k/, where at each input x, the box arbitarrily chooses a subset of f/sub 1/(x), . . ., f/sub k/(x) to output. They show how to reconstruct the functions f/sub 1/,. . ., f/sub k/ from the black box. This allows them to group the same points into sets, such that for each set, all outputs to points in the set are from the same algebraic function. The methods are robust in the presence of errors in the black box. The model and techniques can be applied in the areas of computer vision, machine learning, curve fitting and polynomial approximation, self-correcting programs and bivariate polynomial factorization.",
A direct geometrical method for bounding the error exponent for any specific family of channel codes. I. Cutoff rate lower bound for block codes,"A direct, general, and conceptually simple geometrical method for determining lower and upper bounds on the error exponent of any specific family of channel block codes is presented. It is considered that a specific family of codes is characterized by a unique distance distribution exponent. The tight linear lower bound of slope -1 on the code family error exponent represents the code family cutoff rate bound. It is always a minimum of a sum of three functions. The intrinsic asymptotic properties of channel block codes are revealed by analyzing these functions and their relationships. It is shown that the random coding technique for lower-bounding the channel error exponent is a special case of this general method. The requirements that a code family should meet in order to have a positive error exponent and at best attain the channel error exponent are stated in a clear way using the (direct) distance distribution method presented.",
Using random task graphs to investigate the potential benefits of heterogeneity in parallel systems,"The authors consider multiprogrammed multiprocessors and parallel programs modeled as random task graphs. A theoretical analytical model for studying combinations of extreme cases of workload parallelism (highly parallel versus highly sequential) and of system utilization (light versus heavy load) is presented. A simulation model was used to study intermediate cases. From these two models, conditions under which heterogeneity presents a significant performance improvement over homogeneous architectures are derived. A study of the effect of scheduling policies for heterogeneous architectures on workloads of different degrees of parallelism under various system load conditions is presented.",
A new segmentation technique of Arabic text,"Character recognition has attracted an immense research interest. Hand printed Latin text and printed Arabic text are cursive script. One of the difficulties involved in processing such text is the segmentation of the text into distinct characters. Thereafter, the recognition of these characters. The paper proposes a new segmentation technique for Arabic text.",
Circuit enhancement by eliminating long false paths,"The authors propose to identify and perform logic replacement for a portion; called a segment, of a long path instead of the path itself. This results in less gate and lead duplication and hence reduction in the increase of circuit area. They give sufficient conditions for the choice of segments that can maintain the performance of the circuit. If the restriction on the choice of segments is relaxed then two very effective heuristics are obtained for removing long false paths. The experimental results show that the proposed algorithm and heuristics are feasible for large designs and the increase in circuit area is significantly reduced.",
Newton's method for fractional combinatorial optimization,"The authors considers Newton's method for the linear fractional combinatorial optimization. He proves a strongly polynomial bound on the number of iterations for the general case. He considers the maximum mean-weight cut problem, which is a special case of the linear fractional combinatorial optimization. This problem is closely related to the parametric flow problem and the flow problem when the maximum arc cost is being minimised. He proves that Newton's method runs in O(m) iterations for the maximum mean-weight cut problem. One iteration is dominated by the maximum flow computation. This gives the best known strongly polynomial bound of O(m/sup 2/n) for all three problems mentioned.",
P-functions-ternary logic functions capable of correcting input failures and suitable for treating ambiguities,"The authors consider a new class of special ternary logic functions: the P-functions capable of correcting input failures, based on the regular ternary logic. There are three major results. First, the P-functions are a special subset of the regular functions with no information loss. Second a ternary logic function defined by the all-prime-implicant disjoint of any Boolean connective is a P-function. Third, a P-function may be identified from the irredundant disjunctive form. The relationship between P-functions and other meaningful ternary logic functions is discussed.",
Data-oriented exception handling,"Exception handling mechanisms were added to programming languages to segregate normal algorithmic processing from error processing. However, handlers which are typically associated with exceptions through a program's control features, clutter source text when features are nested or when different objects require different responses to exceptions. The authors describe a method for associating handlers with data objects in declarations that better segregates algorithmic and error processing. They call their notion data-oriented exception handling to distinguish it from more conventional, control-oriented mechanisms. Empirical studies of Ada programs indicate that conventional exception handling mechanisms are more complex than necessary and that data-oriented exception handling can be used to produce programs that are smaller, better structured, and easier to understand and modify.",
Mixed Level Hierarchical Test Generation for Transition Faults and Overcurrent Related Defects,,
A recursive T-matrix algorithm for strips and patches,"A recursive T-matrix algorithm (RTMA) is formulated to extend its applicability to infinitely thin and conducting scatterers. Canonical geometries consisting of strips or patches are considered. These geometries have direct application in finite-size frequency selective surfaces (FSSs). The formulation of this T-matrix algorithm starts from the method of moments (MOM). Thus, the connection between the MOM and the T-matrix algorithm is established. Three-dimensional patch problems are formulated analogously to the two-dimensional strip problems so that the need to use the vector addition theorem for the patch problems is eliminated and a unified formulation results. The T-matrix for a single strip or patch is also derived using MOM ideas. Computation of the current distributions on the conducting scatterers is also achieved. Results displaying the radar cross section (RCS) of and the current distribution on a sample FSS geometry are presented.","Method of moments,
Strips,
Current distribution,
Matrix converters,
Computers,
History,
Scattering"
Dynamic hierarchical caching in large-scale distributed file systems,"A simple method for constructing dynamic heirarchies on a file-by-file basis is described. The results of a trace-driven simulation of a dynamic hierarchical file system are presented. A reduction in server traffic of a factor of more than two for shared files compared with a flat scheme is obtained, without a large increase in client access time. Low-overhead techniques for maintaining cache consistency by detecting missed cache invalidation are discussed.",
Human interface with computers in everyday life,"The computerization of equipment making up our ordinary living environment is proceeding rapidly, and the networking of these computerized objects is likely to become a major issue in the future. Embedded microchips endow equipment with advanced functions, often bringing the need for a high level of information exchange with users. For this reason, human/machine interface (HMI) with computerized objects requires at least the same level of advancement and standardization as HMI in personal computers and workstations. The author discusses the concepts and policies being incorporated in the TRON Project's standardization of HMI, based on the above premises. He describes the 'TRON Human Interface Specifications for Computers in Everyday life' as a specific result of these standardization efforts.",
A Performance Study of Memory Consistency Models,"Recent advances in technology are such that the speed of processors is increasing faster than memory latency is decreasing. Therefore the relative cost of a cache miss is becoming more important. However, the full cost of a cache miss need not be paid every time in a multiprocessor. The frequency with which the processor must stall on a cache miss can be reduced by using a relaxed model of memory consistency. In this paper, we present the results of instruction-level simulation studies on the relative performance benefits of using different models of memory consistency. Our vehicle of study is a shared-memory multiprocessor with processors and associated write-back caches connected to global memory modules via an Omega net- work. The benefits of the relaxed models, and their the increasing hardware complexity, are assessed with varying cache size, line size, and number of processors. We find that substantial benefits can be accrued by using relaxed models but the magnitudes of the benefits depend on the architecture being modeled, the benchmarks, and how the code is scheduled. We did not find any major difference in levels of improvement among the various relaxed models.",
Timing-based mutual exclusion,"The benefits that can be obtained by using timing information in mutual exclusion algorithms are examined. A simple and efficient timing-based mutual exclusion algorithm is given. This algorithm always guarantees mutual exclusion (i.e. even when run asynchronously) and also avoids deadlock in case certain (realistic) inexact timing constraints are met. The algorithm uses only two shared read/write registers (a total of log n+1 bits), thus overcoming the n register lower bound for asynchronous algorithms. It is proved that the problem cannot be solved with only one shared register, so that this algorithm is optimal in terms of the number of registers. A lower bound is proved for the time complexity of any deadlock-free mutual exclusion protocol, as a function of the number of shared registers it employs. This bound shows that the algorithm described is near optimal, in terms of time complexity. It is shown that two natural ways of weakening the timing assumptions lead (unfortunately) to an n register lower bound.",
Truly alphabet-independent two-dimensional pattern matching,"A. Amir, G. Benson and M. Farach (see Proc. 24th STOC, p.59-68 (1992)) gave an algorithm for two-dimensional pattern matching (ABF for short) whose text processing is independent of the alphabet and takes O(n/sup 2/) time, but whose pattern processing is dependent on the alphabet and takes O(m/sup 2/log mod Sigma mod ) time. The authors present an algorithm that is truly independent of the alphabet and takes linear O(m/sup 2/+n/sup 2/) time. As in the Knuth-Morris-Pratt algorithm, the only operation on the alphabet is the equality test of two symbols. All previous algorithms except the ABF algorithm reduce the two-dimensional problem into one-dimensional string matching, and use known techniques in string matching. The ABF algorithm uses two-dimensional periodicity for text processing, but their pattern processing resorts to one-dimensional techniques. The authors present a two-dimensional technique for both pattern processing and text processing.",
"Design, implementation, and evaluation of Virtual Internet Protocol",The design and implementation of the Virtual Internet Protocol (VIP) are described. The VIP was implemented by modifying an operating system kernel based on 4.3BSD. The overhead of VIP is compared to that of IP. Measured results indicate that VIP can achieve host migration transparency in the Internet with negligible overhead.,
Time-varying potential field based 'perception-action' behaviors of mobile robot,"An efficient method is presented for implementing mobile robot perception-action behaviors, based on the time-varying potential field. The concept of dynamic potential is proposed to achieve the control scheme. The scheme was successfully implemented on the THMR-II mobile robot for a variety of applications. The drawbacks of known potential field methods are solved by the composition of the behavior controls. Experimental results based on sonar and vision signals are given to show that the method had good real-time response and adaptability, and was robust in dynamic environments.",
Zero-knowledge proofs of knowledge without interaction,"A zero-knowledge proof system of knowledge is a protocol between two parties called the prover and the verifier. The prover wants to convince the verifier that he 'knows' the proof of a given theorem without revealing any additional information. This is different from a zero-knowledge proof system of membership where the prover convinces the verifier only of the veridicity of the statement. Zero-knowledge proofs of knowledge are very useful tools in the design of secure protocols. Though, the concept of a proof of knowledge is a very subtle one and great care is needed to obtain a satisfying formalization. The authors investigate the concept of a zero-knowledge proof of knowledge with a non-interactive model. Here, the prover and the verifier share a short random string and the only communication allowed is from the prover to the verifier. Although this is a simpler model than the interactive one, still formalizing zero-knowledge proofs of knowledge is a delicate task.",
A Design Methodology For The High-level Synthesis Of Fault-tolerant Asics,,
An evaluation of planar-adaptive routing (PAR),"Network performance can be improved by allowing adaptive routing, but doing so introduces new possibilities of deadlock which can overwhelm the flexibility advantages. Planar-adaptive routing resolves this tension by limiting adaptive routing to a series of two-dimensional planes, reducing hardware requirements for deadlock prevention. The authors explore the performance of planar-adaptive routers for two, three, and four-dimensional networks. Under nonuniform traffic loads, the planar-adaptive router significantly outperforms the dimension-order router, while giving comparable performance under uniform loads. With equal resources, the planar-adaptive router provides performance superior to fully adaptive routers because it requires less resources for deadlock prevention, freeing resources to increase the number of virtual lanes.",
Misc: A Multiple Instruction Stream Computer,,
Information routing and reliability issues in distributed sensor networks,"Communication issues and problems in information routing in distributed sensor networks (DSNs) are considered. Two important communication constraints, viz., the delay constraint and the reliability constraint, are identified, and their impact on information routing is discussed. It is shown that the maximum end-to-end delay in a network depends on the diameter of the network, and efficient distributed algorithms are presented to determine the diameter of asynchronous networks. A distributed algorithm that determines the diameter of an asynchronous tree network when an arbitrary node in the network initiates the algorithm is introduced. An efficient algorithm for determining the diameter when multiple nodes initiate the algorithm is presented. An algorithm to determine the diameter of arbitrary networks is presented, and its message complexity is shown. Effects of link/node failures on network delay are studied, and important network structure design criterion are discussed. The distributed, dynamic routing algorithms are reviewed, and their adaptation to DSN environments is discussed.",
Formalized timing diagrams,"Traditionally, the timing behavior of digital circuits has been described using timing or waveform diagrams. These diagrams concisely represent the shape of the waveforms that are observed at the interface of a circuit and the temporal relationships between their edges. Timing information takes two principal forms: propagation delays that abstract the internal implementation of the circuit and timing constraints that specify how the circuit can be used by its environment. The author proposes a formalization of the concepts and notations used in timing diagrams that enable them to be used in conjunction with hardware description language specifications of the circuit's internal function. WAVES, an interactive timing diagram editor that was designed to embody these formalisms is also described. WAVES is unique in that it captures complex timing behaviour including concurrent, conditional, and iterative event sequences.",
Witnesses for Boolean matrix multiplication and for shortest paths,"The subcubic (O(n/sup w/) for w(3) algorithms to multiply Boolean matrices do not provide the witnesses; namely, they compute C=A.B but if C/sub ij/=1 they do not find an index k (a witness) such that A/sub ik/=B/sub kj/=1. The authors design a deterministic algorithm for computing the matrix of witnesses that runs in O(n/sup w/) time, where here O(n/sup w/) denotes O(n/sup w/(log n)/sup O(1)/). The subcubic methods to compute the shortest distances between all pairs of vertices also do not provide for witnesses; namely they compute the shortest distances but do not generate information for computing quickly the paths themselves. A witness for a shortest path from v/sub i/ to v/sub j/ is an index k such that v/sub k/ is the first vertex on such a path. They describe subcubic methods to compute such witnesses for several versions of the all pairs shortest paths problem. As a result, they derive shortest paths algorithms that provide characterization of the shortest paths in addition to the shortest distances in the same time (up to a polylogarithmic factor) needed for computing the distances; namely O(n/sup (3+w)/2/) time in the directed case and O(n/sup w/) time in the undirected case. They also design an algorithm that computes witnesses for the transitive closure in the same time needed to compute witnesses for Boolean matrix multiplication.",
"Fault tolerant graphs, perfect hash functions and disjoint paths","Given a graph G on n nodes the authors say that a graph T on n + k nodes is a k-fault tolerant version of G, if one can embed G in any n node induced subgraph of T. Thus T can sustain k faults and still emulate G without any performance degradation. They show that for a wide range of values of n, k and d, for any graph on n nodes with maximum degree d there is a k-fault tolerant graph with maximum degree O(kd). They provide lower bounds as well: there are graphs G with maximum degree d such that any k-fault tolerant version of them has maximum degree at least Omega (d square root k).",
Two-dimensional specification of universal quantification in a graphical database query language,"A technique is proposed for specifying universal quantification and existential quantification (combined with negation) in a two-dimensional (graphical) database query language. Unlike other approaches that provide set operators to simulate universal quantification, this technique allows a direct representation of universal quantification. Syntactic constructs for specifying universal and existential quantifications, two-dimensional translation of universal quantification to existential quantification (with negation), and translation of existentially quantified two-dimensional queries to relational queries are presented. The resulting relational queries can be processed directly by many existing database systems. The authors claim that this technique renders universal quantifications easy to understand. To substantiate this claim, they provide a simple, easy-to-follow guideline for constructing universally quantified queries.",
Assignment of ADT modules to processors,"The utilization of reusable software components can help to reduce the complexity of developing and maintaining parallel programs, but can lead to inefficiencies. The potential inefficiencies are addressed by providing a model of parallel execution (asynchronous remote procedure call, or ARPC) that not only speeds up programs, but also encourages the development of layered software by increasing parallelism in correspondence to increases in layering. The paper presents an efficient algorithm for assigning the reusable modules of a program to the processing elements of a parallel computer that supports ARPC. The objectives of the assignment algorithm are to permit maximum inter-module parallelism with the fewest possible PEs, and to prevent deadlock. The algorithm differs from previous solutions to the assignment problem in that the modules to be assigned are generic abstract data type modules, not procedures, tasks, or processes.",
On the equivalence of neural networks and fuzzy expert systems,"It is proven that any continuous, layered, feedforward neural net can be approximated to any degree of accuracy by a (discrete) fuzzy expert system, and that any continuous, discrete, fuzzy expert system with one block of rules may be approximated to any degree of accuracy by a three layered, feedforward neural net. The second result may be generalized to multiple blocks of rules by considering total (discrete) input and total (discrete) output from the fuzzy expert system. It is concluded that fuzzy expert systems and neural nets can both approximate functions (mappings, systems).",
Electrical and Thermal Feedback Effects on the Small-Signal Drain Characteristics of Partially-Depleted Soi Mosfets,,
Fast minimization of mixed-polarity AND/XOR canonical networks,"A quasi-minimal algorithm for canonical restricted mixed polarity (CRMP) AND/XOR forms is presented. These forms, which include the consistent and inconsistent generalized Reed-Muller (GRM) forms, are both very easily testable and, on average, have smaller numbers of terms than sum-of-product (SOP) expressions. The set of test vectors for detecting stuck-at and bridging faults of a function realized in CRMP forms, like that of consistent (GRM) forms, is independent of the function. This test can be of order (n+4)r, where n is the number of variables in the function and r is the number of component consistent GRMs in the CRMP. The experimental results confirm the compactness of CRMPs as compared to SOP expressions.",
How hard are sparse sets?,"The frontier of knowledge about the structural properties of sparse sets is explored. A collection of topics that are related to the issue of how hard or easy sparse sets is surveyed. The strongest currently known results, together with the open problems that the results leave, are presented.",
trulla : An Algorithm For Path Planning Among Weighted Regions By Localized Propagations,,
Near-optimum control of multiple-access collision channels,"A method based on recursive computation of the expected number of attempts and successes during the collision resolution phase of an access control algorithm is introduced for the design of near-optimum control strategies for multiple access collision channels with ternary and binary feedback. With this approach it is possible to circumvent the extremely difficult and still unsolved problem of finding the access control algorithm which achieves the highest throughput by settling for a near-optimum solution. The key to the design of the algorithms is to approximate the originally infinite-dimensional optimization problem by a one-dimensional optimization problem. In the ternary feedback case, the proposed algorithm achieves a throughput virtually identical to the highest throughput reported. Several forms of binary feedback are considered, and algorithms are introduced that achieve the highest throughput reported.","Feedback,
Throughput,
Communication system control,
Access control,
Algorithm design and analysis,
Design optimization,
Communications Society,
Computer science education,
Control engineering education,
Communication networks"
A ray model for decimetric radiowave propagation in an urban area,"A ray-tracing model involving multiple reflections and diffractions is proposed to predict wideband decimetric radio wave propagation in an urban area. A computer code was developed in which only buildings close to the vehicle are considered. Wall irregularities and electromagnetic properties of material are taken into account by a constant reflection factor, while diffraction attenuation is computed from geometrical theory of diffraction results. Simulated channel path losses and complex impulse responses are compared with some measurements performed in Paris at a 900-MHz central frequency.",
Waste makes haste: tight bounds for loose parallel sorting,"Conventional parallel sorting requires the n input keys to be output in an array of size n, and is known to take Omega (log n/log log n) time using any polynomial number of processors. The lower bound does not apply to the more 'wasteful' convention of padded sorting, which requires the keys to be output in sorted order in an array of size (1+o(1))n. The authors give very fast randomised CRCW PRAM algorithms for several padded-sorting problems. Applying only pairwise comparisons to the input and using kn processors, where 2",
Opal: a single address space system for 64-bit architecture address space,"The recent appearance of architectures with flat 64-bit virtual addressing opens an opportunity to reconsider the way in which operating systems use virtual address spaces. An operating system called Opal is being built for these wide-address architectures. The key feature of Opal is a single global virtual address space that extends to data on long-term storage and across the network. The case for the use of a single virtual address space is outlined, the model of addressing and protection used in Opal is presented, and some of the problems and opportunities raised by the approach are discussed.","Computer architecture,
Operating systems,
Protection,
Space technology,
Hardware,
Computer science,
Buildings,
Workstations,
Resource management,
Yarn"
Mating constraint languages for assembly sequence planning,"The authors analyze the most commonly used form of constraint languages for assembly planning: mating constraint languages. These constraints are typically composed of relations asserting that a certain pair of parts must be mated before some other pair of parts may be mated. However there are many significant differences between the forms of these constraints used by different authors. It is proven that some of these forms, such as those based on less-than relations and those based on less-than-or-equal-to relations, are equivalent. A variety of theorems that address which kinds of mating constraint languages are able to represent which kinds of sets of plans are included.","Assembly systems,
Data structures,
Computer science,
Constraint theory,
Fasteners,
Law,
Legal factors,
Manufacturing processes,
Process planning"
Enhanced Region Scheduling On A Program Dependence Graph,,
Certifying the correctness of software,"Software is either correct or incorrect in design to a specification in contrast to hardware which is reliable to a certain level to a correct design. Software of any size or complexity can only be tested partially, and typically a very small fraction of possible inputs are actually tested. Certifying the correctness of such software requires two conditions, namely (1) statistical testing with inputs characteristic of actual usage, and (2) no failures in the testing. If any failures arise in testing or subsequent usage, the software is incorrect, and the certification invalid. If such failures are corrected, the certification process can be restarted, with no use of previous testing.",
Strong recoverability in multidatabase systems,"A multidatabase system (MDBS) consists of a number of multiple autonomous database management systems (DBMSs) in which global transactions are executed under the control of the MDBS, and local transactions are executed under the control of a local DBMS. Each local DBMS ensures local serializability. The function of the MDBS is to ensure global serializability. The major difficulty in ensuring global serializability stems from the fact that in the presence of local transactions, and without any restrictions on the local concurrency control of the participating local DBMSs., even serial execution of global transactions does not guarantee global serializability. These difficulties could be avoided if the serialization order of transactions were always the same as their commitment order. The authors study the class of transaction scheduling mechanisms in which transaction serialization order can be determined by controlling their commitment order. They use these results to design a multidatabase transaction management scheme that ensures global serializability.",
Heavy ion test results for the 68020 microprocessor and the 68882 coprocessor,"The authors present a set of techniques making it possible to perform heavy-ion testing on present 32-bit microprocessors. In particular, they study how the program executed by the circuit during the irradiation can modify the calculated upset cross-section. The approach is illustrated by experimental results obtained on both the Motorola 68020 microprocessor and its coprocessor 68882, by means of particle accelerators as well as a Cf/sup 252/ fission-decay source.",
Generalization in cascade-correlation networks,"Two network construction algorithms are analyzed and compared theoretically as well as empirically. The first algorithm is the cascade correlation learning architecture proposed by S. E. Fahlman (1990), while the other algorithm is a small but striking modification of the former. Fahlman's algorithm builds multilayer feedforward networks with as many layers as the number of added hidden units, while the other algorithm operates with just one layer of hidden units. This implies that their computational capabilities and the representation of the generalizations they deal with are quite diverse, and it is demonstrated how the generalization ability of the networks generated by Fahlman's algorithm is outperformed by the networks built by the new algorithm.",
Segmentation by nonlinear diffusion. II,"An algorithm that systematically uses nonuniform smoothing to find boundary components in the form of connected, regularized curves is presented. The boundary, represented by a variable continuously defined over the image domain, as well as the smoothing of the image are determined by a nonlinear system of diffusion equations. Nonlinear diffusion is used again to threshold the boundary variable to produce the actual object boundaries. Laplacians of smoothed gradients are the main tool used. Nonuniform smoothing permits the use of multiple smoothings and the use of derivatives of up to order six.",
A Competitive Distribution Theory of Neocortical Dynamics,"Peristimulus inhibition in sensory pathways is generally attributed to lateral inhibitory connections. However, in the neocortex circuitry is incompletely understood at present, and in some cases there is an apparent mismatch between observed inhibitory effects and intracortical inhibitory connections. This paper studies the hypothesis that an additional mechanism, competitive distribution of activation, underlies some inhibitory effects in cortex. Analysis of a mathematical model based on this hypothesis predicts that per stimulus inhibitory effects can be caused by competitive distribution of activation, and computer simulations confirm these predictions by demonstrating Mexican Hat patterns of lateral interactions, transformation of initially diffuse activity patterns into tightly focused ""islands"" of activation, and edge enhancement. The amount of inhibition can be adjusted by varying the intensity of the underlying competitive process. The concept of competitive distribution of activation provides an important perspective for interpreting neocortical and thalamocortical circuitry and can serve as a guide for further morphological and physiological studies. For example, it provides an explanation for the existence of recurrent cortex-to-thalamus connections that perform a logical AND-operation, and predicts the existence of analogous neocortical circuitry.",
Cluster-M Paradigms for High-Order Heterogeneous Procedural Specification Computing,,
Network Supercomputing: Experiments with a Cray-2 to Cm-2 Hippi Connection,,
A prescriptive formal model for data-path hardware,"The authors present a formal representation for register-level digital designs. The formalism is expressed in term of three models of a design, the data-flow structure, and timing models, and by bindings that express the interrelationships of the three models. The authors describe the desiderata that led to the particular choice of representation: a uniform representation for specification and implementation, the ability to express detailed implementation constraints, formality, descriptiveness, ease of testing, ease of encoding, executability, and prescriptiveness. They then describe related work and describe the representation and correctness constraints. Formal semantics for the representation are given, and a brief overview of a system that implements them is presented.",
A nonlinear digital filter using fuzzy clustering,"A novel digital signal processing technique, fuzzy filtering, is proposed for estimating signals with edges, contaminated with additive white Gaussian noise. In this filter, the concept of fuzzy clustering is utilized for classifying signals. This filter classifies the input signal sequence into a flat part and a changing one ambiguously using a fuzzy-logic membership function. Then, the signal is estimated on the basis of the classification. Fuzzy clustering is more effective than conventional definite classification, since some edges in the signal are ambiguous. Moreover, by combining with median filtering a filter for removing both white Gaussian noise and impulsive noise can be obtained. Computer simulations demonstrate its superior capability.","Digital filters,
Filtering,
Gaussian noise,
Signal processing,
Computer simulation,
Computer science,
Digital signal processing,
Additive white noise,
Fuzzy logic,
Degradation"
Horn programming in linear logic is NP-complete,"The question of developing a computational interpretation of J.-Y. Girard's (1987) linear logic and obtaining efficient decision algorithms for this logic, based on the bottom-up approach, is addressed. The approach taken is to start with the simplest natural fragment of linear logic and then expand it step-by-step. The smallest natural Horn fragment of Girard's linear logic is considered, and it is proved that this fragment is NP-complete. As a corollary, an affirmative solution for the problem of whether the multiplicative fragment of Girard's linear logic is NP-complete is obtained. Then a complete computational interpretation for Horn fragments enriched by two additive connectives and by the storage operator is given. Within the framework of this interpretation, it becomes possible to explicitly formalize and clarify the computational aspects of the fragments of linear logic in question and establish exactly the complexity level of these fragments.",
Vehicle density and communication load estimation in mobile radio local area networks (MR-LANs),"The communication bandwidth of MR-LANs required to serve cooperative driving applications, which are under development in several European projects, is estimated. The bandwidth capacity is found to depend strongly on the road configurations and the related vehicle densities. The values range between 100 kb/s and 3 Mb/s at a carrier frequency of 60 GHz. If one switches to a carrier of 6 GHz, the required bandwidth must be doubled approximately, due to the large reuse distance. However, the bandwidth need to cover a much larger range of 200 kb/s up to 6 Mb/s.<>","Mobile communication,
Intelligent networks,
Land mobile radio,
Local area networks,
Vehicle driving,
Road safety,
Bandwidth,
Velocity measurement,
Measurement standards,
Computer science"
Using communication-to-computation ratio in parallel program design and performance prediction,"The authors goal is to be able to predict the performance of a parallel program early in the program development process; to that end they require prediction methods that can be based on incomplete programs. They describe how a single method based on communication-to-computation (C/C) ratio can be used to predict performance accurately and yet fairly simply in some commonly encountered cases. They show how C/C-ratio-based methods are accomplished for both distributed-memory and coherent-memory multiprocessors. They show that focusing on C/C ratio simplifies the use of theory, machine benchmarking and application measurement necessary to provide good parallel performance prediction. In addition, the methods demonstrated are useful because they can be applied to program fragments, or serially executed code.",
An efficient convex hull computation on the reconfigurable mesh,Presents a fast parallel solution to the convex hull problem on a two dimensional reconfigurable mesh. The parallel algorithm computes the convex hull of N/sup 1/2/ planar points on a N/sup 1/2/*N/sup 1/2/ reconfigurable mesh. The algorithm is very efficient and completes the convex hull computation in O(1) time. Efficient parallel sorting of N/sup 1/2/ data items on the reconfigurable mesh and improved parallel enumerating techniques utilized as basic steps in the convex hull computation are also shown.,
An LVQ based reference model for speaker-adaptive speech recognition,"A novel type of hierarchical phoneme model for speaker adaptation, based on both hidden Markov models (HMM) and learned vector quantization (LVQ) networks is presented. Low-level tied LVQ phoneme models are trained speaker-dependently and independently, yielding a pool of speaker-biased phoneme models which can be mixed into high-level speaker-adaptive phoneme models. Rapid speaker adaptation is performed by finding an optimal mixture for these models at recognition time, given only a small amount of speech data; subsequently, the models are fine-tuned to the new speaker's voice by further parameter reestimation. In preliminary experiments with a continuous speech task using 40 context-free phoneme models at task perplexity 111, the authors achieved 82% word accuracy for speaker-dependent recognition and 73% in the speaker-adaptive mode.","Speech recognition,
Hidden Markov models,
Vector quantization,
Context modeling,
Neural networks,
Computer science,
Adaptation model,
Probability distribution,
System testing,
Statistical analysis"
Parallel lossless image compression using Huffman and arithmetic coding,"The authors show that high-resolution images can be encoded and decoded efficiently in parallel. They present an algorithm based on the hierarchical multi-level progressive (MLP) method, used either with Huffman coding or with a new variant of arithmetic coding called quasi-arithmetic coding. The coding step can be parallelized, even though the codes for different pixels are of different lengths; parallelization of the prediction and error modeling components is straightforward.","Image coding,
Arithmetic,
Decoding,
Predictive models,
Pixel,
Concurrent computing,
Registers,
Computer science,
Huffman coding,
Parallel processing"
A measure of symmetry based on shape similarity,"The authors view symmetry as a continuous feature, and define a continuous symmetry measure (CSM) of shapes. The general definition of symmetry measure allows a comparison of the amount of symmetry of different shapes and the amount of different symmetries of a single shape. Furthermore, the CSM is associated with the symmetric shape that is closest to the given one, enabling visual evaluation of the CSM.",
Accelerating the iterative inverse scattering algorithms by using the fast recursive aggregate T-matrix algorithm,"A review and a convergence analysis of the Born and distorted Born iterative methods are given. The fast recursive aggregate T-matrix algorithm is reviewed and then applied to the solution of the direct scattering part in the iterative inverse scattering algorithms. Together with the conjugate gradient method in the inversion part of the iterative inverse scattering algorithms, the overall computational complexity for the iterative inverse scattering algorithms is reduced from O(N3) to O(N2), representing a significant reduction of their computational complexity. The resulting distorted Born iterative algorithm is demonstrated to have a high-resolution ability of reconstructing one- or two-pixel pulse objects.",
Efficiently computing communication complexity for multilevel logic synthesis,"A new method for computing the communication complexity of a given partitioning whose running time is O(pq), where p is the number of implicants (cubes) in the minimum covering of the function and q is the number of different overlapping of those cubes, is presented. Two heuristics for finding a good partition which give encouraging results are presented. Together, these two techniques allow a much larger class of functions to be synthesized. Two heuristic partitioning methods have been tested for certain circuits from the MCNC benchmark set. Using either heuristic, 11 out of 14 examples actually achieve the optimal solutions. A prototype program designed using the above techniques was developed and tested for circuits from the MCNC benchmark set. The experiment shows that the new symbolic manipulation technique is several orders of magnitude faster than an old version.",
VisaVis-contributions to practice and theory of highly interactive visual languages,"Higher-orderness, highly interactive, a great amount of flexibility, color, increasing the visual extent and parallelism are all catchwords related to the development of visual languages. The paper reports on the functional visual language VisaVis coming up with a new user interaction strategy integrating higher order functions smoothly. VisaVis uses colors and shadows to convey information about the degree of interaction. A comparison with existing visual languages is presented to picture reached results to the reader. The translation into a meta-language which preserves inherent parallelism in a visual program is outlined. Additionally the concept of an implicit type system is introduced being sound and complete which prepares for prevention of run-time errors and increases the visual extent at the same time.",
Improving the radiation burn-out susceptibility of N-channel power MOSFETs,"Computer simulation was used to calculate the dose-rate thresholds of several different power MOSFET structures. Computational results indicate that significant improvements in radiation tolerance and burnout of the device are possible by reducing the lateral size of the power MOSFET unit cell or by using a lower emitter injection efficiency for the bipolar structure. Modification of some other factors, such as the base minority carrier lifetime or the epi/substrate interface shape, shows some minor improvements in device radiation tolerance.",
Program mobile robots in Scheme,"The authors have implemented a software environment that permits a small mobile robot to be programmed using the Scheme programming language. The environment supports incremental modifications to running programs and interactive debugging using a distributed read-evaluate-print loop. The programming environment separates the essential onboard run-time system from the development environment, which runs on a separate workstation. The development environment takes advantage of the workstation's large address space and user environment. It is fully detachable, so that the robot can operate autonomously if desired, and can be reattached for retrospective analysis of the robots behavior. To make concurrent applications easier to write, the run-time library provides multitasking and synchronization primitives. Tasks are lightweight, and all tasks run in the same address space.",
Experiments with a performance driven module generator,"The authors describe a performance-driven module generator (perflex) for efficient generation of fast static combinational CMOS circuit modules. A new flexible CMOS layout style provides the foundation for implementing fast circuits. Timing optimization is performed via transistor sizing, transistor reordering, and the reduction of wiring capacitance on critical paths, all of which are performed in close interaction with the simulated-annealing layout process. The main contributions are the new layout style, which is well suited for the synthesis of high-speed circuits, and the way in which well-known performance optimization techniques are embedded into the layout generation process to achieve fine-grain optimization.",
A fast recursive algorithm for computing CR-type bounds for image reconstruction problems,"The authors describe a method for computing matrix CR bounds for image reconstruction problems using an iterative algorithm that avoids the intractable inversion of the Fisher matrix required by direct methods. The algorithm produces a close approximation to the CR bound, requiring only O(n/sup 2/) floating point operations per pixel of interest, an order of magnitude savings relative to the O(n/sup 3/) flops required by noniterative methods. To illustrate the utility of the iterative algorithm, a prototypical application is studied: the dependence of achievable reconstruction accuracy on angular and radial sampling.",
Interactive road finding for aerial images,"Fully automatic road recognition remains an elusive goal in spite of many years of research. Most practical systems today use tedious manual tracing for the entry of data from satellite and aerial images to geographical data bases. The paper presents a semi-automatic method for the entry of such data. First ribbons of high contrast are found by analyzing gray scale surface principal curvatures. Then, pixels belonging to such ribbons are fitted by conic splines, and then a graph is constructed whose nodes are end points of the arcs fitted by the splines. The key new idea is to assign edges between all nodes and label them with a cost function based on physical constraints on roads. Once a pair of end points is chosen, a shortest path algorithm is used to determine the road between them. Thus a global optimization is performed over all possible candidates.",
Bounds on the performance of heuristic algorithms for multiprocessor scheduling of hard real-time tasks,"The authors analyze the performance of a heuristic algorithm, H/sub k/, which tries to keep at least k processors busy, if possible. H/sub k/ combines the features of two known heuristic scheduling algorithms: list scheduling and the H scheduling algorithm. The authors analyze its schedule length bound for both uniform tasks, i.e. tasks with the same computation time, and nonuniform tasks, i.e. tasks with arbitrary computation times. When k=2, the time complexity of H is the same as the complexity of the H scheduling algorithm and list scheduling, which is O(n/sup 2/r), where n is the number of tasks and r is the number of resources. Whereas the H scheduling algorithm has a poor schedule length bound but performs very well in finding feasible schedules, and list scheduling does not perform well in finding feasible schedules but has a good bound, the results show that H/sub 2/ has both a good schedule length bound and performs well in finding feasible schedules.",
Heuristic algorithms for constructing near-optimal structures of linear multihop lightwave networks,"The goal of the study described is to exploit the capabilities of emerging lightwave technology and the fact that the IEEE 802.6 MAN is a linear network, to construct near optimal linear multihop lightwave networks. Heuristic algorithms are proposed for constructing photonic implementations of near optimal distributed queue dual bus (DQDB) structures. Two sets of heuristic optimization algorithms are formulated. The first set is concerned with minimizing the maximum flow in any link in the network, while the second set of heuristics is aimed at minimizing the network-wide mean packet delay. Important properties of these algorithms are analyzed and their performance is demonstrated with several representative numerical examples.",
A genetic algorithm for macro cell placement,A new genetic algorithm for the macro cell placement problem is presented. The algorithm is based on a generalization of the two-dimensional bin packing problem. The genetic encoding of a macro cell placement and the corresponding genetic operators are described. The algorithm has been tested on MCNC benchmarks and the quality of the produced placements is comparable to the best published results.,
A taxonomy of software visualization,"Software visualization is the use of interactive computer graphics, typography, graphic design, animation, and cinematography to enhance the interface between the software engineer or the computer science student and their programs. Although several taxonomies of software visualization have been proposed, they use few dimensions and do not span the space of important distinctions between systems. The authors propose a novel and systematic taxonomy of six areas making up thirty characteristic features of software visualization technology. The taxonomy is presented and illustrated in terms of its application to seven systems of historic importance and technical interest.",
The type and effect discipline,"The type and effect discipline, a framework for reconstructing the principal type and the minimal effect of expressions in implicitly typed polymorphic functional languages that support imperative constructs, is introduced. The type and effect discipline outperforms other polymorphic type systems. Just as types abstract collections of concrete values, effects denote imperative operations on regions. Regions abstract sets of possibly aliased memory locations. Effects are used to control type generalization in the presence of imperative constructs while regions delimit observable side effects. The observable effects of an expression range over the regions that are free in its type environment and its type; effects related to local data structures can be discarded during type reconstruction. The type of an expression can be generalized with respect to the variables that are not free in the type environment or in the observable effect.",
On the performance bounds for a class of rectilinear Steiner tree heuristics in arbitrary dimension,"A family of examples on which a large class C of minimum spanning tree-based rectilinear Steiner tree heuristics has a performance ratio arbitrarily close to 3/2 times optimal is given. The class C contains many published heuristics whose worst-case performance ratios were previously unknown. Of particular interest is that C contains two heuristics whose worst-case ratios had been conjectured to be bounded away from 3/2, and the construction also points out an incorrect claim of optimality for one of these heuristics. The examples also force the worst possible behavior in a number of heuristics outside C. The construction generalizes to d dimensions, where the heuristics will have performance ratios of at least 2d - 1/d; this improves the previous lower bound on performance ratio in arbitrary dimension.",
Parallel algorithms for optimal compression using dictionaries with the prefix property,"The authors study parallel algorithms for lossless data compression via textual substitution. Dynamic dictionary compression is known to be P-complete, however, if the dictionary is given in advance, they show that compression can be efficiently parallelized and a computational advantage is obtained when the dictionary has the prefix property. The approach can be generalized to the sliding window method where the dictionary is a window that passes continuously from left to right over the input string.","Parallel algorithms,
Dictionaries,
Data compression,
Computer science,
Books,
Pipelines,
Polynomials,
Phase change random access memory"
Segmentation of tomographic data without image reconstruction,"Geometric tomography (GT), a technique for processing tomographic projections in order to reconstruct the external and internal boundaries of objects, is presented. GT does not necessitate the reconstruction of an image of the slice of the object. It is shown that the segmentation can be performed directly with the raw data, the sinogram produced with the scanner, and that those segmented shapes can be geometrically transformed into reconstructed shapes in the usual space. If one is interested in only the boundaries of the objects, they do not need to reconstruct an image, and therefore the method needs much less computation than those using traditional computed tomography techniques. Experimental results are presented for both synthesized and real data, leading to subpixel positioning of the reconstructed boundaries. GT gives its best results for sparse, highly contrasted objects such as bones or blood vessels in angiograms, it allows 'on the fly' processing of the data, and real time tracking of the object boundaries.",
Threshold selection based on histogram modeling,This research is concerned with modeling the gray-level probability density function of the image and then using it to select optimal threshold values. Image histogram modeling by kernel density estimation is considered. The main goal is to model the histogram properly. A number of analytic techniques for threshold selection are discussed and empirically evaluated on test as well as real-world scenes.,
On the parallel computation of the algebraic path problem,"The algebraic path problem is a general description of a class of problems, including some important graph problems such as transitive closure, all pairs shortest paths, minimum spanning tree, etc. In this work, the algebraic path problem is solved on a processor array with a reconfigurable bus system. The proposed algorithms are based on repeated matrix multiplications. The multiplication of two n*n matrices takes O(log n) time in the worst case, but, for some special cases, O(1) time is possible. It is shown that three instances of the algebraic path problem, transitive closure, all pairs shortest paths, and minimum spanning tree, can be solved in O(log n) time, which is as fast as on the CRCW PRAM.","Concurrent computing,
Tree graphs,
Parallel algorithms,
Computer science,
Computational modeling,
Phase change random access memory,
Gaussian processes,
Systolic arrays,
Terrorism,
Heart"
The consequences of fixed time performance measurement,"In measuring the performance of parallel computers, the usual method is to choose a problem and test the execution time as the processor count is varied. This model underlies definitions of 'speedup,' 'efficiency,' and arguments against parallel processing such as Ware's (1972) formulation of Amdahl's law (1967). Fixed time models use problem size as the figure of merit. Analysis and experiments based on fixed time instead of fixed size have yielded surprising consequences: the fixed time method does not reward slower processors with higher speedup; it predicts a new limit to speedup, which is more optimistic than Amdahl's; it shows an efficiency which is independent of processor speed and ensemble size; it sometimes gives non-spurious superlinear speedup; it provides a practical means (the SLALOM benchmark) of comparing computers of widely varying speeds without distortion.",
The triangular lattice protocol: a highly fault tolerant and highly efficient protocol for replicated data,"A protocol for managing replicated data in which data copies are organized as a triangular lattice is introduced. The smallest quorum size is O( square root N), where N is the number of data copies, which is currently considered optimal for a fully distributed environment. The protocol has the property of graceful degradation. The quorum sizes increase gradually as data copy failures increase. The protocol also has the property of asymptotically high availability, i.e., the availability approaches 1 as the number of data copies goes to infinity if the probability that a data copy available is greater than 0.5.",
Testing generality in JANUS: a multi-lingual speech translation system,"For speech translation to be practical and useful, speech translation systems should be portable to multiple languages without substantial modification. The authors present results of expanding the English-based JANUS speech translation system to translate from spoken German sentences to English and Japanese utterances. The authors also report the results of implementing part of the linked predictive neural network (LPNN) speech recognition module on a massively parallel machine. The JANUS approach generalizes well, with overall system performance of 97%. This surpasses English-based JANUS performance.",
Accuracy of memory reference traces of parallel computations in trace-drive simulation,"For given input the global trace generated by a parallel program in a shared memory multiprocessing environment may change as the memory architecture, and management policies change. A method is proposed for ensuring that a correct global trace is generated in the new environment. This method involves a new characterization of a parallel program that identifies its address change points and address affecting points. An extension of traditional process traces, called the intrinsic trace of each process, is developed. The intrinsic traces maximize the decoupling of program execution from simulation by describing the address flow graph and path expressions of each process program. At each point where an address is issued, the trace-driven simulator uses the intrinsic traces and the sequence of loads and stores before the current cycle, to determine the next address. The mapping between load and store sequences and next addresses to issue, sometimes, requires partial program reexecution. Programs that do not require partial program reexecution are called graph-traceable.",
Concurrent file operations in a high performance FORTRAN,"The authors propose constructs to specify I/O (input/output) operations for distributed data structures in the context of Vienna FORTRAN. These operations can be used by the programmer to provide information which will allow the compiler and runtime environment to optimize the transfer of data to and from secondary storage. Although the language constructs presented have been proposed in the context of Vienna FORTRAN, they can be easily integrated into any other high-performance FORTRAN extension.",
The implementation and evaluation of integrity maintenance rules in an object-oriented database,"The authors describe an approach to the declarative representation of integrity constraints in an object-oriented database and the use of integrity maintenance rules for the active maintenance of constraints. A semantic data model is used to automatically generate class definitions and state-altering database operations with constraints represented as objects in the database. Integrity maintenance production rules are automatically generated from constraints and stored as extensions to class operations, hiding the details of constraint checking and rule triggering. High-level transactions call state-altering operations and invoke the integrity maintenance process at commit time. Integrity constraints are declaratively represented in the database system, with operations encapsulating rules about how to respond to constraint violations. An analysis of problems associated with cyclic and anomalous rule behavior.",
Functional synthesis using area and delay optimization,"The authors present two algorithms that synthesize a netlist of register-transfer level (RTL) components from a functional description while minimizing hardware costs and delay. Functional synthesis is composed of two subtasks, functionality recognition and component mapping, which were incorporated in the functional synthesis algorithms tool (FSA). The two algorithms solve the component mapping problem and accomplish area and delay optimization. The experiments showed that in most cases the algorithms produced a design that was comparable to that of a human designer. It was also found that FSA improved the design quality by 18% in about half of the example runs. FSA was able to improve 66% of the example designs when using functionality recognition by a 42% improvement in design quality.",
A token based distributed k mutual exclusion algorithm,"The authors present an algorithm for solving the k mutual exclusion problem in a distributed system. The algorithm is token based, whereby a token is passed among sites. Only sites that either receive the token with a nonzero semaphore or receive the token with a zero semaphore and later receive a release message from a previous site are allowed to enter their critical sections. Attached to the token is a queue which lists the sites scheduled to receive the token and a general semaphore. In all cases except extremely light token request traffic, the number of messages per critical section execution can be expressed as a small constant. This constant approaches three in an extremely heavy token request environment.","Computer science,
Traffic control,
Permission,
Clocks,
Tellurium"
Two new techniques for compiled multi-delay logic simulation,"The authors describe two techniques for compiled event driven multidelay logic simulation that provide significant performance improvements over interpreted multidelay logic simulation. These two techniques are based on the concept of retargetable branch instructions that can be used to switch segments of code into and out of the instruction stream. The second algorithm, called the shadow technique, has been designed especially for systems with instruction caches. Benchmark experiments showed that these two techniques were up to 15 times faster than the interpreted multidelay simulator, with an average improvement of about five times for the fastest method.",
Terrain Mapping For Long-duration Autonomous Walking,,
An Actor-Based Framework for Heterogeneous Computing Systems,,
SNPP: A simple network payment protocol,"A protocol is proposed to securely implement payment transactions between mutually distrustful parties. This protocol is designed to operate over an open network, and can be implemented using a currently available encryption technology. A logical verification of the protocol is included, as well as a status report on its implementation.",
Tiling a polygon with rectangles,"The authors study the problem of tiling a simple polygon of surface n with rectangles of given types (tiles). They present a linear time algorithm for deciding if a polygon can be tiled with 1 * m and k * 1 tiles (and giving a tiling when it exists), and a quadratic algorithm for the same problem when the tile types are m * k and k * m.",
Clustering with competing self-organizing maps,"Competing self-organizing maps are used to cluster data. Because maps are more complicated than single stereotypes, this clustering is different from k-means clustering in that the proper number of clusters will be discovered. This discovery process for the number of clusters is studied and compared to k-means clustering. Also, because self-organizing maps are probabilistic algorithms, the frequency of a clustering outcome is used as a measure of the validity of the clustering.",
A performance comparison of the Rete and TREAT algorithms for testing database rule conditions,"The authors present the results of a simulation comparing the performance of the two most widely used production rule condition testing algorithms, Rete and TREAT, in the context of a database rule system. The results show that TREAT almost always outperforms Rete. TREAT requires less storage than Rete, and is less sensitive to optimization decisions than Rete. Based on these results, it is concluded that TREAT is the preferred algorithm for testing join conditions of database rules. Since Rete does outperform TREAT in some cases, this study suggests a next step which would be to develop a hybrid version of Rete and TREAT with an optimizer that would decide which strategy to use based on the rule definition and statistics about the data and update patterns.",
Optimal codes for correcting single errors and detecting adjacent errors,"Optimal codes that correct single errors and detect double errors within nibbles of power of two length are presented. For each n, a code of length n with the largest possible dimension which corrects single errors and detects double adjacent errors is presented. The problem of constructing optimal codes which correct single errors and detect double adjacent errors within nibbles of length l is discussed.","Error correction codes,
Parity check codes,
Reflective binary codes,
Space vehicles,
Linear code,
Hydrogen,
Computer science"
Asynchronous unison,Unbounded and bounded designs of asynchronous unison systems are discussed. It is shown that both systems are stabilizing in the sense that their steady state behaviors do not depend on their initial states. The systems can therefore tolerate memory and reconfiguration faults that may yield them in arbitrary states. It is also shown that unison systems are useful in designing multiphase systems.,"Clocks,
Steady-state,
Computer science,
Synchronization,
Fault tolerant systems"
Integrating security in a group oriented distributed system,"A distributed security architecture is proposed for incorporation into group oriented distributed systems, and in particular, into the Isis distributed programming toolkit. The primary goal of the architecture is to make common group-oriented abstractions robust in hostile settings in order to facilitate the construction of high-performance distributed applications that can tolerate both component failure and malicious attacks. These abstractions include process groups and causal group multicast. A delegation and access control scheme is also proposed for use in group-oriented systems. The focus is on the security architecture; particular cryptosystems and key exchange protocols are not emphasized.",
Effects of software changes on module cohesion,"Program slices are used to model module cohesion. For the authors purposes, a slice is a projection of program text that includes only the data tokens relevant to one output. The authors define six cohesion metrics in terms of these slices, and evaluate the effects of classes of module changes on these metrics. They find that the effects on cohesion metrics are notably more predictable when the changes result from adding code rather than from moving code.",
Reliable broadcasting in faulty hypercube computers,"A nonredundant broadcasting algorithm for faulty hypercube computers is proposed. The concept of unsafe nodes is introduced to identify those nonfaulty nodes that will cause a detour or backtracking because of their proximity to faulty nodes. It is assumed that each healthy node, safe or unsafe, knows the status of all the neighboring nodes. The broadcasting is optimal, meaning that a message is sent to each node via a Hamming distance path if the broadcasting is initiated from a safe node. It is also shown that when the source node is unsafe and there is an adjacent safe node, then the broadcasting can be achieved with only one more time step than the fault-free case.",
Adding a new dimension to the teaching of audience analysis: cultural awareness,The rationale behind teaching native English speakers to be sensitive to the cultural differences they will find when they communicate with nonnative speakers in the classroom and in the professional marketplace is considered. A teaching strategy that technical writing instructors can use in their classrooms to foster cultural awareness is described in detail. It is concluded that such an educational strategy is important for a future in which interaction with multicultural colleagues becomes inevitable and essential for business success.,"Education,
Cultural differences,
Writing,
Power generation economics,
Global communication,
Books,
Natural languages,
Companies,
Business communication,
Communication industry"
Comparing images using the Hausdorff distance under translation,"Efficient algorithms are provided for computing the Hausdorff distance between a binary image and all possible relative positions (translations) of a model, or a portion of that model. The computation is in many ways similar to binary correlation. However, it is more tolerant of perturbations in the locations of points because it measures proximity rather than exact superposition.",
Transformation systems are more economical and informative class descriptions than formal grammars,"The concept of the transformation system was introduced earlier by the author as a basic part of a general model for pattern learning. In this paper, for several formal languages (of various types) the equivalent transformation systems are presented. From these examples one can draw the conclusion that the transformation systems give shorter and more informative structural class descriptions than the formal grammars.","Formal languages,
Chromium,
Computer science,
Niobium,
Electronic mail,
Face recognition,
Pattern recognition"
Pre-run-time scheduling of processes with exclusion relations on nested or overlapping critical sections,"Nested or overlapping critical sections in processes frequently occur in many hard-real-time system applications. For a pre-run time schedule, the ability to schedule such processes can often significantly increase the chances of finding a feasible schedule. The authors study the properties of exclusion relations defined on nested or overlapping critical sections. An algorithm is presented that is able to systematically search for a feasible schedule that satisfies a given set of release times, deadline constraints, and precedence and exclusion relations, where the exclusion relations are defined on critical sections that may nest within or overlap with each other.",
"Color, change, and control of quantitative data display","Calico, a dynamic tool for the creation and manipulation of color mappings for the exploration of multivariate, quantitative data, was used to study the effects of user control and smooth change on user preference, accuracy, and confidence. The results of the study, as well as other user experiences with Calico, support the hypothesis that dynamic manipulation of color mappings is a useful feature of systems for the exploration of quantitative data using color. The main effect observed is a clear user preference for representations providing control over the mapping, a small but significant increase in accuracy, and greater confidence in information gleaned from manipulable displays. A smaller and less consistent effect showed greater user preference for an confidence in representations which provided smooth change between images.",
Set operations in object-based data models,"The semantics of set operations are not adequate for the richer data models of object-based database systems that include object-oriented and semantic data modeling concepts. The reason is that precise semantics of set operations on complex objects require a clear distinction between the dual notions of a set and a type, both of which are present in the class construct found in object-based data models. This gap is filled here by a framework for executing set theoretic operations on the class construct. The proposed set operations, including set difference, union, intersection and symmetric difference, determine both the type description of the derived class as well as its set membership. For the former, inheritance rules are developed for property characteristics such as single-valued versus multivalued and required versus optional. For the latter, the object identity concept is developed if borrowed from data modeling research. The framework allows for property inheritance among classes that are not necessarily IS-A related.",
Real-time data processes in a balloon-borne apparatus,In a balloon-borne experiment signals from detectors are processed in a balloon-borne apparatus to fit the data bandwidth of storage devices installed in the apparatus. The process begins at front-end processors receiving signals from detectors and proceeds under successive stages by dedicated processors. Event data are finally fed to a computer bank where the events are further selected before being written into the storage devices. The computer bank is made of transputer modules. The transputers are widely employed and some processors are implemented with the transputers. The integration of the processors is described and the function and implementation of the individual processors are outlined. The authors are planning a series of balloon-borne experiments searching for antiparticles of cosmic origins. Firstly the authors will measure the antiproton flux. Antiprotons need to be identified under the overwhelming background of protons.,
Autonomous transaction execution with epsilon serializability,"The authors study the feasibility of autonomous transaction execution in systems with asynchronous transaction processing based on epsilon serializability (ESR). The abstract correctness criteria defined by ESR are implemented by techniques such as asynchronous divergence control and asynchronous consistency restoration. Concrete application examples in a distributed environment, such as banking, illustrate the advantages of using ESR to support execution autonomy. The ability for asynchronous transaction processing also supports efficient concurrent transaction and query processing.","Paramagnetic resonance,
Availability,
Computer science,
Concrete,
Banking,
Concurrent computing,
Distributed databases,
Transaction databases,
Delay,
Force control"
ANN with two-dendrite neurons and its weight initialization,The authors propose the multidendrite multiactivation product unit and the vectorial connection model for artificial neural networks. A generalized backpropagation learning rule is also developed for multilayer feedforward networks with a new neuron model and connections. Each hidden neuron is a multiactivation product unit which requires vectorial axon connections and a productive activation function. An optimal weight initialization algorithm is developed for a three-layer network with hidden units of 2D vectorial connections. The weights between the input layer and the hidden layer are derived from the feature selection methods used in pattern recognition. The activation function is the product of a 2D Hermite spline base function. The weights between the hidden layer and the third layer are scaled coefficients of the 2D Hermite spline interpolations. The performances of networks initialized by the new algorithm are compared with those obtained by selecting random initial weights.,
Refining PID Controllers Using Neural Networks,"The KBANN (Knowledge-Based Artificial Neural Networks) approach uses neural networks to refine knowledge that can be written in the form of simple propositional rules. We extend this idea further by presenting the MANNCON (Multivariable Artificial Neural Network Control) algorithm by which the mathematical equations governing a PID (Proportional-Integral-Derivative) controller determine the topology and initial weights of a network, which is further trained using backpropagation. We apply this method to the task of controlling the outflow and temperature of a water tank, producing statistically significant gains in accuracy over both a standard neural network approach and a nonlearning PID controller. Furthermore, using the PID knowledge to initialize the weights of the network produces statistically less variation in test set accuracy when compared to networks initialized with small random numbers.",
Fault tolerance training improves generalization and robustness,"A recurrent theme in the neural network literature is that noise is good. Other researchers have presented experimental evidence of improvements due to adding noise to the input data, randomly presenting data rather than cycling through it, truncating bits of the weights, using ad hoc modifications of the error signal, stochastic updating, and others. Another source of noise, one that also forces the network to develop a more robust internal representation, is proposed. During training, one randomly introduces the types of failures that one might expect to occur during operation. It is shown how this leads to significant improvements in the network's ability to avoid the overfitting problem, generalize to new data, and cope with internal failures.",
Fast computer vision algorithms for reconfigurable meshes,"A bus system that can change dynamically to suit computational needs is referred to as reconfigurable. The authors are interested in obtaining fast algorithms for a number of low-level vision tasks on a two-dimensional mesh augmented with a reconfigurable bus system (reconfigurable mesh). Specifically, for an n*n digitized image stored one pixel per processor they present O(loglogn) algorithms to compute low-level descriptors including perimeter, area, histogram, median row, center as well as several moments.","Computer vision,
Computational modeling,
Computer science,
Histograms,
Image processing,
Automata,
Reconfigurable architectures,
Pixel,
NASA,
Very large scale integration"
Delay spreads and channel dynamics measurements at ISM bands,"To understand the potential of indoor radio systems as communication media between portable computers and local area networks, the authors built a wideband indoor radio propagation measurement apparatus. The apparatus operates in the industrial, scientific, and medical (ISM) bands centered around 910 MHz, 2.44 GHz, and 5.8 GHz. They briefly describe the measurement apparatus, the measurement procedures, and the measurement areas in an academic environment, Columbia University. Complex multipath delay profiles were recorded in classrooms, small-room offices, open-layout offices, an auditorium, a library, and a machine room. The effects of both delay spread and channel dynamics on designing a high-speed indoor radio data transmission scheme are also discussed.",
Performance Optimization of Pipelined Primary Caches,"The CPU cycle time of a high-performance processor is usually determined by the the access time of the primary cache. As processor speeds increase, designers will have to increase the number of pipeline stages used to fetch data from the cache in order to reduce the dependence of CPU cycle time on cache access time. This paper studies the performance advantages of a pipelined cache for a GaAs implementation of the MIPS based architecture using a design methodology that includes long traces of multiprogrammed applications and detailed timing analysis, The study evaluates instruction and data caches with various pipeline depths, cache sizes, block sizes, and refill penalties. The impact on CPU cycle time of these alternatives is also factored into the evaluation. Hardware-based and software-based strategies are considered for hiding the branch and load delays which may be required to avoid pipeline hazards. The results show that software-based methods for mitigating the penalty of branch delays can be as successful as the hardware-based branch-target buffer approach, despite the code-expansion inherent in the software methods. The situation is similar for load delays; while hardware-based dynamic methods hide more delay cycles than do static approaches, they may give up the advantage by extending the cycle time. Because these methods are quite successful at hiding small numbers of branch and load delays, and because processors with pipelined caches also have shorter CPU cycle times and larger caches, a significant performance advantage is gained by using two to three pipeline stages to fetch data from the cache.","Optimization,
Delay effects,
Permission,
Costs,
Pipeline processing,
Laboratories,
Computer science,
Gallium arsenide,
Design methodology,
Application software"
On operational availability of a large software-based telecommunications system,"Modern telecommunications systems are dependent on software for their successful operation. In many cases, the software operates on an established hardware platform and subsequent releases of the system offer primarily in the software component. Because of the increased dependence of the society on advanced telecommunications systems, the reliability and availability of network switching elements are very important. Empirical information on the operational unavailability due to total system outages of a large software-based telecommunications system is presented and discussed. About 50% of these outages are reported as being caused by software. The data is used to show that the unavailability of this system can be described well using a classical two-state availability model.",
Restoration of scanning probe microscope images,"Scanning probe microscopy (SXM), which includes techniques such as scanning tunneling microscopy (STM) and scanning force microscopy (SFM), is becoming popular for 3D metrology in the semiconductor industry and for high resolution 3D imaging of surfaces in Materials Science and Biology. The authors present imaging models for SXM that take into account the effect of probe geometry on topographic images produced by SXM in 'contact' and 'non-contact' modes. The authors formulate methods for restoring an SXM image to obtain the original surface. Criteria for determining certainty of restoration are developed. It is shown that the methods developed can be expressed in terms of gray scale morphological operators. The efficacy of the approach is demonstrated by applying it to synthetic and real data.",
How well can data temporal consistency be maintained?,"A model of hard real-time systems where tasks access shared data is presented, and temporal consistency is defined in terms of the age and dispersion of data. Based on this model, two variants of a multiversion lock-based concurrency control algorithm and two priority-driven preemptive scheduling algorithms, rate-monotone and earliest-deadline-first, are evaluated. Simulation results indicate how well data temporal consistency is maintained for different workload characteristics. These results can be used to guide the design of applications; by avoiding undesirable parameters, it is made easier to maintain data temporal consistency.",
A laboratory for microprocessor teaching at different levels,"The design of a laboratory for microprocessor experimental teaching in which flexibility is one of the major design requirements is presented. The laboratory is intended to be used for software and hardware experiments, and is dedicated to students with very different levels of microprocessor knowledge. The basic development station includes a VME single-board computer, based on the 68010 microprocessor, connected through a serial link to a personal computer that acts as the system user interface, allowing the editing, assembly, loading, and debugging of low-level programs. The microprocessor may be connected to the user hardware through a VME interface board which has been specifically designed and developed for this purpose. This interface provides the user with the microprocessor bus signals, some of which have been emulated, and makes the VME bus transparent to users. Thus, the user needs no prior knowledge of this bus. It also acts as a protection system against critical errors in the user hardware.",
Computing in solvable matrix groups,"The author announces methods for efficient management of solvable matrix groups over finite fields. He shows that solvability and nilpotence can be tested in polynomial-time. Such efficiency seems unlikely for membership-testing, which subsumes the discrete-log problem. However, assuming that the primes in mod G mod (other than the field characteristic) are polynomially-bounded, membership-testing and many other computational problems are in polynomial time. These problems include finding stabilizers of vectors and of subspaces and finding centralizers and intersections of subgroups. An application to solvable permutation groups puts the problem of finding normalizers of subgroups into polynomial time. Some of the results carry over directly to finite matrix groups over algebraic number fields; thus, testing solvability is in polynomial time, as is testing membership and finding Sylow subgroups.",
Compiling VHDL into a high-level synthesis design representation,"An approach to the use of VHDL (VHSIC hardware description language) as an input specification to the CAMAD high-level synthesis system is presented. A synthesis-oriented compiler which takes a subset of VHDL as input and compiles it into the interal design representation of CAMAD is described. CAMAD can then be synthesized into register-transfer level design. Since CAMAD supports the design of hardware with concurrency and asynchrony, the VHDL subset includes the concurrent features of the language. Conclusions concerning how to deal with signals, wait statements, structured data, and subprograms are presented.",
Majority gates vs. general weighted threshold gates,Small-depth circuits that contain threshold gates (with or without weights) and parity gates are studied. All circuits considered are of polynomial size. Several results that complete the work of characterizing possible inclusions between many classes defined by small-depth circuits are proved.,"Circuits,
Polynomials,
Neural networks,
Computational modeling,
Physics computing,
Wires,
Computer science,
Neurofeedback"
A variant of second-order multilayer perceptron and its application to function approximations,"A second-order multilayer perceptron that uses a different activation function, the quadratic sigmoid function, is proposed. Unlike the conventional sigmoid activation function, the quadratic sigmoid function exhibits second-order characteristics among the input components. Based on this new activation function, a learning algorithm is developed for the new multilayer perceptron. The proposed multilayer perceptron has been used to approximate continuous-valued functions. The approximation results show that the learning speed and the network size were significantly improved in comparison with the conventional multilayer perceptrons which use the sigmoid activation functions.","Multilayer perceptrons,
Function approximation,
Neurons,
Neural networks,
Polynomials,
Application software,
Computer science,
Nonhomogeneous media,
Multi-layer neural network,
Costs"
Solving maximum likelihood equations for two-parameter software reliability models using grouped data,"Existence conditions are given for maximum likelihood parameter estimates for several commonly employed two-parameter software reliability models. For these models, the maximum likelihood equations can be expressed in terms of a single equation in one unknown. Bounds are given on solutions to these single equations problems to serve as initial intervals for search algorithms like bisection. Uniqueness of the solutions is established in some cases. Results are given for the case of grouped failure data.",
A new architecture for achieving translational invariant recognition of objects,"A multistage network that will reduce the translational uncertainty of a one-dimensional object is presented. To implement this network, novel network structures like multiple-valued outputs, competition between links instead of nodes, and cooperation of signals at the links are used. The number of nodes and links needed to implement the architecture is small. If the input field consists of n cells, then the total number of cells needed is only O(n). The total number of connections needed is O(nlogn). It is shown that size-invariant recognition can also be achieved if the input to the architecture is provided by a scale-sensitive network called a masking field.","Computer architecture,
Retina,
Computer science,
Information systems,
Uncertainty,
Self-organizing networks,
Unsupervised learning,
Stability,
Neural networks,
Surfaces"
Undirected connectivity in O(log/sup 1.5/n) space,"The authors present a deterministic algorithm for the connectivity problem on undirected graphs that runs in O(log/sup 1.5/n) space. Thus, the recursive doubling technique of Savich (1970) which requires Theta (log/sup 2/n) space is not optimal for this problem.","Sampling methods,
Parallel algorithms,
Polynomials,
Phase change random access memory"
Efficient utilization of spare capacity for fault detection and location in multiprocessor systems,"One scheme for detecting faults at the processor level in a multiprocessor system (see A. Dahbura et al., 1989) works by running secondary versions of jobs on the unused, or spare, processors of the system. The authors build upon this scheme and propose three new multiprocessor allocation strategies that run a viable number of versions per job. These schemes permit online detection and, in some cases, location of faulty processors in a system, without degrading its delay/throughput performance. Two new metrics, the fault detection capability and the fault location capability, are introduced to evaluate these schemes. Extensive simulation results are provided to show that these schemes utilize spare capacity more efficiently, thereby improving upon the fault detection and location capabilities of the system.",
An efficient database storage structure for large dynamic objects,"The author presents storage structures and algorithms for the efficient manipulation of general-purpose large unstructured objects in a database system. The large object is stored in a sequence of variable-size segments, each of which consists of a large number of physically contiguous disk blocks. A tree structure indexes byte positions within the object. Disk space management is based on the binary buddy system. The scheme supports operations that replace, insert, delete bytes at arbitrary positions within the object, and append bytes at the end of the object.",
Page segmentation without rectangle assumption,"A new technique for page segmentation without skew normalization is described and applied to both English and Japanese complex printed-page layouts. There is no need to make any assumption about the shape of blocks, hence the technique can handle not only skewed pages but it can also be extended to handle documents where columns are not rectangles. In this technique, based on the bottom-up strategy, the connected components are extracted on the reduced image and are classified with their local information. Since the skew angle is also estimated with the local information of blocks, the computational time is very short. Merging text blocks into string lines and into columns is performed with the skew information.",
A robust algebraic method for human face recognition,"The feature image and projective image are first proposed to describe the human face, and a new method for human face recognition in which projective images are used for classification is presented. The projective coordinates of projective image on feature images are used as the feature vectors which represent the inherent attributes of human faces. Finally, the feature extraction method of human face images is derived and a hierarchical distance classifier for human face recognition is constructed. The experiments have shown that the recognition method based on the coordinate feature vector is a powerful method for recognizing human face images, and recognition accuracies of 100 percent are obtained for all 64 facial images in eight classes of human faces.",
An integrated real-time locking protocol,"The authors examine a priority-driven locking protocol called integrated real-time locking protocol. They show that this protocol is free of deadlock, and in addition, a high-priority transaction is not blocked by uncommitted lower protocol. They show that this protocol is free of deadlock, and in addition, a high-priority transaction is not blocked by uncommitted lower priority transactions. The protocol does not assume any knowledge about the data requirements or the execution time of each transaction. This makes the protocol widely applicable, since in many actual environments such information may not be readily available. Using a database prototyping environment, it was shown that the proposed protocol offers a performance improvement over the two-phase locking protocol.",
A hybrid scheme for processing data structures in a dataflow environment,"The asynchronous nature of the dataflow model of computation allows the exploitation of maximum inherent parallelism in many application programs. However, before the dataflow model of computation can become a viable alternative to the control flow model of computation, one has to find practical solutions to some problems such as efficient handling of data structures. The paper introduces a new model for handling data structures in a dataflow environment. The proposed model combines constant time access capabilities of vectors as well as the flexibility inherent in the concept of pointers. This allows a careful balance between copying and sharing to optimize the storage and processing overhead incurred during the operations on data structures. The mode) is compared by simulation to other data structure models proposed in the literature, and the results are good.",
Implementing sequential machines as self-timed circuits,"A self-timed finite state machine (FSM) is described. It is based on a formally proven, efficient implementation of self-timed combinational logic and a self-timed master-slave register. Temporal behavioral constraints are formalized, and the system is shown to abide by them. The synthesis method is algorithmic and serves as an automatic compiler of self-timed FSMs. The specification of the FSM is given by a state table, similar to that of synchronous machines. The circuit operates according to a sequence of events that replaces the role of the central clock in the synchronous FSM. The inputs and outputs of the circuit are double-rail (or ternary) and the circuit produces a completion signal. The method is compared with other approaches.",
The nature of fault exposure ratio,"The fault exposure ratio K is an important factor that controls the per-fault hazard rate, and hence the effectiveness of software testing. The paper examines the variations of K with fault density which declines with testing time. Because faults get harder to find, K should decline if testing is strictly random. However, it is shown that at lower fault densities K tends to increase, suggesting that real testing is more efficient than random testing. Data sets from several different projects are analyzed. Models for the two factors controlling K are suggested, which jointly lead to the logarithmic model.",
Absolute orientation from uncertain point data: a unified approach,"A general and flexible method for fusing and integrating different 2D and 3D measurements for pose estimation is proposed. The 2D measured data are viewed as 3D data with infinite uncertainty in a particular direction. This representation unifies the two categories of the absolute orientation problem into a single problem that varies only in the uncertainty values associated with the measurements. With this paradigm a uniform mathematical formulation of the problem is obtained, and different kinds of measurements that can be fused to obtain a better solution. The method, which is implemented using Kalman filtering, is robust and easily parallelizable.","Noise measurement,
Covariance matrix,
Computer science,
Position measurement,
Gratings,
Kalman filters,
Filtering,
Robustness,
Sensor fusion,
Iterative methods"
Safe optimization for hard real-time programming,"Classical compiler optimizations are designed to reduce the expected execution time or memory use of programs. Optimizations for hard real time programs must meet more stringent constraints: all transformations applied to the program must be safe, in that they will never cause a deadline to be missed in any execution of the program. The authors show that optimization of hard real time programs cannot be separated from code generation, register allocation, and scheduling, even under a very simple model of program execution; it is therefore difficult. Optimization is also necessary, in that it may be needed to ensure that the program meets its deadlines. They examine the classical source code transformations for both sequential optimization and parallel programming (vectorization and concurrentization), presenting brief examples showing when each transformation may be unsafe. They classify each of these transformations in a system of five categories of safety, and describe what additional information (if any) is required to ensure that each transformation is safe.",
A subject-indexed bibliography of distributed artificial intelligence,"An updated version of a large bibliography of articles and books related to distributed artificial intelligence (DAI) is presented. It is intended to be a complete and comprehensive list of research on DAI. It does not contain references to research on distributed computing, parallel processing for AI, connectionism, general AI, or research in social science disciplines that are important to DAI such as sociology, symbolic interactionism, or economics.",
The isomorphism conjecture holds relative to an oracle,"The authors introduce symmetric perfect generic sets. these sets vary from the usual generic sets by allowing limited infinite encoding into the oracle. They then show that the Berman-Hartmanis (1977) isomorphism conjecture holds relative to any sp-generic oracle, i.e., for any symmetric perfect generic set A, all NP/sup A/-complete sets are polynomial-time isomorphic relative to A. As part of the proof that the isomorphism conjecture holds relative to symmetric perfect generic sets they also show that P/sup A/=FewP/sup A/ for any symmetric perfect generic/sup /A.",
Symbolic Synthesis of Supervisory Controllers,"Ramadge and Wonham [1] gave algorithms for finding controllers in their supervisory control framework. Their automatic synthesis techniques are implemented here using binary decision diagrams [2]. This technique of symbolic representation capitalizes on loose coupling between controlled plant components. We are able to synthesize a controller for a wafer-manufacturing plant, for which an explicit representation would have about 106 states.","Automatic control,
Control system synthesis,
Supervisory control,
Semiconductor device manufacture,
Manufacturing processes,
Data structures,
Boolean functions,
Binary decision diagrams,
Production facilities,
Information systems"
Foundations of intrusion detection (computer security),"Computer use is modeled as a mixture of two stochastic processes, normal and misuse. Intrusion detection is formally defined as identifying those transactions generated by the misuse process. Bounds for detection performance are derived in terms of the ratios of the densities of the processes at the individual transactions. It is shown that any optimal intrusion detection system must rank transaction suspicion consistently with these ratios. Sparsity of data requires that transactions be grouped into equivalence classes that preserve the order of the true ratio ranking and reduce the number of singleton and unobserved transactions. Results are described that demonstrate that in general this 'singleton reduction' problem is NP-hard.","Intrusion detection,
Computer security,
Stochastic processes,
Computer science,
Laboratories,
National security,
Humans,
Computer crime,
Access control,
Computer hacking"
On texture in document images,"A multichannel filtering-based texture segmentation method is applied to a variety of document image processing problems: text-graphics separation, address-block location, and bar code localization. In each of these segmentation problems, the text context or bar code in the image is considered to define a unique texture. Thus, all three document analysis problems can be posed as texture segmentation problems. Two-dimensional Gabor filters are used to compute texture features. Both supervised and unsupervised methods are used to identify regions of text or bar code in the document images. The performance of the segmentation and classification scheme for a variety of document images demonstrates the generality and effectiveness of the approach.","Gabor filters,
Image segmentation,
Pixel,
Frequency,
Image recognition,
Image processing,
Laboratories,
Computer science,
Application software,
Document image processing"
Vienna Fortran 90,"Vienna Fortran 90 is a language extension of Fortran 90 which enables the user to write programs for distributed memory multiprocessors using global data references only. Performance of software on such systems is profoundly influenced by the manner in which data is distributed to the processors. Hence, Vienna Fortran 90 provides the user with a wide range of facilities for the mapping of data to processors. It combines the advantages of the shared memory programming paradigm with mechanisms for explicit user control of those aspects of the program which have the greatest impact on efficiency. The paper presents the major features of Vienna Fortran 90 and gives examples of their use.",
On error-and-erasure decoding of cyclic codes,"Procedures are presented for error-and-erasure decoding of cyclic codes up to the Hartmann-Tzeng (HT) bound. Emphasis is placed on converting the problem of error-and-erasure decoding to an error-only decoding problem so that the Berlekamp-Massey or the Feng-Tzeng multisequence shift-register synthesis algorithms can be applied. This work has thus extended the result, which was up to a special case of the HT bound, obtained by P. Stevens (1990) on error-and-erasure decoding of binary cyclic codes.<>",
Techniques for integrating parallelizing transformations and compiler based scheduling methods,"Although the tasks of applying transformations and scheduling instructions are typically implemented in separate phases of a parallelizing compiler, interactions between these phases occur. The authors discuss these interdependencies and demonstrate that the separate phase approach can result in the application of a sequence of transformations that is not effective. The techniques presented for integrating these tasks utilize an iterative approach to applying program transformations and scheduling instructions for execution on a multiprocessor. These integrated techniques employ a demand driven approach to applying transformations; by iterating between the scheduling and transforming tasks, transformations are applied to the program only if and where they are needed. The authors also introduce an automatic transformation application and selection algorithm that provides further control over the application of transformations.",
Evolution Versus Design: Controlling Autonomous Robots,,"Robot control,
Cognitive robotics,
Control systems,
Mobile robots,
Robot sensing systems,
Artificial neural networks,
Control system synthesis,
Computer architecture,
Genetic algorithms,
Time factors"
Currency exchange rate forecasting by error backpropagation,"The paper describes a neural network system for forecasting time series and its application to a non-trivial task in forecasting currency exchange rates. The architecture consists of a two-layer backpropagation network with a fixed number of inputs modelling a window moving along the time series in fixed steps to capture the regularities in the underlying data. Several network configurations are described and the results are analysed. The effect of varying the window and step size is also discussed as are the effects of overtraining. The error backpropagation network was trained with currency exchange data for the period 1988-9 on hourly updates. The first 200 trading days were used as the training set and the following three months as the test set. The network is evaluated both for long term forecasting without feedback (i.e. only the forecast prices are used for the remaining trading days) and for short term forecasting with hourly feedback. By careful network design and analysis of the training set, the backpropagation learning procedure is an active way of forecasting time series. The network learns the training set near perfect and shows accurate prediction, making at least 20% profit on the last 60 trading days of 1989.","Exchange rates,
Backpropagation,
Neural networks,
Educational institutions,
Computer errors,
Computer science,
Application software,
Computer architecture,
Error correction,
Testing"
A structurally adaptive neural tree for the recognition of large character set,"This paper presents an adaptive self-organizing neural tree and its application to character recognition. The neural tree is suitable for hierarchical classification and it can grow and shrink to adapt to the changing environment. It also performs parametric adaptation to cope with small changes in the environment. When applied to character pattern recognition, it shows promising performance.",
Comparison of hybrid minimum laxity/first-in-first-out scheduling policies for real-time multiprocessors,"The behavior of two policies for scheduling customers with deadlines until the beginning of service onto multiprocessors is studied. Both policies attempt to approximate the performance of the minimum laxity (ML) scheduling policy without incurring its complete overhead by dividing the queue in two: one, of maximum size n>0, managed using the minimum laxity policy, and another, of unbounded size, managed in a first-in-first-out manner. One policy, F/ML(n), places the ML queue at the front, i.e. customers finding n or more in the system enter the first-in-first-out (FIFO) queue which in turn feeds the ML queue. The other policy, ML(n)/F, places the ML queue at the back, i.e. arriving customers enter the ML queue and if the total number in the system exceeds n, forces one customer from the ML queue to the FIFO queue. It is shown that these seemingly dissimilar policies exhibit exactly the same behavior for a fixed value of n both when customers are allowed to be discarded when they miss their deadlines before entering service and when they are not allowed to be discarded. Monotonicity properties are established for both policies.",
An efficient algorithm for production systems with linear-time match,A specialized match algorithm called Uni-Rete is reported. Uni-Rete is a specialization of the widely used Rete match algorithm to unique attributes. Performance results for Uni-Rete indicate over tenfold speedup with respect to Rete. The implications of Uni-Rete for non-unique-attribute systems are discussed.,
Incorporating computer-aided design into an electrical engineering/computer science curriculum,"The restructuring of the circuits and computer hardware courses at the University of Michigan's Department of Electrical Engineering and Computer Science to include a uniform set of electronic design automation (EDA) tools beginning early in the undergraduate curriculum is discussed. The ability to teach good engineering in the department has been significantly strengthened by these changes. The program and the details which have made it successful, including using a consistent set of well-supported commercial tools throughout the curriculum, providing adequate computing resources through a tuition surcharge for engineering students, and offering department-wide support through CAD short courses and consulting hours, are described.","Design automation,
Computer science,
Education,
Design engineering,
Electronic design automation and methodology,
Integrated circuit packaging,
Design methodology,
Circuit simulation,
Circuit testing,
Hardware"
On set-valued functions and Boolean collections,"The notion of a Boolean collection of set is introduced, and several combinatorial aspects of these collections are exploited. These collections of set appear to play a role in the approximation of non-Boolean set-valued functions by Boolean functions and, therefore, are relevant in the study of biocircuits and in the study of circuits based on frequency multiplexing, where set-valued functions are used.",
Matching complex images to multiple 3D objects using view description networks,The effective matching of a single 2D image of a cluttered scene to a library of multiple polyhedral models is achieved by organizing the 3D models into a network of descriptions of their 2D projections from expected views. The process of efficiently searching for image-model matches via a view description network is presented and demonstrated on images containing multiple objects and outdoor scenes. The experiments show that a recognition system based on view description networks is capable finding the correct matches to 3D objects in complex images with a potentially high level of efficiency.,"Image segmentation,
Libraries,
Layout,
Organizing,
Indexing,
Computer science,
Image recognition,
Contracts,
Assembly,
Object detection"
Logical hierarchies in PTIME,"A generalized quantifier is n-ary if it binds any finite number of formulas, but at most n variables in each formula. It is proved that for each integer n, there is a property of finite models which is expressible in fixpoint logic, or even in DATALOG, but not in the extension of first-order logic by any set of n-ary quantifiers. It follows that no extension of first-order logic by a finite set of quantifiers captures all DATALOG-definable properties. Furthermore, it is proved that for each integer n, there is a LOGSPACE-computable property of finite models which is not definable in any extension of fixpoint logic by n-ary quantifiers. Hence, the expressive power of LOGSPACE, and a fortiori, that of PTIME, cannot be captured by adding to fixpoint logic any set of quantifiers of bounded arity.","Logic,
Mathematics,
Polynomials,
Vocabulary,
Database languages"
Hierarchical symmetry,"The authors view symmetry as a continuous feature and dependent on resolution. Combining a continuous symmetry measure (CSM) with a multiresolution scheme, the authors present a method that hierarchically detects symmetric and almost symmetric patterns. Evaluation of symmetry at low frequencies guides the process to find the symmetry at higher frequencies.",
Optimal generating kernels for image pyramids by piecewise fitting,"A novel class of generating kernels for image pyramids is introduced. When these kernels are convolved with intensity functions of images, continuous piecewise surfaces composed of polynomial tensor products are fitted to the intensity functions. The fittings are optimal in the sense that the mean square error between them and the original intensity functions is minimized. Two members of the class are introduced, and symmetry, normalization, unimodality, and equal contribution properties are proved. These kernels possess attractive properties such as small window size, fast inverse transformation, and minimum error. Experiments show that they compare favorably with existing ones in terms of mean square error.",
Karhunen-Loeve Subspace,"The Karhunen-Loeve expansion is a well-known technique in the pattern recognition field, however, there is no exact proof of the K-L expansion in the context of approximation to a set of patterns. This paper provides an exact proof of the following well-known theorem: an N-dimensional subspace provides the best approximation to a set of patterns if and only if it is spanned by the first N-number of eigenelements of the covariance operator of the pattern set.",
Abstractions for parallel N-body simulations,Introduces C++ programming abstractions for maintaining load-balanced partitions of irregular and adaptive trees. Such abstractions are useful across a range of applications and MIMD architectures. The use of these abstractions is illustrated for gravitational N-body simulation. The strategy for parallel N-body simulation is based on a technique for implicitly representing a global tree across multiple processors. This substantially reduces the programming complexity and the overhead for distributed memory architectures. The overhead is further reduced by maintaining incremental data structures.,
A lattice framework for integrating vision modules,"How information processing by individual modules such as stereopsis, motion, texture, and color modules may be integrated, or assimilated, is addressed. A framework for assimilation based on a partial ordering of constraints implicit in all active modules is proposed. Such constraints, for example the rigidity constraint for motion, although often robust are also fallible, and hence are more properly regarded as premises. Such premises are used to construct a preference ordering for (classes of) interpretations of the image. Interpretations associated with maximal states in the ordering are taken as the assimilated interpretation of the modules. This approach stresses the need to use world knowledge to reason about the plausibility and consistency of interpretations of the image data.",
Modularity meets inheritance,"Several roles of classes in existing languages are unbundled by providing a suite of operators independently controlling such effects as combination, modification, encapsulation, name resolution, and sharing, all on the single notion of a module. It is pointed out that all module operators are forms of inheritance: thus, inheritance not only is not in conflict with modularity in the present system, but is its foundation. This allows a previously unobtainable spectrum of features to be combined in a cohesive manner, including multiple inheritance, mixings, encapsulation, and strong typing. The proposed approach is demonstrated in a language called Jigsaw. The language is modular in two senses: it manipulates modules and it is highly modular in its own conception, permitting various module combinators to be included, omitted, or newly constructed in various realizations.",
On the influence of programming models on shared memory computer performance,"Experiments are presented indicating that on shared-memory machines, programs written in the nonshared-memory programming model generally offer better performance, in addition to being more portable and scalable. The authors study the LU decomposition problem and a molecular dynamics simulation on three shared-memory machines with widely differing architectures, and analyze the results from three perspectives: performance, speedup, and scaling.",
Protection planning in transmission networks,"The protection of transmission networks is discussed. Algorithms and tools which are useful both to support the activity of network planners and to build an automatic network protection system are presented. A definition of general and constrained routing and protection problems in a transmission network is given. Protection planning tools, their functions,and implementation are discussed. An algorithm for multiconstrained routing and protection problems is introduced. The concept of the automatic network protection system is given, and its main features are described. The results of a protection study carried out using the described algorithms are presented.",
Hybrid weak-perspective and full-perspective matching,"Full-perspective mappings between 3-D objects and 2-D images are more complicated than weak-perspective mappings, which consider only rotation, translation, and scaling. Therefore, in 3-D model-based robot navigation, it is important to understand how and when full-perspective must be taken into account. A probabilistic combinatorial optimization algorithm is used to search for an optimal match between 3-D landmarks and 2-D image features. Three variations are considered. A weak-perspective algorithm rotates, translates, and scales an initial 2-D projection of the 3-D landmark. A full perspective selects a most promising alternative, but then updates the pose and reprojects the landmark. Like the full-perspective algorithm, the hybrid algorithm reliably recovers the true pose of the robot, and like the weak-perspective algorithm, it runs 5 to 10 faster than the full-perspective algorithm.",
Effect of hot spot on the performance of multistage interconnection networks,"Hot spots in multistage interconnection networks (MSINs) results in performance degradation of the network. The authors develop an analytical model for the performance evaluation of unbuffered MSINs under a single hot spot, followed by a performance comparison with buffered MSINs. For uniform traffic, a buffered network performs better than an unbuffered network. For a nonuniform traffic pattern causing congestion (for example, tree saturation) in the network, an unbuffered network outperforms a buffered network. This leads the authors to suggest a hybrid network which will be capable of switching from the buffered mode to the unbuffered mode in the presence of network congestion.",
Preemptibility in real-time operating systems,"Real-time operating systems generally depend on some form of priority information for making scheduling decisions. Priorities may take the form of small integers or deadline times, for example, and the priorities indicate the preferred order for execution of the jobs. Unfortunately, most systems suffer from some degree of priority inversion where a high priority job must wait for a lower priority job to execute. The authors consider the nature of the nonpreemptible code sections, called critical sections or critical regions, which give rise to this priority inversion in the context of a soft real-time operating system where average response time for different priority classes is the primary performance metric. An analytical model is described which is used to illustrate how critical regions may affect the time-constrained jobs in a multimedia (soft real-time) task set.","Real time systems,
Operating systems,
Delay,
Computer science,
Processor scheduling,
Analytical models,
Multimedia systems,
Programming profession,
Hardware,
Oceans"
A Simulator For Programming The Behavior Of An Autonomous Sensor-based Mobile Robot,,
Quadratic dynamical systems,"The paper promotes the study of computational aspects, primarily the convergence rate, of nonlinear dynamical systems from a combinatorial perspective. The authors identify the class of symmetric quadratic systems. Such systems have been widely used to model phenomena in the natural sciences, and also provide an appropriate framework for the study of genetic algorithms in combinatorial optimisation. They prove several fundamental general properties of these systems, notably that every trajectory converges to a fixed point. They go on to give a detailed analysis of a quadratic system defined in a natural way on probability distributions over the set of matchings in a graph. In particular, they prove that convergence to the limit requires only polynomial time when the graph is a tree. This result demonstrates that such systems, though nonlinear, are amenable to quantitative analysis.",
Security constraint processing during multilevel secure database design,"By means of simple examples, a design technique for multilevel secure databases is proposed. The design activity covers the conceptual modeling and design phase and consists of the development of secure data schemata and secure function schemata. Data schemata represent the semantics and secrecy properties of data while function schemata describe processes and activities within the system. As security constraints defined on data or functions may influence each other, it argued that the design of a secure system must be data- as well as function-driven. Although the example chosen is quite simple, it is possible to express and model complex security relevant data semantics.",
High-pressure steam engines and computer software,"It is argued that we do not want to impede progress by writing unachievable standards or inadvertently increase risk by implementing the wrong standards. We have not scientifically established the benefits and effectiveness of most of our software engineering techniques. Depending on a particular software engineering methodology to assure safety by assuming it will produce error-free or ultra-high reliability software is dangerous. And as the technology progresses, standards that require the use of specific approaches often lag behind. Manufacturers may feel no ethical or legal duty to go beyond what is required in the standard. Moreover, manufacturers or those who will personally benefit financially from particular techniques being included or not included in the standards sometimes play a dominant role in the drafting process. The result may be watered down req1~irements or the recommendation of techniques with more commercial than technical value. The alternative is to construct flexible standards specifying general criteria for acceptability of a methodology instead of a specific methodology and ensuring that those building safety-critical software have the competency and personal responsibility to use the best approaches available at the time and for the particular project characteristics. As Edison argued with respect to electricity, increased government regulation of our technology may not be to anyone's benefit; but it is inevitable unless we, as the technology's developers and users, take the steps necessary to ensure safety in the devices that are constructed and technical competencies in those that construct them.",
On the graph bisection problem,"Some interesting theoretical aspects of graph bisection, a fundamental problem with several applications in the design of very-large-scale-integrated (VLSI) circuits, are presented. Sufficient conditions of optimality are presented, along with a bound on the cost of an optimal bisection. It is then shown that for dense graphs a bisection that approximates an optimal one can be easily found by using a simple greedy method. A class of graphs for which the ratio of an upper and a lower bound on the optimal cost approaches one as the number of vertices in the graph increases is exhibited.",
Analysis of the periodic update write policy for disk cache,"A disk cache is typically used in file systems to reduce average access time for data storage and retrieval. The 'periodic update' write policy, widely used in existing computer systems, is one in which dirty cache blocks are written to a disk on a periodic basis. The average response time for disk read requests when the periodic update write policy is used is determined. Read and write load, cache-hit ratio, and the disk scheduler's ability to reduce service time under load are incorporated in the analysis, leading to design criteria that can be used to decide among competing cache write policies. The main conclusion is that the bulk arrivals generated by the periodic update policy cause a traffic jam effect which results in severely degraded service. Effective use of the disk cache and disk scheduling can alleviate this problem, but only under a narrow range of operating conditions. Based on this conclusion, alternate write packages that retain the periodic update policy's advantages and provide uniformly better service are proposed.","File systems,
Delay,
Memory,
Information retrieval,
Processor scheduling,
Degradation,
Cache storage,
Documentation,
Computer science,
Sprites (computer)"
VICbus: VME inter-crate bus-a versatile cable bus,"VICbus is a multiplexed multimaster cable bus primarily intended for interconnecting backplane bus systems, such as VMEbus, but which may also be used wherever a high-performance, general-purpose cable bus is required. It is implemented using differential line transmission to interconnect up to 31 devices on a total cable length of 100 m. Both compelled (asynchronous) and noncompelled (synchronous) data transmission protocols are specified. An efficient bus arbitration mechanism takes into consideration the long signal propagation times on cables. A simple interrupt mechanism permits the transparent use of interrupts on interconnected VMEbus backplanes. The data transfer protocols, bus arbitration, interrupts, register, and implementation details are discussed.","Protocols,
Backplanes,
Cables,
Redundancy,
Master-slave,
Computer networks,
High performance computing,
Data communication,
Fault tolerant systems,
ISO standards"
A methodology for iconic language design with application to augmentative communication,"The authors describe a design methodology for iconic languages based upon the principle of semantic compaction. The design methodology serves two purposes. First of all, it is a descriptive model of the design process for the iconic language of the Minspeak system. Second, it is also a prescriptive model for the design of other iconic languages for human-machine interface. This investigation raises a number of interesting issues regarding iconic languages and iconic communications.",
A Computationally Efficient Algorithm for Training Recurrent Connectionist Networks,"The primary goal of this paper is to investigate the training of recurrent networks for control and signal processing applications. This paper first a characterizes a class of network architectures that are well suited for the incremental learning of nonlinear multivariable dynamic mappings, and then presents a general, computationally efficient algorithm for training this class of recurrent networks. The learning algorithm is a local modification of the Extended Kalman Filter that views the network as a parametric model of a nonlinear dynamic system. Computational efficiency of the learning scheme is achieved by exploiting local properties of the network architectures. The ability of this algorithm to train recurrent networks successfully is demonstrated by way of two examples.",
Compositing Motion-Compensated Video Within the Network,,
A VISI Smart Sensor For Fast Range Imaging,,"Intelligent sensors,
Layout,
Optical imaging,
Image sensors,
Very large scale integration,
Sensor arrays,
Sensor phenomena and characterization,
Circuit testing,
Optical sensors,
Robustness"
A matrix product algorithm and its comparative performance on hypercubes,A matrix product algorithm is studied in which one matrix operand is transposed prior to the computation. This algorithm is compared with the Fox-Hey-Otto algorithm on hypercube architectures. The Transpose algorithm simplifies communication for nonsquare matrices and for computations where the number of processors is not a perfect square. The results indicate superior performance for the Transpose algorithm.,"Hypercubes,
Broadcasting,
Concurrent computing,
Computer science,
Computer architecture,
Parallel machines,
Libraries,
Context,
Costs,
Algorithm design and analysis"
Improved variations relating the Ziv-Lempel and Welch-type algorithms for sequential data compression,"Several data compression algorithms relating existing important source coding algorithms, including Ziv-Lempel codes, Rissanen's Context, and Welch's LZW method, are presented. First, an intermediate algorithm between the two Ziv-Lempel methods for universal data compression is proposed, which has the same asymptotic optimality as the well-known method based on the incremental parsing. The proposed algorithm is then compared with the context gathering algorithm. Context, in terms of gathering direction and gathering frequency. It is shown that while the proposed algorithm and Context have the same gathering frequency, they have opposite directions of context gathering. Practical variations are also considered. By combining the proposed algorithm with Welch's device, two practical data compression methods are obtained. They, as well as Welch's LZW method, start with a small table of symbol strings and build the table during compression and decompression. In practical methods, higher compression efficiency can be gained by accelerating the growth of the table.",
Unsupervised and supervised classifications by rival penalized competitive learning,"For the classical k-means clustering algorithm, the problem of selecting an appropriate k is a hard problem and affects the performance of k-means strongly. When used for clustering analysis, the conventional competitive learning (CL) algorithms also have a similar crucial problem-the selection of an appropriate number of neural units. The performance of frequency sensitive competitive learning (FSCL)-one version of the improved CL algorithms, also significantly deteriorates when the number of units is inappropriately selected. The paper proposes a new algorithm called rival penalized competitive learning (RPCL), which has the ability of automatically allocating an appropriate number of units for an input data set. The experimental results have shown that RPCL outperforms FSCL significantly when they are used for unsupervised classification, and supervised classification through the radial basis function net.","Clustering algorithms,
Algorithm design and analysis,
Power capacitors,
Subspace constraints,
Frequency,
Computational efficiency,
Robots,
Computer science,
Mathematics,
Least squares methods"
Processor assignment in heterogeneous parallel architectures,It has been already demonstrated that cost-effective multiprocessor designs may be obtained by combining in the same architecture processors of different speeds (heterogeneous architecture) so that the serial and critical portions of the application may benefit from a fast single processor. The paper presents a systematic way to build static heuristic scheduling algorithms for such environments. Several algorithms are proposed and their performances are compared through simulation. One of the proposed algorithms is shown to achieve substantial performance gains as the degree of heterogeneity of the architecture increases.,"Parallel architectures,
Scheduling algorithm,
Processor scheduling,
Educational institutions,
Computer architecture,
Computer science,
Performance gain,
Coupled mode analysis,
Supercomputers,
Heuristic algorithms"
Approximate performance models of polling systems using stochastic Petri nets,"The performance of a polling system is modeled by stochastic Petri nets and its analysis is done by numerically solving the underlying Markov chain. One key problem in using stochastic Petri nets for real applications is that the size of underlying Markov chain tends to be large, and thus to be computationally intractable. In order to carry out the performance analysis of a large complex system in practice, the authors develop approximation methods at the Petri net level for the finite population, asymmetric polling systems and analyze the error due to the approximation. The mean cycle time and the mean response time of the system are approximated by the folding method and by the fixed-point iteration method. The effect of an increasing number of customers on the polling systems is studied using these approximations. The approximation methods are shown to save more than 95% of computation cost without a concomitant loss in accuracy. The methods perform very well at low offered loads.","Stochastic systems,
Petri nets,
Performance analysis,
Approximation methods,
State-space methods,
Computer science,
Stochastic processes,
Error analysis,
Delay,
Centralized control"
Compiler verification in LF,"A methodology for the verification of compiler correctness based on the LF logical framework as realized within the Elf programming language is presented. This technique is used to specify, implement, and verify a compiler from a simple functional programming language to a variant of the Categorical Abstract Machine (CAM).","Program processors,
Computer aided manufacturing,
CADCAM,
Computer science,
Computer languages,
Mechanical factors"
The radiation field in and around Hadron collider detectors,"The origin and composition of the intense radiation field to be expected in parts of the detector systems for the coming generation of multi-TeV proton-proton colliders are described. Energy spectra and flux levels of the different radiation components are given, based on Monte-Carlo computer simulations of the high-energy p-p collisions and of the development of the cascades generated in the detector. Evidence is presented for the experimental justification of these cascade simulations. The effect of detector design on the expected flux levels is demonstrated.","Radiation detectors,
Computer simulation,
Neutrons,
Computational modeling,
Organic materials,
Large Hadron Collider,
Geometry,
Inorganic materials,
Physics computing,
Testing"
Incremental delivery using abstract data types and requirements clustering,"It has been recognized that abstract data types (ADTs) are important in software development. Developers use ADTs to implement systems. Customers are usually not able to understand ADTs due to lack of technical knowledge. Thus, they may not easily envision (or rather, may not be concerned with) how the use of ADTs meet their requirements. This paper uses the concepts of ADTs to accomplish incremental delivery and develops a methodology to deliver data-dominant systems incrementally. An important outcome of this methodology is an algorithm to cluster requirements based on ADTs obtained from the Onion methodology. A case study demonstrating the methodology is presented.",
Software Reuse Economics: Cost-benefit Analysis On A Large-scale Ada Project,"The software industry is painfully realizing that a software reuse effort, if not carefully planned and properly carried out, oftentimes becomes an inhibitor rather than a catalyst to software productivity and quality. Despite numerous ar ticles in the areas of domain analysis, component classification, automated component storage/retrieval tools, reuse metrics, etc., only a handful have managed to address the economics of software reuse. In order to be successful, not only must a reuse program be technically sound, it must also be economically worthwhile. After all, reducing costs and increasing quality were the two main factors that drove software reuse into the software mainstream. This paper presents a number of reuse economics models used to perform an economic assessment of a reuse effort on a large-scale Ada project: the United States Federal Aviation Administration's Advanced Automation System (FAA/AAS). Reuse economics models, cost/benefit tracking methods, and reuse catalystslinhibitors are addressed.",
The geometry of the multivariable phase margin,"A collection of multiplicative perturbations with a given structure can be viewed as a nontrivial n-dimensional manifold. This manifold can be divided into regions of stability and instability where the unperturbed identity matrix is a point on the manifold. The stability margin for a collection of such structured perturbations can be defined as the smallest distance on the manifold from the identity matrix to the region of instability. The class of unitary perturbations which has been shown to define the multivariable phase margin is examined. Specifically, it is seen that the margin is the smallest arc length on the three-sphere S/sup 3/ between the north pole and the region of instability.",
A decentralized deadlock-free concurrency control method for multidatabase transactions,"A global concurrency control mechanism for multidatabase systems that preserves the autonomy of local databases and is free from global deadlocks is presented. The mechanism extends the notion of timestamps to a multidatabase environment to enforce the global serialization order through additional data operations on a data item stored in local systems. The main advantage of the mechanism is that it allows a fully distributed architecture, in which concurrency control decisions can be made on the basis of locally available information. Since no centralized information is maintained by the mechanism, it provides a higher degree of fault tolerance and allows incremental growth.",
HPTR: Hardware partition in time redundancy technique for fault tolerance,"A fault-masking technique for both arithmetic and logical operations in an arithmetic logic unit (ALU) is proposed. The technique, which is basically time redundant, takes advantage of both time and hardware redundancy concepts. The method with which error correction is accomplished resembles that of triplication of hardware. Time redundancy is then used to complete the computation and obtain the final result on the same hardware. For example, a 12-b addition operation can be realized by using each of three 4-b adder modules three times in parallel. During each partial calculation, the error correction is accomplished by taking the majority gate of the results from the three 4-b adder blocks. The operation of an N-bit full-adder is shown as an example to describe the basis of the hardware partition in time redundancy (HPTR) technique.",
Axiomatic test sequence generation for extended finite state machines,"A test suite generation method is proposed for conformance testing of communication protocols to solve the problem of generating test sequences for protocol specification models that have memories. A program verification technique called axiomatic semantics, is used to test protocols specified by extended finite state machines (EFSMs). While an EFSM is verified by the technique, observable events are recorded. By carefully manipulating the execution path in EFSM, the observed events can be used to examine the correctness of the protocol implementations.",
Issues in selective perception,"A historical review of the status of selection in machine vision is followed by some thoughts about the contributions of hardware and software architectures to the field. The ideas of parallel computation and encapsulated visual modules is captured in a suggested architecture. An example system shows that Bayes nets offer a mechanism to support selective perception. Finally, some related research issues are suggested.",
A source-to-source transformation for increasing rule-based system parallelism,"Rule-based systems have been hypothesized to contain only minimal parallelism. However, techniques to extract more parallelism from existing systems are being investigated. Among these methods, it is desirable to find those which balance the work being performed in parallel evenly among the rules, while decreasing the amount of work being performed sequentially in each cycle. The automatic transformation of creating constrained copies of culprit rules accomplishes both of the above goals. Rule-based systems are plagued by occasional rules which slow slow down the entire execution. These culprit rules require much more processing than others, causing other processors to idle while they continue to match. By creating constrained copies of culprit rules and distributing them to their own processors, more parallelism is achieved, as evidenced by increased speed up. This effect is shown to be specific to rule-based systems with certain characteristics. These characteristics are identified as being common within an important class of rule-based systems: expert database systems.",
Data alignment: transformations to reduce communication on distributed memory architectures,"The relative storage, or alignment, of array data in distributed memory critically determines the amount of communication overhead. This paper expresses data alignment in a linear algebraic framework. Aligned data can be viewed as forming a hyperplane in the iteration space. This allows the quantification of data alignment and the determination of the existence of transformations and the determination of the existence of transformations to reduce nonlocal access. This has led to a new alignment transformation which is applicable to a wider class of problems than existing techniques. The global impact of such transformations are discussed as is the effect of alignment on partitioning.",
Image representation and tomographic reconstruction using spherically-symmetric volume elements,"Spherically symmetric volume elements are alternatives to the more conventional voxels for the construction of volume images in the computer. The use of these volume elements instead of the conventional voxels introduces additional parameters which enable the user to control the smoothness properties of the represented image. The authors have investigated the relationship between the values of these parameters and the properties of the image representation. They also report on their experience with iterative reconstruction algorithms that use these volume elements for the image representation. Experiments with ideal data show that the reconstruction using a blob basis function shows better behavior (mean value, standard deviation, maximum overshoot) in comparison with the classical voxels for objects of dimensions greater than the blob diameter. In the case of X-ray data consistent with the blob model the overshoot is practically eliminated for the blob reconstruction and substantially reduced for the voxel case, and the reconstruction noise is reduced as well.",
Scheduling between basic blocks in the CADDY synthesis system,"In 'high level' IC synthesis, basic blocks are caused by the control schemes and the block structure of the specification language (branches, loops). These schemes must be considered by the construction of the controller. A method is presented to handle the basic blocks in a more flexible way which allows one to move operations between basic block boundaries. The goal is to improve the number of control steps of the circuit under fixed hardware resources.","Automatic control,
Hardware,
High level synthesis,
Circuit synthesis,
Timing,
Processor scheduling,
Control system synthesis,
Computer science,
Specification languages,
Costs"
"Performance of a six-legged planetary rover: power, positioning, and autonomous walking","The authors quantify several performance metrics for the Ambler, a six-legged robot configured for autonomous traversal of Mars-like terrain. They present power consumption measures for walking on sandy terrain and for vertical lifts at different velocities. They document the accuracy of a novel dead reckoning approach, and analyze the accuracy. They describe the results of autonomous walking experiments in terms of terrain traversed, walking speed, number of instructions executed and endurance.",
New signal-space orthonormal bases via the metaplectic transform,"The discretization of the metaplectic transform (MT) is considered, and it is shown that it can lead to completely new orthonormal bases (ONBs) for the signal space of square integrable functions. Two new classes of bases, the scale-and-shear bases and the translation-and-shear bases, are derived to demonstrate the discretization process. Besides generalizing the current methods of generating time-frequency-concentrated ONBs, MT bases possess extra degrees of freedom that can be used to match a wider variety of signals.",
Multi-sensor based AUV with distributed vehicle management architecture,"The authors introduce a project to build a multisensor-based autonomous underwater vehicle (AUV) named the Twin-Burger, which is the newest vehicle of the Institute of Industrial Science, the University of Tokyo. The Twin-Burger is being designed as a versatile testbed on which the techniques as represented by software architectures can be implemented and tested. The first in-water experiment is expected in 1992. The distributed vehicle management architecture is proposed as a software architecture for the Twin-Burger. The architecture is being developed to approach the most critical problem in the distributed system, that is, how to manage heterogeneous software modules in a homogeneous structure. Performance of the software developed for this management system will be tested using a multipurpose environment simulator.","Software testing,
Remotely operated vehicles,
Underwater vehicles,
Software architecture,
Computer architecture,
Software development management,
Mobile robots,
Software performance,
Environmental management,
System testing"
A novel approach for subcube allocation in hypercube multiprocessors,"A novel approach for dynamic subcube allocation in hypercube multiprocessors which supports a multiuser environment is proposed. A dynamic binary tree with nodes labeled by a binary reflected gray code is used for processor allocation along with two arrays of free lists. The time complexities for both allocation and deallocation are shown to be linear-orders of magnitude improvement over the existing exponential and even superexponential algorithms. A best-fit strategy, the proposed scheme does not excessively fragment the hypercube, unlike some existing strategies. In addition, static optimality is guaranteed. The performance of the proposed scheme is compared on such parameters as average delay in honouring a request, average allocation time, and average deallocation time against some existing schemes, demonstrating its effectiveness.",
On the randomized complexity of volume and diameter,"The authors give an O(n/sup 7/log/sup 2/n) randomised algorithm to approximate the volume of a convex body, and an O(n/sup 6/log n) algorithm to sample a point from the uniform distribution over a convex body. For convex polytopes the algorithm runs in O(n/sup 7/log/sup 4/n) steps. Several tools are developed that may be interesting on their own. They extend results of Sinclair-Jerrum (1988) and the authors (1990) on the mixing rate of Markov chains from finite to arbitrary Markov chains. They describe an algorithm to integrate a function with respect to the stationary distribution of a general Markov chain. They also analyze the mixing rate of various random walks on convex bodies, in particular the random walk with steps from the uniform distribution over a unit ball. In several previous positive and negative results, the problem of computing the diameter of a convex body behaved similarly as the volume problem. In contrast to this, they show that there is no polynomial randomized algorithm to compute the diameter within a factor of n/sup 1/4/.",
Review and Unification of Reduced Order Force Control Methods,"In this paper, we compare some of the recent methods developed for simultaneous position and force control of a single a-link constrained robot manipulator. Mathematical models of the constrained manipulator are introduced and the advantages and disadvantages of the associated control formulations are discussed. The similarities between each of the proposed formulations are also highlighted. Finally, a transformation is presented which generalizes the methods of decompling force from the position dynamics.",
A complete parametrization of 2D nonseparable orthonormal wavelets,The problem of constructing compactly supported orthonormal multidimensional (k-D) nonseparable wavelets is considered. A complete solution to the problem of parametrizing all possible two-dimensional (2-D) wavelets having arbitrary degree of regularity is given. These results can be seen as a generalization of the Daubechies (1988) wavelets in two dimensions and go beyond those specific examples constructed by other workers in the field. Previous work on the multidimensional version of the problem does not provide a complete parametrization useful for generating all wavelets of interest.,
Type-specific coherence protocols for distributed shared memory,The concept of a structured distributed shared memory in which memory units are objects is introduced. The coherence of object replicas is maintained by type-specific coherence protocols that are based on the semantics of operations on objects. The aim is to reduce message traffic and operation latency in many common situations. The protocols subsume traditional distributed shared memory protocols based on the read/write model.,
A continuous media communication service and its implementation,"Continuous media (CM) traffic often requires more network throughput and more stringent delay bounds than conventional discrete media traffic. At the same time, transmission requirements of CM traffic can usually be estimated more accurately, both in terms of the resources required for transmission and the time at which the next transmission request will occur. A data transport service that uses these considerations to provide a richer and more efficient service to CM traffic than message-based transport services is discussed, and a prototype implementation is described. The service is evaluated via simulation experiments, which indicate that this service can often utilize network resources more efficiently for the transmission of CM traffic than message-based services.",
Route Planning For Mobile Robots Amidst Moving Obstacles,,
An approach to dynamic software cache consistency maintenance based on conditional invalidation,"Introduces a class of software protocols for the maintenance of cache consistency in multiprocessors with shared main memory and private caches. These protocols are designed to be built into the operating system primitives for mutual exclusion. The approach is based on a dynamic decision about invalidation of the shared segment copy residing in the private cache, at the moment of entering into the appropriate critical region. The authors gradually introduce three consistency schemes.","Software maintenance,
Hardware,
Cache memory,
Protocols,
Scalability,
Programming profession,
System software,
Costs"
Delay models for verifying speed-dependent asynchronous circuits,"It is demonstrated that the binary inertial delay model can lead to false positive results when used in the verification of speed-dependent asynchronous circuits. A delay model called the binary chaos delay model solves this problem in many cases. The two timing models are compared by using them in the verification of a FIFO controller circuit. The models can be viewed as two extremes of a more general, parameterized model.",
Linear systems toolbox: system analysis and control design in the matlab environment,"The software package linear system toolbox in Matlab is described. The Linear Systems Toolbox is aimed at providing some commonly used system analysis functions which are either not available or not reliable in other software packages. This tool box contains about 50 functions. It includes, among other functions, the computation of geometric subspaces and the invariant zeros, the inner-outer factorization of a linear system, the determination of the infinite zero structures, Morse's and Saberi's indices and strong stability, and the solutions to the decoupling and squaring down problems. Some examples are included to demonstrate the use of the tool box.",
Network issues for Sequoia 2000,"The goals of the Sequoia 2000 Network are to provide high throughput for the massive observation input data and image output data characterizing global change applications, as well as real-time services for animations and collaboration tools such as video conferencing. The first phase of the network will be based on a T3 (45 Mb/s) backbone and FDDI (fiber distributed data interface) for local distribution. The research issues that are emphasized include protocols that provide deterministic and statistical performance guarantees and take advantage of hierarchical coding of information, and the design of I/O system software that integrates process and device communication software with network protocol software.",
Processor-efficient parallel solution of linear systems. II. The positive characteristic and singular cases,"For pt.I see Proc. 3rd Ann. ACM Symp. Parallel Algms. Architecture, p. 180-91 (1991). The authors show that over any field, the solution set to a system of n linear equations in n unknowns can be computed in parallel with randomization simultaneously in poly-logarithmic time in n and with only as many processors as are utilized to multiply two n * n matrices. A time unit represents an arithmetic operation in the field. For singular systems the parallel timings are asymptotically as fast as those for non-singular systems, due to the avoidance of binary search in the matrix rank problem, except when the field has small positive characteristic; in that case, binary search is avoided at a somewhat higher processor count measure.",
Effects of Backscattering Enhancement on Soil Moisture Sensitivity,,
The scale space aspect graph,"Currently the aspect graph is computed under the assumption of perfect resolution in the viewpoint, the projected image, and the object shape. Visual detail is represented that an observer might never see in practice. By introducing scale into this framework, a mechanism is provided for selecting levels of detail that are large enough to merit explicit representation, effectively allowing control over the size of the aspect graph. To this end the scale space aspect graph is introduced, and an interpretation of the scale dimension in terms of the spatial extent of image features is considered. A brief example is given for polygons in a plane.",
A time-based model for investigating parallel logic-level simulation,"A model for studying the effects of timing models and synchronization strategies for event-driven parallel logic-level simulation is presented. Two timing models, variable-delay and unit-delay, and two synchronization strategies, synchronous and conservative asynchronous, are discussed. The average parallelism of circuits using the two timing models are compared, and the execution times of circuits using various timing models and synchronization strategies are considered. It is shown that the circuit parallelism using unit-delay timing provides an upper bound on that of any timebase used in variable-delay timing and that with either timing model, the execution time of the conservative asynchronous strategy is a lower bound over the synchronous strategy, assuming an unlimited number of processors. However, assuming that all events take the same amount of time, it is shown that with unit-delay timing, the execution time of the synchronous strategy equals that of the asynchronous strategy.",
MHTP-a multimedia high-speed transport protocol,"In considering transport layer protocols for multimedia applications in high-speed networks, several chacteristics of multimedia applications have to be considered. These characteristics include high-speed transmission capability, real-time constraints, and large bandwidth required by applications, and packet loss of some percentage is acceptable in some multimedia applications. A transport layer protocol for high-speed multimedia applications, namely MHTP (multimedia high-speed transport protocol), is proposed to resolve problems in interworking multimedia systems using high-speed networks.",
Learning Factorial Codes by Predictability Minimization,"I propose a novel general principle for unsupervised learning of distributed nonredundant internal representations of input patterns. The principle is based on two opposing forces. For each representational unit there is an adaptive predictor, which tries to predict the unit from the remaining units. In turn, each unit tries to react to the environment such that it minimizes its predictability. This encourages each unit to filter ""abstract concepts"" out of the environmental input such that these concepts are statistically independent of those on which the other units focus. I discuss various simple yet potentially powerful implementations of the principle that aim at finding binary factorial codes (Barlow et al. 1989), i.e., codes where the probability of the occurrence of a particular input is simply the product of the probabilities of the corresponding code symbols. Such codes are potentially relevant for (1) segmentation tasks, (2) speeding up supervised learning, and (3) novelty detection. Methods for finding factorial codes automatically implement Occam's razor for finding codes using a minimal number of units. Unlike previous methods the novel principle has a potential for removing not only linear but also nonlinear output redundancy. Illustrative experiments show that algorithms based on the principle of predictability minimization are practically feasible. The final part of this paper describes an entirely local algorithm that has a potential for learning unique representations of extended input sequences.",
Recent MCNP developments,"MCNP is a general purpose Monte Carlo code for calculating the time-dependent-continuous-energy transport of neutrons, photons, and/or electrons in three-dimensional geometries. The authors focus on a number of recent significant advances and new directions for MCNP, the MCNP benchmark project that also provides insight into the reliability of modern computer codes and data libraries, and a timing study measuring the performance of MCNP on several computing platforms.",
Detecting unsafe error recovery schedules,"A mechanism for modeling timing, precedence, and data-consistency constraints on concurrently executing processes is presented. The model allows durations and intervals between events to be specified. An algorithm is provided to detect schedules which may be unsafe with respect to the constraints. This work, motivated by the design and validation of autonomous error-recovery strategies on the Galileo spacecraft, appears to be applicable to a variety of asynchronous real-time systems.",
Using microbenchmarks to evaluate system performance,"An implicit assumption underlying the use of microbenchmarks is that the time required for the microbenchmark to exercise the code path in question is the same as it when the code path is used by real programs. The vulnerability of this assumption is demonstrated by showing the significant variation that can occur with even simple microbenchmarks. The behavior of cache memory can distort the performance of a microbenchmark. Cache collisions can occur between memory in the same address space, or between memory in different address spaces. Flushing the cache while running a microbenchmark and counting memory accesses, rather than instructions, are two techniques for reducing the variability of results. It is stressed that it is important to understand low-level details about architectural implementation when interpreting microbenchmarks.",
"Comments on ""An architecture for addition and subtraction of long word length numbers in the logarithmic number system"" by D.M. Lewis","D.M. Lewis (ibid., vol.39, no.11, p.1325-36, Nov. 1990) recently described an architecture for performing addition and subtraction in the logarithmic number system using a Taylor series approximation and ROM tables. Here it is shown that a 25% improvement can be achieved in the table used to implement addition. This improvement is significant when Lewis' technique is used to implement variations of the logarithmic number system which do not require the subtraction logarithm.",
Back to the future: towards a theory of timed regular languages,"The authors introduce two-way timed automata-timed automata that can move back and forth while reading a timed word. Two-wayness in its unrestricted form leads, like nondeterminism, to the undecidability of language inclusion. However, if they restrict the number of times an input symbol may be revisited, then two-wayness is both harmless and desirable. The authors show that the resulting class of bounded two-way deterministic timed automata is closed under all boolean operations, has decidable (PSPACE-complete) emptiness and inclusion problems, and subsumes all decidable real-time logics we know. They obtain a strict hierarchy of real-time properties: deterministic timed automata can accept more languages as the bound on the number of times an input symbol may be revisited is increased. This hierarchy is also enforced by the number of alternations between past and future operators in temporal logic. The combination of the results leads to a decision procedure for a real-time logic with past operators.",
Optimizing triangulations by curvature equalization,"An algorithm that attempts to improve a triangulation by shifting the vertices so that curvature within the triangles is nearly equal is presented. Unnecessary triangles are removed. The method is an effective way of guaranteeing that the triangle vertices are points of higher curvature, and that the triangle edges correspond to distinctive edges on the surfaces. Triangulations of surfaces with constant curvature-and hence no distinctive features-will gain nothing from this or any other optimization algorithm. As demonstrated by the results, the techinque of moving triangle vertices can improve some triangulation models. Greatest improvements occur with surfaces characterized by sharp edges, such as the pyramid and ridge models. Less improvement occurs on models that already approximate the surface topology and/or have less distinctive features.",
A probabilistic limit on the virtual size of replicated disk systems,"Recently, there has been considerable interest in parallel disk drive systems, in which full or partial replication of the stored data is used for both fault tolerance and enhanced performance. The performance-enhancement derives both from the ability to do parallel reads, and from the reduction of seek time which results from being able to assign a read to whichever drive will produce the shortest seek. Although earlier work implied that for a k-drive system, mean seek distance for read converges to 0 as k to alpha , a refined analysis is presented which shows that this limit is actually nonzero. It is further shown that the system behaves probabilistically as if k were small, no matter how large the physical value of k is.",
Walsh function current patterns and data synthesis for electrical impedance tomography,"A data collection method which uses Walsh functions as injection current patterns is presented. This method can satisfy two conditions: the optimality of current patterns in every iteration and the single-time data measurement condition. The use of Walsh functions simplifies the design of current sources since only two levels of current (+1 and -1) are required, whereas sinusoidal injection requires a digital-to-analog converter to produce many different values of currents. Compared to diagonal or neighboring type of pulses as injection current patterns, Walsh injection current patterns provide more information about the interior of the subject since Walsh function simulate low and high spatial frequency patterns. Therefore, Walsh function injection uses the simplicity of pulse type injection and yields the better distinguishability or SNR of sinusoidal injection,.",
The timing system for the ASDEX Upgrade experiment control,For the adaptive control system of the ASDEX Upgrade tokamak experiment a new digital timing system was developed. Its structure is centralized and distributed. The timing system defines a systemwide 100-ns absolute timescale by central generation of clock and time zero information. Distributed processes are synchronized by time events and state events generated centrally. The timing system supports preprogrammed operation and adaptive operation in close collaboration with the central control computers. A summary is presented of the ASDEX Upgrade timing system design and implementation and of aspects of the integration into the control system.,
The impact of ASIC devices on the SEU vulnerability of space-borne computers,"Application-specific integrated circuits (ASICs) offer a number of advantages over traditional multicomponent microcircuits, including reductions in both size and power dissipation, and are therefore prime candidates to replace such microcircuits in space borne electronics systems. The results of recent tests of the susceptibilities of various ASIC devices to cosmic ray and trapped proton induced single event upset (SEU) and latchup are reported and are compared to the susceptibilities of the devices that they would replace. This comparison leads to a discussion of the impact of ASIC devices on the SEU susceptibility of spaceborne computers.",
Interpretation of motion trajectories using focus of expansion,"The focus of expansion (FOE) of a group of motion trajectories is defined to be a point in the image plane at which the trajectories intersect when they are extended. The FOE observed over a time sequence defines the locus of the FOE. The authors present an analytical approach for the study of dynamic events as they project on the image plane by analyzing the locus of the FOE. They find that the locus of the FOE can be used to make qualitative assertions regarding the type of motion. Interesting behavior of the locus of the FOE for various types of motion is observed. The cases include a single point and a horizontal, a vertical, and a sloped straight line. It was also possible to determine whether the object has approaching or receding motion or when the object changes its direction of motion. This inference can be used in qualitative computer vision.",
GDNN: a gender-dependent neural network for continuous speech recognition,"Most parametric representations of speech are highly speaker dependent, and probability distributions suitable for a certain speaker may not perform as well for other speakers. It is desirable to incorporate constraints on analysis that rely on the same speaker producing all the frames in an utterance. Experiments for speaker consistency modeling by using a classification network to help generate gender-dependent phonetic probabilities for a statistical recognition system are reported. Results show a good classification rate for the gender classification net. Simple use of such a model to augment an existing larger network that estimates phonetic probabilities does not help speech recognition performance. When the net is properly integrated in a hidden Markov model (HMM) recognizer, it significantly improves word accuracy.",
A new filter for feature extraction of line pattern texture with application to cancer detection,"Proposes a nonlinear filter for extracting local features of linear texture patterns. This filter calculates at each pixel the degree of local concentration of line patterns based upon a new measure called the concentration index. Basic properties of this measure are shown both theoretically and experimentally, and the filter is applied to detection of cancer lesions from stomach X-ray images.",
Read-thrice DNF is hard to learn with membership and equivalence queries,"A general technique is developed to obtain nonlearnability results in the model of exact learning from equivalence and membership queries. The technique is applied to show that, assuming NP not=co-NP, there does not exist a polynomial-time membership and equivalence query algorithm for exactly learning read-thrice DNF formulas-boolean formulas in disjunctive normal form where each variable appears at most three times. This result adds evidence to the conjecture that DNF is hard to learn in the membership and equivalence query model.","Polynomials,
Telephony,
Computer science,
Switches,
Protocols,
Standards development"
Design and implementation of the EnableWare specification-a human-machine interface for physically challenging people,"EnableWare is a specification and implementation of the human-machine interface (HMI) which enables physically disabled people to access computers. The BTRON HMI specification includes the EnableWare specification in standard. This assures that physically impaired people can use BTRON with no or a little software/hardware modification. The authors first analyze the difficulties of physically impaired people to use computers. Second, they propose EnableWare functions which help motor, visually, and auditory impaired users, and the architecture realizing them. Finally, on the basis of their EnableWare implementation experience on BTRONI, they propose several architectural design guidelines for the HMI system which can be operated by the physically disabled.",
Replanning with compliant rotations in the presence of uncertainties,"As an extension to the translational patch-planner developed earlier (Xiao, 1990) the author presents strategies for generating rotational patch-plans to handle orientational errors of a held object. The replanning approach consists of patch-planning based on knowledge of contact and motion strategy planning. Replanning-oriented contact and task models are introduced. The strategies for generating compliant patch rotations and synthesizing rotational and translational patch-plans are presented and discussed. The issues of motion strategy planning and the eventual success of replanning are discussed.",
Communication efficient global load balancing,"Proposes a scalable parallel algorithm, called direct mapping, for balancing workload in a global, synchronous way. Direct mapping is particularly attractive for SIMD architectures, as it makes use of the scan operation. Unlike previously proposed scalable methods for the problem of interest, direct mapping transfers the minimum volume of workload necessary to achieve perfect load balance. This paper describes the algorithm, and studies its performance via simulation in comparison to previously proposed methods.",
AACE-algorithm animation for computer science education,"Describes AACE, a methodology for educational algorithm animation that the author developed while building an integrated hypermedia algorithm animation environment extending a fundamental algorithms textbook. After presenting the general structure of AACE, he discusses questions of the ideal user interface for algorithm animations. He compares his approach to the development of algorithm animation that he calls 'structure-based' with the more conventional 'unified view'-based approach.",
Computing a shortest k-link path in a polygon,"The authors consider the problem of finding a shortest polygonal path from s to t within a simple polygon P, subject to the restriction that the path have at most k links (edges). They give an algorithm to compute a k-link path with length at most (1 + epsilon ) times the length of a shortest k-link path, for any error tolerance epsilon >0. The algorithm runs in time O(n/sup 3/k/sup 3/ log (Hk/ epsilon /sup 1/k/)), where N is the largest integer coordinate among the n vertices of P. They also study the more general problem of approximating shortest k-link paths in polygons with holes. In this case, they give an algorithm that returns a path with at most 2k links and length at most that of a shortest k-link path; the running time is O(kE/sup 2/), where E is the number of edges in the visibility graph. Finally, they study the bicriteria path problem in which the two criteria are link length and 'total turn' (the integral of mod Delta theta mod along a path). They obtain in an exact polynomial-time algorithm for polygons with holes.",
A genetic cascade-correlation learning algorithm,"Gradient descent techniques such as backpropagation have been used effectively to train neural network connection weights; however, in some applications gradient information may not be available. Biologically inspired genetic algorithms provide an alternative. The paper explores an approach in which a traditional genetic algorithm using standard two-point crossover and mutation is applied within the cascade-correlation learning architecture to train neural network connection weights. In the cascade-correlation architecture the hidden unit feature detector mapping is static; therefore, the possibility of the crossover operator shifting genetic material out of its useful context is reduced.",
Multiple motions from instantaneous frequency,"The measurement of multiple velocities using phase-based methods is discussed. In particular, phase gradients (instantaneous frequency) from different bandpass channels (quadrature filter outputs) are used to estimate multiple image velocities in a single neighborhood. The approach is similar to that of M. Shizawa and K. Mase (1990) in which nth-order differential operators are required to compute n simultaneous velocity estimates. However, to use instantaneous frequency, the output of each channel must be differentiated only once.",
The Xpress Transfer Protocol,,
A technique for documenting the framework of an object-oriented system,"The paper presents techniques for documenting the design of frameworks for object-oriented systems and applies the approach to the design of a configurable message passing system. The technique decomposes a framework into six concerns: the class hierarchy, protocols, control flow, synchronization, entity relationships and configurations of the system. An abstract description of each concern is specified using standard notations. Subtyping is used to ensure that the abstract specifications apply to the abstract classes, concrete classes, and instances of the system. The message passing framework documented with these techniques is general, portable, and efficient. It supports parallel message based applications on both tightly coupled shared memory architectures and loosely coupled distributed memory architectures. The message passing system framework has been coded in C++, runs on the Choices operating system, and has been benchmarked on a system of Encore Multimax 320 tightly-coupled multiprocessors. The system is being implemented on a network of SUN SPARCstation 2s.","Message passing,
Control systems,
Memory architecture,
Object oriented modeling,
Protocols,
Computer science,
Marine vehicles,
Operating systems,
Sun,
User interfaces"
Towards a new paradigm of human-robot-computer interaction,"The merging of two lines of research, human-computer interaction and human-robot interaction, can lead to a field of research that might be called human-robot-computer interaction. Human-robot-computer interaction is a research field for understanding how multiple humans, robots and computers interact with each other, and generating effective design methodologies for their interaction. Towards this end, the author launched a project called PRIME (Physically-grounded human-Robot-computer Interaction in Multiagent Environment). Its goal is to develop keen knowledge for understanding and designing human-robot-computer interaction, in which humans can naturally behave and cooperate with each other by using multiple robots and computers. The aim is to systematically integrate autonomous mobile robots into open and distributed computer networks and their interface systems so as to integrate the information world of computers with the physical world of humans and robots. It seems that this approach is conceptually new to people both in computer science and in robotics. The author presents some fundamental problems in human-robot-computer interaction, following a brief summary of related work. Next, some results obtained in PRIME project are described, followed by concluding remarks.",
Architecture of an array processor using a nonlinear skewing scheme,"The problem of constructing an array processor with N processing elements, N memories, and an interconnection network which provides conflict-free access and alignment of various N-vectors including rows, columns, diagonals, contiguous blocks, and distributed blocks of N*N arrays, where N is any even power of two, is discussed. The use of linear skewing schemes offers no solution to this problem. The solution developed makes use of a nonlinear skewing scheme. The solution leads to a simple, efficient array processor architecture. In particular, the memory organization requires O(log N) gates to generate memory addresses for any of the N-vectors simultaneously in O(1) time. The interconnection structure is able to accomplish data alignment for any of the N-vectors with a single pass through a network of O(N log N) gates. As the system uses the minimum number of memories, it allows both processing elements and memories to achieve the highest utilization possible.","Multiprocessor interconnection networks,
Power system interconnection,
Process control,
Control systems,
Terrorism,
Councils,
Concurrent computing,
Computer science,
Computer architecture,
Stress"
Scale efficient organizations,"The authors suggest that scale efficiency in an organization is the result of four constituents: autonomous agents, parallel activity, asynchronous communications, and certain consensus-producing mechanisms. The first three of these constituents are reasonably easy to obtain using existing computer technologies. The authors conjecture that the consensus-producing mechanisms can be very simple. Two that have been identified are social instincts (where agents adopt the approaches of their most successful neighbors) and a destructor mechanism (where a subset of agents is made responsible for destroying work they deem to be inferior). The destructor mechanism has been demonstrated with the traveling salesman problem.",
Combined Longitudinal and Lateral Control of a Platoon of Vehicles,"In this paper, we consider the problem of combined longitudinal and lateral control of a platoon of non-identical vehicles on a curved lane of a highway. Based on nonlinear models of vehicles' combined longitudinal and lateral dynamics, we propose nonlinear control laws for a platoon of vehicles accelerating on a curved lane of highway. The implementation issues regarding the needed sensors, estimators, guidance system, and communication link are discussed. Simulation results show that the proposed control laws perform well, for roads with suitably large radius of curvature, under nominal operation.",
OMOS-an object server for program execution,"The benefits of object-oriented programming are well known, but popular operating systems provide very few object-oriented features to users, and few are implemented using object-oriented techniques themselves. The authors discuss a mechanism for applying object-oriented programming concepts to program binding (linking) and execution. They describe OMOS, an object/meta-object server that embodies a flexible object framework. The OMOS framework projects an object-oriented structure onto programs and shared libraries that may not have been originally developed for use within an object-oriented environment. This framework provides natural facilities for inheritance, interposition, and overloading of operations, as well as development of classes with dynamically evolving behavior.",
Parametrizing and fitting bounded algebraic curves and surfaces,"An approach to fitting of implicit algebraic curves and surfaces to point data is introduced. Two families of polynomials with bounded zero sets are presented. Members of these families have the same number of degrees of freedom as general polynomials of the same degree. Methods for fitting members of these families of polynomials to measured data points are described. Experimental results for sets of points in R/sup 2/ and R/sup 3/ for curves and surfaces, respectively, are presented.",
Relational databases with exclusive disjunctions,"The author presents a mechanism for representing exclusive disjunctive information in database tables using various tuple types and a range for the count of the number of tuples in the unknown relation denoted by a table. The relational algebra operators are extended to take the new tables as operands. Query evaluation in the extended model is sound and complete for relational algebra expressions consisting of projection, difference, Cartesian product, or selection operators. Possible storage structures for storing the base tables and algorithms for inserting tuples into a table are described.",
Beyond micro-kernel design: decoupling modularity and protection in Lipto,"It is argued that a modular operating system architecture should provide support for modularity independent of protection domains. Given such support, modules and interfaces can be designed according to sound software engineering principles, without concern for cross-domain invocation costs. The partitioning of modules into domains and across machines becomes a matter of configuration, rather than design. Current micro-kernel-based architectures do not sufficiently address this issue since their communication mechanisms are designed for the nonlocal, i.e., cross-domain, case. An architecture that provides location-transparent binding and access of modules optimized for the local case, thereby decoupling the orthogonal concepts of modularity and protection, is proposed.","Protection,
Operating systems,
Computer science,
Costs,
Acoustical engineering,
Design engineering,
Design optimization,
Modems,
Contracts,
Sun"
Teaching the FFT using Matlab,"An approach to teaching the fast Fourier transform (FFT) using specially designed exercises to be done on modern workstations is presented. The interactive programming, high-speed calculations, and versatile graphics of the software system, Matlab, have proven particularly effective. Example exercises are given and discussed.",
Computer aided tuning and validation of fuzzy systems,"A set of tools to support the design of fuzzy controllers is illustrated. The tools, based upon dedicated optimization algorithms, allow the tuning and the validation of the fuzzy models. A modified Monte Carlo method has been developed to define stochastic algorithms to complement the deterministic approach, because of the peculiar structure of the systems addressed. The authors show that the design tools are suitable for giving a consistent answer to the tuning needs of fuzzy control systems. During experiments the proposed algorithms have successfully lead to model optimization allowing the fulfilment of design requirements.",
The art of systems architecting,"The design of complex systems is viewed as a blend of the art of architecture with the science of engineering. The principles of systems are discussed, with examples to illustrate each point. The artistic elements of architecture are then considered, and four methods in common use, depending on the nature and phase of the project, the particular problem to be solved, and the style of the architect, are described. The role of architecting throughout the system development cycle is examined. Architecting and concurrent engineering are compared and seem to be complementary strategies.",
Tuning of striping units in disk-array-based file systems,"Striping files across the disks of a disk array is a promising approach to improve the I/O performance of data management systems. An important tuning parameter of this method is the striping unit that is, the maximum number of logically consecutive blocks that are allocated on one disk. The striping unit determines the degree of parallelism in servicing a request by multiple disks, and its affects the achievable throughput of I/O requests. Since a good choice of a file's striping unit depends on the file's access characteristics such as average request size, it is proposed that file-specific striping units be chosen rather than choosing the same global striping unit for all files. The paper presents a method for tuning file-specific striping units, based on the access characteristics of the individual files and the throughput requirements of the application. Performance experiments are presented, based on a synthetic benchmark that was run on the file system prototype FIVE and a simulation testbed for disk-arrays. The experiments indicate significant performance gains of file-specific striping units compared to an optimally chosen global striping unit.",
Event-restricted Monte Carlo simulations for Compton telescope image reconstruction studies,"Event-restricted Monte Carlo simulations are used to simulate Compton telescope data sets. The data sets can be used for evaluation of different reconstruction techniques and to assess the relative performance of different telescope geometries. These simulations restrict computations to photons which interact in the detectors under specific conditions (i.e., produce 'valid events'), thus significantly reducing computational time and effort. The authors describe the computer code and the restrictions that are imposed on the Monte Carlo modeling, and present some examples of reconstructed data sets that were produced.",
Virtual Smoke: an interactive 3D flow visualization technique,"A technique is given for computer visualization of simultaneous three-dimensional vector and scalar fields such as velocity and temperature in reacting fluid flow fields. The technique, which is called Virtual Smoke, simulates the use of colored smoke for experimental gaseous fluid flow visualization. However, it is noninvasive and can animate, in particular, the dynamic behaviors of steady-state or instantaneous flow fields obtained from numerical simulations. Virtual Smoke is based on volume seeds and volume seedlings, which are direct volume visualization methods previously developed for highly interactive scalar volume data exploration. Data from combustion simulations are used to demonstrate the effectiveness of Virtual Smoke.","Fluid flow,
Data visualization,
Fluid dynamics,
Computational modeling,
Rendering (computer graphics),
Cities and towns,
Animation,
Steady-state,
Graphics,
Computer science"
Self-witnessing polynomial-time complexity and prime factorization,"For a number of computational search, problems, the existence of a polynomial-time algorithm for the problem implies that such an algorithm for the problem is constructively known. Some instances of such self-witnessing polynomial-time complexity are presented. The main result demonstrates this property for the problem of computing the prime factorization of a positive integer, based on a lemma which shows that a certificate for primality or compositeness can be constructed for a positive integer p in deterministic polynomial time given a complete factorization of p-1. A consequence is that primality testing is unconditionally in the intersection of UP and coUP.",
Efficient parallel algorithms for selection and searching on sorted matrices,"Parallel algorithms for more general versions of the well known selection and searching problems are formulated. The authors look at these problems when the set of elements can be represented as an n*n matrix with sorted rows and columns. The selection algorithm takes O(lognloglogn log* n) time with O(n/log nlog* n) processors on an EREW PRAM. The searching algorithm takes O(loglogn) time with O(n/loglogn) processors on a CREW PRAM, which is optimal. The authors also show that no algorithm using at most n log/sup c/ n processors, c>or=1, can solve the matrix search problem in time faster than Omega (log log n).",
Data flow testing of parallelized code,"The authors present a novel system for re-engineering and retesting programs for execution in a shared memory multiprocessor environment. The system consists of two main components: a compiler that reengineers a sequential program for execution on shared memory multiprocessors, and a data-flow tester for the parallelized code. Several important enhancements to an existing parallelizing compiler have been made, including an efficient intermediate program representation on which data-flow analysis is performed. The compiler also inserts probes in a parallelized program to make it testable in its new environment. By inserting the probes in appropriate places, a compact execution trace is produced. The data-flow tester uses a new dynamic data-flow analysis algorithm to determine the test case coverage.",
The Enhancement of Gate-Induced-Drain-Leakage (gidl) Current in Soi Mosfet and its Impact on Soi Device Scaling,,
Requirements for optimal execution of loops with tests,"Both the efficient execution of branch intensive code and knowing the bounds on the same are important issues in computing in general and supercomputing in particular. In prior work, it has been suggested that the hardware needed to execute code with branches optimally is exponentially dependent on the total number of dynamic branches executed, this number of branches being proportional at least to the number of iterations of the loop. For classes of code taking at least one cycle per iteration to execute, this is not the case. For loops containing one test (normally in the form of a Boolean recurrence of order one), it is shown that the hardware necessary varies from exponential to polynomial in the length of the dependence cycle L, while execution time varies from one time cycle per iteration to less than L time cycles per iteration; the variation depends on specific code dependences. These results bring the eager evaluation of imperative code closer to fruition.",
A constraint satisfaction approach to the resolution of uncertainty in image interpretation,A technique for image interpretation based on the constraint satisfaction methodology is described. The technique uses an intelligent backtracking algorithm to solve the constraint satisfaction problem and also analyzes failures of the backtracking routine to suggest modifications to help locate a solution. This technique is able to overcome uncertainties in image interpretation by generating partial solutions and inferring values for the missing objects. An outline of this processing is presented and an application of this technique is also given. The technique is compared to another approach in the same domain. Preliminary results on over 1000 test images are included.<>,
On semantic query optimization in deductive databases,"The focus is semantic query optimization in the presence of integrity constraints such as inclusion dependencies and context dependencies (CDs). The authors provide the motivation for the type of integrity constraints considered and for the work at large. They introduce CDs formally and illustrate their power in capturing semantics with an example. An inference mechanism is described for reasoning with these constraints. Sufficient conditions for testing redundancy of atoms in rules and rules in programs are described, and polynomial time algorithms are provided for detecting and eliminating such redundancies. The technique uniformly applies to recursive as well as nonrecursive queries. The approach is illustrated with examples. The discussion and examples are presented in terms of recursive rules only.",
FARM: an efficient feed-through pin assignment algorithm,"The authors propose an efficient feedthrough pin assignment algorithm, FARM, to minimize the maximum channel density, and at the same time to reduce the wire length and via number. A novel vertical channel routing formulation is devised to model the pin assignment problem. A multirow density minimization followed with a single-row pin assignment is proposed to complete the assignment process. Some experimental results and a comparison with previous work are given.",
On Bridging Faults in ECL Circuits,,
Robust statistics in shape fitting,"The concept of robustness in statistics is examined. Starting from the concepts of the breakdown point and equivariance properties of an estimator, the desired equivariance properties for shape fitting are defined, and high breakdown point methods with these properties are found.",
Equivalences on observable processes,"The finest observable and implementable equivalence on concurrent processes is sought as part of a larger program to develop a theory of observable processes where semantics of processes are based on locally and finitely observable process behavior and all process constructs are allowed, provided their operational meaning is defined by realistically implementable transition rules. The structure of transition rules is examined, and several conditions that all realistically implementable rules should satisfy are proposed. It is shown that the ISOS contexts capture exactly the observable behavior of processes. This leads to the result that copy plus refusal equivalence is the finest implementable equivalence.",
Addressing moved modules in a capability-based distributed shared memory,"The MONADS distributed shared memory (DSM) consists of a single, very large, paged virtual memory space distributed across an arbitrary number of discrete nodes connected to a network. Each node acts as a server for the virtual memory pages stored at that node. The key to transparent access to the pages of the modules stored in the DSM is the use of structured addresses containing embedded location information. There is a problem with allowing modules to be moved because the location information, embedded in the addresses used to access the data in them, does not describe the correct storage location. This paper reviews an initial solution to the problem of accessing pages from moved modules. The required sequence of operations represents a significant, and usually unnecessary system overhead, since most page retrievals involve locally stored pages. An alternate solution to the problem is presented. This solution allows most page accesses, both local or remote and from moved or unmoved modules, to occur without unnecessary overheads.",
A Genetic Approach to Finding a Controller to Back Up a Tractor-Trailer Truck,"Problems of control can be recast as requiring the discovery of a computer program (i.e., control strategy) that takes the state variables of a problem as its inputs and produces the values of the control variables as its output This paper describes the recently developed genetic programming paradigm which genetically breeds a population of computer programs to solve problems. Genetic programming begins with a population of hundreds or thousands of random computer programs and improves them from generation to generation using the Darwinian operation of fitness proportionate reproduction and the genetic operation of sexual recombination. The sexual recombination operation combines parts of two parental computer programs to produce new offspring programs, each parent being selected proportional to fitness, This paper shows, step by step, how to apply genetic programming to the four dimensional control problem of backing up a tractor-trailer truck to a loading dock. Genetic programming breeds an approximately correct computer program (i.e., control strategy) that successfully performs the required task.",
An integrated voice and data radio access system,"A method for a digital mobile radio communication system to incorporate data transmission into full-duplex digital voice transmission channels is presented. In this method a voice terminal sends a short packet to a base station prior to sending a voice signal. When the base station receives the short packet or detects a collision between the short packet and data packet, it inhibits data transmission. Finding a pause period of voice signal transmission, the base station broadcasts a message to enable the data transmission. The results of computer simulation with voice data from real telephone conversations show that through the present system the almost maximum performance of the slotted ALOHA system is reached. Applying the proposed method to a 12-channel, 32-kb/s voice coding TDMA system, one can get a data transmission channel with average capacity of 270 kb/s on the voice communication system.",
Sentence processing with realistic feedback,"The author presents a connectionist natural language processing model, SAIL1, which uses a recurrent network topology to process English sentences. SAIL1 will build the sentence meaning representation incrementally, incorporating into the meaning only the information derived from words prior to the current word. The network is trained only on that part of the sentence meaning representing the data presented up to that time. Thus, the recurrent feedback is said to be realistic. SAIL1 has demonstrated its usefulness by successfully generalizing to create meaning representations for novel sentences.",
PPMB: a partial-multiple-bus multiprocessor architecture with improved cost-effectiveness,"The authors address the design and performance analysis of partial-multiple-bus interconnection networks. They are bus architectures that have evolved from the multiple-bus structure by dividing buses into groups and reducing bus connections. Their effect is to reduce cost and alleviate arbitration and drive requirements without degrading performance significantly. One such structure, called processor-oriented partial-multiple-bus (PPMB), is proposed. It serves as an alternative to the conventional structure called memory-oriented partial-multiple-bus (MPMB) and is aimed at higher system performance at less or equal system cost. It has been shown, both analytically and by simulation, that a substantial increase in system bandwidth (up to 20%) is achieved by the PPMB structure over the MPMB structure. With very large systems, the results also imply a significantly improved cost-effectiveness over the conventional multiple-bus architecture.","Costs,
Bandwidth,
Multiprocessor interconnection networks,
Degradation,
Performance analysis,
System performance,
Analytical models,
Computer science,
Load management"
Learning to Segment Images Using Dynamic Feature Binding,"Despite the fact that complex visual scenes contain multiple, overlapping objects, people perform object recognition with ease and accuracy. One operation that facilitates recognition is an early segmentation process in which features of objects are grouped and labeled according to which object they belong. Current computational systems that perform this operation are based on predefined grouping heuristics. We describe a system called MAGIC that learns how to group features based on a set of presegmented examples. In many cases, MAGIC discovers grouping heuristics similar to those previously proposed, but it also has the capability of finding nonintuitive structural regularities in images. Grouping is performed by a relaxation network that attempts to dynamically bind related features. Features transmit a complex-valued signal (amplitude and phase) to one another; binding can thus be represented by phase locking related features. MAGIC's training procedure is a generalization of recurrent backpropagation to complex-valued units.",
A prototype for data-driven visual attention,"Mounting evidence suggests that attentional mechanisms may be required to successfully perform many vision tasks. The paper presents an attentional prototype for early visual processing. The model is composed of a processing hierarchy and an attention beam that traverses the hierarchy, passing through the regions of greatest interest and inhibiting the regions that are not relevant. The type of input to the prototype is not limited to visual stimuli. Aspects of attention such as localizing spatial regions of interest and ordering their importance are addressed; other aspects of attention such as the role of task guidance are encompassed by the model but are not detailed here. Simulations using high-resolution digitized images were conducted, with oriented edge information as the input to the model. The results confirm that this prototype is both robust and fast, and promises to be essential to any real-time vision system.",
A parallel programming tool for scheduling on distributed memory multiprocessors,"PYRROS is a tool for scheduling and parallel code generation for distributed memory message passing architectures. In this paper, the authors discuss several compile-time optimization techniques used in PYRROS. The scheduling part of PYRROS optimizes both data and program mapping so that the parallel time is minimized. The communication and storage optimization part facilitates the generation of efficient parallel codes. The related issues of partitioning and 'owner computes rule' are discussed and the importance of program scheduling is demonstrated.",
Heuristics for the extraction of rules from discrete-time recurrent neural networks,"It is pointed out that discrete recurrent neural networks can learn to classify long strings of a regular language correctly when trained on a small finite set of positive and negative example strings. Rules defining the learned grammar can be extracted from networks by applying clustering heuristics in the output space of recurrent state neurons. Empirical evidence that there exists a correlation between the generalization performance of recurrent neural networks for regular language recognition and the rules that can be extracted from a neural network is presented. A heuristic that makes it possible to extract good rules from trained networks is given, and the method is tested on networks that are trained to recognize a simple regular language.",
Genetic cascade learning for neural networks,"Genetic cascade learning is a new constructive algorithm for connectionist learning which combines genetic algorithms and the architectural feature of the cascade-correlation learning algorithm. Like the cascade-correlation learning architecture, this new algorithm also starts with a minimal network and dynamically builds a suitable cascade structure by training and installing one hidden unit at a time until the problem is successfully learned. This step-wise constructive algorithm exhibits more scalability than existing genetic algorithms and is free of the competing conventions problem which results from the fact that functionally equivalent networks may have different assignments of functionality to individual hidden units. Initial tests of genetic cascade learning are carried out on a difficult supervised learning problem as well as a reinforcement learning control problem.","Neural networks,
Genetic algorithms,
Scalability,
Supervised learning,
Encoding,
Computer science,
Electronic mail,
Testing,
Size control,
Network topology"
Generalized quantifiers and pebble games on finite structures,Generalized quantifiers in the realm of finite structures are studied and combined with an infinitary logic L/sub infinity omega //sup omega / to obtain new logics that can be used to express polynomial-time properties that are not definable in the original logic. It is shown that equivalence of finite structures relative to the new logics can be characterized in terms of certain pebble games that are a variant of the Ehrenfeucht-Fraisse games. This time-theoretic characterization is combined with sophisticated combinatorial tools in order to investigate the scopes and limits of generalized quantifiers in finite model theory.,
A redefined software life cycle model for improved maintenance,"Software maintenance has been considered the postdevelopment phase of the software life cycle model. The authors suggest however, that maintenance should be integrated into all phases rather than being a separate stage. They propose a redefined software life cycle model with respect to software maintenance. The maintenance phase is seen as a miniature development cycle. In maintenance, a need is identified, it is analyzed, the existing system is understood, and the modifications are implemented. The contemporary maintenance approaches such as re-engineering and reverse engineering are also discussed in the context of the proposed life cycle model.","Software maintenance,
Software systems,
Programming,
Life testing,
Informatics,
Computer science,
Reverse engineering,
Context modeling,
Hardware,
Software engineering"
Performance analysis of finite buffered multistage interconnection networks,"The authors present a model which can accurately evaluate the performance of single-buffered and multibuffered MINs (multistage interconnection networks) with 2*2 switching elements (SESs). Earlier models were inaccurate because of the simplicity, or hard to expand for larger SEs or buffer sizes due to their complexity. The proposed model for single-buffered MINs has only three states, including the blocked state, while it is very accurate by realistically modeling the transactions between buffers in adjacent stages and network cycles. The model was expanded for multibuffered MIN, and it was found to be still very accurate. Comparisons with simulation and the YLL model (see H.Y. Yoon et al., 1990) revealed that the proposed models are consistently much more accurate irrespective of the size of the network, buffer, and traffic condition. The proposed model can be easily expanded for any other structures and operation conditions of MINs.<>",
Transactions in distributed shared memory systems,"The authors propose a distributed shared memory model based on a paged segmented two-level address space and an extended set of memory operations. In addition to the traditional read and write operations, the memory model includes operations which support mapping between local and global address spaces and mapping of processes to transactions. An architecture and associated algorithm are outlined for a virtual memory management unit to provide concurrency control for transactions. Although the traditional concept of the transaction is assumed, only the aspects of concurrency control and coherence are addressed.",
"Spherical subspace tracking: analysis, convergence and detection schemes","Some of the properties and applications of spherical subspace updating are described. A proof of convergence for the two-level spherical update is briefly summarized and discussed. Square root (SVD) versions of the spherical update are developed, and multilevel updates are introduced. A minimum description length (MDL) detection scheme is developed based on a four-level spherical update. The four-level MDL detection performance is virtually identical with the performance of full eigenstructure based MDL. However, the four-level spherical update is noniterative and much less complex than full eigen updating, i.e., O(nr) versus O(n/sup 3/), where n is the data dimension and r is the size of the dominant (signal) subspace.","Convergence,
Eigenvalues and eigenfunctions,
Matrix decomposition,
Computer science,
Noise robustness,
Stochastic resonance,
Computational modeling,
Multiple signal classification,
Least squares methods,
White noise"
Colour image segmentation using boundary relaxation,Proposes a colour distance measure based on the new TekHVC colour space and demonstrates its application to the problem of colour image segmentation. Two segmentation algorithms are presented and compared-relaxation at the boundaries of a split and merge and an optimal region grower. The authors conclude that the output of the region grower is the most suitable for the purposes of subsequent region grouping and object recognition.,
Scenario driven requirements analysis method,"Application specific scenarios are used to develop a system's requirements-specification document and then iterate through the software development lifecycle. A seamless object-oriented approach is presented, suitable for the development of large real-time systems. It starts with requirements-analysis and specifications definition. It then iterates through the design, implementation, and test phases. The items of interest in each phase of the lifecycle are the same: scenarios and objects. This is the basis of maintaining tracability and conceptual integrity. The approach is intended to be simple, maintains high quality, and thereby reduces lifecycle cost. The advantage of a scenario-based method is that scenarios make 'communications' easier. A PBX telecommunications example demonstrates the practicality of the method.","Object oriented modeling,
Programming,
Software engineering,
Costs,
Buildings,
Virtual prototyping,
Computer science,
Application software,
Testing,
Documentation"
"A fast, versatile single dual-parameter multichannel analyzer","The design of a single dual-parameter multichannel pulse-height analyzer is reported. The analyzer is especially cut out for pulse-height spectrum measurements from high counting rate sources. The instrumentation-peculiar characteristics are as follows: (1) the true acquisition phase is an autonomous one; (2) the analyzer has a count capacity of 2/sup 32/-1 counts/channel, a minimum dead time of 200 ns, and a maximum conversion gain of 2/sup 20/ channels; (3) the measurement points can be grouped in measurement blocks (MBK); (4) the acquired data are transferred from the instrumentation to the computer under interrupt control-several interrupt possibilities are foreseen for the sake of flexibility; and (5) the system is constructed from commercially available components.",
Secure composition of systems,"Composability properties of component systems are addressed. By means of analysis of external relations among components, security problems associated with composition of the components are investigated. To solve these problems, two security models are presented. By comparing these two models, important properties of secure composition of component systems are identified.",
A Petri Net Framework For Representing Mechanical Assembly Sequences,,
Hash table in massively parallel systems,"The authors look at the performance and new collision resolution strategies for hash tables in massively parallel systems. The results show that using a hash table with linear probing yields O(logN) time performance for handling M accesses by N processors when the load factor of the table is 50%, where N is the size of the hash table. This is better than the performance of using sorted arrays. Two phase hashing gives an average time complexity O(logN) for M simultaneous accesses to a hash table of size N even when the table has 100% load. Simulation results also show that hypercube hashing significantly outperforms linear probing and double hashing.",
Minor loops in magnetization-dependent Preisach models,"It is noted that the moving model and the product model have different variations in the height of minor loops and thus a means of differentiating between the models. Measurements show that, for particulate magnetic recording media, the moving model yields more realistic results and that previous reversible magnetization models are inadequate. Two new models for the reversible magnetization that are compatible with the moving model are analyzed. Both models give a symmetrical reversible susceptibility variation along the M-axis, which is not observed experimentally.",
Minimum-norm updating with the rank-revealing URV decomposition,"In many practical direction-of-arrival (DOA) problems the number of sources and their directions from an antenna array do not remain stationary. Hence a practical DOA algorithm must be able to track changes with a minimal number of snapshots. DOA algorithms, based on a new decomposition, the URV decomposition, that are not expensive to compute or difficult to update are presented. The algorithms are compared with algorithms based on the singular value decomposition (SCD).",
On minimizing hardware overhead for pseudoexhaustive circuit testability,A self-contained method with very low bypass storage cell (BSC) overhead is presented. The method uses a graph model to represent the circuit under test. This unifying model makes the method applicable to both the gate level and the module level. A non-necessarily-partitioning technique reduces the number of BSCs considerably.,
Unidirectional and bidirectional search algorithms,"Four classifications of artificial intelligence search techniques are discussed: unidirectional uniprocessor, bidirectional uniprocessor, unidirectional multiprocessor, and bidirectional multiprocessor search techniques. Wave-shaping PBA* (WS-PBA*) and search-space-clustering PBA*, (SSC-PBA*), two bidirectional AI search techniques, are compared. It is concluded that by maintaining a small number of formed clusters SSC-PBA* will be significantly faster than major wave-shaping bidirectional search algorithms.",
A constructive formalization of the catch and throw mechanism,"The catch/throw mechanism, a programming construct for nonlocal exit, plays an important role when programmers handle exceptional situations. A constructive formalization that captures the mechanism in the proofs-as-programs notion is given. A modified version of LJ equipped with inference rules corresponding to the operations of catch and throw is introduced. Then it is shown that one can actually extract programs that made use of the catch/throw mechanism from proofs under a certain realizability interpretation. Although the catch/throw mechanism provides only a restricted access to the current continuation, the formulation remains constructive.",
A possibilistic interpretation of fuzzy sets by the context model,"The context model provides a formal framework for the representation, interpretation, and analysis of vague and uncertain data. The authors apply the context model to clarify the numerical foundations of fuzzy set theory and some well-known concepts like the extension principle. They introduce the semantic background of the context model, especially the concept of valuated vague characteristics. Some relationships between the context model and possibility theory are discussed. The epistemic and physical interpretation of fuzzy sets is dealt with by the context model.",
A new approach to global optimization using ideas from nonlinear stability theory,Describes a method for determining the global optimum of a function on a compact manifold. The method determines and connects all the local minima and local maxima of a function on a compact manifold. The method is based on properties of stability regions associated with the equilibria of the gradient vector field. Applications of the method include global optimization and nonlinear equation solving.,
"A hybrid neural network, dynamic programming word spotter","A novel keyword-spotting system that combines both neural network and dynamic programming techniques is presented. This system makes use of the strengths of time delay neural networks (TDNNs), which include strong generalization ability, potential for parallel implementations, robustness to noise, and time shift invariant learning. Dynamic programming models are used by this system because they have the useful capability of time warping input speech patterns. This system was trained and tested on the Stonehenge Road Rally database, which is a 20-keyword-vocabulary, speaker-independent, continuous-speech corpus. Currently, this system performs at a figure of merit (FOM) rate of 82.5%. FOM is the detection rate averaged from 0 to 10 false alarms per keyword hour. This measure is explained in detail.",
New results and algorithms for MCM substrate testing,"Substrate testing is critical to cost-effective MCM (multichip module) production. The authors formulate this problem as the verification of a set of trees using k-probes, and present linear-time algorithms for optimal probe generation. The algorithms yield near-optimal probe sets for complete fault coverage. It is shown that the associated probe scheduling problem is metric, and a bounded-error scheduling heuristic is obtained. Furthermore, an insertion-based heuristic is presented which exploits the special structure of 3-pin and the power/ground nets in the MCM substrate. This heuristic significantly improves probing costs over previous methods. Simulations using industry benchmarks show reductions in testing costs of up to 21% over the best previous methods.",
Expanded Delta Networks for Very Large Parallel Computers,"We analyze a generalization of the traditional delta network, dubbed Expanded Delta Network (EDN), which provides multiple paths that can be exploited to reduce contention. In massively parallel SIMD computers, the trend is to put a large number of processors on a chip, but due to I/O constraints only a subset of the processors may have access to the network at any time. This leads to the Restricted Access Expanded Delta Network of which the MasPar MP-1 router network is an example.",
Temporal specialization,"The authors explore a variety of temporal relations with specialized relationships between transaction and valid time. An example is a retroactive temporal event relation, where the event must have occurred before it was stored, i.e., the valid time-stamp is restricted to be less than the transaction time-stamp. The authors discuss many useful restrictions, defining a large number of specialized types of temporal relations, and indicate some of their applications. A detailed taxonomy of specialized temporal relations is presented. This taxonomy may be used during database design to specify the particular time semantics of temporal relations.",
Parsing graphs representing two dimensional figures,"Generalized two dimensional context free grammars an extension of context free grammars to two dimensions, is described. This extension is a generalization of Tomita's two dimensional context free grammars (M. Tomita, 1989), and better fits into the families of graph grammars described by Crimi (1990) Relation Grammars and by Flasinski (1988) edNLC Grammars, Figure Grammars are particularly useful for applications such as handwritten mathematical expressions. A two dimensional extension of the Cocke-Kasami-Younger parser for context-free languages is used to parse figures using these grammars.",
On performance measurements of TCP/IP and its device driver,"A performance measurement of the processing overhead of TCP/IP on personal computers interconnected by Ethernet is given. In this measurement of the processing overhead comes from TCP and the Ethernet device driver. For TCP, a large portion of the overhead comes from the checksum computation. Almost all overhead of the lower layer comes from moving data from the main memory to the Ethernet card. Hence, if the bus speed can be increased and the TCP checksum can be performed by hardware, the processing overhead generated from TCP/IP and lower layers can be greatly reduced. The results presented shed light on designing communication protocols on personal computers.",
Real-time Descartes: a real-time specification language,"Real-time Descartes is a formal language for specifying real-time software, which is an extension of the executable Descartes specification language. Many formal specification techniques have been proposed to conceptualize real-world semantics of the inherently complex nature of real-time systems. Descartes as one of the specification languages based on the functional model has the advantages of easy constructibility and comprehensibility. Real-time Descartes makes effective use of the advantages of the finite state machine (FSM) model, the assertional model, and the process model while overcoming the disadvantages of the functional model. Easy constructibility and comprehensibility of Real-time Descartes will lessen the burden from software developers and reduce the understanding gap among participants.",
Lower bounds on the competitive ratio for mobile user tracking and distributed job scheduling,"The authors prove a lower bound of Omega (log n/log log n) on the competitive ratio of any (deterministic or randomised) distributed algorithm for solving the mobile user problem on certain networks of n processors. The lower bound holds for various networks, including the hypercube, any network with sufficiently large girth, and any highly expanding graph. A similar Omega (log n/log log n) lower bound is proved for the competitive ratio of the maximum job delay of any distributed algorithm for solving a distributed scheduling problem on any of these networks. The proofs combine combinatorial techniques with tools from linear algebra and harmonic analysis and apply, in particular, a generalization of the vertex isoperimetric problem on the hypercube, which may be of independent interest.",
"Problem domain, structural and logical abstractions in reverse engineering","Reverse engineering abstractions are considered. Three kinds of abstractions are identified: problem domain, structural, and logical. Problem domain abstractions correspond to concepts from a program's application area. Structural abstractions are used to eliminate implementation details and redundant information. Logical abstractions are properties that can be logically derived from code. A method for generating functional specifications is described, which incorporates the abstraction techniques. It has been applied to a variety of COBOL programs and been found to generate natural abstract program descriptions. The authors describe work in progress, including the construction of an analysis tool that will be used to help verify the approach and to assess its complexity and computational requirements.",
Two new techniques for compiled multi-delay simulation,"Two techniques for compiled multidelay simulation are presented. One is event-driven and the other is based on the concept of levelized compiled simulation. Experimental results are presented which show a significant performance improvement for compiled event-driven simulation over interpreted event-driven simulation, although this improvement is somewhat less than would normally be expected. An analysis of both the compiled and interpretive simulators that supports the experimental data is presented. The effects of caching and locality of reference are presented for the compiled event-driven simulator. The performance enhancements for the non-event-driven technique are substantial, but this technique has the disadvantage of generating an enormous amount of code for some circuits. Suggestions for future research are also presented.",
The science of making ERORS: what error tolerance implies for capacity in neural networks,"Discusses the development of formal protocols for handling error tolerance which allow a precise determination of the computational gains that may be expected. The error protocols are illustrated in the framework of a densely interconnected neural network architecture (with associative memory the putative application), and rigorous calculations of capacity ar shown. Explicit capacities are also derived for the case of feedforward neural network configurations.",
Information technology and the new organization,"How can one understand the diverse changes that information technology can cause in organizations? The authors argue that many of these changes can be explained in terms of three orders of effects of decreasing costs for any technology: substitution of the new technology for the old, increased demand for the function the technology provides, and the evolution of new technology-intensive structures. This framework is used to organize many familiar examples of information technology effects, and to predict the continued evolution of new organizations. For instance, the argument suggests the increasing importance of 'buying' rather than 'making' and of organizational 'adhocracies' rather than traditional hierarchies. Strategic implications of these changes are noted, and speculative predictions about more radical organizational structures are also included.",
Assembling polyhedra with single translations,"The problem of partitioning an assembly of polyhedral objects into two subassemblies that can be separated arises in assembly planning. The authors describe an algorithm to compute the set of all translations separating two polyhedra with n vertices in O(n/sup 4/) steps and show that this is optimal. Given an assembly of k polyhedra with a total of n vertices, an extension of this algorithm identifies a valid translation and removable subassembly in O(k/sup 2/n/sup 4/) steps if one exists. Based on the second algorithm, a polynomial time method for finding a complete assembly sequence consisting of single translations is derived. An implementation incorporates several changes to achieve better average-case performances. Experimental results obtained for composite objects consisting of isothetic polyhedra are described.",
Route Planning And Navigation System For An Autonomous Land Vehicle,,
A decomposition theorem and bounds for randomized server problems,"The authors prove a lower bound of Omega ( square root logk/loglogk) for the competitive ratio of randomized algorithms for the k-server problem against an oblivious adversary. The bound holds for arbitrary metric spaces (of at least k+1 points) and provides a new lower bound for the metrical task system problem as well. This improves the previous best lower bound of Omega (loglogk) for arbitrary metric spaces, more closely approaching the conjectured lower bound of Omega (logk). They also prove a lower bound of Omega (/sup logk///sub loglogk/) for the server problem on k+1 equally-spaced points on a line, which corresponds to some natural motion-planning problems.",
Meta-Systems: An Approach Combining Parallel Processing and Heterogeneous Distributed Computing Systems,,
Unstructured tree search on SIMD parallel computers: a summary of results,"The authors present methods for load balancing of unstructured tree computations on large-scale SIMD (single-instruction multiple-data) machines and analyze the scalability of these and other schemes. An efficient formulation of tree search on a SIMD machine comprises two major components: (i) a triggering mechanism, which determines when the search space redistribution must occur to balance search space over processors; and (ii) a scheme to redistribute the search space. The authors devised a redistribution mechanism and a triggering mechanism. Either of these can be used in conjunction with triggering and redistribution mechanisms developed by other researchers. The authors analyze the scalability of these mechanisms. The results are verified experimentally. The analysis and experiments show that the novel load balancing methods are highly scalable on SIMD architectures. Their scalability is shown to be no worse than that of the best load balancing schemes on MIMD (multiple-instruction multiple-data) architectures. The authors verified their theoretical results by implementing the 15-puzzle problem on a CM-2 SIMD parallel computer.","Concurrent computing,
Scalability,
Load management,
Computer architecture,
Computer science,
Large-scale systems,
High performance computing,
Artificial intelligence,
Operations research,
Partitioning algorithms"
Strong sequentiality of left-linear overlapping term rewriting systems,"G. Huet and J.J. Levy (INRIA Rep. 359, 1979) showed that for every strongly sequential orthogonal (i.e., left-linear and non-overlapping) term rewriting system, index reduction strategy is normalizing. Their result is extended to overlapping term rewriting systems. It is shown that index reduction is normalizing for the class of strongly sequential left-linear term rewriting systems in which every critical pair can be joined with root balanced reductions. This class includes all weakly orthogonal left-normal systems, for which a leftmost-outermost reduction strategy is normalizing.",
Motion planning for spider robots,"The authors consider a simple instance of the problem of planning motions of legged robots. The robot is modeled as a point where all its legs are attached, and the footholds where the robot can securely place its feet consist of a set of points in the plane. Efficient algorithms to compute stable motions in such situations are presented.",
SUPERB support for irregular scientific computations,"Runtime support for parallelization of scientific programs is needed when some information important for decisions in this process cannot be accurately derived at compile time. This paper describes a project which integrates runtime parallelization with the advanced compile-time parallelization techniques of SUPERB. Besides the description of implementation techniques, language constructs are proposed, providing means for the specification of irregular computations. SUPERB is an interactive SIMD/MIMD parallelizing system for the Suprenum, iPSC/860 and Genesis-P machines. The implementation of the runtime parallelization is based on the Parti procedures developed at ICASE NASA.",
Properties of energy edge detectors,"The author introduces a framework for investigating the properties of energy edge detectors and uses it to derive some results of interest. He shows a necessary condition on the form of constituent linear filters in quadratic detectors, subject to some conditions, and demonstrates some limitations of such detectors. It is shown that no quadratic detector can detect an edge at 0 for both a sinewave and a cosine wave, which has implications for detecting narrowband edges with spatially local filters. It is also shown that the scale-space behavior of energy detectors is not well-behaved, in that it contains bifurcations as scale increases, i.e. new edges can be created as the image is smoothed.",
Quasipolynomial size circuit classes,"Circuit complexity theory has tried to understand which problems can be solved by 'small' circuits of constant depth. Normally 'small' has meant 'polynomial in the input size', but a number of recent results have dealt with circuits of size 2 to the log n/sup 0(1)/ power, or quasipolynomial size. The author summarizes the reasons for thinking about the complexity classes so introduced, surveys these results and gives an overview of these classes. He also shows that the Barrington-Immerman-Straubing uniformity definition for polynomial-size classes can easily be extended to quasipolynomial size as well, with most of the key results remaining true in the uniform setting.",
Performance comparison of distributed deadlock detection algorithms,"A performance evaluation study of two proposed distributed deadlock detection algorithms, the central controller and distributed deadlock detection algorithms, is described. The author examines and reports the magnitude by which these algorithms provide an increase in the throughput, and an increase in the number of blocked, restarted transactions. A performance evaluation model is presented for a distributed database environment. A list of performance parameters and evaluation criteria is included.",
Pi: a parallel architecture interface,"The authors define Pi, a parallel architecture interface that separates model and machine issues, allowing them to be addressed independently. This provides greater flexibility for both the model and machine builder. Pi addresses a set of common parallel model requirements, including low-latency communication, fast task switching, low-cost synchronization, efficient storage management, the ability to exploit locality, and efficiency support for sequential code. Since Pi provides generic parallel operations, it can efficiently support many parallel programming models, including hybrids of existing models. Pi also forms a basis of comparison for architectural components. The authors present an overview of Pi, and a description of several model examples which have been constructed and evaluated on the interface.",
Communication-oriented assignment of task modules in hypercubic multicomputers,"The problem of mapping a task that is composed of interacting modules onto a hypercube multicomputer is formulated and solved by minimizing an objective function called the communication traffic. The objective function allows module assignments to be found with the usual straightforward combinatorial optimization techniques. The problem of finding an assignment that minimizes the communication traffic is proved to be NP-hard, so a standard state-space search algorithm as well as other heuristic algorithms are used to find optimal/suboptimal solutions. The relative performances of various algorithms are evaluated using simulations. The assignments obtained from these algorithms are evaluated using an event-driven simulator to learn how they perform in real-world execution environments.",
Approximate analysis of discrete-time tandem queueing networks with customer loss,"The departure process of an IBP/Geo/1/K queue by an interrupted Bernoulli process (IBP) is approximated. Several different approximation models are considered, and their accuracy is examined through extensive validation tests. These models are used in a simple decomposition algorithm to analyze a tandem configuration of finite capacity queues with customer loss. Validation tests show that the decomposition algorithm has good accuracy.","Queueing analysis,
Switches,
Asynchronous transfer mode,
Testing,
Computer science,
Algorithm design and analysis,
Network servers,
Solid modeling,
Propagation losses,
Moment methods"
Fuzzy logic with unless-rules,"Unless-rules are intended to deal with problems of reasoning with incomplete information and/or resource constraints. An unless-rule is proposed to be of the form 'if X is A then Y is B unless Z is C'. Such rules are employed in situations in which the conditional statement if X is A then Y is B usually holds and the assertion Z is C holds rarely. Thus, using a rule of this type the exception condition can be ignored when the resources needed to establish its presence are tight or there simply is no information available as to whether it holds or does not hold. In this case of incomplete information, since it is the case that if X is A then Y is B usually holds, one may be willing to jump to the conclusion Y is B given that X is A because no information as to whether Z is C holds is available.",
Computational geometry and computer graphics,"The interaction between computer graphics and computational geometry is explored through two scenarios. Spatial subdivisions studied from the viewpoint of computational geometry are shown to have found application in computer graphics. Hidden surface removal problems of computer graphics have led to sweep-line and area subdivision algorithms in computational geometry. Two promising research area with practical applications, precise computation and polyhedral decomposition, are examined.",
An abstract standardisation theorem,"An axiomatic version of the standardization theorem that shows the necessary basic properties between nesting of redexes and residuals is presented. This axiomatic approach provides a better understanding of standardization, and makes it applicable in other settings, such as directed acyclic graphs (dags) or interaction networks. conflicts between redexes are also treated. The axioms include stability in the sense given by G. Berry (Ph.D. thesis, Univ. of Paris, 1979), proving it to be an intrinsic notion of deterministic calculi.",
Parameter tolerances and generalisation abilities of cellular neural networks,"The problem of cellular neural network parameter tolerances is discussed with special regard to the network generalization abilities. The authors point out that from an analysis of the parameter tolerances for individual cells an estimation can be made for the whole cellular neural structure (e.g., through expansion in series of nonlinear functions in the set of given points in the training regions). In the case of cellular neural networks the expected accuracy of such an estimation can be good, because the respective nonlinear transformation is applied only once (for a one layer network) and the mathematical expressions of the expanded series are related for sparse weight matrices only.",
vVHDL: a visual hardware description language,"Complex hardware systems design demands the effective use of organized approaches to design. The VHSIC hardware description language (VHDL) was developed for use in the design process. Traditionally, engineers have developed hardware descriptions based on schematic circuit diagrams, which are a visual notation. When using VHDL, designers are hampered by the cumbersome nature of the language syntax. The authors have developed a visual hardware description language, Visual VHDL (vVHDL), that incorporates the major features of VHDL. This paper presents the syntax of vVHDL and the design system used for developing vVHDL programs.",
Fault tolerant neural networks in optimization problems,"The authors discuss the influence of stuck-at faults in neural networks for solving optimization problems. They use a Hopfield model of a neural network, applying it to the traveling salesman problem of five cities. The asymmetric nature of fault tolerance of the network against stuck-at-zero and stuck-at-one faults is revealed. A method to alleviate this asymmetry and enhance the fault tolerance greatly is proposed.",
Correction of T2 distortion in multi-excitation RARE sequence,"Correction schemes have been implemented to correct for T2 distortions in a multiexcitation RARE (rapid acquisition with relaxation enhancement) sequence where data from multiple echoes and multiple excitations are combined. Computer simulation studies and human imaging studies have been conducted to develop and test the correction procedures. A direct method and an iterative technique have been investigated. The direct technique utilizes Hermitian symmetry of the T2 weighted data and is shown to reduce distortions in T2 weighted images. The iterative scheme begins with an estimation of T2, wherefrom k-space data are computed and compared to the true data to provide error images. The error images are then used to refine iteratively the reconstructed images at a specified echo time. The iterative procedure has been used to improve T1 weighted images acquired through a sequence based on acquisition of two half-plane Fourier samples. These correction techniques should enable a practical implementation of RARE for producing T1 and T2 weighted images comparable to standard spin echo images.",
On four-connecting a triconnected graph,"The author considers the problem of finding a smallest set of edges whose addition four-connects a triconnected graph. This is a fundamental graph-theoretic problem that has applications in designing reliable networks. He presents an O(n alpha (m,n)+m) time sequential algorithm for four-connecting an undirected graph G that is triconnected by adding the smallest number of edges, where n and m are the number of vertices and edges in G, respectively, and alpha (m, n) is the inverse Ackermann function. He presents a new lower bound for the number of edges needed to four-connect a triconnected graph. The form of this lower bound is different from the form of the lower bound known for biconnectivity augmentation and triconnectivity augmentation. The new lower bound applies for arbitrary k, and gives a tighter lower bound than the one known earlier for the number of edges needed to k-connect a (k-1)-connect graph. For k=4, he shows that this lower bound is tight by giving an efficient algorithm for finding a set edges with the required size whose addition four-connects a triconnected graph.",
An efficient protocol for voting in distributed systems,"A voting protocol that can reduce the communication costs in distributed systems significantly is proposed. The technique arranges nodes in small intersecting groups, such that a site, in absence of failures, needs to communicate only with members of its group to collect the quorum. A method for constructing such logical groups is presented. It is shown that the message overhead of any operation in a system of N nodes is O( square root N) when there are no or few failures in the system. The availability and the communication overheads of the proposed protocol are compared with those of existing protocols.","Voting,
Costs,
Access protocols,
Computer science,
Educational institutions,
Availability,
Fault tolerant systems,
Communication system control,
Partitioning algorithms,
Weight control"
Handprinted digit recognition using spatiotemporal connectionist models,"A connectionist model for recognizing unconstrained handprinted digits is described. Instead of treating the input as a static signal, the image is canned over time and converted into a time-varying signal. The temporalized image is processed by a spatiotemporal connectionist network. The resulting system offers shift-invariance along the temporalized axis, a reduction in the number of free parameters, and the ability to process images of arbitrary length. For a set of real-world ZIP code digit images, the system achieved a 99.1% recognition rate on the training set and a 96.0% recognition rate on the test with no rejections. A 99.0% recognition rate on the test set was achieved when 14.6% of the images were rejected.","Spatiotemporal phenomena,
Image recognition,
Character recognition,
Image converters,
Information science,
Postal services,
System testing,
Sorting,
Image databases,
Time varying systems"
Optimizing the time cost of parallel structures by scheduling parallel processes to access the critical section,In a shared-memory parallel processing environment there are a number of inherent hardware and software bottlenecks. One of these bottlenecks is the exclusive accesses that are needed to the shared variables within a critical section. The time cost of synchronization of processes which require access to the critical section can be minimized by using optimal scheduling methods. This paper presents a set of pre-run-time optimal scheduling algorithms for accessing the critical sections by the processes which are spawned at FORK operation and are terminated at the associated JOIN operation.,
On the circuit implementation problem (combinatorial logic circuits),"The authors consider the problem of selecting an implementation of each circuit module from a cell library to satisfy overall delay and area, or delay and power requirements. Two versions of the circuit implementation problem, the basic circuit implementation problem and the general circuit implementation problem, are shown to be NP-hard. A pseudo-polynomial-time algorithm for the basic circuit implementation problem on series-parallel circuits is developed, and heuristics for the basic circuit implementation problem on general circuits are formulated. The run times for the heuristics are tabulated.",
Performance prediction modeling of multicomputers,"An efficient execution model for tree structured computations is presented. A general framework for analyzing the performance of this type of computation for any given topology is discussed. The framework is used to derive models for two widely used parallel programming strategies: processor farms and divide and conquer. The models were validated on a large multicomputer, and it was shown that their accuracy is such that they can be used to predict the performance of applications that use the above strategies. The use of these models to evaluate performance and to restructure the application to improve performance is discussed.",
An exploratory study of ad hoc query languages to databases,"The authors describe an exploratory study performed to compare three different interface styles for ad hoc query to a database. Subjects with wide-ranging computer experience performed queries of varying difficulty using either an artificial, a graphical, or a natural language interface. All three interfaces were commercial products. The study revealed strengths and weaknesses of each interface and showed that interaction with the natural language interface was qualitatively different than interaction with either the graphical or artificial language systems.",
Adaptive control of a dynamic system using genetic-based methods,"The authors present genetic-based learning algorithms for automatically inducing control rules for a typical unstable, multioutput, dynamic system, namely, a simulated pole-cart system. They compare the performance of the genetic method with that of other learning algorithms for the same task. The experiments demonstrate that the results obtained with the genetic-based controller are comparable to those of existing methods. A further enhancement of genetic learning is possible by applying the structured genetic algorithm, which appears to offer improvements over the simple genetic algorithm in terms of robustness and speed of optimization.","Adaptive control,
Genetic algorithms,
Control systems,
Automatic control,
Computer science,
Computational modeling,
Robustness,
Angular velocity,
Acceleration,
Gravity"
The design of low sensitivity digital filters using multi-criterion optimization strategies,Multicriterion optimization methods for determining low-sensitivity digital filters for a given structure are considered. Pareto optimal as well as min/max methods are considered. It is shown that the methods yield low sensitivity designs via the presented computer algorithms. Filter scaling can be directly incorporated in the designs.,"Digital filters,
Design optimization,
Frequency,
Quantization,
Equations,
Optimization methods,
Computer science,
Algorithm design and analysis,
Transfer functions,
Power filters"
New order preserving access methods for very large files derived from linear hashing,"A class of order-preserving dynamic hashing structures is introduced and analyzed. The access method is referred to as the dynamic random-sequential access method (DRSAM) and is derived from linear hashing. A new logical to physical mapping that is based on sequential bucket allocations in hash order is proposed. With respect to previous methods, this allocation technique has the following characteristics: (1) the structure captures the hashed order in consecutive storage areas so that order preserving (OPH) schemes should result in performance improvements for range queries and sequential processing; and (2) it adapts elastic buckets for the control of file growth. Under specific conditions, this approach outperforms the partial expansion method previously proposed by P.-A. Larson (1982).","Knowledge management,
Cost function,
Artificial intelligence,
Computer science,
Military computing,
Analytical models"
Image recovery in computer tomography from partial fan-beam data by convex projections,"For the image recovery process the authors use the convex projections method, also known as the method of projections onto convex sets (POCS). Several incomplete-data geometries, including those associated with limited source travel and beam-blocking internal opacities, are considered. To enable the recovery several prior-knowledge constraints including one associated with the directivity of the image vector are used. The overall recovery algorithm can be practically implemented by exploiting the Toeplitz structure of key operators.",
Fractional covers and communication complexity,"It is possible to view communication complexity as the solution of an integer programming problem. The authors relax this integer programming problem to a linear programming problem, and try to deduce from it information regarding the original communication complexity question. This approach works well for nondeterministic communication complexity. In this case the authors get a special case of Lovasz's fractional cover measure and use it to completely characterize the amortized nondeterministic communication complexity. In the case of deterministic complexity the situation is more complicated. The authors discuss two attempts, and obtain some results using each of them.",
Efficient parallel programming with Linda,"A number of computer scientists have contended that Linda cannot possibly be implemented efficiently on distributed memory machines because there is simply too much overhead. They believe that Linda will not be able to compete with message passing on such machines even for solving computationally intensive problems. The authors address this claim by discussing C-Linda's performance in solving a particular scientific computing problem, the shallow water equations. They have implemented and evaluated the performance of the Linda program on a variety of machines. They present results for shared memory machines (Sequent Symmetry and the Encore Multimax), for distributed memory machines (iPSC/2 and iPSC/860 hypercubes), and for a network of Sparcstations connected by an Ethernet. The same Linda program was executed on all these machines and its performance was evaluated and compared to that of implementations using alternative methods available on all machines. In the authors' experience, the Linda program has generally been easier and more convenient to write than the native versions for each machine.",
Saliencies and symmetries: toward 3D object recognition from large model databases,"The construction of interpretation tables from database models is introduced, and a recognition procedure using scene feature groups is discussed. Techniques for extraction of feature group equivalence classes and computation of feature group saliency are discussed. Two methods to reduce the computational burdens associated with a large model database are proposed and tested on polyhedral objects. The first method reduces the population of protohypotheses in the interpretation tables consulted during recognition by excluding redundant feature groups produced from object symmetries. The second method assigns a population-based numerical measure of saliency to each feature group retrieved from the scene; this measure allows only the most salient feature groups to be used in object recognition.",
"Proton-induced SEU, dose effects, and LEO performance predictions for R3000 microprocessors",The authors present low-energy (,
Origins of the calculus of binary relations,"The genesis of the calculus of binary relations, which was introduced by A. De Morgan (1860) and was subsequently greatly developed by C.S. Peirce (1933) and E. Schroder (1895), is examined. Its further development, from the perspective of modern model theory, in the 1940s and 1950s is described.",
A PET camera simulator with multispectral acquisition capabilities,"The Sherbrooke PET (positron emission tomography) simulator was designed and built to investigate the performance characteristics of a high-resolution PET camera based on avalanche photodiode detectors. The simulator consists of a computer-controlled scanning table with 32 detection channels shared between front-end casettes and FASTBUS boards, and of a PC-based multichannel analyzer (MCA) used as histogramming memory for multiparametric data acquisition. Tomograph data are collected by scanning one of two opposite arrays of detectors and by rotating the object in a predetermined sequence to simulate a complete ring of detectors with various sampling schemes. All acquisition parameters are programmable through digital-to-analog converters or on-board registers. Data can be acquired in several modes: calibration, where direct or coincident energy spectra from all detectors can be registered simultaneously; standard, where only energy-validated coincident events are histogrammed as lines-of-response (LOR) addresses; and multispectral, where the LOR address is encoded with the energy information to provide a multiparameter histogram.",
Advances in ITRON specifications-supporting multiprocessor and distributed systems,"The design policies and overviews of the extended ITRON specifications supporting distributed systems and multiprocessor systems under investigation are described. Wide applicability and high run-time performance are primary goals of these extended specifications, which are realized by inheriting the design policy of the original specification that excessive virtualization of hardware should be avoided. The authors review the design policies of the ITRON specifications, and present how the policies are incorporated in the extended specifications. The extensions expand the application areas of ITRON and make important steps towards the realization of HFDS, which is the final goal of the TRON Project.",
Improving the quadratic objective function in module placement,A simple transformation of the quadratic objective which recaptures the linear nature of the original minimum-wirelength objective is proposed for module placement operations. Computational results for a wide range of standard benchmarks show that this refinement gives very significant savings in both total wirelength and channel width for linear placement: these values are respectively reduced by an average of 7% and 18% over results obtained with the previous standard approach.,
Embedding and reconfiguration of binary trees in faulty hypercubes,"Considers the problem of embedding and reconfiguring binary tree structures in faulty hypercubes. The authors assume that the number of faulty nodes is about n, where n is the number of dimensions of the hypercube; they further assume that the location of faulty nodes are known. The embedding techniques are based on a key concept called free dimension, which can be used to partition a cube into subcubes such that each subcube contains at most one faulty node. Using this approach, two distributed schemes are provided for embedding and reconfiguration of binary trees in faulty hypercubes.",
Formal Specification And Validation In Production Plants,,
Operational aspects of linear lambda calculus,"It is proved that the standard sequent calculus proof system of linear logic is equivalent to a natural deduction style proof system. The natural deduction system is used to investigate the pragmatic problems of type inference and type safety for a linear lambda calculus. Although terms do not have a single most-general type (for either the standard sequent presentation or the natural deduction formulation), there is a set of most-general types that may be computed using unification. The natural deduction system also facilitates the proof that the type of an expression is preserved by any evaluation step. An execution model and implementation is described, using a variant of the three-instruction machine. A novel feature of the implementation is that garbage-collected nonlinear memory is distinguished from linear memory, which does not require garbage collection and for which it is possible to do secure update in place.","Calculus,
Logic programming,
Computer science,
Safety,
Scholarships,
Resource management,
Linear programming,
Neutron spin echo,
Concurrent computing"
SEAL detects cell misordering,"The performance of a 32 bit cyclic redundancy check (CRC) for detecting cell misordering in an asynchronous transfer mode adaptation layer, called simple and efficient adaptation layer (SEAL), is discussed. It is shown that 32 bit CRC used in SEAL provides robust detection of cell misordering. For any frame size up to 4 Gb, the probability of undetected misordering is 2/sup -32/.",
A programmable logic array suitable for use in digital system design laboratories,"A specially designed programmable logic array (PLA) suitable for use in digital system design laboratories for undergraduates is presented. Rewriting the PLA is done just by transferring the new codes; no explicit erasing process is required. The number of product terms allowed implementation on the PLA is unlimited. The computation speed of the PLA is less than 100 ns. The PLA can communicate with a host computer by accepting a variety of commands for writing PLA codes and monitoring input and output values for the PLA. Using software tools developed for the PLA, the student can perform laboratory experiments at various levels. Another software tool permits programming the PLA in a high-level language. The excitation (next-state) and output functions of a controller circuit are naturally described in a simple syntactic construct. Laboratory experiments utilizing the PLA and student responses are also given.",
An expert system model for detection of lymphocyte subsets,"Flow cytometric analysis permits us to use known combinations of mo nolonal antiboies in immunophenotyping the path of lymphoytic leukemia, non-hodgkin lymphomas and mv asociated disass. Our expert system model utilizes the values obtained from Flow Cytometric analysis in order to characterize cell maturation stages and thereby diagnose the disas state using known facts. KEE (Knowledge Engineering Environment) is used to implement this expert system as a diagnostic and research tool.",
Scalable reader-writer locks for parallel systems,"Current algorithms for reader-writer synchronization do not scale for readers: readers cannot acquire locks in parallel. The authors describe two new algorithms that allow parallelism among readers during lock acquisition; this is achieved by distributing the lock state among different processors, and by trading reader throughput for writer throughput. Their experiments show that when reads are a large percentage of lock requests, the throughput of each of their algorithms scales significantly better than current algorithms.",
Superpipelined control and data path synthesis,"The authors describe a superpipelined control and data path synthesis system. The system can handle pipelined modules in the data path, perform functional pipelining in the data path, and schedule the data path using a pipelined controller. Three control styles-serial, parallel, and pipelined-were implemented. The system automatically picks one depending on the data path, the clock frequency, and the functional unit and control path delays. The results showed that using a modifiable clock cycle time and a parameterized control style can significantly improve the throughput of high-performance systems.",
An implementation of flush channels based on a verification methodology,Flush channels generalize more conventional asynchronous message passing protocols. A distributed system that uses flush channels allows a programmer the flexibility of specifying the delivery order of each message in relation to other messages transmitted on the channel. An implementation technique that follows directly from a verification methodology for flush channels is presented. A relatively formal argument in support of the technique is included.,"Circuits,
Delay,
Protocols,
Computer science,
Educational institutions,
Programming profession,
Bandwidth,
Message passing,
Distributed computing,
Out of order"
Provably good algorithms for performance-driven global routing,"The authors propose a provably good performance-driven global routing algorithm for both cell-based and building block design. The approach is based on a new bounded-radius minimum routing free formulation, which simultaneously minimizes both routing cost and the longest interconnection path, so that both are bounded by small constant factors away from optimal. The authors' method generalizes to Steiner global routing in arbitrary weighted graphs, and to the case where varying wirelength bounds are prescribed for different source-sink paths. Extensive simulations confirmed that the approach gave very good performance, and exhibited a smooth tradeoff between the competing requirements of minimum delay and minimum total wirelength.",
Adaptive threshold-based scheduling for real-time and non-real-time traffic,"A study on scheduling mixed real-time and nonreal-time traffic is presented. The work is motivated by the need to provide satisfactory performance tradeoffs in a dynamic load condition where the arrival rates and proportions of the real-time and nonreal-time packets vary with time. The authors first examine two threshold-based schemes, queue length threshold and minimum early threshold, and propose the corresponding adaptive schemes based on results from approximate analysis and simulation. The idea is to improve performance by adjusting tradeoff points adaptively as the arrival rates change. The authors further discuss the idea of integrating the two thresholds. The new algorithm ADP, is evaluated by simulation under various load conditions and compared with other common scheduling disciplines as well as an optimal offline algorithm. It is concluded that, by setting appropriate threshold functions in accordance with the requirements of applications, one can achieve satisfactory bounded loss ratio for real-time packets and acceptably low average delay for nonreal-time packets in a wide range of workload conditions.",
Modeling human visual object recognition,"The topics discussed here are network models of object recognition; a computational theory of recognition; psychophysical support for a view-interpolation model: and an open issue, features of recognition. The authors survey a successful replication of central characteristics of performance in 3-D object recognition by a computational model based on interpolation among a number of stored views of each object. Network models of 3-D object recognition based on interpolation among specific stored views behave in several respects similarly to human observers in a number of recognition tasks. Even closer replication of human performance in recognition should be expected, once the issue of the features used to represent object views is resolved.",
CAESAR: a system for case based software reuse,"The authors show how the compositional software reuse approach can be fruitfully cast in the case-based reasoning (CBR) paradigm. Any CBR system in which the cases are software artifacts must rely on software-specific concepts to provide adequate knowledge representation. However, the fact that these software artifacts can be executed on a computer should yield stronger results than could be expected from generic CBR. The CAESAR system relies on advanced data flow analysis concepts for its representation of knowledge about software modules. Cases and their fragments are retrieved and adapted to solve new problems. The new cases which result are executed on system-generated test sets to evaluate the results of CBR.",
Efficient distance computation using best ellipsoid fit,"The effectiveness of the ellipsoid representation for geometrical reasoning is demonstrated in the context of robotics. Specifically, a robot collision-detection problem that consists of computing a quantity that reflects, as a function of the geometrical data, the amount of clearance between the robot and its environment is discussed. The method consists of two algorithms. The first computes the optimal ellipsoid surrounding a convex polyhedron. The second computes an analytic formula for the free margin about one ellipsoid with respect to another, as a standard eigenvalue problem. An efficient incremental version of the latter algorithm is proposed. This system has been implemented, and preliminary simulation results are provided.",
DESIGNING FOR SOFTWARE TESTABILITY USING AUTOMATED ORACLES,,"Software design,
Automatic testing,
Software testing,
System testing,
Monitoring,
Software reliability,
Software systems,
Boolean functions,
Computer science,
Runtime"
Media Synchronization in Distributed Multimedia File Systems,,
The distributed k-server problem-a competitive distributed translator for k-server algorithms,"The authors consider the k-server problem in a distributed setting. Given a network of n processors, and k identical mobile servers, requests for service appear at the processors and a server must reach the request point. Besides modeling problems in computer networks where k identical mobile resources are shared by the processors of the network, this models a realistic situation where the transfer of information is costly and there is no central control that governs the behavior of servers that move around to satisfy requests for service. The problem is that of devising algorithms that minimize not only the travel of the server but also the communication cost incurred for the transmission of control messages. The main contribution is a general translator to transform any deterministic global-control competitive k-server algorithm into a distributed competitive one. As consequences they get poly(k)-competitive distributed algorithms for the line, trees and the ring.",
Generalized boundary and transition conditions and the question of uniqueness,"To better simulate the material properties of a surface, a method that is attracting attention is to include higher derivatives in the boundary specification of the field. In the case of a thin layer, the result is a generalized boundary or transition condition whose order is specified by the highest (Nth) derivative present. The conditions are logical extensions of the first order ones corresponding to the usual surface impedance or sheet conditions, but when applied to a surface with discontinuities, they do not produce a unique solution to the problem if N > 1. The standard edge conditions alone are no longer sufficient and additional constraints are necessary. It is shown how these can be obtained from a rather general derivation of the conditions, applicable for conditions through at least the third order.",
Textual image compression,"The authors describe a method for lossless compression of images that contain predominantly typed or typeset text-they call these textual images. An increasingly popular application is document archiving, where documents are scanned by a computer and stored electronically for later retrieval. Their project was motivated by such an application: Trinity College in Dublin, Ireland, are archiving their 1872 printed library catalogues onto disk, and in order to preserve the exact form of the original document, pages are being stored as scanned images rather than being converted to text. The test images are taken from this catalogue. These typeset documents have a rather old-fashioned look, and contain a wide variety of symbols from several different typefaces-the five test images used contain text in English, Flemish, Latin and Greek, and include italics and small capitals as well as roman letters. The catalogue also contains Hebrew, Syriac, and Russian text.",
A heterogeneous parallel accelerator for image analysis and radar signal processing,"The highly specialised Neural Accelerator Board (NAB), and the Shiva (a reconfigurable multiprocessor) are two architectures designed to augment general purpose workstations. The NAB uses custom VLSI components to perform weighted 10-bit fixed-point multiply/accumulate operations at a total rate of 20 giga-operations per second. The Shiva uses Intel i860 microprocessors to achieve a good balance of floating point, graphics, and integer performance. The two can be combined into a heterogeneous, reconfigurable multiprocessor, which has applications in image analysis and radar signal processing. This paper outlines the benefits of heterogeneity and reconfigurability. A description is given of the architectures of the NAB and the Shiva, with details of the proposed applications.",
Routing in modular fault tolerant multiprocessor systems,"The authors consider a class of modular multiprocessor architectures in which spares are added to each module to cover for faulty nodes within that module, thus forming a fault tolerant basic block (FTBB). The goal is to preserve the logical adjacency between active nodes by means of a routing algorithm which delivers messages successfully to their destinations. Two phase routing strategies are introduced that route messages first to their destination FTBB, and then to the destination nodes within the destination FTBB. This strategy may be applied to a variety of architectures including binary hypercubes and 3-D tori. In the presence of f faults in these systems. It is shown that the worst case length of the message route is max( sigma +f, (K+1) sigma )+M, where sigma is the shortest path in the absence of faults, and M and K are the numbers of primary nodes and spare nodes in a FTBB, respectively. The average routing overhead is much lower than the worst case overhead.",
On efficient concurrent fault simulation for synchronous sequential circuits,The authors report on an efficient fault simulation method for synchronous sequential circuits. The method is based on concurrent fault simulation and has the simplicity of deductive fault simulation. Several new ideas to reduce computation time and memory requirements are proposed. New fault simulators were developed to simulate transition faults as well as stuck-at faults. The experimental results demonstrate that the proposed method is effective for simulating faults in large synchronous sequential circuits in the workstation environment.,
Software evolution through iterative prototyping,"The process of developing and evolving complex software systems is intrinsically exploratory in nature. Some prototyping activity is therefore inevitable in every stage of that process. Our program development and evolution methodology is predicated upon this observation. In this methodology, a prototype software system is developed as an approximation to an envisioned target system by compromising along one or more of the following dimensions: system performance, system functionality, or user interface. However, the prototype is not the end-product of the pro- cess. Instead, we support iterative evolution of the prototype towards the envisioned system by gradually dealing with the three general areas of compromise. This paper describes the methodology of using this al- ternative lifecycle; to wit, the programming language concepts and related implementation technology that support practice of the suggested methodology. We summarize the lessons we have learned in building and using this technology over the last several years.",
Controlled request DQDB: achieving fairness and maximum throughput in the DQDB network,"The author presents a new technique, called controlled request, to combat the unfairness problem in the distributed queue dual bus (DQDB) protocol that achieves 100% throughput. Transmission of requests in the controlled request DQDB method is controlled by a mechanism that is similar to the one used in DQDB to transmit segments. Fairness is achieved by using the bandwidth balancing technique to prevent an overloaded node form continuously transmitting requests. Simulation studies showed that the controlled request DQDB scheme achieves better performance than the DQDB protocol with bandwidth balancing.",
Some recent results on computing with 'neural nets',"Neural networks, understood here as systems consisting of linearly interconnected dynamical elements (integrators in continuous-time, or delay lines in discrete time) and scalar nonlinearities, provide an appealing model of analog computation. The authors describe some recent results on the approximation properties and the computational capabilities of such dynamical systems.",
Simulation of self-stabilizing algorithms in distributed systems,"The property of self-stabilization in distributed systems was originally introduced by Dijkstra (1974). Depending on the connectivity and propagation delay in the system, each machine gets a partial view of the global state. The set of global states can be split up into two categories, legal and illegal. In a self-stabilizing system, regardless of the initial state of the system, legal or illegal, the system automatically converges to a legal state in a finite number of steps. Also, if an error occurs in the system causing the system to be put into an illegal state, the system again corrects itself and converges to a legal state in a finite amount of time. Many self-stabilizing algorithms have been developed, but the complexity of self-stabilizing algorithms is difficult to determine. This paper provides an experimental analysis of various self-stabilizing algorithms in order to help determine the efficiency of these algorithms and to compare algorithms which solve the same problem.",
An algebraic approach to line-drawing analysis in the presence of uncertainty,"Following the work of K. Sugihara (1984), the authors represent the geometric constraints imposed by the line-drawing of a polyhedron as a set of linear equalities and inequalities. They, however, explicitly take into account the uncertainty in the vertex position. This allows the circumvention of the superstrictness of the constraints without deleting any constraints. For a given error bound, the condition whether a line-drawing is the correct projection of a polyhedron is reduced to linear programing, and the 3D shape recovery is reduced to optimization under linear constraints. The approach has been implemented, and examples are presented.",
A survey of graph grammars: theory and applications,"Graph grammars provide a useful formalism for describing structural manipulations of multidimensional data. The authors review briefly theoretical aspects of graph grammars, particularly of the embedding problem, and then summarize graph-grammar applications. Currently graph grammars are used most successfully in application areas other than pattern recognition. Widespread application of graph grammars to picture processing tasks will require research into problems of large-scale grammars, readability of grammars, and grammatical processing of uncertain data.",
The accuracy and precision of curvature estimation methods,"Deals with the estimation of curvature from digital image data, especially the selection of a curvature estimation procedure based on its accuracy and precision. The authors establish that almost all curvature estimation techniques from literature suffer from a severe directional inaccuracy and/or poor precision (errors depend on the method, orientation and scale ranging from 1% to more than 200%). A practical solution to the curvature estimation problem is presented.",
Network dynamics: an experimental study of the Internet,"A characterization of network dynamics in terms of transit times and losses is examined. The applicability of this characterization is established through experimental evaluation of connections on the Internet, using instrumentation at the kernel level as well as at the application level. The results of this study indicate that this characterization is useful and yield several surprising outcomes, which are presented.",
An Efficient Graph-Theoretic Algorithm for Three-Layer Channel Routing,,
Relating static and dynamic machine code measurements,"In an effort to relate static measurements of machine code instructions and addressing modes to their dynamic counterparts, both types of measurements were made on nine different machines using a large and varied suite of programs. Using classical regression analysis techniques, the relationship between static architecture measurements and dynamic architecture measurements was explored. The statistical analysis showed that many static and dynamic measurements are strongly correlated and that it is possible to use the more easily obtained static measurements to predict dynamic usage of instructions and addressing modes. With few exceptions, the predictions are accurate for most architectural features.",
Canonical restricted mixed-polarity exclusive sums of products,"The concept of canonical restricted mixed polarity (CRMP) exclusive sum of products (ESOP) forms is introduced. It includes the inconsistent canonical Reed-Muller and generalized Reed-Muller forms as special cases. The set of CRMP forms is included in the set of ESOP expressions. An attempt to characterize minimal CRMP forms for completely specified Boolean functions is presented, as well as an attempt to gain insight into the complexity of computation needed to find such a form. Some fundamental properties unique to CRMPs are proved. It is also proved that the upper bound on the number of terms in the CRMP form is smaller than that in the conventional normal forms and is equal to that of the ESOPs. A theorem providing a lower bound on the number of CRMP terms is also given. These results prove the validity of the CRMP concept. An efficient generic heuristic algorithm to find the CRMP form is presented.",
Fully dynamic biconnectivity in graphs,"The author presents an algorithm for maintaining the bi-connected components of a graph during a sequence of edge insertions and deletions. It requires linear storage and preprocessing time. The amortized running time for insertions and for deletions is O(m/sup 2/3/), where m is the number of edges in the graph. Each query of the form 'Are the vertices u and v biconnected?' can be answered in time O(1). This is the first sublinear algorithm for this problem. If the input is a planar embedded graph, the amortized running time for insertions and deletions drops to O( square root nlogn) and the worst case query time is O((logn)/sup 2/), where n is the number of vertices in the graph. The best previously known solution takes time O(n/sup 2/3/) per update or query.",
The algorithmic aspects of the regularity lemma,"The regularity lemma of Szemeredi (1978) is a result that asserts that every graph can be partitioned in a certain regular way. This result has numerous applications, but its known proof is not algorithmic. The authors first demonstrate the computational difficulty of finding a regular partition; they show that deciding if a given partition of an input graph satisfies the properties guaranteed by the lemma is co-NP-complete. However, they also prove that despite this difficulty the lemma can be made constructive; they show how to obtain, for any input graph, a partition with the properties guaranteed by the lemma, efficiently. The desired partition, for an n-vertex graph, can be found in time O(M(n)), where M(n)=O(n/sup 2.376/) is the time needed to multiply two n by n matrices with 0,1-entries over the integers. The algorithm can be parallelized and implemented in NC/sup 1/.",
I/O-efficiency of shortest path algorithms: an analysis,"To establish the behavior of algorithms in a paging environment, the author analyzes the input/output (I/O) efficiency of several representative shortest path algorithms. These algorithms include single-course, multisource, and all pairs ones. The results are also applicable for other path problems such as longest paths, most reliable paths, and bill of materials. The author introduces the notation and a model of a paging environment. The I/O efficiencies of the selected single-source, all pairs, and multisource algorithms are analyzed and discussed.",
Indexing function-based categories for generic recognition,"The authors report the implementation and evaluation of a function-based recognition system that takes an uninterrupted 3-D object shape as its input and reasons to determine if the object belongs to the superordinate category furniture, and if so, into which (sub)category it falls. The system has analyzed over 250 input objects, and the results largely agree with intuitive human interpretation of the objects. The study confirms that a relatively small number of knowledge primitives may be used as the basis for defining a relatively broad range of object categories. The greatest derivation from intuitive human interpretation occurs with objects that humans would not typically label as one of the known categories defined, but which have some novel orientation in which they could serve the function of one of these categories. This is because the system uses a purely function-based definition of the object category.",
Undecidability of the Horn-clause implication problem,"The authors prove that the problem 'given two Horn clauses H/sub 1/=( alpha /sub 1/ V-product alpha /sub 2/ to beta ) and H/sub 2/=( gamma /sub 1/ V-product . . . V-product gamma /sub k/ to delta ), where alpha /sub i/, beta , gamma /sub i/, delta are atomic formulas, decide if H/sub 2/, is a consequence of H/sub 1/' is not recursive. This solves one of the last open decidability problems concerning formulas in pure predicate logic (i.e. without equality symbol). The proof depends on a thorough analysis of derivation trees of one rule of inference with two premisses and one conclusion, and it may have further applications.",
Computer modelling of microwave cooking using the transmission-line model,A combined electromagnetic and thermal diffusion model using transmission line modelling (TLM) is introduced. Empty and loaded microwave oven cavities are modelled in two dimensions and the standing wave patterns are obtained at 2.45 GHz. The power dissipated within the foodstuff is also computed and is used as the source to a thermal model. Temperature distributions within a foodstuff are then generated using these data.,"Electromagnetic heating,
Transmission line theory"
An algorithm for impedance imaging,We describe a simple fast algorithm we have used for impedance imaging.,
The category of constraint systems is Cartesian-closed,"A general definition of constraint systems utilizing Gentzen-style sequents is given. Constraint systems can be regarded as enriching the propositional Scott information systems with minimal first-order structure: the notion of variables, existential quantification, and substitution. Approximate maps that are generic in all but finitely many variables are taken as morphisms. It is shown that the resulting structure forms a category (called ConstSys). Furthermore, the structure of Scott information systems lifts smoothly to the first-order setting. In particular, it is shown that the category is Cartesian-closed, and other usual functors over Scott information systems (lifting, sums, Smyth power-domain) are also definable and recursive domain equations involving these functors can be solved.","Information systems,
Analog computers,
Concurrent computing,
Logic programming,
Electronic mail,
Equations,
Power system modeling,
Computer languages,
Heart,
Machinery"
Overcoming ad hoc development: enabling/disabling factors in software quality maturation,Results obtained from a two year study of thirty software development organizations are given. The purpose of the study was to determine what factors enable software developers to advance beyond ad hoc development processes and what factors inhibit that advancement.,
Proton-sensitive custom SRAM detector,"A custom 4k-bit static RAM (SRAM) chip was tested with protons. The SRAM was developed to determine the single event upset hardness of hardness of CMOS latches using alpha particle measurements and can also function as a proton detector. The authors describe a calibration procedure for the SRAM detector, allowing spectrometers to be designed for measuring proton, helium, and heavier ion environments inside spacecraft computers. The detector was calibrated for protons using the Caltech Tandem Van de Graaff. The SPICE circuit simulation program was used to compute an effective calibration curve and this curve was then used, with the proton data, to compute an effective charge collection depth, allowing calibration.",
Fault-tolerant wait-free shared objects,"The authors classify object failures into two broad categories: responsive and non-responsive. They require that wait-free objects subject to responsive failures continue to respond (in finite time) to operation invocations. The responses may be incorrect. In contrast, wait-free objects subject to non-responsive failures are exempt from responding to operation invocations. Such objects may 'hang' on the invoking process. They divide responsive failures into three models: R-crash,R-omission, and R-arbitrary. They divide non-responsive failures into crash, omission, and arbitrary. An object subject to crash failure behaves correctly until it fails, and once it fails, it never responds to operation invocations. An object subject to omission failures may fail to respond to the invocations of an arbitrary subset of processes, but continue to respond to the invocations of the remaining processes (forever).",
A software environment for studying computational neural systems,"UCLA-SFINX is a neural network simulation environment that enables users to simulate a wide variety of neural network models at various levels of abstraction. A network specification language enables users to construct arbitrary network structures. Small, structurally irregular networks can be modeled by explicitly defining each neuron and can be modeled by explicitly defining each neuron and corresponding connections. Very large networks with regular connectivity patterns can be implicitly specified using array constructs. Graphics support, based on X Windows System, is provided to visualize simulation results. Details of the simulation environment are described, and simulation examples are presented to demonstrate SFINX's capabilities.",
On the optimal asymptotic performance of universal ordering and of discrimination of individual sequences,The authors consider the problem of ordering strings of a fixed length over a discrete alphabet according to decreasing probabilities of having been emitted by an unknown finite-state source. Data compression is applied to derive a universal algorithm that solves this problem with an optimal asymptotic performance. This result is employed in the solution of the following problem: discriminate an individual sequence as emitted by an independently identically distributed random source of equally likely symbols or as a signal corrupted by noise. Tight lower and upper bounds on the asymptotic performance of finite-state discriminators are given.<>,
Adaptive deadlock-free worm-hole routing in hypercubes,"Two new algorithms for worm-hole routing in the hypercube are presented. The first hypercube algorithm is adaptive, but non-minimal in the sense that some derouting is permitted. Then another deadlock-free adaptive worm-hole based routing algorithm for the hypercube interconnection is presented which is minimal. Finally some well-known worm-hole algorithms for the hypercube were evaluated together with the new ones on a hypercube of 2/sup 10/ nodes. One oblivious algorithm, the Dimension-Order, or E-Cube routing algorithm (W. Dally, C. Seitz, 1987) was tried. In addition, three partially adaptive algorithms were considered: the Hanging algorithm (Y. Birk, P. Gibbons, D. Soroker, J. Sanz, 1989 and S. Konstantinidou, 1990), the Zenith algorithm (S. Konstantinidou, 1990), and the Hanging-Order algorithm (G.-M. Chia, S. Chalasani, C.S. Raghavendra, 1991). Finally, a fully adaptive minimal algorithm presented independently by L. Gravano, G. Pifarre, S.A. Felperin and J. Sanz (1991) and J. Duato was tried. This algorithm allows each message to choose adaptively among all the shortest paths from its source to its destination. Only four virtual channels per physical link are needed to achieve this. This technique is referred to as Fully. The results obtained show that the two new algorithms are good candidates as a choice for worm-hole routing in the hypercube network.",
"Lynx/Galactica Net: a distributed, cache coherent multiprocessing system","The Lynx/Galactica Net system forms a clustered, shared memory multiprocessor with scalable performance. The Lynx component is a single-board multiprocessor using advanced, three-dimensional packaging technology to put four high performance RISC processors, memory, and I/O on a single 6m VME board. Galactica Net consists of a high speed mesh network combined with memory update hardware to maintain cache and memory coherence. Multiple Lynx computer nodes are connected together by Galactica Net to form shared memory systems with thousands of processors. A key feature of the Lynx/Galactica Net system is a tight coupling between the operating system and the coherency protocol for efficient, low-overhead coherency. An indication of the expected performance is provided through simulations using hardware-collected parallel address traces.",
Experimental evaluation of a generic abstract interpretation algorithm for Prolog,"The practical value of research involving the abstract interpretation of Prolog programs was examined experimentally. The design and implementation of the generic abstract interpretation algorithm originally proposed by B. Le Charlier (1991), its instantiation in a sophisticated abstract domain containing modes, types, sharing and aliasing, and its evaluation in terms of performance and accuracy are described. The overall implementation (over 5000 lines of Pascal) was systematically analyzed on a variety of programs. The experimental results, given the abstract domain and the programs analyzed, indicate that: the number of iterations of the algorithm is bounded by 7.5*N and is in most cases smaller than 3*N, where N is the size of the analyzed program (e.g. the number of program points); the CPU time in seconds is bounded by N and is in most cases smaller than 0.6*N; the algorithm explores few elements (less than 11% and often none) outside the subset of the fixpoint required to answer the query and hence is close to optimality; and the results are quite accurate and could be used in a Prolog compiler.",
The performance impact of vector processor cashes,"To accurately evaluate the performance impact of a vector cache, the authors simulate three vector processor designs, each of which is derived from expected technology changes applied to the Ardent Titan. The simulator is an accurate timing model incorporating the necessary aspects of the processor, cache, and memory system. It is found that current trends in memory and processor performance lead to increasingly severe memory speed and bandwidth limitations. Either of two designs using large cache memories (2MB, 4MB) on the average double processor performance relative to a design without a cache. Hit ratios for almost all of the programs used in the simulations, drawn from real Ardent workloads, are over 99%. Based on this work, it is recommended that future supercomputers incorporate large caches for both vector and scalar data.",
Software caching on cache-coherent multiprocessors,"The authors explore the utility of software caching on a machine with coherent caches. In particular, they show that by caching at the application level one can avoid the problem of false sharing on cache-coherent machines. They compare the performance of software caching with that of other techniques for alleviating false sharing and show that software caching performs better than the alternatives when the reference behavior of an application changes dynamically. It is concluded that software caching, as well as other techniques developed for noncoherent shared-memory multiprocessors, can be profitably used on machines with hardware coherent caches and that programs based on these techniques are efficient across a variety of shared-memory machines.",
3 D shape and light source location from depth and reflectance,"A methodology for accurate determination of surface normals and light source location from depth and reflectance data is introduced. Estimation of local surface orientation using depth data alone from range finders with standard depth errors can produce significant error, while shape-from-shading using reflectance data alone produces approximate surface orientation results that are highly dependent on the correct initial surface orientation estimates and regularization parameters. Combining these two sources of information gives vastly more accurate surface orientation estimates under general conditions than either one alone, and can also provide better knowledge of local curvature. Novel iterative methods that enforce satisfaction of the image irradiance equation and surface integrability without using regularization are proposed. These iterative methods work when the light source is any finite distance from the object, producing variable incident light orientation over the object.",
Design of piecewise-linear Markov maps generating white chaos: an inverse problem of dynamical systems,"Discusses the design of a discrete dynamical system generating chaos with a white spectrum. This chaos is referred to as white chaos. The results on the design of a piecewise-linear Markov map generating white chaos are summarized. For any number of subintervals of maps, maps always exist if the rank of the incident matrix is equal to 1. However, no piecewise linear Markov map whose incident matrix's rank is equal to 1 can generate white chaos whose higher-order power spectra are also uniform. (2) The following conjecture is obtained. The number of subintervals of maps is not less than two times as many as the rank of the incident matrix. Several concrete examples are included.",
Restrictions of P-fuzzy switching functions,A P-fuzzy switching function is a meaningful class of fuzzy switching functions that is representable by a logic formula consisting of prime implicants. A restriction of a P-fuzzy switching function is a mapping of the restricted domain within a finite subset of,
"Fault-tolerant embeddings of rings, meshes, and tori in hypercubes","The authors study the ability of the hypercube to implement algorithms with ring, mesh, and torus communication patterns when the hypercube contains faults. The primary result is a fault-free embedding of the longest possible ring into an n-cube with at most (n-h(n)) even faulty nodes and (n-h(n)) odd faulty nodes, where h(n) is a function such that h(n)=O( square root n log n). Given the above bounds on the parities of the faults, the result obtained improved upon previous results both in the number of faults that are tolerated and in the length of the ring that is embedded. In addition, the result leads to improved bounds for fault-free embeddings of meshes and tori into faulty hypercubes.",
Communicating with virtual paths and virtual channels (ATM networks),"The authors give several examples of virtual path and virtual channel use for different types of communication, and then compare the two mechanisms. For most types of communication, both virtual path and virtual channel connections are more-or-less equally capable. However, for relatively high bandwidth communication involving more than five to ten participants, virtual path connections can more efficiently support some interconnection patterns. In general, the authors believe that both connection types are desirable and both should be extended to the client by network providers.",
On the second eigenvalue and linear expansion of regular graphs,"The authors investigate the relation between the second eigen-value and the linear expansion of regular graphs. The spectral method is the best currently known technique to prove lower bounds on the expansion. He improves this technique by showing that the expansion coefficient of linear-sized subsets of a k-regular graph G is at least k/2(1- square root max(0,1-/sub lambda 1(G)2//sup 4k-4/))/sup -/ , where lambda /sub 1/(G) is the second largest eigenvalue of the graph. In particular, the linear expansion of Ramanujan graphs, which have the property that the second largest eigenvalue is at most 2 square root k-1, is at least (k/2)/sup -/. This improves upon the best previously known lower bound of 3(k-2)/8. For any integer k such that k-1 is prime, he explicitly constructs an infinite family of k-regular graphs G/sub n/ on n vertices whose linear expansion is k/2 and such that lambda /sub 1/(G/sub n/)",
A supplementary compensator for reliable stabilization with passive redundancy,"A problem of reliable stabilization with passive redundancy is considered. An interconnection-type supplementary compensator is presented which corresponds to a new type of resulting total control system. The reliable stabilizability due to it is equivalent to the strong stabilizability of C/sub 1/, which is indispensable in this new problem. Moreover, if C/sub 1/ is strongly stabilizable, there exists an interconnection-type supplementary compensator which solves the reliable control problem, i.e., it can simultaneously achieve both reliable stability with passive redundancy and the resulting total compensator with an arbitrary transfer function.",
HABSI: an expert system to reconstruct crime scene based on bloodstain interpretations,"The authors present a new way to reconstruct a crime scene by using modern technology. They select bloodstain evidence which is based on Mark theory as the approach. Mark theory relates to the gathering, analyzing, and inferencing of physical evidence. The crime scene is reconstructed using the expert system HABSI, which uses a heuristic approach to bloodstain interpretation. EXSYS was used as an expert system shell to develop the system. The knowledge and the rule base are described. The goal was to represent the concept and implementation of fuzzy set theory to aid in the problem of reconstructing the crime scene. The prototype meets the initial requirements. Iterative refinements of the knowledge base through knowledge acquisition, knowledge representation, knowledge programming, and knowledge testing were conducted until user expectations were met.",
An application of qualitative risk analysis to computer security for the commercial sector,"Computer security is emerging as the business risk of the 1990s for many organizations operating in the commercial sector. Unlike military, government, defense and financial organizations, the mid- to low-risk commercial sector does not have well-developed security procedures. However, owing to the very different security needs of the commercial sector, it is inappropriate to apply the procedures used by high-risk organizations. The characteristic system security concerns of the commercial sector, are identified, some solutions are suggested, and a structured and systematic approach to security assessment in the form of a qualitative approach to security risk analysis is investigated.",
Charles Babbage as an algorithmic thinker,"While the career of the Charles Babbage (1791-1871) shows a remarkable range of interests, strong threads bind together several of the principal ones: algorithmic thinking, with intimate links to algebra and to semiotics. The links connect especially his mathematical researches in functional equations with his work on mathematical tables and on calculating machines, but they are evident also in some of his social and industrial concerns. Evidence is presented to show that Babbage was consciously aware of at least some of these links. Attention to them casts light upon his achievements.",
A computational analysis of Girard's translation and LC,"J.-Y. Girard's (1992) new translation from classical to constructive logic is explained. A compatible continuation-passing-style (CPS) translation is given and converted to a C-rewriting machine evaluator for control-operator programs and a set of reduction/computation rules sufficient to represent the evaluator. It is found necessary to add one reduction rule to M. Felleisen's (Ph.D. thesis, Indiana Univ., 1987) calculus (evaluation under lambda -abstraction). This reduction rule arises from a modified call-by-name CPS-translation. Turning to Girard's new classical logic LC, an intuitionistic term-extraction procedure is provided for it, producing CPS functional programs. Using the syntactic properties of this language, it is possible to give simple proofs for the evidence properties of LC. This work sheds light on the design space of CPS-translations and extends the relation between control-operator languages and classical logic.",
Education for sustainability: a report card on engineering,"The results of a study undertaken to determine how much engineering students learn about the way technology influences human life, society, and nature and to what extent the knowledge is used to adjust engineering methods and approaches to achieve a greater compatibility with these contexts are presented. The results suggest that the next generation of engineers is not in a good position to make a significant contribution to the development of a more sustainable way of life by substantially reducing negative impacts. The implementation of a technology policy and research strategy designed to explore the possibilities of preventive engineering that could lead to healthier social and natural ecologies, a stronger economy, more jobs, and a more sustainable way of life is discussed, and examples of such implementations are presented.",
Techniques for reducing hardware requirement of self checking combinational circuits,"The authors present two methods that can be used to reduce the hardware requirement for a self checking implementation of a given combinational function. They give examples to show that these give very significant reduction over the traditional SFS implementation. They believe that by careful use of such optimizations, the size of self checking implementations can be brought down within acceptable limits for use in practice.",
HALO: an efficient global placement strategy for standard cells,"A standard cell placement procedure that is based on an efficient global placement strategy, called HALO (hierarchical alternating liner ordering), is proposed. This method generates a global 2D placement of circuit modules by hierarchical application of linear ordering in an alternating direction. The HALO global placement procedure is followed by a detailed placement procedure which consists of row assignment, feed-through cell assignment and intrarow cell assignment steps. Experimental results on two benchmark circuits, primary1 and primary2, consisting of 752 and 2907 cells, have shown decreases of the half-perimeter routing lengths by 7% and 24%, respectively, compared with the best available results obtained so far. Total CPU time, including the subsequent detailed placement, was less than half that of previously published work.",
Learning 3D-shape perception with local linear maps,The authors consider the task of learning to extract 3D shape information about complex objects from monocular gray level pixel images. It is shown that this task can be efficiently solved by a network architecture of local linear maps. Very little preprocessing is necessary. No prior identification of salient object features or their image coordinates is required. The approach was demonstrated by training a network to identify the posture of a simulated robot hand with 10 joints from its image. Results are presented that show how the achieved accuracy depended on network size and the number of available training examples. Experiments are also reported on combining several networks. The robustness of the recognition process is discussed.,
Testing for linear errors in nonlinear computer programs,"This paper provides an approach to test nonlinear functions in computer programs, whether this function is used for control flow, such as a predicate inequality or equality constraint, or is given as an input-output relationship. This approach will obtain test data to detect linear errors in the given nonlinear function. An error-space criterion previously given by Zeil will be utilized, and a necessary and sufficient condition for the test data will be specified to guarantee the satisfaction of this criterion. This leads to a simple and efficient method to select test data which satisfies that condition; only (n+2) tests are required, where n is the number of input variables. An analysis will be given to show that this simple approach can be very effective in detecting nonlinear errors as well.",
SPMD execution of programs with dynamic data structures on distributed memory machines,"A combination of language features and compilation techniques that permits SPMD (single-program multiple-data) execution of programs with pointer-based dynamic data structures is presented. The Distributed Dynamic Pascal (DDP) language, which supports the construction and manipulation of local as well as distributed data structures, is described. The compiler techniques developed translate a sequential DDP program for SPMD execution in which all processors are provided with the same program but each processor executes only that part of the program which operates on the elements of the distributed data structures local to the processor. Therefore, the parallelism implicit in a sequential program is exploited. An approach for implementing pointers that is based on the generation of names for the nodes in a dynamic data structure is presented. The name-based strategy makes possible the dynamic distribution of data structures among the processors as well as the traversal of distributed data structures without interprocessor communication.",
A mildly exponential approximation algorithm for the permanent,"An approximation algorithm for the permanent of an n*n 0,1-matrix is presented. The algorithm is shown to have worst-case time complexity exp (0(n/sup 1/2/ log/sup 2/ n)). Asymptotically, this represents a considerable improvement over the best existing algorithm, which has worst-case time complexity of the form e/sup theta (n)/.",
Image data compression using counterpropagation network,"The counterpropagation network functions as a statistically optimal self-adapting look-up table. When using this network for image data compression the Kohonen network generates a series of vector class indices with the input of subimages that come from the orthogonally divided pictorial image. These indices along with the weight vectors of the outstar network which has learned the vectors associated with the classes can be stored for reconstruction of the original image. The learning of intermediate forms of vector classes, the compression process, and the results, such as the compression ratios and the distortion ratios with respect to the target data, the compression unit, and the restored image, are discussed.",
An Integrated Method for Planning Smooth Collision-Free Trajectories for Robot Arms,,
COSY data acquisition system for physical experiments,"A three-level data processing and acquisition system is being developed. Signals from various detector arrangements are digitized and preprocessed by CAMAC, FASTBUS, and VME modules. A multiprocessor system based on VMEbus is used for event building, data recording, and buffered data transfer to the host computer. All crates are connected by parallel VICbus. For this, an intelligent CAMAC rate controller with VICbus is under development. Microcomputer-based VME modules are equipped with CPUs of the 680X0 family, working under the OS-9 real-time operating system. The data acquisition system is mainly based on commercially available modules.",
Memory architecture support for the SIMD construction of a Gaussian pyramid,"A memory system is introduced for the efficient construction of a Gaussian pyramid. The memory system consists of an address calculating circuit, an address routing circuit, a data routing circuit, a memory module selection circuit, and 2/sup n/+1 memory modules. The memory system provides parallel access to 2/sup n/ image points whose patterns are a block, a row, or a column, where the interval of the block or column is one and the interval of the row is one or two. The performance of a generic SIMD (single-instruction multiple-data) processor using the proposed memory system is compared with that of one using an interleaved memory system for the recursive construction of a Gaussian pyramid.",
A Continuous Approach To Robot Motion Planning With Many Degrees Of Freedom,,
Architecture and performance of the DELPHI trigger system,"The authors describe in detail the basic concepts of the design, the composition of the data flow, and the tools developed to monitor the trigger in real time. The results of the trigger performance in terms of efficiencies achieved during the first two and a half years of operation in the LEP (Large Electron Positron Collider) machine are also shown. So far, a total of approximately 10/sup 6/ hadronic Z/sup 0/s have been collected from 21 million recorded events. The DELPHI trigger system provides an efficiency nearly 100% over the covered solid angle for all particles and physical channels. The system has also proved to be stable despite very different beam conditions. This is a consequence of the high redundancy provided by the different detectors for all e/sup +/e/sup -/ final state processes, which also ensures a method for calculating the absolute trigger efficiencies using data only.",
PISCES: a tool for predicting software testability,"Before a program can fail, a software fault must be executed, that execution must alter the data state, and the incorrect data state must propagate to state that results directly in an incorrect output. This paper describes a tool called PISCES (developed by Reliable Software Technologies Corporation) for predicting the probability that faults in a particular program location will accomplish all three of these steps causing program failure. PISCES is a tool that is used during software verification and validation to predict a program's testability.",
Iterative TIN generation from digital evaluation models,"A technique for producing a triangulated irregular network (TIN) from a digital elevation model (DEM) is described. The overall goal is to produce an approximate terrain description that preserves the major topographic features using a greatly reduced set of points selected from the original DEM. The TIN generation process is iterative; at each iteration, areas in the DEM that lie outside of a user-supplied error tolerance in the TIN are identified, and points are chosen from the DEM to more accurately model these areas. Point selection involves the computation of the difference between the actual DEM and an approximate DEM. This approximate DEM is calculated by interpolating elevation points from the TIN.",
Central repository data models for cleanroom systems development,An integrated cleanroom systems engineering environment must have at its foundation an effective central repository. The authors describe the cleanroom systems development process (CSDP) and discuss the necessary development information to be stored in the repository. Detailed data models for box structure requirements and design information are presented. They then discuss the use of the central repository in the cleanroom development process with supporting CASE tools. The paper concludes with future research directions for a improved cleanroom repository.,
Outsourcing assistance with computer system selection: a success factors model,"The outsourcing of IS expertise to supplement in-house resources is a widespread and growing practice This paper describes the empirical investigation of characteristics of clients and external consultants, and of their interactions, which influence consultant engagement success when selecting a computer system. The study model is tested through (1) a pilot case study, (2) cross-case analysis of five firms and (3) a survey of clients and consultants involved in 49 computerization projects. Path analysis suggests (1) clients and consultants have similar influence on the level of client involvement, (2) the relationship between the client and the consultant is the key to success, and (3) while no direct effect of involvement on success is identified, the indirect effect of involvement through relations is large.","Outsourcing,
Information systems,
Predictive models,
Computer science,
Testing,
Hydrogen,
Quality assurance,
Feedback,
Costs"
Inference of letter-phoneme correspondences by delimiting and dynamic time warping techniques,"An algorithm for inferring correspondences between letters and phonemes from a large set of word spellings and their associated phonemic forms is described. The algorithm uses two techniques to infer correspondences: delimiting and dynamic time warping (DTW). The first technique delimits the part of the word spelling and pronunciation that cannot be aligned with the existing set of correspondences. The second technique derives correspondences from the delimited part of that word. The inferred correspondences are evaluated in terms of translation performance tested with unseen words, proper names and novel words. The translation performance is compared with those obtained using the manually driven correspondences as the benchmark. Nonparametric statistical tests are used to establish whether the performances of inferred correspondences are significantly different from the manually derived correspondences.",
Coding for compression in full-text retrieval systems,"Witten, Bell and Nevill (see ibid., p.23, 1991) have described compression models for use in full-text retrieval systems. The authors discuss other coding methods for use with the same models, and give results that show their scheme yielding virtually identical compression, and decoding more than forty times faster. One of the main features of their implementation is the complete absence of arithmetic coding; this, in part, is the reason for the high speed. The implementation is also particularly suited to slow devices such as CD-ROM, in that the answering of a query requires one disk access for each term in the query and one disk access for each answer. All words and numbers are indexed, and there are no stop words. They have built two compressed databases.",
Asymmetric Parallel Boltzmann Machines are Belief Networks,,
Novel noise-filtering ability of heterogeneous five layered neural network trained identity mapping using BP algorithm,"Shows that the heterogeneous five-layered network has much more robustness than the conventionally used three-layered network in spite of the cost for constructing the five-layered network, where each network is realizing identity mapping. It can detect the feature of the input-output relationship at the third layer units in the learning process and unfold the feature to the output layer units, so that adaptive outputs are obtained at the output layer units even if the input patterns corrupted with noise are given. The ability largely depends on the steepness of the sigmoid function used at the hidden layer(s). While this is true for both types of networks, the steepness of the activation function of the hidden layer units nearest to the input layer influences the five-layered network most, and selection of suitable steepness yields the best performance. The reason why the heterogeneous five-layered network has much more robustness than the heterogeneous three-layered network is investigated. How the noise-filtering is done at the hidden layer units with a steep sigmoid function is examined.",
An environment for initial software engineering teaching,"The teaching of software engineering skills is traditionally seen as an activity which follows the acquisition of the ability to 'program'. It is proposed that initial software engineering skills can be taught in conjunction with the development of programming skills, by providing a problem-oriented curriculum based on the use of notations to describe 'things'. This approach is enhanced if a high degree of integration exists between the concepts and principles introduced to the learner during the study of notations and the organisation of the software development system used for the application of those concepts and principles. This paper argues that initial software engineering skills can be introduced at an early stage so that fundamental and general principles can be applied as soon as possible. Secondly, it argues that a practical environment can be organised which builds directly on, and which exemplifies, the same principles. The approach described provides the learner with a model of systematic software development that is transferable, in whole or part, to conventional less regular, unfamiliar or novel environments.",
A periodic deadlock detection and resolution algorithm with a new graph model for sequential transaction processing,"The authors address the deadlock problem in sequential transaction processing where the strict two-phase locking and the multiple granularity locking protocol with five lock modes are used. The scheduling policy honors lock requests in a first-in-first-out basis except for lock conversions. As a basic tool, a direct graph model called the holder/wire-transaction waited-by graph (H/W-TWBG) is introduced to capture the precise status of systems in terms of deadlock. The properties of H/W-TWBG are presented. Based on H/W-TWBG, the identification principles of the victim candidates are established in a deadlock cycle, and a periodic deadlock detection and resolution algorithm which has a reasonable time and storage complexity is preserved. One important feature of the deadlock resolution scheme is that some deadlocks can be resolved without aborting any transaction.",
Amplification and percolation (probabilistic Boolean functions),"The authors extend R.B. Boppana's results (1989) in two ways. They first show that his two lower bounds hold for general read-once formulae, not necessarily monotone, that may even include exclusive-or gates. They are then able to join his two lower bounds together and show that any read-once, not necessarily monotone, formula that amplifies (p-/sup 1///sub n/,p+/sup 1///sub n/) to (2/sup -n/,1-2/sup -n/) has size of at least Omega (n/sup alpha +2/). This result does not follow from Boppana's arguments and it shows that the amount of amplification achieved by L.G. Valiant (1984) is the maximal achievable using read-once formulae.",
"Proxies, application interfaces, and distributed systems","Proxy objects are local representatives of remote objects in a distributed system. The authors use proxies to construct a transparent application programming interface (API) for the Choices distributed operating system. In earlier work, proxies were used in Choices to provide a protected, object-oriented interface to system objects. The addition of Remote Proxies allows applications to access all resources in a uniform way by simply invoking methods on objects, irrespective of whether they are local, in the kernel, in a different user virtual address space or remote. They also extend proxies to optimize access to remote and protected objects and to provide support for changing server interfaces. They describe a new remote procedure call (RPC) facility for invoking methods on remote objects through the proxy mechanism. The API is made dynamically reconfigurable by using table lookup to perform all functions normally provided by stubs in conventional RPC implementations. The API permits new versions of a service to be introduced without requiring recompilation of application client code.",
An implementation of the VIVA visual language on the NeXT computer,This paper describes a visual programming environment for image processing implemented on the NeXT computer. It is based upon the visual language VIVA (Visualization of Vision Algorithms). Iconic representations of image processing operations are placed and connected together into dataflow networks in a workbench window. The workbench includes a set of editing tools which facilitate algorithm development. Operator parameters can be interactively adjusted as algorithms are repeatedly executed to produce an optimized output. The optimized algorithm can then be saved and reused in subsequent programs.,
Computer-supported collaborative work: a new agenda for human factors engineering,"Discusses the concept of collaborative work and the ways in which the emerging computer technologies may or may not support these group efforts. The domain of computer-supported collaborative work sets a new agenda for human factors engineering, and, in keeping with a human factors perspective, a group-centered approach to collaborative system design is proposed and discussed.","Collaborative work,
Human factors,
Induction generators,
Design engineering,
Space technology,
Productivity,
Laboratories,
Design automation,
Databases,
Electronic mail"
Logical time in visualizations produced by parallel programs,"Techniques that manipulate logical time in order to produce coherent animations of parallel program behavior despite the presence of asynchrony are presented. The techniques interpret program behavior in light of user-defined abstractions and generate animations based on a logical, rather than a physical, view of time. If this interpretation succeeds, the resulting animation is easily understood. If it fails, the programmer can be assured that the failure was not an artifact of the visualization. It is shown that these techniques can be generally applied to enhance visualizations of a variety of types of data as they are produced by parallel, MIMD (multiple instruction stream, multiple data stream) computations.",
Monocular 3-D visual tracking of a moving target by an eye-in-hand robotic system,"The framework of controlled active vision is applied to the problem of monocular full 3-D robotic visual tracking (three translations and three rotations). Full 3-D tracking of a moving target by a monocular hand-eye system is demonstrated. A single camera is used. A simple adaptive scheme is proposed, and the relative distance of the target from the camera is assumed to be partially unknown. The number of parameters that must be estimated online is minimal, resulting in a feasible real-time implementation of the scheme. The strong coupling of the rotational and translational degrees of freedom is treated in a way that guarantees robust tracking of the object. The limitations of the approach are discussed, and the results from its application to the TROIKABOT system (a set of three PUMA 560's manipulators) are presented.",
A scalable multicast service for mesh networks,"The authors investigate the scalability of a multicast algorithm designed for wormhole-routed mesh networks. The algorithm, known as the U-mesh algorithm, is shown to scale well in four ways: with the dimension of the mesh, with the number of destinations, with the system size, and with the problem size. It is demonstrated that the only factor that affects the multicast latency is the number of destinations and that, for a given number of destinations, the number of time steps required to perform a multicast operation is minimal. Performance measurements of implementations on a 64-node nCUBE-2 and a 168-node Symult 2010 are given.",
Memory requirements of first-order digital filters,"The authors pose the question of the memory requirements of digital filters as determined by filter parameters and desired accuracy, and present a full analysis for first-order filters. The main feature of this investigation is that lower bounds are obtained with no structural assumption on the finite-state machine selected to approximate the ideal filter. Two specific realizations are discussed, a classical state-roundoff implementation and a higher order FIR-approximation. Upper and lower bounds on memory requirements are shown to be in remarkable agreement.",
Corporate perspectives on technology transfer: the expert-systems apprenticeship program,"The authors describe their experiences in designing, marketing, implementing, and evaluating a six-month, $1.1 million technology-transfer program called the expert-systems apprenticeship program (ESAP). ESAP had a formal classroom component to instruct eight employees in expert-system concepts, followed by an apprenticeship phase, during which the staff designed and implemented prototype systems under the guidance of experienced knowledge engineers. These prototypes were company-sponsored projects that solved real business problems. The prototypes not only demonstrated the applicability of the technology to the company's business, but also seeded the corporation with working systems to promote continued development of expert systems.",
ODSS and the twilight of the decision support movement: social segmentation and the legacy of infrastructure,"The ODSS concept is new, and pulls into focus and into confusion aspects of the underlying decision support concept. The authors trace this concept's roots to the generalized management-as-decisionmaking (MAD) ideology that grew up following WW II and subsequently came to dominate many aspects of management thought. They liken the MAD movement to the medieval morality play, in both structure and evolution. The twilight of the MAD movement result from the same causes that eclipsed the morality play in the early days of the Renaissance. A review of ODSS literature from recent sources shows that the breakdown of the rhetoric of decision support corresponds to the general weakening of the MAD movement, and presages a rhetorical reconstruction of the aims and objectives of those who seek to apply information technologies to the social interactions among individuals and groups in organizations. They review the legacy of infrastructure left by the MAD and Decision Support movements, and make a general call for innovation and tolerance in the ongoing rhetorical reconstruction.",
Logical database design with inclusion dependencies,"Classical data dependencies are oblivious to important constraints which may exist between sets of attributes occurring in different relation schemes. The authors study how inclusion dependencies can be used to model these constraints, leading to the design of better database schemes. A normal form called the inclusion normal form (IN-NF) is proposed. Unlike classical normal forms, the IN-NF characterizes a database scheme as a whole rather than the individual relation schemes. It is shown that a database scheme in IN-NF is always in improved third normal form, while the converse is not true. It is demonstrated that the classical relational design framework may be extended to facilitate the design of database schemes in IN-NF.",
Subtype inequalities,"The satisfiability problem for subtype inequalities in simple types is studied. The naive algorithm that solves this problem runs in nondeterministic exponential time for every predefined poset of atomic subtypings the satisfiability problem for subtype inequalities is PSPACE-hard. On the other hand, it is proved that if the poset of atomic subtypings is a disjoint union of lattices, then the satisfiability problem for subtype inequalities is solvable in PTIME. This result covers the important special case of the unification problem that can be obtained when the atomic subtype relation is equality.",
Computational Complexity of Test-Point Insertions and Decompositions,,
Structural stability aspects of alternate routing in non-hierarchical networks under reservation,"A behavioral characterization of nonhierarchical alternate routing schemes in which a certain number of trunks are reserved for direct routed traffic is presented. It is found that the fundamental behavioral characteristic of the schemes with trunk reservation control is the same as that of the schemes without reservation. A sufficient condition, which can be utilized to find the minimum number of trunks to be reserved for direct routed traffic so as to avoid the instability, obtained. Although the sufficient condition allows absolute stability of the system from the point of view of catastrophe theory, the designer may select a lower number of trunks to be reserved, provided that the stable equilibrium states remain close to each other. A performance index for comparing various levels of reservations among themselves is proposed.",
A practical implementation of the data base machine-Teradata DBC/1012,The paper discusses how the convergence of multiple technologies made the product possible and how it is used to solve business problems for companies world wide.,
A non-linear projection method based on Kohonen's topology preserving maps,"A nonlinear projection method is presented to visualize high-dimensional data as a two-dimensional image. The proposed method is based on the topology preserving mapping algorithm of Kohonen (1990). This algorithm is used to train a two-dimensional network structure. Then, the interpoint distances in the feature space between the units in the network are graphically displayed to show the underlying structure of the data. The authors present and discuss some methods to quantify how well a topology preserving mapping algorithm maps the high-dimensional input data onto the network structure. They compare the projection method with the well-known method of Sammon (1969). Experiments indicate that the performance of the Kohonen projection method is comparable or better than Sammon's method. Another advantage of the method is that its time complexity only depends on the resolution of the output image, and not on the size of the dataset.",
Correspondence analysis for regional tracking in coronary arteriograms,"A new method of correspondence analysis on the basis of geometrical similarity in tracking the region of interest (ROI) of coronary arteriograms is described. The method is insensitive to scaling, rotation, and gray-level variation. Experiments also show that the algorithm is valid even when large deformations exist. It is an important step toward a new approach to regional myocardial dysfunction analysis.",
An Effective Timing-Driven Placement Algorithm For Macro Cells,,
A characterization framework for visual languages,"The general goal of this research is to facilitate the development of visual language environments for the class of visual languages that are based on graph models. The approach the authors take relies on a conceptual framework to define general model components and behaviors; any particular language is defined by selecting and enhancing components and behaviors within the framework. The objective is to provide a system, based on the conceptual framework, in which the language designer defines a data model in conjunction with a distinct, but related, representation of the model. The language specific modules of the resulting visual language system are generated from the specification. These language modules can be viewed as system independent abstract data types which are placed into a fixed system environment. This work enables the visual language developer to easily experiment with different aspects of a visual language. It also provides a basis for the development of, and experimentation with, mechanisms used to support the use of complex visual languages and their environments. The authors address the issue of usability and language complexity by providing support for the development of mechanisms such as visual abstraction hierarchies, multiple views, multiple windows, language component filtering, etc.",
On robust Schur property of discrete-time polynomials,"Markov-like parameters have been defined for a discrete-time polynomial recently and a new method of Schur stability analysis of such polynomials has been established in the space of such parameters. These results are generalized for the Schur invariance property, and the maximum allowable variation in the associated parameters is obtained via evaluating some corner points. The result presented gives a quick qualitative measure of stability robustness of discrete-time polynomials.",
Distribution + persistence = global virtual memory,"The Distributed Systems Group at the University of New South Wales is constructing a distributed operating system based on global virtual memory (GVM). The system combines local and remote storage into a single large virtual address space. This provides a uniform method for naming and accessing objects regardless of their location, removes the distinction between persistent and transient data, and simplifies the migration of data and processes. The GVM system uses conventional computing nodes connected to specialised network interfaces. A fault-tolerant migration and replication protocol keeps the system operational and consistent in case of network errors or node crashes. Password capabilities are used to control access to the GVM.",
Fault Detection In Intelligent Material,,
Distributed consensus in semi-synchronous systems,"The Distributed consensus problem assumes that all processors in the system have some initial values; the goal is to make all non-faulty processors agree on one of these values. This paper investigates the time needed to reach consensus in a partially synchronous model with omission failures. In this model, the processors have no direct knowledge about time, but the time between consecutive steps of each processor is always between two known constants c/sub 1/ and c/sub 2/; the ratio C=/sup c2///sub c1/ measures the timing uncertainty in the system. Moreover, messages are delivered within time d. This paper provides an improved protocol for the above problem. When the majority of the processors are fault-free, the protocol achieves consensus in time 3( phi +1)d+Cd, where phi is the actual number of faults in a specific execution of the protocol. This allows an increase in efficiency up to 25% over the existing protocol which requires time 4( phi +1)d+Cd.",
The morphological structure of images,"The authors investigate the use of mathematical morphology to construct scale-spaces. These scale-spaces are based on differential equations, which are solved by morphological operators, describing the evolution of images in scale-space.",
Output Tracking Control of Nonlinear Systems with Weakly Non-minimum Phase,"This paper is concerned with the problem of designing a robust output tracking controller for MIMO nonlinear systems with weakly non-minimum phase. Based on our system formulation, control plants with uncertainties and/or with actuator dynamics fall into the class under consideration. Under some mild assumptions, it is shown that the overall states and the tracking errors are uniformly bounded. Furthermore, the tracking errors converge to a small residual set.",
On the distributed subcube-allocation strategies in the hypercube multiprocessor systems,"The authors propose a novel system framework for the design of distributed job-scheduling and subcube-allocation strategies in hypercube multiprocessor/multicomputer systems. A generalized-lattice ordering scheme is proposed for processors. An elegant system information structure, the subcube identification table (SIT), is proposed for efficient distribution, retrieval, and update of free-subcube information. Locations of free subcubes can be determined by any node through direct lookup of its SIT. A novel interprocessor communication mechanism called the sync-broadcast is presented for SIT update/construction, and for resolving contention between subcube-requests for consistent allocation/deallocation of subcubes. Different job scheduling schemes can be easily implemented based on the proposed scheme.",
A proposal of fault-checking fuzzy control,The effects of faults in fuzzy control systems are examined and are shown not to be negligible. A fault-detecting method that increases the fault tolerance characteristics of fuzzy control systems is proposed. Simulation results show the validity of the proposed fault-checking method for all kinds of faults considered.,
The reuse of software design and software architecture,"In this paper, a method is presented for the reuse of software designs and software architectures. A software design refers to the abstractions and mechanisms that provide the behavior a system or a component requires. A software architecture refers to the organizational structure of a software system or a component. According to this method, a software design can be represented in terms of extended data-flow graphs (EDFGs) and formal specifications. The graphs and the specifications can be organized into a hierarchical structure, representing different levels of abstraction. Such a structure can be easily understood, modified, reconstructed, aiming at varieties of design targets.",
Semantic issues in the design of languages for debugging,"Some of the inherently difficult issues that will be faced by a designer of any imperative debugging language are surveyed. A powerful debugging language called GDL (General-purpose Debugging Language) is outlined, the particular set of mechanisms included in GDL is justified, and the issue of minimality of this set is addressed. The focus is especially on the semantic issues that arise when the language's mechanisms are combined, in short, the issue of being well-integrated. It is noted that GDL's mechanisms are well-integrated, but some mechanisms are rather inefficient for many debugging applications. However, in expanding GDL's mechanisms for such applications, new semantic problems arise. It is shown how these semantic problems can be avoided by following certain coding conventions.",
A signed hypergraph model of constrained via minimization,"The author proposes a use of the notion of hypergraphs to describe the general constrained via minimization (CVM) problem. He shows that the formulation of the general CVM by means of hypergraphs turns out to be surprisingly simple and general. In the case of two-layer routing, a signed hypergraph model is introduced. On the basis of this model, the author develops a fast (linear-time) heuristic and obtains promising results; he also presents two methods of modeling multiway splits by graphs, producing better results than all the previous methods.",
An optimization algorithm for determining the compatibility coefficients of relaxation labeling processes,"The problem of determining compatibility coefficients for relaxation labeling processes has received considerable attention and a number of different methods have been suggested. The authors propose a method developed within an optimization framework. After formulating the problem of determining the coefficients as a nonlinear programming problem, they develop a gradient-descent algorithm for solving it. Results on an application of relaxation processes are given.",
Worst Case Performance Analysis of Linear Systems with Jumps with Applications to Sampled-Data Systems,"In this paper, we consider a continuous-time linear system with finite jumps at discrete instants of time. An iterative method to compute the L2-induced norm of a linear system with jumps is presented. Each iteration requires solving an algebraic Riccati equation. We also show that a linear feedback interconnection of a continuous-time finite dimensional linear time- invariant (FDLTI) plant and a discrete-time finite dimensional linear Shift-invariant (FDLSI) controller can be represented as a linear system with jumps. This leads to an iterative method to compute the L2-induced norm of a sampled-data system.",
World model representations for mobile robots,"World Model is a key component of any intelligent machine. The modeling system must be able to adequately model the complexity of objects in the environment and it must contain enough structure to allow the low level sensory data to map to the model during the robot operations. The world model builds its representation of the environment based on the data returned by the sensory system of the robot. However, the environment is not static and cannot always be constrained. There is much uncertainty in the world. The representation needs to be able to deal with the uncertainties and update its internal structures. This paper evaluates several world models suitable for mobile robot applications.",
IPL: the InterBase Parallel Language,"IPL is a declarative distributed language designed to support application level programming in the InterBase project. This paper presents the IPL language and shows how it support flexible transactions, mixed transactions, time-constrained transactions and other features. Besides its transaction-oriented features, IPL can be used as a general purpose distributed programming language.",
On serializability of distributed nested transactions,"A model of nested transactions in distributed database systems is presented. The modeling approach is based on conflict serializability extended to accommodate multilevel transactions. Based on these definitions, serialization graph testing for nested transactions is discussed. Three concurrency control algorithms and proofs of their correctness are presented. The algorithms are an adaptation of serialization graph testing, an adaptation of the timestamp ordering protocol, and a variation of an optimistic protocol presented by H.T. Kung and J.T. Robinson (1981).",
A network level fractional channel to support guaranteed real-time communication,"A network-level abstraction called phi -channel that supports the requirements of real-time applications is proposed. A phi -channel represents a simplex, end-to-end communication channel between a source and a destination. The channel is characterized by a set of specific performance parameters associated with its traffic, namely packet maximum end-to-end delay and the maximum number of packets that can be sent over that delay. The primary attribute supported by the phi -channel is on-time reliability. The basic scheme used to verify the feasibility of accepting a phi -channel, and the run-time support to guarantee its performance are described. The results of a simulation experiment implementing the basic functionalities of the proposed scheme are presented.",
An object-oriented toolkit for constructing specification editors,"The authors discuss Spectacle, an object-oriented library of software components designed for constructing language-based, graphical, specification editors. Spectacle provides the programmer with a basic toolkit for building an X-Window editor: minimal knowledge of both C++ and the X-Window graphical environment is assumed. The editing tools that are derived from Spectacle can be implemented as stand-alone editors are integrated into larger-scale software development environments. Spectacle editors are syntax-directed and menu driven. The authors outline the basic structure of the library and examine each software component separately. The user-interface model provided by Spectacle is described. Two example prototype editors are presented.","Formal specifications,
Specification languages,
Typesetting,
Application software,
Software tools,
Computer science,
Programming,
Large-scale systems,
Software libraries,
Software design"
Experimental evaluation of certification trails using abstract data type validation,"The authors report on an attempt to assess the performance of algorithms utilizing certification trails on abstract data types. Specifically, they have applied this method to the following problems: heapsort, Huffman tree, shortest path, and skyline. Previous results used certification trails specific to a particular problem and implementation. The approach allows certification trails to be localized to data structure modules making the use of this technique transparent to the user of such modules.",
Average dependence and random oracles,"A reconstruction of the foundations of complexity theory relative to random oracles is begun. The goals are to identify the simple, core mathematical principles behind randomness; to use these principles to push hard on the current boundaries of randomness; and to eventually apply these principles in unrelativized complexity. The focus in this work is on quantifying the degree of separation between NP/sup R/ and coNP/sup R/ relative to a random oracle R. A technique called average dependence is introduced and used to investigate what is the best lower bound on the size of nondeterministic circuits that accept coNP/sup R/ sets and how close a coNP/sup R/ set can come to 'approximating' an arbitrary NP/sup R/ set. The results show that the average dependence technique is a powerful method for addressing certain random oracle questions but that there is still much room for improvement. Some open questions are briefly discussed.",
Implementation Of Real-time Control Schemes On A Parallel Processing Architecture Using Transputers,,
System design trajectory based on open distributed processing,"The idea of open distributed processing (ODP) is an attempt to model the establishment of integrated distributed environments. It spans heterogeneous systems and extends OSI. This proposal offers new opportunities for various applications: telecommunications, intelligent networks, broadband communications, and fibre optics. The paper presents an architectural ODP model and a methodical approach to support the design trajectory of networks and information systems. It suggests three general step by step top-down approaches and their refinement by special formal descriptions according to a so-called ODP viewpoint.",
Experience with a graph-based propagation programming tool,"A graph-based tool for object-oriented programming, referred to as propagation patterns, has been developed as part of the Demeter system. The Demeter system consists of the programming language independent Demeter method and a suite of platform-specific Demeter tools. Propagation patterns use a technique based on propagation within a graph to specify groups of collaborating classes. Experience has shown that the propagation pattern tool reduces development effort and makes software easier to engineer and reuse. The Demeter system is introduced, the propagation pattern technique for software engineering is described within the context of the Demeter system, and experience in the use of propagation patterns is summarized.",
Performance of Multiple-Bus Multiprocessor Under Non-Uniform Memory Reference Model,"Performance evaluation of multiple-bus multiprocessor systems is usually carried out under the assumption of uniform memory reference model. Hot spots arising in multiprocessor systems due to the use of shared variables, synchronization primitives etc., give rise to non-uniform memory reference patterns. The objective of this paper is to study the performance of multiple bus multiprocessor system in the presence of hot spots. Analytic expressions for the average memory bandwidth and probability of acceptance of prioritized processors have been derived. The results are validated by simulation results.","Multiprocessing systems,
Bandwidth,
Petroleum,
Minerals,
Computer science,
Computational modeling,
Computer architecture,
Parallel processing,
Laboratories,
Cities and towns"
Specification of a coprocessor for efficient access of data structures,"Most of todays applications are developed using high-level programming languages, which allow information to be represented as various types of data structures. However, the support provided by current architectures for accessing these types of data is very limited, Previous research proposed the use of an access coprocessor (AP). The authors define the access coprocessor instruction set, specify the access-execute processors synchronization protocols and illustrate the working of the system with three benchmark algorithms. Their results show that substantial speedup in program execution-time can be achieved by EP-AP concurrency and the use of special instructions by the AP to efficiently access data structures.",
Mega-Systems-the issue of advanced systems development,"A new class of software systems, the class of Mega-Systems, is discussed. The class of Mega-Systems includes the categories of Huge Systems, Package Systems, Systems of Systems and Generic Systems. The attributes and the characteristics of Mega-Systems are identified and related to traditional systems. Based on the discussion of these attributes, a new approach for the development of Mega-Systems is proposed. An adaptation of the GenSIF framework is suggested as a general model for the development of all categories of Mega-Systems.",
Visualizations of 2-D hidden unit space,"For the visualizations, the backpropagation learning procedure was applied to strictly layered feedforward networks with one hidden layer that contained just two units. Values on the input units were binary (0, 1). The squashing function on the output units was the standard sigmoid with upper and lower bounds at 0 and 1. An expanded range, (-1, 1) was used for the hidden units to enhance learning speed and enhance the separation of patterns in the HUAP visualization technique. The resulting images reveal several properties of the hidden unit representations achieved by backpropagation. These include (1) that the normal solution to XOR collapses the pattern space to a one-dimensional manifold and (2) the high symmetry of the hidden unit patterns achieved in the N-2-N encoder task.",
Relations between fault tolerance and internal representations for multi-layer perceptrons,"Fault tolerance is often mentioned as an important, intrinsic property of neural networks but it has not often been the subject of directed study. Such fault tolerance as does exist must depend strongly upon the exact nature of the internal representations captured during training, and the way these are distributed across the network. A representative pattern-recognition task is used to assess the fault tolerance of feedforward neural nets as a function of hidden-layer size. Damage resistance is found to increase with the number of hidden neurons, although this finding is sensitive to the exact performance metric employed. The technique of augmentation, which can increase the fault tolerance of a net of given size, is described. To understand the relations between the obtained measures of fault tolerance and the nets' internal representations, a number of analyses are used. These techniques have more usually been used to simplify network structure by identifying and removing redundancies, but they are equally applicable to the study of fault tolerance.",
Alternative Approaches to ATM/Internet Interoperation,,
Supervised learning on large redundant training sets,"A novel algorithm combining the good properties of offline and online algorithms is introduced. The efficiency of supervised learning algorithms on small-scale problems does not necessarily scale up to large-scale problems. The redundancy of large training sets is reflected as redundancy gradient vectors in the network. Accumulating these gradient vectors implies redundant computations. In order to avoid these redundant computations a learning algorithm has to be able to update weights independently of the size of the training set. The stochastic learning algorithm proposed, the stochastic scaled conjugate gradient (SSCG) algorithm, has this property. Experimentally, it is shown that SSCG converges faster than the online backpropagation algorithm on the nettalk problem.","Supervised learning,
Backpropagation algorithms,
Redundancy,
Large-scale systems,
Computational efficiency,
Stochastic processes,
Computer science,
Neural networks,
Feedforward neural networks,
Code standards"
Vision for vehicle guidance using two road cues,"An autonomous vehicle must be able to find and maintain visual contact with a negotiable path (a road) in front of it. Presents a strategy for road tracking that uses two road cues in order to maintain better visual contract with a road than could be achieved with either cue alone. Also, using two cues to find the road, it is possible to study the ability of a system to recover when contradictory evidence exists concerning the location of the road in front of the vehicle. The two cues used are the road surface shading and its boundaries. The road surface properties captured in an image are modeled by bi-variate polynomial surface patches of up to second order. The road boundaries, and other line-like features of a road, are modeled by line segments fit to image edges. The surface patches and line segments that model the road in one image are used along with knowledge of the vehicle's motion to predict the appearance of the road in a subsequent image. At each image frame the models are updated to take into account new aspects of the road's appearance.",
A Simulation Based Study of TLB Performance,"This paper presents the results of a simulation-based study of various translation lookaside buffer JLB) architectures, in the context of a modem VLSI RISC processor. The simulators used address traces, generated by instrumented versions of the SPECmarks and several other programs running on a DECstation 5000. The performance of two-level TLBs and fully-associative TLBs were investigated. The amount of memory mapped was found to be the dominant factor in TLB performance. Small first-level FIFO instruction TLBs can be effective in two level TLB configurations. For some applications, the cycles-per-instruction (CPI) loss due to TLB misses can be reduced from as much as 5 CPI to negligible levels with typical TLB parameters through the use of variable-sized pages.",
Exploiting iteration-level parallelism in dataflow programs,"An approach to extracting iteration-level parallelism from dataflow programs is presented. The method exploits the single-assignment principle, which guarantees that any data value has exactly one producer. To minimize interprocessor communication, the code is modified so that, at run time, each producer executes on the processor that holds the corresponding data. Overhead resulting from possibly remote read accesses is alleviated by a software technique similar to caching. The performance of this process-oriented dataflow system (PODS) is demonstrated using the hydrodynamics simulation benchmark called SIMPLE, in which a 19-fold speedup on a 32-processor architecture has been achieved.",
"A ""Reader-Centered"" Approach to Online Information",,"Documentation,
Information science,
Computer errors,
Problem-solving,
Psychology,
Laboratories,
Milling machines,
Professional communication,
Information analysis,
Bridges"
The design and implementation of a parallel join algorithm for nested relations on shared-memory multiprocessors,"The authors examine the problem of performing a join involving nested relations in a parallel, shared-everything environment. First they show the difference between joining flat relations and joining nested relations, and then develop a parallel hash-based join algorithm, called the partitioned nested hashed-loops algorithm. Both input/output (I/O) and CPU parallelism are addressed. The implementation and experimental results are presented. The experiments include the effect of the number of CPUs, the amount of memory, the size of the result, the effect of projections, and the effect of the levels of nesting. The experiments showed excellent CPU parallelism speedup.",
Temporal Petri nets and structural induction for rings of processes,A structural induction theorem for rings consisting of an arbitrary number of identical components is presented. The components of a ring are modeled using a Petri net and a temporal logic formula. The theorem can be used to formally infer the correctness of a ring of any large size from the correctness of a ring having only a few components. The usefulness of the theorem is demonstrated using the example of token-passing mutual exclusion.,
Knowledge-based control,"Knowledge-based control is defined here as the management of dynamic systems whose states admit qualitative modeling. Contributions from several disparate disciplines, such as artificial intelligence, the decision sciences, and fuzzy control, are examined. An aeronautical application is used to illuminate the concepts examined. Two levels of architecture are presented for implementing qualitative decision and control for an aircraft. A geometric rather than algebraic approach is taken to the knowledge-based control problem.",
Inductive learning for expert systems in manufacturing,"The authors evaluate several inductive learning techniques using semiconductor wafer failure data gathered during its manufacturing process and where there is currently an expert system in use with rules derived from experts. The learning systems include symbolic (ID3, GID3, CN2), connectionist (Quickprop) and a hybrid model (SC-net). A year's worth of data and expert system diagnoses were available for training these systems. The learning systems were evaluated according to three criteria: the accuracy of the induced rules, the quality of the induced rules as judged by two domain experts and by direct comparison with the existing expert system rules, and the flexibility of the systems in learning to diagnose multiple failures on a wafer. Based on these evaluations, the use of machine learning tools for automatic knowledge acquisition in a real manufacturing domain is discussed.",
Automatic tracking of SPAMM grid in MR images,"A novel approach to the automatic tracking of the SPAMM (spatial modulation of magnetization) grid in cardiac MR (magnetic resonance) images is presented. The tracking is used to extract grid points from MR images and to establish correspondences between grid points belonging to images taken at consecutive frames. Such correspondences are useful for motion and deformation estimation. Spatio-temporal tracking of the SPAMM grid is achieved by using snakes-active contour models with an associated energy functional. A minimizing strategy suitable for tracking the SPAMM grid is presented. By continuously minimizing their energy functionals, their snakes lock on to and follow the 2-D motion and deformation of the grid. Point correspondences are automatically made available. No explicit matching is necessary.",
A new machine learning system using concept theory based rule induction,"A machine learning system through rule induction by the application of concept theory (CT) is described. Conceptual clustering of examples (CCE), one form of learning by discovery, determines the natural classes of input training instances. A concept for each class is thereafter formed. CT is then applied over those concepts to induce concept rules (CR). Further modifications of CR are performed by the application of the technique of learning by analogy to the input instances and CR, thereby inducing modified concept rules (MCR).","Learning systems,
Chromium,
Terminology,
Computer science,
Application software,
Expert systems,
Machine learning,
Engines,
Query processing"
Parallel evaluation of attribute grammars,"Examines the generation of parallel evaluators for attribute grammars, targeted to shared-memory MIMD computers. Evaluation-time overhead due to process scheduling and synchronization is reduced by detecting coarse-grain parallelism (as opposed to the naive one-process-per-node approach). As a means to more clearly expose inherent parallelism, it is shown how to automatically transform productions of the form X to Y X into list-productions of the form X to Y/sup +/. This transformation allows for many simplifications to be applied to the semantic rules, which can expose a significant degree of inherent parallelism, and thus further increase the evaluator's performance. Effectively, this constitutes an extension of the concept of attribute grammars to the level of abstract syntax.",
Sampling of cache congruence classes,Techniques for sampling of cache congruence classes are considered. A sampling policy that selects on the basis of where a reference hits the cache (physically) instead of when a reference arrives is examined. The notion of weighted misses is used to provide some meaningful interpretations of the miss ratios associated with workload partitioning.,
Halvers and expanders (switching),"The authors investigate the asymptotic efficiency of certain combinatorial networks called halvers, which are basic building blocks of many parallel algorithms. They improve the efficiency of halvers in terms of their depth. The novelty is the use of combinatorial circuits whose basic units are k-sorter switches.","Switches,
Sorting,
Parallel algorithms,
Switching circuits,
Registers,
Bipartite graph,
Delay effects,
Binary trees"
Fast implementation of 3D PET reconstruction using vector and parallel programming techniques,"The authors discuss methods for reducing the computation time for 3-D PET (positron emission tomography) reconstruction through the use of fast computer hardware, vector and parallel programming techniques, and algorithm optimization. The strengths and weaknesses of i860 microprocessor based workstation accelerator boards are investigated in implementations of 3-D PET reconstruction. One key issue in achieving speed on the SuperCard 2 has been minimizing memory accesses, and eliminating redundant calculations through approximations and look-up tables. This has allowed the calculation time to decrease from 20 minutes on the MicroVax 3200 to 146 seconds on a dual i860 system.",
Application of an Artificial Neural Network in Canopy Scattering Inversion,,
PPL: an explicitly parallel production language for large scale parallelism,"Considerable work has been done on parallelizing compilers for production languages, but the results are inadequate for tasks with large-scale parallelism. It is argued that explicitly parallel production languages are necessary for such tasks. PPL (Parallel Production Language), an explicitly parallel production language, is described. PPL is closely related to the OPS family of languages and is based primarily on OPS5.","Large-scale systems,
Production systems,
Parallel processing,
Fires,
Image databases,
Concurrent computing,
Computer science,
Unsolicited electronic mail,
Program processors,
Parallel algorithms"
Designing databases in real-time embedded systems,"The issues involved in implementing databases in hard real-time systems are investigated. The requirements of real-time databases are examined, and two new correctness measures, external consistency and temporal consistency, are proposed. An approach to defining transaction periods so that databases can guarantee the desired real-time performance is studied.",
Protocol modularity in systems for managing replicated data,"The authors describe their experience in attempting to modularize Consul, a fault-tolerant system for managing replicated data. Their experience is that, while modularity is needed to simplify the design and implementation of such systems, protocol dependencies, both direct and indirect, impact the way in which protocols are designed and implemented. They also identify certain operating system features that simplify such a design. Based on this experience, work is in progress to develop a new model for fault-tolerant protocols that will facilitate modularization.",
Exploiting fractalness of error surfaces: New methods for neural network learning,"Learning in neural networks can be formulated as global optimization of a multimodal error function over a high-dimensional space of connection weights. A general scaling model that describes the error surface as high-dimensional fraction Brownian motion (FBM), i.e., as a class of random fractals, is developed. The parameter of FBM can be extracted by spectral analysis of the error profile over a random walk in weight space. Scaling structure within the error surface has important implications for stochastic optimizations such as Boltzmann learning. Experimental data that confirm the fractalness of error surfaces for a wide range of problems and connection topologies are reviewed, and the implications of these results are discussed.",
"Learning fuzzy information in a hybrid connectionist, symbolic model","An implementation of fuzzy variables using pi-shaped membership functions is shown in a hybrid symbolic connectionist expert system tool that uses fuzzy logic to implement reasoning with uncertainty and imprecision and that can learn from imprecise data. A method of dynamically modifying the arms, or fuzzy part of the membership functions, during learning is shown. Examples illustrating the method are presented. The results indicate that the presented system is capable of learning membership functions for applications such as control or classification.",
Some architectural and compilation issues in the design of hierarchical shared memory multiprocessors,"Latency and synchronization overheads have been identified as two fundamental problems in large-scale shared memory multiprocessors. The authors discuss architectures based on hierarchical memories which exploit the notion of partial sharing of variables to significantly reduce latency and synchronization overheads. They examine a particular class of architectures, the tree-structured hierarchical memory multiprocessor architectures (THMM), by suggesting an implementation and considering the compile-time parallelization of nonnested iterative loops with constant dependence distance and unit stride. They compare speedup figures for parallelized loops on the THMM and on a conventional memory multiprocessor.",
On the efficient decoding of Reed-Solomon codes based on GMD criterion,An efficient algorithm for GMD (generalized minimum distance) decoding is presented. It requires an algebraic errors-and-erasures decoding procedure to execute only one time. The Welch-Berlekamp iterative method is efficiently used to reduce the number of algebraic decoding procedures. A method for hardware implementation of this GMD decoding is shown.,
Interface-usability evaluation: science of trade-offs,"The effectiveness of four techniques in evaluating the usability of a graphical user interface is presented. The techniques are heuristic evaluation, usability testing, guidelines, and cognitive walkthrough. The techniques are compared as to the number, type, and severity of the problems each could identify for a specific product.",
Cooperative Motion Planning For Autonomous Manipulators,,
A min-max semantics for fuzzy likelihood,"The problem of formalizing the notion of likelihood is considered, as expressed by adjectives such as likely, very likely, rather unlikely, certain, and so on. A formal logic is devised which operates at two distinct semantic levels: a lower level where propositions are assigned a degree of likelihood in the interval",
A unified framework for survivable telecommunications network design,A unified framework for telecommunications switched traffic and transmission facility network design for survivability is presented. This design is considered for backbone nonhierarchical teletraffic networks with dynamic routing capabilities which use at most two traffic links for connecting a call. The facility network is considered to be sparse. The approach addresses the survivable design by considering both the traffic network and facility network explicitly in an integrated mathematical model/algorithm.,
A fast protocol conversion technique using reduction of state transition graphs,"A technique to improve the formal protocol conversion method suggested by K. Okumura (1986) is presented. The algorithm first constructs the reduced state transition graphs (STGs) of the protocols for which the converter is to be designed, and then follows the Okumura algorithm to produce a reduced communicating finite state machine (CFSM) model of the converter. This reduced machine is expanded to obtain the complete single CFSM converter. The reduction of STGs lowers the computational complexity of Okumura's algorithm by one or two orders of magnitude but does not disturb the desired functionality of the converter. The approach has been applied to design a converter between two example protocols.",
Universal relations,"Two operators, join and equivalence, are defined on R, a polynomial-time verifiable binary relation witnessing language A in NP. It is proved that if R has these two operators and there is an instance of A with certain specific properties, then A is NP-complete. Relations with the above properties are called universal relations. It is shown that if set A has a universal relation, then for any set B in NP, there is a reduction f from B to A such that for every x, one can recover the set of witnesses of x from that of f(x). Further, it is shown that obvious witnessing relations of some well-known complete problems as well as those of k-creative sets are universal, whereas an obvious witnessing relation for the graph isomorphism problem is not universal. Finally, it is shown that the two operators join and equivalence are closely related respectively to paddability and d-self-reducibility.",
Minimal model semantics for nonmonotonic modal logics,"Intuitively clear Kripke-style semantics for nonmonotonic modal logic are provided. Minimal model semantics is defined, and soundness and completeness of the semantics for nonmonotonic modal logics are proved. It is shown how the semantics looks for some most popular or most interesting modal logics. Applications to finding expansions and comparing nonmonotonic logics based on different monotonic modal logics are presented. A few examples of using the semantics for obtaining intuitively clear proofs of some results of nonmonotonic modal logics are given.",
Feature selection for improved classification,"The authors apply the feature-selection technique of K. Fukunaga and W. Koontz (1970), an extension of the Karhunen-Loeve transformation, to spoken letter recognition. Feedforward networks trained for letter-pair discrimination with the new features showed up to 37% reduction in classifier error rate relative to networks trained with spectral coefficients. This performance increase was accompanied by a 91% reduction in feature dimension. For three-letter discrimination, the new features performed comparably to spectral coefficients, with a 90% reduction in feature dimension.","Eigenvalues and eigenfunctions,
Principal component analysis,
Training data,
Computer science,
Drives,
Error analysis,
Neural networks,
Speech analysis,
Acoustic emission,
Data mining"
A class of programming language mechanisms to facilitate multiple implementations of the same specification,"To facilitate construction and use of multiple implementations of the same specification, it is shown that an important class of programming language mechanisms, not present in languages such as Ada, is essential. Ways to enhance Ada with these mechanisms are proposed, and a small set of programming language mechanisms to facilitate the use of multiple implementations is presented. By means of these mechanisms, the functionality and the performance of software systems can be separated, specified, analyzed, and verified. It is argued, using realistic examples, that it is necessary to name specifications and implementations separately, to distinguish parameters of specifications and implementations, and for it to be possible for clients to associate different implementations with different instances of the same abstractions. To support these possibilities, it is shown that some basic language mechanisms are essential. How the proposed solutions can be extended to produce performance-parameterized implementations and reusable translators is outlined.",
On the Bayesian deconvolution of planets,Considers Bayesian methods and spatial stochastic processes applied to the deconvolution of images of planets. Under simple but realistic prior assumptions about the true underlying image of a planet the Bayesian framework is put to work. The method has been tested on CCD images of Jupiter.,"Bayesian methods,
Deconvolution,
Planets,
Spatial resolution,
Computer science,
Testing,
Jupiter,
Optical distortion,
Image reconstruction,
Probability distribution"
Extending the structured modeling framework for discrete-event simulation,"Structured modeling (SM) has made a significant contribution to the development of integrated model management systems by providing a common framework for presenting a wide variety of models. However, because SM focuses on representing the static portion of models, it is somewhat awkward to use for discrete-event simulation (DEVS). The author presents a proposal for extended structured modeling (ESM), an extension of the SM framework intended to accommodate the needs of DEVS. Specifically, she proposes adding three new types of elements to SM: random attribute elements to represent random variables; action elements to represent changes in static model elements; and transaction elements to represent control structures for dynamic interactions. She illustrates the use of ESM for describing a DEVS model and shows that the proposed extensions are consistent with the desirable properties of the original SM framework.",
Reliability of cluster-based multiprocessor systems,"The reliability of a cluster-based multiprocessor system is analytically evaluated using modeling techniques. The results indicate that the cluster-based system has low reliability relative to the crossbar and multiple-bus systems. The weaknesses of the cluster-based system architecture, as far as reliability is concerned, are identified and a slight modification of the system architecture is proposed as a remedy. Using the same analytical modeling techniques, the reliability of the modified cluster-based systems's reliability is close to that of crossbar and multiple-bus systems.",
Detection of amplitude modulation using bispectra,"The two sidebands generated around the carrier frequency by amplitude modulation (AM) can be treated as the result of quadratic phase coupling (QPC) between the frequency of the information bearing signal and the frequency of the carrier. Although the bispectrum is useful for detecting QPC, it will generate ambiguity. To avoid the ambiguity observed in the bispectrum, a simple fix of the existing bispectrum estimator, which allows the detection of amplitude modulation and distinguishes spontaneous frequencies from those due to nonlinear coupling, is proposed. A simulation example is provided to illustrate the effectiveness of the approach, followed by discussion of its possible use.","Amplitude modulation,
Frequency,
Phase detection,
Detectors,
Computer science,
Educational institutions,
Signal generators,
Ocean waves,
Electroencephalography,
Displays"
Traffic patterns in a scalable multiprocessor through transputer emulation,"The authors present a multiprocessor emulator designed to evaluate a scalable shared virtual memory architecture called the Data Diffusion Machine (DDM). The DDM is characterised by the lack of any fixed home location for data, with the virtual address being completely decoupled from the physical location of a datum. The authors describe the design of the emulator for the DDM and its transputer-based implementation. The emulator provides a flexible platform for evaluating the architecture and enables one to study the overall behaviour of the machine while running real, lace shared-memory applications. They present a profile of traffic observed at the controllers in the DDM hierarchy while running a variety of real shared-memory applications.","Emulation,
Distributed decision making,
Hardware,
Discrete event simulation,
Computer science,
Memory architecture,
Control systems,
Programming profession,
Timing,
Distributed computing"
On graph bipartization,"The author discusses an undirected, connected graph G(V,E) without multiple edges and self loops. The minimum node (edge) deletion bipartite subgraph problem for G(V,E) is considered. Constant time computable upper and lower bounds are presented on the number of nodes (edges) deleted. The bounds are useful when very little is known about G(V,E). Heuristic solutions for each of these problems are introduced. The time complexity of both heuristics is O( mod V mod /sup 2/).","Computer science,
Tiles,
Application software,
Computer applications,
Printed circuits,
Upper bound,
NP-complete problem,
Bipartite graph"
Partitioning of time index for optical disks,"The authors present a storage model for temporal databases that accommodates large amounts of temporal data. The model supports efficient search for object versions based on temporal conditions, using a time index. They define an access structure, the monotonic B/sup +/-tree, that is suitable for implementing a time index for append-only temporal databases. The storage model uses a combination of magnetic disks and write-once optical disks to keep current, past, and even future states of a database online and readily accessible. It provides an automatic archiving of both object versions and time index blocks to optical disks.","Optical sensors,
Indexes,
History,
Database systems,
Indexing,
Costs,
Computer science,
Data engineering,
Environmental management,
Aging"
A transputer-based 'list mode' parallel system for digital radiography with 2D silicon detectors,The authors believe that a dedicated parallel computer system can represent an effective and flexible approach to the problem of list mode acquisition and reconstruction of digital radiographic images obtained with a double-sided silicon microstrip detector. They present a transputer-based implementation of a parallel system for data acquisition and image reconstruction from a silicon crystal with 200 mu m read-out pitch. They are currently developing a prototype of the system connected to a detector with a 10 mm/sup 2/ sensitive area.,
Factoring Networks by a Statistical Method,"We show that it is possible to factor a multilayered classification network with a large output layer into a number of smaller networks, where the product of the sizes of the output layers equals the size of the original output layer. No assumptions of statistical independence are required.",
Variation of traffic parameters in ATM networks,"The authors consider the problem of change in traffic parameters of a connection in an asynchronous transfer mode (ATM) network and have found out that the traffic parameters of a connection may change appreciably along its path. They present a simulation-based study to examine the magnitude of this phenomenon. The experiments showed that, under certain circumstances, there may be a significant variation in traffic characteristics of a connection at different nodes along its path. Resource allocation must take this variation into account to ensure that quality of service requirements of different connections can be satisfied. A way to handle the problem would be to restore the original traffic pattern on the connection, either fully or partially, at each node along the path. A scheme is proposed to partially reconstruct the original traffic pattern, and its effectiveness was studied by means of simulation experiments.","Telecommunication traffic,
Intelligent networks,
Switches,
Traffic control,
Asynchronous transfer mode,
Quality of service,
Bandwidth,
Network servers,
Computer science,
B-ISDN"
Mixed H2/H∞ control for discrete-time systems via convex optimization,"A mixed H2/H∞ control problem for discrete-time systems is considered for both state-feedback and output-feedback cases. It is shown that these problems can be effectively solved by reducing them to convex programming problems. In the state-feedback case, nearly optimal controllers can be chosen to be static gains, while in the output-feedback case the controller dimension does not exceed the plant dimension.","Output feedback,
Optimal control,
Riccati equations,
State feedback,
Control systems,
Control system synthesis,
Performance gain,
Sufficient conditions,
State estimation,
Stability"
Saving queries with randomness,The power of randomness to save a query to an NP-complete set is studied. Error probabilities for the random reduction of the P/sup SAT////sup (k)/,
Finite memory realization of 2D FIR filters,"Some properties of state space realizations of 2-D FIR (finite impulse response) filters are investigated. It is shown that hidden modes are allowed in minimal realizations and, consequently, there exist minimal realizations of FIR filters which are not finite memory.",
DQDB MAN as a transit network for ATM CPNs,The authors examine the internetworking of the distributed queue dual bus (DQDB) metropolitan area network (MAN) with asynchronous transfer mode (ATM) of broadband integrated services digital network (B-ISDN). Several scenarios are discussed. It is suggested that the best solution is through the use of a connection-oriented (CO) DQDB service. Some of the provisions of the CO DQDB service necessary for an efficient and simple interworking are provided.,
An integrated system for medical diagnosis: Laboratory findings,"An integrated multidiscipline computer aided system for the diagnosis of neuromuscular disorders was developed. The system is able to process data based on the following diagnostic procedures: i. clinical assessment, ii. neurophysiological assessment, iii. muscle biopsy, iv. genetic assessment, and v. biochemical assessment. The self organising feature maps neural network algorithm was applied on clinical and laboratory data collected from 71 subjects. Diagnostic yield of models investigated varied from 76 to 90%.",
Artificial neural networks with nonlinear synapses and nonlinear synaptic contacts,"A neural network model with polynomial synapses and product contacts is investigated. The model further generalizes the sigma-pi and product units models. All the coefficients and exponents of the polynomial terms and the degrees of the polynomials (the number of polynomial terms) are learned, not predetermined. The polynomial synapses together with product contacts can produce any polynomial term. Since the number of learnable parameters is learned, in this aspect the present network is much like the growth networks. Several mechanisms in the present network contribute to a better generalization performance than the growth networks, which usually exhibit poor generalization. Gradient descent algorithms for training feedforward networks with polynomial synapses and product contacts are developed. Experimental results are presented.","Artificial neural networks,
Polynomials,
Neurons,
Neural networks,
Transfer functions,
Computer science"
Modifying VM Hardware To Reduce Address Pin Requirements,,"Virtual manufacturing,
Hardware,
Registers,
Pins,
Very large scale integration,
Computer science,
Buffer storage,
Costs,
Instruction sets,
Computer aided instruction"
Link-level connection control schemes in a high-speed satellite data network: a performance comparison,"The author makes a performance comparison between a connection-oriented (CO) logical link control (LLC) protocol and a connectionless (CL) LLC protocol in a high-speed satellite packet network with the time-division-multiple-access (TDMA)-reservation multiple-access protocol. In particular, the way that the channel transmission rate affects the performance of the two LLC protocols is examined. The most suitable LLC protocol for any given system environment is determined. The comparison indicates that the CL-LLC protocol has more advantages over the CO-LLC protocol as the channel transmission rate increases and that the suitable region for the CL-LLC protocol becomes wider as the receiver-buffer capacity increases and as the network load decreases.",
Automated inspection of machine parts,"Describes a CAD-model-based machine vision system for dimensional inspection of machined parts, with emphasis on the theory behind the system. The original contributions of the work are: the use of precise definitions of geometric tolerances suitable for use in image processing, the development of measurement algorithms corresponding directly to these definitions; the derivation of the uncertainties in the measurement tasks; and the use of this uncertainty information in the decision-making process. Experimental results have verified the uncertainty derivations statistically and proved that the error probabilities obtained by propagating uncertainties are lower than those obtainable without uncertainty propagation.","Inspection,
Solids,
Machine vision,
Coordinate measuring machines,
Surface fitting,
Computer science,
Image processing,
Measurement uncertainty,
Decision making,
Error probability"
Rapid software prototyping,"Rapid software prototyping is an iterative software development methodology aimed at improving the analysis, design, and development of proposed systems. The paper describes rapid prototyping at the system and software levels and reviews the characteristics of computer-aided prototyping. The authors then describe the state-of-the-art in rapid prototyping and discuss technologies that improve the future outlook for prototyping, such as prototyping languages, software reuse, and designer interfaces. To add some cohesion to the concepts, they describe the characteristics of a computer-aided rapid prototyping system. Finally, they provide summaries of the outstanding papers that comprise the rapid prototyping mini-track.",
Compiler optimizations for distributed-memory programs,"The single-program multiple-data (SPMD) mode of execution is an effective approach for exploiting parallelism in programs written using the shared-memory programming model on distributed memory machines. However, during SPMD execution one must consider dependencies due to the transfer of data among the processors. Such dependencies can be avoided by reordering the communication operations (sends and receives). However, no formal framework has been developed to explicitly recognize the represent such dependencies. The author identifies two types of dependencies, namely communication dependencies and scheduling dependencies, and proposes to represent these dependencies explicitly in the program dependency graph. Next, he presents program transformations that use this dependency information in transforming the program and increasing the degree of parallelism exploited. Finally, the author presents program transformations that reduce communication related run-time overhead.",
A memory-based approach to design and implement systolic arrays for DFT and DCT,"A new design and implementation approach for the discrete Fourier transform (DFT) and discrete cosine transform (DCT) is discussed. The approach, called memory-based approach, is based on a design concept of combining and exploiting both the advantages induced from the systolic array architectures and the efficient implementation techniques of substituting multipliers by read-only-memory (ROM) together. Based on this approach, the proposed arrays feature high computing speeds, low complexity and hardware cost of the processing elements (PEs), and low I/O cost. Moreover, high regularity both among and inside the PEs can be found in the proposed arrays. These merits make the proposed designs much more feasible for VLSI implementation.",
Controlling concurrent access to objects in the Raven system,"The paper presents the rationale and design of the concurrency control features of Raven, an object-oriented distributed and parallel programming language and system. Raven's parallel constructs support coarse grained parallelism and are designed to permit programmers to use parallelism with relative ease. To achieve this Raven provides automatic concurrency control on an object's instance data at method invocation time. Raven allows multiple execution threads to access an object strictly for reading or a single execution thread to access an object for the updating of instance data. Raven is operational on a variety of machine architectures, including a shared memory multiprocessor. Experience indicates Raven's concurrency support simplifies the task of converting sequential code to run in a parallel or distributed environment.","Control systems,
Concurrency control,
Parallel processing,
Programming profession,
Automatic control,
Yarn,
Concurrent computing,
Computer science,
Parallel programming,
Writing"
Methods for information system project selection: an experimental study of AHP and SMART,"Presents the findings of an experimental study of the perceived goodness of two multi-criteria methods for IS project selection: the analytic hierarchy process (AHP) and the simple multi-attribute rating technique (SMART). Student subjects were asked to solve either a simple or a complex problem, by either using any method (the control batches were not given training on AHP or SMART) or by using AHP or SMART. The task was to select one project from a number of proposed projects, given a set of scores for each proposed project on each of the selection criteria. The experimental results show that SMART is generally preferable to AHP, particularly for selection problems involving a large number of alternatives and selection criteria.",
On the ubiquity of logging in distributed file systems,"It is argued that logging should be at the forefront of techniques considered by a system designer when implementing a distributed file system. The use of logging in different guises in the Coda file system is described. Coda is a distributed file system whose goal is to provide highly available, scalable, secure and efficient shared file access in an environment of Unix workstations. High availability is achieved through two complementary mechanisms, i.e., server replication and disconnected operation. Logging is used in at least three distinct ways in the current implementation of Coda. First, value logging forms the basis of the recovery technique for recoverable virtual memory (RVM), a transactional virtual memory package. Second, operating logging is used in the replay log that records update activity made by a client while disconnected from all servers. Third, operation logging is used in resolution logs on severs to allow transparent resolution of directory updates made to partitioned server replicas.",
SIR: simultaneous induction of rules using neural networks,"One major drawback of the decision-tree-based inductive knowledge acquisition methodology is its inability to form high-level features from raw attributes. While neural learning has no such problem, its difficulty is in the opaqueness of the acquired knowledge. The authors address both these issues and present a neural learning methodology that yields production rules formed on the basis of high-level features that are also learned during the learning phase. Furthermore, the competitive component of the learning in the proposed methodology automatically determines the number of rules for a given learning situation. Two examples are presented to illustrate the methodology.",
Easy state tables for compound statement sequence detectors,"A very simple divide-and-conquer method for a class of word statements which breaks down a statement to obtain several simple state tables is presented. By following rules for combining the tables, a correct final state table can be constructed. The method has additional bonuses in that what if changes can be explored, and logically impossible word statements can be detected. The method is easy to apply and it provides students with a way of solving difficult problems correctly.",
Effects of periodic communication on distributed decision-making,"A set of performance scenarios as a function of periodic communication is hypothesized and leads to an analysis of optimal communication rates. In general, the performance should decrease over time until new information arrives concerning the global state. To explore the hypothesis, a model of distributed game automata that make decisions probabilistically concerning group or coalition formation. The uncertainty in the players' coalition strategies can be reduced by increasing communication but at the expense of more overhead. In a job scheduling application, the players make good decisions concerning group formation only if there is sufficient communication. The results agree with the hypothesized trade-off of decision quality versus communication overhead.","Distributed decision making,
Processor scheduling,
Degradation,
Uncertainty,
Costs,
Biological system modeling,
Computer science,
Performance analysis,
Game theory,
Automata"
An integrated system for medical diagnosis: Clinical findings,The diagnostic usefulness of artificial neural network (ANNs) is explored by means of an integrated system for medical diagnosis. The models were developed by using the unsupervized self organizing feature maps algorithm. Clinical data for training and testing the ANNs was collected from 71 subjects by applying examination protocols that were developed by an expert neurologist. The diagnostic yield obtained by the examined models was in the region of 86 to 93 %.,
"Data structural bootstrapping, linear path compression, and catenable heap ordered double ended queues","The authors provide an efficient implementation of catenable mindeques. To prove that the resulting data structure achieves constant amortized time per operation, they consider order preserving path compression. They prove a linear bound on deque ordered spine-only path compression, a case of order persevering path compression employed by the data structure.",
Visual translation: from native language to sign language,Visual translation is a new and promising research field for practical and academic reasons. A model of a system which translates text from a native language into animated sign language is described. The authors also describe some design principles and applied methodologies which they believe can be guiding principles for later research in this field.,
Towards open CSCW systems,"Applications designed to support the work of groups is becoming increasingly important to future distributed systems. This paper considers the role of distributed systems within the development of cooperative systems. In particular, the authors focus on the need to provide open CSCW systems and their impact on distributed systems. The work currently being undertaken in open distributed systems (ODP) is used to highlight significant trends for future open CSCW systems. It is shown that the CSCW and ODP community share mutual interests and have complementary aims and goals developed from different perspectives. Within the paper the authors provide a brief introduction to CSCW highlighting the requirements CSCW places on distributed systems. The development of an environment to support open CSCW systems is introduced and briefly described. Finally, the relationships between requirements and models for open CSCW systems and the basic reference model of ODP are discussed.",
On measuring and evaluating synchronization and virtual memory performance of a multiprocessor with multistage interconnection network,"Two important system effects on a multiprocessor with multistage interconnection network are studied and examined: the critical section and barrier for synchronization, and processor locality and virtual memory computing for memory management. Several synchronization algorithms using the interconnection network have been evaluated and implemented. The performance of these algorithms has been measured and compared through several numerical examples. Parallel computing makes a new type of locality, called processor locality which requires that data references to memory from a single processor. The issue of processor locality on the interconnection network has been investigated experimentally. The virtual memory computing effects are measured and evaluated on the multiprocessor system. All the experiments and measurements have been done on the BBN GP1000, a shared-memory multiprocessor with multistage interconnection network.",
Grasshopper-a persistent operating system for conventional hardware,"The paper describes Grasshopper, an operating system designed to provide generic mechanisms capable of being tailored to support a wide range of persistence paradigms. A constraint placed on this design is that the system must be implementable on conventional architectures which support paged virtual memory. The basic system abstractions relating to addressing environments, processes, and protection are described. It is shown that these provide explicit support for distributed persistent objects and processes, stability, and access control. At the same time the system provides the flexibility to allow user implementation of alternative object management techniques.","Operating systems,
Hardware,
Memory management,
Protection,
File systems,
Computer science,
Computer architecture,
Stability,
Access control,
Maintenance"
Toward massive distributed file systems,"Massive scale in distributed file systems remains an elusive goal. Existing systems are generally limited to only a few hundred clients or make restrictive assumptions, such as that widely shared files are read-only. It is argued that a truly massive system must scale for all kinds of files; file access traces suggest that occasionally written files make up too large a proportion of shared reads to be ignored. The file access patterns that are likely to be important in the large-scale systems of the future are outlined, and a scheme for constructing dynamic client hierarchies that may work on a much greater scale than conventional approaches is described.",
A bounded error estimation approach to image reconstruction,"A bounded error (BE) approach to image reconstruction is investigated. In this approach a bound on the measured projections errors is specified and the set of images which is consistent with both the data and the error bound is constructed. The error bound can account for both statistical noise uncertainty, e.g., due to randoms correction or other Poisson-destructive preprocessing, and model uncertainty, e.g., due to a mismodeled or uncalibrated system matrix. The consistent set of images is a set estimate of the image from which point estimates, i.e., image reconstructions can be selected.",
A tool for reusable software component retrieval via normalized specifications,"Introduces the concept of reusable software component retrieval using normalized formal specifications. Reusable Ada software components are stored in a software base that supports a rapid prototyping system called CAPS (Computer Aided Prototyping System). Each component in the software base has a corresponding formal specification. A query in the form of a formal specification is used to search for candidate components that satisfy the requirements of the query. The specification languages used are the Prototype System Description Language (PSDL) and OBJ3. Each specification is normalized to facilitate component retrieval. This paper describes the software base model, syntactic and semantic normalization, and the component retrieval mechanisms.",
The development of an integrated system design environment,"A four stage system design environment is proposed which includes requirements specification, hardware software separation, module specification and system integration stages from a systems integration perspective. As part of realizing this paradigm, a system level specification language, DODAN, is introduced. Based on this specification language, a prototype, DAA, is implemented which addresses the systems level requirements specification stage. Another prototype, DARMS, was implemented to experiment with the module specification stage. This four stage model is described along with experiences in implementing and working with the requirements specification and module specification prototypes.",
A novel algorithm for HMM word spotting performance evaluation and error analysis,"A hidden Markov model (HMM) wordspotter is described. The emphasis is on the algorithms for HMM scoring and performance evaluation, which offer several advantages over those currently used. These advantages include the ability to: determine both the beginning and ending points of a spotted word, generate a smooth receiver operating characteristic (ROC) in a computationally efficient manner, and compare word spotters on the same task using a nonparametric significance test.","Hidden Markov models,
Error analysis,
Speech enhancement,
Computer errors,
Natural languages,
Laboratories,
Computer science,
Performance analysis,
Algorithm design and analysis,
Character generation"
OS/2 cleanroom environment: a progress report on a cleanroom tools development project,"CASE tools to support the cleanroom software development process are being developed for the OS/2 and Presentation Manager environment following the SAA and CUA standards. The paper presents a brief description of the tools, and reports the metrics from design, functional verification and statistical certification testing of the first seven increments of the project.",
PMM: a parallel architecture for production systems,"The authors investigate methods to speed up the match phase of the execution of production systems. The Rete match algorithm is taken as the basis of the implementation. A partially shared Rete network is proposed for parallel implementation and a hierarchical two-level parallel architecture based on this network is outlined. The proposed architecture achieves significant speedup by reducing the dynamic scheduling overheads of fine-grained jobs in a multiprocessor implementation of the Rete network, while still taking advantage of the sharing of common computations in the network.",
Descriptive complexity of Hash P functions,"A logic-based framework for defining counting problems is given, and it is shown that it exactly captures the problems in Valiant's counting class Hash P. The expressive power of the framework is studied under natural syntactic restrictions, and it is shown that some of the subclasses obtained in this way contain problems in Hash P with interesting computational properties. In particular, using syntactic conditions, a class of polynomial-time-computable Hash P problems is isolated, as well as a class in which every problem is approximable by a polynomial-time randomized algorithm. These results set the foundation for further study of the descriptive complexity of the class Hash P. In contrast, it is shown, under reasonable complexity theoretic assumptions, that it is an undecidable problem to tell if a counting problem expressed in the framework is polynomial-time computable or is approximable by a randomized polynomial-time algorithm. Some open problems are discussed.",
Transparently interposing user code at the system interface,"The author reports on the development of an object-oriented toolkit which substantially increases the ease of interposing user code between clients and instances of the system interface by allowing such code to be written in terms of the high-level objects provided by this interface, rather than in terms of the intercepted system calls themselves. This toolkit helps enable new interposition agents to be written which otherwise would not have been attempted. It is used to construct several agents including protected environments for running untrusted binaries, modified file system namespaces, logical devices implemented entirely in user space, transparent network data compression and/or encryption agents, and system call tracing tools. Examples of other agents which could be built include transactional software environments and emulators for other operating system environments.",
Body surface charge mapping and its application to electrocardiography,We have developed a new surface-source model to account for the bioelectrical potential on the body surface. A two-dimensional representation of three-dimensional bioelectrical sources has been developed using an equivalent surface charge model. The proposed equivalent surface charge mapping technique has been evaluated by computer simulations and applied to body surface Laplacian mapping data.,
Remote memory as a resource in distributed systems,"To reduce reliance on disk I/O, the remote memory model is extended, such that dedicated server machines with substantial amounts of memory provide backing storage to client workstations. Remote memory provides the traditional service of swap space, but at faster access speeds. The remote memory server manages objects created, named, and destroyed by client machines. Objects are named by clients and can be shared by multiple clients. The memory server keeps track of idle memory available on other machines, shipping objects to those machines as needed. The memory server is operating-system- and architecture-independent, allowing all network clients to use the memory server. Thus, performance of the overall system can be improved by adding memory to the shared server.",
Nuclear power plant digital instrumentation and control modifications,"An instrumentation and control systems upgrade is planned for Three Mile Island Unit 1, an 871 MW Babcock and Wilcox pressurized water reactor. Installation will be completed in phases extending over four or more operating cycles. It will encompass most nonnuclear instrumentation and control functions, including makeup/letdown, condensate demineralizer, feedwater demand, and reactor demand. The system platform chosen is a state-of-the-art, fault-tolerant architecture which has been extensively evaluated by the B&W Owners Group. The platform will also provide operator interface for other vendor supplied digital control systems such as turbine control.",
Model based concordance compression,"The authors discuss concordance compression using the framework now customary in compression theory. They begin by creating a mathematical model of concordance generation, and then use optimal compression engines, such as Huffman or arithmetic coding, to do the actual compression. It should be noted that in the context of a static information retrieval system, compression and decompression are not symmetrical tasks. Compression is done only once, while building the system, whereas decompression is needed during the processing of every query and directly affects the response time. One may thus use extensive and costly preprocessing for compression, provided reasonably fast decompression methods are possible. Moreover, compression is applied to the full files (text, concordance, etc.), but decompression is needed only for (possibly many) short pieces, which may be accessed at random by means of pointers to their exact locations. Therefore the use of adaptive methods based on tables that systematically change from the beginning to the end of the file is ruled out. However, their concern is less the speed of encoding or decoding than relating concordance compression conceptually to the modern approach of data compression, and testing the effectiveness of their models.",
The synthesis of circuits with a specified natural frequency given a set of linear devices,"A circuit composed of elements taken from a range of linear devices has a set of possible natural frequencies. Two techniques for synthesizing circuits with any permitted natural frequency within the possible range are given. The first technique uses six of each device type, ideal transformers, and ideal wire. The second requires only two devices plus ideal transformers and ideal wire. Conditions for zero power flow among the devices used in the synthesis are given.",
Axiomatizable classes of finite models and definability of linear order,"It may happen that a first order formula with two free variables over a signature defines a linear order of some finite structure of the signature. Then, naturally, this finite structure is rigid, i.e. admits the single (trivial) automorphism. Also, the class of all the finite structures such that the formula defines a linear order on any of them, is finitely axiomatizable in the class of all finite structures (of the signature). It is shown that the inverse is not true, i.e. that there exists a finitely axiomatizable class of rigid finite structures, such that no first-order formula defines a linear order on all the structures of the class. To illustrate possible applications of the result in finite model theory, it is shown that Y. Gurevich's (1984) result that E.W. Beth's (1953) definability theorem fails for finite models is an immediate corollary.",
Randomized geometric algorithms and pseudo-random generators,"The so called randomized incremental algorithms in computational geometry can be thought of as a generalization of Quicksort to higher dimensional geometric problems. They all construct the geometric complex in the given problem, such as a Voronoi diagram or a convex polytope, by adding the objects in the input set, one at a time, in a random order. The author shows that the expected running times of most of the randomized incremental algorithms in computational geometry do not change (up to a constant factor), when the sequence of additions is not truly random but is instead generated using only O(log n) random bits. The pseudo-random generator used is a generalization of the well known linear congruential generator.",
A dynamic cardiac SPECT computer simulation,"A computer simulation was developed to investigate the effects that cardiac motion, time-varying tracer activity, and differences in relative attenuation between the blood and extravascular (tissue) activity regions have on kinetic modeling using dynamic SPECT (single photon emission computed tomography) imaging. The projection/reconstruction process did not introduce significant errors in the fitted parameters. The blood and tissue activity curves showed little difference for various heart rates >5 BPM for 10 s scans. If the blood region of interest was contaminated by tissue, then both the forward (k/sub 21/) and back (k/sub 12/) exchange increased depending on the amount of contamination. Spillover of tissue activity into the blood region due to cardiac motion increased f/sub v/ but had little effect on k/sub 21/ and k/sub 12/. Nonuniform attenuation changed k/sub 21/ and f/sub v/ significantly (>32% change). Only the parameters f/sub v/ and k/sub 21/ were dependent on the relative attenuation difference between the blood and tissue activity regions.",
Statistical Reference Chip-Code Designs for Lpi Enhancement in Ds/ss Communication Systems,,
A magnetic neural network utilizing universal arithmetic modules for pulse-train signal processing,"The authors consider two types of magnetic neural network architecture based on pulse-train signal processing with high reliability. One is realized by neuron units and synapse units, both of which use only a universal arithmetic module (UAM) having adder, multiplier, and delay (memory) functions all in one unit. This architecture thus results in an extremely homogeneous implementation. The other is realized by dividing the function of the UAM into a neuron unit and a synapse unit. The neuron unit provides functions of nonlinear adder and memory by using the properties of the magnetic core such as pulse storage, integration, and nonlinearity.","Neural networks,
Arithmetic,
Signal processing,
Pulse circuits,
Biomedical signal processing,
Computer science,
Delay,
Marketing and sales,
Magnetic noise,
Adders"
Client-network interaction in a real-time communication environment,"A model for client-network interaction developed for the Tenet real-time protocol suite is presented. The model includes new mechanisms for the establishment and runtime management of real-time connections. By improving the information exchanged between the network and the clients, the model makes it possible to reduce the complexity of and the time required to establish a real-time connection, and increases the network utilization. A class of real-time communication service that supports adaptive quality of service is introduced, in order to enhance the ability of the network to deal with congestion situations.","Protocols,
Computer science,
Computer network reliability,
Quality of service,
Telecommunication network reliability,
Application software,
Delay,
Communication system traffic control,
Runtime,
Collaborative work"
Efficient use of parallelism in intermediate level vision tasks,"The primary task of intermediate level vision (ILV) is to take the output of low level vision, which is typically a subset of pixels from the original image array, and to generate a representation of image content which is appropriate for symbolic manipulations at a higher level. These tasks, e.g. boundary detection, various types of segmentation or the computation of attributes of image components, involve operations on individual pixels, sets of pixels with a common label or on entities extracted from the raw pixel data, such as orientation of lines or distance between pairs of parallel lines. A class of tasks which operate on individual pixels or sets of pixels is described, problems which are raised in parallel implementations of this class of tasks are considered, and solutions are suggested.","Pixel,
Parallel processing,
Image segmentation,
Data structures,
Computer science,
Concurrent computing,
Computer vision,
Costs,
Appropriate technology,
Data mining"
Printed antennas - New research frontiers,,
A formal approach for security evaluation,"The authors discuss security issues and consider the extent to which internal relations among entities in a system should be taken into account when carrying out security analysis. They present a concrete and flexible security model expressed in terms of the internal relations in the system, rather than abstract state machines. Based on this model, security analysis can be carried out by decomposing the analysis of the whole system into analyses of subsets of the relations, and the security property of the whole system can be derived by composition of these secure relation subsets.",
A formal approach for security evaluation,,
A note on the instance complexity of pseudorandom sets,"The relationship between the notion of pseudorandomness and the notion of hard instances is investigated. It is proved that if A is random (or pseudorandom), then most instances to A are hard instances (or, respectively, have nontrivial instance complexity). These results are used to show that if one-way functions that are secure against polynomial-size circuits exist, then an NP-hard problem A must have a nonsparse core of which all instances have nontrivial instance complexity.",
Hyper model management systems,"Studies the integration of model management and hypertext systems to produce a hyper model management system (HMMS). Model management systems (MMS) constitute a class of software that is designed to support the construction, storage, retrieval, and use of models in the context of decision support systems. Hypertext systems allow users to split information into data fragments which the user can browse to find information by taking nonlinear paths in computer based texts. Such environments can be readily provided for the subtask of model management by hypertext systems. The different kinds of model knowledge can be captured within different types of hypertext nodes and the relationships among these can be maintained by hypertext links. The authors describe some aspects of model management where hypertext can have a significant impact. However, plain hypertext is ineffective in dealing with the dynamic nature of information in model management tasks where data is revised, models executed, and reports are created on-the-fly. Dynamic domains require dynamic hypertexts. The authors also study the requirements for dynamic hypertexts. These can be satisfied within the class of generalized hypertext systems by using special hypertext nodes and links. The authors explore different architectures to integrate MMS and hypertext systems to obtain HMMSs.",
Neural network models for illusory contour perception,A physiologically motivated model of illusory contour perception is examined by simulating a neural network architecture that was tested with gray-level images. The results indicate that a model that combines a bottom-up feature aggregation strategy with recurrent processing is best suited for describing this type of perceptual completion.,
"The single event upset response of the Analog Devices, ADSP2100A, digital signal processor","The authors present the results of a radiation evaluation program carried out on the ADSP2100A, which is a single-chip microprocessor optimized for 12.5 MIPS digital signal processing. Single event upset/latch-up (SEU/SEL) testing using Californium-252 was the primary aim of this program; however, accelerator heavy-ion and proton SEU/SEL data as well as total ionizing dose data are also presented. Californium-252 SEU testing covered both 12. 5- mu m and 21.3- mu m epitaxial layer DSPs, whereas only the 12.5- mu m type was tested with heavy ions and protons. Heavy-ion SEU testing covered the LET (linear energy transfer) range of 3.4 to 79.2 MeV/(mg/cm/sup 2/) and SEU testing covered the proton energies of 200, 500 and 800 MeV. A total ionizing dose rate of 64.0 rd(Si)/min was used for the cobalt-60 testing. The hardware design and software used are described and details of the various tests and test facilities are given. The authors report on the use of the SEU data for the calculation of expected in-orbit upset rates using the CREME suite of programs.",
Using SOMs as feature extractors for speech recognition,"The authors demonstrate that the self-organizing maps (SOMs) of Kohonen can be used as speech feature extractors that are able to take temporal context into account. They have investigated two alternatives for using SOMs as such feature extractors, one based on tracing the location of highest activity on a SOM, the other on integrating the activity of the whole SOM for a period of time. The experiments indicated that an improvement is achievable by using these methods.",
"TRAMP, the next generation data acquisition system for RTP","The Rijnhuizen Tokamak Project (RTP) is a medium-sized tokamak experiment that requires a very reliable data-acquisition system due to its pulsed nature. Analyzing the limitations of an existing CAMAC-based data-acquisition system showed that a substantial increase of performance and flexibility could best be obtained by the construction of an entirely new system. This system, called TRAMP (transient recorder and Amoeba multiprocessor), is based on tailor-made transient recorders with a multiprocessor computer system in VME running Amoeba. The performance of TRAMP exceeds the performance of the CAMAC system by a factor of four. Plans to increase flexibility and performance are presented.",
A simple assertional proof system for real-time systems,"A simple proof system for a real-time system model similar to that of timed I/O automata is presented. By introducing state variables indicating the last event occurrence time and event deadline time, one can express real-time properties in terms of traditional safety and progress assertions (e.g. invariant, unless, and leads-to) which are interpreted in the standard way. As a result, one can prove them using traditional proof rules (with weak fairness assumptions being replaced by finite upper bound timing assumptions). Unlike other approaches, one does not use a current time variable. The proof system is illustrated on a real-time mutual exclusion algorithm. The authors have also applied it to examples from the timed I/O automata literature.",
The complexity of the Hajos calculus,"The Hajos construction is a simple, nondeterministic procedure for generating the class of graphs that are not 3-colorable. A.J. Mansfield and D.J.A. Welsh have posed the problem of proving whether or not there exists a polynomial-size Hajos construction for every non-3-colorable graph. The main result of this paper is a proof that the Hajos calculus is polynomially-bounded if and only if extended Frege proof systems are polynomially bounded. This result links an open problem in graph theory to an important open problem in the complexity of propositional proof systems. In addition, the authors establish an exponential lower bound for a strong subsystem of the Hajos calculus. Lastly, they discuss an interesting graph-theoretical consequence of this result.",
A connectionist approach to predict antenatal outcome,"This article describes te construction and structure of an anificial neural network (A for the prognosis of antenatal state. The results obtained had been compared with those of the prognostic module of the expert system NST-EXPERT and with those obtained by the perinatologists colaborating in the validation study of the latter. The ANN presented here has proved to be an adequate method to accomplish the prognostic paner recognition task. For this reason, a hybrid system incorporating the A techniques to manage the neonatal prognosis and the original diagnosis ad therapeutic modules of the expert system NST-EXPERT is proposed.",
Improved layer assignment for packaging multichip modules,"The layer assignment problem plays an important role in packaging multichip modules, since the number of layers is directly related to the cost of the final product. In this paper, the authors propose a new model for the problem and a heuristic layer assignment algorithm based on the new model. The experimental results presented show that the solution provided by the algorithm is close to the lower bound.",
There is no Internet connection,,
Video Compression and Noise Reduction Using Transform/Subband Coding and Adaptive Amplitude Modulation,"This article presents the basic ideas behind transform and subband representations of a signal. Although transform and subband representations appear to be different, in fact, they are equivalent. This theoretical relationship gives useful insights into the design of video processing and compression systems. An application of this result to the design of an adaptive amplitude modulation/demodulation (AM/DM) system for noise reduction of images is described. Also discussed is the AM noise-reduction technique for additive noise, and a method is presented to reduce the AM side information by exploiting the transform representation of an image.",
Scalar program performance on multiple-instruction-issue processors with a limited number of registers,"The performance of multiple-instruction-issue processors with variable register file sizes is examined for a set of scalar programs. The authors make several important observations. First, multiple-instruction-issue processors can perform effectively without a large number of registers. In fact, the register files of many existing architectures (16-32 registers) are capable of sustaining a high instruction execution rate. Second, even for small register files (8-12 registers), substantial performance gains can be obtained by increasing the issue rate of a processor. In general, the percentage increase in performance achieved by increasing the issue rate is relatively constant for all register file sizes. Finally, code transformations designed for multiple-instruction-issue processors are found to be effective for all register file sizes; however, for small register files, the performance improvement is limited due to the excessive spill code introduced by the transformations.",
Deterministic scanning and hybrid algorithms for fast decoding of IFS (iterated function system) encoded image sets,"Deterministic algorithms for decoding IFS (iterated function system) sets involve determining all the IFS (dynamic) descendants of seed pixels. Realistic algorithms require pruning of previously encountered pixels on the descendant tree. Timing data are reported for the random iteration algorithm, and for three new deterministic algorithms: the scanning algorithm; the stack algorithm; and a hybrid combination. Decoded timing data indicate the superiority of the pruned hybrid algorithm.","Iterative decoding,
Image coding,
Pixel,
Timing,
Iterative algorithms,
Computer science,
Image segmentation,
Approximation algorithms,
Decision trees,
Data structures"
A simple perfect hashing method for static sets,"Perfect hashing refers to hashing without collisions. There are a number of methods proposed in the literature for determining perfect hashing functions for a given key set. Direct perfect hashing methods are those which do not involve auxiliary table lookup. This paper proposes a direct perfect hashing method using random functions. This method is shown to be as good as any other in performance, and simple to use.",
Supercomputers-modeling reality,"The mathematical modeling capabilities of supercomputers and the possibilities they open up for scientific research are explored. The need for teraflop machines and progress in that direction are discussed. Some modeling applications are described. These include internal combustion engines, semiconductor crystal growth, electromagnetic simulation and design, molecular biology, imaging, geology, meteorology, ocean services, and turbulence.","Supercomputers,
Computational modeling,
Computer aided manufacturing,
Drugs,
Engines,
Laboratories,
Testing,
High performance computing,
Computational fluid dynamics,
Graphics"
A continuation method for emission tomography,"The authors offer a framework, deterministic annealing (DA), in which two important technical problems are addressed. One of these problems is associated with the minimization of objective functions composed of both binary and continuous variables. The second concerns local minima. The DA method offers a principled and efficient means of handling the problems associated with mixed continuous and binary variable objectives. The application of the DA method results in a sequence of objective functions (defined only on the continuous variables) whose sequence of solutions approaches that of the original mixed variable objective function. The sequence is indexed by a control parameter ( beta ). At each beta , a standard descent optimization algorithm is used to find a solution that is then used as an initial condition for the next setting of beta . The energy functions at low beta are smooth approximations of the energy functions at higher beta . Consequently, it is easier to minimize the energy functions at low beta and then track the minimum through the variation of beta .",
Authenticating multicast Internet electronic mail messages using a bidirectional MAC is insecure,"The 1988 version of the message encryption and authentication procedures for Internet electronic mail makes use of bidirectional MAC (BMAC). When used for multicast electronic mail it is important that this BMAC act as a one-way function. It is shown that it is not a one-way function, which means that the BMAC technique should not be used for authenticating multicast messages.","Internet,
Electronic mail,
Cryptography,
Authentication,
Computer science,
Code standards,
Postal services"
People who live in an on-line virtual world,"When designing a human interface of a computer-mediated communication, it is important to take a socio-behavioral approach for understanding the nature of the communication. This study was conducted to investigate the users' social and behavioral characteristics in an online virtual world.",
A model of human approach to describing algorithms using diagrams,"A model of the human approach to describing algorithms is developed by analyzing algorithm descriptions by humans using pen and paper. The authors consider algorithms which are described by drawing data objects on paper and demonstrating a sequence of actions on the data. The model formalizes the abstractness, visibility, and referenceability of objects in the workspace; the 'natural' ways of deterministically and nondeterministically selecting objects; and a wide range of actions for manipulating objects including conditional, condition-based repetition, and parallel actions. The steps of an algorithm for finding a minimum spanning tree are formalized in the proposed model.","Humans,
Concrete,
Algorithm design and analysis,
Computer languages,
Computer science,
Filtering,
Parallel processing,
Tree graphs"
Steering the maintenance costs: an exploration of the maintenance construct,"Maintenance is a natural and necessary part of the system life-cycle and its costs. It is important to control where time and money are spent and what kind of maintenance is performed. Systems maintenance personnel must keep their eye on the potential uses of information technology for competitive purposes in order to classify existing systems projects. For this purpose it is necessary to be able to measure both maintenance, the efforts and costs, and the quality factor maintainability. Such measuring facilitates planning and steering the maintenance work in information systems organizations. The authors present a framework for evaluating software quality in organizations. They combine structure, readability, size, numbers of errors and complexity metrics, and some process attribute metrics to measure maintainability. The collected values are stored in a metric database, from where periodic reports are written. Availability to measurements offers means for the organization to distribute their information systems resources to more profitable objects and to be in control of the maintenance costs, i.e. coordination and reuse of the newly found resources.",
A Cad-based System For Automated Inspection Of Machined Parts,,
The Ignatius environment: supporting the design and development of expert-system user interfaces,"The Ignatius user interface management system, with which designers can create user interfaces for conversational and model-based expert systems, is discussed. Because conversational and model-based expert systems require different approaches to user interface management, Ignatius consists of two separate but communicating tools: the surface interaction manager and the session discourse manager. The interaction manager represents user interface components as objects with attributes. The discourse manager manages the discourse structures of conversational expert systems, structures traditionally regarded as side effects of problem solving. Ignatius was tested by building a user interface to the Antibody Analysis Advisor (A/sup 3/), a conversational expert system that helps laboratory technicians choose analysis techniques for finding antibodies in blood samples. The surface interaction objects, session discourse structure, and an example execution in A/sup 3/ are described.",
Analysing aerial photographs with ADAM,"The use of the advanced distributed associative memory (ADAM) in the analysis of features in infrared line scan imagery is described. An ADAM neural network maps an input vector or image to an output vector or image. The ADAM neural network is capable of recognizing features in aerial images using a deterministic noniterative training algorithm. A novel form of weight update allowing a weighted training procedure and a binary runtime system to increase the classification success of ADAM is presented. The results of segmenting urban and field areas, as well as road identification, are discussed.",
Efficient area optimization for multi-level spiral floorplans,"An algorithm for solving the area optimization problem for multilevel spiral/slicing floorplans is presented. It is shown that in the worst case, there are exponentially many useful implementations for a multilevel spiral floorplan. The reasons why this does not happen very often are also shown. The experimental data suggest that in most cases, the area optimization problem of multilevel spiral/slicing floorplans can be solved in O(n/sup 2/ log n) time and O(n/sup 2/) space, where n is the number of basic rectangles of the floorplans.","Spirals,
Circuit topology,
Computer science,
Very large scale integration,
Registers,
Joining processes,
Partitioning algorithms,
Polynomials,
Optimization methods"
A connectionist approach for thresholding,"Thresholding is a necessary and useful step in many applications of image processing. The general process of thresholding is first to select several gray levels, or thresholds, then use these values to classify the pixels into several subranges. Previous methods for selecting thresholds are usually designed based on assumed distributions of pixels or some sort of heuristics. It is difficult to apply any of these methods when the domain of images is changed. There is a need for seeking a more flexible and robust technique in such situation. The paper presents a connectionist approach for learning and selecting thresholds by using the Kohonen algorithm which is an unsupervised neural network. The approach is able to find thresholds for classifying images without a teacher. Experimental results show that the approach is promising.","Image processing,
Robustness,
Neural networks,
Equations,
Chaos,
Computer science,
Application software,
Training data,
Probability density function"
"Distributed algorithms for shortest-path, deadlock-free routing and broadcasting in Fibonacci cubes","Distributed routing and broadcasting algorithms for the Fibonacci cube are presented. The routing algorithm is shown to find shortest and deadlock-free paths. Two communication models are considered for the broadcasting. It is shown that the all-port broadcasting algorithm is optimal in terms of minimized routing steps. An upper bound is obtained for the one-port broadcasting algorithm, which is shown to be optimal for certain cases. The time complexities of the all- and one-port broadcasting algorithms are examined.",
Improved lower bounds for Shellsort,"The authors give improved lower bounds for Shellsort based on a new and relatively simple proof idea. The lower bounds obtained are both stronger and more general than the previously known bounds. In particular, they hold for nonmonotone increment sequences and adaptive Shellsort algorithms, as well as for some recently proposed variations of Shellsort.",
Analysis of thinning algorithms,"Uses a combinatorial approach to analyse the differences of thinning algorithms among iteration and sub-iteration, thinning by coordinate and by edges of patterns. The authors also propose a serial model thinning algorithm in which the skeletons only consist of three types of points: connected points, end-points, and hole-points.",
An optimized reconfigurable architecture for transputer networks,"This paper presents the architecture of a fully reconfigurable distributed memory computing system. It is assumed that the processors communicate via message passing on an application specific regular network of degree four. To realize any network of this class, they use a special multistage Clos network which is built up by a minimal number of equal sized switches. These switches can be configured to realize any connection between input and output ports. To map a network onto the architecture, the process graph has to be partitioned into a number of subsets. The authors prove that the number of external edges between the subsets can be bounded. For that reason, it is possible to minimize the number of links and switches in the architecture without losing the ability to realize any regular network of degree four. Moreover, any user specific network can be mapped efficiently on the architecture. The practical relevance of this work was shown by the realization of the architecture by Parsytec. Their largest system has 320 processors.",
Implementation and evaluation of a parallel text searcher for very large text databases,"The Utah Retrieval System Architecture (URSA) was initially developed in 1981 developed as an alternative to central-processor-based information retrieval systems. It combined distributed processing and a windowed user interface with a hardware-based search server combined with using document surrogates such as partially-inverted files. The authors have now started the development and testing of a medium-scale (about 10 gigabyte) parallel backend search server to demonstrate its operation and to gather data on the use of such a backend processor in actual operation, including information about query complexity and arrival rates. This searcher, based on a hardware-augmented RISC processor, builds on their experience developing and operating the custom VLSI FSA-based search engine. The use of a programmable processor allows the easy implementation of complex search patterns, such as numeric range matching, while the special hardware augmentation provides considerably better performance than would be available from a standard RISC processor server.",
Understanding three-view drawings based on heuristics,"A system that reconstructs 3D models from hand-drawn three-view drawings represented by binary images is described. The authors lay main stress on the description of a heuristics directed reconstruction algorithm. The proposed algorithm performs a combinatorial search based on the face decision strategy along with two heuristics aiming at simulating the human's understanding way of interpretation. One is for finding a good sequence of search nodes, and the other for finding more natural scenes earlier than unusual ones.",
Interactive computer modules for undergraduate chemical engineering instruction,"The goal of the computer modules component of the project 'A Focus on Developing Innovative Engineers', funded by the National Science Foundation, is to develop a complete set of interactive computer modules for courses in the undergraduate chemical engineering curriculum, where each computer module reinforces one of the key course concepts. The modules are developed by a team consisting of faculty as technical advisor, an undergraduate student programmer, and a postdoctoral research fellow serving as supervisor and master programmer. After development, the modules are tested by undergraduate students at the University of Michigan and by external faculty, before general distribution. Modules for the Introduction to Chemical Engineering course have been tested and distributed, and modules are currently being tested in the Fluids/Transport, Separations, and Chemical Reactor Design courses. The modules prepared to date are outlined.",
Fault-tolerant multi-destination routing in hypercube multicomputers,"Multicast algorithms for faulty hypercube multicomputers are discussed. Two types of algorithms are proposed. Type I algorithms have the following features: they are distributed, in the sense that the same algorithm is implemented in all involved nodes and based on local information only; they can always find shortest paths from the source to all destinations whenever such exist; and they are easy to implement in hardware. The algorithms deal with nodes faults only, and they cannot deliver messages to those destinations that can be reached through some longer paths. Type II algorithms deal with both link faults and node faults. They can deliver messages to all reachable destinations if the total number of faults is less than the dimension of the hypercube. However, these algorithms are not easy to implement in hardware.",
Two Pattern Learning Algorithms Using Dynamical Systems,,
A method of diagnosing logical faults in combinational circuits,"The authors propose a method of diagnosing any logical fault in combinational circuits. The basic idea of the method has been obtained from an observation that only an error generated on one of the fault-nets propagates often to the primary outputs under a given test though more than one fault-net exist in the circuit under test. In this method, the fault-nets are located through a repetition of deducing candidates for each individual fault-net under the assumption of single fault-net and ascertaining which is the real one by probing. Probing internal nets is done only for finding the real fault-nets from these candidates. Consequently, it becomes possible to greatly decrease the number of probed nets. Preliminary experimental results show that fault locations are almost completely identified by probing 20% of the nets at most.","Circuit faults,
Combinational circuits,
Circuit testing,
Fault diagnosis,
Computer science,
Computer errors,
Fault location,
Very large scale integration,
Costs,
Prototypes"
Analysis and recognition of alphanumeric handprints by parts,"An advanced hierarchical model has been proposed to produce a more effective character recognizer based on the probability of occurrence of the patterns. New definitions such as crucial parts, efficiency ratios, degree of confusion, similar character pairs, etc. have also been given to facilitate pattern analysis and character recognition. Using these definitions, computer algorithms have been developed to recognize the characters by parts, including halves, quarters, and sixths. The recognition rates have been analyzed and compared with those obtained from subjective experiments. Based on the results of both computer and human experiments, a detailed analysis of the crucial parts and the Canadian standard alphanumeric character set has been made revealing some interesting fundamental characteristics of these handprint models. The results should be useful for pattern analysis and recognition, character understanding, handwriting education, and human-computer communication.","Character recognition,
Humans,
Pattern recognition,
Pattern analysis,
Machine intelligence,
Handwriting recognition,
Computer science education,
Mathematical analysis,
Algorithm design and analysis,
Writing"
On the duality between routing and scheduling systems with finite buffer space,"A duality property is established between scheduling the routing problems associated with a set of parallel queues. This allows determination of the optimal policy for either system, once it is determined for its dual system. In systems with no buffer at the controller the critical requirement is that the scheduling policy is preemptive; when there is buffer space dedicated to the controller, the crucial assumption is that both routing and scheduling policies should be non-idling.",
A constructive algorithm for spectral factorization of parahermitian polynomial matrices,"Presents a constructive algorithm for spectral factorization of 2D parahermitian positive definite polynomial matrices. Such an algorithm is expected to be useful in many problems in multidimensional signal and system theory. While earlier solutions to the problem in the mathematical literature deal with existence type results, the present algorithm is also believed to provide an elementary proof of the most nontrivial fact that a factorization of a specific type can always be carried out. An example illustrating the main aspects of the algorithm is included.",
Partially shared variables and hierarchical shared memory multiprocessor architectures,"Latency and synchronization overheads have been identified as two fundamental problems in large-scale shared memory multiprocessors. The notion of partial sharing of variables is introduced, and architectures based on hierarchical memories which exploit this notion of partial sharing to reduce the latency and synchronization overheads significantly are suggested. A particular class of architectures, the tree structure, hierarchical memory multiprocessor architectures (THMMs), is examined by suggesting an implementation and considering the execution and the performance of several well-known applications such as matrix multiplication, solution of partial differential equations, solution of linear recurrence relations, barrier synchronization, and reduction operations. Speedup and cost figures for these examples are compared when executing on the THMM and on a conventional memory multiprocessor.",
A VLSI-chip for a hardware-accelerator for the simplex-method,"A hardware realization of the simplex method, the central method of linear programming, a presented. the algorithm is customized for numerical stability (arithmetics) as well as hardware proximity. The resulting hardware is based on a parallel architecture with up to eight processing units, employing standard floating point units (FPUs), RAMs, and custom VLSI chips. It has been designed for use in an IBM PC/AT environment.",
Parallel mean field annealing neural network for solving traveling salesman problem,"The authors propose a parallel mean field annealing (MFA) algorithm and a new energy function for finding traveling salesman optimal tours. The proposed parallel MFA neural network has the advantages of a simplified energy function, and that it converges more rapidly to an optimal solution. The experimental results showed that the parallel MFA and the new energy function can generate the optimal solution.","Annealing,
Neural networks,
Traveling salesman problems,
Cities and towns,
Neurons,
Temperature,
Hopfield neural networks,
Computer science,
Educational institutions,
Large-scale systems"
Numerical performances of autoregressive spectrum estimators based on three-term recurrences,"The numerical performance of two fast algorithms for estimating the power spectral density of an autoregressive process is studied. The algorithms perform similarly to the Burg algorithm, but require only two-thirds as many multiplications as the most efficient implementation of the Burg algorithm. This allows the high resolution associated with the Burg algorithm to be obtained using many fewer computations. One algorithm is the deterministic form of the split lattice algorithm adjoined to the split Levinson recursions; however, its resolution is relatively poor. The other algorithm corrects a bias in the first algorithm, and has resolution similar to the Burg algorithm.",
Hyper Petersen network: a fault-tolerant multiprocessor topology,"The authors propose and analyze a new hypercube-like topology, called the hyper Petersen (HP) network, which is constructed from the cartesian product of a binary hypercube and the Petersen graph. The properties of HP topology include regularity, high degree of symmetry and connectivity, and small diameter. For example, an n-dimensional HP network with N=1.25*2/sup n/ nodes is a regular graph having degree delta =n, node-connectivity kappa =n, and diameter d=n-1, whereas a binary hypercube graph with the same diameter covers only 2/sup n-1/ nodes, each of degree (n-1). Thus the HP topology covers 2.5 times extra nodes at the cost of increasing the degree by one. Again with the same degree and connectivity, the diameter of HP network is one less than that of a hypercube, yet having 1.25 times larger packing density. Furthermore, various topologies such as meshes, trees, and twisted hypercubes can be embedded on the HP topology.",
Performance evaluation of the Rekursiv object oriented computer,"The Linn Rekursiv is an object-oriented computer. An implementation of the persistent programming language PS-algol has been developed for it. Experiences with this implementation have shown certain drawbacks of its modified Harvard architecture for the implementation of persistent object-oriented languages. The general problems of implementing such languages and how the Rekursiv is intended to help are discussed. Data are presented on the relative performances of the Rekursiv and other processors executing PS-algol in 3 areas: procedure calls, list processing and array access, and conclusions are drawn as to which are the more and less valuable features of its architecture.",
Verification of the general position assumption in the practice of stereovision,In feature-based stereo analysis the use of restrictive knowledge-based assumptions constrains effectively the processes of interpreting and matching image features. Among these assumptions the general position assumption plays a significant role and is employed in many approaches. But working with complex scenes shows that this assumption is quite often violated for some parts of the scene. The paper proposes an active stereovision approach which completes automatically the reconstruction of a given scene and avoids thereby special views and errors in the interpretation and matching of image features.,
System Level Specification and Synthesis,,
Particle simulation on heterogeneous distributed supercomputers,"The authors describe the implementation and performance of a three dimensional particle simulation distributed between a Thinking Machines CM-2 and a Cray Y-MP. These are connected by a combination of two high-speed networks; a high performance parallel interface (HIPPI) and an optical network (Ultra Net). This is the first application to use this configuration at NASA Ames Research Center. The authors describe their experience implementing and using the application and report the results of several timing measurements. They show that the distribution of applications across disparate supercomputing platforms is feasible and has reasonable performance. In addition, several practical aspects of the computing environment are discussed.",
An approach for fairness improvement in DQDB networks,"The authors discuss an approach for fairness improvement in distributed queue dual bus (DQDB) network, which is a draft standard for IEEE 802.6 metropolitan area network (MAN). The DQDB medium access mechanism may be unfair for some realistic situations where both throughput and delay are dependent upon the geographic location of each node in the network. The authors analyze the asymmetric access property of DQDB and propose an approach called reservation capacity priority control (RCPC), which is both more efficient and fair for sending the segments. The RCPC allows the system to operate more uniformly and has a high degree of fairness in bandwidth sharing. The simulation results show that RCPC approach is more fair than bandwidth balancing mechanism under all traffic conditions.",
Feasibility of Ultrawideband Radar,,
Minimizing Total Wire Length By Flipping Modules,,
Let's PARTY: Process Algebra With Real-time From York,"There are many real-time process algebras, but they invariably make restrictive assumptions about representable behavior, or do not have proof theory for a suitably large class of behaviours. We introduce the Process Algebra with Real-Time from York (PARTY), which uses a simple yet powerful, intuitive and general model of real-time behavior. A real-time process interacts with its environment by instantaneous actions. There is no restriction on the tame between successive events, and internal action is hidden. The equivalence of recursively defined finite state processes is decidable, and a program has been written. for analyzing PARTY processes.",
Hyperweave: a fault-tolerant expandable interconnection network,"Hyperweave, a novel hierarchical, expandable interconnection network, is presented. Its topology is an improvement over the earlier proposed extended hypercube topology. Hyperweave has better node fault-tolerance, a greater number of disjoint paths between any two nodes, and a larger bisection width than the extended hypercube. A message-routing algorithm is presented, and an embedding of the extended hypercube on the Hyperweave is shown.",
Arden-architecture development environment,"Software supports, such as compiler and simulation tools, are increasingly crucial for architecture development. A flexible system called Arden is being developed to help evolve efficient architectures. Arden combines a retargetable compiler with a back-end simulation tool which provides quantitative information for making a good decision in architecture designs. User-oriented specification for the code generator has simplified the machine descriptions and requires only 31 rules in describing DLX architecture. An experimental bottom-up matching algorithm which reduces the pattern matching to a numerical computation problem and improves the space complexity is presented.",
A model for address-oriented software and hardware,"Introduces the concept of 'address-oriented software', which is software that assigns particular meaning to the values of memory addresses. Such software is often not well supported by the services of the operating system in which it operates. The authors provide some examples of address-oriented algorithms, and propose a general model of the operations they use, called 'address management', which they intend to use as the basis of a new operating system. They derive a hardware model from their formal model, and suggest implementation techniques. A partial implementation of their hardware model is an integral part of the ARM 600 processor, currently in development.",
Supporting the information mesh,"A model for the role of the network in a distributed computing environment that will necessarily require abstractions in the operating system has been developed. This model is based on information that is long lived and widely distributed. It assumes that interesting information can be distributed around the world, and survives outside any particular application, application toolkit, or programming language runtime system. Within the information mesh, computations or activities will take place in one of three forms: one in which the focus of attention is changed, but the application remains the same; one in which the focus changes, and the application itself must also change; and a third that is less specific, more global, e.g., searching. In the cases of such global operations, one may need to limit the scope of terms of the mesh, since these are operations over regions of the mesh. It is important to include links and a native form of link shadow in each operating system, if the workstation running that operating system is to allow the user to collaborate in the information mesh.",
Optimum Steiner tree generation,Several phases of the VLSI design process use rectilinear Steiner spanning trees in estimating wire length. Since the problem is NP-complete heuristics form the major portion of the collection of algorithms for this problem. Exact solutions are rare and very few have even been implemented. Thus they seem not to be practical. The authors first reduce the feasible solution space so that exact solutions are possible. Then they develop two branch and bound algorithms which achieve exact solutions. Distributing the computation between processors and parallel computation methods are currently being tested in an attempt to extend the size of the problems which can be actually solved.,
Decentralized H∞ norm bounding control for discrete-time systems,"This paper presents the design of a decentralized control scheme, which not only stabilizes the system, but also guarantees disturbince attenuation as measured by the H∞ norm. The results rely on the existence of the solution to the state-feedback H∞ norm bounding problem, as well as a solution of a certain modified discrete algebraic Riccati equation.","Control systems,
Riccati equations,
Distributed control,
Continuous time systems,
Discrete transforms,
Sufficient conditions,
Attenuation measurement,
Control theory,
Costs,
Centralized control"
Optimizing Transient Antenna Response,,
Aggregation in model-based reasoning using prime models: a preliminary report,"The paper presents how domain models can be aggregated into intermediate levels, each of which can be realized as an instance of a corresponding abstract prime model. One advantage of model aggregations is its ability to reason from first principles at different levels of decomposition. This is especially desirable when dealing with large and complex physical systems.","Inference mechanisms,
Circulatory system,
Artificial intelligence,
Respiratory system,
Immune system,
Computer science,
Problem-solving,
Computational efficiency,
Natural languages,
Humans"
Robust box bounds: throughput guarantees for closed multiclass queueing networks with minimal stochastic assumptions,"To use queuing theory to analyze real systems such as computer communications networks, one makes assumptions that are, strictly speaking, untrue. The authors provide an exact analysis for cases with greatly relaxed assumptions. Service times can have general increasing failure rate distributions, different by class even at FIFO nodes. Routing can be arbitrary, including dependencies along the route, provided the number of visits to each node is a random variable. Only the mean service time and mean visit rates at nodes need be specified. A lower throughput bound is found which gives a minimum guaranteed throughput for each class; together with the familiar multiclass asymptotic upper bounds they give a convex feasible region in a multidimensional throughput space. A detailed analysis is given for systems with FIFO and infinite-server nodes, and the extension to processor-sharing nodes is described. The results can be reinterpreted as a set of bounds on the separate throughputs. This is equivalent to a circumscribed rectangular region called the robust box bounds.",
Assessment of support for program understanding,"Discusses tools for program understanding during the software maintenance phase. The program understanding is crucial to successful maintenance, but it is still poorly supported by analysis-oriented tools. In the light of cognitive studies for program understanding, the authors assess the existing tools for program understanding, and suggest an approach which facilitates the understanding of complex code during maintenance via the chunking process. During this process programmers recognize the abstract function or meaning of groups of statements and then piece together these chunks to form even larger chunks until the entire code is understood and mapped out. Chunking support can be effective as part of a maintenance toolkit. It lets maintenance personnel control code abstraction and ask many semantic questions about chunks and their relationship to other parts of the code.",
Evaluation of image resolution in X-wave imaging system,"A novel pulse-echo imaging system based on X-wave nondiffracting transmission and reception is described. In the theoretical model of this system a position-dependent filter has been used for pulse generation and subsequently for processing of the received echoes. In practice, the system can be implemented using an annular array transducer and a filter bank. The point spread function (PSF) of the imaging system has been derived. The PSF has an asteroid shape with branches extending to infinity. To reduce the effects of branches and improve image resolution, a space-invariant restoration filter is used. The performance of the imaging system, for broadband as well as for bandlimited X-waves, and the restoration process are evaluated by computer simulations. Simulation results indicate that the system is capable of providing high resolution, large depth of field images.",
A Russian meteor burst communication experiment and measurement-prediction comparison,"Meteor radar measurements performed in Kazan, Russia, in early April 1992, and forward scatter measurements on the Moscow-to-Kazan meteor burst link performed in May 1992, are presented. These measurements are used to demonstrate the prediction accuracy possible with three meteor burst computer models: a Monte Carlo model and two volume integration models. The Monte Carlo method predicted the backscatter and forward scatter more accurately than the other models.",
A global synchronization algorithm for the Intel iPSC/860,"Precisely synchronizing the processors of a distributed memory multicomputer provides them with a common baseline from which time can be measured. This amounts to providing the processors with a global clock. This work investigates a global processor synchronization algorithm for the Intel iPSC/860. Previous work has shown that for certain communication problems, such as the one-to-all broadcast and the complete exchange, the most effective use of the iPSC/860 interconnection network is obtained only when communicating pairs of processors are suitably synchronized. For other communication problems, such as the shift operation, global processor synchronization ensures the most effective use of the communication network. This work presents an algorithm that synchronizes processors more closely than the synchronization primitive by Intel. This new synchronization algorithm is used as the basis of an efficient implementation of the shift operation.",
Promoting the use of an object-oriented software development methodology by merging structured and object-oriented analysis methods,The author discusses factors that are partially responsible for the gap between the state of the art and the state of the practice for object-oriented software development methods. The focus is on identifying factors that inhibit the speed of adoption of object-oriented software development techniques and on discussing methods of addressing these inhibiting factors. A methodology is presented that is designed to decrease the resistance to change by integrating traditional and object-oriented analysis techniques.,
Extracting spinal cord contours from transaxial MR images using computer vision techniques,"Computer vision techniques were applied to finding spinal cord contours in MR (magnetic resonance) images of the lumbar spine. For each slice, the method starts with an approximate spinal cord center supplied by the user. A search was then made for significant edges by moving outwards along 16 equally spaced radii. Edges were interpolated on radii for which no significant gradient existed. The contour was smoothed by adjusting the position of each edge with respect to the edges found on neighboring radii. The results of the experiments are reported. The research demonstrates that it is feasible to use a fairly simple image processing algorithm on a personal computer to automatically extract the spinel cord contours from transaxial MR images.",
Automatic Synthesis of FMS System Design Models from System Requirements,,
Evaluation of Forge: an interactive parallelization tool,"The evaluation of Forge used five typical NAS applications. Analysis of the results revealed three critical areas in need of improvement. First, if tools parallelize loops without performing machine-specific optimizations, performance can be significantly degraded. For highly vectorized codes, the degradation is the most severe. Second, to help user find false dependencies, tool messages should be understandable by application scientists. Query facilities for variable usage and definition should be provided. To guide parallelization, tools must estimate granularity and overhead. Third, the benchmarks contain a large number of small to medium size loops which limit the maximum speedup obtainable by parallelization. Worse yet, they all contain serial loops whose bounds are proportional to problem size. When the size of these loops is large, the speedup can be independent of problem size. Merely converting sequential programs cannot satisfy NAS needs; one must support the design and implementation of parallel algorithms. Finally, issues in creating a future NAS parallel programming environment are discussed.","Concurrent computing,
Degradation,
NASA,
Application software,
Writing,
Parallel programming,
Computer science,
Algorithm design and analysis,
Parallel algorithms,
Aerodynamics"
IASCE: an intelligent assistant to software cost estimation,"A CASE (computer-aided software design) tool called IASCE has been developed to help the project manager estimate a proposed project cost. This tool collects accurate data from current software so that researchers can explore new software models and metrics. IASCE also supports multiple software cost estimation models and their corresponding metrics, tractable for project management control, feedback, and learning activities. In addition, IASCE provides for the establishment of project-specific cost models and corporate metrics for the models, permits tracing of these models and metrics throughout the software life cycle via feedback and post mortem evaluation, and offers a mechanism for long-range improvements of software cost estimation. It can be tailored to a specific software development environment.","Costs,
Project management,
Computer aided software engineering,
Software tools,
Programming,
Computer industry,
Software development management,
Feedback,
Job shop scheduling,
Computer science"
A measure of fault-tolerance for distributed networks,"The authors consider probabilistic networks having links that are perfectly reliable but nodes that fail randomly and independently with known probabilities. They define a fault-tolerance measure of such network that is directly affected by the choice of its underlying graph and the location of its node-components. A state of the network is tolerant if the currently operating nodes comprise a connected subnetwork. The probability of the network being in a tolerant state is the fault-tolerance (FT) measure of the network. The authors are concerned with the design of globally-best tolerant networks, that maximize FT for any given set of node-operating probabilities. They study this measure of fault-tolerance by developing combinatorial tools and by determining the optimal networks in both 'sparse' and 'dense' classes.",
Efficient construction of catastrophic patterns for VLSI reconfigurable arrays with bidirectional links,"Patterns of faults that are catastrophic for regular architectures, particularly the systolic arrays, have been studied. For a given link configuration, there are many fault patterns which are catastrophic. Among those, there is a particular fault pattern, called the reference fault pattern, which is crucial for the development of testing techniques; furthermore, the efficiency of any testing algorithm can be further improved in the presence of efficient algorithms for constructing the reference fault pattern. The authors develop a new algorithm for the construction of the reference fault pattern for VLSI reconfigurable arrays in which the links are bidirectional. The complexity of the new algorithm is O(kN) which is a significant improvement over the existing O(N/sup 2/) algorithm, where k is the number of bypass links, and N is the length of the largest bypass link.",
On languages with very high information content,It is shown that any language in ESPACE that is bounded truth-table reducible in polynomial time to a set with very high space-bounded Kolmogorov complexity must be bounded truth-table reducible in polynomial time to a sparse set.,
"Linear-Time Motion Planning for Two Square, Movable Obstacles in a Grid Environment",,"Robots,
Motion planning,
Shape,
Tiles,
Computer science,
Polynomials,
Geometry,
Bismuth"
Modeling and simulation of the SDC data collection chip,"A description is presented of modeling and simulation of the data collection chip (DCC) design for the Solenoidal Detector Collaboration (SDC). Models of the DCC written in Verilog and VHDL are described, and results are presented. The models have been simulated to study queue depth requirements and to compare control feedback alternatives. Insight into the management of models and simulation tools is given. Finally, techniques useful in the design process for data acquisition systems are discussed.",
CPW-FED Slot-Oscillators for Power Combining Applications,"We have combined integrated circuit antenna technology with microwave oscillator design to build an active slot-oscillator. The design is planar, does not require via holes and is compatible with monolithic transistor technology. The coplanar-waveguide (CPW-fed) antenna impedance is calculated using a full-wave analysis technique. Slot-oscillators were built at 7 GHz, 13 GHz and 22 GHz and the predicted oscillation frequencies agree well with experiments. The design is easily scaled to millimeter-wave frequencies and can be extended to power combining arrays.",
Achieving Goals Through Interaction With Sensors And Actuators,,
Knowledge-based support for scientific programming,"The author considers how knowledge-based tools can support scientific computing, with a focus on the support of code generation. Scientific computing traditionally is carried out by mathematical modelers who write their own Fortran programs. As faster machines and new architectures make more complex problems computationally feasible, programming becomes more cost effective. Scientific computing comprises a variety of activities including model formulation, coding, and interpretation. The SINAPSE program synthesis system illustrates the use of knowledge-based techniques in model solution. SINAPSE is designed to be part of a problem-solving environment for forward modeling that includes several additional scientific programming activities. SINAPSE generates code by applying refinements and optimizing transformations, first producing an algorithm description and then an array-based, high-level language program before generating target code. SINAPSE generates implementations targeted toward a specified architecture.",
Exploiting Locality to Provide Adaptive Routing of Real-Time Flows in Global Internets: Abstract,,
On generalized diameters of interconnection networks,"The authors study the generalized diameters for many existing networks for parallel computations, such as trees, hypercubes, meshes and butterflies. The generalized diameter, called the i-ameter and denoted by d/sub i/(G), of a graph G=(V,E) is the length of the shortest Steiner tree that can be established between any i nodes in G. This generalized notion of diameter allows the computation of the communication cost for any number of nodes, in a given network. Exact values of the i-ameter are computed for complete binary trees and the k-ary trees. For other networks, exact values of i-ameter are given for smaller values of i, and bounds are given for higher values.",
Prediction of software reliability using feedforward and recurrent neural nets,"The authors present an adaptive modeling approach based on connectionist networks and demonstrate how both feedforward and recurrent networks and various training regimes can be applied to predict software reliability. They make an empirical comparison between this new approach and five well-known software reliability growth prediction models using data sets from 14 different software projects. The results presented suggest that connectionist networks adapt well to different data sets and exhibit better overall long-term predictive accuracy than the analytic models. This observation is true not only for the aggregate data, but for each individual item of data as well. The connectionist approach offers a distinct advantage for software reliability modeling in that the model development is automatic if one uses a training algorithm such as the cascade correlation. Two important characteristics of connectionist models are easy construction of appropriate models and good adaptability towards different data sets (i.e., different software projects).",
A neuro-expert system architecture with application to alarm processing in a power system control centre,"A generic neuro-expert system architecture which can overcome difficulties faced by stand-alone expert systems and artificial neural networks is proposed. It can be applied in various problem domains, such as engineering and fault diagnosis, which require problem decomposition. It is recommended for use in real-time systems. The neuro-expert system architecture can be used at different levels of a power system hierarchy for alarm interpretation and fault diagnosis.",
A CASE environment for parallel programming,"The Linda program builder (LPB), a computer-assisted software engineering (CASE) tool for explicit programming, is presented. It isolates much of the administrative effort in constructing parallel programs, and maintains a program-describing database. This database feeds information to the compiler for optimization, to a visualizer for enhanced program visualization, and to other tools in the environment. The LPB is a window-oriented, menu-based, user-friendly system which provides coordination frameworks for program construction. It also represents an alternative approach to high-level programming languages.","Computer aided software engineering,
Parallel programming,
Program processors,
Visual databases,
Scientific computing,
Optimizing compilers,
Visualization,
Programming environments,
Computer science,
Feeds"
New algorithms for the FFT computation of symmetric and translational complex conjugate sequences,"A previously proposed algorithm for the FFT (fast Fourier transform) computation of real symmetric and antisymmetric sequences reduced the N-point symmetric FFT computation to a N/4-point complex FFT computation, but the postprocessing involved division by sin(2 pi k/N). For large size N, this may cause stability problems. An algorithm is presented which overcomes the problem for real symmetric and antisymmetric data sequences. A similar algorithm is given for the translational complex conjugate symmetric data sequence.",
A Network Simulation of Thalamic Circuit Operations in Selective Attention,"The ability of a thalamic circuit to process information selectively from a spatial location was investigated in neural network models. Starting with the known general structure of the thalamic circuit, we considered three variations of the projections from the inhibitory cells of the reticular nucleus onto the cells of the pulvinar nucleus of the dorsal thalamus. The three circuits were modeled as systems of difference equations, and their operations were simulated by computer-based numerical integration. In all three circuits, when input from a target location was slightly larger than the input from neighboring locations, the time evolution of principal (relay) cell outputs showed substantial selective enhancement at the target location compared with neighboring locations. The selective enhancement effect was produced not only on ascending inputs but also on descending cortical inputs. Simulations separating the lateral inhibitory and feedback-enhancement components of the circuits suggested that the feedback-enhancement component substantially magnified the ability of lateral inhibition to produce a target/surround difference.",
Rattlesnake: A Network for Real-Time Multimedia Communications,,
Variable precision representation for efficient VQ codebook storage,"In vector quantization (VQ) with fast search techniques, the storage available limits the number of codevectors used in VQ. Variable precision representation (VPR) is a simple codebook compression scheme. VPR for each vector y stores the number e(y), the number of leading bits which are zero in all elements, and avoids storing those leading bits. When storing the difference of codevectors in a binary tree structured VQ codebook, VPR can save from 24% to 44% in storage. Storing the codevector difference removes the redundancy between similar codevectors. Also as the mean square error of the VQ encoder is lowered, on the average, the difference becomes smaller and yields to better compression. To process vectors in VPR format, the operator uses a bit-serial, element-parallel scheme to evaluate the inner product. The operator's throughput can be increased by replicating its core.",
Parallel radix 4 FFT algorithms on an eight-neighbor processor array,Hardware algorithms for one-dimensional fast Fourier transform (FFT) computation on an 8-neighbor processor array are presented. These algorithms achieve high-speed FFT computation by combining the radix 4 butterfly computation with the communication capabilities of the 8-neighbor processor array. Three algorithms are considered. Two data mapping methods and algorithms are shown: the algorithm for similarity allocation and the algorithm for superposition allocation. The radix 4 and the radix 2 FFT algorithms are compared and evaluated.,
High-speed Image Processor For The Extraction Of 3-D Depth Information From Image Sequence,,
Recovery of Close-to-Nominal Pre-Fault Performance Using the Pseudo-Inverse/Eigenstructure Assignment Method,"A method for recovering close-to-nominal pre-fault performance of a dynamical system is presented. This method, based on the pseudo-inverse of the control matrix and the eigenstructure method of design, is not iterative and therefore should prove quite useful for on-line control restructuring applications. The method presented here guarantees stability of the closed loop restructured system.",
"Construction and parameterization of all static and dynamic H/sub 2/-optimal state feedback solutions, optimal fixed modes and fixed decoupling zeros","The authors consider an H/sub 2/ optimization problem via state feedback. The problems dealt with are of general singular type which have a left invertible transfer matrix function from the control input to the controlled output. This class subsumes the regular H/sub 2/ optimization problems. The authors construct and parameterize all the static and dynamic H/sub 2/ optimal state feedback solutions. Moreover, all the eigenvalues of an optimal closed-loop system are characterized. All optimal closed-loop systems share a set of eigenvalues called the optimal fixed modes. Every H/sub 2/ optimal controller must assign among the closed-loop eigenvalues the set of optimal fixed modes. This set of optimal fixed modes includes a set of optimal fixed decoupling zeros which shows the minimum absolutely necessary number and locations of pole-zero cancellations present in any H/sub 2/ optimal design. It is shown that both the sets of optimal fixed modes and optimal fixed decoupling zeros do not vary depending upon whether the static or the dynamic controllers are used.",
Scalability analysis of partitioning strategies for finite element graphs: a summary of results,"The authors present a scalability analysis of three partitioning strategies, namely striped partitioning, binary decomposition, and scattered decomposition. The analysis is performed using the Isoefficiency metric, which helps in predicting the performances of these schemes on a range of processors and architectures. The performance of each of these schemes is related to the various problem characteristics such as mesh geometry and density. Isoefficiencies are presented for hypercube and mesh connected architectures. Theoretical results are verified through simulations.",
An integrated approach to fault tolerance,"Describes Manetho, an experimental protocol system, whose goal is to explore the extent to which transparent fault tolerance can be added to long-running distributed applications. Transparent techniques are attractive because they can automatically add fault tolerance to existing applications that were written without consideration for reliability. Previous techniques for providing transparent fault-tolerance relied on rollback-recovery. However, rollback recovery is not appropriate for server processes where the lack of service during rollback is intolerable. Furthermore, rollback-recovery assumes that a process can be restarted on any available host. As a result, extended downtime cannot be tolerated for example in file servers, which have to run on the host where the disks reside. Manetho solves these problems with an integrated approach by using process replication for server processes and rollback-recovery for client processes.",
On the complexity of two circle strongly connecting problems,"Given n demand points in the plane, the circle strongly connecting problem (CSCP) is to locate n circles in the plane, each with its center in a different demand point, and determine the radius of each circle such that the corresponding digraph G=(V, E), in which a vertex nu /sub 1/ in V stands for the point p/sub i/, and a directed edge ( nu /sub i/, nu /sub j/) in E, if and only if p/sub j/ located within the circle of p/sub i/, is strongly connected, and the sum of the radii of these n circles is minimal. The constrained circle strongly connecting problem is similar to the CSCP except that the points are given in the plane with a set of obstacles and a directed edge ( nu /sub i/, nu /sub j/) in E, if and only if p/sub j/ is located within the circle of p/sub i/ and no obstacles exist between them. It is proven that both these geometric problems are NP-hard. An O(n log n) approximation algorithm that can produce a solution no greater than twice an optimal one is also proposed.","Joining processes,
Approximation algorithms,
Computational geometry,
Euclidean distance,
Spread spectrum communication,
Radio network,
Councils,
Computer science,
Scattering"
Splitting And Merging: An Approach To Disjunctive Concept Acquisition,,
A model for dataflow computations: result sharing and its performance evaluation,While the dataflow model of computation is a popular way to model concurrent processing it ignores the potential for fast and efficient problem solving which is possible with the reuse of past computational results (result sharing). The concurrent processing and result sharing aspects in problem solving have been integrated into a unified scheme called concurrent processing with result sharing (CPRS) model (1987). In the current paper the CPRS model and the notion of CPRS decomposition based on problem dynamics are presented. The feasibility of the model is demonstrated by developing a dynamic dataflow architecture called the CPRS architecture. A simulation study of this architecture is used to evaluate its performance for solving realistic applications.,
Path planning: an approach based on connecting all the minimizers and maximizers of a potential function,An improved potential-based method for robot path planning is developed by connecting all the local minima and local maxima of the potential function defined in the configuration space of the robot. The authors construct an adjacency graph of the local minima and maxima of the potential function. An edge connecting a local minimum and a local maximum has an associated pair of perturbations which gives a way of moving between them. The method is based on the stability theory of dynamical systems. The usefulness of the method was demonstrated on a two-dimensional piano mover's problem with three degrees of freedom.,
Neural networks applied to the collagenous disease Osteogenesis imperfecta,"Osteogenesis imperfecta is a serious disease which causes bones to be abnormally brittle, and thus, easily broken. It occurs when there is a mutation in the primary sequence of type I collagen. It varies in clinical representation including lethal and non-lethal forms. Severity of the disease appears to be dependent on the type of mutation in the genes COL1A1 and COL1A2. In an attempt to understand the clinical phenotypes of Osteogenesis imperfecta, the authors began an examination of the tertiary structure and primary sequence of collagen type I. The primary sequence of collagen type I was examined to look for neighborhood differences which might lead to specific phenotypes of the disease. Simple patterns were derived and tested. Representation schemes for use with a neural network were found and tested to try to discern the difference between the simplest classification of lethal and non-lethal clinical phenotypes.",
A framework for process maintenance (software),"The authors present a framework, called the process cycle, which can assist in supporting and controlling process maintenance. The process cycle incorporates engineering management, performance, and improvement of processes by human agents subjected to desirable goals and policy constraints. Process maintenance is supported by incorporating feedback cycles so that processes, goals, and policies can be assessed and improved. In particular the authors address the identification of the reasons why processes change, the overall process change process, and the issue of policy improvement. Furthermore, they assess the applicability of the process cycle framework by relating it to current process maintenance practices. It is pointed out that an implication of using the process cycle for process maintenance is that there is a clear logical separation of concern in the various roles played by people, tools used, activities carried out, goals, and policies specified.",
An upper and a lower bound for tick synchronization,"The tick synchronization problem is defined and studied in the semisynchronous complete network with n processes. An algorithm for the tick synchronization problem enables each process to make an estimate of real time close enough to those of other processes. It is assumed that the (real) time for message delivery is at most d and the time between any two consecutive signs of any process is in the interval (c, 1), where 0",
Economic evaluation of a mature ATM network,"The economic evaluation of a mature ATM network is presented. The authors discuss the issues involved and present two examples. Four customer categories are taken into account, namely residential, small business, medium business, and large business customers. The aim is to introduce a simple meaningful model, which incorporates the most important factors that influence the economic viability of an asynchronous transfer mode (ATM) network, and to present the limits and limitations of the area of economic evaluation. The revenue, cost, and net income (of the network operator) are calculated for two different scenarios, that is with and without residential customers.",
Coupled-Mode Analysis of Polarization Splitting Directional Coupler,,
Prefetch Unit for Vector Operations on Scalar Computers,"Current caches are not adequate for vector operations. A new kind of support for vector operations, called prefetch unit, is designed to improve the performance of the scalar (SISD) processors. The prefetch unit can be used for any SISD architecture and also for many kinds of MIMD architectures. It may run in parallel and asynchronously with other parts of processor. It keeps trace of the history of memory references, and initializes rarely any superfluous prefetches.",
On efficient band matrix arithmetic,"An efficient parallel Las Vegas algorithm is presented for computation of the determinant of a non-singular band matrix and for the solution of a system of linear equations with a band matrix as coefficient matrix. The algorithm can be implemented using time polylogarithmic in n with O(nm/sup omega -1/) processors, in order to process an input matrix with order n and band width m, provided that n*n matrices can be multiplied in logarithmic time with O(n/sup omega /) processors. If asymptotically efficient matrix multiplication is used ( omega <3), then the time-processor product for the resulting algorithm is less than the number of steps used to solve these problems via Gaussian elimination. The algorithm is more general than previous processor efficient parallel algorithms for band matrix computations, since it can be applied to invert arbitrary nonsingular band matrices over arbitrary fields.",
Parallel self-reducibility,"The authors examine the relationship between the complexity of solving a decision problem with that of solving a search problem. In particular, if they are given a solution for a decision problem in the form of an oracle, they consider the difficulty of finding evidence supporting the decision. For example, suppose they have an oracle which, when given a graph, indicates whether that graph has a Hamilton cycle (HC). The authors goal is to find a Hamilton cycle in a graph, thus proving it has one. After defining their problems using a relational model they show that if any NP-complete problem is self-reducible in parallel, then all NP-complete problems are. They also show that all P-complete problems have parallel self-reductions. Under the (unlikely) assumption that NP=co-NP, it is shown that NP-complete problems can be self-reduced. However, probabilism can be shown to help: any NP-complete problem has a randomized parallel self-reduction. Finally, natural evidence for an NP problem is discussed.",
Prognosis with neural networks using statistically based feature sets,"The authors report on several techniques for feature selection utilized in the development of a prognostic tool of predicting recovery for patients with head trauma injuries. The database was examined for features, which were extracted using statistical techniques. ANN (artificial neural network) models were built based on the feature selection of the statistical techniques. These models were trained and tested. Results showed that the ability of the ANN to generalize was dependent on three factors: method of data representation, number of outcome classes, and specific features in the data set. The ANN architecture was kept constant for all the cases. Of the statistical techniques used, the backward selection applied to RA (regression analysis) and stepwise selection applied to LDA (linear disciminant analysis) feature models yielded the best generalizations.",
A stable algorithm with perturbed and unmodeled systems,"The authors present the analysis and synthesis of a perturbed and unmodeled system based on model reference adaptive control. A novel robust adaptive control algorithm is described. By adjusting the parameter mu properly, it is concluded that the algorithm will be globally bounded within a specified region if only initial conditions are bounded. All signal vectors will tend to be exponentially stable as time t goes infinite under specified initial conditions.",
Driver Characteristics And In-car Map Display Memory Recall Performance,,
Combinatorial optimization for spacecraft scheduling,"The application of combinatorial optimization techniques to the automatic spacecraft scheduling problem is described. The problem is to search over the candidate sequences of experiments for a sequence that maximizes the value of the science conducted while minimizing constraint conflicts. Exploratory computational results indicate that pseudorandom research techniques, such as simulated annealing, generate viable sequences in reasonable times.",
Inter-module code analysis using 3-dimensional interactive graphics,"A display technique using interactive 3-D color graphics is presented, that is aimed at supporting inter-module code analysis by displaying the inter-connection graphs needed for inter-module code analysis. Inter-module code analysis is a process by which a programmer can analyse a program consisting of a collection of interconnected modules. By using 3-D space, some of the display problems that beset 2-D display techniques are overcome. Entities in the program source are represented with geometric objects. Interconnection relationships between entities are represented with color-coded arrows and the display of the inter-connection graph is interactively controlled by the user. In addition to standard changes in the 3-D viewing parameters that allow the user to move the viewpoint in 3-D space, the user can interactively reposition entities and select which entities are to be visible.",
Constraint propagation over ordered domains,"A new algorithm is described for propagating constraints over ordered domains. The method is particularly suitable for applications where variables may be restricted to a sequence of contiguous values within a domain. By describing the characteristics of the domains, and adding variables and constraints, it is possible to specify a wide variety of problems in a simple and intuitive way. The algorithm may then be invoked to limit the solution space. It is particularly suitable for interactive use, with the user modifying the ranges of variables and then invoking constraint propagation to establish all consequences.<>",
Language constructs for structured parallel programming,"Advocates a structured style for parallel program development. It is argued that a high-quality parallel computing program should be terminating (the program always halts in finite time) and determinate (the program always produces the same result for the same input). A methodology is presented for structured parallel programming, drawing on the successful philosophies of structured sequential programming. A set of structured constructs is presented to demonstrate this methodology. Conditions for termination and determinacy are then derived, which suggests a set of rules for the development of terminating and determinate programs. Infinite waiting and indeterminacy anomalies are characterized. An algorithm is described to detect these anomalies by syntactical analysis.","Parallel programming,
Parallel processing,
Biology computing,
Physics computing,
Operating systems,
Algorithm design and analysis,
Concurrent computing,
Computer applications,
Biological system modeling,
Computer science"
Using virtual addresses as object references,"An alternative to surrogates is to use ordinary virtual addresses for inter-object referencing. Usually (but not always) this involves mapping distributed or persistent data into specified parts of the application's address space relying on page faults to trap and resolve references to nonresident data. The choice between these two referencing schemes involves tradeoffs. Virtual addresses promise easier integration with programming languages and faster local pointer dereferences, whereas surrogates can simplify object-based aspects of storage management, such as garbage collection and heap compaction. The key justifications for surrogate pointers are eliminated by 64-bit address spaces and proper operating system virtual memory support. When these facilities are available, the flexibility of surrogate pointers may not be worth their cost.",
Using box structures with the Z notation,"The box structure method (BSM) provides a framework that can be used to introduce formality into the requirements specification stage of software development. A method of requirements specification is presented which integrates the Z notation with BSM. The requirements specification is confined to the top level black box specification and the corresponding top level state box specification. The authors describe criteria for good requirements specification and explain advantages of the integrated method for achieving them. Summary introductions are given to both BSM and Z followed by an examination of the relationship between the two methods. They explain the integrated method and illustrate it using a simple birthday reminder system. Finally, they discuss issues that have emerged from the use of this method and indicate areas for future research.",
METRICS: a tool for the display and analysis of mappings in message-passing multicomputers,"METRICS is a software tool for the static (compile time) analysis of mappings. METRICS is designed for use in the mapping of parallel computations consisting of a set of communicating parallel processes which communicate through explicit message passing. The target architectures currently supported include the mesh and hypercube as well as user-defined topologies. The underlying routing schemes include store-and-forward, virtual cut-through, and wormhole routing. METRICS is designed to display the mapping in a clear, logical, and intuitive format so that the user can evaluate it quantitatively as well as visually. The contributions of METRICS include its rich underlying formalism, the temporal communication graph, a hybrid between the static task graph and the DAG; its mechanisms for handling massive parallelism using subviews, scrolling, and hierarchical grouping; and the broad spectrum of mapping metrics used in the analysis of each mapping.",
Using dummy reads to maintain consistency in heterogeneous database systems,"A distributed heterogeneous database system is a collection of interconnected local database systems with diverse properties and local autonomy. In such a system, it is difficult to maintain consistency without compromising local autonomy. A global concurrency control protocol is proposed that maintains consistency without compromising local autonomy. The scheme is based on the observation that sufficient read operations attached to global transactions can prevent local schedules from diverging while keeping the database states intact. The protocol is simple and easy to implement. It does not require the knowledge about local concurrency control methods. Thus local concurrency control mechanisms can be changed without affecting the global concurrency control scheme.","Database systems,
Transaction databases,
Concurrency control,
Protocols,
Computer science,
Data models,
Data structures"
FM/sup 2/: a simulator for fine-grained message-passing multicomputers in k-ary n-cube networks,"A simulation tool, called FM/sup 2/, for analyzing low-dimensional k-ary n-cube networks and their processor/router architecture is presented. The simulator helps to evaluate the network performance in fine-grained, scalable multicomputers by using a predefined simulation language. The language can be used to specify network parameters such as system configuration, flow control mechanism, processor/router interface, channel arbitration, and routing algorithm. Outputs generated by the simulator include average message latency, expected execution time, network hot spots, contention spots, message hit ratio, and size of message pools. A non-blocking send and blocking receive programming model is assumed.",
A 2D interactive parser of iconic languages,"In this paper we give algorithms for the construction of a 2D interactive parser which helps a user to construct correct two-dimensional iconic sentences according to positional LALR grammars. At each step of the parsing process the user is provided with a feasible set of icons. Moreover, the areas on the screen where each icon in the set may be placed are highlighted. In this way both syntactic and structural errors are avoided.",
"The emergence of computing science research and teaching at Cambridge, 1936-49","The motivation behind the creation of the Cambridge University Mathematical Laboratory and its original terms of reference are described. The changes to the laboratory caused by World War II are discussed. The Cambridge Mathematical Laboratory was reestablished in 1945 under the directorship of M.V. Wilkes. The ways in which Wilkes developed the work of the laboratory and built up a research team to work on the EDSAC project, which established Cambridge as a major center of computer research, are considered.",
A Combined Extended Circular Image And Spatial Occupancy Approach To 2-D Contour Matching.,,
Parametric ASIC-design by CADIC,"Large ASIC's often include regular blocks such as memories, arithmetic units and random logic. The design system CADIC enables a comfortable description of small and large blocks by a graphic interface. The paper describes experiences in the design of an ASIC chip implementing an efficiently testable floating point adder. By help of this example it is shown that CADIC combines both kinds of logic. Also it is possible to optimize the propagation delay of the floating point adder using specially adapted subcircuits.",
An optimization network for solving a set of simultaneous linear equations,"A network for solving systems of simultaneous linear equations based on Hopfield's neural network model with continuous, real-valued outputs is described. The network is composed of highly interconnected simple neurons with a linear transfer function at each node. It is guaranteed to converge to a correct solution for all solvable systems of equations irrespective of the choice of the node transfer function; the use of complex nonlinearities at the nodes only affects the network convergence time. When a system which admits a solution is given as input, the network converges spontaneously and rapidly to a very accurate solution in all cases. When an unsolvable system is provided as input, the network outputs fail to converge and make the energy function close to zero even after a very large number of iterations.",
Optimal allocation for partially replicated database systems on ring networks,The authors consider a distributed database with partial replication of data objects located on a ring network. Certain placements of replicated objects optimize the probability of read-only success and the probability of write-only success. The authors also obtain optimal placements for k-terminal reliability and expected minimal path length for read-only and write-only operations.,
Extending inductive methods to create practical tools for building expert systems,"Induction programs make several assumptions that limit their practical utility. Research to overcome the limitation of working within a fixed vocabulary is reported. A recently reported phenomenon in machine learning is that there is a tradeoff between the simplicity of concept descriptions and coverage of training instances, and a learning system cannot have both. It is argued that if a learning system can generate new terms, it can achieve both simplicity and coverage. A method for generating one new kind of terms, comparative terms, is given. The experimental results on a mushroom classification task show that a single comparative term can achieve 90% predictive accuracy.",
A Feature - Based Scheme For Reconstructing 3D Parts From 2D Orthographic Projections,,
"Integrated FASTBUS, VME and CAMAC diagnostic software at Fermilab","A fully integrated system for the diagnosis and repair of data acquisition hardware in FASTBUS, VME, and CAMAC is described. A short cost/benefit analysis of using a distributed network of personal computers for diagnosis is presented. The SPUDS (Single Platform Uniting Diagnostic Software) software package developed at Fermilab is introduced. Examples of how SPUDS is currently used in the Fermilab equipment repair facility as an evaluation tool and for field diagnostics are given.","Fastbus,
CAMAC,
Data acquisition,
Costs,
Software tools,
Microcomputers,
Hardware,
Distributed computing,
Laboratories,
Computer networks"
Combining forecasts using recursive equal weighting and linear programming,"Two combining methods, called recursive equal weighting (REW) and linear programming (LP), respectively, are introduced. Their forecasting performance is compared with other combining methods. The proposed REW method not only reaches a forecasting accuracy comparable to that of the theoretically optimal combining methods, but also provides some valuable insights into the methodology of combination, i.e., the combination of combined forecasts can further improve the forecasting performance. The occurrence of outliers is shown to lead to inaccuracy in the ordinary least squares (OLS) solution, while the proposed LP method can effectively eliminate their effects.",
Local optimization using simulated annealing,"The authors present a tool for general purpose local optimization. Randomized combinatorial search heuristics such as simulated annealing (SA) are an effective means of exploring function space to find regions of high performance. Their ability to optimize functions once regions of high performance are found is limited. To improve, and accelerate, their local optimization capabilities, a perturbation operator that selectively perturbs the solution string was created. During the initial phases of optimization, the significance of each bit position is monitored. As the search continues, the probability of perturbations is shifted away from the most significant bits to the least. As the strength of techniques such as SA is achieved through their ability to sample a diverse set of hyperplanes, the perturbation probability is never allowed to decrease to zero for any bit position. This technique was tested on twelve problems, including problems in which the significance of each bit position was nonstatic through the search progression. The local optimization tool was also tested on K. DeJong's five-problem test set (1975).",
A configuration management system in Hitel Platform-call admission control and continuous service,The authors introduce techniques to support continuous service using a central IDB (Information DataBase) mechanism and to control system overload and manage network resources.,
Supporting multiple domains in a single reuse repository,"Domain analysis typically results in the construction of a domain-specific repository. Such a repository imposes artificial boundaries on the sharing of similar assets between related domains. A lattice-based approach to repository modeling can preserve a reuser's domain specific view of the repository, while avoiding replication of commonly used assets and supporting a more general perspective on domain interrelationships.",
Program structure as basis for parallelizing global register allocation,"A model that uses knowledge about program structure to guide global register allocation explicitly is proposed. Restrictions that must be met by the live ranges of loops and conditionals such that the corresponding portion of the register conflict graph is an interval graph are defined. Interval graphs are desirable because they can be colored optimally in polynomial time and because clique separators can be located systematically in interval graphs. Clique separated components of the conflict graph can be colored individually and recombined to an overall coloring, a platform for parallel global register allocation. The method has been implemented and results are presented for a benchmark of C kernels. It was possible to map most conflict graphs of the benchmark to an equivalent interval graph. In each conflict graph, it was possible to identify a large number of clique separators; the parallelization of global register allocation is then straightforward.",
Fundamental properties of extended Kleene-Stone logic functions,"In order to treat modality (necessity, possibility) in fuzzy logic, the intuitionistic logical negation is required. Infinite multivalued logic functions that introduce the intuitionistic logical negation into fuzzy logic functions are called Kleene-Stone logic functions, and they make it possible to treat modality. The domain in which Kleene-Stone logic functions can handle modality, however, is too limited. The authors define alpha -KS logic functions as infinite multivalued logic functions using a unary operation instead of the intuitionistic logical negation of Kleene-Stone logic functions. Some algebraic properties of alpha -KS logic functions are demonstrated, and a necessary and sufficient condition for a seven-valued logic function to be an alpha -KS logic function is shown.",
Input pattern encoding through generalized adaptive search,"In a neural network approach to a sequence prediction problem such as Chinese character prediction, if an orthogonal set is used to encode the Chinese characters, there will be more than 6000 units in the input layer. The authors demonstrate that the number of units in the input layer can be greatly reduced with proper encoding. A neural network maps a group of input vectors to a group of target vectors. It generalizes the responses for inputs that are similar to the inputs on which it has been trained. With this similarity property, if the input pattern vectors are encoded according to the interrelationship among the target patterns, the network may behave better, and fewer units will be needed in the input layer. The authors present such an input pattern encoding method for a neural network with recurrent connections. A modified genetic algorithm was used to do a generalized adaptive search for a good encoding.",
Neural network recognition of objects based on impact dynamics,"A system is presented which can classify unknown objects by the waveform produced upon their impact with a known object. The output of an accelerometer mounted on the known object is read into a unit that computes the waveform's discrete Fourier transform (DFT), which is then fed into a two-layer neural network recognition module. The specific application described observes a collision between two objects, one of which is a wooden platform while the other is made out of a different material. After being shown sample waveforms produced by collisions with three types of objects, the system can then classify new collisions with the objects within 6 ms after the impact. Both the DFT unit and the classification network are implemented with Intel's 80170NX Electrically Trainable Analog Neural Network (ETANN).",
Diagnostic support system design for artificial heart control,Design of a diagnostic technique used in an intelligent support system for artificial heart control is presented. Parameters which may cause abnormal variables of the recipient of artificial hearts are searched with the use of a large dynamic model Human. The advantage of this technique is that candidates of abnormal parameters can be pointed out avoiding real-time parameter estimation whose results would be unreliable for the large scale model.,
"Hierarchies in transitive closure logic, stratified Datalog and infinitary logic","The authors establish a general hierarchy theorem for quantifier classes in the infinitary logic L/sub infinity omega //sup omega / on finite structures. In particular, it is shown that no infinitary formula with bounded number of universal quantifiers can express the negation of a transitive closure. This implies the solution of several open problems in finite model theory: On finite structures, positive transitive closure logic is not closed under negation. More generally the hierarchy defined by interleaving negation and transitive closure operators is strict. This proves a conjecture of N. Immerman (1987). The authors also separate the expressive power of several extensions of Datalog, giving new insight in the fine structure of stratified Datalog.",
A structuring technique for compute-aggregate-broadcast algorithms on distributed memory computers,"A technique for structuring compute-aggregate-broadcast algorithms on distributed memory computers is presented. The compute-aggregate-broadcast paradigm provides an abstraction of the problem for the programmer, allowing for separation of computation and synchronization. Such algorithms are well suited for application on distributed memory computers. The structuring technique assists the parallel programmer with synchronization, allowing the programmer to concentrate more on developing code for computation. Two examples are presented.",
A neural predictor for recurrence of breast cancer,"This paper describes the application of a neural network model (SOC: Self-Organizing Classifer) to the problem of classifying the time of recurrence of breast cancer. Diferently from other neural models, SOC shows good convergence and generalization abilities even in the case of a small data set, thus being particularly suitable for medical applications.","DNA,
Presses,
System-on-a-chip,
Biological system modeling"
A loosely-coupled parallel graphics architecture based on a conflict-free multiport frame buffer,"This paper describes a parallel computer architecture for real-time image synthesis. The architecture is based on a loosely-coupled array of general purpose processors equipped with a novel frame buffer subsystem called a conflict-free multiport frame buffer (CFMFB) which enables every processor to write any region of the screen without access conflicts. An efficient polygon rendering method using the CFMFB is also described. The method assigns a subset of the polygons to each processor, which independently calculates the images of the assigned polygons with the Z-buffer algorithm. The performance of the system is estimated through simulation experiments with sample scenes.",
DeltaStar: a general algorithm for incremental satisfaction of constraint hierarchies,"The DeltaStar incremental algorithm for solving constraint hierarchies, which was developed as part of a continuing investigation on the design and implementation of constraint programming languages, is described. DeltaStar is a framework for incremental solvers built above an existing flat solver that provides the constraint solving techniques. By plugging different flat solvers into DeltaStar, different hierarchical solvers can quickly be produced and experimented with. Two implementations of DeltaStar, as well as previous algorithms that can be viewed as instances of DeltaStar, are discussed.","Logic programming,
Computer languages,
Algorithm design and analysis,
Computer science,
Graphics,
Object oriented programming,
USA Councils,
Tin,
Equations,
Iterative algorithms"
Design of an assembly planning system using unsupervised learning algorithm,"An efficient approach using an unsupervised learning algorithm to generate assembly plans is proposed. Two algorithms, pattern clustering and retrieval algorithm (PCRA) and pattern adaptation algorithm (PAA), are presented, and are applied to a container assembly example. The symbolic knowledge slots adaptation is implemented in C language integrated production system (CLIPS). Assembly plans are encoded into patterns and fed into the designed self-organizing neural network. Based on the defined function, similar assembly plants automatically form a cluster. When a similar assembly plan is given, it can retrieve the appropriate cluster to identify the most approximate assembly pattern for adaptation.","Algorithm design and analysis,
Assembly systems,
Unsupervised learning,
Neural networks,
Hamming distance,
Clustering algorithms,
Binary codes,
Computer science,
Pattern clustering,
Expert systems"
"A multi-paradigm programming language for constructing fault-tolerant, distributed systems","The design of FT-SR, a programming language based on SR and oriented toward constructing fault-tolerant distributed systems, is presented. The language, which is based on the existing SR language, is unique in that it has been designed to support equally well any of the programming paradigms that have been developed for this type of system, including the object/action model, the restartable action paradigm, and the state machine approach. To do this, the language is designed to support the implementation of systems modeled as collections of fail-stop atomic objects. Such objects execute operations as atomic actions except when a failure or series of failures cause underlying implementation assumptions to be violated; in this case, notification is provided. An example program consisting of a data manager and its associated stable storage is given.",
Performance analysis of the rotating slot generator scheme,"A thorough investigation of the performance of the rotating slot generator (RSG) scheme, based on simulation, is presented. RSG is a medium access control protocol appropriate for high-capacity long-distance metropolitan area networks (MANs). It uses the looped bus architecture of the distributed queue dual bus (DQDB) in which the slot generators for both busses are colocated inside the same station. However in RSG, all the stations, one after the other in a cyclic order, undertake the task of generating and destroying the slots on both busses. In this way the location of the station relative to the slot generator changes dynamically, and its effect on the performance is drastically reduced. The authors investigate the fairness and performance of RSG under symmetric and asymmetric loading, underload and overload conditions, and under the presence of a single or multiple priority classes of traffic. They also compare its performance with different variations of DQDB.",
Neural network based reinforced learning,"Reinforcement learning equations for modifying neural network backpropagation weights were derived. Subsequent convergence analysis showed guaranteed convergence. Experiments conducted in simulation and on a physical system showed the algorithm considered here learned to control quickly, quicker than other learning algorithms doing the same task. It could also adapt to changes in the physical parameters. There were also clear indications that the algorithm could generalize, and accommodate changes in the control environment, without the need for further training. This is due to the distributed knowledge representation ability supported by neural networks.",
Parallel Data Vault Methods for Larger Scale Stochastic Dynamic Programming,"The decomposition of the finite difference approximation to stochastic dynamic programming problems is described for the optimal control of nonlinear, continuous time dynamical systems. The stochastic components include both Gaussian and Poisson random white noise. A parallel data vault mass storage method is developed to take advantage of the decomposition, and therefore to help alleviate Bellman's curse of dimensionality in dynamic programming computations. It is shown that data vault memory on the data parallel Connection Machine type computational model can be enhance the efficiency of the decomposition performance. Extension of the data vault technique to a more general stochastic optimal control problem is discussed. Performance on the Connection Machine for larger scale stochastic dynamic programming problems, such as resource management problems with up to a projected six states, are illustrated and discussed.","Stochastic processes,
Dynamic programming,
Stochastic resonance,
Optimal control,
Concurrent computing,
Finite difference methods,
Stochastic systems,
White noise,
Computational modeling,
Resource management"
Efficient algorithms for locating a core of a tree network with a specified length,The authors present efficient algorithms for finding a core of tree with a specified length for both sequential and parallel computational models. The algorithms can be readily extended to a tree network in which arcs have nonnegative integer lengths. The authors also present a parallel version of the algorithm on an EREW PRAM (parallel random access machine) model. The results presented might provide a basis for the study of other facility shapes such as trees and forests of fixed sizes.,
Loop transfer recovery for general nonminimum phase discrete time systems - part 1: analysis,"A complete analysis of loop transfer recovery (LTR) for general nonstrictly proper, not necessarily minimum phase discrete time systems is presented. Three different observer based controllers, namely, 'prediction estimator', and full or reduced order type 'current estimator' based controllers, are used. The analysis corresponding to all these three controllers is unified into a single mathematical frame work. The LTR analysis given here focuses on three fundamental issues, (1) the recoverability of a target loop when it is arbitrarily given, (2) the recoverability of a target loop while taking into account its specific characteristics, and (3) the establishment of necessary and sufficient conditions on the given system so that it has at least one recoverable target loop transfer function or sensitivity function. Various differences that arise in LTR analysis of continuous and discrete systems are pointed out.",
Taiwan: meeting the new challenges (engineering education),"The state of engineering education in Taiwan is presented in terms of the number of engineering departments in Taiwanese universities and the number of students graduated from those departments. The basic philosophy of undergraduate engineering education in Taiwan, providing a general-purpose training to most people who want it, is discussed. The manner in which the education system is managed in Taiwan and the challenges it faces in the future are outlined.","Engineering education,
Government,
Educational products,
Industrial economics,
Computer aided manufacturing,
Space technology,
Computer science,
Economic indicators,
Cultural differences,
Educational technology"
A VLSI hardware accelerator for dynamic time warping,Describes an area and time efficient systolic array architecture for computations in Dynamic Time Warping (DTW). The special purpose architecture is used to perform the band matrix multiplication in order to compute the local distance metric based on Itakura's log likelihood distance. The time complexity of the algorithm is O(nk) where n and k are the number of elements in the row of the first and second input matrices. The number of processors is equal to the bandwidth w of the output band matrix. The speedup of the parallel algorithm compared to the sequential algorithm is wz where z is the multiplier stages within a PE. The parallel algorithm can be implemented as a single VLSI chip.,
On minimum and maximum spanning trees of linearly moving points,"The authors investigate the upper bounds on the numbers of transitions of minimum and maximum spanning trees (MinST and MaxST for short) for linearly moving points. Suppose that one is given a set of n points in general d-dimensional space, S=(p/sub 1/,p/sub 2/, . . ., p/sub n/), and that all points move along different straight lines at different but fixed speeds, i.e., the position of p/sub i/ is a linear function of a real parameter. They investigate the numbers of transitions of MinST and MaxST when t increases from - infinity to + infinity . They assume that the dimension d is a fixed constant. Since there are O(n/sup 2/) distances among n points, there are naively O(n/sup 4/) transitions of MinST and MaxST. They improve these trivial upper bounds for L/sub 1/ and L/sub infinity / distance metrics. Let c/sub p/(n, min) (resp. c/sub p/(n, max)) be the number of maximum possible transitions of MinST (resp. MaxST) in L/sub p/ metric for n linearly moving points. They give the following results; c/sub 1/(n, min)=O(n/sup 5/2/a(n)), c/sub infinity /(n, min)=O(n/sup 5/2/a(n)), c/sub 1/(n, max)=O(n/sup n/) and c/sub infinity /(n, max)=O(n/sup 2/) where O(n) is the inverse Ackermann function. They also investigate two restricted cases.","Upper bound,
Business,
Postal services,
Computational geometry,
Motion planning,
Robots"
Maximizing non-linear concave functions in fixed dimension,"Consider a convex set P in R/sup d/ and a piece wise polynomial concave function F: P to R. Let A be an algorithm that given a point x in IR/sup d/ computes F(x) if x in P, or returns a concave polynomial p such that p(x) <0 but for any y in P, p(y) >or= 0. The author assumes that d is fixed and that all comparisons in A depend on the sign of polynomial functions of the input point. He shows that under these conditions, one can find max/sub P/ F in time which is polynomial in the number of arithmetic operations of A. Using this method he gives the first strongly polynomial algorithms for many nonlinear parametric problems in fixed dimension, such as the parametric max flow problem, the parametric minimum s-t distance, the parametric spanning tree problem and other problems. In addition he shows that in one dimension, the same result holds even if one only knows how to approximate the value of F. Specifically, if one can obtain an alpha -approximation for F(x) then one can alpha -approximate the value of maxF. He thus obtains the first polynomial approximation algorithms for many NP-hard problems such as the parametric Euclidean traveling salesman problem.",
Recent result on classification of finite dimensional maximal rank estimation algebras with state space dimension 3,"R. W. Brockett (1983) proposed to classify all finite dimensional estimation algebras. An affirmative solution to Brockett's problem will allow construction of all possible finite dimensional recursive filters from the Lie algebraic point of view. The concept of an estimation algebra with maximal rank was introduced by L. F. Tam et al. (1990). This is the most important general subclass of estimation algebras. S. S.-T. Yau and W.L. Chiou (1991) have already classified all maximal rank finite dimensional estimation algebras with state space dimension at most 2. Here, the case for state space dimension 3 is studied.",
A method for the non-stationary analysis of heart rate fluctuations related to instantaneous lung volume,This paper describes a method for the time domain characterization of the heart rate fluctuations relating to the instantaneous lung volume. The recursive least squares algorithm is utilized to track the change in the impulse response of the heart rate to the instantaneous lung volume signal. Computer simulation has validated the proposed method. Results of a real data analysis are also presented as an illustrative example.,"Fluctuations,
Cardiology,
Lungs"
Ultra-high-resolution brain SPECT imaging: simulation results,"A three-dimensional hemispherical SPECT (single photon emission computed tomography) brain imager with a multiple-pinhole coded aperture and modular scintillation detectors has been built. This instrument achieves a reconstructed volume resolution of 4-5 mm. Very high detector spatial resolution can even further improve reconstructed resolution. The authors have designed a novel submillimeter-resolution gamma-ray detector using a hybrid combination of a semiconductor detector and a time-integrating multiplexer readout instead of scintillation detectors and photomultipliers. In order to study the effects of high detector resolution on reconstructions, they have performed computer-simulation studies of a hemispherical brain imager system. Reconstructions were performed using an iterative search algorithm on a custom-designed parallel computer, from a calculated system matrix relating all voxels in the object space to all pixels on the detector. A resolution close to 2 mm on the reconstructed images obtained from these simulations is found.",
A high resolution cardiac mapping system,"We have developed a 256-channel high resolution cardiac mapping system consisting of electrode sensor arrays, analog signal conditioners, data acquisition interfaces, a host computer and software. The system has been designed to achieve low noise level, wide amplification range, and continuous recording capability. The system has been designed and developed for high resolution cardiac mapping and other applications.",
Software development with transformable components,A software development environment for describing and utilizing domain specific abstraction mechanisms is described. DARMS (Design Abstract Representation and Manipulation Shell) is a prototype environment which has been developed over the past three years.,
VLSI implementation of a dynamic retina,"The authors report on efforts to construct a silicon retina that generates output signals in real time outputs that correspond directly to those of biological retinas. It uses the principle of signal aggregation and demonstrates a tolerance for device imperfections that is characteristic of a collective system. The proposed silicon retina responds only to variations in the intensity of black and white light. The output of the retina is analogous to the output of the ganglion cells in the vertebrate retina. Its components operate well above the threshold voltage, i.e., each component operates in a voltage range of 0-5 V, while the current reaches few tens in an ampere.",
Extended model variety analysis for integrated processing and understanding of signals,"The authors extend their previous work (Nawab and Lesser, 1991; Weiss et al., 1991) on model variety analysis of a signal processing algorithm with respect to the class of all input signals that may potentially arise in a given signal understanding application. This analysis has two related objectives. The first objective is to partition the set of all possible signals in the application domain into two sets according to whether each signal is correctly or incorrectly processed by the signal processing algorithm under consideration. The second objective of model variety analysis is to characterize the nature of the distortions in the signal processing output for the cases where the input signal is incorrectly processed. The results of model variety analysis are useful for designing signal understanding systems for applications where it is necessary for the signal processing to be carried out in a situation-dependent manner. Model variety analysis and its usefulness for the design of signal understanding systems are illustrated through examples involving the use of short-time Fourier transform (STFT) processing for a sound understanding application.",
Comparison of noise removal techniques used in digital mammography,"Four distinct methods have recently been proposed for noise removal in mammography images: a tree-structured iterative selective median filter, a selective median filter, an improved median filter, and a weighted majority minimum range filter. These four methods, along with two general noise removal techniques, and the three standard techniques of mean, median, and k-nearest neighbors, are compared. A simulated mammography phantom to which varying levels of binary and Gaussian noise have been added is used. Two methods of measuring noise, a normalized root mean squared error and a signal-to-noise ratio, were used to compare and rank the nine different filters. There are no clear winners in all categories. Further research is needed to discover whether, by combining the best features of the best filters, one can produce a significantly improved method of noise removal.<>",
A systematic approach for designing systolic arrays,"The authors show that the problems of determining the existence of a valid transformation and finding an optimal valid transformation (if it exists) for a given nested loop algorithm can be computed easily. Their strategy exploits restricted row operation and normal form of integer matrix as well as the concept of the generalized inverse of a non-square matrix. In particular, three procedures, corresponding to three different rank values of the given dependency matrix, are proposed.",
A Robust Model Reference Control Using Variable Structure Design the General Case for Multivariable Plants,"Motivated by the recent works in parameterization of multivariable plants [1] [2], a new robust model reference control scheme using variable structure design (VSD) concept is proposed in this paper which contributes to improve the performance of the control system. The main contribution of this paper is the extension of [5] into multivariable case with unmodeled dynamics and output disturbances. Furthermore, the control strategy using the concept of ""average control"" rather than ""equivalent control"" is also analyzed.",
Software visualization and Yosemite National Park,"As software systems grow in size and complexity, so does the difficulty of understanding and maintaining them. Research in software understanding attempts to mitigate this problem by making various aspects of software development more visible, accessible, and comprehensible. The authors propose a hypertext-based approach to software visualization in which navigation in software-space is modeled after physical navigation in Yosemite National Park. Physical navigation capabilities are mapped into the domain of software development, where a user of a software-project visualization system navigates among interrelated units of information. They use the metaphor to define a set of requirements for the visualization system. They define linguistic constructs for a navigation language to be used in software-world. They discuss practical implications of implementing the visualization system.",
Formal derivation of an efficient parallel 2-D Gauss-Seidel method,"Presents a formal derivation of a highly efficient parallel implementation of the 2-D Gauss-Seidel method for machines based on the two-dimensional mesh of processors. A methodology is illustrated which formalizes the process of mapping and scheduling a high level algorithm onto a particular target parallel architecture. It starts from a simple initial program. Equational transformations are then applied: to partition the abstract problem onto processors; to make communication among processors explicit; to pipeline the computation by wave-front scheduling; and finally to map logical processors onto physical processors for perfect processor utilization. All the derivation steps preserve equalities so that the derived programs are equivalent to the initial program. Using this methodology, the paper develops efficient implementations for other parallel architectures.",
Distributed computing on Cayley networks,"The authors study the bit-complexity (i.e. total number of bits transmitted) of computing Boolean functions on anonymous Cayley networks. They present a simple group-theoretic characterization of the Boolean functions computable on a given Cayley network and also give an efficient algorithm for computing all such functions. For many networks of interest, the algorithm is the most efficient known. The complexity bounds derived from the present results are the best known for several networks of interest, including rings, tori, hypercubes, and star-, pancake- and bubble-sort networks.",
Disjunctive strictness analysis,"The problem of constructing a disjunctive strictness analysis for a higher-order, functional language is addressed. A system of disjunctive types for strictness analysis of typed lambda -calculus is introduced, and the types are used to define a program logic for strictness analysis. A disjunctive abstract interpretation is then obtained as a sound and complete model of the program logic. The results extend earlier work on using the tensor product of lattices to analyze disjunctive properties of programs by abstract interpretation.",
The case for independent updates,"The authors present the case for allowing independent updates on replicated databases. In autonomous, heterogeneous, or large scale systems, using two-phase commit for updates may be infeasible. Instead, the authors propose that a site may perform updates independently. Sites that are available can receive these updates immediately. But sites that are unavailable, or otherwise do not participate in the update transaction receive these updates later through propagation, rather than preventing the execution of the update transaction until sufficient sites can participate. Two or more sites come to agreement using a reconciliation procedure that uses reception vectors to determine how much of the history log should be transferred from one site to another. They also consider what events can initiate a reconciliation procedure.",
Design and performance of the DELPHI data acquisition system,"The data acquisition system of the DELPHI experiment at LEP allows the recording of data from the front-end electronics of 15 different detectors housed in about 100 Fastbus crates. Each detector has the possibility of monitoring its data in parallel with the global data acquisition as well as of running in a stand-alone mode. A description is presented of the design of the system and the performance achieved so far. Emphasis is given to the readout system, and an overview is provided of the systems for control and monitoring.","Data acquisition,
Detectors,
Hardware,
Monitoring,
Laboratories,
Counting circuits,
Event detection,
Software tools,
Computer architecture,
Acceleration"
Generalizing the hop: object-level programming for legged motion,"A model-independent method for controlling a hopping robot is presented. The approach focuses on the interaction between the hopper and its surroundings at points of contact. It is only through reactions at contact points that a hopper can alter its momenta. A generalization of the virtual leg abstraction allows control programs to be expressed as constraints on the external forces and torques acting on the hopper. The relationship between the nature of the external contacts and motion control strategies is investigated. The approach was tested in simulation using the model-driven dynamic simulator Newton. The experiments demonstrate the utility of simulation for studying physical control problems. Through simulation, a broad range of design parameters can be easily tested to determine the limits of the control strategy.",
Decomposition of geometric-shaped structuring elements using morphological transformations on binary images,A unified technique to simplify the decomposition of various types of big geometric-shaped structuring elements into dilations of smaller structuring components by the use of a mathematical transformation is presented. The method can be applied to all types of ID gray-scale structuring elements to decompose them into dilations of smaller structuring components. The desired morphological erosion and dilation are equivalent to a simple inverse transformation over the result of operations on the transformed decomposable structuring elements. A strategy to decompose a large cyclic cosine structuring element is described. A technique for decomposing a two-dimensional convex structuring element into one-dimensional elements is also developed.,
Spatial reasoning based on multivariate belief functions,"The authors propose knowledge representation and evidence propagation schemes based on multivariate belief functions and present a medical image recognition system to demonstrate the effectiveness of their application to spatial reasoning. The proposed system, which is based on the blackboard architecture, can mimic the reasoning process of a human expert in identifying the anatomical structures in a set of correlated images acquired from X-ray CT and PD- and T/sub 2/-weighted MRI. In the blackboard-oriented system, different kinds of evidence provided by various knowledge sources form a hierarchy of evidential space to which the Dempster-Shafer theory is applied. The multivariate belief functions are used to represent domain specific knowledge such as rules or facts.",
An introduction to BagL,"Introduces a compilable program specification language, BagL. BagL is the result of a formal study to ascertain how data/control structure interaction can be abstracted. BagL meets the accepted properties of a 'good' language. BagL maintains a consistent level of abstraction; is extensible, orthogonal, concise, and unambiguous; and addresses software evolutionary issues. A visual interface for the formal BagL language is presented, as well as the syntax and informal semantics of BagL.",
The Use of Nonlinear Elimination in Steady-State Circuit and Device Simulation,,
Parameter Identification of Systems with Uncertain Dynamics and Disturbances,"A method is presented for parameter identification of systems with uncertain dynamics and input/output disturbances. The system model is in stable factor form and is assumed to contain both parametric and nonparametric uncertainty, but only parametric uncertainty, namely, unknown parameters, are identified from the available input/output data, which are contaminated by norm-bounded nonparametric uncertainty and disturbances. A finite-time energy bound of the perturbation due to nonparametric uncertainty and disturbances is constructed in real time and is used in the parameter identification algorithm to ensure monotone reduction of parameter errors.",
A clock net routing algorithm for high performance VLSI,"Presents a new algorithm, called FSTM ('feasible segment tree method'), for the clock net routing of high performance VLSI designs. To avoid the clock skew, FSTM constructs a binary tree such that for each internal vertex of the tree, the cardinality of its sub-trees are balanced and the distances to its children are equal. The authors evaluate their results in terms of wire length and delay time (by the SPICE simulator). Experiments show that the clock net trees routed by FSTM achieve 13% in wire length, 3% in maximum delay and 36% in clock skew improvement over previously published results.",
Time-normalization techniques for speaker-independent isolated word recognition,"Investigates various time-normalization techniques that are useful in the context of speaker-independent isolated word recognition. At the lowest level, the authors make use of LPC coefficients as the features to be normalized. The authors discuss the various methods by which one can normalize these features. To begin with, the authors arrive at a typical number of frames associated with a word. Then, the authors normalize all the training and test data to this number of frames. Initial results bring out the point that normalization techniques help in reducing the number of patterns with which the unknown has to be compared.",
Exploring GenNet behaviors-using genetic programming to explore qualitatively new behaviors in recurrent neural networks,"Until the recurrent backdrop algorithms came along, there was a widespread belief that no generally acceptable procedure existed to train nonconvergent networks. It is shown that recurrent backdrop is not the only algorithm capable of doing this. The alternative proposed uses the technique of genetic programming (GP), i.e., using genetic algorithms (GAs) to evolve output behavior in neural networks (called GenNets). At least one example of a GenNet is presented for each of three cases of time-dependent/independent inputs/outputs, and it is shown how GP techniques were used to evolve GenNets whose operating conditions satisfied the three cases. Some of the extraordinary properties of time-independent GenNets are discussed. The sophisticated behaviors generated by GenNets and recurrent backdrop algorithms are compared. It is claimed that the GenNet behavior is more flexible and interesting because it does not require the training process to be closely supervised.",
Time-Frequency Representations of Auditory Signatures,,
A Parallel Algorithm for the Multi-input Sylvester-Observer Equation,"We present a new algorithm for solving the Multi-input Sylvester-Observer Equation. The algorithm embodies two main computational phases: the solution of a series of independent equation systems, and a series of matrix-matrix multiplications. As such, the algorithm is well suited for a parallel machine. By reducing the coefficient matrix to lower Hessenberg form, one can implement the algorithm efficiently, with few floating-point operations and little workspace. We present experimental results on the CRAY Y-MP and the Siemens S600/10 that confirm the efficiency of our algorithm.",
Optimal allocation for partially replicated database systems on tree-based networks,The authors consider a partially replicated distributed database located on a tree network each of whose links may fail with a probability p. For small p they derive necessary conditions for optimal placement of copies in order to maximize the probabilities of successful read-only and write-only transactions. These results suggest several heuristics for general networks. Numerical results are presented.,
Application of analogical reasoning to pursuit of targets in robotics,"The authors suggest a new approach of target tracking by a robot. Robot joints are independently controlled. This research improves other research carried on decentralized control of automated systems in the Laboratory of Automatics and Computer Science of Marseille (LAIM) (Brun-Picard (1988), Carmona (1990). Previous research showed the feasibility of the decentralization of control algorithms. The authors propose to decentralize intelligence to improve the decentralized unit autonomy. The solution consists in associating an agent with a robot joint. Each agent is considered as an intelligent agent and is able to take account of previous trial experience. The authors show the feasibility of the implementation of learning in control systems. The learning process will improve the control system efficiency.","Distributed control,
Learning systems,
Robots,
Tracking"
Axiomatic semantics of a hardware specification language,"Formal hardware design verification is to examine whether a structural specification of a circuit meets its behavioral specification. Despite the progress in formal verification, there is a big gap between hardware designers and verifiers, partially because there are no common specification languages for them to use. The authors show that formal semantics could bridge such a gap. By providing an axiomatic semantics to an existing hardware design language called the Iowa logic specification language (ILSL), the authors show that a circuit description in ILSL can be automatically converted into a set of first-order formulas which is the semantic description of the circuit and is acceptable by an existing theorem prover called the rewrite rule laboratory (RRL). In particular, they show how iterative statements of ILSL are converted into recursive functions of RLL. Their work thus results in a uniform specification language in which both hardware design and automatic verification can be done.","Hardware,
Specification languages,
Bridge circuits,
Formal verification,
Signal design,
Computer science,
Cities and towns,
Logic design,
Logic circuits,
Laboratories"
A digital signal processing course based on lecture/laboratory integration,An integrated course on digital signal processing (DSP) based on theory and engineering practice is described. The course is organized as a unit containing a traditional lecture component on DSP theory interacting with a hardware based laboratory component containing experiments and projects. The innovative aspect of this course is the digital signal processing laboratory. It consists of DSP workstations which are built around a fixed-point digital signal processor. Concepts taught in the lecture component are analyzed in the laboratory so students can learn practical aspects in the context of a real system. The laboratory is organized into three modules and each module is examined in detail. A representative project performed in the laboratory is described.,
A module generator for high performance CMOS circuits,"The authors describe a timing driven approach to the problem of generating fast, area-efficient CMOS modules consisting of static combinational logic. This approach has its foundation in a unique CMOS layout style which offers good electrical properties suitable for implementing fast circuits. Circuit delays are optimized by the reduction of parasitic capacitance along the critical paths and by transistor reordering. By using a hybrid cost function in the simulated annealing optimization process, the layout area is optimized as well. Preliminary experimental results are presented.",
Tidy animations of tree algorithms,"In software visualization and algorithm animation it is important that advances in system technologies are accompanied by corresponding advances in animation presentations. The authors describe methods for animating three manipulation algorithms, one of the most challenging algorithm animation domains. In particular, they animate operations on pairing heap data structures which are used to implement priority queues. Their animations use tree layout heuristics and smooth transitions for illustrating intermediate algorithm states to promote viewer understanding.",
An asymptotically optimal parallel bin-packing algorithm,"The authors introduce a bin-packing heuristic that is well-suited for implementation on massively parallel SIMD (single-instruction multiple-data) or MIMD (multiple-instruction multiple-data) computing systems. The average-case behavior (and the variance) of the packing technique can be predicted when the input data have a symmetric distribution. The method is asymptotically optimal, yields perfect packings, and achieves the best possible average case behavior with high probability. The analytical result improves upon any online algorithms previously reported in the literature and is identical to the best results reported so far for offline algorithms.",
Effects of non-tip external forces and impulses on robot dynamics,"The dynamics of robot manipulation with arbitrary forces, torques, and impulses applied to any link in the mechanism are studied. Using the principle of virtual work, and formulating the Lagrangian dynamics with spatial vectors, a modification to a linear-time forward dynamics algorithm can express the equations of motion of a manipulator that has either time-varying or impulsive forces applied anywhere on the manipulator. This permits the efficient simulation of accidental contact, and of multiple contacts that arise naturally in dextrous manipulation. The authors have implemented the equations as part of a computer simulation of robot dynamics, to test the effects of various external loadings. The initial results were derived from the study of free, unpowered planar mechanisms of two and three links subject to gravity.",
An architecture for artificial realities,"VIDEOPLACE, a two-dimensional artificial reality system that perceives participants and generates a response to their physical behavior in 1/30 second, is discussed. Since it is the only system that comes close to this speed of response, its heterogeneous parallel processing architecture and synchronous software methodology are relevant to the design of other systems.",
Assessing user experience with CASE tools: an exploratory analysis,"The paper reports on the results of a survey of 19 large organizations in the Twin Cities of Minnesota. The survey gathered data on the experiences, expectations, realizations, and suggestions regarding the use of CASE tools. It focused on what they considered to be the critical success factors in the introduction and use of CASE. Most organizations had strong management support and a high ranking executive to champion the adoption and use of CASE. More organizations had made a commitment to use construction tools than design, and to use design tools than planning tools. Larger organizations were further along in their commitment to use CASE than smaller organizations.",
Finite amplitude acoustic propagation modeling using the extended angular spectrum method,"The angular spectrum method is a technique for modeling the propagation of acoustic fields between parallel planes. The technique may be used to predict an acoustic pressure field distribution over a plane, based upon a known pressure field contour at a parallel plane. In addition to the modeling of diffractive phenomena, the technique has been extended to include the effects of attenuation, dispersion, refraction, and phase distortion. Recently, the ability to predict the effects of finite amplitude propagation through nonlinear media has also been incorporated into the model. This paper focuses on the incorporation of the latter effect. The motivation behind this research and the theory upon which the model is based are summarized, and comparisons between experimental data and extended angular spectrum predictions are presented.",
Layout algorithms for DFD processors,Presents two algorithms that are useful for integration into CASE tools that support data flow diagrams (DFDs). They provide the means to relieve the user of the tedious task of making layout decisions by automating some of these decisions. The automatic layout algorithm yields to achieve a neat layout of the objects in a data flow diagram. The incremental placement algorithm adopts the layout algorithm and find its place in application like the replacement of a process object in a diagram with its child diagram.,
Detection of multiple faults in CMOS circuits using a behavioral approach,"Presents an approach for the detection of multiple stuck-open (SOP) and stuck-on (SON) faults in CMOS combinational logic circuits. It is proved that multiple SON and SOP faults do not mask each other. This is achieved using a behavioral analysis in which the maskable fault patterns are proved to be impossible. New testing approaches are proposed. Testing is implemented using a combination of two-pattern test sequences as well as universal test sets, as proposed in previous papers by different authors.",
Escaping the disk bottleneck in fast transaction processing,"An approach to avoiding the disk access bottleneck for transaction processing applications is described. The approach is based on the use of primary copy replication, and takes advantage of recent hardware advances such as inexpensive high-speed CPUs and networks, and uninterruptable power supplies. In addition to improving response time, the architecture increases overall availability and reliability. The work described is in a preliminary stage. The overall architecture and its motivation are discussed. File system techniques in the context of transaction processing are reported.",
An approach to multilanguage persistent type system,"One important concept established through research of persistent programming languages is orthogonal persistence. The techniques so far proposed for this concept are, however, limited to single language systems. This paper proposes a systematic method to achieve orthogonal persistence in a multilanguage system by combining a technique for higher-order remote procedure calls and a mechanism of orthogonal persistence in a single language system. The proposed method can be used to develop a multilanguage persistent type system, where any data of any types including higher-order functions can persist and can later be used from a different language. The necessary data conversion between languages is transparent to the user. In addition to an effective algorithm to implement a multilanguage persistent system, the authors system has rigorous type discipline and formal properties that enable them to show that multilanguage sharing preserves the intended semantics of persistent data.",
Lower bounds on the depth of monotone arithmetic computations,"Consider an arithmetic expression of length n involving only the operations (+,*) and non-negative constants. The authors prove lower bounds on the depth of any binary computation tree over the same set of operations and constants that computes such an expression. In their main result they exhibit a family of arithmetic expressions that requires computation trees of depth at least 1.5 log/sub 2/n-O(1). The authors also consider the family of arithmetic expressions defined by alternating 5-3 trees. For this family they show a tight bound of 5/(log/sub 2/15)log/sub 2/n+O(1) on the depth of any computation tree. This is the best known tight bound for any family of arithmetic expressions.",
Computational science experiences on the Intel Touchstone DELTA supercomputer,"Argonne National Laboratory's involvement in the Concurrent Supercomputing Consortium-the consortium that owns and operates the Touchstone DELTA System-has been motivated primarily by the need to make high-performance computing resources available to its computer science research groups and to those researchers using large-scale computation in their scientific work. Since early May 1991, when the Touchstone DELTA System (DELTA) was first installed at Caltech, Argonne has been actively using it to investigate a variety of scientific problems. In the present work, the author describes some experiences and progress in global climate modeling, computational biophysics, and computational quantum chemistry. He also draws some conclusions regarding the usability of machines like the DELTA.",
Context driven call: principles,"Context driven call (CDC), which allows the user to squeeze from the distributed system as much parallelism as possible, but without using new language constructions and without developing special parallel algorithms, is proposed. CDC is based on the client/server model, but the server can perform operations on client's behalf in parallel with the operations done by the client itself. The central abstraction in CDC is the remote object, which is a capsule with two elements: object state and object value. Permitting a weak dependency between the local and the remote object values, CDC provide more parallelism. By supporting strong object state consistency, it ensures proper concurrency control. The CDC application is a priori divided into two parts: a client, which is an executable program, and the corresponding application stub pool (ASP), which is a library. ASP consists of stubs that perform remote operations on the client's behalf. Compiling the ASP on the server's machine and loading it in bind time to the server, the client is able to customize the server for its own requirements.",
The object-oriented advantage in prototyping a remote file system,"The authors have prototyped a remote file system for the Choices object-oriented operating system that permits the caching strategy to be user selectable on a per file basis. Choices provides a convenient object-oriented toolkit for building file systems, which they employed, reusing code whenever possible. The client provides the driving force in the architecture. The server maintains a small cache, fulfills requests, and performs callbacks. The client supports both whole file caching and block caching. Only the client needs to be aware of the type of caching being used for a particular file. Different clients can provide different caching strategies at the same time but the data within a client it is kept consistent. The server and client cooperate to maintain the consistency of the file system via callbacks. Because of the object-oriented architecture of the Choices file system they were able to prototype the system in approximately 6 weeks. There was a significant amount of code reuse.",
Static representation of speech dynamics for isolated word recognition,"A static model (SM) in the form of a single vector is proposed to represent the temporal properties of a sequence of speech feature vectors. In contrast to a hidden Markov model which captures the conditional probabilities of state transitions of consecutive observations x/sup to //sub t/ and x/sup to //sub t+1/ over time, an SM captures their average joint probabilities of belonging to a pair of phonetic classes omega /sub i/ and omega /sub j/ without any Markovian assumption. SM is tested with isolated words derived from the TIMIT database as well as artificially created words. The vocabulary is a subset of TIMIT consisting of 21 words derived from the two 'sa' sentences spoken by 420 speakers. The artificial vocabulary of 10 words is designed to study the limitations of SM. Experimental results indicate that apart from a rather mild limitation of SM in handling a certain type of vocabulary, SM actually performs better than baselined continuous hidden Markov models (CHMM) in terms of recognition rate as far as isolated word recognition is concerned, and it takes only 60% of the time needed by CHMM in recognition.",
The expressive power of multi-parent creation in monotonic access control models,"Formal demonstration of equivalence or nonequivalence of different security models helps identify the fundamental constructs and principles in such models. The authors demonstrate the nonequivalence of two monotonic access control models that differ only in the creation operation for new subjects and/or objects; in particular, they show that single-parent creation is less expressive than multi-parent creation in monotonic models. The paper also demonstrates that in nonmonotonic models, multi-parent creation can be reduced to single-parent creation, thereby neutralizing the difference in expressive power. The nonequivalence proof is carried out on an abstract access control model, following which the results are interpreted in standard formulations. In particular, they apply the results to demonstrate nonequivalence of the schematic protection model (SPM) and the extended schematic protection model (ESPM). They also show how the results apply to the typed access matrix model (TAM).",
Integer sorting in O(1) time on an n*n reconfigurable mesh,"A constant-time integer sorting algorithm on a reconfigurable mesh is presented. More specifically, a sequence of n integers can be sorted in O(1) time on a reconfigurable mesh of size n*n. As applications of integer sorting, a constant-time algorithm to convert an edge-list representation of a graph to an adjacency-list representation and a constant-time algorithm to convert a parent-pointer representation of a rooted tree to standard form are described.",
A System For Planning And Executing Two-finger Force-Closure Grasps Of Curved 2D Objects,,
Algorithms for minimum-bend single row routing problem,"The objective function of this problem is to minimize the number of doglegs (or bends) per net. The problem is of critical interest in the design of high-performance multilayer printed circuit boards; it also finds application in over-the-cell routing and design of microwave ICs. The approach is based on a graph theoretic representation in which an instance of the single row routing problem is represented by three graphs-an overlay graph, a containment graph, and an interval graph. Using this graph representation, three algorithms for the minimum-bend single row routing problem are developed. It is shown that the algorithms have very tight performance bounds. In particular, it is proved that the maximum number of doglegs per net is bounded by O(k), where k is the size of the maximum clique in a certain graph representing the problem.",
Paperless manufacturing for IC assembly,"The ongoing paperless manufacturing programs in application-specific integrated circuit (ASIC) assembly operations are described. Drawbacks of paperwork and approaches to paperwork elimination are discussed. Two projects related to paperless manufacturing in ASIC assembly are presented: an automated marking system project, which minimized operator input during product marking operation, and an electronic specification system project, which facilitated point-of-use specification retrieval. Some aspects of an integrated shop floor control system that addresses process control and lot tracking issues are discussed.",
Implementation of relational database operations in optics,"Optics have some very interesting attributes that can have a major impact on the performance of future database management systems. Among these attributes are high speed, massive parallelism, and non-interference of light beams. The impact of optics can be felt at all levels; storage, interconnection and processing. The authors introduce a hybrid opto-electronic system based on a highly parallel optical database processing unit. They discuss the architecture and indicate how various relational database operations can be performed optically. They present algorithms for each of the operations along with corresponding timing equations. The relational operations include union, set difference, intersection, projection, selection, and equi-join. Initial results of a performance analysis indicate that 10/sup 11/ tuple comparisons per second are possible.",
An optimal pairing scheme in associative memory classifier and its application in character recognition,"An optimal pairing scheme in associative memory classifier is discussed, especially when Hadamard vectors are selected as inner codes. As such a scheme is applied to recognize a set of multi-font Chinese characters, an improvement in the classification performance of this associative memory network is observed.",
The Dharma scheduler-definitive scheduling in Aurora on multiprocessors architecture,"In any Or-parallel system which implements the full Prolog language, such as Aurora, there is the problem of processing time being wasted in regions of the search tree which are later pruned away. The author proposes the Dharma scheduler, which introduces a new concept in scheduling for Aurora. Rather than performing scheduling based on the nodes in the search tree, the Dharma scheduler uses the branches of the tree. The author believes that scheduling at this higher level of abstraction has a number of advantages and will make it possible to tackle the problem of wasted speculative work. Early performance results suggest that the Dharma scheduler is faster than any other existing scheduler for Aurora in applications where only the first solution is required. The author presents the design of the Dharma scheduler and performance results.",
Knowledge acquisition support environment (KASE),"A knowledge acquisition support environment (KASE) is described that assists the knowledge engineer from the initial elicitation of domain expert knowledge through the actual prototyping of a working knowledge-based system (KBS). The KASE system is based on the commercially available KMS hypermedia system. Salient aspects of KASE include a collaborative environment, an easy to use interface, hierarchically structured templates to record knowledge, extensive validation capabilities, and creation of facts, rules and properties in an intermediate knowledge canonical form to allow prototyping. KASE had been successfully used to acquire knowledge for a complex expert system.<>",
Experiments and comparison of inference methods of regular grammars,"Some common algorithms for regular grammatical inference with different regular grammars have been tested in order to clarify how they can consider those languages. The methods of so-called successor, canonical derivative, k-tails, tail-clustering, and skeleton have been examined experimentally. The two last-mentioned methods were shown to be the best and the most general when inferring regular grammars that were close to minimal initial grammars used to generate input strings for the inference process. It was noticed that the quality of the inferred grammars depends to a considerable extent on the properties of input strings.",
A productive user environment for generating progress notes,"Describes the implementation methodology of an intelligent progress note system which is designed to support physicians in writing problem-oriented progress notes. The authors are currently developing their system on PCs in Microsoft Windows 3.0 by using Spinnaker Plus. The conversion of the system from a PC base to Macintosh or OS/2 has proven to be easy. The design applies cognitive models of memory as well as hypermedia to provide a creative and productive environment for the physician. The basis of the work is observation of practicing physicians writing progress notes in today's paper-driven world. The hope is to simulate some of the more routine parts of the thinking processes that physicians devote to producing the progress note, to save time, and to provide useful reminders, so that the users can concentrate on the more complex parts of the task.",
Writing sequential programs for parallel processors: implementation experience,"The PRAM model has proven to be a fertile ground for algorithm development. However, it assumes that processors operate synchronously, whereas shared-memory multiprocessors are asynchronous and are likely to remain so. This has motivated development of asynchronous PRAM models. Observing the dependence constraints implicit in a computation allows the author to design a large class of synchronous algorithms which run correctly on asynchronous processors without degradation in either time or work bounds. Of great practical interest is his use of randomization for dynamic load-balancing, dealing with asynchrony and providing transparent parallelization. This allows him to give a sequential specification for a parallel algorithm. This, in turn allows him to write sequential programs for parallel processors. He discusses his experience implementing asynchronous PRAM algorithms on shared memory multiprocessors.",
Narada: an environment for specification and execution of multi-system applications,"Describes Narada, an environment in which multi-system; applications can be defined using high-level specifications, without dealing explicitly with the details of task synchronization and data exchange. Once an application is defined, it can be executed automatically, providing location transparency and resolving most of the hardware and software incompatibilities. The paper discusses the task specification language used by Narada and shows how it can be used as an intermediate execution language for multidatabase query languages and to support various extended transaction models. The paper also discusses how programs specified in this language can be executed in a heterogeneous computing environment consisting of autonomous software systems.",
Dynamic reordering of high latency transactions using a modified micropipeline,"An asynchronous architecture for dynamically reordering sequences of instructions issued to a processing element is presented. The optimizations supported are the exchange of two instructions and the cancellation of an instruction using its predecessor. The design is a modification of I. Sutherland's (1989) micropipeline, and is called the asynchronous reordering micropipeline (ARM). The optimizations to be effected by the ARM are captured using rewrite rules that transform instruction subsequences into more optimal (and semantically equivalent) subsequences. One application of the ARM is in optimizing transactions issued to a system called the rollback chip (RBC), which is used to accelerate the state-saving and rollback activities performed by a processing node when it runs distributed discrete-event simulation using time warp.",
Knowledge-based matching for 3D radiotherapy planning,"Develops a system that performs segmentation and recognition of major organs in CT images of human abdomen for 3D organ reconstruction used in radiotherapy. A knowledge-based system has been developed that features the use of constraint-based dynamic thresholding, negative-shape constraints to rapidly rule out infeasible segmentations, and progressive landmarking that takes advantage of the different degrees of certainty of unsuccessful identification of each organ. The results of the experiments indicate that the knowledge-based approach is promising.",
Formal Specifications are Mathematical Example from Robotics,,
Mapping tree-structured computations onto mesh-connected arrays of processors,"The author shows how to parallelize tree-structured computations for d-dimensional (d>or=1) mesh-connected arrays of processors. A tree-structured computation T consists of n computational tasks whose dependencies form a task tree T of n constant degree nodes. Each task can be executed in unit time and sends one value to its parent task after it has been executed. The author presents linear time algorithms for partitioning and mapping the task tree T onto a p/sup 1/d/*. . .*p/sup 1/d/ mesh-connected array of processors so that one can schedule the processors to perform computation T in O(n/p) time, for p",
An experiment in software redundancy with diverse methodologies,"The goal of this experiment was to study the possibility of achieving highly reliable software using an approach to software redundancy with diverse methodologies. The experiment was similar to an experiment done by Knight and Leveson (1986) except that two different programming methodologies were used. Data from the experiment were analyzed using the simple statistical model for multiversion programming developed by Knight and Leveson and the more sophisticated statistical model of Eckhardt and Lee (1985), to see if results were consistent with the previous results for a single methodology. A still more sophisticated statistical model due to Littlewood and Miller (1989) was used to assess the effectiveness of using diverse methodologies.",
Fast read-only transactions in replicated databases,"The authors present a propagation mechanism, called the commit propagation mechanism (CPM), which increases the availability of data for read-only transactions. The proposed mechanism is piggy-backed on the messages used in the two-phase commit protocol. The CPM was combined with the standard quorum protocol in two different replicated database systems. In a fully replicated database, CPM allows any read-only transaction to execute locally at a single site without the need for any communication overhead. In a partially replicated database, CPM either ensures that the set of copies residing at a site are mutually consistent, or indicates which copies violate such consistency.",
A New Clustering Algorithm For Multispectral Remote Sensing Imagery,,
Linear programming supporting Ada-tasking static analysis: a Petri net approach,"Basing on the algebraic representation of Petri net models of Ada tasking programs, the authors have defined a set of linear programming problems to support the static analysis of various queries about tasking behavior, such as queries about deadlock existence, possible parallelism, possible occurrence of an event, reachable states, definite occurrence of events, and quantitative questions. The linear programming problems are defined in such a way that their solutions can be used to guide net simulation to confirm the analysis conclusion. The stress of this method is that the enumeration of the entire state space of a Petri net is avoided. The defined problems are valid as long as the underlying net model is a safe net.",
"Comments on ""Dynamic programming approach to optimal weight selection in multilayer neural networks"" [with reply]","The commenter claims that in the above-titled paper (ibid., vol.2, p.465-467, July 1991), which presents an efficient algorithm using dynamic programming to find weights which load a set of examples into a feedforward neural network with minimal error, a contradiction lies buried in the paper's notation. In reply, the author maintains that the comments are due to some misunderstandings about the implementation of dynamic-programming-based algorithms and clarifies the work.",
An architecture for query processing in persistent object stores,"Query optimizers for persistent object systems should be extensible to react to user-supplied abstract types. Current architectures support only a single, non-extensible technique for controlling the optimization process. The authors propose an alternative to the current extensible architectures that will support multiple optimizer control strategies and the addition of new control strategies. The optimizer consists of a collection of optimization regions, each of which can transform queries according to a particular control strategy, set of transformations and cost model. A global optimizer control coordinates the movement of a query between these regions. This architecture provides extensibility in the optimizer's repertoire of control strategies through the addition of new regions. The authors describe their approach and demonstrate its utility by following the optimizer as it works on an example query. The optimizer will move the query between three distinct regions. The different regions illustrate different kinds of transformations and different strategies for application of those transformations.",
Dynamic load balancing algorithms in loosely-coupled real-time systems,"The authors study dynamic load balancing algorithms in loosely coupled hard-real-time systems. The gradient model, focused addressing and the bidding methods are used. The gradient model entails transferring backlogged tasks to nearby idle processors according to pressure gradient indirectly established by request from idle processors. The focused addressing node uses network-wide surplus information in determining the target node to send excessive tasks to. Busy nodes in the bidding method send out requests for bids to migrate tasks that are not to be completed. In the model, each job is divided into a hard task and a soft task. All hard tasks must be finished by their deadlines and will not be migrated to other nodes. If a soft task cannot be completed by its deadline, it can be migrated to a neighboring node with less load or more surplus CPU time. Three load-balancing algorithms were evaluated.",
The evolution of employee empowerment,"The authors present the evolution of employee involvement programs into empowered self-directed work teams (SDWTs) to drive continuous improvement methodologies. With the primary goal of increased manufacturing performance and customer satisfaction, SDWTs are responsible for the day-to-day operations and directions of existing wafer fabs at Harris Semiconductor in Palm Bay, Florida. The authors specifically focuses on the transformation of an employee involvement program into SDWTs to improve key fab performance indices such as throughput yield (TPY), cycle time, performance-to-schedule, and reduction of costs. The process focuses on required skill sets, necessary training to achieve these skills, support group formation, and a performance incentive program. The results described include 10% improvement in TPY over seven quarters; 70% reduction in cycle time over seven quarters; 30% improvement in die yield over seven quarters; and 7.3% budget savings realized from gainshare program during the first two quarters of implementation.",
Design and implementation of the real-time internet protocol,,
An axiomatic approach of software functionality measure,"Three axioms for functional complexity of software are proposed. The first axiom asserts that functional complexity is a function and is computable at the specification level. The second axiom argues that an empty specification has zero functional complexity. The third axiom asserts that a harder specification has no less functional complexity than an easier one. With these three axioms and various definitions of the notions of functional complexity, a number of theorems are proved. Code metrics, including statement count, M. Halstead's (1977) programming effort, and T. McCabe's cyclomatic number are reviewed, together with specification metrics including L. Hellerman's (1972) metric, D. Schutt's (1977) metric, N. Coulter's (1987) metric, and A. Albrecht's (1983) functional point. These metrics are evaluated with respect to the three axioms. Results show that code metrics do not satisfy these axioms, while Hellerman, Schutt, and Coulter metrics do.",
Quantitative Modeling of Soil Genesis Processes,,
Dynamic object management for distributed data structures,"In distributed-memory multiprocessors, remote memory accesses incur larger delays than local accesses. Hence, insightful allocation and access of distributed data can yield substantial performance gains. The authors argue for the use of dynamic data management policies encapsulated within individual distributed data structures. Distributed data structures offer performance, flexibility, abstraction, and system independence. This approach is supported by data from a trace-driven simulation study of parallel scientific benchmarks. Experimental data on memory locality, message count, message volume, and communication delay, suggest that data-structure-specific data management is superior to a single, system-imposed policy.",
"Comment on ""Modeling a shared-load k-out-of-n*G system","The commenter states that there is no reason to perform the steady-state analysis as attempted by J. Shao and L.R. Lamberson (see ibid., vol.40, no.2, p.205-9, June 1991) for a Markov chain that has an absorbing failure state. Corrected expressions are provided.",
A near-optimal parallel algorithm for edge-coloring outerplanar graphs,"The article presents a parallel EREW PRAM algorithm that runs in O(log/sup 2/n) time using n/logn processors to optimally color the edges of an outerplanar graph. The algorithm improves the best known algorithm in both time, and number of processors. This more efficient algorithm is a result of a new approach for solving the problem. Also presented is a parallel EREW PRAM algorithm that runs in O(logn) using n/logn processors for finding a maximal matching in outerplanar graphs.",
System development with integration architectures,"The concepts presented in this paper show a possible alternative of the existing post-facto, bottom-up approach used in developing an integrated system. Based on the needs of distributed and complex application systems, the authors propose a pre-planned development process. This integrated approach introduces the notion of a meta-level of control and management which coordinates otherwise independent projects. Domain analysis and integration architectures are identified as the two main components of the proposed generic integration framework. Finally, they describe project management as an embedded sub-task in a generic, domain oriented development effort.",
Improving statistical speech recognition,"A summary of the theory of the hybrid connectionist HMM (hidden Markov model) continuous speech recognition system is presented. Experimental results indicating that the connectionist methods can significantly improve the performance of a context-independent HMM system to a performance close to that of the state of the art context-dependent system of much higher complexity are given. Experimental results demonstrating that a state of the art context-dependent HMM system can be significantly improved by interpolating context-independent connectionist probability estimates are reported. The development of a principled network decomposition method that allows the efficient and parsimonious modeling of context-dependent phones with no independence assumptions, is reported.",
A probabilistic approach to query processing in heterogeneous database systems,"In heterogeneous database systems, partial values can be used to resolve the interoperability problems, including domain mismatch, inconsistent data, and missing data. Performing operations on partial values may produce maybe tuples in the query result which cannot be compared. Thus, users have no way to distinguish which maybe tuple is the most possible answer. The concept of partial values is generalized to probabilistic partial values. The authors develop a full set of extended relational operators for manipulating relations containing probabilistic partial values. With this approach, the uncertain answer tuples of a query are associated with degrees of uncertainty. That provides users a comparison among maybe tuples and a better understanding on the query results. Besides, extended selection and join are generalized to alpha -selection and alpha -join, respectively, which can be used to filter out may be tuples with low possibilities-those which have possibilities smaller than alpha .",
An object-oriented environment for simulation and evaluation of architectures,"Reports on an object-oriented package that was designed and implemented to help prototype different architectures. To this purpose, a package of classes was created to give the user of the package the ability to prototype various systems. The package affords the user the capability to prototype complicated systems which can have one or more of each of the following: memory, loader and/or CPU, as well as their subcomponents. The system is provided with a debugging facility so that a user can trace the execution of the hexadecimal jobs, one instruction at a time, using the four windows of the debugger.",
Performance evaluation of local real-time schedulers,"Through the use of a simulation study, the authors show how the effectiveness of a scheduling algorithm varies depending on the metric of interest and the execution environment under which it runs. They describe the timing requirements of real-time jobs. Three measures of response time controls are described. The model of a scheduling algorithm's execution environment is described, followed by a discussion on the variations in execution environment necessary to investigate adequately the behavior of a given scheduling algorithm. A simulation case study is described. A description of the modeling and simulation of a single processor running M job classes is included. Two scheduling algorithms for controlling response times are described, the results of running three scheduling algorithms under varying execution environments are presented.",
Visual-aural representations of performance for a scalable application program,"Visual and aural portrayals of parallel program execution are used to gain insight into how a program is working. The combination of portrayals in a coordinated performance environment provides the user with multiple perspectives and stimuli to comprehend complex, multidimensional run-time information. An open question for either medium is how well does it scale? That is, how effectively can it be used to represent program performance on a large parallel computer system? This paper investigates using sound in conjunction with graphics to represent the performance of a scalable application program, the SLALOM benchmark program, executed on the nCUBE 2 distributed memory parallel computer. Custom auralization software is coupled with the PICL and ParaGraph tools. The techniques and results of visually and aurally monitoring program execution on increasing numbers of processors are presented.",
A real-time knowledge processing executive for Army rotorcraft applications,The authors describe research in the development of a real-time knowledge-based system execution environment suitable for use in next-generation Army helicopters. They first describe the unique problems which must be solved in real-time knowledge processing applications. They then describe an overall processing architecture for achieving the requisite real-time performance. The execution environment is being specifically designed for embedded applications such as the mission equipment package of the RAH-66 Comanche helicopter. The environment will provide the requisite software execution facilities which heretofore have not been available in an integrated embedded execution environment. This execution environment will provide the control features required to manage real-time problem solving.,
Complex objects in the temporal object system,"In many engineering applications, changes to the state and/or structure of an object needs to be maintained over a period of time. Existing object-oriented data models allow such changes in the state (referred to as version management) and structure (referred to as schema evolution) of an object. However, when the structure changes, the old structure is replaced by the new one. The authors propose a temporal object system (TOS) which maintains changes to both the structure and the state of an object. Objects in this system are referred to as temporal objects and are allowed to evolve over time. The authors discuss how to extend TOS in order to construct complex temporal objects from an aggregation of temporal objects.",
Issues and problems in the I/O subsystem. I. The magnetic disk,"For many years, processor cycle times have continued to increase at a very rapid rate. On top of this, advances in multiprocessor technology have allowed potential system performance to increase at an even faster rate. The result is that the performance of many of today's computer systems is limited by the I/O subsystem. In this paper, the authors attempt to do two things: (1) separate I/O space into three categories, based on their very different raisons d'etre and consequently very different characteristics, and (2) focus on the issues pertaining to improving the performance of one basic mechanism in the I/O subsystem, the magnetic disk. They do the former in order to set the framework of the I/O space. (If one is to improve the performance of the I/O subsystem, one, first has to understand the nature of I/O and not cloud one's efforts by treating I/O as one homogeneous structure.) They do the latter as the first step in dealing with the various mechanisms that make up the I/O space.",
Visual author languages for computer-aided learning,"It would seem that some of the most successful applications of visual programming have been in problem domains that are fairly restrictive and well-defined. It is swiftly becoming realized that the creation of educational courseware is one such domain for which are investment of visual programming effort is amply repaid by the pedagogical benefits. Visual languages in this class range from, at one extreme, purely textual programming languages tailored to the manipulation of graphical elements, through languages that are highly visual but which involve the use of textual instructions for low-level operations, to (at the other end of the spectrum) true visual languages for courseware authorising. In this paper, the authors describe their research work on evaluating the suitability of the various approaches to visual authoring.",
A survey and classification of hypertext documentation systems,"The authors describe and classify different hypertext documentation approaches by surveying a number of existing systems. They comprehensively list features of each system but do not numerically compare systems because of the subjective nature of evaluation. Instead, the data provided should be used as a basis for local comparisons by the reader. The classification breaks systems down according to publishing type, i.e. those designed for both publishing and accessing hypertext, either publishing or accessing documentation, and those that use general-purpose hypertext systems for document production and presentation. These categories are further subdivided according to functionality and specific system information.",
The Spice of Writing: Extracurricular Projects for Technical Writers,,
Multiagent planning using a reason maintenance system,"The article presents an application of reason maintenance systems for distributed reasoning about actions in multiagent planning. An important problem in multiagent planning is reasoning about shared resources. An action proposed by one agent on a shared resource may, in general, affect the status of the partial plans of other agents. The article maintains the dependencies of states of resources on actions. It employs a distributed truth maintenance system. It records the negotiations in the dependency net and demonstrates how distributed backtracking can be performed in case of dead ends or inconsistencies arising in the local/global worlds.",
An integrated access control in heterogeneous distributed database systems,"Integrated access control combines mandatory access control (MAC) and discretionary access control (DAC) together, with MAC based on a lattice of sensitivity labels and DAC based on individual and group access privileges. The necessity for integrating MAC and DAC arises in an open, heterogeneous multidatabase system. An integrated access control, which can provide a new and general framework to access control in heterogeneous distributed database systems (HDDBSs), is reported. The integrated access control, placed at the level of global data manager in each site, is used for security enforcement in an HDDBS. The global data manager maintains a data dictionary that contains metadata describing the global schema of the multilevel databases, clearances of users, security classifications of data, and access authorizations. Integrated access control restricts both access to information and the flow of information only in authorized ways.",
Effect of local ischemia on induction of cardiac reentries,"In this paper, we study the effects of local ischemia on the process of triggering of reentry mechanism. We present computer simulations based on a cellular automata model of the propagation of the depolarizing wave through a ventricular surface element. We simulate a local area of ischemia where effects of refractory period dispersion are investigated. We use a gaussian distribution of the refractory periods characterized by a mean value and a standard deviation. These simulations show that there exist critical conditions necessary to initiate a reentry mechanism invading progressively the whole ventricle.",
Building information system requirements using generic structures,"The author presents generic knowledge to speed up the construction of information system requirements and, more importantly, the behavioral part of entities. The solution is based on the hypothesis that generic structures independent of a particular application can be associated to classes of real-world phenomena. These structures can be reused in the development of different projects. The hypothesis is that there exists classes of similar real-world phenomena which are described using identical structures. A generic structure describes either the static and behavioral properties of a class of phenomena. Designing an application can be seen as the recognition of these phenomena and the instantiation of the associated generic structures. The formalism used to express the generic knowledge is presented, namely the triple . A presentation of generic knowledge with examples is given. The use of such knowledge is illustrated through an example.",
A model and methodology for distributed integration,The authors identify some of the problems in integration. They give a survey of the various integration strategies that have been proposed in the literature. The success of these integration strategies depends heavily on the characteristics of the application and choosing the appropriate strategy has been for the most part done subjectively. What is needed is a general model which allows the authors to quantitatively explore the tradeoffs and select a strategy or combination of strategies. They propose such a model for the integration process based on graph theory. Their model provides a quantitative method for comparing the different integration strategies to be used for integrating a particular system. Another issue in systems integration is maintaining the consistency of assumptions made by different software engineers. They suggest a technique to keep track of consistent assumptions during the development process.,
Reuse of Plans As a Tool for Development of remote Sensing Expert Systems,,
Organizational modeling using virtual agents and virtual communities,"The concepts of virtual agents and virtual communities are introduced. Based on these concepts, a remote procedure dispatching (RPD) scheme and an ambassador model are proposed. While virtual agents and virtual communities are images of remote agents dynamically created and maintained by a local agent as computer network domain objects, the RPD scheme supplements remote procedure call by allowing remote procedures to be dispatched to remote sites, and the ambassador model allows an image or an ambassador of an agent to be dispatched to remote hosts. Then, the virtual agents can be organized into virtual communities for coordination purposes. The major advantages of this approach lies in its flexibility for agent-oriented unilateral protocol selection and protocol change. Thus, it provides a supplement to the client-server model for organizational modeling. A prototype design and implementation are presented. The basic ideas are illustrated with an example in information retrieval and business administration.",
Performance evaluation of a traffic control mechanism for ATM networks,"A traffic control mechanism capable of monitoring and controlling a rich family of incoming traffic behavior is introduced. The traffic control mechanism is capable of supporting a number of different cell time scale control and resource allocation schemes. For each of a variety of incoming cell sequence time behaviors and a given control and resource allocation scheme, the grade of service that can be provided by the traffic control mechanism is determined. Some possible roles for the traffic control mechanism in a traffic control infrastructure are presented along with the detailed performance analysis. Some new results on the stochastic behavior of a bursty source are included.",
The stages of evolution of information systems functions: Findings in the Bahrain environment,"An evaluation and comparison, using Nolan's stage model, is made of the organizational IS (information system) functions in selected business organizations in the environment of a developing country, namely, Bahrain. A linear framework was developed by combining selected features of five benchmark variables. The empirical study validated certain aspects of the stage model. The research also showed that Nolan's growth model was applicable, with certain contingency adjustments, in the environment of a developing country. The sample firms were primarily distributed between growth stages 2 and 4. The findings also demonstrated that IS growth stage and its performances were primarily determined by the policy and strategy of top management in supporting the IS functions, and, to a lesser extent, by the length of experience in IS usage.","Information systems,
Management information systems,
Technology transfer,
Business,
Application software,
Information management,
Technology management,
Computer science,
Instruction sets,
Cities and towns"
"Adapting AVS to Support Scientific Applications As Heterogeneous, Distributed Programs",,
A calculus of dataflow networks,"A CCS-style calculus of dataflow networks with a standard structural operational semantics is defined. A version of weak bisimulation equivalence, called buffer bisimilarity, is defined for this calculus, and its equational theory is investigated. The main result is a completeness theorem for proving equations valid under buffer bisimilarity. The axioms have a familiar, category-theoretic flavor, in which a dataflow process with m input ports and n output ports is represented by an arrow from m to n in a category whose objects are the finite ordinals.",
Formal analysis of waiting times for distributed real-time processes,"An approach to automated timing analysis of distributed real-time programs is presented. The method is based on the static analysis of the task system and generation of global operation (GO) paths for which the timing analysis is applied. It is shown that a closed form solution algorithm is NP-complete. In order to more efficiently determine maximum waiting times for tasks sharing resources, even for large programs with many tasks, a reduced flow graph problem is defined by neglecting the differences in the execution times of the local operations. A solution for this problem gives an upper bound for the original analysis problem. A conjecture that the reduced problem is NP-complete even for two tasks is disproved by giving a formally correct polynomial time solution algorithm. The maximum number of steps for computing the maximum waiting for the reduced problem is linear with respect to the numbers of task's server requests.",
N-learners Problem: Fusion Of Concepts,,"Interconnected systems,
Contracts,
Sensor fusion,
Computer science,
Intelligent systems,
Laboratories"
Integrative engineering program for modern converging technologies,"The Chinese University of Hong Kong aims to produce a new breed of engineers who can adapt to the rapid development in high technology, particularly the modern converging technologies, by introducing an integrative engineering program which centers around electronics, computer science, information technology, and computer-aided engineering. The program was introduced in August 1988 and entered its second year with a first-year intake of 145. It is expected that the first-year intake will be doubled by 1994, and it is planned that in the near future, the integrative engineering program will include other disciplines, such as systems (manufacturing) engineering and materials engineering.",
UPP graphs and UMFA networks-architecture for parallel systems,"A graph with unique path property (UPP) has 2/sup n/ vertices and a unique path of length n between every two vertices. These graphs are very important in the design of architectures and algorithms for interconnection networks. Given two UPP graphs, an algorithm is introduced to determine isomorphism between the graphs. A construction is given for nonisomorphic UPP graphs and a lower bound of 2/sup x/, where x=(2/sup n+1/-3-2)/9, nonisomorphic graphs with 2/sup n/ vertices is shown. UMFA (uniform minimal full access) networks are multistage interconnection networks that use the same interconnection pattern between every two consecutive stages. These networks are derived from UPP graphs, and the most known network of this type is the Omega network. The problem of rearrangeability of UMFA networks is discussed.","Multiprocessor interconnection networks,
Algorithm design and analysis,
Tree graphs,
Parallel processing,
Computer science"
Arthur Samuel: Pioneer in Machine Learning,"Professor Emeritus Arthur L. Samuel died July 29, 1990, in Stanford, california at the age of 89. He was a pioneer of artificial intelligence research whose life spanned a broad personal and scientific history.",
Newthink - An Orwellian specification language for real-time safety critical systems,"We are currently experiencing an explosion in the use of computers in safety critical applications, particularly in the guise of embedded, real-time systems. Recent standardization activities in the United Kingdom and elsewhere have highlighted the safety implications of such massive deployment of computer software. The use of formal methods is often advocated as a way of increasing confidence in such software. Here, we describe our on-going work on an orwellian methodology for the development of safety critical real-time systems with particular reference to practices advocated by recent standards",
NLUS-a Prolog based natural language understanding system,"NLUS is a Prolog-based natural language understanding system, which exploits multi-knowledge representation formalisms. Sentences input from the user are converted into semantic networks and/or production rules; whereas the grammar rules are represented in predicate logic. After processing a sentence, the software may initiate its inference engine to deduce a response. A question would also be parsed and converted into a semantic structure which may contain possibly some missing information. To find an answer to a question, the missing information may be extracted from another related semantic structure in the working memory. At present, the software can handle sentences with relatively simple syntactic structures and some restricted types of questions. However, intelligent man-machine dialogues can be realized. It is particularly good at handling the rule-oriented type of sentences and is considered a decent prototype for experimenting with natural language understanding.",
Solving bandwidth and priority domination problems of DQDB metropolitan area networks,"The bandwidth domination problem (BDP) in the distributed queue dual bus (DQDB) medium access control (MAC) protocol could occur if the network bandwidth is dominated by a single node when it is active early and other nodes having heavy traffic demands are active later. The priority domination problem (PDP) is the problem that the network bandwidth may be dominated by an upstream node with lower priority when it is active early and other nodes with higher priorities are active later. To solve the BDP a mechanism is provided such that the bandwidth can be shared among all active nodes. To solve the PDP a mechanism is provided such that nodes with higher priority can capture all the bandwidth. The authors propose two adaptive algorithms to solve the BDP and a priority mechanism to solve the PDP. The adaptive algorithms and priority mechanism were evaluated by simulation. It is also shown that if the adaptive algorithms and priority mechanism are combined together, then the nodes with highest priority can use all the bandwidth and the bandwidth can be balanced among these nodes rapidly.","Bandwidth,
Metropolitan area networks,
Media Access Protocol,
Access protocols,
Adaptive algorithm,
Counting circuits,
Computer science,
Electronic mail,
LAN interconnection,
Workstations"
Two fast data acquisition and processing systems for a compact gamma-camera,"A compact gamma-camera has been constructed using a 3-mm-thick single NaI(Tl) crystal viewed by a 5-in-diameter Hamamatsu position-sensitive photomultiplier tube (R3292). In order to use this system in applications where the counting rate is high, such as in dynamic scintigraphy and industrial nondestructive testing, a fast data acquisition and processing system is very important. The design and operation of two fast data collection and processing systems capable of handling events within 30 mu s are presented. One of the systems is based on the use of a commercial Vector 32C/8500 processor board, while the other makes use of multiple T805 transputers. A comparison of the two systems is presented.",
Low-cost flexible simulation with the static perfect shuffle network,The static perfect shuffle (shuffle-exchange) network is based on H. S. Stone's (1971) perfect shuffle network; the two-by-two switches are removed and replaced by exchange links between processors. The network could be used in a low-cost flexible simulator for other networks such as multistage cube networks and hypercubes. The simulation of switched networks and of static networks is discussed.,
The Steiner tree problem with minimum number of vertices in graphs,"The Steiner tree problem is to find a tree in a connected undirected distance graph G=(V, E, d) which spans a given set S contained in V. The minimum Steiner tree for G and S is a tree which spans S with a minimum total distance on its edges. The authors consider a special case of the Steiner tree problem in graphs. For this problem they assume that the underlying graph G does not have any direct edge between the vertices in S contained in V. The problem is to find a tree in G which spans the vertices in S and uses minimum number of vertices in V-S.","Approximation algorithms,
Tree graphs,
Computer science,
Algorithm design and analysis,
Communication networks,
Wire,
Routing,
Very large scale integration,
Transportation,
Steiner trees"
Specification of real-time distributed database systems,"A unified framework is given for the specification of external consistency constraints, integrity constraints, and temporal consistency constraints of a real-time distributed database system. The formalism is event based and facilitates both relative and quantitative reasoning about time. The functional model of V.S. Alagar and G. Ramanathan (1991) is extended with constructs needed to specify the requirements of real-time databases. To illustrate the use of these constructs, the specification and proof of correctness of a real-time concurrency control protocol are presented.",
An improved classification tree analysis of high cost modules based upon an axiomatic definition of complexity,"Identification of high cost modules has been viewed as one mechanism to improve overall system reliability, since such modules tend to produce more than their fair share of problems. A decision tree model has previously been used to identify such modules. In this paper, a previously developed axiomatic model of program complexity is merged with the previously developed decision tree process for an improvement in the ability to identify such modules. This improvement has been tested using data from the NASA Software Engineering Laboratory.",
Single Phase Dynamic CMOS POS PLA,,
Lateral cortical inhibition without lateral inhibitory connections,"The authors consider how a set of neurons forming a cortical column, none of which individually can competitively distribute its activity, can function collectively to produce competitive distribution of activation. To address this issue, they describe a model cortical column composed of three populations of excitatory neurons that collectively distribute their activity competitively. The idea of competitive distribution and the neural circuitry that could bring it about are described. Computer simulation results, implications, and testable predictions of the theory are presented.",
Full and Reduced Order Observer based Controller Design for H2-Optimization,"In this paper the most general H2 control problem is considered. We derive necessary and sufficient conditions when the infimum is attained by state feedback. We do the same for the measurement feedback case where we derive necessary and sufficient conditions when the infimum is attained by proper dynamic compensators. We also investigate reduced order compensators if some states are observable without noise. We discuss for all of these cases the freedom that the non-uniquenes of optimal compensators gives us in assigning the closed-loop eigenvalues. The second half of this paper investigates the case when the infimum cannot be attained. We give a constructive algorithm to find a minimizing sequence of stabilizing controllers and discuss the freedom in the asymptotic locations of the closed-loop eigenvalues. Again we do the above for three different cases: static state feedback, full order measurement feedback and reduced order measurement feedback. Unfortunately, due to the space limitation, we are unable to put the results of reduced order compensator design in this proceedings.",
Lattice Boltzmann method on a cluster of IBM RISC System/6000 workstations,"There is a wide consensus among researchers that parallel computing is the most promising way to cope with the ever increasing quest of computational power raised by modern research in science and engineering. The specific way how parallelism is effectively implemented at the architectural level, remains, however still an open issue. An instance of parallel computing which is gaining a growing popularity is the one consisting of distributed environments built out of pools of networked workstations. The main merit of this approach, hereafter referred to as to 'cluster computing', lies in its cost effectiveness with respect to 'traditional' shared-memory supercomputers. A cost-effectiveness which is basically driven by the impressive development of fast RISC (reduced instruction set computer) microprocessors. An implementation of the lattice Boltzmann method on a homogeneous cluster of IBM RISC System/6000 superscalar workstations is presented.",
Activated hidden connections to accelerate the learning in recurrent neural networks,"A method of accelerating the learning in recurrent neural networks is considered. Owing to a possible large number of connections, it has been expected that recurrent neural networks will converge faster. To activate hidden connections and use hidden units efficiently, a complexity term proposed by D.E. Rumelhart was added to the standard quadratic error function. A complexity term method is modified with a parameter to be normally effective for positive values, while negative values are pushed toward values with larger absolute values. Thus, some hidden connections are expected to be large enough to use hidden units and to speed up the learning. From the author's experiments, it was confirmed that the complexity term was effective in increasing the variance of connections, especially hidden connections, and that eventually some hidden connections were activated and large enough for hidden units to be used in speeding up the learning.",
An investigation of the view update problem for object-oriented views,"An investigation of the view update problem for object-oriented views is presented. Views are formed using an object algebra that provides a set-oriented approach to the retrieval of objects. A view is defined to include an intension and an extension, where the extension of a view is updated by modifying objects in the scope of the query intension. The rich set of semantic constraints inherent in an object-oriented data model, enhanced with semantic modeling concepts, helps to make the effects of view updates explicit. The contribution of this research is the development of an approach for analyzing semantic constraints associated with the view intension to (1) identify alternative view update translations and (2) identify potential update side effects. The approach can be used to help in the design of view update operations that correctly reflect the intended semantics of the update.",
Generation and segmentation of motion trajectories,"Presents an algorithm for selecting and linking interesting flow vectors across a sequence of frames for computing motion trajectories. The authors track tokens which have both interesting pixel gray values in the spatial domain and in the optical flow field in the temporal domain. This and operation effectively removes some redundant trajectories. Due to errors introduced during the computation of optical flow, and the linking of such flow vectors across a sequence of frames, the resultant trajectories are not always smooth. The authors discuss a Kalman filtering based approach for smoothing the trajectories. This approach is also able to deal with the occlusion of feature points. The authors also present a simple algorithm for segmenting motion trajectories.",
Data acquisition studies for the Superconducting Super Collider,"A progress report is presented on the program for developing data acquisition systems for experiments at the Superconducting Super Collider Laboratory. Using the MODSIM II object-oriented discrete-event simulation language, a study is made of the behavior and interaction of various front-end circuits, data-collection chips, data-gathering networks, multilevel triggers, and buffer implementations. Results include system deadtime, throughput, and efficiency as they are influenced by data rates and system architecture.",
A hybrid architecture for a high performance and physical small low-level image processing system,"Deals with the hardware implementation of a low-level image processing unit for mobile autonomous systems. High processing performance and a small physical size of the sensor and processing unit are two important factors. The image processing unit described here combines between high system performance and flexibility. The emphasis for this design lies on two aspects, i.e. adapted processors, in this case SIMD processor-arrays, and guided data reduction by means of finding partial images.","Image processing,
Sensor systems,
Hardware,
Acoustic sensors,
Communication system control,
Control systems,
Image sensors,
Computer architecture,
Computer science,
Mobile computing"
Efficient bi-level reconfiguration algorithms for fault tolerant arrays,"Considers the problem of reconfiguring processor arrays subject to computational loads that alternate between two modes. A strict mode is characterized by a heavy computational load and severe constraints on response time while a relaxed mode is characterized by a relatively light computational load and relaxed constraints on response time. In the strict mode, reconfiguration is performed by a distributed local algorithm in order to achieve fast recovery from faults. In the relaxed mode, a global reconfiguration algorithm is used to restore the system to a state that maximizes the probability that future faults occurring in subsequent strict modes will be repairable. Several new results are given for this problem. Efficient reconfiguration algorithms are described for a number of general classes of architectures. These general algorithms obviate the need for architecture-specific algorithms for architectures in these classes. It is unlikely that similar algorithms can be obtained for related classes of architectures since the reconfiguration problem for these classes is NP-complete. Finally, a general approximation algorithm is described that can be used for any architecture. Experimental results are given, suggesting that this algorithm is very effective.",
Design For Reliabiltiy,,
Object-oriented programming testing methodology,"Inheritance is an important attribute in object-oriented programming (OOP). This notion supports the class hierarchy design and captures the is-a relationship between a class and its subclass. It contributes to food properties of modularity, reusability and incremental design. However, misuse of multiple (repeated) inheritance leads to an improper class hierarchy which suffers from name-conflict and implicit errors. This type of error is very difficult to detect by conventional testing methodologies. This paper describes a graph-theoretical testing methodology for detecting this type of error. An algorithm to support this testing methodology is also presented.",
How to denest Ramanujan's nested radicals,"The author presents a simple condition when nested radical expressions of depth two can be denested using real radicals or radicals of some bounded degree. He describes the structure of these denestings and determines an upper bound on the maximum size of a denesting. Also for depth two radicals he describes an algorithm that will find such a denesting whenever one exists. Unlike all previous denesting algorithms the algorithm does not use Galois theory. In particular, he avoids the construction of the minimal polynomial and splitting field of a nested radical expression. Thus he can obtain the first denesting algorithm whose run time is at most, and in general much less, than polynomial in description size of the minimal polynomial. The algorithm can be used to determine non-trivial denestings for expressions of depth larger than two.",
A fuzzy relaxation algorithm for matching imperfectly segmented images to models,"A graph theoretic approach for matching imperfectly segmented images with stored scene models is presented. The specific segmentation errors addressed are missing objects, extra objects, missing relations, and mismeasured attributes. By combining enhanced fuzzy relaxation and association graph techniques, the method integrates global inter-object relations and local object attributes to obtain more reliable matching.","Image segmentation,
Layout,
Computer science,
Computer errors,
Computer vision,
Navigation,
Geometry,
Image sensors,
Area measurement,
Reflectivity"
Zero-one laws for modal logic,"It is shown that a 0-1 law holds for propositional modal logic, both for structure validity and for frame validity. In the case of structure validity, the result follows easily from the well-known 0-1 law for first-order logic. However, the proof gives considerably more information. It leads to an elegant axiomatization for almost-sure structure validity, and sharper complexity bounds. Since frame validity can be reduced to a II/sub 1//sup 1/ formula, the 0-1 law for frame validity helps delineate when 0-1 laws exist for second-order logics.","Logic,
Vocabulary,
Computer science"
An expert system for forecasting model selection,"An expert system for forecasting model selection, written in Turbo-Prolog and implemented on a PC 386, allows a nonexpert in the forecasting field to utilize the relevant knowledge and use it to choose appropriate forecasting techniques. Detailed discussion of three components of this system-the knowledge base, the inference mechanism, and the user interface (explanation facility)-is included. An inference algorithm is proposed, which is capable not only of dealing with uncertainty of information, but also of searching paths in parallel and giving all solutions at once.",
A new framework for designing parallel algorithms on series parallel graphs,"The authors propose a novel framework for designing efficient parallel algorithms on series parallel graphs. Recently, a novel approach for recognizing series parallel graphs was presented by D. Eppstein. Eppstein explored characterizations of the ear decomposition of series parallel graphs, which can be identified efficiently, in parallel. The authors extend Eppstein's results and show in a unified manner how to solve problems on series parallel graphs efficiently, in parallel, by finding a special ear decomposition of the graph. They demonstrate the utility of their novel framework by presenting O(log n) concurrent read exclusive write (CREW) parallel random access machine (PRAM) algorithms for the construction of a depth-first spanning tree, st-numbering, and a breadth-first spanning tree on series parallel graphs.",
Complex system identification methods for fast echo canceler initialization,"The authors propose a new recursive version of a technique proposed by G. Long and F. Ling (1990) for the initialization of a data-driven echo canceler (DDEC). They prove that the Long and Ling algorithm yields a least-squares solution, and then a new technique is presented which is comparable to the recursive-least-squares (RLS) algorithm. However, the use of a unique training sequence reduces the complexity of the RLS algorithm to that of the least-mean-square (LMS) algorithm. An analysis of the covariance of the estimated weight vector is presented, and simulation results show a remarkable improvement in both convergence speed and steady-state error.",
Efficient rule matching in large scale rule based systems,"The paper presents an efficient rule matching algorithm for a large scale production system. The matching algorithm is state saving and does incremental evaluation. Implementation details are presented which include optimization of join tests, and efficient buffering of data blocks. A cost analysis, both in terms of matching evaluation cost and storage cost for the saved state is presented. Results from the performance study show that substantial savings in matching cost are obtained with little space overhead for the saving state. Matching becomes computationally intensive in a secondary memory environment, and efficient algorithms are a must for successful integration of production systems and databases. The authors show how the OPS5 and relational model are compatible, and thus implementation techniques in one domain are applicable to the other.",
Cutwidth approximation in linear time,"Graph width metrics have been widely studied for their relevance to VLSI design. Examples include cutwidth, pathwidth, bandwidth and several others that arise in circuit layout. When the width is bounded, graphs that satisfy these metrics can often be recognized by finite lists of obstruction tests. One of the most foundational tests is to determine whether K/sub 4/ is immersed in a graph. The authors present for the first time a fast, practical algorithm to perform this test, and discuss its relevance to cutwidth and other metrics.",
Parallel heap: improved and simplified,"Describes a new updated version of the data structure parallel heap. Employing p processors, a parallel heap allows detections of Theta (p) highest-priority items and insertion of Theta (p) new items each in O(logn) time on an EREW PRAM where n is the size of the parallel heap. Furthermore, it can efficiently utilize processors in the range 1 through n. This version does not require dedicated maintenance processors, and performs insertion and deletion in place.",
Design languages for cleanroom software engineering,"Choosing a good design language is essential for success in using the cleanroom software engineering techniques. The design language should be tailored to support the important aspects of cleanroom, most importantly, functional decomposition of intended functions and functional verification. To support these goals, a good design language should be capable of providing a high level of abstraction. Many existing implementation languages, such as C++, C, and PL/1, are suitable for this purpose, given appropriate guidelines on their use. These languages have the additional benefits of being familiar to users, and making the design-to-code step unnecessary. The paper describes the important principles in creating a design language for use with cleanroom software engineering. It then discusses the guidelines needed to produce a viable design language from one existing implementation language.","Software engineering,
Computer languages,
Guidelines,
Data structures,
Design engineering,
Programming,
Software testing,
Error correction,
Software design,
Sections"
Paradigms for the shaping of surfaces in a virtual environment,"This paper describes several paradigms for the direct manipulation of a surface in computer graphics. The surface is considered as a collection of points in three-dimensional space. These points may be the vertices of polygons, the control points of splines, and so on. Three paradigms are described and evaluated: direct grabbing of the surface at a single point and moving a neighborhood of that point; pushing on the surface with a tool; and pushing on the surface with a model of the user's hand. These paradigms are based on a spatially weighted transformation. This transformation is based on a 'bump' weight function on the surface which is shaped and placed by the user. Construction of the bump function and the definition of the weighted transformation is described. An interface for these paradigms in a virtual environment is also described.",
Optimal group diagnosis procedures for VLSI/WSI array architectures,"Addresses the problem of partitioning VLSI/WSI (wafer scale integration) array architectures into disjoint maximal diagnosis blocks (MDBs) and finding an optical group diagnosis policy for testing and locating faulty elements (modules) in these MDBs. The optimization criterion is to minimize the accumulated diagnosis cost in deriving a feasible reconfiguration solution. The technique for partitioning an array is based on the parallel partition approach. The problem of finding an optimal group diagnosis procedure is modeled as a (t+1)-ary decision tree, where t is the size of an MDB. Instead of dealing with a (t+1)-ary decision tree directly, the problem is further reduced to that of handling a binary decision tree or a block-walking representation. Properties related to the group diagnosis procedures and binary decision trees are derived. Simulation results are provided to further support the effectiveness of the proposed approach over other approaches.",
"Integrated computer-aided software engineering (CASE): adoption, implementation, and impacts","The introduction of integrated computer-aided software engineering (CASE) is beginning to have significant impact on business and information systems organizations. With integrated CASE, IS organizations can develop better quality systems faster to support critical business processes and to assist the development and marketing of information-intensive products and services. The paper first describes a technical architecture for integrated CASE. Then, an innovation process model is proposed to provide explanations and strategies for the adoption, selection, adaptation, implementation, and impacts of integrated CASE. Future research and development on integrated CASE are discussed.",
Transversality theorem: a useful tool for establishing genericity,"It is demonstrated, by way of examples in linear algebra and control, optimization, and geometry, that the transversality theorem of differential topology is a very useful tool for establishing the genericity of a property which is dependent on a finite number of real parameters and which is expressible using a system of nonlinear equations. Some of the results derived are nontrivial to establish by direct means without resorting to the use of the transversality theorem.",
Discrete neural networks and fingerprint identification,"The author has developed a general method for discretization of feedforward neural networks and has empirically demonstrated the usefulness of the method by successfully applying it to the nontrivial task of fingerprint identification. Surprisingly, the discrete neural network (DNN) developed in this way demanded just 4 b for the table representation of the sigmoid function, and only 6 b for the representation of the matching discrete solution. It is clearly shown that there is no significant difference in the performance on the test set between the real neural network and the DNN. Thus, it is concluded that the discretization methods proposed have shown themselves to be realistic.",
The benefits of service rebalancing,"Service rebalancing, which provides a way to determine an efficient division of effort between a client and its server, is introduced. Decisions concerning this division of labor are made at runtime rather than at design time. Evaluating the current environment in which the client and server are executing and moving mode between client and server based on this evaluation can enhance the performance of client/server programs. The advantages of service rebalancing include the elimination of a static division between client and server, on-the-fly updating of modules, load balancing, sharing of common code between multiple clients, and the enforcement of neatly modularized programming. Some of the problems and issues related to service rebalancing, including equanimity and the current status of the work, are discussed.",
CADDY: a highly integrated environment to support conceptual database design,"The authors describe the development of the computer-aided software engineering (CASE) environment CADDY (computer-aided design of nontraditional databases), which offers an integrated set of tools for specifying, analyzing, and prototyping a database application on a conceptual level. The development process consisted of a sequence of development steps, where each step corresponded to one of five main tasks. These five tasks are described. Remaining questions about the CADDY environment are discussed.",
Polarization Characteristics of Bianisotropic Materials,,
Manipulabilities Of Serial-parallel Manipulator Systems,,
Operational construction of integrity constraints,"Shows that data and knowledge base integrity constraints can be regarded as queries. This allows the author to use his visual query language Vizla for the construction of constraints in an operational style. The primary tool for this is the Vizla filter, which lets through only those elements of a set that satisfy a filter predicate. The main contribution of the paper is a method of using filter predicates as constraints, but fuzzy integrity constraints are also considered.",
The Lambda time slot permuter: a bit-controlled time slot permuter,"The authors formulated a general method for constructing time slot permuters from spatial permutation networks. Using the method, they constructed a new time slot permuter, the Lambda time-slot permuter. The Lambda time slot permuter is obtained from the bit-controlled, self-routing permutation network, the Lambda network. While the Lambda time slot permuter requires more hardware than the time slot permuter based on the Benes network described by S.V. Ramanan et al. (1990), its control is very simple. In the Lambda time slot permuter, a single bit from the destination tag in the first of a pair of time slots entering an exchange element is used as the control bit so that the switch setting can be done before the second time slot arrives; thus, it is possible that the switch setting does not incur any delay. The Lambda time slot permuter is suitable for a class of applications where on-the-fly control of the time slot permuter is important, and is especially efficient for a pipelined operation.",
Integrating semantic inference in a probabilistic approach to information retrieval. II,"For pt. I see Proc. of ICCI 1992 Conf. (1992). Semantic-based approaches and probabilistic approaches are actually used in information retrieval separately. Their integration allows the semantic-based approach to be endowed with a well-founded theoretic background, and the probabilistic approach to be evaluated with semantic consideration. The paper demonstrates that such an integration is sound theoretically. Using several concepts developed in the study of subjunctive conditionals, a modal logic model is proposed which is capable of describing the approach suggested in part I, and it is proved to be a probabilistic model.",
Theory and method research of software environment for developing expert decision support system,"The authors discuss the theory and method of a software environment for developing an expert decision support system. Combined with the discussion of some issues such as knowledge representation and acquisition; management of knowledge base, database and model base; inference mechanism; etc., a specific expert decision support system development environment (EDSS-DE) developed by the authors is introduced. Experiments show that the design goal of EDSS-DE is fulfilled.",
Rapid connectionist speaker adaptation,"SVCnet, a system for modeling speaker variability, is presented. Encoder neural networks specialized for each speech sound produce low-dimensionality models of acoustical variation, and these models are further combined into an overall model of voice variability. A training procedure is described which minimizes the dependence of this model on which sounds have been uttered. Using the trained model (SVCnet) and a brief, unconstrained sample of a new speaker's voice, the system produces a speaker voice code that can be used to adapt a recognition system to the new speaker without retraining. A system which combines SVCnet with a MS-TDNN recognizer is described.",
A neural network model for route planning constraint integration,"The ability to plan routes that avoid obstacles and achieve mission goals in a timely fashion is a requirement in ground, air, and undersea autonomous systems. A neural network solution to route planning based upon the Hopfield model is presented. The translation of the terrain information into the Hopfield network representation is discussed. Primary emphasis is placed upon the generation of an energy function capable of representing the planning and mission constraints common to all three operating domains. Utilizing the energy function based upon goal point distance, terrain gradients, and feedback of the vehicle's altitude data, results are shown demonstrating the route planning capability on actual terrain database imagery. Ongoing efforts to integrate the route planner into an overall vehicle planning scheme are discussed.",
A new algorithm for order statistic,A new algorithm for rank filtering and stack filtering is presented here. This algorithm is simple and results in fast and easy implementations. It is based on transforming the given sequence into equivalent rank preserving sequences by means of bit manipulation. The algorithm can also implement stack filters without requiring threshold decomposition.,
Pulse propagation on a semiinfinite horizontal wire above ground: Near-zone fields,"The near zone electric field distribution due to a transient current pulse propagating on a semiinfinite wire above the ground is investigated. A quasi-transverse electromagnetic approximation to the modal equation for the propagation wave number is used to obtain the time history of the pulse on the wire. Spectral domain techniques are then used to obtain an expression for the electric field. In the resulting two-dimensional Sommerfeld integrals, representation of the angular integral in terms of incomplete Lipschitz-Hankel integrals allows for the efficient computation of the frequency domain near and intermediate zone fields. A numerical inverse Fourier transform is then applied to obtain the transient response. Numerical results, presented in both the time and frequency domains, Me used to determine when the previously obtained far zone approximations can be applied. The results in this paper are for the quasi-transverse electromagnetic component of current; however, similar techniques can be applied to the Earth-attached and continuous modes.",
Associative parallel lexing,"Presents near constant time associative parallel lexing (APL) algorithms. The best time complexity thus far claimed is O(logn) (n denotes the number of input characters for the parallel prefix lexing (PPL) algorithm. The linear state recording step in the PPL algorithm, which needs to be done only once for each grammar has been ignored in claiming the log n time complexity for the PPL algorithm. Furthermore, the PPL algorithm does not consider recording line numbers for the tokens and distinguishing identifier tokens as keywords or user-identifiers. The APL algorithms perform all of these functions. Thus, without considering the efforts spent on these functions, the APL algorithm takes constant time since every step depends on the length of the tokens, not on the length of the input. Generalizing and including these extra functions, the APL algorithm takes near constant time.",
Portable parallel Level-3 BLAS in Linda,"Describes an approach towards providing an efficient Level-3 BLAS library over a variety of parallel architectures using C-Linda. A blocked linear algebra program calling the sequential Level-3 BLAS can now run on both shared and distributed memory environments (which support Linda) by simply replacing each call by a call to the corresponding parallel Linda Level-3 BLAS. The authors summarise some of the implementation and algorithmic issues related to the matrix multiplication subroutine. All the various matrix algorithms being block-structured, they are particularly interested in parallel computers with hierarchical memory systems. Experimental data for their implementations show substantial speedups on shared memory, disjoint memory and networked configurations of processors. The authors also present the use of their parallel subroutines in blocked dense LU decomposition and present some preliminary experimental data.",
Single plane model extension using projective transformations and data fusion,A priori knowledge of the relative positions of four or more coplanar points or lines is used to derive the positions of other points and lines on the same plane in a manner invariant to camera location and intrinsic camera parameters. A framework for data fusion in the projective plane is presented to merge the position estimates of coplanar points and lines derived in this way.,"Geometry,
Cameras,
Transmission line matrix methods,
Solid modeling,
Computer science,
Calibration,
Computer vision,
H infinity control,
Topology,
Uncertainty"
Fast algorithms for matrix normal forms,"A Las Vegas type probabilistic algorithm is presented for computing the Frobenius normal form of an n*n matrix T over any field K. The algorithm requires O/sup approximately /(MM(n))=MM(n)/sup ./(log n)/sup O(1)/ operations in K, where O(MM(n)) operations in K are sufficient to multiply two n*n matrices over K. This nearly matches the lower bound of Omega (MM(n)) operations in K for this problem, and improves on the O(n/sup 4/) operations in K required by the previously best known algorithm. The author applies the algorithm to evaluate a polynominal g in K(x) at T with /sup approximately /(MM(n)) operations in K when deg g",
New dimensions of technical vitality distance learning,"The author states that one should not constrain oneself in one's vision of the future. One should approach it with an open mind and be an enabler who makes things happen. This is especially true in education and the author's remarks are directed primarily to continuing education and life-long learning for working technical professionals in the USA. These issues are discussed with reference to the corporate perspective, educational technologies, and satellite delivery.",
A VME barrel shifter system for event reconstruction for up to 3 Gbps signal trains,"A VME barrel shifter system for event reconstruction was developed for the SDC (Solenoidal Detector Collaboration) experiment. A special semi-custom switch IC was also developed for it. The system takes in fragments of a physical event through its inputs, combines and reorganizes them, and produces a complete data set of the event from one of its outputs. The complete output data set for successive events will be delivered to waiting computers at its outputs. Up to 3-Gb/s signal trains can be fed through the switch unit. This system is VME 6U compatible and the switching can be controlled by a commercially available VME module. The building blocks of this barrel shifter system are switch modules, O/E and E/O converter modules, and a dedicated crate. The switch modules are a dual-4*4/quad-2*2 unit and an 8*8 unit; they can be combined to deal with a very large number of input/output channels.",
A comparison of user interface research and development centers,"The trends of strategic pursuits for human interface research and development centers are important when planning and evaluating corporate decision making for product development. This article establishes four classes of computer platforms and analyzes the user interface research goals and the tools being developed to achieve those goals at leading research and development centers. The analysis is based on public documents and telephone interviews. Using the data collected and the analysis, trends in research are noted and interpreted. The resulting information is valuable for strategic planning in both engineering and marketing groups.",
Sharing a dynamic secret,"The authors propose a new finite ideal threshold scheme which provides Shannon perfect secrecy and can be used to handle the changeable master keys system in finite times without affecting any secret shadow. Since the idea was inspired by A. Shamir's (1979) threshold scheme, this threshold scheme is introduced. The definition of the finite ideal threshold scheme is given. The dynamic secret is described. The security analysis of the method is considered.",
A simulation environment for early lifecycle software reliability research and prediction,,
Performance comparison of active-sender and active-receiver policies for distributed caching,"The authors propose a distributed caching approach to off-loading data access requests from overloaded data servers in a distributed system to nodes that are idle or less busy. Helping out the busy servers on data accesses, the idle or less busy nodes are called mutual servers. Frequently accessed data are cached in the main memory of mutual servers in addition to server and client local caches. The authors evaluate several data propagation strategies among data servers and mutual servers. Simulation results show that the active-sender passive-receiver policy is the method of choice in most cases. Active-sender policies are best able to exploit the main memory of other idle nodes in the expected normal condition where some nodes are overloaded and others are less loaded. All active policies perform far better than the policy without distributed caching.",
A microprocessor-based office image processing system-an extension of work,"The authors extend the work done by L.M. Ni et al. (see ibid., vol.C-31, p.1017-22 (1982)) on microprocessor-based office image processing systems. Ni et al. did not distinguish between the compute-bound and I/O-bound state of the machine in the case where image input time is greater than the output time. The authors clearly show the above distinction and present the correct expressions for such cases.",
Two-state self-stabilizing algorithms,"A distributed system consists of a set of loosely connected state machines which do not share a global memory. All the possible global states of the system can be split up into legal and illegal states. A self-stabilizing system is a network of processors, which, when started from an arbitrary (and possibly illegal) initial state, always returns to a legal state in a finite number of steps. One issue in designing self-stabilizing algorithms is the number of state required by each machine. The paper presents algorithms which will be self-stabilizing while only requiring each machine in the network to have two states. Probability is used in some of the algorithms in order to make this possible. The algorithms are given along with correctness proofs.",
Animation for on-line documents-an end-user system using object-oriented constraints,"CBAD is designed to support mental abstraction of animation sequences and their components, freeing users from the need to deal with graphic representation, or implementation details and requiring no programming expertise. Using a metaphore based on movie directing, one creates animations in CBAD by assigning predefined animation actors with certain tasks. Complex behavior of predefined actors is achieved by establishing inter-actor relations, internally expressed as constraints maintained automatically by the system. Constraints are encapsulated and solved distributively.",
A relational model for the representation of mathematical programming models,"A first order predicate calculus for the representation of mathematical optimization models is developed. It is shown that the relational scheme of a database can be inferred from the algebraic representation of the optimization models. More importantly, it is shown that the indices for an iterated operator can be inferred. This inference results in the reduction of syntactical burden on users of systems which will be based on this model. Assuming a relational representation of data, a relational model for the expression of constraints and objective functions of the optimization models is introduced.",
A heterogeneous distributed database system based on extended relational model,"The most important requirement for a heterogeneous distributed database system (HDDBS) is the capability of providing an integrated view of its component databases that is transparent in data distribution and the heterogeneity of the components. While a HDDBS provides the logical integration of its constituent databases, it should preserve their autonomy. The authors propose a heterogeneous database management system which extends the relational model to integrate and capture the semantic heterogeneity of the component databases.",
Eigenfrequencies of non-collinearly coupled beams with dissipative joints,"A method for asymptotically computing the in-plane eigenfrequencies for the general two-dimensional beam structure is presented. The method allows dissipative joints between the beams. Calculations are then performed to find the vibrations for an example beam structure. The results are of interest in connection with the construction of large space structure, such as a large communication satellite or a space platform.",
Temporal constraints and their interpretations in natural language,"A series of extensions of tense theory of atomic events to accommodate durative events is presented. The interaction of tenses with time adverbials is discussed and a constraint for tense-adverb agreement is proposed. Sentences containing clauses connected by a temporal connective, such as 'when', 'before', 'after', etc. may have different aspect interpretations, depending on the situation types and verb forms involved. In particular, 'before' and 'after' are not always inverses of each other. One can adopt a similar mechanism to take account of this kind of sentence. Their temporal constraints are described, and their temporal interpretations can be obtained accurately.",
Inheritance and specificity. II. Reference class selection,"For pt.I see Proc. of 4th Internat. Conf. on Computing and Info. (1992). The author examines the problem of reference class selection within the context of Bacchus (1990) and Halpern's (1989) combined probability logic. He introduces the idea of second order randomization where the independence properties of particular predicates are based on the independence properties of randomized predicates. This is a natural extension to first order randomization, where the degree of belief in a proposition about a particular individual is based on the statistical properties of randomized individuals. This approach solves problems involving conflicting sources of statistical knowledge that present difficulties for many other approaches.",
Deterministic vs. nondeterministic transitive closure logic,"It is shown that transitive closure logic (FO+TC) is strictly more powerful than deterministic transitive closure logic (FO+DTC) on unordered structures. In fact, on certain classes of graphs, such as hypercubes or regular graphs of large degree and girth, every query in (FO+DTC) is first-order expressible. On the other hand, there are simple (FO+pos TC) queries on these classes that cannot be defined by first-order formulas.",
An open system architecture for a persistent object store,"The authors describe an open system architecture for a persistent object store which is able to support a disparate range of persistent programming languages and their individual requirements. The ideal architecture would combine the flexibility and safety of a highly modular system with the performance of a tuned production system. The authors present an approach towards the ideal by realising part of the interface to the persistent object store in terms of conventions. This permits the costly use of interfaces to be circumvented on the basis of trust. The persistent object store may be used to construct programming language specific instances of the open architecture. To date the open architecture has been used to implement the persistent programming language Napier88, the functional programming language STAPLE, the object-oriented database programming language Galileo and the typeful programming language Quest.",
The vesicular dataflow model,The Vesicular Dataflow (VDF) model is presented in the paper. The VDF model has been formulated to introduce a way of storing and retrieving information and hence to reduce the main drawback of the basic DF model. Tokens can be stored in vesicles in the VDF model and then distributed in non-deterministic way. State-dependent computations and global variables can be expressed in the dataflow manner. Informal definition of the VDF model and some simple applications are covered by the paper.,
Performance-driven interconnection optimization for microarchitecture synthesis,"The interconnection synthesis problem in microarchitecture-level designs is addressed. With emphasis on the speed of data movement operations, algorithms are proposed that take into consideration the effect of each data-transfer-to-bus binding on the data transfer delay time. Two types of problems are considered: resource-constrained binding and performance-constrained binding. The integer linear programming (ILP) formulations are derived to optimally solve these problems. In order to speed up the computation, a bipartite weighted matching method for the resource-constrained binding and a greedy merging method for the performance-constrained binding are also proposed. Experimental results indicate that the proposed algorithms are very effective.",
Parallel preconditioning and approximation inverses on the Connection Machine,"The authors present a new approach to preconditioning for very large, sparse, non-symmetric, linear systems. It explicitly computes an approximate inverse to the original matrix that can be applied most efficiently for iterative methods on massively parallel machines. The algorithm and its implementation on the Connection Machine CM-2 are discussed in detail and supported by timings obtained from real problem data.",
Decomposition of data flow diagrams,"Data flow diagrams are an important design aid in system development. CASE tools allow data flow diagram construction and modification to be automated. Decomposition is the top-down development of a data flow diagram starting with the system inputs and the system outputs. Decomposition may also be automated, resulting in an interactive process for data flow diagram design. Adler (1988) described an algebra for the decomposition of data flow diagrams. A set of quality measures was also described. The authors show that these quality measures do not correspond to the intuitive notion of a good decomposition. A new set of criteria is proposed which does correspond to the intuitive notion of a good decomposition. The use Adler's algebra leads to an inefficient decomposition process, as well as one which is not guaranteed to find a good decomposition. The authors give an efficient algorithm which gives a good decomposition.",
A fluid model approximation to quantitative information feedback in congestion control,"A new approach for deriving quantitative information for rate-based congestion schemes is presented. Using the fluid model, it is shown that the bottleneck capacity can be estimated from round trip delay when the sender is increasing its traffic rate linearly. The exact solution for a time-dependent M(t)/M(t)/1 queue verifies that the approximation is accurate when the traffic load is high. The analytical results were verified with simulation experiments, and the practical issues in applying the estimation techniques in congestion control schemes are discussed.",
Efficient hierarchical interconnection for multiprocessor systems,"The authors present a novel approach to the design of a class of hierarchical interconnection networks for multiprocessor systems. This approach, based on an architecture providing separate networks for each level, gives a general and flexible way to construct efficient hierarchical networks. The performance and cost-effectiveness of the resulting networks are analyzed and compared in detail, using both unbuffered and buffered network models. It is shown that, if the design parameters are determined based on the degree of locality, the cost-effectiveness of a hierarchical network can be significantly improved. In addition, the authors investigate how to construct a cost-effectiveness hierarchical network by determining appropriate design parameters. Two associated algorithms are developed for this purpose.",
Issues concerning software reuse-in-the-large,"Software reuse is the reapplication of artifacts and knowledge from the development of one system to another system, in order to reduce the effort of software development and maintenance of that other system. Software reuse can be classified in different ways according to different views. The authors view is that to classify software reuse in reuse-in-the-small and reuse-in-the-large is useful. After comparing the techniques which can be applied to these two kinds of reuse respectively, they are convinced that reuse-in-the-small is fundamentally limited by its inherent lack of information about improving the whole process of software development and maintenance. They believe that, these limitations can be overcome by applying reuse-in-the-large which, therefore, is more likely to be a challenge to solve the software crisis and will continue to be a hot topic in the near future. The authors describe what software reuse is, why it is necessary, how it can be achieved, current achievements, research problems and their future work.",
High-order perceptrons for decoding error-correcting codes,"The authors prove that the single-error correcting (2/sup n/-1, 2/sup n/-1-n) Hamming code and its extended single-error correcting/double-error detecting (2/sup n/, 2/sup n/-1-n) code can be decoded by low-complexity single-layer perceptrons which use high-order polynomials as their discriminant functions. It is illustrated that multiple-error correcting codes can be decoded by two-layer networks with high-order perceptrons in the first layer and linear perceptrons in the second layer.","Decoding,
Error correction codes,
Multilayer perceptrons,
Polynomials,
Computer science,
Neural networks,
Hopfield neural networks,
Backpropagation,
Costs,
Law"
Combining multiple neural network paradigms and applications using SESAME,"SESAME (software environment for the simulation of adaptive modular system) has been developed to make experiments possible in fields like pattern recognition and control that combine different neural network models and learning paradigms in an elegant manner. SESAME represents an object-oriented integrated framework for experiments in pattern recognition and control. All experiment components are uniform building blocks, which can be put together arbitrarily by means of a common communication interface. Experiment substructures can be integrated to construct building blocks, which may be reused for other experiments. Examples drawn from different application domains and learning paradigms illustrate the potential of this approach.",
Characterization of the response of a double side mu -strip silicon detector to X-rays in the diagnostic energy range,The use of a double sided mu -strip silicon crystal for X-ray detection is being investigated. The detector is 300 mu m thick and the read-out pitch is 100 mu m for both sides. It operates in capacitance charge division mode by means of floating strips between read-out strips. The detector has been irradiated by /sup 241/Am and /sup 109/Cd sources. Different zones within the 100- mu m read-out pitch have been individually exposed. The following characteristics have been studied as a function of the impact point of the photon: (a) the charge collection mechanism; (b) the relative detection efficiency; (c) the energy resolution; and (d) the spatial resolution. The absolute efficiency of the detector has been measured at three energy values.,
Albatross - The communication scheme as a key to fulfil hard real-time constraints,"Based on experiences from an autonomous mobile robot project called MOBOT-III, we found hard realtime-constraints for the operating-system-design. ALBATROSS is ""A flexible multi-tasking and realtime network-operatingsystem- kernel,"" not limited to mobile-robot-projects only, but which might be useful also wherever you have to guarantee a high reliability of a realtime-system. The focus in this article is on a communication-scheme fulfilling the demanded (hard realtime-) assurances although not implying time-delays or jitters on the critical informationchannels. The central chapters discuss a locking-free shared buffer management, without the need for interrupts and a way to arrange the communication architecture in order to produce minimal protocol-overhead and short cycle-times. Most of the remaining communication-capacity (if there is any) is used for redundant transfers, increasing the reliability of the whole system. ALBATROSS is actually implemented on a multi-processor VMEbus-system.",
Improved parametric models and DPCM techniques for EGG data compiression,"This paper presents a novel algorithm for compression of single lead Electrocardiogram (ECG) signals. The method is based on Pole-Zero modelling of the Discrete Cosine Transformed (DCT) signal. An extension is proposed to the well known Steiglitz-Hcbride algorithm, to model the higher frequency components of the input signal more accurately. This is achieved by weighting the error function minimized by the algorithm to estimate the model parameters. The data compression achieved by the parametric model is further enhanced by Differential Pulse Code Modulation (DPCM) of the model parameters. The method accomplishes a compression ratio in the range of 1:20 to 1:40, which far exceeds those achieved by most of the current methods.","Brain modeling,
Electrocardiography,
Computational modeling,
Atmospheric modeling,
Data compression,
Presses,
Electroencephalography"
A reliable distributed system using dual level fault tolerance,"A reliable distributed environment was developed by beginning with a working distributed environment (POSYBL) that contained no explicitly implemented fault tolerant techniques, and augmenting the system with a dual level of fault tolerance. This created the fault tolerant POSYBL environment. Surveying of several current fault tolerant techniques and estimating the amount of reliability each technique would make towards a reliable distributed system showed that there does not exist a single practical fault tolerant technique that would handle half of a certain set of reliability concerns. Addressing less than half of the set of reliability concerns does not make a system fault tolerant for that set of concerns. Therefore, more than one technique was used to create the fault tolerant POSYBL system, which handles a majority of the listed reliability concerns.",
Some properties of exponential time complexity classes,"The authors separate NE from P/sub x/ (NP), where x=n/sup 0(1)/-T. The class EXP-low(1) is introduced and applied in the investigations of stable properties for both EXP and NEXP hard sets. A set A is in EXP-low(1)(EXP-low resp.) if EXP/sup A(1)/=EXP(EXP/sup A/=EXP). The authors separate EXP-low(1) from EXP-low by constructing a set A such that EXP/sup A(1)/=EXP and EXP/sup A/=EXP/sup EXP/.",
DNN-disciplined natural naming: a method for systematic name creation in software development,"Giving names to different concepts is a common activity that software developers have to do in their work. Typical nameable concepts are various program elements (variables, tables, structures, functions, etc.). The same information that is encoded in the names of program elements usually exists in other software documents, e.g. requirements definitions and design documents. Naming affects how readable and understandable software documents are. Every concept should always have the same name when it appears in any software document. Disciplined natural naming (DNN) is a method for creating names to be used in all software documents, from requirements definitions to source programs. DNN should be executed as the first step of software development. The tools of DNN are name creation tables and name templates which are used in a stepwise manner.",
Object allocation in distributed systems with virtual replication,"The authors investigate the problem of object allocation in a distributed environment with virtually replicated data. The traditional approach to improving data availability in a distributed system is to replicate data. A high degree of replication, however, imposes a serious burden to the system when updates are performed. Data inference can be used to reduce the degree of replication in the system while still providing high data availability. A model to allocate objects under such an environment is proposed. Rules based on application semantics are developed to reduce the search space for optimal allocation. Heuristic algorithms are proposed for allocation when the reduced search space is still prohibitively large. Examples are given to illustrate the effectiveness of the proposed algorithms.",
Identification in H∞ with nonuniformly spaced frequency response measurements,"In this paper, the problem of ""system identification in H∞"" is investigated in the case when the given frequency response data is not necessarily on a uniformly spaced grid of frequencies. A large class of robustly convergent identification algorithms are derived.",
Hybrid architectures for intelligent robotic systems,"Hybrid architectures, based on combinations of analogic, symbolic, and neural methods, are well suited for real-time applications in advanced robotics. Real-time industrial applications are mainly based on the correction of preplanned programs. So far, the planning and control modules of these kind of applications are often unable to react and/or classify un-expected events. The approach described attempts to integrate the sensor-based analogic method and the neural method into a multiple-level architecture that operates on an analogic world model, so that the action planning can be performed in a smart, reactive way. Given the task, the system builds the world model of the scenario. The reasoning and planning modules act both at the strategic as well as reactive levels, and the activated sensor-based motor strategies handle the sensorial data inputs and drive the robot controller module in the execution of the stream of motor commands. The interaction between the different levels is mainly based on the idea of maintaining and updating in real-time the world model, so that each module can locally operate on specific parts of the whole world model.",
GOOSY-VME: the data acquisition and analysis system at GSI,"The VAX/VMS data acquisition and analysis system GOOSY has been used for several years at GSI (Gesellschaft fur Schwerionenforschung, Darmstadt, Germany) and other laboratories. A VME-based, parallel working front-end system has been implemented and is in use for experiments. The system is described. Results from performance measurements are reported. Future developments are presented.",
An encoding rule of fuzzy associative memories,"A new encoding rule of memories with Max-Min composition units is presented. Under some condition, the proposed rule can efficiently encode multiple fuzzy pattern pairs in a single memory and perfect association of these pairs can be achieved. The correctness of the proposed rule is proved and an illustrative example given.",
Message based control of parallel high level depth and intensity matching,Considers dynamic message based control of cooperating depth and intensity algorithms to determine object identity and location in a multiple instruction multiple date (MIMD) environment. The authors describe message based cooperation between algorithms examining a single model and propose further levels of control which allow more complex systems to be built.,"Layout,
Parallel processing,
Computer science,
Image segmentation,
Heuristic algorithms,
Focusing,
Machine vision,
Process control,
Control systems,
Prototypes"
A simulation study of replication control protocols using volatile witnesses,"Voting protocols guarantee the consistency of replicated data objects by disallowing all access requests that cannot gather a sufficient quorum of replicas. The performance of voting protocols can be greatly enhanced by adding to the replicas small independent entities that hold no data but can attest to the state of the replicated data object. It has been recently proposed to store these witnesses in volatile storage. Volatile witnesses respond faster to write requests than those stored in stable storage. They can also be more easily regenerated as many local area networks contain a majority of diskless sites. The authors present a simulation study of the availability afforded by two voting protocols using volatile witnesses and investigate the impact of access rates, network topology and witness placement on the availability of the replicated data.",
Scheduling real-time computations with extended deadlines,"In many applications, a real-time job allows part of its computation to be finished after its primary deadline but before its extended deadline. The authors study the scheduling issues for real-time computations with extended deadlines. They call the part of a computation which must be completed before the primary deadline its hard part, and the rest its soft part. Two variations of this problem are studied. In the first model, the system receives a penalty for each late soft part. In the second model, there is an extra computation overhead for each late soft part. For each model, algorithms to produce a feasible schedule are presented.",
Fuzzy control of postoperative pain,"Post-operative pain is difficult to model, this difficulty being due to non-linearity, time varying behavior and intro and inter-patient variability. In this study, we describe the application of a two-stage fuzzy controller in the relief of post-operative pain. In the first stage, a fuzzy system operates until the required set-point (i.e. no pain) is attained, following which a CACI system, operating about the set-point, is used to avoid an increasing plasma concentration of opiate. The controller has been implemented in OPS-83 and in Microssoft-C.",
Time complexity of systolic array testing,"The testing time for a C-testable orthogonal iterative systolic array (OISA) is derived where no knowledge on cell functions are assumed. The test inputs are regenerated as inputs for some inner cells at some future times at known distances (regeneration distances) from the outputs of those cells which are currently being tested. For minimum test time, it is required that the test input with maximum regeneration distance be applied last. For the non-OISAs, reconfigurable functional routers in each cell is proposed. A non-OISA can be reconfigured into one or more OISAs.",
Supercomputing around the world,"In keeping with the 'Voyages of Discovery' theme of the Supercomputing 1992 conference, representatives of supercomputing endeavours from around the world have met to speak on national and international supercomputing activities. This minisymposium brings together international representatives from five areas of the world to discuss supercomputing activities in countries that have been underrepresented at the Supercomputing conferences in the past. The topics discussed are high-performance computing and networking in Europe, the supercomputing environment in Taiwan, supercomputing in Australia, India's initiative in massively parallel supercomputing, and supercomputing in Brazil.",
A metalanguage based on a theory of specification,"A specification metalanguage is presented for the purpose of describing and analyzing specifications written in existing specification languages. Specification theory-based metalanguage (STM) was developed to describe specifications in terms of components defined within a theory of specification. STM constitutes the application of theoretical definitions and analyses to individual specifications. The process of describing specifications in STM produces needed manual analysis, while the completed description can be automatically processed by the language processor and description simulator. A summary of STM features is presented. Manual analysis results are pointed out in discussing an example of STM description.",
Interpreting Science in Informal Settings: Opportunities and Challenges for Technical Communicators,,
A flexible modelling software for data acquisition,"Flexible modeling software for pulsed data acquisition is described which is based on an event-driven simulator. It can be used to simulate a wide variety of systems which can be modeled as open queuing networks. Modeling program techniques and applications in plasma physics laboratories are described, and an overview is given of the simulation technique.",
SAD kernels: a software tool to evaluate synchronization behavior of multiprocessors,"The authors propose a method to characterize the performance of multiprocessor systems at the level of a single grain, called a unit grain, of execution. The characterization is via experimental measurement of individual components of performance. The authors introduce a family of artificial workload kernels, called SAD-kernels, as an effective tool for measuring this performance. The usefulness of these kernels lies in their ability to selectively assess a given shared-memory multiprocessor along several performance dimensions that can be controlled by the person performing the evaluation. The proposed methodology was demonstrated by measuring and comparing the performance of two commercial shared-memory machines currently in use.","Kernel,
Software tools,
Data structures,
Degradation,
Protection,
Computer science,
Large-scale systems,
Current measurement,
Measurement standards,
Particle measurements"
Consistent singleton models of a temporal constraint network,"The authors provide an efficient algorithm that obtains consistent singleton models of a temporal network by applying a forward pruning technique for the search space. It is important that an intelligent system should be able to capture the notion of time and be able to reason about it. The primitives to represent times are points and intervals. An interval representation for time is used. Obtaining all the satisfiable models of a constraint network. even if the constraints are limited to the pointisable subset of interval relations, takes exponential time in the worst case. Therefore, any success in this area depends on efficient pruning techniques and heuristics. A technique based on pruning the search space is described.",
Operating systems support for collaborative work,"There are a cluster of new facilities that OSs should provide to next-generation software applications, of which collaborative applications form an important subset. Providing these facilities involves both the introduction of new mechanisms at the kernel level and the ability to extend these into what has traditionally been termed the user level, to provide the ability to tailor a computer system with respect to the kinds of object one can manipulate and the ways in which group members can perform such manipulations. Object-oriented operating systems are in a unique position to address the provision of these facilities, given the naturally open and extensible nature of object-oriented systems in general. Getting the correct kinds of openness and extensibility requires close collaboration with the potential users of the facilities. The authors urge the evolution of a symbiotic working relationship between the designers and implementors of next-generation object-oriented operating systems and CSCW tool implementors, in order to ensure that the appropriate facilities are provided.",
On average P vs. average NP,"Structures of polynomial-time computable distributions and polynomial-time many-one reductions on randomized decision problems are investigated. The scope is widened from the most studied class DNP (distributional-NP) to the class ANP (average-NP), which consists of randomized decision problems accepted by nondeterministic Turing machines in average polynomial time. Results indicate that the structures of average-case complexity classes are very different from their counterparts in worst-case complexity due to the complex structures of probability distributions and distribution functions.",
Neurocomputing methods for pattern recognition in nuclear physics-Elastic tracking,The recent progress on the development and application of novel neurocomputing techniques for pattern recognition problems of relevance to relativistic heavy ion collider experiments is reviewed. The elastic tracking (ET) algorithm is shown to achieve sub-pad two track resolution without preprocessing. ET can extend tracking capabilities to much higher densities than possible via conventional road finding or even previously proposed novel Hopfield network algorithms. ET is an adaptive template matching algorithm formulated in terms of dynamical systems.,
Second generation creativity support software,"While first generation creativity support programs have had successes in improving problem solver performance in idea generation tasks, limitations of this type of software have also become apparent. The paper identifies these limitations and describes design principles for and components of second generation creativity support software.",
Learning separations by Boolean combinations of half-spaces,"Given two subsets S/sub 1/ and S/sub 2/ (not necessarily finite) of R/sup d/ separable by a Boolean combination of N halfspaces, the authors consider the problem of learning the separation function from a finite set of examples. The solution consists of a system of N perceptrons and a single consolidator which combines the outputs of the individual perceptrons. The authors show that an off-line version of this problem where the examples are given in a batch, can be solved in time polynomial in the number of examples. The authors also provide an on-line learning algorithm that incrementally solves the problem by suitably training a system of N perceptrons much in the spirit of classical perceptron learning algorithm.",
Learning in connectionist networks using the Alopex algorithm,"The Alopex algorithm is described as a universal learning algorithm. The algorithm is stochastic and it can be used for learning in networks of any topology, including those with feedback. The neurons could contain any transfer function and the learning could involve minimization of any error measure. The efficacy of the algorithm is investigated by applying it on multilayer perceptrons to solve problems such as XOR, parity, and encoder. These results are compared with results obtained using a backpropagation learning algorithm. Taking the specific case of the XOR problem, it is shown that a smoother error surface with fewer local minima could be obtained by using an information-theoretic error measure. An appropriate 'annealing' scheme for the algorithm is described, and it is shown that Alopex can escape out of the local minima.",
Supporting inheritance in relational database systems,"The IS-A relationship (the class-subclass relationship) is one of the most fundamental and important properties in an object-oriented (OO) language and OO database management system (OODBMS). Due to the popularity and domination of relational database management systems (RDBMSs) and the fundamental importance of inheritance, supporting IS-A relationships in a RDBMS becomes very desired, and is essential to adapt a RDBMS to more advanced applications. The authors present an extended SQL system called ESQL which facilitates IS-A relation hierarchies in a RDBMS. The proposed ESQL uses constraints to resolve data redundancy and updating abnormality problems that exist in current OO languages such as C++ and Smalltalk, and OODBMS such as GemStone, PostGres, O/sub 2/, Iris, and Orion. Features such as inheritance constraints, subrelation assertions, mappings, and automatic tuple placement into its most specific subrelation are distinct in ESQL. These features are missing in current RDBMSs, OODBMSs and OO languages.",
"Very weak, P-weak majorization and their application","In a number of queuing systems with blocking and/or multiple classes of arriving customers, the classical majorization orderings become too strong to apply. In order to establish queue length inequalities that give rise to stochastic orderings on critical performance metrics for these systems, two new forms of majorization are introduced and studied. These are very weak majorization and p-weak majorization.",
A simple genetic algorithm applied to discontinuous regularization,"A simple genetic algorithm without mutation has been applied to discontinuous regularization. The relative slope of the energy-to-fitness function has been introduced as a measure of the rate of convergence. The intuitively better rate of convergence (slow in the beginning, faster in the end) has been shown to be superior to an exponential transformation-function in the present case. A probabilistic model of the performance of the algorithm has been introduced. From this model it has been found that a division into subpopulations decreases the performance, unless more than one computer is available.",
3D object recognition: interpretation tree search on a MIMD machine,"This paper presents a parallel implementation of a tree search strategy for recognition of 3D objects in range images. A coarse-grained and a medium-grained implementaton of the tree search algorithm is presented and analyzed. The performances of the two implementations are analyzed on a 96-node BBN GP-1000 and on a 48-node BBN TC-2000; and, for comparison, on a Sun SPARCstation 2.",
"Comments, with reply, on ""Receding horizon control of nonlinear systems"" by D.Q. Mayne and H. Michalska","The commenter points out earlier work on the problem addressed in the above-titled paper by D.Q. Mayne and H. Michalska (ibid., vol.35, no.7, p.814-824, July 1990). In their reply, the authors acknowledge that they overlooked the earlier paper and point out differences in their treatment of the subject.",
Parallel heap operations on EREW PRAM: summary of results,"The authors present parallel algorithms for heap operations on an EREW PRAM. They first present a parallel heap construction algorithm with p processors running in O(n/p+logp) time. It takes 3.625n/p+4log p time in the worst case. The algorithm is optimal when p= theta (n/logn). They then propose a method to delete the root of a heap in parallel. To facilitate dynamic processor allocation, a data structure is developed in a preparatory step using O((n/logn)/sup 1-1/p/) processors in O(logp) time. A sequence of root deletion operations is realized such that each of these operations takes O((logn)/p+logp+loglogn) time using p processors. The authors also suggest an O((logn)/p+log p) time optimal parallel insert algorithm using p processors. When p= theta ((logn)/loglogn), both algorithms run in O(loglogn) time. The algorithms can also be extended to a parallel algorithm for deleting an element from a heap, given the address of the element.",
Syntactic approach to the deadlock detection problem,"A method for solving the deadlock detection problem in operating systems with single unit resources is introduced by using the formalism of the automata and languages theory. The waiting relations between processes are represented in a wait-string. The study of the properties of wait-strings which contain deadlocked processes allows a solution to be obtained for the deadlock detection problem in the form of a finite automation (FA). The designed FA, which accepts the wait-strings with deadlock, acts as a deadlock detection algorithm. Its performance is proved. The design method of the FA is itself a detection algorithm based on the same principles. Therefore its formal proof is also valid, and can be used when strong memory requirements are imposed.",
A new method for the study of hazard and the uses of it,"The present paper considers the problem of hazard in digital structures. The first stage to be achieved is a rigorous analysis of hazard in combinatorial logic circuits already existing, and whose physical implementation is well known. The analysis method suggested is developed on the scheme of the time constants method. The second stage consists of studies on the functioning of a finite automaton. The authors trace the output of the circuit only for transitions compatible with the state transition graph of the automaton. They design a variable duty factor ring oscillator that will use to the maximum the possibilities of the circuit without risks of hazardous functioning.","Hazards,
Input variables,
Circuits,
Automata,
Computer science,
Delay effects,
Education,
Synchronization,
Clocks,
Oscillators"
Parallel routing algorithms for incomplete hypercube interconnection networks,"A severe restriction on a complete hypercube topology is that the number of processors must be a power of 2. Such a restriction limits its applicability. An incomplete hypercube may provide more flexibility in system sizes. There are three classes of variant incomplete hypercube interconnection networks: I/sup r//sub m/, I/sup r//sub M/ and I/sup r//sub A/. The authors focus on the parallel routing algorithms for these three classes of incomplete hypercubes. Parallel paths between any given two nodes mean that these paths have the same source and destination nodes but with different intermediate nodes. Parallel communication can speed up the data transfer operation and increase the system fault-tolerance and the communication reliability between two nodes.",
Preventing recursion deadlock in concurrent object-oriented systems,"This paper presents solutions to the problem of deadlock due to recursion in concurrent object-oriented programming languages. Two language-independent, system-level mechanisms are proposed: a novel technique using multi-ported objects, and a named-threads scheme that borrows from previous work in distributed computing. The authors compare the solutions, and present an analysis of their relative merits.",
Learning approximate diagnosis,"In earlier work on incorporating explanation-based learning (EBL) in model-based diagnosis (MBD), a diagnostic architecture integrating EBL and MBD components was suggested. The authors relax the requirement on completeness and specificity of the diagnostic candidates. They allow the learning component to make errors in a training phase where it is given feedback on its actual performance. A method is described for trading off accuracy for efficiency. In this approach, most diagnosis problems are handled by the associational rules learned from previous problems. Model-based reasoning and learning are activated only when performance drops below a given threshold. Empirical results are presented on circuits with an increasing number of components illustrating how this approach scales up.<>",
Image-processing technique for investigating dielectric breakdown trees,"An image-processing system has been used to measure tree branch lengths and fork angles in PMMA. A logarithmic distribution of branch lengths has been found, while the mean value of the forking angle is 65.7 degrees . Treeing is discussed in terms of mechanical and electronic breakdown mechanisms.",
Integrating probabilistic LR parsing into speech understanding systems,"The application of probabilistic LR parsing to the problem of continuous speech understanding is described. A probabilistic model for LR parsing is introduced, the integration of the parser into a speech understanding system is discussed, and recognition results are presented. The goal of speech understanding is to process continuous speech input from users and provide appropriate responses. This requires a speech recognition system with a high sentence recognition rate, and a low sentence error rate (since rejection is allowed, these are not identical). The authors demonstrate that probabilistic LR parsing can help meet these requirements by applying linguistic and statistical constraints to speech recognition, and by providing effective rejection criteria. In experiments using the MIT VOYAGER spontaneous speech corpus, the use of a probabilistic LR parser improved the percentage of utterances for which correct semantics were produced from 23% (using a perplexity 72 word-pair grammar) to 58%. System performance, as measured by the metric 100* (N/sub corret/-N/sub error/)/N/sub total/, was 44.5 at a 32.7% rejection rate.",
Action selection in interactive model-based diagnosis,"The authors developed a probabilistic diagnosis theory that incorporates probabilistic reasoning into model-based diagnosis. In addition to the structural and functional information normally used in model-based diagnosis, probabilities of component failure are also used to solve the two major subtasks of interactive model-based diagnosis: hypothesis generation and action selection. The authors describe the action selection strategy based on this probabilistic theory. The major contributions are the incorporation of probabilistic reasoning into model-based diagnosis and the integration of repair as a part of diagnosis.<>",
"An approach for parallelizing OPS5 production systems and a faster match, C based indexing scheme for hypercube machines","An algorithm for reducing the amount of time spent by a production system in its MATCH phase is presented. The algorithm utilizes C language's arithmetic operations, which are not efficiently computed in standard production system languages, and also constricts the activity of the MATCH phase as performed in the OPS5 programming language. The parallelization is achieved by distributing the search amongst the nodes of a hypercube. The MATCH phase is an effort to satisfy the LHS (left hand side) of a PR (production rule) by the contents of a WM (working memory). C programming language was used for the implementation of the monkey-and-banana problem written in OPS5.",
A framework for learning and inference in network management,"A network management framework which builds the management information infrastructure and equips the management applications with learning and reasoning abilities for automatic and adaptive management tasks is presented. Views consist of global virtual management information constructed by logical rules from the distributed physical management information. Through these views, management applications can access physical network entities. Management applications learn network patterns and reason on the discovered patterns and prespecified domain knowledge to predict network behavior, diagnose problems, and trigger control actions. The abstract view definitions, domain knowledge, and network patterns are a set of logical rules stored in the application-dependent MKB (management knowledge base), while the physical management information is stored in the standard MIB (management information base) at each node.",
Back propagation as a test of the efficient markets hypothesis,"The paper presents some research on the application of artificial neural networks to economic modeling. The efficient markets hypothesis (EMH) states that at any time, the price of a security fully captures all known information about that stock, so the price behaves like a random walk in time, except when there are changes in information. The authors test whether a non-linear statistical method, error back propagation, can do better than chance in forecasting stock trends. An error back propagation model is estimated at different levels of time aggregation (daily and monthly) on stock price and stock index returns. The paper brings forth some new and encouraging results on the ability of neural network models to predict the direction of stock price movements and to account for some of the nonlinearities found in stock return data.",
Transient fault tolerance in redundant systems,"Outlines some problems which result from transient faults in designing fault tolerant systems. Based on this analysis, a systematic approach to effective transient fault tolerance in redundant systems is presented. The main point of this approach is to design error handling procedures, taking into account a variety of available error detection mechanisms and the context of error appearance. Implementation of these strategies required some special hardware and software. This approach is illustrated for systems with double and triple modular redundancy.",
Kernel regression and radial basis function net: some theoretical studies,"After building up some connections between the radial basis function (RBF) network and kernel regression estimator (KRE), the authors introduce several recent theoretical results on KRE. They show that KRE can not only be used as a neural network model, but can also provide new results on the theoretical analysis of an RBF net in terms of the ability of approximation, the rate of convergence, and the size of the receptive field of the radial basis function. These results are quite useful for further theoretical studies on the RBF as well as in guiding the design of the RBF net in practice.",
On the verification and validation of protocols with high fault coverage using UIO sequences,"Various new classes of unique input/output (UIO) sequences for verification and validation (conformance testing) of protocols modeled as finite state machines (FSMs) are presented. The proposed sequences are referred to as adaptive because test sequence generation is not a mere concatenation of test subsequences for all edges of the FSM, but rather subsequences are concatenated using appropriate conditions in the UIO sequence for length minimization and no degradation of fault coverage.",
Fast unimodular reduction: planar integer lattices,"The author shows that a shortest basis for the 2-dimensional lattice Lambda (u, v) generated by an input pair u, v in Z/sup 2/ can be computed in O(M(n) log n) where n is the bit-size of the input numbers and M(n) is the complexity of multiplying two n-bit integers. This generalizes Schonhage's technique (1971) for fast integer GCD to a higher dimension.",
"Progress measures, immediate determinacy, and a subset construction for tree automata","Using the concept of a progress measure, a simplified proof is given of M.O. Rabin's (1969) fundamental result that the languages defined by tree automata are closed under complementation. To do this, it is shown that for infinite games based on tree automata, the forgetful determinacy property of Y. Gurevich and L. Harrington (1982) can be strengthened to an immediate determinacy property for the player who is trying to win according to a Rabin acceptance condition. Moreover, a graph-theoretic duality theorem for such acceptance conditions is shown. Also presented is a strengthened version of S. Safra's (1988) determinization construction. Together these results and the determinacy of Borel games yield a straightforward method for complementing tree automata.",
A Comparison Of Adaptive And Static Load Balancing Strategies By Using Simulation Methods,,
Parallel error tolerance scheme based on the hill climbing nature of simulated annealing,"In parallelizing simulated annealing in a multicomputer, maintaining the global state S involves explicit message traffic and is a critical performance bottleneck. One way to mitigate this bottleneck is to amortize the overhead of these state updates over as many parallel state changes as possible. Using this technique introduces errors in the calculated cost C(S) of a particular state S used by the annealing process. Analytically derived bounds are placed on this error in order to assure convergence to the correct result. The resulting parallel simulated annealing algorithm dynamically changes the frequency of global updates as a function of the annealing control parameter, i.e., temperature. Implementation results on the Intel iPSC/2 are reported.",
Efficient constrained encoding for VLSI sequential logic synthesis,"A fast heuristic algorithm called ENCORE is proposed for the dichotomy-based constrained encoding problem. Its implementation has been tested on MCNC synchronous sequential logic benchmarks. For the case of complete encoding, ENCORE generates the same or shorter encoding lengths than the programs KISS, NOVA and DIET, for most of the benchmarks, and uses much less CPU time. For bounded-length encoding, ENCORE produces better overall quality than both random encoding and NOVA. ENCORE has also been applied to state assignment problems for asynchronous machines; it consistently obtains optimal or near-optimal results for a variety of examples found in the literature.",
PERFLEX: a performance driven module generator,"A performance-driven approach to module generation, called PERFLEX, for static combinational CMOS logic circuits is described. The flexible layout style supports implementation of fast and reliable circuits. Improvement in circuit speed is achieved through minimization of diffusion and interconnection capacitance, transistor sizing, and transistor reordering. By integrating transistor sizing and reordering steps in the layout process, fine-grain optimization is achieved. Experimental results are presented.",
An object-oriented approach to computer architecture simulation,"An object-oriented approach to modeling and simulation computer architectures is presented. Rather than concentrating on a specific system, the more generic concepts of processors, memories, clocks, registers, instruction sets, etc. are developed. By building upon these basic concepts, it is then possible to simulate virtually any processor to nearly any level of detail.",
Robust Linear Quadratic Designs with Respect to Parameter Uncertainty,"We derive a linear quadratic regulator which is robust to parametric uncertainty, by using the overbounding method of Petersen and Hollot. The resulting controller is determined from the solution of a single modified Riccati equation. We show that when applied to a structural system, the controller gains add robustness by minimizing the potential energy of uncertain stiffness elements, and minimizing the rate of dissipation of energy through uncertain damping elements. We are also considering a worst-case disturbance in the direction of the uncertainty. Finally, we prove that we have increased performance robustness with the robust LQR when compared to a mismatched LQR design where we design the controller on the nominal system, but apply it to the actual uncertain system.",
ACTA: a comprehensive transaction framework for extended transactions,"Summary form only given. Although powerful, the transaction model adopted in traditional database systems is found lacking in functionality and performance when used for new applications, such as CAD/CAM, and design environments. Various extensions to traditional transaction model have been proposed to address these drawbacks. In order to analyze these ad hoc extensions and in search for a good implementation support for the new applications, the authors have developed a comprehensive transaction framework, called ACTA. ACTA characterizes the semantics of interactions in terms of different types of dependences between transactions and in terms of transactions' effects on objects.<>","Computer science,
Power system modeling,
History,
Database systems,
Application software,
Design automation,
Computer aided manufacturing,
CADCAM,
Computer languages,
Mechanical factors"
Interpolative robot control with the nested network approach,"A nested network method is presented for learning functions of high dimensions. The method, which is derived from the split-and-merge algorithm, creates a representation at multiple levels of coarseness from randomly distributed learning samples, and thus exhibits both fast and accurate learning. It is applied to learning the inverse kinematics in a three-degree-of-freedom pick-and-place problem. Without the need for building a model of the environment, the preprocessed sensor data is mapped onto joint displacements that must move the robot manipulator to the target object. Learning samples are obtained without a model of the manipulator. Instead the mapping from joint motion to camera motion is measured and taught directly to the nested network. A nested network method based on search trees adapts in real-time and reaches a grasping precision of up to 1-mm in only three steps.",
Protecting replicated objects against media failures,"Presents a replication control protocol that provides excellent data availabilities while guaranteeing that all writes to the object are recorded in at least two replicas. The protocol, robust dynamic voting (RDV) accepts reads and writes as long as at least replicas remain available. The replicated object remains inaccessible until either the two last available replicas recover or one of the two last available replicas can collect the votes of a majority of replicas. The authors evaluate the read and write availabilities of replicated data objects managed by the RDV protocol and compare them with those of replicated objects managed by majority consensus voting, dynamic voting and hybrid dynamic voting protocols. They show that RDV can provide extra protection against media failures with no significant loss of availability.",
IBC: A Working Tool for Robust Parametric Identification,In this paper. we explore the utility of Information-Based Complexity (IBC) for control-oriented robust parametric identification in the presence of noisy data. In addition. we show that a number of IBC algorithms and their associated worst-case errors are computable by means of vertex optimization.,
A connectionist approach to text-phonemics translation using syntactic neural networks,"A self-organizing connectionist scheme for text-phonemics translation, capable of conversion in either direction, is described. It consists of two cross-coupled syntactic neural networks, one acting as a parser in one symbol domain and the other as a generator in the other domain. No prior alignment of graphemes with phonemes is necessary-only presentation of whole-word orthographic-phonemic pairs. Results are presented for English text-to-phonemics translation and vice versa, with the system trained on a sample of up to 2000 word pairs and tested both on the training set and an equal-sized disjoint test set. Translation accuracy is assessed as a function of language-sample size and of network size, and performance is compared with that of other connectionist text-to-speech systems. Although not currently competitive with traditional, rule-based techniques, the connectionist approach is considerably less labor-intensive.",
A high level framework for developing DSS workbenches,"The term 'DSS workbench' (DSSW) is open to wide interpretations. Though the author fully subscribes to the view that such diversity is healthy, enriching and highly desirable during the early stages of concept formulation, he also believes that it is critical to have higher level frameworks for organizing and integrating the diverse thoughts, and for making judicious choices regarding research priorities and directions. In the interest of addressing this need, this paper examines the design space of DSS workbenches, presents a high level framework for building them, and discusses its implications.",
Determining longest common subsequences of two sequences on a linear array of processors,This paper presents special-purpose linear array processor architecture for determining longest common subsequences (LCS) of two sequences. The algorithm uses systolic and pipelined architectures suitable for VLSI implementation. The algorithms are also suitable for implementation on parallel machines. The author first develops a 'greedy' algorithm to determine some of the LCS and then proposes a generalization to determine all LCS of the given pair of sequences. Earlier hardware algorithms were concerned with determining only the length of LCS or the edit distance of two sequences.,
"CAL and CAD Software for Microwave Education, Engineering and Related Applications","A program package called ""Electromagnetic Waves"" in seven parts has been developed. It is intended for computer aided learning (CAL) with widely making use of animated graphics of fields and waves which are simulated during the study.",
Fault-tolerant concurrent branch and bound algorithms derived from program verification,"One approach for providing fault tolerance is through examining the behavior and properties of the application and deriving executable assertions that detect faults. This paper focuses on transforming the assertions of a verification proof of a program to executable assertions. These executable assertions may be embedded in the program to create a fault-tolerant program. It is also shown how the natural redundancy of the program variables can be used to reduce the number of executable assertions needed. While this approach has been applied to the sequential programming environment, the distributed programming environment presents special challenges. The authors discuss the application of concurrent programming axiomatic proof systems to generate executable assertions in a distributed environment using distributed branch and bound as a model problem.",
RCCN: radial basis competitive and cooperative network,"The radial basis bidirectional competitive and cooperative network (RCCN) is a bidirectional mapping network that accommodates and generates radial basis function units (RBFUs) with the help of efficient use of the accommodation boundaries. The analysis and simulation show that the automatic generation scheme provides the necessary and sufficient enhancement of the network, the hierarchical learning scheme ensures the desired accuracy in mapping, the mapping scheme processes the many-to-many relation for both directions with sufficient accuracy, and using ellipsoidal boundaries is more efficient and flexible compared to circles. RCCN may create an enormous number of RBFUs and degenerate in accuracy by learning with noisy samples. However, greater efficiency can be expected if RBFUs are allowed to have individual accommodation boundary sizes under the optimal learning scheme.",
Classification-accuracy monitored backpropagation,"For IC diagnostic purposes, the classification accuracy of training patterns (CAT) and the classification accuracy of unseen patterns (CAU) can be used as a measure of feedforward neural network (FFN) performance. To maximize FFN generalization performance, a CAU monitored back-propagation (BP) training technique is investigated and compared with the conventional minimum mean squared error criterion. To prevent over-training, an extra set of untrained data is used to monitor the generalization accuracy of the FFN. Using this technique, the trained FFN is optimized for generalization. The experiment has shown that the CAU monitored BP training algorithm improved the FFN classifier generalization accuracy compared to the minimum mean squared error criterion.",
"Complementary, High-Performance Lateral Bjts in a Simox C-Bicmos Technology",,
The IUCF cooler ring betatron tune modulation system,"To meet accelerator physics studies requirements for high-frequency modulation of a synchrotron quadrupole field, a modulation system was developed to allow accurate field control inside the vacuum chamber for frequencies up to 3 kHz. Limitations in directly modulating the DC bias current supply led to the motivation for a specialized system. The system consists of a computer-controlled function generator, a 300-V pk-pk/800 mA pk-pk power amplifier, a quadrupole field pickup coil, and an AC isolation subsystem to restrict modulation to a single quadrupole. The power amplifier may be run in constant AC current mode, constant external AC field mode. Responses of the laminated iron quadrupole and stainless steel beampipe to such modulation are discussed. Interconnection of the various system elements (multiwinding quadrupoles and DC bias supplies) required an AC isolation subsystem. This subsystem synthesizes a high AC impedance while maintaining negligible DC insertion impedance, minimizing DC power losses and isolation component physical size. System performance and typical beam responses are summarized.",
A Self-learning Controller For Monocular Grasping,,"Robot sensing systems,
Manipulators,
Cameras,
Sensor systems,
Acceleration,
Robot control,
Image processing,
Robot vision systems,
Velocity control,
Computer science"
Abstract fixpoint semantics and abstract procedural semantics of definite logic programs,"A class of abstract interpretations of definite logic programs are discussed that are characterized by stable abstraction functions and a procedural characterization of the abstract fixpoint semantics is given. The authors give the notion of partial unification and define abstract fixpoint semantics. They then define a partial SLD resolution procedure over the concrete domain and relate it to the abstract fixpoint semantics by proving its soundness and completeness. They generalize the partial SLD resolution procedure, resulting in an abstract SLD resolution procedure over the abstract domain. They illustrate the computation of the abstract fixpoint semantics for depth abstractions and the application of the abstract SLD resolution procedure.",
Surface Following and Modelling for Planar N-Link Manipulator Arms Equipped with Proximity Sensors,,
Conceptual data modeling: assessing empirical studies,"Conceptual data modeling is used in a variety of IS activities, including enterprise modeling, system requirements determination, logical database design, and data oriented application development. Recently a number of empirical studies have examined conceptual data models. The results from these studies are fragmented, often statistically insignificant, and sometimes conflicting. The authors examine the current literature and explain why the results have been so inconclusive. They pose a theoretical basis for empirical research in this area and discuss issues related to external validity, measurement, and type three errors as they relate to this area of research. Finally, they summarize preliminary findings from a study organized according to this theoretical basis.",
Explicit expressions for cascade factorizations of general non-strictly proper systems,"The authors present explicit expressions for two different cascade factorizations of any detectable system which is not necessarily left invertible and which is not necessarily strictly proper. The first is a well-known minimum phase/all-pass factorization by which G(s) is written as G/sub m/(s)V(s), where G/sub m/(s) is left invertible and of minimum phase, while V(s) is a stable right invertible all-pass transfer function matrix which has all unstable invariant zeros of G(s) as its invariant zeros. The second is a generalized cascade factorization by which G(s) is written as G/sub M/(s)U(s), where G/sub M/(s) is left invertible and of minimum-phase with its invariant zeros at desired locations in the open left-half s-plane, while U(s) is a stable right invertible system which has all awkward invariant zeros, including the unstable invariant zeros of G(s), as its invariant zeros, and is asymptotically all-pass.",Transfer functions
Adaptation and modification of Nassi-Shneiderman charts to represent Descartes specifications visually,"Descartes is an executable specification language that supports the rapid prototyping of partial through complete software specifications. A technique developed to represent Descartes executable specifications visually by adapting the charts of I. Nassi and B. Shneiderman (1973), is described. Symbols are identified for the data structuring methods and the rationale for selecting these symbols is discussed. The benefits gained in moving a graphical technique up to the front end of the software life cycle are discussed. Sample specifications are included to illustrate the effectiveness of the technique.",
Automated data acquisition and analysis for evaluation of PET detector units,"In order to quickly evaluate detector units prior to incorporation into a positron emission tomography (PET) scanner, an automated method for measuring the critical characteristics of detector units was developed. The procedure uses annihilation radiation (/sup 68/Ge) to measure timing and energy resolution, count rate uniformity, and position encoding. Several detector units are connected to a multiplexor, allowing sequential data collection from the individual detector units. Data from a detector's photomultiplier tubes are collected using standard Nuclear Instrumentation Modules (NIMs) electronics, and computer automated measurement and control (CAMAC) analog-to-digital converters and scalers. Acquisition is controlled by a Macintosh computer running LabVIEW. Data are automatically transferred to a Sun workstation for analysis. This system has been used to evaluate several different detector units, including a six by six bismuth germanate (BGO) crystal array mounted on two Hamamatsu Photonics R1548 photomultiplier tubes.",
Algebraic decision trees and Euler characteristics,"For any set S contained in R/sup n/, let chi (S) denote its Euler characteristic. The author shows that any algebraic computation tree or fixed-degree algebraic decision tree must have height Omega (log mod chi (S) mod )for deciding the membership question of a compact semi-algebraic set S. This extends a result by A. Bjorner, L. Lovasz and A. Yao where it was shown that any linear decision tree for deciding the membership question of a closed polyhedron S must have height greater than or equal to log/sub 3/ mod chi (S) mod .",
A qualitative model of the HIV vital cycle,"Qualitative modelling is a recent artificial intelligence approach to physical system modelling. This approach has been successfully applied in several fields. On the basis of an analysis and qualitative modelling of cell growth, we reckon that a qualitative model of the vital cycle of HIV can be proposed, including the phases in which HIV can be attacked. The actions of antiviral drugs can also be qualitatively modelled, provided their action mechanism is known, even only in a broad sense.",
A Novel Scheme for Designing Error Correcting Codes Using Cellular Automata,,
An expert system for fault diagnosis in FASTBUS network initialization,"FBNEXPERT is an expert system designed to help operators in controlling and maintaining a FASTBUS data acquisition system; it can also assist human experts during trouble-shooting and fault diagnosis. It is based on a shell (NEXPERT) which interacts with a knowledge base, where all the information about the FASTBUS system is collected, including the description of the configuration (from the files used for the initialization procedure) and the results of tests and previous diagnoses. During the diagnostic process, FBNEXPERT spans several levels of description of the FASTBUS system and applies various co-operating strategies.",
Development of a fault-tolerant distributed tuple-space,"Tuple-space is the underlying mode for a set of language extensions known as Linda. These extensions are normally implemented by compiler modifications and are intended to facilitate parallel programming. The authors have separated the tuple-space concept from the complexity of compiler modification and focused it on the distributed environment. The tuple-space is a network-global storage space in which the unit of storage is a tuple consisting of key and content. These persistent storage objects are addressed associatively via their key. The tuples, along with a small set of primitives, provide for interprocess creation, communication, and synchronization. With tuple-space as the framework, fault tolerance emerges as the glue needed to produce a useful system. Tuple-space implementation is targeted for a network of Unix systems. Diverse applications were chosen to establish a requisite testing platform. These applications and performance on tile application, are discussed.",
Program transformation in massively parallel systems,"The authors present two problems in mapping highly maintainable expressive parallel code manipulating multidimensional arrays in massively parallel computers: bottlenecks due to simultaneous accesses in the EREW model, and interprocessor communication. They present a source code transformation approach to solve the expressibility-high-performance problem for the multidimensional arrays designed with a four-level hierarchical design of the data types (aggregate, abstract, logical, and physical levels). A systematic method is developed to transform parallel high-level low-performance code into parallel low-level efficient ones. The method is illustrated with matrix multiplication. The method is also used to generate high-performance logical-level code for the backpropagation algorithm of neural networks that makes extensive use of matrices. The transformed code has a much higher performance than the code with a naive mapping.",
A VLSI implementable design for Boltzmann machine,"The authors report on a VLSI design for the realization of a Boltzmann machine. It is shown analytically and by the use of simulation results that the acceptance probability function for the proposed design is the same as that of the Boltzmann machine. Using such a design, it is possible to build special purpose hardware for obtaining good solutions for several optimization problems. The acceptance probability characteristics of the Boltzmann machine are analyzed.",
Task scheduling in hard real-time distributed systems on a bus local area network,"The authors propose a scheme for global scheduling in a distributed system using a bus network, which is shared by nodes in the system through a contention-free medium access protocol. Unlike existing solutions, the scheme does not require complete global state information to be collected for a node that has an unschedulable aperiodic task to find a node that can execute the task. The nodes are organized in the system in a logical ring fashion to synchronize the global scheduling process. To evaluate the performance of the scheme, two protocols are developed. Simulation results show that the performance of the scheme is close to an ideal distributed system, in which the centralized global scheduler takes care of aperiodic tasks without any communication and task migration overhead.",
The asymptotic complexity of merging networks,"Let M(m,n) be the minimum number of comparators needed in a comparator network that merges m elements x/sub 1/or=m. Batcher's odd-even merge yields the following upper bound: M(m,n)or=m to infinity :M(m,n)>or=/sup 1///sub 2/(m+n)log/sub 2/(m+1)-O(m); in particular, M(n,n)>or=nlog/sub 2/n-O(n). The authors' proof technique extends to give similarly tight lower bounds for the size of monotone Boolean circuits for merging, and for the size of switching networks capable of realizing the set of permutations that arise from merging.",
Distributed implementation of optimization problems on bipartite network topology-fault tolerant computation and reduction of local minima problem,"The author reports on advantages obtained by combined use of a bipartite network topology and a distributed implementation scheme for solving optimization problems. These properties are defective hardware, reduction of local minima, and parallel inter-unit communication. Several methods for deciding connection weights are provided. The probabilistic updating rule is illustrated by the implementation of the Boltzmann machine on bipartite network topology. A probabilistic updating scheme using analog units is given.","Network topology,
Fault tolerance,
Buffer storage,
Computer networks,
Computer science,
Graph theory,
Recurrent neural networks,
Neural network hardware,
Neural networks"
A transparent monitoring tool for shared-memory multiprocessors,"Monitoring and debugging of parallel programs is complicated by race conditions, which can cause software monitoring to alter program behavior. To avoid these unwanted modifications of program execution, the authors present a flexible scheme for transparently monitoring parallel programs in a shared-memory environment. To achieve transparency, the monitor observes causal relations between events in different threads of execution, and intervenes when an impending event would change the order of occurrence of causally related events, as compared to unmonitored execution of the same program. Constructs used to support this monitoring scheme are developed, including mechanisms to deal with unsynchronized and coarse grained clocks. The monitoring scheme requires the instrumentation of every shared-memory access. To measure the overhead created by this intrusion, a prototype monitor has been implemented. Preliminary performance results produced by the prototype are presented and discussed.",
The local area network as a window to distributed virtual memory,"The progress in local area networking significantly impacts the evolution into distributed computing. In this paper, the author challenges the common approach to local area networking and propose a new view. A logical cluster of workstations interconnected via a local area network is viewed as an integrated system with one single virtual address space. The physical memory of the workstations that are members of this logical cluster represents distributed physical memory resources available for allocation to the distributed virtual address space of an individual application. To meet this objective, the design of a local area network (including LAN controller buffer and protocols) is re-examined. The buffer of the LAN controller is viewed as a caching store for remote memory. The LAN, hence, becomes a window to extended distributed virtual memory.",
Apprenticeship instruction through adaptive human-computer interaction,"Discusses an approach and issues regarding the use of intelligent adaptive user interfaces, coupled with hypermedia, to provide supportive learning situations for users within an instructional paradigm of cognitive apprenticeship. Existing models of user interaction are examined and extended with a supportive learning model of user interaction. The paper addresses learning opportunities provided by implementing this model of interaction using intelligent computer-human interaction, as well as identifies issues which are yet to be resolved in providing supportive learning situations within the apprenticeship learning paradigm.",
Bindings between names and objects in a persistent system,"The paper addresses the issues of uniformity and simplicity in the area of the bindings between user object references (names) and system object references in persistent systems. Uniform treatment of these entities will allow simplification of the mechanisms which handle them. The authors propose a design, following an object-based approach, in which user environments are structured as collections of bindings. All objects which a user may access have a corresponding binding in the user's environment. All bindings are handled by the same mechanisms. There are no special cases-all data structures in the system (or the objects used to contain the data structures) are regarded as conceptually equivalent for purposes of storage, retrieval and activation. This ensures uniformity across the name space.",
R&D in Analog Circuits: Possibilities and Needed Support,"It is argued that the importance of analog and mixed-analog-digital integrated circuits has increased in terms of volume and in terms of the number of applications, as analog circuits accompany the computer wherever the latter must interface with the real world. A number of important applications are identified, and several examples of open R&D topics are given. The context and nature of analog circuit R&D are discussed, and several factors that hinder such R&D are examined. These include some factors which are non-technical in nature but are of no lesser importance than the technical ones.",
The use of formal methods in parallel operating systems,"The authors report on the use of formal methods for the development of parallel operating systems for two experimental declarative systems over a five-year period. A common specification approach has evolved as part of the development of these two very different systems: one being for a parallel graph reduction machine and written in a functional language enhanced with state-based objects, the other was written in C/sup ++/. A brief overview of each system is given before concentrating on the use of formal methods. A description is given of how both a technique for formally specifying sequential systems (VDM) and a technique for specifying concurrent systems (temporal logic) have been used together. In both cases, the issue of verification is addressed.",
On the parallel solution of set covering and set partitioning problems,"The development, implementation, and evaluation of parallel algorithms for solving set covering and set partitioning problems are described. Existing algorithms for these NP-complete problems cannot always determine an optimal solution for a problem instance in a reasonable amount of time. While the use of parallel processing is not expected to alleviate the suspected intractability of these problems, it is hoped that it will be possible to obtain optimal solutions to many more real world problems as the result of parallel processing. The computational results that were obtained using a 32-node Intel iPSC/2 hypercube system are described.",
A knowledge-based approach to automated interpretation of performance model results,"Models used to evaluate the performance of complex time-critical computer systems can produce voluminous amounts of data. The paper discusses the integration of knowledge-based systems with performance models to produce knowledge-based performance evaluation systems that provide automated interpretation of model results. A three stage conceptual model of interpretation is developed. Design alternatives for developing knowledge-based performance evaluation systems are explored. The critical dependencies among automated interpretation, design representation, and performance models are described, and a threshold-based strategy for problem identification using the notion of causal factoring is discussed. A prototype system called PEDAS illustrates the authors approaches.","Knowledge based systems,
Expert systems,
Measurement,
Humans,
Context modeling,
Time factors,
Automation,
Logic programming,
Application software,
Hardware"
On the constructions of multiple-burst error-correcting codes,"Disjoint difference sets with regard to the largest elements are used to construct multiple-burst error-correcting codes using majority-logic decoding. Almost all of D.M. Mandelbaum's (1972) codes are improved with shorter lengths. Because they are quasi-cyclic and majority-logic decodable, they are of practical interest.",
Some lower and upper bounds for algebraic decision trees and the separation problem,"The complexity of computing Boolean functions with algebraic decision trees over GF(2) and R is considered. Some lower and upper bounds for algebraic decision trees of various degrees are found. It is shown that over GF(2) decision trees of degree d are more powerful than trees of degree or=n/2-O( square root n log /sup O(1)/n) are more powerful than trees of degree cn, with 0",
A multi-task neural network approach to speech recognition,"Improving the speaker-independent generalization exhibited by neural network approaches to phoneme identification is an area of continuing interest to speech recognition researchers. The author reports research exploring the combined impact of multiple task constraints and differing speech input representations on network generalization. The multiple tasks required of the networks are based on a psychological model of speech perception. Using 12 American vowels to train and test the networks, the differing input representations are motivated by current theories of vowel perception and human audition. Network results compare favorably to baseline performance results established by a K-nearest neighbor classification and the classification performance of human listeners on the same task. These results are also extremely good when compared to performance reported by other researchers.",
Is the pen mightier than the keyboard?,"The authors investigate whether pen-based interfaces are acceptable for general business applications in terms of user performance and user preferences. In six experiments novice and experienced subjects compared a pen-based interface to a keyboard across four general business applications: text editing, spreadsheet, graphics, and disk management. The study found that subjects executed most of the tasks more slowly with a pen-based interface than with the keyboard. Subjects reported that the handwriting recognition component of the pen-based interface was too inaccurate, too slow, and too demanding for user attention. However, they responded well to the touch-button software navigation and screen position control components, suggesting potential for future use.",
On multiple-fault diagnosis of baseline interconnection networks,"A multiple-fault diagnosis procedure which used three distinct test vectors to diagnose a 4*4 baseline network is presented. Multistage interconnection networks are briefly introduced, and the fault model is given. The necessary and sufficient conditions are derived for the input test vectors to diagnose a single switching element. It is proved that six tests are necessary and sufficient to diagnose a 4*4 and an 8*8 baseline network. A multiple-fault diagnosis procedure for an N*N baseline network is presented by using only 2 log/sub 2/ N tests.",
ORL: an object retrieval language interface to an object algebra,"The authors present the design of ORL, an object retrieval language interface to the EQUAL object algebra. ORL has an extended SQL syntax and is implemented on top of the ONTOS object-oriented database system. The complete system provides an interactive query facility as an alternative to the programatic OSQL interface provided by ONTOS. In general, ORL provides a more concise, user-friendly approach to the expression of queries over objects than the object algebra on which it is based. The translation of ORL queries to their equivalent object algebra expressions is described.",
Motion trajectories,"A simple algorithm for selecting and linking interesting flow vectors across a sequence of frames for computing motion trajectories is presented. Tokens that have both interesting pixel gray values in the spatial domain and in the optical flow field in the temporal domain are tracked. This AND operation effectively removes some redundant trajectories. Due to errors introduced during the computation of optical flow, and the linking of such flow vectors across a sequence of frames, the resultant trajectories are not always smooth. A Kalman-filtering-based approach for smoothing the trajectories is discussed.","Image motion analysis,
Optical filters,
Optical computing,
Optical sensors,
Joining processes,
Computer science,
Image sequences,
Layout,
Kalman filters,
Filtering"
Assessing industrial prototyping projects,"The paper presents the results of case studies of industrial software projects in which explicit use was made of prototyping. The major concern was to analyze the experience gained in the projects with the use of prototyping, and in particular to juxtapose these findings and the claims made for prototyping. On the basis of this analysis, the authors set out the benefits, but also the limitations of prototyping.",
An alternative software development model supporting software evolution,"Producing high quality software within a budget and schedule is still a problem. In order to increase the productivity and reliability the development methodology should concentrate on requirements specifications and design phases and support an incremental development process. This paper discusses a software design environment for realizing such a methodology. The integrated software design environment consists of a number of tools integrated for capturing, presenting and exercising software design information. A design representation language which provides high level constructs for encoding design knowledge is introduced into the environment as a uniform basis for integrating different phases of the development process. This paper includes a detailed analysis of the structure of the software design environment and its language as well as its prototype that has been built. A design example is also given to demonstrate the behavior of the prototype.",
Kaleidoscope visualization of fine-grain parallel programs,"A software visualization tool is described that transforms program execution trace data from a multiprocessor into a single, color image. The image is essentially the program's logical procedure-invocation tree, displayed radially from the root. An algorithm is described that condenses the image both radially and laterally, producing a color-dense abstraction of the program's execution behavior: a program signature, within a workstation window. An implementation of the tool was made in X-Windows, including a user interface that can zoom the image and annotate any node in the image with the corresponding procedure-invocation data. Experimentation with the system was performed with trace data from Panda, a concurrent logic programming system on shared-memory multiprocessors. The authors demonstrate how the tool helps the programmer develop intuitions about parallel performance and how condensation successfully abstracts very large traces.",
Observable algorithms on concrete data structures,"A contribution to the investigation of sequentiality and full abstraction for sequential programming languages, focusing on the language PCF, is presented. Ideas of R. Cartwright and M. Felleisen (1992) on observable sequentiality are fit into the framework of concrete data structures and sequential algorithms. An extension of the category of sequential algorithms is shown to provide an order-extensional model of PCF. The key to this is the presence of errors in the semantic domains. The model of observable algorithms is fully abstract for an extension of PCF. This extension has errors too, as well as a control operation catch as found in languages such as Scheme or CommonLisp.",
"What Are Nature's ""natural"" Ways Of Computing?",,
A neural net model based on discrete Gabor transformation,"It has been shown that Gabor representation can be effectively used for image analysis, segmentation and compression. A straightforward and efficient method is proposed for transforming discrete signals into generalized non-orthogonal Gabor representations. If both signal and the window function are real functions, complete Gabor coefficients can be found by multiplying a constant complex matrix and inverse of a sparse real matrix. A fast algorithm is suggested to compute the inverse of the matrix. Properties of Gabor coefficients based on the new method are discussed. A neural network model based on this method is proposed.",
The power of adaptiveness and additional queries in random-self-reductions,"Relationships between adaptive and nonadaptive random-self-reductions are examined. The question of what happens to random-self-reductions if the number of queries they are allowed to make is restricted is also explored. The following results are shown. (1) There exist sets that are adaptively random-self-reducible but not nonadaptively random-self-reducible. Under reasonable assumptions, there exist such sets in NP. (2) There exists a function that has a nonadaptive (k+1)-random-self-reduction but does not have an adaptive k-random-self-reduction. (3) For any countable class of functions C and any unbounded function k(n), there exists a function that is nonadaptively k-uniformly-random-self-reducible but is not in C/poly.","Polynomials,
Cryptography,
Computer science,
Distributed computing,
Marine vehicles,
Random number generation"
Analyzing self-stabilization with finite-state machine model,An approach to analyzing self-stabilization based on the finite-state machine model is presented. A finite-state machine is used to model the behavior of each node in a distributed system. when the self-stabilizing algorithms are applied. The approach is useful for analyzing the correctness of self-stabilizing algorithms and their time complexity. A self-stabilizing algorithm for finding maximal matching is used as an example to show how the finite-state machine model is applied. A simpler proof for the correctness and an upper bound of the time complexity tighter than the one proved by a variant function are attained.,"Protocols,
Algorithm design and analysis,
Computer science,
Upper bound,
Distributed algorithms,
Fault detection,
Fault tolerant systems,
Councils,
Contracts,
Tree data structures"
"Query optimization for KBMSs: temporal, syntactic and semantic transformations",The authors describe a framework for query optimization for knowledge base management systems (KBMSs) based on the knowledge representation language Telos. The framework involves temporal and syntactic simplifications and semantic modification of the queries. Temporal simplification attempts to select parts of a knowledge base that are relevant to a query from a temporal viewpoint. Syntactic simplification exploits structural properties of the data model and attempts to transform the query into an equivalent and more efficient one. Semantic transformation uses knowledge specific to the application domain to transform a user-specified query into another form which gets the same answer and is processed efficiently. The three steps were integrated into a global algorithm for query optimization that utilizes all features of the considered KBMS.,"Query processing,
Knowledge management,
Knowledge representation,
Computer science,
Cost function,
Data models,
Inference mechanisms,
Knowledge acquisition,
Documentation,
Spatial databases"
Equational semantics for Basic LOTOS and an example of its use in a transformational proof style,"LOTOS is a formal description technique for specifying and analyzing distributed systems. It is shown that equational semantics can be given for a subset called Basic LOTOS. A method based on Boolean equations is used. The semantics are shown to be consistent and complete. The equations for Basic LOTOS are found to form a sufficient basis for writing elegant proofs in a transformational style, which has many advantages compared to the more informal style in which proofs are normally presented. An example of such a transformational proof is given.",
Self-tuning control algorithm for wearable artificial pancreas,"Wearable artificial pancreas require sophisticated control algorithms to ensure patient safety during normal life far from medical assistance and without the help of glucose infusion. A self-tuning controller was designed to be implemented into an already developed portable micro-controller unit. It was widely tested, by computer simulation, under different operating conditions: it appears to be insensitive to changes in patient behavior, and produces more physiological insulin concentration than PD algorithms now used by bedside artificial pancreas. Its ability to work with subcutaneous sensors was also positively tested by simulation.",
Mathematical analysis of “SpiderWeb” surface construction algorithm,"“SpiderWeb” is an algorithm to build continuous triangle mesh surfaces embedded in noisy voxel data. This paper outlines a complete proof of the algorithm properties. The main feature of “SpiderWeb” is that its response to noise is the creation of non-manifold closed bubbles. Extremely noisy volume data produces a surface that has the consistency of closed-cell foam rubber. Despite this, the internal and external surfaces are continuous (closed and unbounded) and consistent (oriented). Its main application is surface construction in noisy MRI and Ultrasound data without prefiltering.",
SiGe-Base Bipolar Transistors for Cryogenic BiCMOS Applications,"We demonstrate that the cryogenic (e.g., 77K=LNT) properties of SiGe-base heterojunction bipolar transistors and circuits are sufficiently advanced to warrant a serious consideration of the merits of cryogenic BiCMOS technologies for future LNT computer applications. In this paper we review the features of epitaxial SiGe-base bipolar technologies which make them particularly Suitable for LNT operation, examine the DC and dynamic properties of SiGe-base transistors operating at low temperatures, highlight the profile design constraints unique to the LNT environment, and discuss future research directions and opportunities.",
Quantifying Adaptive Performance Improvement in the Frequency Domain,"A new input/output analysis technique is introduced to rigorously describe adaptive system performance in a frequency domain sense. Signals are decomposed onto orthogonal subspaces, representing individual frequency components, and spectral bounds for the prediction error are derived. The problem formulation compares adaptive system performance relative to a fixed, nominal system, providing a direct measure of the performance benefits of adaptation. Simulation of an adaptive identification algorithm is used to indicate the accuracy of the analysis method, showing that the subspace approach can provide substantially improved measures of algorithm performance.",
A method for determining surface electrode location and boundary shape using impedance measurements,"We have developed an algorithm to determine the boundary shape of a homogeneous volume conductor in cases where the surface can be defined by the location of electrodes. The algorithm adjusts the positions of electrodes in space to provide the best fit to impedance data. We tested the algorithm in a computer simulation that determined electrode locations on the surface of a 10 cm diameter sphere. Legendre polynomials were used to generate simulated impedance data for 66 electrodes evenly distributed over the surface. Starting from three different inititial configurations, the algorithm located the position of the electrodes to within a mean error of 2.5 mm",
Artificial bootstrap,"The author investigates the migration of a process from the symbol level to the knowledge level based on one such study done on an atomic reactor. In engineering there are self-emerging processes grouped under the common term bootstrap. The nature of such bootstraps is examined in providing explanations for exotic new states in the reactor. Knowledge engineers formulate the performance of the reactor on a problem space, where they are forced to postulate the existence of a special function, called the delta function, to explain the occurrences of bootstraps. At the symbol level, the existence of bootstrap operation triggered by a delta function is seen to have its origin from the basic nonmonotonic behavior of the system. At the knowledge level, it is argued that a bootstrap or its persuasive explanation comes from the knowledge engineer who is the architect of the system, both at the symbol and knowledge level. It is argued that knowledge engineers should be able to design metarules to control and explain bootstraps.",
Convergence analysis of adaptive notch filter realized with floating-point arithmetic,A method for obtaining the convergence speed of an adaptive IIR notch filter realized with floating-point arithmetic is proposed. Expressions for the necessary iterations of convergence are derived. The analysis clarifies the effects of quantization error on the convergence behavior of the variable coefficient. The results of computer simulations are presented to substantiate the analysis.,
Choosing a filter structure: component sensitivity and design-for-testability,"The choice of filter structure and its effects on circuit test and implementation sensitivity are examined. Preliminary results have shown the lattice structure to often have a low relative structure-algorithm time constant, making it a strong candidate for implementation in many applications. Since the parameters of such systems can be easily determined from input/output data, and the system design is insensitive to the design parameters, such structures can be used to advantage where design-for-testability is needed.",
Two-dimensional neural networks for handwritten Chinese character recognition,"A two-dimensional Hopfield network approach is proposed to solve the handwritten Chinese character matching problem. The Hopfield net can solve the problem even if the number of strokes in the unknown character and the model character are different. In the recognition stage, the matching rates between the input character and each model character in the database are computed and used to indicate which one is the best match. The proposed technique provides a more general formulation such that some difficult issues in Chinese character recognition like rotational and translation invariance problems are solved. Theory shows that the proposed scheme requires fewer heuristics than other methods. Experimental results are reported using both synthetic and real handwritten Chinese characters to corroborate the theory.",
A decorrelating neural network for color constancy,"Color perception remains roughly constant independent of the illuminant color. This is called color constancy, and much color research has focused on the color constant descriptor. In this paper, we describe a neural network model for color constancy according to the minimally redundant criterion proposed by Barlow. The proposed model with modifiable connections is trained by the anti-Hebbian rule to decorrelate the triplet of cone responses to 1569 Munsell color chips under three different illuminants. After the learning process, the network removes the effect of the change of illuminant by adapting to illuminant colors and achieves color constancy.",
Modeling of Sar Returns from a Red Pine Stand,,
MATEG: a hierarchical test generator for module-based circuits,"The general algorithms and heuristics developed in the module-level automatic test pattern generator called MATEG are described. MATEG is a generalization of the branch-and-bound test generation algorithm for module-based circuits. MATEG retains accuracy of the deterministic test generation, and reduces computation time by exploiting the hierarchy in the circuit-under-test. Some experimental results are presented to demonstrate the efficiency of this approach.","Circuit testing,
Logic testing,
Design methodology,
Logic circuits,
Circuit synthesis,
Logic gates,
Automatic testing,
Computer science,
Heuristic algorithms,
Test pattern generators"
A real-time algorithm for fair interprocess synchronization,"The implementation of nondeterministic pairwise synchronous communication among a set of asynchronous processes is modeled as a binary interaction problem. An algorithm for this problem, which satisfies a strong fairness property that guarantees freedom from process starvation, is described. The message and time complexities are independent of the total number of processes in the system. The ways in which the algorithm may be extended to cope with fail-stop process failures are discussed.",
Learning visual coordinate transformations with competition,"As the angle of gaze changes, so does the retinal location of the visual image of a stationary object. Since the object is correctly perceived as stationary, the retinopic coordinates of the object have been transformed into craniotopic coordinates somehow using eye position information. Neurons in area 7a of posterior parietal cortex in macaque monkeys are thought to contribute to this transformation. The author describes a model of area 7a that incorporates a topographic map. They trained networks using competitive backpropagation learning to learn the transformation task and develop this topographic map. The trained networks generalized well to previously unseen patterns. The study showed that a competitive backpropagation learning rule can train networks employing competitive activation mechanisms to learn continuous valued functions and that it is possible at least computationally to construct a topographic map in area 7a which might be used for eye position independent spatial coding.",
Resources restricted aggressive scheduling,"A scheduling methodology is described for high-level synthesis of designs with a significant amount of control structure. The objective is to utilize all the available resources while scheduling with respect to resource restriction. To do so, a vector/matrix structure is built which provides a global view of resource usage at each node. It supports the migration of operations across basic blocks to wherever idle resources are available. With it, the authors formulate a list scheduling algorithm in which the dispatching priority changes dynamically with respect to resource availability.",
NURSExpert: an integrated expert system environment for the bedside nurse,"NURSExpert, a comprehensive expert system which integrates several specialized knowledge-based systems into a single tool for organizing patient care, is described. NURSExpert is composed of several highly specialized components that work together in the patient care activity. N-CAREPLAN BUILDER assists in the development of patient care plans. N-INSTRUCT is a computer-based learning system that extends nurse education to the bedside. N-INTERACTION assesses the possibility of interactions between various aspects of a patient's course of treatment (i.e. drug-drug, drug-IV, drug-lab, and drug-food). N-ACUITY assists in determining unit staffing requirements based on required patient care needs. NURSExpert is designed to be integrated into the computing environment of the typical hospital information system. In such a design, critical patient data including admissions, discharges, transfers, laboratory test results, and pharmacy orders can be made available to NURSExpert for use in its decision-making process.",
Searching for the orthogonal states of a neural network,"Two approaches to finding orthogonal states of a neural network are discussed. The first is a recursive approach; it builds N orthogonal vectors form N/2 orthogonal vectors. The second is a formula approach, in which orthogonal vectors can be obtained using a formula. It is observed that the formula approach is more efficient than the recursive approach. Properties of the neural network constructed from the orthogonal vectors are presented. An example is discussed.",
An efficient range search algorithm for visualizing extrema of volume data,"A fast range search algorithm for visualizing extrema of d-dimensional volume data in real time as the user interactively moves the query range is presented. The algorithm is based on an efficient data structure, called index heap, which needs only O(N/log N) space and O(d2/sup d/N) preprocessing time to be set up, where N is the size of the d-dimensional data volume. The algorithm can answer an extremum query in O(4/sup d/) expected time, and its worst-case time complexity is O(2/sup d/ log N) per query. For dimensions two and three, the range search for extrema is effected in average O(1) time per query independently of the size of query range. Unlike previous range query algorithms in the computational geometry literature, the proposed algorithm is very simple and can be easily implemented.",
Retracts in simply type lambda beta eta -calculus,"Retractions existing in all models of simply typed lambda -calculus are studied and related to other relations among types, such as isomorphisms, surjections, and injections. A formal system to deduce the existence of such retractions is shown to be sound and complete with respect to retractions definable by linear lambda -terms. Results aiming at a system complete with respect to the provable retractions tout court are established.",
NSF Sponsored Innovation in Engineering and Computer Science,,
Induction support for KBDSS development: a proposed system design,"Over the past few years, designing and implementing DSSs that incorporate artificial intelligence/expert system technology (knowledge-based DSS, or KBDSS) have represented an important new research arena. Most efforts have resulted in frameworks for further research and/or the development of demonstrative applications that have been assessed with regard to their impacts on decision makers. Much has been learned in the past decade related to preferred KBDSS development methodologies, predictable pitfalls, desirable technological approaches. etc. The acquisition of knowledge for inclusion into a KBDSS, however, remains an under-addressed research issue. A design is proposed for a knowledge acquisition support tool that incorporates machine learning induction algorithms. The proposed design for an induction support system represents one approach for evolving an intelligent computer-based assistant for KBDSS builders and practitioners.","Artificial intelligence,
Decision support systems,
Machine learning,
Neural networks,
Knowledge acquisition,
Genetic algorithms,
Spread spectrum communication,
Learning systems,
Intelligent systems,
Algorithm design and analysis"
"Deep Sub-Micron, Bipolar-Mos Hybrid Transistors Fabricated on Simox",,
Explicit fundamental solution to Kolmogorov equation,The original motivation of this study was to solve the Duncan-Mortensen-Zakai equation in nonlinear filtering theory. It was found that to do so one has to solve the so-called Kolmogorov equation. A scheme for solving the Kolmogorov equation explicitly is outlined.,
High Performance Parallel Local Memory Computing at Fermilab,,
Requirements for design-relevant psychological models,"Cognitive engineering is largely concerned with creating environmental designs to support skillful and effective human activity. Psychological models must meet special constraints in order to effectively support this enterprise. The goal is to identify a set of constraints that models must meet if they can usefully guide design. The author discusses two types of constraints on acceptable psychological models that arise due to the need to represent both internal and external influences on cognition and behavior. The first set of constraints is structural. The second set of constraints concerns the content of acceptable models. It is concluded that cognitive engineering most requires models capable of representing the human and environment as an integrated unit, and which represent the activities underlying fluent, skilled behavior.",
A visual concurrent LISP environment and its application,"In the multiparadigm programming environment VOCOL, an attempt is made to integrate the visual, functional, concurrent and object-oriented programming paradigms. VCLISP, a visual concurrent LISP environment, is developed both as a stepping stone to this multiparadigm environment and as a stand-alone programming environment. The design of the VCLISP system and its various facets, including LISP programming features, visual features and concurrent constructs, are presented.",
Efficient directory management for distributed naming,"In a distributed system, accesses to an object may come from many nodes. The name of an object may need to be resolved at those nodes. To improve the efficiency and availability of name resolution, a directory file is often replicated at several nodes. Consistency control of data replicas becomes an important issue in such systems. By using the special consistency requirements of naming services and the data structure of directory files, the author designs a new and efficient method of managing directory file replicas to provide consistent naming services. His approach has the following features: (1) each node issues updates asynchronously. (2) minimum delay of reflecting a remote update on the local replica. (3) neither global locking nor globally synchronized clocks are used.",
Hybrid-mode analysis of coplanar strips and coplanar waveguides,,
Improving the performance of a distributed computing system through inconsistent caches,"In a server client based distributed computing system, data can be cached at the clients to increase read efficiency and system scalability. When the consistency of the caches can be relaxed and the inconsistency controlled, the performance of the distributed system can be further improved. The authors elaborate on this concept and present a prototype system which they have constructed to show the viability of the concept.",
CAMAC-based data acquisition for the Apnea Unit,"Summary form only given. The Apnea Unit, an active-passive neutron examination and assay unit, extends the traditional differential dieaway technique for the nondestructive assay of transuranic waste. A key aspect of the new capabilities of this device is the novel approach to the data acquisition. The unit currently gives individual support to over 80 /sup 3/He gas proportional tubes for neutron detection and maintains a detailed list-mode time history for each detector. The CAMAC-based data acquisition system centers on a multi-time tagging module which records detector hits and their associated time. The data are managed in a CAMAC crate by an event handler which services the time tagging modules and blocks the resulting data through a FIFO into a personal computer. The richness of the resulting data is already being used to profile the contents of an assay drum and to differentiate events associated with cosmic rays.<>",
The refinement of real-time systems,"The Temporal Agent Model (TAM) is a widespectrum development language for real-time systems. In TAM, limited resources are modelled by deriving release times and absolute deadlines from weakest precondition predicate transformers. The language syntax is described, a refinement calculus is presented and a number of examples are discussed. Our development method does not address issues such as schedulability and process allocation.",
An approximate analysis of a token ring network with nonpreemptive priority under go-back-to-higher-priority discipline,"The authors present an approximate analysis of an asymmetric token ring network with nonpreemptive priority under a new discipline named the go-back-to-higher-priority discipline. This discipline is described and the token ring network is analysed on the basis of the independent hypothesis for the distribution of the cycle time. Then, probabilities for the number of messages at the token's arrival, a mean cycle time, a mean intervisit time of the token and a mean waiting time of messages for each priority level are obtained. To calculate the mean waiting time for a lower priority level, a root of the denominator of the generating function plays an important role. In some numerical examples with simulation results, the mean waiting time for the go-back-to-higher-priority discipline is compared with that for an asymmetric token ring network with nonpreemptive priority under a one-limited discipline.","Token networks,
Numerical simulation,
Computer science,
Systems engineering and theory,
Local area networks,
Protocols,
Telecommunication traffic,
Legged locomotion"
Support for persistent objects: two architectures,"Describes the architecture of the IBM RISC System/6000 and the IBM AS/400 from the standpoint of their suitability for implementing persistent object systems. Both systems provide facilities in their hardware, microcode and operating system that, carefully used, can simplify the implementation of persistent object systems and improve their performance. The facilities provided are not, however, perfectly matched to the requirements of persistent object systems. The authors discuss design trade-offs and identify recommended extensions.",
QUID: a quick user-interface design method using prototyping tools,"Experience with prototyping tools for user interfaces indicates that just providing tools does not solve the problem of producing useful interfaces. Rapid prototyping is a design method for user interface development that emphasizes usability. However, it is a bottom-up approach and thus in inherent conflict with more traditional software engineering techniques, which are top-down and specification-driven. The solution is to integrate both approaches in a single method. The quick user interface design (QUID) method is a user-centered method that is particularly useful for producing an initial prototype so that iterations of the prototype/test loop can begin from as good a design as possible. The method is a refinement of participatory design, adapted specifically for use with interface prototyping tools. In practice, the authors have observed novice designers use this method quickly to produce prototypes that are useful because the method promotes systematic attention to users.",
Surveillance for controlled performance degradation during failures,"Graceful performance degradation due to failures can be achieved by maintaining updated system reachability information. This can be accomplished through the early detection of site and communication failures and repairs. Surveillance protocols are responsible for gathering and updating this information which are known as views. The author present a simple, reliable surveillance protocol along with its application to distributed transaction processing systems. The authors examine the effect of surveillance on the performance of transaction processing during failures with and without surveillance. They show that while the cost of surveillance overhead is affordable through a fixed additional MIPS, the benefits of surveillance are indispensable.",
Design of an advanced binary decision machine for on/off industrial control,"An advanced binary decision machine (ABDM) is proposed. A BDM tests a Boolean input variable and branches according to the state of the input. The input, test, and branch operations are performed in one microinstruction. The architecture of the ABDM is shown. It consists of three main components: a control storage; a microsequencer; and an input/output (I/O) subsystem. The ABDM has a powerful instruction set and a high operating speed. It exhibits several features that are essential in complex on/off control applications, including forking, latching and unlatching of an entire input bank, outputting of either a scalar output or a vector output, looping, conditional looping, and nesting of subroutines.",
On the decidability of linear Z-temporal logic and the monadic second order theory of the integers,"The authors extend the monadic theory of the natural numbers and compare the weak monadic theory and the full monadic theory of the integers using automata on bi-infinite words. They also extend linear temporal logic (i.e. N-temporal logic) to Z-temporal logic and then compare Z-temporal logic with the first order monadic theory of the integers. This extension is obtained by using the classical modalities (i.e. X, F, G, U, S), by adding the existential and the universal past operators (i.e. X, F), and by interpreting formulas over Z-words instead of omega -words.",
Computer Simulations in Chemical Engineering Education,,
A new interpretation of lattice structure convergence rates,"The authors examine the lattice structure and its use as a model structure for the identification of signals and systems. The structure is examined in a state-space context, and the parameter information content developed earlier is explored in this useful parameterization. The behavior of a recursive prediction error method (RPEM) lattice identifier, as observed by J.J. Shynk (1987), is explained. The analysis indicates why lattice structures are generally a very good structure on which to base signal or system identification.",
ETKS: generative task modelling in user interface design,This paper examines the benefits and problems of utilising an existing task modelling theory in an advanced interface design tool. The authors offer solutions to problems they encountered and give detailed examples illustrating those proposed solutions. In particular they introduce the beginnings of a formal task modelling language with a well defined syntax and semantics. In addition they outline a task modelling tool for use as part of a user interface design environment (UIDE) that encapsulates these. They focus on the role of a task modelling tool in a UIDE.,
Learning of the Coulomb energy network on the variation of the temperature,"A method that minimizes the energy function on the variation not only of weight but also of temperature for the Coulomb energy network (CEN) is proposed. The proposed method is compared with the traditional learning method using only weight variation. It is shown that learning is done more efficiently and accurately with the proposed method. Since weight and temperature can be learned in parallel, the speed of learning might be doubled if appropriate hardware support is provided. The concept of the distance is used to solve the linearly nonseparable classification problem, which cannot be solved in the traditional supervised CEN.",
Characterization of semiconductor devices using technological and geometric parameters,"In many cases the characterization of semiconductor devices in terms of their technological and geometric parameters is more important for process analysis and device design optimization than that in terms of electrical parameters. The authors present an extension to the FIT-3 parameter extraction program which allows the use of any combination of technological geometric and electrical parameters in characterization of semiconductor devices. The approach is flexible enough to be used for a variety of technologies and for all basic analyses (DC, AC and time-domain).",
Structured Construction of VLSI Circuits Using Adjacency Lists,,
Fast Algorithms for Close-to-Toeplitz-Plus-Hankel Systems of Equations,,
Performance Evaluation of Integrated Services Dqdb and Fddi Networks,,
Robust shape analysis using multistrategy learning,"This paper describes how to integrate subsymbolic and symbolic processes in order to create high-performance shape analysis systems. The specific methodology introduced integrates morphological processing and machine learning techniques such as genetic algorithms (GAs) and empirical inductive generalization. The optimal operators (defined as variable morphological structuring elements) evolved by GAs are used to derive discriminant feature vectors, which are then used by empirical inductive learning to generate rule-based class description in disjunctive normal form. The rule-based descriptions are finally optimized by removing small disjuncts in order to enhance the robustness of the shape analysis system. Experimental results are presented to illustrate the feasibility of the methodology for discriminating among classes of arbitrarily shaped objects, for learning the concepts of convexity and concavity, and for building robust recognition methods.",
Learning capabilities of recurrent neural networks,"The author relates the power of recurrent neural networks to those of other conventional models of computation like Turing machines and finite automata, and proves results about their learning capabilities. Specifically, it is shown that (a) probabilistic recurrent networks and probabilistic Turing machine models are equivalent; (b) probabilistic recurrent networks with bounded error probabilities are not more powerful than deterministic finite automata: (c) deterministic recurrent networks have the capability of learning P-complete language problems; and (d) restricting the weight-threshold relationship in deterministic recurrent networks may allow the network to learn only weaker classes of languages.",
A Modularized Approach To CIM Education,,
"Comments, with reply, on ""Extensions to SQL for historical databases"" by N.L. Sarda","The commenters point out that the author of the above-titled paper (see ibid., vol.2, p.220-30, 1990) failed to acknowledge their contemporary publications of almost identical results and the subsequent, comprehensive refinement of this work. The author replies that he did not have access to their publications. He indicates some differences between their work and his.",
Centralized surveillance of high risk births,"Ultrasonography and cardiotocography are the most widely used diagnostic tools for evaluating foetal stress. We aim to integrate both in a versatile, obstetric monitoring system giving immediate access to processed numerical and alphanumeric data, graphs and images. System resource and task management will be carried out at the top level by a task-sequencing expert system that will enable/disable monitoring, signal processing and display functions, and distribute them among the patients, in accordance with hierarchical task and diagnostic protocol schemes.","Biomedical monitoring,
Monitoring,
Cardiology,
Variable speed drives,
Measurement uncertainty,
Couplings,
Histograms"
Amplification of the functional closure operation,A novel type of closure on the set of all finitary operations on a finite universe is introduced. It is known that the traditional closure generates a continuum structure of closed sets. The problem of which closures admit only finitely many closed sets is studied.,
Sensitivity and Complementary Sensitivity Integrals Applied to a Class of Ill-Conditioned Plants,"We consider a standard robust performance problem for two input, two output diagonal systems. By using the classical sensitivity integral together with an analogous result for the complementary sensitivity function, we derive an upper bound that the plant condition number must satisfy if robust performance is to be achievable. The upper bound is given in terms of the weighting functions used to represent the design specifications.",
The Time-constrained Barrier Synchronizer and its Applications in Parallel Systems,"A barrier synchronizer, allowing processors to participate dynamically by letting them register their intent to participate within a timeout period, is presented. The synchronizer allows some applications - like software combining and highly concurrent queue operations - to be implemented in a rather unconventional but highly efficient manner. The barrier synchronizer generates successive time windows, allowing requests within the same window to be combined, thus ensuring a more-or-less fixed latency for the Fetch-and-Op primitive.",
Decidable problems in shallow equational theories,"Results for syntactic theories are generalized to shallow theories. The main technique used is the computation by ordered completion techniques of conservative extensions of the starting shallow presentation which are, respectively, ground convergent, syntactic, and cycle-syntactic. In all cases, the property that variables occur at depth at most one appears to be crucial. shallow theories thus emerge as a fundamental nontrivial, union-closed subclass of equational theories for which all important questions are decidable.",
A lingua franca for concurrent logic programming,"Two of the more important concurrent logic programming languages with nonflat guards are GHC and Parlog. They balance the requirements of having clean semantics and providing good control facilities rather differently, and their respective merits are compared and contrasted. Since concurrent logic programming would benefit from both, but neither language is able to express all the programs expressible in the other language, a lingua franca of these languages is defined and justified. A method is given for translating GHC and Parlog to and from it. The method preserves the arities and execution conditions of each clause. It enables a lingua franca implementation to support both languages transparently, and to provide a simple concurrent logic programming language suitable for programming in its own right.",
Long-term potentiation: A developmental study in the freely-moving rat,"Hippocampal dentate granule cell field potentials were recorded from 30- and 90-day old rats before, and at timepoints out to 24 hrs after tetanization of the perforant pathway. Evoked field potentials were analyzed for tetanization-induced changes in measures of the population EPSP slope (a measure of synaptic drive) and the population spike amplitude (a measure of cellular discharge). The results indicate a dissociation between potentiation of the EPSP slope and population spike components of the granule cell response in 30-day old animals. This is reflected as a greater net rise in transmission efficacy than that obtained in the 90-day age group. The results of early efforts to characterize the dentate granule response in freely-moving 15-day old animals are also presented.",
Hybrid loop interchange: optimization for parallel programs,"Parallel loops account for the greatest amount of parallelism in numerical programs. Executing nested loops in parallel with low run-time overhead is thus very important for achieving high performance in parallel processing systems. However, in parallel processing systems with caches or local memories in memory hierarchies, 'thrashing problem' may arise whenever data moves back and forth between the caches or local memories in different processors. Previous techniques can only deal with the rather simple cases with one linear function in the perfectly nested loop. The authors present a parallel program optimizing technique called hybrid loop interchange (HLI) for the cases with multiple linear functions and loop-carried data dependences in the nested loop. With HLI they can easily avoid the 'thrashing problem' without reducing the program parallelism.",
Computer-aided instruction for VLSI design using the NeXT workstation-phase III,"In response to the need for interactive computer-aided instruction (CAI) tools for higher education, a prototype VLSI tutorial using the NeXT workstation has been developed. The NeXT workstation was used as the CAI platform due to its ease in integrating text, graphics, image, and sound to provide an interactive environment. The resulting system is a Hypercard-like video/audio system which teaches the fundamentals of VLSI design. A generic tutorial system has been created requiring the developer to produce only images and lectures. The research discussed presents the addition of tutorials for Electric Circuit Analysis I (sophomore level course) and Digital Signal Analysis and Processing (junior level course).",
Representation and control of knowledge bases for support of multiple tasks,"The goal was to develop a use-independent knowledge structure at the domain and strategy level and to enable a knowledge-based system to exhibit diverse dimensions of expertise, such as problem-solving, explanation, and learning, using the knowledge base. The authors show the functional capabilities of such advanced generic expert systems with respect to representation and control of problem solving strategy knowledge. In this approach, domain and meta level knowledge is represented in a declarative, explicit, and modular way. This improved representation at the strategy and domain level enables the performance system, MINERVA, and the learning program, ODYSSEUS, to use the same knowledge base. Explicit representation of schedular knowledge enables MINERVA to solve a problem opportunistically and to generate multi-level explanations of its own problem-solving.<>",
A Partitioned Translation Lookaside Buffer Approach to Reducing Address Bandwidth,"Simulations indicate a simple modification of existing virtual memory hardware can significantly reduce the number of pins required to transmit address information from processor to off-chip memory. This modification consists of partitioning a TLB so that virtual page numbers are stored in a cache on the processor and corresponding real page numbers are stored in registers at the memory, making it possible to transmit a small register index instead of the entire real page number.",
Towards a national collaboratory: an Internet file system,"Jade is a distributed file system that provides a uniform way to name and access files in an Internet environment. It makes three important contributions. First, Jade integrates a heterogeneous collection of existing file systems, where heterogeneous means that the underlying physical file systems support different file access protocols. It is designed under the restriction that the underlying file systems may not be modified. Secondly, the system is partitioned into a collection of per-user, autonomous, well-balanced, logical file systems, each of which consists of a set of physical file systems and a dedicated private, logical name space. Finally, the author presents a global, Internet-wide name space that is built on top of Jade without any modification of the file system.",
"Aladdin: a high performance, distributed memory multiprocessor","Describes the design of the Aladdin architecture and the implementation of the prototype which Alliant Techsystems is under contract to deliver to DARPA and the Army's CCNVEO. The primary goal of the Aladdin project is to design an architecture that has high throughput and is compact, programmable, modular, reconfigurable and scalable. The architecture must be suitable for automatic target recognition (ATR) and radar processing, get flexible enough to be reconfigured for applications such as avionics processing. The architecture is demonstrated in a soupcan-sized prototype that consists of 64 320C30's with 92 MBytes of memory, and 16 Alliant Techsystems proprietary Parallel Recirculating Pipeline (PREP) chips supported by 512 KBytes of multiport memory. It has a throughput of 2 GFLOPS, 1 GOPS, 1056 MIPS, and can be programmed in Ada, C and Image Algebra.",
Structure optimization of multilayer neural networks with cross connections,"Problems of choosing the structure (the number of layers and the number of neurons in a layer) for multilayer neural networks with cross connections and consisting of neurons with two lattices are considered for the solution of pattern recognition problems. Consideration is given to multilayer neural networks with complete cross connections where the attribute set of each layer consists of initial space attributes and output signals of the first, second, and (j-1)th layers. An attempt is made to formalize the structural determination of these networks and their structural optimization according to various criteria.<>",
Conducting business history research in MIS: notes on the Harvard MIS History Project,"During the Spring of 1988, the Harvard MIS History Project was established. Its primary mission is to develop a historical tradition in MIS research. To date, several exemplary IT-based business histories have been initiated. Studies of the Bank of America (including major changes in the banking industry) and of American Airlines are nearing completion. This paper argues that there is a currently unfilled need for an historical tradition in MIS research. It discusses why histories, especially an MIS-focused history, are important. Broad outlines for a methodological approach are also presented.",
"A comparison of high-speed data links, their commercial support and ongoing R&D activities","The authors describe high-speed communication links and protocols of interest for high-energy physics data acquisition systems. The protocols covered are High Performance Parallel Interface (HIPPI), Serial HIPPI, Fibre Channel (FC), and Scalable Coherent Interface (SCI). The initial work required to implement an SDC (Solenoidal Detector Collaboration)-like data acquisition system is also described.",
Fuzzy clustering using extended MFA for continuous-valued state space,"In classical clustering, an item must belong to any one cluster, whereas fuzzy clustering describes more accurately the ambiguous type of structure in data. MFA (mean field annealing) combines characteristics of simulated annealing and a neural network, and exhibits the rapid convergence of the neural network, while preserving the solution quality afforded by SSA (stochastic simulated annealing). An extended MFA algorithm to solve the fuzzy clustering problem is proposed. It has continuous-value state space. The results of the experiment are given and compared with those of the fuzzy ISODATA algorithm. Fuzzy clustering using the MFA algorithm shows a lower energy state than that of the fuzzy ISODATA algorithm. The perturbing of only one variable is simpler and faster than traditional SSA method to perturb all the variables together, and ultimately enables true parallelism.",
A Signal-Independent Svd-Based Method for Band-Limiting Finite Extent Sequences,,
SELSYN-C: a self-synchronizing parallel programming language,"The authors report their design and implementation of a new self-scheduling parallel programming language, SELSYN-C. Their approach to the challenge of parallel programming language design and implementation is two-fold: (1) the design of simple extensions to C that are both easy to use, and useful for effective compilation, and (2) the design of efficient and effective scheduling strategies that can be automatically supported by a compiler and associated run-time environment.",
The Siberian approach for an open-system high-performance computing architecture,"Describes the 'Siberia' project, which is being developed at the Computing Centre of the Siberian Division of the Russian Academy of Sciences. This project has a pragmatic and a research objective. The pragmatic objective is the creation of a high-performance computer system (HCS) intended for the operation of the supercomputing centre for global simulation and large-scale computation. The research objective is the investigation of ways to develop open general-purpose parallel systems of special-purpose parallel components. The latter should be a basis for operational design, development or adaptation of scalable problem-oriented systems. The concepts of large-block system design, sustaining multiple hardware paradigms, multiple software models, as well as existing languages and environments, are considered. The architecture and software of the HCS are presented. Topics for possible research cooperation are emphasized.",
On the nature of bias and defects in the software specification process,"Implementation bias in a specification is an arbitrary constraint in the solution space. The authors describe the problem of bias and then present a model of the specification and design processes describing individual subprocesses in terms of precision/detail programs, and a model of bias in multi-attribute software specifications. While studying how bias is introduced into a specification it was realized that software defects and bias are dual problems of a single phenomenon. This has been used to explain the large proportion of faults found during the coding phase at the Software Engineering Laboratory at NASA Goddard Space Flight Center.",
Formal specification of fault management system using O-Estelle,"The authors discuss the formal description of a real time application, viz a fault management system (FMS) for the OSI environment, using O-Estelle. O-Estelle is an object oriented specification language that has been proposed by the authors for describing real time applications (Prabhakaran and Ragahvan, 1990). O-Estelle is an Estelle based language with extended features. A distributed FMS is a set of fault managers running concurrently on several systems. It is the responsibility of the fault manager (FM) on each system to detect, isolate and possibly rectify the faults in the system. Management services are provided to the FM to perform its tasks and to communicate with FMs on other systems. The formal description of such a distributed application requires additional features in description languages like Estelle. O-Estelle description of the FMS can be used for protocol verification and semiautomatic generation of software for FMS.","Formal specifications,
Flexible manufacturing systems,
Fault detection,
Computer network management,
Computer errors,
Error analysis,
Real time systems,
Object oriented modeling,
Application software,
Computer science"
A prototype functional language implementation for hierarchical-memory architectures,"Programming languages are the most important tool at a programmer's disposal. All other tools correct, visualize, or evaluate the product crafted by this tool. The advent of multiprocessor computer systems has greatly complicated the programmer's task and increased his need for high-level languages capable of automatically taming these architectures. The authors describe a prototype implementation of Sisal for multiprocessor, hierarchical-memory systems. The implementation includes elicit compiler and runtime control that effectively exploits the different levels of memory and manages interprocess communications (IPC). They give preliminary performance results for this system on the BBN TC2000.",
Barriers and break-points in dataflow: extensions to SISAL language,"The pure dataflow model of computation has such advantages as fine-grain parallelism, freedom from side-effects, and synchronization based purely on data dependencies. However, the model is not very amenable for describing coarse-grain parallelism, barriers and break-points. The paper shows how a dataflow language (SISAL) can be extended to permit the definition of coarse-grain processes, synchronization using join construct, and break-points for the purpose of debugging. The extensions do not violate the data-driven principles.",
A new class of interconnection networks based on alternating group,"The authors present an analysis of a new class of interconnection scheme based on the Cayley graph of the alternating group. The definition and an analysis of the symmetry of this class of graphs are presented, and a shortest-path routing algorithm is given. An algorithm for embedding of the Hamiltonian cycle is presented, and an algorithm for embedding grids is given. A greedy spanning tree algorithm for one source broadcasting and an analysis of the contention problem are also given.",
Estimating register cost using spots,"A modified register allocation algorithm whose register cost uses distinct spots is introduced. With this method, the five range of a variable can be viewed as a collection of spots, which are coordinate distances. Together with the usage counts of a variable and the increased weight on variables in loop structures, the cost of each variable already in a register is estimated. In the case where a spill is unavoidable, a variable in a register with minimum cost is chosen. Primary results show that this method increases speed about 21% in terms of the number of load/store instructions when compared with Chow's graph-coloring method.",
Flexible Task-Specific Control Using Active Vision,,
Decentralized Strong Stabilization Problem,"In the decentralized strong stabilization problem for linear time-invariant finite-dimensional systems, the objective is to stabilize a given plant using a stable decentralized controller. A solvability condition for this problem is given in terms of a parity interlacing property which is to be satisfied among the real unstable poles and real unstable decentralized blocking zeros of the plant. The problem of synthesizing decentralized stabilizing controllers with minimum number of unstable poles is also solved.",
On a fundamental relationship between software reuse and software synthesis,"While specifications for reusability state what software component is needed, specifications used to deduce programs state what problem is to be solved. Due to the imprecision found in languages intended for either area, there are often multiple, correct interpretations of the specifications. This is the problem of ambiguity. Ultimately there is a balance which must be struck between precision in specification and ambiguity. To raise the level of abstraction in problem solving, precision is sacrificed, thus introducing the perils of ambiguity. The paper introduces results concerning ambiguity from the area of program synthesis and relates these results to the area of software reusability. Both software reusability and synthesis are areas which figure prominently in rapid prototyping.",
Architectural support for conditional antidependency elimination,"Conditional antidependency elimination is a new low level (core) transformation for global code optimizing. It can eliminate or change control dependencies for individual operations, although with additional operations introduced for all relevant traces. With a proper high level guidance, near optimal or even optimal execution speeds are obtained. The described guidance rules for an IF-THEN-ELSE structure give optimal code for both traces. A VLIW machine architecture is modified by introducing twin registers for reducing the number of additional operations in conditional antidependency elimination. These registers are transparent for the user, since the compiler selects which variables use twin registers.","Optimizing compilers,
Scheduling algorithm,
Computer science,
VLIW,
Parallel processing,
Optimal control"
Simultaneous SPECT and CT with shutter controlled radionuclide line sources and parallel collimator geometry,"Summary form only given. A computer-controlled shutter device with four narrow collimated radionuclide line-sources for combined SPECT (single photon emission computed tomography) and CT (computed tomography) using a rotating gamma camera has been designed. Accurate attenuation of information is limited to four sections of the object but the activity of the sources, and thus the number of events through these sections, can be increased without overloading the camera. With /sup 99/Tc/sup m/, SPECT data are acquired with the shutter closed and CT data with the shutter open. In this case, correction for disturbing emission data in the transmission data is necessary and the examination time is prolonged by 30-50%. With four 1 GBq /sup 99/Tc/sup m/ line-sources, the image noise was about 8% (SD) in each of the four sections at a transmission acquisition time of 3 s/angle and 128 angles. The reliability of the transmission data and its noise propagation have been further analyzed by simulation and by phantom and patient-measurements for various radionuclides and different methods of attenuation correction.<>",
Management of persistent objects in the Nexus distributed system,"The Nexus distributed operating system is designed to provide support for persistent objects in a local area network independent of any specific high-level language. The paper describes the generic object management facility of Nexus which can be used to implement different object-oriented programming languages or application systems above Nexus. An object manager serves two functions: first it acts as the class-object, and second it acts as the manager for the instances of its class. The generic object manager is linked to a user-specified type definition to build an object manager for that type. If needed, system developers can tailor the object manager to implement specific policies.","Kernel,
Operating systems,
Computer languages,
Object oriented programming,
Workstations,
Object oriented modeling,
Intelligent networks,
Computer science,
Local area networks,
High level languages"
The study and development of combined artificial intelligence architectures to solve important problems in computer vision,"The author proposes a number of architectures for continued development of intelligent computer vision systems. He describes an approach to developing computer vision systems which will include the development of an overall system based on three parts. First, aspects of human and computer vision, and intelligence are studied. The second part of the project is the development of artificial intelligence (AI) algorithms for application to specific problems and issues in computer vision. The last part of the project is the integration of these algorithms and existing techniques under a new architecture so that more complex, less restricted applications can be addressed.",
Resource-requirement minimization in relocation problems with precedence constraints,"The relocation problem is a generalized resource-constrained job scheduling problem in the aspect that the amount of resources returned at the completion of a job is not necessarily equal to that demanded. The authors propose fundamental properties of the basic relocation problem. Also, they consider a variant RPPC into which precedence constraints are introduced. They show that RPPC is NP-complete, even if the precedence graphs are bi-partite. Furthermore, efficient algorithms are presented to solve some polynomially solvable subproblems.",
Visual metaphors: 3D interfaces for knowledge workers,"Between 1984 and 1987 a team of researchers in the Human Interface Program at the Microelectronics and Computer Technology Corporation (MCC) investigated innovative ways of building and using 3D user interfaces and graphic realism to support knowledge workers. Their research included knowledge-based applications of 3D user interfaces such as SemNet and was principally focused on a user interface development environment which they called the Metaphor Builder. This suite of tools included a representation scheme called GrafBag, a 3D editor called Visage, and a model editor called GrabGraf. The authors validated these tools by building the Visual Office, a 3D environment for managing work contexts. This research was accomplished in an advanced development environment created by integrating a Lisp machine with a 3D display engine. The authors describe how the Visual Office was designed and implemented using components of the Metaphor Builder.",
Apple tasting and nearly one-sided learning,"In the standard on-line model the learning algorithm tries to minimize the total number of mistakes made in a series of trials. On each trial the learner sees an instance, either accepts or rejects that instance, and then is told the appropriate response. The authors define a natural variant of this model ('apple tasting') where the learner gets feedback only when the instance is accepted. They use two transformations to relate the apple tasting model to an enhanced standard model where false acceptances are counted separately from false rejections. They present a strategy for trading between false acceptances and false rejections in the standard model. From one perspective this strategy is exactly optimal, including constants. They apply the results to obtain a good general purpose apple tasting algorithm as well as nearly optimal apple tasting algorithms for a variety of standard classes, such as conjunctions and disjunctions of n boolean variables. They also present and analyze a simpler transformation useful when the instances are drawn at random rather than selected by an adversary.",
Learning to predict DNA hydration patterns,"The authors examine the problem of learning to predict hydration patterns around DNA molecules. It is assumed that there is a limited, but so far unknown, set of hydration patterns, and that there is a set of features of a DNA molecule which determines its pattern. Since the patterns for the DNA molecules in the database were not known a priori, most traditional classifier learners cannot be applied directly. The authors have combined cluster analysis with a decision tree learner to develop classifiers, even though training examples were not initially labeled with classes. Some empirical results of this learning are presented, and it is shown how the learned decision trees are being used to gain insight into the domain of DNA crystallography.<>",
Nearly optimal vector quantization via linear programming,The authors present new vector quantization algorithms. The new approach is to formulate a vector quantization problem as a 0-1 integer linear program. They first solve its relaxed linear program by linear programming techniques. Then they transform the linear program solution into a provably good solution for the vector quantization problem. These methods lead to the first known polynomial-time full-search vector quantization codebook design algorithm and tree pruning algorithm with provable worst-case performance guarantees. They also introduce the notion of pseudorandom pruned tree-structured vector quantizers. Initial experimental results on image compression are very encouraging.,"Vector quantization,
Linear programming,
Algorithm design and analysis,
Clustering algorithms,
Iterative algorithms,
Approximation algorithms,
Partitioning algorithms,
Computer science,
Image coding,
Contracts"
An incremental protocol test method: formal modeling and architectures,"To ensure that the implementation of a communication protocol conforms to its specification, a protocol test process is invoked to check for conformance. In this paper, an incremental protocol test method is proposed. The incremental protocol test method is based on modifying test architectures and enhancing formal description techniques (FDTs) functionalities so that they are powerful enough to be used in both the design phase and the test phase. To provide for direct control and observation, the proposed method has: a single high level formal representation mechanism, which is the OPS5 production system, to be used in both the design phase and the test phase; a test sequence generator and state monitor (TGM) that is added to the local environment. In this way, protocol test sequence generation is formally represented in production rules by combining those related elements in the formal protocol specification with additional elements used for controllability and observability in the test process.",
Computational Entropies,,
An optimal parallel algorithm for finding the smallest enclosing rectangle on a mesh-connected computer (for rectangle read triangle),"The authors consider the problem of finding the smallest triangle circumscribing a convex polygon with n edges. They show that this can be done in O( square root n) time by efficient data partition schemes and proper set mapping and comparison operations using a so called square root n-decomposition technique. Since the nontrivial operation on MCC requires Omega ( square root n), the time complexity is optimal within a constant time factor.",
Solutions to the phase problem of X-ray crystallography on the Connection Machine CM-2,"The authors have developed a formulation of the phase problem of X-ray crystallography in terms of a minimal function of phases and a new minimization algorithm called shake-and-bake for solving this minimal function. The implementation details of the shake-and-bake strategy on the Connection Machine CM-2 are presented. The shake-and-bake algorithm has been used to determine the atomic structure of four test structures, ranging from 28 to 317 atoms. These results indicate that shake-and-bake is effective on structures of this size.",
Motion Estimation Of Unknown Object For Space Robotic Missions,,
Bridging Behavioral and Register-Transfer Synthesis,"This paper considers register-transfer synthesis and optimization from a control-data flowgraph specification. In contrast to scheduling under resource constraints, we derive a register-transfer (RT) description without imposing constraints on resources. The initial RT-level description may seem to have an excessive number of functional units and multiplexors, however it will typically exhibit also high signal reconvergence. We demonstrate with non-trivial benchmark examples that regions of high signal reconvergence offer high resynthesis and optimization potential also at RT-level, producing standard cell realizations that are comparable and competitive with alternate approaches in all aspects: layout area, path delay and gate-level testability. Tradeoffs in resource allocation are examined at RT-level only after optimizing the initial description. The RT-level description we generate serves as a top-level input to OASIS, which expands it to the required data-path components, synthesizes all control specifications, performs test generation and global optimization by redundancy removal and submits the final standard cell netlist for automatic placement and routing.",
A Functional/Declarative Dichotomy for Characterizing Simulation Models,,
Analytical modeling of advanced reactor passive containment cooling systems to assess wind sensitivity,"Summary form only given. A computer analysis was performed to determine the effects of wind on the Heavy Water Reactor Facility (HWRF) Passive Containment Cooling System (PCCS). The PCCS is designed to remove heat released to the containment following a postulated beyond design basis event. Because the PCCS relies on natural convection and buoyancy-driven flow to remove heat, external wind effects must be evaluated to assure that the system performance is not degraded for any credible wind condition. The TEMPEST code was used to analyze the HWRF PCCS for various wind velocities and directions. A 3-D model for the PCCS and surrounding structures was constructed, and the results of this analysis indicate that the design is essentially wind-neutral, with no appreciable increased or decreased performance for wind speeds of 0-60 ft/s. The results of this analysis will be used to provide pretest predictions for wind tunnel testing scheduled for 1993.<>","Analytical models,
Inductors,
Cooling,
Performance analysis,
Wind speed,
System performance,
Degradation,
Wind forecasting,
Testing,
Scheduling"
A Fast Algorithm for Extrapolation of Discrete-Time Periodic Band-Limited Signals,,
"The DaCapo project: distributed, active, communicating, persistent objects","DeCapo unifies state, processing thread, synchronization, distribution, persistence, and mobility into the concept of an object. This is reflected both in the DaCapo programming language and the DaCapo system. By doing so, the authors have achieved a simple, yet powerful object model for object-oriented distributed software systems.",
An evolutionary focus on information technology: graduate CIS education at Georgia State University,Describes the characteristics of the graduate programs in computer information systems (CIS) at Georgia State University and the way in which the faculty manage their continual evolution. The authors articulate the underlying assumptions about the future need of graduates and incorporates trends in the development and use of information technology into program planning. Integration of information technology and management of information systems are a distinct theme of the program.,
Towards a tool for the design of cooperating expert systems,"A tool to aid the designer of cooperative distributed problem solving (CDPS) systems will determine whether a proposed CDPS system violates any of the constraints for CDPS systems, and will display a prediction of the performance that can be expected from that CDPS system. This tool will rely on a predictive model for the performance of the expert systems in the CDPS system. Using the Blackbox Expert (a DAI testbed), an experiment was conducted to test the performance of expert systems in a CDPS system. Statistically significant differences in the Blackbox Expert's performance were found when the CDPS system was changed. The results of the experiment are being using to create a predictive model for the performance of the Blackbox Expert when it is a member of the CDPS system.",
Design and implementation of a distributed semaphore facility,"This paper describes a distributed semaphore facility called DISEM. DISEM supports semaphore mechanism in a distributed workstations environment, it is implemented at the application level for workstations running a version or a derivative of UNIX operating system which support BSD sockets and System V IPCs. In addition, DISEM also provides fault tolerant service in case a workstation crashes. Generally speaking, DISEM is a useful and portable facility for supporting of distributed semaphore in a local network of workstations.",
Persistence+undoability=transactions,"Persistence means objects live potentially forever. Undoability means that any change to a program's store can potentially be undone. In their design and implementation of support for single-threaded nested transactions in Standard ML of New Jersey (SML/NJ), the authors provide persistence and undoability as orthogonal features and combine them in a simple and elegant manner. They provide support for persistence through an SML interface that lets users manipulate a set of persistent roots and provides a save function that causes all data reachable from the persistent roots to be moved into the persistent heap. They provide support for undoability through an SML interface that exports two functions: checkpoint, which checkpoints the current store, and restore, which undoes all changes made to the previously checkpointed store. Finally, they succinctly define a higher-order function transact completely in terms of the interfaces for persistence and undoability.",
Control Information Database,"The University of Glasgow has been awarded a contract by the U.K. Science and Engineering Research Council to setup and run a computer database, accessible via JANET, to ""facilitate information dissemination within the Control community"". The database is available for access over JANET, and from other networks with connections to JANET including the worldwide Internet.",
Data-parallel training of spatiotemporal connectionist networks on the Connection Machine,"An algorithm for optimizing spatiotemporal connectionist networks utilizing training set parallelism has been implemented on the Connection Machine (CM). The algorithm supports several optimization methods including backpropagation, conjugate gradient, and pseudo-Newtonian. By allocating one CM processor per training example, the computational complexity of the gradient derivation becomes independent of the number of training examples. The author has experimentally corroborated this independence, and reports the timing performance of the Connection Machine implementation on a series of spatiotemporal discrimination tasks. He also presents the timing performance of a serial implementation of the algorithm, running on an IBM RS/6000, to emphasize the efficacy of the data-parallel approach.",
Unraveling mechanisms in vesicular dataflow model,The vesicular dataflow (VDF) model has been proposed as an extension to the classic dataflow (DF) model to strengthen its potential. Vesicles are places where tokens can be stored and retrieved from. State-dependent computations are possible following the dataflow principle. Embedding of the unraveling mechanisms directly to the dataflow programs can be accomplished by employing vesicles. The flexibility of token colouring mechanisms was achieved by shifting the problem from implementation level to model level.,
A visual specification model for evolutionary information systems,"The paper presents an approach viewed from an application perspective to cope with changes in an evolutionary information system. It presents a visual specification design, change, and redesign. The VSM includes change management to make resolvable schema changes transparent for existing programs so the redesign or modification of the system can be avoided. It also provides change history to assist a designer in redesigning the specification when the change is unresolvable.",
The power of combining the techniques of algebraic and numerical computing: improved approximate multipoint polynomial evaluation and improved multipole algorithms,The authors demonstrate the power of combining the techniques of algebraic computation with ones of numerical computation. They do this by improving the known methods for polynomial evaluation on a set of real points and for simulation of n charged particles on the plane. In both cases they approximate (rather than exactly compute) the solutions and do this by exploiting algebraic techniques of the algorithm design.,
SPY: a monitoring system for the silicon vertex detector of CDF,"Summary form only. With the advent of silicon multistrip revelators, the problem of monitoring all their channels (in the present case approximately 40000) in a relatively short time, before or during data acquisition, becomes important. To do that, a system has been developed that takes data from the 'serial' front-end of the relevator and processes them in an online style, giving the results to the Experiment Computer Cluster. This is done with 12 boards accommodating two 2048 words*27 bits FIFOs each, that will hold an event, and with a computing engine (a 30-MHz 38030 with 12 MBytes of RAM) with one Ethernet port to connect it to the other computers.<>",
Intracranial pressure dynamics in patients with severe head injury: A mathematical study,"The time pattern of intracranial pressure (ICP) was examined in five patients with severe head injury using an original mathematical model of craniospinal dynamics. With this model we simulated the ICP response to the injection or withdrawal of small amount of fluid into the cranial cavity, and the ICP pulse amplitude sincronous with the cardiac beat. Results of our simulations indicate that, in two patients, the time pattern of ICP can be explained through a balance between CSF production rate, CSF reabsorption rate and the storage capacity of the craniospinal system. However, in the other three patients, the ICP time pattern exhibited an anomalous response following fluid injection or fluid withdrawal. The model explains these responses imputing them to active changes in cerebral blood volume induced by regulatory mechanisms. In conclusion, our study supports the idea that the ICP pattern cannot be imputed only to CSF dynamics and craniospinal compliance. In several cases the interaction between ICP and cerebral hemodynamics must be also taken into account to gain sufficient understanding of the biomechanical factors leading to ICP changes in patients with severe head injury.",
A logical model and schema integration architecture for determining equivalence in ER-diagrams,"Equivalence determination, a subset of the schema integration process is discussed. An integration architecture that assists in the automation of the process is described and a formalism that maps from ERDs to a first-order logic model suitable for implementation with a language like Prolog is described.",
Service and traffic management for IBCN,"The future Integrated Broadband Communications Network (IBCN) will provide high-speed communication capabilities that support a variety of existing and new services. The management of such a complex environment requires innovative management systems. NEMESYS is a project within the European Commission's Research and Development in Advanced Communications in Europe (RACE) program. The project goals are to demonstrate and evaluate the use of advanced information processing techniques for quality-of-service and traffic management. To reach these goals, a series of experimental prototypes are being built. This paper describes the assumptions, objectives, and approach of NEMESYS, and in particular, the design and implementation of an experiment that investigates service and traffic management techniques in a simulated asynchronous transfer mode environment. Because the project is not yet finished, some preliminary results are presented.",
"Intraoperative, real-time 3-D digitizer for neurosurgical treatment and planning","Summary form only given. An easy-to-use interface has been developed that allows real-time image localization and 3-D volume data set reformatting for use with computed-tomography (CT) and magnetic-resonance-imaging (MRI) images. As the basis for an intraoperative armless and frameless means of head stereotaxis, the surgeon uses a 3-D digitizer and an ultrasonic neurowand intraoperatively to register fiducials located on a patient's head with image voxels stored in a workstation. Once this registration step is performed, the tip of the wand can be located in both the image and patient coordinate systems. In near real-time, coronal, sagittal, and axial sections (triplanar display) of the patient's anatomy located by the wand are displayed on a graphics workstation. The neurowand has been used to chart and record the positions of scalp and intradural electroencephalography electrodes in 3-D MRI volume data sets. Three-dimensional rendering of these data reveals the precise location of the electrodes with respect to the gyral and sulcal anatomy of the brain.<>",
Time and probabilities in specification and verification of real-time systems,"We present a framework for specification and verification of real-time and reliability in distributed systems. The framework consists of a language for describing the operational behaviour of systems, a logic for formulating system properties, and an algorithm for verifying that descriptions an the language satisfy formulas expressed in the logic. The language, TPCCS, as an extension of Miher¿s Calculus of Communicating Systems (CCS) with discrete tame and probabilities. The logic, TPCTL, is a branching time temporal logic, essentially extending Emerson, Clarke and Sistla¿s CTL with quantitative time and probabilities. The logic can be used to formulate reliability, real-time, and performance properties. A small example is used to illustrate how the operational behaviour of a system can be formulated in TPCCS, how its properties can be specified in TPCTL, and how we can verify that the TPCCS description satisfies the specified properties.",
Embedding discriminant directions in backpropagation,"A two-phase backpropagation algorithm is presented. In the first phase the directions of the weight vectors of the first hidden layer are constrained to remain in directions suitably chosen by pattern recognition, data compression, or speech and image processing techniques. Then, the constraints are removed and the standard backpropagation algorithm takes over to further minimize the error function. The first phase swiftly situates the weight vectors in a good position which can serve as the initialization of the standard backpropagation algorithm. The generality of its application, its simplicity, and the shorter training time it requires, makes this approach attractive.",
Application of Linda to molecular modeling,"Presents a sampling of work applying parallel computation to computational chemistry using the Linda machine-independent parallel programming language. The authors focus on two projects in particular. The first project parallelized the well-known distance geometry program, DGEOM, while the second project looked at a molecular dynamic code. In both cases, the Linda programs were relatively easy to develop and delivered good performance on a variety of MIMD architectures.",
Comparing results from defect-tolerant yield models,"To date, many models have been developed to predict the yield of defect-tolerant integrated circuits (ICs). In this paper, results obtained from several of these models are compared. Their sensitivity to various model parameters is also examined. These results lead one to conclude that, despite differences in the predicted amount of redundancy, it may be possible to obtain good solutions. The differences in the solutions come from the models as well as from the parameters used in these models, and solutions are said to be good when the resulting figures of merit are rather insensitive. Consequently, a simple method is proposed to select the number of spares to add in defect-tolerant ICs.",
Saving gas and saving money-integrating an expert system into the process monitoring of steel making,"As a by-product of an oxygen steel-making process, large amount of carbon monoxide gas are produced. This gas, which is a valuable fuel, was not being collected during every steel-making blow due to engineering faults. The main reasons were associated with the operation of the programmable logic controller (PLC) controlling gas collection on each vessel. The PLC, which is programmed to abort gas collection whenever problems arise in the gas recovery system, was giving no warning to the process engineers that it intended to abort gas collection, nor a reason for dong so. The building of an expert system to interpret the output of the PLC and waste gas analysis system and report error conditions that had either prevented or aborted gas recovery during the current blow, or would prevent gas recovery in a future one, is described.",
A Methodology for the Desigu of Human-Computer Interfaces for Factory Automation Systems,,
Use of unit clauses and clause splitting in automatic deduction,"A mechanical theorem prover usually has to perform unification which is a very time-consuming operation. Therefore, it is necessary to reduce the number of unification operations to obtain speedups. There are two ways to do this. One is to restrict the literals to be unified with the underlying literal, and the other is to make clauses small. Four techniques: unit simplification, ground unit clause generation, UR simulation, and small proof checking, can restrict the literals to be unified with. All these techniques take advantage of unit clauses. The clause splitting technique is able to reduce the length of a clause by splitting the clause into shorter clauses. These techniques improve dramatically the efficiency of a theorem prover, using the hyper-linking method, in many cases.",
Imaging tool applications for nuclear power plants,"All nuclear power utilities are interested in saving costs, reducing radiation exposure, making task supervision easier, and enhancing worker effectiveness. Recent EPRI (Electric Power Research Institute) research indicates that imaging tools, ranging from low-cost CCTV (closed-circuit TV) to videodisc systems and photogrammetry, can be effective means for achieving these benefits. Some of the techniques, such as CCTV and videodisc systems, are already being used extensively and offer proven results. Others are scarcely being used despite their potential. Current programs for updating existing plants and designing new ones make it important to recognize that images-whether films, transparencies, video, line drawings, computer graphics, or others-play an essential role in plant operations and maintenance. The authors present examples of potential cost-saving benefits and limitations of some principal techniques.","Power generation,
Costs,
Cameras,
Circuits,
TV,
Virtual reality,
Inductors,
Energy management,
Project management,
Image recognition"
User-friendly software system for analyzing antennas and radiowave propagation links,"The authors describe a software system that simplifies the use of proven analysis codes by interfacing them with a user-friendly, Windows-based pre-/postprocessor. A user with only a basic understanding of PCs and Windows will be able to use the system to predict the performance of any antenna structure or communication link. This broad applicability is achieved by integrating a unique selection of available algorithms into a single package. The system uses closed-form and simple moment method (MM) solutions that allow an analyst to perform quick parametric studies of generic antenna types. It also uses state-of-the-art MM and GTD (geometric theory of diffraction) codes to model in detail virtually any antenna structure of any size. Propagation codes are included so that complete end-to-end system performance can be determined.",
Parallel language constructs for efficient parallel processing,"Proposes some basic language extensions to incorporate a parallel procedure model into the C programming language. In order to improve on other proposals, the authors set the goals of their design to attain increased efficiency, flexibility, and expressiveness, and to improve parallel program structure. They begin by discussing the motivation for these goals, and then present an overview of their proposed model for parallel procedures. They then describe the design of the run-time system that supports the parallel procedure model. A novel scheme for nesting parallel procedure contexts in multiple stack frames is included in the run-time system, thus eliminating the need for costly process control blocks. After describing the details of the language and run-time system design, the authors then present detailed performance data for two parallel programs using this system.",
On recognition of Bengali numerals with backpropagation learning,The authors address various aspects of the problems associated with processing and recognition of printed and handwritten Bengali numerals. A scheme has been proposed for recognizing handwritten as well as printed numerals with different fonts and writing styles. The scheme was successfully used for the recognition of samples of handwritten numerals and the font from printed numerals with a high degree of accuracy. The scheme was also extended for noisy and occluded numerals. The standard multilayer perceptron (MLP) augmented with MAXNET was used as a classifier. The experiments presented have established the superiority of the MLP and MAXNET combined over the standard MLP classifier and the classical nearest neighbor classifier.,
On the power of abstract interpretation,"R.C. Sekar et al. (1991) studied the power of strictness analysis techniques and showed that strictness analysis is perfect up to variations in constants. The authors generalize this approach to abstract interpretation in general by defining a notion of similarity semantics. This semantics associates with a program a collection of interpretations all of which are obtained by blurring the distinctions that a particular static analysis ignores. The authors define completeness with respect to similarity semantics and obtain two completeness results. For first-order languages, abstract interpretation is complete with respect to a standard similarity semantics, provided the base abstract domain is linearly ordered. For typed higher-order languages, it is complete with respect to a logical similarity semantics again under the condition of a linearly ordered base abstract domain.",
Incorporation of global positioning system into autonomous underwater vehicle navigation,"The authors provide a brief introduction to the global positioning system (GPS). In addition, the issues of incorporating GPS into autonomous underwater vehicles (AUVs) navigation are explored. Test results conducted on a stationary GPS receiver are analyzed for suitability in AUV navigation. These results meet the minimum criteria of AUV employment as established. It was demonstrated that small, low-cost, low-power GPS receivers, in general, are suitable for AUV applications. In addition, a system design that the Naval Postgraduate School is now pursuing to incorporate GPS into AUV navigation is presented.",
Recurrent refractory neural field,The author introduces and describes a recurrent neural field that is made up of refractory neurons. Every neutron of the field is chaotically connected to others with stochastically distributed bonds and shows the stochastical time varying threshold. The paper takes the location of the neuron in the space-time-firing state of the neuron field into account. The term neural field is used to describe a single layer intraconnected neural network. The input and output signals are distributed between clusters of closely connected neurons. A simple example shows good logical abilities of the refractory neural field. A three neuron refractory field is able to solve the exclusive OR problem.,
An orientation and resolution independent texture classifier in segmentation of images of unknown rotation and scale,Describes an orientation and resolution insensitive texture classifier for demarcating regions of common texture within a rotated and/or scaled image. The algorithm involves a mask 'tuning' process performed over equal size pure texture samples in the multi-orientation and multi-scale data set via a two-dimensional linked-list. The development of a guided random search approach for parameter optimization is detailed and the segmentation results of collages of Brodatz textures are provided.,
Distribution of winners in local lateral inhibition,"The dynamics of an iterative local lateral inhibition system are analyzed. The study of lateral inhibition is generalized in two significant ways. First, the inhibition range from each neuron is limited to a subset of the neurons, called the neighborhood. The only requirement for these neighborhoods in the discussion is that they be symmetric. That is, if a is a neighbor of b, then b is a neighbor of a. Second, a positive feedback is added to the model as part of the nonlinear normalization function. This normalization function has only to satisfy some very broad requirements. When the neighborhood relaxation expands to all pairs of neurons, the system becomes complete lateral inhibition, and the common winner-take-all consequence should be expected. It is proved that those assignments with a winner in the neighborhood of each loser are asymptotically stable fixed points, and other fixed points are unstable.","Neurons,
Neurofeedback,
Computer science,
Organizing,
Neural networks,
Stability,
Piecewise linear techniques"
A new approach to the associative memory design using neural networks,Proposes a design for associative memory using a neural network. The problem of associative memory is transformed to a constrained optimization problem. The information storage and retrieval algorithms and the network architecture for the proposed associative memory are described. Simulations were carried out to test the proposed storage/retrieval algorithms. The results of these simulations are presented.,
An NC algorithm for finding minimum weighted completion time schedule on series parallel graphs,"The authors present a parallel algorithm for solving the minimum weighted completion time scheduling problem for transitive series parallel graphs. The algorithm takes O(log/sup 2/ n) time with O(n/sup 3/) processors on a CREW (concurrent-read exclusive-write) PRAM (parallel random-access machine), where n is the number of vertices of the input graph. It is noted that this is the first NC algorithm for solving the problem.",
Intelligent vs. unintelligent programming systems for novices,"The approach presented concentrates on integrating intelligent and unintelligent approaches to come up with an environment that helps novices develop not only problem-solving skills, but also an accurate conceptual and mental model of the programming process. DISCOVER, an intelligent discovery program system supports novices in an initial unintelligent free discovery programming phase and in a subsequent intelligent guided discovery programming phase. In the initial phase, novices explore, observe, and discover the dynamic behavior of individual programming concepts and whole programs as well as of the national machine to build the underlying conceptual programming knowledge. In the subsequent phase, novices compose together programming concepts and language constructs, observed and discovered in the initial phase, to solve given problems under explicit intelligent guidance of system domain expert to transform their programming knowledge into programming skill. Several design issues and decisions that have influenced the development of DISCOVER are discussed.",
An Implementation Tool for Safety Management Expert System,,
Using atomic data structures for parallel simulation,"Synchronizing access to shared data structures is a difficult problem for simulation programs. Frequently, synchronizing operations within and between simulation steps substantially curtails parallelism. The paper presents a general technique for performing this synchronization while sustaining parallelism. The technique combines fine-grained, exclusive locks with futures, a write-once data structure supporting producer-consumer parallelism. The combination allows multiple operations within a simulation step to run in parallel; further, successive simulation steps can overlap without compromising serializability or requiring roll-backs. The cumulative effect of these two sources of parallelism is dramatic: the example presented shows almost 20-fold increase in parallelism over traditional synchronization mechanisms.","Data structures,
Parallel processing,
Computational modeling,
Databases,
Computer science,
Laboratories,
Contracts,
Protection,
Protocols,
Writing"
An Effective Spanning Tree Algorithm for a Bridged LAN,,
Dynamic logical structures: a position statement for managing replicated data,"The authors discuss extensions to the grid protocol to improve the fault-tolerance of write operations by using the notions of structured read and write grid quorums. As is the case in the standard quorum protocols, the increased fault-tolerance for write operations is at the increased cost of executing read operations. In order to let users continue using the analogues of the read-one-write-all protocol in the context of a logical structure, they develop reconfiguration protocols for dynamically adapting to failures and recovery. This results in the following dichotomy. Users accesses are through the simple analogues of the read-one-write-all protocol with respect to a logical structure and therefore have low communication cost for read operations. On the other hand, the reconfiguration protocol uses the notion of quorums in the context of a logical structure to ensure high data availability. A similar approach can be applied to the tree protocol.",
A constant-time channel-assignment algorithm on reconfigurable meshes,"A layout problem is specified. A two-sided printed circuit board featuring horizontal lines, called channels, on one side and vertical lines on the other. 2n components are considered along with an interconnection pattern specified in the form of n pairs of components. The interconnections are to be realized with horizontal and vertical wire runs according to specifications. The basic constraints is that two pairs can use the same channel only if their connections do not conflict with one another. The problem of interest is referred to as the channel-assignment problem and asks for a layout that minimizes the total number of channels. To overcome the inefficiency of long-distance communications among processors, some parallel architectures have been augmented by bus systems. If such a bus system can be dynamically changed to suit communication needs among processors, it is referred to as reconfigurable. The authors propose a constant-time algorithm to solve the channel-assignment problem of size n on a reconfigurable mesh of size n*n.",
Unifying multi-paradigms in software system design,"Large software systems are often aimed to deal with problems of multi-application domains or disciplines, where each class of problems has its own defining features, difficulties and emphases. No existing computation model or design paradigm is appropriate for all varieties of problems faced in software design. A unification of existing computation paradigms is thus necessary to accommodate the diverse needs in system design. In this paper, the authors propose a framework based on the notions of logical entity abstraction and instantiation (LEAI), which enables a user to select appropriate computation paradigms to design various parts (or subsystems) of a software system, and to compose the parts into a integrated system. An example is given to illustrate the application of the framework.",
The benefits of maintenance exercises in project-based courses in software engineering,"A particular justification for teaching software maintenance is presented. Specifically, it is pointed out that, when an instructor assigns maintenance exercises in a project-based course in software engineering, and when the assignment includes a carefully organized management model, students learn far more than they would from a traditional from-scratch development project.",
The Role of CAEME in the Stimulation and Propagation of Effective Electromagnetics Education in the USA and Abroad,"The NSF/IEEE Center for Computer Applications in Electromagnetic Education (CAEME) was established in early 1990 as a result of a grant from the Undergraduate Science, Engineering, and Mathematics Division of the National Science Foundation. To help provide broad and international participation in its activities, the Center is managed by the executive office of IEEE. CAEME's objective is to stimulate and accelerate the use of computers and software tools to help boost electrmagnetic education. It is shown in this paper that the Center has helped in propagating effective EM education by providing seed funds for software development projects, organizing workshops and special sessions, and through the publication of software books that contain diskettes of developed software. The Center also developed interactive video lessons and is almost self-supporting through corporate sponsorship.",
Necessary and sufficient conditions under which an H/sub 2/-optimal control problem has a unique solution,"A set of necessary and sufficient conditions under which a general H/sub 2/-optimal control problem has a unique solution is derived. It is shown that the solution for an H/sub 2/-optimal control problem, if existent, is unique if and only if the transfer function from the control input to the controlled output is left invertible, and the transfer function form the disturbance to the measurement output is right invertible.",
A framework for incorporating best practices at nuclear power plants,"In ethnographic fieldwork at nuclear power plants in the USA and Germany, the authors observed that capturing the context in which a practice is developed is crucial to preserving its essence and enhancing its transferability. They formalized the concept of context and concluded that the context of a best practice can be captured by recording its underlying rationale in a deliberation- or process-oriented (vs. an artifact- or outcome-oriented) mode. They adapted an existing computer-based decision management system to capture the knowledge that goes into conceiving, designing, and implementing a practice. The main assumption is that while the context is different from plant to plant, the nature of the process in which practices are developed or adapted is the same. The representation of the system is based on invariants of this process, and is thus able to provide a uniform, seamless environment ideally suited for the transfer of useful knowledge for the development or implementation of best practices. Using context-rich data from the nuclear power plants visited, the approach was tested by simulating the development and transfer of a best practice.",
Stability of a threshold-recall control self-organizing recurrent neural network,The stability of a recurrent neural network that is made up of neurons that show the activation recall dependent excitation threshold is studied. The activation function of every neuron in the network is adjusted based on the neuron activation recall. The activation threshold of the neuron is considered to be a function of the neuron activation response. Bias-adjusting neurons and activation-threshold-adjusting neurons are examined.,
A New Approach To Schedule Operations Across Nested-ifs And Nested-loops,,
Modeling and analysis of high speed parallel token ring networks,"Four factors in parallel token ring systems which can improve network performance are identified. An analytical model is developed to predict the performance of these systems. The predictions obtained with the analytical model are compared with simulation results. While the current model accurately predicts the performance of networks with 16 or more rings, it is not so accurate at lower numbers of rings. The short/long cycle behavior of the token interarrival times is identified as one cause of the inaccuracies. The benefits and limitations of parallel token ring networks for gigabit speeds are discussed.",
Predicting the impact of scheduling modifications on system performance: case study,"A measurement-based model is used to conduct a detailed evaluation of scheduling policies of the Alliant FX/80. The model is also used to evaluate the real workload performance impact of various processor configurations. The model is constructed from measurements obtained during normal machine operation. It is capable of predicting the completion time of a given application executing under real workloads. The evaluation of scheduling policies presented demonstrates the flexibility and power of the modeling methodology. It is shown that the model is not limited to single-point evaluations of system changes. The model has the ability to investigate worst case behavior, as well as estimate the probability that an application will finish by a given deadline. Results from empirical studies which validate the model are also presented.",
CCHIME: a cache coherent hybrid interconnected memory extension,This paper presents a hybrid shared memory architecture which combines the scalability of a multistage interconnection network with the contention reduction benefits of coherent caches. The authors achieve this by replacing the memory modules and final stages of a multistage interconnection network with clusters of coherent caches. The performance of Cache Coherent Hybrid Interconnected Memory Extension (CCHIME) is evaluated by analyzing the results of extensive simulations of the network and coherent cache clusters. These results indicate that the CCHIME architecture can achieve lower memory access latencies and higher throughputs than typical multistage interconnection networks.,
Maximum and minimum matchings for series-parallel networks,"Series-parallel networks are often used as models for electric circuits. The authors use series-parallel graphs to represent series-parallel networks. Since, there are many different graph representations for a series-parallel networks, they are interested in studying maximum matching in different graph representations of a single network. The number of edges in a maximum matching of G is called the edge independence number of G ad denoted by beta (G). For a network N, the maximum matching number, beta (N), is defined to be max( beta (G(N))) where G(N) is a graph representation for N. The minimum matching number, beta *(N), is defined to be min( beta (G(N))). The authors present linear time algorithms to compute beta (N) and beta *(N) for any series-parallel network N.",
Electromagnetic Interactions with Cementious Materials,,
"Reversible Agents Need Robots Waste Bits To See, Talk, And Achieve?",,
User Response Time Optimization in a Metropolitan Area Network a Concept,,
"References, local variables and operational reasoning","A.R. Meyer and K. Sieber (Proc. 15th ACM. Symp. on Principles of Programming Languages, 1988, p.191-208) gave a series of examples of programs that are operationally equivalent (according to the intended semantics of block-structured Algol-like programs) but are not given equivalent denotations in traditional denotational semantics. They propose various modifications to the denotational semantics that solve some of these discrepancies, but not all. The present authors approach the same problem, but from an operational rather than a denotational perspective. They present the first-order part of a new logic for reasoning about programs, and they use this logic to prove the equivalence of the Meyer-Sieber examples.",
An object-based approach to the specification of applications for office support systems,"The design of a specification methodology for office systems is described. In particular, the authors discuss the desired properties of a computational model upon which a specification methodology for office systems should be based. An overview of ABSL, a specification language that they developed, is presented. The central concept in ABSL is an object which is the principal mechanism for representing the data and computations. The design of ABSL is based on the formal theory of the actor model. The actor model is chosen because not only it captures the abstract power of object-orientation paradigm, but provides as well a mathematically precise abstract machine for analysis of asynchronous and concurrent computations.",
Learning probabilities for causal networks,"The author presents an unsupervised method to learn probabilities of random events. Learning is done by letting variables adaptively respond to positive and negative environmental stimuli. The basic learning rule is applied to learn prior and conditional probabilities for causal networks. By combining with a stochastic factor, this method is extended to learn probabilities of hidden causations, a type of event important in modeling causal relationships. In contrast to many existing neural network learning paradigms, probabilistic knowledge learned by this method is independent of any particular type of task. This method is especially suited for acquiring and updating knowledge in systems based on traditional artificial intelligence representation techniques.",
A divide and conquer approach to shortest paths in planar layered digraphs,"The authors give efficient parallel algorithms to compute shortest-paths in planar layered digraphs. They show that these digraphs admit special kinds of separators, called one-way separators, which allow paths in the graph to cross them only once. They use these separators to give divide-and-conquer solutions to the problem of finding the shortest paths. They first give a simple algorithm that works on the CREW (concurrent-read exclusive-write) PRAM (parallel random-across machine) model and computes the shortest path between any two vertices of an n-node planar layered diagraph in time O(log/sup 3/ n) using n/log n processors. A CRCW (concurrent-read concurrent-write) version of this algorithm runs in O(log/sup 2/ n log log n) time and uses O(n/log log n) processors. The authors then improve the time bound to O(log/sup 2/ n) on the CREW model and O(log n log log n) on the CRCW model. The processor bounds still remain n log n for the CREW model and n/log log n for the CRCW model.","Computer science,
Parallel algorithms,
Concurrent computing,
Particle separators,
Shortest path problem,
Sparse matrices,
Transmission line matrix methods,
Phase change random access memory,
Application software,
Dynamic programming"
Shortest m-watchmen routes for histograms: the minmax case,"The authors consider the problem of computing an optimum set of watchmen routes in a histogram. A watchman, in the terminology of art galleries, is a mobile guard and in this version one wants to minimize the length of the longest route in the solution. The authors give an O(n/sup 2/ log n) time algorithm to compute the MinMax optimum set of m watchmen in a histogram polygon.",
Behavior Control Based Resolution Trapped Local Minima of Mobile Robot,"In this paper, the major contribution is that an efficient method is proposed to solve trapped local minima of mobile robot, based on the composition of behavior controls. A lot experimental results based on sonar signal are given to show that the method has better real-time response, adaptability and robust in dynamic environments.",
Fault-tolerance for multistage interconnection networks,"A new fault-tolerant multistage interconnection network architecture is proposed. Using k redundant processors and f redundant switching elements per stage, the authors scheme can tolerate any k processor failures and any f switching element failures per stage. A fault-tolerant multistage interconnection network constructed using their scheme can operate as if it is a non-redundant multistage interconnection network. That is, no additional control information is necessary for routing even when some initial processors and initial switching elements have already failed and been replaced. Furthermore, the reconfiguring process of replacing failed processors and failed switching elements with spare ones can be carried out distributively. The authors scheme also compares favorably with other proposed fault-tolerant multistage interconnection architectures in terms of extra hardware requirements and it can also provide higher system reliability than other proposed schemes. Finally, even for systems with a large number of processors, n>or=1024, their scheme can still achieve very high reliability. Hence, their scheme is well-suited for use in long-life unmaintained applications.",
Limit Cycles and Tone Behavior of Sigma Delta Modulators,,
Control Policies for Scheduling of Semiconductor Manufacturing Plants,"Two important goals in scheduling semiconductor manufacturing plants are to minimize the mean and variance of the manufacturing cycle time. The manufacturing cycle time is the time taken by a job to traverse through the manufacturing system and become a finished product. In addition to the obvious economic and competetive adavantages, reducing the cycle time is also beneficial in minimizing the time that a wafer is exposed to contamination during the manufacturing process, thus providing higher yield. On the other hand, a small variance of the cycle time allows tighter production planning, and more consistent on-time deliveries of the end product. To meet these two goals, good input release policies and job scheduling policies have to be determined. The former determines job release control at the system input, while the latter allows proper job sequencing at each processing station. In a recent paper, Wein [3] has reported on the comparative performance of a number of release and scheduling policies on a simulated research and development fabrication line. In this paper, besides the policies studied by Wein, we propose two new scheduling policies, the Least Slack (LS) and the Least Optimized Slack (LOS) policies, and report on their performance in a discrete event simulation. Our preliminary results appear to demonstrate that the LOS scheduling policy can reduce both the mean and standard deviation of cycle times by perhaps significant amounts, especially under heavy traffic.",
The apparatus for the electromagnetic stimulation in stomatology,"The aim of this paper was to present the possibilities of the electromagnetic (EM) stimulation in stomatology. According to the results of our experiments the EM stimulation seems to be a useful additional therapy in cases where increased bone repair, soft tissue repair, blood circulation, improved medicament intake and bacteria rejection is needed.",
Building expert systems by training with automatic neural network generating ability,"The authors examine the construction of a connectionist expert system without specifying the network structure before training. The generated connectionist expert system consists of many features, such as operation of forward and backward inference based on partial input information, online learning, noisy data handling, generalization, and the explanation ability. Two sample problems, the Knowledge Base Evaluator 1 and Treatment of Posiboost, are considered in order to illustrate the workings of the connectionist expert system. The training algorithm, which has network generating ability, is presented to build the knowledge base of the connectionist expert system. It provides the abilities needed to realize the described features of the connectionist expert system. This proposed system can be easily used to build expert systems quickly, and the inferencing in the developed systems will be fast.<>",
Efficient implementation of non-standard connectives and quantifiers in deductive reasoning systems,"A rule use information (RUI) structure has been proposed to implement nonstandard connectives and quantifiers that generalize conjunction, disjunction, implication, universal quantifier, and existential quantifier. The current implementation of the RUI structure in the SNePS Inference Package (SNIP) maintains a single RUI set for each rule, which causes a combinatorial number of substitution compatibility checks between RUIs as the number of antecedents in a rule and their instances increase. The problem of efficient RUI handling for deduction rules with non-standard connectives and quantifiers is addressed. Two kinds of algorithms are proposed, and methods of distributing RUIs over several sets are discussed. Complexity analyses and test results show that these schemes of RUI set distribution keep the complexity of RUI set handling to polynomial in terms of the number of RUIs and the number of substitution compatibility tests.",
Quadtree interconnection network layout,"Quadtree data structure has been used in a number of applications. However, VLSI embedding of quadtree based parallel architecture using grid model has not been studied. This paper studies VLSI embedding of quadtree using grid model. H-tree layout for binary tree is extended for trivial quadtree layout, followed by two layout strategies for rectangular grids. Two generic layout styles (standard layout and X-layout) are proposed for higher order grids (e.g., hexagonal and octagonal grids). Base tile layout patterns are proposed for area compaction with recursive X-layout. In each case, layout dimensions and I/O bandwidth are computed. The authors demonstrate how the two generic layouts can be mixed to obtain higher I/O bandwidth and estimate the area sacrifice. An improved recursive layout mixing strategy is proposed.",
Plume segmentation using local entropic thresholding,An approach for segmenting plume images using local entropic thresholding is proposed. Several threshold values are calculated by using entropy measurement on a cooccurrence matrix of an image. These threshold values are used to segment the image into a lower-level image which consists of a few regions. Finally several experiments are conducted to examine how the proposed approach performs.,"Image segmentation,
Entropy,
Atmospheric measurements,
Pollution measurement,
Histograms,
Air pollution,
Pixel,
Symmetric matrices,
Protection,
Detectors"
On Convolution,,"Convolution,
Petri nets,
Logic,
Algebra,
Quantum computing,
Computer science,
Distributed computing,
Abstracts,
Quantum mechanics"
The geometry of visual interception,"Under the traditional paradigm of considering vision as a recovery problem, visual interception is just another application of the structure-from-motion module. However, the inherent difficulties of three-dimensional reconstruction have delayed any real-time applications. The authors offer a robust solution under the active qualitative vision paradigm. From the image intensity function, they obtain the locomotive intrinsics of the agent and the target. Based on this relative information, they present a control strategy that decides in real time whether the velocity of the agent should be increased or decreased at any time instant, thus guiding the agent to intercept the target. The problem of visual interception can thus be solved by simple computation without correspondence.",
Medical diagnostic expert systems: performance vs. representation,"A research effort is described which represents an inquiry into an important problem of automated acquisition, indexing, retrieval, and effective use of knowledge in diagnostic tasks. The principal tool is INC2, an incremental concept formation system which automates both the design and the use of diagnostic decision-support systems by a novice. The system's prediction performance is evaluated in the domains of breast cancer, primary tumor, and audiology cases, relative to the language used for representing concepts. The study includes the whole continuum of concept representations from logical to probabilistic ones. The results demonstrate that the quality of performance indeed depends on the chosen representation language.","Medical diagnosis,
Medical expert systems,
Diagnostic expert systems,
Computer science,
Indexing,
Breast cancer,
Breast neoplasms,
Problem-solving,
Medical treatment,
Organizing"
Formal power series: an algebraic approach to the GapP and Hash P functions,"The algebraic structure of GapP and Hash P functions is introduced by formalizing them as power series ring and semiring, respectively. It is proved that for every invertible GapP function g, P/sup g/=P/sup 1/g/, and for all positive integers i, P/sup g/=P to the g/sup i/, power. Applying the Ladner theorem for functions, it is shown that P/sup s/=P/sup (s)/ for all S if and only if P=PP, where (S) is the subring generated by S. It also concluded that the class of rational series is contained in FP. Considering the group of all invertible functions, it is proved that all functions in the same coset with respect to FP are Turing equivalent, every Turing degree inside GapP except FP contains infinitely many cosets, and P not=PP if and only if the index of FP is infinite.","Automata,
Computer science,
Complexity theory,
Polynomials,
Arithmetic,
Power generation"
Neural network approach to N-person games,Heterogeneous N-person games with limited interaction are considered. A global behavior of players in the game is observed. The average total payoff received by the team of players is chosen as a criterion of the global behavior. The game is implemented by a neural network. The model is applied to solve an optimal task assignment problem in a multiprocessor system.,
Interconnect Optimization Techniques in Data Path Synthesis,,
Studies on protocol layer residency in an intelligent Network Interface Unit,This paper discusses various issues related to partitioning of a protocol stack between a host machine and an NIU. It describes the experiments carried out to understand the partitioning of the OSI protocol layers. OSINET networking software is used in the experiments designed specifically for this purpose. The implementation details along with performance measurements are presented.,
Search operations on distributed directories,"The ISO's X.500 directory service provides agents with information about entities within a distributed environment. The standard identifies information (entry data) to be maintained by the directory as well as information (knowledge) that is used by the directory agents to facilitate cooperative activity, such as searching, updating and manipulating entry data. It does not address the implementation of distributed algorithms for these operations. This paper discusses different types of knowledge and algorithms for distributed search. The knowledge can be categorized into two types: that dealing with network interconnection or topology and that dealing with directory information.",
IKD: a knowledge-based tool for integrating a knowledge base and a database,"In order to integrate a knowledge-based system (KBS) and relational database system (RDBS) more naturally and flexibly, it is necessary to work with these two systems cooperatively. The IKD system functions as an interface between the KBS and RDBS by representing their conceptual structures in frames. Two types of frames are distinguished from one another: one defines the data structure of an integrating database (DB) and the other represents conceptual objects dealing with a KBS. Several types of operations on the DB are processed based on message passing among frames.",
Effect of interstitial anisotropy and the extracellular volume conductor on action potential morphology in a thin layer of cardiac tissue,"We simulated conduction in a thin layer of cardiac tissue using both a bidomain and monodomain model of the structure. The two models predict similar wavefronts and action potential shapes when the intracellular and interstitial spaced are both insulated. The most significant differences in active tissue are observed in the foot of the transmembrane potential, the portion of the upstroke due to passive current flow. The two models yield markedly different behavior when the interstitial space is not insulated but permitted to exchange currents with a thin layer of bounding fluid.",
Method for determining the optimum input power level in Wiener kernel measurement,We proposed a method for determining the optimum input power level which gives maximum precision in Wiener kernel measurement by the cross-correlation method.,
A knowledge base management system on relation model and term rewriting,"The author first discusses the status of knowledge base management systems (KBMSs). A new data model and an approach for knowledge base management systems is presented regarding the integration of the relational model with term rewriting techniques. Based on this model an efficient KBMS has been designed and implemented with C and ORACLE, which has the following features: multi-user languages on the extensions of SQL, QBE and PROLOG; data/knowledge definition, representation and manipulation; reasoning and explaining; security and integrity check; and optimal recursive processing.",
Self-routing least common ancestor networks,"Fat-trees, KYKLOS, baseline and SW-banyan networks, and the TRAC and CM-5 networks belong to a family of networks called least-common-ancestor networks (LCANs). In this paper, attention is restricted to LCANs with identical switches and a uniform stage interconnect. The least common ancestor of two nodes (PEs), A and B, is the node at greatest depth that counts A and B among its descendants: this node corresponds to an LCA switch. Given a source-destination pair, communication progresses upwards to an LCA switch; the stage that it belongs to is called the LCA level. Then, routing returns downwards to the destination. Source-destination pairs are connected using as few stages as their degree of mutual locality permits. Network parameters that facilitate this routing are shown.",
A TRD trigger for the Tevatron Collider experiment at D0,"A VME-based module for use as an input to the D0 detector level 1.5 is described. Its main function will be the confirmation of electron candidates flagged by the first-level calorimeter trigger using digitized data from the transition radiation detector (TRD). Features of the board include the use of fast FIFOs to store incoming track coordinates, dual-ported SRAM lookup tables for addressing integrated charge data and forming scalars, multipliers/accumulators for speed of calculation, and a single synchronous finite state machine to control all board operations.",
Enhancing Computer Engineering Education with Verilog/suo R/ HDL,"A hardware description language (HDL) has been introduced in a senior-level computer engineering course to promote the understanding of computer organization and design at the register-transfer and the gate level. This paper describes various components of the HDL and the pedagogical aspects of its incorporation into an existing course. Additionally, completed student projects and comments from a student questionnaire are analyzed to access the students' knowledge of computer engineering fundamentals and to determine if this knowledge is enhanced or diminished by the incorporation of a HDL into the design component of the course. These analyses subsequently justify the study of, and inclusion of a HDL as a part of the design component for courses spanning an undergraduate computer engineering sequence.",
DREAM: a special-purpose architecture for large scale finite difference calculations,"Presents the concept of DREAM (Disk REsource Array Machine), an architecture designed for large-scale finite difference simulations. On preset computers, the size of finite difference calculation is limited by the size of the memory. The DREAM system uses magnetic disks as the main memory. With main memory made of magnetic disks, one can construct a machine with 100 times larger memory for the same cost. With the DREAM architecture, neither the data transfer rate nor the access time of the disk unit limit the computing speed. The data transfer rate is increased by accessing a number of disks in parallel. The access time becomes negligible for finite difference calculations in which all data are accessed in long vectors. A DREAM system with 2 GByte memory and 40-80 MFLOPS speed costs around 20000 dollars. A system with a 1 TByte disk would cost several million dollars.",
Neural networks for process control,"The authors explore many of the current issues involved in adaptive artificial neural network (ANN) controllers. The major issues covered include: exploring basic neural network controller designs described in the literature, new approaches involving the combination of ANN techniques with linguistic based approaches, describing sources of input and output data for parameter estimation, and a framework for comparing adaptive artificial neural network controllers with other adaptive controllers using benchmark examples. In addition, hybrid neural network/fuzzy controllers are described.",
Abduction in annotated logic programming,"The author investigates techniques to make the logic programming paradigm more expressive for knowledge representation, while simultaneously retaining the computational advantages of efficiency and simplicity. He extends the annotated language of K. Thirunarayan and K. Kifer (1989) in various directions to obtain an enriched representation language. In particular, rule bodies are permitted to be a conjunction of literals, and the rules to be recursive. A class of annotated logic programs called the stratified programs is identified which can be given a unique supported minimal Herbrand model as their meaning. Abductive reasoning is integrated into this annotated logic framework. The notion of an explanation is formalized, and when an explanation can be regarded as acceptable is specified.",
A prototype for including simulation of IS dynamics in CASE environments,"Describes a method to integrate information systems (IS) design performance evaluation with the IS development process. The nature and cost of an information system is shaped by decisions about where to provide computer support, the hardware platform, and the database management system (DBMS) architecture-decisions influenced largely by how quickly work must be done. A prototype system has been developed which produces simulation results automatically from data flow diagrams (DFDs) augmented with information regarding the performance of system components. The objective is to make the evaluation of IS design dynamics a common and integral part of the development process by producing simulation results directly from computer-aided software engineering (CASE) tool data dictionaries. The prototype reads DFDs from a custom DFD-drawing tool and formulates a corresponding simulation model. The prototype provides model-based expert advice in the use of the simulation model and in the interpretation of its output. The use of the prototype is illustrated through its application to a proposed research clinic information system.",
Computer security myths mythtakes or 'The real security problem is. . .',"Some common beliefs about computer security and the impact they have had on the field are discussed. In addition to identifying the myths, examples of blind adherence to the myths are given.",
Compiled unit-delay simulation for cyclic circuits,"Three techniques for handling cyclic circuits in a compiled unit-delay simulation are presented. These techniques are based on the PC-set method and the parallel technique of compiled unit-delay simulation. The first technique, called the synchronous parallel technique, is applicable only to synchronous circuits, but provides significant performance improvements over interpreted unit-delay simulation. The second and third techniques. called the convergence algorithm and the asynchronous parallel technique, are applicable to all circuits, both synchronous and asynchronous. The convergence algorithm, which is based on the PC-set method, provided significant performance increases for some circuits, but performed poorly on others. The asynchronous parallel technique performed rather poorly, and is covered only briefly.",
Revisiting parallel speedup complexity,"Two 'folk theorems' that permeate the parallel computation literature are reconsidered in this paper. The first of these, known as the speedup theorem, states that the maximum speedup a sequential computation can undergo when p processors are used is p. The second theorem, known as Brent's Theorem, states that a computation requiring one step and n processors can be executed by p processors in at most (n/p) steps. The authors exhibit for each theorem a problem to which the theorem does not apply. Their approach is purely theoretical and uses only abstract models of computation, namely the RAM and PRAM. Practical issues pertaining to the applicability of their results to specific existing computers, whether sequential or parallel, are not addressed.",
An explicit model for noninvasive measurement of blood samples,"An explicit model for tracer plasma time-activity curve (PTAC) is proposed based on practical experimental data in this paper, which can be potentially used to measure PTAC noninvasively from external probe or left ventricle images and to study the reliability of other physiological parameters measurements with positron emission tomography, which require PTAC as the input information.",
Proceedings of the Twenty-Fifth Hawaii International Conference on System Sciences,,
Data driven neural-based measurement discrimination for IC parametric faults diagnosis,Describes experimental results obtained with the use of data driven neural-based system for statistical IC fault diagnosis. Measurement discrimination is established through a reduction method involving data pre-processing in a fashion consistent with a specific definition of parametric faults. The effects of this preprocessing are examined in the context of a realistic IC parametric fault diagnostic problem.,
Programs in information systems at Florida International University,"Describes the history, goals, objectives, and priorities of the educational programs in information systems that are currently in place at Florida International University. The authors also describe the research paradigm that brings together the diverse research interests of the faculty in the Department of Decision Sciences and Information Systems. This research paradigm covers four different but related areas of research: IS development, IS and support tools, consequences of IS use, and management of information systems. Recent and ongoing studies in these areas are presented as well as future directions for the research program.",
Efficient detection of potential inconsistency in taxonomic knowledge with uncertainty,"The authors present the logical framework for detection of potential conflicts in knowledge bases with uncertainty. In the solution, it is assumed that the uncertainty measure is modeled by the possibilistic necessity measure. The method presented allows the modeling of the effect of a user defined certainty threshold for belief propagation, and utilization of a partially inconsistent knowledge base. An efficient computation method is presented which is applicable for knowledge in a certain simple form, typically satisfied by a taxonomic knowledge base. The deductive system implemented by this method deals properly with cycles, and is both sound and complete.",
Characterisation of Heterojunction Bipolar Transistors incorporating Si/Si1-xGex epitaxial double layers with n+ emitter implants,"Transistors fabricated with systematic variations in Ge fraction, base doping and junction spacer width show near-ideal electrical characteristics. Emitter implantation generates anomalous boron diffusion in the base.",
"Proceedings., 33rd Annual Symposium on Foundations of Computer Science",,
An AT/sup 2/ lower bound for wavelet transforms in VLSI,"The lower bounds on the area and time complexity of computing the wavelet transforms in VLSI are derived. The discrete wavelet transform (DWT) is shown to have a lower bound that matches the lower bound for the DFT, while it is seen that the discrete short time Fourier transform (DSTFT) is, in general, more difficult to compute. It is shown that for the DWT, AT/sup 2/= Omega (N/sup 2/ log/sup 2/(N)) and for the DSTFT, AT/sup 2/= Omega (N/sup 2/M/sup 2/log/sup 2/(N/sub w/+N)).",
A real-time goal-interaction free task planner,"The authors describe a real-time task planning algorithm, PLANNER. The high planning speed achieved in PLANNER is due to three techniques adopted in the planner. First, priority numbers are assigned to each literal of the conjunctive goals and each literal of the preconditions of the robot operations; the priority assignment is combined with a depth first search technique to make the goal-interaction problem vanish in task planning. Second, binary numbers are used to represent facts and robot operations, which greatly increases the speed of operation searching. Third, simple hardware circuits are used to match a subgoal to all operations and facts in a parallel fashion. The total speed gain of PLANNER over the traditional task planner is the product of the speed gains of these three techniques. PLANNER can be used for a fairly large subset of conjunctive problems that have priority among its subproblems.",
A model integrating the processes of user interface development and software development,"Before software engineers can integrate the separate processes of user interface development and mainstream software development, they must investigate candidate methologies that let developers apply different development strategies to different parts of an interactive system. Disciplined long-term investigation requires that the fundamental principles governing each process be fixed and that evolving development methods comprising each process be accommodated. The author proposes a computer-based process model that fixes the principles and accommodates evolving methods. An argument for its feasibility and worthiness for further study is presented.",
From characteristic invariants to stiffness matrices,"A fitting relationship in an assembly implies that the relative location of the bodies belongs to a coset of the symmetry group of the mating feature pair. When a symmetry group is continuous, there are infinitesimal displacements which preserve the relationship. Assembly of two bodies normally involves the establishment of successively more constraining relations, many of which are fitting relations. The continuous topological structure of the associated group determines possible directions of assembly at any state in the assembly process. To accommodate to errors, it is necessary to choose a stiffness matrix appropriate to a given assembly state, which allows the robot to comply with wrenches normal to the possible assembly directions. The derivation of such matrices from a computational geometric representation of the mating feature symmetry group is considered.",
An Annual Model of SSM/I Radiobrightness for Dry Soil,,
A Time-Domain Approach to Model Validation,In this paper we offer a novel approach to control-oriented model validation problems. This approach differs from other available techniques in that it directly uses time-domain input output data to validate uncertainty models. The algorithms we develop are computationally tractable and reduce to (generally non-differentiable) convex feasibility programming problems.,"Time domain analysis,
Uncertainty,
Robust control,
System identification,
Noise measurement,
Additive noise,
Filtering,
Predictive models,
Noise robustness,
Feedback control"
Scalar memory references in pipelined multiprocessors: a performance study,"Interleaved memories are essential in pipelined computers to attain high memory bandwidth. As a memory bank is accessed, a reservation is placed on the bank for the duration of the memory cycle, which is often considerably longer than the processor cycle time. This additional parameter, namely, the bank reservation time or the bank busy time, adds to the complexity of the memory model. For Markov models, exact solutions are not feasible even without this additional parameter due to the very large state space of the Markov chain. The authors develop a Markov model which explicitly tracks the bank reservation time. Because only one processor and the requested bank are modeled, the transition probabilities are not known and have to be approximated. The performance predicted by the model is in close agreement with simulation results.",
On the generation of d-ordered sets: a proof based on determinant theory,"A simple proof of the theorem of determinants that yields d-ordered sets is given. Nothing more complicated than the Laplacian expansion of a determinant is used in the proof, which consists essentially of two parts. First a bordered determinant is used to yield the necessary determinantal equation. Then, transpositions of columns bring the minors in the equation into the required form so that they satisfy the conditions for a d-ordered set.",
FREA: a distributed program reliability analysis program,"The authors present an algorithm for computing distributed program reliability in distributed computing systems (DCSs). The algorithm, called FREA (fast reliability evaluation algorithm), is based on the generalized factoring theorem with several incorporated reliability-preserving reductions to speed up reliability evaluation. The effect of file distributions, program distributions, and various topologies on reliability of the DCS was studied by using the proposed algorithm. Compared with existing algorithms on various network topologies, file distributions, and program distributions, the proposed algorithm was much more economic in both time and space. To compute the distributed program reliability, the ARPA network is studied to illustrate the feasibility of the proposed algorithm.",
A New algorithm for combined PLA folding,,
Dynamic genericity in imperative languages: example in CML,"Genericity, a form of polymorphism, is implemented through generic abstract data types (GADTs) generators in most modern programming languages. The GADTs are used for both compile time (static) and run time (dynamic) instantiations of concrete abstract data types. The paper introduces the implementation of a new approach to dynamic genericity which utilizes the polymorphic GADT feature in a secure, efficient, and powerful way for the first time in a newly developed imperative programming language, Contour Model Language (CML).",
Selective and robust perception using multiresolution estimation techniques,"Data and model-driven processes are basic to image understanding systems and correspond preattentive and focal attentive processes, respectively. The authors describe how to develop preattentive and focal attentive processes primed by known object models complementary to efforts on data driven preattentive processes. The techniques used to implement attentional mechanisms are shown to be robust with respect to noise given as changes in illumination, able to reduce crosstalk and able to count outliers.",
Function-oriented vision chips for factory automation,"The emphasis is on high-speed processor architectures for visual processing. There are, in general, two types of high-speed processor architectures: highly programmable processors and function-oriented processors. Function-oriented processors are discussed. The author describes research trends in function-oriented industrial vision chips. Vision chips are categorized into digital, analog, and hybrid chips, which are discussed. It is expected that higher-level visual processing will get more attention for vision chips in the future while many current vision chips address early vision technologies or low-level visual processing. A key in extending early vision capabilities to high-level visual capabilities is the fusion of information from multiple imperfect visual recognition subsystems.",
Rational number approximation in higher radix floating point systems,"Recent research has shown that hybrid non-binary floating point bases, particularly decimal-based systems, can match or exceed the error performance of more traditional binary systems. The authors address a more general question of whether such bases offer any further advantages in the domain of rational number approximation. They consider the effect of the choice of floating point base on rational number approximation in systems which exhibit the typical characteristics of floating point representations, normalized encodings, limited exponent range, and storage allocated in a fixed number of bits per datum. The frequency with which terminating and representable results can be expected is considered for binary, decimal, and other potentially interesting bases (base 30 and base 210).",
Automated bar coding of air samples at Hanford (ABCASH),"The authors describe the basis, main features, and benefits of an automated system for tracking and reporting radioactive air particulate samples. The system was developed due to a recognized need for improving the quality and integrity of air sample data related to personnel and environmental protection. The data capture, storage, and retrieval of air sample data are described. The automation aspect of the associated database and data input eliminates a large potential for human error. The system utilizes personal computers, handheld computers, a commercial personal-computer database package, commercial programming languages, and complete documentation to satisfy the system's automation objective.",
Bifurcation and Chaos in Simple Nonlinear Circuits,,
Hankel norm computation for infinite-dimensional H∞ model matching problems,"This paper considers the problem of computing the induced L2 norm for Hankel operators which are not necessarily compact. Ih the literature such a norm has traditionally been computed by attempting to solve a complex infinite-dimensional eigenvalue-eigenfunction problem. In this paper, it is shown that a sequence of simple finite-dimensional eigenvalue-eigenvector problems can be solved to estimate the desired induced norm.",
The distance education situation and CAI at the University of South Africa,"The Department of Computer Science and Information Systems at the University of South Africa (Unisa-a distance teaching university) has, over the years, been struggling with the twin problems of lack of staff and a difficult subject to teach adequately using only the traditional medium (the written or printed word) employed at Unisa. The article describes the rationale for choosing computer-aided instruction (CAI) to address both problems.",
DEVE: an expert system for hardware design verification,"An expert system approach to digital hardware design verification is described. Artificial-intelligence-based approaches typically use general-purpose theorem-proving to show that the design meets the formal specification. In contrast, the expert system DEVE interprets the specification to invoke proper domain-specific verification methods in a knowledge-based environment.",
Integrating widget design knowledge with user interface toolkits,"It is shown how user interface design information can be presented to designers as part of a user interface toolkit, through an example of guidelines for widget use in the NeXT interface builder. This is part of larger framework for recording and reusing user interface design knowledge with scenario-oriented design rationales. The research reported combines generic guidelines with specific design rationales. Emphasis is placed on the design tradeoffs involved with choosing user interface widgets to implement required user operations. The representation used for design rationales, and its adaptation for more general guidelines is presented, together with an outline of how this representation was integrated with the NeXT interface builder.",
An Analysis of the Polarimetric Matched Signal and Image Filter: Application to Radar Target Versus Clutter Optimal Discrimination in Pol-Sar Image,,
Non-Linear Control with End-Point Acceleration Feedback for a Two-Link Flexible Manipulator: Experimental Results,"In this paper, experimental results for a two-stage controller comprised of a rigid-body based nonlinear control augmented with a linear dynamic output feedback derived from Youla's parameterization of stabilizing controllers are presented for a two-link flexible arm at CRRL. It is shown that the outer-loop controller enhances vibration damping and robustness of the closed-loop dynamics to parameter variations.",
Object-oriented SECS programming system,"An object-oriented programming (OOP) environment for developing SEMI Equipment Communication Standard (SECS) applications with the C++ and C programming languages in a Unix workstation environment is described. The system (referred to as OOSECS) defines a set of programming objects corresponding to the standard SECS-II item types, messages, and headers as well as a number of support classes and operations. Conversion between standard program datatypes and SECS-II items is transparent or explicitly managed by the developer. Within a standard framework using standard C++ input/output methods SECS-II messages may be created, analyzed, and transmitted and received between internal buffers, external files, and communication channels.",
Organizing software repositories modeling requirements and implementation experiences,"The authors discuss the representational requirements for capturing and processing the conceptual knowledge about software descriptions. Software repositories should not only provide the service of managing evolving objects and software-related descriptions in integrated environments. This requires addressing the representational adequacy and semantics of present object management systems. Based on experiences gained in a series of computer-aided software engineering (CASE) integration projects, they point out abstractional, assertional, and dynamic clustering requirements of data modeling language for repository managers. A simple example illustrates how the deductive object management system ConceptBase, embodying Telos as its data model, meets these requirements.",
Sizewell B integrated control and instrumentation system: a vision becomes reality,"Nuclear Electric's Sizewell B station is an 1188 MW PWR located in Suffolk, UK. The Westinghouse supplied control and instrumentation system for the Sizewell B station represents the first implementation of this state-of-the-art digital technology in an integrated plant-wide protection, control, and computer system. The benefits of the Westinghouse approach are enumerated.",
Applying force-directed placer to wafer scale placement,"A placement algorithm for discretionary wiring WSI system, WFDP, is proposed in this paper. WFDP employes force-directed placement algorithm. First the relative locations of macro circuit component are determined. In the phase of determining the real location of the circuit component, it avoids the problem of determining the real location of arbitrary component by employing divide-conquer strategy and removing the hierarchical division. Its computation is much more simpler than other homologous algorithm. A simple model used to estimate the quality of placement is also proposed. Although the WFDP is aimed at WSI, it can also be used in the placement of other redundancy-oriented device or system such as RVLSI, etc.",
Lightweight hardware support for protection in object-oriented systems,"The paper describes ACOM (access control monitor), a hardware device developed to enforce run time protection in a persistent object-oriented system. To obtain a wide acceptance, the efficiency of these systems must be comparable to conventional language systems. One of the key issues is to exploit the efficiency of virtual memory management of contemporary processors. A careful analysis of the hardware-software trade-off leads to a simple hardware device which can efficiently support encapsulation and protection of small objects in an object-oriented systems. The main idea is to separate encapsulation and protection from address translation issues.","Hardware,
Protection,
Encapsulation,
Operating systems,
Computer science,
Access control,
Computerized monitoring,
Memory management,
Object oriented programming,
Object oriented databases"
Automated phantom assay system,An automated phantom assay system developed for assaying phantoms spiked with minute quantities of radionuclides is described. The system includes a computer-controlled linear-translation table that positions the phantom at exact distances from a spectrometer. A multichannel analyzer (MCA) interfaces with a computer to collect gamma spectral data. Signals transmitted between the controller and MCA synchronize data collection and phantom positioning. Measured data are then stored on disk for subsequent analysis. The automated system allows continuous unattended operation and ensures reproducible results.,
An algorithm for embedding a class of non-even routing problems in even routing problems,"The authors present part of a complete solution of a two-terminal net routing problem for certain non-convex grids without holes that they call channel graphs. They present an algorithm for embedding a non-even channel graph routing problem in an even channel graph routing problem. They refer to the algorithm as EMBED. EMBED runs in time O(b), where b is the number of vertices on the boundary, and is similar to an algorithm described by M. Becker and K. Mehlhorn (1986) for planar graphs. Due to the restrictions the authors place on the shape of channel graph routing problems they are able to obtain a lower complexity for their algorithm than that of the Becker and Mehlhorn algorithm. Their algorithm has complexity O(bn), where n is the number of vertices in the graph.",
Distributed EZ (string processing language),"EZ is a system that integrates traditional operating systems and programming languages into a very-high-level persistent string processing language. The authors describe the design and initial implementation of a distributed memory manager that distributes EZ's virtual address space transparently among a network of homogeneous computers. The design adapts the techniques used in recent implementation of shared virtual memory for use in EZ's persistent environment. Unlike most implementations of shared virtual memory, control information is distributed and migrates. This memory manager works in concert with a distributed mark-and-sweep garbage collector, which is also concurrent and real-time. This collector trades time for space and minimal disruption of mutators, which reduces communication costs.",
A systematic approach to CASE selection,"Seven CASE tools were evaluated and compared by the author and a group of graduate students. From the results of the author's evaluations, a rather fundamental topic is presented as an example to highlight some of the problems that arise during CASE selection. The identified problems especially seem to hit potential CASE users who are yet unfamiliar with current CASE technology. An approach is introduced and discussed aiming at a more systematic evaluation of tools without the need of CASE experts to perform it. Reuse of experience is suggested to reduce effort; the approach allows managers to directly express their preferences and constraints without being too much bothered by technological issues. Their individual decisions influence the process and the results of the evaluation. In introducing the approach step by step, they show how more and more hidden problems from the above example are mastered. This uncovers a number of crucial points which determine whether CASE selection will satisfy the potential user, i.e. if it can be successful or if it is bound to fail.",
Development of a Real-Time Digital Computer Control Laboratory,"Recently, the author was funded through the National Science Foundation to develop a Real-time Control Laboratory. The objective of this new project is to substantially improve the instructional capability of undergraduate instruction in real-time system analysis and control. In addition, the great flexibility of microprocessors in both single and multi-loop control actions offers the students a more versatile means of design and experimentation. In this paper the design, development and implementation of this control educational project is reported.",
Optimal Sliding-Window Detector for Disruptions in Random Sequences,,
"The ""G-F"" 2-Valued Formula Generating Complete Set of Tests to Multiple Faults",,
The design and implementation of a knowledge base management system,"A new data model and an approach for knowledge base management systems (KBMSs) are presented in order to integrate a relation model with term-rewriting techniques. An efficient KBMS has been designed and implemented with C and ORACLE, and has the following features: (1) multi-user-languages on the extensions of SQL, QBE, and PROLOG-like; (2) data/knowledge definition, representation and manipulation; (3) reasoning and explaining; (4) security and integrity check; and (5) optimal recursive processing.",
Multilanguage programming: an automatic-type-mapping approach,"The data type correspondence problem arises when one tries to interconnect, within a single program, modules written in different languages and therefore within the framework of different type systems. An interconnection model is proposed which hides details such as interlanguage data type mappings and low level communications, which are irrelevant or confusing to most programmers. Using this model, the authors develop an automated solution to the problem of finding, for a given type in a given programming language, the corresponding type in another programming language. They compare this approach with others which have been proposed in the literature, and discuss a prototype implementation in detail.",
A hypertext approach to enterprise modelling,"The application of a hypertext authoring approach to enterprise modeling is considered. A hypertext transformation model for systems development is developed. This model views systems development as a transformation process. The role of hypertext in this process is in providing support for information capture, whereby nodes of information are created, and links made between them. The attachment of attribute/value pairs to the nodes and links makes flexible transformation and (re-)structuring of captured information possible.",
Closed-form solutions to a class of H/sup infinity /-optimization problems-output feedback case,The authors present a closed-form solution to a class of H/sup infinity / suboptimal control problems via output feedback. The issue of pole/zero cancellations in the closed-loop system resulting from the H/sub infinity /-suboptimal output feedback control law is examined.,
Adaptive Feedback Control of Linear Stochastic Systems,"We consider adaptive control of linear stochastic systems, i.e., the control of unknown linear systems subject to stochastic disturbances whose spectra are also Unknown. We examine the basic convergence issues, including the convergence of adaptive controllers and parameter estimates as well as the convergence of input and output. Despite over a decade of effort, previous works in this area are very much fragmented. Relatively complete convergence results are available only for adaptive minimum variance control of unit delay systems. In this paper we propose the generalized certainty equivalence approach to stochastic adaptive control, where the estimates of disturbance innovations as well as parameter estimates are utilized. Based on this, the self-optimality of adaptive minimum variance controllers using an indirect approach and the stochastic gradient algorithm is established for general delay systems. Then we show that the self-optimality implies the self-tuning of adaptive controllers in general, by exhibiting the convergence of the parameter estimates to the null space of a certain covariance matrix and by characterizing the null space. The role of the system disturbance in providing an ""internal excitation"" is delineated. Finally we determine the exact order of external excitation required in order for the parameter estimates to converge to the true parameter.",
KM-a knowledge-based modeling framework for multi-model information systems (MMIS),"There is an increasing interest in the development of advanced complex information systems capable of capturing significant application knowledge. The paper proposes a multi-model approach for the development of complex information management systems based on a simple framework in which diverse modeling techniques are applied. The KM modeling features provide a novel mechanism to support the entity modeling, process modeling and policy modeling aspects of MMIS systems.",
Recognition of handwritten Chinese characters by searching the multiway heterogeneous tree,"The number of Chinese characters is very large, frequently it exceeds 5000 in daily usage. In order to achieve accuracy and speed in the recognition of handwritten Chinese characters, it is essential to have a well-organized model database. In the paper, the structural and statistical information of Chinese characters are represented by hierarchical attributed graphs. A heterogeneous multiway tree structure is used to organize the model database. For an input character, a corresponding model character in the database is found by a search process which can be divided into a number of simple and local decisions at different levels of the tree. The matching process becomes quite efficient and accurate.",
Static analysis of PostScript code,"It is pointed out that stack-based languages, such as PostScript, present a major challenge to static analysis techniques because of their almost unlimited polymorphism. A regular expression notation that is used to represent allowed combinations of types on the stack at different points in a PostScript program is introduced. An abstract interpretation algorithm can then be used to perform static-type analysis. The analysis has applications in detecting probable errors in the PostScript code or, ultimately, in permitting full or partial compilation of portions of code.",
Improved parallel polynomial division and its extensions,"The authors compute the first N coefficients of the reciprocal r(x) of a given polynomial p(x), (r(x)p(x)=1 mod x/sup N/, p(0) not=0), by using, under the PRAM arithmetic models, O(h log N) time-steps and O((N/h)(1+2/sup -h/log/sup (h)/ N)) processors, for any h, h=1,2, . . .,log/sup */ N, provided that O(logm) steps and m processors suffice to perform DFT on m points and that log/sup (0)/ N=N, log/sup (h)/ N=log/sub 2/log/sup (h-1)/N, h=1, . . .,log/sup */N, log/sup */N=max(h:log/sup (h)/N>0). The same complexity estimates apply to some other computations, such as the division with a remainder of two polynomials of degrees O(N) and the inversion of an N*N triangular Toeplitz matrix. They also show how to extend the techniques to parallel implementation of other recursive processes, such as the evaluation modulo x/sup N/ of the m-th root, p(x)/sup 1/m/, of p(x) (for any fixed natural m), for which we need O(log N log log N) time-steps and O(N/log log N) processors. The paper demonstrates some new techniques of supereffective slowdown of parallel algebraic computations, which they combine with a technique of stream contraction.",
Directed spreading activation in multiple layers for low-level feature extraction,"Spreading activation neural networks have been proposed in literature. The paper proposes a directed spreading activation neural network model which performs a large number of early vision tasks. It is shown how directed two-dimensional (2D) diffusion followed by detection of local maxima can effectively perform feature extraction, feature centroid determination and feature clustering all on multiple scales in a purely data-driven manner. The feature map, which is the result of this directed spreading activation process can be used in learning and recognition of 2D object shapes from their binary patterns invariant to affine transformations.",
Architecture support for window environments,"The authors introduce a layered classification of visualization primitives, according to which graphics related functions are organized in four levels. The first level refers to drawing. That level is typically supported with dedicated graphics coprocessors, like TMS240xO. The second and third levels refer to handling of graphics objects in a window environment. Level four refers to multimedia integration. Hardware/software acceleration of functions on level two and three is the subject of this research. After a simulation-based statistical analysis of selected benchmark programs, four functions on levels two and three are selected as the most critically needing an acceleration. Algorithmic improvements are introduced for these four functions, and the details of their hardware and/or software support is explained. Results of an analytical analysis are also given.",
On Intelligent Control Strategy for ORE Dressing Process,,
915 MHz interstitial hyperthermia: Dosimetry from heating pattern reconstruction based on radiometric temperature measurements,"Using hyperthermia in conjunction with other therapeutic against humancancer continues to be a high level of interest. Most known methods are based on the use of electromagnetic energy to elevate the malignant tissue up to 42°C, generally using external non invasive techniques. In the case of deep or semi-deep sited tumors it appears very interesting to deliver the heating power directly inside the tumor. For this purpose we have design several thin antennas different in their active length inserted in the catheter already implanted for the Ir 192 brachytherapy.",
On piecewise-planar representation of images,"It is customary to represent an analog image in digital form by dividing its support to pixels, and within each pixel to represent the brightness by a quantized scalar i.e., to approximate the 2-D image function by a horizontal planar patch. This paper studies a representation scheme in which the image function is represented within each pixel by an inclined planar patch. If the image function is to be represented by b bits per pixel, a bit allocation trade-off arises, and the optimal allocation of bits to the representation of the average value and of the two slope coefficients within each pixel needs to be determined. Analysis shows that allocating all the bits to represent the average brightness is not always optimal, and bits should be allocated to the representation of the slope coefficients. Similar results were obtained for the 1-D case.",
Experiments on the concurrent rule execution in database systems,"Issues pertinent to the concurrent execution of rules in a database management system (DBMS) are studied. Rules are modeled as database transactions. As such, they should follow serializability as their correctness criterion for execution. Rule execution has the additional constraint that the rules, conditions must be true in the database for the actions that execute, and rules must fail when their conditions are not true any longer. Based on this observation, two locking-based protocols are discussed. Information on the possible conflicts between conditions and actions of rules is used to provide greater concurrent access to the relations, based on a new lock paradigm. A simulation testbed was developed in order to study the rule features and database characteristics that play an important role in the performance of concurrent production rule execution.",
Decomposing heterogeneous inter-entity relationship updates,"New problems of updating views involving inter-entity relationships or joins are identified, beyond those reported previously in the literature. A general purpose method and a set of algorithms are presented for correctly decomposing multilingual update requests on a network of distributed heterogeneous databases. The method and algorithm also apply to both homogeneous nondistributed and distributed database environments. The method, called prototype views and update rules, applies to individual relationships in an entity relationship (ER) view of the network database and gives a floorplan for update decomposition. The network database view represents a unified conceptual view of all the individual databases in the heterogeneous network (i.e. of the objects shared across the network). The update request is decomposed into a sequence of intermediate control language steps to subsequently guide the particular updates to each of the underlying databases in the network. Individual database updates are performed by each particular database management system (DBMS).","Erbium,
Distributed databases,
Data models,
Object oriented modeling,
Database systems,
Computer architecture,
Prototypes,
Computer networks,
Computer science"
The graphical user interface of a medical workstation project,"Within the COMED project, medical workstations have been developed which provide computer-assisted methods for image management, 2D and 3D image visualization and processing, teleconferencing and data communication An ""user-friendly"" human-computer interaction has to be provided.",
Disturbance attenuation via minimal order observers,The issue of the H/sub infinity / compensator design based on minimal order observers is addressed. A new approach for robust control design is proposed. Results and control algorithms pertaining to precise H/sub infinity / loop transfer recovery (H/sub infinity //LTR) are derived. A numerical example illustrating the proposed design procedure is also presented.,
Fusing of immunoscintigraphy SPECT with CT or MRI for improved multimodality image interpretation,"Correlation of PET or SPECT functional with CT or MRI anatomic transaxial images often enhances the information available on these studies. Careful registra­tion of images from two types of studies may be used to identify a structure containing to a PET or SPECT abnormality or to evaluate the functional or metabolic characteristics of an abnormal or normal structure. CTSPECT or PET image registration has been applied to brain imaging for metabolic and cerebral perfusion studies [1–3], more recently, to Ga-67 imaging of the chest [4], as well as to CT-SPECT correlation in cancer patients undergoing immunoscintigraphy [5–7]. We have applied an image registration technique to correlate CT or MRI of the abdomen and chest with SPECT images obtained after the administration of tumor-directed radiolabeled monoclonal antibodies. Correlation of PET or SPECT functional with CT or MRI anatomic transaxial images often enhances the information available on these studies. Careful registration of images from two types of studies may be used to identify a structure containing to a PET or SPECT abnormality or to evaluate the functional or metabolic characteristics of an attempt to improve our interpretation of these imaging studies.",
Variable-rate coding for meteor-burst communication using punctured convolutional codes,"Meteor-burst (MB) communication is an attractive means of beyond line of sight radio communication for many applications. Error control coding provides powerful means for addressing problems posed by the uneven distribution of received power observed with the MB channel. The author considers the use of variable-rate punctured convolutional codes for implementing an adaptive transmission scheme for MB communication. The scheme has been subjected to experimental verification by simulation. The validity of the approach is confirmed: for a given target bit error rate, a substantial improvement in throughput is observed with the adaptive scheme as compared to a fixed coding rate scheme.",
Retrofits to BWR safety and nonsafety systems using digital technology,"The history of safety-related and non-safety-related control systems designed into GE boiling water reactor (BWR) nuclear power stations is reviewed. Design limitations and parts availability for these older designs indicate the need to provide system replacements. Two contemporary digital product lines developed and offered by GE-Nuclear Energy provide system replacements. NUMAC is the safety-related product line and the GE Fanuc product line is used for non-safety-related applications. The resolution of issues encountered in the implementation of digital products in BWR systems such as application, qualification, and operator interface is discussed. The application of GE Fanuc equipment to the non-safety-related recirculation flow control system of a BWR-3 type reactor is discussed in some detail.",
A software environment for programming distributed memory machines,"For efficiency, multiprocessor local memory machines work mostly on the message passing principle, and therefore are programmed using the framework of communicating sequential processes. This programming should be easy to do, and this ease obviously requires an adequate software environment. One such environment, ADAM, is the main topic of the paper. Especially important and time consuming in the development cycle of a distributed application is the debugging phase. Therefore among the tools provided by the ADAM environment, those dedicated to debugging have been emphasized. The most interesting are: a centralized simulator-debugger at the level of the language; a tool based upon traces that enables to see the communication that took place during an execution. The most original part of this work consists of debugging mechanisms dedicated to communication.",
Conditions for a Cayley Coset Graph to Be Simple,,
An Approach To Portable Parallel Programs,,
A feature selection method for multi-class-set classification,A versatile technique for set-feature selection from class features without any prior knowledge for multi-class-set classification is presented. A class set is a group of classes in which the patterns represented with class features can be classified with a existing classifier. The features used to classify patterns between classes within a class set are referred to as class features and the ones used to classify patterns between class sets as set features. A set-feature set is produced from class-feature sets under the criterion of minimizing the encounter zones between class sets in set-feature space. The performance of this technique was illustrated with an experiment on the understanding of circuit diagrams.,
Saliency mapping in associative vision machine,"A very effective measure of saliency, proposed by A. Sha'ashua and S. Ullman (1988), is based on curve length, continuity, and smoothness. Implemented as an iterative process to reduce complexity, it still takes 0.5 s/iteration on the Connection Machine. The authors present an associative algorithm more than three orders of magnitude faster when executed on the ARTVM (Associative Real Time Vision Machine). This is a classical associative architecture, adapted for vision and modular VLSI, that requires a very modest hardware complement (<100 chips).",
Numerical calculation of temperature field for the case of simple convection model in autoclave,"A numerical study of temperature field for the case of 8.5-L autoclave, filled with water, is performed using the iteration method. The natural convection in liquid is assumed to be steady, axisymmetric and laminar. Two thermal steady states of the vessel are considered, with weak cooling and with intense heat exchange between the surroundings and the baffle region. For both states, almost identical local temperatures under the plunger (350 degrees C) and under the bottom of the vessel (390 degrees C) are achieved. The results show several common features for both thermal states. The velocity of water flow is several times higher in the upper than in the lower zone, and a strong concentration of isotherms exists in the interzone region. The radial and axial temperature gradients become greater when additional cooling is applied to the vessel.",
A Study on Physiological Parameter Estimation Accuracy for Tracer Kinetic Modeling with Posttron Emission Tomography (PET),"Tracer kinetic modeling with Positron Emission Tomography requires measurements of the time-activity curves in both plasma (PTAC) and tissue to estimate physiological parameters. Ideally, this PTAC should be the tracer local capillary plasma time-activity curve (CPTAC). However, due to the inaccessibility of direct measurement of CPTAC, the arterial plasma time-activity curve (APTAC) is usually used to replace CPTAC. The range of physiological parameter estimation errors caused by this replacement is not clear yet. In this paper, CPTAC is derived from the APTAC measurement and a 4-compartment PTAC model [2]. This CPTAC is then used to study the effects of using APTAC to replace CPTAC and APTAC measurement errors on the estimation of the physiological parameter. The results show that using APTAC directly in parameter estimation can cause considerable biases and increase the uncertainty of parameter estimation.",
Three-dimensional computer graphics using EGA or VGA card,"An upper-level undergraduate 3-D computer graphics course using the IBM PC with an enhanced graphics adapter (EGA) or video graphics array (VGA) card was developed. Topics discussed in this course include three-dimensional viewing transformations, geometric transformations, animation, hidden line and surface removal, interpolations, and shading techniques. A broad coverage of computer graphics techniques and the easy accessibility of the IBM PC to a large number of students are the major features of the course.",
Micromachined silicon substrate electrodes for extracellular recording,"This paper reviews the present status of multichannel silicon microprobes for recording extracellular potentials in CNS. A wide variety of probe geometries are now available for acute and chronic electrophysiological studies. One and two dimensional arrays offer possibilities for precisely placed electrode recording sites meeting the geometrical needs of the investigation by matching the cytoarchitecture of the tissue under study. Similar multichannel stimulating arrays allow precisely controlled current/charge waveforms to be delivered to highly-localized areas of tissue. On-chip circuitry has been developed for these probes to permit features such as amplification, impedance buffering, multiplexing, and self-testing to be realized, while minimizing the number of external leads. Long term chronic experiments are possible through the use of an unique silicon ribbon cable construction which integrates the interconnect with the electrode thus removing the need for failure prone bonds near the electrode.","Probes,
Silicon,
Impedance,
Electrodes"
A remote console system for balloon borne experiments,"A remote console system is developed to improve remote control over balloon-borne experimental apparatus. The remote console system, residing at a ground station for balloon-borne experiments, sends commands to the apparatus and receives transmissions from it. The system communicates by radio with microcomputers incorporated in the experimental apparatus borne on the balloon, where the microcomputers control the apparatus individually. Personal computers in the system emulate the remote console of the microcomputers. The apparatus is thereby remotely controlled through the personal computers placed at the ground station. The system includes plural personal computers which are interconnected so as to share the transmissions from the apparatus. The transactions between the ground station and the balloon-borne apparatus are supplied to work stations to be analyzed further. The authors describe the implementation of the system and the communication between the ground station and the balloon-borne apparatus.",
On the coding delay of a general coder,"The authors propose a general model for a sequential coder, and investigate the associated coding delay. This model is employed to derive lower and upper bounds on the delay associated with commonly used encoders and decoders for noiseless data compression.",
A multilayered neural network for processing 2D tomographic images in neurosurgery,"Summary form only given. A prototype artificial neural network (ANN) which is capable of processing serial sections of the brain obtained from computed-tomography (CT) or magnetic resonance imaging (MRI) tomographs has been designed. The segmented, outlined images, representing internal brain structures, both normal and abnormal, are then used as an input to a 3-D stereotaxic radiosurgery planning software. The algorithm was implemented as a software simulation in a microcomputer, structured as three cascading subnetworks. The ANN performs very well in the overall task of obtaining automatically outlined and segmented brain slices, for the purposes of 3-D reconstruction and surgical planning.<>",
Implementing automated procurement engineering at BG&E,"Baltimore Gas and Electric's (BG&E's) approach to implementing an automated procurement engineering process is presented. The process emphasizes part safety classification, procurement specification, and warehouse description standardization, of a limited population of the most frequently procured parts (stocked replacement items for safety-related systems, structures, and components). Logical grouping of over 10000 stock items resulted in consolidation to 275 automated procurement specifications maintained through a PC-based computer application. This automation has resulted in the following cost benefits: reduced procurement engineering staff, reduced procurement request backlog, reduced volume of bid exceptions/deviations, and elimination of duplicate stocked items.",
SOFTMTARE TESTING: OPPORTUNITY AND NIGHTMARE,,
The conversion of diagrams to knowledge bases,"If future electronic documents are to be truly useful, one must devise ways to automatically turn them into knowledge bases. In particular, one must be able to do this for diagrams. This paper discusses biological diagrams. The author describes the three major aspects of diagrams: visual salience, domain conventions and pragmatics. He next describes the organization of diagrams into informational and substrate components. The latter are typically collections of objects related by generalized equivalence relations. To analyze diagrams, the author defines graphics constraint grammars (GCGs) that can be used for both syntactic and semantic analysis. Each grammar rule describes a rule object and consists of the production, describing the constituents of the object, constraints that must hold between the constituents and propagators that build properties of the rule object from the constituents. The author discusses how a mix of parsing and constraint satisfaction techniques are used to parse diagrams with GCGs.",
Abstracting and Explaining Simulation Model Behaviour,,
Minimization of NAND circuits by rewriting-rules heuristic,"A method is given for further minimizing the multilevel NAND gate circuit having single-rail inputs obtained by applying the inhibiting-loop method of K. Goto (1989) to the given function. Using several theorems proposed by the authors several rules are used to determine whether the same input exists in the preceding and succeeding gate levels, and to determine whether the common input exists at the same first level of some parallel multilevel NAND gates, or other conditions. The Lisp language program utilizing this method was run on the microVAX-II computer for three-variable P-equivalence classes and four-variable functions. As a result, the coincidences for the three-variable functions and four-variable functions between the ideal results and the obtained results were 40% and 11%, respectively, when using the inhibiting-loop method alone. However, the results improved to 90% and 64%, respectively, by the addition of this reducing method.",
The design of a linear image processor,"A linear array can be applied to both low-level and intermediate-level processing tasks. The design of a semi-single instruction, multiple data (SIMD) linear array for low-level processing tasks is described. Its special features include a dual-communication channel, a decoding network and a binary unit. Its potential applications in intermediate-level processing are also addressed.",
The ZEUS calorimeter second-level trigger and readout system,"The ZEUS CAL-SLT (calorimeter second-level trigger) and calorimeter data-acquisition systems, implemented on a transputer network of more than 100 transputers, are fully operational. Requirements for the CAL-SLT and readout system led to: assignment cabling of calorimeter cells to processors; the use of the INMOS transputer on account of its built-in multitasking capabilities and its straight-forward application as a building block in processor networking using its four DMA-driven bidirectional serial data links for communication; and the use of two processors for each calorimeter region, one dedicated to triggering, the other to data readout.",
Exploiting Instruction-level Parallelism With The Conjugate Register File Scheme,,
Multi-scale analysis of discrete point sets,Presents the shape of a sparse point set S in R/sup 2/. A crucial step in finding the shape of a sparse point set is the definition of its boundary. This boundary is a graph indicating a relation among the elements of S. No well defined definition of such a boundary is found in literature. For continuous point sets this problem does not exist as the boundary has a unique definition. The authors pose general criteria a boundary definition should satisfy and show that the alpha -graph satisfies those criteria. The boundary is a function of the scale parameter alpha . The authors further show that the alpha -graph has a strong relation with mathematical morphology. As an application the use of the alpha -graph in the multi-scale recognition of industrial objects is shown.,
Surface reconstruction from derivatives,Most methods to reconstruct surfaces from their derivatives assume two orthogonal derivatives in perfect registration. The authors propose an approach to use derivatives in arbitrary directions and to register orthogonal derivatives if they are not registered. They also develop a method to integrate second derivatives in the reconstruction.,
Palm: an integrated parallelism enhancement environment with static-dynamic scheduling,"While everyone agrees that algorithm, compiler, and architecture should operate hand in hand to produce the most efficient parallel code, a unified research effort leading to an environment that a user can quickly use to map a 'dusty deck' as well as software in newer languages to an efficient code for a variety of commercial compilers and architectures, has been lacking. The authors have undertaken an integrated approach leading to an environment that may be used for both important classes of architectures: shared memory, and private memory MIMD machines in a language independent manner. Various utilities permit measurement of potential parallelism in an algorithmic step, perform source code modification to assist the compiler in utilizing the embedded parallelism, and tune the code to a specific architecture. The Static Dynamic Scheduler, which is a part of the environment estimates the processor requirements of basic blocks of given program and allocates the processors partially at compile time and partially at run time, to obtain a good tradeoff between speedup and utilization.",
Learning and representing concepts with graded structure,"The author presents a novel method for representing and learning concepts with graded structure. The method uses a hybrid concept representation that combines symbolic and numeric representations. In learning a concept, the method builds a general concept description for representing common cases of the concept. Such a description is in the form of decision rules, interpreted by a weighted distance measure, and numerical thresholds. The method has been implemented in the system FCLS (flexible concept learning system) and tested on a variety of problems.<>",
A hierarchical deformation model for online cursive script recognition,"The authors propose a hierarchical deformation model to describe the deformation of cursive Chinese characters for online character recognition. This approach consists of two levels of match processes. First, the attributed string editing algorithm determines the stroke correspondence between the input and the reference pattern. Next, the constrained parabola transformation is used to reduce the difference between the matched strokes appropriately. Experimental results show that the hierarchical deformation model provides a robust distance measure between patterns, and obtains a quite accurate approximation to the deformation of cursive Chinese characters with much lower computational cost.",
Optimal allocation of shared data over distributed memory hierarchies,"Nonreplicated shared data of distributed applications is optimally allocated to pre-specified multilevel memory partitions at the sites of a heterogeneous multicomputer network to minimize a weighted combination of systemwide mean time delay performance and mean communication cost per access request. Greedy and fast optimization algorithms are presented for nonqueueing lightly-loaded as well as heavily-loaded multiqueue system models with channel, l/O, and memory hierarchy queues. Extensions to data exhibiting nonuniform access demand rates and distinct query and update statistics are presented.",
An overview of computer graphics training course,"The computer graphics training course at the Department for Computer Science, University of Maribor, Slovenia is considered. The reasons why computer graphics is needed as part of the computer science curriculum are considered. The computer graphics course curriculum is then reviewed. The main focus is given on the description of computer graphics training. Software teaching tools developed by the authors are described.",
Long range correlations in healthy dynamics and their breakdown with disease: A new paradigm for physiological monitoring,"We propose a new framework for conceptualizing and quantitating the dynamics of health and disease, using neuroautonomic regulation of the heartbeat as a model system. This theory is based on two postulates: 1) Complex physiological systems operate far from equilibrium and demonstrate long-range correlations indicative of a fractal (scale-invariant) mechanism; 2) Pathologic dynamics are marked by a breakdown in this long-range correlation behavior.",
Severity measurements using neural networks,"The authors introduce a novel patient severity measurement model using neural networks. A three layer, fully connected backpropagation neural network was used in the pilot experiment. The results are promising and demonstrate that the backpropagation neural network technique is capable of assessing the severity value by learning from raw data. The neural network is easy to improve and of relatively low cost. It saves the expert's valuable time used in assigning numerical values to variables.",
CONSCIENCE: Control and System Identification using Elements of Neural Network Computation Engineering,"Neural networks are attracting a lot of interest as process models for model predictive control. This paper presents a neural network model predictive control algorithm (NNMPC). The optimal control problem is formulated, and it is solved using a feasible sequential quadratic program that handles position and velocity constraints. The process model is a recurrent neural network. In order to train a recurrent network, a more general learning law was needed. This learning law is presented. Further a significant computational advantage is realized in the model prediction control calculations by using a part of this general learning law. This benefit is discussed. Finally the NNMPC procedure is illustrated using a first principles representation of a multi-input, single-output industrial reactor.",
Rapid learning with large weight changes and plasticity,"A first step towards a rapid-learning algorithm is presented. The learning rules enable a network to learn new information from few training examples without destroying previously learned information. In order to learn from few training examples, the neural network must allow relatively large weight changes. The large changes have the effect that the network reproduces presented training examples. In order not to destroy previously learned information, the new learning rules should not change connections which have stabilized their connection weights. The authors propose to associate an additional value, called plasticity, with each connection, which indicates how much the connection weight can be adjusted. Simulations using the proposed learning rules demonstrate that they enable a network to learn rapidly to distinguish among several patterns.",
A case study of automatic landings,"The case study described is over 20 years old, but it is not just of historic interest: the pioneering techniques used are still applicable and similar problems still await analysis. Above all, it is not often that one has the opportunity of looking back 20 years with the benefit of hindsight and still being able to benefit from the experience. The case study was a 'safety study', which would today be called a hazard analysis, in the form of a contract placed upon Software Sciences Ltd. The terms of reference were to accept the studies and judgements made of the airborne and ground guidance equipments and to identify, and preferably quantify, all other possible hazards to a specifically defined operation.",
Non-Iterative Computation of the Infimum in H∞-Optimization for Plants with Invariant Zeros on the jw Axis,"This paper presents a simple and non-iterative procedure for the computation of the exact value of the infimum in the singular H∞ optimization problem and is a continuation of our earlier work [1]-[3]. Our problem formulation in general and we do not place any restrictions on the finite and infinite zero structures of the system, and the direct feedthrough terms between the control input and the controlled output variables, and between the disturbance input and the measurement output variables. Our method is applicable to a class of singular H∞-optimization problem for which the transfer functions from the control input to the controlled output and from the disturbance input to the measurement output satisfy certain geometric conditions. In particular this paper extends the result of [3] by allowing these two transfer functions to have invariant zeros on the jw axis.",
A convolution-based DCT algorithm,A convolution-based algorithm for computing the discrete cosine transform (DCT) (with power of two length) that is based on some theorems of number theory is proposed: It computes a length-N DCT (with N a power of two) using only N multiplications.,
Design of reliable networks,"The author considers a reliable network synthesis problem. It is assumed that in a computer network, denoted as G/sub n,e,/ the number of nodes n, the number of edges e, and the operational probability of each edge are known. The system reliability of the network is defined to be the probability that every pair of nodes can communicate with each other. The problem is to find a network G*/sub n,e/ that maximizes system reliability over the class of all networks having n nodes and e edges. The optimal networks are found for the classes of networks G/sub n,n-1/, G/sub n,n/ and G/sub n,n+1/, respectively. In addition, an upper bound of maximum reliability for networks with n-nodes and e-edges is derived in terms of node degrees. Computational results for the reliability upper bound are also presented. The results show that the proposed reliability upper bound is effective.",
Cache Write Generate for High Performance Parallel Processing,"We present, Generate, a new cache write handling scheme that avoids unnecessary reads from main memory, reduces bus contention, and increases the available bandwidth of the memory. Cache Write Generate increases the amount of CPU execution and memory load/store overlap, and decreases the memory cycle time. We compare the performance of cache write generate with write around and write allocate in single processor and shared bus multiprocessors and demonstrate a speedup of 1.2 to 1.5 over allocate and write around.",
Anomalous Electrical Deactivation of Low Concentration Rapid Thermally Annealed Arsenic Implanted Silicon,Lattice location studies of rapid thermally annealed As implanted Si have revealed a previously unreported buried region of stable non-substitutional arsenic-interstitial defects. Profiling analysis indicates that As atoms within these complexes are electrically active. Dissolution of this defect band with increasing annealing time is shown to correlate with further decreases in electrical activation. These results suggest that diffusion and activation of ion implanted As concentrations beneath electrical solubility are mediated on RTA timescales by non-equilibrium implantation-induced point defect distributions.,
A low power 12-bit ADC for nuclear instrumentation,"A low-power, successive-approximation, analog-to-digital converter (ADC) for low-rate, low-cost, battery-powered applications is described. The ADC is based on a commercial 50-mW successive-approximation CMOS device (CS5102). An on-chip self-calibration circuit reduces the inherent differential nonlinearity to 7%. A further reduction of the differential nonlinearity to 0.5% is attained with a four-bit Gatti function. The Gatti function is distributed to minimize battery power consumption. All analog functions reside with the ADC, while the noisy digital functions reside in the personal-computer-based histogramming memory. Fiber-optic cables carry all digital information between the ADC and this memory.",
Finding strongly connected components of circle cover graph in one-dimensional,"Given a set C=(c/sub 1/, c/sub 2/, . . ., c/sub n/) of n circles in the plane, the circle cover graph is the digraph G(C)=(V, E) where a vertex upsilon /sub i/ in V stands for the center of circle c/sub i/, and a directed edge < upsilon /sub i/, upsilon /sub j/> in E if and only if circle c/sub i/ covers the center of circle c/sub j/. The authors propose an O(n log n) algorithm with O(n) space to find all the strongly connected components of G(C) for the one-dimensional case. Based on this result, the time complexity of the algorithm proposed by N.F. Huang, C.H. Huang (Inf. Process. Lett., vol.40, p.13-20, October, 1991) to solve the repeaters allocation problem for one-dimensional case can be improved from O(n log n+e) to O(n log n); where e is the number of edges in G(C).",
Extended cycle shrinking: an optimal loop transformation,"The author discusses a novel loop transformation technique, extended cycle shrinking (ECS), that is based on cycle shrinking (CS). While CS is a very powerful technique in dealing with dependences involving a cycle, it fails to generate an optimal program in many cases. The ECS can generate optimal programs for a class of loops called regular cycle dependence loops.",
Linear local and global model checking algorithms for a kernal temporal logic language,Finite transition systems play a central role as formal models for reactive and concurrent systems. A promising technique for automatically verifying transition systems is model checking. In the model-theoretic approach one mechanically determines whether a system ts meets a specification f (expressed as a formula of some temporal logic) by checking whether ts is a model for f. The authors present a kernel specification formalism BTL. They discuss efficient (linear-time) global and local model checking algorithms for BTL. The global algorithm will compute all states that satisfy a given formula whereas the local algorithm will only check a formula for one state (typically the initial system state). Both algorithms run in time linear in the size of the transition system and the length of the formula.,
Generating all maximal independent sets on trees in lexicographic order,"An algorithm to generate all maximal independent sets in lexicographic order with polynomial time delay between the output of two successive independent sets was proposed by Johnson and Yannakakis (Inform. Process. Let., vol.27, p.119-23, 1988). This algorithm needs exponential amount of space. Johnson suggested an open problem which is to find such an algorithm with polynomial time-delay and space needed between the output of two successive maximal independent sets. The authors investigate this problem on trees. They first introduce a new problem, the constrained maximal independent set problem, which is NP-complete for general graphs. They show that, for trees, the constrained maximal independent set problem can be solved in theta (n) time, where n is the number of vertices. Based upon this algorithm, they propose another algorithm that generates all maximal independent sets in lexicographic order.",
Defaults as first-class citizens,"A nonmonotonic logic with explicit defaults, NML3, is presented. It is characterized by the following features: (1) the use of the strong Kleene three-valued logic as a basis; (2) the addition of an explicit default operator which enables distinguishing tentative conclusions from ordinary conclusions in the object language; and (3) the use of the idea of preferential entailment to generate nonmonotonic behavior. The central feature of the formalism, the use of an explicit default operator with a model-theoretic semantics based on the notion of a partial interpretation, distinguishes NML3 from most previous formalisms. By capitalizing on the distinction between tentative and ordinary conclusions, NML3 provides increased expressibility in comparison to many of the standard nonmonotonic formalisms and greater flexibility in the representation of subtle aspects of default reasoning. This is shown through examples.",
Ultrasonic scanning system for prosthetic applications in rehabilitation medicine,"A laboratory prototype imaging system has been built to aid in the development of an ultrasonic imaging system to generate three-dimensional mapping of skin and bone surfaces needed for computer-aided design of prosthetic limbs. The laboratory system incorporates a commercial ultrasonic imaging transducer. A first-order model of the ultrasonic image was developed to study the effect of varying system parameters. Preliminary data and analysis support the feasibility of using ultrasonic imaging techniques to obtain the three-dimensional data needed for computer-aided design of prosthetic limbs. The laboratory system will be used to generate data needed to develop the image processing techniques and system designs needed to develop an operational system. System concepts and design, numerical modeling, and experimental results are discussed.",
A microcomputer system for assessment of auditory brainstem responses,"To reduce the time needed for the analysis of the auditory brainstem responses, a microcomputer system has been developed for the assesment. It is based on the syntactic pattern recognition of the peaks with the attributed automata, and the comparison of detected peaks and normal peaks with the evaluation function, choosing representatives of peaks so that the values of this function will be maximized.",
The Technical Communicator as Sociologist: Does the Mind Have a Gender?,,
Abstract data groups: structuring distributed programs as layers,"Processes that cooperate in a binary fashion and hierarchical compositions of these are a popular structuring concept for distributed programming. The issue of modularizing distributed programs is discussed, and a modularization mechanism, abstract data groups (ADGs), is introduced. Examples are used to show why ADGs are useful and to indicate problems with previous methods. A comparison with related work is also presented.",
A relation merging technique for relational databases,"A merging technique for relational schemas consisting of relation-schemes, key dependencies, referential integrity constraints, and null constraints is presented. The author examines the conditions required for using this technique with relational database management systems that provide different mechanisms for maintaining null and referential integrity constraints. For relational schemas developed using an extended entity-relationship (EER) oriented design methodology, it is shown that a relation-scheme can be used for representing multiple object-sets not only for the standard binary many-to-one relationship-set structure, but for more complex structures as well.","Merging,
Relational databases,
Erbium,
Design methodology,
Computer science,
Research and development,
Cyclotrons,
Data models"
EPLOT: a machine-independent graphics system,"EPLOT was designed as an inexpensive and interactive small graphics library to be run on workstations, stand-alone microcomputers and mainframes, or microcomputers used as graphics terminals. It started as a minor extension to the machine-independent UNIX PLOT library but now includes capabilities for menu and mouse operations, animation, and other functions required in student projects. EPLOT allows the easy development and transfer of interactive graphics programs between SUN, MSDOS, Amiga, ATARI, and Apple Macintosh systems. It has played an important role in the philosophy of the computer graphics course offered at the authors' institution. The scope of EPLOT is demonstrated through a series of projects and programs.",
On the Complexity of Zero Finding for Univariate Functions,"We study the zero finding problem for univariate functions changing sign at the endpoints of an interval, and we survey some results of different authors. The complexity of zero finding, i.e., the minimal cost to determine a zero with a given accuracy ϵ, is studied in the worst and in the average case setting. For classes of smooth functions the results in both settings differ significantly. While ln(1/ϵ) is the order of the worst case complexity, the average case complexity is at most of the order ln ln(1/ϵ).",
High speed querying with the DAP 510,"Most database queries can be reduced to a few distinct classes of requests. These are (1) finding the k/sup th/ smallest element in an unordered set S, (2) finding the k/sup th/ through the (k+i)/sup th/ smallest elements in an unordered set S, and (3) return the record with a specific key. This paper presents a fast, efficient selection based system implemented on the DAP 510 for each of these query types. The DAP or the distributed array of processors is a commercially available array processor, a product of Active Memory Technology. This massively parallel computer attaches to a host computer as a peripheral processor. It differs from the conventional serial processor in that it can perform the same operation on many items of data in parallel.",
Derivation of Hard Deadlines for Real-Time Control Systems,"The computation-time delay in the feedback controller of a real-time control system may cause failure to update the control input during one or more sampling periods. A dynamic failure is said to occur if this delay exceeds a certain limit called a hard deadline. We present a method for calculating the hard deadlines in linear time-invariant control systems. To derive necessary conditions for (asymptotic) system stability, the state difference equation is modified based on an assumed maximum delay and the probability distribution of delays whose magnitudes are less than, or equal to, the assumed maximum delay. Moreover, the allowed state-space - which is derived from given input and state constraints - is used to calculate the hard deadline as a function of time and the system state. We also consider a one-shot delay model in which a single event causes a dynamic failure.",
Macintosh software for simulating resolution and scatter effects in PET,"To further understand and correct for the influence of the tomograph spatial resolution and scattered events in PET (positron emission tomography) studies of the central nervous system, the author has developed a methodology and software on a Macintosh personal computer for simulating PET image data from digitized anatomical information. He has used this approach to examine biases in interpreting PET brain tumor studies by implanting digital approximations of tumors into brain anatomy.",
Parallel electro-optical rule-based system for fast execution of expert systems,"This paper proposes the use of optics for a fast and parallel implementation of rule-based systems. The proposed optical system is hybrid in nature in which electronics is used for the user interface and optics for the rule-based inference engine. The proposed system uses two-dimensional planes as basic computational entities, and is therefore able to provide concurrent rule processing. Furthermore, it provides very efficient implementation of the basic operation needed in rule-based systems, namely, matching, selection, and rule firing. The execution speed of the proposed system is theoretically estimated and is shown to be potentially orders of magnitude faster than current systems.",
Nondeterministic and alternating computations,This paper proves that alternating computations with O(t(n)) time can simulate nondeterministic computations with O(t(n) log* t(n)) time and O(t(n)) nondeterministic moves. From this the authors prove that nondeterministic linear time is not closed under complementation if nondeterministic Turing machines with O(n log* n) time and linear nondeterministic moves are strictly more powerful than nondeterministic linear time.,
An adaptive back-propagation learning method: A preliminary study for incremental neural networks,"The authors apply the concept of minimizing weight sensitivity cost and training square-error functions using gradient descent optimization techniques, and they obtain a novel supervised backpropagation learning algorithm on a biased two-layered perceptron. In addition to illustrating the conflict locality of an inserted training instance with respect to previous training data, they point out that this adaptive learning method can get a network with a measurable generalization ability. This work can also be extended to an incremental network in which no training instances are needed to be remembered.",
Distribution of Odd Periodic Correlation Values of Binary Sequences,,
Using the IIPS framework to specify machine-discovery problems,"The authors apply the IIPS (inductive inference problem specification) framework to the task of specifying machine-discovery problems. They specify the problems attempted by equation-finding programs in general, and by BACON.1 in particular.",
A scalable data acquisition system for CEBAF: architecture and status,"A new data acquisition system is under development at CEBAF in support of experiments due to begin in 1994. CODA (CEBAF On-line Data Acquisition) has been designed to run on Unix workstations connected via Ethernet to multiple intelligent front-end crates, VME and FASTBUS, with CAMAC supported through VME. The system is modular and scalable, from a single front-end crate and one workstation with data transferred over Ethernet, up to as many as 32 clusters of front-end crates connected (eventually) via a high-speed network to a farm of analysis workstations. CODA includes a device-independent slow controls package with (currently) drivers for CAMAC, VME, and CAEN high voltage. Experience with early versions is discussed.",
Scatterometer Measurement of Differential Mueller Matrix of Distributed Targets,,
Database design for the use of Machine Induction to predict protein secondary structures,"In this short paper we briefly describe the prototype of a Protein Structure Prediction System (PSPS), which is being developed at Brunei University, UK for Biomedical applications. The PSPS is based on protein structure predicting Machine Induction algorithms [1], [2], [3], and an associated protein database designed for this application.",
Graph theoretic knowledge representation and knowledge organisation,"An attempt is made to develop an alternative knowledge representation method using the interpretive structural modeling (ISM) technique. Applying ISM entails generation of oriented and hierarchically arranged digraphs. These are considered a combination of conceptual graphs. The advantage obtained is that digraphs are precise minimum edge maps of the problem domain at hand, based on contextual relation(s) assumed among domain elements. The contextual relations also influence the form of the mapping structure. Since there is sufficient background knowledge in ISM, logical rules which help create an appropriately organized knowledge base are easily obtained.",
Research notes: An information analysis decision system,,
A novel systolic array processor for MVDR beamforming,"A fully pipelined systolic array for computing the minimum variance distortionless response (MVDR) was first proposed by J.G. McWhirter and T.J. Shepherd (1989). The fundamental concept is to fit the MVDR beamforming to the nonconstrained recursive least-squares (RLS) minimization. A different approach is proposed for MVDR beamforming which does not require the nonconstrained RLS minimization; then a fully parallel and pipelined systolic array is presented for the newly proposed algorithm, and finally the similarity and differences between both MVDR beamforming designs are described.<>","Systolic arrays,
Array signal processing,
Resonance light scattering,
Matrix decomposition,
Algorithm design and analysis,
Educational institutions,
Minimization methods,
Concurrent computing,
Least squares methods"
A neural network approach to large dimensional spectral pattern processing,"The authors present a multiple neural network system that extracts and interprets spatiotemporal features from two-dimensional spectral images. The system uses interconnected multiple networks where the first network extracts spatial features and successive networks label and classify the features. The labeling network uses a priori knowledge on its connection weights, thereby eliminating the need for extensive learning. The model was applied to speech spectral images to extract morphological properties of speech sound corresponding to certain phonetic cues. This approach enabled extraction of spatio-temporal features from large images using neural networks and also provided a mechanism to use a priori knowledge in the connection weights of the network.","Neural networks,
Feature extraction,
Data mining,
Labeling,
Filtering,
Speech recognition,
Backpropagation,
Linear predictive coding,
Computer science,
Speech processing"
Face recognition: combining cognitive psychology and image engineering,"Many cognitive tasks that are easy for humans to perform are proving difficult to emulate in computer systems. Combining the disciplines of psychology and engineering may offer a solution to some of these problems. A connectionist or neural network model of face recognition by humans which incorporates aspects of a model proposed by cognitive psychologists is presented. A comparative set of experiments has been performed using this simulation and human subjects for familiar face recognition. By employing the same stimuli for both humans and the computer model, it is possible to advance not only our understanding of human cognition but also to develop improved automated systems for face recognition.<>","Cognitive science,
Face recognition,
Feedforward neural networks,
Psychology"
Specular Surface Stereo: A New Method For Retrieving the Shape of a Water Surface,,
A new method for measurement of safety rod drop times,A method for measurement of safety rod drop times is proposed that is based on a fast electromagnetic transducer and an analog-to-digital converter (ADC) connected to a computer system. Evaluation of recorded data is conducted by computer codes that were developed. The first measurements performed at the fast-thermal core HERBE constructed in the RB heavy water nuclear reactor at the Nuclear Engineering Laboratory of the Vinca Institute showed that a relative uncertainty of less than 6% can be achieved in determination of the rod drop time with time intervals ranging from 0.4 to 10.0 s.,
An analytical performance model for parallel production systems,"An analytical model for parallel production systems is developed, where rule firing is modeled as a transaction. Both resource contention and data contention are modeled in detail, and the performance of locking-based and optimistic approaches is analyzed. It is shown that significant speedup can be gained in parallel rule execution. The main contribution is the insight into parallel rule firing provided by the parametric model.",
Performance Improvement for Vector Pipeline Multiprocessor Systems Using a Disordered Execution Model,"Memory contention may cause dramatic loss of performance in vector pipeline multiprocessor systems. To enhance memory performance, the disordered execution model aims at scheduling vector element accesses in order to avoid memory conflicts. This scheduling relies on memory bank activities at access issue time. A disordered pipeline execution is associated with disordered memory access in order to maintain the chaining of all processor functional units. An analytical model and simulations demonstrate the interest of this model.",
Surface generation in a tutorial dialogue based on analysis of human tutoring sessions,Presents a surface generator for an intelligent tutoring system based on analysis of human tutoring sessions. The tutoring system is designed to help first-year medical students understand the negative feedback system that regulates blood pressure. The authors illustrate the generation of appropriate natural language output using Lexical Functional Grammar based on a study of the cardiovascular sublanguage.<>,
On Cauchy system of searchlight problem in turbid slab,"With the aid of invariant embedding, the authors consider a mathematical model of a searchlight on a target of turbid slab, bounded below by a diffuse reflector. In the real physical situation, the faint background light illuminating the top may be allowed for. However, for the sake of simplicity, the angular distribution of radiation emergent from the top of the turbid slab with a point source is discussed, by embedding the problem within a family of parameters. The invariant embedding is used to obtain the Cauchy system of the scattering function in the searchlight problem. The initial-value solution coincides with that obtained via the integral operator method.","Slabs,
Light scattering,
Optical reflection,
Particle scattering,
Lighting,
Laser beams,
Riccati equations,
Information science,
Laboratories,
Computer science"
Simulating Teaching by Reasoning About Instructional Objectives,,
A model for activity-driven development of auditory receptive fields,"This paper presents a stimulus-driven model for the development of auditory receptive fields. The model is shown to develop all receptive field types found in the mammalian cochlear nucleus, as defined by their frequency responses. The success of this model in developing auditory receptive fields and its similarity to a model that was previously shown to develop visual receptive fields demonstrates that one development scheme is capable of forming appropriate receptive field structures for two different sensory modalities, vision and audition.",
The bus-usage method for the analysis of reconfiguring networks algorithms,"Reconfigurable networks have attracted increased attention recently, as an extremely strong parallel model which is realizable in hardware. The authors consider the basic problem of gathering information which is dispersed among the nodes of the network. They analyze the complexity of the problem on reconfigurable linear-arrays. The analysis introduces a novel criteria for the efficiency of reconfigurable network algorithms, namely the bus-usage. The bus-usage quantity measures the utilization of the network sub-buses by the algorithm. It is shown how this yields bounds on the algorithm run-time, by deriving a run-time to bus-usage trade-off.",
Recognition of connected numeral strings using partial boundary features,"Connected or touching numerals appear very often in handwritten documents when they are to be processed by a recognition system. They could be the results of writing habit, limited resolution of the graphic input device, or some preprocessing of the image. In this paper the author describes an approach to identifying connected numerals without a priori knowledge of the number of the numerals in the string. The left boundary of the numeral cage is used for the classification. Special methods are developed for determining the left boundary and extracting the features on it.",
An efficient store for object bases,"Storage management is the crucial issue in determining the overall performance of any database system. Execution of different data manipulation operations is, in general, supported by auxiliary data structures (accelerators, indexes). Object management brings a new quality into the computer data processing and, in turn, requires new implementation techniques capable of fulfilling the object processing efficiently. Navigation along various types of references among objects has become the performance bottle-neck since the traditional techniques used for navigation are by no means sufficient. In this paper, a new organization, called navigation index, is proposed. With this organization, the navigation is performed by computations based on the theory of simple continued fractions. The performance problem is formalized and the navigation index evaluated in relation to other implementation techniques.",
Debugging mapped parallel programs,"As more sophisticated tools for parallel programming become available, programmers will inevitably want to use them together. However, some parallel programming tools can interact with each other in ways that make them less useful. In particular, it a mapping tool is used to adapt a parallel program to run on relatively few processors, the information presented by a debugger may become difficult to interpret. The authors examine the problems that can arise when programmers use debuggers to interpret the patterns of message traffic in mapped parallel programs. They also suggest how to avoid these problems and made debugging tools more useful.",
Intelligent fault localization in software,,
Semantic query processing in multidatabase systems: a logic-based approach,"A multidatabase system (MDBS) is a system that integrates the operational data of several autonomous database systems and provides a uniform interface and control mechanisms to control access to those data. To efficiently retrieve and manipulate the data stored in MDBS, a metadata dictionary is needed as a repository of essential information for reasoning, controlling, and maintaining the retrieval/manipulation processes. The authors develop a two-level active metadata dictionary approach based on logic for building a metadata dictionary, query processing, and maintenance in MDBS. The low-level metadata dictionaries (LLMDs) keep metadata for each corresponding local database in MDBS, respectively. The high-level metadata dictionary (HLMD) integrates the metadata about all LLMDs.",
Bridging the gap between CASE tools and project management through a decision support system based on metrics,"The paper describes the architecture of a decision support system that includes a kernel consisting of three modules: decision strategy, decisions history, and decision analysis. It focuses attention on decision analysis, looking at the types of data that should be stored in a project database, the measurement process that should be used, and the software tools required to improve the capabilities of software development environments.",
Issues in the design of EHTS: a multiuser hypertext system for collaboration,"The paper describes the architecture, issues from the design, and experiences from the use of EHTS (Emacs hyper text system), a multiuser hypertext system for collaboration. EHTS consists of a text editor, a graphical browser, and an active hypertext database named HyperBase. HyperBase is built on the client-server model and has been designed especially to support collaboration among its users, by providing an event mechanism and a fine-grained lock mechanism. Events from HyperBase are used to notify the editor and browser about important actions on the shared data, enabling them to monitor changes. Four categories of issues from the design and experiences from the use of EHTS are reported: architecture, collaboration, user interface, and data model. Based on experiences with the client-server model, the author suggests a new and improved architecture for the event driven multiuser hypertext system. One major lesson learned is that events and fine-grained locks can provide powerful support for data sharing among multiple users simultaneously working in the same environment. The need for a flexible data model is another lesson learned. It is difficult to predict what data model objects actually will be needed, when the data model is designed before the user interface.",
Sequencing interactive features in process planning using episodal associative memory,"One of the problems in feature-based process planning is the sequencing of features. Features must be given an order for removal. This order, or sequence, is partially dependent on the geometric relationships between the features, if the geometric relationships between features are such that they dictate a particular sequence, the features are said to have an interaction. Identifying these interactions is an important first step in creating the process plan. An approach to solving this problem using constructive solid geometry operations and the episodal associative memory (EAM) is demonstrated. EAM is an approach to the construction of a memory that can efficiently and accurately associate a given problem or idea to relevant information in memory. Groups of features that have similar geometric relationships are clustered together by the EAM.",
A decentralised remote procedure call transaction manager,"A model for decentralized management of remote procedure call (RPC) transactions in a distributed system is presented. After the introduction of the problem and the RPC transaction model, the algorithms and some properties of the transaction management model are described. The decentralized RPC transaction management model has no transaction coordinators and therefore can tolerate any host failure. The model is transparent to programmers. It can act as a run-time system within the programming environment. Programmers can use RPC transaction calls as usual RPC calls.",
"Scheduling a mixed interactive and batch workload on a parallel, shared memory supercomputer","The authors analyze three approaches to scheduling mixed batch and interactive workloads on a supercomputer: (i) fixed partition, in which memory resources are statically allocated between the workloads: (ii) no partition, in which the interactive workload preempts resources as needed from the batch workload, and (iii) no partition with grouped admission, in which the interactive workload preempts resources only when the number of waiting interactive jobs reaches a threshold value. The authors also investigate the potential benefits of using virtual memory to perform the automatic overlay of jobs too large to fit in the amount of real memory instantaneously available to them. Using analytic tools, they compare the different policies according to the average speedup achieved by the batch workload given that a mean interactive job response time objective must be met by each. They show that, under a wide variety of conditions, fixed partition performs better than the other policies.",
Computer-aided software engineering standards and integration,"Standardization is intended to overcome the last hurdle in the integration of computer aided software engineering (CASE) in an open system environment. Since there are numerous CASE and CASE related standard efforts currently under development on national and international levels, there is a wide spectrum of overlapping CASE standards research that must be identified and evaluated as to its specific present and future implications. Primarily the effects of CASE standards as they pertain to CASE vendors and users are discussed, along with the integration options of modern system development environments.",
"Information partitions, deadlock, and non-sequential stochastic control","In control theory it is often assumed that a system's inputs and outputs can be ordered a priori in time. In practice, many distributed systems (those subject to deadlock, for instance) are not sequential in this sense. As a consequence, the task of identifying good designs is difficult to formulate as a stochastic control problem, e.g., nonsequential designs need not possess expected rewards. A property of a design's information partition that is necessary and sufficient to ensure deadlock-freeness is identified and shown to ensure that the design possesses an expected reward. This analysis, which suggests a framework for the constrained optimization of nonsequential stochastic control problems, is motivated by the fact, established in this work, that there exist deadlock-free designs that cannot be associated with any deadlock information structure.",
A remote gain control for photomultiplier tubes,"Measurements were made on Burle C83062 and Hamamatsu R2497 type photomultiplier tubes (PMTs) to determine an optimum method for remotely controlling their gain. The tubes' gain was varied by three different methods and energy and time measurements were done to determine the tube performance of each method. One method was chosen as optimum for its 10:1 gain range with only 250-ps time shift. A circuit was implemented as a computer-controllable PMT gain setting circuit which emulated this method. The circuit has applications in positron emission tomography, high energy physics, and virtually any radiation detection system involving PMTs.","Gain control,
Photomultipliers,
Positron emission tomography,
Voltage,
Radiation detector circuits,
Resistors,
Cathodes,
Energy measurement,
Optical coupling,
Technological innovation"
Design of PC — Based evoked potential processing system,"A IBM PC-based processing system for evoked potentials has been developed. The system includes: 1) preamplifier and preprocessing, 2) data acquisition (A/D converter), 3) programmable auditory stimulator, 4) IBM PC-based analysing and processing system. In this system, two methods of signal processing, overlapping averaging and adaptive averaging filter, have been used. The results have shown that this system has high performance and low cost.",
From Process-Oriented Functional Specifications to Efficient Asynchronous Circuits,,
A Generic Geometrical Path Planning For The Coordinated Motion Of Two Manipulators,,
A feature-based determination of optical flow field,"K. Kanatani (1985) and T. L. Huntsberger and S. N. Jayaramamurthy (1987) proposed a feature-based method for the determination of the optical flow field. They reported some successful results. However, the results were obtained under very strong assumptions or in a theoretically incorrect manner. The authors propose a theoretically correct feature-based method to determine the optical flow field, and evaluate the performance of several sets of feature candidates.",
A new method for topological placement for predictable performance,A novel concept for topological module placement for predictable performance based on segmenting the layout surface into topological rings is introduced. The method can be applied to hierarchical layout systems. It is flexible in terms of design styles and module specifications. The resulting placement observes user-defined signal runtimes.,
Computer generated equivalent circuit models for coaxial-line offset open circuits,"Offset open circuits have been investigated at the National Physical Laboratory, NPL (Malvern), as primary impedance standards for calibrating coaxial line measuring instruments such as six-port reflectometers and automatic network analysers. A need has developed for equivalent-circuit models of offset open circuits to assess their physical realisation. The authors have analysed a range of air-dielectric 14 mm, 50 Omega coaxial-line offset open circuits and have produced an equivalent circuit whose elements are frequency independent and which separates the capacitance due to the open circuit from the effects of the length of the line.",
The renaissance of CASE through computer aided reverse engineering (CARE),"CARE's aim is to improve the maintainability of existing systems. This is achieved by simplification and abstraction and also by restructuring. During restructuring, the programming paradigms are transformed. The abstractions and transformations produced by current or future CARE tools still form a multiple paradigm environment of cooperating standard languages. In future, new tools must be provided within CASE for the design of the communication between various subsystems, each of which is developed using paradigms suited to the particular problem. The repository systems are seen as a decisive contribution to quality improvement in software development. The visualization of architectural relationships and the use of metrics lead to a significant reduction in structural infringements, compared with current-day editing. The term 'software design' is taking shape particularly due to the work in the region of the cognitive sciences. The influence of this science and the techniques of software representation derived from it may lead to a renaissance of CASE.","Computer aided software engineering,
Reverse engineering,
Programming,
Visualization,
Software design,
Shape"
Layered architecture of multiple programming language system for multiparadigm programming,"A layered architecture that can provide a unified environment for multiparadigm programming on sequential processors is described. The architecture gives open-endedness to a system for programming in multiple languages based on multiple paradigms. Language-specific constructs such as control structures and variable definitions are given in an upper layer. Lower layers describe concepts common to all languages, such as data types and reference protocols. Since communication among languages is handled in the lower layers, the upper layers provide an open-ended abstraction for multiparadigm programming.","Computer languages,
Programmable control,
Protocols,
Logic programming,
Object oriented programming,
Knowledge representation,
Programming profession,
Parallel programming,
Libraries,
Information science"
Design of Periodic Output Feedback for Robust Stability,"Discrete-time H&3x0221E; results are applied to the design of piecewise-constant, periodic output feedback systems for stability robustness with respect to additive perturbations of the plant state matrix.",
An Interdisciplinary Case Study Program for Technology Students,,
Solving a nonlinear two-point boundary value problem,A two-point boundary value problem (TP-BVP) occurs during the process of solving a single differential equation or a set of differential equations whose solution has to satisfy both the given initial and final boundary conditions. The author shows that zeroing the discrepancy function is the crucial step in solving nonlinear TP-BVPs and uses M.P. Kennedy and L.O. Chua's (1988) neural network model to solve this problem. The advantages of this approach include its suitability for VLSI implementation.,
Fault-tolerant CSP,"In a network of communicating processes performing a distributed computation, one can replicate some or all of the communicating processes on different nodes to increase successful probability of the distributed computation against node failures. The authors use communicating sequential process (CSP) to express this scheme by appropriately translating the commands which communicate with replicated processes. In order to make the translation scheme simple and easy to implement, the order of the replicas are deterministic.",
XDL-the process modelling language for PVC-M,"PVC-M is a process-oriented configuration management system which recognizes (i) loose coupling between data and process models and (ii) the diversity of requirements by software developers and design methodologies that they adopt. The data and process models in PVC-M may communicate: information and control can be passed back and forth between the two. The object-oriented paradigm seems to provide a framework that can facilitate a clean integration of data and process models. The author discusses XDL, PVC-M's dynamically object-oriented process modeling language. XDL can be used to model several real-time, concurrent systems. The base language, SDL, supports nondeterminism.","Object oriented modeling,
Page description languages,
Computer science,
Computer architecture,
Multilevel systems,
Visualization,
Testing,
Programming,
Printers,
Operating systems"
Self-checking against formal specifications,"The authors use an algebraic technique of formally specifying a module that implements an abstract data type, with a C/sup ++/ implementation. An explicit mapping from implementation states to abstract values is added to the C/sup ++/ code. The form of specification allows mechanical checking of desirable properties such as consistency and completeness, particularly when operations are added incrementally to the data type. During unit testing, the specification serves as a test oracle. Any variance between computed and specified values is automatically detected. When the module is made part of some application, the checking can be removed, or may remain in place for further validating the implementation. The specification, executed by rewriting, can be thought of as itself an implementation with maximum design diversity, and the validation as a form of multiversion-programming comparison.",
Effect of initial system on homotopy methods for the H/sub 2/ reduced order model problem,"The effects of different initial systems on the efficiency of homotopy methods for solving the H/sub 2/ reduced order model problem was considered. Two major strategies for improving the efficiency are examined. One strategy, which involves solving the initial problem, usually leads to better results, but there is no known method to solve the initial problem for all or a majority of the initial systems. Another strategy, which considers constructing the initial system such that its eigenvalues resemble the eigenvalues of the final system, in some cases is more efficient. Also, a hybrid that combines the two previous strategies is considered. Finally, it is shown by an example that an unwise choice of the initial system can lead to a very inefficient algorithm.","Reduced order systems,
Symmetric matrices,
Nonlinear equations,
Quadratic programming,
Hydrogen,
Computer science,
Government,
Couplings,
Continuous time systems,
White noise"
Is SIMD enough for scientific and engineering applications on massively parallel computers?,"Some basic issues involved in matching an application to a distributed memory parallel machine are addressed. In particular, data communication and processor synchronization as they relate to MIMD (multiple instruction-multiple data) and SIMD (single-instruction-multiple data) architectures are discussed. To illustrate the differences, the authors describe the implementation and performance of several engineering and scientific applications that have been coded for both kinds of machines. They find that many problems are well suited to both architectures. However, when the natural parallelism in a simulation requires a loose synchronization between processors, the MIMD paradigm offers a greater programming flexibility than SIMD.",
Network design and performance for a massively parallel SIMD system,"It is shown that a nearest neighbor communication network can be complimented with a log-diameter multistage network to handle different communications patterns. This is especially useful when the pattern of data movement is not uniform. The designed network is evaluated for two cases: a dense case with many processing elements communicating and a sparse case. For 32-b data, the algorithm for computing partial sums of an array improves by 2.7 times with the multistage interconnection network. In a sparse random case, the number of cycles taken to communicate 32 b is 4000 (with 10% of the nodes communicating). Thus, it is concluded that a network like a multistage omega network is very useful for SIMD (single-instruction multiple-data) massively parallel machines. This is especially true if the machine is to be used for applications where long distance and nonuniform routing patterns are needed.",
Flexible circuit simulation with mixed-domain and mixed-mode applications,"Flexible circuit simulation through user-defined enhancements of traditional circuit analysis algorithms is presented. In particular, enhancements of the DC transfer curve analysis are used for mixed-domain simulation as required in analysis of self-heating effects of GaAs devices while enhancements of time-domain analysis are used for simulation of mixed analog-digital circuits at different levels of abstraction.",
"Overview of the Scalable Coherent Interface, IEEE STD 1596 (SCI)","The Scalable Coherent Interface (SCI) standard defines a new generation of interconnection that spans the full range from supercomputer memory 'bus' to campus-wide network. SCI provides bus-like services and a shared-memory software model while using an underlying packet protocol on many independent communication links. Initially these links are 1 GByte/s (wires) and 1 GBit/s (fiber), but the protocol scales well to future faster or lower-cost technologies. The interconnect may use switches, meshes, and rings. The SCI distributed-shared-memory model is simple and versatile, enabling a smooth integration of highly parallel multiprocessors, workstations, personal computers, input/output, networking, and data acquisition.",
On interoperability for KBMS applications-the horizontal integration task,"Interoperability of programming languages with persistency requires new concepts to make a single knowledge base management system (KBMS), a custom-tailored tool for applications of various programming languages and of different programming paradigms. The authors describe a method for the horizontal integration of KBMS applications from different programming languages. They used the commonly known ADT definition technique to maintain a vertical integration between languages and the KBMS, and propose schema sharing and polymorphism as the background for this particular kind of interoperability. The suggested approach was validated by an extended KBMS object manager, the conceptual object manager. Some of the design principles of the conceptual object manager, the vertical integration task, and the semantics of the horizontal integration are considered.",
Design of dependable real-time systems (extended abstract),"Summary form only given. In this presentation, the current challenges to the power sector are illustrated. The main pillars of the strategy of power sector and their justifications are presented and discussed. The draft of the new electricity law is presented including how the law has handled the strategic targets. Also, the impact of the law on; the structure of the power sector, development of renewable energy and supporting energy efficiency, is discussed. Finally the challenges facing the reforms are presented.",
Minimizing external wires in generalized single-row routing,"Much of the recent work on the automated design of VLSI chips has concentrated on routing problems associated with such designs. One major class of routing problems focuses on single-row routing. Recently, the traditional single-row routing model has been generalized to allow external wires. Under this generalized model, it is possible to route many more single-row routing instances than in the traditional model. There is, however, a clear disadvantage in the use of external wires, since they force a lengthening of the channels surrounding the single row of terminals. Thus, it is desirable for these generalized single-row routings to use a minimum number of external wires. A linear-time algorithm for determining the minimum number of external wires needed to route a given instance of single-row routing is provided here.",
A Bridge Of Bits,,
Noise propagation in SPECT images reconstructed using an iterative maximum-likelihood algorithm,"Computer simulations were performed to investigate the effects of the photon noise in radionuclide projection data and the uncertainty in the attenuation map on the image noise in attenuation-corrected SPECT (single photon emission computed tomography) images reconstructed using a maximum-likelihood expectation-maximization algorithm. Simulated radionuclide projection data from a head phantom were acquired using a fan-beam geometry consistent with the emission-transmission (ETCT) system being developed at the University of California at San Francisco. The mean ( mu ) of the reconstructed pixel values in the region of interest started to converge after 10 iterations and the standard deviation ( sigma ) increased with the number of iterations. The sigma / mu ratio was found to be inversely proportional to the square root of the total detected counts and proportional to the relative uncertainty in the attenuation maps. These two noise components contributed independently towards the noise in the reconstructed image. In a typical ETCT system employing an X-ray tube for attenuation map acquisition, the uncertainty in the reconstructed radionuclide distribution would be limited mainly by photon noise in the projection data.",
Computing parallel prefix and reduction using coterie structures,"The efficient computation of region parameters in image understanding by a SIMD (single-instruction multiple-data) array requires that those regions be processed simultaneously. The difficulty is in orchestrating nonuniform data-dependent communication using only a single thread of control. The authors have found that, on reconfigurable broadcast meshes, coterie structures can be used to overcome this problem. They present a deterministic algorithm to compute parallel prefix in O(log N) communication steps for a number of real images and sketch a randomized reduction algorithm based on graph contraction that has O(log N) complexity for all images.",
3D cursors for volume rendering applications,"An interface metaphor is proposed for developing a 3-D cursor for volume rendering applications. The metaphor, luminous gel, is a material for molding a 3-D cursor. It has been demonstrated that such a cursor's location and spatial relationships with volume-rendered 3-D objects are readily perceivable. Editing tools made in luminous gel have also been developed, which are useful as effective positioning tools for functional operations and inspecting devices for feature exploration and scene understanding by enabling immediate depth perception and object highlighting. The editing tools have also be further elaborated for performing planar and curved sectioning directly and naturally.",
Recurrent competitive Hebbian learning,"Competitive Hebbian learning is extended to networks with trainable lateral connections, in addition to the trainable feedforward connections considered previously by the author (1991,1992). These recurrent systems are able to learn to respond to ordering in time of the input vectors. The theoretical framework for the extension of competitive Hebbian learning to recurrent systems is presented. This is followed by three demonstrations of recurrent competitive Hebbian learning, two unsupervised and one quasi-supervised. The first example is a system of two nodes which are trained on a set of Gaussian spots presented in a 10-by-10 input array. The second example shows the system learning to respond to vertical lines in a small, 4-by-4 input array. The final example is of a system trained to produce useful responses to a tiny Boolean algebra test, where the Boolean variables are the successive values of the single input variable.",
Object-oriented programming in the large using group concept,A method for constructing large distributed software systems in an object-oriented way is presented. The authors define a group which is an object in the sense of programming in the large. A group may be distributed over many computing nodes. The concept uses a graph formalism to describe the whole system and its transformations.,
Top-down teaching enables task-relevant classification with competitive learning,"A method of augmenting the basic competitive learning algorithm with a top-down teaching signal which allows task relevant information to guide the development of synaptic connections is described. This teaching signal removes the restriction inherent in unsupervised learning and allows high-level structuring of the representation while maintaining the speed and biological plausibility of a local Hebbian-style learning algorithm. The function of the teaching input is illustrated geometrically, and examples of the use of this algorithm in small problems are presented. This work supports the hypothesis that cortical back-projections are important for the organization of sensory traces during learning.",
The impact of task-length parameters on the performance of the random load-balancing algorithm,"Considers the problem of dynamic load balancing in an n processors parallel system. The authors focus on the algorithm which randomly assigns newly generated tasks to processors for execution. This process is modeled by randomly throwing weighted balls into n holes. For a given program A, the ball weights (task lengths) are chosen according to an unknown probability distribution D(A) with expectation mu , maximum M and minimum m. For any A, D(A) and a constant 0< in",
Dynamic selection through gating lattices,"The authors introduce the gating lattice as a parallel distributed model for adaptive sampling of visual images. A gating lattice is a parallel switch capable of dynamic gating, i.e., selecting and propagating one of several input patterns. Gating is distributed in that it is locally controlled. An example of a dynamic-selection problem is given, and the appropriate gating lattice is introduced. The equivalence of the gating lattice with the Ising lattice is specified. Simulations have led to the conclusion that gating lattices form an adequate substrate for models of visual attention.","Lattices,
Neurons,
Computer science,
Image sampling,
Large-scale systems,
Layout,
Retina"
A Partitioning Scheme For Multiple Pla Based Control Part Synthesis In Ideas,,
Obtaining tight upper-bounds for the state complexities of DFA operations,"The authors consider the state complexity of basic operations of regular languages. They show that the number of states that is sufficient and necessary in the worst case for a deterministic finite automaton (DFA) to accept the catenation of an m-state DFA language and an n-state DFA language is exactly m2/sup n/-2/sup n-1/, for m, n>1. The result of 2/sup n-1/+2/sup n-2/ states is obtained for the star of an n-state DFA language, n>1. State complexities for other basic operations and for regular languages over a one-letter alphabet are also studied.",
On operational equivalence of COSY programs,"COSY equipped with an operational semantics, bisimulation, and equivalence between COSY programs are considered. The operational semantics enables the author to introduce a refined notion of an (observational) equivalence between COSY programs. His refinement is complete in this sense that observationally equivalent programs represent identical causality relations, i.e. they are behaviorally equivalent.","Computer science,
Electronic mail,
Concurrent computing,
Intersymbol interference,
Interleaved codes"
Relative-clock-based specification and test result analysis of distributed systems,"A model employing totally ordered events of a distributed system based on a logical clock has been presented by L. Lamport (1978). The authors propose a new interpretation and extension of Lamport's notion of concurrency by introducing the concept of relative concurrency to capture the nature of concurrency of distributed systems by means of a relative (or logical) clock. They then derive a totally ordered global events model based on the relative clock. Based on this model, they represent and interpret timing (ordering) information from observable scenarios, including collision scenarios of the system, expressed in an extended trace assertion language (ETAL) specification. Finally, a new approach is illustrated with a realistic example for test result analysis including timing information based on the global events model.",
A layout tool for Glotos,"Glotos is a visual representation of Lotos, and both are semantically equivalent. In this paper, a Glotos layout tool is described, which takes either the Lotos or the edited Glotos specification as input and generates an aesthetic Glotos layout as output. In both cases, a Glotos syntax tree is created. A bottom-up procedure is then used to calculate the boundary for each Glotos constructor. Finally, a top-down procedure determines x, y coordinates for each visual constructor. Unlike other layout tools, the Glotos layout tool makes full use of the syntactic and semantic information of Glotos in layouting, which greatly improves the efficiency of the layout tool.",
An Approximation Analysis of an ATM Heterogeneous Bursty Arrivals,"We analyze approximately a discrete-time queue which represents an ATM multiplezer. The queue receives input from N heterogeneous arrival processes, each modelled by an Interrupted Bernoulli Process. Comparisons with simulation data showed that the approximation algorithm has a good accuracy.",
An object-oriented analysis model of an iconic interface to Macsyma,"This describes the object-oriented analysis conceptual model (OOAM) of a highly visual interface to Macsyma, which is an interactive, text-based system for performing symbolic, mathematical computations. It shows how the prominent structural features of the OOAM permit the analyst to graphically and mathematically evaluate aspects of interface perceptual quality through various metrics. The model grows like O(n) with the number, n, of mathematical operators in the interface. This kind of model is particularly suited for analyzing the user's perception of interfaces that change over time or in which the visual aspects dominate the textual ones.",
An incremental concept formation approach to acquisition of anaphoric regularity in Mandarin Chinese,A modified version of the incremental learning model of Lebowitz's UNIMEM (1986) is proposed. This new model is called G-UNIMEM which is motivated from natural language acquisition study. It can extract causal relations from a set of training instances annotated with specified cause and goal features. The experiment is carried out on the acquisition of anaphoric regularity in Mandarin Chinese.,
Standards in artificial intelligence as seen from a technology user's point of view,"Experience has brought to light certain differences between what the research community produces and what technology users need. These differences may be caused by a divergence in the standards held by users and practitioners. The divergence exists in four major areas: education, means of implementation, communication with appropriate parties, and need satisfaction. The focus of practitioners is on technology itself, while the focus of users is on the goals to which technology is applied. These goals cannot be grasped by people who have had a device-oriented instead of a comprehension-oriented education. Standards in the means of implementation is another source of divergence. Frequently, what is seen as a good language/hardware suite from the practitioner's point of view is not so good from a user's point of view. Communication with appropriate parties is a related diverging standard. If the customer cannot use a product and understand it then it has no value. Whatever standards are selected, they must be focused on customer needs.",
Quasi-statically Planned Self-posture Changeability For Link System,,
Optimizing large networks by repeated local optimization using a windowing scheme,"Describes a windowing scheme for optimizing large networks. Instead of actually breaking up a network into smaller, disjoint subnetworks, optimizing them separately, and then splicing them back together afterwards, the authors partition the network into overlapping regions and use a varying size window to sweep through these regions, each time making only the gates within a region visible to the logic optimizing algorithm, SYLON-REDUCE. To enhance opportunities for optimization, some partial don't care information is considered for the outputs of each region. Using this scheme, considerable reduction in network size was achieved for several large multilevel benchmarks within a reasonable amount of time. The results were better than or comparable to existing logic optimizers such as MIS. The windowing scheme also allows effective timing optimization to be performed on large networks.",
An environment for the development of microcode for pipelined architectures,"An environment for the development of microcode for parallel and pipelined machines is presented. The system is based on a set of low-level transformations called pipelined percolation scheduling (PPS). The PPS transformations are integrated into a system which does automatic code compaction, but also allows interactive control of the parallelization process, while the system deals with the burdensome details of architecture, correctness-preservation and synchronization. The atomicity, generality and modularity of PPS permit the integration of new, user-defined higher-level transformations on top of the core transformations, to achieve the best performance for the target architecture.",
Cnest and Cscope: Tools for the literate programming environment,The authors describe two tools for the literate programming language Cweb: Cnest and Cscope. Cweb is a Web programming environment for the programming language C using the typesetting program T/sub E/X. An overview of Web is given. Cnest and Cscope operate within the EMACS editing environment and provide support both for the program developer and for the maintenance programmer. Their implementations are discussed in detail.,
Value-added locking: concurrently supporting transactions and queries in DBMS,"This paper presents an approach value-added locking (VAL), that allows effective transaction processing and the execution of complex, read-only, and long-lived queries simultaneously on the same database. VAL integrates the concepts of altruistic locking and quasi-copies to provide a mechanism that allows users, application designers to database administrators to fine-tune the system performance in terms of transaction throughput and queries' average response times. By deploying VAL, a significant gain in system performance may be expected. It also shows that a conventional concurrency control mechanisms such as 2-phase locking becomes a special case of the approach.","Transaction databases,
Throughput,
Delay,
System performance,
Database systems,
Sun,
Computer science,
Performance gain,
Concurrency control,
Centralized control"
Description of digital firing circuit of an HVDC rectifier for its realization,"High voltage direct current (HVDC) systems are used in energy transmission, especially for large distance transmission and transmission between two asynchronous networks. Recently, with the development of electronics and computer science, more and more control systems are being numerallized since a digital control system may provide, in addition to its flexibility, a solution to the problem of operation security. In this paper, the authors present a description of digital firing circuit of an HVDC rectifier. The aim of the description is to facilitate its realization and, if wanted, to ensure its operation security.",
Modelling real-time systems requirements with Metaview,"Escalating manpower costs in developing systems have caused an increasing need for greater productivity in systems development. This is particularly true in the requirements analysis and design phases. The ease with which new support environments can be created is increased through the use of a metasystem. Metasystems for defining and realizing computer-aided requirements specification environments are discussed. An introduction to metasystems that describes a basic system architecture and model of use is provided. The roles of the metasystem definer, specification environment definer and requirements analyst are discussed. An overview of the EARA (entity-attribute-relationship-aggregate) model in Metaview is given. The main focus of the paper is on modelling the specifications of requirements for real-time systems. Metasystems are also discussed in the context of consistency and completeness constraints. An illustrative set of constraints for the sample real-time systems environment is presented. The modelling of this environment gives an indication of the expressive power of Metaview's data model.",
Human performance modeling in manned weapon systems,"The authors present a methodology developed for integrating human performance in performance modeling of manned weapon systems. Literature in this area is briefly reviewed to provide necessary background knowledge. A discussion of alternative methodologies for the performance modeling of such systems is provided. The proposed methodology is composed of four parts: (1) formally define the system; (2) formally define the performance functions, or the effectiveness function; (3) formally define the measurement; and (4) perform the sensitivity analysis. The purpose of the methodology is to integrate the human factor into the system from the very beginning of the design of the system. This is achieved by systematically considering all the interacting parts of the system, omitting minor errors only after quantifying the errors.",
A model for polygon similarity estimation,"A model for polygon similarity estimation is presented. The advantages of the model are that it introduces a numerical measure of similarity between two polygons; it can be applied for all polygon forms and any number of vertices; and it gives acceptable intuitively interpreted results even in the cases of great differences in the number of polygon vertices. The model has been tested in a large number of experiments. The discussion is restricted to simple planar polygons, i.e., those polygons whose edges do not intersect themselves and whose vertices are represented by ordered pairs of Cartesian coordinates.",
Optimal greedy algorithms for indifference graphs,"Investigates the class of indifference graphs that models the notion of indifference relation arising in social sciences and management. The authors examine algorithmic properties of indifference graphs. Recently it has been shown that indifference graphs are characterized by a very special ordering on their sets of vertices. It is shown that this linear order can be exploited in a natural way to obtain optimal greedy algorithms for a number of computational problems on indifference graphs, including finding a shortest path between two vertices, computing a maximum matching, the center, and a Hamiltonian path.",
Adaptive segmentation of textured images using linear prediction and neural networks,"An adaptive technique for classifying and segmenting textured images is presented. This technique uses an efficient least squares algorithm for recursive estimation of two-dimensional autoregressive texture models and neural networks for recursive classification of the models. A network with fixed, but space-varying, interconnection weights is used to optimally select a small representative set of these models, while a network with adaptive weights is appropriately trained and used to recursively classify and segment the image. An online modification of the latter network architecture is proposed for segmenting images that comprise textures for which no prior information exists. Experimental results are given which illustrate the ability of the method to classify and segment textured images in an effective way.",
Using statistical bandwidth in token ring networks,"A new network access protocol, called restricted destination access protocol, for transmitting data packets in token ring networks, is proposed and analyzed. This protocol is based on the existing token passing access protocol and makes use of the extra statistical bandwidth that exists in token ring networks. A transmission capacity of greater than unity can be supported. Simulation results using the protocol in a modified fiber distributed data interface (FDDI) network are included.",
Probabilistic diagnosis in wafer-scale systems,"Studies fault diagnosis based on a realistic probabilistic model for wafer-scale multiprocessor systems. In this model, an individual processor fails independently with probability p. The authors use a comparison testing approach. The testing is performed in multiple stages by the processors. They assume that different testing tasks are executed in different stages, and the coverage of each testing task is imperfect and is represented by a parameter c/sub v/. Imperfect coverage can be used to model intermittent faults where individual test may be incapable of detecting a fault. The authors present an efficient distributed self-diagnosis algorithm that probabilistically identifies faulty and fault free units. They show that our algorithm achieves very high accuracy even when the system is sparsely interconnected, and a large number of faulty units are present in the system.",
"Comparison of reinforcement algorithms on discrete functions: learnability, time complexity, and scaling","The authors compare the performances of a variety of algorithms in a reinforcement learning paradigm, including Ar-p, Ar-i, reinforcement-comparison (plus a new variation), and backpropagation of reinforcement gradient through a forward model. The task domain is discrete multioutput functions. Performance is measured in terms of learnability, training time, and scaling. Ar-p outperforms all others and scales well relative to supervised backpropagation. An ergodic variant of reinforcement-comparison approaches Ar-p performance. For the tasks studied, total training time (including model and controller) for the forward model algorithm is 1 to 2 orders of magnitude more costly than for Ar-p, and the controller's success is sensitive to forward model accuracy. Distortions of the reinforcement gradient predicted by an inaccurate forward model cause the controller's failures.",
Structural induction for rings using temporal Petri nets,The authors present a novel structural induction theorem for rings consisting of identical components that are modeled using a Petri net and a temporal logic formula. The theorem can be used to formally infer the correctness of a ring of any large size from the correctness of a ring having fewer components.. The use of the theorem is illustrated using the problem of demand-driven token circulation.,
Reliability and performance of multi-level loop computer networks,"An improved network architecture which incorporates high reliability, high performance, and optimal accommodation to environmental topologies is presented. The network investigated is tree-shaped, where the leaves represent host computers or loop subnetworks and the vertices are ring adapters attaching hosts or bridges interconnecting subnetworks. For ease of modeling only balanced and homogeneous structures are considered where loop subnetworks have the same topology. Multilevel hierarchical loop networks have minimal diameter when the number of nodes in the subnetworks is proportional to the root of the number of all attached stations. In this case, the diameter grows only with the logarithm of the number of stations. This implies that network reliability and performance are significantly improved using the proposed multilevel hierarchical architecture. The performance analysis assumes the protocol of buffer insertion.",
Incremental mapping for solution-adaptive multigrid hierarchies,"The full multigrid method uses a hierarchy of successively finer grids. In a solution-adaptive grid hierarchy each grid is obtained by adaptive refinement of the grid on the previous level. On a distributed memory multiprocessor, each grid level must be partitioned and mapped so as to minimize the multigrid cycle execution time. In this report, several grid partitioning and load (re)mapping strategies that deal with this problem are compared. The influence of the type of multigrid cycle is examined. Results obtained on an iPSC hypercube are reported.",
A framework for distributed decision support systems,"Decision support systems have been primarily designed to support individual decision making. From the viewpoint of organizational decision making, an even greater potential gain can be achieved by using computers to support distributed decision making. Distributed decision support systems offer a methodology which can be used to combine distributed and heterogeneous models and problem solving processes under a single unified framework. In this paper, a formal definition of distributed decision support systems is provided. A framework for building the components of a distributed decision support system is then introduced. In particular, the authors examine the language system, problem solving system, and coordination components of the system.",
Two-way coloring approaches for method dispatching in object-oriented programming systems,"In object-oriented systems, heavy message sending has slowed down the execution efficiency. Most of the current solutions are based on message tables according to a class-hierarchy to develop more efficient method searching algorithms. An approach with little space overhead and constant dispatch time is proposed. The general strategy is called the two-way coloring technique. The algorithm can be applied in both typed and untyped object-oriented languages. For typed languages, the space overhead is not greater than the conventional approaches, but it can dispatch methods in the same situations as untyped languages. For untyped languages, the constraint for dispatch is not decreased and the space overhead is not much higher, but it can dispatch methods in constant time. Based on the comparison with conventional approaches, the proposed approach demonstrates its advantages on space overhead, dispatching speed, and applicability. Several case studies are presented as a comparison with existing run time dispatch mechanisms.",
How to Solve Your Pedagogical Problems in Microwaves,"We present, in this article, some of the problems often encountered by the students when they start on a microwave course. We bring answers to these problems by means of Computer Assisted Learning and state in the conclusion our observations following an experiment of C.A.L. carried out at the University of Lille.",
Massively parallel MIMD solution of the parabolized Navier-Stokes equations,"Reaching new milestones in science and engineering will require the speed and scalability offered by massively parallel computers. The primary challenge to the users of this technology will be the development of scalable software. All the software's functionality, including the generation of grids, the algorithmic solvers, and the production of output for interpretation and visualization, must scale across multiple processors. As an example of the scalable application concept, the authors have developed a highly parallel, scalable version of a parabolized Navier-Stokes (PNS) code used to simulate steady three-dimensional flow past supersonic and hypersonic flight vehicles. The primary goal of this research has been to develop a fully scalable version of the PNS procedure and to demonstrate that it can achieve high performance on a massively parallel, multiple instruction multiple data (MIMD) computer.",
Intelligent software control for nuclear power plants,"The authors propose a strategy for the introduction of intelligent control in nuclear power plants which recognizes the industry culture. Key features of the proposed strategy are: (i) incremental implementation by means of autonomous modules; (ii) software architectures that cannot propagate faults to other system components; (iii) self-diagnostic features within each module that include automatic fail-safe shutdown and reversion to conventional hardware systems; (iv) controlled degradation of the automated control system, leading to graceful shutdown in the event of major disturbances outside of the system competence to reject; and (v) integration of human operator interfaces with each subsystem and preservation of human competence in the loop. The design of an intelligent controller for a feedwater heater provides an illustrative example for the proposed concept.",
A branch and bound decision tree Bayes classifier for robust multi-font printed Chinese character recognition,"A branch and bound classifier is proposed as an m-ary decision tree with each node representing a set of disjoint classes. Associated with each set is a space S and an estimate of the maximum likelihood of any x in S belonging to a class of the set. By comparing this estimate with the best-likelihood-found-so-far for x, it can be decided if the node is worth visiting. This classifier is applied to recognize 4879 classes of multi-font printed Chinese characters with practically the same recognition rate (98%), but in 5% of the time required, when compared with a full-search Bayes classifier.",
Deformation process modeling in medical imaging,"A computational model for generating a graphic deformation process of the left ventricle of a heart from the diastolic state to the systolic state is presented. The deformation process is represented by several intermediate states which are interpolated from the two given states of the left ventricle. The model includes a topology preserved mapping, a generic correspondence scheme, and a process generator. The strength of the proposed technique is that it can handle the cases where two original shapes have different numbers of vertices. This makes the construction of the two original shapes independent.",
The influence of object size on the regions of interest for edge detection-preliminary results,Presents preliminary results from an investigation of edge detection with a principal components analysis. In this way the parameters of an edge detector can be derived from data about edges in images. The preliminary investigations study how the optimal region of interest varies with the size of objects in the image.,
Fuzzy control is often better than manual control of the very experts whose knowledge it uses: an explanation,"A mathematical explanation as to why fuzzy control is smoother and more stable than control by experts whose experience was used to design the fuzzy control is presented. The analysis indicates that fuzzy control is always continuous and exhibits better performance, even in complicated control situations.","Fuzzy control,
Human factors,
Computer science,
NASA,
Velocity control,
Testing,
Fuzzy set theory,
Application software,
Computer simulation,
Space missions"
Improving search for tree-structured vector quantization,"The authors analyze the approximate performance of tree search and provide tight upper bounds on the amount of error resulting from tree search and for a single input vector. These bounds are not encouraging but fortunately, the performance of tree-structured VQ in practice does not seem to be as bad. From the analysis, they derive a simple heuristic to improve the approximation of tree search. The strategy is to identify for each code vector some of its closest neighboring code vectors determined by the partition. After a code vector is found for an input vector by tree search, the closest neighboring code vectors are then searched for the best match. Unfortunately, the average number of neighboring code vectors of a given code vector can be as many as the total number of code vectors. Thus, the performance improvement of the strategy depends on the number of code vectors that are searched. Experimental results show that a number logarithmic in the size of the codebook provides significant performance gain while preserving the asymptotic search time complexity.",
"A monolithic CMOS 16 channel, 12 bit, 10 microsecond analog to digital converter integrated circuit","A monolithic CMOS 16-channel, 12 bit, 10- mu s analog-to-digital converter has been designed and tested. The circuit converts 16 channels in parallel via a single slope ramp and Gray code counter algorithm. When biased for 10.0 mu s conversions of a 2 V input range into 4050 voltage bins and ohmically connected to a computer, initial testing shows that typical performance is a noise level of 0.3 bins, rms, integral nonlinearity of 4 bins, adjacent channel crosstalk effects less than 1 bin, and total chip power consumption of 110 mW. The chip contains 16 sample and hold circuits, out of range logic, a Gray-to-binary converter, and tri-state data outputs for microprocessor compatibility. The die size is 4.4*1.5 mm in a 2 polysilicon, 1.2. mu feature size CMOS process, and has 52 bonding pads. Off-chip requirements are a single power supply, a single high-speed clock, a precision voltage reference, three biasing resistors, and supply filtering capacitors. This custom circuit has advantages of lower power dissipation and less PC board area than competitive approaches, and is designed for further monolithic system integration.",
Fuzzy Neural Position Controller For Servomotor,,
Resource recovery in a distributed processing environment,"The objective of much recent work in the telecommunications community has been the formulation of a suitable architecture for the support of advanced multimedia services. An important focus of this work has been the definition of appropriate modularity, layering, and partition of functionality in order to provide an open and maintainable infrastructure. A step toward the formulation of a general fault-tolerance approach for use in such a context is described. The philosophy underlying this fault-tolerance, work is overall system stability, not necessarily the perfect handling of every call. A resource recovery method is presented. This method enables the system to regain the control of lost physical resources.",
Registration and matching using orthogonal wavelets,"Algorithms for applying the orthogonal wavelet pyramid representation in matching and registration for pattern recognition are presented. They compensate for lack of translation invariance by beginning from feasible points at a coarse level and by tracking registrations through ever finer resolution levels, and they quickly compare coarse representations of candidates for matching against library prototypes without generating the intervening finer resolution representations.",
Efficient analysis of polling systems,"A large variety of computer communications systems, in particular the token ring network, are modeled and analyzed as polling systems. The authors present the descendant set approach as a general efficient algorithm for deriving all moments of packet delay (in particular, mean delay) in these systems. The method can apply to a very large variety of model variations including: the exhaustive, gated, and fractional service policies; the cyclic visit order; arbitrary periodic visit orders, (polling tables); random polling orders; and customer routing. For most variations the method significantly outperforms the algorithms commonly used.",
Network security in the Unix environment,"The authors enumerate some primary security holes that are the targets of intrusion, and they provide strategies for preventing them. Problems associated with passwords, file exports, Network Information Service, sendmail configurations, 'dot' (hidden) files, file directory permissions, old accounts, login names, logs, and anonymous FTP. Software packages for addressing security problems are discussed.",
Lesion size quantification in SPECT using learning vector quantizer,"An artificial neural network has been developed to determine the size of cold lesions detected in single photon emission computed tomography (SPECT) images. The neural network is Kohonen's learning vector quantizer (LVQI) and is trained to discriminate cold lesions of eight different sizes ranging from one to eight pixels in radius. The images generated for the study are simulated 64*64 SPECT images of a slice of an active cylinder with a nonactive cylindrical lesion. The authors present the proposed network and experimental results for two noise levels (50000 and 100000 counts/slice), showing the capability of such a network to determine quite accurately the size of detected abnormalities in SPECT images.",
TAME: an integrated environment for task-based knowledge and specification acquisition,"A knowledge acquisition framework in which both domain knowledge and specification elicited and refined can interact with a knowledge engineer is proposed. TAME, a hypertext-based knowledge acquisition assistant supporting the framework in an integrated environment, is described. TAME supports a task-based specification methodology (TBSM) in knowledge acquisition and specification elicitation in the following ways. First, TAME's templates provide the building blocks and autolinks in the acquisition process. Second, TAME's browsing and retrieval aids allow users to navigate in the knowledge document using search, navigation links, etc. Finally, TAME generates feedback to inform users about incomplete refinements, duplications, and inconsistent composition of task state expressions (TSEs).","Knowledge acquisition,
Prototypes,
Expert systems,
Knowledge engineering,
Navigation,
Computer science,
Guidelines,
System testing,
Impedance,
Knowledge based systems"
Graphics based PC analysis of alpha spectra,"Recently developed personal computer software performs interactive analysis of alpha-particle spectra using high-resolution graphics. Spectra are collected with a commercial multichannel analyzer (MCA) board and analyzed using the software described. The operator is required to approve each peak integration area before analysis proceeds. Sample analysis can use detector efficiencies or spike yields or both. Background corrections are made and upper limit values are calculated when specified. Nuclide identification uses a library of up to 64 nuclides with up to eight alpha lines for each nuclide. Analysis time is short and is limited by interaction with the operator, not by calculation time. Utilities include nuclide library editing, library subset editing, energy calibration, efficiency calibration, and background. update.",
Detector response restoration for high resolution positron emission tomography,"A mathematical method was studied to model the detector response of high-spatial-resolution positron emission tomography systems consisting of close-packed small crystals, and to restore the resolution deteriorated due to crystal penetration and/or nonuniform sampling across the field of view (FOV). The simulated detector system has 600 bismuth germanate crystals of 3.14 mm width and 3 cm length packed on a single ring of 60 cm diameter. The space between crystals was filled up with lead (i.e., septa). Each crystal was in coincidence with 200 opposite crystals so that the FOV had a radius of 30 cm. The detector response was modeled based on the attenuating properties of the crystals and the septa, and the geometry of the detector system. The modeled detector response function was used to restore the projections from the sinogram of the ring detector system. The projections had a uniform sampling of 1.57 mm across the FOV and had the crystal penetration and/or the nonuniform sampling compensated. A chest phantom with a few small circular cold objects ( approximately=4 mm diameter) located at the center and near the periphery of the FOV was computer-generated and used to test the restoration. The reconstructed images from the restored projections demonstrated resolution improvement off the FOV center, while preserving the resolution near the center.",
Graphic interface design for DSS dialog management: a composite graphics approach,"Text mode has been widely used for the dialog management of conventional decision support systems. It can be predicted, however, that a graphics mode will replace text mode. The paper creates a new computer graphics model, the composite graphics model, which can be widely accepted by DSS builders. It also develops a graphic display generator system based on a composite graphics model and shows the way to integrate composite graphics with a DSS tool.",
Consistent linear speedup in parallel alpha-beta search,"Alpha-beta search is an important heuristic technique used in pruning a game tree. Recently, parallelism has been introduced to further improve the efficiency of such heuristic searches. The paper presents a new parallel alpha-beta search algorithm that applies a prioritizing scheme. To verify its performance, the algorithm was implemented on sequent symmetry shared memory multiprocessor system. Experimental results show that for the best ordering uniform trees, one is able to obtain a consistent speedup of a linear order to the number of processors used. An overall speedup with random node ordering is illustrated. The paper concludes with some characteristics of the alpha-beta search that make the application of priorities suitable for its corresponding parallel algorithm.",
Towards computer-assisted qualitative analysis for model development: theory and algorithms,"The modeling process involves a qualitative analysis, also referred to as problem structuring, of the problem prior to formulation of the mathematical representation. Current modeling systems provide limited support to modelers in the qualitative analysis. The author develops hypotheses about qualitative analysis for model development, specifically optimization models. His hypothesis views qualitative analysis as a process that includes, among other things, identification of complete, consistent, and relevant elements of a problem. The hypothesis has been implemented as a prototype system that can be part of integrated modeling environments to support the modeling process. Although the hypothesis, and the algorithms used in the current system are domain-independent, the author illustrates them with production planning examples.",
Accuracy assessment on camera calibration method not considering lens distortion,"The authors investigate the effect of neglecting lens distortion, and present a theoretical analysis of the calibration accuracy. The error bound derived is a function of a few factors, including the number of calibration points, the observation error of 2-D image points, the radial lens distortion coefficient, and the image size and resolution. This error bound provides a guideline for selecting both a proper camera calibration configuration and an appropriate camera model while providing the desired accuracy. Experimental results from both computer simulations and real experiments are given.",
A New Form Of Adaptive Observer,,
Systematics of the SQS current pulses on the plateau region,"Some basic features of detectors operated in the self-quenching streamer mode, (also referred to as the limited streamer mode), e.g., their pulse height spectra, are not easy to interpret, requiring the development and checking of models of the complex process involved. In the present work a comparison is made between data and the behavior predicted by different models. In particular, the dependence of the total charge on the applied voltage and the reconstruction of the pulse form are considered. The tests presented tend to reject some models and to favor the one presented by I. Gallimberti (1979) for long streamers.",
A logic to unify semantic network knowledge systems with object-oriented database models,"In recent years, coupling knowledge-based systems with existing database systems has gained tremendous attention in both artificial intelligence and database communities. However, many existing approaches suffer from (1) poor support of the semantic modeling capabilities in the underlying relational database systems that is required by the coupled knowledge systems; (2) inadequate performance due to the separation of inference engines from database engines; (3) weak knowledge consistency due to the separation of data and knowledge stored in different domains. The author takes a novel approach by tightly coupling semantic-network based knowledge systems with object-oriented database models. In order to support the highly semantic knowledge-based system, he augments existing object-oriented data models with extra modeling capabilities, such as the interaction of generalization/specialization with aggregation and other association relationships in semantic nets. All semantic information is transformed and encoded into first-order logic representation for efficient reasoning.",
The role of propagation in database support for performance-modeling environments,"The authors investigate the role of propagation in database support for performance-modeling environments (PMEs) and elaborate on the use of the active data model (ADAM) object-oriented design tool to design performance modeling applications that include propagation. ADAM was used to design a particular performance model including the complex interdependencies between the components of the model, thereby maintaining the consistency of data throughout the model. The analysis contains background on propagation and the performance models of interest, and a discussion of the benefits of propagation for PMEs is discussed by presenting a list of goals for the database support for PMEs and outlining two categories of propagations for performance-modeling data.",
Computer-guided training: how to make it work,"Much research has been conducted to study computer- guided training. Training wheels, chunking, information content, minimal manual, and color coding are important principles in designing on-line help. While the usefulness of each principle has been demonstrated individually, the combined effect of following all the principles is unknown. This paper investigates the combined effect of these principles to better understand the application of pro-active and passive computer guidance. Results demonstrate useful guidelines for software engineers in designing computer-aided instruction and tutoring.",
An integrated knowledge-based development tool using the C language,"Many tasks that programmers need to implement may be solved using conventional computing techniques. More complex tasks, however, do not conform as nicely to such techniques. EX-C is an extended programming environment the authors have developed around the C programming language. EX-C provides a fully integrated development environment for conventional and AI programming. The authors discuss the techniques used in EX-C and provide an example of its use in the development of a knowledge-based system for farm management.",
Randomized consensus in expected O(n log/sup 2/ n) operations per processor,"The paper presents a new randomized algorithm for achieving consensus among asynchronous processors that communicate by reading and writing shared registers. The fastest previously known algorithm requires a processor to perform an expected O(n/sup 2/ log n) read and write operations in the worst case. In the algorithm, each processor executes at most an expected O(n log/sup 2/ n) read and write operations, which is close to the trivial lower bound of Omega (n). All previously known polynomial-time consensus algorithms were structured around a shared coin protocol in which each processor repeatedly adds random +or-1 votes to a common pool. Consequently, in all of these protocols, the worst case expected bound on the number of read and write operations done by a single processor is asymptotically no better than the bound on the total number of read and write operations done by all of the processors together. The authors succeed in breaking this tradition by allowing the processors to cast votes of increasing weights. This grants the adversary greater control since he can choose from up to n different weights (one for each processor) when determining the w i ht of the next vote to be cast. They prove that the shared coin protocol is correct nevertheless using martingale arguments.",
An event-state approach to handling temporal queries in an extended relational database system,"Many database applications such as office information systems, computer aided design and manufacturing require temporal support. The requirement for storing all the historical information has resulted in performance and storage problems. This paper presents and illustrates an event-state approach to effectively and efficiently store and retrieve temporal data. This model demonstrates that by using the events that have occurred, facilities can be constructed that would permit the processes of 'rolling-back' to a historical state and/or 'rolling-forward' to the then current state. The proposed temporal features have been incorporated in a relational database system. Processing efficiency and temporal query capabilities have been illustrated and discussed.",
A theoretical framework for a class of frequency estimation algorithms,"This paper discusses a general class of algorithms for estimating the frequencies of a set of complex exponentials, and presents a corrected proof of the validity of the algorithms when applied to either real or complex data. The linear-prediction least-squares algorithms, involve the formulation of the estimation problem in terms of finding the roots of a polynomial in C(x) (the vector space of polynomials over the complex numbers C) that has minimum norm with respect to some inner product defined over C(x).",
Simulation of SPECT imaging with converging-hole collimators,"The authors have developed a computer program that simulates the images acquired in SPECT (single photon emission computed tomography) using a gamma-ray camera with a converging-hole collimator and following complex orbital trajectories. The nonstationary imaging properties of the collimator are simulated using the generalized collimator transfer function; thereby avoiding the unrealistic approximations for camera response. The body is approximated as a cylinder having constant attenuation, and the source distribution is approximated as a summation of many 3-D Gaussian functions having different source strengths, center points, and widths. The camera trajectory is specified at each imaging position by the center of the camera crystal and an orthogonal matrix that determines the camera orientation. The constant attenuation, Gaussian sources, and generalized collimator transfer function combine to produce an analytic expression for the image intensity in each pixel. Poisson statistics are then used to simulate realistic SPECT images. Complete sets of SPECT image data in less than 30 minutes on a DEC 3100 have been produced.",
Information hiding in parallel programs: model and experimental evaluation on the Connection Machine,"An approach for incorporating information hiding within parallel software components is developed. The loss of performance is overcome by having intracomponent encapsulation layers, massive state transition operations, multiple-entry data structures, and program transformation. The approach was experimentally evaluated for three types of objects and application programs on a Connection Machine (CM-2). The results indicate that the approach can reduce the loss of performance due to information hiding. The results indicate that there is some loss of performance for the sorted-array implementation of the set object. Also, the performance of the hash data structure was much worse than expected. Hardware message queues would greatly improve the performance.",
Estimation of relative regional neuroreceptor concentration by PET or SPECT: a single late image compared with a late plus early image,"The potential for using a single SPECT (single photon emission computed tomography) or PET (positron emission tomography) image to estimate quantitatively the relative regional neuroreceptor concentration was previously analyzed theoretically. The success of this approach depends on acquiring the image at a time when changes in the regional radioactivity localization are much more sensitive to changes in receptor concentration than to changes in delivery. In the present work, the authors have applied a computer simulation approach to determine the joint and marginal probability distributions for the ipsilateral/contralateral ratio of receptor concentrations and delivery. They have studied the effect on the probability distributions, of the values of the sensitivities to receptor and delivery, and the inclusion of radioactivity localizations at an early time point in addition to those at the later time point. The probability distributions depend on the sensitivities to both delivery and receptor. Incorporation of data an early time point results in a significant sharpening of the probability distributions.",
A Host Interface to the Dtm High Speed Network,"DTM dynamic synchronous transfer mode, is a new time division multiplexing technique for fiber networks currently being developed and implemented at the Royal Institute of Technology in Stockholm, Sweden. This paper describes the hardware and software aspects of the design of a SBus host interface to the DTM network for a Sun SPARCstation. The interface is based on a dual ported shared memory residing on the interface card and accessible over the SBus from the host CPU. The host operating system allocates message buffers directly in this memory. The interface has hardware support for segmenting and reassembling packets to and from the data units of the DTM. The software part of the interface manages the shared memory and the virtual circuits provided by the DTM network.",
"Visualization, 1992. Visualization '92, Proceedings., IEEE Conference on",,
The effects of segmentation on back-propagation networks,"Segmented neural networks and their capabilities when used to process several types of data are examined. The effect that segmentation has upon the network's topology and the learning rule is investigated. The training method used is a variation of the backpropagation (BP) rule. Network segmentation causes some variation in the behavior of the learning rule. Modifications to the BP rule are also examined which illustrate how it can be improved for use with a segmented topology. Testing involves comparisons of segmented and unsegmented networks in an attempt to identify the effects of delays caused by the segmentation of the neural components. Comparisons are made between the rate of learning and recall, accuracy, and capacity for several configurations of a BP network.",
Instruments for monitoring airborne radioactivity,The author reviews some of the methods and instruments developed at Harwell Laboratory for monitoring airborne particulate activity in (1) ducts and stacks which might carry radioactive aerial effluents; (2) working areas within nuclear facilities where a hazard from airborne radioactivity might exist; and (3) the breathing zones of individuals who might be exposed. Instruments for both real-time and retrospective measurements are described. Particular attention is given to instruments using alpha spectrometry and individual compensation against each radon and thoron daughter; discrimination by decay rate; extended-range monitors and combined alpha beta monitors.,
CBT training of CAI developers,"A computer-based training (CBT) program, Explorer, has been developed to help train faculty in computer-assisted instruction (CAI) techniques. Faculty use the menu-driven Explorer to investigate instructional design principles by previewing critically acclaimed CAI, experimenting with presentation design, evaluating sample interaction sequences, controlling external media, and running simulations. Designed to be a subject of instruction as well as a tool of instruction. Explorer incorporates modules that faculty may use in their CAI projects. That design decision reflects the industrial CBT and academic software engineering backgrounds, of the project staff. Both the Explorer program and the synergism between CBT professionals and educators that led to its creation are described.",
"Linguistic Mechanism, Physical Mechanism, And Secondary Non-r.e.ness Of The Physical World",,
Distributed system modeling with bidirectional Petri nets,"A new tool for modeling systems called bidirectional Petri nets (BPNs) is presented. It increases the degree of abstraction drastically, and makes it possible to model complicated systems concisely. The method uses a two-level system modeling technique. The first level has the responsibility for all basic transmissions, and the second level models the higher-level structure of the whole system. The abstraction process is demonstrated by means of an example. The queue migration algorithm for mutual exclusion in computer networks is chosen as an example.",
Distributed testing of the packet-network of pipes-a transputer-based multiprocessor,"The paper describes a testing method for packet-switched interconnection networks in loosely coupled multiprocessors. The testing procedure has been developed for PIPES, a transputer-based multiprocessor system. From an analysis of the fault models applicable to the specific switching elements, several test families have been developed. Fault coverage depends on the size of the testing sets. At the end a location algorithm for single faults is presented, together with an interactive location algorithm for multiple faults.",
Optimal parallel hull construction for simple polygons in O(log log n) time,"The author proposes an optimal parallel algorithm for computing the convex hull of a simple polygon. The algorithm achieves a runtime of O(log log n) using O(n/log log n) processors of a CRCW-PRAM. The data structure representing the convex hull is not the standard one, i.e. an array storing the vertices of the hull in clockwise order. Indeed, a lower bound of Omega (log n/log log n) on the runtime for any algorithm employing a polynomial number of processors and computing the array-representation is known. Nevertheless, the representation is adequate for further parallel processing; standard queries like computing the intersection of the hull with a given line, etc., can be answered in time O(log n/(log p+1)+1) using p processors. In addition subchain hull queries are supported optimally in time O(log k/(log p+1)+1), where k is the length of the subchain. The algorithm can easily be adapted to other hull-like structures for simple polygons; as e.g. the orthogonal hull, and the visibility region from a point under various definitions of visibility.","Concurrent computing,
Runtime,
Clocks,
Parallel processing,
Phase change random access memory,
Parallel algorithms,
Data structures,
Computational modeling,
Computational geometry,
Bridges"
IDPS: a massively parallel heuristic search algorithm,"Presents an efficient SIMD parallel algorithm, called IDPS (iterative deepening parallel search). The performance of four variants of IDPS is studied through experiments conducted on the well known test-bed problem for search algorithms, the 15-puzzle. During the experiments, data were gathered under two different static load-balancing schemes. Under the first scheme, an average efficiency of approximately /sup 3///sub 4/ was obtained for 4 K, 8 K, and 16 K processors. Under the second scheme, average efficiencies of 0.92 and 0.76 were obtained for 8 K and 16 K processors, respectively. It is also shown that for admissible search, linear or superlinear average speedup can be obtained for problems of significant size.",
Visual database interface for end user computing,"This paper proposes a new interface, visual database interface (VDI), for the novice end users to design, implement and query the database systems. The semantic data model used by VDI is an enhanced ER model (EER) with the inclusion of generalization/specialization, aggregation and categorization abstractions. The tools available in VDI include a graphical EER diagrammer for conceptual design and a graphical knowledge query language (VKQL) for data manipulation. The data definition and normalization tasks, which are considered to be the most difficult for end users, have been completely automated by the VDI Normalizer and the DB Creator.","Visual databases,
Computer interfaces,
Relational databases,
Data models,
Database systems,
Control systems,
Engineering management,
Information systems,
Computer science,
Erbium"
Software measurement for the space shuttle HAL/S maintenance environment,"The authors discuss the development of a complexity domain model for the HAL/S programming language in which all of the space shuttle software is written. Their research has indicated that some aspects of software complexity in other programming language environments are strongly related to software problems incurred during software maintenance. The goal of the current research effort is to establish the particular relationship between the complexity domain model and measurable aspects of software maintenance. From a maintenance perspective, the specific objective is to identify those software complexity attributes that are most closely related to or highly correlated with measures related to software maintenance. This project is expected to lead to the creation of a large database of space system metrics data, the development of a metrics capture tool, and the identification of leading indicators of software maintenance problems.",
Efficient recovery in Harp (replicated Unix file system),Harp is a replicated Unix file system accessible via the VFS interface. It provides highly available and reliable storage for files and guarantees that file operations are executed atomically in spite of concurrency and failures. Replication enables Harp to safely trade disk accesses for network communication and thus to provide good performance both during normal operation and during recovery. The authors focus on the techniques Harp uses to achieve efficient recovery.,
Enforcement of integrity constraints against transactions with transition axioms,"The authors address an enforcement technique of integrity constraints against transaction updates in a relational database system. Transition axioms have been used effectively in checking integrity constraints for single update statements. The authors extend the idea of transition axioms to a transaction which is a sequence of read and update statements. Integrity constraints in this scheme are simplified without database access before the actual operations are performed avoiding the need to undo an illegal transaction. Transaction partitioning, which can reduce the overhead of checking integrity constraints significantly, is proposed. Partitioning a transaction becomes crucial when a transaction is associated with multiple integrity constraints.",
Scheduling conditions for concurrent real-time readers and writers,The article studies real-time systems which have a set of periodic readers and writers accessing a shared data object. The sufficient scheduling conditions for these tasks to finish their executions before the end of their periods are derived. The paper also studies a scheduling technique called job coalescence which combines many reader jobs or writer jobs into a job cluster and executes the cluster as a single job.,
Toward a scalable concurrent architecture for real-time processing of stochastic control and optimization problems,Reports on the development of a scalable multiple-instruction multiple-data (MIMD) concurrent architecture which is intended to serve as an effective alternative for solving stochastic differential and optimization systems. This architecture has in turn motivated the application of group theory and invariance analysis to acquire further insights in understanding the original problem. The speed-up ratios attained by this architecture can realistically justify its potential deployment in certain real-time applications. A case study related to real-time stochastic control and optimization serve to illustrate this possibility.,
Cell height reduction by routing over-the-cells,"The authors apply the concept of over-the-cell routing to the global routing problem in leaf cell synthesis. A cell layout is divided into 5 routing regions in the model. The global routing problem can be formulated to route those critical net segments over the diffusions or the middle channel such that the overall cell height is minimum. The routing of transmission gates has been a problem because it produces a cyclic constraint in the middle channel. A new routing pattern is proposed which is cyclic free for transmission gate connections. In this approach, tree patterns are generated for each net. Then, the global routing is modeled and solved as an integer linear programming problem. Finally, the detailed routing of the cell layout is completed. All the cell benchmarks were solved in very short time. In comparison with previous results, the approach produced denser layouts.",
The categorical framework of open systems,"One of the major challenges facing today's computer scientists is developing a computer system for an autonomous mobile robot which constantly interacts with its environment, updates its knowledge based including the world model, and carries out tasks specified by humans. This kind of computer system, which is capable of updating its database dynamically and grows along with new components without damaging its integrity, is called an open system. Due to the massive influx of input data the system has to perform computations concurrently. And also human users should be able to interact with the system in the object-oriented fashion. Hence an open system can be described as an object-oriented concurrent system which can accommodate new components. The most fundamental elements of the open system are objects and processes: an object is a human-oriented concept in that humans think of the real world in terms of objects, whereas a process is machine-oriented. A category is introduced as the mathematical model for the system, and objects and processes are precisely defined in the categorical framework.",
High Performance Interconnection Between High Data Rate Networks,,
Application of a modified H- psi method in three-dimensional eddy-current problems,Magnetic field intensity H and scalar magnetic potential psi are used directly in the analysis and computation of 3D eddy-current fields. A functional for H and psi is used. Results show that this method can be used to solve 3D eddy-current fields with greatly reduced computer storage.,
Pseudo-inverse with increasing threshold: an error-recovery pattern recognition algorithm,"A pseudo-inverse algorithm with an increasing threshold value for pattern recognition is presented. This method is particularly useful when the original matrix is not a square matrix. The algorithm and its implementation are studied. Using English capital letters as samples, the error-recovery capability of the proposed algorithm is observed to be better than that of the fixed threshold algorithm. Noisy patterns with 20% errors, i.e., 12 in Hamming distance, can be recognized using this approach.",
Time-variant AR spectral estimation in the study of vasovagal syncope,"The AutoRegressive (AR) spectral estimation is implemented in a recursive way with a forgetting factor w both in the classical RLS form, with a constant w value, and in the Fortescue variant with w changing with time, according to the changing characteristics of the signals. The time-variant AR algorithm is here employed, in the study of heart rate and blood pressure variability signals obtained during syncope episodes. The spectral parameters (LF, HF powers, LF/HF ratio), which are able to quantify the sympatho-vagal balance in the assessing of the heart rate and blood pressure values, are evaluated on a beat-to-beat basis, in order to obtain more information about the role played by the autonomie nervous system during these episodes.",
Applications of visualisation within British Telecom,"The subject of visualisation includes any technique which utilises interactive visual displays as the main means of imparting information to a user. It includes the already widely available numerical data visualisation techniques used in many scientific and engineering fields, together with aspects from newer areas such as telepresence and virtual reality. The improving performance and reducing cost of computer-based graphical systems and the availability of linking telecommunications systems of high bandwidth, all support a trend towards visual working in fields outside of science or engineering. This paper looks at work started in British Telecom in this area, to support information handling activities and to explore future telecommunications service possibilities.",
Generalized compressed tree machines,"Parallel machines interconnecting up to thousands of processors have been proposed and recently built. One of the earliest and the most prominent one is a complete binary tree machine. The authors propose a family of tree machines called generalized compressed tree machines. Generalized compressed tree machines may, in general, be viewed as a derivative of the complete binary tree networks.",
Building network-based interactive media,"It is pointed out that the design of a network-based interactive multimedia application depends on the characteristics of the network, the modes of user interaction and the media types that will be used. Careful selection of these elements in the design process is needed to create successful applications. The characteristics of network-based interactive media applications interact to provide various qualities of service to the user. Several examples of previously built network-based interactive multimedia systems are presented, including a kiosk-based system delivering information about a trade show, a system delivering world news and electronic mail and a system assisting doctors during childbirth.",
Thrifty Technology Mapping With Rich Libraries,"Technology mapping is used during logic synthesis to bind a circuit description to a given library of cells. The mapping process is divided into the phases of decomposition, matching and covering. We have developed a method of matching which is functional in nature, as opposed to the usual structural approach. The new matching technique allows the use of very large libraries. New techniques for decomposition and covering are also described. For circuits with fanout, we propose several heuristics for determining when to share and when to duplicate logic. These heuristics are quantitatively compared using a set of benchmark circuits.",
A model for the perception of temporal patterns,"F. Lerdahl and R. Jackendoff (1983) suggested a two-stage model as part of a general theory of rhythmic organization. In the first-stage, well-formedness rules impose 'grammatical' constraints on the set of possible rhythmic groupings. In the second stage, preference rules select the best rhythmic grouping based on listeners' perceptual tendencies. A preliminary model, motivated by the work of Lerdahl and Jackendoff, that attempts to account for some of experimental results in rhythm perception. The model was realized by a recurrent neural network composed of several modules. Simulations explored the model's response to a number of temporal patterns chosen to illustrate various problematic aspects of rhythmic organization.","Rhythm,
Timbre,
Humans,
Shape,
Computer science,
Recurrent neural networks,
Discrete event simulation,
Emergent phenomena,
Pattern analysis"
Cyclic inheritance detection for object-oriented database,"Inheritance is the main theme of schema design for the object-oriented software and object-oriented database. Misuse of inheritance will lead to cyclic inheritance which suffers from redundant classes and endless self-inheritance. For a class hierarchy with cyclic inheritance, to detect all the cyclic inheritances is a NP-complete problem. A graph-theoretical reduction methodology to reduce them in polynomial time is described. An algorithm to support this reduction is presented.",
Availability of coding based replication schemes,"The availability of a coding-based replication scheme where simple voting is used to maintain correctness of replicated data is evaluated. It is shown that the storage requirement for maintaining the data with a given availability is reduced significantly. The ways that some of the extensions of the voting scheme can be modified to manage this coding-based replication are also described. The availability of these is evaluated, and the reduction in the storage space requirements achieved is studied.",
Intelligent factories using fuzzy expert systems,,
An algorithm for preventing deadlocks in distributed systems,The authors deal with a new method for preventing deadlocks in resource sharing for distributed systems. The algorithm is based on the notion of coloring the nodes of the waitfor graph and is built on a signaling mechanism which can be implemented on an underlying routing protocol. This algorithm supports multiple resources and multiple outstanding requests. The proof of correctness of the algorithm is also presented.,
Multithreaded computer systems,"In this minisymposium speakers address architectural principles and issues of multithreaded computer systems, examine approaches to providing implicitly parallel software for these machines, and give an industrial perspective that includes the potential wider influence of multithreaded computers. Multithreaded computer systems are parallel machines in which threads are sequentially executed code segments. Each processor has hardware support for quickly switching contexts among runnable threads. Other features include some form of data matching, split-phase memory accesses, and a dataflow-like regime for thread instantiation. They combine features of conventional von Neumann systems with those of fine-grained dataflow architectures.",
An operator assistance system for beam adjustment of a cyclotron,"The authors discuss a computer-based operator system for cyclotron operators. The main feature of the system is a visual display of feasible setting regions (FSRs) of adjustable parameters. The FSR, derived from constraints among these parameters, shows the valid ranges where set points can be adjusted. Search traces by the operator are superimposed on the same screen as an aid to the operator's memory. In order to derive the FSR, first the cyclotron is modeled as a series of mappings of beam states, giving a conceptual description of the relation between beam states and constraints. Next, based on the model, the beam adjustment can be regarded as a search for the optimum mapping. This process is formulated as a nonlinear minimization problem; and its solution determines the FSR. Finally, to realize real-time display of the FSR, two methods which make the display response time shorter are proposed.",
Pulse propagation on coupled microstrip with an etched groove,,
The Parallel Asynchronous Recursion model,"The authors introduce and evaluate a novel model of parallel computation, called the parallel asynchronous recursion (PAR) model. This model offers distinct advantages to the program designer and the parallel machine architect, while avoiding some of the parallel random-access machine; (PRAM's) shortcomings. The PAR model can be thought of as a procedural programming language augmented with a process control structure that can, in parallel, recursively fork independent processes and merge their results. The unique aspect of the PAR model lies in its memory semantics, which differ substantially from both global and distributed memory models. It provides a high level of abstraction that removes the tasks of explicit processor scheduling and synchronization. Efficient simulations of the PAR model on well-established models confirm that the PAR model's advantages can be obtained at a reasonable cost.",
RCS evaluation of complex objects coated with radar absorbing materials using the complex ray method,The strategy and results of an RCS (radar cross section) evaluation of a dihedral corner reflector coated with lossy materials using the complex ray method are described. A computer program based on the analysis presented has been developed to perform effective RCS calculations of dihedral corner reflectors having the inner surfaces coated with or without radar adsorbing materials. One of the calculated models is a 90 degrees dihedral corner reflector. Good agreement between calculated and measurement results indicates that the complex ray method is well suited to the RCS evaluation of complex lossy objects.,
On conformance in the context of open systems,"Conformance is one of the key notions in the context of open systems and therefore must be precisely defined. Existing formalizations define conformance independently of the environment into which the open system will be embedded. It is argued that it is, in general, not adequate to guarantee conformance in an intuitive sense. Conformance should relate the visible behavior defined by two specifications, which conceptually occurs at external interaction points. Based on this assumption, an additional condition which is sufficient to overcome the difficulty is identified. The condition is based on compatibility between interaction points, a notion which is introduced and formally defined. An approach to verify this condition and some general results are presented. The application of this approach to open systems interconnection (OSI) is outlined.",
A Methodology for Network Security,,
Application of artificial neural network (ANN) technique to rough surface inverse scattering problems,"Summary form only given. The authors introduced an ANN multilayered perceptron technique and its application to rough surface inverse scattering problems. For the rough surface scattering problems considered, the values of the spectral correlations of the scattered intensities are the input and the desired roughness parameters, the RMS height, and the correlation distances are the output. The authors solved the forward problem, applied the input, and used arbitrarily chosen initial weights and bias to obtain the output. They then found the error between the target and the output. They used the backpropagation technique to change the weight and bias to reduce the error. The above learning procedure was repeated many times to train the ANN. Once the ANN was trained, the measured inputs were applied to the ANN and the desired outputs were obtained quickly. Next the inverse problem of finding the surface parameters, sigma and l, from the measurement was considered.",
Creating and customizing reusable interface objects using stimulus response demonstration,"The development of user interfaces has become easier with the advent of graphical layout systems. Such systems allow a developer to locate and size predefined interactive objects directly in the interface he is developing. However, the objects provided in graphical layout systems have restricted forms and behaviors. Thus, the developer has limited flexibility in the kinds of interfaces he can create. DEMO is a user interface development system (UIDS) that allows interface objects to be created from scratch. Using a drawing editor, the developer specifies the interactive behavior of the objects by stimulus-response demonstration. DEMO generalizes from the demonstrations, and automatically generates an implementation of the interface.",
Educating knowledge-based software engineers,"The educational requirements for the field of knowledge-based software engineering (KBSE) are defined. By analyzing an updated version of the program transformation system paradigm, ten topic areas reflecting KBSE educational requirements are identified. It is shown that many of the ten topics can be satisfied by using courses already available in most graduate level computer science/engineering program when examples and course projects are specifically directed at KBSE concepts. A comparison of the ten KBSE topic areas to the 21 software engineering education topic areas developed by the Software Engineering Institute (SEI) shows that few of the KBSE requirements are satisfied by the 21 SEI topic areas. Additionally, recent efforts at the US Air Force Institute of Technology show that a KBSE program, including laboratory support, can be quickly started.",
The k-layer Topological Via Minimization Problem on a Circular Channel,,
An expert system-like architecture for integrating disparate information sources,"Despite the intensive research efforts that have been invested in information technology, in many respects the pattern of distributed heterogeneous information systems has not changed much since its inception. Conventional distributed database technology was not designed to satisfy efficiently the advanced forms of interoperability required by modern information intensive applications. A revision and major enhancement of the contemporary methods and techniques used in the field of distributed information processing seems to be inevitable. This paper reports on an ongoing effort oriented toward developing an expert system-like architecture for an integrated environment in which a collection of cooperating heterogeneous distributed information processing elements is merged to form a loosely coupled association.",
Computer-Aided Education in Automatic Control Engineering,,
A demand driven access protocol for high speed networks,"A demand driven access (DDA) protocol for fiber-optic slotted rings is presented. The proposed protocol is simple and distributed. Under light load conditions, the protocol allows for efficient use of the available bandwidth since no overhead is incurred. In effect, the protocol is demand driven since access arbitration is only activated as the load increases in order to guarantee all nodes a maximum access delay. The protocol is designed for a counter-rotating dual-ring topology. Counter-rotating rings are required to carry backpressure control information in the opposite direction of the data flow. Furthermore, slots are freed at the destination node (as opposed to the source node). This considerably increases the potential throughput of the network. Simulation results demonstrate that for a ring a N nodes, given a uniform destination distribution, a maximum throughput of close to N/4 packets per slot time is achieved under heavy load conditions. Under these load conditions, the average access delay per packet is also on the order of N/4 slot times. The DDA protocol is shown to outperform FDDI both in terms of throughput and access delay.","Access protocols,
High-speed networks,
Throughput,
Bandwidth,
Optical fiber LAN,
FDDI,
Optical buffering,
Computer science,
Delay effects,
Network topology"
Tdr for Microwave Circuits,,
An improved reliable distributed mutual exclusion algorithm,"Reliability and efficiency are two important characteristics of a good distributed mutual exclusion algorithm. Efficiency is generally considered in terms of the number of message transfers required. Considering the reliability aspect, it is desirable that an algorithm should be 'fully fault tolerant', i.e. capable of providing failed node removal and restart facility. Raymond's algorithm is efficient and it needs only O(log N) messages to enter a critical section. The authors show that Raymond's algorithm is not fully fault-tolerant and improve it to provide fully fault-tolerant capability for the case of single node failure.",
New approach for over-the-cell channel routing,Obtaining small chip size is always an important goal in the automatic layout design of VLSI circuits. The advantages of using the routing area over the cells for interconnections to further reduce the channel width for the layout with standard cell design style is discussed. An efficient iterative algorithm for over-the-cell channel routing is presented. The execution speed of the router is significantly greater than that of previously reported units.,
Advanced Level Robotics/Automatics University New Adjoint (ALRAUNA) Program,"The author discusses the proposed ALRAUNA (Advanced Level Robotics/Automatics University New Adjoint Program) at FEMENA, (Faculty of Electrical Engineering, Mechanical Engineering, and Naval Architecture), University of Split, Split, Croatia. The objective of the proposed program is to solve the bottleneck problem of the education of qualified engineers and technicians in modern robotic work cells, production lines, and automated factories. The ALRAUNA program includes job competencies, course outlines and objectives, and laboratories for courses in applied physics, electromechanical devices, electrical and electronic devices, hydraulics, pneumatics, controllers, computers, robots, sensors, vision systems, robotic interfacing, and workcell integration. The ALRAUNA graduate student has to be a technical",
Monadic theory of term rewritings,"The monadic second-order theory of term rewritings is considered. It is shown that the monadic theory of the rewriting (or the suffix rewriting) of a ground rewrite system is undecidable. Furthermore, the first-order theory is undecidable for the prefix derivation according to a linear context-free grammar on linear terms. Nevertheless, a new notion on terms with variables is introduced: a term is entire if each of its subterms either is a variable, or is without variable or has the same variables as the term. It is shown that the monadic theory is decidable (respectively undecidable) for the prefix rewriting according to a rewrite system on entire terms, with an axiom (respectively without axiom).",
Simulating the Gries/Dijkstra design process,"Software design processes are investigated using a three-part approach. For a design method of interest, walkthroughs are first performed on a number of small problems. Second, a simulation program is constructed which duplicates the design produced by the walkthroughs. Third, a process program is constructed that supports human application of the method. This program is being pursued for the formal design process developed by Dijkstra and Gries. (E.W. Dijkstra, 1975, 1976; D. Gries, 1981). This method takes as input a pre- and post-condition specification written in predicate logic and through a sequence of steps transforms it into an algorithm written using guarded commands. A simulation program is described for this process that is based on a library of cliches describing solutions to common programming problems. A prototype implementation was constructed in Prolog and used to generate a number of example designs.",
On reusing linkage designs,"A representation for design cases and a method for indexing known cases to ease their retrieval, given the specification of a new problem, are presented. Each description includes structural and performance characteristics. Methods to retrieve known cases, to match them to often incomplete problem specifications, and to adapt them to solve the problem are devised.",
Non-deterministic communication complexity with few witnesses,"Nondeterministic communication protocols in which no input has too many witnesses are studied. Two different lower bounds are presented for n/sub k/(f), defined as the minimum complexity of a nondeterministic protocol for the function f in which each input has at most k witnesses. One result shows that n/sub k/(f) is bounded below by Omega ( square root c(f)/k) where c(f) is the deterministic complexity. A second result bounds n/sub k/(f) by log(rk(M/sub f/))/k-1, where rk(M/sub f/) is the rank of the representing matrix of f. It follows that the communication complexity analogue of the Turing-complexity class FewP is equal to the analogue of the class P.",
Virtual reality in medicine,"This paper gives a brief overview of three dimensional input and output devices as well as future scenarios in which these devices could be used to visualize and interact with 3-D medical data in 3-D space in a ""natural way"" using virtual reality tehniques in real time on a medical workstation.",
A distortion invariant feature extraction algorithm used with associative memory classifier,"The authors propose a feature extraction algorithm which can extract feature vectors not only invariant to geometric distortions but also suitable for the associative memory classifier developed in the authors' previous work (1991). In addition to the deformation invariant property, the suitability of feature vectors for a neural network system is of a major concern in the feature extraction process when the latter is utilized as a pattern classifier. Under this circumstance, data reduction becomes less important since neural networks are intrinsically appropriate for accommodating large amounts of data. These opinions were justified by experiments on the recognition of a set of multifont Chinese characters with the associative memory classifier using the features extracted by the algorithm.",
Improvements on Fidge logical clocks,"A logical clock mechanism has been developed for maintaining the partial ordering of events in distributed systems. The mechanism handles events in an ad hoc way and its comparison rule is not quite simple. Two major improvements on the mechanism are presented. General maintenance rules are developed to handle various kinds of interprocess events, and the comparison rule is simplified by maintaining the clocks with a new technique called two-phase update. These improvements make the logical clock mechanism more general and efficient for supporting distributed system development.",
The information technology legacy and future directions at MIT,"The Information Technology Group at the MIT Sloan School of Management has two principles that underlie its research, teaching and professional activities. The first is a balance and depth on both the organizational and technical aspects of information technology. The second is the striving for innovation, leadership and excellence.",
Noise effects on differential conduction at an axon branch,Effects of membrane noise (channel noise) on the conduction of action potentials at a branching point on an axon are studied on the basis of a stochastic version of the Hodgkin-Huxley cable model. Computer simulation shows that the channel noise causes random differential conduction into daughter branches on an axon of small radius (≃ 0.1 µm).,
Constraint-based scheduling: a recursive approach,"The authors introduce the idea of constraint-based scheduling and consider some constraints as a good factor in scheduling. The idea is used to develop a novel scheduling method. A schedule problem is used to present the method. The parallel-serial plan (PSP) is defined. A recursive approach to find the best scheduling for a PSP is outlined. The complexity of the algorithm is discussed, and the algorithm is extended for the scheduling of a plan.",
A scalable snoopy coherence scheme on distributed shared-memory multiprocessors,"The authors present a scalable snoopy scheme based on a single-hop-connected multiple-bus topology. To reduce the hardware complexity, each processor will snoop on a dynamically changing subset of the buses. The physically-distributed-logically-shared memory model is chosen to let processors take advantage of local memory accesses for private data. The proposed scheme can enjoy fast memory access and can also take advantage of greater scalability. At the same time, the number of transceivers can grow naturally with the number of processors in the system. Comparing this solution with the directory schemes and the traditional snoopy coherent schemes indicates that the performance of the scheme is promising.",
Experiments with pipelining parallelism in SISAL,"Streams in functional languages allow clear description of many problems which can be expressed in terms of successive transformations of data-they provide declarative expression of software pipelining. SISAL is a functional language with predominantly strict semantics but including non-strict streams to allow expression of pipelined parallelism, processing of notionally infinite streams, and communication between program modules. The authors discuss an implementation, using buffered streams, of SISAL streams on conventional multiprocessors, and programming techniques for some stream problems-a circuit simulation, prime number sieve and a text processor. They present experimental results showing the effect of various buffering parameters, and useful speedup. They point out some potential problems with the SISAL view of streams.","Pipeline processing,
Parallel processing,
Parallel programming,
Computer science,
Parallel machines,
Software engineering,
Circuit simulation,
Concurrent computing,
Parallel algorithms,
Parallel languages"
The use of Gibbs random fields for image segmentation,"Presents a robust and adaptive technique for segmentation of a noisy image. The original image is modeled by an underlying Gibbs random field, and the noise is the mixture of an additive independent Gaussian noise and a salt or pepper noise. The processes of maximum a posteriori segmentation and maximum-likelihood estimation for the image model parameters are carried out simultaneously.",
An automated design specification and verification tool for systolic architectures,"Presents a Prolog-based verifier, VSTA, for formal specification and verification of systolic architectures. VSTA allows users to design systolic array architectures in the systolic temporal arithmetic (STA) specification language, and the designs can be semi-automatically verified by the system. In addition, the authors describe how a systolic array for LU decomposition can be specified and verified with respect to its algorithm. The proof techniques used are mathematical induction and rewriting. The induction technique is adopted to exploit the regularity and locality nature of systolic array architectures. A number of verification tactics are developed in the verifier and their operational rules are used in the verifier. Using the powerful symbolic computation ability of Prolog, particularly pattern matching, automatic backtracking, and the depth-first searching rules, the verifier performs efficiently in the construction of proofs.",
The generic oracle hypothesis fails,"According to the generic oracle hypothesis, results relativized to generic oracles are likely to represent the unrelativized world. The paper shows that the generic oracle hypothesis is false by demonstrating that IP/sup G/ not=PsPACE/sup G/ for even subrecursive variants of generic oracles G.",
A probabilistic stroke-based Viterbi algorithm for handwritten Chinese characters recognition,"This paper presents a probabilistic approach to recognize handwritten Chinese characters. According to the stroke writing sequence, strokes and interleaved stroke relations are built manually as a 1D string, called online models, to describe a Chinese character. The recognition problem is formulated as an optimization process in a multistage directed graph, where the number of stages is the length of the modelled stroke sequence. Nodes in a stage represent extracted strokes. The Viterbi algorithm, which can handle stroke insertion, deletion, splitting, and merging, is applied to compute the similarity between each modelled character and the unknown character. The unknown character is recognized as the one with the highest similarity. Experiments with 500 characters uniformly selected from the database CCL/HCCR1 are conducted, and the recognition rate is about 94.3%.",
"A Family Of Reconfigurable Neurocomputers For The ""Intelligent Factory""",,
Unsupervised sequence classification,"The authors first introduce a novel approach for unsupervised sequence classification, the competitive sequence learning (CSL) system. The CSL system consists of several extended Kohonen feature maps which are ordered in a hierarchy. The CSL maps develop a representation for subsequences during the training procedure, with an increasing abstraction on the higher maps. The authors apply their approach to real speech data and report preliminary results on a word recognition task. A generalization rate of 70% is achieved. The CSL system performs learning by listening: it divides the continuous sequence of input patterns into statistically relevant subsequences. This representation can be used to find appropriate subword models by means of a self-organizing neural network.",
A multi-block data compression method based on arithmetic coding for a library database,Statistical analysis of the distributional and correlational properties of the characters in a large library data file with formatted records leads to the employment of a number of cumulative probability distributions to encode characters in various fields of each record. The performance of the proposed technique is compared with those of two-pass and adaptive character-based arithmetic coding methods. Experimental results show that the proposed technique yields a 13.6 to 13.9% increase in compression for a file in the Sydney Micro Library System.,
N-dimensional perfect pipelining,"Introduces a technique to parallelize nested loops at the fine grain level. It is a generalization of perfect pipelining which was developed to parallelize a single-nested loop at the fine grain level. The authors explain their method, contrast it with other techniques, show the effect of their technique on some real examples, and briefly discuss an architecture best suited for exploiting this parallelism.",
Iterative rule simplification for noise tolerant inductive learning,"An iterative noise reduction learning algorithm is presented in which rules are learned in two phases. The first phase improves the quality of training data through a concept-driven closed-loop filtration process. In the second phase, classification rules are relearned from the filtered training data set.",
Constraint satisfaction for production system match,"An attempt is made to improve production system match by incorporating the arc consistency (AC) algorithm, in the RETE algorithm. This approach combines the constraint graphs of RETE and AC into a single network, which is then incrementally updated. Empirical studies show the technique to be most efficacious with expensive rules. Thus, by using the lookahead from AC preprocessing, in many cases costly RETE computation can be effectively reduced.",
On the characteristics of Coefficients in SST Estimation Functions by Split-Window Method,,
The Parallel Solution of the Electromagnetic Field Finite Element Equation,"Summary from only given, as follows. The Implementation of a parallel Gaussian elimination solution of S-D electromagnetic field finite element equation an Parallel Transputer System (MIMD, host on PC) is described. To increase the processing ability of the system, the computation and the matrix storage are both distributed to each transputer.",
Distributed problem solving in spite of processor failures,"Processor failures not leading to a network partition are considered, and the issue of computing associative functions in spite of processor failures is addressed. An intuitive and fundamental result formally proved is that failure detection and computing associative functions are equivalent in faulty networks: one can be performed if and only if the other can be performed. Protocols and impossibility results in various system models are presented in the context of computing associative functions and solving topological problems.",
A process-modeling based approach to comparing and integrating software design methodologies,"Experience in using a systematic approach to compare and integrate software design methodologies is reported. A comparison approach based on modeling the design methodologies and classifying their components is discussed. Six design methodologies were composed in the context of using this approach, and assessed in relation to comparable work of other researchers. Experiences with assessments of the comparison approach indicate that it is a powerful tool for analyzing software development methodologies.",
A graph testing concurrency control protocol for object bases,Presents a protocol for concurrency control in object bases. The object bases model of Hadzilacos and Hadzilacos (1991) is used as a framework to describe the protocol and to derive a proof of correctness. The protocol accepts all correct executions. A definition of order preserving serializability suitable for the model is also presented. A slight modification of the protocol ensures that the produced executions obeys the defined order-preserving serializability. The protocol detects inconsistencies by constructing a graph for each node of the nested execution and testing its acyclicity.,
A research model for managing end-user computing: making sense of the past decade,"To date no comprehensive research model for the management of end-user computing (EUC) has been introduced to help 'make sense' of the past decade of research. The paper addresses this gap in the research by presenting a model for EUC management studies which focuses on individual-level factors. Four factors are detailed: the end user, task, tool, and end-user action. To demonstrate the utility of the research model, a sample of EUC management studies published between 1983 and 1990 in major IS journals and conference proceedings is discussed in terms of the main components of the model. The paper concludes with an assessment of the progress which has been made towards accumulating knowledge about end-user computing management.",
Visualization requirements in the atmospheric and environmental sciences (five case study reports),"Reports from five research centers involved with atmospheric and environmental visualization issues are presented in this case study. Visualization with heterogeneous computer architectures is highlighted in the US EPA Scientific Visualization Center discussion. The NASA Marshall Space Flight Center effort to develop the multidimensional analysis of sensor systems (MASS) environment is presented. Florida State University's building of a new scientific visualization package, Sci An, is reported. This is followed by a discussion of the design and implementation of VIS-AD, an experimental laboratory for developing scientific algorithms, at the University of Wisconsin-Madison. The visualization of global atmospheric data at IBM Thomas J. Watson Research Center is highlighted.",
Configurational entropy stabilizes pattern formation in a hetero-associative neural network,"The authors report on a prototype implementation and preliminary studies of a new class of computational engine. This engine introduces statistical mechanical considerations into a simple neural network design, affording greater stability in the pattern classes generated in response to different input stimulus. The current instantiation of the engine consists of two 1-D layers, with feedforward connections between the input layer and the computational layer. The computational layer achieves its total configuration via response to many factors, including input activations obtained from the input layer, and minimization of a Gibbs free energy function. A Hamming distance metric is used to assess the difference between intraclass patterns and interclass patterns. The interclass distance between prototype patterns produced in response to different inputs is an order of magnitude greater than the intraclass distance in the computational layer patterns produced in response to a given input.",
Complexity issues in the design of functional languages with explicit parallelism,"It is shown that for a functional language with explicit parallelisms, at least two different parallel operators are necessary from a complexity point of view. In principle, just one of these operators is semantically sufficient, but the other cannot be implemented in constant time using this one operator. The parallel functional language is a first-order language (in order to keep the semantics simple) and is intended for shared memory architectures, for example, PRAMS. Operational semantics for the various kinds of PRAMs (parallel random-access machines) are defined, and some examples of implementations of parallel algorithms in this language are given. This semantics also includes processor scheduling. The complexity results presented also apply to higher-order functional languages, because the lower-bound proofs for the simulation do not make use of the first-order property.",
On the effects of the Gibbs-Markov model parameters on MAP region segmentation using dynamic programming,"The authors study the effect of clique potentials in the Gibbs-Markov model equations when used in maximum a posteriori (MAP) image segmentation of textured images. The focus is on the simple Derin-Elliott model in which the low level process consists of a constant gray level with additive Gaussian noise with zero mean and variance, and the high level process is a second order Gibbs-Markov random fields. Experimental results are presented.",
Integrating edge and surface information for range image segmentation,The authors show that the synergetic combination of both surface- and edge-based segmentation processes can lead to more accurate segmentation results than just either one alone. A segmentation algorithm which integrates edge and surface information to come up with a high-level description of a scene given a range image is proposed. It is shown that the surface parameters can be used for accurate computation of surface discontinuity parameters. The presence or absence of a predicted surface discontinuity in the image can be used to guide and correct the process of extracting homogeneous surface regions in the range image. Experimental results on real range images indicated the advantages of the proposed technique.,
Optimal and near optimal tree scheduling for parallel systems,"The authors present seven algorithms for multiprocessor scheduling of task trees. The objective function of the algorithms is to minimize parallel time (the time between the start of the first processor and the completion of the last processor) in an environment where interprocessor communication costs are significant. Test results are given for implementations of (1) an optimal algorithm that produces a schedule that cannot be improved upon, (2) a greedy algorithm that has minimal overhead, and (3) a 'light load' algorithm which combines the best features of the optimal algorithm and the greedy one. The authors illustrate the trade-off between generating optimal schedules and creating scheduling programs that perform their allocation in a reasonable amount of time. They also give a new NP-complete result.",
On embedding ternary trees into Boolean hypercubes,"It is pointed out that the problem of efficiently embedding a k-ary tree into hypercube with k>or=3 has largely remained unsolved, even though optimal embeddings (i.e. embeddings achieving minimum delta , lambda , and in ) of complete and incomplete binary trees into hypercubes have been known for some time. Thus, in their quest for designing efficient embeddings of k-ary trees into hypercube for arbitrary k, the authors present some preliminary results that give efficient embeddings for the situations when k=3, 2/sup p/, 3/sup p/, 2/sup p/*3/sup q/ and p, q>0. The embedding of complete ternary trees and the embedding of complete k-ary trees are considered.",
Multiresolution approach to solving diffusion equation for edge detection,"Considers the problem of edge detection by solving an anisotropic diffusion equation, which has the intrinsic property that low-contrast regions are smoothed and high-contrast regions are sharpened. Since wavelets are known to provide better representation of singularities (i.e., edges), a more efficient scheme than those suggested earlier for solving the diffusion equation is formulated in terms of wavelet expansions of the image. These expansions also provide a natural way of estimating the local contrast and hence of implementing a space-varying parametrization of the diffusion equation for improved performance. The method described can be viewed as the wavelet counterpart of the standard spectral method for solving partial differential equations.",
Bounds on the time to detect failures using bounded-capacity message links,"The authors consider a system of distributed processors that communicate by passing messages and that have inexact information about time. Specifically, a processor knows that a single message is delayed by at most time d and the time between any two of its consecutive steps is at least e/sub 1/ and at most e/sub 2/; it has no other way of estimating elapsed time. The author extends this model by making a realistic assumption about how the delay of messages is affected by the rate at which they are sent. He defines a model of message links with bounded capacity, which are guaranteed to deliver messages at only a given rate. If a processor sends messages at a greater rate, they may incur greater delay. The effect of this bounded capacity on the time necessary to detect processor failures, is quantified. The author considers a system of two processors connected by a bidirectional message link of a given (integral) capacity.","Protocols,
Delay effects,
Delay estimation,
Laboratories,
Computer science,
Bidirectional control,
Fault tolerance,
Distributed algorithms,
Fault detection"
Can software maintenance be taught?,"It is noted that three arguments have been used as the basis for not developing specific courses in software maintenance. The arguments are worded as follows: maintenance is a direct continuation of software development and should therefore be taught as a proper follow-on to the development task; the real technical change is in developing systems from scratch so the technical challenge of performing maintenance does not require a separate course; and finally, aside from development activities and developing for maintenance there is not sufficient material available to prepare for a course in software maintenance. The author demonstrates that all three assumptions are erroneous and should be discarded. Recommendations are then given on how to teach software maintenance and on what is needed to teach it more effectively.",
Different explanatory dialogue styles and their effects on knowledge acquisition by novices,"The knowledge that people recruit and acquire during an explanatory dialogue is important in understanding how these dialogues are successfully carried out and how explanation and learning occur. The aim is to improve explanation provision by intelligent tutoring and knowledge based systems. In this paper an empirical study is described which investigated the effects of different explanatory dialogue styles on the knowledge acquisition by novices. Two dialogue styles were manipulated, 'active' giving strong spontaneous guidance and 'passive', giving weak guidance. The students who participated in the active dialogue style tended to acquire more knowledge than the students in the passive condition. However, providing students with strong guidance was very costly and the most efficient use of expert resources may be to teach students in a passive manner.",
Plasma erosion opening switch using laser-produced plasma,"An opening switch which can repeatedly conduct a large current and then rapidly interrupt this current is necessary to construct a practical inductive energy storage pulsed power generator. Though the plasma erosion opening switch (PEOS) can interrupt a large current rapidly, the effective number of switch operations is limited because of the decrease of the carbon sprayed on the insulator with each shot. Here, a PEOS using a laser-produced plasma, which can possibly be operated for hundreds of thousands of shots without maintenance, is studied experimentally.","Conductors,
Carbon,
Switches,
Lasers,
Plasma sources,
Capacitors"
Analysis of Multithreaded Microprocessors under Multiprogramming,"We examine multithreading to improve uniprocessor cost/performance on multiple processes. Processor utilization and cache behavior are studied analytically and under simulation by interleaving reference traces to model timesharing and multithreading. Multithreading a small number of threads is superior with large on-chip caches and significant memory latency. The switch need not be extremely fast. Surprisingly, miss ratios under multithreading may be lower than under timesharing, because switch on-miss multithreading favors processes with better cache behavior.",
Enhancing Boosting with Semantic Register in a Superscalar Processor,"IAS-S Supports boosting with ""semantic register"" and boosting boundary register to remove the dependences caused by conditional branches. In IAS-S, there is no dedicated shadow register file, and multiple levels of boosting is supported without multiple copies of register files. Any general-purpose register in IAS-S can be regarded as a sequential register or a shadow register flexibly. Furthermore, multi-way jump mechanism is combined with boosting to reduce the penalty due to frequent control transfers.",
Branch Merging For Effective Exploitation Of Instruction-level Parallelism,,
What is failure? or: constructive negation by fail answers,A standard approach to negation in logic programming is negation as failure. Its major drawback is that it cannot produce answer substitutions to negated queries. Approaches to overcoming this limitation are termed constructive negation. The paper presents an approach based on construction of finitely failed trees for some instances of a negated query. A correct definition of a failed tree is given (it turns out that a straightforward definition leads to unsoundness). The method is applicable to normal programs. If finitely failed trees are concerned then its semantics is given by Clark's completion (and the author's approach is a proper extension of SLDNF-resolution). If infinite failed trees are allowed then the method is sound for the well-founded semantics.,
"An automatic adjustment method of backpropagation learning parameters, using fuzzy inference","Fuzzy inference is introduced into a conventional backpropagation learning algorithm for neural networks. This procedure repeatedly adjusts the learning parameters and leads the system to convergence at the earliest possible time. The technique is appropriate in the sense that optimum learning parameters are being applied in every learning cycle automatically, whereas conventional backpropagation does not contain any well-defined rule regarding the proper selection of learning parameters.",
Metalinguistic features for formal parallel-program transformation,"A set of metalinguistic features and their applications in formal parallel-program transformation are described. Program transformation is an effective methodology for developing correct and efficient parallel programs. However, manually carrying out the transformation is usually very cumbersome and error-prone. These metalinguistic features provide convenient language constructs for expressing and automating transformation steps. These features include a rationalized version of quoting and unquoting, a set a constructors, selectors, and predicates, and a collection of semantics preserving operators. The authors describe the metalinguistic features, illustrate how Crystal programs are conveniently manipulated with these meta constructs, and present a formal denotational semantics of the rationalized quoting and unquoting. They demonstrate the applications of these metalinguistic features by formally deriving a class of parallel palindrome recognition programs.",
An optimal algorithm for finding maximum induced bipartite subgraphs of circular-arc graphs,"Given an intersection model S, which is a family of n arcs around a circle, of a circular-arc graph G, this algorithm requires O(n logn) time and O(n) space, if the endpoints of arcs are not sorted, and O(n) time is sufficient, if the endpoints of arcs are sorted.",Computer science
Algorithms for a k-tree core of a tree,"The authors define a generalization of a core which they call a k-tree core. Given a tree T and parameter k, a k-tree core is a subtree T' of T containing exactly k leaves that minimizes d(T')= Sigma /sub upsilon in V(T)/d( upsilon , T'), where d( upsilon , T') is the distance from vertex upsilon to subtree T'. They then give two algorithms to find a k-tree core of a tree with n vertices. The complexities of these algorithms are O(kn) and O(n lg n) respectively. This work is motivated by a resource allocation problem dealing with a partially replicated distributed database defined on a tree network.","Distributed databases,
Terminology,
Computer science,
Resource management"
An all-sharing load balancing protocol in distributed systems on the CSMA/CD local area network,"A protocol for dynamic load balancing in distributed systems on the CSMA/CD local area network is presented. Using the protocol, the workload is evenly distributed throughout the system when load-balancing activity is triggered, and effective load distribution is accomplished through transmission of load-balancing messages in a collision-free manner. Analytical and simulation results are presented to show the efficiency of the protocol.",
Group address recognition with perfect hashing hardware - Extended abstract,,
Hybal: A Self Tutoring Algorithm for Concept Learning in Highly Autonomous Systems,,"Machine learning,
Genetic algorithms,
Algorithm design and analysis,
Merging,
Computer science,
Partitioning algorithms,
Artificial intelligence,
Corporate acquisitions,
Symbiosis,
Machine learning algorithms"
A CMOS VLSI Chip for Motion Detection,,
Performances of the Obelix event builder and producer,The event builder and producer is the kernel of the Obelix online system. The data from each subdetector flow in parallel into the global event builder memory. Then they are sent to the host computer where the producer injects them into the buffer manager for recording and monitoring. The event builder and producer tasks are integrated within the overall run control system.,
On structural analysis for a class of high-rate convolutional codes,"The authors perform structural analysis of the class of Xi codes. They conduct the sufficient conditions that let them determine whether a Xi code is also a Xi /sub f/ code or not. It is found that the branch structure of the trellis in the YHM-A (Yamada et al. 1983) for a Xi /sub f/ code is the same as that of the trellis for a punctured convolutional coding (PCC). The authors point out that the PCC can be easily constructed from the trellis of a Xi /sub f/ code. Several Pics of constraint lengths 5,. . ., 12 are constructed from the good Xi /sub f/ codes found in CharnKeitKong et al. (1992). To evaluate the bit error performance of the newly found Pics; the distance spectra of these Pics are calculated.",
Practical evaluation of several cone beam orbits for SPECT,"Several alternative orbits have been suggested for cone beam SPECT (single photon emission computed tomography) since the standard circular orbit provides insufficient sampling. The authors used a computer simulation to evaluate the practicality of several orbits using the following criteria: spatial resolution, sensitivity, elimination of truncation, and theoretical sufficiency of the acquired data. All orbits were evaluated for brain imaging with a realistic human model. The results indicate that the simple transverse circular orbit has high sensitivity and resolution, but of course the acquired data are insufficient. Modest improvement in resolution was obtained with a contoured transverse plane orbit. A single straight line orbit was inadequate. Three orbits, each composed of two noncoplanar curves, satisfied the sufficiency condition, and thus should produce more accurate reconstructions. Their resolution was similar to the circle, but the sensitivity was reduced by 15-30%. None of the orbits studied was as good as the transverse plane orbits (circle and contoured) in both resolution and sensitivity.",
Computer assisted collimation and tomography: A new prospect to enhance the sensitivity and the resolution of gamma cameras,A new method intended to increase both sensitivity and resolution of gamma cameras is described. It utilizes a collimator with big holes and solves an inverse problem to perform the tomography and the collimation. This multiplex method seems very promising in single photon emission computed tomography (SPECT),
Solving linear recurrences with loop raking,"The article presents a variation of the partition method for solving m/sup th/-order linear recurrences that is well-suited to vector multiprocessors. The algorithm fully utilizes both vector and multiprocessor capabilities, and reduces the number of memory accesses as compared to the more commonly used version of the partition method. The variation uses a general loop restructuring technique called loop raking. The article describes an implementation of this technique on the CRAY Y-MP and presents performance results on first- and second-order linear recurrences, as well as on Livermore loops, 5, 11 and 19, which are based on linear recurrences.",
Cardiac synchronised data acquisition and analysis of physiological variables,"The problem of recording a wide range of biological signals with bandwidths ranging from fractions of one hertz for respiratory waveforms to kilohertz for sympathetic nerve activity is of fundamental importance in the physiological laboratory. Computer based hardware and software solutions for the problem of data acquisition display and analysis of experimental data are discussed and a flexible new instrument, capable of recording most physiological signals with high accuracy and significant levels of data reduction is presented. Integration of this instrument with a commercially available scientific software package ASYST/ASYSTANT leads to a low cost, simple to use solution to data acquisition in the physiological laboratory. Data acquisition problems from renal and cardiovascular research, demonstrating the flexibility and capabilities of this instrument are presented as examples.",
Optimal design of megabyte second-level caches for minimizing bus traffic in shared-memory shared-bus multiprocessors,"As the design of shared-memory shared-bus multi-processors is heading toward employing megabyte second-level caches, how to optimize the design of the second-level caches in order to minimize the traffic on the shared bus and thus improve the system scalability is of great interest. The paper presents a comprehensive study on this issue through extensive trace-driven simulations and concludes with a few general and effective rules.",
Determination Of Object Location Via Decomposition Of Movement,,
Skew incidence on a thick metal-dielectric join,"A skew incidence solution is presented for the diffraction by a metal-dielectric junction. Some practical applications of this result relate to a characterization of surface propagation across the seashore and the scattering by airframe discontinuities including those found in conformal arrays. The two-dimensional version of this problem has been treated previously for E and H polarization, and it is shown that the new skew incidence solution reduces to these special cases when beta = pi /2. The generalized scattering matrix formulation and the Weiner-Hopf technique are used to solve the integral equations arising after enforcing field continuity across the dielectric interfaces and the condition that the tangential electric fields vanish on the metallic surfaces.","Scattering,
Diffraction,
Transmission line matrix methods,
Equations,
Computer science,
Application software,
Surface treatment,
Polarization,
Dielectrics,
Slabs"
Multilingual natural language processing environments,"The authors describe the need for multilingual natural language processing and review previous work relating to the field. They present a proposal for a multilingual natural language processing environment, providing an overview of the total plan and describing specific components that have been implemented or are nearing the final design stage. Examples of several application areas are included in which this approach would be an effective tool for research and development.<>",
Applications and meaning of inheritance in software specifications,"Presents a novel inheritance mechanism for a specification language. This mechanism supports stepwise refinement by combining constraints that can be inherited from several sources. Inheritance in specifications differs from inheritance in programming languages. The proposed mechanism has been designed specifically to support computer-aided requirements analysis. The main design issues for the mechanism are explained, and the application of the mechanism to requirements analysis is illustrated via examples.","Application software,
Specification languages,
Organizing,
Programming,
Computer languages,
Software systems,
Design automation,
Computer science,
Software reusability,
Data structures"
Evaluation of multi-element monolithic CdZnTe arrays for gamma and X-ray imaging,"Summary form only given. The properties of a number of multielement, CdZnTe imaging devices for application in industrial radioscopy and axial computed tomography have been investigated. In addition, several 16-element linear arrays as well as a square 64 element 2-D array have been produced and analyzed. All of these devices have been fabricated on single substrates of CdZnTe with vacuum-deposited electrical contacts. The imagers have been evaluated for both the degree and speed of charge collection and their efficiency to X-rays of energies from 20 to 120 keV. Measurements have been conducted to determine energy resolution and rise time as a function of position of interaction within a single pixel volume. The arrays are characterized for uniformity as well as spatial point speed distribution to evaluate their usefulness as X-ray imagers. Read-out systems that use both pulse and current mode sensing have been tested, and their performance have been determined.<>",
On Average Case Complexity of Problems that are Intractable in the Worst Case,"The worst case setting seems to be the most important setting for studying complexity of approximately solved problems. Unfortunately, some problems of practical importance are intractable or even unsolvable in the worst case setting and to cope with the inherent difficulty of such problems one has to switch to other settings. A natural alternative is provided by the average case setting under which worst case intractable and/or unsolvable problems become tractable. In this paper we will discuss some results on multivariate integration and function approximation and show by how much the complexity is reduced when the average case is utilized.","Function approximation,
Switches,
Computer science,
Cost function,
Integral equations,
Stress"
An Optimal Object Representation For Aspect Classification,,
Towards object-based heuristics,"A survey and critique of previous work is given, and two object-based heuristics are developed. The structured nature of objects is the motivation for the nonaccidental alignment criterion; parallel lines within the object's bounding contour are related to the object-centered coordinate system. The regularity and symmetry inherent in many man-made objects is the motivation for the orthogonal basis constraint, an oblique set of coordinate axes in the image is presumed to be the projection of an orthogonal set of 3D coordinate axes in the scene. These heuristics are demonstrated on real and synthetic image contours.",
Authors' reply to comments on 'Pole and zero estimation in linear circuits' by P.E. Gray and J.K. Matchett,"A comment by P.E. Gray and J.K. Matchett (see ibid., vol.38, p.1404, Nov. 1991) on the above-titled paper (see ibid., vol.36, pp.838-845, June 1989) appeared with an errata for the paper, which was mistitled as a reply to their comment. A response to the comment is given here, supporting the accuracy of the pole-zero estimation method that occasioned the comment.",
An algebraic approach to the manipulation of complex objects,"The authors present an algebra (LOA) for complex objects, which has been developed within LOGIDATA+, a national project funded by the Italian National Research Council, as an internal language in a prototype system for the management of extended relational databases with complex object types. The object algebra is a set-oriented manipulation language that plays in the object oriented DBMS the same role as the relational algebra in a relational system. That is providing efficient access to mass storage structures and simplifying query optimization. The algebra refers to a data model that includes structured data types and object identity, thus allowing both classes of objects and value-based relations. The algebra has required extension of the semantics of operators with respect to the nested relation model, and to introduce additional operators for type conversion and OID invention. The paper also briefly discusses the implementation of the primitives of the object algebra in the prototype by means of the operators of the relational algebra.",
Stochastic Petri Nets For Knowledge Representation And Reasoning,,
Historical efforts on R&M integration into engineering curricula,"The author describes what the US Air Force has done to achieve improved R&M (reliability and maintainability). The Air Force has been vitally interested in all graduate engineers becoming knowledgeable of R&M so they will be able to readily include R&M in their designs. It is pointed out that R&M must be designed into new systems as they evolve through the complete design process, and not be attempted as an extra addition or afterthought. Only by having the designer be proficient in the principles and tools of R&M can the final design be successful. The only way for all the designers to have the knowledge of R&M is to include R&M in the design courses within the academic environment. It is noted that the time is here for R&M education to be included in every engineer's education. This does not imply that the education must be increased, or that some items must be eliminated to make room for the R&M principles in design. What is implied is that the measurement of the design is not adequate until the success of the design (R&M) is determined.",
Searching with a lie using only comparison questions,"S.M. Ulam (Adventures of Mathematician Scribner, New York, 1976) presented the following problem. If one person picks a number from one to one million and the other person could ask yes or no questions, how many questions would be required to find the number with certainty if the opponent were allowed to lie once or twice. J. Spencer (Mathematics Magazine vol.57, no.2, 1984) found that by using a weight balancing strategy, if nc' are allowed. However, it will be shown that, by using a somewhat modified algorithm, if n",
A new algorithm for pattern recognition of voices,"An algorithm is developed to distinguish between the speech of male and female. A simple hardware device is devised to implement the algorithm. Various techniques, such as fast Fourier transform (FFT), threshold crossings (TCs), threshold crossings of the derivative of the signal, and sine-wave crossings are used to distinguish between the voices. These techniques are analyzed and compared. The results show that the sine-wave crossings technique is simple to implement, does not need normalization or differentiation of the signal to remove its DC component, and can be used for real time (online) analysis.",
EFRM-based detection and extraction of ridge and valley features in grey level images,Describes a method for locating and extracting ridge and valley (and hence line) features in grey level images. A representation of the image known as the extended facet region model (EFRM) is first formed. The primary grouping constraint in this process is the orientation of patches in the image intensity surface. Inspection of geometric relationships between entities in the EFRM leads to the identification of ridge and valley structures and the subsequent placement of extracted line paths. The structures have knowledge of the local topological form of the image.,
"XFace, an X tool for presenting multivariate data, and its use with software metrics","XFace is a tool for displaying on X devices multivariate data as graphical images called Flury-Riedwyl faces. The tool allows the user to map variables to facial features such as eye size, slant, and position; pupil size and position; eyebrow curvature, density, and position; hair color and line; mouth curvature and size; face line; and nose shape. Symmetric faces support up to 17 variables and asymmetric faces support up to 34 variables. The menu-driven tool was developed in C and uses X Windows with Athena Widgets for portability. The system was developed to display software metrics. A manager may map each module's metrics to a face so that a quick scan determines modules with characteristics that vary from the project norm and which may require attention.",
A synchronization scheme for distributed multimedia information systems,"The authors propose a synchronization scheme for distributed multimedia information systems. The scheme consists of two layer synchronization: inter-stream synchronization and intra-stream synchronization. The inter-stream synchronization layer provides a temporal relationship between media and presents media to the user in the required synchronization fashion. The intra-stream synchronization provides functionality to establish and maintain individual medium connections with some specified synchronization characteristics. The proposed scheme can provide synchronization of media with arbitrary temporal relationships which could be originated from one or more sources on the network. Synchronization is also maintained in the event of user interaction, such as to pause and resume a multi-stream presentation.",
IP addressing and routing in a local wireless network,"IP is the basic protocol in the Internet. The authors explore a variety of possibilities to adapt the wireless environment to that of IP. They describe the requirements and show how these can be accommodated by using the existing IP. At the heart of the problem is the lack of a capability in the current IP routing services to track topological changes. Several alternatives are described, each making use of a different combination of the addressing and routing features offered by IP. The alternatives are compared. The tradeoffs among these alternatives are explored.",
"A new methodology for isolating and diagnosing inconsistencies in image matching, as applied to the analysis of 2-D electrophoretic gels","An image comparison algorithm employing a new notion of match consistency has been developed for the application of mutation detection on images of two-dimensional electrophoretic gels. The application requires a very high degree of accuracy in image comparison due to the rareness of mutation. The image comparison algorithm achieves high accuracy through monitoring, isolating and diagnosing inconsistencies in the matching process. The methodology is based on algorithms for monitoring symmetry relations between match hypothesis made during the course of processing. Algorithms are given which explore violations of the basic symmetry relation. Diagnostic procedures partition symmetry violations into classes that are identified with the failure of certain essential heuristics within the comparison algorithm. This methodology provides the basis for understanding and overcoming the limitations of these heuristics in order to achieve higher accuracy.",
The CERN control protocol for power converters,"The CERN Control Protocols provide, for a class of similar devices, a unique and standard access procedure from the control system. Behavioral models have been proposed for the different kinds of power converters, and the corresponding functionalities, with their parameters, variables and attributes, have been identified. The resulting data structures have been presented using the ISO ASN.1 metalanguage, which permits universal representation independent of any computer environment. Implementations in the UNIX-based CERN accelerator control systems are under development. A description of the implementation phase as it is presently being developed at CERN in a cluster of 120 power converters is presented.",
FASVQ: a feasible vector quantization architecture,Image encoding using a new high-speed and high-quality FASVQ (filtering and seeking vector quantization) architecture is proposed. The FASVQ coding scheme consists of three phases. The first and the second phases look like a filter which prune away those codevectors with larger distortions through a single cost estimation function. The third selects exhaustively the minimum distortion codevector within a fixed number of candidates suggested in the first and the second phases. This architecture can realize an environment with a frame rate of thirty 512*512 YUV (4:1:1) color image frames per second. The results of simulation for this coding scheme are presented.,
Synchronization support for efficient parallel discrete event simulation,"As a case study on the applicability of the EDA (extended dataflow architecture) model, CE-graphs (concurrent event graphs) have been defined to achieve high performance of parallel discrete event simulations (PDES) on parallel computers. Two levels of communication and synchronization are devised to execute CE-graphs efficiently, namely coarse-grained or medium-grained token (message) passing and fine-grained variable operations. The CE-graph approach can expose the highest degree of parallelism among independent events, while most existing approaches for PDES can only exploit parallelism at the level of components of a real system. Furthermore, the CE-graph approach can handle pre-emption situations in a natural way, which can be a difficult task for other approaches.",
Proceedings 1992 International Carnahan Conference on Security Technology: Crime Countermeasures,,
Constructing an X-based teleconferencing system,"A teleconferencing system making use of computers and network communication lets people participate in a conference without staying together. During the conference, participants communicate with one another through electronic devices such as terminal, mouse, etc., and network. The authors present the construction of a teleconferencing system based on a standard software system, X/Window System. It discusses an X-based system model for tools necessary in a teleconferencing system, then analyzes the concurrency controls and communication mechanisms among these tools. A prototype for text-based conference called CTUTC for chairperson-members is presented since X provides dynamic-window configuration. The authors model provides a framework from which an iconic-based generating system is possibly built.",
Graphical representations and software engineering,"This paper reports the ongoing activities to generate graphical representation manipulating user interfaces from very high level specifications. First, an overview of graphical notations that are relevant for software engineering is given. Second, the capabilities offered by the current version of the generator G/sup 2/F are presented. Third, the paper shows how software technology techniques in turn have been applied to extend G/sup 2/F by the power of attribute grammars.",
I&C modernization for VVER reactors,"The I&C (instrumentation and control) modernization program for the Temelin VVER 1000 plants illustrates the advantages of a modern digital distributed processing architecture in providing a flexible modular approach incorporating the latest I&C technology available in the nuclear industry. Beginning with a comprehensive safety analysis and functional design consistent with Western practice, the modernization goes beyond simply meeting Western standards of safety. Incorporation of extensive self-diagnostic capability, the use of modern high-speed data communications, and the exploitation of powerful workstations in a distributed processing environment all bring advantages in installation, operation, and maintenance over conventional system designs. For the future, the modernization provides the basis for easy adoption of new improved sensors, faster, more powerful processors, or decision support packages such as expert systems for equipment and system performance monitoring and diagnosis, predictive maintenance planning, or total plant operations optimization.","Inductors,
Distributed processing,
Safety,
Reactor instrumentation,
Industrial control,
Data communication,
Workstations,
Sensor systems,
Packaging machines,
Diagnostic expert systems"
Physics Of Computational Abstraction,,
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science,,
A new parallel algorithm for breadth-first search on interval graphs,"The authors design an efficient parallel algorithm for constructing a breadth-first spanning tree of an interval graph. Their novel approach is based on elegantly capturing the structure of a given collection of intervals. This structure reveals important properties of the corresponding interval graph, and is found to be instrumental in solving many other problems including the computation of a breadth-depth spanning tree, which they report for the first time. The algorithm requires O(logn) time employing O(n) processors on the EREW PRAM model.",
Comments on 'Using cache mechanisms to exploit nonrefreshing DRAM's for on-chip memories',"For the original article see ibid., vol.26, no.4, pp.657-61 (Apr. 1991). In the above-titled paper by D.D. Lee and R.H. Katz, a method for eliminating the need for refreshing for DRAM on-chip caches is presented as a new approach. It is pointed out that the commenters in fact introduced this method in a previous paper (Comput. Arch. News, vol.16, no.4, pp. 45-50, Sept. 1988).",
HiTest: an architecture for highly parallel software,"HiTest is a special-purpose, dynamically reconfigurable, multiple single-instruction, multiple-data (SIMD) architecture designed for highly parallel software testing. The architecture can substantially reduce the total time needed for testing. It is particularly well suited for mutation analysis. The architecture and its use for mutation analysis and software testing in general are described, and the results of a performance analysis are reported.",
New Definitions and Measures for Time-Frequency Distributions,,
Optical interconnects for electronic systems at the board level of packaging,,
Parallel algorithms for all maximal equally-spaced collinear sets and all maximal regular lattices,"The authors present parallel solutions to the AMESCS (all maximal equally-spaced collinear subset) and AMRSS (all maximal regularly-spaced subset) problems and show how their solutions to the latter generalize to the AMRSDLS (all maximal regularly-spaced D-dimensional lattice subsets) problem. Their algorithms differ significantly from the optimal sequential algorithms presented in A.B. Kahng and G. Robins (1991), which do not scale well to (massively) parallel machines. The optimality of the authors' Arbitrary CRCW PRAM (parallel random access machine) algorithms is open; however, the algorithms they present are within a logarithmic factor of optimal. Further, the algorithms are optimal for the mesh-connected computer.",
Network Issues In The Broadband Era,,
An architecture for real-time inference engines on personal computers,"Design and implementation possibilities for real-time inference engines on personal computers and PC-based workstations are studied. FLEXIE, a PC-based real-time inference engine, and an integral part of FLEX, a prototype real-time expert system shell for personal computers is described. A fast pattern-matcher, based on an extension of the RETE algorithm, is built into FLEXIE in order to make it possible to include external real-time information into the inference process. The design of the pattern-matching algorithm makes it suitable for hardware implementation. It can made the pattern-matching process run considerably faster, a key issue for real-time inference. An architecture for such a hardware pattern-matcher is proposed, and initial simulation results are presented. They show an overall speed-up of more than an order of magnitude.",
Reusing database queries in analogical domains,"The authors develop an approach which reuses queries from a well known domain called the base domain in an unfamiliar one called the target domain. The objective is to model the behavior of naive users who often adapt queries from documentation examples to the problem at hand. They rely on a weak form of derivational analogy-traces of a planner operating in the base domain are used to derive a target domain query's implementation in SQL from its specification. The very simple planner used builds in the base domain plans that result in particularly simple, prototypical queries. Queries are specified in a high level subset of a natural language.",
Analysis of asynchronous binary arbitration on digital-transmission-line buses,"The widely used asynchronous binary arbitration scheme on the digital-transmission-line model for buses is analyzed. A common misconception is that in this model, binary arbitration settles in at most four units of bus-propagation delay, regardless of the number of arbitration buses. This conjecture is disproved by showing that the settling time of binary arbitration depends on the arrangement of modules on the bus lines. An arrangement of modules on m buses for which binary arbitration settles only after m/2 units of bus-propagation delay is presented. It is also proved that for any arrangement of modules on m buses, binary arbitration settles in at most m/2+2 units of bus-propagation delay. It is then shown that for linear arrangements of modules in increasing order of priorities and equal spacings between modules, three units of bus-propagation delay are necessary and sufficient for binary arbitration to settle.",
A class of logic problems solvable by linear programming,"Several problems of propositional logic, such as satisfiability, MAXSAT and logical inference, can be formulated as integer programs. The authors consider sets of clauses for which these integer programs can be solved as linear programs. They prove that balanced sets of clauses have this property.",
Hash-semijoin: a new technique for minimizing distributed query time,"Traditional semijoin and semijoin with multiple hash functions are two important methods to reduce the data transmission cost in distributed DBMS. However, these two methods are sometimes inefficient, due to their complexity and lack of flexibility. To remedy these problems, the authors propose a new technique, named hash-semijoin. They identify the situations in which it performs better than traditional semijoin and semijoin with multiple hash functions. The optimal hash functions used in hash-semijoins are also studied.",
Parallel reduction of a chain query in distributed databases,"This paper extends the results of P.A. Bernstein and D.W. Chiu (1981), P.A. Bernstein and N. Goodman (1981), and J.D. Ullman (1988), by constructing a parallel algorithm for a subset of tree queries called chain queries. An efficient parallel algorithm for a construction of full reducers for chain queries is presented and analyzed. The authors claim that the full reduction of a chain query can be done in parallel by executing only 2n-2 semijoins in the time required for an n-1 semijoins evaluation.",
An integrated package for assessment of student assignments in software engineering,"The author describes a software package, running under MSDOS, developed to assist lecturers in the assessment of software assignments. The package itself does not make value judgments upon the work, except when it can do so absolutely, but displays the students' work for assessment by qualified staff members. The algorithms for the package are presented, and the functionality of the components is described. The package can be used for the assessment of software at three stages in the development process: (1) algorithm logic and structure, using Warnier-Orr diagrams; (2) source code structure and syntax in Modula-2; and (3) runtime performance of executable code.",
Experiments using minimal-length encoding to solve machine learning problems,"Describes a system called Emily which was designed to implement the minimal-length encoding principle for induction, and a series of experiments that was carried out with some success by that system. Emily is based on the principle that the formulation of concepts (i.e., theories or explanations) over a set of data can be achieved by the process of minimally encoding that data. Thus, a learning problem can be solved by minimising its descriptions.",
A semantics-based methodology for integrated computer-aided distributed database design,"Presents an integrated semantics-based methodology and an architectural framework for an effective computer-aided DDB design system called Auto-DDB. Auto-DDB facilitates the entire distributed database (DDB) design life cycle (e.g. from requirement specification to allocation schema generation). The design methodology which underlies the construction of Auto-DDB is based on a semantic data model, SEER (synthesized extended entity relationship model), and a transaction model, DTS (distributed transaction scheme). Design heuristic rules rooted in database theories are associated with SEER and DTS constructs for Auto-DDB to automatically transform the application semantics that have been acquired into logical and fragmentation schemata with improved structure to facilitate allocation design.",
I/O performance of fully-replicated disk systems,"Mirrored disk storage is an accepted technique to enhance fault-tolerance of data through complete replication. Recent research suggested that in addition to higher reliability, mirrored disks can offer better I/O performance by either allowing parallel reads or by reducing the seek time in cases where shortest seek distance algorithms can be used. Accurate analysis of mirrored disk systems shows that there is a significant correlation between the distributions of the disk heads positions, which makes them both interdependent and non-uniform. Furthermore, after each write all disk heads move to the same position to form what the authors call a 'bundle'. Such phenomenon may seriously deteriorate system performance. Subsequent reads gradually break up the bundles. Finally, under low rates of request arrivals, the authors provide analytical expressions for optimal anticipation points for two and three mirrored disks under general read/write combinations. Their work makes the following contributions: (1) new heuristics for treating the 'bundling phenomenon' adaptively, for applications with unknown read/write ratios; (2) a new technique that improves the expected seek time and workload balancing by using 'shifted mirroring'.","Availability,
Magnetic heads,
Laboratories,
Computer science,
System performance,
Memory,
Redundancy,
Throughput,
Magnetic separation,
Distributed computing"
A methodology for user centred link structures for textbook to hypertext conversion,"Current hypertext programs provide little support for converting existing linear textbooks to hypertext. Recent literature has identified that many designers do not have a methodological framework for link (and node) structures within which to undertake a text to hypertext conversion, and this appears to be a fundamental fault when attempts are made to convert textbooks into hypertext. The paper addresses the issue by focussing on how links need to support users' reading strategies. A questionnaire has helped to identify how and why users undertake certain actions when reading a textbook. The authors believe that users will read and make use of hypertext if the link structures support readers' goals and if the hypertext can provide a 'personal feel' that linear textbooks provide. By 'personal feel' they mean that users are able to employ their own unique marking and navigation strategies. A note taking facility has been designed to aid such tasks.",
Convergence criteria for iterative nonlinear filters,"The authors present a general theory for the convergence of iterative nonlinear filters. An introduction to lattice theory is provided, and the theory of mathematical morphology is presented in the context of lattice theory. An important form of a nonlinear filter is provided by the iteration of the original nonlinear filter. The result of repeated iteration of a convergent nonlinear filter is called a root of the filter. In many cases, the root of a nonlinear filter is a particularly desired outcome (e.g., median filter). Conditions for the convergence of the iteration of a nonlinear filter are proposed.",
Logical development of a Petri net deadlock analysis program,"If a well-structured concurrent program is represented as a Petri net, it is possible to analyze the network for deadlock. By well-structured concurrent program is meant one in which levels of nesting follow structured programming tenets. Program liveness is defined for a well-structured concurrent program represented as a Pefri net, a Prolog program which will analyze the Petri net for deadlock is presented, and it is proved that the program truly implements the specification of program liveness.","System recovery,
Petri nets,
History,
Resource management,
Computer science,
Logic programming,
Formal specifications,
Calculus,
Concurrent computing,
Programming environments"
MEMPHIS 2000-a modular experiment multiparameter pulse height instrumentation system,"For the data acquisition in nuclear physics experiments with multidetector arrays like OSIRIS, the MEMPHIS 2000 system has been developed. The important features are the compact mechanics, the galvanic decoupling of the sensitive analog part from the host computer power supplies, and simple interfacing with existing computer hardware and ADCs. The use of bit-slice processors provides software control of the setup and the configuration of the whole system. The one-crate version consists of 28 high-resolution (16-b) input channels for NIM-ADCs (Silena Type 7420/G, 7411), two bit-slice processors for ADC control, and three microprocessors for software download, data transfer, and setup. Online acquisition, recording, and analysis of experimental data as well as experiment control are implemented on the VAX-Station.",
Expert-supported object-oriented analysis in knowledge engineering,"One of today's major bottlenecks in software development and knowledge engineering is the analysis phase. Both software engineers and knowledge engineers have to collect and classify all relevant information to identify proper objects. An evolutionary, seamless, non-domain-specific object-oriented analysis (OOA) method is derived that starts at the definition of a software system and integrates knowledge engineering needs in a new manner, especially when following a deep knowledge approach. Based on this method, an expert-supported OOA tool environment (ESA) is presented that supports an analyst starting at the collection of the requirements through the analysis of any software system up to a preliminary high-level design. Due to the many similarities between OOA and knowledge engineering, the method and its supporting tool are rather valuable means in knowledge engineering and are conceived for the needs practitioners.",
A Difficulty Of Planning In The Blocks World,,
A new approach to the numerical solution of constrained mechanical system dynamics,"A novel approach to the numerical solution of the vector field associated with constrained mechanical systems, called the perturbation approach, is introduced. It is a specialization of a method of solving general vector fields due to Shampine. The perturbation approach has several advantages over other approaches. The performance of the approaches on a constrained robot problem is used to show the efficacy of the new approach.",
Explanation trees in CONTEXT: a constraint explanation tool,"The organization and presentation of constraints within a constraint explanation tool known as CONTEXT is described. CONTEXT provides a means for transforming constraints into propagation rules for actively maintaining constraints. The focus is on the functionality of CONTEXT as a constraint explanation tool, describing a structure known as explanation trees. Explanation trees provide a basis for the presentation of constraints, the validation of constraint structures, the identification of propagation actions, and query processing for constraint checking at execution time. The primary contribution of explanation trees within CONTEXT is the manner in which they support the explanation of schema constraints from the point of view of any relevant database update operation.",
On self-testing of array systems,A novel self-testing method which is applicable to one- and two-dimensional arrays is presented. This method is based on a criterion referred to as GI (group identical) testability. GI testability is an extension and modification of PI (partition identical) testability and it is used to simplify response verification for self-testing. It is shown that the response verifier for PI testability does not detect all faults. A novel response verifier for GI-testable arrays is proposed. The proposed approach to self-testing has been evaluated with respect to a two-dimensional WSI (wafer scale integration) array whose cell implements the inner product step for matrix multiplication in 16 bits (integer format).,
Benchmarking performance of massively parallel AI architectures,"The authors address the architectural evaluation of massively parallel machines suitable for artificial intelligence (AI). The approach is to identify the impact of specific algorithm features by measuring execution time on a SNAP-1 and a Connection Machine-2 using different knowledge base and machine configurations. Since a wide variety of parallel AI languages and processing architectures are in use, the authors developed a portable benchmark set for Parallel AI Computational Efficiency (PACE). PACE provides a representative set of processing workloads, knowledge base topologies, and performance indices. The authors also analyze speedup and scalability of fundamental AI operations in terms of the massively parallel paradigm.",
The use of learning technology (methods and processes) in order to achieve the goal of technical education,"The use of leading-edge learning technology to rapidly upgrade competence in technical fields is considered. The author highlights the question of how the latest technology in learning methods is used to speed up the development of technical skills. Examples of methods and processes are computers, instructional television, and organizational development. The implementation examples used are from the electrical engineering discipline.",
COLUMNUS-an architecture for multi-spin-coding algorithms,"In order to improve performance when large systems of simple discrete variables are simulated on general-purpose-computers, multi-spin-coding algorithms have been developed. In this paper, a new architecture is proposed which exploits that kind of SIMD parallelism to a high degree using a large array of cheap memory chips which is directly connected to an army of bit-sequential processors. As each processor can perform different operations simultaneously on the incoming bits, an SIMD*MISD architecture for bit operations results. Many applications including lattice-oriented spin simulations and attractor neural network are presented and discussed for efficiency on this structure. As neural network simulations can be largely accelerated by restricting operations to flipped spins, special hardware is suggested which allows the generation of their indices at a maximum rate.",
Learning structural and corruption information from samples for Markov random field binary image reconstruction,"The authors have advanced Markov random field research by addressing the issue of obtaining a reasonable, nontrivial, noise model. They address this issue by looking at original images together with noisy imagery, and so creating a probability distribution for pairs of neighborhoods across both images. This models the noise within the MRF probability distribution, and provides an easy way to generate Markov random fields for annealing or other relaxation methods.",
Solution of matrix equations via algebraic transformations,An algebraic result useful in the computational solution of sets of algebraic matrix equations is derived. An important advantage of the method is that the solution of only one equation is sufficient to determine the solutions of all matrix equations of the class considered without these equations having to be solved directly. An application example from the area of system theory is presented.,
MIDAS: design philosophy and internals,"The authors have developed a multiuser storage system named MIDAS (multiuser index-based data access system). They describe the internal structure in conjunction with the design principles of MIDAS. To achieve a high degree of concurrency, the original B/sup +/-tree was modified and the various system tables were divided into several independent partitions. A database in MIDAS can have more than one disk volume and a file can be spread over several volumes. An extent-based disk manager was implemented by means of the raw device interface to circumvent shortcomings of the UNIX file system. The transaction notion was supported via the strict two-phase locking method with multiple granularity and a hybrid recovery scheme. The overall system architecture of MIDAS is presented. Some major modules in MIDAS are described.",
A product planning support system for strategic planning and implementation,"A model is proposed which integrates goal programming, the analytic hierarchical process, and the Delphi method. This model allows managers to systematically identify the strategic goals of the organization and set priorities among them, generate product/service alternatives for achieving these goals, evaluate product/service alternatives and select the most promising, and allocate funds among those alternatives. The application of the proposed model is illustrated through a hypothetical example.",
Industrial strength software engineering training programs,"Includes presentations on industry training programs for software engineers and project managers that range from new hires through continuing education programs. Software engineering education in an academic setting is addressed as a precursor to a discussion of three approaches in industry to software engineering training. The introduction of a cross-functional technical training team and a project management training team at the Bull Worldwide Information Systems organization in Phoenix, Arizona is addressed. An overview of software engineering training within a Strategic Business Unit of Motorola, Inc. is presented. The training program includes corporate initiatives, general software engineering training, and applications specific training, utilizing a mix of Motorola training, local universities, vendor-supplied training, and internally developed workshops. The experience gained by Tata Consultancy Services training group is discussed regarding designing, organizing, and conducting software engineering training programs, initially on an experimental basis, and subsequently as a regular feature.",
A 2.5 approximation algorithm for the multi-via assignment problem,"The via assignment problem, whose objective is to minimize the number of via columns used, is known to be NP-hard even when each net includes at most three vias. The authors develop efficient approximation algorithms for solving this problem. An algorithm for the case in which the size of each net is bounded by three is presented, and is then extended to the case in which the nets have arbitrary sizes.",
Cancer treatment with high intensity focused ultrasound: A combined therapy/imaging system for precision noninvasive lesion formation,"A system with combined therapy/imaging capability for noninvasive lesion formation in tissue using high-intensity focused ultrasound will be presented. The system combines a highly focused therapeutic device with an imaging transducer for monitoring the treated volume in realtime using signal processing algorithms of ultrasound radio frequency (RF) echo data. Preliminary results indicate that it is feasible to distinguish between reversible and irreversible change in the state of the tissue due to high-intensity focused ultrasound. An autoregressive model has been assumed for processing echo data from the treated region. The reflection coefficients for a low-order AR model are calculated from A-line data taken during the treatment (every 1 to 2 seconds). The contours of the reflection coefficients can be used to distinguish between reversible and irreversible change in the state of the tissue. Noninvasive quantitative measures of thresholds for irreversible tissue damage based on the AR reflection coefficients are currently being investigated. Experimental results from our investigation will be presented. In addition, a review of the current status of research on tissue ablation using high-intensity focused ultrasound will be given.",
On the semantics of protocols among distributed intelligent agents,"A theory of the interaction among agents and a formal semantics for their interactions are presented. The semantics of the messages exchanged, not the process of exchanging them, is emphasized. A recent theory of communication that gives the object model-theoretic semantics for speech acts is applied to this problem. This allows the important properties of protocols to be formalized abstractly, i.e. at the level of the application, not of the implementation. Further constraints on good designs can also be stated, which simplify the requirements imposed on the member agents. The resulting theory not only provides some insights into designing distributed intelligence systems, but also helps in their validation. As an example, it is applied to a logical reconstruction of the classical Contract Net protocol.",
SEMATECH and the factory of the future,"It is noted that from now through the year 2000, US semiconductor manufacturing lines will undergo remarkable changes. SEMATECH's role in helping shape those changes as it works with the industry to develop manufacturing techniques that will withstand ever-greater pressures for cost-containment, precision processing, and submicron geometries is discussed. SEMATECH is driving efforts to improve manufacturing productivity by taking advantage of the US's strength in systems. Doing so requires an intimate understanding of past, present, and future fab drivers and parametrics. According to SEMATECH, the factory of the future must be an information-based, precision-manufacturing operation that is fully computerized and controlled using microenvironments, with automation. Use of CIM (computer-integrated manufacturing), vastly lower defect densities, appropriate automation, and improved environmental controls will be critical. The bottom line is that paradigm shifts must occur in wafer handling, wafer processing, material purities, fab organization, CIM and more.",
Completion of closed form solution set to optical flow equations,"M. Subbarao and A. M. Waxman (1985) gave the closed-form solution to the nonlinear formulation of the motion and structure equation of Waxman and S. Ullman (1983). They gave a rigorous proof of the uniqueness of their closed-form optical flow solutions for planar surfaces in motion. However, they failed to consider one special case where the planar pitch parallel to the image plane was translating only in the Z direction. The authors give a separate closed-form solution for this special case, thus completing the solution set for optical flow equations.",
MAP region segmentation based on composite random field models,"A composite of two random field models is used to describe the observed image: a high-level process that describes the various regions in the images is modeled by a Gibbs-Markov model, and a low-level process that describes each particular region is modeled by a simultaneous autoregressive model. Using this composition, a recursive maximum a posterior (MAP) segmentation algorithm is formulated and various issues related to parameter estimation are discussed.",
High resolution anatomic model fabrication from CT: Visualizing 3-D error,"A new CAM rapid prototype technology is being used to produce life-size anatomic models for custom prosthesis design and surgical planning. An 80 slice CT study was used to produce three bone models with stereolithography, each employing variations in solid models derived from segmented CT data. The error in linear measurements between the CT data and the fabricated model is discussed and a procedure involving a secondary CT scan of the plastic fabricated model and subsequent registration and visualization of error is presented.",
Remote visualization and parallelism using existing networks,"A method for using existing networks and available parallel channels to provide the needed throughput for remote visualization is proposed. This method keeps the functionalities of the traditional protocol stack but introduces parallelism at all points where bottlenecks can develop. The approach allows the use of existing protocol standards and off-the-shelf hardware to permit new applications that require higher bandwidths. The design tradeoffs in this approach are discussed to develop working architectures needed to solve the animation problems of 5, 10, and 33 frames/s, or 10 Mb every 200 ms, 100 ms, and 30 ms, respectively.",
Solving equality constrained least squares problems,"Constrained least squares problems occur often in practice, mostly as sub-problems in many optimization contexts. For solving large and sparse instances of these problems on parallel architectures with distributed memory, the use of static data structures to represent the sparse matrix is preferred during the factorization. But the accurate detection of the rank of the constraint matrix is also very critical to the accuracy of the computed solution. The author examines the solution of the constrained problem using weighting approach. All computations can be carried out using a static data structure that is generated using the symbolic structure of the input matrices, making use of a recently proposed rank detection procedure. The author shows good speed-ups in solving large and sparse equality conditioned least squares problems on hypercubes of up to 128 processors.",
SEMST-a support environment for the management of software testing,"This paper presents a newly developed environment for supporting the management of software testing. This environment has been built on the top of UNIX and RCS to maintain all versions of the specifications, the test cases and programs, as well as managing the relationships among these components. It is a practical model of applying software configuration management methods to the testing process.",
Separating the communication complexities of MOD m and MOD p circuits,"The author proves in this paper that it is much harder to evaluate depth-2, size-N circuits with MOD m gates than with MOD p gates by k-party communication protocols: he shows a k-party protocol which communicates O(1) bits to evaluate circuits with MOD p gates, while evaluating circuits with MOD m gates needs Omega (N) bits, where p denotes a prime, and m a composite, non-prime power number. As a corollary, for all m, he shows a function, computable with a depth-2 circuit with MOD m gates, but not with any depth-2 circuit with MOD p gates. He proves in the second part that the GIP function by L. Babai et al. (1989) needs exponential size in n when it is computed by some depth-3 circuits, with threshold, symmetric, and MOD m gates.",
A graph-based subcube allocation and task migration in hypercube systems,"The authors propose a task migration scheme based on the HSA (heuristic subcube allocation) strategy to solve the fragmentation problem in a hypercube. This scheme, called CSC (complementary subcube coalescence), uses a heuristic and an undirected graph, called the SC (subcube) graph. If an incoming request is not satisfied due to the system fragmentation, the task migration scheme is performed to generate higher dimension subcubes. Simulation results show that the HSA strategy gives better efficiency than the Buddy and GC strategies in the adaptive mode. Moreover, the HSA strategy has a significantly lower migration cost than that of the Buddy and GC strategies.",
Time-variant estimation of the spectral parameters of Heart Rate Variability,"Recursive Auto-Regressive (AR) identification algorithms, applied to the study of Heart rate Variability (HRV), allow to investigate transient biological phenomena. Each time the AR parameters are updated, the positions of poles must be evaluated in order to quantify frequency and power of spectral peaks by means of a spectral decomposition based on the residual integration method. We describe a recursive method for pole tracking that estimate the new pole positions on the basis of the AR parameters variations, in a more efficient way than traditional factorization algorithms. The method is suitable for an on-line monitoring of traditional HRV parameters, which measure the symphato-vagal balance elicited by the control mechanisms of cardiovascular system.",
Gain In Nanoelectronic Devices,,
Teaching engineering disciplines to tool developers,An approach to teaching engineering of computer-aided software engineering (CASE) tools that combines detailed tool algorithm knowledge with an engineering process for such tools is proposed. A methodology for the inclusion of engineering disciplines in CASE development education is described. Teaching methods from first basic principles to more developed processes are suggested. Specific recommendations are made for curriculum development.,
Design of an integrated test battery for assessing effects on human performance,"One problem of test battery design in occupational health and safety has been the absence of a unifying theoretical framework for the selection of tests. Consequently, systematic interpretation of observed deficits has been impeded. A computer aided battery of tests based on a model of human information processing was designed. Together, the tests provide a comprehensive and integrated evaluation of sensory, motor and cognitive performance. The tests, their relationship to the model on which they are based and the purpose-specific hardware and software designed to run the tests are detailed.",
The new high-speed digital signature,"The digital signature is an ideal mechanism for authenticating with computer-generated messages. Recently, as enhanced network services have developed, the importance of a high-speed digital signature has become apparent. Previously, the best secure scheme of knowing digital signature systems has been RSA. However, this scheme has a problem in that the processing speed for generating signature messages is slow. A high-speed digital signature scheme is proposed to solve these problems. The proposed scheme has the security level even with the difficulty of factoring in large numbers. This scheme is based on a congruent polynomial of low degree to high processing speed. A random number is used in the generation of the signature, and inequality is used in verification. This scheme is compared with the RSA scheme to evaluate its performance.",
DFIFO protocol and analysis,"To meet the challenge of future communication requirements, the authors explore protocols for communication networks at data rates of 1 to 10 Gb/s, called gigabit networks. In particular, a new protocol, referred to as the distributed first in first out (DFIFO) protocol, is presented. The objectives of this new protocol are to enhance network throughput and reduce media access control (MAC) delay to meet the requirements of gigabit networks. The key concept of the DFIFO protocol is the global time stamp (GTS) scheme, which provides a global timing reference so that data segments in the entire network are ordered in a FIFO manner. By using the destination removal policy, DFIFO is able to use the network bandwidth effectively. The DFIFO protocol simulation model results are provided.",
Decision support for the management of lipid disorders using Causal Probabilistic Networks: A development strategy,This paper describes the development of a computer system for decision support in the management of patients with hyperlipidaemia. It illustrates how a Causal Probabilistic Network representation may be used to suggest treatment for lipid disorders to minimise an individual's risk of Coronary Heart Disease.,"Hypertension,
Biochemistry,
Cardiology"
"Toward Engineering Literacy: Understanding the Interplay between Engineering and Science, A Case Study",,
Complete and efficient methods for supporting side-effects and cuts in And-Or parallel Prolog,"Practical Prolog programs usually contain extralogical features like cuts, side-effects, and database manipulating predicates. It is noted that, in order to exploit implicit parallelism from real applications, a parallel logic programming system should necessarily support these features. How Prolog's extralogical features can be supported in an And-Or parallel logic programming system is discussed. It is shown that to support extralogical features an And-Or parallel logic programming system should recompute the solutions to independent goals instead of sharing them. An abstraction called the composition tree for representing And-Or parallel execution with recomputation is described. The notion of 'local-leftmostness' in the composition tree is introduced and used for deriving complete and efficient methods for supporting extralogical predicates in And-Or parallel logic programming systems based on the composition tree abstraction.",
Matrix multiplication on a toroidal parallel architecture,"Matrix multiplication is one of the class of algorithms which have considerable application and which may provide substantial increase in efficiency when implemented on an appropriate parallel machine. In particular, the author presents an algorithm for dense matrix multiplication on a toroidal architecture with n/sup 2/ processors, which has a runtime of h+nm+(n-1)a, where the matrices to be multiplied are square of order n; and where h=the time to transmit one word between adjacent processors; m=the time to multiply two words in a processor; a=the time to add two words in a processor; with a local storage requirement of 2n+2 words. Furthermore, the coefficients of the product are stored in the local memory of the same processors as the corresponding coefficients of the factors.",
Educational tool for design of parallel processing systems,"A software package which can be used as an educational tool for the design of a subset of parallel processing architecture (PPA) systems is presented. A user-friendly interface guides the user through the different steps involved in specifying and emulating PPA systems using program-driven simulation. The user can choose any of the following PPA systems categorised according to Flynn's taxonomy: MISD (multiple instruction single data), SIMD (single instruction multiple data) and MIMD (multiple instruction multiple data). Workload and scheduler specifications can be defined by the user. The evaluation model is based on the queuing theory for the modelling and simulation of PPA systems. The simulation program is based on a linked list structure to represent events. The package includes HELP and ERROR LOG utilities, and provides graphical illustrations of the results and performance indices.",
Integrated software environments,"A modeling environment that can combine mathematical, artificial intelligence, and many other computer-based methods to explore a problem space is described. A new approach to constructing this kind of modeling environment is used. The environment uses explicit knowledge of its own structure to support the user in selecting and adapting the system components. The knowledge is in the form of wrappings, which are expert interfaces to the programs, tools, and other resources in the environment. This approach is a simple and powerful mechanism for allowing different kinds of resources to work together in an integrated way. The structure of a program is described that implements this approach. The program is used to study both the types of wrapping descriptions and the wrapping processes.<>",
Analyzing information content of MR images,"The information content of magnetic resonance images is analyzed for the purpose of achieving more compression using the existing algorithms. It is found that the first five bits of all images contain no information and therefore can be totally compressed. The experiments also showed that, by segmenting and transforming the image, the entropy and therefore the compression rate can change. A vertical (along z axis) segmentation method is presented which can improve the compression rate by 10%. Other types of segmentation method (along x or y axes) can also be studied. The transformation method used was a simple differential coding method which resulted in almost no improvement in compression. This was an interesting observation, since this same transformation can drastically improve the compression of other types of data such as satellite imagery.",
Extraction and classification of graphical symbol candidates based on perceptual organization,"A general-purpose graphical symbol extraction method is proposed in which the visual characteristics of graphical symbols are used. The graphical symbols are modeled as gatherings of short line segments and loops. Based on these models, two different methods are applied in parallel to a diagram, and two results are generated and integrated into the candidates. Further, a method to classify the extracted graphical symbol candidates by comparing their shape and structure is described. An important point of the method is that no a priori knowledge of the diagram under consideration is introduced, hence the method is applicable to a wide range of diagrams.",
A semantic browser for object oriented program development,"Object-oriented methods allow programmers to construct software with a simple and uniform structure. Object-oriented programs should be simple to maintain and extend. Source code browsers are not sufficient for understanding object-oriented programs. The authors have combined a strongly-typed object-oriented language with an integrated, interactive development environment. For several reasons, they designed the compiler as an integral component of the environment. Coupling the compiler and the browser simplifies symbol table management in the compiler. Conversely, the same coupling ensures that information is semantically checked before the browser displays it. Also, programmers do not have to understand the class hierarchy because the compiler creates class views.",
Treatment of human-computer interface in a decision support system,"The authors discuss the efforts at Sandia National Laboratories in developing the adaptive conceptual model manager within the constraint of environmental decision-making. A computer workstation that hosts the conceptual model manager and the Sandia Environmental Decision Support System (SEDSS) is also discussed. The SEDSS currently addresses the problems of monitor-well network design. Mathematical models of the site's geohydrology are used to determine likely flow paths and to place wells optimally. Using computational models of flow in the unsaturated and saturated zones, and applying Monte Carlo simulation techniques to sample parameters describing their conceptual model of the site's hydrology and geology, it is possible to determine where one might optimally locate wells around the site to achieve a desired probability of plume detection should a leak occur.",
A pattern based approach of integrating data and knowledge to support cooperative query answering,"A framework for integrating class-oriented data grouping and subject-oriented knowledge grouping to support cooperative query answering is proposed. This framework is characterized by a three layer data/knowledge organization: object layer, object-subject layer, and subject layer, where a database at the object layer and a knowledge base at the subject layer are coupled by virtual database patterns specified at the object-subject layer. Based on such an architecture, communicating databases and knowledge bases are organized and maintained independently but linked dynamically under specific subjects. Cooperative query answering can then be accomplished through tracing the behavior dependencies amongst cooperating objects under those subjects. To implement this approach, mechanisms of dynamic-classifications, deductions, focus transitions and goal rewrites are introduced. An experimental cooperative database system, CoBase, was developed to demonstrate the effectiveness of the approach.",
Quantifying saliency of feature points on 3-D curved surfaces from range images,"A method for quantifying saliency of 3D feature points from range images of model surfaces is proposed. The saliency is characterized by the discriminating power of the feature points for distinguishing the model objects they belong to from others. It is measured by local shape similarity, and the similarity coefficients of surface points are calculated by parameterizing local surface representations into the local orientation coordinate systems. An algorithm for performing the Hough transform weighted by the similarity coefficients is developed to optimally determine the saliency coefficients of the feature points. It is shown that the method is especially useful for dealing with the occlusion problem that must be solved when constructing a flexible robot vision system.",
Recognition of catastrophic faults,"For a given design, it is not difficult to identify a set of elements whose failure will have catastrophic consequence. There exist many patterns (random distribution) of faults, not in a block, which can be fatal for the system. Therefore, the characterization of such fault patterns is crucial for the identification, testing and detection of such catastrophic events. This paper, is concerned with the development of efficient recognition schemes; that is, efficient mechanisms which automatically determine whether or not an observed/detected pattern of faults will have catastrophic consequences. The problem of recognizing whether a fault pattern is catastrophic has been addressed.",
Teaching Computer Communications in Germany and in the US: A Comparative Look,,
On polynomial time algorithms for tree-decomposable graphs,"Recent work in the design of efficient algorithms for optimization problems on tree-decomposable graphs concentrates on developing general approaches which lead to families of related algorithms, rather than on developing isolated ad hoc algorithms. The author extends previous results to obtain novel classes of related polynomial time algorithms for problems not previously handled by any general approach. Two families of polynomial time algorithms are presented for packing, partitioning, and covering problems, and for multiset and multiproperty problems.",
Exploiting correlations among competing models with application to large vocabulary speech recognition,"In a typical speech recognition system, computing the match between an incoming acoustic string and many competing models is computationally expensive. Once the highest ranking models are identified, all other match scores are discarded. The authors propose to make use of all computed scores by means of statistical inference. They view the match between an incoming acoustic string s and a model M/sub i/ as a random variable Y/sub i/. The class-conditioning distributions of (Y/sub 1/,. . .Y/sub N/) can be studied offline by sampling, and then used in a variety of ways. For example, the means of these distributions give rise to a natural measure of distance between models. One of the most useful applications of these distributions is as a basis for a new Bayesian classifier. The latter can be used to significantly reduce search effort in large vocabularies, and to quickly obtain a short list of candidate words. An example hidden Markov model (HMM)-based system shows promising results.",
Remote Sensing Image Classification By A Gis Guided Spatial Analysis,,
A test suite approach for Fortran90D compilers on MIMD distributed memory parallel computers,"Describes a test suite approach for a Fortran90D compiler, a source-to-source parallel compiler for distributed memory systems. Different from Fortran77 parallelizing compilers, a Fortran90D compiler does not parallelize sequential constructs. Only parallelism expressed by Fortran90D parallel constructs is exploited. The authors discuss compiler directives and the methodology of parallelizing Fortran programs. An introductory example of Gaussian elimination is used, among other programs in the test suite, to explain the compilation techniques.",
Compression of dictionaries via extensions to front coding,"Front-coding is a technique used to reduce the redundancy in a representation of a dictionary, taking advantage of common prefixes. However, redundancy still exists in the front-coded representation; suffixes and infixes of words are not coded. The authors method attempts to remedy this deficiency by iteratively applying front-coding techniques to the suffixes. By applying a variant Huffman coding method, it is possible to represent the Huffman tree of suffixes in the form of another dictionary, to which the method can be iteratively applied. On large natural-language dictionaries the authors have achieved compression ratios as favourable as 11%.",
Formal verifications: an industrial case study,"By means of the mu PABX example, the adequacy of temporal logic was demonstrated for the specification and formal verification of industrial reactive systems. The aim of the mu PABX system is to provide services that are issued by phone-users of the mu PABX. In contrast to a real PABX, the mu PABX offers only one type of service to its subscribers: two-party voice calls. Formal verification avoids the deficiencies of testing by proving mathematically that the system behaves according to the specification. For this to be possible, the system behavior must be defined with mathematical precision. The focus is on the formal verification of the mu PABX. It is demonstrated that, if temporal logic is used, the task of proof construction can be 100% automated. An implementation of the mu PABX system is discussed.",
IS information technology based on enough science?,Information technology should be about applying scientific principles and engineering methods to information. The author's thesis is that we have some engineering methods but not enough science. He starts by drawing a distinction between data and information.,
Efficiency in pure blackboard systems,"The blackboard model is a versatile framework for implementing expert systems. In recent years the speed of blackboard access has been improved but the execution cycle, which manages knowledge source activation and execution, still needs substantial improvement. A method of condensing knowledge sources is presented, and it is shown how to efficiently activate and execute a class of blackboard application systems using the condensed representation. It is shown that the time complexity of the execution cycle of a condensed system is faster than that of the conventional approach by the ratio of the time required for blackboard retrievals to the time required for vector element retrievals. In practice, this ratio is approximately four order of magnitude.",
Tools for automating experiment design: a machine learning approach,"Work that uses an inductive learning tool, HEP-RL (high-energy-physics rule learner), in the design of a very complex artifact, a high-energy-physics experiment, is reported. The important contribution is the observation that the results of learning provide a more complete and robust design. This is because there were end users of the learning able to suggest constraints beyond the usual simple coverage metrics. This allowed for more confidence in the design.",
A semantic framework for the design of data intensive applications in a persistent programming language,"The type system of a programming language and the data model of a DBMS provide a similar function-the abstract description of the structure of the application world. Type systems available in persistent programming languages such as Napier88 are extremely powerful and precise tools for describing structures on which computation of arbitrary complexity may be expressed. The data models commonly found in a DBMS are usually less expressive, but compensate by being easier to use. In particular semantic data models are designed to permit the description of the structure of a database using concepts close to those used to structure information in the real world. This paper describes an attempt to combine the best features of both worlds by creating a semantic data model interface to Napier88. The database structure is captured as an IFO schema and transformed into a set of Napier88 type declarations and low level procedures which act as a basis on which to build the application.",
A neural network that uses a Hebbian/backpropagation hybrid learning rule,"A novel neural network architecture is proposed that provides a unified framework for Hebbian and backpropagation-based learning. The learning rule for this architecture, called the hybrid learning rule, combines the features of the Hebbian learning rule, which is a good feature extractor, and the backpropagation algorithm, which is an excellent classifier. By combining these two learning rules into the hybrid learning rule, the hybrid learning rule should have the strengths of both without any of the weaknesses. The hybrid learning rule was applied to the problem of isolated character recognition. While the hybrid learning rule failed to perform better than the backpropagation algorithm, it did generate receptive fields similar to those found by R. Linsker (1986), T.D. Sanger (1989), and D.H. Hubel and T.N. Wiesel (1962).",
Multiparadigm data structures in Leda,"Multiparadigm programming is a term used to describe a style of software development that makes use of facilities originally designed in support of a number of different programming language paradigms. A conception of multiparadigm programming is illustrated by describing how various data structures can be implemented in Leda, a strongly typed compiled multiparadigm programming language. Specifically, a style of program development that draws upon features from a number of different programming language paradigms is illustrated. Aspects of imperative programming, object-oriented programming, functional programming, and logic (or relational) programming are used. It is shown how these various language paradigms can be integrated in a single problem domain, and how each can derive benefit from the others. The problem considered is the creation of a few simple data structures for lists and two-dimensional tables. The development of this example is used as a means to introduce Leda.",
Requirements specification for a real-time embedded expert system for rapid prototyping,"Several commercial expert system shells provide knowledge engineers with the capability of developing expert system applications, but are not able to meet the size constraints or provide the run-time performance needed to address problems associated with delivery of embedded real-time applications. In addition, there is no provision to provide deliverable code in Ada, a requirement for many US DoD systems. The embedded consultant project addresses these issues by knowledge-base size reduction by means of code optimization techniques, and by an inference engine, written in Ada, designed for real-time applications. A new rapid prototyping approach for real-time applications is described. The methodology is based on the reuse of existing software components. The approach, and the significance of the work are discussed.",
Experience at the Massachusetts Institute of Technology (MIT) Laboratory for Computer Science,"The author describes MIT and its Laboratory for Computer Science. He argues that with programming on several hundred advanced workstations and several multiprocessor systems, with construction of hardware prototypes, with industrial partnerships for the construction of systems too ambitious for the Laboratory facilities, and with analytical and theoretical work throughout, the MIT Laboratory for Computer Science is truly a dynamic and inspiring place.","Computer science education,
Laboratories,
Multiprocessing,
Workstations"
An expert system for radiological images,"We present an expert system developed to confirm or to assess the presence of a pathology on the basis of morphological data, coming from radiological images. This system is based on object oriented programming. The basis of this system is a lingustic description of the radiological image referred as “feature image”. We can recognise three different levels of use. The first from a real image to some possible pathologies, the second from some pathologies to a possible expected image, the third, a consultation level on the anatomical region considered. We have tested the system on images of the thorax.",
Neural Network Construction Of Boolean Function Used In Process Control,,
Dynamic testing and diagnostics of digitizing signal analyzers,"A dynamic testing method for evaluating the effective bit number of digitizing signal analyzers is presented. This technique is valid when, owing to particular working conditions, only a limited number of digitizing signal analyzer sampling points can be collected. In such a case existing test methodologies can present problems. The proposed method is based on a regression algorithm and, by employing one and a half periods of the sinewave test signal, requires very short computation time. After a summary of the existing test methodologies, the performance and limits of the method proposed are analyzed. To demonstrate the applicability of the method, preliminary simulation results for several devices and data relative to one particular digitizer are reported.",
Perspectives on massively parallel computation,"The areas of algorithms applications, architectures, and system software are discussed with reference to massively parallel computation.","Concurrent computing,
Parallel processing,
Programming profession,
Application software,
Computer architecture,
Biographies,
Computer science,
Mathematics,
Educational institutions,
Laboratories"
Optimistic make (software design),"The notion of encapsulations is introduced as the basic construct used to support optimistic make (a software tool). The authors describe the implementation of optimistic make in the V-System on a collection of SUN workstations. Statistics measured from this implementation are used to synthesize a workload for a discrete-event simulation, and to validate the simulation's results. The simulation shows a speedup distribution over pessimistic make with a median of 1.72 and a mean of 8.28. The speedup distribution is strongly dependent on the ratio between the target out-of-date times and the command execution times. With faster machines the median of the speedup distribution grows to 5.1, and then decreases again.","Design optimization,
Software design,
Encapsulation,
Computational modeling,
Delay,
Workstations,
Programming,
Computer science,
Sun,
Statistical distributions"
Hierarchical message dissemination in very large WANs,A hierarchical broadcasting technique in very large arbitrary networks which achieves near optimal cost and time measures is proposed. The network is partitioned into hierarchical clusters which are interconnected with each other through gate nodes. The approach is based on using a fully distributed minimum spanning tree algorithm within the gate-node network while achieving time optimal broadcasting within the local clusters by formulating the problem as finding maximum matching in constrained bipartite graphs. Extensive simulation results are presented which show the tradeoff between the two conflicting performance criteria.,
The MetaMP approach to parallel programming,"The authors are researching techniques for the programming of large-scale parallel machines for scientific computation. They use an intermediate-level language, MetaMP, that sits between High Performance Fortran (HPF) and low-level message passing. They are developing an efficient set of primitives in the intermediate language and are investigating compilation methods that can semi-automatically reason about parallel programs. The focus is on distributed memory hardware. The work has many similarities with HPF efforts although their approach is aimed at shorter-term solutions. They plan to keep the programmer centrally involved in the development and optimization of the parallel program.",
"A CMOS Resistive-fuse Processor for 2-D Image Acquisition, Smoothing, and Segmentation","An integrated CMOS resistive-fuse processor capable of smoothing out noise while preserving the edges of a 32×32 image is described. An on-chip photo-transistor imager converts the optical image into electrical currents. The design of a single-pixel processing element using resistive fuses is described. The processed output is read out using a row decoder and a column MUX. Operating from a single 5-V supply, the chip typically dissipates only 10 mW.","CMOS process,
Smoothing methods,
Image segmentation,
Fuses,
Voltage,
Resistors,
Circuits,
MOS devices,
CMOS technology,
Optical noise"
On the parallel processing capabilities of LCA networks,"Lowest Common Ancestor networks (LCANs) are hierarchical interconnection networks for communication in SIMD and MIMD machines. The connectivity and permutational properties of specific families of LCANs have been previously studied. LCANs are built with switches in a tree-like manner. A level in the hierarchy is akin to a stage in a multistage interconnect and their topology is similar to that of hypertrees and fat trees. Their hierarchical structure lends itself to implementation in the fabrication hierarchy, namely chips, boards and backplanes. In this paper, a preliminary investigation of the algorithmic capabilities of LCANs (in terms of their parameters) is reported.",
A new reservation scheme for cyclic reservation multiple access,"Cyclic reservation multiple access (CRMA) is an access scheme for high speed local and metropolitan area networks based on slotted unidirectional dual-bus structure. In CRMA, the headend generates the reserve commands periodically. Each node reserves a number of slots in each reserve command. Finally, the headend generates a sequence of cycles each of which is used to service the reservations on the corresponding reserve command. The length of each cycle is equal to the total number of slots reserved by the nodes in the corresponding reserve command. Generally, a longer cycle length will conduct a longer access delay and a lower slots utilization. The authors propose a new reservation scheme to make the cycle length as short as possible. That is, some of used slots can be reused by the downstream nodes and hence the throughput is improved.",
Analysis of a virtual memory model for maintaining database views,"An analytical model is given for predicting the performance of a new support strategy for database views. This strategy, called the virtual method, is compared with traditional methods for supporting views. The analytical model's predictions of improved performance by the virtual method are then validated by comparing these results with those achieved in an experimental implementation.","Analytical models,
Performance analysis,
Relational databases,
Queueing analysis,
Computer science,
Predictive models,
Costs,
NASA,
Space technology,
Memory management"
Issues surrounding specification languages for software automation,"Software automation tools which assist in the building of software from specifications are described. The problems and promise of both informal and formal approaches to software automation are discussed. Specification languages which serve as the basis for a software automation tool provide the most specific basis for their discussion. Issues which need to be addressed are identified. These include the problems inherent in feature-based approaches: the lack of reasoning power inherent in some specification languages; the problems of inconsistency, ambiguity, and incompleteness; and the nonmonotonic aspects of software.",
How to store a triangular matrix,"The problem of storing a triangular matrix so that each row and column is stored as a vector, i.e. the locations form an arithmetic progression, is discussed. Storing rows and columns as vectors can speed up access significantly. It is shown that there is no such storage method that does not waste approximately one-half of the computer memory.",
Human performance data visualization for system design teams,"A multimedia design tool is being developed to enhance the usability of ergonomic data by crew system designers and multidisciplinary design teams. The Computer-Aided Systems Human Engineering: Human Performance Visualization Subsystem (CASHE: HPVS), Version 1.0, will help both individual designers and design teams to experience and manipulate human performance technical data so that performance implications of design decisions can be understood more clearly. By providing the ability to gain a common understanding of behavioral data through direct experience via simulation, the HPVS is also intended to reduce miscommunication in multidisciplinary design teams regarding human performance issues.",
Developing a Technical Communication Component for Engineering Design Courses,,
A distributed production system for problem solving,"Much work has been done in improving the efficiency of production systems, but single PS models are not suitable for applications in distributed problem solving. To address such multiagent behaviours problem solving the authors present a distributed asynchronous production system model (DAPS), where multiple production systems (PSs) co-operate to solve a problem. In DAPS the PSs run highly asynchronously, thus reducing the bottlenecks in synchronous models; PSs communicate by sharing working memory elements. The authors present methods for distributed match and execute phases, propose a modified select strategy, and indicate applications in the domain of distributed planning.",
Generating complete depth maps in passive vision systems,"The authors describe a hybrid system which uses multiple depth resources, rule-based depth interpolation and predictive rendering to generate accurate and dense depth maps. Initial depth estimates are obtained from multiple views (shape-from-generalised-stereo) and by shape-from-focus. The resultant sparse depth maps are then interpolated symbolically. The interpolated depth map for each region is corrected by inverse rendering. It is shown that nontrivial integration of depth resources reduces many of the problems normally associated with considering each depth resource individually.",
Seeking concurrency in rule-based programming,"This paper describes a formal approach for developing concurrent rule-based programs. Specification refinement is used to generate an initial version of the program. Program refinement is then applied to produce a highly concurrent and efficient version of the same program. Techniques for deriving concurrent programs through either specification or program refinement have been described in previous literature. The main contribution of this paper consists of extending the applicability of these techniques to a broad class of rule-based programs. To the best of our knowledge, this is the first time formal derivation is employed in the context of rule-based programming.",
Managing replicated data in heterogeneous database systems,"In a heterogeneous database system, supporting transaction semantics is expensive, and sometimes impossible. thus, in such systems, traditional methods such as quorum consensus cannot be used directly for managing replicated data. A method to manage replicated data in a heterogeneous database system is proposed. The method is based on the idea of quorum consensus but does not rely on transaction semantics. It is more robust than the other methods introduced in the literature, and can be used in systems where one copy serializability is the correctness criteria.",
Grammars and relations,The potential benefits obtained when context-free grammars are used to define complex objects in the relational model are demonstrated. The grammar formalism facilitates relational queries on the hierarchical structure of these objects and promotes the use of grammar-based tools as front ends to relational database systems.,
Convergence properties of the algebraic reconstruction technique (ART),"The behavior of the algebraic reconstruction technique (ART), particularly in the inconsistent case, is considered. The aim is to understand better the analogous multiplicative ART (MART), and to solve open problems concerning its behavior.",
Programs to detect and manage aging of instrumentation and control components for license renewal (nuclear plants),"Requirements for the renewal of commercial nuclear plant operating licenses are defined in 10CFR54, the License Renewal Rule. In a recent application of the Rule, over 1600 process instrumentation and control components were identified as important to license renewal. A grouping program was developed to break down the large populations into manageable, generic groups. Forty-six groups were selected based on component boundaries, design principles, environment, operating and maintenance history, and similar expectations for aging mechanisms and service life. Evaluations were then conducted on a group basis, to define significant aging mechanisms, review plant programs, and identify enhancements to ensure full coverage for the license renewal period.",
Matching Mental Models to Written Instructions for Computing,,
SpeechWare: a prosthesis for speech and motor impairment,"SpeechWare 2.0 is a customizable speech prosthesis for people with communications as well as motor disabilities. It runs on an Apple Macintosh computer and provides user empowerment over synthesized and digitized speech, telephone and print communications, and household environmental control. The advantage of a ProsthesisWare approach is that it permits customization for each person's cognitive and physical capabilities and does not depend on neurological plasticity. The disadvantage is that ProsthesisWare requires new technical, programming, and support infrastructures to be established in the rehabilitation industry.",
Energy-function approach to high-level synthesis scheduling,"A new scheduling algorithm based on an energy function is presented. Scheduling is performed iteratively under the direction of an energy function until all the operations are scheduled and the total energy gets into a minimum. In each iteration of scheduling, it is possible to either schedule an operation to a control step (assign) or exclude the possibility of scheduling an operation to a control step (unassign). The energy function determines the operation to be selected and to which control step this operation is assigned or unassigned. Search width and depth are introduced to reduce the time complexity in selecting the operation to be scheduled in each iteration.",
Recent development in large-scale systems research in China,"A general view of large-scale systems research in China is given, which includes model reduction, stability, hierarchical and decentralized control, steady-state optimizing control, large-scale decision making and application research achievements of both industrial processes and societal and economic systems, and so on. Finally, a perspective for future research is viewed based on the present situation.","Large-scale systems,
Distributed control,
Stability,
Control systems,
Control theory,
Steady-state,
Environmental economics,
Electrical equipment industry,
Industrial control,
Computer science"
When object-oriented operating system is time critical,"This paper presents performance results of the object-oriented real-time operating system Theta. There are two current versions of Theta which are written in the object-oriented languages, C++ and COB. In both languages, object-orientation is embedded into the C language. The overhead of the C++ and the COB versions are compared with that of C. Our experiments show that if the classes are carefilly chosen, there is no significant overhead for real-time applications.",
Inheritance-based object-oriented software metrics,"There is no software metrics based on object-oriented programming languages (OOPLs) developed to help object-oriented software development. A graph-theoretical complexity metric to measure object-oriented software complexity is described. It shows that inheritance has a close relation with the object-oriented software complexity, and reveals that misuse of repeated (multiple) inheritance will increase software complexity and be prone to implicit software errors. An algorithm to support this software metric is presented. Its time complexity is O(n/sup 3/).",
Sub-logarithmic algorithms for the largest empty rectangle problem,"The authors show that the largest empty rectangle problem can be solved by reducing it, in a natural way, to the all nearest smaller values problem. They provide two classes of algorithms: the first one assumes that the input points are available sorted by x (resp. y) coordinate. The authors algorithm corresponding to this case runs in O(log log n) time using n/sup 2//log log n processors in the common-CRCW-PRAM model. For unsorted input, they present algorithms that run in O(log n/log log n) time using n/sup 2/ log log n/log n processors in the common-CRCW-PRAM, or in O(log n) time using n/sup 2//log n processors in the EREW-PRAM model. No sub-logarithmic time parallel algorithms have been previously reported for this problem.",
Multi level combinational circuits and hazard detection,"The author addresses static hazards in multi-level combinational logic circuits. A novel approach is introduced based on a uniform hybrid method that is capable of identifying race conditions and detecting all types of hazards: static, logic, function, and dynamic, that have the potential to exist in combinational logic circuits under given conditions. This method is based on a binary switching algebra, and uses hardware simulation techniques together with more formal symbol manipulation mechanisms in order to identify potential hazards in logic design.",
A digital neural network for the traffic control problem on crossbar switch networks,"The traffic control problem on crossbar switch networks is represented by a parameter-free energy function. The proposed neural network is applied to update the state of the energy function until a stable state is reached. Within O(n) iteration steps, where n is the size of an n*n network, the energy function reaches a stable state which corresponds to a feasible solution of the traffic control problem. Simulation results show that this neural network also generates either optimal or near-optimal solutions.","Switches,
Neural networks,
Traffic control,
Buffer storage,
ISDN,
Cost function,
Equations,
Sun,
Computer science,
Power engineering and energy"
Object Oriented Approach to the Simulation of Shipboard Electric Power Systems,"An object oriented approach for time domain simulations of shipboard electric power systems is proposed. It offers a flexible, user friendly alternative to conventional simulators, allowing design and operation analysis under a variety of operating conditions and topologies. The most general model of an electric power system consists of a set of nonlinear differential equations subject to algebraic constraints, which describes the evolution of the System, following certain contingencies. The algorithm presented adopts an object oriented approach by decomposing the system into its underlying components/devices, developed and maintained independent of one another. The differential equations are solved on the device level using a waveform representation of variables, which exploit both partitioning and parallel processing features. The ideas presented are tested on different test cases and conclusions are drawn.",
Heuristics for computing robust tests for stuck-open faults from stuck-at test sets,"Heuristics for identifying stuck-open faults for which a robust test can be computed from any stuck-at-test set are presented. Experimental results show that these heuristics can be used to compute robust tests for a large percentage of stuck-upon faults. Since stuck-at test generation is considerably faster than computing a robust test-pair for a given stuck-open fault, these heuristics can be used to speed up the process of computing robust tests for stuck-open faults. The author addresses the problem of computing robust tests for stuck-open faults in static CMOS circuits consisting of NOT, NAND, NOR, AND and OR gates.",
A model of some short term mechanisms controlling systemic pressure,"In this work we analyze the role of the reflex control of total systemic vascular capacity through an original mathematical model of the human cardiovascular system. The model includes the elastic and resistive properties of systemic and pulmonary arteries and veins, the dependence of cardiac output on atrial pressure, and the action of the carotid sinus baroreflex on both systemic resistance and heart rate as well as on systemic venous unstressed volume. The values of model feedback gains were assigned to simulate the results of some experiments performed on vagotomized animals in an open loop condition. The effect of the carotid sinus baroreflex on unstressed volume, cardiac output and arterial pressure is correctly reproduced by the model. Analysis of the interactions between the mechanisms involved in the short-term arterial pressure control demonstrates that a mechanism acting on systemic venous capacity may have a significant role in cardiovascular homeostasis. It may especially contribute to the regulation of arterial pressure by modulating central venous pressure, hence improving cardiac performance and buffering the effect of acute hemodynamic changes.","Cardiology,
Hemodynamics,
Baroreflex"
Hierarchical analysis of visual motion,"A hierarchical data structure for analyzing visual motion is presented. Although the literature on perception is abundant with studies on visual motion, none of the studies investigated the importance of a hierarchical model in the analysis of visual motion. The model was implemented on a supercomputer (Cyber 205). The algorithms of hierarchical correlation were performed on binary images. The results are compared with those obtained using similar serial algorithms. The impact of such a hierarchy on component directional selectivity and on pattern directional selectivity is studied.",
A new parallel quadtree construction algorithm on a hypercube,"Most existing parallel quadtree construction algorithms regard quadtree nodes only as combinatorial objects. Therefore, the restoration of geometric relations requires extra communication overhead by either traversing the embedded quadtree or sorting the quadtree nodes. A different approach is adopted. It considers the quadtree nodes as both combinatorial objects as well as geometric entities with spatial adjacency relations. By incorporating the notion of adjacency preserving, a new parallel quadtree construction algorithm is proposed. It is shown to be efficient in both time and communication aspects. The initial data loading process is investigated, and an efficient loading algorithm is proposed to provide a better structure for the following construction phase.",
Information systems teaching and research at the National University of Singapore,"The three-year undergraduate program in computer and information sciences was started in 1983. Graduate level teaching and research started in 1986. Funding of research is quite adequate, but other resources such as research expertise, research students, and research time are in short supply. To some extent, shortage of research expertise is alleviated by forging research alliances with universities in the USA and through the appointment of visiting professors. The major current research areas are telecommuting, applications of IT in small businesses, group decision support systems, and government policy and diffusion of information technology. Future plans envisage strengthening the graduate level curriculum, starting the PhD program, and identifying new research areas.",
A simulation based analysis of naming schemes for distributed systems,"As the Internet grows in size and number of users, the way in which resources are identified and accessed becomes increasingly important. This implies the need for an efficient naming service. A naming service is a facility that enables clients to name objects, and subsequently use these names to locate these objects. Developing a naming facility and choosing the naming conventions involves a tradeoff between performance, user friendliness, object mobility, availability of naming information, individual autonomy, storage space requirement, and the cost of maintaining data consistency. The purpose of this paper is to analyze three different naming schemes in a wide area network, and study the impact of design parameters such as transmission capabilities, cache hit ratio, and servers' rate of failure on the performance of a naming facility.",
Trends in computer-based systems engineering,"It is argued that problems in the development of large computer-based systems indicate that a new discipline is needed at the systems engineering level. Designing systems with distributed processing and databases requires analysis of critical end-to-end processing flows to determine feasibility and proper allocation. An expanded skills base would be required to perform either systems, software, or hardware engineers to perform the necessary tradeoff studies. This paper informs managers, engineers, educators, and researchers about the need for computer-based systems engineering and the strategic opportunities this discipline provides for systems engineering improvement.",
Simulating the process of multiattribute choice with neural networks,"In most multiattribute utility models, it is assumed that the analytical forms of the partial and global utility functions are known, and the problem is then one of estimating the parameters of the model. It is shown that a class of neural networks can be used to solve this multiattributable choice problem. The process of multiattribute choice involving a set of alternatives is discussed. An equivalence between the multiattribute utility model, as presented, and an a posteriori probability model, which can be computed by a neural network, is established. This result is applied to a small illustrative example for training a neural network.",
Automatic mapping and load balancing of pointer-based dynamic data structures on distributed memory machines,"Describes an algorithm for automatically mapping and load balancing unstructured, dynamic data structures on distributed memory machines. The algorithm is intended to be embedded in a compiler for a parallel language (DYNO) for programming unstructured numerical computations. The result is that the mapping and load balancing are transparent to the programmer. The algorithm iterates over two basic steps: (1) It identifies groups of nodes ('pieces') that disproportionately contribute to the number of off-processor edges of the data structure and moves them to processors to which they are better connected. (2) It balances the loads by identifying groups of nodes ('flows') that can moved to adjacent processors without creating new pieces. The initial results are promising, giving good load balancing and a reasonably low number of inter-processor edges.",
Self-optimizing avionics: the future of avionics,"Numerous technologies are reaching a maturity level where they will merge and contribute to a new class of military weapons having self-optimization attributes of mission objectives at several levels. Among the technologies are integrated avionics, data fusion technology, data links, computer science, and computer engineering. An overview of self-optimizing concepts is presented along with operational implementation considerations, including network architecture, control of optimization decisions, aircraft configuration options, and affordability. Numerous payoffs within the context of leveraged technology are cited to support the expectations of major initiatives and investments in these concepts in coming years.",
Toward the specification of an ISA for high performance computing engines. I. The hardware perspective,"An instruction set architecture (ISA) is a contract between the compiler that provides, in response to a high level language program, directives for the interpreter to carry out, and the interpreter (microarchitecture) that carries out those directives. Implementation structures of today tend to drive ISA definitions, and in general that is a mistake. From the authors' perspective the ultimate microengine is one constrained only by flow dependencies, so an ISA that facilitates data-flow execution will likely be beneficial even in the face of new microarchitectures.",
Use of Diluted Magnetic Semiconductor in Mmics,,
Triggering mechanism for constraints solving in constraint-based geometric modeling system,"Symbolic and numerical techniques are coupled together in a proposed geometric modeling system. The geometric modeling system is based on geometrical constraints. It is unnecessary to give constraints in the correct order and the ability of replacing incorrect constraints with their inverse constraints exists in the system itself. A new structure, a biconnected constraint description graph, is used. A triggering mechanism for controlling of the constraint propagation is developed for this structure. An algorithm for converting the biconnected constraint description graph into an acyclic constraint description graph is outlined.",
Training dynamics of systems in a variable environment,"The authors describe an approach to bounded training time and robustness in learning systems such as neural networks that is based on the topological properties of an associated flow. The method uses data transformations to create a modified problem for which the desired topological properties hold. A simple example, the two-layer perceptron, is used to illustrate the concepts considered here.",
Methodology to implement an Amoeba complex object server,"The paper describes the methodology used in the design of a complex object server application for the Amoeba distributed operating system. It uses the top-down design that was suggested by Parnas, in which a model is turned into an implementation by gradually adding details. The paper also describes the abstraction levels that show up if going from a specification of the behaviour towards an implementation, and shows the methodology in which performance will be measured (instead of estimated) whereas the system has not yet been functionally implemented in its entirety.",
A system for kinematic analysis of lumbar spine motion,Active lumbar spine movement was acquired and analyzed using a computer controlled data acquisition and analysis system. A 3Space Isotrak was used to record rotational displacement and velocity in three dimensions. The Isotrak was interfaced to a Macintosh computer running LabVIEW software to display real-time kinematic parameters. Results from five subjects showed ranges of motion in the sagittal plane to be in accordance with previous literature reports. This paper is one of the first to analyze the parameter of velocity as a component of lumbar spine motion.,
3D CAD-based inspection. I. Coarse verification,Presents an efficient scheme for CAD-based inspection of objects in range imagery. A template-matching technique is used to compare a random set of surface points from the object model to the sensed object. Several matching statistics are proposed and examined for verification suitability. The authors propose this technique as the first step for coarse verification of an assembled object whose pose and identity are known.,
Dynamic reconfiguration of CSP programs for fault tolerance,"In a distributed computation being performed by a network of communicating processes, failure of a process due to the failure of its host node can cause the entire computation to be aborted. The author proposes a scheme to make a distributed program resilient to the failure of one of its constituent processes. The distributed computation is completed despite the failure of a process. The scheme is for CSP programs and allows nondeterminism within a process. In CSP, the process name is used in input/output commands. Since synchronous communication is used, if a process specified in the input/output command of a process P does not execute a matching output/input command, P might get blocked. In the proposed scheme, if a process fails, another process starts executing on a backup node from the last checkpoint (CP) of the failed process. Programmed exception handling is used to ensure proper recovery and fault tolerance.",
eQuality: a knowledge acquisition approach to process management and decision support tools,"Process management is a method for improving Boeing's business processes, however many aspects have been difficult to implement. eQuality is a software system based on a shell called Axotl that is being designed to support the process management life cycle. The authors take a knowledge acquisition approach to the development of the tool, emphasizing the importance of mediating and intermediate knowledge representations; and also sharing and reuse of knowledge through a layered architecture. eQuality's process documentation capability includes sketchpad views to allow the recording of informal text or graphic information. Model views are used for interactive graphical editing of on integrated business enterprise model. Analysis and simulation tools supporting process improvement are implemented with attribute, function, and task editors that make use of a user scripting language and extensible function library. A virtual project notebook is used to organize project information and help facilitate group meetings.","Decision feedback equalizers,
Knowledge acquisition,
Knowledge management,
Companies,
Costs,
Manufacturing processes,
Job shop scheduling,
Processor scheduling,
Computer aided software engineering,
Computer science"
Concurrency exploitation in data-driven distributed systems,"Studies the effect of the degree of task firing strictness (data availability) on the performance of a data-driven multiprocessing system. A prototype distributed system model, where inherent concurrency is exploited at the procedural level, is discussed. A set of behavioral programs has been simulated, and the speed-up versus the degree of task firing strictness (for different network delays) has been plotted. Simulation shows that, as the degree of strictness is relaxed, more concurrency is exploited in a computation, whence a better utilization of the distributed system resources is achieved.",
Exploiting parallelism in 3D object recognition using the Connection Machine,"The authors show how data parallelism can be exploited at various stages in the recognition and localization of 3D objects from range data. These stages are edge detection, segmentation, feature extraction; matching, and pose determination. Qualitative classification of surfaces based on the signs of the mean and Gaussian curvature is used to come up with dihedral feature junctions as features for matching and pose determination. Dihedral feature junctions are shown to be fairly robust to occlusion and offer a viewpoint-independent modeling technique for the curved objects under consideration. This offers a considerable saving in terms of storing the object models as compared to the viewpoint-dependent modeling techniques which need to store multiple views of a single object model. Dihedral feature junctions are quite easy to extract and do not require very elaborate segmentation. Experimental results on the Connection Machine showed the advantages of exploiting parallelism in 3D object recognition.",
Integrated I&C upgrade plant demonstration status (nuclear plants),"Several utilities are working with EPRI (The Electric Power Research Institute) to develop long range, integrated I&C (instrumentation and control) upgrade strategies and plans for nuclear plants. The background and status of these joint utility/EPRI projects is presented. The overall I&C upgrade process that is emerging is depicted. After the objectives and goals are established, overall requirements, the architecture plan, and the system evaluation process are prepared for a specific plant. The remaining part of the process is then used repetitively to evaluate and implement I&C upgrades in an integrated manner. This provides a process for accomplishing continuous incremental improvement to meet plant goals and objectives.","Modems,
Power generation,
Costs,
Power system reliability,
Guidelines,
Process planning,
Computer architecture,
Safety,
Instruments,
Personnel"
Single row routing with indifference graphs on the DAP,"The distributed array of processors (DAP) is a commercially available massively parallel machine which is often applied to numerically intensive problems which exploit its matrix manipulation abilities. It is shown that the DAP can be efficiently used to solve non-numerical problems as well. Specifically, a heuristic solution to the well-known single row routing problem in a VLSI is proposed. Instances of this problem are modeled using a subclass of interval graphs, and it is shown that this approach leads to efficient algorithms. sequential and parallel. Both algorithms were implemented, the sequential providing a benchmark by which to measure the speed-up of the parallel implementation on the DAP 510.","Routing,
Digital audio players,
Circuits,
Joining processes,
Wire,
Computer science,
Parallel machines,
Transmission line matrix methods,
Very large scale integration,
Velocity measurement"
Hierarchical interconnection networks: routing performance in the presence of faults,"The authors develop a Markov model which can effectively estimate the successful routing probability and internode distance of hierarchical interconnection networks in the presence of faults. A BH/BH (binary hypercube/binary hypercube) network is tested using the model and verified by computer simulations. Comparisons with computer simulation reveal that the proposed model is very accurate. The network performance, when all nodes generate messages, is also expected to be effectively evaluated with the model.",
An elliptical orbit backprojection filtering algorithm for SPECT,"An orbit geometry where the central projection ray of the detector does not pass through the center of rotation for all projection angles can be useful for reducing uniformity artifacts, and, more importantly, for avoiding truncation when imaging the heart with converging collimators. A backprojection filtering algorithm for an elliptical orbit geometry is presented. It is shown that the point response function for parallel geometry is shift-invariant and is equal to l/r modulated by the orbit geometry. The algorithm is verified by computer simulations.",
Exponential stability of additive neural networks,"Exponential and stochastic stabilities of additive neural networks are analyzed. The results are especially suitable for asymmetric neural networks. A constraint on the connection matrix has been founded under which the neural network has a unique and exponentially stable equilibrium. Given any real matrix, this constraint can be satisfied if the gain coefficients and resistances in the neural net circuit are suitably adjusted. A one-to-one and smooth map between input currents and the equilibria of the neural network can be set up. The uniqueness results can be applied to analyze the master/slave net. For the neural network disturbed by some noise, the stochastic stability of the network is also discussed.",
Forming an information technology department in turbulent times,"The goals, objectives, characteristics, prerequisites, and courses of an information technology curriculum developed at the University of Veszprem in Hungary are discussed. Basic, introductory, and core courses as well as special subjects are listed, and the program schedule of the five years is presented. The place and role of information engineering in a changing world is discussed, including some thoughts on the role of information technology in the general university curricula.","Information technology,
Laboratories,
Education,
Educational technology,
Automation,
Europe,
Mechanical engineering,
Electrical engineering computing,
Informatics,
Solids"
Knowledge with real-time semantics,"A method of incorporating real-time semantics in production rules, thus making them suitable for representing knowledge of a real-time expert system, is presented. It is intended that the knowledge representation should allow the incorporation of time-dependent heuristics and dynamic models in the knowledge base. An illustration of this method, the NetManager expert system, is noted.",
Improved trinary associative memory for character recognition,"Character recognition by a trinary associative memory (TAM) neural network model is investigated. Three different inner product thresholding schemes, namely, zero plus average thresholding, arithmetic mean thresholding, and a novel adaptive thresholding are examined. It was shown by a simulation that the novel threshold prescription scheme with the permanent inhibition scheme enhanced the convergence as well as storage capacity of the inner product associative memory.","Associative memory,
Character recognition,
Vectors,
Convergence,
Arithmetic,
Pattern recognition,
Computer science,
Neural networks,
Information retrieval,
Optical character recognition software"
Acoustic propagation modeling using the extended angular spectrum method,"The extended angular spectrum method is a technique for modeling the propagation of acoustic fields between parallel planes. The technique may be used to predict an acoustic pressure field distribution over a plane, based upon a known pressure field contour at a parallel plane. The technique has been used to ""backward propagate"" measured fields to determine the particle velocity distributions at transducer surfaces. However, the results of comparing ""forward propagated"" fields with those measured have been less successful. Recently improvements have been made to the model and to the associated experimental system which have greatly improved the forward prediction ability. The results demonstrate the ability of the extended angular spectrum method to accurately predict acoustic field contours in the forward propagation case.","Acoustics,
Acoustic measurements,
Particle measurements,
Atmospheric measurements,
Transducers"
Modularity for logical knowledge bases,"The author argues that modularity is essential for the design, verification, and maintenance of large-scale knowledge based systems. Motivated by work on software modules and algebraic specification, he introduces a module concept with formal interfaces, and gives semantics and correctness notions for such modules based on logic programming. Single modules communicate with their environment by their interfaces. He discusses how modular systems can be built from single modules by means of so-called module operations, and derive for the composition operation results concerning compositionality of semantics and correctness preservation.",
Numerical Performance of Two-Sided Linear Prediction,,
On the number of solutions of resistive circuits containing operational amplifiers with saturation,"Some conditions are given for a nonlinear equation F(X)+AX=b of a resistive circuit including linear resistors and operational amplifiers with ideal saturation characteristics to have several specific types of solutions. The concern is mainly with solutions lying in the saturation regions of the amplifiers. These solutions can be regarded as equilibrium points, of some dynamical circuits including Hopfield networks.",
Load balancing in the fine-grained object-oriented language Ellie,"The paper presents the main goals of the Ellie project which have been to design and implement a general, powerful, fine-grained, object-oriented, programming language intended for machine independent programming of distributed memory parallel computers. The implementation includes operating system facilities for message routing and load balancing. The main subject of the paper is load balancing suitable for fine-grained processes/objects. Assisting compile-time information and grain-size adaption are suggested. To realize what kind of load balancing problems Ellie introduces, the paper also describes the relevant Ellie facilities. Ellie has been implemented on a network of 16 transputers and an annotation system is provided for load balancing experiments.",
Adaptive control and identification of nonlinear system according to the procedure of distributed parameters,"Parameter identification of block oriented nonlinear systems containing continuous nonlinearities is presented. The procedure, based on the recursive least squares identification algorithm, is presented. The entire input signal area is divided into the N sections. For each section, there exists one line in the matrix of parameters. The use of covariance matrix resetting and the combinations of forgetting factors yield good simulation results. The procedure is used for adaptive control of nonlinear processes. The results obtained are demonstrated for a model air flow control device. Advantages and disadvantages of the proposed solution are discussed.",
The parallel complexity of minimizing column conflicts,Two-layer channel routers typically require a post-processing phase to reduce or eliminate column conflicts. Attempts have been made to parallelize this problem using local search heuristics that swap horizontal channel wire segments. The authors show that all such heuristics for this problem are P-hard and unlikely to be efficiently parallelizable.,
Computer-assisted instruction development model for a computer concepts course,"Describes the computer-assisted instruction (CAI) model used for the development of courseware that forms part of the tutorial package for the computer concepts course at the University of South Africa. The courseware design model which was followed consisted of five phases: preparation for the project, predesign, design, programming and formative evaluation, and summative evaluation.",
Distributed and Optimistic Make: implementation and performance,"Two enhanced versions of the Make utility compatible with the conventional version were developed, namely Distributed Make and Optimistic Make. Distributed Make uses the idle CPU cycles in a network of workstations to improve response time by running compilations concurrently on lightly loaded remote workstations. Optimistic Make runs in the background while the user is editing. When the user saves a file, any targets that are rendered out-of-date are recompiled even while the user continues editing. Thus, when the user finishes the editing session, most of the compilations have already been done. The performances of these two versions of Make were evaluated in a network of SUNs. Distributed Make was found to achieve a close to linear speedup in certain cases. Optimistic Make reduced response time by a factor of 2-7 with little degradation in editor response. Thus, both significantly reduce the program development cycle.",
An integration of neural learning and rule-based systems to mechanical assemblies,"A system that integrates design and planning for mechanical assemblies is presented. The system integrates neural network computing that captures the designer's design concept and rule-based system to generate a task-level assembly plan automatically. The design concept is expressed by a standard pattern format representing qualitative assembly information. A neural network model together with a feature-based model translates the input pattern into a preliminary boundary representation (B-rep). Based on a refinement B-rep assembly representation, assembly plans are generated for practical use in a single-robot assembly workcell. A feasible assembly plan that minimizes tool changes and subassembly reorientations is generated from the system.",
Stereo correspondence by surface segmentation,"The authors present a new algorithm for stereo matching which makes use of simultaneous feature matching, surface reconstruction and segmentation. Each of these three phases is described. The algorithm integrates these three related subprocesses in the process of extracting surfaces from stereo data. The integration is synergetic: the whole is greater than the sum of the parts. After the segmentation phase, each segmented surface is bounded by a closed boundary. The algorithm yields a rich description of a scene in terms of global surface patches and closed surface boundaries. Experimental results are included for a pair of stereo images of an aerial view of the Pentagon building.",
Attribute grammar for shape recognition and its VLSI implementation,"Shape recognition has wide applications in many fields. An attribute grammar approach to shape recognition combines both advantages of syntactic and statistical methods and makes shape recognition more accurate and efficient. However, the time complexity of a sequential shape recognition algorithm using attribute grammar is O(n/sup 3/) where n is the length of an input string. The paper presents a parallel shape recognition algorithm and its implementation on a fixed-size VLSI architecture. The proposed algorithm has time complexity O(n/sup 3//k/sup 2/). Experiments have also been conducted to verify the performance of the proposed algorithm. The proposed algorithm and architecture could be very useful for image processing, pattern recognition and related areas.",
Methodology for establishing a 'gold standard' (for a medical expert system),"Presents a statistical method for establishing a consensus diagnosis among several experts, which is the common 'gold standard' used for evaluating the diagnostic performance of a medical expert system. This method involves the use of the extended kappa statistic developed by J.L. Fleiss (1971) and R.J. Light (1971) in the social sciences for the study of a similar problem. The method is carried out in two stages. First, the existence of an overall agreement or disagreement among the medical experts in their diagnoses of a sample of patients is established. Second, in the case of overall agreement, one selects the particular disorders that have a significant level of agreement among the experts, and uses the experts' diagnoses as the 'gold standard' for the sample of patients that were classified in those disorders.",
Using a functional language and graph reduction to program multiprocessor machines or functional control of imperative programs,"Describes an effective means for programming shared memory multiprocessors whereby a set of sequential activities are linked together for execution in parallel. The glue for this linkage is provided by a functional language implemented via graph reduction and demand evaluation. The full power of functional programming is used to obtain succinct, high level specifications of parallel computations. The imperative procedures that constitute the sequential activities facilitate efficient utilization of individual processing elements, while the mechanisms inherent in graph reduction synchronize and schedule these activities.",
Adaptive methods and rectangular partitioning problem,"Partitioning problems for rectangular domains having nonuniform workload for mesh-connected SIMD architectures are discussed. The considered rectangular workloads result from application of adaptive methods to the solution of hyperbolic differential equations on SIMD machines. A new form of the partitioning problem is defined in which sub-meshes of processors are assigned to tasks, each task being a discretized rectangular sub-domain. The work per processor (i.e. the work density) is balanced among the K sub-rectangular meshes of processors. First, a formalization of the 1D problem is given and a O(Kn/sup 3/) time and (Kn/sup 2/) space optimal algorithm is proposed. A more efficient heuristic algorithm is also given for the 1D problem. Finally 2D heuristics are developed by projecting the weights on to a 1D array.",
Evaluation of overflow probabilities in resource management,"In a number of network and database management applications, an upper bound has to be evaluated on the probability that the capacity of a server will be exceeded. The authors refer to this probability as the overflow probability of the server. The problem is, in essence, determining the probability that the sum of N independent random variables exceeds a given threshold. Evaluation of the overflow probability by brute-force enumeration requires a computation time which increases exponentially with N, so attempts have been made to approximate the overflow probability using Chernoff bounds. They present a simple scheme that can be used to evaluate the overflow probability with higher accuracy and lower computational effort than the Chernoff bounds approach. A set of algorithms is presented in C-like pseudocode that can be used to evaluate the overflow probability.",
Congrats: a system for converting graphics to sound,"Describes a prototype implementation of the Congrats system. The prototype which the authors have built is only a small subset of the actual system, and is meant more to show what can be done using sound and elucidate the concepts involved. When complete, it will provide a whole new range of educational aids for the visually impaired, and thereby open up subjects that have till now remained inaccessible.",
Bit-string optimization in a brachytherapy dosimetry problem,"A problem in radiotherapy planning is solved by applying the following search algorithms: artificial genetic search, with fixed crossover probability, with variable crossover probability, and with cut-point distribution; simulated annealing, serial and parallel; stochastic hill-climbing; next-ascent hill-climbing; and steepest-ascent hill-climbing. Given a number of points at each of which a predetermined dose of radiation is required, the problem is to optimize the settings of the radiation sources present in each of three directions (X, Y, and Z) in a three-dimensional selection device such that the sum-squared dose variation is minimized.",
Distributed program reliability analysis,"This paper presents an algorithm for computing the distributed program reliability in distributed computing systems (DCS). The algorithm, called FREA (fast reliability evaluation algorithm), is based on the generalized factoring theorem with several incorporated reliability-preserving reductions to speedup the reliability evaluation. The effect of file distributions, program distributions, and various topologies on reliability of the DCS is studied in detail using the proposed algorithm. Compared with existing algorithms on various network topologies, file distributions, and program distributions, the proposed algorithm is much more economic in both time and space. To compute the distributed program reliability, the ARPA network is studied to illustrate the feasibility of the proposed algorithm.",
An integrated approach towards a distributed simulation tool for digital designs,"The use of simulation tools for determining the functional correctness of a digital design and to ensure an acceptable level of design confidence is in widespread use. The distributed synchronous simulation principle offers a chance for simple, efficient coding of operational models of a design as well as clearly understood communication. A language PSL for describing design-modules has been developed, especially tailored for compiling those modules to highly efficient synchronous occam processes. With regard to enforcing easy re-use of declared modules, the structure of interfaces of the generated occam-procedures has been unified. A communication concept is developed which offers dead-lock-free message-transfer without buffering and flow-control facilities for a distributed system of synchronous processes.",
A Force Directed Hill-Climbing Placement Algorithm,,
A controlled study of the suitability and limitations of static modeling of speech,"A static model (SM) in the form of a single vector is proposed to represent the temporal properties of a sequence of speech feature vectors. In contrast to a hidden Markov model which captures the conditional probabilities of state transitions of consecutive observations x/sub t/ and x/sub t+1/ over time, an SM captures their average joint probabilities of belonging to a pair of phonetic classes omega /sub i/ and omega /sub j/ without any Markovian assumption. An artificial vocabulary of ten words is designed to study the limitations of SM. Experimental results indicate that apart from a rather mild limitation of SM in handling certain types of vocabulary, SM performs better in terms of recognition rate as far as isolated word recognition is concerned.",
Third order matching is decidable,"The problem of determining whether a term is an instance of another in the simply typed lambda -calculus, i.e. of solving the equation a=b where a and b are simply typed lambda -terms and b is ground, is addressed. An algorithm that decides whether a matching problem in which all the variables are at most third order has a solution is given. The main idea is that if the problem a=b has a solution, then it also has a solution whose depth is bounded by some integer s depending only on the problem a=b, so a simple enumeration of the substitutions whose depth is bounded by s gives a decision algorithm. This result can also be used to bound the depth of the search tree in Huet's semi-decision algorithm and thus to turn it into an always-terminating algorithm. The problems that occur in trying to generalize the proof given to higher-order matching are discussed.",
"An efficient object-based algorithm for spatial searching, insertion and deletion","The authors propose an object-based index structure for manipulating spatial objects with non-zero size. They introduce the main ideas of the proposed index structure. A detailed description of the algorithms is given for searching, insertion, and deletion in a database system with a high frequency of retrievals and a low frequency of insertions and deletions. The algorithms are then described for retrievals, insertions, and deletions for a database system with a nearly equal frequency of retrievals, insertions and deletions.",
Computer-based nuclear radiation detection and instrumentation teaching laboratory system,"A computer-based nuclear radiation detection and instrumentation teaching laboratory system has been developed at the University of Florida for use in its Nuclear Engineering Sciences teaching laboratories. The system is based on the innovative use of Macintosh II microcomputers, the IEEE-488 communication and control bus system (and protocol), compatible nuclear instrumentation modules (NIM), test equipment, and LabVIEW 2 graphical software, applications software and locally prepared, interactive, menu-driven HyperCard based multiexercise laboratory instruction sets and procedures. The laboratory teaching station concept entails using the computer to establish a 'man-machine interface/communications system' that can provide user-friendly instructions and online instrument control for system setup, test, data acquisition, storage, analysis, plotting, and laboratory report preparation.",
Flow Control and Routing Algorithms in Packet-Switched Networks,,
Constraint checking for circular restriction site mapping (DNA),"Computationally, constraint checking for circular restriction site maps is considerably more difficult than for linear maps. The authors consider complete single and double digestions of plasmids, circular DNA molecules. To allow for experimental error in fragment measurements, a range is specified for each fragment length. The authors find exactly those solutions that satisfy the discrete constraints of the date. For sites s/sub i/ and s/sub j/ they consider linear inequalities in either of the forms L/sub ij/",
An heterogeneous M-SIMD architecture for Kalman filter controlled processing of image sequences,"The use of a heterogeneous multiple-SIMD (M-SIMD) architecture with image-based measurements and optimal (Kalman) estimators for the analysis of image sequences is illustrated. The architecture integrates SIMD and MIMD processing paradigms, combining heterogeneity of processor types matched to the computation at each level and operational autonomy within an SIMD array. It is suited to real-time simultaneous data parallel (iconic) and control parallel (numeric) processing.",
Rapid prototyping in an object-oriented pictorial dataflow environment,"Object-oriented programming is proving to be quite useful in several areas which have not been served well by more conventional languages. Rapid prototyping is one such area in which the object-oriented approach shows great promise. Adding pictorial features to an object-oriented environment greatly facilitates the display of the various objects, methods, and relationships involved in the system. Combining this with a dataflow language results in a system which is nearly ideal for the rapid prototyping of software systems utilizing dataflow diagrams. Prograph is a language which sports all three of these features. The authors present an overview of a rapid prototyping effort, in Prograph, of a fairly complex software system in which the prototype was quickly and easily designed from the system dataflow diagrams.",
Elaborated Rank Order Processors with a Band-Pass Effect,,
Connectionist acoustic word models,"Other researchers have claimed significant improvements to their recognizers by using word models based on data-driven subphonetic units rather than traditional subword models. A possible advantage of this approach is that subphonetic models can be derived automatically from the data, so that the recognizer is trained to discriminate between acoustic categories. The authors describe some of the problems with the units that are derived from acoustic-phonetic considerations (when used for a hidden-Markov-model-based recognizer), and propose a novel technique for constructing acoustic word models using a multilayer perceptron (MLP). The authors are designing a subphonetic unit called the UNnone which is similar to fenones. A vector quantizer is used to partition the acoustic space into a set of clusters. Once the vector quantizer has been designed, the training vectors are compared to the reference vectors using a Euclidean distance measure. The label corresponding to the closest reference vector is assigned to the input vector. These labels are used as targets for training the MLP.",
Selective scene modeling,Proposes an efficient architecture for selective image modeling. The authors give an example in which models of different scale are reconstructed in parallel. It is shown that this redundant representation can effectively be pruned using the criterion of minimum description length. Models that are selected in the final description indicate the appropriate scale of observation.,
An edge-adaptive iterative method for image restoration,"The paper proposes an edge-adaptive iterative method for restoring a blurred image. An original image is represented as a multiple image model composed of four kinds of edge regions and a flat region. The image is restored with the maximum a posteriori (MAP) criterion, which is realized by the steepest descent technique. The parameters of the original image and edge orientation are estimated from the image temporally restored by a deconvolution method. Computer simulations show that this method suppresses ringing artifacts near sharp edges and avoids smoothing edges in the cases of a motion blur and an out-of-focus blur.",
Some new techniques for evidence-based object recognition: EB-ORS1,"The authors have extended the evidence-based object recognition system of Jain and Hoffman (1988) to include some new view-independent features, a new optimized rule generation procedure based upon minimum entropy clustering and a neural network which estimates optimal evidence weights and provides an associated matching procedure. This approach provides an objective definition of the difficulty of an object recognition problem. The authors also evaluate the procedures and performance of the system with two sets of CAD (range) models.",
On minimum-bend single row routing,"The objective function of the problem is to minimize the number of doglegs (or bends) per net. The approach is based on graph-theoretic representation in which an instance of the single row routing problem is represented by three graphs: an overlap graph, a containment graph, and an interval graph. Using this graph representation, three algorithms are developed. It is shown that the algorithms have very tight performance bounds. In particular, it is proved that the maximum number of doglegs per net is bounded by O(k), where k is the size of the maximum clique in a certain graph representing the problem.",
An error-detectable array for all-substring comparison,"All-substring comparison for pattern P and string S gives the minimum distance between P and all the consecutive substrings in S, which is more general than usual string comparison problems. Run-time error detection is a desirable property in practice. The author designs an error-detectable systolic array for the problem of all-substring comparison, and analyzes the performance of the design. He incorporates a novel design methodology, called ITRED, in the design. By using this methodology at the dependency graph level, tests are triggered in the inputs by users, so this approach gives the users flexibility in trading off throughput for error coverage. Little extra hardware is required in this approach.",
TM-scattering from a rectangular channel in a conducting plane,"Transverse magnetic (TM) plane-wave scattering from a rectangular channel engraved in a perfectly conducting plane is investigated. A Fourier-transform technique is employed to express the scattered field in the spectral domain in terms of parallel-plate waveguide modes. An approximate series solution for scattering is presented in a closed-form which is valid for the high-frequency scattering regime. Approximate solutions which are valid for the quasi-static and low-frequency scattering regimes are also obtained. Using the stationary phase approximation, the far-zone scattered field is obtained and its scattering behavior is studied in terms of the scattering angle, frequency, and channel size.",
An Efficient Systolic Architecture For Qmf Filter Bank Trees,,
IEEE P1232 AI-ESTATE: the standard for test related AI applications takes shape,"In February 1990, the IEEE approved Project Authorization Request (PAR) 1232, authorizing the IEEE SCC-20 (ATLAS) Committee to begin development of a new test standard, AI-ESTATE. AI-ESTATE stands for the artificial intelligence-expert system tie to automatic test equipment. The author defines AI-ESTATE and discusses its background, long-term goals, and architecture, its current status, and the committee's plan of action for continuing development of the standard. AI-ESTATE will define the interfaces between any test related reasoning system, its users, target test equipment, and external knowledge bases and databases. AI-ESTATE will also define several test related knowledge bases and databases, including fault trees and information flow models.",
An accurate measuring system for VTR magnetic track,,
IEEE Transactions on Software Engineering,,
A path-oriented matrix-based knowledge representation system,"Most AI search/representation techniques are oriented toward an infinite domain of objects and arbitrary relations among them. In reality much of what needs to be represented in AI can be expressed using a finite domain and unary or binary predicates. Well-known vector- and matrix-based representations can efficiently represent finite domains and unary/binary predicates, and allow effective extraction of path information by generalized transitive closure/path matrix computations. In order to avoid space limitations in this approach, a set of abstract sparse matrix data types was developed along with a set of operations on them. This representation forms the basis of an intelligent information tool for representing and manipulating relational data. The tool is being used in developing a system that helps flight crews cope with in-flight malfunctions.",
Reviewing recovery-management under real-time requirements in distributed systems,"Dependencies between computations may lead to unpredictable behaviour of the commit/abort protocols possibly contradicting given real-time requirements. Moreover, it is even possible that the protocols do not terminate. By using redundant dependency storing and by restricting concurrency without isolating computations from each other efficient commit/abort protocols can be provided. Obviously, there exists an alternative to the isolation of computations in distributed real-time systems which allows more concurrency between computations.",
A semi-custom multi-channel preamplifier integrated circuit for spaceborne nuclear instrumentation,"A monolithic eight-channel preamplifier for spaceborne nuclear instrumentation is being developed using a semicustom application specific integrated circuit (ASIC) based on bipolar tile-array technology. This general-purpose charge-sensitive bipolar octal preamplifier (BOP) was designed using a complementary current mirror approach so that it would be useful for amplifying both positive-going and negative-going input pulses while consuming low to moderate power. The input stages use a common-collector/common-base topology for good bandwidth and slew characteristics. The output stages use power devices configured as class AB and are capable of driving 50- Omega loads. Each of the eight channels can be biased or enabled separately. The design is implemented with dielectrically isolated, vertical geometry transistors. Such devices are inherently radiation-hard and have PNP transistors whose performance is superior to that of the lateral geometry types. The availability of dielectrically isolated topologies allows such devices to be usable in an environment where total dosages can be as high as 1 Mrad. Computer simulations of the BOP in various configurations show that design requirements were met.",
Design of an integrated query and manipulation notation for database languages,"A common task in data intensive applications is to locate a group of items and then manipulate them, e.g. to give a bonus to all of the employees in a department. Conventional relational query languages like SQL provide facilities for such manipulation-queries, but are not smoothly integrated with a programming language and lack computational power. It has been argued that comprehensions, a construct found in some languages, are a good query notation for database programming languages. An extension to comprehensions is proposed that permits the data to be manipulated by side-effect in addition to being queried. These side-effecting queries are computationally powerful and smoothly integrated into a database programming language, unlike conventional relational query languages. Furthermore side-effecting comprehensions are concise and some may be automatically optimized.",
Competitive learning in asynchronous pulse density integrated circuits,The authors introduce a MOS circuit for the integrated implementation of pulse-coded competitive learning. They describe an autoadaptive synapse circuit for a pulse-coded competitive learning rule. The specific focus is upon an adaptive synapse cell which combines a capacitive analog storage element with subthreshold adaptation circuitry. The adaptation circuitry is designed to compensate for nonlinear device transconductance in the subthreshold operating region. The simulation results presented verify circuit operation in a 2-input-3-output competitive network. Accurate clustering of random training data was demonstrated.,
H∞ suboptimal controller design via transfer recovery,An approach based on observer theory to obtain H∞ suboptimal controllers is presented in this paper. An H∞/LTR output feedback design procedure is shown to consist of one H∞ state feedback design and one frequency-shaped state estimator design.,
Optimal deterministic task distribution for multiprocessors,"Considers the problem of distributing tasks on a multiprocessor network. Some processors cannot accept any tasks, hence the problem is formulated as one of routing packets from an arbitrary subset S to an arbitrary subset T, where the exact target node for a particular packet is unspecified. The solution presented matches n2/sup n/ tasks to target nodes in O(logn) time-on a butterfly, using a deterministic routing and with low (<10) constant factor. As a corollary, the paper also obtains a simple solution to the (n, K) token distribution problem.",
The Nucleus-microkernel for the RHODOS distributed operating system,"New architectural approaches are required in the design of distributed operating systems, to meet the requirements of openness and high performance. One approach is to build the distributed operating system as a set of independent system servers, cooperating through a small set of primitive operations provided by a microkernel. The Nucleus is the microkernel of the RHODOS system. It is explained why a microkernel-based design was chosen. The features and advantages of the system are reported, and the Nucleus data structures and other services provided to facilitate the microkernel abstraction are described.",
Debugger visualization techniques for parallel architectures,"The author outlines the requirements for debugger visualizations and describes the difficulties involved in devising graphical techniques which reduce the complexity of parallel behavior to manageable proportions. Examples are presented which demonstrate that visualization techniques can elucidate several aspects of run-time behavior. In this sense, they can improve the usefulness of parallel debugging tools: the application of specialized representational schema facilitates the recognition of patterns which would be hidden in any textual report. This allows the human programmer, adept at identifying visual anomalies, to isolate behavioral problems more quickly and accurately.",
Recognition using motion and shape,Presents a method for matching sets of trajectories which supplements motion information with knowledge about the spatial relationships between points on the moving object. First the authors present a simple algorithm which matches two single trajectories using only motion information. They convert the 2D motion trajectories into two 1D signals based on the speed and direction components. The signals are then represented by scale-space images both to simplify matching and because the scale- space representations are translation and rotation invariant. They extend the matching algorithm to include spatial information and propose a second algorithm which matches multiple trajectories by combining motion and spatial match scores. Both algorithms were tested with real and synthetic data.,
Visualization of hypercube pedagogical parallel programs,"Examines algorithm animation requirements for the various visualization purposes and extends the capabilities of any existing facilities, the AFIT Algorithm Animation Research Facility (AAARF). The structure of AAARF is summarised and its visualization capabilities presented and analysed. This analysis focuses on the parallel data requirements of the AAARF users, and the meaningful display of large amounts of data. This paper discusses a series of refined animations suitable for a variety of purposes which are capable of conveying detailed information in a concise and timely manner. These animations are built upon pedagogical efforts in a classroom environment. The educational merits of AAARF are discussed in terms of demonstrations, algorithm analysis, and program debugging. To assist novice users in accomplishing these tasks with AAARF, an 'expert system' interface has been implemented to advise on optimizing the environment configuration. Other AAARF improvements are also mentioned, which extend the capabilities of this public domain package.",
Reflections on CAEME software and new developments towards software implementation in classroom teaching,"The NSF/IEEE Center for Computer Applications in Electromagnetics Education (CAEME) has been in operation for two years. It has funded 19 software development projects, organized several workshops and special sessions, and published a book that includes diskettes and videos of the developed software. Features of the first CAEME software book are reviewed and procedures for its integration in classroom teaching are discussed. Specific examples illustrating the use of modern technologies such as interactive video to help develop educational aids to integrate CAEME software in classroom teaching are demonstrated.",
Problem specific environments for parallel computing,"Considers general-purpose and problem-specific tools for parallel problem solving. A comparison is made between the two approaches, in terms of effort and usefulness, for two example problems. The advantages of special-purpose, problem-specific environments are described, and the effort required to construct such environments is seen to be reasonable.","Parallel processing,
Problem-solving,
Concurrent computing,
Programming profession,
Software tools,
Computer science,
Software debugging,
Software performance,
Design optimization,
Monitoring"
Simple algorithms for tracing solution curves,The author presents some simple and practical algorithms for tracing implicitly defined solution curves. These algorithms use hyperspheres instead of hyperplanes that are used in the typical predictor-corrector algorithms. Effective techniques for preventing the reversion phenomenon of the curve tracing are also proposed. The proposed algorithms are geometrically clear and can be easily programmed. It is also shown that the algorithms can be easily implemented on existing circuit simulators such as SPICE.,
Experimental study and PIC-simulation for the PCM operation,"The results of computer simulation for the PCM and the PCA operations are reported. The plasma annulus is considered to be cold, collisionless media (rp = 0.9 cm, δp = 0.1 cm, Lp = 30 cm, R = 1.8 cm) with dielectric constant εp = (1 - ωp2/ω2). The microwave power must be amplified by REB is generated by the M-band magnetron: λ = 2.71 cm, P = 150 kW. The hollow high-current REB (γ = 2.2) is PIC-simulated for the case of its injection into the plasma annulus. The electromagnetic fields are resulted from the numerical solving of Maxwell equations. This simulation showed that there exists the microwave generation at the wavelength λ - 3 cm. Moreover, the generation wavelength decreases as the plasma density increases. The microwave power generated is of about tens megawatts for the REB current of 2 kA. The maximal efficiency is of about 5%. The excitation of the co-axial plasma waveguide by the external wave with microwave power of 100 kW leads to the increase in the output microwave power within narrow region of plasma density. This takes place if the the input frequency is coincident with the one of wave inherently generated. Also we present the experiment for the PCM operation and the preliminary experiment devoted to the PCA operation.",
Multiple tree quorum algorithm for replica control in distributed database systems,"A novel replica control algorithm, called the multiple tree quorum (MTQ) algorithm, is proposed to manage replicated data in distributed database systems. This algorithm provides a high availability for read and write operations by imposing a logical structure of multiple trees on data copies. With the MTQ algorithm, a read operation is limited to a couple of data copies, and a write operation is allowed as long as the majority of the roots of the trees and the majority of the children of each node selected are available. Compared to other algorithms, the MTQ requires lower message cost for an operation while providing higher availability.",
Mixing list recursion and arithmetic,"A procedure that constructs mechanically the appropriate lemmas for proving assertions about programs with arrays is described. A certain subclass of formulas for which the procedure is guaranteed to terminate and thus constitutes a decision procedure is exhibited. This subclass allows for ordering over integers but not for incrementation. A more general subclass that allows for incrementation, but without the termination property, is considered. It is also indicated how to apply the method to a still more general subclass that allows for full arithmetic. These results are extended to the case in which predicates have more than one list argument.",
Load information distribution via active interconnection networks,"Existing multicomputers typically use passive, dedicated network interfaces. By comparison, an active interconnect network can manipulate the data in messages transitting through a node; these might use existing systolic processors as the network interface. Active interconnects will become increasingly common in distributed memory multicomputers because they can be used to implement a variety of routing algorithms, reduction operators and efficient memory-fetch operations. The authors measures the effectiveness of distributing load information using active interconnection networks. He does not expect the benefits of distributing load information to solely justify the existence of active interconnection networks; rather, he foresees that active networks will shortly be commonplace, and seeks to measure their benefit for tightly coupled distributed operating systems.",
A RISC/UNIX workstation second stage trigger,"Recent advances in reduced-instruction-set computer (RISC) workstations have greatly altered the economics of processing power available for experiments. In addition, VME interfaces available for many of these workstations make it possible to use them in experiment front ends for filtering and compressing data. Such a second-stage trigger has been implemented at LAMPF (Clinton P. Anderson Meson Physics Facility) using a commercially available workstation and VME interface. The implementation is described, and measurements of data transfer speeds are presented.",
A generalization of discrete hidden Markov model and of Viterbi algorithm,"The concepts of composite and basic symbols and composite and basic states are introduced and a generalized hidden Markov model is defined to allow variable length and depth of dependency. A recursive function is defined to compute the probability distribution of the transitions from basic or composite states to composite states. The Viterbi algorithm is generalized to compute the optimal state sequence given an observation sequence of length T with time cost of O (T*(max.(N, N/sub c/))/sup 2/), where N and N/sub c/ are the numbers of basic states and composite states respectively.","Hidden Markov models,
Viterbi algorithm,
Probability distribution,
Text recognition,
Signal processing algorithms,
Computer science,
Distributed computing,
Cost function,
Speech processing,
Signal processing"
Performance prediction of message passing SIMD multiprocessor systems,"The paper focuses on two points: (1) the prediction of the execution signature of massively parallel applications prior to execution/implementation based on a more informative characterization of the workload, and (2) the definition of a more general form of speedup and efficiency. The systems considered are of SIMD message passing paradigm.","Message passing,
Multiprocessing systems,
Parallel algorithms,
Topology,
State estimation,
Computer science,
Educational institutions,
Application software,
Matrix decomposition,
Concurrent computing"
The Minnesota Imaging Project research application for understanding an emerging technology,"The Minnesota Imaging Project (MIP) is a joint academic-practitioner research program at the Carlson School of Management. The MIP research team consists of individuals with diverse and significant experience with imaging, supported by group decision support systems (GDSS) technology. The MIP team is implementing a research application as the means to investigate several research issues. The project is evaluating a new phased, joint development methodology designed for new technologies. The research application has several characteristics that will permit it to be developed and studied on a small scale, and yet generalized to a broad set of applications: groups of knowledge workers that work together, frequently dispersed in time and place, focusing on the paper-based information they use, with modest amounts of file folder and workflow, and with important indexing and retrieval requirements. The research subjects are: the GDSS and the Rhetoric faculty teams, and the MIP research team.","Productivity,
Computer applications,
Project management,
Technology management,
History,
Decision support systems,
Design methodology,
Indexing,
Information retrieval,
Rhetoric"
Using qualitative bond graph reasoning to derive look-up tables for fuzzy logic controllers,"Qualitative reasoning, bond graphs and fuzzy logic are developed respectively in three different fields: computer science, system dynamics and automatic control. They all have their own strengths and weaknesses. Fortunately, these methods are compensating and they can be used to offset each other's weaknesses. Qualitative reasoning on bond graphs leads to ambiguities in its reasoning process while these ambiguities can be resolved by self-organising fuzzy logic through employing the system identification approach to articulate models. On the other hand, fuzzy logic treats a system as a black box and does not use any structural information, while qualitative reasoning on bond graphs contains this information and can be used to systematically derive look-up tables in fuzzy logic. The paper presents a method of using structural information to generate look-up tables, which will then be used for fuzzy logic control. An example is analysed to explain the concepts.",
Electronic mail in broadcast networks,"The authors discuss benefits and problems of the use of satellite networks for electronic mail applications, with emphasis being put on group communication problems. A brief survey of the message handling system is given first. This is followed by an introduction to related addressing issues. Two different conceivable scenarios incorporating satellite systems are examined. It is shown that satellite networks provide for some features which particularly help to reduce the network load in the case of intensive use of group communication services.",
An expert system approach for interface management in decision support systems,"Recent developments in decision support systems (DSSs) design suggest that as the capabilities of systems expand, the need for designing effective and flexible interfaces increases significantly. However, little research has been done in the area of interface management in DSS. This paper examines the role of user, task, and system characteristics in determining display methods, and advocates an expert system approach to system-user interface management within the context of a DSS. The authors present the architecture of such a system-expert system interface manager (ESIM)-discuss a prototype implementation, and identify areas for future research.",
An error correcting algorithm for Hopfield network,"The principle and the weakness of the Hopfield network are discussed. It is found that the assumption that the Hopfield network made on the noise effect of input patterns is inappropriate and an adaptive training algorithm that minimizes the noise effect of the input patterns is presented. This algorithm alters the connection weights of the network. It is shown that the storage capacity of the resultant model increases from 0.16n to greater than 1.14n, where n is the number of neurons in the network. Moreover, the model has a higher error tolerance level than the original model.",
Comparison of ID3 and its generalized version,"A generalized ID3 learning algorithm, which possesses more processing capabilities than the original ID3, is proposed. This generalized ID3 learning algorithm can manage uncertain training instances and consider the different importance of different training instances in finding an appropriate decision tree in a noisy environment. If appropriate priori domain knowledge is available, this algorithm can further utilize it in reducing the effect of noise. Relations on generality, accuracy, tree complexity and time complexity of ID3 and generalized ID3 are also discussed, with experiments verifying their correctness.",
The importance of the orientation of the polymer membrane hydrophone in the acoustic field,"The performance of spot poled PVDF membrane hydrophones was examined. It was found that the sensitivity of the hydrophone is markedly dependent on the spatial polarization distribution. In addition, the experimental data show there can be a significant difference between the voltage sensitivities measured in the same hydrophone probe depending on which electrode is actually facing the acoustic source. The measurements carried out in the frequency range 1–20 MHz indicate that this difference, while negligible below 2 MHz may exceed 1.6 dB at higher frequencies. The theoretical model allowing comprehensive characterization of the membrane hydrophone probe to be predicted was developed and experimentally verified. The results of this work indicate that in the critical applications such as the quantitative field measurements or ultrasonic dosimetry, the membrane hydrophone's electrode exposed to the ultrasound source should be carefully identified.",
Logical approaches to uncertainty and vagueness in the view of the context model,"The context model provides a framework for clear semantics of concepts for handling uncertainty and vagueness. The authors analyze non-truth-functional logics with capabilities for the representation of uncertainty and vagueness in the view of the context model. It becomes apparent that among other approaches probabilistic and possibilistic logic can be considered as logics with additional restrictions in the general environment of the context model. Due to the semantic background of the context model it is possible to clarify and interpret the meaning of concepts like revision and expansion, and to describe the general assumptions used in various approaches.",
Toward a parsimonious architecture for intelligent organizational information systems,"An architecture for intelligent organizational information systems is proposed which consists of three functions: processing, communicating, and memory-any or all of which may be performed by either humans or computers. Processing occurs on a set of communicating processors with access to memory, and is defined as having three sub-functions: sensing, interpreting, and acting. The communicating and memory functions are seen to have certain basic characteristics whether described in terms from human organization or computer organization literature. The architecture may prove a useful guide for future research which begins to consider intelligent organizational information systems with increasingly synergistic roles played by humans and computers.",
Constructing a multitasking programming environment,"The construction of a multitasking programming environment called MCPE is presented. MCPE contains multiple tasks so that it can speed up response and utilize idle CPU time. Tasks communicate with each other through shared data storage. The tasks (such as a structure editor and a static analyzer) were designed as lightweight processes. The shared data storage (such as the grammar tree and the symbol table) are managed by monitors to guarantee effective sharing. Access on shared data storage is broadcast, so that the related tools can terminate unnecessary jobs. MCPE has been built on Smalltalk using a library of reusable codes, such as the MVC (model, view controller) triad and classes. The experiments showed that response time has been reduced. New tools can easily be built by reusing these classes and can be added to MCPE with no further delay in system response.",
Embedding the hypercube into the 3-dimension mesh,A constant time and space algorithm for embedding the hypercube architecture into the 3-dimension mesh (3D-mesh) is presented. This enables the cube/sub i/ operation to be performed on the embedded hypercube machine where the interprocessor communication function cube/sub i/ is defined on the embedded hypercube's PEs as cube/sub i/(b/sub n-1/...b/sub i/...b/sub 0/)=b/sub n-1/...b/sub i/...b/sub 0/ and b/sub i/ is the binary complement of b/sub i/.,
Color compression and spectral analysis of biological images,"Optical microscopy plays a key role in the biological sciences. Color images, as seen through the microscope and as subsequently digitized for computer analysis, respresent basic data for qualitative and quantitative interpretation. We have developed a new compression algorithm for such images that can achieve a 2- to 8-fold increase in compression of the color information as a preprocessing step to further well-known image compression schemes. At the same time, the picture is optimally preprocessed for optical spectral analysis. This technique has been found to be very useful in cell biology when applied to stained specimens. Even with these large compression ratios, little significant information is lost.",
An integrated system for real-time software,"A language supporting the construction of real-time software systems for reusable components is described in this paper. An architecture suited to the efficient execution of such software is also described. Additionally, the author provides a framework for analyzing real-time systems developed and executed in this context. Specifically, the assignment of modules to the processors of a parallel machine is considered and the analysis of programs to determine if deadlines are met is discussed.",
"Degraded voltage resulting in nonsafety UPS failure at Nine Mile Point Unit 2-August 13, 1991","At approximately 5.48 am on August 13, 1991, phase B of the main setup transformer of Niagara Mohawk Nine Mile Point Unit 2 nuclear power plant experienced a failure resulting in degraded voltage in phase B of the electrical AC distribution system. The author describes the events at the plant and an engineering analysis of the event. Five nonsafety-related uninterruptible power supplies. (UPSs) tripped. The tripping of these UPSs resulted in the loss of plant process computers, control room annunciation, and a significant portion of nonsafety-related instrumentation and control circuits. Safety-related instrumentation remained unaffected by these transient conditions. There was no radioactive release, and the plant was brought to a cold shutdown in an orderly manner.",
SDC muon tracking system,"Summary form only. The design of a muon tracking system for the central region of the SDC detector is discussed. The basic tracking elements are aluminum drift tubes with circular cross section with simple field shaping electrodes. The maximum length of the tubes is 9 m and they are operated in proportional mode using a nonflammable gas mixture. These drift tubes are bonded together into modules using structural epoxy. Tubes are properly oriented and precision located during the module assembly by mechanical constraints which are built into the tube endcaps. CNC (computer numerical control) machined reference end plates ensure the relative alignment of anode wires within a module. The largest module is envisaged to be approximately 9 m*8 m and to contain a mixture of theta , phi , and stereo views. Finite element analysis shows that a three-point kinematic support can be used. Full length prototype detectors have been built and studied. Cosmic ray and beam tests have been performed.<>",
Genesis: a generic simulation subsystem for parallel architectures,"Genesis is a library of C++ classes that serves as building blocks in modeling parallel architectures. This paper presents the architectural representation scheme on which Genesis is based. The design choices of Genesis and some of the reasons behind the choices are discussed. The author describes the way the performance parameters (architecture, program, assignment method, and routing scheme) are specified in Genesis. Some of the implementation details are considered. Some related simulation systems are reviewed and compared with Genesis.",
Diversity in the high-tech workplace: preparing for responsibility,Computer Sciences Corporation's approach to developing personnel to take on management responsibilities is described.,
Integrating Fault Diagnosis and Hypermedia,,
In situ microwave ionized air chemistry measurements,"The collision frequency of conduction electrons with neutral air molecules and the conduction electron density of ionized air in the Aurora test cell have been measured with microwave techniques. The macroscopic time-varying, nonlinear air conductivity of ionized air has also been determined. It is concluded that the microwave techniques outlined can be used as an independent check of the ionized air conductivity, computer codes, and the parameters used in these codes. In general, within the parameter space of the measurements, the experimental data presented are in good agreement with the predictions of the air chemistry packages.",
Closing the gap between different object models,"Programming language, database and operating system objects are essentially implementation variants of the same basic programming paradigm, i.e. objects as found in object-oriented programming languages. Yet, these object models differ significantly with regard to programming support, granularity, lifetime, persistence, concurrency, fault-tolerance and others. The paper points out the differences between these object models and argues that it makes sense to provide one generalized dynamic object model. A technique to define and use operating system objects in the same way as programming language objects independent from the object model provided by the underlying operating system is shown.",
Validation and performance evaluation of the partition and replicate algorithm,"The partition-and-replicate-strategy (PRS) algorithm for distributed query processing is evaluated and its performance is validated. Although in principle PRS is better than single-site processing, early experimental results indicate the contrary. Based on experimental results, the factor which causes performance deterioration is identified and a remedy is provided. As a result, it is shown that the PRS strategy outperforms single-site processing in a realistic environment and that various parameters, such as the number of processing sites, partitioning speed relative to join speed, and sizes of the join relations, affect the performance of the PRS strategy significantly. Among these parameters, the algorithm is most sensitive to the partition speed.",
The information systems research program at the Wharton School: doing more with less,"The Wharton MIS program is extremely small, is embedded in a larger, multi-disciplinary Decision Sciences Department, and is perpetually short of resources. This requires the authors at all times to maintain careful focus and direction in all of their teaching and research efforts, and has led them to adopt the following over-riding policy statement: 'If it's not worth doing, it's not worth doing well!' It has also led the authors to careful utilization and conservation of their limited resources. The program has two research streams: the coast guard project on model management extends the state-of-the-art in man-machine interaction, model management and complex decision support, while the Reginald H. Jones Center project on information systems, telecommunications, and business strategy has been one of the premier research programs in the strategic and competitive impacts of information technology.",
Experience in using three testing tools for research and education in software engineering,"It is a common belief that good software tools are necessary to support both research and education in software engineering. The authors document their experience, in support of this belief, with two data flow testing tools named ASSET and ATAC and one mutation testing tool named MOTHRA. These tools have been in use at Purdue University in research projects related to software testing and reliability. The tools have also been used in both undergraduate and graduate courses in software engineering.",
A case study in modeling a nuclear formation evaluation sub,"Measurement-while-drilling (MWD) requires extremely rugged tools. These tools are called subs. The modular neutron porosity (MNP) sub is one of several modular formation evaluation MWD tools that can be joined together in various combinations at the wellsite. The design of this sub was based heavily on the results of Monte Carlo modeling. Modeling efforts for the MNP sub are discussed. All modeling for the MNP tool was performed using the MCNP code. Once the model has been developed, its credibility must be established by comparing model predictions with experimental results. This requires that experiments meet stringent criteria. Standard experiments use large tanks filled with carefully prepared rock matrices. Eleven such tanks were initially available. The model results are compared with measurements taken in these tanks. The model can be used to predict tool response to many situations not reproducible in a laboratory. High temperatures, high pressures, and pore fluids composed of liquid-gas mixtures are typical of conditions encountered in real oil wells that are difficult to reproduce in a laboratory. Tool design and the effects of design modifications can also be evaluated efficiently using the model.",
Current Status of Heterojunction Bipolar and High-Electron Mobility Transistor Technologies,"The current status of Heterojunction Bipolar and High-Electron Mobility Transistor technology is reviewed. Applications include analog and digital circuits with focus on high power and optical communications for HBT's and millimeter-wave low-noise and power modules for HEMT's. Material choices, designs, technology, reliability issues and circuit demonstrations are addressed.",
A neural network integrated with hypertext for legal document assembly,"Hypertext technology is increasingly finding application in law firms, since much of the work of a lawyer involves accessing, assessing and sculpting text. There are some severe limitations inherent in hypertext. In document assembly, users break documents into small units (clauses and subclauses) and link them into a complex web, but links between text units do not cater for all associations of ideas that users may wish to make. Much research aims to provide means of accessing information not restricted by the hypertext structure. Recent methods include free text retrieval (FTR), vector retrieval. FTR is unsuitable for complex legal applications-it is necessary to distinguish between clauses which may share a common vocabulary. Vector retrieval does not allow indirect associations of words, documents. The authors have implemented a novel, neural network-based approach to information retrieval in legal hypertext systems. Practical considerations in the design include handling an often changing collection of text units.",
Coded nonlinear continuous phase modulation,A class of nonlinear continuous phase modulation (CPM) signals is introduced by extending nonlinear continuous phase frequency shift keying (CPFSK) signals. Coding is considered to further improve the performance of nonlinear CPM signals. Numerical results indicate that both uncoded and coded CPM signals achieve attractive minimum Euclidean distances. Gains of over 1.8 dB over previous schemes have been reported at the same number of states. The spectral properties of nonlinear CPM signals are kept close to those of full response linear CPM with a modulation index of 0.5. It is shown that both uncoded and coded nonlinear CPM signals can be realized by using a finite state machine and a standard FM modulator.,"Continuous phase modulation,
Maximum likelihood detection,
Euclidean distance,
AWGN,
Baseband,
Frequency,
Automata,
Code standards,
Phase detection,
Computer science"
A partially supervised learning algorithm for linearly separable systems,"An important aspect of human learning is the ability to select effective samples to learn and utilize the experience to infer the outcomes of new events. This type of learning is characterized as partially supervised learning. A learning algorithm of this type is suggested for linearly separable systems. The algorithm selects a subset S from a finite set X of linearly separable vectors to construct a linear classifier that can correctly classify all the vectors in X. The sample set S is chosen without any prior knowledge of how the vectors in X-S are classified. The computational complexity of the algorithm is analyzed, and the lower bound on the size of the sample set is established.","Supervised learning,
Vectors,
Algorithm design and analysis,
Machine learning algorithms,
Machine learning,
Humans,
Computational complexity,
Neural networks,
Laboratories,
Computer science"
Petri-net based line extractor for binary images,"A line extractor network for binary images is presented utilizing the basic principles of the Petri-net architecture as the framework. A brief introduction to the Petri-net formalism describes the terminology, structure, and execution control required for general network definition. The authors discuss the line extractor network in terms of basic Petri-net notation and identify the required extensions to the formalism contained within the proposed network. Simulation results for several input line patterns provide an indication of the network performance to identify lines of various lengths, widths, and orientations contained within a binary image. Remarks include a comparison with other line detection methods and hardware requirements for networks implementation.",
Hypermedia in CACSD education for distributed parameter systems,"Hypermedia in computer-aided control system design (CACSD) education is discussed. Experiences with using the TDP simulator for distributed parameter systems are presented. Individual tools for modeling, designing, and simulating distributed parameter systems in the TDP simulator are discussed. Special attention is paid to interfaces between these tools.","Distributed parameter systems,
Mathematical model,
Computational modeling,
Computer science education,
Educational programs,
Biological system modeling,
Mathematics,
Control systems,
Robust stability,
Animation"
Complex Boltzmann networks and one stage learning,"The author considers the discrete Boltzmann net with complex activations and weights. In particular he shows the following: it is possible to define an energy Hamiltonian with properties similar to the one in the real case; with appropriate clamping of a set of pattern units, the usual two-stage learning can be accomplished in one stage; and this model is still strongly related to the physical Spin Glass model, although not to the simple Ising model. Simulations, extensions, and future work are discussed.","Neural networks,
Laboratories,
Computational linguistics,
Mathematics,
Computer science,
Educational institutions,
Clamps,
Glass,
Computer networks,
Optical computing"
A modern course on digital design at the University of Twente,"At the University of Twente, the Netherlands a modern course on basic digital design has been developed. This course, which is based on a text book in English (K. J. Breeding, 1992), is supported by a sophisticated computer-assisted learning program and life-like practical work with extensive use of computer-aided-design tools. These features largely reduce the need for human teachers. Major parts of the course are particularly suited to be copied by other institutes.",
An architecture of a threaded many-to-many remote procedure call,"The client-agent-server architecture, which serves as a flexible mechanism for many-to-many remote procedure calls, is discussed. The architecture provides a transparent view of the server to a client. The client accesses the server group through the agent while retaining only an abstract view of the server. The call primitives for the client, agent groups, hook construction and primitives (hooks are basic building block which a server group provides to the agent group), and server groups used in the architecture are described. Implementation issues are reviewed.",
Categorization for network fault diagnosis,"A new method of LAN fault diagnosis is described based on host behavior categorization. Monitored network traffic is used to represent a host's behavior as a point in a high-dimensional parameter space. A number of these points (one for each host) is categorized by an inductive Bayesian classifier and the resulting categorization is used to predict future network host behavior. If a host's subsequent behavior is not consistent with its expected class, the host is flagged anomalous and becomes a focus of further diagnosis. The system has been tested on approximately a network-year of data and has successfully diagnosed all known faults in this data due to programmer error and has even pointed out several that had previously gone undetected. Ways to improve the system's performance with complementary diagnostic techniques are introduced.",
Class reference reduction in object-oriented databases,"The authors propose a semantic query-optimizer (SQO) using semantic integrity constraints (SICs) in an object-oriented database system (OODB). SICs assert permissible or consistent database states (a database state is the stored data at a given time instance) for a database application. For example, in a payroll database, the minimum hourly rate has to be $4.35 by law. The basic idea of SQO is to optimize queries by transforming a query qualification into another semantically equivalent one using semantic integrity constraints such that evaluating the transformed query would be less costly. Although semantic query optimization has been well studied in the context of relational and deductive database systems, certain distinct object-oriented features such as IS-A class hierarchy have not been taken into consideration. This is probably due to that OODB is relatively new and that there is lack of research so far on SICs in OODBs.",
Examining routing solutions,"A visualization tool, Examine, is presented to aid router development. Examine has the ability to display routing operations in a variety of ways (e.g., selective display of layers and nets). In addition, Examine has rudimentary animation facilities that enable a router developer to view a sequence of routing frames or a routing frame composite.",
A computer concepts course,"During 1989 a new course on computer concepts was approved at the University of South Africa. It was decided to use a new approach to the teaching-at-a-distance education environment by introducing a multimedia teaching package for this course on computer concepts for computer users. The contents of the course and the reasons for having such a course are described in the article, together with the tutorial package for the course, the administrative arrangements made for the presentation of the course and a presentation of the authors' findings during the first year of operation of the course.",
MAMACG: a tool for automatic mapping of matrix algorithms onto mesh array computational graphs,"The design of MAMACG, a software tool for automatically mapping an important class of matrix algorithms into mesh array computational graphs, is described. MAMACG is a concrete realization of the multimesh graph (MMG) method, implemented in Elk, a dialect of LISP with built-in X-graphics capabilities.",
Human factors in virtual worlds. 1. Information structure and representation,"The now-popular conception of virtual reality as a household item offering unlimited entertainment in designer fantasies is unlikely to reach the mass market for some time. The more immediate and interesting applications of VR are practical ones in the fields of science, medicine, industry and technology, in which the professional user may benefit from an enhanced experience of working in a more-or-less familiar environment. By the author's definition, VR is simply a design approach that aims to immerse the user in the sensory experiences associated with a different environment, ultimately providing an 'altered sense of presence'. Technologically, VR is essentially a synthesis of advanced or novel techniques in human-computer interaction (HCI). Thus, all the established principles and methods of human factors and ergonomics in the design of human-machine systems still apply. The authors consider how VR concepts lend themselves to the much-vaunted inclusion of human factors as a driving force in systems design.",
Optimistically building a consensus sequence using F-inexact matches (DNA),"Biological and physical limitations require that DNA be sequenced in fragments. During the process of sequencing the DNA, errors are occasionally introduced. This paper addresses the problem of reconstructing the original DNA sequence given only the fragments that may contain errors. The authors give a new algorithm based on suffix arrays to solve the problem of reconstructing the original DNA sequence. A worst-case and expected-case time analysis of the algorithm is presented. A program based on this algorithm is used to reconstruct the human beta globin region on chromosome 11 (HUMHBB in GenBank) when given a set of 300 to 500 mers drawn randomly from the HUMHBB locus.",
Non-recursive thinning algorithms using chain codes,"Describes the development of contour generation thinning algorithms that are non-recursive. Two algorithms are presented, both of them involves the use of 4 sub-cycles. Additional data structures are incorporated in the chain code to ensure consistency in the propagation of contour pixels. In both algorithm, the 4-distance metric is used. The first algorithm erodes a 4-connected contour in an iteration. The second algorithm remembers the state of the bitmap at the beginning of an iteration, with the result that an 8-contour is eroded.",
Maximal detection of myocardium in echocardiograms for supervised refinement,"A novel thresholding method to separate the myocardium of correct thickness from a sequence of two-dimensional echocardiograms is presented. The threshold is made adaptive by maintaining a constant wall width ratio throughout the image sequence. The width ratio is computed at an interactively indicated wall section where the wall width is known a priori. The method is well suited for detecting the heart walls in long axis views of the echocardiograms, but in general it can be used for detection or any striped object pattern.",
Parallel programming in SR,"Synchronizing Resources (SR) is a language for writing distributed programs which supports many forms of interprocess communication to obtain high expressiveness. The design of SR is evaluated from the perspective of parallel programming. Several programs for parallel applications implemented in SR are studied, and some observations are made about the expressiveness and ease of use of SR. The results indicate that nearly all facilities provided by SR are useful for parallel programming. The language lacks message passing through mailboxes, message forwarding, and globally shared variables. SR is also fairly simple to understand. A strong point in the design is the orthogonality of the message sending and receiving constructs. Some points of criticism concern the multicast mechanism and the type-insecurity of the language.",
Minimization of the L∞-Induced Norm for Sampled-Data Systems,"In this paper, a complete solution for the l1 sampled-data problem is furnished for arbitrary plants. The l1 sampled-data problem is described as follows: Given a continuous-time plant, with continuous-time performance objectives, design a digital controller that delivers this performance. This problem differs from the standard discrete-time methods in that it takes into consideration the inter-sampling behavior of the closed loop system. The resulting closed loop system dynamics consist of both continuous-time and discrete-time dynamics and thus such systems are known as hybrid systems. It is shown that given any degree of accuracy, there exists a standard discrete-time l1 problem, which can be determined apriori, such that for any controller that achieves a level of performance for the discrete-time problem, the same controller achieves the same performance within the prescribed level of accuracy if implemented as a sampled-data controller. This is accomplished by first converting the the hybrid system into an equivalent infinite dimensional discrete-time system using the lifting technique in continuous time, then the infinite dimensional parts of the system which model the inter-sample dynamics are approximated. This approximation is done independently of the controller, and explicit bounds are obtained for the degree of approximation. It is shown that the convergence of this approximation is at least as 1/n.",
On statistical reconstruction of random fields and the art of forgery,"The problem of statistical reconstruction of Gaussian random fields is considered. It is shown that the reconstruction is made up of the deterministic (predictable and hence unique) component and the stochastic (unpredictable and hence nonunique) component. The reconstruction procedure is briefly sketched for general homogeneous random fields. It is shown that major computational simplifications can be achieved if the unilateral conditional Markov (CM) model of the field is adopted. For CM fields, the possibility of decomposing the restoration procedure into a number of computationally less demanding sub-problems is discussed.","Art,
Stochastic processes"
Semantic Models For Parallel Computers,,
Efficient evaluation of arbitrary set-associative caches on multiprocessors,The authors propose a simple solution to the problem of efficient stack evaluation of LRU (least recently used) cache memories with an arbitrary two's power set-associativity on multiprocessors. It is an extension of stack evaluation techniques for all-associativity LRU cache on a uniprocessor. Special marker entries are used in the stack to represent data pages (also called data blocks or lines) deleted by an invalidation-based cache coherence protocol. A technique of marker-splitting is used when a data page below a marker in the stack is accessed. One-pass evaluation of memory access trace will yield hit ratios for all cache sizes and set associativities on multiprocessor caches in a single pass over a memory reference trace with the use of this technique.,
Attribute support for inter-domain use,"This paper describes the user attribute service (UAS), a tool providing the storage and management of application-specific per-user security attributes for applications running in a distributed environment. The UAS provides for the security and integrity of attribute-to-user bindings, as well as the secrecy of those bindings, if the application or user requests it. Four goals of the UAS are support of least privilege, local control and autonomy, instantiation of trust relationships, and psychological acceptability. Mechanisms to group and enable privilege attributes support the least privilege principal at the user request level. Functions are designed to enhance the usability of the UAS within and across domains by attribute holders and security managers.",
External sorting on a reconfigurable message-passing multicomputer: experimental results and analysis,"An actual implementation of the external sorting problem on a multicomputer, with careful attention paid to the overlap between computations and I/O in order to minimize total execution time, is reported. The problem is divided into two steps. The first involves creation of multiple sorted runs. The second involves merging the runs. Step 1 is accomplished using pipelined sort; step 2 is implemented on a tree of processors. An analytical model for step 1 is presented. The execution time predicted by the proposed analytical model is compared with the experimental results.",
PENCIL/C concurrent programming of high speed communication protocols,"In high-speed networking, increasing transmission rates at decreasing error rates have caused a gap between physical performance of the transmission medium and the end-to-end performance offered to the user. High-speed protocols of lower layers have been developed, in some cases based on specially designed VLSI components, e.g., XTP. But lower layers as well as higher levels of communication protocols require techniques for deriving efficient software implementation from specification. A straightforward method achieving an efficient concurrent solution is introduced. It is based on higher Petri nets. One important part of this method is the concurrent programming language PENCIL/C, which is introduced. Some excerpts from an XTP implementation show the power of this concept.",
Performance of a typical ISO protocol profile (MAP 3.0)-measurements and discussion,"A discussion is presented of the performance of the MAP protocol profile, which is a typical example of a layered OSI protocol profile in a local area network environment, and the results of a number of measurements are given. Static aspects of performance, which are dominated by the implementation, are covered. The main issue is the examination of dynamic aspects, which are dominated by the transport layer.",
Experiences with integrating operating systems,"Discusses the authors' industry experience in integrating operating system projects. Systems integration is broadly classified into module integration and version integration. Problems encountered in integrating individual modules based on multiple versions are discussed, together with techniques used to minimise or overcome them. Version integration occurs when new releases in the licensed software have to be integrated into manufacturers' proprietary versions. While version integration is more of an art than a science, certain measures undertaken at the module integration phase can reduce the time involved and problems encountered in version integration.","Operating systems,
Manufacturing,
Art,
Large scale integration,
Project management,
Engineering management,
Particle measurements,
Phase measurement,
Software measurement,
Time measurement"
Performance evaluation of dynamic supporting algorithms,"The widely used performance measures for replicated file systems are file availability and reliability. The authors compare such measures for the dynamic supporting algorithm, the dynamic supporting (G) algorithm, and other algorithms, e.g., the available copies and the majority voting algorithms. Since replicas and votes are conceptually separated, the two dynamic supporting algorithms could achieve very high availability and reliability while still keeping storage cost very low, especially with only two replicas. Both stochastic analysis and simulation results are reported. The performance improvement of the dynamic supporting algorithms is demonstrated by the results.",
Decentralized blocking zeros. I. Decentralized strong stabilization problem,"The authors consider the synthesis of decentralized stabilizing controllers with a minimum number of unstable poles for linear time-invariant finite-dimensional systems. The new concept of decentralized blocking zeros, which is an appropriate generalization of blocking zeros to multichannel systems, plays a crucial role. Decentralized blocking zeros are introduced and the decentralized strong stabilization problem (DSSP), which is the standard decentralized stabilization problem with stable local controllers, is considered. It is shown that DSSP has a solution just in the case where the multichannel system is free of unstable decentralized fixed modes and the parity interlacing property is satisfied between the real nonnegative poles and real nonnegative decentralized blocking zeros. The problem of synthesizing a decentralized stabilizing controller with a minimum number of unstable poles is a generalization of DSSP. This minimum number turns out to be the number of odd distributions of real nonnegative poles among the real nonnegative decentralized blocking zeros. It is also shown that the unstable poles of a decentralized stabilizing controller can nearly arbitrarily be distributed (spread) among the poles of the local controllers.",
Strategies for machine instruction transformation in an expert system,"To build an expert system which can transform machine language programs between any pair of computers, an intermediate language is proposed. A program is first converted to an equivalent program in this intermediate language, which in turn is converted to the assembly language and machine language of the destination machine. Several strategies are developed to ensure a proper and efficient transformation. The authors discuss a local transformation, a basic block transformation, and instruction side effect handling. An example of program transformation between the VAX and the IBM 370 systems is given.","Expert systems,
Assembly,
Computer aided instruction,
Computer science,
Hardware,
High level languages,
Computer architecture,
User interfaces,
Computer languages"
Mobile robot control based on dynamic potential,"An efficient method is presented for implementing mobile robot perception-action behaviors, based on time-varying environment potential field approach. First, in this paper, the concept of dynamic potential U(x, y, z, t) is proposed for representing the environment of a mobile robot, and the form of U(x, y, z, t) is deduced, and then the velocity control of the vehicle with two wheel is directly calculated by transition function T of U(x, y, z, t). Finally, the perception-action layer is successfully implemented for avoiding collision, wandering, and integrating path planning and steering control on THMR-II (TsingHua university Mobile Robot system). Based on sonar array signals, the experimental results are given to show that THMR-II has better reflexive function, real-time obstacle avoidance, adaptablity and robustness for complex environments.",
Validation of LOTOS specifications using an interpreter: an application to telephone systems,LOTOS (language of temporal ordering specifications) is a formal description technique (FDT) that was developed by the International Organization for Standardization (ISO) for the specification of Open Systems Interconnection services and protocols. A design methodology for the description in LOTOS of telephone systems with modern features is provided. The description of a sample telephone system is formalized. A technique for the validation of a LOTOS specification using the facilities provided by the University of Ottawa interpreter is presented.,
Managing personal files across independent file management units,"This paper presents the design and implementation of the PFS personal file management system. PFS provides transparent and reliable access to personal files that are dispersed across reliable independent file servers. PFS is unique and practical since it runs on variations of the Unix system, it does not modify the operating system kernel, and more importantly, it operates in environments in which a user lacks administrative control. By means of the PFS, a user creates a global structure of personal files that appear identical despite the server that the user accesses. Since each file is replicated once, the system provides transparent access to files despite one failure at any server.",
Specifications in software development,Summary form only given. Various kinds of specifications used during software development are presented through examples. The focus is on the practical aspects of the nature and use of formal specifications. Some open research problems that should be of particular interest are mentioned.<>,
Nonlinear analysis of the sleep EEG at hippocampal subfields,Nonlinear signal processing method was used to examine the EEG collected at hippocampal subfields CAl and the dentate gyrus during REM sleep. Bispectral analysis revealed that intra- and inter-quadratic nonlinear interactions exist between CAl and the dentate gyrus in the frequency band of 6–8 Hertz.,
An architecture for active hypertext on distributed systems,"The combination of hypertext and distributed systems technologies enhances effectiveness in information management and dissemination. An architecture which integrates these technologies is presented, the issues that influenced its design are cited, and its realization is outlined. Easy and graceful integration of new applications in the framework is supported by the generic and extensible character of the architecture. The proposed architecture caters for activity; event-driven computations constantly cheek for the preservation of consistency and rigidly enforce the behavior specified by the application programmer. A production rule formalism is used to customize the structure of the hypergraph and define additional constraints on the semantics of the server operations.",
The 1990-91 Taulbee survey report (computer science education),"The key findings of the 1990-91 Taulbee Survey Report describing the results of a study of the Forsythe list of computing departments are presented. The Forsythe list enumerates all departments in the US and Canada that grant PhDs in computing, specifically in computer science (CS) and computer engineering (CE). Completed in December 1991, the latest survey concerns the production and employment of PhDs who graduated in 1990-91 and the faculty of PhD-granting computing departments during the 1991-92 academic year. The results indicate that the production of PhDs in CS departments increased significantly; the number of faculty in PhD-granting departments leveled off for the first time in two decades; those departments employed more full professors than assistant professors for another first; and minority figures persisted on the low side.",
A new over-the-cell channel router,"A new over-the-cell channel router is presented. The authors solved the over-the-cell problem in two phases: (1) routing over cells, and (2) routing within the channel. The first phase reduces the channel density as far as possible by routing some critical nets over the cells. It was found that only the critical nets being routed over the cell may reduce the channel density. The maximum density segment (MDS) in the channel is defined, and the nets to be routed over the cells were chosen among the nets which cover the MDSs, so that the channel density was likely to be reduced. The second phase can be done by using a conventional channel router. The algorithm was coded in C and implemented on a SUN4/110 workstation. The experimental results are comparable to or better than previously published results.",
How to migrate processes in distributed computing systems-a Markov team approach,"A process migration mechanism offers a means to exploit the performance reserves present in networks of workstations used as personal computers by allowing migration of processes from overloaded to underused processors. Several distributed operating systems provide such a facility, the benefits of its use depending on the specification of a proper process migration policy. An analytical model, the Markov team model, to assist in the design of such a policy is presented. This model is derived from results of classical team theory and Markov decision processes. The special case of homogeneous distributed computing systems and methods for parameter estimation are discussed. Numerical examples are used to demonstrate the benefits of using this model.",
H∞-optimal control for singularly perturbed systems part i: perfect state measurements,"We study the H∞-optimal control of singularly perturbed linear systems under perfect state measurements. Using a differential game theoretic approach, we show that as the singular perturbation parameter ϵ approaches zero, the optimal disturbance attenuation level for the full-order system under a quadratic performance index converges to a value that is bounded above by the maximum of the optimal disturbance attenuation levels for the slow and fast subsystems under appropriate ""slow"" and ""fast"" quadratic cost functions. Furthermore, we construct a composite controller based on the solution of the slow and fast games, which guarantees a desired achievable performance level for the full-order plant, as ϵ approaches zero. A ""slow"" controller, however, is not generally robust in this sense, but still under some conditions, which are delineated in the paper, the fast dynamics can be totally ignored. The paper also studies optimality when the controller includes a feedforward term in the disturbance.",
Cutting planes and constant depth Frege proofs,"The cutting planes refutation system for propositional logic is an extension of resolution and is based on showing the nonexistence of solutions for families of integer linear inequalities. The author defines a modified system of cutting planes with limited extension and shows that this system can polynomially simulate constant-depth Frege proof systems. The principal tool to establish this result is an effective version of cut elimination for modified cutting planes with limited extension. Thus, within a polynomial factor, one can simulate classical propositional logic proofs using modus ponens by refutation-style proofs, provided the formula depth is bounded by a constant. Propositional versions of the Paris-Harrington theorem, Kanamori-McAloon theorem, and variants are proposed as possible candidates for combinatorial tautologies that may require exponential-size cutting planes and Frege proofs.",
Dual-Polarization Radar Measurements in an Oklahoma. Hailstorm,,
An efficient data interface for heterogeneous distributed environments,"A multi-language-based data interface system for heterogeneous distributed processing is introduced. A prototyped environment based on this system is discussed, and an evaluation of the prototyped system is presented. It is shown that by keeping the syntax of the specification language flexible and close to existing high-level languages, a user can learn the interface language quickly. Semantically, this data interface views structured data as consisting of two parts: the data values themselves and the representation of the structure among the data values. Through this separation, it is possible to have pipelined data type checking and data conversion operations.",
Reconfiguration of two-dimensional VLSI arrays by time-redundancy,"The authors present various approaches for reconfiguring two-dimensional VLSI arrays using pure time-redundancy, i.e., no spare cells are employed. This technique is based on the full processing utilization of fault free cells. The basic principles of the proposed time-redundancy technique are discussed. The first approach is based on a distributed execution of the reconfiguration process. The second is based on a more complex reconfiguration procedure which accounts for an iterative execution of the first approach. These approaches have been evaluated under multiple faults in both cells and in the switches of the provided interconnection network.",
Ambiguity in human communication and the design of computer-mediated-communication systems,"Unlike physical or biological systems, human social systems are loosely-coupled in nature. Ambiguity and interpretation play important roles in human communication. Language is a key means of creating and maintaining shared realities through consensual processes. Consequently, an understanding of the interpretational nature of social interactions is required for the design of computer-mediated communication systems. Computer-based systems vary in their abilities to cope with the ambiguities inherent in social interactions; the mediation of 'rich' social interactions with computer technology is often problematic. Some existing computer-mediated communication systems are examined with respect to the issues discussed.",
Banyan heap machine,"New designs for performing a group of priority queue operations on a set of elements are presented. Processors in this design, called the banyan heap machine are connected together to form a linear chain. The algorithms for the banyan heap machine are the generalization of binary heap algorithms to a more general acyclic graph called banyan. This design, unlike existing designs, requires fewer processors to meet the same capacity requirement, and also, processors do not have geometrically varying memory sizes. This results in a completely homogeneous system. The key advantage of the banyan heap machine is in its ability to retrieve elements at different percentile levels.",
Criteria for digital computers used in the design of nuclear generation plant safety systems,"Summary form only. The Nuclear Power Engineering Committee has realized that standards for computers used as part of the design of nuclear safety systems have not kept up with software engineering practices. Standards developed by the IEEE Computer Society, ASME NQA-1 and NQA-2, Part 2.7, and the International Electrotechnical Commission have established the software engineering practices. The author has considered how software engineering practices in compliance with the aforementioned organizations were used to rewrite ANSI/IEEE-ANS-7-4.3.2, 'Application Criteria for Digital Computers Used in Nuclear Facility Safety Systems'. These software engineering practices were used as additional requirements in P-7-4.3.2 when addressing the quality criteria of IEEE-603-1991. These engineering practices addressed computer system development, verification, and validation, and configuration management.<>",
Enforce constraints in archival databases,"In an archival database, there are insertions but almost no deletions, or deletions take place in a batch mode. Such an environment allows the authors to identify many databases in which constraint enforcement can be done very fast, i.e., in constant time. They describe an example which illustrates that unbounded database schemes are still useful in some applications, such as in the archival environment.",
Line spectrum elimination of undesired signal by IIR adaptive digital filter,"The authors propose a new method of line-spectrum elimination by making use of IIR adaptive digital filter (ADF) which is constructed of parallel connected second order IIR filters. And a new algorithm to control the poles of the IIR ADF is also proposed. The new algorithm utilizes the converged values of filter coefficients representing zeros of the IIR ADF as the frequency errors of the pole. The effectiveness of the new algorithm is shown in simulation results. Since the proposed algorithm can independently control each second order filter connected in parallel, the proposed IIR ADF can eliminate multiple narrow band signals.",
Pipelined Processing Technique in Object Detection and Location: A Simulated Method,"This is a study of a parallel, Hough based method for detecting identifying and locating objects within an image. A simulation model based on the hardware architecture is being used. The results show the method to be accurate and reliable.",
