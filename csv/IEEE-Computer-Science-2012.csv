Title,Abstract,Keywords
Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups,"Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition.","Automatic speech recognition,
Speech recognition,
Hidden Markov models,
Training,
Gaussian processes,
Acoustics,
Neural networks,
Data models"
"Hyperspectral Unmixing Overview: Geometrical, Statistical, and Sparse Regression-Based Approaches","Imaging spectrometers measure electromagnetic energy scattered in their instantaneous field view in hundreds or thousands of spectral channels with higher spectral resolution than multispectral cameras. Imaging spectrometers are therefore often referred to as hyperspectral cameras (HSCs). Higher spectral resolution enables material identification via spectroscopic analysis, which facilitates countless applications that require identifying materials in scenarios unsuitable for classical spectroscopic analysis. Due to low spatial resolution of HSCs, microscopic material mixing, and multiple scattering, spectra measured by HSCs are mixtures of spectra of materials in a scene. Thus, accurate estimation requires unmixing. Pixels are assumed to be mixtures of a few materials, called endmembers. Unmixing involves estimating all or some of: the number of endmembers, their spectral signatures, and their abundances at each pixel. Unmixing is a challenging, ill-posed inverse problem because of model inaccuracies, observation noise, environmental conditions, endmember variability, and data set size. Researchers have devised and investigated many models searching for robust, stable, tractable, and accurate unmixing algorithms. This paper presents an overview of unmixing methods from the time of Keshava and Mustard's unmixing tutorial to the present. Mixing models are first discussed. Signal-subspace, geometrical, statistical, sparsity-based, and spatial-contextual unmixing algorithms are described. Mathematical problems and potential solutions are described. Algorithm characteristics are illustrated experimentally.","Hyperspectral imaging,
Vectors,
Educational institutions,
Mortar"
Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition,"We propose a novel context-dependent (CD) model for large-vocabulary speech recognition (LVSR) that leverages recent advances in using deep belief networks for phone recognition. We describe a pre-trained deep neural network hidden Markov model (DNN-HMM) hybrid architecture that trains the DNN to produce a distribution over senones (tied triphone states) as its output. The deep belief network pre-training algorithm is a robust and often helpful way to initialize deep neural networks generatively that can aid in optimization and reduce generalization error. We illustrate the key components of our model, describe the procedure for applying CD-DNN-HMMs to LVSR, and analyze the effects of various modeling choices on performance. Experiments on a challenging business search dataset demonstrate that CD-DNN-HMMs can significantly outperform the conventional context-dependent Gaussian mixture model (GMM)-HMMs, with an absolute sentence accuracy improvement of 5.8% and 9.2% (or relative error reduction of 16.0% and 23.2%) over the CD-GMM-HMMs trained using the minimum phone error rate (MPE) and maximum-likelihood (ML) criteria, respectively.","Hidden Markov models,
Artificial neural networks,
Training,
Speech recognition,
Context modeling,
Acoustics,
Mathematical model"
Experiment-Driven Characterization of Full-Duplex Wireless Systems,"We present an experiment-based characterization of passive suppression and active self-interference cancellation mechanisms in full-duplex wireless communication systems. In particular, we consider passive suppression due to antenna separation at the same node, and active cancellation in analog and/or digital domain. First, we show that the average amount of cancellation increases for active cancellation techniques as the received self-interference power increases. Our characterization of the average cancellation as a function of the self-interference power allows us to show that for a constant signal-to-interference ratio at the receiver antenna (before any active cancellation is applied), the rate of a full-duplex link increases as the self-interference power increases. Second, we show that applying digital cancellation after analog cancellation can sometimes increase the self-interference, and thus digital cancellation is more effective when applied selectively based on measured suppression values. Third, we complete our study of the impact of self-interference cancellation mechanisms by characterizing the probability distribution of the self-interference channel before and after cancellation.","Real-time systems,
Wireless communication,
Estimation,
Radio frequency,
Receiving antennas,
Interference"
Hesitant Fuzzy Linguistic Term Sets for Decision Making,"Dealing with uncertainty is always a challenging problem, and different tools have been proposed to deal with it. Recently, a new model that is based on hesitant fuzzy sets has been presented to manage situations in which experts hesitate between several values to assess an indicator, alternative, variable, etc. Hesitant fuzzy sets suit the modeling of quantitative settings; however, similar situations may occur in qualitative settings so that experts think of several possible linguistic values or richer expressions than a single term for an indicator, alternative, variable, etc. In this paper, the concept of a hesitant fuzzy linguistic term set is introduced to provide a linguistic and computational basis to increase the richness of linguistic elicitation based on the fuzzy linguistic approach and the use of context-free grammars by using comparative terms. Then, a multicriteria linguistic decision-making model is presented in which experts provide their assessments by eliciting linguistic expressions. This decision model manages such linguistic expressions by means of its representation using hesitant fuzzy linguistic term sets.","Pragmatics,
Fuzzy sets,
Grammar,
Semantics,
Decision making,
Uncertainty,
Humans"
Zero Duality Gap in Optimal Power Flow Problem,"The optimal power flow (OPF) problem is nonconvex and generally hard to solve. In this paper, we propose a semidefinite programming (SDP) optimization, which is the dual of an equivalent form of the OPF problem. A global optimum solution to the OPF problem can be retrieved from a solution of this convex dual problem whenever the duality gap is zero. A necessary and sufficient condition is provided in this paper to guarantee the existence of no duality gap for the OPF problem. This condition is satisfied by the standard IEEE benchmark systems with 14, 30, 57, 118, and 300 buses as well as several randomly generated systems. Since this condition is hard to study, a sufficient zero-duality-gap condition is also derived. This sufficient condition holds for IEEE systems after small resistance (10-5 per unit) is added to every transformer that originally assumes zero resistance. We investigate this sufficient condition and justify that it holds widely in practice. The main underlying reason for the successful convexification of the OPF problem can be traced back to the modeling of transformers and transmission lines as well as the non-negativity of physical quantities such as resistance and inductance.",
A benchmark for the evaluation of RGB-D SLAM systems,"In this paper, we present a novel benchmark for the evaluation of RGB-D SLAM systems. We recorded a large set of image sequences from a Microsoft Kinect with highly accurate and time-synchronized ground truth camera poses from a motion capture system. The sequences contain both the color and depth images in full sensor resolution (640 × 480) at video frame rate (30 Hz). The ground-truth trajectory was obtained from a motion-capture system with eight high-speed tracking cameras (100 Hz). The dataset consists of 39 sequences that were recorded in an office environment and an industrial hall. The dataset covers a large variety of scenes and camera motions. We provide sequences for debugging with slow motions as well as longer trajectories with and without loop closures. Most sequences were recorded from a handheld Kinect with unconstrained 6-DOF motions but we also provide sequences from a Kinect mounted on a Pioneer 3 robot that was manually navigated through a cluttered indoor environment. To stimulate the comparison of different approaches, we provide automatic evaluation tools both for the evaluation of drift of visual odometry systems and the global pose error of SLAM systems. The benchmark website [1] contains all data, detailed descriptions of the scenes, specifications of the data formats, sample code, and evaluation tools.","Cameras,
Simultaneous localization and mapping,
Calibration,
Trajectory,
Visualization"
"A Review on Ensembles for the Class Imbalance Problem: Bagging-, Boosting-, and Hybrid-Based Approaches","Classifier learning with data-sets that suffer from imbalanced class distributions is a challenging problem in data mining community. This issue occurs when the number of examples that represent one class is much lower than the ones of the other classes. Its presence in many real-world applications has brought along a growth of attention from researchers. In machine learning, the ensemble of classifiers are known to increase the accuracy of single classifiers by combining several of them, but neither of these learning techniques alone solve the class imbalance problem, to deal with this issue the ensemble learning algorithms have to be designed specifically. In this paper, our aim is to review the state of the art on ensemble techniques in the framework of imbalanced data-sets, with focus on two-class problems. We propose a taxonomy for ensemble-based methods to address the class imbalance where each proposal can be categorized depending on the inner ensemble methodology in which it is based. In addition, we develop a thorough empirical comparison by the consideration of the most significant published approaches, within the families of the taxonomy proposed, to show whether any of them makes a difference. This comparison has shown the good behavior of the simplest approaches which combine random undersampling techniques with bagging or boosting ensembles. In addition, the positive synergy between sampling techniques and bagging has stood out. Furthermore, our results show empirically that ensemble-based algorithms are worthwhile since they outperform the mere use of preprocessing techniques before learning the classifier, therefore justifying the increase of complexity by means of a significant enhancement of the results.","Learning systems,
Accuracy,
Training,
Proposals,
Noise,
Algorithm design and analysis,
Bagging"
Three things everyone should know to improve object retrieval,"The objective of this work is object retrieval in large scale image datasets, where the object is specified by an image query and retrieval should be immediate at run time in the manner of Video Google [28]. We make the following three contributions: (i) a new method to compare SIFT descriptors (RootSIFT) which yields superior performance without increasing processing or storage requirements; (ii) a novel method for query expansion where a richer model for the query is learnt discriminatively in a form suited to immediate retrieval through efficient use of the inverted index; (iii) an improvement of the image augmentation method proposed by Turcot and Lowe [29], where only the augmenting features which are spatially consistent with the augmented image are kept. We evaluate these three methods over a number of standard benchmark datasets (Oxford Buildings 5k and 105k, and Paris 6k) and demonstrate substantial improvements in retrieval performance whilst maintaining immediate retrieval speeds. Combining these complementary methods achieves a new state-of-the-art performance on these datasets.",
A Survey of Monte Carlo Tree Search Methods,"Monte Carlo tree search (MCTS) is a recently proposed search method that combines the precision of tree search with the generality of random sampling. It has received considerable interest due to its spectacular success in the difficult problem of computer Go, but has also proved beneficial in a range of other domains. This paper is a survey of the literature to date, intended to provide a snapshot of the state of the art after the first five years of MCTS research. We outline the core algorithm's derivation, impart some structure on the many variations and enhancements that have been proposed, and summarize the results from the key game and nongame domains to which MCTS methods have been applied. A number of open research questions indicate that the field is ripe for future work.","Games,
Monte Carlo methods,
Artificial intelligence,
Game theory,
Computers,
Markov processes,
Decision theory"
ViNEYard: Virtual Network Embedding Algorithms With Coordinated Node and Link Mapping,"Network virtualization allows multiple heterogeneous virtual networks (VNs) to coexist on a shared infrastructure. Efficient mapping of virtual nodes and virtual links of a VN request onto substrate network resources, also known as the VN embedding problem, is the first step toward enabling such multiplicity. Since this problem is known to be NP-hard, previous research focused on designing heuristic-based algorithms that had clear separation between the node mapping and the link mapping phases. In this paper, we present ViNEYard-a collection of VN embedding algorithms that leverage better coordination between the two phases. We formulate the VN embedding problem as a mixed integer program through substrate network augmentation. We then relax the integer constraints to obtain a linear program and devise two online VN embedding algorithms D-ViNE and R-ViNE using deterministic and randomized rounding techniques, respectively. We also present a generalized window-based VN embedding algorithm (WiNE) to evaluate the effect of lookahead on VN embedding. Our simulation experiments on a large mix of VN requests show that the proposed algorithms increase the acceptance ratio and the revenue while decreasing the cost incurred by the substrate network in the long run.","Substrates,
Bandwidth,
Indium phosphide,
Stress,
Computer science,
Linear programming,
Computer architecture"
3-D Object Retrieval and Recognition With Hypergraph Analysis,"View-based 3-D object retrieval and recognition has become popular in practice, e.g., in computer aided design. It is difficult to precisely estimate the distance between two objects represented by multiple views. Thus, current view-based 3-D object retrieval and recognition methods may not perform well. In this paper, we propose a hypergraph analysis approach to address this problem by avoiding the estimation of the distance between objects. In particular, we construct multiple hypergraphs for a set of 3-D objects based on their 2-D views. In these hypergraphs, each vertex is an object, and each edge is a cluster of views. Therefore, an edge connects multiple vertices. We define the weight of each edge based on the similarities between any two views within the cluster. Retrieval and recognition are performed based on the hypergraphs. Therefore, our method can explore the higher order relationship among objects and does not use the distance between objects. We conduct experiments on the National Taiwan University 3-D model dataset and the ETH 3-D object collection. Experimental results demonstrate the effectiveness of the proposed method by comparing with the state-of-the-art methods.","Three dimensional displays,
Solid modeling,
Databases,
Computational modeling,
Vectors,
Educational institutions,
Visualization"
Mobile Data Offloading through Opportunistic Communications and Social Participation,"3G networks are currently overloaded, due to the increasing popularity of various applications for smartphones. Offloading mobile data traffic through opportunistic communications is a promising solution to partially solve this problem, because there is almost no monetary cost for it. We propose to exploit opportunistic communications to facilitate information dissemination in the emerging Mobile Social Networks (MoSoNets) and thus reduce the amount of mobile data traffic. As a case study, we investigate the target-set selection problem for information delivery. In particular, we study how to select the target set with only k users, such that we can minimize the mobile data traffic over cellular networks. We propose three algorithms, called Greedy, Heuristic, and Random, for this problem and evaluate their performance through an extensive trace-driven simulation study. Our simulation results verify the efficiency of these algorithms for both synthetic and real-world mobility traces. For example, the Heuristic algorithm can offload mobile data traffic by up to 73.66 percent for a real-world mobility trace. Moreover, to investigate the feasibility of opportunistic communications for mobile phones, we implement a proof-of-concept prototype, called Opp-off, on Nokia N900 smartphones, which utilizes their Bluetooth interface for device/service discovery and content transfer.","Mobile communication,
Mobile computing,
IEEE 802.11 Standards,
Femtocells,
Social network services,
Mobile handsets,
Computer science"
"Game-Theoretic Methods for the Smart Grid: An Overview of Microgrid Systems, Demand-Side Management, and Smart Grid Communications","The future smart grid is envisioned as a large scale cyberphysical system encompassing advanced power, communications, control, and computing technologies. To accommodate these technologies, it will have to build on solid mathematical tools that can ensure an efficient and robust operation of such heterogeneous and large-scale cyberphysical systems. In this context, this article is an overview on the potential of applying game theory for addressing relevant and timely open problems in three emerging areas that pertain to the smart grid: microgrid systems, demand-side management, and communications. In each area, the state-of-the-art contributions are gathered and a systematic treatment, using game theory, of some of the most relevant problems for future power systems is provided. Future opportunities for adopting game-theoretic methodologies in the transition from legacy systems toward smart and intelligent grids are also discussed. In a nutshell, this article provides a comprehensive account of the application of game theory in smart grid systems tailored to the interdisciplinary characteristics of these systems that integrate components from power systems, networking, communications, and control.",
Completely Stale Transmitter Channel State Information is Still Very Useful,"Transmitter channel state information (CSIT) is crucial for the multiplexing gains offered by advanced interference management techniques such as multiuser multiple-input multiple-output (MIMO) and interference alignment. Such CSIT is usually obtained by feedback from the receivers, but the feedback is subject to delays. The usual approach is to use the fed back information to predict the current channel state and then apply a scheme designed assuming perfect CSIT. When the feedback delay is large compared to the channel coherence time, such a prediction approach completely fails to achieve any multiplexing gain. In this paper, we show that even in this case, the completely stale CSI is still very useful. More concretely, we show that in an MIMO broadcast channel with transmit antennas and receivers each with 1 receive antenna, K/1+1/2+···+1/K (>;1) degrees of freedom is achievable even when the fed back channel state is completely independent of the current channel state. Moreover, we establish that if all receivers have independent and identically distributed channels, then this is the optimal number of degrees of freedom achievable. In the optimal scheme, the transmitter uses the fed back CSI to learn the side information that the receivers receive from previous transmissions rather than to predict the current channel state. Our result can be viewed as the first example of feedback providing a degree-of-freedom gain in memoryless channels.",
Action bank: A high-level representation of activity in video,"Activity recognition in video is dominated by low- and mid-level features, and while demonstrably capable, by nature, these features carry little semantic meaning. Inspired by the recent object bank approach to image representation, we present Action Bank, a new high-level representation of video. Action bank is comprised of many individual action detectors sampled broadly in semantic space as well as viewpoint space. Our representation is constructed to be semantically rich and even when paired with simple linear SVM classifiers is capable of highly discriminative performance. We have tested action bank on four major activity recognition benchmarks. In all cases, our performance is better than the state of the art, namely 98.2% on KTH (better by 3.3%), 95.0% on UCF Sports (better by 3.7%), 57.9% on UCF50 (baseline is 47.9%), and 26.9% on HMDB51 (baseline is 23.2%). Furthermore, when we analyze the classifiers, we find strong transfer of semantics from the constituent action detectors to the bank classifier.","Detectors,
Humans,
Semantics,
Support vector machines,
Spatiotemporal phenomena,
Correlation,
Vectors"
Interference management in OFDMA femtocell networks: issues and approaches,"One of the effective techniques of improving the coverage and enhancing the capacity and data rate in cellular wireless networks is to reduce the cell size (i.e., cell splitting) and transmission distances. Therefore, the concept of deploying femtocells over macrocell has recently attracted growing interests in academia, industry, and standardization forums. Various technical challenges towards mass deployment of femtocells have been addressed in recent literature. Interference mitigation between neighboring femtocells and between the femtocell and macrocell is considered to be one of the major challenges in femtocell networks because femtocells share the same licensed frequency spectrum with macrocell. Further, the conventional radio resource management techniques for hierarchical cellular system is not suitable for femtocell networks since the positions of the femtocells are random depending on the users' service requirement. In this article, we provide a survey of the different state-of-the-art approaches for interference and resource management in orthogonal frequency-division multiple access (OFDMA)-based femtocell networks. A qualitative comparison among the different approaches is provided. To this end, open challenges in designing interference management schemes for OFDMA femtocell networks are discussed.",
An evaluation of the RGB-D SLAM system,"We present an approach to simultaneous localization and mapping (SLAM) for RGB-D cameras like the Microsoft Kinect. Our system concurrently estimates the trajectory of a hand-held Kinect and generates a dense 3D model of the environment. We present the key features of our approach and evaluate its performance thoroughly on a recently published dataset, including a large set of sequences of different scenes with varying camera speeds and illumination conditions. In particular, we evaluate the accuracy, robustness, and processing time for three different feature descriptors (SIFT, SURF, and ORB). The experiments demonstrate that our system can robustly deal with difficult data in common indoor scenarios while being fast enough for online operation. Our system is fully available as open-source.",
Cooperatively Coevolving Particle Swarms for Large Scale Optimization,"This paper presents a new cooperative coevolving particle swarm optimization (CCPSO) algorithm in an attempt to address the issue of scaling up particle swarm optimization (PSO) algorithms in solving large-scale optimization problems (up to 2000 real-valued variables). The proposed CCPSO2 builds on the success of an early CCPSO that employs an effective variable grouping technique random grouping. CCPSO2 adopts a new PSO position update rule that relies on Cauchy and Gaussian distributions to sample new points in the search space, and a scheme to dynamically determine the coevolving subcomponent sizes of the variables. On high-dimensional problems (ranging from 100 to 2000 variables), the performance of CCPSO2 compared favorably against a state-of-the-art evolutionary algorithm sep-CMA-ES, two existing PSO algorithms, and a cooperative coevolving differential evolution algorithm. In particular, CCPSO2 performed significantly better than sep-CMA-ES and two existing PSO algorithms on more complex multimodal problems (which more closely resemble real-world problems), though not as well as the existing algorithms on unimodal functions. Our experimental results and analysis suggest that CCPSO2 is a highly competitive optimization algorithm for solving large-scale and complex multimodal optimization problems.",
Dual Averaging for Distributed Optimization: Convergence Analysis and Network Scaling,"The goal of decentralized optimization over a network is to optimize a global objective formed by a sum of local (possibly nonsmooth) convex functions using only local computation and communication. It arises in various application domains, including distributed tracking and localization, multi-agent coordination, estimation in sensor networks, and large-scale machine learning. We develop and analyze distributed algorithms based on dual subgradient averaging, and we provide sharp bounds on their convergence rates as a function of the network size and topology. Our analysis allows us to clearly separate the convergence of the optimization algorithm itself and the effects of communication dependent on the network structure. We show that the number of iterations required by our algorithm scales inversely in the spectral gap of the network, and confirm this prediction's sharpness both by theoretical lower bounds and simulations for various networks. Our approach includes the cases of deterministic optimization and communication, as well as problems with stochastic optimization and/or communication.","Convergence,
Optimization,
Network topology,
Algorithm design and analysis,
Stochastic processes,
Program processors,
Minimization"
"NVSim: A Circuit-Level Performance, Energy, and Area Model for Emerging Nonvolatile Memory","Various new nonvolatile memory (NVM) technologies have emerged recently. Among all the investigated new NVM candidate technologies, spin-torque-transfer memory (STT-RAM, or MRAM), phase-change random-access memory (PCRAM), and resistive random-access memory (ReRAM) are regarded as the most promising candidates. As the ultimate goal of this NVM research is to deploy them into multiple levels in the memory hierarchy, it is necessary to explore the wide NVM design space and find the proper implementation at different memory hierarchy levels from highly latency-optimized caches to highly density- optimized secondary storage. While abundant tools are available as SRAM/DRAM design assistants, similar tools for NVM designs are currently missing. Thus, in this paper, we develop NVSim, a circuit-level model for NVM performance, energy, and area estimation, which supports various NVM technologies, including STT-RAM, PCRAM, ReRAM, and legacy NAND Flash. NVSim is successfully validated against industrial NVM prototypes, and it is expected to help boost architecture-level NVM-related studies.","Nonvolatile memory,
Arrays,
Phase change random access memory,
Wires,
Distributed databases,
Integrated circuit modeling"
The Open Motion Planning Library,"The open motion planning library (OMPL) is a new library for sampling-based motion planning, which contains implementations of many state-of-the-art planning algorithms. The library is designed in a way that it allows the user to easily solve a variety of complex motion planning problems with minimal input. OMPL facilitates the addition of new motion planning algorithms, and it can be conveniently interfaced with other software components. A simple graphical user interface (GUI) built on top of the library, a number of tutorials, demos, and programming assignments are designed to teach students about sampling-based motion planning. The library is also available for use through Robot Operating System (ROS).",
Molecular Communication and Networking: Opportunities and Challenges,"The ability of engineered biological nanomachines to communicate with biological systems at the molecular level is anticipated to enable future applications such as monitoring the condition of a human body, regenerating biological tissues and organs, and interfacing artificial devices with neural systems. From the viewpoint of communication theory and engineering, molecular communication is proposed as a new paradigm for engineered biological nanomachines to communicate with the natural biological nanomachines which form a biological system. Distinct from the current telecommunication paradigm, molecular communication uses molecules as the carriers of information; sender biological nanomachines encode information on molecules and release the molecules in the environment, the molecules then propagate in the environment to receiver biological nanomachines, and the receiver biological nanomachines biochemically react with the molecules to decode information. Current molecular communication research is limited to small-scale networks of several biological nanomachines. Key challenges to bridge the gap between current research and practical applications include developing robust and scalable techniques to create a functional network from a large number of biological nanomachines. Developing networking mechanisms and communication protocols is anticipated to introduce new avenues into integrating engineered and natural biological nanomachines into a single networked system. In this paper, we present the state-of-the-art in the area of molecular communication by discussing its architecture, features, applications, design, engineering, and physical modeling. We then discuss challenges and opportunities in developing networking mechanisms and communication protocols to create a network from a large number of bio-nanomachines for future applications.","Molecular communication,
Receivers,
Nanobioscience,
Chemicals,
Biological information theory"
NeNMF: An Optimal Gradient Method for Nonnegative Matrix Factorization,"Nonnegative matrix factorization (NMF) is a powerful matrix decomposition technique that approximates a nonnegative matrix by the product of two low-rank nonnegative matrix factors. It has been widely applied to signal processing, computer vision, and data mining. Traditional NMF solvers include the multiplicative update rule (MUR), the projected gradient method (PG), the projected nonnegative least squares (PNLS), and the active set method (AS). However, they suffer from one or some of the following three problems: slow convergence rate, numerical instability and nonconvergence. In this paper, we present a new efficient NeNMF solver to simultaneously overcome the aforementioned problems. It applies Nesterov's optimal gradient method to alternatively optimize one factor with another fixed. In particular, at each iteration round, the matrix factor is updated by using the PG method performed on a smartly chosen search point, where the step size is determined by the Lipschitz constant. Since NeNMF does not use the time consuming line search and converges optimally at rate in optimizing each matrix factor, it is superior to MUR and PG in terms of efficiency as well as approximation accuracy. Compared to PNLS and AS that suffer from numerical instability problem in the worst case, NeNMF overcomes this deficiency. In addition, NeNMF can be used to solve -norm, -norm and manifold regularized NMF with the optimal convergence rate. Numerical experiments on both synthetic and real-world datasets show the efficiency of NeNMF for NMF and its variants comparing to representative NMF solvers. Extensive experiments on document clustering suggest the effectiveness of NeNMF.","Gradient methods,
Convergence,
Matrix decomposition,
Sparse matrices,
Least squares approximation,
Educational institutions"
Sensor-Based Activity Recognition,"Research on sensor-based activity recognition has, recently, made significant progress and is attracting growing attention in a number of disciplines and application domains. However, there is a lack of high-level overview on this topic that can inform related communities of the research state of the art. In this paper, we present a comprehensive survey to examine the development and current status of various aspects of sensor-based activity recognition. We first discuss the general rationale and distinctions of vision-based and sensor-based activity recognition. Then, we review the major approaches and methods associated with sensor-based activity monitoring, modeling, and recognition from which strengths and weaknesses of those approaches are highlighted. We make a primary distinction in this paper between data-driven and knowledge-driven approaches, and use this distinction to structure our survey. We also discuss some promising directions for future research.","Monitoring,
Hidden Markov models,
Wearable sensors,
Biomedical monitoring,
Human factors,
Data models"
"Lyapunov, Adaptive, and Optimal Design Techniques for Cooperative Systems on Directed Communication Graphs","This paper presents three design techniques for cooperative control of multiagent systems on directed graphs, namely, Lyapunov design, neural adaptive design, and linear quadratic regulator (LQR)-based optimal design. Using a carefully constructed Lyapunov equation for digraphs, it is shown that many results of cooperative control on undirected graphs or balanced digraphs can be extended to strongly connected digraphs. Neural adaptive control technique is adopted to solve the cooperative tracking problems of networked nonlinear systems with unknown dynamics and disturbances. Results for both first-order and high-order nonlinear systems are given. Two examples, i.e., cooperative tracking control of coupled Lagrangian systems and modified FitzHugh-Nagumo models, justify the feasibility of the proposed neural adaptive control technique. For cooperative tracking control of the general linear systems, which include integrator dynamics as special cases, it is shown that the control gain design can be decoupled from the topology of the graphs, by using the LQR-based optimal control technique. Moreover, the synchronization region is unbounded, which is a desired property of the controller. The proposed optimal control method is applied to cooperative tracking control of two-mass-spring systems, which are well-known models for vibration in many mechanical systems.","Laplace equations,
Multiagent systems,
Regulators,
Synchronization,
Eigenvalues and eigenfunctions,
Lyapunov methods"
Modern Microwave Ferrites,"Microwave ferrites are ubiquitous in systems that send, receive, and manipulate electromagnetic signals across very high frequency to quasi-optical frequency bands. In this paper, modern microwave ferrites are reviewed including spinel, garnet, and hexaferrite systems as thin and thick films, powders and compacts, and metamaterials. Their fundamental properties and utility are examined in the context of high frequency applications ranging from the VHF to millimeter-wave bands. Perspective and outlook of advances in theory, processing, and devices occurring in the science and engineering communities since the year 2000 are presented and discussed.","Ferrites,
Magnetic resonance,
Magnetization,
Magnetic anisotropy,
Magnetic noise,
Magnetic shielding"
Adaptive Hypergraph Learning and its Application in Image Classification,"Recent years have witnessed a surge of interest in graph-based transductive image classification. Existing simple graph-based transductive learning methods only model the pairwise relationship of images, however, and they are sensitive to the radius parameter used in similarity calculation. Hypergraph learning has been investigated to solve both difficulties. It models the high-order relationship of samples by using a hyperedge to link multiple samples. Nevertheless, the existing hypergraph learning methods face two problems, i.e., how to generate hyperedges and how to handle a large set of hyperedges. This paper proposes an adaptive hypergraph learning method for transductive image classification. In our method, we generate hyperedges by linking images and their nearest neighbors. By varying the size of the neighborhood, we are able to generate a set of hyperedges for each image and its visual neighbors. Our method simultaneously learns the labels of unlabeled images and the weights of hyperedges. In this way, we can automatically modulate the effects of different hyperedges. Thorough empirical studies show the effectiveness of our approach when compared with representative baselines.","Learning systems,
Image classification,
Training,
Educational institutions,
Manifolds,
Support vector machines,
Computer science"
Vehicle-to-Aggregator Interaction Game,"Electric vehicles (EVs) are likely to become very popular worldwide within the next few years. With possibly millions of such vehicles operating across the country, one can establish a distributed electricity storage system that comprises of the EVs' batteries with a huge total storage capacity. This can help the power grid by providing various ancillary services, once an effective vehicle-to-grid (V2G) market is established. In this paper, we propose a new game-theoretic model to understand the interactions among EVs and aggregators in a V2G market, where EVs participate in providing frequency regulation service to the grid. We develop a smart pricing policy and design a mechanism to achieve optimal frequency regulation performance in a distributed fashion. Simulation results show that our proposed pricing model and designed mechanism work well and can benefit both EVs (in terms of obtaining additional income) and the grid (in terms of achieving the frequency regulation command signal).",
Detecting activities of daily living in first-person camera views,"We present a novel dataset and novel algorithms for the problem of detecting activities of daily living (ADL) in firstperson camera views. We have collected a dataset of 1 million frames of dozens of people performing unscripted, everyday activities. The dataset is annotated with activities, object tracks, hand positions, and interaction events. ADLs differ from typical actions in that they can involve long-scale temporal structure (making tea can take a few minutes) and complex object interactions (a fridge looks different when its door is open). We develop novel representations including (1) temporal pyramids, which generalize the well-known spatial pyramid to approximate temporal correspondence when scoring a model and (2) composite object models that exploit the fact that objects look different when being interacted with. We perform an extensive empirical evaluation and demonstrate that our novel representations produce a two-fold improvement over traditional approaches. Our analysis suggests that real-world ADL recognition is “all about the objects,” and in particular, “all about the objects being interacted with.”","Cameras,
Hidden Markov models,
Visualization,
Detectors,
Face,
Biomedical monitoring,
Taxonomy"
Neural-Network-Based Decentralized Adaptive Output-Feedback Control for Large-Scale Stochastic Nonlinear Systems,This paper focuses on the problem of neural-network-based decentralized adaptive output-feedback control for a class of nonlinear strict-feedback large-scale stochastic systems. The dynamic surface control technique is used to avoid the explosion of computational complexity in the backstepping design process. A novel direct adaptive neural network approximation method is proposed to approximate the unknown and desired control input signals instead of the unknown nonlinear functions. It is shown that the designed controller can guarantee all the signals in the closed-loop system to be semiglobally uniformly ultimately bounded in a mean square. Simulation results are provided to demonstrate the effectiveness of the developed control design approach.,
Kalman Filter for Robot Vision: A Survey,"Kalman filters have received much attention with the increasing demands for robotic automation. This paper briefly surveys the recent developments for robot vision. Among many factors that affect the performance of a robotic system, Kalman filters have made great contributions to vision perception. Kalman filters solve uncertainties in robot localization, navigation, following, tracking, motion control, estimation and prediction, visual servoing and manipulation, and structure reconstruction from a sequence of images. In the 50th anniversary, we have noticed that more than 20 kinds of Kalman filters have been developed so far. These include extended Kalman filters and unscented Kalman filters. In the last 30 years, about 800 publications have reported the capability of these filters in solving robot vision problems. Such problems encompass a rather wide application area, such as object modeling, robot control, target tracking, surveillance, search, recognition, and assembly, as well as robotic manipulation, localization, mapping, navigation, and exploration. These reports are summarized in this review to enable easy referral to suitable methods for practical solutions. Representative contributions and future research trends are also addressed in an abstract level.","Kalman filters,
Tracking,
Robot kinematics,
Robot vision,
Computer vision,
Visualization"
"Wireless Myths, Realities, and Futures: From 3G/4G to Optical and Quantum Wireless","1) The Myth: Sixty years of research following Shannon's pioneering paper has led to telecommunications solutions operating arbitrarily close to the channel capacity-“flawless telepresence” with zero error is available to anyone, anywhere, anytime across the globe. 2)The Reality: Once we leave home or the office, even top of the range iPhones and tablet computers fail to maintain ""flawless telepresence"" quality. They also fail to approach the theoretical performance predictions. The 1000-fold throughput increase of the best third- generation (3G) phones over second-generation (2G) GSM phones and the 1000-fold increased teletraffic predictions of the next decade require substantial further bandwidth expansion toward ever increasing carrier frequencies, expanding beyond the radiofrequency (RF) band to optical frequencies, where substantial bandwidths are available. 3) The Future: However, optical and quantum-domain wireless communications is less developed than RF wireless. It is also widely recognized that the pathloss of RF wireless systems monotonically increases with the carrier frequency and this additional challenge has to be tackled by appropriate countermeasures in future research. Hence, we set out to seek promising techniques of tackling the aforementioned challenges and for resolving the conflicting design constraints imposed on the flawless telepresence systems of the future. To disspell the myth, we evaluate both the operational 3G as well as the emerging fourth-generation (4G) wireless systems and demonstrate that there is a substantial difference between their theoretical and their practically attainable performance. The reality is that the teletraffic predictions indicate further thirst for bandwidth, which cannot be readily satisfied within the most popular 1-2-GHz carrier-frequency range, where the best propagation conditions prevail. We briefly consider the 10-300-GHz unlicensed band as a potential source of further spectrum, followed by a review of advances way beyond the upper edge of the RF range at 300 GHz, namely to the realms of optical wireless (OW) communications. As the carrier frequency is increased, the pathloss is also increased, which results in ever smaller cells. Furthermore, the high-frequency RF waves predominantly obey line-of-sight (LOS) propagation-like visible light. The future requires advances in both infrared and visible-light communications for circumventing the LOS nature of light. We hypothesize that light-emitting diode (LED) arrays acting as ""massive"" multiple-input-multiple-output (MIMO) components as well as transmitter/receiver cooperation might be conceived. The heterogeneous networks of the near future will rely on seamless, near-instantaneous handovers among OW hotspots, RF hotspots, and oversailing larger cells. These ""massive"" MIMOs might impose a high complexity, hence their reduced-complexity noncoherently detected counterparts might be favored. Finally, we conclude by touching upon the promising research area of quantum-domain communications, which might be expected to circumvent the aforementioned complexity problem of massive MIMOs with the aid of efficient quantum-domain search techniques-a truly exciting research era",
Semisupervised Multiview Distance Metric Learning for Cartoon Synthesis,"In image processing, cartoon character classification, retrieval, and synthesis are critical, so that cartoonists can effectively and efficiently make cartoons by reusing existing cartoon data. To successfully achieve these tasks, it is essential to extract visual features that comprehensively represent cartoon characters and to construct an accurate distance metric to precisely measure the dissimilarities between cartoon characters. In this paper, we introduce three visual features, color histogram, shape context, and skeleton, to characterize the color, shape, and action, respectively, of a cartoon character. These three features are complementary to each other, and each feature set is regarded as a single view. However, it is improper to concatenate these three features into a long vector, because they have different physical properties, and simply concatenating them into a high-dimensional feature vector will suffer from the so-called curse of dimensionality. Hence, we propose a semisupervised multiview distance metric learning (SSM-DML). SSM-DML learns the multiview distance metrics from multiple feature sets and from the labels of unlabeled cartoon characters simultaneously, under the umbrella of graph-based semisupervised learning. SSM-DML discovers complementary characteristics of different feature sets through an alternating optimization-based iterative algorithm. Therefore, SSM-DML can simultaneously accomplish cartoon character classification and dissimilarity measurement. On the basis of SSM-DML, we develop a novel system that composes the modules of multiview cartoon character classification, multiview graph-based cartoon synthesis, and multiview retrieval-based cartoon synthesis. Experimental evaluations based on the three modules suggest the effectiveness of SSM-DML in cartoon applications.","Measurement,
Feature extraction,
Vectors,
Shape,
Animation,
Visualization,
Image color analysis"
Applying Convolutional Neural Networks concepts to hybrid NN-HMM model for speech recognition,"Convolutional Neural Networks (CNN) have showed success in achieving translation invariance for many image processing tasks. The success is largely attributed to the use of local filtering and max-pooling in the CNN architecture. In this paper, we propose to apply CNN to speech recognition within the framework of hybrid NN-HMM model. We propose to use local filtering and max-pooling in frequency domain to normalize speaker variance to achieve higher multi-speaker speech recognition performance. In our method, a pair of local filtering layer and max-pooling layer is added at the lowest end of neural network (NN) to normalize spectral variations of speech signals. In our experiments, the proposed CNN architecture is evaluated in a speaker independent speech recognition task using the standard TIMIT data sets. Experimental results show that the proposed CNN method can achieve over 10% relative error reduction in the core TIMIT test sets when comparing with a regular NN using the same number of hidden layers and weights. Our results also show that the best result of the proposed CNN model is better than previously published results on the same TIMIT test sets that use a pre-trained deep NN model.","Hidden Markov models,
Convolution,
Speech,
Artificial neural networks,
Speech recognition,
Acoustics,
Training"
Rotation-Invariant Image and Video Description With Local Binary Pattern Features,"In this paper, we propose a novel approach to compute rotation-invariant features from histograms of local noninvariant patterns. We apply this approach to both static and dynamic local binary pattern (LBP) descriptors. For static-texture description, we present LBP histogram Fourier (LBP-HF) features, and for dynamic-texture recognition, we present two rotation-invariant descriptors computed from the LBPs from three orthogonal planes (LBP-TOP) features in the spatiotemporal domain. LBP-HF is a novel rotation-invariant image descriptor computed from discrete Fourier transforms of LBP histograms. The approach can be also generalized to embed any uniform features into this framework, and combining the supplementary information, e.g., sign and magnitude components of the LBP, together can improve the description ability. Moreover, two variants of rotation-invariant descriptors are proposed to the LBP-TOP, which is an effective descriptor for dynamic-texture recognition, as shown by its recent success in different application problems, but it is not rotation invariant. In the experiments, it is shown that the LBP-HF and its extensions outperform noninvariant and earlier versions of the rotation-invariant LBP in the rotation-invariant texture classification. In experiments on two dynamic-texture databases with rotations or view variations, the proposed video features can effectively deal with rotation variations of dynamic textures (DTs). They also are robust with respect to changes in viewpoint, outperforming recent methods proposed for view-invariant recognition of DTs.","Histograms,
Databases,
Discrete Fourier transforms,
Lighting,
Spatiotemporal phenomena,
Electronic mail,
Educational institutions"
Molecular Communication in Fluid Media: The Additive Inverse Gaussian Noise Channel,"In this paper, we consider molecular communication, with information conveyed in the time of release of molecules. These molecules propagate to the transmitter through a fluid medium, propelled by a positive drift velocity and Brownian motion. The main contribution of this paper is the development of a theoretical foundation for such a communication system; specifically, the additive inverse Gaussian noise (AIGN) channel model. In such a channel, the information is corrupted by noise that follows an IG distribution. We show that such a channel model is appropriate for molecular communication in fluid media. Taking advantage of the available literature on the IG distribution, upper and lower bounds on channel capacity are developed, and a maximum likelihood receiver is derived. Results are presented which suggest that this channel does not have a single quality measure analogous to signal-to-noise ratio in the additive white Gaussian noise channel. It is also shown that the use of multiple molecules leads to reduced error rate in a manner akin to diversity order in wireless communications. Finally, some open problems are discussed that arise from the IG channel model.","Molecular communication,
Receivers,
Transmitters,
Channel models,
Timing,
Educational institutions"
Issues and future directions in traffic classification,"Traffic classification technology has increased in relevance this decade, as it is now used in the definition and implementation of mechanisms for service differentiation, network design and engineering, security, accounting, advertising, and research. Over the past 10 years the research community and the networking industry have investigated, proposed and developed several classification approaches. While traffic classification techniques are improving in accuracy and efficiency, the continued proliferation of different Internet application behaviors, in addition to growing incentives to disguise some applications to avoid filtering or blocking, are among the reasons that traffic classification remains one of many open problems in Internet research. In this article we review recent achievements and discuss future directions in traffic classification, along with their trade-offs in applicability, reliability, and privacy. We outline the persistently unsolved challenges in the field over the last decade, and suggest several strategies for tackling these challenges to promote progress in the science of Internet traffic classification.",
Slow Feature Analysis for Human Action Recognition,"Slow Feature Analysis (SFA) extracts slowly varying features from a quickly varying input signal [1]. It has been successfully applied to modeling the visual receptive fields of the cortical neurons. Sufficient experimental results in neuroscience suggest that the temporal slowness principle is a general learning principle in visual perception. In this paper, we introduce the SFA framework to the problem of human action recognition by incorporating the discriminative information with SFA learning and considering the spatial relationship of body parts. In particular, we consider four kinds of SFA learning strategies, including the original unsupervised SFA (U-SFA), the supervised SFA (S-SFA), the discriminative SFA (D-SFA), and the spatial discriminative SFA (SD--SFA), to extract slow feature functions from a large amount of training cuboids which are obtained by random sampling in motion boundaries. Afterward, to represent action sequences, the squared first order temporal derivatives are accumulated over all transformed cuboids into one feature vector, which is termed the Accumulated Squared Derivative (ASD) feature. The ASD feature encodes the statistical distribution of slow features in an action sequence. Finally, a linear support vector machine (SVM) is trained to classify actions represented by ASD features. We conduct extensive experiments, including two sets of control experiments, two sets of large scale experiments on the KTH and Weizmann databases, and two sets of experiments on the CASIA and UT-interaction databases, to demonstrate the effectiveness of SFA for human action recognition. Experimental results suggest that the SFA-based approach (1) is able to extract useful motion patterns and improves the recognition performance, (2) requires less intermediate processing steps but achieves comparable or even better performance, and (3) has good potential to recognize complex multiperson activities.","Feature extraction,
Humans,
Visualization,
Neurons,
Vectors,
Spatiotemporal phenomena,
Pattern recognition"
Impact of High PV Penetration on Voltage Profiles in Residential Neighborhoods,"The objective of this paper is to provide an assessment on voltage profiles in residential neighborhoods in the presence of photovoltaic (PV) systems. The network was modeled in PSCAD using common feeder characteristics that Canadian system planners use in suburban residential regions. A simulation study was performed to investigate potential voltage rise issues in the network up to 11.25% total PV penetration in the feeder and LV transformer capacity penetration up to 75%. Results indicate that the PV penetration level should not adversely impact the voltage on the grid when the distributed PV resources do not exceed 2.5 kW per household on average on a typical distribution grid. Moreover, the role of feeder impedance, feeder length, and the transformer short circuit resistance in the determination of the voltage rise is quantified.","Voltage control,
Load modeling,
Substations,
Reactive power,
Inverters,
PSCAD,
Loading"
Neural Synaptic Weighting With a Pulse-Based Memristor Circuit,"A pulse-based programmable memristor circuit for implementing synaptic weights for artificial neural networks is proposed. In the memristor weighting circuit, both positive and negative multiplications are performed via a charge-dependent Ohm's law (). The circuit is composed of five memristors with bridge-like connections and operates like an artificial synapse with pulse-based processing and adjustability. The sign switching pulses, weight setting pulses and synaptic processing pulses are applied through a shared input terminal. Simulations are done with both linear memristor and window-based nonlinear memristor models.",
Joint Relay and Jammer Selection for Secure Two-Way Relay Networks,"In this paper, we investigate joint relay and jammer selection in two-way cooperative networks, consisting of two sources, a number of intermediate nodes, and one eavesdropper, with the constraints of physical-layer security. Specifically, the proposed algorithms select two or three intermediate nodes to enhance security against the malicious eavesdropper. The first selected node operates in the conventional relay mode and assists the sources to deliver their data to the corresponding destinations using an amplify-and-forward protocol. The second and third nodes are used in different communication phases as jammers in order to create intentional interference upon the malicious eavesdropper. First, we find that in a topology where the intermediate nodes are randomly and sparsely distributed, the proposed schemes with cooperative jamming outperform the conventional nonjamming schemes within a certain transmitted power regime. We also find that, in the scenario where the intermediate nodes gather as a close cluster, the jamming schemes may be less effective than their nonjamming counterparts. Therefore, we introduce a hybrid scheme to switch between jamming and nonjamming modes. Simulation results validate our theoretical analysis and show that the hybrid switching scheme further improves the secrecy rate.","Relays,
Jamming,
Security,
Physical layer,
Protocols,
Interference,
Numerical models"
Cyber Security and Privacy Issues in Smart Grids,"Smart grid is a promising power delivery infrastructure integrated with communication and information technologies. Its bi-directional communication and electricity flow enable both utilities and customers to monitor, predict, and manage energy usage. It also advances energy and environmental sustainability through the integration of vast distributed energy resources. Deploying such a green electric system has enormous and far-reaching economic and social benefits. Nevertheless, increased interconnection and integration also introduce cyber-vulnerabilities into the grid. Failure to address these problems will hinder the modernization of the existing power system. In order to build a reliable smart grid, an overview of relevant cyber security and privacy issues is presented. Based on current literatures, several potential research fields are discussed at the end of this paper.","Smart grids,
Protocols,
Computer security,
IEC standards,
Privacy"
Hierarchical Trust Management for Wireless Sensor Networks and its Applications to Trust-Based Routing and Intrusion Detection,"We propose a highly scalable cluster-based hierarchical trust management protocol for wireless sensor networks (WSNs) to effectively deal with selfish or malicious nodes. Unlike prior work, we consider multidimensional trust attributes derived from communication and social networks to evaluate the overall trust of a sensor node. By means of a novel probability model, we describe a heterogeneous WSN comprising a large number of sensor nodes with vastly different social and quality of service (QoS) behaviors with the objective to yield ""ground truth"" node status. This serves as a basis for validating our protocol design by comparing subjective trust generated as a result of protocol execution at runtime against objective trust obtained from actual node status. To demonstrate the utility of our hierarchical trust management protocol, we apply it to trust-based geographic routing and trust-based intrusion detection. For each application, we identify the best trust composition and formation to maximize application performance. Our results indicate that trust-based geographic routing approaches the ideal performance level achievable by flooding-based routing in message delivery ratio and message delay without incurring substantial message overhead. For trust-based intrusion detection, we discover that there exists an optimal trust threshold for minimizing false positives and false negatives. Furthermore, trust-based intrusion detection outperforms traditional anomaly-based intrusion detection approaches in both the detection probability and the false positive probability.","Peer to peer computing,
Wireless sensor networks,
Protocols,
Tin,
Quality of service,
Intrusion detection,
Routing"
Camera Constraint-Free View-Based 3-D Object Retrieval,"Recently, extensive research efforts have been dedicated to view-based methods for 3-D object retrieval due to the highly discriminative property of multiviews for 3-D object representation. However, most of state-of-the-art approaches highly depend on their own camera array settings for capturing views of 3-D objects. In order to move toward a general framework for 3-D object retrieval without the limitation of camera array restriction, a camera constraint-free view-based (CCFV) 3-D object retrieval algorithm is proposed in this paper. In this framework, each object is represented by a free set of views, which means that these views can be captured from any direction without camera constraint. For each query object, we first cluster all query views to generate the view clusters, which are then used to build the query models. For a more accurate 3-D object comparison, a positive matching model and a negative matching model are individually trained using positive and negative matched samples, respectively. The CCFV model is generated on the basis of the query Gaussian models by combining the positive matching model and the negative matching model. The CCFV removes the constraint of static camera array settings for view capturing and can be applied to any view-based 3-D object database. We conduct experiments on the National Taiwan University 3-D model database and the ETH 3-D object database. Experimental results show that the proposed scheme can achieve better performance than state-of-the-art methods.","Three dimensional displays,
Solid modeling,
Cameras,
Arrays,
Databases,
Educational institutions,
Computational modeling"
Kernel Sparse Representation-Based Classifier,"Sparse representation-based classifier (SRC), a combined result of machine learning and compressed sensing, shows its good classification performance on face image data. However, SRC could not well classify the data with the same direction distribution. The same direction distribution means that the sample vectors belonging to different classes distribute on the same vector direction. This paper presents a new classifier, kernel sparse representation-based classifier (KSRC), based on SRC and the kernel trick which is a usual technique in machine learning. KSRC is a nonlinear extension of SRC and can remedy the drawback of SRC. To make the data in an input space separable, we implicitly map these data into a high-dimensional kernel feature space by using some nonlinear mapping associated with a kernel function. Since this kernel feature space has a very high (or possibly infinite) dimensionality, or is unknown, we have to avoid working in this space explicitly. Fortunately, we can indeed reduce the dimensionality of the kernel feature space by exploiting kernel-based dimensionality reduction methods. In the reduced subspace, we need to find sparse combination coefficients for a test sample and assign a class label to it. Similar to SRC, KSRC is also cast into an ℓ1-minimization problem or a quadratically constrained ℓ1 -minimization problem. Extensive experimental results on UCI and face data sets show KSRC improves the performance of SRC.","Kernel,
Machine learning,
Training,
Learning systems,
Sparse matrices,
Compressed sensing,
Vectors"
"Face detection, pose estimation, and landmark localization in the wild","We present a unified model for face detection, pose estimation, and landmark estimation in real-world, cluttered images. Our model is based on a mixtures of trees with a shared pool of parts; we model every facial landmark as a part and use global mixtures to capture topological changes due to viewpoint. We show that tree-structured models are surprisingly effective at capturing global elastic deformation, while being easy to optimize unlike dense graph structures. We present extensive results on standard face benchmarks, as well as a new “in the wild” annotated dataset, that suggests our system advances the state-of-the-art, sometimes considerably, for all three tasks. Though our model is modestly trained with hundreds of faces, it compares favorably to commercial systems trained with billions of examples (such as Google Picasa and face.com).",
SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights,"Learning and then recognizing a route, whether travelled during the day or at night, in clear or inclement weather, and in summer or winter is a challenging task for state of the art algorithms in computer vision and robotics. In this paper, we present a new approach to visual navigation under changing conditions dubbed SeqSLAM. Instead of calculating the single location most likely given a current image, our approach calculates the best candidate matching location within every local navigation sequence. Localization is then achieved by recognizing coherent sequences of these “local best matches”. This approach removes the need for global matching performance by the vision front-end - instead it must only pick the best match within any short sequence of images. The approach is applicable over environment changes that render traditional feature-based techniques ineffective. Using two car-mounted camera datasets we demonstrate the effectiveness of the algorithm and compare it to one of the most successful feature-based SLAM algorithms, FAB-MAP. The perceptual change in the datasets is extreme; repeated traverses through environments during the day and then in the middle of the night, at times separated by months or years and in opposite seasons, and in clear weather and extremely heavy rain. While the feature-based method fails, the sequence-based algorithm is able to match trajectory segments at 100% precision with recall rates of up to 60%.","Trajectory,
Videos,
Visualization,
Cameras,
Vectors,
Robot sensing systems,
Navigation"
Online Optimal Control of Affine Nonlinear Discrete-Time Systems With Unknown Internal Dynamics by Using Time-Based Policy Update,"In this paper, the Hamilton-Jacobi-Bellman equation is solved forward-in-time for the optimal control of a class of general affine nonlinear discrete-time systems without using value and policy iterations. The proposed approach, referred to as adaptive dynamic programming, uses two neural networks (NNs), to solve the infinite horizon optimal regulation control of affine nonlinear discrete-time systems in the presence of unknown internal dynamics and a known control coefficient matrix. One NN approximates the cost function and is referred to as the critic NN, while the second NN generates the control input and is referred to as the action NN. The cost function and policy are updated once at the sampling instant and thus the proposed approach can be referred to as time-based ADP. Novel update laws for tuning the unknown weights of the NNs online are derived. Lyapunov techniques are used to show that all signals are uniformly ultimately bounded and that the approximated control signal approaches the optimal control input with small bounded error over time. In the absence of disturbances, an optimal control is demonstrated. Simulation results are included to show the effectiveness of the approach. The end result is the systematic design of an optimal controller with guaranteed convergence that is suitable for hardware implementation.","Optimal control,
Cost function,
Artificial neural networks,
Approximation methods,
Nonlinear dynamical systems,
Estimation error"
Fuzzy c-Means Algorithms for Very Large Data,"Very large (VL) data or big data are any data that you cannot load into your computer's working memory. This is not an objective definition, but a definition that is easy to understand and one that is practical, because there is a dataset too big for any computer you might use; hence, this is VL data for you. Clustering is one of the primary tasks used in the pattern recognition and data mining communities to search VL databases (including VL images) in various applications, and so, clustering algorithms that scale well to VL data are important and useful. This paper compares the efficacy of three different implementations of techniques aimed to extend fuzzy c-means (FCM) clustering to VL data. Specifically, we compare methods that are based on 1) sampling followed by noniterative extension; 2) incremental techniques that make one sequential pass through subsets of the data; and 3) kernelized versions of FCM that provide approximations based on sampling, including three proposed algorithms. We use both loadable and VL datasets to conduct the numerical experiments that facilitate comparisons based on time and space complexity, speed, quality of approximations to batch FCM (for loadable data), and assessment of matches between partitions and ground truth. Empirical results show that random sampling plus extension FCM, bit-reduced FCM, and approximate kernel FCM are good choices to approximate FCM for VL data. We conclude by demonstrating the VL algorithms on a dataset with 5 billion objects and presenting a set of recommendations regarding the use of different VL FCM clustering schemes.",
An Improved Reversible Data Hiding in Encrypted Images Using Side Match,"This letter proposes an improved version of Zhang's reversible data hiding method in encrypted images. The original work partitions an encrypted image into blocks, and each block carries one bit by flipping three LSBs of a set of pre-defined pixels. The data extraction and image recovery can be achieved by examining the block smoothness. Zhang's work did not fully exploit the pixels in calculating the smoothness of each block and did not consider the pixel correlations in the border of neighboring blocks. These two issues could reduce the correctness of data extraction. This letter adopts a better scheme for measuring the smoothness of blocks, and uses the side-match scheme to further decrease the error rate of extracted-bits. The experimental results reveal that the proposed method offers better performance over Zhang's work. For example, when the block size is set to 8 8, the error rate of the Lena image of the proposed method is 0. 34%, which is significantly lower than 1.21% of Zhang's work.","Data mining,
Encryption,
Histograms,
Estimation,
Materials,
Correlation"
Learning latent temporal structure for complex event detection,"In this paper, we tackle the problem of understanding the temporal structure of complex events in highly varying videos obtained from the Internet. Towards this goal, we utilize a conditional model trained in a max-margin framework that is able to automatically discover discriminative and interesting segments of video, while simultaneously achieving competitive accuracies on difficult detection and recognition tasks. We introduce latent variables over the frames of a video, and allow our algorithm to discover and assign sequences of states that are most discriminative for the event. Our model is based on the variable-duration hidden Markov model, and models durations of states in addition to the transitions between states. The simplicity of our model allows us to perform fast, exact inference using dynamic programming, which is extremely important when we set our sights on being able to process a very large number of videos quickly and efficiently. We show promising results on the Olympic Sports dataset [16] and the 2011 TRECVID Multimedia Event Detection task [18]. We also illustrate and visualize the semantic understanding capabilities of our model.",
Speaker Diarization: A Review of Recent Research,"Speaker diarization is the task of determining “who spoke when?” in an audio or video recording that contains an unknown amount of speech and also an unknown number of speakers. Initially, it was proposed as a research topic related to automatic speech recognition, where speaker diarization serves as an upstream processing step. Over recent years, however, speaker diarization has become an important key technology for many tasks, such as navigation, retrieval, or higher level inference on audio data. Accordingly, many important improvements in accuracy and robustness have been reported in journals and conferences in the area. The application domains, from broadcast news, to lectures and meetings, vary greatly and pose different problems, such as having access to multiple microphones and multimodal information or overlapping speech. The most recent review of existing technology dates back to 2006 and focuses on the broadcast news domain. In this paper, we review the current state-of-the-art, focusing on research developed since 2006 that relates predominantly to speaker diarization for conference meetings. Finally, we present an analysis of speaker diarization performance as reported through the NIST Rich Transcription evaluations on meeting data and identify important areas for future research.",
Bringing Wind Energy to Market,"Wind energy is a rapidly growing source of renewable energy generation. However, the current extra-market approach to its assimilation into the electric grid will not scale at deep penetration levels. In this paper, we investigate how an independent wind power producer might optimally offer its variable power into a competitive electricity market for energy. Starting with a stochastic model for wind power production and a model for a perfectly competitive two-settlement market, we derive explicit formulae for optimal contract offerings and the corresponding optimal expected profit. As wind is an inherently variable source of energy, we explore the sensitivity of optimal expected profit to uncertainty in the underlying wind process. We also examine the role of forecast information and recourse markets in this setting. We quantify the role of reserves in increasing reliability of offered contracts and obtain analytical expressions for marginal profits resulting from investments in improved forecasting and local auxiliary generation. The formulae make explicit the relationship between price signals and the value of such firming strategies.","Wind power generation,
Contracts,
Wind energy,
Wind forecasting,
Uncertainty,
Schedules,
Production"
Economics of Electric Vehicle Charging: A Game Theoretic Approach,"In this paper, the problem of grid-to-vehicle energy exchange between a smart grid and plug-in electric vehicle groups (PEVGs) is studied using a noncooperative Stackelberg game. In this game, on the one hand, the smart grid, which acts as a leader, needs to decide on its price so as to optimize its revenue while ensuring the PEVGs' participation. On the other hand, the PEVGs, which act as followers, need to decide on their charging strategies so as to optimize a tradeoff between the benefit from battery charging and the associated cost. Using variational inequalities, it is shown that the proposed game possesses a socially optimal Stackelberg equilibrium in which the grid optimizes its price while the PEVGs choose their equilibrium strategies. A distributed algorithm that enables the PEVGs and the smart grid to reach this equilibrium is proposed and assessed by extensive simulations. Further, the model is extended to a time-varying case that can incorporate and handle slowly varying environments.","Energy exchange,
Electric vehicles,
Batteries,
Economics,
Power system economics"
An Ensemble Classification-Based Approach Applied to Retinal Blood Vessel Segmentation,"This paper presents a new supervised method for segmentation of blood vessels in retinal photographs. This method uses an ensemble system of bagged and boosted decision trees and utilizes a feature vector based on the orientation analysis of gradient vector field, morphological transformation, line strength measures, and Gabor filter responses. The feature vector encodes information to handle the healthy as well as the pathological retinal image. The method is evaluated on the publicly available DRIVE and STARE databases, frequently used for this purpose and also on a new public retinal vessel reference dataset CHASE_DB1 which is a subset of retinal images of multiethnic children from the Child Heart and Health Study in England (CHASE) dataset. The performance of the ensemble system is evaluated in detail and the incurred accuracy, speed, robustness, and simplicity make the algorithm a suitable tool for automated retinal image analysis.",
Opportunistic Spectrum Access in Cognitive Radio Networks: Global Optimization Using Local Interaction Games,"We investigate the problem of achieving global optimization for distributed channel selections in cognitive radio networks (CRNs), using game theoretic solutions. To cope with the lack of centralized control and local influences, we propose two special cases of local interaction game to study this problem. The first is local altruistic game, in which each user considers the payoffs of itself as well as its neighbors rather than considering itself only. The second is local congestion game, in which each user minimizes the number of competing neighbors. It is shown that with the proposed games, global optimization is achieved with local information. Specifically, the local altruistic game maximizes the network throughput and the local congestion game minimizes the network collision level. Also, the concurrent spatial adaptive play (C-SAP), which is an extension of the existing spatial adaptive play (SAP), is proposed to achieve the global optimum both autonomously as well as rapidly.","Games,
Throughput,
Optimization,
Interference,
Sensors,
Minimization,
Aggregates"
ORION 2.0: A Power-Area Simulator for Interconnection Networks,"As industry moves towards multicore chips, networks-on-chip (NoCs) are emerging as the scalable fabric for interconnecting the cores. With power now the first-order design constraint, early-stage estimation of NoC power has become crucially important. In this work, we present ORION 2.0, an enhanced NoC power and area simulator, which offers significant accuracy improvement relative to its predecessor, ORION 1.0.","Transistors,
Clocks,
Integrated circuit modeling,
Estimation,
Switches,
Mathematical model,
Logic gates"
Trust Computations and Trust Dynamics in Mobile Adhoc Networks: A Survey,"Trust is an important aspect of mobile adhoc networks (MANETs). It enables entities to cope with uncertainty and uncontrollability caused by the free will of others. Trust computations and management are highly challenging issues in MANETs due to computational complexity constraints, and the independent movement of component nodes. This prevents the direct application of techniques suited for other networks. In MANETs, an untrustworthy node can wreak considerable damage and adversely affect the quality and reliability of data. Therefore, analyzing the trust level of a node has a positive influence on the confidence with which an entity conducts transactions with that node. In this work we present a detailed survey on various trust computing approaches that are geared towards MANETs. We highlight the summary and comparisons of these approaches. In addition, we analyze various works on trust dynamics including trust propagation, prediction and aggregation algorithms, the influence of network dynamics on trust dynamics and the impact of trust on security services.","Mobile computing,
Ad hoc networks,
Measurement,
Peer to peer computing,
Sensors,
Security,
Monitoring"
Opportunistic Spectrum Access in Unknown Dynamic Environment: A Game-Theoretic Stochastic Learning Solution,"We investigate the problem of distributed channel selection using a game-theoretic stochastic learning solution in an opportunistic spectrum access (OSA) system where the channel availability statistics and the number of the secondary users are apriori unknown. We formulate the channel selection problem as a game which is proved to be an exact potential game. However, due to the lack of information about other users and the restriction that the spectrum is time-varying with unknown availability statistics, the task of achieving Nash equilibrium (NE) points of the game is challenging. Firstly, we propose a genie-aided algorithm to achieve the NE points under the assumption of perfect environment knowledge. Based on this, we investigate the achievable performance of the game in terms of system throughput and fairness. Then, we propose a stochastic learning automata (SLA) based channel selection algorithm, with which the secondary users learn from their individual action-reward history and adjust their behaviors towards a NE point. The proposed learning algorithm neither requires information exchange, nor needs prior information about the channel availability statistics and the number of secondary users. Simulation results show that the SLA based learning algorithm achieves high system throughput with good fairness.","Games,
Throughput,
Availability,
Heuristic algorithms,
Convergence,
Sensors,
Learning automata"
Volatility of Power Grids Under Real-Time Pricing,"The paper proposes a framework for modeling and analysis of the dynamics of supply, demand, and clearing prices in power systems with real-time retail pricing and information asymmetry. Characterized by passing on the real-time wholesale electricity prices to the end consumers, real-time pricing creates a closed-loop feedback system between the physical layer and the market layer of the system. In the absence of a carefully designed control law, such direct feedback can increase sensitivity and lower the system's robustness to uncertainty in demand and generation. It is shown that price volatility can be characterized in terms of the system's maximal relative price elasticity, defined as the maximal ratio of the generalized price-elasticity of consumers to that of the producers. As this ratio increases, the system may become more volatile. Since new demand response technologies increase the price-elasticity of demand, and since increased penetration of distributed generation can also increase the uncertainty in price-based demand response, the theoretical findings suggest that the architecture under examination can potentially lead to increased volatility. This study highlights the need for assessing architecture systematically and in advance, in order to optimally strike the trade-offs between volatility/robustness and performance metrics such as economic efficiency and environmental efficiency.","Pricing,
Real-time systems,
Power system dynamics,
Uncertainty,
Load modeling,
Power grids,
Lyapunov methods"
A Self-Learning Particle Swarm Optimizer for Global Optimization Problems,"Particle swarm optimization (PSO) has been shown as an effective tool for solving global optimization problems. So far, most PSO algorithms use a single learning pattern for all particles, which means that all particles in a swarm use the same strategy. This monotonic learning pattern may cause the lack of intelligence for a particular particle, which makes it unable to deal with different complex situations. This paper presents a novel algorithm, called self-learning particle swarm optimizer (SLPSO), for global optimization problems. In SLPSO, each particle has a set of four strategies to cope with different situations in the search space. The cooperation of the four strategies is implemented by an adaptive learning framework at the individual level, which can enable a particle to choose the optimal strategy according to its own local fitness landscape. The experimental study on a set of 45 test functions and two real-world problems show that SLPSO has a superior performance in comparison with several other peer algorithms.",
Low-Dose X-ray CT Reconstruction via Dictionary Learning,"Although diagnostic medical imaging provides enormous benefits in the early detection and accuracy diagnosis of various diseases, there are growing concerns on the potential side effect of radiation induced genetic, cancerous and other diseases. How to reduce radiation dose while maintaining the diagnostic performance is a major challenge in the computed tomography (CT) field. Inspired by the compressive sensing theory, the sparse constraint in terms of total variation (TV) minimization has already led to promising results for low-dose CT reconstruction. Compared to the discrete gradient transform used in the TV method, dictionary learning is proven to be an effective way for sparse representation. On the other hand, it is important to consider the statistical property of projection data in the low-dose CT case. Recently, we have developed a dictionary learning based approach for low-dose X-ray CT. In this paper, we present this method in detail and evaluate it in experiments. In our method, the sparse constraint in terms of a redundant dictionary is incorporated into an objective function in a statistical iterative reconstruction framework. The dictionary can be either predetermined before an image reconstruction task or adaptively defined during the reconstruction process. An alternating minimization scheme is developed to minimize the objective function. Our approach is evaluated with low-dose X-ray projections collected in animal and human CT studies, and the improvement associated with dictionary learning is quantified relative to filtered backprojection and TV-based reconstructions. The results show that the proposed approach might produce better images with lower noise and more detailed structural features in our selected cases. However, there is no proof that this is true for all kinds of structures.","Dictionaries,
Image reconstruction,
Computed tomography,
Noise,
TV,
X-ray imaging,
Minimization"
Adaptive Fuzzy Control of a Class of Nonlinear Systems by Fuzzy Approximation Approach,"Controlling nonstrict-feedback nonlinear systems is a challenging problem in control theory. In this paper, we consider adaptive fuzzy control for a class of nonlinear systems with nonstrict-feedback structure by using fuzzy logic systems. A variable separation approach is developed to overcome the difficulty from the nonstrict-feedback structure. Furthermore, based on fuzzy approximation and backstepping techniques, a state feedback adaptive fuzzy tracking controller is proposed, which guarantees that all of the signals in the closed-loop system are bounded, while the tracking error converges to a small neighborhood of the origin. Simulation studies are included to demonstrate the effectiveness of our results.",
Counting People With Low-Level Features and Bayesian Regression,"An approach to the problem of estimating the size of inhomogeneous crowds, which are composed of pedestrians that travel in different directions, without using explicit object segmentation or tracking is proposed. Instead, the crowd is segmented into components of homogeneous motion, using the mixture of dynamic-texture motion model. A set of holistic low-level features is extracted from each segmented region, and a function that maps features into estimates of the number of people per segment is learned with Bayesian regression. Two Bayesian regression models are examined. The first is a combination of Gaussian process regression with a compound kernel, which accounts for both the global and local trends of the count mapping but is limited by the real-valued outputs that do not match the discrete counts. We address this limitation with a second model, which is based on a Bayesian treatment of Poisson regression that introduces a prior distribution on the linear weights of the model. Since exact inference is analytically intractable, a closed-form approximation is derived that is computationally efficient and kernelizable, enabling the representation of nonlinear functions. An approximate marginal likelihood is also derived for kernel hyperparameter learning. The two regression-based crowd counting methods are evaluated on a large pedestrian data set, containing very distinct camera views, pedestrian traffic, and outliers, such as bikes or skateboarders. Experimental results show that regression-based counts are accurate regardless of the crowd size, outperforming the count estimates produced by state-of-the-art pedestrian detectors. Results on 2 h of video demonstrate the efficiency and robustness of the regression-based crowd size estimation over long periods of time.","Bayesian methods,
Approximation methods,
Kernel,
Feature extraction,
Ground penetrating radar,
Training,
Motion segmentation"
Discrete-continuous optimization for multi-target tracking,"The problem of multi-target tracking is comprised of two distinct, but tightly coupled challenges: (i) the naturally discrete problem of data association, i.e. assigning image observations to the appropriate target; (ii) the naturally continuous problem of trajectory estimation, i.e. recovering the trajectories of all targets. To go beyond simple greedy solutions for data association, recent approaches often perform multi-target tracking using discrete optimization. This has the disadvantage that trajectories need to be pre-computed or represented discretely, thus limiting accuracy. In this paper we instead formulate multi-target tracking as a discrete-continuous optimization problem that handles each aspect in its natural domain and allows leveraging powerful methods for multi-model fitting. Data association is performed using discrete optimization with label costs, yielding near optimality. Trajectory estimation is posed as a continuous fitting problem with a simple closed-form solution, which is used in turn to update the label costs. We demonstrate the accuracy and robustness of our approach with state-of-the-art performance on several standard datasets.",
Robust Secure Transmission in MISO Channels Based on Worst-Case Optimization,"This paper studies robust transmission schemes for multiple-input single-output (MISO) wiretap channels. Both the cases of direct transmission and cooperative jamming with a helper are investigated with imperfect channel state information (CSI) for the eavesdropper links. Robust transmit covariance matrices are obtained based on worst-case secrecy rate maximization, under both individual and global power constraints. For the case of an individual power constraint, we show that the nonconvex maximin optimization problem can be transformed into a quasi-convex problem that can be efficiently solved with existing methods. For a global power constraint, the joint optimization of the transmit covariance matrices and power allocation between the source and the helper is studied. We also investigate the robust wiretap transmission problem for the case with a quality-of-service constraint at the legitimate receiver. Numerical results show the advantage of the proposed robust design. In particular, for the global power constraint scenario, although cooperative jamming is not necessary for optimal transmission with perfect eavesdropper's CSI, we show that robust jamming support can increase the worst-case secrecy rate and lower the signal to interference-plus-noise ratio at the eavesdropper in the presence of channel mismatches between the transmitters and the eavesdropper.",
Camera-based navigation of a low-cost quadrocopter,"In this paper, we describe a system that enables a low-cost quadrocopter coupled with a ground-based laptop to navigate autonomously in previously unknown and GPS-denied environments. Our system consists of three components: a monocular SLAM system, an extended Kalman filter for data fusion and state estimation and a PID controller to generate steering commands. Next to a working system, the main contribution of this paper is a novel, closed-form solution to estimate the absolute scale of the generated visual map from inertial and altitude measurements. In an extensive set of experiments, we demonstrate that our system is able to navigate in previously unknown environments at absolute scale without requiring artificial markers or external sensors. Furthermore, we show (1) its robustness to temporary loss of visual tracking and significant delays in the communication process, (2) the elimination of odometry drift as a result of the visual SLAM system and (3) accurate, scale-aware pose estimation and navigation.","Visualization,
Simultaneous localization and mapping,
Delay,
Cameras,
Accuracy,
Navigation"
A Splitting-Based Iterative Algorithm for Accelerated Statistical X-Ray CT Reconstruction,"Statistical image reconstruction using penalized weighted least-squares (PWLS) criteria can improve image-quality in X-ray computed tomography (CT). However, the huge dynamic range of the statistical weights leads to a highly shift-variant inverse problem making it difficult to precondition and accelerate existing iterative algorithms that attack the statistical model directly. We propose to alleviate the problem by using a variable-splitting scheme that separates the shift-variant and (""nearly"") invariant components of the statistical data model and also decouples the regularization term. This leads to an equivalent constrained problem that we tackle using the classical method-of-multipliers framework with alternating minimization. The specific form of our splitting yields an alternating direction method of multipliers (ADMM) algorithm with an inner-step involving a ""nearly"" shift-invariant linear system that is suitable for FFT-based preconditioning using cone-type filters. The proposed method can efficiently handle a variety of convex regularization criteria including smooth edge-preserving regularizers and non- smooth sparsity-promoting ones based on the ℓ1-norm and total variation. Numerical experiments with synthetic and real in vivo human data illustrate that cone-filter preconditioners accelerate the proposed ADMM resulting in fast convergence of ADMM compared to conventional (nonlinear conjugate gradient, ordered subsets) and state-of-the-art (MFISTA, split-Bregman) algorithms that are applicable for CT.","Computed tomography,
Image reconstruction,
Convergence,
Acceleration,
Minimization,
Iterative methods,
Optimization"
Dynamic Security Risk Management Using Bayesian Attack Graphs,"Security risk assessment and mitigation are two vital processes that need to be executed to maintain a productive IT infrastructure. On one hand, models such as attack graphs and attack trees have been proposed to assess the cause-consequence relationships between various network states, while on the other hand, different decision problems have been explored to identify the minimum-cost hardening measures. However, these risk models do not help reason about the causal dependencies between network states. Further, the optimization formulations ignore the issue of resource availability while analyzing a risk model. In this paper, we propose a risk management framework using Bayesian networks that enable a system administrator to quantify the chances of network compromise at various levels. We show how to use this information to develop a security mitigation and management plan. In contrast to other similar models, this risk model lends itself to dynamic analysis during the deployed phase of the network. A multiobjective optimization platform provides the administrator with all trade-off information required to make decisions in a resource constrained environment.","Computer security,
Risk management,
Bayesian methods,
Computer crime,
Computational modeling,
Analytical models,
Computer hacking"
On the Partially Overlapped Channel Assignment on Wireless Mesh Network Backbone: A Game Theoretic Approach,"The Wireless Mesh Network (WMN) has already been recognized as a promising broadband access network technology from both academic and commercial perspective. In order to improve the performance of WMNs, extensive research efforts have been dedicated towards finding means to increase the number of simultaneous transmissions in the network while avoiding signal interference among radios. In case of WMNs based on IEEE 802.11 b/g standards, most recent research works have relied upon the usage of orthogonal channels for solving the Channel Assignment (CA) problem. In this paper, we explore the possibility of exploiting Partially Overlapped Channels (POCs) by introducing a novel game theoretic distributed CA algorithm. Our proposed algorithm outperforms both the conventional orthogonal channel approach and the recent heuristic CA algorithms using POC. The proposed algorithm is shown to achieve near-optimal performance in the average case. In addition, the upper bound Price of Anarchy for Multi-Radio Multi-Channel (MRMC) networks is derived to evaluate the effectiveness of the proposed approach.",
Design and Analysis of a Robust Broadcast Scheme for VANET Safety-Related Services,"IEEE- and ASTM-adopted dedicated short-range communications (DSRC) standards are key enabling technologies for the next generation of vehicular safety communications. Vehicle-safety-related communication services, which require reliable and fast message delivery, usually demand broadcast communications in vehicular ad hoc networks (VANETs). In this paper, we propose and justify a distributive cross-layer scheme for the design of the control channel in DSRC with three levels of broadcast services that are critical to most potential vehicle-safety-related applications. The new scheme for enhancing broadcast reliability includes preemptive priority in safety services, dynamic receiver-oriented packet repetitions for one-hop emergency warning message dissemination, a multifrequency busy tone and minislot within the distributed interframe space (DIFS) in IEEE 802.11, and robust distance-based relay selection for multihop broadcast of emergency notification messages. Compared with a current draft of IEEE 802.11p and other schemes for DSRC safety-related services, the scheme proposed in this paper is more robust and scalable and easy to implement. Additionally, we investigate the reliability and performance of the proposed broadcast scheme for DSRC VANET safety-related services on the highway analytically and by simulations. The analytic model accounts for the impact of the hidden terminal problem, the fading channel conditions, varied message arrival intervals, and the backoff counter process on reliability and performance.",
Bridging the Gap between Social Animal and Unsocial Machine: A Survey of Social Signal Processing,"Social Signal Processing is the research domain aimed at bridging the social intelligence gap between humans and machines. This paper is the first survey of the domain that jointly considers its three major aspects, namely, modeling, analysis, and synthesis of social behavior. Modeling investigates laws and principles underlying social interaction, analysis explores approaches for automatic understanding of social exchanges recorded with different sensors, and synthesis studies techniques for the generation of social behavior via various forms of embodiment. For each of the above aspects, the paper includes an extensive survey of the literature, points to the most important publicly available resources, and outlines the most fundamental challenges ahead.","Humans,
Signal processing,
Face,
Animals,
Electronic mail,
Context"
Data Security and Privacy Protection Issues in Cloud Computing,"It is well-known that cloud computing has many potential advantages and many enterprise applications and data are migrating to public or hybrid cloud. But regarding some business-critical applications, the organizations, especially large enterprises, still wouldn't move them to cloud. The market size the cloud computing shared is still far behind the one expected. From the consumers' perspective, cloud computing security concerns, especially data security and privacy protection issues, remain the primary inhibitor for adoption of cloud computing services. This paper provides a concise but all-round analysis on data security and privacy protection issues associated with cloud computing across all stages of data life cycle. Then this paper discusses some current solutions. Finally, this paper describes future research work about data security and privacy protection issues in cloud.","Cloud computing,
Data privacy,
Computational modeling,
Encryption,
Data models"
A Survey on Service-Oriented Network Virtualization Toward Convergence of Networking and Cloud Computing,"The crucial role that networking plays in Cloud computing calls for a holistic vision that allows combined control, management, and optimization of both networking and computing resources in a Cloud environment, which leads to a convergence of networking and Cloud computing. Network virtualization is being adopted in both telecommunications and the Internet as a key attribute for the next generation networking. Virtualization, as a potential enabler of profound changes in both communications and computing domains, is expected to bridge the gap between these two fields. Service-Oriented Architecture (SOA), when applied in network virtualization, enables a Network-as-a-Service (NaaS) paradigm that may greatly facilitate the convergence of networking and Cloud computing. Recently the application of SOA in network virtualization has attracted extensive interest from both academia and industry. Although numerous relevant research works have been published, they are currently scattered across multiple fields in the literature, including telecommunications, computer networking, Web services, and Cloud computing. In this article we present a comprehensive survey on the latest developments in service-oriented network virtualization for supporting Cloud computing, particularly from a perspective of network and Cloud convergence through NaaS. Specifically, we first introduce the SOA principle and review recent research progress on applying SOA to support network virtualization in both telecommunications and the Internet. Then we present a framework of network-Cloud convergence based on service-oriented network virtualization and give a survey on key technologies for realizing NaaS, mainly focusing on state of the art of network service description, discovery, and composition. We also discuss the challenges brought in by network-Cloud convergence to these technologies and research opportunities available in these areas, with a hope to arouse the research community's interest in this emerging interdisciplinary field.",
Exponential Stabilization of Memristive Neural Networks With Time Delays,"In this paper, a general class of memristive neural networks with time delays is formulated and studied. Some sufficient conditions in terms of linear matrix inequalities are obtained, in order to achieve exponential stabilization. The result can be applied to the closed-loop control of memristive systems. In particular, several succinct criteria are given to ascertain the exponential stabilization of memristive cellular neural networks. In addition, a simplified and effective algorithm is considered for design of the optimal controller. These conditions are the improvement and extension of the existing results in the literature. Two numerical examples are given to illustrate the theoretical results via computer simulations.",
The Science of Guessing: Analyzing an Anonymized Corpus of 70 Million Passwords,"We report on the largest corpus of user-chosen passwords ever studied, consisting of anonymized password histograms representing almost 70 million Yahoo! users, mitigating privacy concerns while enabling analysis of dozens of subpopulations based on demographic factors and site usage characteristics. This large data set motivates a thorough statistical treatment of estimating guessing difficulty by sampling from a secret distribution. In place of previously used metrics such as Shannon entropy and guessing entropy, which cannot be estimated with any realistically sized sample, we develop partial guessing metrics including a new variant of guesswork parameterized by an attacker's desired success rate. Our new metric is comparatively easy to approximate and directly relevant for security engineering. By comparing password distributions with a uniform distribution which would provide equivalent security against different forms of guessing attack, we estimate that passwords provide fewer than 10 bits of security against an online, trawling attack, and only about 20 bits of security against an optimal offline dictionary attack. We find surprisingly little variation in guessing difficulty; every identifiable group of users generated a comparably weak password distribution. Security motivations such as the registration of a payment card have no greater impact than demographic factors such as age and nationality. Even proactive efforts to nudge users towards better password choices with graphical feedback make little difference. More surprisingly, even seemingly distant language communities choose the same weak passwords and an attacker never gains more than a factor of 2 efficiency gain by switching from the globally optimal dictionary to a population-specific lists.","Measurement,
Dictionaries,
Entropy,
Privacy,
Semantics,
Cryptography"
Simultaneous Reconstruction of Activity and Attenuation in Time-of-Flight PET,"In positron emission tomography (PET) and single photon emission tomography (SPECT), attenuation correction is necessary for quantitative reconstruction of the tracer distribution. Previously, several attempts have been made to estimate the attenuation coefficients from emission data only. These attempts had limited success, because the problem does not have a unique solution, and severe and persistent “cross-talk” between the estimated activity and attenuation distributions was observed. In this paper, we show that the availability of time-of-flight (TOF) information eliminates the cross-talk problem by destroying symmetries in the associated Fisher information matrix. We propose a maximum-a-posteriori reconstruction algorithm for jointly estimating the attenuation and activity distributions from TOF PET data. The performance of the algorithm is studied with 2-D simulations, and further illustrated with phantom experiments and with a patient scan. The estimated attenuation image is robust to noise, and does not suffer from the cross-talk that was observed in non-TOF PET. However, some constraining is still mandatory, because the TOF data determine the attenuation sinogram only up to a constant offset.","Attenuation,
Image reconstruction,
Positron emission tomography,
Phantoms,
Image resolution,
Maximum likelihood estimation,
Joints"
Model Predictive Control of an AFE Rectifier With Dynamic References,"In this paper, a finite control set model predictive controller for closed-loop control of an active front-end rectifier is presented. The proposed method operates in discrete time and does not require additional modulators. The key novelty of the control algorithm presented lies in the way dynamic references are handled. The control strategy is capable of providing suitable references for the source active power and the rectified voltage, without requiring additional control loops. Experimental results show that fast and accurate tracking of dynamic dc voltage and reactive power references can be achieved, while respecting the restrictions on maximum power levels of the rectifier.","Switches,
Cost function,
Predictive models,
Reactive power,
Capacitors,
Integrated circuits,
Predictive control"
Feedback Stabilization of Discrete-Time Networked Systems Over Fading Channels,"This paper addresses the mean square stabilization problem for discrete-time networked control systems over fading channels. We show that there exists a requirement on the network over which an unstable plant can be stabilized. In the case of state feedback, necessary and sufficient conditions on the network for mean square stabilizability are derived. Under a parallel transmission strategy and the assumption that the overall mean square capacity of the network is fixed and can be assigned among parallel input channels, a tight lower bound on the overall mean square capacity for mean square stabilizability is presented in terms of the Mahler measure of the plant. The minimal overall capacity for stabilizability is also provided under a serial transmission strategy. For the case of dynamic output feedback, a tight lower bound on the capacity requirement for stabilization of SISO plants is given in terms of the anti-stable poles, nonminimum phase zeros and relative degree of the plant. Sufficient and necessary conditions are further derived for triangularly decoupled MIMO plants. The effect of pre- and post-channel processing and channel feedback is also discussed, where the channel feedback is identified as a key component in eliminating the limitation on stabilization induced by the nonminimum phase zeros and high relative degree of the plant. Finally, the extension to the case with output fading channels and the application of the results to vehicle platooning are presented.","State feedback,
Fading,
MIMO,
Quantization,
Output feedback,
Uncertainty,
Linear matrix inequalities"
Iterative Learning Control in Health Care: Electrical Stimulation and Robotic-Assisted Upper-Limb Stroke Rehabilitation,"Annually, 15 million people worldwide suffer a stroke, and 5 million are left permanently disabled. A stroke is usually caused when a blood clot blocks a vessel in the brain and acts like a dam, stopping the blood reaching the regions downstream. Alternatively, it may be caused by a hemorrhage, in which a vessel ruptures and leaks blood into surrounding areas. As a result, some of the connecting nerve cells die, and the person commonly suffers partial paralysis on one side of the body, termed hemiplegia. Cells killed in this way cannot regrow, but the brain has some spare capacity and, hence, new connections can be made. The brain is continually and rapidly changing as new skills are learned, new connections are formed, and redundant ones disappear. A person who relearns skills after a stroke goes through the same process as someone learning to play tennis or a baby learning to walk, requiring sensory feedback during the repeated practice of a task. Unfortunately, the problem is that they can hardly move and, therefore, do not receive feedback on their performance.",
Active Capacitor Voltage Balancing in Single-Phase Flying-Capacitor Multilevel Power Converters,"Two active capacitor voltage balancing schemes are proposed for single-phase (H-bridge) flying-capacitor multilevel converters. They are based on the circuit equations of flying-capacitor converters. Consequently, they can be implemented using straightforward control rules. In particular, the first technique is based on an algorithm which follows the standard multilevel modulation. Then, it utilizes a redundant state selection table for capacitor voltage balancing. In the second method, multiple duty cycles are defined and modulated in direct response to the capacitor voltages. The most important advantage of these two proposed methods is that they can be utilized to converters with any desired number of levels in their output voltage. Moreover, the analysis and implementation of both methods are straightforward. Through simulation and experimental implementation, these methods are shown to be effective on capacitor voltage regulation in flying-capacitor multilevel converters.",
Energy Management Optimization in a Battery/Supercapacitor Hybrid Energy Storage System,"Batteries and supercapacitors (SC) complement one another; a battery has a relatively high energy density but a low power density, whereas an SC has a relatively high power density but a low energy density. In order to offset their opposing limitations, an active battery/SC hybrid energy storage system (HESS) using a dc/dc converter has been proposed. The major problem concerning an active HESS is in how to control the current flow in order to achieve two objectives: the minimization of the magnitude/fluctuation of the current flowing in and out of the battery and the energy loss seen by the SCs. This problem has not been analytically investigated for an optimal solution regarding these two goals. In this paper, we present an optimal energy management scheme for active HESS. In order to obtain the optimal solution, we formulate the problem as an optimization problem concerning these two objectives. Observing that the feasibility and optimality of the solution critically depends on the boundary parameters of the problem, we present an algorithm that effectively adjusts the parameter values. The proposed algorithm is based on the multiplicative-increase- additive-decrease principle, which guarantees a feasible optimal solution. Through MATLAB simulations, we demonstrate that the proposed scheme can optimally minimize the magnitude/fluctuation of the battery current and the SC energy loss.",
ReTrust: Attack-Resistant and Lightweight Trust Management for Medical Sensor Networks,"Wireless medical sensor networks (MSNs) enable ubiquitous health monitoring of users during their everyday lives, at health sites, without restricting their freedom. Establishing trust among distributed network entities has been recognized as a powerful tool to improve the security and performance of distributed networks such as mobile ad hoc networks and sensor networks. However, most existing trust systems are not well suited for MSNs due to the unique operational and security requirements of MSNs. Moreover, similar to most security schemes, trust management methods themselves can be vulnerable to attacks. Unfortunately, this issue is often ignored in existing trust systems. In this paper, we identify the security and performance challenges facing a sensor network for wireless medical monitoring and suggest it should follow a two-tier architecture. Based on such an architecture, we develop an attack-resistant and lightweight trust management scheme named ReTrust. This paper also reports the experimental results of the Collection Tree Protocol using our proposed system in a network of TelosB motes, which show that ReTrust not only can efficiently detect malicious/faulty behaviors, but can also significantly improve the network performance in practice.","Security,
Peer to peer computing,
Manganese,
Protocols,
Wireless sensor networks,
Monitoring,
Computer architecture"
AutoAssem: An Automated Assembly Planning System for Complex Products,"To automate assembly planning for complex products such as aircraft components, an assembly planning and simulation system called AutoAssem has been developed. In this paper, its system architecture is presented; the main components and the key technologies in each component are discussed. The core functions of the system that have been focused include Digital Assembly Modeling, Assembly Sequence Planning (ASP), Path Planning, Visualization, and Simulation. In contrast to existing assembly planning systems, one of the novelties of the system is it allows the assembly plans be automatically generated from a CAD assembly model with minimal manual interventions. Within the system, new methodologies have been developed to: (i) create Assembly Relationship Matrices; (ii) plan assembly sequences; (iii) generate assembly paths; and (iv) visualize and simulate assembly plans. To illustrate the application of the system, the assembly of a worm gear reducer is used as an example throughout this paper for demonstration purpose. AutoAssem has been successfully applied to virtual assembly design for various complex products so far.","Assembly,
Solid modeling,
Planning,
Object oriented modeling,
Design automation,
Software tools"
Where should the bugs be fixed? More accurate information retrieval-based bug localization based on bug reports,"For a large and evolving software system, the project team could receive a large number of bug reports. Locating the source code files that need to be changed in order to fix the bugs is a challenging task. Once a bug report is received, it is desirable to automatically point out to the files that developers should change in order to fix the bug. In this paper, we propose BugLocator, an information retrieval based method for locating the relevant files for fixing a bug. BugLocator ranks all files based on the textual similarity between the initial bug report and the source code using a revised Vector Space Model (rVSM), taking into consideration information about similar bugs that have been fixed before. We perform large-scale experiments on four open source projects to localize more than 3,000 bugs. The results show that BugLocator can effectively locate the files where the bugs should be fixed. For example, relevant buggy files for 62.60% Eclipse 3.1 bugs are ranked in the top ten among 12,863 files. Our experiments also show that BugLocator outperforms existing state-of-the-art bug localization methods.",
A Novel Valley-Fill SEPIC-Derived Power Supply Without Electrolytic Capacitor for LED Lighting Application,"The high-brightness white-light-emitting diode (LED) has attracted a lot of attention for its high efficacy, simple to drive, environmentally friendly, long lifespan, and compact size. The power supply for LED also requires long life, while maintaining high efficiency, high power factor, and low cost. However, a typical power supply design employs an electrolytic capacitor as the storage capacitor, which is not only bulky, but also with a short lifespan, thus hampering performance improvement of the entire LED lighting system. In this paper, a novel power factor correction (PFC) topology is proposed by inserting the valley-fill circuit in the single-ended primary inductance converter (SEPIC)-derived converter, which can reduce the voltage stress of the storage capacitor and output diode under the same power factor condition. This valley-fill SEPIC-derived topology is, then, proposed for LED lighting applications. By allowing a relatively large voltage ripple in the PFC design and operating in the discontinuous conduction mode (DCM), the proposed PFC topology is able to eliminate the electrolytic capacitor, while maintaining high power factor and high efficiency. Under the electrolytic capacitor-less condition, the proposed PFC circuit can reduce the capacitance of the storage capacitor to half for the same power factor and output voltage ripple as comparing to its original circuit. To further increase the efficiency of LED driver proposal, a twin-bus buck converter is introduced and employed as the second-stage current regulator with the PWM dimming function. The basic operating principle and analysis will be described in detail. A 50-W prototype has been built and tested in the laboratory, and the experimental results under universal input-voltage operation are presented to verify the effectiveness and advantages of the proposal.","Capacitors,
LED lamps,
Topology,
Regulators,
Pulse width modulation"
Multistability of Neural Networks With Time-Varying Delays and Concave-Convex Characteristics,"In this paper, stability of multiple equilibria of neural networks with time-varying delays and concave-convex characteristics is formulated and studied. Some sufficient conditions are obtained to ensure that an n-neuron neural network with concave-convex characteristics can have a fixed point located in the appointed region. By means of an appropriate partition of the n-dimensional state space, when nonlinear activation functions of an n-neuron neural network are concave or convex in 2k+2m-1 intervals, this neural network can have (2k+2m-1)n equilibrium points. This result can be applied to the multiobjective optimal control and associative memory. In particular, several succinct criteria are given to ascertain multistability of cellular neural networks. These stability conditions are the improvement and extension of the existing stability results in the literature. A numerical example is given to illustrate the theoretical findings via computer simulations.","Nonlinear systems,
Delay,
Vectors,
Biological neural networks,
Stability analysis,
Recurrent neural networks"
Physical Layer Security for Two-Way Untrusted Relaying With Friendly Jammers,"In this paper, we consider a two-way relay system where the two sources can only communicate through an untrusted intermediate relay and investigate the physical layer security issue in this two-way untrusted relay scenario. Specifically, we regard the intermediate relay as an eavesdropper from which the information transmitted by the sources needs to be kept confidential, despite the fact that its cooperation in relaying this information is essential. We first indicate that a nonzero secrecy rate is indeed achievable in this two-way untrusted relay system even without the help of external friendly jammers. As for the system with friendly jammers, after further analysis, we can obtain the secrecy rate of the sources can be effectively improved by utilizing proper jamming power from the friendly jammers. Then, we formulate a Stackelberg game between the sources and the friendly jammers as a power control scheme to achieve the optimized secrecy rate of the sources, in which the sources are treated as the sole buyer and the friendly jammers are the sellers. In addition, the optimal solutions of the jamming power and the asking prices are given, and a distributed updating algorithm to obtain the Stackelberg equilibrium is provided for the proposed game. Finally, the simulation results verify the properties and efficiency of the proposed Stackelberg-game-based scheme.","Jamming,
Relays,
Games,
Security,
Physical layer,
Optimized production technology,
Power control"
Video Transport Evaluation With H.264 Video Traces,"The performance evaluation of video transport mechanisms becomes increasingly important as encoded video accounts for growing portions of the network traffic. Compared to the widely studied MPEG-4 encoded video, the recently adopted H.264 video coding standards include novel mechanisms, such as hierarchical B frame prediction structures and highly efficient quality scalable coding, that have important implications for network transport. This tutorial introduces a trace-based evaluation methodology for the network transport of H.264 encoded video. We first give an overview of H.264 video coding, and then present the trace structures for capturing the characteristics of H.264 encoded video. We give an overview of the typical video traffic and quality characteristics of H.264 encoded video. Finally, we explain how to account for the H.264 specific coding mechanisms, such as hierarchical B frames, in networking studies.","Encoding,
Video coding,
Static VAr compensators,
Scalability,
Transform coding,
Streaming media"
"Hardware/Software Codesign: The Past, the Present, and Predicting the Future","Hardware/software codesign investigates the concurrent design of hardware and software components of complex electronic systems. It tries to exploit the synergy of hardware and software with the goal to optimize and/or satisfy design constraints such as cost, performance, and power of the final product. At the same time, it targets to reduce the time-to-market frame considerably. This paper presents major achievements of two decades of research on methods and tools for hardware/software codesign by starting with a historical survey of its roots, by highlighting its major research directions and achievements until today, and finally, by predicting in which direction research in codesign might evolve in the decades to come.","Hardware design languages,
Software development,
Consumer electronics,
System-on-a-chip,
Computer architecture,
Complexity theory,
Simulation"
The Fourth Element,"This tutorial clarifies the axiomatic definition of (v(α); i(β)) circuit elements via a lookup table dubbed an A-pad, of admissible (v; i) signals measured via Gedanken probing circuits. The (v(α); i(β)) elements are ordered via a complexity metric. Under this metric, the memristor emerges naturally as the fourth element, characterized by a state-dependent Ohm's law. A logical generalization to memristive devices reveals a common fingerprint consisting of a dense continuum of pinched hysteresis loops whose area decreases with the frequency ω and tends to a straight line as ω ~ ∞, for all bipolar periodic signals and for all initial conditions. This common fingerprint suggests that the term memristor be used hence-forth as a moniker for memristive devices.","Memristors,
Finite element methods,
Measurement,
Complexity theory,
Hysteresis,
Capacitors,
Tutorials"
Business Intelligence for Enterprise Systems: A Survey,"Business intelligence (BI) is the process of transforming raw data into useful information for more effective strategic, operational insights, and decision-making purposes so that it yields real business benefits. This new emerging technique can not only improve applications in enterprise systems and industrial informatics, respectively, but also play a very important role to bridge the connection between enterprise systems and industrial informatics. This paper was intended as a short introduction to BI with the emphasis on the fundamental algorithms and recent progress. In addition, we point out the challenges and opportunities to smoothly connect industrial informatics to enterprise systems for BI research.",
Meta-Analysis of the First Facial Expression Recognition Challenge,"Automatic facial expression recognition has been an active topic in computer science for over two decades, in particular facial action coding system action unit (AU) detection and classification of a number of discrete emotion states from facial expressive imagery. Standardization and comparability have received some attention; for instance, there exist a number of commonly used facial expression databases. However, lack of a commonly accepted evaluation protocol and, typically, lack of sufficient details needed to reproduce the reported individual results make it difficult to compare systems. This, in turn, hinders the progress of the field. A periodical challenge in facial expression recognition would allow such a comparison on a level playing field. It would provide an insight on how far the field has come and would allow researchers to identify new goals, challenges, and targets. This paper presents a meta-analysis of the first such challenge in automatic recognition of facial expressions, held during the IEEE conference on Face and Gesture Recognition 2011. It details the challenge data, evaluation protocol, and the results attained in two subchallenges: AU detection and classification of facial expression imagery in terms of a number of discrete emotion categories. We also summarize the lessons learned and reflect on the future of the field of facial expression recognition in general and on possible future challenges in particular.","Gold,
Emotion recognition,
Databases,
Face,
Face recognition,
Training,
Protocols"
A Fast Way of Calculating Exact Hypervolumes,We describe a new algorithm WFG for calculating hypervolume exactly. WFG is based on the recently-described observation that the exclusive hypervolume of a point p relative to a set S is equal to the difference between the inclusive hypervolume of p and the hypervolume of S with each point limited by the objective values in p. WFG applies this technique iteratively over a set to calculate its hypervolume. Experiments show that WFG is substantially faster (in five or more objectives) than all previously-described algorithms that calculate hypervolume exactly.,"Optimization,
Complexity theory,
Sorting,
Approximation algorithms,
Algorithm design and analysis,
Evolutionary computation,
Measurement"
Memristor Bridge Synapse-Based Neural Network and Its Learning,"Analog hardware architecture of a memristor bridge synapse-based multilayer neural network and its learning scheme is proposed. The use of memristor bridge synapse in the proposed architecture solves one of the major problems, regarding nonvolatile weight storage in analog neural network implementations. To compensate for the spatial nonuniformity and nonideal response of the memristor bridge synapse, a modified chip-in-the-loop learning scheme suitable for the proposed neural network architecture is also proposed. In the proposed method, the initial learning is conducted in software, and the behavior of the software-trained network is learned by the hardware network by learning each of the single-layered neurons of the network independently. The forward calculation of the single-layered neuron learning is implemented on circuit hardware, and followed by a weight updating phase assisted by a host computer. Unlike conventional chip-in-the-loop learning, the need for the readout of synaptic weights for calculating weight updates in each epoch is eliminated by virtue of the memristor bridge synapse and the proposed learning scheme. The hardware architecture along with the successful implementation of proposed learning on a three-bit parity network, and on a car detection network is also presented.",
On Degrees of Freedom Region of MIMO Networks Without Channel State Information at Transmitters,"We study the effect of the absence of channel knowledge at the transmitters for multiple-input-multiple-output (MIMO) networks. Specifically, we assume perfect channel state information at the receivers, no channel state information at the transmitter(s), and independent identically distributed (i.i.d.) Rayleigh fading across antennas, users and time slots. We provide the characterization of the degrees of freedom (DoF) region for a 2-user MIMO broadcast channel. We then provide a DoF region outer bound for a 2-user MIMO interference channel. This bound is shown to be tight for all possible combinations of the number of antennas at each node except for one case. To analyze the unsolved case, we point out the potential of interference alignment in the 2-user MIMO interference channel with no channel state information at the transmitters. As a byproduct, we explore a special class of MIMO broadcast channels where the capacity region is established by using the outer bound developed in the DoF analysis.","MIMO,
Interference channels,
Receiving antennas,
Transmitting antennas"
Energy Efficient Virtual Network Embedding,"Waste of energy due to over-provisioning and over-dimensioning of network infrastructures has recently stimulated the interest on energy consumption reduction by Internet Service Providers (ISPs). By means of resource consolidation, network virtualization based architectures will enable energy saving. In this letter, we extend the well-known virtual network embedding problem (VNE) to energy awareness and propose a mixed integer program (MIP) which provides optimal energy efficient embeddings. Simulation results show the energy gains of the proposed MIP over the existing cost-based VNE approach.","Substrates,
Energy consumption,
Switches,
Bandwidth,
Green products,
Tin,
Europe"
A Taxonomy and Experimental Study on Prototype Generation for Nearest Neighbor Classification,"The nearest neighbor (NN) rule is one of the most successfully used techniques to resolve classification and pattern recognition tasks. Despite its high classification accuracy, this rule suffers from several shortcomings in time response, noise sensitivity, and high storage requirements. These weaknesses have been tackled by many different approaches, including a good and well-known solution that we can find in the literature, which consists of the reduction of the data used for the classification rule (training data). Prototype reduction techniques can be divided into two different approaches, which are known as prototype selection and prototype generation (PG) or abstraction. The former process consists of choosing a subset of the original training data, whereas PG builds new artificial prototypes to increase the accuracy of the NN classification. In this paper, we provide a survey of PG methods specifically designed for the NN rule. From a theoretical point of view, we propose a taxonomy based on the main characteristics presented in them. Furthermore, from an empirical point of view, we conduct a wide experimental study that involves small and large datasets to measure their performance in terms of accuracy and reduction capabilities. The results are contrasted through nonparametrical statistical tests. Several remarks are made to understand which PG models are appropriate for application to different datasets.","Prototypes,
Artificial neural networks,
Accuracy,
Training,
Taxonomy,
Noise,
Nearest neighbor searches"
Reducing Transient and Steady State Electricity Consumption in HVAC Using Learning-Based Model-Predictive Control,"Heating, ventilation, and air conditioning (HVAC) systems are an important target for efficiency improvements through new equipment and retrofitting because of their large energy footprint. One type of equipment that is common in homes and some offices is an electrical, single-stage heat pump air conditioner (AC). To study this setup, we have built the Berkeley Retrofitted and Inexpensive HVAC Testbed for Energy Efficiency (BRITE) platform. This platform allows us to actuate an AC unit that controls the room temperature of a computer laboratory on the Berkeley campus that is actively used by students, while sensors record room temperature and AC energy consumption. We build a mathematical model of the temperature dynamics of the room, and combining this model with statistical methods allows us to compute the heating load due to occupants and equipment using only a single temperature sensor. Next, we implement a control strategy that uses learning-based model-predictive control (MPC) to learn and compensate for the amount of heating due to occupancy as it varies throughout the day and year. Experiments on BRITE show that our techniques result in a 30%-70% reduction in energy consumption as compared to two-position control, while still maintaining a comfortable room temperature. The energy savings are due to our control scheme compensating for varying occupancy, while considering the transient and steady state electrical consumption of the AC. Our techniques can likely be generalized to other HVAC systems while still maintaining these energy saving features.","Heat pumps,
Transient analysis,
Steady-state,
Temperature control,
Energy efficiency,
Cyberspace,
Energy consumption,
Ventilation,
Air conditioning,
Network topology,
Learning systems,
Predictive control"
Persistent Robotic Tasks: Monitoring and Sweeping in Changing Environments,"In this paper, we present controllers that enable mobile robots to persistently monitor or sweep a changing environment. The environment is modeled as a field that is defined over a finite set of locations. The field grows linearly at locations that are not within the range of a robot and decreases linearly at locations that are within range of a robot. We assume that the robots travel on given closed paths. The speed of each robot along its path is controlled to prevent the field from growing unbounded at any location. We consider the space of speed controllers that are parametrized by a finite set of basis functions. For a single robot, we develop a linear program that computes a speed controller in this space to keep the field bounded, if such a controller exists. Another linear program is derived to compute the speed controller that minimizes the maximum field value over the environment. We extend our linear program formulation to develop a multirobot controller that keeps the field bounded. We characterize, both theoretically and in simulation, the robustness of the controllers to modeling errors and to stochasticity in the environment.",
Using the Averaged Hausdorff Distance as a Performance Measure in Evolutionary Multiobjective Optimization,"The Hausdorff distance dH is a widely used tool to measure the distance between different objects in several research fields. Possible reasons for this might be that it is a natural extension of the well-known and intuitive distance between points and/or the fact that dH defines in certain cases a metric in the mathematical sense. In evolutionary multiobjective optimization (EMO) the task is typically to compute the entire solution set-the so-called Pareto set-respectively its image, the Pareto front. Hence, dH should, at least at first sight, be a natural choice to measure the performance of the outcome set in particular since it is related to the terms spread and convergence as used in EMO literature. However, so far, dH does not find the general approval in the EMO community. The main reason for this is that dH penalizes single outliers of the candidate set which does not comply with the use of stochastic search algorithms such as evolutionary strategies. In this paper, we define a new performance indicator, Δp, which can be viewed as an “averaged Hausdorff distance” between the outcome set and the Pareto front and which is composed of (slight modifications of) the well-known indicators generational distance (GD) and inverted generational distance (IGD). We will discuss theoretical properties of Δp (as well as for GD and IGD) such as the metric properties and the compliance with state-of-theart multiobjective evolutionary algorithms (MOEAs), and will further on demonstrate by empirical results the potential of Δp as a new performance indicator for the evaluation of MOEAs.","Approximation methods,
Measurement,
Optimization,
Convergence,
Approximation algorithms,
Delta modulation,
Benchmark testing"
WAVE: Popularity-based and collaborative in-network caching for content-oriented networks,"In content-oriented networking, content files are typically cached in network nodes, and hence how to cache content files is crucial for the efficient content delivery and cache storage utilization. In this paper, we propose a content caching scheme, WAVE, in which the number of chunks to be cached is adjusted based on the popularity of the content. In WAVE, an upstream node recommends the number of chunks to be cached at its downstream node, which is exponentially increased as the request count increases. Simulation results reveal that the average hop count of content delivery of WAVE is lower than other schemes, and the inter-ISP traffic volume of WAVE is the second lowest (CDN is the lowest). Also, WAVE achieves higher cache hit ratio and fewer frequent cache replacements than other on-demand caching strategies.",
WhittleSearch: Image search with relative attribute feedback,"We propose a novel mode of feedback for image search, where a user describes which properties of exemplar images should be adjusted in order to more closely match his/her mental model of the image(s) sought. For example, perusing image results for a query “black shoes”, the user might state, “Show me shoe images like these, but sportier.” Offline, our approach first learns a set of ranking functions, each of which predicts the relative strength of a nameable attribute in an image (`sportiness', `furriness', etc.). At query time, the system presents an initial set of reference images, and the user selects among them to provide relative attribute feedback. Using the resulting constraints in the multi-dimensional attribute space, our method updates its relevance function and re-ranks the pool of images. This procedure iterates using the accumulated constraints until the top ranked images are acceptably close to the user's envisioned target. In this way, our approach allows a user to efficiently “whittle away” irrelevant portions of the visual feature space, using semantic language to precisely communicate her preferences to the system. We demonstrate the technique for refining image search for people, products, and scenes, and show it outperforms traditional binary relevance feedback in terms of search speed and accuracy.","Footwear,
Visualization,
Training,
Semantics,
Image color analysis,
Humans,
Cognitive science"
Optimal Dispatching of Distributed Generators and Storage Systems for MV Islanded Microgrids,"This paper presents an optimization procedure that enables the optimal dispatching of distributed generators and storage systems in a medium-voltage islanded microgrid. The network is assumed to be supplied by programmable (dispatchable) and nonprogrammable generators (i.e. nondispatchable, such as renewable energy sources-based units). The optimization goal is to minimize the overall microgrid operating cost and the pollutants emission of the programmable generators, assuming that all of the power made available by the renewable generators (photovoltaic and wind systems) is either directly injected into the network or stored in order to be subsequently delivered according to the proposed storage units' management strategy. The optimization is carried out by a niching evolutionary algorithm (NEA) that is able to find multiple optima and the variation of the objective function in their neighborhood. NEAs allow overcoming the performance of standard algorithms used for optimal power-flow calculations in power systems by avoiding falling into local optima. The optimization procedure is performed on a test microgrid and verified by computer simulations. The numerical results show that the solutions can always improve the microgrid performances irrespective of the network operating conditions in all of the considered cases.",
Low-Cost Thin Glass Interposers as a Superior Alternative to Silicon and Organic Interposers for Packaging of 3-D ICs,"Interconnecting integrated circuits (ICs) and 3-D-ICs to the system board (printed circuit board) are currently achieved using organic or silicon-based interposers. Organic interposers face several challenges in packaging 2-D and 3-D-ICs beyond the 32-nm node, primarily due to their poor dimensional stability and coefficient of thermal expansion (CTE) mismatch to silicon. Silicon interposers made with back-end of line wafer processes can achieve the required wiring and I/O density, but their high-cost limit them to high-performance applications. Glass is proposed as a superior alternative to organic and silicon-based interposers for packaging of future ICs and 3-D-ICs with highest I/Os at lowest cost. This paper presents for the first time a novel thin and large panel glass interposer capable of scaling to 700 mm and larger panels with potential for significant cost reduction over interposers made on 200-mm or 300-mm wafers. The formation of small through vias at high speed has been the biggest technical barrier for the adoption of glass as an interposer and system substrate; and this paper describes pioneering research in via-formation in thin glass substrates, using a novel “polymer-on-glass” approach. Electrical modeling and design of through package vias (TPVs) in glass is discussed in detail, and the feasibility of 50-μm pitch TPVs in 180-μm thin glass substrates has been demonstrated. The excellent surface finish and low CTE of glass leads to increased I/O density, and increased functionality per unit area leading to system miniaturization.","Glass,
Laser ablation,
Substrates,
Polymers,
Silicon,
Surface treatment,
Metallization"
Multiclass Imbalance Problems: Analysis and Potential Solutions,"Class imbalance problems have drawn growing interest recently because of their classification difficulty caused by the imbalanced class distributions. In particular, many ensemble methods have been proposed to deal with such imbalance. However, most efforts so far are only focused on two-class imbalance problems. There are unsolved issues in multiclass imbalance problems, which exist in real-world applications. This paper studies the challenges posed by the multiclass imbalance problems and investigates the generalization ability of some ensemble solutions, including our recently proposed algorithm AdaBoost.NC, with the aim of handling multiclass and imbalance effectively and directly. We first study the impact of multiminority and multimajority on the performance of two basic resampling techniques. They both present strong negative effects. “Multimajority” tends to be more harmful to the generalization performance. Motivated by the results, we then apply AdaBoost.NC to several real-world multiclass imbalance tasks and compare it to other popular ensemble methods. AdaBoost.NC is shown to be better at recognizing minority class examples and balancing the performance among classes in terms of G-mean without using any class decomposition.",
Simultaneous and Proportional Estimation of Hand Kinematics From EMG During Mirrored Movements at Multiple Degrees-of-Freedom,"This paper proposes and tests on able-bodied subjects a control strategy that can be practically applied in unilateral transradial amputees for simultaneous and proportional control of multiple degrees-of-freedom (DOFs). We used artificial neural networks to estimate kinematics of the complex wrist/hand from high-density surface electromyography (EMG) signals of the contralateral limb during mirrored bilateral movements in free space. The movements tested involved the concurrent activation of wrist flexion/extension, radial/ulnar deviation, forearm pronation/supination, and hand closing. The accuracy in estimation was in the range 79%-88% (r2 index) for the four DOFs in six able-bodied subjects. Moreover, the estimation of the pronation/supination angle (wrist rotation) was influenced by the reduction in the number of EMG channels used for the estimation to a greater extent than the other DOFs. In conclusion, the proposed method and set-up provide a viable means for proportional and simultaneous control of multiple DOFs for hand prostheses.","Electromyography,
Kinematics,
Estimation,
Wrist,
Muscles,
Training,
Force"
Identification and Learning Control of Ocean Surface Ship Using Neural Networks,"This paper presents the problems of accurate identification and learning control of ocean surface ship in uncertain dynamical environments. Thanks to the universal approximation capabilities, radial basis function neural networks (NNs) are employed to approximate the unknown ocean surface ship dynamics. A stable adaptive NN tracking controller is first designed using backstepping and Lyapunov synthesis. Partial persistent excitation (PE) condition of some internal signals in the closed-loop system is satisfied during tracking control to a recurrent reference trajectory. Under the PE condition, the proposed adaptive NN controller is shown to be capable of accurate identification/learning of the uncertain ship dynamics in the stable control process. Subsequently, a novel NN learning control method which effectively utilizes the learned knowledge without re-adapting to the unknown ship dynamics is proposed to achieve closed-loop stability and improved control performance. Simulation studies are performed to demonstrate the effectiveness of the proposed method.",
Recovering Compressively Sampled Signals Using Partial Support Information,"We study recovery conditions of weighted l1 minimization for signal reconstruction from compressed sensing measurements when partial support information is available. We show that if at least 50% of the (partial) support information is accurate, then weighted l1 minimization is stable and robust under weaker sufficient conditions than the analogous conditions for standard l1 minimization. Moreover, weighted l1 minimization provides better upper bounds on the reconstruction error in terms of the measurement noise and the compressibility of the signal to be recovered. We illustrate our results with extensive numerical experiments on synthetic data and real audio and video signals.","Minimization,
Robustness,
Compressed sensing,
Noise measurement,
Noise,
Weight measurement,
Approximation methods"
Interference-aware resource allocation for device-to-device communications as an underlay using sequential second price auction,"An innovative resource allocation scheme is proposed to improve the performance of device-to-device (D2D) communications as an underlay in the downlink (DL) cellular networks. To optimize the system sum rate over the resource sharing of both D2D and cellular modes, we introduce a sequential second price auction as the allocation mechanism. In the auction, all the spectrum resources are considered as a set of resource units, which are auctioned off by groups of D2D pairs in sequence. We first formulate the value of each resource unit for each D2D pair, as a basis of the proposed auction. And then a detailed auction algorithm is explained using a N-ary tree. The equilibrium path of a sequential second price auction is obtained in the auction process, and the state value of the leaf node in the end of the path represents the final allocation. The simulation results show that the proposed auction algorithm leads to a good performance on the system sum rate, efficiency and fairness.","Resource management,
Interference,
Receivers,
Simulation,
Power control,
Games,
Fading"
Memristor Emulator for Memristor Circuit Applications,"A memristor emulator which imitates the behavior of a TiO2 memristor is presented. Our emulator is built from off-the-shelf solid state components. To develop real world memristor circuit applications, the emulator can be used for breadboard experiments in real time. Two or more memristor emulators can be connected in serial, in parallel, or in hybrid (serial and parallel combined) with identical or opposite polarities. With a simple change of connection, each memristor emulator can be switched between a decremental configuration or an incremental configuration. The hardware and spice simulation of the proposed emulator showed promising results that provides an alternative solution of hp TiO2 memristor model in real circuit.","Memristors,
Resistance,
Integrated circuit modeling,
Mathematical model,
Mirrors,
Capacitors"
A Novel Data Embedding Method Using Adaptive Pixel Pair Matching,"This paper proposes a new data-hiding method based on pixel pair matching (PPM). The basic idea of PPM is to use the values of pixel pair as a reference coordinate, and search a coordinate in the neighborhood set of this pixel pair according to a given message digit. The pixel pair is then replaced by the searched coordinate to conceal the digit. Exploiting modification direction (EMD) and diamond encoding (DE) are two data-hiding methods proposed recently based on PPM. The maximum capacity of EMD is 1.161 bpp and DE extends the payload of EMD by embedding digits in a larger notational system. The proposed method offers lower distortion than DE by providing more compact neighborhood sets and allowing embedded digits in any notational system. Compared with the optimal pixel adjustment process (OPAP) method, the proposed method always has lower distortion for various payloads. Experimental results reveal that the proposed method not only provides better performance than those of OPAP and DE, but also is secure under the detection of some well-known steganalysis techniques.",
"Image reconstruction from highly undersampled (k, t)-space data with joint partial separability and sparsity constraints","Partial separability (PS) and sparsity have been previously used to enable reconstruction of dynamic images from undersampled (k,t)-space data. This paper presents a new method to use PS and sparsity constraints jointly for enhanced performance in this context. The proposed method combines the complementary advantages of PS and sparsity constraints using a unified formulation, achieving significantly better reconstruction performance than using either of these constraints individually. A globally convergent computational algorithm is described to efficiently solve the underlying optimization problem. Reconstruction results from simulated and in vivo cardiac MRI data are also shown to illustrate the performance of the proposed method.","Image reconstruction,
Imaging,
Spatiotemporal phenomena,
Equations,
Convergence,
Numerical models,
Vectors"
An Evolutionary Multiobjective Sleep-Scheduling Scheme for Differentiated Coverage in Wireless Sensor Networks,"We propose an online, multiobjective optimization (MO) algorithm to efficiently schedule the nodes of a wireless sensor network (WSN) and to achieve maximum lifetime. Instead of dealing with traditional grid or uniform coverage, we focus on the differentiated or probabilistic coverage where different regions require different levels of sensing. The MO algorithm helps to attain a better tradeoff among energy consumption, lifetime, and coverage. The algorithm can be run every time a node failure occurs due to power failure of the node battery so that it may reschedule the network. This scheduling is modeled as a combinatorial, multiobjective, and constrained optimization problem with energy and noncoverage as the two objectives. The basic evolutionary multiobjective optimizer used is known as decomposition-based multiobjective evolutionary algorithm (MOEA/D) which is modified by integrating the concept of fuzzy Pareto dominance. The performance of the resulting algorithm, which is called MOEA/DFD, is compared with the performance of the original MOEA/D, which is another very well known MO algorithm called nondominated sorting genetic algorithm (NSGA-II), and an IBM optimization software package called CPLEX. In all the tests, MOEA/DFD is observed to outperform all other algorithms.","Optimization,
Vectors,
Sensors,
Linear programming,
Wireless sensor networks,
Event detection"
Combining Head Pose and Eye Location Information for Gaze Estimation,"Head pose and eye location for gaze estimation have been separately studied in numerous works in the literature. Previous research shows that satisfactory accuracy in head pose and eye location estimation can be achieved in constrained settings. However, in the presence of nonfrontal faces, eye locators are not adequate to accurately locate the center of the eyes. On the other hand, head pose estimation techniques are able to deal with these conditions; hence, they may be suited to enhance the accuracy of eye localization. Therefore, in this paper, a hybrid scheme is proposed to combine head pose and eye location information to obtain enhanced gaze estimation. To this end, the transformation matrix obtained from the head pose is used to normalize the eye regions, and in turn, the transformation matrix generated by the found eye location is used to correct the pose estimation procedure. The scheme is designed to enhance the accuracy of eye location estimations, particularly in low-resolution videos, to extend the operative range of the eye locators, and to improve the accuracy of the head pose tracker. These enhanced estimations are then combined to obtain a novel visual gaze estimation system, which uses both eye location and head information to refine the gaze estimates. From the experimental results, it can be derived that the proposed unified scheme improves the accuracy of eye estimations by 16% to 23%. Furthermore, it considerably extends its operating range by more than 15° by overcoming the problems introduced by extreme head poses. Moreover, the accuracy of the head pose tracker is improved by 12% to 24%. Finally, the experimentation on the proposed combined gaze estimation system shows that it is accurate (with a mean error between 2° and 5°) and that it can be used in cases where classic approaches would fail without imposing restraints on the position of the head.","Head,
Estimation,
Three dimensional displays,
Accuracy,
Cameras,
Solid modeling,
Visualization"
Sparse Bayesian Methods for Low-Rank Matrix Estimation,"Recovery of low-rank matrices has recently seen significant activity in many areas of science and engineering, motivated by recent theoretical results for exact reconstruction guarantees and interesting practical applications. In this paper, we present novel recovery algorithms for estimating low-rank matrices in matrix completion and robust principal component analysis based on sparse Bayesian learning (SBL) principles. Starting from a matrix factorization formulation and enforcing the low-rank constraint in the estimates as a sparsity constraint, we develop an approach that is very effective in determining the correct rank while providing high recovery performance. We provide connections with existing methods in other similar problems and empirical results and comparisons with current state-of-the-art methods that illustrate the effectiveness of this approach.","Bayesian methods,
Sparse matrices,
Principal component analysis,
Robustness,
Matrix decomposition,
Estimation,
Mathematical model"
Image Segmentation by Probabilistic Bottom-Up Aggregation and Cue Integration,"We present a bottom-up aggregation approach to image segmentation. Beginning with an image, we execute a sequence of steps in which pixels are gradually merged to produce larger and larger regions. In each step, we consider pairs of adjacent regions and provide a probability measure to assess whether or not they should be included in the same segment. Our probabilistic formulation takes into account intensity and texture distributions in a local area around each region. It further incorporates priors based on the geometry of the regions. Finally, posteriors based on intensity and texture cues are combined using “ a mixture of experts” formulation. This probabilistic approach is integrated into a graph coarsening scheme, providing a complete hierarchical segmentation of the image. The algorithm complexity is linear in the number of the image pixels and it requires almost no user-tuned parameters. In addition, we provide a novel evaluation scheme for image segmentation algorithms, attempting to avoid human semantic considerations that are out of scope for segmentation algorithms. Using this novel evaluation scheme, we test our method and provide a comparison to several existing segmentation algorithms.",
Robust Exponential Stability of Uncertain Delayed Neural Networks With Stochastic Perturbation and Impulse Effects,"This paper focuses on the hybrid effects of parameter uncertainty, stochastic perturbation, and impulses on global stability of delayed neural networks. By using the Ito formula, Lyapunov function, and Halanay inequality, we established several mean-square stability criteria from which we can estimate the feasible bounds of impulses, provided that parameter uncertainty and stochastic perturbations are well-constrained. Moreover, the present method can also be applied to general differential systems with stochastic perturbation and impulses.","Uncertain systems,
Stochastic processes,
Stability criteria,
Biological neural networks,
Robustness"
Decomposition-Based Multiobjective Evolutionary Algorithm With an Ensemble of Neighborhood Sizes,"The multiobjective evolutionary algorithm based on decomposition (MOEA/D) has demonstrated superior performance by winning the multiobjective optimization algorithm competition at the CEC 2009. For effective performance of MOEA/D, neighborhood size (NS) parameter has to be tuned. In this letter, an ensemble of different NSs with online self-adaptation is proposed (ENS-MOEA/D) to overcome this shortcoming. Our experimental results on the CEC 2009 competition test instances show that an ensemble of different NSs with online self-adaptation yields superior performance over implementations with only one fixed NS.","Vectors,
Evolutionary computation,
Pareto optimization,
Educational institutions,
Approximation algorithms,
Heuristic algorithms"
Incentive mechanisms for smartphone collaboration in data acquisition and distributed computing,"This paper analyzes and compares different incentive mechanisms for a client to motivate the collaboration of smartphone users on both data acquisition and distributed computing applications. Data acquisition from a large number of users is essential to build a rich database and support emerging location-based services. We propose a reward-based collaboration mechanism, where the client announces a total reward to be shared among collaborators, and the collaboration is successful if there are enough users willing to collaborate. We show that if the client knows the users' collaboration costs, then he can choose to involve only users with the lowest costs by offering a small total reward. However, if the client does not know users' private cost information, then he needs to offer a larger total reward to attract enough collaborators. Users will benefit from knowing their costs before the data acquisition. Distributed computing aims to solve computational intensive problems in a distributed and inexpensive fashion. We study how the client can design an optimal contract by specifying different task-reward combinations for different user types. Under complete information, we show that the client will involve a user type as long as the client's preference for that type outweighs the corresponding cost. All collaborators achieve a zero payoff in this case. But if the client does not know users' private cost information, he will conservatively target at a smaller group of efficient users with small costs. He has to give most benefits to the collaborators, and a collaborator's payoff increases in his computing efficiency.","Collaboration,
Data acquisition,
Games,
Distributed computing,
Databases,
Computational modeling,
Contracts"
A Reconfigurable Wideband and Multiband Antenna Using Dual-Patch Elements for Compact Wireless Devices,"A reconfigurable wideband and multiband C-Slot patch antenna with dual-patch elements is proposed and studied. It occupies a compact volume of 50 × 50 × 1.57 (3925 mm3), including the ground plane. The antenna can operate in two dual-band modes and a wideband mode from 5 to 7 GHz. Two parallel C-Slots on the patch elements are employed to perturb the surface current paths for excitation of the dual-band and the wideband modes. Two switches, implemented using PIN diodes, are placed on the connecting lines of a simple feed network to the patch elements. Dual-band modes are achieved by switching “ON” either one of the two patch elements, while the wideband mode with an impedance bandwidth of 33.52% is obtained by switching “ON” both patch elements. The frequencies in the dual-band modes can be independently controlled using positions and dimensions of the C-Slots without affecting the wideband mode. The advantage of the proposed antenna is that two dual-band operations and one wideband operation can be achieved using the same dimensions. This overcomes the need for increasing the surface area normally incurred when designing wideband patch antennas. Simulation results are validated experimentally through prototypes. The measured radiation patterns and peak gains show stable responses and are in good agreements. Coupling between the two patch elements plays a major role for achieving the wide bandwidth and the effects of mutual coupling between the patch elements are also studied.","Wideband,
Dual band,
Antenna measurements,
Broadband antennas,
Impedance"
Boolean Compressed Sensing and Noisy Group Testing,"The fundamental task of group testing is to recover a small distinguished subset of items from a large population while efficiently reducing the total number of tests (measurements). The key contribution of this paper is in adopting a new information-theoretic perspective on group testing problems. We formulate the group testing problem as a channel coding/decoding problem and derive a single-letter characterization for the total number of tests used to identify the defective set. Although the focus of this paper is primarily on group testing, our main result is generally applicable to other compressive sensing models.","Testing,
Noise measurement,
Vectors,
Blood,
Error probability,
Indexes,
Decoding"
High-Frequency Resonant SEPIC Converter With Wide Input and Output Voltage Ranges,"This paper presents a resonant single-ended-primary-inductor-converter (SEPIC) converter and control method suitable for high frequency (HF) and very high frequency (VHF) dc-dc power conversion. The proposed design provides high efficiency over a wide input and output voltage range, up-and-down voltage conversion, small size, and excellent transient performance. In addition, a resonant gate drive scheme is presented that provides rapid startup and low-loss at HF and VHF frequencies. The converter regulates the output using an ON-OFF control scheme modulating at a fixed frequency (170 kHz). This control method enables fast transient response and efficient light-load operation while providing controlled spectral characteristics of the input and output waveforms. A hysteretic override technique is also introduced which enables the converter to reject load disturbances with a bandwidth much greater than the modulation frequency, limiting output voltage disturbances to within a fixed value. An experimental prototype has been built and evaluated. The prototype converter, built with two commercial vertical MOSFETs, operates at a fixed switching frequency of 20 MHz, with an input voltage range of 3.6-7.2 V, an output voltage range of 3-9 V, and an output power rating of up to 3 W. The converter achieves higher than 80% efficiency across the entire input voltage range at nominal output voltage and maintains good efficiency across the whole operating range.","Converters,
Logic gates,
Inverters,
Resonant frequency,
Switches,
Inductors,
Tuning"
Seamless Dual-Link Handover Scheme in Broadband Wireless Communication Systems for High-Speed Rail,"Due to frequent handovers in broadband wireless communications in high-speed rail, communication interruption during handover could seriously degrade the experiences of passengers on the train. Aiming to reduce the interruption time, this paper proposes a seamless handover scheme based on a dual-layer and dual-link system architecture, where a Train Relay Station is employed to execute handover for all users in a train and two antennas are mounted at the front and rear of a train. In the proposed scheme, the front antenna executes handover while the rear antenna is still communicating with BS, so that the communication can keep non-interruptive throughout the handover. Moreover, bi-casting is adopted to eliminate the data forwarding delay between the serving BS and target BS. A complete handover protocol is designed and the performance of the proposed scheme is analyzed. It can be seen from analytical results that the handover failure probability decreases as cell overlap increases and the communication interruption probability decreases with the decrease of train handover location and the increase of cell overlap. The simulation results show that in the proposed scheme, the communication interruption probability is smaller than 1% when the handover location is properly selected and the system throughput is not affected by handover. In conclusion, both theoretical and simulation results show that the proposed scheme can efficiently perform seamless handover for high-speed rail with low implementation overhead.","Broadband antennas,
Wireless communication,
Interrupters,
Delay,
Computer architecture,
Receiving antennas"
Energy-Efficient Relay Selection and Power Allocation for Two-Way Relay Channel with Analog Network Coding,"In this letter, we consider a two-way relay channel (TWRC) with two end nodes and k relay nodes, where end nodes have the full channel-state information (CSI) and relay nodes only have the channel-amplitude information (CAI). With the objective of minimizing transmit power consumption at required end-to-end rates, energy-efficient relay selection (RS) and power allocation (PA) scheme is studied for TWRC based on analog network coding (ANC). Firstly, we propose an energy-efficient single RS and PA (E-SRS-PA) scheme, where the best relay node is selected to minimize total transmit power. Then, we prove that E-SRS-PA scheme is the optimal energy-efficient RS and PA (OE-RS-PA) scheme in ANC-based TWRC, and thus the optimal number of relay nodes to be selected in energy efficiency sense is equal to one. In addition, the closed-form expressions of optimal power allocation of E-SRS-PA scheme are derived. Numerical simulations confirm the optimality of proposed E-SRS-PA and demonstrate the energy efficiency of ANC-based TWRC compared with the other relaying schemes.","Relays,
Network coding,
Resource management,
Optimization,
Joints,
Computer aided instruction,
Array signal processing"
Social interactions: A first-person perspective,"This paper presents a method for the detection and recognition of social interactions in a day-long first-person video of u social event, like a trip to an amusement park. The location and orientation of faces are estimated and used to compute the line of sight for each face. The context provided by all the faces in a frame is used to convert the lines of sight into locations in space to which individuals attend. Further, individuals are assigned roles based on their patterns of attention. The rotes and locations of individuals are analyzed over time to detect and recognize the types of social interactions. In addition to patterns of face locations and attention, the head movements of the first-person can provide additional useful cues as to their attentional focus. We demonstrate encouraging results on detection and recognition of social interactions in first-person videos captured from multiple days of experience in amusement parks.","Cameras,
Context,
Face recognition,
Social network services,
Inference algorithms,
Computer vision,
Vectors"
Accuracy and robustness of Kinect pose estimation in the context of coaching of elderly population,"The Microsoft Kinect camera is becoming increasingly popular in many areas aside from entertainment, including human activity monitoring and rehabilitation. Many people, however, fail to consider the reliability and accuracy of the Kinect human pose estimation when they depend on it as a measuring system. In this paper we compare the Kinect pose estimation (skeletonization) with more established techniques for pose estimation from motion capture data, examining the accuracy of joint localization and robustness of pose estimation with respect to the orientation and occlusions. We have evaluated six physical exercises aimed at coaching of elderly population. Experimental results present pose estimation accuracy rates and corresponding error bounds for the Kinect system.","Joints,
Estimation,
Accuracy,
Cameras,
Humans,
Hip"
Lateral Stability Control of In-Wheel-Motor-Driven Electric Vehicles Based on Sideslip Angle Estimation Using Lateral Tire Force Sensors,"This paper presents a method for using lateral tire force sensors to estimate vehicle sideslip angle and to improve vehicle stability of in-wheel-motor-driven electric vehicles (IWM-EVs). Considering that the vehicle motion is governed by tire forces, lateral tire force measurements give practical benefits in estimation and motion control. To estimate the vehicle sideslip angle, a state observer derived from the extended-Kalman-filtering (EKF) method is proposed and evaluated through field tests on an experimental IWM-EV. Experimental results show the ability of a proposed observer to provide accurate estimation. Moreover, using the estimated sideslip angle and tire cornering stiffness, the vehicle stability control system, making best use of the advantages of IMW-EVs with a steer-by-wire system, is proposed. Computer simulation using Matlab/Simulink-Carsim and experiments are carried out to demonstrate the effectiveness of the proposed stability control system. Practical application of lateral tire force sensors to vehicle control systems is discussed for future personal electric vehicles.","Tires,
Vehicles,
Force,
Wheels,
Observers,
Stability analysis,
Sensors"
A Review of Localization Systems for Robotic Endoscopic Capsules,"Obscure gastrointestinal (GI) bleeding, Crohn disease, Celiac disease, small bower tumors, and other disorders that occur in the GI tract have always been challenging to be diagnosed and treated due to the inevitable difficulty in accessing such a complex environment within the human body. With the invention of wireless capsule endoscope, the next generation of the traditional cabled endoscope, not only a dream has come true for the patients who have experienced a great discomfort and unpleasantness caused by the conventional endoscopic method, but also a new research field has been opened to develop a complete miniature robotic device that is swallowable and has full functions of diagnosis and treatment of the GI diseases. However, such an ideal device needs to be equipped with a highly accurate localization system to be able to exactly determine the location of lesions in the GI tract and provide essential feedback to an actuation mechanism controlling the device's movement. This paper presents a comprehensive overview of the localization systems for robotic endoscopic capsules, for which the motivation, challenges, and possible solutions of the proposed localization methods are also discussed.",
Consensus of Multi-Agent Networks With Aperiodic Sampled Communication Via Impulsive Algorithms Using Position-Only Measurements,"In this technical note, an impulsive consensus algorithm is proposed for second-order continuous-time multi-agent networks with switching topology. The communication among agents occurs at sampling instants based on position only measurements. By using the property of stochastic matrices and algebraic graph theory, some sufficient conditions are obtained to ensure the consensus of the controlled multi-agent network if the communication graph has a spanning tree jointly. A numerical example is given to illustrate the effectiveness of the proposed algorithm.","Multiagent systems,
Topology,
Switches,
Heuristic algorithms,
Network topology,
Eigenvalues and eigenfunctions,
Stochastic processes"
Generalized Two-Hop Relay for Flexible Delay Control in MANETs,"The available two-hop relay protocols with out-of-order or strictly in-order reception cannot provide a flexible control for the packet delivery delay, which may significantly limit their applications to the future mobile ad hoc networks (MANETs) with different delay requirements. This paper extends the conventional two-hop relay and proposes a general group-based two-hop relay algorithm with packet redundancy. In such an algorithm with packet redundancy limit
f
and group size
g
(2HR-
(f,g)
for short), each packet is delivered to at most
f
distinct relay nodes and can be accepted by its destination if it is a fresh packet to the destination and also it is among
g
packets of the group the destination is currently requesting. The 2HR-
(f,g)
covers the available two-hop relay protocols as special cases, like the in-order reception ones
(f≥1,g=1)
, the out-of-order reception ones with redundancy
(f>1,g=∞)
, or without redundancy
(f=1,g=∞)
. A Markov chain-based theoretical framework is further developed to analyze how the mean value and variance of packet delivery delay vary with the parameters
f
and
g
, where the important medium contention, interference, and traffic contention issues are carefully incorporated into the analysis. Extensive simulation and theoretical results are provided to illustrate the performance of the 2HR-
(f,g)
algorithm and the corresponding theoretical framework, which indicate that the theoretical framework is efficient in delay analysis and the new 2HR-
(f,g)
algorithm actually enables both the mean value and variance of packet delivery delay to be flexibly controlled in a large region.","Relays,
Delay,
Markov processes,
Mobile computing,
Redundancy,
Ad hoc networks,
Transient analysis"
Multiple Kernel Fuzzy Clustering,"While fuzzy c-means is a popular soft-clustering method, its effectiveness is largely limited to spherical clusters. By applying kernel tricks, the kernel fuzzy c-means algorithm attempts to address this problem by mapping data with nonlinear relationships to appropriate feature spaces. Kernel combination, or selection, is crucial for effective kernel clustering. Unfortunately, for most applications, it is uneasy to find the right combination. We propose a multiple kernel fuzzy c-means (MKFC) algorithm that extends the fuzzy c-means algorithm with a multiple kernel-learning setting. By incorporating multiple kernels and automatically adjusting the kernel weights, MKFC is more immune to ineffective kernels and irrelevant features. This makes the choice of kernels less crucial. In addition, we show multiple kernel k-means to be a special case of MKFC. Experiments on both synthetic and real-world data demonstrate the effectiveness of the proposed MKFC algorithm.","Kernel,
Clustering algorithms,
Equations,
Integrated circuits,
Mathematical model,
Clustering methods,
Optimization"
Distributed Basis Pursuit,"We propose a distributed algorithm for solving the optimization problem Basis Pursuit (BP). BP finds the least ℓ1-norm solution of the underdetermined linear system Ax = b and is used, for example, in compressed sensing for reconstruction. Our algorithm solves BP on a distributed platform such as a sensor network, and is designed to minimize the communication between nodes. The algorithm only requires the network to be connected, has no notion of a central processing node, and no node has access to the entire matrix A at any time. We consider two scenarios in which either the columns or the rows of A are distributed among the compute nodes. Our algorithm, named D-ADMM, is a decentralized implementation of the alternating direction method of multi- pliers. We show through numerical simulation that our algorithm requires considerably less communications between the nodes than the state-of-the-art algorithms.","Color,
Partitioning algorithms,
Optimization,
Vectors,
Distributed algorithms,
Linear systems,
Compressed sensing"
Continuous mobile authentication using touchscreen gestures,"Securing the sensitive data stored and accessed from mobile devices makes user authentication a problem of paramount importance. The tension between security and usability renders however the task of user authentication on mobile devices a challenging task. This paper introduces FAST (Fingergestures Authentication System using Touchscreen), a novel touchscreen based authentication approach on mobile devices. Besides extracting touch data from touchscreen equipped smartphones, FAST complements and validates this data using a digital sensor glove that we have built using off-the-shelf components. FAST leverages state-of-the-art classification algorithms to provide transparent and continuous mobile system protection. A notable feature is FAST 's continuous, user transparent post-login authentication. We use touch data collected from 40 users to show that FAST achieves a False Accept Rate (FAR) of 4.66% and False Reject Rate of 0.13% for the continuous post-login user authentication. The low FAR and FRR values indicate that FAST provides excellent post-login access security, without disturbing the honest mobile users.","Authentication,
Smart phones,
Mobile communication,
Feature extraction,
Decision trees"
A Survey on Uplink Resource Allocation in OFDMA Wireless Networks,"OFDMA has been selected as the multiple access scheme for state-of-the-art wireless communication systems. Efficient resource allocation in OFDMA wireless networks is essential in order to meet the quality of service requirements of emerging services. In this paper, a survey of resource allocation and scheduling schemes in OFDMA wireless networks is presented. The focus is on the uplink direction. Resource allocation is surveyed in various scenarios: centralized and distributed, instantaneous and ergodic, optimal and suboptimal, single cell and multicell, cooperative and non-cooperative, in addition to different combinations of these variants. Directions for future research are outlined.","Resource management,
Downlink,
OFDM,
Complexity theory,
Wireless communication,
Scheduling,
Fading"
A Survey of Evolutionary Algorithms for Decision-Tree Induction,"This paper presents a survey of evolutionary algorithms that are designed for decision-tree induction. In this context, most of the paper focuses on approaches that evolve decision trees as an alternate heuristics to the traditional top-down divide-and-conquer approach. Additionally, we present some alternative methods that make use of evolutionary algorithms to improve particular components of decision-tree classifiers. The paper's original contributions are the following. First, it provides an up-to-date overview that is fully focused on evolutionary algorithms and decision trees and does not concentrate on any specific evolutionary approach. Second, it provides a taxonomy, which addresses works that evolve decision trees and works that design decision-tree components by the use of evolutionary algorithms. Finally, a number of references are provided that describe applications of evolutionary algorithms for decision-tree induction in different domains. At the end of this paper, we address some important issues and open questions that can be the subject of future research.","Decision trees,
Biological cells,
Encoding,
Genetics,
Evolutionary computation,
Genetic algorithms,
Indexes"
Deadlock Prevention Based on Structure Reuse of Petri Net Supervisors for Flexible Manufacturing Systems,"Deadlocks are an undesirable situation in automated flexible manufacturing systems (FMS). Their occurrences often deteriorate the utilization of resources and may lead to catastrophic results. Finding an optimal supervisor is NP-hard. A computationally efficient method often ends up with a suboptimal one. This paper develops a deadlock prevention method that makes a good tradeoff between optimality and computational tractability for a class of Petri nets, which can model many FMS. The theory of regions guides our efforts toward the development of near-optimal solutions for deadlock prevention. Given a plant net, a minimal initial marking is first decided by structural analysis, and an optimal live controlled system is computed. Then, a set of inequality constraints is derived with respect to the markings of monitors and the places in the model such that no siphon can be insufficiently marked. A method is proposed to identify the redundancy condition for constraints. For a new initial marking of the plant net, a deadlock-free controlled system can be obtained by regulating the markings of the monitors such that the inequality constraints are satisfied, without changing the structure of the controlled system. The near-optimal performance of a controlled net system via the proposed method is shown through several examples.","System recovery,
Control systems,
Monitoring,
Petri nets,
Computational modeling,
Artificial neural networks,
Educational institutions"
A Hybrid Brain Computer Interface to Control the Direction and Speed of a Simulated or Real Wheelchair,"Brain-computer interfaces (BCIs) are used to translate brain activity signals into control signals for external devices. Currently, it is difficult for BCI systems to provide the multiple independent control signals necessary for the multi-degree continuous control of a wheelchair. In this paper, we address this challenge by introducing a hybrid BCI that uses the motor imagery-based mu rhythm and the P300 potential to control a brain-actuated simulated or real wheelchair. The objective of the hybrid BCI is to provide a greater number of commands with increased accuracy to the BCI user. Our paradigm allows the user to control the direction (left or right turn) of the simulated or real wheelchair using left- or right-hand imagery. Furthermore, a hybrid manner can be used to control speed. To decelerate, the user imagines foot movement while ignoring the flashing buttons on the graphical user interface (GUI). If the user wishes to accelerate, then he/she pays attention to a specific flashing button without performing any motor imagery. Two experiments were conducted to assess the BCI control; both a simulated wheelchair in a virtual environment and a real wheelchair were tested. Subjects steered both the simulated and real wheelchairs effectively by controlling the direction and speed with our hybrid BCI system. Data analysis validated the use of our hybrid BCI system to control the direction and speed of a wheelchair.","Wheelchairs,
Electroencephalography,
Foot,
Velocity control,
Feature extraction,
Ash,
Vectors"
Cats and dogs,"We investigate the fine grained object categorization problem of determining the breed of animal from an image. To this end we introduce a new annotated dataset of pets covering 37 different breeds of cats and dogs. The visual problem is very challenging as these animals, particularly cats, are very deformable and there can be quite subtle differences between the breeds. We make a number of contributions: first, we introduce a model to classify a pet breed automatically from an image. The model combines shape, captured by a deformable part model detecting the pet face, and appearance, captured by a bag-of-words model that describes the pet fur. Fitting the model involves automatically segmenting the animal in the image. Second, we compare two classification approaches: a hierarchical one, in which a pet is first assigned to the cat or dog family and then to a breed, and a flat one, in which the breed is obtained directly. We also investigate a number of animal and image orientated spatial layouts. These models are very good: they beat all previously published results on the challenging ASIRRA test (cat vs dog discrimination). When applied to the task of discriminating the 37 different breeds of pets, the models obtain an average accuracy of about 59%, a very encouraging result considering the difficulty of the problem.","Positron emission tomography,
Image segmentation,
Cats,
Dogs,
Layout,
Deformable models,
Head"
FILA: Fine-grained indoor localization,"Indoor positioning systems have received increasing attention for supporting location-based services in indoor environments. WiFi-based indoor localization has been attractive due to its open access and low cost properties. However, the distance estimation based on received signal strength indicator (RSSI) is easily affected by the temporal and spatial variance due to the multipath effect, which contributes to most of the estimation errors in current systems. How to eliminate such effect so as to enhance the indoor localization performance is a big challenge. In this work, we analyze this effect across the physical layer and account for the undesirable RSSI readings being reported. We explore the frequency diversity of the subcarriers in OFDM systems and propose a novel approach called FILA, which leverages the channel state information (CSI) to alleviate multipath effect at the receiver. We implement the FILA system on commercial 802.11 NICs, and then evaluate its performance in different typical indoor scenarios. The experimental results show that the accuracy and latency of distance calculation can be significantly enhanced by using CSI. Moreover, FILA can significantly improve the localization accuracy compared with the corresponding RSSI approach.","OFDM,
Fading,
Receivers,
Accuracy,
Bandwidth,
Training,
Baseband"
Security in the Internet of Things: A Review,"In the past decade, internet of things (IoT) has been a focus of research. Security and privacy are the key issues for IoT applications, and still face some enormous challenges. In order to facilitate this emerging domain, we in brief review the research progress of IoT, and pay attention to the security. By means of deeply analyzing the security architecture and features, the security requirements are given. On the basis of these, we discuss the research status of key technologies including encryption mechanism, communication security, protecting sensor data and cryptographic algorithms, and briefly outline the challenges.",
Evolutionary Pinning Control and Its Application in UAV Coordination,"Maximizing the controllability of complex networks by selecting appropriate nodes and designing suitable control gains is an effective way to control distributed complex networks. In this paper, some novel particle swarm optimization (PSO) approaches are developed to enhance the controllability of distributed networks. The proposed PSO algorithm is combined with a global search scheme and a modified simulated binary crossover (MSBX). In addition, the node importance-based method is introduced to study the controllability of distributed complex networks. A set of experiments show that the PSO with the global search and the MSBX (PSO-GSBX) can outperform some well-known evolutionary algorithms and pinning schemes. Following the PSO-GSBX approach, some interesting findings about pinned nodes, coupling strengths and the eigenvalues for enhancing the controllability of distributed networks are revealed. The obtained results and methods are applied in unmanned aerial vehicle (UAV) coordination to show their effectiveness. These findings will help to understand controllability of complex networks and can be applied in control science and industrial system.",
Design of Ultra-Low Power Biopotential Amplifiers for Biosignal Acquisition Applications,"Rapid development in miniature implantable electronics are expediting advances in neuroscience by allowing observation and control of neural activities. The first stage of an implantable biosignal recording system, a low-noise biopotential amplifier (BPA), is critical to the overall power and noise performance of the system. In order to integrate a large number of front-end amplifiers in multichannel implantable systems, the power consumption of each amplifier must be minimized. This paper introduces a closed-loop complementary-input amplifier, which has a bandwidth of 0.05 Hz to 10.5 kHz, an input-referred noise of 2.2 μ Vrms, and a power dissipation of 12 μW. As a point of comparison, a standard telescopic-cascode closed-loop amplifier with a 0.4 Hz to 8.5 kHz bandwidth, input-referred noise of 3.2 μ Vrms, and power dissipation of 12.5 μW is presented. Also for comparison, we show results from an open-loop complementary-input amplifier that exhibits an input-referred noise of 3.6 μ Vrms while consuming 800 nW of power. The two closed-loop amplifiers are fabricated in a 0.13 μ m CMOS process. The open-loop amplifier is fabricated in a 0.5 μm SOI-BiCMOS process. All three amplifiers operate with a 1 V supply.","Noise,
Gain,
Transistors,
Bandwidth,
Logic gates,
Thermal noise,
Transconductance"
Recent Advances of Large-Scale Linear Classification,"Linear classification is a useful tool in machine learning and data mining. For some data in a rich dimensional space, the performance (i.e., testing accuracy) of linear classifiers has shown to be close to that of nonlinear classifiers such as kernel methods, but training and testing speed is much faster. Recently, many research works have developed efficient optimization methods to construct linear classifiers and applied them to some large-scale applications. In this paper, we give a comprehensive survey on the recent development of this active research area.","Support vector machines,
Linear systems,
Regression analysis,
Classification algorithms,
Algorithm design and analysis"
A Novel Approach for Motion Artifact Reduction in PPG Signals Based on AS-LMS Adaptive Filter,"The performance of pulse oximeters is highly influenced by motion artifacts (MAs) in photoplethysmographic (PPG) signals. In this paper, we propose a simple and efficient approach based on adaptive step-size least mean squares (AS-LMS) adaptive filter for reducing MA in corrupted PPG signals. The presented method is an extension to our prior work on efficient use of adaptive filters for reduction of MA in PPG signals. The novelty of the method lies in the fact that a synthetic noise reference signal for an adaptive filtering process, representing MA noise, is generated internally from the MA-corrupted PPG signal itself instead of using any additional hardware such as accelerometer or source-detector pair for acquiring noise reference signal. Thus, the generated noise reference signal is then applied to the AS-LMS adaptive filter for artifact removal. While experimental results proved the efficacy of the proposed scheme, the merit of the method is clearly demonstrated using convergence and correlation analysis, thus making it best suitable for present-day pulse oximeters utilizing PPG sensor head with a single pair of source and detector, which does not have any extra hardware meant for capturing noise reference signal. In addition to arterial oxygen saturation estimation, the artifact reduction method facilitated the waveform contour analysis on artifact-reduced PPG, and the conventional parameters were evaluated for assessing the arterial stiffness.",
Utility-Aware Refunding Framework for Hybrid Access Femtocell Network,"Femtocell technology addresses the problem of poor indoor coverage, benefiting both wireless service provider (WSP) and end users. With the introduction of femtocell, the cross-tier interference between macro link and femto link becomes a major factor which greatly impacts the network performance. Different access control approaches, by generating different interference patterns, also severely affect the overall throughput of the network and need to be carefully investigated. Among all the access control mechanisms, hybrid access is the most promising one, which allows roaming unregistered users (referred to as macro users) to access the nearby femto base station (BS) while reserving certain resource for registered home users (referred to as femto users), improving overall network capacity. However, to successfully leverage hybrid access is challenging because the femto holders (FHs) are selfish, unwilling to share their femto facilities and spectrum resource with macro users without any incentive mechanism. In this paper, we propose a novel utility-aware refunding framework to motivate hybrid access in femtocell. Within the framework, both WSP and FHs are assumed to be selfish, and target at maximizing their own utilities. WSP provides certain refunding to motivate FHs to open their resource for macro users. FHs decide the resource allocation among femto and macro users according to the amount of refunding WSP offers. Under this framework, the optimal strategies of both WSP and FHs are analyzed by formulating the problem as a Stackelberg Game. A unique Nash Equilibrium is achieved and a hybrid access protocol is designed according to the analysis. Extensive simulations have been conducted and the results show that the utilities of both WSP and FHs are significantly improved exploiting the hybrid access mechanism.",
Intelligent Multiagent Control System for Energy and Comfort Management in Smart and Sustainable Buildings,"Smart and energy-efficient buildings have recently become a trend for future building industry. The major challenge in the control system design for such a building is to minimize the power consumption without compromising the customers comfort. For this purpose, a hierarchical multiagent control system with an intelligent optimizer is proposed in this study. Four types of agents, which are switch agent, central coordinator-agent, local controller-agent, and load agent, cooperate with each other to achieve the overall control goals. Particle swarm optimization (PSO) is utilized to optimize the overall system and enhance the intelligence of the integrated building and microgrid system. A Graphical User Interface (GUI) based platform is designed for customers to input their preferences and monitor the results. Two sets of case studies are carried out and corresponding simulation results are presented in this paper.",
Real-time scheduling of deferrable electric loads,"We consider a collection of distributed energy resources [DERs] such as electric vehicles and thermostatically controlled loads. These resources are flexible: they require delivery of a certain total energy over a specified service interval. This flexibility can facilitate the integration of renewable generation by absorbing variability, and reducing the reserve capacity and reserve energy requirements. We first model the energy needs of these resources as tasks, parameterized by arrival time, departure time, energy requirement, and maximum allowable servicing power. We consider the problem of servicing these resources by allocating available power using real-time scheduling policies. The available generation consists of a mix of renewable energy [from utility-scale wind-farms or distributed rooftop photovoltaics], and load-following reserves. Reserve capacity is purchased in advance, but reserve energy use must be scheduled in real-time to meet the energy requirements of the resources. We show that there does not exist a causal optimal scheduling policy that respects servicing power constraints. We then present three heuristic causal scheduling policies: Earliest Deadline First [EDF], Least Laxity First [LLF], and Receding Horizon Control [RHC]. We show that EDF is optimal in the absence of power constraints. We explore, via simulation studies, the performance of these three scheduling policies in the metrics of required reserve energy and reserve capacity.","Optimal scheduling,
Processor scheduling,
Real-time systems,
Resource management,
Scheduling,
Renewable energy resources,
Schedules"
Web Image Annotation Via Subspace-Sparsity Collaborated Feature Selection,"The number of web images has been explosively growing due to the development of network and storage technology. These images make up a large amount of current multimedia data and are closely related to our daily life. To efficiently browse, retrieve and organize the web images, numerous approaches have been proposed. Since the semantic concepts of the images can be indicated by label information, automatic image annotation becomes one effective technique for image management tasks. Most existing annotation methods use image features that are often noisy and redundant. Hence, feature selection can be exploited for a more precise and compact representation of the images, thus improving the annotation performance. In this paper, we propose a novel feature selection method and apply it to automatic image annotation. There are two appealing properties of our method. First, it can jointly select the most relevant features from all the data points by using a sparsity-based model. Second, it can uncover the shared subspace of original features, which is beneficial for multi-label learning. To solve the objective function of our method, we propose an efficient iterative algorithm. Extensive experiments are performed on large image databases that are collected from the web. The experimental results together with the theoretical analysis have validated the effectiveness of our method for feature selection, thus demonstrating its feasibility of being applied to web image annotation.",
A PLS-Based Statistical Approach for Fault Detection and Isolation of Robotic Manipulators,"In this paper, a statistical approach to fault detection and isolation (FDI) of robot manipulators is presented. It is based on a statistical method called partial least squares (PLS) and on the inverse dynamic model of a robot. PLS is a well-established linear technique in process control for identifying and monitoring industrial plants. Since a robot inverse dynamics can be represented as a linear static model in the dynamical parameters, it is possible to use algorithms and confidence regions developed in statistical decision theory. This approach has several advantages with respect to standard FDI modules: It is strictly related to the algorithm used for identifying the dynamical parameters, it does not need to solve at run time a set of nonlinear differential equations, and the design of a nonlinear observer is not required. This method has been tested on a PUMA 560 simulator, and results of the simulations are discussed.",
Multibiometric Cryptosystems Based on Feature-Level Fusion,"Multibiometric systems are being increasingly de- ployed in many large-scale biometric applications (e.g., FBI-IAFIS, UIDAI system in India) because they have several advantages such as lower error rates and larger population coverage compared to unibiometric systems. However, multibiometric systems require storage of multiple biometric templates (e.g., fingerprint, iris, and face) for each user, which results in increased risk to user privacy and system security. One method to protect individual templates is to store only the secure sketch generated from the corresponding template using a biometric cryptosystem. This requires storage of multiple sketches. In this paper, we propose a feature-level fusion framework to simultaneously protect multiple templates of a user as a single secure sketch. Our main contributions include: (1) practical implementation of the proposed feature-level fusion framework using two well-known biometric cryptosystems, namery,fuzzy vault and fuzzy commitment, and (2) detailed analysis of the trade-off between matching accuracy and security in the proposed multibiometric cryptosystems based on two different databases (one real and one virtual multimodal database), each containing the three most popular biometric modalities, namely, fingerprint, iris, and face. Experimental results show that both the multibiometric cryptosystems proposed here have higher security and matching performance compared to their unibiometric counterparts.","Cryptography,
Error correction codes,
Databases,
Polynomials,
Decoding,
Iris recognition"
SSIM-Motivated Rate-Distortion Optimization for Video Coding,"We propose a rate-distortion optimization (RDO) scheme based on the structural similarity (SSIM) index, which was found to be a better indicator of perceived image quality than mean-squared error, but has not been fully exploited in the context of image and video coding. At the frame level, an adaptive Lagrange multiplier selection method is proposed based on a novel reduced-reference statistical SSIM estimation algorithm and a rate model that combines the side information with the entropy of the transformed residuals. At the macroblock level, the Lagrange multiplier is further adjusted based on an information theoretical approach that takes into account both the motion information content and perceptual uncertainty of visual speed perception. Finally, the mode for H.264/AVC coding is selected by the SSIM index and the adjusted Lagrange multiplier. Extensive experiments show that the proposed scheme can achieve significantly better rate-SSIM performance and provide better visual quality than conventional RDO coding schemes.","Indexes,
Distortion measurement,
Optimization,
Discrete cosine transforms,
Adaptation models,
Bit rate,
Encoding"
Full body gait analysis with Kinect,"Human gait is an important indicator of health, with applications ranging from diagnosis, monitoring, and rehabilitation. In practice, the use of gait analysis has been limited. Existing gait analysis systems are either expensive, intrusive, or require well-controlled environments such as a clinic or a laboratory. We present an accurate gait analysis system that is economical and non-intrusive. Our system is based on the Kinect sensor and thus can extract comprehensive gait information from all parts of the body. Beyond standard stride information, we also measure arm kinematics, demonstrating the wide range of parameters that can be extracted. We further improve over existing work by using information from the entire body to more accurately measure stride intervals. Our system requires no markers or battery-powered sensors, and instead relies on a single, inexpensive commodity 3D sensor with a large preexisting install base. We suggest that the proposed technique can be used for continuous gait tracking at home.","Accuracy,
Joints,
Foot,
Robustness,
Humans,
Standards"
Boosting bottom-up and top-down visual features for saliency estimation,"Despite significant recent progress, the best available visual saliency models still lag behind human performance in predicting eye fixations in free-viewing of natural scenes. Majority of models are based on low-level visual features and the importance of top-down factors has not yet been fully explored or modeled. Here, we combine low-level features such as orientation, color, intensity, saliency maps of previous best bottom-up models with top-down cognitive visual features (e.g., faces, humans, cars, etc.) and learn a direct mapping from those features to eye fixations using Regression, SVM, and AdaBoost classifiers. By extensive experimenting over three benchmark eye-tracking datasets using three popular evaluation scores, we show that our boosting model outperforms 27 state-of-the-art models and is so far the closest model to the accuracy of human model for fixation prediction. Furthermore, our model successfully detects the most salient object in a scene without sophisticated image processings such as region segmentation.",
55-kW Variable 3X DC-DC Converter for Plug-in Hybrid Electric Vehicles,"This paper presents an alternative to the traditional dc-dc converter interfacing the battery with the inverter dc bus in plug-in hybrid electric vehicle (HEV) traction drives. The boost converter used in commercial HEVs meets with obstacles when it comes to upgrading the power rating and achieving high efficiency while downsizing the converter. A four-level flying-capacitor dc-dc converter is explored that can overcome these drawbacks by dramatically reducing the inductance requirement. A special case of the four-level converter, the 3X dc-dc converter, operates at three discrete output/input voltage ratios, thus further reducing the inductance requirement to a minimal value (almost zero). When further compared to its switched-capacitor dc-dc converter counterparts, the 3X dc-dc converter can be operated at variable output/input voltage ratios without sacrificing efficiency, and it lowers the capacitance requirement by utilizing the parasitic inductance. The operating principle, current ripple analysis, the transient control to limit the inrush current, and power loss analysis are introduced. Experimental results of a 55-kW prototype are provided to demonstrate the principle and analysis of this topology.","Switches,
Inductors,
Batteries,
Capacitors,
Inductance,
Pulse width modulation,
Hybrid electric vehicles"
Cooperative Target Tracking Control of Multiple Robots,"This paper focuses on the problem of moving target tracking with a group of mobile robots. Each robot in the group has a pan/tilt camera to detect the target and has limited communication capability to communicate with neighbor robots. The problem is solved by separating it into two parts. One part is the estimation of target position and another is the flocking control of multiple robots moving toward the estimated position. In the target estimation part, we propose to use a novel distributed Kalman filter to estimate the target position. The distributed Kalman filter is deduced based on a standard Kalman filter by modeling the neighbor's information as one of measurements. In the motion control part, a distributed flocking algorithm is developed. It is used to track the estimated target and avoid collision. In both parts, only local communication between neighbor robots is required. Finally, the tracking algorithms are simulated with 2-D and 3-D robots to verify their performance. The simulation results provide a firm conclusion that the proposed algorithms are able to track a moving target. A group of real ground mobile robots is used to test the proposed algorithm. The experiment results show that multiple robots are able to cooperate to track the target under the proposed algorithms and the tracking result outperforms the result produced by individual robots without cooperation.","Robot sensing systems,
Target tracking,
Kalman filters,
Trajectory,
Equations,
Estimation"
A Fast and Robust Sparse Approach for Hyperspectral Data Classification Using a Few Labeled Samples,"The classification of high-dimensional data with too few labeled samples is a major challenge which is difficult to meet unless some special characteristics of the data can be exploited. In remote sensing, the problem is particularly serious because of the difficulty and cost factors involved in assignment of labels to high-dimensional samples. In this paper, we exploit certain special properties of hyperspectral data and propose an l1-minimization -based sparse representation classification approach to overcome this difficulty in hyperspectral data classification. We assume that the data within each hyperspectral data class lies in a very low-dimensional subspace. Unlike traditional supervised methods, the proposed method does not have separate training and testing phases and, therefore, does not need a training procedure for model creation. Further, to prove the sparsity of hyperspectral data and handle the computational intensiveness and time demand of general-purpose linear programming (LP) solvers, we propose a Homotopy-based sparse classification approach, which works efficiently when data is highly sparse. The approach is not only time efficient, but it also produces results, which are comparable to the traditional methods. The proposed approaches are tested for our difficult classification problem of hyperspectral data with few labeled samples. Extensive experiments on four real hyperspectral data sets prove that hyperspectral data is highly sparse in nature, and the proposed approaches are robust across different databases, offer more classification accuracy, and are more efficient than state-of-the-art methods.","Hyperspectral imaging,
Vectors,
Dictionaries,
Support vector machines,
Accuracy,
Kernel"
A 260 GHz fully integrated CMOS transceiver for wireless chip-to-chip communication,"A fully integrated 260GHz OOK transceiver is demonstrated in 65nm CMOS. Communication at 10Gb/s has been verified over a range of 40 mm. The Tx/Rx dual on-chip antenna array is implemented with half-width leaky wave antennas. Each Tx consists of a quadrupler driven by a class-D-1 PA with a distributed OOK modulator, and outputs +5 dBm of EIRP. The Rx uses a double balanced mixer to down-convert to a V-band IF signal that is amplified with a wideband IF driver and demoduated on-chip.","Antenna measurements,
Transceivers,
System-on-a-chip,
Modulation,
Antennas,
CMOS integrated circuits,
Wireless communication"
Rate-Dependent Hysteresis Modeling and Control of a Piezostage Using Online Support Vector Machine and Relevance Vector Machine,"Hysteresis nonlinearity degrades the positioning accuracy of a piezostage and requires a suppression for precision micro-/nanopositioning applications. This paper proposes two new approaches to modeling and compensating the rate-dependent hysteresis of a piezostage driven by piezoelectric stack actuators. By formulating the hysteresis modeling as an online nonlinear regression problem, online least squares support vector machine (SVM) (LS-SVM) and online relevance vector machine (RVM) models are proposed to capture the hysteretic behavior. Both hysteresis models are capable of updating continually with subsequent samples. After a comparative study on modeling performances, an inverse model-based feedforward combined with proportional-integral-derivative feedback control is presented to alleviate the hysteresis effect. Experimental results show that the LS-SVM model-based control scheme is over 86% more accurate than the RVM model-based one in the motion tracking task, whereas the latter is 14 times faster than the former in terms of updating time. Moreover, both LS-SVM and RVM model-based control schemes can suppress the rate-dependent hysteresis to a negligible level, which validates the feasibility and effectiveness of the proposed approaches.","Hysteresis,
Mathematical model,
Support vector machines,
Predictive models,
Training data,
Kernel,
Training"
Mining Spectrum Usage Data: A Large-Scale Spectrum Measurement Study,"Dynamic spectrum access has been a subject of extensive study in recent years. The increasing volume of literatures calls for a deeper understanding of the characteristics of current spectrum utilization. In this paper, we present a detailed spectrum measurement study, with data collected in the 20 MHz to 3 GHz spectrum band and at four locations concurrently in Guangdong province of China. We examine the statistics of the collected data, including channel vacancy statistics, channel utilization within each individual wireless service, and the spectral and spatial correlation of these measures. Main findings include that the channel vacancy durations follow an exponential-like distribution, but are not independently distributed over time, and that significant spectral and spatial correlations are found between channels of the same service. We then exploit such spectrum correlation to develop a 2D frequent pattern mining algorithm that can predict channel availability based on past observations with considerable accuracy.","Correlation,
Energy states,
Time measurement,
Wireless communication,
Availability,
Data mining,
Thyristors"
Social feature-based multi-path routing in delay tolerant networks,"Most routing protocols for delay tolerant networks resort to the sufficient state information, including trajectory and contact information, to ensure routing efficiency. However, state information tends to be dynamic and hard to obtain without a global and/or long-term collection process. In this paper, we use the internal social features of each node in the network to perform the routing process. This approach is motivated from several social contact networks, such as the Infocom 2006 trace, where people contact each other more frequently if they have more social features in common. Our approach includes two unique processes: social feature extraction and multi-path routing. In social feature extraction, we use entropy to extract the m most informative social features to create a feature space (F-space): (F1, F2, ..., Fm), where Fi corresponds to a feature. The routing method then becomes a hypercube-based feature matching process where the routing process is a step-by-step feature difference resolving process. We offer two special multi-path routing schemes: node-disjoint-based routing and delegation-based routing. Extensive simulations on both real and synthetic traces are conducted in comparison with several existing approaches, including spray-and-wait routing and spray-and-focus routing.","Routing,
Hypercubes,
Feature extraction,
Entropy,
Mobile communication,
Delay"
Learning the Dynamics of Arterial Traffic From Probe Data Using a Dynamic Bayesian Network,"Estimating and predicting traffic conditions in arterial networks using probe data has proven to be a substantial challenge. Sparse probe data represent the vast majority of the data available on arterial roads. This paper proposes a probabilistic modeling framework for estimating and predicting arterial travel-time distributions using sparsely observed probe vehicles. We introduce a model based on hydrodynamic traffic theory to learn the density of vehicles on arterial road segments, illustrating the distribution of delay within a road segment. The characterization of this distribution is essentially to use probe vehicles for traffic estimation: Probe vehicles report their location at random locations, and the travel times between location reports must be properly scaled to match the map discretization. A dynamic Bayesian network represents the spatiotemporal dependence on the network and provides a flexible framework to learn traffic dynamics from historical data and to perform real-time estimation with streaming data. The model is evaluated using data from a fleet of 500 probe vehicles in San Francisco, CA, which send Global Positioning System (GPS) data to our server every minute. The numerical experiments analyze the learning and estimation capabilities on a subnetwork with more than 800 links. The sampling rate of the probe vehicles does not provide detailed information about the location where vehicles encountered delay or the reason for any delay (i.e., signal delay, congestion delay, etc.). The model provides an increase in estimation accuracy of 35% when compared with a baseline approach to process probe-vehicle data.",
"Sensing the ""Health State"" of a Community","Mobile phones are a pervasive platform for opportunistic sensing of behaviors and opinions. Three studies use location and communication sensors to model individual behaviors and symptoms, long-term health outcomes, and the diffusion of opinions in a community. These three analyses illustrate how mobile phones can unobtrusively monitor rich social interactions, because the underlying sensing technologies are now commonplace and readily available.","Sensors,
Wireless LAN,
Bluetooth,
Mobile handsets,
Mobile communication,
Biosensors,
Biomedical monitoring,
Medical services"
Vertical Leakage/Breakdown Mechanisms in AlGaN/GaN-on-Si Devices,"Vertical leakage/breakdown mechanisms in AlGaN/GaN high-electron-mobility transistors grown on low-resistivity p-type (111) Si substrate are studied by temperature-dependent current-voltage ( I-V) measurements. It is found that the top-to-substrate vertical breakdown voltage (BV) is dominated by the space-charge-limited current conduction involving both acceptor and donor traps in the GaN buffer/transition layer. From the temperature-dependent transient backgating measurements, the acceptor level at EV + 543 meV and the donor level at EC-616 meV were identified.",
Factors influencing quality of experience of commonly used mobile applications,"Increasingly, we use mobile applications and services in our daily life activities, to support our needs for information, communication or leisure. However, user acceptance of a mobile application depends on at least two conditions: the application's perceived experience, and the appropriateness of the application to the user's context and needs. However, we have a weak understanding of a mobile user's quality of experience (QoE) and the factors influencing it. This article presents a 4-week-long 29-Androidphone- user study, where we collected both QoE and the underlying network's quality of service measurements through a combination of user, application, and network data on the user's phones. We aimed to derive and improve the understanding of users' QoE for a set of widely used mobile applications in users' natural environments and different daily contexts. We present data acquired in the study and discuss implications for mobile applications design.","Mobile communication,
Computer applications,
Quality of service,
Smart phones,
Cascading style sheets,
Electronic mail"
Real-Coded Chemical Reaction Optimization,"Optimization problems can generally be classified as continuous and discrete, based on the nature of the solution space. A recently developed chemical-reaction-inspired metaheuristic, called chemical reaction optimization (CRO), has been shown to perform well in many optimization problems in the discrete domain. This paper is dedicated to proposing a real-coded version of CRO, namely, RCCRO, to solve continuous optimization problems. We compare the performance of RCCRO with a large number of optimization techniques on a large set of standard continuous benchmark functions. We find that RCCRO outperforms all the others on the average. We also propose an adaptive scheme for RCCRO which can improve the performance effectively. This shows that CRO is suitable for solving problems in the continuous domain.","Optimization,
Chemicals,
Containers,
Benchmark testing,
Educational institutions,
Probabilistic logic,
Biological cells"
Object Co-Segmentation Based on Shortest Path Algorithm and Saliency Model,"Segmenting common objects that have variations in color, texture and shape is a challenging problem. In this paper, we propose a new model that efficiently segments common objects from multiple images. We first segment each original image into a number of local regions. Then, we construct a digraph based on local region similarities and saliency maps. Finally, we formulate the co-segmentation problem as the shortest path problem, and we use the dynamic programming method to solve the problem. The experimental results demonstrate that the proposed model can efficiently segment the common objects from a group of images with generally lower error rate than many existing and conventional co-segmentation methods.",
Supervoxel-Based Segmentation of Mitochondria in EM Image Stacks With Learned Shape Features,"It is becoming increasingly clear that mitochondria play an important role in neural function. Recent studies show mitochondrial morphology to be crucial to cellular physiology and synaptic function and a link between mitochondrial defects and neuro-degenerative diseases is strongly suspected. Electron microscopy (EM), with its very high resolution in all three directions, is one of the key tools to look more closely into these issues but the huge amounts of data it produces make automated analysis necessary. State-of-the-art computer vision algorithms designed to operate on natural 2-D images tend to perform poorly when applied to EM data for a number of reasons. First, the sheer size of a typical EM volume renders most modern segmentation schemes intractable. Furthermore, most approaches ignore important shape cues, relying only on local statistics that easily become confused when confronted with noise and textures inherent in the data. Finally, the conventional assumption that strong image gradients always correspond to object boundaries is violated by the clutter of distracting membranes. In this work, we propose an automated graph partitioning scheme that addresses these issues. It reduces the computational complexity by operating on supervoxels instead of voxels, incorporates shape features capable of describing the 3-D shape of the target objects, and learns to recognize the distinctive appearance of true boundaries. Our experiments demonstrate that our approach is able to segment mitochondria at a performance level close to that of a human annotator, and outperforms a state-of-the-art 3-D segmentation technique.","Image segmentation,
Shape,
Feature extraction,
Three dimensional displays,
Image edge detection,
Microscopy,
Image resolution"
Improving write operations in MLC phase change memory,"Phase change memory (PCM) recently has emerged as a promising technology to meet the fast growing demand for large capacity memory in modern computer systems. In particular, multi-level cell (MLC) PCM that stores multiple bits in a single cell, offers high density with low per-byte fabrication cost. However, despite many advantages, such as good scalability and low leakage, PCM suffers from exceptionally slow write operations, which makes it challenging to be integrated in the memory hierarchy. In this paper, we propose architectural innovations to improve the access time of MLC PCM. Due to cell process variation, composition fluctuation and the relatively small differences among resistance levels, MLC PCM typically employs an iterative write scheme to achieve precise control, which suffers from large write access latency. To address this issue, we propose write truncation (WT) to reduce the number of write iterations with the assistance of an extra error correction code (ECC). We also propose form switch (FS) to reduce the storage overhead of the ECC. By storing highly compressible lines in SLC form, FS improves read latency as well. Our experimental results show that WT and FS improve the effective write/read latency by 57%/28% respectively, and achieve 26% performance improvement over the state of the art.",
Quantifying Spinning Reserve in Systems With Significant Wind Power Penetration,"The traditional unit commitment and economic dispatch approaches with deterministic spinning reserve requirements are inadequate given the intermittency and unpredictability of wind power generation. Alternative power system scheduling methods capable of aggregating the uncertainty of wind power, while maintaining reliable and economic performance, need to be investigated. In this paper, a probabilistic model of security-constrained unit commitment is proposed to minimize the cost of energy, spinning reserve and possible loss of load. A new formulation of expected energy not served considering the probability distribution of forecast errors of wind and load, as well as outage replacement rates of various generators is presented. The proposed method is solved by mixed integer linear programming. Numerical simulations on the IEEE Reliability Test System show the effectiveness of the method. The relationships of uncertainties and required spinning reserves are verified.",
Depth camera based indoor mobile robot localization and navigation,"The sheer volume of data generated by depth cameras provides a challenge to process in real time, in particular when used for indoor mobile robot localization and navigation. We introduce the Fast Sampling Plane Filtering (FSPF) algorithm to reduce the volume of the 3D point cloud by sampling points from the depth image, and classifying local grouped sets of points as belonging to planes in 3D (the “plane filtered” points) or points that do not correspond to planes within a specified error margin (the “outlier” points). We then introduce a localization algorithm based on an observation model that down-projects the plane filtered points on to 2D, and assigns correspondences for each point to lines in the 2D map. The full sampled point cloud (consisting of both plane filtered as well as outlier points) is processed for obstacle avoidance for autonomous navigation. All our algorithms process only the depth information, and do not require additional RGB data. The FSPF, localization and obstacle avoidance algorithms run in real time at full camera frame rates (30Hz) with low CPU requirements (16%). We provide experimental results demonstrating the effectiveness of our approach for indoor mobile robot localization and navigation. We further compare the accuracy and robustness in localization using depth cameras with FSPF vs. alternative approaches that simulate laser rangefinder scans from the 3D data.",
Low-Resistance Electrical Contact to Carbon Nanotubes With Graphitic Interfacial Layer,"Carbon nanotubes (CNTs) are promising candidates for transistors and interconnects for nanoelectronic circuits. Although CNTs intrinsically have excellent electrical conductivity, the large contact resistance at the interface between CNT and metal hinders its practical application. Here, we show that electrical contact to the CNT is substantially improved using a graphitic interfacial layer catalyzed by a Ni layer. The p-type semiconducting CNT with graphitic contact exhibits high on-state conductance at room temperature and a steep subthreshold swing in a back-gate configuration. We also show contact improvement to the semiconducting CNTs with different capping metals. To study the role of the graphitic interfacial layer in the contact stack, the capping metal and Ni catalyst were selectively removed and replaced with new metal pads deposited by evaporation and without further annealing. Good electrical contact to the semiconducting CNTs was still preserved after the new metal replacement, indicating that the contact improvement is attributed to the presence of the graphitic interfacial layer.","Contacts,
Nickel,
Carbon,
Annealing,
Gold,
Electrodes"
Heartbeat Classification Using Morphological and Dynamic Features of ECG Signals,"In this paper, we propose a new approach for heartbeat classification based on a combination of morphological and dynamic features. Wavelet transform and independent component analysis (ICA) are applied separately to each heartbeat to extract morphological features. In addition, RR interval information is computed to provide dynamic features. These two different types of features are concatenated and a support vector machine classifier is utilized for the classification of heartbeats into one of 16 classes. The procedure is independently applied to the data from two ECG leads and the two decisions are fused for the final classification decision. The proposed method is validated on the baseline MIT-BIH arrhythmia database and it yields an overall accuracy (i.e., the percentage of heartbeats correctly classified) of 99.3% (99.7% with 2.4% rejection) in the “class-oriented” evaluation and an accuracy of 86.4% in the “subject-oriented” evaluation, comparable to the state-of-the-art results for automatic heartbeat classification.","Heart beat,
Electrocardiography,
Feature extraction,
Databases,
Training,
Support vector machines,
Heart rate variability"
A Distributed Bulk-Oxide Trap Model for \hbox{Al}_{2} \hbox{O}_{3} InGaAs MOS Devices,This paper presents a distributed circuit model for bulk-oxide traps based on tunneling between the semiconductor surface and trap states in the gate dielectric film. The model is analytically solved at dc. It is shown that the distributed bulk-oxide trap model correctly depicts the frequency dispersion in the capacitance- and conductance-voltage data of Al2O3-InGaAs MOS devices that do not fit the conventional interface state model. The slope degradation or stretch-out of the measured capacitance-voltage curve near flatband can be also explained by the distributed bulk-oxide trap model.,"Capacitance,
Dispersion,
Aluminum oxide,
Semiconductor device modeling,
Electron traps,
Interface states,
Logic gates"
Supervised hashing with kernels,"Recent years have witnessed the growing popularity of hashing in large-scale vision problems. It has been shown that the hashing quality could be boosted by leveraging supervised information into hash function learning. However, the existing supervised methods either lack adequate performance or often incur cumbersome model training. In this paper, we propose a novel kernel-based supervised hashing model which requires a limited amount of supervised information, i.e., similar and dissimilar data pairs, and a feasible training cost in achieving high quality hashing. The idea is to map the data to compact binary codes whose Hamming distances are minimized on similar pairs and simultaneously maximized on dissimilar pairs. Our approach is distinct from prior works by utilizing the equivalence between optimizing the code inner products and the Hamming distances. This enables us to sequentially and efficiently train the hash functions one bit at a time, yielding very short yet discriminative codes. We carry out extensive experiments on two image benchmarks with up to one million samples, demonstrating that our approach significantly outperforms the state-of-the-arts in searching both metric distance neighbors and semantically similar neighbors, with accuracy gains ranging from 13% to 46%.",
Design of Disaster-Resilient Optical Datacenter Networks,"Survivability against disasters-both natural and deliberate attacks, and spanning large geographical areas-is becoming a major challenge in communication networks. Cloud services delivered by datacenter networks yield new opportunities to provide protection against disasters. Cloud services require a network substrate with high capacity, low latency, high availability, and low cost, which can be delivered by optical networks. In such networks, path protection against network failures is generally ensured by providing a backup path to the same destination (i.e., a datacenter), which is link-disjoint to the primary path. This protection fails to protect against disasters covering an area which disrupts both primary and backup paths. Also, protection against destination (datacenter) node failure is not ensured by a generic protection scheme. Moreover, content/service protection is a fundamental problem in a datacenter network, as the failure of a datacenter should not cause the disappearance of a specific content/service from the network. So content placement, routing, and protection of paths and content should be addressed together. In this work, we propose an integrated Integer Linear Program (ILP) to design an optical datacenter network, which solves the above-mentioned problems simultaneously. We show that our disaster protection scheme exploiting anycasting provides more protection, but uses less capacity than dedicated single-link failure protection. We show that a reasonable number of datacenters and selective content replicas with intelligent network design can provide survivability to disasters while supporting user demands. We also propose ILP relaxations and heuristics to solve the problem for large networks.","Optical fiber networks,
Routing,
Equations,
Optical switches,
Bandwidth,
Communication networks,
Earthquakes"
60-GHz LTCC Integrated Circularly Polarized Helical Antenna Array,"A 60-GHz wideband circularly polarized (CP) helical antenna array of 4 × 4 elements is designed and fabricated using low temperature cofired ceramic (LTCC) technology. The flexible via hole distribution is fully utilized to achieve a helical antenna array to obtain good circular polarization performance. Meanwhile, grounded coplanar waveguide (GCPW) to stripline is utilized for probe station measurement. Unlike traditional helical antennas, the proposed helical antenna array is convenient for integrated applications. The fabricated antenna array has dimension of 12 × 10 × 2 mm3. The simulated and measured impedance, axial ratio (AR) and radiation pattern are studied and compared. The proposed antenna array shows a wide measured impedance bandwidth from 52.5 to 65.5 GHz for | S11| <; -10dB, wideband measured AR bandwidth from 54 to 66 GHz for AR <;3 dB, respectively.","Antenna measurements,
Arrays,
Antenna arrays,
Helical antennas,
Gain,
Antenna radiation patterns,
Frequency measurement"
Tracking the articulated motion of two strongly interacting hands,"We propose a method that relies on markerless visual observations to track the full articulation of two hands that interact with each-other in a complex, unconstrained manner. We formulate this as an optimization problem whose 54-dimensional parameter space represents all possible configurations of two hands, each represented as a kinematic structure with 26 Degrees of Freedom (DoFs). To solve this problem, we employ Particle Swarm Optimization (PSO), an evolutionary, stochastic optimization method with the objective of finding the two-hands configuration that best explains observations provided by an RGB-D sensor. To the best of our knowledge, the proposed method is the first to attempt and achieve the articulated motion tracking of two strongly interacting hands. Extensive quantitative and qualitative experiments with simulated and real world image sequences demonstrate that an accurate and efficient solution of this problem is indeed feasible.",
How low energy is bluetooth low energy? Comparative measurements with ZigBee/802.15.4,"Ultra low power communication mechanisms are essential for future Internet of Things deployments. Bluetooth Low Energy (BLE) is one promising candidate for such deployments. We study the energy consumption of BLE by measuring real devices with a power monitor and derive models of the basic energy consumption behavior observed from the measurement results. We investigate also the overhead of Ipv6-based communication over BLE, which is relevant for future IoT scenarios. We contrast our results by performing similar measurements with ZigBee/802.15.4 devices. Our results show that when compared to ZigBee, BLE is indeed very energy efficient in terms of number of bytes transferred per Joule spent. In addition, IPv6 communication energy overhead remains reasonable. We also point out a few specific limitations with current stack implementations and explain that removing those limitations could improve energy utility significantly.","Energy consumption,
Zigbee,
IEEE 802.15 Standards,
Sensors,
Energy measurement,
Bluetooth,
Interference"
Managing distributed UPS energy for effective power capping in data centers,"Power over-subscription can reduce costs for modern data centers. However, designing the power infrastructure for a lower operating power point than the aggregated peak power of all servers requires dynamic techniques to avoid high peak power costs and, even worse, tripping circuit breakers. This work presents an architecture for distributed per-server UPSs that stores energy during low activity periods and uses this energy during power spikes. This work leverages the distributed nature of the UPS batteries and develops policies that prolong the duration of their usage. The specific approach shaves 19.4% of the peak power for modern servers, at no cost in performance, allowing the installation of 24% more servers within the same power budget. More servers amortize infrastructure costs better and, hence, reduce total cost of ownership per server by 6.3%.",
A Framework for Automatic and Unsupervised Detection of Multiple Changes in Multitemporal Images,"The detection of multiple changes (i.e., different kinds of change) in multitemporal remote sensing images is a complex problem. When multispectral images having B spectral bands are considered, an effective solution to this problem is to exploit all available spectral channels in the framework of supervised or partially supervised approaches. However, in many real applications, it is difficult/impossible to collect ground truth information for either multitemporal or single-date images. On the opposite, unsupervised methods available in the literature are not effective in handling the full information present in multispectral and multitemporal images. They usually consider a simplified subspace of the original feature space having small dimensionality and, thus, characterized by a possible loss of change information. In this paper, we present a framework for the detection of multiple changes in bitemporal and multispectral remote sensing images that allows one to overcome the limits of standard unsupervised methods. The framework is based on the following: 1) a compressed yet efficient 2-D representation of the change information and 2) a two-step automatic decision strategy. The effectiveness of the proposed approach has been tested on two bitemporal and multispectral data sets having different properties. Results obtained on both data sets confirm the effectiveness of the proposed approach.","Vectors,
Image coding,
Feature extraction,
Remote sensing,
Accuracy,
Geologic measurements,
Data mining"
Closed-Loop Decoder Adaptation on Intermediate Time-Scales Facilitates Rapid BMI Performance Improvements Independent of Decoder Initialization Conditions,"Closed-loop decoder adaptation (CLDA) shows great promise to improve closed-loop brain-machine interface (BMI) performance. Developing adaptation algorithms capable of rapidly improving performance, independent of initial performance, may be crucial for clinical applications where patients have limited movement and sensory abilities due to motor deficits. Given the subject-decoder interactions inherent in closed-loop BMIs, the decoder adaptation time-scale may be of particular importance when initial performance is limited. Here, we present SmoothBatch, a CLDA algorithm which updates decoder parameters on a 1-2 min time-scale using an exponentially weighted sliding average. The algorithm was experimentally tested with one nonhuman primate performing a center-out reaching BMI task. SmoothBatch was seeded four ways with varying offline decoding power: 1) visual observation of a cursor (n = 20), 2) ipsilateral arm movements (n = 8), 3) baseline neural activity ( n = 17), and 4) arbitrary weights (n = 11). SmoothBatch rapidly improved performance regardless of seeding, with performance improvements from 0.018 0.133 successes/min to >;8 successes/min within 13.1 5.5 min (n = 56). After decoder adaptation ceased, the subject maintained high performance. Moreover, performance improvements were paralleled by SmoothBatch convergence, suggesting that CLDA involves a co-adaptation process between the subject and the decoder.","Kinematics,
Adaptive algorithms,
Closed loop systems,
Adaptive control,
Brain computer interfaces"
A Universal Space-Time Architecture for Multiple-Antenna Aided Systems,"In this tutorial, we first review the family of conventional multiple-antenna techniques, and then we provide a general overview of the recent concept of the powerful Multiple-Input Multiple-Output (MIMO) family based on a universal Space-Time Shift Keying (STSK) philosophy. When appropriately configured, the proposed STSK scheme has the potential of outperforming conventional MIMO arrangements.","MIMO,
Diversity reception,
Multiplexing,
Transmitting antennas,
Fading,
Receivers"
Understanding Kin Relationships in a Photo,"There is an urgent need to organize and manage images of people automatically due to the recent explosion of such data on the Web in general and in social media in particular. Beyond face detection and face recognition, which have been extensively studied over the past decade, perhaps the most interesting aspect related to human-centered images is the relationship of people in the image. In this work, we focus on a novel solution to the latter problem, in particular the kin relationships. To this end, we constructed two databases: the first one named UB KinFace Ver2.0, which consists of images of children, their young parents and old parents, and the second one named FamilyFace. Next, we develop a transfer subspace learning based algorithm in order to reduce the significant differences in the appearance distributions between children and old parents facial images. Moreover, by exploring the semantic relevance of the associated metadata, we propose an algorithm to predict the most likely kin relationships embedded in an image. In addition, human subjects are used in a baseline study on both databases. Experimental results have shown that the proposed algorithms can effectively annotate the kin relationships among people in an image and semantic context can further improve the accuracy.","Face,
Databases,
Feature extraction,
Semantics,
Face recognition,
Accuracy,
Context"
Toward Brain-Actuated Humanoid Robots: Asynchronous Direct Control Using an EEG-Based BCI,"The brain-computer interface (BCI) technique is a novel control interface to translate human intentions into appropriate motion commands for robotic systems. The aim of this study is to apply an asynchronous direct-control system for humanoid robot navigation using an electroencephalograph (EEG), based active BCI. The experimental procedures consist of offline training, online feedback testing, and real-time control sessions. The amplitude features from EEGs are extracted using power spectral analysis, while informative feature components are selected based on the Fisher ratio. The two classifiers are hierarchically structured to identify human intentions and trained to build an asynchronous BCI system. For the performance test, five healthy subjects controlled a humanoid robot navigation to reach a target goal in an indoor maze by using their EEGs based on real-time images obtained from a camera on the head of the robot. The experimental results showed that the subjects successfully controlled the humanoid robot in the indoor maze and reached the goal by using the proposed asynchronous EEG-based active BCI system.","Training,
Humanoid robots,
Electroencephalography,
Humans,
Navigation,
Testing"
Discriminative Least Squares Regression for Multiclass Classification and Feature Selection,"This paper presents a framework of discriminative least squares regression (LSR) for multiclass classification and feature selection. The core idea is to enlarge the distance between different classes under the conceptual framework of LSR. First, a technique called ε-dragging is introduced to force the regression targets of different classes moving along opposite directions such that the distances between classes can be enlarged. Then, the ε-draggings are integrated into the LSR model for multiclass classification. Our learning framework, referred to as discriminative LSR, has a compact model form, where there is no need to train two-class machines that are independent of each other. With its compact form, this model can be naturally extended for feature selection. This goal is achieved in terms of L2,1 norm of matrix, generating a sparse learning model for feature selection. The model for multiclass classification and its extension for feature selection are finally solved elegantly and efficiently. Experimental evaluation over a range of benchmark datasets indicates the validity of our method.",
Impact of Distributed Generations With Energy Storage Devices on the Electric Grid,"The commonly used distributed generations (DG) technologies include wind generators, photovoltaics, and biomass generators with their sizes varying between several kW to a few MW. Energy storage devices are generally used to smooth variations in DG's MW output due to inherent unpredictability and to minimize exchange of power from grid. Connecting the storage and DGs to the grid have both technical and economic impacts. This paper aims at analyzing the technical and economic impacts of distributed generators along with energy storage devices on the distribution system. The technical analysis includes analyzing the transient stability of a system with DGs and energy storage devices, such as a battery and ultracapacitor. The DGs are represented by small synchronous and induction generators. Different types and locations of faults and different penetration levels of the DGs are considered in the analysis. Energy storage devices are found to have a positive impact on transient stability. For economic analysis, the costs of the system with different DG technologies and energy storage devices are compared using the software tool “hybrid optimization model for electric renewables (HOMER).” Finally, the analysis for cost versus benefits of DGs and energy storage devices is compared briefly.","Stability analysis,
Power system stability,
Batteries,
Transient analysis,
Rotors,
Supercapacitors"
A Robust and Sensitive Metric for Quantifying Movement Smoothness,"The need for movement smoothness quantification to assess motor learning and recovery has resulted in various measures that look at different aspects of a movement's profile. This paper first shows that most of the previously published smoothness measures lack validity, consistency, sensitivity, or robustness. It then introduces and evaluates the spectral arc-length metric that uses a movement speed profile's Fourier magnitude spectrum to quantify movement smoothness. This new metric is systematically tested and compared to other smoothness metrics, using experimental data from stroke and healthy subjects as well as simulated movement data. The results indicate that the spectral arc-length metric is a valid and consistent measure of movement smoothness, which is both sensitive to modifications in motor behavior and robust to measurement noise. We hope that the systematic analysis of this paper is a step toward the standardization of the quantitative assessment of movement smoothness.",
Medical Image Segmentation by Combining Graph Cuts and Oriented Active Appearance Models,"In this paper, we propose a novel method based on a strategic combination of the active appearance model (AAM), live wire (LW), and graph cuts (GCs) for abdominal 3-D organ segmentation. The proposed method consists of three main parts: model building, object recognition, and delineation. In the model building part, we construct the AAM and train the LW cost function and GC parameters. In the recognition part, a novel algorithm is proposed for improving the conventional AAM matching method, which effectively combines the AAM and LW methods, resulting in the oriented AAM (OAAM). A multiobject strategy is utilized to help in object initialization. We employ a pseudo-3-D initialization strategy and segment the organs slice by slice via a multiobject OAAM method. For the object delineation part, a 3-D shape-constrained GC method is proposed. The object shape generated from the initialization step is integrated into the GC cost computation, and an iterative GC-OAAM method is used for object delineation. The proposed method was tested in segmenting the liver, kidneys, and spleen on a clinical CT data set and also on the MICCAI 2007 Grand Challenge liver data set. The results show the following: 1) The overall segmentation accuracy of true positive volume fraction TPVF >; 94.3% and false positive volume fraction FPVF <; 0.2% can be achieved; 2) the initializa- tion performance can be improved by combining the AAM and LW; 3) the multiobject strategy greatly facilitates initialization; 4) compared with the traditional 3-D AAM method, the pseudo-3-D OAAM method achieves comparable performance while running 12 times faster; and 5) the performance of the proposed method is comparable to state-of-the-art liver segmentation algorithm. The executable version of the 3-D shape-constrained GC method with a user interface can be downloaded from http://xinjianchen.word- press.com/research/.",
Task-Dependent Visual-Codebook Compression,"A visual codebook serves as a fundamental component in many state-of-the-art computer vision systems. Most existing codebooks are built based on quantizing local feature descriptors extracted from training images. Subsequently, each image is represented as a high-dimensional bag-of-words histogram. Such highly redundant image description lacks efficiency in both storage and retrieval, in which only a few bins are nonzero and distributed sparsely. Furthermore, most existing codebooks are built based solely on the visual statistics of local descriptors, without considering the supervise labels coming from the subsequent recognition or classification tasks. In this paper, we propose a task-dependent codebook compression framework to handle the above two problems. First, we propose to learn a compression function to map an originally high-dimensional codebook into a compact codebook while maintaining its visual discriminability. This is achieved by a codeword sparse coding scheme with Lasso regression, which minimizes the descriptor distortions of training images after codebook compression. Second, we propose to adapt our codebook compression to the subsequent recognition or classification tasks. This is achieved by introducing a label constraint kernel (LCK) into our compression loss function. In particular, our LCK can model heterogeneous kinds of supervision, i.e., (partial) category labels, correlative semantic annotations, and image query logs. We validated our codebook compression in three computer vision tasks: 1) object recognition in PASCAL Visual Object Class 07; 2) near-duplicate image retrieval in UKBench; and 3) web image search in a collection of 0.5 million Flickr photographs. Our compressed codebook has shown superior performances over several state-of-the-art supervised and unsupervised codebooks.",
Finite-Element-Based Multiobjective Design Optimization Procedure of Interior Permanent Magnet Synchronous Motors for Wide Constant-Power Region Operation,"This paper proposes the design optimization procedure of three-phase interior permanent magnet (IPM) synchronous motors with minimum weight, maximum power output, and suitability for wide constant-power region operation. The particular rotor geometry of the IPM synchronous motor and the presence of several variables and constraints make the design problem very complicated. The authors propose to combine an accurate finite-element analysis with a multiobjective optimization procedure using a new algorithm belonging to the class of controlled random search algorithms. The optimization procedure has been employed to design two IPM motors for industrial application and a city electrical scooter. A prototype has been realized and tested. The comparison between the predicted and measured performances shows the reliability of the simulation results and the effectiveness, versatility, and robustness of the proposed procedure.",
Satellite Image Time Series Analysis Under Time Warping,"Satellite Image Time Series are becoming increasingly available and will continue to do so in the coming years thanks to the launch of space missions which aim at providing a coverage of the Earth every few days with high spatial resolution. In the case of optical imagery, it will be possible to produce land use and cover change maps with detailed nomenclatures. However, due to meteorological phenomena, such as clouds, these time series will become irregular in terms of temporal sampling, and one will need to compare time series with different lengths. In this paper, we present an approach to image time series analysis which is able to deal with irregularly sampled series and which also allows the comparison of pairs of time series where each element of the pair has a different number of samples. We present the dynamic time warping from a theoretical point of view and illustrate its capabilities with two applications to real-time series.","Time series analysis,
Remote sensing,
Radiometry,
Satellites,
Time measurement,
Euclidean distance,
Spatial resolution"
A Survey of H.264 AVC/SVC Encryption,Video encryption has been heavily researched in the recent years. This survey summarizes the latest research results on video encryption with a special focus on applicability and on the most widely-deployed video format H.264 including its scalable extension SVC. The survey intends to give researchers and practitioners an analytic and critical overview of the state-of-the-art of video encryption narrowed down to its joint application with the H.264 standard suite and associated protocols (packaging/streaming) and processes (transcoding/watermarking).,"Encryption,
Streaming media,
Static VAr compensators,
Watermarking,
Context"
A Narrow-Passband and Frequency-Tunable Microwave Photonic Filter Based on Phase-Modulation to Intensity-Modulation Conversion Using a Phase-Shifted Fiber Bragg Grating,"A novel approach to implementing a narrow-passband and frequency-tunable microwave photonic filter (MPF) based on phase-modulation to intensity-modulation conversion in a phase-shifted fiber Bragg grating (PS-FBG) is proposed and experimentally demonstrated. In the proposed MPF, a phase-modulated signal is sent to a PS-FBG. If one of the sidebands falls in the notch of the PS-FBG, the phase-modulated signal is converted to an intensity-modulated signal. Due to the ultra-narrow notch of the PS-FBG, a microwave filter with an ultra-narrow passband is realized. The tunability of the microwave filter is achieved by tuning the wavelength of the optical carrier. A theoretical analysis is performed in which the value of the phase shift and the location of the phase shift in the PS-FBG on the frequency response of the MPF are studied. Two PS-FBGs with different reflection bandwidths and different phase-shift values introduced at the center of the gratings are fabricated and incorporated into the proposed MPF. For the two PS-FBGs, the 3-dB bandwidths are 120 and 60 MHz and the tunable ranges are 5.5 and 15 GHz.","Bandwidth,
Passband,
Amplitude modulation,
Phase modulation,
Tuning,
Frequency modulation,
Optical device fabrication"
Geodesic flow kernel for unsupervised domain adaptation,"In real-world applications of visual recognition, many factors - such as pose, illumination, or image quality - can cause a significant mismatch between the source domain on which classifiers are trained and the target domain to which those classifiers are applied. As such, the classifiers often perform poorly on the target domain. Domain adaptation techniques aim to correct the mismatch. Existing approaches have concentrated on learning feature representations that are invariant across domains, and they often do not directly exploit low-dimensional structures that are intrinsic to many vision datasets. In this paper, we propose a new kernel-based method that takes advantage of such structures. Our geodesic flow kernel models domain shift by integrating an infinite number of subspaces that characterize changes in geometric and statistical properties from the source to the target domain. Our approach is computationally advantageous, automatically inferring important algorithmic parameters without requiring extensive cross-validation or labeled data from either domain. We also introduce a metric that reliably measures the adaptability between a pair of source and target domains. For a given target domain and several source domains, the metric can be used to automatically select the optimal source domain to adapt and avoid less desirable ones. Empirical studies on standard datasets demonstrate the advantages of our approach over competing methods.","Kernel,
Principal component analysis,
Measurement,
Vectors,
Manifolds,
Visualization,
Training"
Human Identification Using Temporal Information Preserving Gait Template,"Gait Energy Image (GEI) is an efficient template for human identification by gait. However, such a template loses temporal information in a gait sequence, which is critical to the performance of gait recognition. To address this issue, we develop a novel temporal template, named Chrono-Gait Image (CGI), in this paper. The proposed CGI template first extracts the contour in each gait frame, followed by encoding each of the gait contour images in the same gait sequence with a multichannel mapping function and compositing them to a single CGI. To make the templates robust to a complex surrounding environment, we also propose CGI-based real and synthetic temporal information preserving templates by using different gait periods and contour distortion techniques. Extensive experiments on three benchmark gait databases indicate that, compared with the recently published gait recognition approaches, our CGI-based temporal information preserving approach achieves competitive performance in gait recognition with robustness and efficiency.",
Human Atlas of the Cardiac Fiber Architecture: Study on a Healthy Population,"Cardiac fibers, as well as their local arrangement in laminar sheets, have a complex spatial variation of their orientation that has an important role in mechanical and electrical cardiac functions. In this paper, a statistical atlas of this cardiac fiber architecture is built for the first time using human datasets. This atlas provides an average description of the human cardiac fiber architecture along with its variability within the population. In this study, the population is composed of ten healthy human hearts whose cardiac fiber architecture is imaged ex vivo with DT-MRI acquisitions. The atlas construction is based on a computational framework that minimizes user interactions and combines most recent advances in image analysis: graph cuts for segmentation, symmetric log-domain diffeomorphic demons for registration, and log-Euclidean metric for diffusion tensor processing and statistical analysis. Results show that the helix angle of the average fiber orientation is highly correlated to the transmural depth and ranges from -41° on the epicardium to +66° on the endocardium. Moreover, we find that the fiber orientation dispersion across the population (13°) is lower than for the laminar sheets (31°). This study, based on human hearts, extends previous studies on other mammals with concurring conclusions and provides a description of the cardiac fiber architecture more specific to human and better suited for clinical applications. Indeed, this statistical atlas can help to improve the computational models used for radio-frequency ablation, cardiac resynchronization therapy, surgical ventricular restoration, or diagnosis and followups of heart diseases due to fiber architecture anomalies.","Heart,
Myocardium,
Tensile stress,
Humans,
Image segmentation,
Computer architecture,
Diffusion tensor imaging"
Smartphone-Based Collaborative and Autonomous Radio Fingerprinting,"Although active research has recently been conducted on received signal strength (RSS) fingerprint-based indoor localization, most of the current systems hardly overcome the costly and time-consuming offline training phase. In this paper, we propose an autonomous and collaborative RSS fingerprint collection and localization system. Mobile users track their position with inertial sensors and measure RSS from the surrounding access points. In this scenario, anonymous mobile users automatically collect data in daily life without purposefully surveying an entire building. The server progressively builds up a precise radio map as more users interact with their fingerprint data. The time drift error of inertial sensors is also compromised at run-time with the fingerprint-based localization, which runs with the collective fingerprints being currently built by the server. The proposed system has been implemented on a recent Android smartphone. The experiment results show that reasonable location accuracy is obtained with automatic fingerprinting in indoor environments.",
Asymptotic Analysis of MAP Estimation via the Replica Method and Applications to Compressed Sensing,"The replica method is a nonrigorous but well-known technique from statistical physics used in the asymptotic analysis of large, random, nonlinear problems. This paper applies the replica method, under the assumption of replica symmetry, to study estimators that are maximum a posteriori (MAP) under a postulated prior distribution. It is shown that with random linear measurements and Gaussian noise, the replica-symmetric prediction of the asymptotic behavior of the postulated MAP estimate of an -dimensional vector “decouples” as scalar postulated MAP estimators. The result is based on applying a hardening argument to the replica analysis of postulated posterior mean estimators of Tanaka and of Guo and Verdú. The replica-symmetric postulated MAP analysis can be readily applied to many estimators used in compressed sensing, including basis pursuit, least absolute shrinkage and selection operator (LASSO), linear estimation with thresholding, and zero norm-regularized estimation. In the case of LASSO estimation, the scalar estimator reduces to a soft-thresholding operator, and for zero norm-regularized estimation, it reduces to a hard threshold. Among other benefits, the replica method provides a computationally tractable method for precisely predicting various performance metrics including mean-squared error and sparsity pattern recovery probability.","Estimation,
Vectors,
Mathematical model,
Noise level,
Compressed sensing,
Equations,
Noise measurement"
"Low-THD, Fast-Transient, and Cost-Effective Synchronous-Frame Repetitive Controller for Three-Phase UPS Inverters","This paper presents a novel synchronous-frame repetitive controller for three-phase UPS inverters. Distinguished from conventional repetitive control techniques, the proposed synchronous-frame approach minimizes the repetitive control time delay to one-sixth of the fundamental period such that the dynamic response is significantly improved. In order to overcome the harmonic distortions under severe load conditions (e.g., unbalanced and nonlinear), in this paper, three synchronous rotating frames are deliberately selected, in each of which the repetitive controller is incorporated. Resultantly, the (6n ±1)th harmonics as well as the triplen harmonics are compensated. Moreover, a high-performance fourth-order linear phase infinite-impulse-response filter is applied to further enhance the accuracy of steady-state tracking. The proposed controller is programmed on the 16-bit fixed-point digital signal processor (TI TMS320LF2407) and eliminates high-resolution current sensors for cost effectiveness. Simulations and experimental tests have been carried out based on an 18-kW three-phase UPS system. Low total harmonic distortion (<;0025;) has been achieved under heavily distorted nonlinear load and unbalanced load. Fast dynamic response has been demonstrated during step load transients.","Harmonic analysis,
Power harmonic filters,
Inverters,
Uninterruptible power systems,
Steady-state,
Delay,
Sensors"
Molecular Communication Using Brownian Motion With Drift,"Inspired by biological communication systems, molecular communication has been proposed as a viable scheme to communicate between nano-sized devices separated by a very short distance. Here, molecules are released by the transmitter into the medium, which are then sensed by the receiver. This paper develops a preliminary version of such a communication system focusing on the release of either one or two molecules into a fluid medium with drift. We analyze the mutual information between transmitter and the receiver when information is encoded in the time of release of the molecule. Simplifying assumptions are required in order to calculate the mutual information, and theoretical results are provided to show that these calculations are upper bounds on the true mutual information. Furthermore, optimized degree distributions are provided, which suggest transmission strategies for a variety of drift velocities.",
Exploiting Statistical Dependencies in Sparse Representations for Signal Recovery,"Signal modeling lies at the core of numerous signal and image processing applications. A recent approach that has drawn considerable attention is sparse representation modeling, in which the signal is assumed to be generated as a combination of a few atoms from a given dictionary. In this work we consider a Bayesian setting and go beyond the classic assumption of independence between the atoms. The main goal of this paper is to introduce a statistical model that takes such dependencies into account and show how this model can be used for sparse signal recovery. We follow the suggestion of two recent works and assume that the sparsity pattern is modeled by a Boltzmann machine, a commonly used graphical model. For general dependency models, exact MAP and MMSE estimation of the sparse representation becomes computationally complex. To simplify the computations, we propose greedy approximations of the MAP and MMSE estimators. We then consider a special case in which exact MAP is feasible, by assuming that the dictionary is unitary and the dependency model corresponds to a certain sparse graph. Exploiting this structure, we develop an efficient message passing algorithm that recovers the underlying signal. When the model parameters defining the underlying graph are unknown, we suggest an algorithm that learns these parameters directly from the data, leading to an iterative scheme for adaptive sparse signal recovery. The effectiveness of our approach is demonstrated on real-life signals-patches of natural images-where we compare the denoising performance to that of previous recovery methods that do not exploit the statistical dependencies.","Dictionaries,
Hidden Markov models,
Computational modeling,
Atomic clocks,
Discrete cosine transforms,
Approximation algorithms,
Bayesian methods"
Fixed Switching Frequency Sliding Mode Control for Single-Phase Unipolar Inverters,"Sliding mode control (SMC) is recognized as robust controller with a high stability in a wide range of operating conditions, although it suffers from chattering problem. In addition, it cannot be directly applied to multiswitches power converters. In this paper, a high performance and fixed switching frequency sliding mode controller is proposed for a single-phase unipolar inverter. The chattering problem of SMC is eliminated by smoothing the control law in a narrow boundary layer, and a pulsewidth modulator produces the fixed frequency switching law for the inverter. The smoothing procedure is based on limitation of pulsewidth modulator. Although the smoothed control law limits the performance of SMC, regulation and dynamic response of the inverter output voltage are in an acceptable superior range. The performance of the proposed controller is verified by both simulation and experiments on a prototype 6-kVA inverter. The experimental results show that the total harmonic distortion of the output voltage is less than 1.1% and 1.7% at maximum linear and nonlinear load, respectively. Furthermore, the output dynamic performance of the inverter strictly conforms the standard IEC62040-3. Moreover, the measured efficiency of the inverter in the worst condition is better than 95.5%.",
A Passive UHF-RFID System for the Localization of an Indoor Autonomous Vehicle,"A global localization system combining odometry data with radio frequency identification (RFID) readings is proposed. RFID tags are placed at the ceiling of the environment and can be detected by a mobile robot unit traveling below them. The detection of the tags is the only information used in the proposed approach (no distance or bearing to the tag is considered available), but differently from similar localization setups reported in the literature, only a small number (about one each square meter or less) of tags are used. This is possible using a suitable tag's antenna in ultrahigh frequency band, expressly designed to obtain regular and stable RFID detection regions, which allows us to consider an efficient Kalman filtering approach to fuse RFID readings with the vehicle odometry data. A satisfactory performance is achieved, with an average position error of about 0.1 m. The hardware/software localization setup described in this paper is cheap and easy to use and may provide a satisfactory approach in several industrial and domestic scenarios.","Robots,
Radiofrequency identification,
Antennas,
Noise,
Kalman filters,
Position measurement"
Investigation of Attitude Tracking Using an Integrated Inertial and Magnetic Navigation System for Hand-Held Surgical Instruments,"Due to the need for accurate navigation in minimally invasive surgery, many methods have been introduced to the operating room for tracking the position and orientation of instruments. This paper considers the subproblem of using integrated inertial and magnetic sensing to track the attitude (orientation) of surgical instruments. In this scenario, it is usually assumed that the sensor is quasi-static and the surrounding magnetic field is steady. For practical hand-held surgical instruments, perturbations exist due to intended and unintended (e.g., tremor) motion and due to distortion of the surrounding magnetic field. We consider the problem of estimating the gravity and magnetic field in the inertial sensor frame with small perturbations. The dynamics of the gravity and magnetic field is studied under perturbations, their relationships to gyroscope measurements are analyzed, and Kalman filters (KFs) are formulated to reduce these perturbations. The estimated gravity and magnetic values (outputs of the KFs) are subsequently used in an extended KF for attitude estimation. In this filter, the prediction model is given by the system dynamics, formulated using quaternions, and the observation model is given by vector analysis of the estimated gravity and magnetic field. Experiments are performed to validate the algorithms under clinically realistic motions. The complete system demonstrates an improvement in the accuracy of the attitude estimate in the presence of small perturbations, and satisfies the specified accuracy requirement of 1°.","Surgery,
Estimation,
Magnetometers,
Gravity,
Navigation,
Instruments,
Accelerometers"
Evaluation of Three MRI-Based Anatomical Priors for Quantitative PET Brain Imaging,"In emission tomography, image reconstruction and therefore also tracer development and diagnosis may benefit from the use of anatomical side information obtained with other imaging modalities in the same subject, as it helps to correct for the partial volume effect. One way to implement this, is to use the anatomical image for defining the a priori distribution in a maximum-a-posteriori (MAP) reconstruction algorithm. In this contribution, we use the PET-SORTEO Monte Carlo simulator to evaluate the quantitative accuracy reached by three different anatomical priors when reconstructing positron emission tomography (PET) brain images, using volumetric magnetic resonance imaging (MRI) to provide the anatomical information. The priors are: 1) a prior especially developed for FDG PET brain imaging, which relies on a segmentation of the MR-image (Baete , 2004); 2) the joint entropy-prior (Nuyts, 2007); 3) a prior that encourages smoothness within a position dependent neighborhood, computed from the MR-image. The latter prior was recently proposed by our group in (Vunckx and Nuyts, 2010), and was based on the prior presented by Bowsher (2004). The two latter priors do not rely on an explicit segmentation, which makes them more generally applicable than a segmentation-based prior. All three priors produced a compromise between noise and bias that was clearly better than that obtained with postsmoothed maximum likelihood expectation maximization (MLEM) or MAP with a relative difference prior. The performance of the joint entropy prior was slightly worse than that of the other two priors. The performance of the segmentation-based prior is quite sensitive to the accuracy of the segmentation. In contrast to the joint entropy-prior, the Bowsher-prior is easily tuned and does not suffer from convergence problems.",
Auto-tuning a high-level language targeted to GPU codes,"Determining the best set of optimizations to apply to a kernel to be executed on the graphics processing unit (GPU) is a challenging problem. There are large sets of possible optimization configurations that can be applied, and many applications have multiple kernels. Each kernel may require a specific configuration to achieve the best performance, and moving an application to new hardware often requires a new optimization configuration for each kernel. In this work, we apply optimizations to GPU code using HMPP, a high-level directive-based language and source-to-source compiler that can generate CUDA / OpenCL code. However, programming with high-level languages may mean a loss of performance compared to using low-level languages. Our work shows that it is possible to improve the performance of a high-level language by using auto-tuning. We perform auto-tuning on a large optimization space on GPU kernels, focusing on loop permutation, loop unrolling, tiling, and specifying which loop(s) to parallelize, and show results on convolution kernels, codes in the PolyBench suite, and an implementation of belief propagation for stereo vision. The results show that our auto-tuned HMPP-generated implementations are significantly faster than the default HMPP implementation and can meet or exceed the performance of manually coded CUDA / OpenCL implementations.","Graphics processing unit,
Abstracts,
Programming,
Nickel,
Tiles,
Benchmark testing"
Five Major Shifts in 100 Years of Engineering Education,"In this paper, five major shifts in engineering education are identified. During the engineering science revolution, curricula moved from hands-on practice to mathematical modeling and scientific analyses. The first shift was initiated by engineering faculty members from Europe; accelerated during World War II, when physicists contributed multiple engineering breakthroughs; codified in the Grinter report; and kick-started by Sputnik. Did accreditation hinder curricular innovations? Were engineering graduates ready for practice? Spurred by these questions, the Accreditation Board for Engineering and Technology (ABET) required engineering programs to formulate outcomes, systematically assess achievement, and continuously improve student learning. The last three shifts are in progress. Since the engineering science revolution may have marginalized design, a distinctive feature of engineering, faculty members refocused attention on capstone and first-year engineering design courses. However, this third shift has not affected the two years in between. Fourth, research on learning and education continues to influence engineering education. Examples include learning outcomes and teaching approaches, such as cooperative learning and inquiry that increase student engagement. In shift five, technologies (e.g., the Internet, intelligent tutors, personal computers, and simulations) have been predicted to transform education for over 50 years; however, broad transformation has not yet been observed. Together, these five shifts characterize changes in engineering education over the past 100 years.","Educational institutions,
Accreditation,
Technological innovation,
Engineering education,
Engineering students,
Engineering profession,
Education"
High-Precision Motion Control Techniques: A Promising Approach to Improving Motion Performance,"In this article, the state of the art on high-precision motion control techniques is surveyed by referring to recent publications, mainly in the transactions and conferences of the IEEEIndustrial Electronics Society (IES), where a 2-degree-of-freedom (DoF) control framework is considered a practical and promising approach to improving motion performance. The actual issues and relevant solutions for each component in the 2-DoF control structure are clarified. Next, one of the examples, a 2-DoF controller design for robust vibration suppression positioning, is presented as an application to industrial high-precision positioning devices. Precise modeling and identification for the target mechatronic systems should be indispensable from the standpoint of more accurate model-based feedforward compensation and/or more progressive design of feedback controllers.",
Low Profile Fully Planar Folded Dipole Antenna on a High Impedance Surface,"A fully planar antenna design incorporating a high impedance surface (HIS) is presented. The HIS is composed by a periodic array of subwavelength dogbone-shaped conductors printed on top of a thin dielectric substrate and backed by a metallic ground plane. First, the characteristics of a dipole over PEC or PMC layers, a dielectric slab, and the HIS are compared and studied in detail, highlighting the advantages provided by the use of the HIS. Then, the design of a low profile folded dipole antenna working at 5.5 GHz on top of the HIS is described. The surface provides close to 6% antenna impedance bandwidth and increased gain up to 7 dBi, while shielding the lower half space from radiation. The antenna structure comprises three metal layers without any vias between them, and its overall thickness is 0.059λ0. The dipole is fed by a balanced twin lead line through a balun transformer integrated in the same antenna layer. A prototype has been built and measurements confirming simulation results are provided.","Dipole antennas,
Surface impedance,
Impedance,
Reflection,
Dielectrics,
Substrates"
Cross-Layer Analysis of the End-to-End Delay Distribution in Wireless Sensor Networks,"Emerging applications of wireless sensor networks (WSNs) require real-time quality-of-service (QoS) guarantees to be provided by the network. Due to the nondeterministic impacts of the wireless channel and queuing mechanisms, probabilistic analysis of QoS is essential. One important metric of QoS in WSNs is the probability distribution of the end-to-end delay. Compared to other widely used delay performance metrics such as the mean delay, delay variance, and worst-case delay, the delay distribution can be used to obtain the probability to meet a specific deadline for QoS-based communication in WSNs. To investigate the end-to-end delay distribution, in this paper, a comprehensive cross-layer analysis framework, which employs a stochastic queueing model in realistic channel environments, is developed. This framework is generic and can be parameterized for a wide variety of MAC protocols and routing protocols. Case studies with the CSMA/CA MAC protocol and an anycast protocol are conducted to illustrate how the developed framework can analytically predict the distribution of the end-to-end delay. Extensive test-bed experiments and simulations are performed to validate the accuracy of the framework for both deterministic and random deployments. Moreover, the effects of various network parameters on the distribution of end-to-end delay are investigated through the developed framework. To the best of our knowledge, this is the first work that provides a generic, probabilistic cross-layer analysis of end-to-end delay in WSNs.","Delay,
Wireless sensor networks,
Media Access Protocol,
Probabilistic logic,
Markov processes,
Quality of service"
Parameter selection for total-variation-based image restoration using discrepancy principle,"There are two key issues in successfully solving the image restoration problem: 1) estimation of the regularization parameter that balances data fidelity with the regularity of the solution and 2) development of efficient numerical techniques for computing the solution. In this paper, we derive a fast algorithm that simultaneously estimates the regularization parameter and restores the image. The new approach is based on the total-variation (TV) regularized strategy and Morozov's discrepancy principle. The TV norm is represented by the dual formulation that changes the minimization problem into a minimax problem. A proximal point method is developed to compute the saddle point of the minimax problem. By adjusting the regularization parameter adaptively in each iteration, the solution is guaranteed to satisfy the discrepancy principle. We will give the convergence proof of our algorithm and numerically show that it is better than some state-of-the-art methods in terms of both speed and accuracy.","TV,
Image restoration,
Vectors,
Convergence,
Minimization,
Null space"
Coordinated data-injection attack and detection in the smart grid: A detailed look at enriching detection solutions,"A smart grid improves the efficiency of power grids via the aid of modern communication, signal processing, and control technologies. While smart grid integration enables power grid networks to be smarter, it also increases the risk of cyberattacks due to the strong dependence on the cyberinfrastructure in the overall system. In this article, the coordinated datainjection attack detection problem in the smart grid is considered. Specifically, the data-injection attack model is first introduced and a thorough survey of existing detection methods is then given. Afterward, three important efforts to enrich the detection solution are presented in detail: 1) attacker versus defender dynamics, where possible interactive attack and defense strategies are discussed in the context of secure phasor measurement unit (PMU) placement 2) distributed attack detection and state recovery, where the focus is how to achieve the optimal centralized performance with a distributed approach 3) quickest detection (QD), where the trade off between the detection speed and detection performance is studied. A list of associated key open problems in this area is then presented to conclude this article.","Smart grids,
Power grids,
Power system management,
Signal processing,
Energy efficiency,
Power system control,
Phasor measurement,
Power system dynamics"
Regularization Parameter Selection for Nonlinear Iterative Image Restoration and MRI Reconstruction Using GCV and SURE-Based Methods,"Regularized iterative reconstruction algorithms for imaging inverse problems require selection of appropriate regularization parameter values. We focus on the challenging problem of tuning regularization parameters for nonlinear algorithms for the case of additive (possibly complex) Gaussian noise. Generalized cross-validation (GCV) and (weighted) mean-squared error (MSE) approaches [based on Stein's unbiased risk estimate (SURE)] need the Jacobian matrix of the nonlinear reconstruction operator (representative of the iterative algorithm) with respect to the data. We derive the desired Jacobian matrix for two types of nonlinear iterative algorithms: a fast variant of the standard iterative reweighted least-squares method and the contemporary split-Bregman algorithm, both of which can accommodate a wide variety of analysis- and synthesis-type regularizers. The proposed approach iteratively computes two weighted SURE-type measures: predicted-SURE and projected-SURE (which require knowledge of noise variance σ2), and GCV (which does not need σ2) for these algorithms. We apply the methods to image restoration and to magnetic resonance image (MRI) reconstruction using total variation and an analysis-type ℓ1-regularization. We demonstrate through simulations and experiments with real data that minimizing predicted-SURE and projected-SURE consistently lead to near-MSE-optimal reconstructions. We also observe that minimizing GCV yields reconstruction results that are near-MSE-optimal for image restoration and slightly suboptimal for MRI. Theoretical derivations in this paper related to Jacobian matrix evaluations can be extended, in principle, to other types of regularizers and reconstruction algorithms.",
Real time robust L1 tracker using accelerated proximal gradient approach,"Recently sparse representation has been applied to visual tracker by modeling the target appearance using a sparse approximation over a template set, which leads to the so-called L1 trackers as it needs to solve an ℓ1 norm related minimization problem for many times. While these L1 trackers showed impressive tracking accuracies, they are very computationally demanding and the speed bottleneck is the solver to ℓ1 norm minimizations. This paper aims at developing an L1 tracker that not only runs in real time but also enjoys better robustness than other L1 trackers. In our proposed L1 tracker, a new ℓ1 norm related minimization model is proposed to improve the tracking accuracy by adding an ℓ1 norm regularization on the coefficients associated with the trivial templates. Moreover, based on the accelerated proximal gradient approach, a very fast numerical solver is developed to solve the resulting ℓ1 norm related minimization problem with guaranteed quadratic convergence. The great running time efficiency and tracking accuracy of the proposed tracker is validated with a comprehensive evaluation involving eight challenging sequences and five alternative state-of-the-art trackers.",
Unstructured human activity detection from RGBD images,"Being able to detect and recognize human activities is essential for several applications, including personal assistive robotics. In this paper, we perform detection and recognition of unstructured human activity in unstructured environments. We use a RGBD sensor (Microsoft Kinect) as the input sensor, and compute a set of features based on human pose and motion, as well as based on image and point-cloud information. Our algorithm is based on a hierarchical maximum entropy Markov model (MEMM), which considers a person's activity as composed of a set of sub-activities. We infer the two-layered graph structure using a dynamic programming approach. We test our algorithm on detecting and recognizing twelve different activities performed by four people in different environments, such as a kitchen, a living room, an office, etc., and achieve good performance even when the person was not seen before in the training set1.","Hidden Markov models,
Humans,
Robot sensing systems,
Joints,
Dynamic programming"
Tumor-Cut: Segmentation of Brain Tumors on Contrast Enhanced MR Images for Radiosurgery Applications,"In this paper, we present a fast and robust practical tool for segmentation of solid tumors with minimal user interaction to assist clinicians and researchers in radiosurgery planning and assessment of the response to the therapy. Particularly, a cellular automata (CA) based seeded tumor segmentation method on contrast enhanced T1 weighted magnetic resonance (MR) images, which standardizes the volume of interest (VOI) and seed selection, is proposed. First, we establish the connection of the CA-based segmentation to the graph-theoretic methods to show that the iterative CA framework solves the shortest path problem. In that regard, we modify the state transition function of the CA to calculate the exact shortest path solution. Furthermore, a sensitivity parameter is introduced to adapt to the heterogeneous tumor segmentation problem, and an implicit level set surface is evolved on a tumor probability map constructed from CA states to impose spatial smoothness. Sufficient information to initialize the algorithm is gathered from the user simply by a line drawn on the maximum diameter of the tumor, in line with the clinical practice. Furthermore, an algorithm based on CA is presented to differentiate necrotic and enhancing tumor tissue content, which gains importance for a detailed assessment of radiation therapy response. Validation studies on both clinical and synthetic brain tumor datasets demonstrate 80%-90% overlap performance of the proposed algorithm with an emphasis on less sensitivity to seed initialization, robustness with respect to different and heterogeneous tumor types, and its efficiency in terms of computation time.","Tumors,
Image segmentation,
Automata,
Magnetic resonance imaging,
Biomedical imaging,
Image edge detection,
Planning"
CASA-Based Robust Speaker Identification,"Conventional speaker recognition systems perform poorly under noisy conditions. Inspired by auditory perception, computational auditory scene analysis (CASA) typically segregates speech by producing a binary time-frequency mask. We investigate CASA for robust speaker identification. We first introduce a novel speaker feature, gammatone frequency cepstral coefficient (GFCC), based on an auditory periphery model, and show that this feature captures speaker characteristics and performs substantially better than conventional speaker features under noisy conditions. To deal with noisy speech, we apply CASA separation and then either reconstruct or marginalize corrupted components indicated by a CASA mask. We find that both reconstruction and marginalization are effective. We further combine the two methods into a single system based on their complementary advantages, and this system achieves significant performance improvements over related systems under a wide range of signal-to-noise ratios.",
Multicast Routing for Decentralized Control of Cyber Physical Systems with an Application in Smart Grid,"In cyber physical systems, communication is needed for conveying sensor observations to controllers; thus, the design of the communication sub-system is of key importance for the stabilization of system dynamics. In this paper, multicast routing is studied for networking of decentralized sensors and controllers. The challenges of uncertain destinations and multiple routing modes, which are significantly different from traditional data networks, are addressed by employing the theories of hybrid systems and linear matrix inequalities, thus forming a novel framework for studying the communication sub-system in cyber physical systems. Both cases of neglible delay and non-negligible delay are discussed. The proposed framework is then applied in the context of voltage control in smart grid. Numerical simulations using a 4-bus power grid model show that the proposed framework and algorithm can effectively stabilize cyber physical systems.",
Single Feed Stacked Patch Circular Polarized Antenna for Triple Band GPS Receivers,"A novel design of a circular polarized antenna for multiband GPS receivers is presented. The design employs the concept of multistacked patches fed through a single coaxial probe. Three patches being stacked together with a slit and symmetry I-slot are used to achieve triple operating frequency bands for GPS including L1 (1.575 GHz), L2 (1.227 GHz) and L5 (1.176 GHz). The proposed antenna has achieved a bandwidth of 2.0%, 1.5%, and 1.7% at GPS L1, L2, and L5 bands, respectively. It exhibits a minimum axial ratio of 0.51 dB with broad beamwidth in the upper hemisphere required for the GPS applications. The design of the proposed antenna is verified in the experiment. In addition, a detailed analysis has been carried out to study the effects of different geometrical parameters on the performance of the antenna.",
Rotationally Invariant Descriptors Using Intensity Order Pooling,"This paper proposes a novel method for interest region description which pools local features based on their intensity orders in multiple support regions. Pooling by intensity orders is not only invariant to rotation and monotonic intensity changes, but also encodes ordinal information into a descriptor. Two kinds of local features are used in this paper, one based on gradients and the other on intensities; hence, two descriptors are obtained: the Multisupport Region Order-Based Gradient Histogram (MROGH) and the Multisupport Region Rotation and Intensity Monotonic Invariant Descriptor (MRRID). Thanks to the intensity order pooling scheme, the two descriptors are rotation invariant without estimating a reference orientation, which appears to be a major error source for most of the existing methods, such as Scale Invariant Feature Transform (SIFT), SURF, and DAISY. Promising experimental results on image matching and object recognition demonstrate the effectiveness of the proposed descriptors compared to state-of-the-art descriptors.","Image matching,
Object recognition,
Estimation error,
Detectors,
Robustness,
Feature extraction"
Complementary Cooperation Algorithm Based on DEKF Combined With Pattern Recognition for SOC/Capacity Estimation and SOH Prediction,"Differences in electrochemical characteristics among Li-ion batteries result in erroneous state-of-charge (SOC)/capacity estimation and state-of-health (SOH) prediction when using the existing dual extended Kalman filter (DEKF) algorithm. This paper presents a complementary cooperation algorithm based on DEKF combined with pattern recognition as an application Hamming neural network to the identification of suitable battery model parameters for improved SOC/capacity estimation and SOH prediction. Two kinds of pattern such as discharging/charging voltage pattern (DCVP) and capacity pattern (CP) were measured, together with the battery parameters, as representative patterns. Through statistical analysis, the Hamming network is applied for identification of the representative DCVP and CP that most closely matche that of the arbitrary battery to be measured. The model parameters of the representative battery are then applied for SOC/capacity estimation and SOH prediction of the arbitrary battery using the DEKF. This avoids the need for repeated parameter measurement.","Batteries,
System-on-a-chip,
Estimation,
Battery charge measurement,
Mathematical model,
Prediction algorithms,
Integrated circuit modeling"
Social-Aware Multicast in Disruption-Tolerant Networks,"Node mobility and end-to-end disconnections in disruption-tolerant networks (DTNs) greatly impair the effectiveness of data forwarding. Although social-based approaches can address the problem, most existing solutions only focus on forwarding data to a single destination. In this paper, we study multicast with single and multiple data items in DTNs from a social network perspective, develop analytical models for multicast relay selection, and furthermore investigate the essential difference between multicast and unicast in DTNs. The proposed approach selects relays according to their capabilities, measured by social-based metrics, for forwarding data to the destinations. The design of social-based metrics exploits social network concepts such as node centrality and social community, and the selected relays ensure achieving the required data delivery ratio within the given time constraint. Extensive trace-driven simulations show that the proposed approach has similar data delivery ratio and delay to that of Epidemic routing, but significantly reduces data forwarding cost, measured by the number of relays used.",
A tutorial of wind turbine control for supporting grid frequency through active power control,"As wind energy becomes a larger portion of the world's energy portfolio and wind turbines become larger and more expensive, wind turbine control systems play an ever more prominent role in the design and deployment of wind turbines. The goals of traditional wind turbine control systems are maximizing energy production while protecting the wind turbine components. As more wind generation is installed there is an increasing interest in wind turbines actively controlling their power output in order to meet power setpoints and to participate in frequency regulation for the utility grid. This capability will be beneficial for grid operators, as it seems possible that wind turbines can be more effective at providing some of these services than traditional power plants. Furthermore, establishing an ancillary market for such regulation can be beneficial for wind plant owner/operators and manufacturers that provide such services. In this tutorial paper we provide an overview of basic wind turbine control systems and highlight recent industry trends and research in wind turbine control systems for grid integration and frequency stability.","Wind turbines,
Generators,
Blades,
Wind energy,
Rotors,
Frequency control,
Torque"
Block-Sparse Recovery via Convex Optimization,"Given a dictionary that consists of multiple blocks and a signal that lives in the range space of only a few blocks, we study the problem of finding a block-sparse representation of the signal, i.e., a representation that uses the minimum number of blocks. Motivated by signal/image processing and computer vision applications, such as face recognition, we consider the block-sparse recovery problem in the case where the number of atoms in each block is arbitrary, possibly much larger than the dimension of the underlying subspace. To find a block-sparse representation of a signal, we propose two classes of nonconvex optimization programs, which aim to minimize the number of nonzero coefficient blocks and the number of nonzero reconstructed vectors from the blocks, respectively. Since both classes of problems are NP-hard, we propose convex relaxations and derive conditions under which each class of the convex programs is equivalent to the original nonconvex formulation. Our conditions depend on the notions of mutual and cumulative subspace coherence of a dictionary, which are natural generalizations of existing notions of mutual and cumulative coherence. We evaluate the performance of the proposed convex programs through simulations as well as real experiments on face recognition. We show that treating the face recognition problem as a block-sparse recovery problem improves the state-of-the-art results by 10% with only 25% of the training data.","Dictionaries,
Coherence,
Vectors,
Face recognition,
Silicon,
Optimization,
Computer vision"
Web and Personal Image Annotation by Mining Label Correlation With Relaxed Visual Graph Embedding,"The number of digital images rapidly increases, and it becomes an important challenge to organize these resources effectively. As a way to facilitate image categorization and retrieval, automatic image annotation has received much research attention. Considering that there are a great number of unlabeled images available, it is beneficial to develop an effective mechanism to leverage unlabeled images for large-scale image annotation. Meanwhile, a single image is usually associated with multiple labels, which are inherently correlated to each other. A straightforward method of image annotation is to decompose the problem into multiple independent single-label problems, but this ignores the underlying correlations among different labels. In this paper, we propose a new inductive algorithm for image annotation by integrating label correlation mining and visual similarity mining into a joint framework. We first construct a graph model according to image visual features. A multilabel classifier is then trained by simultaneously uncovering the shared structure common to different labels and the visual graph embedded label prediction matrix for image annotation. We show that the globally optimal solution of the proposed framework can be obtained by performing generalized eigen-decomposition. We apply the proposed framework to both web image annotation and personal album labeling using the NUS-WIDE, MSRA MM 2.0, and Kodak image data sets, and the AUC evaluation metric. Extensive experiments on large-scale image databases collected from the web and personal album show that the proposed algorithm is capable of utilizing both labeled and unlabeled data for image annotation and outperforms other algorithms.",
Energy-efficient collaborative sensing with mobile phones,"Mobile phones with a rich set of embedded sensors enable sensing applications in various domains. In this paper, we propose to leverage cloud-assisted collaborative sensing to reduce sensing energy consumption for mobile phone sensing applications. We formally define a minimum energy sensing scheduling problem and present a polynomial-time algorithm to obtain optimal solutions, which can be used to show energy savings that can potentially be achieved by using collaborative sensing in mobile phone sensing applications, and can also serve as a benchmark for performance evaluation. We also address individual energy consumption and fairness by presenting an algorithm to find fair energy-efficient sensing schedules. Under realistic assumptions, we present two practical and effective heuristic algorithms to find energy-efficient sensing schedules. It has been shown by simulation results based on real energy consumption (measured by the Monsoon power monitor) and location (collected from the Google Map) data that collaborative sensing significantly reduces energy consumption compared to a traditional approach without collaborations, and the proposed heuristic algorithm performs well in terms of both total energy consumption and fairness.","Sensors,
Mobile handsets,
Roads,
Schedules,
Mobile communication,
Collaboration,
Energy consumption"
Data gathering in wireless sensor networks through intelligent compressive sensing,"The recently emerged compressive sensing (CS) theory provides a whole new avenue for data gathering in wireless sensor networks with benefits of universal sampling and decentralized encoding. However, existing compressive sensing based data gathering approaches assume the sensed data has a known constant sparsity, ignoring that the sparsity of natural signals vary in temporal and spatial domain. In this paper, we present an adaptive data gathering scheme by compressive sensing for wireless sensor networks. By introducing autoregressive (AR) model into the reconstruction of the sensed data, the local correlation in sensed data is exploited and thus local adaptive sparsity is achieved. The recovered data at the sink is evaluated by utilizing successive reconstructions, the relation between error and measurements. Then the number of measurements is adjusted according to the variation of the sensed data. Furthermore, a novel abnormal readings detection and identification mechanism based on combinational sparsity reconstruction is proposed. Internal error and external event are distinguished by their specific features. We perform extensive testing of our scheme on the real data sets and experimental results validate the efficiency and efficacy of the proposed scheme. Up to about 8dB SNR gain can be achieved over conventional CS based method with moderate increase of complexity.","Wireless sensor networks,
Pollution measurement,
Correlation,
Temperature measurement,
Current measurement,
Temperature sensors,
Data models"
Mapping Myocardial Fiber Orientation Using Echocardiography-Based Shear Wave Imaging,"The assessment of disrupted myocardial fiber arrangement may help to understand and diagnose hypertrophic or ischemic cardiomyopathy. We hereby proposed and developed shear wave imaging (SWI), which is an echocardiography-based, noninvasive, real-time, and easy-to-use technique, to map myofiber orientation. Five in vitro porcine and three in vivo open-chest ovine hearts were studied. Known in physics, shear wave propagates faster along than across the fiber direction. SWI is a technique that can generate shear waves travelling in different directions with respect to each myocardial layer. SWI further analyzed the shear wave velocity across the entire left-ventricular (LV) myocardial thickness, ranging between 10 (diastole) and 25 mm (systole), with a resolution of 0.2 mm in the middle segment of the LV anterior wall region. The fiber angle at each myocardial layer was thus estimated by finding the maximum shear wave speed. In the in vitro porcine myocardium (n = 5), the SWI-estimated fiber angles gradually changed from +800 ± 7° (endocardium) to +30° ± 13° (midwall) and -40° ± 10° (epicardium) with 0° aligning with the circumference of the heart. This transmural fiber orientation was well correlated with histology findings (r2 - 0.91 ± 0.02, p <; 0.0001). SWI further succeeded in mapping the transmural fiber orientation in three beating ovine hearts in vivo. At midsystole, the average fiber orientation exhibited 71° ± 13° (endocardium), 27° ± 8° (midwall), and - 26° ± 30° (epicardium). We demonstrated the capability of SWI in mapping myocardial fiber orientation in vitro and in vivo. SWI may serve as a new tool for the noninvasive characterization of myocardial fiber structure.","Myocardium,
Probes,
Imaging,
Ultrasonic imaging,
Optical fiber polarization,
In vivo,
Heart"
A Smart Health Monitoring Chair for Nonintrusive Measurement of Biological Signals,"We developed nonintrusive methods for simultaneous electrocardiogram, photoplethysmogram, and ballistocardiogram measurements that do not require direct contact between instruments and bare skin. These methods were applied to the design of a diagnostic chair for unconstrained heart rate and blood pressure monitoring purposes. Our methods were operationalized through capacitively coupled electrodes installed in the chair back that include high-input impedance amplifiers, and conductive textiles installed in the seat for capacitive driven-right-leg circuit configuration that is capable of recording electrocardiogram information through clothing. Photoplethysmograms were measured through clothing using seat mounted sensors with specially designed amplifier circuits that vary in light intensity according to clothing type. Ballistocardiograms were recorded using a film type transducer material, polyvinylidenefluoride (PVDF), which was installed beneath the seat cover. By simultaneously measuring signals, beat-to-beat heart rates could be monitored even when electrocardiograms were not recorded due to movement artifacts. Beat-to-beat blood pressure was also monitored using unconstrained measurements of pulse arrival time and other physiological parameters, and our experimental results indicated that the estimated blood pressure tended to coincide with actual blood pressure measurements. This study demonstrates the feasibility of our method and device for biological signal monitoring through clothing for unconstrained long-term daily health monitoring that does not require user awareness and is not limited by physical activity.","Electrocardiography,
Monitoring,
Sensors,
Electrodes,
Heart rate,
Biomedical monitoring"
A Junctionless Nanowire Transistor With a Dual-Material Gate,"A dual-material-gate junctionless nanowire transistor (DMG-JNT) is proposed in this paper. Its characteristic is demonstrated and compared with a generic single-material-gate JNT using 3-D numerical simulations. The results show that the DMG-JNT has a number of desirable features, such as high ON-state current, a large ON/OFF current ratio, improved transconductance Gm, high unity-gain frequency fT, high maximum oscillation frequency fMAX, and reduced drain-induced barrier lowering. The effects of different control gate ratios Ra and varied work-function differences between the two gates are studied. Finally, the optimization of Ra and the work-function difference for the proposed DMG-JNT is presented.","Logic gates,
Threshold voltage,
Doping,
Transconductance,
Metals,
Transistors,
Semiconductor process modeling"
Rethinking Vehicular Communications: Merging VANET with cloud computing,"Despite the surge in Vehicular Ad Hoc NETwork (VANET) research, future high-end vehicles are expected to under-utilize the on-board computation, communication, and storage resources. Olariu et al. envisioned the next paradigm shift from conventional VANET to Vehicular Cloud Computing (VCC) by merging VANET with cloud computing. But to date, in the literature, there is no solid architecture for cloud computing from VANET standpoint. In this paper, we put forth the taxonomy of VANET based cloud computing. It is, to the best of our knowledge, the first effort to define VANET Cloud architecture. Additionally we divide VANET clouds into three architectural frameworks named Vehicular Clouds (VC), Vehicles using Clouds (VuC), and Hybrid Vehicular Clouds (HVC). We also outline the unique security and privacy issues and research challenges in VANET clouds.","Vehicular ad hoc networks,
Cloud computing,
Vehicles,
Security,
Computer architecture,
Privacy,
Taxonomy"
Computational sprinting,"Although transistor density continues to increase, voltage scaling has stalled and thus power density is increasing each technology generation. Particularly in mobile devices, which have limited cooling options, these trends lead to a utilization wall in which sustained chip performance is limited primarily by power rather than area. However, many mobile applications do not demand sustained performance; rather they comprise short bursts of computation in response to sporadic user activity. To improve responsiveness for such applications, this paper explores activating otherwise powered-down cores for sub-second bursts of intense parallel computation. The approach exploits the concept of computational sprinting, in which a chip temporarily exceeds its sustainable thermal power budget to provide instantaneous throughput, after which the chip must return to nominal operation to cool down. To demonstrate the feasibility of this approach, we analyze the thermal and electrical characteristics of a smart-phone-like system that nominally operates a single core (~1W peak), but can sprint with up to 16 cores for hundreds of milliseconds. We describe a thermal design that incorporates phase-change materials to provide thermal capacitance to enable such sprints. We analyze image recognition kernels to show that parallel sprinting has the potential to achieve the task response time of a 16W chip within the thermal constraints of a 1W mobile platform.","Heating,
Phase change materials,
Capacitance,
Silicon,
Thermal conductivity,
Mobile communication"
Understanding how Deep Belief Networks perform acoustic modelling,Deep Belief Networks (DBNs) are a very competitive alternative to Gaussian mixture models for relating states of a hidden Markov model to frames of coefficients derived from the acoustic input. They are competitive for three reasons: DBNs can be fine-tuned as neural networks; DBNs have many non-linear hidden layers; and DBNs are generatively pre-trained. This paper illustrates how each of these three aspects contributes to the DBN's good recognition performance using both phone recognition performance on the TIMIT corpus and a dimensionally reduced visualization of the relationships between the feature vectors learned by the DBNs that preserves the similarity structure of the feature vectors at multiple scales. The same two methods are also used to investigate the most suitable type of input representation for a DBN.,"Hidden Markov models,
Vectors,
Mel frequency cepstral coefficient,
Training,
Speech,
Biological neural networks"
Discriminating the Simultaneous Occurrence of Three-Phase Induction Motor Rotor Faults and Mechanical Load Oscillations by the Instantaneous Active and Reactive Power Media Signature Analyses,This paper deals with the use of the instantaneous active and reactive power signature analyses and their derived signals-the instantaneous power factor and phase angle - for discriminating broken rotor bars and airgap eccentricity conditions (rotor faults) from mechanical load oscillation effects in operating three-phase squirrel cage induction motors. Both simulation and experimental results are presented to show the effectiveness and the merits of the proposed approach that offers the possibility to distinguish between the three conditions by comparing the signature analyses of two different quantities for each abnormality condition.,"Rotors,
Induction motors,
Reactive power,
Torque,
Stators,
Oscillators,
Bars"
"An Integrated Region-, Boundary-, Shape-Based Active Contour for Multiple Object Overlap Resolution in Histological Imagery","Active contours and active shape models (ASM) have been widely employed in image segmentation. A major limitation of active contours, however, is in their 1) inability to resolve boundaries of intersecting objects and to 2) handle occlusion. Multiple overlapping objects are typically segmented out as a single object. On the other hand, ASMs are limited by point correspondence issues since object landmarks need to be identified across multiple objects for initial object alignment. ASMs are also are constrained in that they can usually only segment a single object in an image. In this paper, we present a novel synergistic boundary and region-based active contour model that incorporates shape priors in a level set formulation with automated initialization based on watershed. We demonstrate an application of these synergistic active contour models using multiple level sets to segment nuclear and glandular structures on digitized histopathology images of breast and prostate biopsy specimens. Unlike previous related approaches, our model is able to resolve object overlap and separate occluded boundaries of multiple objects simultaneously. The energy functional of the active contour is comprised of three terms. The first term is the prior shape term, modeled on the object of interest, thereby constraining the deformation achievable by the active contour. The second term, a boundary-based term detects object boundaries from image gradients. The third term drives the shape prior and the contour towards the object boundary based on region statistics. The results of qualitative and quantitative evaluation on 100 prostate and 14 breast cancer histology images for the task of detecting and segmenting nuclei and lymphocytes reveals that the model easily outperforms two state of the art segmentation schemes (geodesic active contour and Rousson shape-based model) and on average is able to resolve up to 91% of overlapping/occluded structures in the images.","Shape,
Level set,
Training,
Image segmentation,
Active contours,
Principal component analysis,
Vectors"
Codes for Write-Once Memories,"A write-once memory (WOM) is a storage device that consists of cells that can take on q
values, with the added constraint that rewrites can only increase a cell's value. A length-n
, t
-write WOM-code is a coding scheme that allows t
messages to be stored in n
cells. If on the i
th write we write one of M_{i}
messages, then the rate of this write is the ratio of the number of written bits to the total number of cells, i.e., \log_{2}M_{i}/n
. The sum-rate of the WOM-code is the sum of all individual rates on all writes. A WOM-code is called a fixed-rate WOM-code if the rates on all writes are the same, and otherwise, it is called a variable-rate WOM-code. We address two different problems when analyzing the sum-rate of WOM-codes. In the first one, called the fixed-rate WOM-code problem, the sum-rate is analyzed over all fixed-rate WOM-codes, and in the second problem, called the unrestricted-rate WOM-code problem, the sum-rate is analyzed over all fixed-rate and variable-rate WOM-codes. In this paper, we first present a family of two-write WOM-codes. The construction is inspired by the coset coding scheme, which was used to construct multiple-write WOM-codes by Cohen and recently by Wu, in order to construct from each linear code a two-write WOM-code. This construction improves the best known sum-rates for the fixed- and unrestricted-rate WOM-code problems. We also show how to take advantage of two-write WOM-codes in order to construct codes for the Blackwell channel. The two-write construction is generalized for two-write WOM-codes with q
levels per cell, which is used with ternary cells to construct three- and four-write binary WOM-codes. This construction is used recursively in order to generate a family of t
-write WOM-codes for all t
. A further generalization of these t
-write WOM-codes yields additional families of efficient WOM-codes. Finally, we show a recursive method that uses the previously constructed WOM-codes in order to construct fixed-rate WOM-codes. We conclude and show that the WOM-codes constructed here outperform all previously known WOM-codes for 2\leqslant t\leqslant 10
for both the fixed- and unrestricted-rate WOM-code problems.","Vectors,
Upper bound,
Linear code,
Radio frequency,
Decoding,
Educational institutions"
Reliability Evaluation of Grid-Connected Photovoltaic Power Systems,"This study presents a systematic way to evaluate reliability performance of large grid-connected photovoltaic (PV) power systems considering variation of input power and ambient-condition-dependent failure rates of critical components including PV modules, inverters, and capacitors. State enumeration is used to analyze real-life grid-connected PV systems. Ambient-condition-dependent failure rates of major components in PV systems are formulated and incorporated in reliability analysis. A series of reliability indices are defined to quantify PV systems' reliability performance. In addition, sensitivity analyses are extensively conducted to investigate the impact of different factors on the performances of PV power systems. Test results on a practical 20-kW PV project are presented to demonstrate the effectiveness of the proposed method.","Reliability,
Power system reliability,
Inverters,
Capacitors,
Insulated gate bipolar transistors,
Temperature"
Joint Blind Source Separation With Multivariate Gaussian Model: Algorithms and Performance Analysis,"In this paper, we consider the joint blind source separation (JBSS) problem and introduce a number of algorithms to solve the JBSS problem using the independent vector analysis (IVA) framework. Source separation of multiple datasets simultaneously is possible when the sources within each and every dataset are independent of one another and each source is dependent on at most one source within each of the other datasets. In addition to source separation, the IVA framework solves an essential problem of JBSS, namely the identification of the dependent sources across the datasets. We propose to use the multivariate Gaussian source prior to achieve JBSS of sources that are linearly dependent across datasets. Analysis within the paper yields the local stability conditions, nonidentifiability conditions, and induced Cramér-Rao lower bound on the achievable interference to source ratio for IVA with multivariate Gaussian source priors. Additionally, by exploiting a novel nonorthogonal decoupling of the IVA cost function we introduce both Newton and quasi-Newton optimization algorithms for the general IVA framework.","Vectors,
Cost function,
Joints,
Algorithm design and analysis,
Mutual information,
Correlation,
Entropy"
Feature Selection With Harmony Search,"Many search strategies have been exploited for the task of feature selection (FS), in an effort to identify more compact and better quality subsets. Such work typically involves the use of greedy hill climbing (HC), or nature-inspired heuristics, in order to discover the optimal solution without going through exhaustive search. In this paper, a novel FS approach based on harmony search (HS) is presented. It is a general approach that can be used in conjunction with many subset evaluation techniques. The simplicity of HS is exploited to reduce the overall complexity of the search process. The proposed approach is able to escape from local solutions and identify multiple solutions owing to the stochastic nature of HS. Additional parameter control schemes are introduced to reduce the effort and impact of parameter configuration. These can be further combined with the iterative refinement strategy, tailored to enforce the discovery of quality subsets. The resulting approach is compared with those that rely on HC, genetic algorithms, and particle swarm optimization, accompanied by in-depth studies of the suggested improvements.",
SWSpec: The Requirements Specification Language in Service Workflow Environments,"Advanced technologies have changed the nature of business processes in the form of services. In coordinating services to achieve a particular objective, service workflow is used to control service composition, execution sequences as well as path selection. Since existing mechanisms are insufficient for addressing the diversity and dynamicity of the requirements in a large-scale distributed environment, developing formal requirements specification is necessary. In this paper, we propose a Service Workflow Specification language, called SWSpec, which allows arbitrary services in a workflow to formally and uniformly impose their requirements. As such, the solution will provide a formal way to regulate and control workflows as well as enrich the proliferation of service provisions and consumptions in opened environments.","High definition video,
Joining processes,
Scalability,
Business,
Industries,
Unified modeling language"
Bandwidth and Latency Requirements for Smart Transmission Grid Applications,"The rapid increase of phasor measurements on the high voltage power system has opened opportunities for new applications to enhance the operation of the grid. To take advantage of the high sampling rates of these measurement data, these applications will require a high-bandwidth, networked communication system. The specifications for this next generation communication system that will overlay the continental power grids are under intense discussion at this time by organizations like the North-American Synchro-Phasor Initiative (NASPI). In this paper we present a method to simulate, design and test the adequacy of a communication system for a particular transmission grid. The main difference from typical communication system studies is that we formulate the communication requirements from the power grid application requirements, that is, the communication design, simulation and testing is from the viewpoint of the anticipated power applications. The method is demonstrated on a WECC 225 bus and a Polish 2383 bus transmission system models.",
Resource allocation using a reverse iterative combinatorial auction for device-to-device underlay cellular networks,"An innovative auction-based allocation scheme is proposed to improve the performance of device-to-device (D2D) communications as an underlay in the downlink (DL) cellular networks. To optimize the system sum rate over the resource sharing of both D2D and cellular modes, we introduce a reverse iterative combinatorial auction as the allocation mechanism. In the auction, all the spectrum resources are considered as a set of resource units, which compete to obtain business as bidders while packages of D2D pairs are auctioned off as goods in each auction round. We first formulate the valuation of each resource unit for packages of D2D links. And then a detailed non-monotonic descending price auction algorithm is explained. Further, we prove that the proposed scheme is cheat-proof, converges in a finite number of iteration rounds, and has lower complexity compared to a traditional combinatorial allocation. The simulation results demonstrate that the algorithm efficiently leads to a good performance on the system sum rate.","resource allocation,
cellular radio,
combinatorial mathematics,
iterative methods,
radio spectrum management"
Performance Analysis of Cognitive Radio Spectrum Access With Prioritized Traffic,"Dynamic spectrum access (DSA) is an important design aspect for cognitive radio networks. Most of existing DSA schemes are to govern unlicensed user (i.e., secondary user, SU) traffic in a licensed spectrum without compromising the transmissions of the licensed users, in which all the unlicensed users are typically treated equally. In this paper, prioritized unlicensed user traffic is considered. Specifically, the unlicensed user traffic is divided into two priority classes (i.e., high and low priority). We consider a general setting in which the licensed users' transmissions can happen at any time instant. Therefore, the DSA scheme should perform spectrum handoff to protect the licensed user's transmission. Different DSA schemes (i.e., centralized and distributed) are considered to manage the prioritized unlicensed user traffic. These DSA schemes use different handoff mechanisms for the two classes of unlicensed users. We also study the impact of subchannel reservation for high-priority SUs in both DSA schemes. Each of the proposed DSA schemes is analyzed using a continuous-time Markov chain. For performance measures, we derive blocking probability, the probability of forced termination, call completion rate, and mean handoff delay for both high- and low-priority unlicensed users. The numerical results are verified using simulations.","Manganese,
Sensors,
Media Access Protocol,
Markov processes,
Bandwidth,
Quality of service,
Analytical models"
Comb-Push Ultrasound Shear Elastography (CUSE): A Novel Method for Two-Dimensional Shear Elasticity Imaging of Soft Tissues,"Fast and accurate tissue elasticity imaging is essential in studying dynamic tissue mechanical properties. Various ultrasound shear elasticity imaging techniques have been developed in the last two decades. However, to reconstruct a full field-of-view 2-D shear elasticity map, multiple data acquisitions are typically required. In this paper, a novel shear elasticity imaging technique, comb-push ultrasound shear elastography (CUSE), is introduced in which only one rapid data acquisition (less than 35 ms) is needed to reconstruct a full field-of-view 2-D shear wave speed map (40 × 38 mm). Multiple unfocused ultrasound beams arranged in a comb pattern (comb-push) are used to generate shear waves. A directional filter is then applied upon the shear wave field to extract the left-to-right (LR) and right-to-left (RL) propagating shear waves. Local shear wave speed is recovered using a time-of-flight method based on both LR and RL waves. Finally, a 2-D shear wave speed map is reconstructed by combining the LR and RL speed maps. Smooth and accurate shear wave speed maps are reconstructed using the proposed CUSE method in two calibrated homogeneous phantoms with different moduli. Inclusion phantom experiments demonstrate that CUSE is capable of providing good contrast (contrast-to-noise ratio ≥25 dB) between the inclusion and background without artifacts and is insensitive to inclusion positions. Safety measurements demonstrate that all regulated parameters of the ultrasound output level used in CUSE sequence are well below the FDA limits for diagnostic ultrasound.","Acoustic beams,
Imaging,
Acoustics,
Ultrasonic imaging,
Elasticity,
Force,
Image reconstruction"
CSMA/CN: Carrier Sense Multiple Access With Collision Notification,"A wireless transmitter learns of a packet loss and infers collision only after completing the entire transmission. If the transmitter could detect the collision early [such as with carrier sense multiple access with collision detection (CSMA/CD) in wired networks], it could immediately abort its transmission, freeing the channel for useful communication. There are two main hurdles to realize CSMA/CD in wireless networks. First, a wireless transmitter cannot simultaneously transmit and listen for a collision. Second, any channel activity around the transmitter may not be an indicator of collision at the receiver. This paper attempts to approximate CSMA/CD in wireless networks with a novel scheme called CSMA/CN (collision notification). Under CSMA/CN, the receiver uses PHY-layer information to detect a collision and immediately notifies the transmitter. The collision notification consists of a unique signature, sent on the same channel as the data. The transmitter employs a listener antenna and performs signature correlation to discern this notification. Once discerned, the transmitter immediately aborts the transmission. We show that the notification signature can be reliably detected at the listener antenna, even in the presence of a strong self-interference from the transmit antenna. A prototype testbed of 10 USRP/GNU Radios demonstrates the feasibility and effectiveness of CSMA/CN.","Correlation,
Receivers,
Multiaccess communication,
Wireless communication,
Transmitting antennas,
Radio transmitters"
Semantic Model Vectors for Complex Video Event Recognition,"We propose semantic model vectors, an intermediate level semantic representation, as a basis for modeling and detecting complex events in unconstrained real-world videos, such as those from YouTube. The semantic model vectors are extracted using a set of discriminative semantic classifiers, each being an ensemble of SVM models trained from thousands of labeled web images, for a total of 280 generic concepts. Our study reveals that the proposed semantic model vectors representation outperforms-and is complementary to-other low-level visual descriptors for video event modeling. We hence present an end-to-end video event detection system, which combines semantic model vectors with other static or dynamic visual descriptors, extracted at the frame, segment, or full clip level. We perform a comprehensive empirical study on the 2010 TRECVID Multimedia Event Detection task (http://www.nist.gov/itl/iad/mig/med10.cfm), which validates the semantic model vectors representation not only as the best individual descriptor, outperforming state-of-the-art global and local static features as well as spatio-temporal HOG and HOF descriptors, but also as the most compact. We also study early and late feature fusion across the various approaches, leading to a 15% performance boost and an overall system performance of 0.46 mean average precision. In order to promote further research in this direction, we made our semantic model vectors for the TRECVID MED 2010 set publicly available for the community to use (http://www1.cs.columbia.edu/~mmerler/SMV.html).","Semantics,
Visualization,
Event detection,
Feature extraction,
Computer science,
Hidden Markov models,
Educational institutions"
An SMDP-Based Service Model for Interdomain Resource Allocation in Mobile Cloud Networks,"Mobile cloud computing is a promising technique that shifts the data and computing service modules from individual devices to a geographically distributed cloud service architecture. A general mobile cloud computing system is comprised of multiple cloud domains, and each domain manages a portion of the cloud system resources, such as the Central Processing Unit, memory and storage, etc. How to efficiently manage the cloud resources across multiple cloud domains is critical for providing continuous mobile cloud services. In this paper, we propose a service decision making system for interdomain service transfer to balance the computation loads among multiple cloud domains. Our system focuses on maximizing the rewards for both the cloud system and the users by minimizing the number of service rejections that degrade the user satisfaction level significantly. To this end, we formulate the service request decision making process as a semi-Markov decision process. The optimal service transfer decisions are obtained by jointly considering the system incomes and expenses. Extensive simulation results show that the proposed decision making system can significantly improve the system rewards and decrease service disruptions compared with the greedy approach.","Mobile communication,
Mobile handsets,
Cloud computing,
Resource management,
Computational modeling,
Mobile computing,
Analytical models"
Optimal PMU Placement by an Equivalent Linear Formulation for Exhaustive Search,"Observability of bulk power transmission network by means of minimum number of phasor measurement units (PMUs), with the aid of the network topology, is a great challenge. This paper presents a novel equivalent integer linear programming method (EILPM) for the exhaustive search-based PMU placement. The state estimation implemented based on such a placement is completely linear, thereby eliminating drawbacks of the conventional SCADA-based state estimation. Additional constraints for observability preservation following single PMU or line outages can easily be implemented in the proposed EILPM. Furthermore, the limitation of communication channels is dealt with by translation of nonlinear terms into linear ones. Optimal PMU placement is carried out on the IEEE 118-bus test system in different scenarios. The comparison between obtained results of EILPM and those of other methods reveals optimality of the solutions. Moreover, the proposed method is successfully applied on the Iranian National Grid, which demonstrates it can effectively be employed for practical power networks.",
Distributed Alternating Direction Method of Multipliers,"We consider a network of agents that are cooperatively solving a global unconstrained optimization problem, where the objective function is the sum of privately known local objective functions of the agents. Recent literature on distributed optimization methods for solving this problem focused on subgradient based methods, which typically converge at the rate O (1/√k), where k is the number of iterations. In this paper, k we introduce a new distributed optimization algorithm based on Alternating Direction Method of Multipliers (ADMM), which is a classical method for sequentially decomposing optimization problems with coupled constraints. We show that this algorithm converges at the rate O (1/k).",
Automated 3-D Segmentation of Lungs With Lung Cancer in CT Data Using a Novel Robust Active Shape Model Approach,"Segmentation of lungs with (large) lung cancer regions is a nontrivial problem. We present a new fully automated approach for segmentation of lungs with such high-density pathologies. Our method consists of two main processing steps. First, a novel robust active shape model (RASM) matching method is utilized to roughly segment the outline of the lungs. The initial position of the RASM is found by means of a rib cage detection method. Second, an optimal surface finding approach is utilized to further adapt the initial segmentation result to the lung. Left and right lungs are segmented individually. An evaluation on 30 data sets with 40 abnormal (lung cancer) and 20 normal left/right lungs resulted in an average Dice coefficient of 0.975±0.006 and a mean absolute surface distance error of 0.84±0.23 mm, respectively. Experiments on the same 30 data sets showed that our methods delivered statistically significant better segmentation results, compared to two commercially available lung segmentation approaches. In addition, our RASM approach is generally applicable and suitable for large shape models.",
Accurate Respiration Measurement Using DC-Coupled Continuous-Wave Radar Sensor for Motion-Adaptive Cancer Radiotherapy,"Accurate respiration measurement is crucial in motion-adaptive cancer radiotherapy. Conventional methods for respiration measurement are undesirable because they are either invasive to the patient or do not have sufficient accuracy. In addition, measurement of external respiration signal based on conventional approaches requires close patient contact to the physical device which often causes patient discomfort and undesirable motion during radiation dose delivery. In this paper, a dc-coupled continuous-wave radar sensor was presented to provide a noncontact and noninvasive approach for respiration measurement. The radar sensor was designed with dc-coupled adaptive tuning architectures that include RF coarse-tuning and baseband fine-tuning, which allows the radar sensor to precisely measure movement with stationary moment and always work with the maximum dynamic range. The accuracy of respiration measurement with the proposed radar sensor was experimentally evaluated using a physical phantom, human subject, and moving plate in a radiotherapy environment. It was shown that respiration measurement with radar sensor while the radiation beam is on is feasible and the measurement has a submillimeter accuracy when compared with a commercial respiration monitoring system which requires patient contact. The proposed radar sensor provides accurate, noninvasive, and noncontact respiration measurement and therefore has a great potential in motion-adaptive radiotherapy.","Radar measurements,
Tumors,
Tuning,
Baseband,
Radio frequency,
Couplings"
General Type-2 Fuzzy C-Means Algorithm for Uncertain Fuzzy Clustering,"Pattern recognition in real-world data is subject to various sources of uncertainty that should be appropriately managed. The focus of this paper is the management of uncertainty associated with parameters of fuzzy clustering algorithms. Type-2 fuzzy sets (T2 FSs) have received increased research interest over the past decade, primarily due to their potential to model various uncertainties. However, because of the computational intensity of the processing of general T2 fuzzy sets (GT2 FSs), only their constrained version, i.e., the interval T2 (IT2) FSs, were typically used. Fortunately, the recently introduced concepts of α-planes and zSlices allow for efficient representation and computation with GT2 FSs. Following this recent development, this paper presents a novel approach for uncertain fuzzy clustering using the general type-2 fuzzy C-means (GT2 FCM) algorithm. The proposed method builds on top of the previously published IT2 FCM algorithm, which is extended via the α- planes representation theorem. The fuzzifier parameter of the FCM algorithm can be expressed using linguistic terms such as “small” or “high,” which are modeled as T1 FSs. This linguistic fuzzifier value is then used to construct the GT2 FCM cluster membership functions. The linguistic uncertainty is transformed into uncertain fuzzy positions of the extracted clusters. The GT2 FCM algorithm was found to balance the performance of T1 FCM algorithms in various uncertain pattern recognition tasks and to provide increased robustness in situations where noisy or insufficient training data are present.","Clustering algorithms,
Frequency selective surfaces,
Uncertainty,
Fuzzy logic,
Partitioning algorithms,
Fuzzy sets,
Pragmatics"
A Posture Recognition-Based Fall Detection System for Monitoring an Elderly Person in a Smart Home Environment,"We propose a novel computer vision-based fall detection system for monitoring an elderly person in a home care application. Background subtraction is applied to extract the foreground human body and the result is improved by using certain postprocessing. Information from ellipse fitting and a projection histogram along the axes of the ellipse is used as the features for distinguishing different postures of the human. These features are then fed into a directed acyclic graph support vector machine for posture classification, the result of which is then combined with derived floor information to detect a fall. From a dataset of 15 people, we show that our fall detection system can achieve a high fall detection rate (97.08%) and a very low false detection rate (0.8%) in a simulated home environment.","Feature extraction,
Senior citizens,
Histograms,
Computer vision,
Sensors,
Support vector machines"
Semantic-Gap-Oriented Active Learning for Multilabel Image Annotation,"User interaction is an effective way to handle the semantic gap problem in image annotation. To minimize user effort in the interactions, many active learning methods were proposed. These methods treat the semantic concepts individually or correlatively. However, they still neglect the key motivation of user feedback: to tackle the semantic gap. The size of the semantic gap of each concept is an important factor that affects the performance of user feedback. User should pay more efforts to the concepts with large semantic gaps, and vice versa. In this paper, we propose a semantic-gap-oriented active learning method, which incorporates the semantic gap measure into the information-minimization-based sample selection strategy. The basic learning model used in the active learning framework is an extended multilabel version of the sparse-graph-based semisupervised learning method that incorporates the semantic correlation. Extensive experiments conducted on two benchmark image data sets demonstrated the importance of bringing the semantic gap measure into the active learning process.","Semantics,
Correlation,
Image reconstruction,
Vectors,
Training,
Visualization,
Labeling"
A Sparsity-Driven Approach for Joint SAR Imaging and Phase Error Correction,"Image formation algorithms in a variety of applications have explicit or implicit dependence on a mathematical model of the observation process. Inaccuracies in the observation model may cause various degradations and artifacts in the reconstructed images. The application of interest in this paper is synthetic aperture radar (SAR) imaging, which particularly suffers from motion-induced model errors. These types of errors result in phase errors in SAR data, which cause defocusing of the reconstructed images. Particularly focusing on imaging of fields that admit a sparse representation, we propose a sparsity-driven method for joint SAR imaging and phase error correction. Phase error correction is performed during the image formation process. The problem is set up as an optimization problem in a nonquadratic regularization-based framework. The method involves an iterative algorithm, where each iteration of which consists of consecutive steps of image formation and model error correction. Experimental results show the effectiveness of the approach for various types of phase errors, as well as the improvements that it provides over existing techniques for model error compensation in SAR.","Data models,
Vectors,
Cost function,
Imaging,
Mathematical model,
History,
Image reconstruction"
Best Merge Region-Growing Segmentation With Integrated Nonadjacent Region Object Aggregation,"Best merge region growing normally produces segmentations with closed connected region objects. Recognizing that spectrally similar objects often appear in spatially separate locations, we present an approach for tightly integrating best merge region growing with nonadjacent region object aggregation, which we call hierarchical segmentation or HSeg. However, the original implementation of nonadjacent region object aggregation in HSeg required excessive computing time even for moderately sized images because of the required intercomparison of each region with all other regions. This problem was previously addressed by a recursive approximation of HSeg, called RHSeg. In this paper, we introduce a refined implementation of nonadjacent region object aggregation in HSeg that reduces the computational requirements of HSeg without resorting to the recursive approximation. In this refinement, HSeg's region intercomparisons among nonadjacent regions are limited to regions of a dynamically determined minimum size. We show that this refined version of HSeg can process moderately sized images in about the same amount of time as RHSeg incorporating the original HSeg. Nonetheless, RHSeg is still required for processing very large images due to its lower computer memory requirements and amenability to parallel processing. We then note a limitation of RHSeg with the original HSeg for high spatial resolution images and show how incorporating the refined HSeg into RHSeg overcomes this limitation. The quality of the image segmentations produced by the refined HSeg is then compared with other available best merge segmentation approaches. Finally, we comment on the unique nature of the hierarchical segmentations produced by HSeg.","Image classification,
Image segmentation,
Spatial resolution,
Image analysis,
Object detection,
Hyperspectral imaging"
Reconfiguring UWB Monopole Antenna for Cognitive Radio Applications Using GaAs FET Switches,"A novel ultrawideband (UWB) microstrip monopole antenna with reconfigurable multiband function is presented. Reconfigurability is achieved by using GaAs field effect transistor (FET) switches to connect multiple stubs of different lengths to the main feed line of the monopole. The antenna is compact and flexible in terms of the availability of different reconfiguration bands and, most importantly, the simple biasing of the GaAs FET switches will not have a severe effect on the antenna performance. Using GaAs FET switches did not degrade the antenna radiation patterns due to the simple biasing technique and the few external biasing components needed, besides these switches did not degrade the antenna gain and efficiency due to their low insertion loss and low on resistance. When the antenna was reconfigured from UWB to work into multiple frequency bands, the total peak gain improved by 20% compared to the UWB case. In addition, the total efficiency of the antenna has not been significantly reduced in any reconfigured band, whereas the out-of-band total efficiency is hugely reduced, which highlights the filtering role of the reconfiguration process. The total dc power consumption of the antenna switches is still very low (<; 33 μW), and this will lead to simple integration of the antenna in some portable communication systems or future cognitive radio front ends.",
Trajectory Planning and Second-Order Sliding Mode Motion/Interaction Control for Robot Manipulators in Unknown Environments,"The problem of determining an interaction control strategy, allowing a manipulator to reach a goal point even in the presence of unknown obstacles, is faced in this paper. To this end, on the basis of position/orientation and force measurements, first, a path planning strategy is proposed. The path planning is based on an a priori trajectory, which is determined without the prior knowledge of the obstacle presence in the workspace, and on a real-time approach to generate auxiliary temporary trajectories on the basis of the properties of the obstacle surface in a vicinity of the contact point, estimated through force measurements. To determine the input laws of the manipulator, a robust hybrid position/force control scheme is adopted. First- and second-order sliding mode controllers are considered to generate the robot input laws, and the obtained performances are experimentally compared with those of classical PD control. Experiments are made on a COMAU SMART3-S2 anthropomorphic industrial manipulator.","Trajectory,
Force,
Manipulators,
Sensors,
Force measurement,
Force control"
"Modeling, Identification, and Control of Tendon-Based Actuation Systems","In this paper, we deal with several aspects related to the control of tendon-based actuation systems for robotic devices. In particular, the problems that are considered in this paper are related to the modeling, identification, and control of tendons sliding on curved pathways, subject to friction and viscoelastic effects. Tendons made in polymeric materials are considered, and therefore, hysteresis in the transmission system characteristic must be taken into account as an additional nonlinear effect because of the plasticity and creep phenomena typical of these materials. With the aim of reproducing these behaviors, a viscoelastic model is used to model the tendon compliance. Particular attention has been given to the friction effects arising from the interaction between the tendon pathway and the tendon itself. This phenomenon has been characterized by means of a LuGre-like dynamic friction model to consider the effects that cannot be reproduced by employing a static friction model. A specific setup able to measure the tendon's tension in different points along its path has been designed in order to verify the tension distribution and identify the proper parameters. Finally, a simple control strategy for the compensation of these nonlinear effects and the control of the force that is applied by the tendon to the load is proposed and experimentally verified.","Tendons,
Friction,
Force,
Robots,
Materials,
Joints,
Routing"
Probabilistic Exposure Fusion,"The luminance of a natural scene is often of high dynamic range (HDR). In this paper, we propose a new scheme to handle HDR scenes by integrating locally adaptive scene detail capture and suppressing gradient reversals introduced by the local adaptation. The proposed scheme is novel for capturing an HDR scene by using a standard dynamic range (SDR) device and synthesizing an image suitable for SDR displays. In particular, we use an SDR capture device to record scene details (i.e., the visible contrasts and the scene gradients) in a series of SDR images with different exposure levels. Each SDR image responds to a fraction of the HDR and partially records scene details. With the captured SDR image series, we first calculate the image luminance levels, which maximize the visible contrasts, and then the scene gradients embedded in these images. Next, we synthesize an SDR image by using a probabilistic model that preserves the calculated image luminance levels and suppresses reversals in the image luminance gradients. The synthesized SDR image contains much more scene details than any of the captured SDR image. Moreover, the proposed scheme also functions as the tone mapping of an HDR image to the SDR image, and it is superior to both global and local tone mapping operators. This is because global operators fail to preserve visual details when the contrast ratio of a scene is large, whereas local operators often produce halos in the synthesized SDR image. The proposed scheme does not require any human interaction or parameter tuning for different scenes. Subjective evaluations have shown that it is preferred over a number of existing approaches.","Pixel,
Probabilistic logic,
Dynamic range,
Heuristic algorithms,
Image generation,
Visualization,
Humans"
"In Cloud, Can Scientific Communities Benefit from the Economies of Scale?","The basic idea behind cloud computing is that resource providers offer elastic resources to end users. In this paper, we intend to answer one key question to the success of cloud computing: in cloud, can small-to-medium scale scientific communities benefit from the economies of scale? Our research contributions are threefold: first, we propose an innovative public cloud usage model for small-to-medium scale scientific communities to utilize elastic resources on a public cloud site while maintaining their flexible system controls, i.e., create, activate, suspend, resume, deactivate, and destroy their high-level management entities-service management layers without knowing the details of management. Second, we design and implement an innovative system-DawningCloud, at the core of which are lightweight service management layers running on top of a common management service framework. The common management service framework of DawningCloud not only facilitates building lightweight service management layers for heterogeneous workloads, but also makes their management tasks simple. Third, we evaluate the systems comprehensively using both emulation and real experiments. We found that for four traces of two typical scientific workloads: High-Throughput Computing (HTC) and Many-Task Computing (MTC), DawningCloud saves the resource consumption maximally by 59.5 and 72.6 percent for HTC and MTC service providers, respectively, and saves the total resource consumption maximally by 54 percent for the resource provider with respect to the previous two public cloud solutions. To this end, we conclude that small-to-medium scale scientific communities indeed can benefit from the economies of scale of public clouds with the support of the enabling system.","Cloud computing,
Dynamic scheduling,
Investments,
Economies of scale,
Resource management"
Experimental Characterization and Numerical Modeling of Tissue Electrical Conductivity during Pulsed Electric Fields for Irreversible Electroporation Treatment Planning,"Irreversible electroporation is a new technique to kill cells in targeted tissue, such as tumors, through a nonthermal mechanism using electric pulses to irrecoverably disrupt the cell membrane. Treatment effects relate to the tissue electric field distribution, which can be predicted with numerical modeling for therapy planning. Pulse effects will change the cell and tissue properties through thermal and electroporation (EP)-based processes. This investigation characterizes these changes by measuring the electrical conductivity and temperature of ex vivo renal porcine tissue within a single pulse and for a 200 pulse protocol. These changes are incorporated into an equivalent circuit model for cells and tissue with a variable EP-based resistance, providing a potential method to estimate conductivity as a function of electric field and pulse length for other tissues. Finally, a numerical model using a human kidney volumetric mesh evaluated how treatment predictions vary when EP- and temperature-based electrical conductivity changes are incorporated. We conclude that significant changes in predicted outcomes will occur when the experimental results are applied to the numerical model, where the direction and degree of change varies with the electric field considered.","Conductivity,
Electric fields,
Numerical models,
Immune system,
Mathematical model,
Tumors,
Kidney"
Color Local Texture Features for Color Face Recognition,"This paper proposes new color local texture features, i.e., color local Gabor wavelets (CLGWs) and color local binary pattern (CLBP), for the purpose of face recognition (FR). The proposed color local texture features are able to exploit the discriminative information derived from spatiochromatic texture patterns of different spectral channels within a certain local face region. Furthermore, in order to maximize a complementary effect taken by using both color and texture information, the opponent color texture features that capture the texture patterns of spatial interactions between spectral channels are also incorporated into the generation of CLGW and CLBP. In addition, to perform the final classification, multiple color local texture features (each corresponding to the associated color band) are combined within a feature-level fusion framework. Extensive and comparative experiments have been conducted to evaluate our color local texture features for FR on five public face databases, i.e., CMU-PIE, Color FERET, XM2VTSDB, SCface, and FRGC 2.0. Experimental results show that FR approaches using color local texture features impressively yield better recognition rates than FR approaches using only color or texture information. Particularly, compared with grayscale texture features, the proposed color local texture features are able to provide excellent recognition rates for face images taken under severe variation in illumination, as well as for small- (low-) resolution face images. In addition, the feasibility of our color local texture features has been successfully demonstrated by making comparisons with other state-of-the-art color FR methods.","Image color analysis,
Feature extraction,
Face,
Gray-scale,
Face recognition,
Color,
Gabor filters"
A Wideband Frequency Tunable Optoelectronic Oscillator Incorporating a Tunable Microwave Photonic Filter Based on Phase-Modulation to Intensity-Modulation Conversion Using a Phase-Shifted Fiber Bragg Grating,"An optically tunable optoelectronic oscillator (OEO) with a wide frequency tunable range incorporating a tunable microwave photonic filter implemented based on phase-modulation to intensity-modulation conversion using a phase-shifted fiber Bragg grating (PS-FBG) is proposed and experimentally demonstrated. The PS-FBG in conjunction with two optical phase modulators in the OEO loop form a high-Q, wideband and frequency-tunable microwave photonic bandpass filter, to achieve simultaneously single-frequency selection and frequency tuning. Since the tuning of the microwave filter is achieved by tuning the wavelength of the incident light wave, the tunability can be easily realized at a high speed. A theoretical analysis is performed, which is verified by an experiment. A microwave signal with a frequency tunable from 3 GHz to 28 GHz is generated. To the best of our knowledge, this is the widest frequency tunable range ever achieved by an OEO. The phase noise performance of the OEO is also investigated.","Microwave photonics,
Band pass filters,
Microwave oscillators,
Tuning,
Bandwidth"
SLAW: Self-Similar Least-Action Human Walk,Many empirical studies of human walks have reported that there exist fundamental statistical features commonly appearing in mobility traces taken in various mobility settings. These include: 1) heavy-tail flight and pause-time distributions; 2) heterogeneously bounded mobility areas of individuals; and 3) truncated power-law intercontact times. This paper reports two additional such features: a) The destinations of people (or we say waypoints) are dispersed in a self-similar manner; and b) people are more likely to choose a destination closer to its current waypoint. These features are known to be influential to the performance of human-assisted mobility networks. The main contribution of this paper is to present a mobility model called Self-similar Least-Action Walk (SLAW) that can produce synthetic mobility traces containing all the five statistical features in various mobility settings including user-created virtual ones for which no empirical information is available. Creating synthetic traces for virtual environments is important for the performance evaluation of mobile networks as network designers test their networks in many diverse network settings. A performance study of mobile routing protocols on top of synthetic traces created by SLAW shows that SLAW brings out the unique performance features of various routing protocols.,"Humans,
Mobile communication,
Mobile computing,
Protocols,
Global Positioning System,
Performance evaluation,
Routing"
Fast search in Hamming space with multi-index hashing,"There has been growing interest in mapping image data onto compact binary codes for fast near neighbor search in vision applications. Although binary codes are motivated by their use as direct indices (addresses) into a hash table, codes longer than 32 bits are not being used in this way, as it was thought to be ineffective. We introduce a rigorous way to build multiple hash tables on binary code substrings that enables exact K-nearest neighbor search in Hamming space. The algorithm is straightforward to implement, storage efficient, and it has sub-linear run-time behavior for uniformly distributed codes. Empirical results show dramatic speed-ups over a linear scan baseline and for datasets with up to one billion items, 64- or 128-bit codes, and search radii up to 25 bits.","Binary codes,
Databases,
Complexity theory,
Hamming distance,
Search problems,
Upper bound,
Memory management"
An Ant Colony Optimization Approach for Maximizing the Lifetime of Heterogeneous Wireless Sensor Networks,"Maximizing the lifetime of wireless sensor networks (WSNs) is a challenging problem. Although some methods exist to address the problem in homogeneous WSNs, research on this problem in heterogeneous WSNs have progressed at a slow pace. Inspired by the promising performance of ant colony optimization (ACO) to solve combinatorial problems, this paper proposes an ACO-based approach that can maximize the lifetime of heterogeneous WSNs. The methodology is based on finding the maximum number of disjoint connected covers that satisfy both sensing coverage and network connectivity. A construction graph is designed with each vertex denoting the assignment of a device in a subset. Based on pheromone and heuristic information, the ants seek an optimal path on the construction graph to maximize the number of connected covers. The pheromone serves as a metaphor for the search experiences in building connected covers. The heuristic information is used to reflect the desirability of device assignments. A local search procedure is designed to further improve the search efficiency. The proposed approach has been applied to a variety of heterogeneous WSNs. The results show that the approach is effective and efficient in finding high-quality solutions for maximizing the lifetime of heterogeneous WSNs.","Sensors,
Wireless sensor networks,
Silicon,
Upper bound,
Monitoring,
Routing,
Ant colony optimization"
"Study on the Impact of Partition-Induced Dataset Shift on
k
-Fold Cross-Validation","Cross-validation is a very commonly employed technique used to evaluate classifier performance. However, it can potentially introduce dataset shift, a harmful factor that is often not taken into account and can result in inaccurate performance estimation. This paper analyzes the prevalence and impact of partition-induced covariate shift on different k-fold cross-validation schemes. From the experimental results obtained, we conclude that the degree of partition-induced covariate shift depends on the cross-validation scheme considered. In this way, worse schemes may harm the correctness of a single-classifier performance estimation and also increase the needed number of repetitions of cross-validation to reach a stable performance estimation.","Reliability,
Partitioning algorithms,
Classification algorithms,
Accuracy,
Testing,
Algorithm design and analysis"
Enhancing Collaborative Filtering by User Interest Expansion via Personalized Ranking,"Recommender systems suggest a few items from many possible choices to the users by understanding their past behaviors. In these systems, the user behaviors are influenced by the hidden interests of the users. Learning to leverage the information about user interests is often critical for making better recommendations. However, existing collaborative-filtering-based recommender systems are usually focused on exploiting the information about the user's interaction with the systems; the information about latent user interests is largely underexplored. To that end, inspired by the topic models, in this paper, we propose a novel collaborative-filtering-based recommender system by user interest expansion via personalized ranking, named iExpand. The goal is to build an item-oriented model-based collaborative-filtering framework. The iExpand method introduces a three-layer, user-interests-item, representation scheme, which leads to more accurate ranking recommendation results with less computation cost and helps the understanding of the interactions among users, items, and user interests. Moreover, iExpand strategically deals with many issues that exist in traditional collaborative-filtering approaches, such as the overspecialization problem and the cold-start problem. Finally, we evaluate iExpand on three benchmark data sets, and experimental results show that iExpand can lead to better ranking performance than state-of-the-art methods with a significant margin.",
Object Tracking via Partial Least Squares Analysis,"We propose an object tracking algorithm that learns a set of appearance models for adaptive discriminative object representation. In this paper, object tracking is posed as a binary classification problem in which the correlation of object appearance and class labels from foreground and background is modeled by partial least squares (PLS) analysis, for generating a low-dimensional discriminative feature subspace. As object appearance is temporally correlated and likely to repeat over time, we learn and adapt multiple appearance models with PLS analysis for robust tracking. The proposed algorithm exploits both the ground truth appearance information of the target labeled in the first frame and the image observations obtained online, thereby alleviating the tracking drift problem caused by model update. Experiments on numerous challenging sequences and comparisons to state-of-the-art methods demonstrate favorable performance of the proposed tracking algorithm.","Adaptation models,
Target tracking,
Vectors,
Analytical models,
Computational modeling,
Algorithm design and analysis"
Spatially coupled ensembles universally achieve capacity under belief propagation,"We investigate spatially coupled code ensembles. For transmission over the binary erasure channel, it was recently shown that spatial coupling increases the belief propagation threshold of the ensemble to essentially the maximum a-priori threshold of the underlying component ensemble. This explains why convolutional LDPC ensembles, originally introduced by Felström and Zigangirov, perform so well over this channel. We show that the equivalent result holds true for transmission over general binary-input memoryless output-symmetric channels. More precisely, given a desired error probability and a gap to capacity, we can construct a spatially coupled ensemble which fulfills these constraints universally on this class of channels under belief propagation decoding. In fact, most codes in that ensemble have that property. The quantifier universal refers to the single ensemble/code which is good for all channels if we assume that the channel is known at the receiver. The key technical result is a proof that under belief propagation decoding spatially coupled ensembles achieve essentially the area threshold of the underlying uncoupled ensemble. We conclude by discussing some interesting open problems.","Parity check codes,
Decoding,
Entropy,
Couplings,
Convolutional codes,
Belief propagation,
Encoding"
A Negative Imaginary Approach to Modeling and Control of a Collocated Structure,"A transfer-function is said to be negative imaginary if the corresponding frequency response function has a negative definite imaginary part (on the positively increasing imaginary axis). Negative imaginary transfer-functions can be stabilized using negative imaginary feedback controllers. Flexible structures with compatible collocated sensor/actuator pairs have transfer-functions that are negative imaginary. In this paper a model structure that typically represents a collocated structure is considered. An identification algorithm which enforces the negative imaginary constraint is proposed for estimating the model parameters. A feedback control technique, known as integral resonant control (IRC), is proposed for damping vibrations in collocated flexible structures. Conditions for the stability of the proposed controller are derived, and shown that the set of stabilizing IRCs is convex. Finally, a flexible beam with two pairs of collocated piezoelectric actuators/sensors is considered. The proposed identification scheme is used determining the transfer-function and an IRC is designed for damping the vibrations. The experimental results obtained are reported.","Actuators,
Stability analysis,
Laser beams,
MIMO,
Transfer functions,
Measurement by laser beam,
Damping"
Fast Vanishing-Point Detection in Unstructured Environments,"Vision-based road detection in unstructured environments is a challenging problem as there are hardly any discernible and invariant features that can characterize the road or its boundaries in such environments. However, a salient and consistent feature of most roads or tracks regardless of type of the environments is that their edges, boundaries, and even ruts and tire tracks left by previous vehicles on the path appear to converge into a single point known as the vanishing point. Hence, estimating this vanishing point plays a pivotal role in the determination of the direction of the road. In this paper, we propose a novel methodology based on image texture analysis for the fast estimation of the vanishing point in challenging and unstructured roads. The key attributes of the methodology consist of the optimal local dominant orientation method that uses joint activities of only four Gabor filters to precisely estimate the local dominant orientation at each pixel location in the image plane, the weighting of each pixel based on its dominant orientation, and an adaptive distance-based voting scheme for the estimation of the vanishing point. A series of quantitative and qualitative analyses are presented using natural data sets from the Defense Advanced Research Projects Agency Grand Challenge projects to demonstrate the effectiveness and the accuracy of the proposed methodology.",
Coalitional Games in Partition Form for Joint Spectrum Sensing and Access in Cognitive Radio Networks,"Unlicensed secondary users (SUs) in cognitive radio networks are subject to an inherent tradeoff between spectrum sensing and spectrum access. Although each SU has an incentive to sense the primary user (PU) channels for locating spectrum holes, this exploration of the spectrum can come at the expense of a shorter transmission time, and, hence, a possibly smaller capacity for data transmission. This paper investigates the impact of this tradeoff on the cooperative strategies of a network of SUs that seek to cooperate in order to improve their view of the spectrum (sensing), reduce the possibility of interference among each other, and improve their transmission capacity (access). The problem is modeled as a coalitional game in partition form and an algorithm for coalition formation is proposed. Using the proposed algorithm, the SUs can make individual distributed decisions to join or leave a coalition while maximizing their utilities which capture the average time spent for sensing as well as the capacity achieved while accessing the spectrum. It is shown that, by using the proposed algorithm, the SUs can self-organize into a network partition composed of disjoint coalitions, with the members of each coalition cooperating to jointly optimize their sensing and access performance. Simulation results show the performance improvement that the proposed algorithm yields with respect to the noncooperative case. The results also show how the algorithm allows the SUs to self-adapt to changes in the environment such as changes in the traffic of the PUs, or slow mobility.",
Second-Order Cyclostationarity of Mobile WiMAX and LTE OFDM Signals and Application to Spectrum Awareness in Cognitive Radio Systems,"Spectrum sensing and awareness are challenging requirements in cognitive radio (CR). To adequately adapt to the changing radio environment, it is necessary for the CR to detect the presence and classify the on-the-air signals. The wireless industry has shown great interest in orthogonal frequency division multiplexing (OFDM) technology. Hence, classification of OFDM signals has been intensively researched recently. Generic signals have been mainly considered, and there is a need to investigate OFDM standard signals, and their specific discriminating features for classification. In this paper, realistic and comprehensive mathematical models of the OFDM-based mobile Worldwide Interoperability for Microwave Access (WiMAX) and third-Generation Partnership Project Long Term Evolution (3GPP LTE) signals are developed, and their second-order cyclostationarity is studied. Closed-from expressions for the cyclic autocorrelation function (CAF) and cycle frequencies (CFs) of both signal types are derived, based on which an algorithm is proposed for their classification. The proposed algorithm does not require carrier, waveform, and symbol timing recovery, and is immune to phase, frequency, and timing offsets. The classification performance of the algorithm is investigated versus signal-to-noise ratio (SNR), for diverse observation intervals and channel conditions. In addition, the computational complexity is explored versus the signal type. Simulation results show the efficiency of the algorithm is terms of classification performance, and the complexity study proves the real time applicability of the algorithm.","OFDM,
WiMAX,
Classification algorithms,
Mobile communication,
Timing,
Algorithm design and analysis,
Signal to noise ratio"
Probabilistic Analysis of Small-Signal Stability of Large-Scale Power Systems as Affected by Penetration of Wind Generation,"This paper proposes a method of probabilistic analysis to investigate the impact of stochastic uncertainty of grid-connected wind generation on power system small-signal stability. The proposed method is “analytical” in contrast to the numerical method of Monte Carlo simulation which relies on large number of random computations. It can directly calculate the probabilistic density function (PDF) of critical eigenvalues of a large-scale power system from the PDF of grid-connected multiple sources of wind power generation, thus to determine the probabilistic small-signal stability of the power system as affected by the wind generation. In the paper, an example of 16-machine power system with three grid-connected wind farms is used to demonstrate the application of the proposed method. The results of probabilistic stability analysis of the example power system are confirmed by the Monte Carlo simulation. It is shown that the stochastic variation of grid-connected wind generation can cause the system to lose stability even though the system is stable deterministically. The higher the level of wind penetration is, the more the probability that the system becomes unstable could be. Hence indeed penetration of stochastically variable wind generation threatens stable operation of power systems as far as system small-signal stability is concerned.",
Big Data Processing in Cloud Computing Environments,"With the rapid growth of emerging applications like social network analysis, semantic Web analysis and bioinformatics network analysis, a variety of data to be processed continues to witness a quick increase. Effective management and analysis of large-scale data poses an interesting but critical challenge. Recently, big data has attracted a lot of attention from academia, industry as well as government. This paper introduces several big data processing technics from system and application aspects. First, from the view of cloud data management and big data processing mechanisms, we present the key issues of big data processing, including cloud computing platform, cloud architecture, cloud database and data storage scheme. Following the Map Reduce parallel processing framework, we then introduce Map Reduce optimization strategies and applications reported in the literature. Finally, we discuss the open issues and challenges, and deeply explore the research directions in the future on big data processing in cloud computing environments.","Information management,
Data handling,
Data storage systems,
Cloud computing,
Computer architecture,
Data models,
Distributed databases"
Projection X-Space Magnetic Particle Imaging,"Projection magnetic particle imaging (MPI) can improve imaging speed by over 100-fold over traditional 3-D MPI. In this work, we derive the 2-D x-space signal equation, 2-D image equation, and introduce the concept of signal fading and resolution loss for a projection MPI imager. We then describe the design and construction of an x-space projection MPI scanner with a field gradient of 2.35 T/m across a 10 cm magnet free bore. The system has an expected resolution of 3.5 × 8.0 mm using Resovist tracer, and an experimental resolution of 3.8 × 8.4 mm resolution. The system images 2.5 cm × 5.0 cm partial field-of views (FOVs) at 10 frames/s, and acquires a full field-of-view of 10 cm × 5.0 cm in 4 s. We conclude by imaging a resolution phantom, a complex “Cal” phantom, mice injected with Resovist tracer, and experimentally confirm the theoretically predicted x-space spatial resolution.","Magnetic resonance imaging,
Fading,
Image resolution,
Saturation magnetization,
Image reconstruction,
Magnetic noise"
Using Propositional Logic for Requirements Verification of Service Workflow,"This paper presents a requirement-oriented automated framework for formal verification of service workflows. It is based on our previous work describing the requirement-oriented service workflow specification language called SWSpec. This language has been developed to facilitate workflow composer as well as arbitrary services willing to participate in a workflow to formally and uniformly impose their own requirements. As such, SWSpec provides a formal way to regulate and control workflows. The key component of the to-be-proposed framework centers on verification algorithms that rely on propositional logic. We demonstrate that logic-based workflow verification can be applied to SWSpec which is capable of checking compliance and also detecting conflicts of the imposed requirements. By automating compliance checking process, this framework will support scalable services interoperation in the form of workflows in opened environments.","Labeling,
Specification languages,
Industries,
Heuristic algorithms,
Algorithm design and analysis,
Cognition,
Context"
A Novel Immune Clonal Algorithm for MO Problems,"Research on multiobjective optimization (MO) becomes one of the hot points of intelligent computation. Compared with evolutionary algorithm, the artificial immune system used for solving MO problems (MOPs) has shown many good performances in improving the convergence speed and maintaining the diversity of the antibody population. However, the simple clonal selection computation has some difficulties in handling some more complex MOPs. In this paper, the simple clonal selection strategy is improved and a novel immune clonal algorithm (NICA) is proposed. The improvements in NICA are mainly focus on four aspects. 1) Antibodies in the antibody population are divided into dominated ones and nondominated ones, which is suitable for the characteristic of one multiobjective optimization problem has a series Pareto-optimal solutions. 2) The entire cloning is adopted instead of different antibodies having different clonal rate. 3) The clonal selection is based on the Pareto-dominance and one antibody is selected or not depending on whether it is a nondominated one, which is different from the traditional clonal selection manner. 4) The antibody population updating operation after the clonal selection is adopted, which makes antibody population under a certain size and guarantees the convergence of the algorithm. The influences of the main parameters are analyzed empirically. Compared with the existed algorithms, simulation results on MOPs and constrained MOPs show that NICA in most problems is able to And much better spread of solutions and better convergence near the true Pareto-optimal front.","Immune system,
Vectors,
Cloning,
Optimization,
Measurement,
Convergence,
Heuristic algorithms"
Robust CoHOG Feature Extraction in Human-Centered Image/Video Management System,"Many human-centered image and video management systems depend on robust human detection. To extract robust features for human detection, this paper investigates the following shortcomings of co-occurrence histograms of oriented gradients (CoHOGs) which significantly limit its advantages: (1) The magnitudes of the gradients are discarded, and only the orientations are used; (2) the gradients are not smoothed, and thus, aliasing effect exists; and (3) the dimensionality of the CoHOG feature vector is very large (e.g., 200 000). To deal with these problems, in this paper, we propose a framework that performs the following: (1) utilizes a novel gradient decomposition and combination strategy to make full use of the information of gradients; (2) adopts a two-stage gradient smoothing scheme to perform efficient gradient interpolation; and (3) employs incremental principal component analysis to reduce the large dimensionality of the CoHOG features. Experimental results on the two different human databases demonstrate the effectiveness of the proposed method.","Feature extraction,
Humans,
Histograms,
Interpolation,
Vectors,
Robustness,
Convolution"
Easy-to-Swallow Wireless Telemetry,"Many countries will experience the effects of an aging population, resulting in a high demand of healthcare facilities. Development of novel biomedical technologies is an urgent necessity to improve diagnostic services for this demographic. Electrocar diogram (ECG) and temperature recording have been used for more than 50 years in medical diagnosis to understand various biological activities [1], [2]. A more recent development, electronic pill technology, requires the integration of more complex systems on the same platform when compared to conventional implantable systems. A small miniaturized electronic pill can reach areas such as the small intestine and can deliver real time video images wirelessly to an external console. Figure 1 shows an electronic pill system (i.e., wireless endoscopy) for a medical monitoring system. The device travels through the digestive system to collect image data and transfers the data to a nearby computer for display with a distance of one meter or more. A high resolution videobased capsule endoscope produces a large amount of data, which can then be delivered over a high-capacity wireless link.","Telemetry,
Wireless communication,
Aging,
Sociology,
Medical services,
Statistics"
Aggregate Interference Modeling in Cognitive Radio Networks with Power and Contention Control,"In this paper, we present interference models for cognitive radio (CR) networks employing various interference management mechanisms including power control, contention control or hybrid power/contention control schemes. For the first case, a power control scheme is proposed to govern the transmission power of a CR node. For the second one, a contention control scheme at the media access control (MAC) layer, based on carrier sense multiple access with collision avoidance (CSMA/CA), is proposed to coordinate the operation of CR nodes with transmission requests. The probability density functions (PDFs) of the interference received at a primary receiver from a CR network are first derived numerically for these two cases. For the hybrid case, where power and contention controls are jointly adopted by a CR node to govern its transmission, the interference is analyzed and compared with that of the first two schemes by simulations. Then, the interference PDFs under the first two control schemes are fitted by log-normal PDFs to reduce computation complexity. Moreover, the effect of a hidden primary receiver on the interference experienced at the receiver is investigated. It is demonstrated that both power and contention controls are effective approaches to alleviate the interference caused by CR networks. Some in-depth analysis of the impact of key parameters on the interference of CR networks is given as well.","Interference,
Power control,
Aggregates,
Receivers,
Approximation methods,
Radio transmitters"
Linear Precoding for Finite-Alphabet Signaling Over MIMOME Wiretap Channels,"In this paper, we investigate the secrecy rate of finite-alphabet communications over multiple-input-multiple-output-multiple-antenna eavesdropper (MIMOME) channels. Traditional precoding designs based on Gaussian input assumption may lead to substantial secrecy rate loss when the Gaussian input is replaced by practical finite-alphabet input. To address this issue, we investigate linear precoding designs to directly maximize the secrecy rate for MIMOME systems under the constraint of finite-alphabet input. By exploiting the theory of Karush-Kuhn-Tucker (KKT) analysis and matrix calculus, we first present necessary conditions of the optimal precoding design when instantaneous channel-state information (CSI) of the eavesdropper is known at the transmitter. In this light, an iterative algorithm for finding the optimal precoding matrix is developed, utilizing a gradient decent method with backtracking line search. Moreover, we find that the beamforming design in MIMONE systems, which is a secrecy-capacity-achieving approach for Gaussian signaling, no longer provides the maximum secrecy rate for finite-alphabet input data. This case is substantially different from the Gaussian input case. In addition, we derive the closed-form results on the precoding matrix, which maximizes the secrecy rate in the low signal-to-noise ratio (SNR) region, and reveal the optimal precoding structure in the high-SNR region. A novel jamming signal generation method that draws on the CSI of the eavesdropper to additionally increase the secrecy rate is further proposed. The precoding design with only statistical CSI of the eavesdropper available at the transmitter is also considered. Numerical results show that the proposed designs provide significant gains over recent precoding designs through a power control policy and the precoding design with the Gaussian input assumption in various scenarios.",
Vehicular Cloud Computing,"Mobile Cloud Computing is a new field of research that aims to study mobile agents (people, vehicles, robots) as they interact and collaborate to sense the environment, process the data, propagate the results and more generally share resources. Mobile agents collectively operate as Mobile Clouds that enable environment modeling, content discovery, data collection and dissemination and other mobile applications in a way not possible, or not efficient, with conventional Internet Cloud models and mobile computing approaches. In this paper, we discuss design principles and research issues in mobile cloud computing. We then focus on the Mobile Vehicular Cloud and review cloud applications ranging from urban sensing to intelligent transportation.",
Reinforcement Learning Controller Design for Affine Nonlinear Discrete-Time Systems using Online Approximators,"In this paper, reinforcement learning state- and output-feedback-based adaptive critic controller designs are proposed by using the online approximators (OLAs) for a general multi-input and multioutput affine unknown nonlinear discretetime systems in the presence of bounded disturbances. The proposed controller design has two entities, an action network that is designed to produce optimal signal and a critic network that evaluates the performance of the action network. The critic estimates the cost-to-go function which is tuned online using recursive equations derived from heuristic dynamic programming. Here, neural networks (NNs) are used both for the action and critic whereas any OLAs, such as radial basis functions, splines, fuzzy logic, etc., can be utilized. For the output-feedback counterpart, an additional NN is designated as the observer to estimate the unavailable system states, and thus, separation principle is not required. The NN weight tuning laws for the controller schemes are also derived while ensuring uniform ultimate boundedness of the closed-loop system using Lyapunov theory. Finally, the effectiveness of the two controllers is tested in simulation on a pendulum balancing system and a two-link robotic arm system.",
Novel Adaptive Gravitational Search Algorithm for Fuzzy Controlled Servo Systems,This paper presents a novel adaptive Gravitational Search Algorithm (GSA) for the optimal tuning of fuzzy controlled servo systems characterized by second-order models with an integral component and variable parameters. The objective functions consist of the output sensitivity functions of the sensitivity models defined with respect to the parametric variations of the processes. The proposed adaptive GSA solves the optimization problems resulting in a new generation of Takagi-Sugeno proportional-integral fuzzy controllers (T-S PI-FCs) with a reduced time constant sensitivity. A design method for T-S PI-FCs is then proposed and experimentally validated in the representative case study of the optimal tuning of T-S PI-FCs for the position control system of a servo system.,"Process control,
Fuzzy control,
Servosystems,
Servomotors,
Adaptation models"
A Broadband LTE/WWAN Antenna Design for Tablet PC,"A broadband yet compact antenna design applicable to tablets and laptops is proposed. The antenna provides an extensive coverage for existing and upcoming mobile communication bands. Several band broadening and antenna miniaturization techniques were employed, including the use of a parasitic element, meandered structures, branched structures and a lump component. The proposed design is planar, compact and can be fabricated via printed circuit board technology. Measurement results exhibits broad resonant bandwidth. Nearly omni-directional patterns and reasonable radiation efficiency are observed.","Bandwidth,
Broadband antennas,
Reflection,
Current distribution,
Inductors,
Antenna measurements"
Gait Recognition Under Various Viewing Angles Based on Correlated Motion Regression,"It is well recognized that gait is an important biometric feature to identify a person at a distance, e.g., in video surveillance application. However, in reality, change of viewing angle causes significant challenge for gait recognition. A novel approach using regression-based view transformation model (VTM) is proposed to address this challenge. Gait features from across views can be normalized into a common view using learned VTM(s). In principle, a VTM is used to transform gait feature from one viewing angle (source) into another viewing angle (target). It consists of multiple regression processes to explore correlated walking motions, which are encoded in gait features, between source and target views. In the learning processes, sparse regression based on the elastic net is adopted as the regression function, which is free from the problem of overfitting and results in more stable regression models for VTM construction. Based on widely adopted gait database, experimental results show that the proposed method significantly improves upon existing VTM-based methods and outperforms most other baseline methods reported in the literature. Several practical scenarios of applying the proposed method for gait recognition under various views are also discussed in this paper.",
Synchronization of Coupled Oscillators is a Game,"The purpose of this paper is to understand phase transition in noncooperative dynamic games with a large number of agents. Applications are found in neuroscience, biology, and economics, as well as traditional engineering applications. The focus of analysis is a variation of the large population linear quadratic Gaussian (LQG) model of Huang et al. 2007, comprised here of a controlled N-dimensional stochastic differential equation model, coupled only through a cost function. The states are interpreted as phase angles for a collection of heterogeneous oscillators, and in this way the model may be regarded as an extension of the classical coupled oscillator model of Kuramoto. A deterministic PDE model is proposed, which is shown to approximate the stochastic system as the population size approaches infinity. Key to the analysis of the PDE model is the existence of a particular Nash equilibrium in which the agents ""opt out' of the game, setting their controls to zero, resulting in the ""incoherence' equilibrium. Methods from dynamical systems theory are used in a bifurcation analysis, based on a linearization of the partial differential equation (PDE) model about the incoherence equilibrium. A critical value of the control cost parameter is identified: above this value, the oscillators are incoherent; and below this value (when control is sufficiently cheap) the oscillators synchronize. These conclusions are illustrated with results from numerical experiments.","Oscillators,
Mathematical model,
Games,
Markov processes,
Approximation methods,
Cost function,
Equations"
Underwater Data Collection Using Robotic Sensor Networks,"We examine the problem of utilizing an autonomous underwater vehicle (AUV) to collect data from an underwater sensor network. The sensors in the network are equipped with acoustic modems that provide noisy, range-limited communication. The AUV must plan a path that maximizes the information collected while minimizing travel time or fuel expenditure. We propose AUV path planning methods that extend algorithms for variants of the Traveling Salesperson Problem (TSP). While executing a path, the AUV can improve performance by communicating with multiple nodes in the network at once. Such multi-node communication requires a scheduling protocol that is robust to channel variations and interference. To this end, we examine two multiple access protocols for the underwater data collection scenario, one based on deterministic access and another based on random access. We compare the proposed algorithms to baseline strategies through simulated experiments that utilize models derived from experimental test data. Our results demonstrate that properly designed communication models and scheduling protocols are essential for choosing the appropriate path planning algorithms for data collection.",
Robust Reversible Watermarking via Clustering and Enhanced Pixel-Wise Masking,"Robust reversible watermarking (RRW) methods are popular in multimedia for protecting copyright, while preserving intactness of host images and providing robustness against unintentional attacks. However, conventional RRW methods are not readily applicable in practice. That is mainly because: 1) they fail to offer satisfactory reversibility on large-scale image datasets; 2) they have limited robustness in extracting watermarks from the watermarked images destroyed by different unintentional attacks; and 3) some of them suffer from extremely poor invisibility for watermarked images. Therefore, it is necessary to have a framework to address these three problems, and further improve its performance. This paper presents a novel pragmatic framework, wavelet-domain statistical quantity histogram shifting and clustering (WSQH-SC). Compared with conventional methods, WSQH-SC ingeniously constructs new watermark embedding and extraction procedures by histogram shifting and clustering, which are important for improving robustness and reducing run-time complexity. Additionally, WSQH-SC includes the property-inspired pixel adjustment to effectively handle overflow and underflow of pixels. This results in satisfactory reversibility and invisibility. Furthermore, to increase its practical applicability, WSQH-SC designs an enhanced pixel-wise masking to balance robustness and invisibility. We perform extensive experiments over natural, medical, and synthetic aperture radar images to show the effectiveness of WSQH-SC by comparing with the histogram rotation-based and histogram distribution constrained methods.","Watermarking,
Wavelet coefficients,
Robustness,
Histograms,
Sensitivity,
Brightness"
A learned feature descriptor for object recognition in RGB-D data,"In this work we address the problem of feature extraction for object recognition in the context of cameras providing RGB and depth information (RGB-D data). We consider this problem in a bag of features like setting and propose a new, learned, local feature descriptor for RGB-D images, the convolutional k-means descriptor. The descriptor is based on recent results from the machine learning community. It automatically learns feature responses in the neighborhood of detected interest points and is able to combine all available information, such as color and depth into one, concise representation. To demonstrate the strength of this approach we show its applicability to different recognition problems. We evaluate the quality of the descriptor on the RGB-D Object Dataset where it is competitive with previously published results and propose an embedding into an image processing pipeline for object recognition and pose estimation.",
Local Naive Bayes Nearest Neighbor for image classification,"We present Local Naive Bayes Nearest Neighbor, an improvement to the NBNN image classification algorithm that increases classification accuracy and improves its ability to scale to large numbers of object classes. The key observation is that only the classes represented in the local neighborhood of a descriptor contribute significantly and reliably to their posterior probability estimates. Instead of maintaining a separate search structure for each class's training descriptors, we merge all of the reference data together into one search structure, allowing quick identification of a descriptor's local neighborhood. We show an increase in classification accuracy when we ignore adjustments to the more distant classes and show that the run time grows with the log of the number of classes rather than linearly in the number of classes as did the original. Local NBNN gives a 100 times speed-up over the original NBNN on the Caltech 256 dataset. We also provide the first head-to-head comparison of NBNN against spatial pyramid methods using a common set of input features. We show that local NBNN outperforms all previous NBNN based methods and the original spatial pyramid model. However, we find that local NBNN, while competitive with, does not beat state-of-the-art spatial pyramid methods that use local soft assignment and max-pooling.","Accuracy,
Nearest neighbor searches,
Indexes,
Kernel,
Approximation methods,
Approximation algorithms,
Training"
Analysis of Co-Occurrence Texture Statistics as a Function of Gray-Level Quantization for Classifying Breast Ultrasound,"In this paper, we investigated the behavior of 22 co-occurrence statistics combined to six gray-scale quantization levels to classify breast lesions on ultrasound (BUS) images. The database of 436 BUS images used in this investigation was formed by 217 carcinoma and 219 benign lesions images. The region delimited by a minimum bounding rectangle around the lesion was employed to calculate the gray-level co-occurrence matrix (GLCM). Next, 22 co-occurrence statistics were computed regarding six quantization levels (8, 16, 32, 64, 128, and 256), four orientations (0° , 45° , 90° , and 135° ), and ten distances (1, 2,...,10 pixels). Also, to reduce feature space dimensionality, texture descriptors of the same distance were averaged over all orientations, which is a common practice in the literature. Thereafter, the feature space was ranked using mutual information technique with minimal-redundancy-maximal-relevance (mRMR) criterion. Fisher linear discriminant analysis (FLDA) was applied to assess the discrimination power of texture features, by adding the first m-ranked features to the classification procedure iteratively until all of them were considered. The area under ROC curve (AUC) was used as figure of merit to measure the performance of the classifier. It was observed that averaging texture descriptors of a same distance impacts negatively the classification performance, since the best AUC of 0.81 was achieved with 32 gray levels and 109 features. On the other hand, regarding the single texture features (i.e., without averaging procedure), the quantization level does not impact the discrimination power, since AUC=0.87 was obtained for the six quantization levels. Moreover, the number of features was reduced (between 17 and 24 features). The texture descriptors that contributed notably to distinguish breast lesions were contrast and correlation computed from GLCMs with orientation of 90° and distance more than five pixels.","Quantization,
Lesions,
Breast,
Ultrasonic imaging,
Cancer,
Feature extraction,
Mutual information"
Robust and Scalable Graph-Based Semisupervised Learning,"Graph-based semisupervised learning (GSSL) provides a promising paradigm for modeling the manifold structures that may exist in massive data sources in high-dimensional spaces. It has been shown effective in propagating a limited amount of initial labels to a large amount of unlabeled data, matching the needs of many emerging applications such as image annotation and information retrieval. In this paper, we provide reviews of several classical GSSL methods and a few promising methods in handling challenging issues often encountered in web-scale applications. First, to successfully incorporate the contaminated noisy labels associated with web data, label diagnosis and tuning techniques applied to GSSL are surveyed. Second, to support scalability to the gigantic scale (millions or billions of samples), recent solutions based on anchor graphs are reviewed. To help researchers pursue new ideas in this area, we also summarize a few popular data sets and software tools publicly available. Important open issues are discussed at the end to stimulate future research.","Semisupervised learning,
Noise measurement,
Cost function,
Image processing,
Laplace equations,
Supervised learning,
Image classification"
Internal Hexa-Band Folded Monopole/Dipole/Loop Antenna With Four Resonances for Mobile Device,"A fold monopole/dipole/loop antenna offers unique advantages over a conventional Planar Inverted-F Antenna (PIFA) and monopole antenna for a mobile cellular device. Perhaps the most significant benefit is the fact that up to three resonant modes could be generated in a single continuous loop structure. In this paper, a novel hexa-band internal folded monopole/dipole/loop antenna has been proposed. The proposed antenna has four resonances in which three of them are 0.5λ , 1λ and 1.5λ modes. The distinctive feature of the antenna is an extra 2λ folded dipole mode, which has not been reported so far, is excited and utilized. All these four modes can be employed to cover the Low LTE700/GSM850/900 Band (LB: 698-960 MHz) and the High GSM1850/1900/UMTS2100 Band (HB: 1710-2170 MHz). The proposed loop antenna has been simulated, prototyped and tested. It is shown that the numerically simulated results are in close agreement with the experimental prototype results and proved that the antenna operates as proposed.",
Robust Multichannel Blind Deconvolution via Fast Alternating Minimization,"Blind deconvolution, which comprises simultaneous blur and image estimations, is a strongly ill-posed problem. It is by now well known that if multiple images of the same scene are acquired, this multichannel (MC) blind deconvolution problem is better posed and allows blur estimation directly from the degraded images. We improve the MC idea by adding robustness to noise and stability in the case of large blurs or if the blur size is vastly overestimated. We formulate blind deconvolution as an l1 -regularized optimization problem and seek a solution by alternately optimizing with respect to the image and with respect to blurs. Each optimization step is converted to a constrained problem by variable splitting and then is addressed with an augmented Lagrangian method, which permits simple and fast implementation in the Fourier domain. The rapid convergence of the proposed method is illustrated on synthetically blurred data. Applicability is also demonstrated on the deconvolution of real photos taken by a digital camera.",
Building Autonomous Sensitive Artificial Listeners,"This paper describes a substantial effort to build a real-time interactive multimodal dialogue system with a focus on emotional and nonverbal interaction capabilities. The work is motivated by the aim to provide technology with competences in perceiving and producing the emotional and nonverbal behaviors required to sustain a conversational dialogue. We present the Sensitive Artificial Listener (SAL) scenario as a setting which seems particularly suited for the study of emotional and nonverbal behavior since it requires only very limited verbal understanding on the part of the machine. This scenario allows us to concentrate on nonverbal capabilities without having to address at the same time the challenges of spoken language understanding, task modeling, etc. We first report on three prototype versions of the SAL scenario in which the behavior of the Sensitive Artificial Listener characters was determined by a human operator. These prototypes served the purpose of verifying the effectiveness of the SAL scenario and allowed us to collect data required for building system components for analyzing and synthesizing the respective behaviors. We then describe the fully autonomous integrated real-time system we created, which combines incremental analysis of user behavior, dialogue management, and synthesis of speaker and listener behavior of a SAL character displayed as a virtual agent. We discuss principles that should underlie the evaluation of SAL-type systems. Since the system is designed for modularity and reuse and since it is publicly available, the SAL system has potential as a joint research tool in the affective computing research community.",
Proof-Carrying Hardware Intellectual Property: A Pathway to Trusted Module Acquisition,"We present a novel framework for facilitating the acquisition of provably trustworthy hardware intellectual property (IP). The proposed framework draws upon research in the field of proof-carrying code (PCC) to allow for formal yet computationally straightforward validation of security-related properties by the IP consumer. These security-related properties, agreed upon a priori by the IP vendor and consumer and codified in a temporal logic, outline the boundaries of trusted operation, without necessarily specifying the exact IP functionality. A formal proof of these properties is then crafted by the vendor and presented to the consumer alongside the hardware IP. The consumer, in turn, can easily and automatically check the correctness of the proof and, thereby, validate compliance of the hardware IP with the agreed-upon properties. We implement the proposed framework using a synthesizable subset of Verilog and a series of pertinent definitions in the Coq theorem-proving language. Finally, we demonstrate the application of this framework on a simple IP acquisition scenario, including specification of security-related properties, Verilog code for two alter- native circuit implementations, as well as proofs of their security compliance.","Hardware,
Hardware design languages,
Security,
Semantics,
IP networks,
Syntactics,
Field programmable gate arrays"
Robust visual tracking via multi-task sparse learning,"In this paper, we formulate object tracking in a particle filter framework as a multi-task sparse learning problem, which we denote as Multi-Task Tracking (MTT). Since we model particles as linear combinations of dictionary templates that are updated dynamically, learning the representation of each particle is considered a single task in MTT. By employing popular sparsity-inducing ℓp, q mixed norms (p ∈ {2, ∞} and q = 1), we regularize the representation problem to enforce joint sparsity and learn the particle representations together. As compared to previous methods that handle particles independently, our results demonstrate that mining the interdependencies between particles improves tracking performance and overall computational complexity. Interestingly, we show that the popular L1 tracker [15] is a special case of our MTT formulation (denoted as the L11 tracker) when p = q = 1. The learning problem can be efficiently solved using an Accelerated Proximal Gradient (APG) method that yields a sequence of closed form updates. As such, MTT is computationally attractive. We test our proposed approach on challenging sequences involving heavy occlusion, drastic illumination changes, and large pose variations. Experimental results show that MTT methods consistently outperform state-of-the-art trackers.","Target tracking,
Dictionaries,
Joints,
Visualization,
Robustness,
Encoding,
Lighting"
Carbon Nanotube Robust Digital VLSI,"Carbon nanotube field-effect transistors (CNFETs) are excellent candidates for building highly energy-efficient electronic systems of the future. Fundamental limitations inherent to carbon nanotubes (CNTs) pose major obstacles to the realization of robust CNFET digital very large-scale integration (VLSI): 1) it is nearly impossible to guarantee perfect alignment and positioning of all CNTs despite near-perfect CNT alignment achieved in recent years; 2) CNTs can be metallic or semiconducting depending on chirality; and 3) CNFET circuits can suffer from large performance variations, reduced yield, and increased susceptibility to noise. Today's CNT process improvements alone are inadequate to overcome these challenges. This paper presents an overview of: 1) imperfections and variations inherent to CNTs; 2) design and processing techniques, together with a probabilistic analysis framework, for robust CNFET digital VLSI circuits immune to inherent CNT imperfections and variations; and 3) recent experimental demonstration of CNFET digital circuits that are immune to CNT imperfections. Significant advances in design tools can enable robust and scalable CNFET circuits that overcome the challenges of the CNFET technology while retaining its energy-efficiency benefits.",
Transferring Visual Prior for Online Object Tracking,"Visual prior from generic real-world images can be learned and transferred for representing objects in a scene. Motivated by this, we propose an algorithm that transfers visual prior learned offline for online object tracking. From a collection of real-world images, we learn an overcomplete dictionary to represent visual prior. The prior knowledge of objects is generic, and the training image set does not necessarily contain any observation of the target object. During the tracking process, the learned visual prior is transferred to construct an object representation by sparse coding and multiscale max pooling. With this representation, a linear classifier is learned online to distinguish the target from the background and to account for the target and background appearance variations over time. Tracking is then carried out within a Bayesian inference framework, in which the learned classifier is used to construct the observation model and a particle filter is used to estimate the tracking result sequentially. Experiments on a variety of challenging sequences with comparisons to several state-of-the-art methods demonstrate that more robust object tracking can be achieved by transferring visual prior.","Target tracking,
Visualization,
Dictionaries,
Image coding,
Vectors,
Image reconstruction,
Principal component analysis"
User-Aware Image Tag Refinement via Ternary Semantic Analysis,"Large-scale user contributed images with tags are easily available on photo sharing websites. However, the noisy or incomplete correspondence between the images and tags prohibits them from being leveraged for precise image retrieval and effective management. To tackle the problem of tag refinement, we propose a method of Ranking based Multi-correlation Tensor Factorization (RMTF), to jointly model the ternary relations among user, image, and tag, and further to precisely reconstruct the user-aware image-tag associations as a result. Since the user interest or background can be explored to eliminate the ambiguity of image tags, the proposed RMTF is believed to be superior to the traditional solutions, which only focus on the binary image-tag relations. During the model estimation, we employ a ranking based optimization scheme to interpret the tagging data, in which the pair-wise qualitative difference between positive and negative examples is used, instead of the point-wise 0/1 confidence. Specifically, the positive examples are directly decided by the observed user-image-tag interrelations, while the negative ones are collected with respect to the most semantically and contextually irrelevant tags. Extensive experiments on a benchmark Flickr dataset demonstrate the effectiveness of the proposed solution for tag refinement. We also show attractive performances on two potential applications as the by-products of the ternary relation analysis.","Tensile stress,
Tagging,
Semantics,
Correlation,
Media,
Noise measurement,
Data models"
A Comprehensive Survey of Voice over IP Security Research,"We present a comprehensive survey of Voice over IP security academic research, using a set of 245 publications forming a closed cross-citation set. We classify these papers according to an extended version of the VoIP Security Alliance (VoIPSA) Threat Taxonomy. Our goal is to provide a roadmap for researchers seeking to understand existing capabilities and to identify gaps in addressing the numerous threats and vulnerabilities present in VoIP systems. We discuss the implications of our findings with respect to vulnerabilities reported in a variety of VoIP products. We identify two specific problem areas (denial of service, and service abuse) as requiring significant more attention from the research community. We also find that the overwhelming majority of the surveyed work takes a black box view of VoIP systems that avoids examining their internal structure and implementation. Such an approach may miss the mark in terms of addressing the main sources of vulnerabilities, i.e., implementation bugs and misconfigurations. Finally, we argue for further work on understanding cross-protocol and cross-mechanism vulnerabilities (emergent properties), which are the byproduct of a highly complex system-of-systems and an indication of the issues in future large-scale systems.","Servers,
Protocols,
Media,
Authentication,
Taxonomy,
Internet telephony"
Linear Precoding for Finite-Alphabet Inputs Over MIMO Fading Channels With Statistical CSI,"This paper investigates the linear precoder design that maximizes the average mutual information of multiple-input multiple-output fading channels with statistical channel state information known at the transmitter. It formulates the design from the standpoint of finite-alphabet inputs, which leads to a problem that is very important in practice but extremely difficult in theory: First, the average mutual information lacks closed-form expression and involves prohibitive computational burden. Second, the optimization over the precoder is nonconcave and thus easily gets stuck in local maxima. To address these issues, this study first derives lower and upper bounds for the average mutual information, in which the computational complexity is reduced by several orders of magnitude compared to calculating the average mutual information directly. It proves that maximizing the bounds is asymptotically optimal and shows that, with a constant shift, the lower bound actually offers a very accurate approximation to the average mutual information for various fading channels. This paper further proposes utilizing the lower bound as a low-complexity and accurate alternative for developing a two-step algorithm to find a near global optimal precoder. Numerical examples demonstrate the convergence and efficacy of the proposed algorithm. Compared to its conventional counterparts, the proposed linear precoding method provides significant performance gain over existing precoding algorithms. The gain becomes more substantial when the spatial correlation of MIMO channels increases.","Mutual information,
Vectors,
MIMO,
Signal processing algorithms,
Resource management,
Transmitters,
Optimization"
CMOS and Memristor-Based Neural Network Design for Position Detection,"Most hardware neural networks have a basic competitive learning rule on top of a more involved processing algorithm. This work highlights two basic learning rules/behavior: winner-take-all (WTA) and spike-timing-dependent plasticity (STDP). It also gives a design example implementing WTA combined with STDP in a position detector. A complementary metal-oxide-semiconductor (CMOS) and a memristor-MOS technology (MMOST) design simulation results are compared on the bases of power, area, and noise handling capabilities. Design and layout were done in 130-nm IBM process for CMOS, and the HSPICE model files for the process were used to simulate the CMOS part of the MMOST design. CMOS consumes area, 55-W max power, and requires a 3-dB SNR. On the other hand, the MMOST design consumes , 15-W max power, and requires a 4.8-dB SNR. There is a potential to improve upon analog computing with the adoption of MMOST designs.",
Analysis and Design of a Three-Level LLC Series Resonant Converter for High- and Wide-Input-Voltage Applications,"In this paper, the analysis and design of a three-level LLC series resonant converter (TL LLC SRC) for high- and wide-input-voltage applications is presented. The TL LLC SRC discussed in this paper consists of two half-bridge LLC SRCs in series, sharing a resonant inductor and a transformer. Its main advantages are that the voltage across each switch is clamped at half of the input voltage and that voltage balance is achieved. Thus, it is suitable for high-input-voltage applications. Moreover, due to its simple driving signals, the additional circulating current of the conventional TL LLC SRCs does not appear in the converter, and a simpler driving circuitry is allowed to be designed. With this converter, the operation principles, the gain of the LLC resonant tank, and the zero-voltage-switching condition under wide input voltage variation are analyzed. Both the current and voltage stresses over different design factors of the resonant tank are discussed as well. Based on the results of these analyses, a design example is provided and its validity is confirmed by an experiment involving a prototype converter with an input of 400-600 V and an output of 48 V/20 A. In addition, a family of TL LLC SRCs with double-resonant tanks for high-input-voltage applications is introduced. While this paper deals with a TL LLC SRC, the analysis results can be applied to other TL LLC SRCs for wide-input-voltage applications.","Switches,
Zero voltage switching,
Capacitors,
Stress,
Rectifiers,
Logic gates"
An Efficient Learning Procedure for Deep Boltzmann Machines,"We present a new learning algorithm for Boltzmann machines that contain many layers of hidden variables. Data-dependent statistics are estimated using a variational approximation that tends to focus on a single mode, and data-independent statistics are estimated using persistent Markov chains. The use of two quite different techniques for estimating the two types of statistic that enter into the gradient of the log likelihood makes it practical to learn Boltzmann machines with multiple hidden layers and millions of parameters. The learning can be made more efficient by using a layer-by-layer pretraining phase that initializes the weights sensibly. The pretraining also allows the variational inference to be initialized sensibly with a single bottom-up pass. We present results on the MNIST and NORB data sets showing that deep Boltzmann machines learn very good generative models of handwritten digits and 3D objects. We also show that the features discovered by deep Boltzmann machines are a very effective way to initialize the hidden layers of feedforward neural nets, which are then discriminatively fine-tuned.",
Spatial Interference Cancellation for Multiantenna Mobile Ad Hoc Networks,"Interference between nodes is a critical impairment in mobile ad hoc networks. This paper studies the role of multiple antennas in mitigating such interference. Specifically, a network is studied in which receivers apply zero-forcing beamforming to cancel the strongest interferers. Assuming a network with Poisson-distributed transmitters and independent Rayleigh fading channels, the transmission capacity is derived, which gives the maximum number of successful transmissions per unit area. Mathematical tools from stochastic geometry are applied to obtain the asymptotic transmission capacity scaling and characterize the impact of inaccurate channel state information (CSI). It is shown that, if each node cancels interferers, the transmission capacity decreases as as the outage probability vanishes. For fixed , as grows, the transmission capacity increases as where is the path-loss exponent. Moreover, CSI inaccuracy is shown to have no effect on the transmission capacity scaling as vanishes, provided that the CSI training sequence has an appropriate length, which we derive. Numerical results suggest that canceling merely one interferer by each node may increase the transmission capacity by an order of magnitude or more, even when the CSI is imperfect.","Mobile computing,
Ad hoc networks,
Interference cancellation,
Receivers,
Transmitters,
Training"
Unified Framework to Regularized Covariance Estimation in Scaled Gaussian Models,"We consider regularized covariance estimation in scaled Gaussian settings, e.g., elliptical distributions, compound-Gaussian processes and spherically invariant random vectors. Asymptotically in the number of samples, the classical maximum likelihood (ML) estimate is optimal under different criteria and can be efficiently computed even though the optimization is nonconvex. We propose a unified framework for regularizing this estimate in order to improve its finite sample performance. Our approach is based on the discovery of hidden convexity within the ML objective. We begin by restricting the attention to diagonal covariance matrices. Using a simple change of variables, we transform the problem into a convex optimization that can be efficiently solved. We then extend this idea to nondiagonal matrices using convexity on the manifold of positive definite matrices. We regularize the problem using appropriately convex penalties. These allow for shrinkage towards the identity matrix, shrinkage towards a diagonal matrix, shrinkage towards a given positive definite matrix, and regularization of the condition number. We demonstrate the advantages of these estimators using numerical simulations.","Covariance matrix,
Optimization,
Manifolds,
Maximum likelihood estimation,
Robustness,
Convergence"
Flying Capacitors Reduction in an Improved Double Flying Capacitor Multicell Converter Controlled by a Modified Modulation Method,"This paper proposes an improved configuration of double flying capacitor multicell (DFCM) converter. The main advantages of the proposed converter, compared to the conventional DFCM converter, are the doubling of the number of output voltage levels and improvement of the output voltage frequency spectrum. This progress is achieved by adding only two low-power switches and one dc voltage source, whose voltage rating is a small fraction of the main dc-link voltage rating, to the conventional configuration of the DFCM converter. However, the number and voltage rating of high-frequency switches and capacitors and the number of high-frequency switchings during a full cycle are kept constant. The doubling of the number of output voltage levels in the proposed converter makes it possible to decrease the number of cells, the number of flying capacitors, as well as their voltage rating and the amount of stored energy in flying capacitors. Moreover, a modulation method based on phase-shifted carrier pulsewidth modulation is proposed to control the new converter. Simulation and measured experimental results are presented to illustrate the performance of the proposed configuration and its control strategy.","Capacitors,
Topology,
Switches,
Semiconductor diodes,
Educational institutions,
Electrical engineering,
Pulse width modulation"
Modeling and control of a flying robot for contact inspection,"This paper focuses on the modeling and control of a flying robot. The complete system, composed of a quadrotor unmanned aerial vehicle and a custom-made manipulator, has been designed for remote inspection by contact of industrial plants. The goal of this paper is to show the dynamical characteristics of the flying robot during tasks that require physical interaction, and to determine a control strategy that allows to safely interact with unknown environments. The methodology has been implemented on a real prototype and tested in an indoor area. Experimental results validate the proposed controller and show its effectiveness.","Manipulator dynamics,
Vehicles,
Vehicle dynamics,
Frequency modulation,
Force"
Physical-Layer Secrecy for OFDM Transmissions Over Fading Channels,"This paper considers the information theoretic secrecy rates that are achievable by an orthogonal frequency-division multiplexing (OFDM) transmitter/receiver pair in the presence of an eavesdropper that might either use an OFDM structure or choose a more complex receiver architecture. The analysis is made possible by modeling the system as a particular instance of a high dimensional multiple-input multiple-output wiretap channel. The secrecy capacity is formulated as a maximization problem under a trace constraint, and simple expressions are given for its high signal-to-noise (SNR) limit. The low rate limit of the secrecy outage probability is also evaluated under a fading channel model. As for the finite SNR case, the secrecy rates that can be achieved with particular inputs are considered. Numerical results are provided under a Rayleigh fading channel model and under dependence of the main and eavesdropper channels. The secrecy loss due to the OFDM structure constraints, and the information gain for an eavesdropper that uses a more complex receiver, are also considered.","OFDM,
Receivers,
MIMO,
Physical layer,
Signal to noise ratio,
Transmitters,
Communication system security"
VDN: Virtual machine image distribution network for cloud data centers,"Cloud computing centers face the key challenge of provisioning diverse virtual machine instances in an elastic and scalable manner. To address this challenge, we have performed an analysis of VM instance traces collected at six production data centers during four months. One key finding is that the number of instances created from the same VM image is relatively small at a given time and thus conventional file-based p2p sharing approaches may not be effective. Based on the understanding that different VM image files often have many common chunks of data, we propose a chunk-level Virtual machine image Distribution Network (VDN). Our distribution scheme takes advantage of the hierarchical network topology of data centers to reduce the VM instance provisioning time and also to minimize the overhead of maintaining chunk location information. Evaluation shows that VDN achieves as much as 30-80× speed up for large VM images under heavy traffic.","Servers,
Linux,
Collaboration,
Network topology,
Peer to peer computing,
Virtual machining"
Joint Estimation of Channel and Oscillator Phase Noise in MIMO Systems,"Oscillator phase noise limits the performance of high speed communication systems since it results in time varying channels and rotation of the signal constellation from symbol to symbol. In this paper, joint estimation of channel gains and Wiener phase noise in multi-input multi-output (MIMO) systems is analyzed. The signal model for the estimation problem is outlined in detail and new expressions for the Cramér-Rao lower bounds (CRLBs) for the multi-parameter estimation problem are derived. A data-aided least-squares (LS) estimator for jointly obtaining the channel gains and phase noise parameters is derived. Next, a decision-directed weighted least-squares (WLS) estimator is proposed, where pilots and estimated data symbols are employed to track the time-varying phase noise parameters over a frame. In order to reduce the overhead and delay associated with the estimation process, a new decision-directed extended Kalman filter (EKF) is proposed for tracking the MIMO phase noise throughout a frame. Numerical results show that the proposed LS, WLS, and EKF estimators' performances are close to the CRLB. Finally, simulation results demonstrate that by employing the proposed channel and time-varying phase noise estimators the bit-error rate performance of a MIMO system can be significantly improved.","Phase noise,
MIMO,
Estimation,
Channel estimation,
Receiving antennas"
Automatic Stage Scoring of Single-Channel Sleep EEG by Using Multiscale Entropy and Autoregressive Models,"In this paper, we propose an automatic sleep-scoring method combining multiscale entropy (MSE) and autoregressive (AR) models for single-channel EEG and to assess the performance of the method comparatively with manual scoring based on full polysomnograms. This is the first time that MSE has ever been applied to sleep scoring. All-night polysomnograms from 20 healthy individuals were scored using the Rechtschaffen and Kales rules. The developed method analyzed the EEG signals of C3-A2 for sleep staging. The results of automatic and manual scorings were compared on an epoch-by-epoch basis. A total of 8480 30-s sleep EEG epochs were measured and used for performance evaluation. The epoch-by-epoch comparison was made by classifying the EEG epochs into five states (Wake/REM/S1/S2/SWS) by the proposed method and manual scoring. The overall sensitivity and kappa coefficient of MSE alone are 76.9% and 0.65, respectively. Moreover, the overall sensitivity and kappa coefficient of our proposed method of integrating MSE, AR models, and a smoothing process can reach the sensitivity level of 88.1% and 0.81, respectively. Our results show that MSE is a useful and representative feature for sleep staging. It has high accuracy and good home-care applicability because a single EEG channel is used for sleep staging.","Sleep,
Electroencephalography,
Sensitivity,
Brain models,
Entropy,
Manuals"
Three-Dimensional Segmentation of Fluid-Associated Abnormalities in Retinal OCT: Probability Constrained Graph-Search-Graph-Cut,"An automated method is reported for segmenting 3-D fluid-associated abnormalities in the retina, so-called symptomatic exudate-associated derangements (SEAD), from 3-D OCT retinal images of subjects suffering from exudative age-related macular degeneration. In the first stage of a two-stage approach, retinal layers are segmented, candidate SEAD regions identified, and the retinal OCT image is flattened using a candidate-SEAD aware approach. In the second stage, a probability constrained combined graph search-graph cut method refines the candidate SEADs by integrating the candidate volumes into the graph cut cost function as probability constraints. The proposed method was evaluated on 15 spectral domain OCT images from 15 subjects undergoing intravitreal anti-VEGF injection treatment. Leave-one-out evaluation resulted in a true positive volume fraction (TPVF), false positive volume fraction (FPVF) and relative volume difference ratio (RVDR) of 86.5%, 1.7%, and 12.8%, respectively. The new graph cut-graph search method significantly outperformed both the traditional graph cut and traditional graph search approaches (p <; 0.01, p <; 0.04) and has the potential to improve clinical management of patients with choroidal neovascularization due to exudative age-related macular degeneration.","Image segmentation,
Retina,
Training,
Fluids,
Three dimensional displays,
Surface fitting"
Realistic Analytical Phantoms for Parallel Magnetic Resonance Imaging,"The quantitative validation of reconstruction algorithms requires reliable data. Rasterized simulations are popular but they are tainted by an aliasing component that impacts the assessment of the performance of reconstruction. We introduce analytical simulation tools that are suited to parallel magnetic resonance imaging and allow one to build realistic phantoms. The proposed phantoms are composed of ellipses and regions with piecewise-polynomial boundaries, including spline contours, Bézier contours, and polygons. In addition, they take the channel sensitivity into account, for which we investigate two possible models. Our analytical formulations provide well-defined data in both the spatial and k-space domains. Our main contribution is the closed-form determination of the Fourier transforms that are involved. Experiments validate the proposed implementation. In a typical parallel magnetic resonance imaging reconstruction experiment, we quantify the bias in the overly optimistic results obtained with rasterized simulations-the inverse-crime situation. We provide a package that implements the different simulations and provide tools to guide the design of realistic phantoms.","Phantoms,
Sensitivity,
Magnetic resonance imaging,
Polynomials,
Analytical models,
Coils,
Computational modeling"
Optimizing RFID Network Planning by Using a Particle Swarm Optimization Algorithm With Redundant Reader Elimination,"The rapid development of radio frequency identification (RFID) technology creates the challenge of optimal deployment of an RFID network. The RFID network planning (RNP) problem involves many constraints and objectives and has been proven to be NP-hard. The use of evolutionary computation (EC) and swarm intelligence (SI) for solving RNP has gained significant attention in the literature, but the algorithms proposed have seen difficulties in adjusting the number of readers deployed in the network. However, the number of deployed readers has an enormous impact on the network complexity and cost. In this paper, we develop a novel particle swarm optimization (PSO) algorithm with a tentative reader elimination (TRE) operator to deal with RNP. The TRE operator tentatively deletes readers during the search process of PSO and is able to recover the deleted readers after a few generations if the deletion lowers tag coverage. By using TRE, the proposed algorithm is capable of adaptively adjusting the number of readers used in order to improve the overall performance of RFID network. Moreover, a mutation operator is embedded into the algorithm to improve the success rate of TRE. In the experiment, six RNP benchmarks and a real-world RFID working scenario are tested and four algorithms are implemented and compared. Experimental results show that the proposed algorithm is capable of achieving higher coverage and using fewer readers than the other algorithms.","Radiofrequency identification,
Particle swarm optimization,
Algorithm design and analysis,
Interference"
Initial delay vs. interruptions: Between the devil and the deep blue sea,"End user quality perception in the context of Internet applications is often characterized by waiting times before service consumption as well as interruptions during service consumption. In particular in case of bad network conditions, network and service providers have to trade off between these two impairment types, i.e. between the devil and the deep blue sea. In this paper we investigate this tradeoff in order to guide the design and development of Internet applications and network management approaches. The contribution of this paper is twofold. Firstly, we quantify the impact of initial delays on the user perceived Quality of Experience (QoE) for different application scenarios by means of subjective laboratory and crowdsourcing studies. We show that QoE for a given waiting time strongly depends on the concrete application at hand but that rating diversity remains fairly application-invariant. Secondly, using the example of YouTube video streaming we compare the influence of initial delays and interruptions (stallings) during watching. Our results demonstrate that users are extremely sensitive to interruptions and that services should be designed accordingly e.g. by increasing initial delay for prebuffering to overcome lack of resources.","Delay,
Streaming media,
YouTube,
Internet,
Authentication,
Laboratories"
A Real-Time Visual Inspection System for Discrete Surface Defects of Rail Heads,"Discrete surface defects impact the riding quality and safety of a railway system. However, it is a challenge to inspect such defects in a vision system because of illumination inequality and the variation of reflection property of rail surfaces. This paper puts forward a real-time visual inspection system (VIS) for discrete surface defects. VIS first acquires a rail image by the image acquisition system, and then, it cuts the subimage of rail track by the track extraction algorithm. Subsequently, VIS enhances the contrast of the rail image using the local normalization (LN) method, which is nonlinear and illumination independent. At last, VIS detects defects using the defect localization based on projection profile (DLBP), which is robust to noise and very fast. Our experimental results demonstrate that VIS detects the Type-II defects with a recall of 93.10% and Type-I defects with a recall of 80.41%, and the proposed LN method and DLBP algorithm are better than the related well-established approaches. Furthermore, VIS is very fast with a linear computational time complexity, and it can be in real time to run on a 216-km/h test train under our experimental setup.","Rails,
Inspection,
Lighting,
Visualization,
Head,
Surface roughness,
Rough surfaces"
3-D Face Recognition Using eLBP-Based Facial Description and Local Feature Hybrid Matching,"This paper presents an effective method for 3-D face recognition using a novel geometric facial representation along with a local feature hybrid matching scheme. The proposed facial surface description is based on a set of facial depth maps extracted by multiscale extended Local Binary Patterns (eLBP) and enables an efficient and accurate description of local shape changes; it thus enhances the distinctiveness of smooth and similar facial range images generated by preprocessing steps. The following matching strategy is SIFT-based and performs in a hybrid way that combines local and holistic analysis, robustly associating the keypoints between two facial representations of the same subject. As a result, the proposed approach proves robust to facial expression variations, partial occlusions, and moderate pose changes, and the last property makes our system registration-free for nearly frontal face models. The proposed method was experimented on three public datasets, i.e. FRGC v2.0, Gavab, and Bosphorus. It displays a rank-one recognition rate of 97.6% and a verification rate of 98.4% at a 0.001 FAR on the FRGC v2.0 database without any face alignment. Additional experiments on the Bosphorus dataset further highlight the advantages of the proposed method with regard to expression changes and external partial occlusions. The last experiment carried out on the Gavab database demonstrates that the entire system can also deal with faces under large pose variations and even partially occluded ones, when only aided by a coarse alignment process.","Face,
Face recognition,
Shape,
Feature extraction,
Histograms,
Robustness,
Facial features"
Driver Behavior Classification at Intersections and Validation on Large Naturalistic Data Set,"The ability to classify driver behavior lays the foundation for more advanced driver assistance systems. In particular, improving safety at intersections has been identified as a high priority due to the large number of intersection-related fatalities. This paper focuses on developing algorithms for estimating driver behavior at road intersections and validating them on real traffic data. It introduces two classes of algorithms that can classify drivers as compliant or violating. They are based on (1) support vector machines and (2) hidden Markov models, which are two very popular machine learning approaches that have been used successfully for classification in multiple disciplines. However, existing work has not explored the benefits of applying these techniques to the problem of driver behavior classification at intersections. The developed algorithms are successfully validated using naturalistic intersection data collected in Christiansburg, VA, through the U.S. Department of Transportation Cooperative Intersection Collision Avoidance System for Violations initiative. Their performances are also compared with those of three traditional methods, and the results show significant improvements with the new algorithms.","Vehicles,
Hidden Markov models,
Support vector machines,
Machine learning algorithms,
Classification algorithms,
Safety,
Computational modeling"
A New Approach for Diagnosability Analysis of Petri Nets Using Verifier Nets,"In this paper, we analyze the diagnosability properties of labeled Petri nets. We consider the standard notion of diagnosability of languages, requiring that every occurrence of an unobservable fault event be eventually detected, as well as the stronger notion of diagnosability in K steps, where the detection must occur within a fixed bound of K event occurrences after the fault. We give necessary and sufficient conditions for these two notions of diagnosability for both bounded and unbounded Petri nets and then present an algorithmic technique for testing the conditions based on linear programming. Our approach is novel and based on the analysis of the reachability/coverability graph of a special Petri net, called Verifier Net, that is built from the Petri net model of the given system. In the case of systems that are diagnosable in K steps, we give a procedure to compute the bound K. To the best of our knowledge, this is the first time that necessary and sufficient conditions for diagnosability and diagnosability in K steps of labeled unbounded Petri nets are presented.","Petri nets,
Automata,
Vectors,
System recovery,
Artificial neural networks,
Delays"
Reliability Analysis of Nonrepairable Cold-Standby Systems Using Sequential Binary Decision Diagrams,"Many real-world systems, particularly those with limited power resources, are designed with cold-standby redundancy for achieving fault tolerance and high reliability. Cold-standby units are unpowered and, thus, do not consume any power until needed to replace a faulty online component. Cold-standby redundancy creates sequential dependence between the online component and standby components; in particular, a standby component can start to work and then fail only after the online component has failed. Traditional approaches to handling the cold-standby redundancy are typically state-space-based or simulation-based or inclusion/exclusion-based methods. Those methods, however, have the state-space explosion problem and/or require long computation time particularly when results with a high degree of accuracy are desired. In this paper, we propose an analytical method based on sequential binary decision diagrams (SBDD) for combinatorial reliability analysis of nonrepairable cold-standby systems. Different from the simulation-based methods, the proposed approach can generate exact system reliability results. In addition, the system SBDD model and reliability evaluation expression, once generated, are reusable for the reliability analysis with different component failure parameters. The approach has no limitation on the type of time-to-failure distributions for the system components or on the system structure. Application and advantages of the proposed approach are illustrated through several case studies.","Logic gates,
Boolean functions,
Data structures,
Fault trees,
Discrete Fourier transforms,
Redundancy"
"Polar Codes for the
m
-User Multiple Access Channel","In this paper, polar codes for the m-user multiple access channel (MAC) with binary inputs are constructed. It is shown that Arikan's polarization technique applied individually to each user transforms independent uses of an m-user binary input MAC into successive uses of extremal MACs. This transformation has a number of desirable properties: 1) the “uniform sum-rate” of the original MAC is preserved, 2) the extremal MACs have uniform rate regions that are not only polymatroids but matroids, and thus, 3) their uniform sum-rate can be reached by each user transmitting either uncoded or fixed bits; in this sense, they are easy to communicate over. A polar code can then be constructed with an encoding and decoding complexity of O(n log n) (where n is the block length), a block error probability of o(exp (- n1/2 - ε)), and capable of achieving the uniform sum-rate of any binary input MAC with arbitrary many users. Applications of this polar code construction to channels with a finite field input alphabet and to the additive white Gaussian noise channel are also discussed.","Mutual information,
Decoding,
Convergence,
Random variables,
Error probability,
Encoding,
Electromyography"
Extraction of Airways From CT (EXACT'09),"This paper describes a framework for establishing a reference airway tree segmentation, which was used to quantitatively evaluate 15 different airway tree extraction algorithms in a standardized manner. Because of the sheer difficulty involved in manually constructing a complete reference standard from scratch, we propose to construct the reference using results from all algorithms that are to be evaluated. We start by subdividing each segmented airway tree into its individual branch segments. Each branch segment is then visually scored by trained observers to determine whether or not it is a correctly segmented part of the airway tree. Finally, the reference airway trees are constructed by taking the union of all correctly extracted branch segments. Fifteen airway tree extraction algorithms from different research groups are evaluated on a diverse set of 20 chest computed tomography (CT) scans of subjects ranging from healthy volunteers to patients with severe pathologies, scanned at different sites, with different CT scanner brands, models, and scanning protocols. Three performance measures covering different aspects of segmentation quality were computed for all participating algorithms. Results from the evaluation showed that no single algorithm could extract more than an average of 74% of the total length of all branches in the reference standard, indicating substantial differences between the algorithms. A fusion scheme that obtained superior results is presented, demonstrating that there is complementary information provided by the different algorithms and there is still room for further improvements in airway segmentation algorithms.",
Wavelet-Based Energy Features for Glaucomatous Image Classification,"Texture features within images are actively pursued for accurate and efficient glaucoma classification. Energy distribution over wavelet subbands is applied to find these important texture features. In this paper, we investigate the discriminatory potential of wavelet features obtained from the daubechies (db3), symlets (sym3), and biorthogonal (bio3.3, bio3.5, and bio3.7) wavelet filters. We propose a novel technique to extract energy signatures obtained using 2-D discrete wavelet transform, and subject these signatures to different feature ranking and feature selection strategies. We have gauged the effectiveness of the resultant ranked and selected subsets of features using a support vector machine, sequential minimal optimization, random forest, and naïve Bayes classification strategies. We observed an accuracy of around 93% using tenfold cross validations to demonstrate the effectiveness of these methods.","Feature extraction,
Discrete wavelet transforms,
Support vector machines,
Retina,
Matrix decomposition"
Secure and Efficient Handover Authentication Based on Bilinear Pairing Functions,"Seamless handover over multiple access points is highly desirable to mobile nodes, but ensuring security and efficiency of this process is challenging. This paper shows that prior handover authentication schemes incur high communication and computation costs, and are subject to a few security attacks. Further, a novel handover authentication protocol named PairHand is proposed. PairHand uses pairing-based cryptography to secure handover process and to achieve high efficiency. Also, an efficient batch signature verification scheme is incorporated into PairHand. Experiments using our implementation on laptop PCs show that PairHand is feasible in real applications.","Authentication,
Manganese,
Protocols,
Computer crime,
Privacy,
Communication system security"
Human gesture recognition using Kinect camera,"In this paper, we propose a comparison of human gesture recognition using data mining classification methods in video streaming. In particular, we are interested in a specific stream of vector of twenty body-joint positions which are representative of the human body captured by Kinect camera. The recognized gesture patterns of the study are stand, sit down, and lie down. Classification methods chosen for comparison study are backpropagation neural network, support vector machine, decision tree, and naive Bayes. Experimental results have shown that the backpropagation neural network method outperforms other classification methods and can achieve recognition with 100% accuracy. Moreover, the average accuracy of all classification methods used in this study is 93.72%, which confirms the high potential of using the Kinect camera in human body recognition applications. Our future work will use the knowledge obtained from these classifiers in time series analysis of gesture sequence for detecting fall motion in a smart home system.","Humans,
Support vector machines,
Cameras,
Gesture recognition,
Decision trees,
Accuracy,
Neural networks"
Real-Time Probabilistic Covariance Tracking With Efficient Model Update,"The recently proposed covariance region descriptor has been proven robust and versatile for a modest computational cost. The covariance matrix enables efficient fusion of different types of features, where the spatial and statistical properties, as well as their correlation, are characterized. The similarity between two covariance descriptors is measured on Riemannian manifolds. Based on the same metric but with a probabilistic framework, we propose a novel tracking approach on Riemannian manifolds with a novel incremental covariance tensor learning (ICTL). To address the appearance variations, ICTL incrementally learns a low-dimensional covariance tensor representation and efficiently adapts online to appearance changes of the target with only computational complexity, resulting in a real-time performance. The covariance-based representation and the ICTL are then combined with the particle filter framework to allow better handling of background clutter, as well as the temporary occlusions. We test the proposed probabilistic ICTL tracker on numerous benchmark sequences involving different types of challenges including occlusions and variations in illumination, scale, and pose. The proposed approach demonstrates excellent real-time performance, both qualitatively and quantitatively, in comparison with several previously proposed trackers.","Target tracking,
Tensile stress,
Manifolds,
Adaptation models,
Covariance matrix,
Feature extraction"
A Sampling-Based Tree Planner for Systems With Complex Dynamics,"This paper presents a kinodynamic motion planner, i.e., Kinodynamic Motion Planning by Interior-Exterior Cell Exploration (KPIECE), which is specifically designed for systems with complex dynamics, where integration backward in time is not possible, and speed of computation is important. A grid-based discretization is used to estimate the coverage of the state space. The coverage estimates help the planner detect the less-explored areas of the state space. An important characteristic of this discretization is that it keeps track of the boundary of the explored region of the state space and focuses exploration on the less covered parts of this boundary. Extensive experiments show that KPIECE provides significant computational gain over existing state-of-the-art methods and allows us to solve some harder, previously unsolvable problems. For some problems, KPIECE is shown to be up to two orders of magnitude faster than existing methods and use up to 40 times less memory. A shared memory parallel implementation is presented as well. This implementation provides better speedup than an embarrassingly parallel implementation by taking advantage of the evolving multicore technology.","Planning,
Robots,
Computational modeling,
Dynamics,
Heuristic algorithms,
Space exploration,
Numerical models"
Portable Real-Time Microwave Camera at 24 GHz,"This paper presents a microwave camera built upon a two-dimensional array of switchable slot antennas. The camera borrows from modulated scattering techniques to improve isolation among the array elements. The camera was designed to measure vector electric field distribution, be compact, portable, battery operated, possess high dynamic range, and be capable of producing real-time images at video frame-rate. This imaging system utilizes PIN diode-loaded resonant elliptical slot antennas as its array elements integrated in a simple and relatively low-loss waveguide network thus reducing the complexity, cost and size of the array. The sensitivity and dynamic range of this system is improved by utilizing a custom-designed heterodyne receiver and matched filter for demodulation. The performance of the multiplexing scheme, noise-floor and dynamic range of the receivers are presented as well. Sources of errors such as mutual-coupling and array response dispersion are also investigated. Finally, utilizing this imaging system for various applications such as 2-D electric field mapping, and nondestructive testing is demonstrated.","Arrays,
Electromagnetic waveguides,
Slot antennas,
Imaging,
Antenna measurements,
Electric fields,
Retina"
Ensuring Distributed Accountability for Data Sharing in the Cloud,"Cloud computing enables highly scalable services to be easily consumed over the Internet on an as-needed basis. A major feature of the cloud services is that users' data are usually processed remotely in unknown machines that users do not own or operate. While enjoying the convenience brought by this new emerging technology, users' fears of losing control of their own data (particularly, financial and health data) can become a significant barrier to the wide adoption of cloud services. To address this problem, in this paper, we propose a novel highly decentralized information accountability framework to keep track of the actual usage of the users' data in the cloud. In particular, we propose an object-centered approach that enables enclosing our logging mechanism together with users' data and policies. We leverage the JAR programmable capabilities to both create a dynamic and traveling object, and to ensure that any access to users' data will trigger authentication and automated logging local to the JARs. To strengthen user's control, we also provide distributed auditing mechanisms. We provide extensive experimental studies that demonstrate the efficiency and effectiveness of the proposed approaches.","Access control,
Distributed databases,
Authentication,
Monitoring,
Cryptography,
Privacy"
A New Adaptive Line Enhancer Based on Singular Spectrum Analysis,"Original adaptive line enhancer (ALE) is used for denoising periodic signals from white noise. ALE, however, relies mainly on second order similarity between the signal and its delayed version and is more effective when the signal is narrowband. A new ALE based on singular spectrum analysis (SSA) is proposed here. In this approach in the reconstruction stage of SSA, the eigentriples are adaptively selected (filtered) using the delayed version of the data. Unlike the conventional ALE where (second) order statistics are taken into account, here the full eigen-spectrum of the embedding matrix is exploited. Consequently, the system works for non-Gaussian noise and wideband periodic signals. By performing some experiments on synthetic signals it is demonstrated that the proposed system is very effective for separation of biomedical data, which often have some periodic or quasi-periodic components, such as EMG affected by ECG artefacts. This data are examined here.","Electromyography,
Electrocardiography,
Eigenvalues and eigenfunctions,
Signal to noise ratio,
Noise measurement,
Covariance matrix"
A Robust O(n) Solution to the Perspective-n-Point Problem,"We propose a noniterative solution for the Perspective-n-Point ({\rm P}n{\rm P}) problem, which can robustly retrieve the optimum by solving a seventh order polynomial. The central idea consists of three steps: 1) to divide the reference points into 3-point subsets in order to achieve a series of fourth order polynomials, 2) to compute the sum of the square of the polynomials so as to form a cost function, and 3) to find the roots of the derivative of the cost function in order to determine the optimum. The advantages of the proposed method are as follows: First, it can stably deal with the planar case, ordinary 3D case, and quasi-singular case, and it is as accurate as the state-of-the-art iterative algorithms with much less computational time. Second, it is the first noniterative {\rm P}n{\rm P} solution that can achieve more accurate results than the iterative algorithms when no redundant reference points can be used (n\le 5). Third, large-size point sets can be handled efficiently because its computational complexity is O(n).","Three dimensional displays,
Cameras,
Iterative methods,
Polynomials,
Robustness,
Vectors"
Pro-Energy: A novel energy prediction model for solar and wind energy-harvesting wireless sensor networks,"Energy harvesting is one of the most promising technologies towards the goal of perpetual operation of wireless sensor networks (WSNs). Environmentally-powered systems, however, have to deal with the variable behavior of ambient energy sources, which results in different amounts and rates of energy available over time. To alleviate the problem of the harvested power being neither constant nor continuous, energy prediction methods can be employed. Such models forecast the source availability and estimate the expected energy intake, allowing the system to take critical decisions about the utilization of the available energy. In this work, we present a novel energy prediction model, named Pro-Energy (PROfile energy prediction model), for multi-source energy harvesting WSNs, which is able to leverage past energy observations to provide accurate estimations of future energy availability. To assess the performance of our proposed solution, we use real-life solar and wind traces that we collected by interfacing TelosB nodes with solar cells and wind micro-turbines, as well as public available traces of solar and wind obtained from weather monitoring stations in the US. A comparative performance evaluation between Pro-Energy and energy predictors previously proposed in the literature, such as EWMA and WCMA, has shown that our solution significantly outperforms existing algorithms for both short and medium term prediction horizons, improving the prediction accuracy up to 60%.","wireless sensor networks,
energy harvesting,
energy resources,
forecasting theory,
prediction theory,
solar power,
wind power,
wind turbines"
Hybrid Selective Harmonic Elimination PWM for Common-Mode Voltage Reduction in Three-Level Neutral-Point-Clamped Inverters for Variable Speed Induction Drives,"This paper proposes a hybrid selective harmonic elimination pulsewidth modulation (SHEPWM) scheme for common-mode voltage reduction in three-level neutral-point-clamped inverter-based induction motor drives. The scheme uses the conventional SHEPWM (C-SHEPWM) to control the inverter at high frequency (≥ 0.9 motor rated frequency) and uses the modified SHEPWM (M-SHEPWM) to control the inverter at low frequency. It also uses a scheme to ensure the smooth transition between the two SHEPWM schemes. As a result, at high frequency, the C-SHEPWM provides the required high modulation index for the motor, while at low frequency, when a passive filter is less effective for common-mode voltage reduction, the M-SHEPWM is used to suppress the common-mode voltage. Experimental results show that the proposed hybrid SHEPWM scheme could meet the modulation index need of the motor and reduce the common-mode voltage in the drive, and the two SHEPWM schemes could transition smoothly.",
"A 2.4-GHz, 27-dBm Asymmetric Multilevel Outphasing Power Amplifier in 65-nm CMOS","We present a 2.4-GHz asymmetric multilevel outphasing (AMO) power amplifier (PA) with class-E branch amplifiers and discrete supply modulators integrated in a 65-nm CMOS process. AMO PAs achieve improved modulation bandwidth and efficiency over envelope tracking (ET) PAs by replacing the continuous supply modulator with a discrete supply modulator implemented with a fast digital switching network. Outphasing modulation is used to provide the required fine output envelope control. The AMO PA delivers 27.7-dBm peak output power with 45% system efficiency at 2.4 GHz. For a 20-MHz WLAN OFDM signal with 7.5-dB PAPR, the AMO PA achieves a drain efficiency of 31.9% and a system efficiency of 27.6% with an EVM of 2.7% rms.","Modulation,
Vectors,
Distortion measurement,
Power generation,
Linearity,
Phase measurement,
CMOS integrated circuits"
Transmission Capacity of Ad-hoc Networks With Multiple Antennas Using Transmit Stream Adaptation and Interference Cancellation,"The transmission capacity of an ad-hoc network is the maximum density of active transmitters per unit area, given an outage constraint at each receiver for a fixed rate of transmission. Assuming that the transmitter locations are distributed as a Poisson point process, this paper derives upper and lower bounds on the transmission capacity of an ad-hoc network when each node is equipped with multiple antennas. The transmitter either uses eigen multi-mode beamforming or a subset of its antennas without channel information to transmit multiple data streams, while the receiver uses partial zero forcing to cancel certain interferers using some of its spatial receive degrees of freedom (SRDOF). The receiver either cancels the nearest interferers or those interferers that maximize the post-cancellation signal-to-interference ratio. Using the obtained bounds, the optimal number of data streams to transmit, and the optimal SRDOF to use for interference cancellation are derived that provide the best scaling of the transmission capacity with the number of antennas. With beamforming, single data stream transmission together with using all but one SRDOF for interference cancellation is optimal, while without beamforming, single data stream transmission together with using a fraction of the total SRDOF for interference cancellation is optimal.",
Multigoal Heuristic Model Predictive Control Technique Applied to a Cascaded H-bridge StatCom,"A multilevel H-bridge StatCom inherently contains redundancy in the available switching states. This paper develops a variation on the typical model predictive control scheme which is able to exploit this redundancy to simultaneously balance the H-bridge capacitor voltages, provide excellent current reference tracking, and minimize converter switching losses. The scheme consists of a dead-beat current controller that has been integrated with heuristic models of the voltage balancing and switching loss characteristics. The integration of a pulsewidth modulation scheme is also described. Simulation and experimental results are presented that confirm the correct operation of the control and modulation strategies. Comparison with traditional control and modulation schemes is provided in terms of the key performance indicators associated with multilevel H-bridge StatComs.","Voltage control,
Switches,
Capacitors,
Voltage measurement,
Cost function,
Switching loss"
On effective TSV repair for 3D-stacked ICs,"3D-stacked ICs that employ through-silicon vias (TSVs) to connect multiple dies vertically have gained wide-spread interest in the semiconductor industry. In order to be commercially viable, the assembly yield for 3D-stacked ICs must be as high as possible, requiring TSVs to be reparable. Existing techniques typically assume TSV faults to be uniformly distributed and use neighboring TSVs to repair faulty ones, if any. In practice, however, clustered TSV faults are quite common due to the fact that the TSV bonding quality depends on surface roughness and cleaness of silicon dies, rendering prior TSV redundancy solutions less effective. To resolve this problem, we present a novel TSV repair framework, including a hardware architecture that enables faulty TSVs to be repaired by redundant TSVs that are farther apart, and the corresponding repair algorithm. By doing so, the manufacturing yield for 3D-stacked ICs can be dramatically improved, as demonstrated in our experimental results.","Through-silicon vias,
Maintenance engineering,
Redundancy,
Circuit faults,
Joining processes,
Timing,
Clustering algorithms"
Bit Weaving: A Non-Prefix Approach to Compressing Packet Classifiers in TCAMs,"Ternary content addressable memories (TCAMs) have become the de facto standard in industry for fast packet classification. Unfortunately, TCAMs have limitations of small capacity, high power consumption, high heat generation, and high cost. The well-known range expansion problem exacerbates these limitations as each classifier rule typically has to be converted to multiple TCAM rules. One method for coping with these limitations is to use compression schemes to reduce the number of TCAM rules required to represent a classifier. Unfortunately, all existing compression schemes only produce prefix classifiers. Thus, they all miss the compression opportunities created by non-prefix ternary classifiers. In this paper, we propose bit weaving, the first non-prefix compression scheme. Bit weaving is based on the observation that TCAM entries that have the same decision and whose predicates differ by only one bit can be merged into one entry by replacing the bit in question with . Bit weaving consists of two new techniques, bit swapping and bit merging, to first identify and then merge such rules together. The key advantages of bit weaving are that it runs fast, it is effective, and it is composable with other TCAM optimization methods as a pre/post-processing routine. We implemented bit weaving and conducted experiments on both real-world and synthetic packet classifiers. Our experimental results show the following: 1) bit weaving is an effective standalone compression technique (it achieves an average compression ratio of 23.6%); 2) bit weaving finds compression opportunities that other methods miss. Specifically, bit weaving improves the prior TCAM optimization techniques of TCAM Razor and Topological Transformation by an average of 12.8% and 36.5%, respectively.","Weaving,
Encoding,
Partitioning algorithms,
Merging,
Hardware,
Power demand,
Polynomials"
Image Compressive Sensing Recovery via Collaborative Sparsity,"Compressive sensing (CS) has drawn quite an amount of attention as a joint sampling and compression approach. Its theory shows that when the signal is sparse enough in some domain, it can be decoded from many fewer measurements than suggested by the Nyquist sampling theory. So one of the most challenging researches in CS is to seek a domain where a signal can exhibit a high degree of sparsity and hence be recovered faithfully. Most of the conventional CS recovery approaches, however, exploited a set of fixed bases (e.g., DCT, wavelet, and gradient domain) for the entirety of a signal, which are irrespective of the nonstationarity of natural signals and cannot achieve high enough degree of sparsity, thus resulting in poor rate-distortion performance. In this paper, we propose a new framework for image compressive sensing recovery via collaborative sparsity, which enforces local 2-D sparsity and nonlocal 3-D sparsity simultaneously in an adaptive hybrid space-transform domain, thus substantially utilizing intrinsic sparsity of natural images and greatly confining the CS solution space. In addition, an efficient augmented Lagrangian-based technique is developed to solve the above optimization problem. Experimental results on a wide range of natural images are presented to demonstrate the efficacy of the new CS recovery strategy.",
Automatic Image Annotation and Retrieval Using Group Sparsity,"Automatically assigning relevant text keywords to images is an important problem. Many algorithms have been proposed in the past decade and achieved good performance. Efforts have focused upon model representations of keywords, whereas properties of features have not been well investigated. In most cases, a group of features is preselected, yet important feature properties are not well used to select features. In this paper, we introduce a regularization-based feature selection algorithm to leverage both the sparsity and clustering properties of features, and incorporate it into the image annotation task. Using this group-sparsity-based method, the whole group of features [e.g., red green blue (RGB) or hue, saturation, and value (HSV)] is either selected or removed. Thus, we do not need to extract this group of features when new data comes. A novel approach is also proposed to iteratively obtain similar and dissimilar pairs from both the keyword similarity and the relevance feedback. Thus, keyword similarity is modeled in the annotation framework. We also show that our framework can be employed in image retrieval tasks by selecting different image pairs. Extensive experiments are designed to compare the performance between features, feature combinations, and regularization-based feature selection methods applied on the image annotation task, which gives insight into the properties of features in the image annotation task. The experimental results demonstrate that the group-sparsity-based method is more accurate and stable than others.","Feature extraction,
Training,
Image color analysis,
Histograms,
Visualization,
Testing,
Training data"
Peripheral Electrical Stimulation Triggered by Self-Paced Detection of Motor Intention Enhances Motor Evoked Potentials,"This paper proposes the development and experimental tests of a self-paced asynchronous brain-computer interfacing (BCI) system that detects movement related cortical potentials (MRCPs) produced during motor imagination of ankle dorsiflexion and triggers peripheral electrical stimulations timed with the occurrence of MRCPs to induce corticospinal plasticity. MRCPs were detected online from EEG signals in eight healthy subjects with a true positive rate (TPR) of 67.15±7.87% and false positive rate (FPR) of 22.05±9.07%. The excitability of the cortical projection to the target muscle (tibialis anterior) was assessed before and after the intervention through motor evoked potentials (MEP) using transcranial magnetic stimulation (TMS). The peak of the evoked potential significantly (P=0.02) increased after the BCI intervention by 53±43% (relative to preintervention measure), although the spinal excitability (tested by stretch reflexes) did not change. These results demonstrate for the first time that it is possible to alter the corticospinal projections to the tibialis anterior muscle by using an asynchronous BCI system based on online motor imagination that triggered peripheral stimulation. This type of repetitive proprioceptive feedback training based on self-generated brain signal decoding may be a requirement for purposeful skill acquisition in intact humans and in the rehabilitation of persons with brain damage.","Muscles,
Electrical stimulation,
Educational institutions,
Electroencephalography,
Electromyography,
Training,
Synchronous motors"
A Universal Denoising Framework With a New Impulse Detector and Nonlocal Means,"Impulse noise detection is a critical issue when removing impulse noise and impulse/Gaussian mixed noise. In this paper, we propose a new detection mechanism for universal noise and a universal noise-filtering framework based on the nonlocal means (NL-means). The operation is carried out in two stages, i.e., detection followed by filtering. For detection, first, we propose the robust outlyingness ratio (ROR) for measuring how impulselike each pixel is, and then all the pixels are divided into four clusters according to the ROR values. Second, different decision rules are used to detect the impulse noise based on the absolute deviation to the median in each cluster. In order to make the detection results more accurate and more robust, the from-coarse-to-fine strategy and the iterative framework are used. In addition, the detection procedure consists of two stages, i.e., the coarse and fine detection stages. For filtering, the NL-means are extended to the impulse noise by introducing a reference image. Then, a universal denoising framework is proposed by combining the new detection mechanism with the NL-means (ROR-NLM). Finally, extensive simulation results show that the proposed noise detector is superior to most existing detectors, and the ROR-NLM produces excellent results and outperforms most existing filters for different noise models. Unlike most of the other impulse noise filters, the proposed ROR-NLM also achieves high peak signal-to-noise ratio and great image quality by efficiently removing impulse/Gaussian mixed noise.","Noise reduction,
Detectors,
Noise measurement,
Filtering,
Gaussian noise,
Robustness"
Audio Inpainting,"We propose the audio inpainting framework that recovers portions of audio data distorted due to impairments such as impulsive noise, clipping, and packet loss. In this framework, the distorted data are treated as missing and their location is assumed to be known. The signal is decomposed into overlapping time-domain frames and the restoration problem is then formulated as an inverse problem per audio frame. Sparse representation modeling is employed per frame, and each inverse problem is solved using the Orthogonal Matching Pursuit algorithm together with a discrete cosine or a Gabor dictionary. The Signal-to-Noise Ratio performance of this algorithm is shown to be comparable or better than state-of-the-art methods when blocks of samples of variable durations are missing. We also demonstrate that the size of the block of missing samples, rather than the overall number of missing samples, is a crucial parameter for high quality signal restoration. We further introduce a constrained Matching Pursuit approach for the special case of audio declipping that exploits the sign pattern of clipped audio samples and their maximal absolute value, as well as allowing the user to specify the maximum amplitude of the signal. This approach is shown to outperform state-of-the-art and commercially available methods for audio declipping in terms of Signal-to-Noise Ratio.","Matching pursuit algorithms,
Reliability,
Time domain analysis,
Time frequency analysis,
Image restoration,
Speech,
Distortion"
On the Design of Constant Modulus Probing Signals for MIMO Radar,"Probing signal waveforms play a central role in the signal processing performance of a multiple-input multiple-output (MIMO) radar. In practice, for a given desired beam pattern, we need to design a probing signal waveform whose beam pattern closely matches the desired one and whose autocorrelation and cross-correlation sidelobes are kept low. The latter properties are important to mitigate undesirable interference caused by multiple targets or scatterers. In this correspondence, we present an efficient optimization method to design a constant modulus probing signal which can synthesize a desired beam pattern while maximally suppressing both the autocorrelation and cross-correlation sidelobes at/between given spacial angles. We formulate this problem as an unconstrained minimization of a fourth order trigonometric polynomial and propose an efficient quasi-Newton iterative algorithm to solve it. Besides, we provide an analysis of the local minima of the fourth-order trigonometric polynomial and prove that any local minima is a 1/2-approximation of its global optimal solution. Numerical examples show that the proposed approach compares favorably with the existing approach.",
L1-Norm-Based Common Spatial Patterns,"Common spatial patterns (CSP) is a commonly used method of spatial filtering for multichannel electroencephalogram (EEG) signals. The formulation of the CSP criterion is based on variance using L2-norm, which implies that CSP is sensitive to outliers. In this paper, we propose a robust version of CSP, called CSP-L1, by maximizing the ratio of filtered dispersion of one class to the other class, both of which are formulated by using L1-norm rather than L2-norm. The spatial filters of CSP-L1 are obtained by introducing an iterative algorithm, which is easy to implement and is theoretically justified. CSP-L1 is robust to outliers. Experiment results on a toy example and datasets of BCI competitions demonstrate the efficacy of the proposed method.","Electroencephalography,
Vectors,
Integrated circuits,
Robustness,
Dispersion,
Iterative methods,
Eigenvalues and eigenfunctions"
Gradient-Directed Multiexposure Composition,"In this paper, we present a simple yet effective method that takes advantage of the gradient information to accomplish the multiexposure image composition in both static and dynamic scenes. Given multiple images with different exposures, the proposed approach is capable of producing a pleasant tone-mapped-like high-dynamic-range image by compositing them seamlessly with the guidance of gradient-based quality assessment. In particular, two novel quality measures, namely, visibility and consistency, are developed based on the observations of gradient changes among different exposures. Experiments in various static and dynamic scenes are conducted to demonstrate the effectiveness of the proposed method.","Cameras,
Dynamic range,
Heuristic algorithms,
Ash,
Quality assessment,
Calibration"
High-Performance Junctionless MOSFETs for Ultralow-Power Analog/RF Applications,"In this letter, we demonstrate the usefulness of ultralow-power (ULP) junctionless (JL) MOSFETs in achieving improved analog/RF metrics as compared to nonunderlap and underlap MOSFETs. At a drain current (Ids) of 10 μA/μm, JL devices achieve two times higher values of cutoff frequency (fT) and maximum oscillation frequency (fMAX) along with 65% improvement in voltage gain (AVO) in comparison to conventional nonunderlap MOSFETs. ULP JL devices, which do not require source/drain (S/D) profile optimization, can perform comparably to underlap devices, thereby relaxing the stringent process constraints associated with S/D profile optimization in nanoscale devices. The results highlight new opportunities for realizing future ULP analog/RF design with JL transistors.","MOSFETs,
Logic gates,
Radio frequency,
Performance evaluation,
Capacitance,
Cutoff frequency"
Automatic assessment of macular edema from color retinal images,"Diabetic macular edema (DME) is an advanced symptom of diabetic retinopathy and can lead to irreversible vision loss. In this paper, a two-stage methodology for the detection and classification of DME severity from color fundus images is proposed. DME detection is carried out via a supervised learning approach using the normal fundus images. A feature extraction technique is introduced to capture the global characteristics of the fundus images and discriminate the normal from DME images. Disease severity is assessed using a rotational asymmetry metric by examining the symmetry of macular region. The performance of the proposed methodology and features are evaluated against several publicly available datasets. The detection performance has a sensitivity of 100% with specificity between 74% and 90%. Cases needing immediate referral are detected with a sensitivity of 100% and specificity of 97%. The severity classification accuracy is 81% for the moderate case and 100% for severe cases. These results establish the effectiveness of the proposed solution.","Image color analysis,
Retina,
Vectors,
Lesions,
Optical imaging,
Diabetes"
Data naming in Vehicle-to-Vehicle communications,"Vehicular networking is becoming reality. Today vehicles use TCP/IP to communicate with centralized servers through cellular networks. However many vehicular applications, such as information sharing for safety and real time traffic purposes, desire direct V2V communications which is difficult to achieve using the existing solutions. This paper explores the named-data approach to address this challenge. We use case studies to identify the design requirements and put forth a strawman proposal for the data name design to understand its advantages and limitations.","Vehicles,
Roads,
Safety,
IP networks,
Ad hoc networks,
Servers"
Handwritten Chinese Text Recognition by Integrating Multiple Contexts,"This paper presents an effective approach for the offline recognition of unconstrained handwritten Chinese texts. Under the general integrated segmentation-and-recognition framework with character oversegmentation, we investigate three important issues: candidate path evaluation, path search, and parameter estimation. For path evaluation, we combine multiple contexts (character recognition scores, geometric and linguistic contexts) from the Bayesian decision view, and convert the classifier outputs to posterior probabilities via confidence transformation. In path search, we use a refined beam search algorithm to improve the search efficiency and, meanwhile, use a candidate character augmentation strategy to improve the recognition accuracy. The combining weights of the path evaluation function are optimized by supervised learning using a Maximum Character Accuracy criterion. We evaluated the recognition performance on a Chinese handwriting database CASIA-HWDB, which contains nearly four million character samples of 7,356 classes and 5,091 pages of unconstrained handwritten texts. The experimental results show that confidence transformation and combining multiple contexts improve the text line recognition performance significantly. On a test set of 1,015 handwritten pages, the proposed approach achieved character-level accurate rate of 90.75 percent and correct rate of 91.39 percent, which are superior by far to the best results reported in the literature.","Character recognition,
Text recognition,
Context,
Handwriting recognition,
Hidden Markov models,
Image segmentation,
Lattices"
Numerical Analysis of a Photonic Crystal Fiber for Biosensing Applications,"This paper presents a theoretical study on a photonic crystal fiber (PCF) surface plasmon resonance biosensor. The proposed PCF sensor introduces the concept of simultaneous detection with H E11x and H E11x modes, which opens up some possibilities for multianalyte/multichannel sensing. Analysis was performed which considered the operation of the sensor in both amplitude and wavelength interrogation modes. Typical sensor resolutions of 4×10-5 RIU and 8×10-5 RIU with respect to H E11x and H E11y, respectively, are reported for the amplitude interrogation mode, while resoutions of 5 × 10-5 RIU and 6×10-5 RIU are reported for H E11x and H E11y, respectively, for the wavelength interrogation mode.","Plasmons,
Helium,
Biosensors,
Refractive index,
Sensitivity,
Frequency conversion,
Optical fiber sensors"
"A Single-Channel, 1.25-GS/s, 6-bit, 6.08-mW Asynchronous Successive-Approximation ADC With Improved Feedback Delay in 40-nm CMOS","A single-channel, asynchronous successive-approximation (SA) ADC with improved feedback delay is fabricated in 40 nm CMOS. Compared with a conventional SAR structure that employs a single quantizer controlled by a digital feedback logic loop, the proposed SAR-ADC employs multiple quantizers for each conversion bit, clocked by an asynchronous ripple clock that is generated after each quantization. Hence, the sampling rate of the 6-bit ADC is limited only by the six delays of the Capacitive-DAC settling and each comparator's quantization delay, as the digital logic delay is eliminated. Measurement results of the 40 nm-CMOS SAR-ADC achieves a peak SNDR of 32.9 dB and 30.5 dB, at 1 GS/s and 1.25 GS/s, consuming 5.28 mW and 6.08 mW, leading to a FoM of 148 fJ/conv-step and 178 fJ/conv-step, respectively, in a core area less than 170 um by 85 um.","Delay,
Quantization,
Clocks,
Computer architecture,
Capacitors,
Capacitance,
Calibration"
Multiobjective Evolutionary Algorithms in Aeronautical and Aerospace Engineering,"Nowadays, the solution of multiobjective optimization problems in aeronautical and aerospace engineering has become a standard practice. These two fields offer highly complex search spaces with different sources of difficulty, which are amenable to the use of alternative search techniques such as metaheuristics, since they require little domain information to operate. From the several metaheuristics available, multiobjective evolutionary algorithms (MOEAs) have become particularly popular, mainly because of their availability, ease of use, and flexibility. This paper presents a taxonomy and a comprehensive review of applications of MOEAs in aeronautical and aerospace design problems. The review includes both the characteristics of the specific MOEA adopted in each case, as well as the features of the problems being solved with them. The advantages and disadvantages of each type of approach are also briefly addressed. We also provide a set of general guidelines for using and designing MOEAs for aeronautical and aerospace engineering problems. In the final part of the paper, we provide some potential paths for future research, which we consider promising within this area.","Optimization,
Aerospace engineering,
Computational modeling,
Evolutionary computation,
Vectors,
Analytical models,
Computational fluid dynamics"
"Slime Mold Solves Maze in One Pass, Assisted by Gradient of Chemo-Attractants","Plasmodium of Physarum polycephalum is a large cell, visible by unaided eye, which exhibits sophisticated patterns of foraging behaviour. The plasmodium's behaviour is well interpreted in terms of computation, where data are spatially extended configurations of nutrients and obstacles, and results of computation are networks of protoplasmic tubes formed by the plasmodium. In laboratory experiments and numerical simulation we show that if plasmodium of P. polycephalum is inoculated in a maze's peripheral channel and an oat flake (source of attractants) in a the maze's central chamber then the plasmodium grows toward target oat flake and connects the flake with the site of original inoculation with a pronounced protoplasmic tube. The protoplasmic tube represents a path in the maze. The plasmodium solves maze in one pass because it is assisted by a gradient of chemo-attractants propagating from the target oat flake.",
Vehicle Detection in Aerial Surveillance Using Dynamic Bayesian Networks,"We present an automatic vehicle detection system for aerial surveillance in this paper. In this system, we escape from the stereotype and existing frameworks of vehicle detection in aerial surveillance, which are either region based or sliding window based. We design a pixelwise classification method for vehicle detection. The novelty lies in the fact that, in spite of performing pixelwise classification, relations among neighboring pixels in a region are preserved in the feature extraction process. We consider features including vehicle colors and local features. For vehicle color extraction, we utilize a color transform to separate vehicle colors and nonvehicle colors effectively. For edge detection, we apply moment preserving to adjust the thresholds of the Canny edge detector automatically, which increases the adaptability and the accuracy for detection in various aerial images. Afterward, a dynamic Bayesian network (DBN) is constructed for the classification purpose. We convert regional local features into quantitative observations that can be referenced when applying pixelwise classification via DBN. Experiments were conducted on a wide variety of aerial videos. The results demonstrate flexibility and good generalization abilities of the proposed method on a challenging data set with aerial surveillance images taken at different heights and under different camera angles.","Image color analysis,
Vehicles,
Feature extraction,
Vehicle detection,
Image edge detection,
Training,
Surveillance"
Automated Residential Demand Response: Algorithmic Implications of Pricing Models,"Smart energy management is an important problem in Smart Grid network, and demand response (DR) is one of the key enabling technologies. If each home uses automated demand response which would opportunistically schedule devices that are flexible to run at any time in a large time window, towards the slots with lower electricity prices, peaks at these slots may happen. We denote such peaks as rebound peaks. We address the potential rebound peak problems of automated DR algorithms, and provide possible solutions. We illustrate why a rebound peak is possible via the insights we obtain from the optimal automated DR algorithm. We show that if the utility electricity supply cost is assumed to be a homogeneous function in the energy consumption over a certain time span, a system of multiple homes and utility company has the lowest total electricity supply cost if the electricity consumption from all the homes is flat over the time span. We study multiple approaches to reduce the rebound peak, and accordingly propose algorithms for DR at each home. Effectiveness of the approaches is verified by numerical results.",
Generation of Propagating Bessel Beams Using Leaky-Wave Modes,"The generation of Bessel beams using a leaky radial waveguide is presented. The radial waveguide consists of a capacitive sheet over a ground plane. It supports an azimuthally invariant leaky-wave mode whose normal electric-field component is a truncated, zeroth-order Bessel function. The annular spectrum and nondiffractive extent of the Bessel beam is clearly linked to the complex wavenumber of the leaky-wave mode. The fields inside the radial waveguide are derived using classical vector potential techniques. A vector approach is employed to avoid paraxial approximations of earlier works and the associated limitations on shaping the Bessel beam. Design rules are provided to synthesize a desired propagating Bessel beam. A simple coaxial feed is proposed for the radial waveguide and its input impedance is derived analytically. The analytical results are also validated numerically. The proposed structure and design procedure can be used for generating arbitrary zeroth-order propagating Bessel beams at microwave and millimeter-wave frequencies.",
"An Energy-Efficient, Adiabatic Electrode Stimulator With Inductive Energy Recycling and Feedback Current Regulation","In this paper, we present a novel energy-efficient electrode stimulator. Our stimulator uses inductive storage and recycling of energy in a dynamic power supply. This supply drives an electrode in an adiabatic fashion such that energy consumption is minimized. It also utilizes a shunt current-sensor to monitor and regulate the current through the electrode via feedback, thus enabling flexible and safe stimulation. Since there are no explicit current sources or current limiters, wasteful energy dissipation across such elements is naturally avoided. The dynamic power supply allows efficient transfer of energy both to and from the electrode and is based on a DC-DC converter topology that we use in a bidirectional fashion in forward-buck or reverse-boost modes. In an exemplary electrode implementation intended for neural stimulation, we show how the stimulator combines the efficiency of voltage control and the safety and accuracy of current control in a single low-power integrated-circuit built in a standard .35 μm CMOS process. This stimulator achieves a 2x-3x reduction in energy consumption as compared to a conventional current-source-based stimulator operating from a fixed power supply. We perform a theoretical analysis of the energy efficiency that is in accord with experimental measurements. This theoretical analysis reveals that further improvements in energy efficiency may be achievable with better implementations in the future. Our electrode stimulator could be widely useful for neural, cardiac, retinal, cochlear, muscular and other biomedical implants where low power operation is important.","Electrodes,
Power supplies,
Switches,
Voltage control,
Inductors,
Resistance,
Capacitors"
A Unified Framework for Key Agreement Over Wireless Fading Channels,"The problem of key generation over wireless fading channels is investigated. First, a joint source-channel approach that combines existing source and channel models for key agreement over wireless fading channels is developed. It is shown that, in general, to fully exploit the resources provided by time-varying channel gains, one needs to combine both the channel model, in which Alice sends a key to Bob over a wireless channel, and the source model, in which Alice and Bob generate a key by exploiting the correlated observations obtained from the wireless fading channel. Asymptotic analyses suggest that in the long coherence time regime, the channel model is asymptotically optimal. On the other hand, in the high power regime, the source model is asymptotically optimal. Second, the framework is extended to the scenario with an active attacker. Assuming that the goal of the attacker is to minimize the key rate that can be generated using the proposed protocol and the attacker will employ such an attack strategy, the attacker's optimal attack strategy is identified and the key rate under this attack model is characterized.",
TSV Redundancy: Architecture and Design Issues in 3-D IC,"3-D technology provides many benefits including high density, high bandwidth, low-power, and small form-factor. Through Silicon Via (TSV), which provides communication links for dies in vertical direction, is a critical design issue in 3-D integration. Just like other components, the fabrication and bonding of TSVs can fail. A failed TSV can severely increase the cost and decrease the yield as the number of dies to be stacked increases. A redundant TSV architecture with reasonable cost is proposed in this paper. Based on probabilistic models, some interesting findings are reported. First, the number of failed TSVs in a tier is usually less than 2 when the number of TSVs in a tier is less than 1000 and less than 5 when the number of TSVs in a tier is less than 10000. Assuming that there are at most 2-5 failed TSVs in a tier. With one redundant TSV allocated to one TSV block, our proposed structure leads to 90% and 95% recovery rates for TSV blocks of size 50 and 25, respectively. Finally, analysis on overall yield shows that the proposed design can successfully recover most of the failed chips and increase the yield of TSV to 99.4%.","Through-silicon vias,
Bonding,
Testing,
Receivers,
Computer architecture,
Redundancy"
Max-Min Optimal Joint Power Control and Distributed Beamforming for Two-Way Relay Networks Under Per-Node Power Constraints,"This paper deals with optimal joint user power control and relay distributed beamforming for two-way relay networks, where two end-users exchange information through multiple relays, each of which is assumed to have its own power constraint. The problem includes the design of the distributed beamformer at the relays and the power control scheme for the two end-users to optimize the network performance. Considering the overall two-way network performance, we maximize the lower signal-to-noise ratio (SNR) of the two communication links. For single-relay networks, this maximization problem is solved analytically. For multi-relay networks, we propose an iterative numerical algorithm to find the optimal solution. While the complexity of the optimal algorithm is too high for large networks, two sub-optimal algorithms with low complexity are also proposed, which are numerically shown to perform close to the optimal technique. It is also shown via simulation that for two-way networks with both single relay and multiple relays, proper user power control and relay distributed beamforming can significantly improve the network performance, especially when the power constraints of the two end-users in the networks are unbalanced. Our approach also improves the power efficiency of the network largely.","Relays,
Array signal processing,
Power control,
Transceivers,
Vectors,
Signal to noise ratio"
A Cooperative Approach to Traffic Congestion Detection With Complex Event Processing and VANET,"Currently, distributed traffic information systems have come up as one of the most important approaches for detecting traffic flow problems on a road. For that purpose, they usually make use of the location information that vehicles share among them through periodical messages that are transmitted across a vehicular ad hoc network (VANET). This paper puts forward an event-driven architecture (EDA) as a novel mechanism to get insight into VANET messages to detect different levels of traffic jams; furthermore, it also takes into account environmental data that come from external data sources, such as weather conditions. The proposed EDA has been developed through the complex-event-processing technology. Simulation tests show that the proposed mechanism can detect traffic congestions, which involve different numbers of lanes and lengths with short delay.","Vehicles,
Roads,
Sensors,
Proposals,
Meteorology,
Monitoring,
Ad hoc networks"
"3000-V 4.3-\hbox{m}\Omega \cdot \hbox{cm}^{2}
InAlN/GaN MOSHEMTs With AlGaN Back Barrier","This letter reports the fabrication of InAlN/GaN high-electron mobility transistors (HEMTs) with a three-terminal off-state breakdown voltage (BV) of 3000 V and a low specific on-resistance of 4.25 mΩ·cm2. To reduce the drain-to-source leakage current in these devices, an AlGaN back barrier has been used. The gate leakage current in these devices is in the ~10-10 A/mm range owing to the use of a SiO2 gate dielectric. This current level is more than six orders of magnitude lower than in Schottky-barrier HEMTs. The combination of an AlGaN back barrier, the high charge sheet density of InAlN/GaN HEMTs, and the low leakage due to the gate-dielectric layer allows for a figure-of-merit BV2/RON,SP of ~2.1 × 109 V2·Ω-1·cm-2.","Gallium nitride,
HEMTs,
MODFETs,
Aluminum gallium nitride,
Logic gates,
Leakage current,
Dielectrics"
Comparison of open-source cloud management platforms: OpenStack and OpenNebula,"Cloud management platforms may manage the resources provided by the infrastructure as a service (IaaS) cloud. With the rapid development of open-source cloud platforms, they have been widely used due to open and free, some of them can substitute commercial clouds. Some existed related works only concisely compare the basic features of open-source platforms, and not including some new released features. In this paper, we firstly present the function of OpenStack and OpenNebula briefly, and then compare them from provenance, architecture, hypervisors, security and other angles in detail. Moreover, we provide some deployment recommendations according to different user demands and platform characteristics.","Cloud computing,
Open source software,
Servers,
Computer architecture,
Virtual machine monitors,
Communities,
Educational institutions"
Estimating the aspect layout of object categories,In this work we seek to move away from the traditional paradigm for 2D object recognition whereby objects are identified in the image as 2D bounding boxes. We focus instead on: i) detecting objects; ii) identifying their 3D poses; iii) characterizing the geometrical and topological properties of the objects in terms of their aspect configurations in 3D. We call such characterization an object's aspect layout (see Fig. 1). We propose a new model for solving these problems in a joint fashion from a single image for object categories. Our model is constructed upon a novel framework based on conditional random fields with maximal margin parameter estimation. Extensive experiments are conducted to evaluate our model's performance in determining object pose and layout from images. We achieve superior viewpoint accuracy results on three public datasets and show extensive quantitative analysis to demonstrate the ability of accurately recovering the aspect layout of objects.,"Solid modeling,
Layout,
Training,
Estimation,
Shape,
Object recognition,
Design automation"
Anisotropic Impedance Surfaces for Linear to Circular Polarization Conversion,"Anisotropic impedance surfaces are employed as low-profile and broadband reflectors that convert orthogonal linear to right- and left-handed circular polarization respectively. By virtue of anisotropy, it is possible to independently control the reflection characteristics of two orthogonal linearly polarized incident plane waves and therefore achieve linear to circular polarization conversion. Equivalent circuits for anisotropic impedance surfaces with arbitrarily shaped elements are employed to demonstrate the operating principle and a design procedure is proposed. The proposed design procedure is demonstrated by means of an example involving a dipole array. A prototype is designed and its performance characteristics are evaluated. The 3-dB relative axial ratio bandwidth exceeds 60%, while low loss and angular stability are also reported. Numerical and experimental results on a fabricated prototype are presented to validate the synthesis and the performance.","Arrays,
Reflection,
Surface impedance,
Polarization,
Impedance,
Surface waves,
Admittance"
ERSA: Error Resilient System Architecture for Probabilistic Applications,"There is a growing concern about the increasing vulnerability of future computing systems to errors in the underlying hardware. Traditional redundancy techniques are expensive for designing energy-efficient systems that are resilient to high error rates. We present Error Resilient System Architecture (ERSA), a robust system architecture which targets emerging killer applications such as recognition, mining, and synthesis (RMS) with inherent error resilience, and ensures high degrees of resilience at low cost. Using the concept of configurable reliability, ERSA may also be adapted for general-purpose applications that are less resilient to errors (but at higher costs). While resilience of RMS applications to errors in low-order bits of data is well-known, execution of such applications on error-prone hardware significantly degrades output quality (due to high-order bit errors and crashes). ERSA achieves high error resilience to high-order bit errors and control flow errors (in addition to low-order bit errors) using a judicious combination of the following key ideas: 1) asymmetric reliability in many-core architectures; 2) error-resilient algorithms at the core of probabilistic applications; and 3) intelligent software optimizations. Error injection experiments on a multicore ERSA hardware prototype demonstrate that, even at very high error rates of 20 errors/flip-flop/108 cycles (equivalent to 25000 errors/core/s), ERSA maintains 90% or better accuracy of output results, together with minimal impact on execution time, for probabilistic applications such as K-Means clustering, LDPC decoding, and Bayesian network inference. In addition, we demonstrate the effectiveness of ERSA in tolerating high rates of static memory errors that are characteristic of emerging challenges related to SRAM Vccmin problems and erratic bit errors.","Probabilistic logic,
Resilience,
Hardware,
Instruction sets,
Reliability engineering,
Computer architecture"
A Hierarchical Model Incorporating Segmented Regions and Pixel Descriptors for Video Background Subtraction,"Background subtraction is important for detecting moving objects in videos. Currently, there are many approaches to performing background subtraction. However, they usually neglect the fact that the background images consist of different objects whose conditions may change frequently. In this paper, a novel hierarchical background model is proposed based on segmented background images. It first segments the background images into several regions by the mean-shift algorithm. Then, a hierarchical model, which consists of the region models and pixel models, is created. The region model is a kind of approximate Gaussian mixture model extracted from the histogram of a specific region. The pixel model is based on the cooccurrence of image variations described by histograms of oriented gradients of pixels in each region. Benefiting from the background segmentation, the region models and pixel models corresponding to different regions can be set to different parameters. The pixel descriptors are calculated only from neighboring pixels belonging to the same object. The experimental results are carried out with a video database to demonstrate the effectiveness, which is applied to both static and dynamic scenes by comparing it with some well-known background subtraction methods.","Histograms,
Image segmentation,
Computational modeling,
Adaptation models,
Training,
Informatics"
A Fusion Approach for Efficient Human Skin Detection,"A reliable human skin detection method that is adaptable to different human skin colors and illumination conditions is essential for better human skin segmentation. Even though different human skin-color detection solutions have been successfully applied, they are prone to false skin detection and are not able to cope with the variety of human skin colors across different ethnic. Moreover, existing methods require high computational cost. In this paper, we propose a novel human skin detection approach that combines a smoothed 2-D histogram and Gaussian model, for automatic human skin detection in color image(s). In our approach, an eye detector is used to refine the skin model for a specific person. The proposed approach reduces computational costs as no training is required, and it improves the accuracy of skin detection despite wide variation in ethnicity and illumination. To the best of our knowledge, this is the first method to employ fusion strategy for this purpose. Qualitative and quantitative results on three standard public datasets and a comparison with state-of-the-art methods have shown the effectiveness and robustness of the proposed approach.","Skin,
Image color analysis,
Humans,
Histograms,
Lighting,
Training,
Face"
An open source tool for simulation and supervision of underwater intervention missions,"This paper presents UWSim: a new software tool for visualization and simulation of underwater robotic missions. The software visualizes an underwater virtual scenario that can be configured using standard modeling software. Controllable underwater vehicles, surface vessels and robotic manipulators, as well as simulated sensors, can be added to the scene and accessed externally through network interfaces. This allows to easily integrate the simulation and visualization tool with existing control architectures, thus allowing hardware-in-the-loop simulations (HIL). UWSim has been successfully used for simulating the logics of underwater intervention missions and for reproducing real missions from the captured logs. The software is offered as open source, thus filling a gap in the underwater robotics community, where commercial simulators oriented to ROV pilot training predominate.","Vehicles,
Vehicle dynamics,
Robot sensing systems,
Mathematical model,
Cameras"
Co-Transduction for Shape Retrieval,"In this paper, we propose a new shape/object retrieval algorithm, namely, co-transduction. The performance of a retrieval system is critically decided by the accuracy of adopted similarity measures (distances or metrics). In shape/object retrieval, ideally, intraclass objects should have smaller distances than interclass objects. However, it is a difficult task to design an ideal metric to account for the large intraclass variation. Different types of measures may focus on different aspects of the objects: for example, measures computed based on contours and skeletons are often complementary to each other. Our goal is to develop an algorithm to fuse different similarity measures for robust shape retrieval through a semisupervised learning framework. We name our method co-transduction, which is inspired by the co-training algorithm. Given two similarity measures and a query shape, the algorithm iteratively retrieves the most similar shapes using one measure and assigns them to a pool for the other measure to do a re-ranking, and vice versa. Using co-transduction, we achieved an improved result of 97.72% (bull's-eye measure) on the MPEG-7 data set over the state-of-the-art performance. We also present an algorithm called tri-transduction to fuse multiple-input similarities, and it achieved 99.06% on the MPEG-7 data set. Our algorithm is general, and it can be directly applied on input similarity measures/metrics; it is not limited to object shape retrieval and can be applied to other tasks for ranking/retrieval.","Shape,
Databases,
Shape measurement,
Transform coding,
Training,
Robustness"
Tracking Mobile Users in Wireless Networks via Semi-Supervised Colocalization,"Recent years have witnessed the growing popularity of sensor and sensor-network technologies, supporting important practical applications. One of the fundamental issues is how to accurately locate a user with few labeled data in a wireless sensor network, where a major difficulty arises from the need to label large quantities of user location data, which in turn requires knowledge about the locations of signal transmitters or access points. To solve this problem, we have developed a novel machine learning-based approach that combines collaborative filtering with graph-based semi-supervised learning to learn both mobile users' locations and the locations of access points. Our framework exploits both labeled and unlabeled data from mobile devices and access points. In our two-phase solution, we first build a manifold-based model from a batch of labeled and unlabeled data in an offline training phase and then use a weighted k-nearest-neighbor method to localize a mobile client in an online localization phase. We extend the two-phase colocalization to an online and incremental model that can deal with labeled and unlabeled data that come sequentially and adapt to environmental changes. Finally, we embed an action model to the framework such that additional kinds of sensor signals can be utilized to further boost the performance of mobile tracking. Compared to other state-of-the-art systems, our framework has been shown to be more accurate while requiring less calibration effort in our experiments performed on three different testbeds.","Mobile handsets,
Manifolds,
Data models,
Laplace equations,
Robot sensing systems,
IEEE 802.11 Standards,
Trajectory"
Discriminating Joint Feature Analysis for Multimedia Data Understanding,"In this paper, we propose a novel semi-supervised feature analyzing framework for multimedia data understanding and apply it to three different applications: image annotation, video concept detection and 3-D motion data analysis. Our method is built upon two advancements of the state of the art: (1) l2, 1-norm regularized feature selection which can jointly select the most relevant features from all the data points. This feature selection approach was shown to be robust and efficient in literature as it considers the correlation between different features jointly when conducting feature selection; (2) manifold learning which analyzes the feature space by exploiting both labeled and unlabeled data. It is a widely used technique to extend many algorithms to semi-supervised scenarios for its capability of leveraging the manifold structure of multimedia data. The proposed method is able to learn a classifier for different applications by selecting the discriminating features closely related to the semantic concepts. The objective function of our method is non-smooth and difficult to solve, so we design an efficient iterative algorithm with fast convergence, thus making it applicable to practical applications. Extensive experiments on image annotation, video concept detection and 3-D motion data analysis are performed on different real-world data sets to demonstrate the effectiveness of our algorithm.",
An Analytical Charge Model for Double-Gate Tunnel FETs,"An analytical charge model for double gate (DG) tunnel FETs (TFETs) is proposed. By splitting the TFET into a series combination of a gated tunnel diode and a DG MOSFET, we solved the Poisson equation with matching boundary conditions to obtain a surface potential model for the DG TFET. Based on that, the source depletion charge and the mobile channel charge are derived. Comparisons between the proposed model and TCAD simulations show good agreements and suggest a 100/0 drain/source channel inversion charge partition. Terminal capacitances calculated based on the proposed charge model are also evaluated and show good agreement with TCAD simulations.","Tunneling,
FET circuits,
Capacitance"
RDDS: A Real-Time Data Distribution Service for Cyber-Physical Systems,"One of the primary requirements in many cyber-physical systems (CPS) is that the sensor data derived from the physical world should be disseminated in a timely and reliable manner to all interested collaborative entities. However, providing reliable and timely data dissemination services is especially challenging for CPS since they often operate in highly unpredictable environments. Existing network middleware has limitations in providing such services. In this paper, we present a novel publish/subscribe-based middleware architecture called Real-time Data Distribution Service (RDDS). In particular, we focus on two mechanisms of RDDS that enable timely and reliable sensor data dissemination under highly unpredictable CPS environments. First, we discuss the semantics-aware communication mechanism of RDDS that not only reduces the computation and communication overhead, but also enables the subscribers to access data in a timely and reliable manner when the network is slow or unstable. Further, we extend the semantics-aware communication mechanism to achieve robustness against unpredictable workloads by integrating a control-theoretic feedback controller at the publishers and a queueing-theoretic predictor at the subscribers. This integrated control loop provides Quality-of-Service (QoS) guarantees by dynamically adjusting the accuracy of the sensor models. We demonstrate the viability of the proposed approach by implementing a prototype of RDDS. The evaluation results show that, compared to baseline approaches, RDDS achieves highly efficient and reliable sensor data dissemination as well as robustness against unpredictable workloads.","Quality of service,
Load modeling,
Data models,
Predictive models,
Real time systems,
Reliability,
Computational modeling"
Distance Based Thresholds for Cluster Head Selection in Wireless Sensor Networks,"Central to the cluster-based routing protocols is the cluster head (CH) selection procedure that allows even distribution of energy consumption among the sensors, and therefore prolonging the lifespan of a sensor network. We propose a distributed CH selection algorithm that takes into account the distances from sensors to a base station that optimally balances the energy consumption among the sensors. NS-2 simulations show that our proposed scheme outperforms existing algorithms in terms of the average node lifespan and the time to first node death.","Sensors,
Wireless sensor networks,
Energy consumption,
Protocols,
Clustering algorithms,
Energy dissipation,
Routing"
Review and Critique of Analytic Models of MOSFET Short-Channel Effects in Subthreshold,"This paper surveys, reviews, and critiques analytic models of MOSFET short-channel effects (SCEs) in subthreshold published over the past four decades. In the first half of this paper, the published models on SCEs are categorized into the following four main groups based on their approach: 1) charging sharing models; 2) empirical expressions; 3) polynomial potential models; and 4) analytic solutions to 2-D Poisson's equation. The strength and weakness of each approach are elaborated in terms of its physical soundness and predictive ability. A key development was the exponential dependence of SCE on channel length (L) , SCE ~ exp(-L/l0), leading to the introduction of scale length (l0). In the second half of this paper, the predictions of each analytic SCE model are examined by generic 2-D numerical simulations. In particular, the merit of each model is judged by its prediction on the scale length (l0) as a function of the thickness and dielectric constant (κ) of the gate insulator. Only one model, i.e., the generalized scale length model that treated the silicon and insulator regions as two distinct dielectric regions with shared boundary conditions, correctly predicted the MOSFET scale length under all dielectric constant and thickness conditions. A variation of the generalized scale length model applies to recent multiple-gate MOSFETs near the limit of scaling.","Mathematical model,
Analytical models,
Numerical models,
Logic gates,
MOSFET circuits,
Silicon,
Poisson equations"
Cardiac Motion and Deformation Recovery From MRI: A Review,"Magnetic resonance imaging (MRI) is a highly advanced and sophisticated imaging modality for cardiac motion tracking and analysis, capable of providing 3D analysis of global and regional cardiac function with great accuracy and reproducibility. In the past few years, numerous efforts have been devoted to cardiac motion recovery and deformation analysis from MR image sequences. Many approaches have been proposed for tracking cardiac motion and for computing deformation parameters and mechanical properties of the heart from a variety of cardiac MR imaging techniques. In this paper, an updated and critical review of cardiac motion tracking methods including major references and those proposed in the past ten years is provided. The MR imaging and analysis techniques surveyed are based on cine MRI, tagged MRI, phase contrast MRI, DENSE, and SENC. This paper can serve as a tutorial for new researchers entering the field.","Magnetic resonance imaging,
Tracking,
Deformable models,
Three dimensional displays,
Strain,
Tagging"
Human Pose Estimation and Activity Recognition From Multi-View Videos: Comparative Explorations of Recent Developments,"This paper presents a review and comparative study of recent multi-view approaches for human 3D pose estimation and activity recognition. We discuss the application domain of human pose estimation and activity recognition and the associated requirements, covering: advanced human–computer interaction (HCI), assisted living, gesture-based interactive games, intelligent driver assistance systems, movies, 3D TV and animation, physical therapy, autonomous mental development, smart environments, sport motion analysis, video surveillance, and video annotation. Next, we review and categorize recent approaches which have been proposed to comply with these requirements. We report a comparison of the most promising methods for multi-view human action recognition using two publicly available datasets: the INRIA Xmas Motion Acquisition Sequences (IXMAS) Multi-View Human Action Dataset, and the i3DPost Multi-View Human Action and Interaction Dataset. To compare the proposed methods, we give a qualitative assessment of methods which cannot be compared quantitatively, and analyze some prominent 3D pose estimation techniques for application, where not only the performed action needs to be identified but a more detailed description of the body pose and joint configuration. Finally, we discuss some of the shortcomings of multi-view camera setups and outline our thoughts on future directions of 3D body pose estimation and human action recognition.","Three dimensional displays,
Humans,
Estimation,
Solid modeling,
Data models,
Analytical models,
Biological system modeling"
Generating Private Recommendations Efficiently Using Homomorphic Encryption and Data Packing,"Recommender systems have become an important tool for personalization of online services. Generating recommendations in online services depends on privacy-sensitive data collected from the users. Traditional data protection mechanisms focus on access control and secure transmission, which provide security only against malicious third parties, but not the service provider. This creates a serious privacy risk for the users. In this paper, we aim to protect the private data against the service provider while preserving the functionality of the system. We propose encrypting private data and processing them under encryption to generate recommendations. By introducing a semitrusted third party and using data packing, we construct a highly efficient system that does not require the active participation of the user. We also present a comparison protocol, which is the first one to the best of our knowledge, that compares multiple values that are packed in one encryption. Conducted experiments show that this work opens a door to generate private recommendations in a privacy-preserving manner.","Vectors,
Encryption,
Privacy,
Collaboration,
Cryptographic protocols"
Accurate Model-Based Reconstruction Algorithm for Three-Dimensional Optoacoustic Tomography,"In many practical optoacoustic imaging implementations, dimensionality of the tomographic problem is commonly reduced into two dimensions or 1-D scanning geometries in order to simplify technical implementation, improve imaging speed or increase signal-to-noise ratio. However, this usually comes at a cost of significantly reduced quality of the tomographic data, out-of-plane image artifacts, and overall loss of image contrast and spatial resolution. Quantitative optoacoustic image reconstruction implies therefore collection of point 3-D (volumetric) data from as many locations around the object as possible. Here, we propose and validate an accurate model-based inversion algorithm for 3-D optoacoustic image reconstruction. Superior performance versus commonly-used backprojection inversion algorithms is showcased by numerical simulations and phantom experiments.","Image reconstruction,
Computational modeling,
Absorption,
Tomography,
Transducers,
Phantoms"
Synthesis of reversible circuits with minimal lines for large functions,"Reversible circuits are an emerging technology where all computations are performed in an invertible manner. Motivated by their promising applications, e.g. in the domain of quantum computation or in the low-power design, the synthesis of such circuits has been intensely studied. However, how to automatically realize reversible circuits with the minimal number of lines for large functions is an open research problem. In this paper, we propose a new synthesis approach which relies on concepts that are complementary to existing ones. While “conventional” function representations have been applied for synthesis so far (such as truth tables, ESOPs, BDDs), we exploit Quantum Multiple-valued Decision Diagrams (QMDDs) for this purpose. An algorithm is presented that performs transformations on this data-structure eventually leading to the desired circuit. Experimental results show the novelty of the proposed approach through enabling automatic synthesis of large reversible functions with the minimal number of circuit lines. Furthermore, the quantum cost of the resulting circuits is reduced by 50% on average compared to an existing state-of-the-art synthesis method.","Logic gates,
Boolean functions,
Quantum computing,
Data structures,
Measurement,
Transforms,
Polynomials"
Asymmetric Coding of Multi-View Video Plus Depth Based 3-D Video for View Rendering,"The recent years have witnessed three-dimensional (3-D) video technology to become increasingly popular, as it can provide high-quality and immersive experience to end users, where view rendering with depth-image-based rendering (DIBR) technique is employed to generate the virtual views. Distortions in depth map may induce geometry changes in the virtual views, and distortions in texture video may be propagated to the virtual views. Thus, effective compression of both texture videos and depth maps is important for 3-D video system. From the perspective of bit allocation, asymmetric coding of the texture videos and depth maps is an effective way to get the optimal solution of 3-D video compression and view rendering problems. In this paper, a novel asymmetric coding method of multi-view video plus depth (MVD) based 3-D video is proposed on purpose of providing high-quality view rendering. In the proposed method, two models are proposed to characterize view rendering distortion and binocular suppression in 3-D video. Then, an asymmetric coding method of MVD-based 3-D video is proposed by combining two models in encoding framework. Finally, a chrominance reconstruction algorithm is presented to achieve accurate reconstruction. Experimental results show that compared with other methods, the proposed method can obtain higher performance of view rendering under the total bitrate constraint. Moreover, the perceptual visual quality of 3-D video is almost unaffected with the proposed method.","Three dimensional displays,
Encoding,
Rendering (computer graphics),
Bit rate,
Visualization,
Materials,
Video coding"
A Control Strategy for Enhanced Operation of Inverter-Based Microgrids Under Transient Disturbances and Network Faults,"This paper proposes an enhanced control strategy for electronically coupled distributed energy resources that improves the performance of the host microgrid under network faults and transient disturbances. The proposed control strategy does not require controller mode switchings and enables the electronically coupled distributed energy resources to ride through network faults, irrespective of whether they take place within the host microgrid or impact the upstream grid. Moreover, the proposed control ensures acceptable power quality for the duration of the faults, which is an important feature for protection against certain classes of faults, as well as for sensitive loads. Further, the paper proposes a supplementary control loop that improves the microgrid post-fault recovery. The effectiveness of the proposed control strategy is demonstrated through a comprehensive set of simulation studies, conducted in the PSCAD/EMTDC software environment.","Voltage control,
Frequency control,
Transient analysis,
Phase locked loops,
Power conversion,
Voltage control,
Fault location,
Microgrids"
System Design Analysis of a 0.22-THz Sheet-Beam Traveling-Wave Tube Amplifier,"The primary constituents of a 0.22-terahertz (THz) sheet-beam traveling-wave tube (TWT) amplifier, composed of a staggered double grating array waveguide, have been designed for broadband THz operation (~ 30%) using the fundamental passband (TE-mode). Currently, we are looking into the possibility of a pulsed low-duty test of this device as a proof of principle (POP) and have been making efforts to construct the system. The optimally designed input coupler has ≤ 1 dB insertion loss at 0.22 THz with ~ 75 GHz (34%) 1-dB matching bandwidths. A thin mica RF window provides a coupling bandwidth spanning multiple octaves. The collector is designed to have a jog for collecting the spent beam along the RF path coupled to the output RF window. Computer simulations show that the collector hybridized with a WR-4 window has ~ 60 GHz matching bandwidth with ~ - 0.5&nbsp;dB insertion loss at 0.22 THz. The hybrid periodic permanent-magnet design combined with the quadrupole magnet (PPM-QM), intended for low-duty pulse operation in a proof-of-concept experiment, allows the elliptical sheet beam from an existing gun (25 : 1 aspect ratio) to unoptimized gun to have 73% beam transmission. The POP pulsed test is designed to be matched to our existing system, which will thereby tolerate beam transmission. However, a proper gun for the sheet-beam tunnel of the designed circuit will provide much better transmission. In our prior works, we successfully proved at W-band that the magnet design provided >; 99% beam transmission of a 10:1 aspect ratio sheet beam. Most of the TWT circuit components have been designed, and currently, a full simulation modeling effort is being conducted.",
GLISTR: Glioma Image Segmentation and Registration,"We present a generative approach for simultaneously registering a probabilistic atlas of a healthy population to brain magnetic resonance (MR) scans showing glioma and segmenting the scans into tumor as well as healthy tissue labels. The proposed method is based on the expectation maximization (EM) algorithm that incorporates a glioma growth model for atlas seeding, a process which modifies the original atlas into one with tumor and edema adapted to best match a given set of patient's images. The modified atlas is registered into the patient space and utilized for estimating the posterior probabilities of various tissue labels. EM iteratively refines the estimates of the posterior probabilities of tissue labels, the deformation field and the tumor growth model parameters. Hence, in addition to segmentation, the proposed method results in atlas registration and a low-dimensional description of the patient scans through estimation of tumor model parameters. We validate the method by automatically segmenting 10 MR scans and comparing the results to those produced by clinical experts and two state-of-the-art methods. The resulting segmentations of tumor and edema outperform the results of the reference methods, and achieve a similar accuracy from a second human rater. We additionally apply the method to 122 patients scans and report the estimated tumor model parameters and their relations with segmentation and registration results. Based on the results from this patient population, we construct a statistical atlas of the glioma by inverting the estimated deformation fields to warp the tumor segmentations of patients scans into a common space.","Tumors,
Image segmentation,
Brain modeling,
Mathematical model,
Equations,
Probabilistic logic,
Educational institutions"
Face Recognition Performance: Role of Demographic Information,"This paper studies the influence of demographics on the performance of face recognition algorithms. The recognition accuracies of six different face recognition algorithms (three commercial, two nontrainable, and one trainable) are computed on a large scale gallery that is partitioned so that each partition consists entirely of specific demographic cohorts. Eight total cohorts are isolated based on gender (male and female), race/ethnicity (Black, White, and Hispanic), and age group (18-30, 30-50, and 50-70 years old). Experimental results demonstrate that both commercial and the nontrainable algorithms consistently have lower matching accuracies on the same cohorts (females, Blacks, and age group 18-30) than the remaining cohorts within their demographic. Additional experiments investigate the impact of the demographic distribution in the training set on the performance of a trainable face recognition algorithm. We show that the matching accuracy for race/ethnicity and age cohorts can be improved by training exclusively on that specific cohort. Operationally, this leads to a scenario, called dynamic face matcher selection, where multiple face recognition algorithms (each trained on different demographic cohorts) are available for a biometric system operator to select based on the demographic information extracted from a probe image. This procedure should lead to improved face recognition accuracy in many intelligence and law enforcement face recognition scenarios. Finally, we show that an alternative to dynamic face matcher selection is to train face recognition algorithms on datasets that are evenly distributed across demographics, as this approach offers consistently high accuracy across all cohorts.","Face recognition,
Training,
Demographics,
Algorithm design and analysis,
Training data,
Cultural differences"
Efficient and Secure Wireless Communications for Advanced Metering Infrastructure in Smart Grids,"An experiment is carried out to measure the power consumption of households. The analysis on the real measurement data shows that the significant change of power consumption arrives in a Poisson manner. Based on this experiment, a novel wireless communication scheme is proposed for the advanced metering infrastructure (AMI) in smart grid that can significantly improve the spectrum efficiency. The main idea is to transmit only when a significant power consumption change occurs. On the other hand, the policy of transmitting only when change occurs may bring a security issue; i.e., an eavesdropper can monitor the daily life of the house owner, particularly the information of whether the owner is at home. Hence, a defense scheme is proposed to combat this vulnerability by adding artificial spoofing packets. It is shown by numerical results that the defense scheme can effectively prevent the security challenge.","Power demand,
Power measurement,
Current measurement,
Delay,
Time division multiple access,
Wireless communication,
Smart grids"
Seamless Formation and Robust Control of Distributed Generation Microgrids via Direct Voltage Control and Optimized Dynamic Power Sharing,"Seamless formation and robust control of distributed generation microgrids are essential requirements to facilitate powerful and flexible control infrastructure in future smart power grids. Motivated by this objective, this paper presents a control structure for microgrid converters based on direct-voltage control and optimized dynamic power sharing. The salient features of the proposed scheme are 1) minimum switching actions between grid-connected and isolated microgrids systems to minimize internal microgrid formation disturbances; 2) active damping control performance in the converter control voltage vector to effectively reject both voltage magnitude disturbances and power angle swings associated with mode transition and load disturbances; and 3) high bandwidth direct voltage control loop in both grid-connected and isolated microgrid modes to improve the dynamic response and disturbance rejection performance. Theoretical analysis and comparative experimental results are presented to validate the effectiveness of the proposed control scheme.","Voltage control,
Robustness,
Control systems,
Damping,
Power system dynamics,
Power conversion"
Enhancement-Mode Operation of Nanochannel Array (NCA) AlGaN/GaN HEMTs,"In this letter, enhancement-mode (E-mode) AlGaN/ GaN high electron mobility transistors (HEMTs) were demon- strated based on lateral scaling of the 2-D electron gas channel using nanochannel array (NCA) structure. The NCA structure consists of multiple parallel channels with nanoscale width defined by electron-beam lithography and dry etching. Because of the improved gate control from the channel sidewalls and partially relaxed piezoelectric polarization, the fabricated 2 μm-gate-length NCA-HEMT with a nanochannel width of 64 nm showed a thresh- old voltage of +0.6 V and a higher extrinsic transconductance of 123 mS/mm, compared to -1.6 V and 106 mS/mm for the conventional HEMT with μm-scale channel width. The scaling of threshold voltages, peak transconductance, and gate leakage as a function of the nanochannel width were investigated. Small-signal RF performance of NCA-HEMTs were characterized for the first time and compared with those of conventional HEMTs.","Gallium nitride,
MODFETs,
HEMTs,
Logic gates,
Aluminum gallium nitride,
Threshold voltage,
Transconductance"
Analysis of the switching speed limitation of wide band-gap devices in a phase-leg configuration,"Advanced power semiconductor devices, especially wide band-gap devices, have inherent capability for fast switching. However, due to the limitation of gate driver capability and the interaction between two devices in a phase-leg during switching transient (cross talk), the switching speed is slower than expected in practical use. This paper focuses on identifying the key limiting factors for switching speed. The results provide the basis for improving gate drivers, eliminating interference, and boosting switching speed. Based on the EPC2001 Gallium Nitride transistor, both simulation and experimental results verify that the limiting factors in the gate loop include the pull-up (-down) resistance of gate driver, rise (fall) time and amplitude of gate driver output voltage; among these the rise (fall) time plays the primary role. Another important limiting factor of device switching speed is the spurious gate voltage induced by cross talk between two switches in a phase-leg. This induced gate voltage is not only determined by the switch speed, but also depends on the gate loop impedance, junction capacitance, and operating conditions of the complementary device.","Logic gates,
Switches,
Transient analysis,
Resistance,
Switching circuits,
Photonic band gap,
Gallium nitride"
Adaptive neighborhood selection for real-time surface normal estimation from organized point cloud data using integral images,"In this paper we present two real-time methods for estimating surface normals from organized point cloud data. The proposed algorithms use integral images to perform highly efficient border- and depth-dependent smoothing and covariance estimation. We show that this approach makes it possible to obtain robust surface normals from large point clouds at high frame rates and therefore, can be used in real-time computer vision algorithms that make use of Kinect-like data.","Smoothing methods,
Estimation,
Vectors,
Covariance matrix,
Noise,
Sensors,
Surface treatment"
High-Accuracy Reference-Free Ultrasonic Location Estimation,"This paper presents a novel reference-free ultrasonic indoor location system. Unlike most previous proposals, the mobile device (MD) determines its own position based only on ultrasonic signals received at a compact sensor array and sent by a fixed independent beacon. No radio frequency or wired timing reference signal is used. Furthermore, the system is privacy aware and one way in that the receive-only MD determines its own position based on ultrasonic signals received from fixed transmit-only beacons. The MD uses a novel hybrid angle of arrival (AoA)-time of flight (ToF) with timing lock algorithm to determine its location relative to the beacons with high accuracy. The algorithm utilizes an AoA-based location method to obtain an initial estimate of its own location. Based on this, it estimates the timing offsets (TOs) between the MD clock and the beacon transmissions. The average TO and the known periodicities of the beacon signals are then used to obtain a second more accurate MD location estimate via a ToF method. The system utilizes wideband spread spectrum ultrasonic signaling in order to achieve a high update rate and robustness to noise and reverberation. A prototype system was constructed, and the algorithm was implemented in software. The experimental results show that the method provides 3-D accuracy better than 9.5 cm in 99% of cases, an 80% accuracy improvement over the conventional AoA-only method.","Acoustics,
Estimation,
Receivers,
Timing,
Accuracy,
Noise,
Arrays"
Scaling social media applications into geo-distributed clouds,"Federation of geo-distributed cloud services is a trend in cloud computing which, by spanning multiple data centers at different geographical locations, can provide a cloud platform with much larger capacities. Such a geo-distributed cloud is ideal for supporting large-scale social media streaming applications (e.g., YouTube-like sites) with dynamic contents and demands, owing to its abundant on-demand storage/bandwidth capacities and geographical proximity to different groups of users. Although promising, its realization presents challenges on how to efficiently store and migrate contents among different cloud sites (i.e. data centers), and to distribute user requests to the appropriate sites for timely responses at modest costs. These challenges escalate when we consider the persistently increasing contents and volatile user behaviors in a social media application. By exploiting social influences among users, this paper proposes efficient proactive algorithms for dynamic, optimal scaling of a social media application in a geo-distributed cloud. Our key contribution is an online content migration and request distribution algorithm with the following features: (1) future demand prediction by novelly characterizing social influences among the users in a simple but effective epidemic model; (2) oneshot optimal content migration and request distribution based on efficient optimization algorithms to address the predicted demand, and (3) a Δ(t)-step look-ahead mechanism to adjust the one-shot optimization results towards the offline optimum. We verify the effectiveness of our algorithm using solid theoretical analysis, as well as large-scale experiments under dynamic realistic settings on a home-built cloud platform.","Cloud computing,
Optimization,
Media,
Servers,
Streaming media,
Heuristic algorithms,
Algorithm design and analysis"
FCL: A general purpose library for collision and proximity queries,"We present a new collision and proximity library that integrates several techniques for fast and accurate collision checking and proximity computation. Our library is based on hierarchical representations and designed to perform multiple proximity queries on different model representations. The set of queries includes discrete collision detection, continuous collision detection, separation distance computation and penetration depth estimation. The input models may correspond to triangulated rigid or deformable models and articulated models. Moreover, FCL can perform probabilistic collision checking between noisy point clouds that are captured using cameras or LIDAR sensors. The main benefit of FCL lies in the fact that it provides a unified interface that can be used by various applications. Furthermore, its flexible architecture makes it easier to implement new algorithms within this framework. The runtime performance of the library is comparable to state of the art collision and proximity algorithms. We demonstrate its performance on synthetic datasets as well as motion planning and grasping computations performed using a two-armed mobile manipulation robot.","Deformable models,
Computational modeling,
Robots,
Collision avoidance,
Libraries,
Shape,
Charge coupled devices"
Side Channel: Bits over Interference,"Interference is a critical issue in wireless communications. In a typical multiple-user environment, different users may severely interfere with each other. Coordination among users therefore is an indispensable part for interference management in wireless networks. It is known that coordination among multiple nodes is a costly operation taking a significant amount of valuable communication resource. In this paper, we have an interesting observation that by generating intended patterns, some simultaneous transmissions, i.e., ""interference,” can be successfully decoded without degrading the effective throughput in original transmission. As such, an extra and ""free” coordination channel can be built. Based on this idea, we propose a DC-MAC to leverage this ""free” channel for efficient medium access in a multiple-user wireless network. We theoretically analyze the capacity of this channel under different environments with various modulation schemes. USRP2-based implementation experiments show that compared with the widely adopted CSMA, DC-MAC can improve the channel utilization efficiency by up to 250 percent.","Interference,
Wireless networks,
Receivers,
Channel capacity,
Synchronization,
Throughput,
Multiaccess communication"
Towards Optimal Electric Demand Management for Internet Data Centers,"Electricity cost is becoming a major portion of Internet data center (IDC)'s operation cost and large-scale IDCs are becoming important consumers of regional electricity markets. IDC's energy efficiency is gaining more attention by data center operators and electricity market operators. Effective IDC electric demand management solutions are eagerly sought by all stakeholders. In this paper, a mixed-integer programming model based IDC electric demand management solution is proposed, which integrates both the impacts of locational marginal electricity prices and power management capability of IDC itself. Dynamic voltage/frequency scaling of individual server, cluster server ON/OFF scheduling, and dynamic workload dispatching are optimized while complying with all the IDC system-wide and individual heterogeneous servers' operation constraints according to the IDC applications' temporal variant workload. Reduced electricity cost can be achieved together with guaranteed QoS requirement and reliability consideration by using the proposed model. World Cup '98 data is utilized to evaluate the effectiveness of the proposed solution. According to the experimental evaluation, electricity cost could be cut by more than 20% in a peak workload period and by more than 80% in a light workload period. Besides, more than 6% electricity cost could be cut by considering the impact of electricity price difference. Experimental results also reveal that higher QoS requirement and reliability consideration could result in higher electricity cost.","Servers,
Power demand,
Electricity,
Cooling,
Reliability,
Central Processing Unit,
Quality of service"
Manipulator Fault Diagnosis via Higher Order Sliding-Mode Observers,"A diagnostic scheme for actuator and sensor faults which can occur on a robot manipulator using a model-based fault diagnosis (FD) technique is addressed. With the proposed FD scheme, it is possible to detect a fault, which can occur on a specific component of the system. To detect actuator faults, higher order sliding-mode unknown input observers are proposed to provide the necessary analytical redundancy. The detection of sensor faults, instead, is made by relying on a generalized observer scheme. The observer input laws are designed according to two well-known second-order sliding-mode approaches: the so-called supertwisting and the suboptimal one. Both typologies of input laws allow to perform a satisfactory FD. The peculiarities of each input law of the observers are discussed. To make possible fault isolation, it is required that a single fault acts only on one component of the system at a time. If one knows that faults occurred only on actuators, then it is possible to isolate multiple simultaneous faults on actuators. The proposed approach is verified in simulation and experimentally on a COMAU SMART3-S2 robot manipulator.","Observers,
Actuators,
Robot sensing systems,
Manipulators,
Vectors,
Fault diagnosis"
Machine Learning in Financial Crisis Prediction: A Survey,"For financial institutions, the ability to predict or forecast business failures is crucial, as incorrect decisions can have direct financial consequences. Bankruptcy prediction and credit scoring are the two major research problems in the accounting and finance domain. In the literature, a number of models have been developed to predict whether borrowers are in danger of bankruptcy and whether they should be considered a good or bad credit risk. Since the 1990s, machine-learning techniques, such as neural networks and decision trees, have been studied extensively as tools for bankruptcy prediction and credit score modeling. This paper reviews 130 related journal papers from the period between 1995 and 2010, focusing on the development of state-of-the-art machine-learning techniques, including hybrid and ensemble classifiers. Related studies are compared in terms of classifier design, datasets, baselines, and other experimental factors. This paper presents the current achievements and limitations associated with the development of bankruptcy-prediction and credit-scoring models employing machine learning. We also provide suggestions for future research.","Training,
Predictive models,
Accuracy,
Neural networks,
Genetic algorithms,
Boosting"
TAHES: A Truthful Double Auction Mechanism for Heterogeneous Spectrums,"Auction is widely applied in wireless communication for spectrum allocation. Most of prior works have assumed that all spectrums are identical. In reality, however, spectrums provided by different owners have distinctive characteristics in both spacial and frequency domains. Spectrum availability also varies in different geo-locations. Furthermore, frequency diversity may cause non-identical conflict relationships among spectrum buyers since different frequencies have distinct communication ranges. Under such a scenario, existing spectrum auction schemes cannot provide truthfulness or efficiency. In this paper, we propose a Truthful double Auction mechanism for HEterogeneous Spectrum, called TAHES, which allows buyers to explicitly express their personalized preferences for heterogeneous spectrums and also addresses the problem of interference graph variation. We prove that TAHES has nice economic properties including truthfulness, individual rationality and budget balance. Results from extensive simulation studies demonstrate the truthfulness, effectiveness and efficiency of TAHES.","Interference,
Cost accounting,
Wireless communication,
Availability,
Vectors,
Pricing,
White spaces"
Classification of Remote Sensing Optical and LiDAR Data Using Extended Attribute Profiles,"Extended Attribute Profiles (EAPs), which are obtained by applying morphological attribute filters to an image in a multilevel architecture, can be used for the characterization of the spatial characteristics of objects in a scene. EAPs have proved to be discriminant features when considered for thematic classification in remote sensing applications especially when dealing with very high resolution images. Altimeter data (such as LiDAR) can provide important information, which being complementary to the spectral one can be valuable for a better characterization of the surveyed scene. In this paper, we propose a technique performing a classification of the features extracted with EAPs computed on both optical and LiDAR images, leading to a fusion of the spectral, spatial and elevation data. The experiments were carried out on LiDAR data along either with a hyperspectral and a multispectral image acquired on a rural and urban area of the city of Trento (Italy), respectively. The classification accuracies obtained pointed out the effectiveness of the features extracted by EAPs on both optical and LiDAR data for classification.","Laser radar,
Optical imaging,
Feature extraction,
Hyperspectral imaging,
Optical sensors,
Vegetation"
Proof of Concept of a Dual-Band Circularly-Polarized RF MEMS Beam-Switching Reflectarray,"In this communication we propose the concept of a circularly polarized reflectarray (RA) antenna capable of independent beam-switching in both K and Ka bands. The RA unit cell comprises one microstrip ring per each operation frequency. Each ring is integrated with six equally spaced series RF micro electro-mechanical systems (RF MEMS) switches, which allows implementing the sequential rotation principle formerly used in circularly-polarized RA for single-frequency operation. A detailed design is proposed, considering the best relative arrangement of the rings corresponding to each frequency, the accurate modeling of the RF MEMS switches, and the full-wave simulation of the full array. The designed RA is implemented on a 4-inch quartz wafer and comprises 109 K-band and 124 Ka-band split-rings. Two prototypes representing two frozen states of the reconfigurable antenna are fabricated and measured. The designed RA can provide
±
120
∘
progressive phase difference in both operation bands exhibiting beam switching to
±
35
∘
and
±
24
∘
off the broad-side in K and Ka bands respectively. The performance of the designed antenna is verified by the agreement of the measured and simulated radiation patterns.","Reflection,
Radio frequency,
Micromechanical devices,
Microswitches,
Antenna measurements,
Integrated circuit modeling,
Reflector antennas"
Autocalibration and Recurrent Adaptation: Towards a Plug and Play Online ERD-BCI,"System calibration and user training are essential for operating motor imagery based brain-computer interface (BCI) systems. These steps are often unintuitive and tedious for the user, and do not necessarily lead to a satisfactory level of control. We present an Adaptive BCI framework that provides feedback after only minutes of autocalibration in a two-class BCI setup. During operation, the system recurrently reselects only one out of six predefined logarithmic bandpower features (10-13 and 16-24 Hz from Laplacian derivations over C3, Cz, and C4), specifically, the feature that exhibits maximum discriminability. The system then retrains a linear discriminant analysis classifier on all available data and updates the online paradigm with the new model. Every retraining step is preceded by an online outlier rejection. Operating the system requires no engineering knowledge other than connecting the user and starting the system. In a supporting study, ten out of twelve novice users reached a criterion level of above 70% accuracy in one to three sessions (10-80 min online time) of training, with a median accuracy of 80.2 11.3% in the last session. We consider the presented system a positive first step towards fully autocalibrating motor imagery BCIs.","Accuracy,
Training,
Optimization,
Electroencephalography,
Brain modeling,
Laplace equations,
Particle measurements"
An Optimization of Allocation of Information Granularity in the Interpretation of Data Structures: Toward Granular Fuzzy Clustering,"Clustering forms one of the most visible conceptual and algorithmic framework of developing information granules. In spite of the algorithm being used, the representation of information granules-clusters is predominantly numeric (coming in the form of prototypes, partition matrices, dendrograms, etc.). In this paper, we consider a concept of granular prototypes that generalizes the numeric representation of the clusters and, in this way, helps capture more details about the data structure. By invoking the granulation-degranulation scheme, we design granular prototypes being reflective of the structure of data to a higher extent than the representation that is provided by their numeric counterparts (prototypes). The design is formulated as an optimization problem, which is guided by the coverage criterion, meaning that we maximize the number of data for which their granular realization includes the original data. The granularity of the prototypes themselves is treated as an important design asset; hence, its allocation to the individual prototypes is optimized so that the coverage criterion becomes maximized. With this regard, several schemes of optimal allocation of information granularity are investigated, where interval-valued prototypes are formed around the already produced numeric representatives. Experimental studies are provided in which the design of granular prototypes of interval format is discussed and characterized.","Prototypes,
Resource management,
Optimization,
Indexes,
Fuzzy sets,
Stress,
Clustering algorithms"
A New Framework for Distributed Detection With Conditionally Dependent Observations,"Distributed detection with conditionally dependent observations is known to be a challenging problem in decentralized inference. This paper attempts to make progress on this problem by proposing a new framework for distributed detection that builds on a hierarchical conditional independence model. Through the introduction of a hidden variable that induces conditional independence among the sensor observations, the proposed model unifies distributed detection with dependent or independent observations. This new framework allows us to identify several classes of distributed detection problems with dependent observations whose optimal decision rules resemble the ones for the independent case. The new framework induces a decoupling effect on the forms of the optimal local decision rules for these problems, much in the same way as the conditionally independent case. This is in sharp contrast to the general dependent case where the coupling of the forms of local sensor decision rules often renders the problem intractable. Such decoupling enables the use of, for example, the person-by-person optimization approach to find optimal local decision rules. Two classical examples in distributed detection with dependent observations are reexamined under this new framework: detection of a deterministic signal in dependent noises and detection of a random signal in independent noises.","Mathematical model,
Jamming,
Equations,
Human computer interaction,
Bayesian methods,
Random variables,
Testing"
A General Relaying Transmission Protocol for MIMO Secrecy Communications,"In this paper, we consider a secrecy relaying communication scenario where all nodes are equipped with multiple antennas. An eavesdropper has the access to the global channel state information (CSI), and all the other nodes only know the CSI not associated with the eavesdropper. A new secrecy transmission protocol is proposed, where the concept of interference alignment is combined with cooperative jamming to ensure that artificial noise from transmitters can be aligned at the destination, but not at the eavesdropper due to the randomness of wireless channels. Analytical results, such as ergodic secrecy rate and outage probability, are developed, from which more insightful understanding of the proposed protocol, such as multiplexing and diversity gains, can be obtained. A few special cases, where outage probability cannot be decreased to zero regardless of SNR, are also discussed. Simulation results are provided to demonstrate the performance of the proposed secrecy transmission protocol.","Relays,
Interference,
Protocols,
Signal to noise ratio,
Strontium,
Antennas"
Principal Visual Word Discovery for Automatic License Plate Detection,"License plates detection is widely considered a solved problem, with many systems already in operation. However, the existing algorithms or systems work well only under some controlled conditions. There are still many challenges for license plate detection in an open environment, such as various observation angles, background clutter, scale changes, multiple plates, uneven illumination, and so on. In this paper, we propose a novel scheme to automatically locate license plates by principal visual word (PVW), discovery and local feature matching. Observing that characters in different license plates are duplicates of each other, we bring in the idea of using the bag-of-words (BoW) model popularly applied in partial-duplicate image search. Unlike the classic BoW model, for each plate character, we automatically discover the PVW characterized with geometric context. Given a new image, the license plates are extracted by matching local features with PVW. Besides license plate detection, our approach can also be extended to the detection of logos and trademarks. Due to the invariance virtue of scale-invariant feature transform feature, our method can adaptively deal with various changes in the license plates, such as rotation, scaling, illumination, etc. Promising results of the proposed approach are demonstrated with an experimental study in license plate detection.","Licenses,
Visualization,
Feature extraction,
Image color analysis,
Image edge detection,
Lighting,
Training"
Temperature-Dependent Characteristics of SiC Devices: Performance Evaluation and Loss Calculation,"Silicon Carbide (SiC) devices have obvious advantages compared with conventional Si devices, and especially so at high temperatures. This paper aims at developing a method for the characterization of SiC JFET conduction and switching losses at high temperatures as well as the calculation of semiconductor losses in SiC JFET-based converters. To this end, the steady-state performance of SiC JFET and Schottky diodes at different temperatures is studied, and an improved conduction loss evaluation is proposed considering the bidirectional conduction paths of the JFET. Specifically, a SiC JFET bridge test bed is built to measure the switching losses at different temperatures with and without antiparallel diodes, where experimental results show that using SiC Schottky diodes in antiparallel eliminates the reverse recovery of the JFET body diode, improving the switching behavior and reducing the losses of the devices. Further, these test results are used to estimate the losses of a 10-kW ac-dc-ac converter, which shows that the use of Schottky diodes as freewheeling devices helps reduce both conduction and switching losses, presenting an even greater reduction at higher operating temperatures.",
Performance Analysis of Hybrid Relay Selection in Cooperative Wireless Systems,"The hybrid relay selection (HRS) scheme, which adaptively chooses amplify-and-forward (AF) and decode-and-forward (DF) protocols based on the decoding results at the relay, is very effective to achieve robust performance in wireless relay networks. This paper analyzes the frame error rate (FER) of the HRS scheme in general wireless relay networks without and with utilizing error control coding at the source node. We first develop an improved signal-to-noise ratio (SNR) threshold-based FER approximation model. Then, we derive an analytical average FER expression as well as a high SNR asymptotic expression for the HRS scheme and generalize to other relaying schemes. Simulation results exhibit an excellent agreement with the theoretical analysis, which validates the derived FER expressions.","Signal to noise ratio,
Relays,
Approximation methods,
Fading,
Diversity reception,
Wireless communication,
Protocols"
The Action Similarity Labeling Challenge,"Recognizing actions in videos is rapidly becoming a topic of much research. To facilitate the development of methods for action recognition, several video collections, along with benchmark protocols, have previously been proposed. In this paper, we present a novel video database, the “Action Similarity LAbeliNg” (ASLAN) database, along with benchmark protocols. The ASLAN set includes thousands of videos collected from the web, in over 400 complex action classes. Our benchmark protocols focus on action similarity (same/not-same), rather than action classification, and testing is performed on never-before-seen actions. We propose this data set and benchmark as a means for gaining a more principled understanding of what makes actions different or similar, rather than learning the properties of particular action classes. We present baseline results on our benchmark, and compare them to human performance. To promote further study of action similarity techniques, we make the ASLAN database, benchmarks, and descriptor encodings publicly available to the research community.","Videos,
Databases,
Benchmark testing,
YouTube,
Training,
Cameras"
Collaborative Fuzzy Clustering Algorithms: Some Refinements and Design Guidelines,"There are some variants of the widely used Fuzzy C-Means (FCM) algorithm that support clustering data distributed across different sites. Those methods have been studied under different names, like collaborative and parallel fuzzy clustering. In this study, we offer some augmentation of the two FCM-based clustering algorithms used to cluster distributed data by arriving at some constructive ways of determining essential parameters of the algorithms (including the number of clusters) and forming a set of systematically structured guidelines such as a selection of the specific algorithm depending on the nature of the data environment and the assumptions being made about the number of clusters. A thorough complexity analysis, including space, time, and communication aspects, is reported. A series of detailed numeric experiments is used to illustrate the main ideas discussed in the study.",
Violent flows: Real-time detection of violent crowd behavior,"Although surveillance video cameras are now widely used, their effectiveness is questionable. Here, we focus on the challenging task of monitoring crowded events for outbreaks of violence. Such scenes require a human surveyor to monitor multiple video screens, presenting crowds of people in a constantly changing sea of activity, and to identify signs of breaking violence early enough to alert help. With this in mind, we propose the following contributions: (1) We describe a novel approach to real-time detection of breaking violence in crowded scenes. Our method considers statistics of how flow-vector magnitudes change over time. These statistics, collected for short frame sequences, are represented using the VIolent Flows (ViF) descriptor. ViF descriptors are then classified as either violent or non-violent using linear SVM. (2) We present a unique data set of real-world surveillance videos, along with standard benchmarks designed to test both violent/non-violent classification, as well as real-time detection accuracy. Finally, (3) we provide empirical tests, comparing our method to state-of-the-art techniques, and demonstrating its effectiveness.","Benchmark testing,
Streaming media,
Real time systems,
Accuracy,
Databases,
Surveillance,
Support vector machines"
Coordinated Energy Cost Management of Distributed Internet Data Centers in Smart Grid,"This paper addresses the problem of electricity cost management for Internet service providers with a collection of spatially distributed data centers. As the demand on Internet services drastically increases in recent years, the electricity consumed by Internet data centers (IDCs) has been skyrocketing. While most existing research focuses on reducing electric energy consumption of IDCs at one specific location, the problem of reducing the total electricity cost has been overlooked. This is an important problem faced by service providers, especially in the present multi-electricity-market environment, where the price of electricity may exhibit temporal and spatial diversities. Further, for these service providers, guaranteeing the quality of service (i.e., service level objectives) such as service delay guarantees to the end users is of critical importance. This paper studies the problem of minimizing the total electricity cost under multiple electricity markets environment while guaranteeing the quality of service geared to the location diversity and time diversity of electricity price. The problem is modeled as a constrained mixed-integer programming and an efficient solution algorithm is proposed. Extensive evaluations based on real-world electricity price data for multiple IDC locations illustrate the efficiency and efficacy of our approach.","Electricity,
Servers,
Delay,
Smart grids,
Internet,
Portals,
Optimization"
HYMN: A Novel Hybrid Multi-Hop Routing Algorithm to Improve the Longevity of WSNs,"Power-aware routing in Wireless Sensor Networks (WSNs) is designed to adequately prolong the lifetime of severely resource-constrained ad hoc wireless sensor nodes}. Recent research has identified the energy hole problem in single sink-based WSNs, a characteristic of the many-to-one (convergecast) traffic patterns. In this paper, we propose HYbrid Multi-hop routiNg (HYMN) algorithm, which is a hybrid of the two contemporary multi-hop routing algorithm architectures, namely, flat multi-hop routing that utilizes efficient transmission distances, and hierarchical multi-hop routing algorithms that capitalizes on data aggregation. We provide rigorous mathematical analysis for HYMN-optimize it and model its power consumption. In addition, through extensive simulations, we demonstrate the effective performance of HYMN in terms of superior connectivity.","Wireless sensor networks,
Routing,
Power demand,
Energy consumption,
Algorithm design and analysis,
Mathematical model,
Wireless communication"
Waiting times in quality of experience for web based services,"A considerable share of applications such as web or e-mail browsing, online picture viewing and file downloads imply waiting times for their users, which is due to the turn-taking of information requests by the user and correspoding response times until each request is fulfilled. Thus, end-user quality perception in the context of interactive data services is dominated by waiting times; the longer the latter, the less satisfied the user becomes. As opposed to heavily researched multimedia experience, perception of waiting times is still not strongly explored in the context of Quality of Experience (QoE). This tutorial will contribute to closing this gap. In its first part, it addresses perception principles and discusses their applicability towards fundamental relationships between waiting times and resulting QoE. It then investigates to which extent the same relationships can also be used to describe QoE for more complex services such as web browsing. Finally, it discusses applications where waiting times determine QoE, amongst other factors. For example, the past shift from UDP media streaming to TCP media streaming (e.g. youtube.com) has extended the relevance of waiting times also to the domain of online video services. In particular, user-perceived quality suffers from initial delays when applications are launched, as well as from freezes during the delivery of the stream. These aspects, which have to be traded against each other to some extent, will be discussed mainly for HTTP video streaming in the last part of this tutorial.","Bandwidth,
Streaming media,
Web pages,
Humans,
Tutorials,
Psychology,
Delay"
Optimizing the Vehicle Routing Problem With Time Windows: A Discrete Particle Swarm Optimization Approach,"Vehicle routing problem with time windows (VRPTW) is a well-known NP-hard combinatorial optimization problem that is crucial for transportation and logistics systems. Even though the particle swarm optimization (PSO) algorithm is originally designed to solve continuous optimization problems, in this paper, we propose a set-based PSO to solve the discrete combinatorial optimization problem VRPTW (S-PSO-VRPTW). The general method of the S-PSO-VRPTW is to select an optimal subset out of the universal set by the use of the PSO framework. As the VRPTW can be defined as selecting an optimal subgraph out of the complete graph, the problem can be naturally solved by the proposed algorithm. The proposed S-PSO-VRPTW treats the discrete search space as an arc set of the complete graph that is defined by the nodes in the VRPTW and regards the candidate solution as a subset of arcs. Accordingly, the operators in the algorithm are defined on the set instead of the arithmetic operators in the original PSO algorithm. Besides, the process of position updating in the algorithm is constructive, during which the constraints of the VRPTW are considered and a time-oriented, nearest neighbor heuristic is used. A normalization method is introduced to handle the primary and secondary objectives of the VRPTW. The proposed S-PSO-VRPTW is tested on Solomon's benchmarks. Simulation results and comparisons illustrate the effectiveness and efficiency of the algorithm.","Vehicles,
Optimization,
Particle swarm optimization,
Genetic algorithms,
Routing,
Heuristic algorithms,
Algorithm design and analysis"
Year,,
Strong Diagnosability and Conditional Diagnosability of Augmented Cubes Under the Comparison Diagnosis Model,"The problem of fault diagnosis has been discussed widely, and the diagnosability of many well-known networks has been explored. Strong diagnosability, and conditional diagnosability are both novel measurements for evaluating reliability and fault tolerance of a system. In this paper, some useful sufficient conditions are proposed to determine strong diagnosability, and the conditional diagnosability of a system. We then apply them to show that an n-dimensional augmented cube AQn is strongly (2n -1)-diagnosable for n ≥ 5, and the conditional diagnosability of AQn is 6n - 17 for n ≥ 6. Our result demonstrates that the conditional diagnosability of AQn is about three times larger than the classical diagnosability.","Program processors,
Hypercubes,
Fault diagnosis,
Multiprocessing systems,
Very large scale integration"
Overlapping Cell Nuclei Segmentation Using a Spatially Adaptive Active Physical Model,"A method for the segmentation of overlapping nuclei is presented, which combines local characteristics of the nuclei boundary and a priori knowledge about the expected shape of the nuclei. A deformable model whose behavior is driven by physical principles is trained on images containing a single nuclei, and attributes of the shapes of the nuclei are expressed in terms of modal analysis. Based on the estimated modal distribution and driven by the image characteristics, we develop a framework to detect and describe the unknown nuclei boundaries in images containing two overlapping nuclei. The problem of the estimation of an accurate nucleus boundary in the overlapping areas is successfully addressed with the use of appropriate weight parameters that control the contribution of the image force in the total energy of the deformable model. The proposed method was evaluated using 152 images of conventional Pap smears, each containing two overlapping nuclei. Comparisons with other segmentation methods indicate that our method produces more accurate nuclei boundaries which are closer to the ground truth.","Deformable models,
Shape,
Mathematical model,
Training,
Force,
Image segmentation,
Transforms"
A Closed-Form Solution to Retinex with Nonlocal Texture Constraints,"We propose a method for intrinsic image decomposition based on retinex theory and texture analysis. While most previous methods approach this problem by analyzing local gradient properties, our technique additionally identifies distant pixels with the same reflectance through texture analysis, and uses these nonlocal reflectance constraints to significantly reduce ambiguity in decomposition. We formulate the decomposition problem as the minimization of a quadratic function which incorporates both the retinex constraint and our nonlocal texture constraint. This optimization can be solved in closed form with the standard conjugate gradient algorithm. Extensive experimentation with comparisons to previous techniques validate our method in terms of both decomposition accuracy and runtime efficiency.","Image color analysis,
Entropy,
Optimization,
Closed-form solutions,
Image decomposition,
Equations,
Lighting"
Mining Frequent Trajectory Patterns for Activity Monitoring Using Radio Frequency Tag Arrays,"Activity monitoring, a crucial task in many applications, is often conducted expensively using video cameras. Effectively monitoring a large field by analyzing images from multiple cameras remains a challenging issue. Other approaches generally require the tracking objects to attach special devices, which are infeasible in many scenarios. To address the issue, we propose to use RF tag arrays for activity monitoring, where data mining techniques play a critical role. The RFID technology provides an economically attractive solution due to the low cost of RF tags and readers. Another novelty of this design is that the tracking objects do not need to be equipped with any RF transmitters or receivers. By developing a practical fault-tolerant method, we offset the noise of RF tag data and mine frequent trajectory patterns as models of regular activities. Our empirical study using real RFID systems and data sets verifies the feasibility and the effectiveness of this design.","Radio frequency,
Trajectory,
Monitoring,
Radiofrequency identification,
Data mining,
Cameras,
Interference"
On Convergence of Differential Evolution Over a Class of Continuous Functions With Unique Global Optimum,"Differential evolution (DE) is arguably one of the most powerful stochastic real-parameter optimization algorithms of current interest. Since its inception in the mid 1990s, DE has been finding many successful applications in real-world optimization problems from diverse domains of science and engineering. This paper takes a first significant step toward the convergence analysis of a canonical DE (DE/rand/1/bin) algorithm. It first deduces a time-recursive relationship for the probability density function (PDF) of the trial solutions, taking into consideration the DE-type mutation, crossover, and selection mechanisms. Then, by applying the concepts of Lyapunov stability theorems, it shows that as time approaches infinity, the PDF of the trial solutions concentrates narrowly around the global optimum of the objective function, assuming the shape of a Dirac delta distribution. Asymptotic convergence behavior of the population PDF is established by constructing a Lyapunov functional based on the PDF and showing that it monotonically decreases with time. The analysis is applicable to a class of continuous and real-valued objective functions that possesses a unique global optimum (but may have multiple local optima). Theoretical results have been substantiated with relevant computer simulations.","Convergence,
Random variables,
Search problems,
Algorithm design and analysis,
Optimization,
Mathematical model,
Probability density function"
A Generic Optical Router Design for Photonic Network-on-Chips,"Photonic network-on-chip (NoC) architectures are emerging as a new paradigm to interconnect a large number of processing cores at chip level, meeting the pressing demand for extremely high bandwidth and low power consumption. Optical routers, which are typically composed of silicon waveguides and optical switches, play a key role in an on-chip photonic interconnection network. In this paper, we propose a micro-ring-resonator (MRR)-based, scalable, and non-blocking passive optical router design, namely the generic wavelength-routed optical router (GWOR). We first introduce the four 4 × 4 GWOR router structures and then show how to construct GWORs of larger sizes by using the proposed 4 × 4 GWORs as the primitive building blocks. The number of MRRs used in the proposed GWOR is the least among the existing passive router designs for the same network size. In addition, we show that the power loss experienced on GWORs is lower than other comparative designs. Furthermore, to improve the bandwidth and fault tolerance capability of the GWORs, the redundant GWOR (RGWOR) structure is presented. RGWOR can provide multiple routing paths between each pair of input-output ports by cascading different types of GWORs.","Optical switches,
Optical waveguides,
Routing,
Photonics,
Passive optical networks,
Optical resonators,
Wavelength assignment"
An Automatic Approach for Learning and Tuning Gaussian Interval Type-2 Fuzzy Membership Functions Applied to Lung CAD Classification System,"The potential of type-2 fuzzy sets to manage high levels of uncertainty in the subjective knowledge of experts or of numerical information has focused on control and pattern classification systems in recent years. One of the main challenges in designing a type-2 fuzzy logic system (FLS) is how to estimate the parameters of the type-2 fuzzy membership function (T2MF) and the footprint of uncertainty (FOU) from imperfect and noisy datasets. This paper presents an automatic approach to learn and tune Gaussian interval type-2 membership functions (IT2MFs) with application to multidimensional pattern classification problems. T2MFs and their FOUs are tuned according to the uncertainties in the training dataset by a combination of genetic algorithm (GA) and cross-validation techniques. In our GA-based approach, the structure of the chromosome has fewer genes than other GA methods, and chromosome initialization is more precise. The proposed approach addresses the application of the interval type-2 fuzzy logic system (IT2FLS) for the problem of nodule classification in a lung computer-aided detection system. The designed IT2FLS is compared with its type-1 fuzzy logic system (T1FLS) counterpart. The results demonstrate that the IT2FLS outperforms the T1FLS by more than 30% in terms of classification accuracy.","Genetic algorithms,
Tuning,
Uncertainty,
Training,
Fuzzy sets,
Pragmatics,
Biological cells"
Dictionary-Based Face Recognition Under Variable Lighting and Pose,"We present a face recognition algorithm based on simultaneous sparse approximations under varying illumination and pose. A dictionary is learned for each class based on given training examples which minimizes the representation error with a sparseness constraint. A novel test image is projected onto the span of the atoms in each learned dictionary. The resulting residual vectors are then used for classification. To handle variations in lighting conditions and pose, an image relighting technique based on pose-robust albedo estimation is used to generate multiple frontal images of the same person with variable lighting. As a result, the proposed algorithm has the ability to recognize human faces with high accuracy even when only a single or a very few images per person are provided for training. The efficiency of the proposed method is demonstrated using publicly available databases available databases and it is shown that this method is efficient and can perform significantly better than many competitive face recognition algorithms.","Dictionaries,
Face recognition,
Training,
Lighting,
Robustness"
A Nonuniform Sampler for Wideband Spectrally-Sparse Environments,"We present a wide bandwidth, compressed sensing based nonuniform sampling (NUS) system with a custom sample-and-hold chip designed to take advantage of a low average sampling rate. By sampling signals nonuniformly, the average sample rate can be more than a magnitude lower than the Nyquist rate, provided that these signals have a relatively low information content as measured by the sparsity of their spectrum. The hardware design combines a wideband Indium-Phosphide heterojunction bipolar transistor sample-and-hold with a commercial off-the-shelf analog-to-digital converter to digitize an 800 MHz to 2 GHz band (having 100 MHz of noncontiguous spectral content) at an average sample rate of 236 Ms/s. Signal reconstruction is performed via a nonlinear compressed sensing algorithm, and the challenges of developing an efficient implementation are discussed. The NUS system is a general purpose digital receiver. As an example of its real signal capabilities, measured bit-error-rate data for a GSM channel is presented, and comparisons to a conventional wideband 4.4 Gs/s ADC are made.","Wideband,
Receivers,
Integrated circuit modeling,
Analog-digital conversion,
Hardware,
Compressed sensing"
A Communication-Assisted Protection Strategy for Inverter-Based Medium-Voltage Microgrids,"This paper proposes a communication-assisted protection strategy implementable by commercially available microprocessor-based relays for the protection of medium-voltage microgrids. Even though the developed protection strategy benefits from communications, it offers a backup protection strategy to manage communication network failures. The paper also introduces the structure of a relay that enables the proposed protection strategy. Comprehensive simulation studies are carried out to verify the effectiveness of the proposed protection strategy under different fault scenarios, in the PSCAD/EMTDC software environment.","Circuit faults,
Relays,
Fault currents,
Medium voltage,
Fault detection,
Power system reliability"
A Survey and Taxonomy of Cyber Foraging of Mobile Devices,"With the ever-increasing advancement of mobile device technology and their pervasive usage, users expect to run their applications on mobile devices and get the same performance as if they used to run their applications on powerful non-mobile computers. There is a challenge though in that mobile devices deliver lower performance than traditional less-constrained and non-mobile computers because they are constrained by weight, size, and mobility in spite of all their advancements in recent years. One of the most common solutions that has ameliorated this performance disparity is cyber foraging, wherein nearby non-mobile computers called surrogates are utilized to run the whole or parts of applications on behalf of mobile devices. In this paper, we present a survey of cyber foraging as a solution to resolve the challenges of computing on resource-constrained mobile devices. We also explain the most notable cyber foraging systems and present a categorization of existing cyber foraging approaches considering their type of dynamicity, granularity, metrics used, surrogate types and scale, location of their decision maker unit, remoteness of execution, migration support, and their overheads.","Mobile handsets,
Resource management,
Taxonomy,
Servers,
Energy consumption,
Internet"
"Energy-Efficient Neuron, Synapse and STDP Integrated Circuits","Ultra-low energy biologically-inspired neuron and synapse integrated circuits are presented. The synapse includes a spike timing dependent plasticity (STDP) learning rule circuit. These circuits have been designed, fabricated and tested using a 90 nm CMOS process. Experimental measurements demonstrate proper operation. The neuron and the synapse with STDP circuits have an energy consumption of around 0.4 pJ per spike and synaptic operation respectively.","Neurons,
Timing,
Transconductance,
Transistors,
Integrated circuit modeling,
Capacitors"
"Interference Alignment and the Generalized Degrees of Freedom of the
X
Channel","We explore the capacity and generalized degrees of freedom (GDOF) of the two-user Gaussian X channel, i.e., a generalization of the two-user interference channel where there is an independent message from each transmitter to each receiver. There are three main results in this paper. First, we characterize the sum capacity of the deterministic X channel under a symmetric setting. Second, we characterize the GDOF of the Gaussian X channel under a similar symmetric model. Third. we extend the sum capacity characterization previously obtained for the Gaussian interference channel in the noisy interference regime to the Gaussian X channel. Specifically, we show that the Gaussian X channel has the same sum capacity as the underlying Gaussian interference channel in this regime.","Interference channels,
Receivers,
Transmitters,
Indexes,
Approximation methods,
Noise measurement"
Design of CMOS Power Amplifiers,"This paper describes the key technology and circuit design issues facing the design of an efficient linear RF CMOS power amplifier for modern communication standards incorporating high peak-to-average ratio signals. We show that most important limitations arise from the limited breakdown voltage of nanoscale CMOS devices and the large back-off requirements to achieve the required linearity, both of which result in poor average efficiency. Two fundamentally different approaches to tackle these problems are presented along with silicon prototype measurements. In the first approach, transformer power combining and bias-point optimization are used to increase the output power and linearity of the “analog” amplifier. In the second approach, a mixed-signal “digital” polar architecture is employed, wherein the amplitude modulation is formed through an RF DAC structure.","CMOS integrated circuits,
Transistors,
Substrates,
Logic gates,
CMOS technology,
Impedance,
Inductors"
Secure Data Aggregation in Wireless Sensor Networks,"In a large sensor network, in-network data aggregation significantly reduces the amount of communication and energy consumption. Recently, the research community has proposed a robust aggregation framework called synopsis diffusion which combines multipath routing schemes with duplicate-insensitive algorithms to accurately compute aggregates (e.g., predicate Count, Sum) in spite of message losses resulting from node and transmission failures. However, this aggregation framework does not address the problem of false subaggregate values contributed by compromised nodes resulting in large errors in the aggregate computed at the base station, which is the root node in the aggregation hierarchy. This is an important problem since sensor networks are highly vulnerable to node compromises due to the unattended nature of sensor nodes and the lack of tamper-resistant hardware. In this paper, we make the synopsis diffusion approach secure against attacks in which compromised nodes contribute false subaggregate values. In particular, we present a novel lightweight verification algorithm by which the base station can determine if the computed aggregate (predicate Count or Sum) includes any false contribution. Thorough theoretical analysis and extensive simulation study show that our algorithm outperforms other existing approaches. Irrespective of the network size, the per-node communication overhead in our algorithm is O(1).","Algorithm design and analysis,
Aggregates,
Base stations,
Wireless sensor networks,
Protocols,
Security,
Educational institutions"
A Reliable Transmission Protocol for ZigBee-Based Wireless Patient Monitoring,"Patient monitoring systems are gaining their importance as the fast-growing global elderly population increases demands for caretaking. These systems use wireless technologies to transmit vital signs for medical evaluation. In a multihop ZigBee network, the existing systems usually use broadcast or multicast schemes to increase the reliability of signals transmission; however, both the schemes lead to significantly higher network traffic and end-to-end transmission delay. In this paper, we present a reliable transmission protocol based on anycast routing for wireless patient monitoring. Our scheme automatically selects the closest data receiver in an anycast group as a destination to reduce the transmission latency as well as the control overhead. The new protocol also shortens the latency of path recovery by initiating route recovery from the intermediate routers of the original path. On the basis of a reliable transmission scheme, we implement a ZigBee device for fall monitoring, which integrates fall detection, indoor positioning, and ECG monitoring. When the triaxial accelerometer of the device detects a fall, the current position of the patient is transmitted to an emergency center through a ZigBee network. In order to clarify the situation of the fallen patient, 4-s ECG signals are also transmitted. Our transmission scheme ensures the successful transmission of these critical messages. The experimental results show that our scheme is fast and reliable. We also demonstrate that our devices can seamlessly integrate with the next generation technology of wireless wide area network, worldwide interoperability for microwave access, to achieve real-time patient monitoring.","Receivers,
Zigbee,
Reliability,
Routing,
Routing protocols,
Wireless communication"
Deep and Wide: Multiple Layers in Automatic Speech Recognition,"This paper reviews a line of research carried out over the last decade in speech recognition assisted by discriminatively trained, feedforward networks. The particular focus is on the use of multiple layers of processing preceding the hidden Markov model based decoding of word sequences. Emphasis is placed on the use of multiple streams of highly dimensioned layers, which have proven useful for this purpose. This paper ultimately concludes that while the deep processing structures can provide improvements for this genre, choice of features and the structure with which they are incorporated, including layer width, can also be significant factors.","Speech recognition,
Training,
Hidden Markov models,
Vocabulary,
Speech,
Acoustics,
Artificial neural networks"
Cooperative Key Generation in Wireless Networks,"The impact of relay nodes on the secret key generation via the physical layer resources is investigated. A novel relay-assisted strategy is proposed to improve the generated secret key rate. The main idea is to exploit the random channels associated with relay nodes in the network as additional random sources for the key generation. This approach is particularly useful when the channels between legitimate nodes change slowly. Four increasingly sophisticated yet more practical scenarios are studied, for which relay-assisted key generation protocols are proposed and are shown to be optimal or order-optimal in terms of the key rate. It is also shown that the multiplexing gain in the key rate scales linearly with the number of relays, which demonstrates that relay-assisted schemes substantially increase the key rate. This is in sharp contrast to scenarios with relays helping information transmission, in which the multiplexing gain does not scale with the number of relays. Furthermore, a cooperative scheme is also proposed in which relays help key generation but the generated keys are kept secure from these relays.","Relays,
Wireless communication,
Communication system security,
Training,
Fading,
Channel estimation,
Protocols"
Tumor Recognition in Wireless Capsule Endoscopy Images Using Textural Features and SVM-Based Feature Selection,"Tumor in digestive tract is a common disease and wireless capsule endoscopy (WCE) is a relatively new technology to examine diseases for digestive tract especially for small intestine. This paper addresses the problem of automatic recognition of tumor for WCE images. Candidate color texture feature that integrates uniform local binary pattern and wavelet is proposed to characterize WCE images. The proposed features are invariant to illumination change and describe multiresolution characteristics of WCE images. Two feature selection approaches based on support vector machine, sequential forward floating selection and recursive feature elimination, are further employed to refine the proposed features for improving the detection accuracy. Extensive experiments validate that the proposed computer-aided diagnosis system achieves a promising tumor recognition accuracy of 92.4% in WCE images on our collected data.",
Shape Engineering for Controlled Switching With Nanomagnet Logic,"We demonstrate that in circuits and systems that comprised of nanoscale magnets, magnet-shape-dependent switching properties can be used to perform Boolean logic. More specifically, by making magnets with slanted edges, we can shift the energy barrier of the device (i.e., so that it is not at a maximum when a device is magnetized along its geometrically hard axis). In clocked systems, we can leverage this barrier shift to make and or or gates that are not majority based. Advantages include reduced gate footprint and interconnect overhead as we eliminate one gate input. In this paper, we report and discuss micromagnetic simulations that illustrate how magnet shape can facilitate nonmajority-gate-based, reduced footprint logic; preliminary fabrication and testing results that illustrate that shape engineering can induce energy barrier shifts; and additional micromagnetic simulations that show other ways in which we might leverage shape in circuits made from nanoscale magnets.","Shape control,
Magnets,
Power engineering and energy,
Logic devices,
Logic circuits,
Energy barrier,
Micromagnetics,
Circuit simulation,
Logic testing,
Circuit testing"
An Adaptive Speed Sensorless Induction Motor Drive With Artificial Neural Network for Stability Enhancement,"An artificial neural network (ANN) based adaptive estimator is presented in this paper for the estimation of rotor speed in a sensorless vector-controlled induction motor (IM) drive. The model reference adaptive system (MRAS) is formed with instantaneous and steady state reactive power. Selection of reactive power as the functional candidate in MRAS automatically makes the system immune to the variation of stator resistance. Such adaptive system performs satisfactorily at very low speed. However, it is observed that an unstable region exists in the speed-torque domain during regeneration. In this work, ANN is applied to overcome such stability related problem. The proposed method is validated through computer simulation using MATLAB/SIMULINK. Sample results from a laboratory prototype (using dSPACE-1104) have confirmed the usefulness of the proposed estimator.","Artificial neural networks,
Reactive power,
Stability,
Induction motors,
Adaptation models,
Computational modeling"
Distributed algorithms for optimal power flow problem,"Optimal power flow (OPF) is an important problem for power generation and it is in general non-convex. With the employment of renewable energy, it will be desirable if OPF can be solved very efficiently so that its solution can be used in real time. With some special network structure, e.g. trees, the problem has been shown to have a zero duality gap and the convex dual problem yields the optimal solution. In this paper, we propose a primal and a dual algorithm to coordinate the smaller subproblems decomposed from the convexified OPF. We can arrange the subproblems to be solved sequentially and cumulatively in a central node or solved in parallel in distributed nodes. We test the algorithms on IEEE radial distribution test feeders, some random tree-structured networks, and the IEEE transmission system benchmarks. Simulation results show that the computation time can be improved dramatically with our algorithms over the centralized approach of solving the problem without decomposition, especially in tree-structured problems. The computation time grows linearly with the problem size with the cumulative approach while the distributed one can have size-independent computation time.","Protocols,
Algorithm design and analysis,
Cost function,
Optimized production technology,
Linear programming,
USA Councils"
Online Overvoltage Prevention Control of Photovoltaic Generators in Microgrids,"For grid-connected microgrids with high penetration of photovoltaic (PV) generation, overvoltage caused by reverse power flow is a major factor that limits PV power output. To tackle the challenge, this paper proposes a new online overvoltage prevention (OOP) control strategy to maintain PV terminal voltages within specified range while maximizing the PV energy yields. The proposed method is based on a precise active power limit prediction using the dynamic Thevenin equivalent. The active power output of PV array can be modulated in real time such that the voltage at a point of interconnection (POI) is always maintained within a specified range without triggering overvoltage protection. Simulation results using the IEEE 33-bus single-phase test system and IEEE 34-bus three-phase system have validated the effectiveness and accuracy of the proposed control method.","Voltage control,
Generators,
Voltage measurement,
Inverters,
Impedance,
Photovoltaic systems"
A General Framework of Multipopulation Methods With Clustering in Undetectable Dynamic Environments,"To solve dynamic optimization problems, multiple population methods are used to enhance the population diversity for an algorithm with the aim of maintaining multiple populations in different subareas in the fitness landscape. Many experimental studies have shown that locating and tracking multiple relatively good optima rather than a single global optimum is an effective idea in dynamic environments. However, several challenges need to be addressed when multipopulation methods are applied, e.g., how to create multiple populations, how to maintain them in different subareas, and how to deal with the situation where changes cannot be detected or predicted. To address these issues, this paper investigates a hierarchical clustering method to locate and track multiple optima for dynamic optimization problems. To deal with undetectable dynamic environments, this paper applies the random immigrants method without change detection based on a mechanism that can automatically reduce redundant individuals in the search space throughout the run. These methods are implemented into several research areas, including particle swarm optimization, genetic algorithm, and differential evolution. An experimental study is conducted based on the moving peaks benchmark to test the performance with several other algorithms from the literature. The experimental results show the efficiency of the clustering method for locating and tracking multiple optima in comparison with other algorithms based on multipopulation methods on the moving peaks benchmark.","Heuristic algorithms,
Clustering algorithms,
Change detection algorithms,
Optimization,
Particle swarm optimization,
Genetic algorithms,
Clustering methods"
Comparative Study With New Accuracy Metrics for Target Volume Contouring in PET Image Guided Radiation Therapy,"The impact of positron emission tomography (PET) on radiation therapy is held back by poor methods of defining functional volumes of interest. Many new software tools are being proposed for contouring target volumes but the different approaches are not adequately compared and their accuracy is poorly evaluated due to the ill-definition of ground truth. This paper compares the largest cohort to date of established, emerging and proposed PET contouring methods, in terms of accuracy and variability. We emphasize spatial accuracy and present a new metric that addresses the lack of unique ground truth. Thirty methods are used at 13 different institutions to contour functional volumes of interest in clinical PET/CT and a custom-built PET phantom representing typical problems in image guided radiotherapy. Contouring methods are grouped according to algorithmic type, level of interactivity and how they exploit structural information in hybrid images. Experiments reveal benefits of high levels of user interaction, as well as simultaneous visualization of CT images and PET gradients to guide interactive procedures. Method-wise evaluation identifies the danger of over-automation and the value of prior knowledge built into an algorithm.","Positron emission tomography,
Computed tomography,
Tumors,
Performance evaluation,
Image segmentation,
Imaging phantoms,
Human computer interaction,
Oncology"
"Research on mobile cloud computing: Review, trend and perspectives","Mobile Cloud Computing (MCC) which combines mobile computing and cloud computing, has become one of the industry buzz words and a major discussion thread in the IT world since 2009. As MCC is still at the early stage of development, it is necessary to grasp a thorough understanding of the technology in order to point out the direction of future research. With the latter aim, this paper presents a review on the background and principle of MCC, characteristics, recent research work, and future research trends. A brief account on the background of MCC: from mobile computing to cloud computing is presented and then followed with a discussion on characteristics and recent research work. It then analyses the features and infrastructure of mobile cloud computing. The rest of the paper analyses the challenges of mobile cloud computing, summary of some research projects related to this area, and points out promising future research directions.","Cloud computing,
Mobile communication,
Mobile computing,
Smart phones,
Servers"
Automatic Seizure Detection Using Wavelet Transform and SVM in Long-Term Intracranial EEG,"Automatic seizure detection is of great significance for epilepsy long-term monitoring, diagnosis, and rehabilitation, and it is the key to closed-loop brain stimulation. This paper presents a novel wavelet-based automatic seizure detection method with high sensitivity. The proposed method first conducts wavelet decomposition of multi-channel intracranial EEG (iEEG) with five scales, and selects three frequency bands of them for subsequent processing. Effective features are extracted, such as relative energy, relative amplitude, coefficient of variation and fluctuation index at the selected scales, and then these features are sent into the support vector machine for training and classification. Afterwards a postprocessing is applied on the raw classification results to obtain more accurate and stable results. Postprocessing includes smoothing, multi-channel decision fusion and collar technique. Its performance is evaluated on a large dataset of 509 h from 21 epileptic patients. Experiments show that the proposed method could achieve a sensitivity of 94.46% and a specificity of 95.26% with a false detection rate of 0.58/h for seizure detection in long-term iEEG.","Electroencephalography,
Support vector machines,
Sensitivity,
Feature extraction,
Discrete wavelet transforms,
Epilepsy"
Experiments on Cross-Language Attribute Detection and Phone Recognition With Minimal Target-Specific Training Data,"A state-of-the-art automatic speech recognition (ASR) system can often achieve high accuracy for most spoken languages of interest if a large amount of speech material can be collected and used to train a set of language-specific acoustic phone models. However, designing good ASR systems with little or no language-specific speech data for resource-limited languages is still a challenging research topic. As a consequence, there has been an increasing interest in exploring knowledge sharing among a large number of languages so that a universal set of acoustic phone units can be defined to work for multiple or even for all languages. This work aims at demonstrating that a recently proposed automatic speech attribute transcription framework can play a key role in designing language-universal acoustic models by sharing speech units among all target languages at the acoustic phonetic attribute level. The language-universal acoustic models are evaluated through phone recognition. It will be shown that good cross-language attribute detection and continuous phone recognition performance can be accomplished for “unseen” languages using minimal training data from the target languages to be recognized. Furthermore, a phone-based background model (PBM) approach will be presented to improve attribute detection accuracies.",
Limiting Factors to the Temperature Performance of THz Quantum Cascade Lasers Based on the Resonant-Phonon Depopulation Scheme,"We analyze the temperature performance of five terahertz (THz)-frequency quantum cascade lasers based on a three-quantum-well resonant-phonon depopulation design as a function of operating frequency in the 2.3-3.8-THz range. We find evidence that the device performance is limited by the interplay between two factors: 1) optical phonon scattering of thermal electrons, which dominates at shorter wavelengths, and 2) parasitic current, which dominates at longer wavelengths. We present a simple model that provides an accurate estimate of the parasitic current in these devices and predicts the dependence of the threshold current density on temperature.","Quantum cascade lasers,
Temperature,
Laser modes,
Phonons,
Temperature dependence"
Evolution of Optical Access Networks: Architectures and Capacity Upgrades,"Passive optical network (PON) is one of the most successful broadband access architectures being deployed worldwide. PONs provide high capacity, increased reach, and low-power consumption at a very reasonable cost, on par with the cost of DSL deployments today. This paper provides an overview of present and emerging PON technologies, and discusses PON's important role in the evolution of optical access from the architectural perspective. While describing the evolution of optical access architecture, we present two important integration options: optical+wireless access integration and metro+access integration. Potential PON capacity upgrades are discussed with special emphasis on achieving a seamless upgrade. We evaluate different PON evolution strategies in the context of next-generation PON, where gradual, demand-based migration demonstrates a number of significant benefits.","Passive optical networks,
Optical fibers,
Optical fiber cables,
Wavelength division multiplexing,
Broadband communication"
The Sampling Rate-Distortion Tradeoff for Sparsity Pattern Recovery in Compressed Sensing,"Recovery of the sparsity pattern (or support) of an unknown sparse vector from a limited number of noisy linear measurements is an important problem in compressed sensing. In the high-dimensional setting, it is known that recovery with a vanishing fraction of errors is impossible if the measurement rate and the per-sample signal-to-noise ratio (SNR) are finite constants, independent of the vector length. In this paper, it is shown that recovery with an arbitrarily small but constant fraction of errors is, however, possible, and that in some cases computationally simple estimators are near-optimal. Bounds on the measurement rate needed to attain a desired fraction of errors are given in terms of the SNR and various key parameters of the unknown vector for several different recovery algorithms. The tightness of the bounds, in a scaling sense, as a function of the SNR and the fraction of errors, is established by comparison with existing information-theoretic necessary bounds. Near optimality is shown for a wide variety of practically motivated signal models.",
A Negative Sequence Compensation Method Based on a Two-Phase Three-Wire Converter for a High-Speed Railway Traction Power Supply System,"This paper presents a negative sequence compensation system based on a novel two-phase three-wire converter to eliminate a negative sequence current for the high-speed railway traction power system with a three-phase V/V traction transformer. In this compensation system, the proposed two-phase three-wire converter is fed by two single-phase power sources formed with two step-down transformers connecting to the two feeder sections. The proposed converter contains three switch legs, one of which is connected to the common ground wire of two single-phase voltages. Hence, a switch leg is saved compared with two conventional single-phase converters, and the ratings of the power switches are not increased. In order to enhance the dynamic and steady-state performances of the compensation system, a compound control method composed of hysteresis control and dividing frequency control is presented. Simulation and experimental results are presented to demonstrate that the proposed compensator and its control strategy are very effective.","Switches,
Rail transportation,
Windings,
Topology,
Static VAr compensators,
Power system dynamics"
Microwave-Induced Thermoacoustic Imaging Model for Potential Breast Cancer Detection,"In this study, we develop a complete microwave-induced thermoacoustic imaging (TAI) model for potential breast cancer imaging application. Acoustic pressures generated by different breast tissue targets are investigated by finite-difference time-domain simulations of the entire TAI process including the feeding antenna, matching mechanism, fluidic environment, 3-D breast model, and acoustic transducer. Simulation results achieve quantitative relationships between the input microwave peak power and the resulting specific absorption rate as well as the output acoustic pressure. Microwave frequency dependence of the acoustic signals due to different breast tissues is established across a broadband frequency range (2.3-12 GHz), suggesting key advantages of spectroscopic TAI compare to TAI at a single frequency. Reconstructed thermoacoustic images are consistent with the modeling results. This model will contribute to design, optimization, and safety evaluation of microwave-induced TAI and spectroscopy.","Acoustics,
Microwave imaging,
Breast tissue,
Dielectrics,
Microwave theory and techniques,
Finite difference methods"
Sparse Approximation to the Eigensubspace for Discrimination,"Two-dimensional (2-D) image-matrix-based projection methods for feature extraction are widely used in many fields of computer vision and pattern recognition. In this paper, we propose a novel framework called sparse 2-D projections (S2DP) for image feature extraction. Different from the existing 2-D feature extraction methods, S2DP iteratively learns the sparse projection matrix by using elastic net regression and singular value decomposition. Theoretical analysis shows that the optimal sparse subspace approximates the eigensubspace obtained by solving the corresponding generalized eigenequation. With the S2DP framework, many 2-D projection methods can be easily extended to sparse cases. Moreover, when each row/column of the image matrix is regarded as an independent high-dimensional vector (1-D vector), it is proven that the vector-based eigensubspace is also approximated by the sparse subspace obtained by the same method used in this paper. Theoretical analysis shows that, when compared with the vector-based sparse projection learning methods, S2DP greatly saves both computation and memory costs. This property makes S2DP more tractable for real-world applications. Experiments on well-known face databases indicate the competitive performance of the proposed S2DP over some 2-D projection methods when facial expressions, lighting conditions, and time vary.","Feature extraction,
Vectors,
Sparse matrices,
Eigenvalues and eigenfunctions,
Manifolds,
Approximation methods,
Matrix decomposition"
Performance Analysis of PMIPv6-Based NEtwork MObility for Intelligent Transportation Systems,"While host mobility support for individual mobile hosts (MHs) has been widely investigated and developed over the past years, there has been relatively less attention to NEtwork MObility (NEMO). Since NEMO Basic Support (NEMO-BS) was developed, it has been the central pillar in Intelligent Transport Systems (ITS) communication architectures for maintaining the vehicle's Internet connectivity. As the vehicle moves around, it attaches to a new access network and is required to register a new address obtained from the new access network to a home agent (HA). This location update of NEMO-BS often results in unacceptable long handover latency and increased traffic load to the vehicle. To address these issues, in this paper, we introduce new NEMO support protocols, which rely on mobility service provisioning entities introduced in Proxy Mobile IPv6 (PMIPv6), as possible mobility support protocols for ITS. As a base protocol, we present PMIPv6-based NEMO (P-NEMO) to maintain the vehicle's Internet connectivity while moving and without participating in the location update management. In P-NEMO, the mobility management for the vehicle is supported by mobility service provisioning entities residing in a given PMIPv6 domain. To further improve handover performance, fast P-NEMO (FP-NEMO) has been developed as an extension protocol. FP-NEMO utilizes wireless L2 events to anticipate the vehicle's handovers. The mobility service provisioning entities prepare the vehicle's handover prior to the attachment of the vehicle to the new access network. Detailed handover procedures for P-NEMO and FP-NEMO are provided, and handover timing diagrams are presented to evaluate the performance of the proposed protocols. P-NEMO and FP-NEMO are compared with NEMO-BS in terms of traffic cost and handover latency.",
Binaural Localization of Multiple Sources in Reverberant and Noisy Environments,"Sound source localization from a binaural input is a challenging problem, particularly when multiple sources are active simultaneously and reverberation or background noise are present. In this work, we investigate a multi-source localization framework in which monaural source segregation is used as a mechanism to increase the robustness of azimuth estimates from a binaural input. We demonstrate performance improvement relative to binaural only methods assuming a known number of spatially stationary sources. We also propose a flexible azimuth-dependent model of binaural features that independently captures characteristics of the binaural setup and environmental conditions, allowing for adaptation to new environments or calibration to an unseen binaural setup. Results with both simulated and recorded impulse responses show that robust performance can be achieved with limited prior training.","Azimuth,
Noise measurement,
Reverberation,
Adaptation models,
Estimation,
Feature extraction,
Time frequency analysis"
Intraoperative Image-based Multiview 2D/3D Registration for Image-Guided Orthopaedic Surgery: Incorporation of Fiducial-Based C-Arm Tracking and GPU-Acceleration,"Intraoperative patient registration may significantly affect the outcome of image-guided surgery (IGS). Image-based registration approaches have several advantages over the currently dominant point-based direct contact methods and are used in some industry solutions in image-guided radiation therapy with fixed X-ray gantries. However, technical challenges including geometric calibration and computational cost have precluded their use with mobile C-arms for IGS. We propose a 2D/3D registration framework for intraoperative patient registration using a conventional mobile X-ray imager combining fiducial-based C-arm tracking and graphics processing unit (GPU)-acceleration. The two-stage framework 1) acquires X-ray images and estimates relative pose between the images using a custom-made in-image fiducial, and 2) estimates the patient pose using intensity-based 2D/3D registration. Experimental validations using a publicly available gold standard dataset, a plastic bone phantom and cadaveric specimens have been conducted. The mean target registration error (mTRE) was 0.34±0.04 mm (success rate: 100%, registration time: 14.2 s) for the phantom with two images 90° apart, and 0.99±0.41 mm (81%, 16.3 s) for the cadaveric specimen with images 58.5° apart. The experimental results showed the feasibility of the proposed registration framework as a practical alternative for IGS routines.","X-ray imaging,
Three dimensional displays,
Optimization,
Computed tomography,
Detectors,
Graphics processing unit,
Calibration"
Coupled Discriminant Analysis for Heterogeneous Face Recognition,"Coupled space learning is an effective framework for heterogeneous face recognition. In this paper, we propose a novel coupled discriminant analysis method to improve the heterogeneous face recognition performance. There are two main advantages of the proposed method. First, all samples from different modalities are used to represent the coupled projections, so that sufficient discriminative information could be extracted. Second, the locality information in kernel space is incorporated into the coupled discriminant analysis as a constraint to improve the generalization ability. In particular, two implementations of locality constraint in kernel space (LCKS)-based coupled discriminant analysis methods, namely LCKS-coupled discriminant analysis (LCKS-CDA) and LCKS-coupled spectral regression (LCKS-CSR), are presented. Extensive experiments on three cases of heterogeneous face matching (high versus low image resolution, digital photo versus video image, and visible light versus near infrared) validate the efficacy of the proposed method.","Face recognition,
Feature extraction,
Spectral analysis,
Image resolution"
Robust DT-CWT Watermarking for DIBR 3D Images,"The popularity of 3D content is on the rise since it provides an immersive experience to viewers. In this situation, depth-image-based rendering (DIBR) has taken on an important role in 3D technology due to its low bandwidth cost and ease of depth configuration. Noting that the viewer could record provided center view or synthesized views for illegal distribution, it is clear that copyright protection must be taken into account for the DIBR 3D content, including the possibility that one single view could be illegally distributed as 2D content. In this paper, we propose a robust watermarking scheme for DIBR 3D images by quantization on dual-tree complex wavelet transform (DT-CWT) coefficients with consideration of imperceptibility. To make the proposed scheme robust to DIBR process, two characteristics of DT-CWT are employed: approximate shift invariance and directional selectivity. We select certain coefficient sub-blocks and group the coefficient rows based on the properties of DIBR. On the extraction side, the threshold is carefully chosen with a low false positive rate. The simulation results show that the embedded watermark is stably extracted from the center view and the synthesized left and right views. In addition, even if the synthesized left and right views are distorted by general attacks, the watermark is successfully extracted. Furthermore, the proposed scheme is robust to pre-processing of the depth image and baseline adjusting, which are common processing on the DIBR system for better quality of 3D views.","Watermarking,
Quantization,
Robustness,
Discrete wavelet transforms,
PSNR,
Three dimensional displays"
Secure Network Coding for Wiretap Networks of Type II,"We consider the problem of securing a multicast network against a wiretapper that can eavesdrop on the packets on a limited number of network edges of its choice. We assume that the network employs network coding to simultaneously deliver the packets available at the source to all the destinations. We show that this problem can be looked at as a network generalization of the wiretap channel of type II introduced in a seminal paper by Ozarow and Wyner. In particular, we show that the transmitted information can be secured by using the Ozarow-Wyner approach of coset coding at the source on top of the existing network code. This way, we quickly and transparently recover some of the results available in the literature on secure network coding for wiretap networks. Moreover, we use this framework to derive new bounds on the code alphabet size that are independent of the network size, and provide algorithms for explicit construction of secure network codes. We also analyze the amount of information that can be leaked to the wiretapper as a function of the number of wiretapped edges.","Vectors,
Encoding,
Security,
Network coding,
Parity check codes,
Receivers,
Routing"
Real-time ECG monitoring and arrhythmia detection using Android-based mobile devices,We developed an application for Android™-based mobile devices that allows real-time electrocardiogram (ECG) monitoring and automated arrhythmia detection by analyzing ECG parameters. ECG data provided by pre-recorded files or acquired live by accessing a Shimmer™ sensor node via Bluetooth™ can be processed and evaluated. The application is based on the Pan-Tompkins algorithm for QRS-detection and contains further algorithm blocks to detect abnormal heartbeats. The algorithm was validated using the MIT-BIH Arrhythmia and MIT-BIH Supraventricular Arrhythmia databases. More than 99% of all QRS complexes were detected correctly by the algorithm. Overall sensitivity for abnormal beat detection was 89.5% with a specificity of 80.6%. The application is available for download and may be used for real-time ECG-monitoring on mobile devices.,"Electrocardiography,
Mobile handsets,
Databases,
Real-time systems,
Signal processing algorithms,
Monitoring,
Feature extraction"
Semi-Automated Road Detection From High Resolution Satellite Images by Directional Morphological Enhancement and Segmentation Techniques,"Extraction of map objects such roads, rivers and buildings from high resolution satellite imagery is an important task in many civilian and military applications. We present a semi-automatic approach for road detection that achieves high accuracy and efficiency. This method exploits the properties of road segments to develop customized operators to accurately derive the road segments. The customized operators include directional morphological enhancement, directional segmentation and thinning. We have systematically evaluated the algorithm on a variety of images from IKONOS, QuickBird, CARTOSAT-2A satellites and carefully compared it with the techniques presented in literature. The results demonstrate that the algorithm proposed is both accurate and efficient.","Roads,
Image segmentation,
Image resolution,
Satellites,
Noise,
Joining processes,
Software algorithms"
A Dual-Channel Time-Spread Echo Method for Audio Watermarking,"This work proposes a novel dual-channel time-spread echo method for audio watermarking, aiming to improve robustness and perceptual quality. At the embedding stage, the host audio signal is divided into two subsignals, which are considered to be signals obtained from two virtual audio channels. The watermarks are implanted into the two subsignals simultaneously. Then the subsignals embedded with watermarks are combined to form the watermarked signal. At the decoding stage, the watermarked signal is split up into two watermarked subsignals. The similarity of the cepstra corresponding to the watermarked subsignals is exploited to extract the embedded watermarks. Moreover, if a properly designed colored pseudonoise sequence is used, the large peaks of its auto-correlation function can be utilized to further enhance the performance of watermark extraction. Compared with the existing time-spread echo-based schemes, the proposed method is more robust to attacks and has higher imperceptibility. The effectiveness of our method is demonstrated by simulation results.","Watermarking,
Robustness,
Decoding,
Educational institutions,
Electronic mail,
Media"
Exploiting Data Fusion to Improve the Coverage of Wireless Sensor Networks,"Wireless sensor networks (WSNs) have been increasingly available for critical applications such as security surveillance and environmental monitoring. An important performance measure of such applications is sensing coverage that characterizes how well a sensing field is monitored by a network. Although advanced collaborative signal processing algorithms have been adopted by many existing WSNs, most previous analytical studies on sensing coverage are conducted based on overly simplistic sensing models (e.g., the disc model) that do not capture the stochastic nature of sensing. In this paper, we attempt to bridge this gap by exploring the fundamental limits of coverage based on stochastic data fusion models that fuse noisy measurements of multiple sensors. We derive the scaling laws between coverage, network density, and signal-to-noise ratio (SNR). We show that data fusion can significantly improve sensing coverage by exploiting the collaboration among sensors when several physical properties of the target signal are known. In particular, for signal path loss exponent of (typically between 2.0 and 5.0), ρf = O(ρd1-1/k, where ρf and ρd are the densities of uniformly deployed sensors that achieve full coverage under the fusion and disc models, respectively. Moreover, data fusion can also reduce network density for regularly deployed networks and mobile networks where mobile sensors can relocate to fill coverage holes. Our results help understand the limitations of the previous analytical results based on the disc model and provide key insights into the design of WSNs that adopt data fusion algorithms. Our analyses are verified through extensive simulations based on both synthetic data sets and data traces collected in a real deployment for vehicle detection.","Sensors,
Wireless sensor networks,
Data models,
Stochastic processes,
Analytical models,
Mobile communication,
Noise"
Human Gait Modeling Using a Genetic Fuzzy Finite State Machine,"Human gait modeling consists of studying the biomechanics of this human movement. Its importance lies in the fact that its analysis can help in the diagnosis of walking and movement disorders or rehabilitation programs, among other medical situations. Fuzzy finite state machines can be used to model the temporal evolution of this type of phenomenon. Nevertheless, the definition of details of the model in each particular case is a complex task for experts. In this paper, we present an automatic method to learn the model parameters that are based on the hybridization of fuzzy finite state machines and genetic algorithms leading to genetic fuzzy finite state machines. This new genetic fuzzy system automatically learns the fuzzy rules and membership functions of the fuzzy finite state machine, while an expert defines the possible states and allowed transitions. Our final goal is to obtain a specific model for each person's gait in such a way that it can generalize well with different gaits of the same person. The obtained model must become an accurate and human friendly linguistic description of this phenomenon, with the capability to identify the relevant phases of the process. A complete experimentation is developed to test the performance of the new proposal when dealing with datasets of 20 different people, comprising a detailed analysis of results, which shows the advantages of our proposal in comparison with some other classical and computational intelligence techniques.","Humans,
Pragmatics,
Mathematical model,
Foot,
Acceleration,
Fuzzy systems,
Computational modeling"
Defeating Primary User Emulation Attacks Using Belief Propagation in Cognitive Radio Networks,"Cognitive radio (CR) is a promising technology for future wireless spectrum allocation to improve the usage of the licensed bands. However, CR wireless networks are susceptible to various attacks and cannot offer efficient security. Primary user emulation (PUE) is one of the most serious attacks for CR networks, which can significantly increase the spectrum access failure probability. In this paper, we propose a defense strategy against the PUE attack in CR networks using belief propagation, which avoids the deployment of additional sensor networks and expensive hardware in the networks used in the existing literatures. In our proposed approach, each secondary user calculates the local function and the compatibility function, computes the messages, exchanges messages with the neighboring users, and calculates the beliefs until convergence. Then, the PUE attacker will be detected, and all the secondary users in the network will be notified in a broadcast way about the characteristics of the attacker's signal. Therefore, all SUs can avoid the PUE attacker's primary emulation signal in the future. Simulation results show that our proposed approach converges quickly, and is effective to detect the PUE attacker.","Belief propagation,
Cognitive radio,
Emulation,
Wireless networks,
Convergence,
Simulation"
Error Weighted Semi-Coupled Hidden Markov Model for Audio-Visual Emotion Recognition,"This paper presents an approach to the automatic recognition of human emotions from audio-visual bimodal signals using an error weighted semi-coupled hidden Markov model (EWSC-HMM). The proposed approach combines an SC-HMM with a state-based bimodal alignment strategy and a Bayesian classifier weighting scheme to obtain the optimal emotion recognition result based on audio-visual bimodal fusion. The state-based bimodal alignment strategy in SC-HMM is proposed to align the temporal relation between audio and visual streams. The Bayesian classifier weighting scheme is then adopted to explore the contributions of the SC-HMM-based classifiers for different audio-visual feature pairs in order to obtain the emotion recognition output. For performance evaluation, two databases are considered: the MHMC posed database and the SEMAINE naturalistic database. Experimental results show that the proposed approach not only outperforms other fusion-based bimodal emotion recognition methods for posed expressions but also provides satisfactory results for naturalistic expressions.","Hidden Markov models,
Emotion recognition,
Databases,
Visualization,
Speech,
Humans,
Correlation"
A Power Link Study of Wireless Non-Radiative Power Transfer Systems Using Resonant Shielded Loops,"This paper discusses the use of magnetically coupled resonators for midrange wireless non-radiative power transfer (WNPT). A quasi-static (circuit) model is developed to establish key measures of performance and to aid in design. The use of directly fed, resonant shielded loops for WNPT is also proposed for the first time. Two experimental WNPT systems employing shielded loops are reported. A comprehensive experimental study is performed, and the performance of the WNPT systems shows close agreement with analytical predictions and developed circuit models. With a single-turn system of loop radius 10.7 cm, power transfer efficiency of 41.8% is achieved at a loop separation of 35 cm (3.3 loop radii). When the number of turns is increased to ten, a power transfer efficiency of 36.5% is achieved at a loop separation of 56 cm (5.3 loop radii). Measured magnetic field levels in the vicinity of the WNPT systems are shown to closely agree with analytical field values.","Integrated circuit modeling,
Magnetic noise,
Feeds,
Magnetic shielding,
Magnetic separation,
Magnetic resonance"
Energy-efficient radio resource and power allocation for device-to-device communication underlaying cellular networks,"Device-to-device (D2D) communication underlaying cellular networks brings significant benefits to resource utilization, improving user's throughput and extending battery life of user equipments. However, the allocation of radio resources and power to D2D communication needs elaborate coordination, as D2D communication causes interference to cellular networks. In this paper, we propose a novel joint radio resource and power allocation scheme to improve the performance of the system in the uplink period. Energy efficiency is considered as our optimization objective since devices are handheld equipments with limited battery life. We formulate the the allocation problem as a reverse iterative combinatorial auction game. In the auction, radio resources occupied by cellular users are considered as bidders competing for D2D packages and their corresponding transmit power. We propose an algorithm to solve the allocation problem as an auction game. We also perform numerical simulations to prove the efficacy of the proposed algorithm.","resource allocation,
cellular radio,
iterative methods,
mobile handsets,
radiofrequency interference"
A Silicon-Based 3-D Hybrid Long-Range Plasmonic Waveguide for Nanophotonic Integration,"Decreasing the widths and thicknesses of thin metal stripes can effectively increase the propagation distance of long-range surface plasmon polaritons, but at the cost of significant reduction on the overall mode confinement, which fundamentally limits the packing density in nanophotonic integration. By utilizing the coupling between the dielectric waveguide and plasmonic modes, we propose a silicon-based 3-D hybrid long-range plasmonic waveguide that not only supports long-range propagation, but also has compact modal size. Our simulation result shows that a propagation distance of 696 μm with an ultrasmall modal area of 0.0013 μm2 can be simultaneously achieved at 1.55 μ m.","Electromagnetic waveguides,
Dielectrics,
Metals,
Silicon,
Films,
Plasmons,
Indexes"
Two-Way Relaying With Multi-Antenna Sources: Beamforming and Antenna Selection,"We propose and analyze two multiple-input-multiple-output (MIMO) two-way relaying schemes with an amplify-and-forward protocol in Nakagami-m fading channels, where multi-antenna sources communicate via a single-antenna relay. Specifically, we present a new framework for the comparative analysis of beamforming and antenna selection with nonidentical fading parameter m in the two source-relay links. To facilitate the comparison, we derive new exact, approximate, and asymptotic expressions for the sum symbol error rate (SSER) with M-ary phase-shift keying (M-PSK) and M-ary quadrature amplitude modulation (M-QAM). Based on the asymptotic SSER, we prove that beamforming and antenna selection have the same diversity order. The diversity order is dominated by the weaker source-relay link, which is determined by the product of the number of source antennas and the fading parameter. We proceed to characterize the fundamental difference between the two schemes in terms of their array gains and average signal-to-noise ratios (SNRs). To obtain further insights, we address the key question of “How to allocate the total transmit power such that the SSER is minimized?” Our answer is given in the form of new concise expressions for the power-allocation factor that optimally distributes the total transmit power between the sources and the relay. A pivotal conclusion is reached that antenna selection offers the same SSER as beamforming when the source in the weaker link is equipped with a single antenna.","Array signal processing,
Relays,
Fading,
Signal to noise ratio,
Transmitting antennas,
MIMO"
Voltage Asymmetry of Spin-Transfer Torques,"Experimentally, it is seen that the free magnetic layer of a spin torque transfer (STT) device experiences a larger in-plane torque when a negative (rather than positive) voltage is applied to the fixed layer. This is surprising because magnets do not have any intrinsic asymmetry. In this paper, we 1) provide a simple physical explanation, based on the polarization of fixed layer in the energy range of transport; 2) extend it to explain the asymmetric bias dependence of out-of-plane torque as observed in some of the experiments; and 3) propose an asymmetric STT structure that can lead to a significant difference in the in-plane torques exerted on two contacts, even if they are identical. This effect 3 has not been observed to our knowledge and if demonstrated can find important applications.","Phase change materials,
Torque,
Magnetic tunneling,
Insulators,
Frequency modulation,
Magnetic devices"
The Effect of Time on Gait Recognition Performance,"Many studies have shown that it is possible to recognize people by the way they walk. However, there are a number of covariate factors that affect recognition performance. The time between capturing the gallery and the probe has been reported to affect recognition the most. To date, no study has isolated the effect of time, irrespective of other covariates. Here, we present the first principled study that examines the effect of elapsed time on gait recognition. Using empirical evidence we show for the first time that elapsed time does not affect recognition significantly in the short-medium term. This finding challenges the existing view in the literature that time significantly affects gait recognition. We employ existing gait representations on a novel dataset captured specifically for this study. By controlling the clothing worn by the subjects and the environment, a Correct Classification Rate (CCR) of 95% has been achieved over the longest time period yet considered for gait on the largest ever temporal dataset. Our results show that gait can be used as a reliable biometric over time and at a distance if we were able to control all other factors such as clothing, footwear etc. We have also investigated the effect of different type of clothes, variations in speed and footwear on the recognition performance. The purpose of these experiments is to provide an indication of why previous studies (employing the same techniques as this study) have achieved significantly lower recognition performance over time. Our experimental results show that clothing and other covariates have been confused with elapsed time previously in the literature. We have demonstrated that clothing drastically affects the recognition performance regardless of elapsed time and significantly more than any of the other covariates that we have considered here.","Databases,
Footwear,
Probes,
Legged locomotion,
Cameras,
Entropy"
Noninvertible Minutia Cylinder-Code Representation,"Although several fingerprint template protection methods have been proposed in the literature, the problem is still unsolved, since enforcing nonreversibility tends to produce an excessive drop in accuracy. Furthermore, unlike fingerprint verification, whose performance is assessed today with public benchmarks and protocols, performance of template protection approaches is often evaluated in heterogeneous scenarios, thus making it very difficult to compare existing techniques. In this paper, we propose a novel protection technique for Minutia Cylinder-Code (MCC), which is a well-known local minutiae representation. A sophisticate algorithm is designed to reverse MCC (i.e., recovering original minutiae positions and angles). Systematic experimentations show that the new approach compares favorably with state-of-the-art methods in terms of accuracy and, at the same time, provides a good protection of minutiae information and is robust against masquerade attacks.","Fingerprint recognition,
Transforms,
Cryptography,
Feature extraction,
Pattern matching,
Robustness"
Practical radio environment mapping with geostatistics,"In this paper we present results from the first application of robust geostatistical modeling techniques to radio environment and coverage mapping of wireless networks. We perform our analysis of these methods with a case study mapping the coverage of a 2.5 GHz WiMax network at the University of Colorado, Boulder. Drawing from our experiences, we propose several new methods and extensions to basic geostatistical theory that are necessary for use in a radio mapping application. We also derive a set of best practices and discuss potential areas of future work. We find that this approach to radio environment mapping is feasible and produces maps that are more accurate and informative than both explicitly tuned path loss models and basic data fitting approaches.","Interpolation,
Educational institutions,
Loss measurement,
Predictive models,
Mathematical model,
WiMAX,
Data models"
"Understanding Plagiarism Linguistic Patterns, Textual Features, and Detection Methods","Plagiarism can be of many different natures, ranging from copying texts to adopting ideas, without giving credit to its originator. This paper presents a new taxonomy of plagiarism that highlights differences between literal plagiarism and intelligent plagiarism, from the plagiarist's behavioral point of view. The taxonomy supports deep understanding of different linguistic patterns in committing plagiarism, for example, changing texts into semantically equivalent but with different words and organization, shortening texts with concept generalization and specification, and adopting ideas and important contributions of others. Different textual features that characterize different plagiarism types are discussed. Systematic frameworks and methods of monolingual, extrinsic, intrinsic, and cross-lingual plagiarism detection are surveyed and correlated with plagiarism types, which are listed in the taxonomy. We conduct extensive study of state-of-the-art techniques for plagiarism detection, including character n-gram-based (CNG), vector-based (VEC), syntax-based (SYN), semantic-based (SEM), fuzzy-based (FUZZY), structural-based (STRUC), stylometric-based (STYLE), and cross-lingual techniques (CROSS). Our study corroborates that existing systems for plagiarism detection focus on copying text but fail to detect intelligent plagiarism when ideas are presented in different words.","Plagiarism,
Taxonomy,
Feature extraction,
Writing,
Pragmatics,
Humans,
Natural languages"
An Incremental Learning Method Based on Probabilistic Neural Networks and Adjustable Fuzzy Clustering for Human Activity Recognition by Using Wearable Sensors,"Human activity recognition by using wearable sensors has gained tremendous interest in recent years among a range of health-related areas. To automatically recognize various human activities from wearable sensor data, many classification methods have been tried in prior studies, but most of them lack the incremental learning abilities. In this study, an incremental learning method is proposed for sensor-based human activity recognition. The proposed method is designed based on probabilistic neural networks and an adjustable fuzzy clustering algorithm. The proposed method may achieve the following features. 1) It can easily learn additional information from new training data to improve the recognition accuracy. 2) It can freely add new activities to be detected, as well as remove existing activities. 3) The updating process from new training data does not require previously used training data. An experiment was performed to collect realistic wearable sensor data from a range of activities of daily life. The experimental results showed that the proposed method achieved a good tradeoff between incremental learning ability and the recognition accuracy. The experimental results from comparison with other classification methods demonstrated the effectiveness of the proposed method further.","Training,
Frequency control,
Acceleration,
Vectors,
Wearable sensors,
Accuracy,
Humans"
ECG Analysis Using Multiple Instance Learning for Myocardial Infarction Detection,"This paper presents a useful technique for totally automatic detection of myocardial infarction from patients' ECGs. Due to the large number of heartbeats constituting an ECG and the high cost of having all the heartbeats manually labeled, supervised learning techniques have achieved limited success in ECG classification. In this paper, we first discuss the rationale for applying multiple instance learning (MIL) to automated ECG classification and then propose a new MIL strategy called latent topic MIL, by which ECGs are mapped into a topic space defined by a number of topics identified over all the unlabeled training heartbeats and support vector machine is directly applied to the ECG-level topic vectors. Our experimental results on real ECG datasets from the PTB diagnostic database demonstrate that, compared with existing MIL and supervised learning algorithms, the proposed algorithm is able to automatically detect ECGs with myocardial ischemia without labeling any heartbeats. Moreover, it improves classification quality in terms of both sensitivity and specificity.","Electrocardiography,
Heart beat,
Classification algorithms,
Feature extraction,
Support vector machine classification,
Training"
Digitally Calibrated 768-kS/s 10-b Minimum-Size SAR ADC Array With Dithering,"Array sensors require a high-performance analog-to-digital converter (ADC) array with small area and low power. Successive-approximation register (SAR) ADC has good potential for ADC array due to its simple analog circuits. However, SAR ADCs with 10-b resolution and higher normally need a large capacitor array due to the stringent matching requirement. The large capacitor array also limits the ADC dynamic performance. The capacitor mismatch has been compensated by analog calibration techniques. In this work, a novel digital calibration method is developed for SAR ADC based on dithering. With dithering, weights of most significant bit (MSB) capacitors can be measured accurately so that very small capacitors can be used in the SAR ADC due to the relaxed matching requirement. A modified bit-cycling procedure is developed to avoid the code gaps caused by capacitor dithering. This calibration technique requires no analog calibration overhead and simple digital decoders. The technique is implemented in an ADC array design including 256 SAR ADCs for a high-speed CMOS imaging sensor in a 0.18-μm CMOS process. The 10-b SAR ADC is designed with the minimum capacitor array size in the process. A single SAR ADC only occupies 15 μm × 710 μm. Sampling at 768 kS/s, peak DNL and peak INL of the original ADCs averaged across the array are 0.82 least significant bit (LSB) and 3.85 LSB, respectively. For a signal close to the Nyquist frequency, original ADCs have 7.96-b average ENOB. After calibration with dithering, ADCs have 0.55-LSB peak DNL and 0.77-LSB peak INL averaged across the array. The average ENOB improves to 9.83 b. Compared with the benchmark 10-b SAR ADCs, this design is the most area-efficient design. In this work, the calibration decoders are implemented off-chip. With a sample-and-hold amplifier, the calibration method can run in the background.","Capacitors,
Calibration,
Quantization,
Sensor arrays,
Switches"
On-Chip Molecular Communication: Analysis and Design,"We consider a confined space molecular communication system, where molecules or information carrying particles are used to transfer information on a microfluidic chip. Considering that information-carrying particles can follow two main propagation schemes: passive transport, and active transport, it is not clear which achieves a better information transmission rate. Motivated by this problem, we compare and analyze both propagation schemes by deriving a set of analytical and mathematical tools to measure the achievable information rates of the on-chip molecular communication systems employing passive to active transport. We also use this toolbox to optimize design parameters such as the shape of the transmission area, to increase the information rate. Furthermore, the effect of separation distance between the transmitter and the receiver on information rate is examined under both propagation schemes, and a guidepost to design an optimal molecular communication setup and protocol is presented.","Receivers,
Transmitters,
Molecular communication,
Information rates,
Channel capacity,
Microchannel,
Nanoscale devices"
Fifty Years of Artificial Reverberation,"The first artificial reverberation algorithms were proposed in the early 1960s, and new, improved algorithms are published regularly. These algorithms have been widely used in music production since the 1970s, and now find applications in new fields, such as game audio. This overview article provides a unified review of the various approaches to digital artificial reverberation. The three main categories have been delay networks, convolution-based algorithms, and physical room models. Delay-network and convolution techniques have been competing in popularity in the music technology field, and are often employed to produce a desired perceptual or artistic effect. In applications including virtual reality, predictive acoustic modeling, and computer-aided design of acoustic spaces, accuracy is desired, and physical models have been mainly used, although, due to their computational complexity, they are currently mainly used for simplified geometries or to generate reverberation impulse responses for use with a convolution method. With the increase of computing power, all these approaches will be available in real time. A recent trend in audio technology is the emulation of analog artificial reverberation units, such as spring reverberators, using signal processing algorithms. As a case study we present an improved parametric model for a spring reverberation unit.","Reverberation,
Delay,
Springs,
Convolution,
Solid modeling,
Computational modeling"
Development and Evaluation of an Ambulatory Stress Monitor Based on Wearable Sensors,"Chronic stress is endemic to modern society. However, as it is unfeasible for physicians to continuously monitor stress levels, its diagnosis is nontrivial. Wireless body sensor networks offer opportunities to ubiquitously detect and monitor mental stress levels, enabling improved diagnosis, and early treatment. This article describes the development of a wearable sensor platform to monitor a number of physiological correlates of mental stress. We discuss tradeoffs in both system design and sensor selection to balance information content and wearability. Using experimental signals collected from the wearable sensor, we describe a selected number of physiological features that show good correlation with mental stress. In particular, we propose a new spectral feature that estimates the balance of the autonomic nervous system by combining information from the power spectral density of respiration and heart rate variability. We validate the effectiveness of our approach on a binary discrimination problem when subjects are placed under two psychophysiological conditions: mental stress and relaxation. When used in a logistic regression model, our feature set is able to discriminate between these two mental states with a success rate of 81% across subjects.",
Throughput Analysis of Cooperative Mobile Content Distribution in Vehicular Network using Symbol Level Network Coding,"This paper presents a theoretical study of the throughput of mobile content distribution (MCD) in vehicular ad hoc networks (VANETs). Since VANET is well-known for its fast-changing topology and adverse wireless channel environments, various protocols have been proposed in the literature to enhance the performance of MCD in a vehicular environment, using packet-level network coding (PLNC) and symbol-level network coding (SLNC). However, there still lacks a fundamental understanding of the limits of MCD protocols using network coding in VANETs. In this paper, we develop a theoretical model to compute the achievable throughput of cooperative MCD in VANETs using SLNC. By considering a one-dimensional road topology with an access point (AP) as the content source, the expected achievable throughput for a vehicle at a certain distance from the AP is derived, for both using PLNC and SLNC. Our proposed model is unique since it captures the effects of multiple practical factors, including vehicle distribution and mobility pattern, channel fading and packet collisions. Through numerical results, we provide insights on optimized design choices for network coding-based cooperative MCD systems in VANETs.",
Robust Student's-t Mixture Model With Spatial Constraints and Its Application in Medical Image Segmentation,"Finite mixture model based on the Student's-t distribution, which is heavily tailed and more robust than Gaussian, has recently received great attention for image segmentation. A new finite Student's-t mixture model (SMM) is proposed in this paper. Existing models do not explicitly incorporate the spatial relationships between pixels. First, our model exploits Dirichlet distribution and Dirichlet law to incorporate the local spatial constrains in an image. Secondly, we directly deal with the Student's-t distribution in order to estimate the model parameters, whereas, the Student's-t distributions in previous models are represented as an infinite mixture of scaled Gaussians that lead to an increase in complexity. Finally, instead of using expectation maximization (EM) algorithm, the proposed method adopts the gradient method to minimize the higher bound on the data negative log-likelihood and to optimize the parameters. The proposed model is successfully compared to the state-of-the-art finite mixture models. Numerical experiments are presented where the proposed model is tested on various simulated and real medical images.","Image segmentation,
Nickel,
Biomedical imaging,
Robustness,
Noise,
Computational modeling,
Mathematical model"
Integrating Appearance and Edge Features for Sedan Vehicle Detection in the Blind-Spot Area,"Changing lanes while having no information about the blind spot area can be dangerous. We propose a vision-based vehicle detection system for a lane changing assistance system to monitor the potential sedan vehicle in the blind-spot area. To serve our purpose, we select adequate features, which are directly obtained from vehicle images, to detect possible vehicles in the blind-spot area. This is challenging due to the significant change in the view angle of a vehicle along with its location throughout the blind-spot area. To cope with this problem, we propose a method to combine two kinds of part-based features that are related to the characteristics of the vehicle, and we build multiple models based on different viewpoints of a vehicle. The location information of each feature is incorporated to help construct the detector and estimate the reasonable position of the presence of the vehicle. The experiments show that our system is reliable in detecting various sedan vehicles in the blind-spot area.","Vehicles,
Feature extraction,
Image edge detection,
Vectors,
Image segmentation,
Training,
Vehicle detection"
Accuracy of the Morphology Enabled Dipole Inversion (MEDI) Algorithm for Quantitative Susceptibility Mapping in MRI,"Determining the susceptibility distribution from the magnetic field measured in a magnetic resonance (MR) scanner is an ill-posed inverse problem, because of the presence of zeroes in the convolution kernel in the forward problem. An algorithm called morphology enabled dipole inversion (MEDI), which incorporates spatial prior information, has been proposed to generate a quantitative susceptibility map (QSM). The accuracy of QSM can be validated experimentally. However, there is not yet a rigorous mathematical demonstration of accuracy for a general regularized approach or for MEDI specifically. The error in the susceptibility map reconstructed by MEDI is expressed in terms of the acquisition noise and the error in the spatial prior information. A detailed analysis demonstrates that the error in the susceptibility map reconstructed by MEDI is bounded by a linear function of these two error sources. Numerical analysis confirms that the error of the susceptibility map reconstructed by MEDI is on the same order of the noise in the original MRI data, and comprehensive edge detection will lead to reduced model error in MEDI. Additional phantom validation and human brain imaging demonstrated the practicality of the MEDI method.","Image reconstruction,
Noise,
Image edge detection,
Inverse problems,
Phantoms,
Magnetic susceptibility"
Pose error robust grasping from contact wrench space metrics,"Grasp quality metrics which analyze the contact wrench space are commonly used to synthesize and analyze preplanned grasps. Preplanned grasping approaches rely on the robustness of stored solutions. Analyzing the robustness of such solutions for large databases of preplanned grasps is a limiting factor for the applicability of data driven approaches to grasping. In this work, we will focus on the stability of the widely used grasp wrench space epsilon quality metric over a large range of poses in simulation. We examine a large number of grasps from the Columbia Grasp Database for the Barrett hand. We find that in most cases the grasp with the most robust force closure with respect to pose error for a particular object is not the grasp with the highest epsilon quality. We demonstrate that grasps can be reranked by an estimate of the stability of their epsilon quality. We find that the grasps ranked best by this method are successful more often in physical experiments than grasps ranked best by the epsilon quality.","Robustness,
Grasping,
Measurement,
Databases,
Uncertainty,
Force,
Joints"
Fuzzy Local Gaussian Mixture Model for Brain MR Image Segmentation,"Accurate brain tissue segmentation from magnetic resonance (MR) images is an essential step in quantitative brain image analysis. However, due to the existence of noise and intensity inhomogeneity in brain MR images, many segmentation algorithms suffer from limited accuracy. In this paper, we assume that the local image data within each voxel's neighborhood satisfy the Gaussian mixture model (GMM), and thus propose the fuzzy local GMM (FLGMM) algorithm for automated brain MR image segmentation. This algorithm estimates the segmentation result that maximizes the posterior probability by minimizing an objective energy function, in which a truncated Gaussian kernel function is used to impose the spatial constraint and fuzzy memberships are employed to balance the contribution of each GMM. We compared our algorithm to state-of-the-art segmentation approaches in both synthetic and clinical data. Our results show that the proposed algorithm can largely overcome the difficulties raised by noise, low contrast, and bias field, and substantially improve the accuracy of brain MR image segmentation.","Image segmentation,
Clustering algorithms,
Kernel,
Educational institutions,
Nonhomogeneous media,
Brain modeling,
Computer science"
RFID technology and its applications in Internet of Things (IoT),"Radio frequency identification system (RFID) is an automatic technology and aids machines or computers to identify objects, record metadata or control individual target through radio waves. Connecting RFID reader to the terminal of Internet, the readers can identify, track and monitor the objects attached with tags globally, automatically, and in real time, if needed. This is the so-called Internet of Things (IoT). RFID is often seen as a prerequisite for the IoT. This paper introduces the technologies of RFID and IoT, discusses the applications and challenges of RFID technology used in IoT.","Protocols,
Internet,
Object recognition,
Security,
RFID tags,
Transponders"
Graph-based analysis and prediction for software evolution,"We exploit recent advances in analysis of graph topology to better understand software evolution, and to construct predictors that facilitate software development and maintenance. Managing an evolving, collaborative software system is a complex and expensive process, which still cannot ensure software reliability. Emerging techniques in graph mining have revolutionized the modeling of many complex systems and processes. We show how we can use a graph-based characterization of a software system to capture its evolution and facilitate development, by helping us estimate bug severity, prioritize refactoring efforts, and predict defect-prone releases. Our work consists of three main thrusts. First, we construct graphs that capture software structure at two different levels: (a) the product, i.e., source code and module level, and (b) the process, i.e., developer collaboration level. We identify a set of graph metrics that capture interesting properties of these graphs. Second, we study the evolution of eleven open source programs, including Firefox, Eclipse, MySQL, over the lifespan of the programs, typically a decade or more. Third, we show how our graph metrics can be used to construct predictors for bug severity, high-maintenance software parts, and failure-prone releases. Our work strongly suggests that using graph topology analysis concepts can open many actionable avenues in software engineering research and practice.","Measurement,
Software,
Collaboration,
Fires,
Maintenance engineering,
Software engineering,
Topology"
Understanding Node Localizability of Wireless Ad Hoc and Sensor Networks,"Location awareness is highly critical for wireless ad-hoc and sensor networks. Many efforts have been made to solve the problem of whether or not a network can be localized. Nevertheless, based on the data collected from a working sensor network, it is observed that the network is not always entirely localizable. Theoretical analyses also suggest that, in most cases, it is unlikely that all nodes in a network are localizable, although a (large) portion of the nodes can be uniquely located. Existing studies merely examine whether or not a network is localizable as a whole; yet two fundamental questions remain unaddressed: First, given a network configuration, whether or not a specific node is localizable? Second, how many nodes in a network can be located and which are them? In this study, we analyze the limitation of previous works and propose a novel concept of node localizability. By deriving the necessary and sufficient conditions for node localizability, for the first time, it is possible to analyze how many nodes one can expect to locate in sparsely or moderately connected networks. To validate this design, we implement our solution on a real-world system and the experimental results show that node localizability provides useful guidelines for network deployment and other location-based services.","Sufficient conditions,
Ad hoc networks,
Wireless communication,
Wireless sensor networks,
Mobile radio mobility management"
Color-Decoupled Photo Response Non-Uniformity for Digital Image Forensics,"The last few years have seen the use of photo response non-uniformity noise (PRNU), a unique fingerprint of imaging sensors, in various digital forensic applications such as source device identification, content integrity verification, and authentication. However, the use of a color filter array for capturing only one of the three color components per pixel introduces color interpolation noise, while the existing methods for extracting PRNU provide no effective means for addressing this issue. Because the artificial colors obtained through the color interpolation process are not directly acquired from the scene by physical hardware, we expect that the PRNU extracted from the physical components, which are free from interpolation noise, should be more reliable than that from the artificial channels, which carry interpolation noise. Based on this assumption we propose a couple-decoupled PRNU (CD-PRNU) extraction method, which first decomposes each color channel into four sub-images and then extracts the PRNU noise from each sub-image. The PRNU noise patterns of the sub-images are then assembled to get the CD-PRNU. This new method can prevent the interpolation noise from propagating into the physical components, thus improving the accuracy of device identification and image content integrity verification.",
Rendezvous Without Coordinates,"We study minimalism in sensing and control by considering a multi-agent system in which each agent moves like a Dubins car and has a limited sensor that reports only the presence of another agent within some sector of its windshield. Using a simple quantized control law with three values, each agent tracks another agent (its target) assigned to it by maintaining that agent within this windshield sector. We use Lyapunov analysis to show that by acting autonomously in this way, the agents will achieve rendezvous given a connected initial assignment graph and the assumption that an agent and its target will merge into a single agent when they are sufficiently close. We then proceed to show that, by making the quantized control law slightly stronger, a connected initial assignment graph is not required and the sensing model can be weakened further. A distinguishing feature of our approach is that it does not involve any estimation procedure aimed at reconstructing coordinate information. Our scenario thus provides an example in which an interesting task is performed with extremely coarse sensing and control, and without state estimation. The system was implemented in computer simulation, accessible through the Web, of which the results are presented in the paper.","Automotive components,
Robot sensing systems,
Merging,
Lyapunov methods,
Vehicles"
New Semi-Supervised Classification Method Based on Modified Cluster Assumption,"The cluster assumption, which assumes that “similar instances should share the same label,” is a basic assumption in semi-supervised classification learning, and has been found very useful in many successful semi-supervised classification methods. It is rarely noticed that when the cluster assumption is adopted, there is an implicit assumption that every instance should have a crisp class label assignment. In real applications, however, there are cases where it is difficult to tell that an instance definitely belongs to one class and does not belong to other neighboring classes. In such cases, it is more adequate to assume that “similar instances should share similar label memberships” rather than sharing a crisp label assignment. Here “label memberships” can be represented as a vector, where each element corresponds to a class, and the value at the element expresses the likelihood of the concerned instance belonging to the class. By adopting this modified cluster assumption, in this paper we propose a new semi-supervised classification method, that is, semi-supervised classification based on class membership (SSCCM). Specifically, we try to solve the decision function and adequate label memberships for instances simultaneously, and constrain that an instance and its “local weighted mean” (LWM) share the same label membership vector, where the LWM is a robust image of the instance, constructed by calculating the weighted mean of its neighboring instances. We formulate the problem in a unified objective function for the labeled, unlabeled data and their LWMs based on the square loss function, and take an alternating iterative strategy to solve it, in which each step generates a closed-form solution, and the convergence is guaranteed. The solution will provide both the decision function and the label membership function for classification, their classification results can verify each other, and the reliability of semi-supervised classification learning might be enhanced by checking the consistency between those two predictions. Experiments show that SSCCM obtains encouraging results compared to state-of-the-art semi-supervised classification methods.","Optimization,
Vectors,
Kernel,
Reliability,
Clustering algorithms,
Learning systems,
Encoding"
CellSense: An Accurate Energy-Efficient GSM Positioning System,"Context-aware applications have been gaining huge interest in the last few years. With cell phones becoming ubiquitous computing devices, cell phone localization has become an important research problem. In this paper, we present CellSense, which is a probabilistic received signal strength indicator (RSSI)-based fingerprinting location determination system for Global System for Mobile Communications (GSM) phones. We discuss the challenges of implementing a probabilistic fingerprinting localization technique in GSM networks and present the details of the CellSense system and how it addresses these challenges. We then extend the proposed system using a hybrid technique that combines probabilistic and deterministic estimations to achieve both high accuracy and low computational overhead. Moreover, the accuracy of the hybrid technique is robust to changes in its parameter values. To evaluate our proposed system, we implemented CellSense on Android-based phones. Results from two different testbeds, representing urban and rural environments, for three different cellular providers show that CellSense provides at least 108.57% enhancement in accuracy in rural areas and at least 89.03% in urban areas compared with current state-of-the-art RSSI-based GSM localization systems. In additional, the proposed hybrid technique provides more than 6 and 5.4 times reduction in computational requirements compared with state-of-the-art RSSI-based GSM localization systems for rural and urban testbeds, respectively. We also evaluate the effect of changing the different system parameters on the accuracy-complexity tradeoff and how the cell tower and fingerprint densities affect system performance.","Cellular phones,
Accuracy,
GSM,
Poles and towers,
Probabilistic logic,
Histograms,
Vectors"
Low-Power Level Shifter for Multi-Supply Voltage Designs,"In this brief, a new low-power level shifter (LS) is presented for robust logic voltage shifting from near/sub-threshold to above-threshold domain. The new circuit combines the multi-threshold CMOS technique along with novel topological modifications to guarantee a wide voltage conversion range with limited static power and total energy consumption. When implemented in a 90-nm technology process, the proposed design reliably converts 180-mV input signals into 1-V output signals, while maintaining operational frequencies above 1-MHz, also taking into account process-voltage-temperature variations.Post-layout simulation results demonstrate that the new LS reaches a propagation delay less than 22 ns, a static power dissipation of only 6.4 nW, and a total energy per transition of only 74 fJ for a 0.2-V 1-MHz input pulse.",
An Output-Capacitor-Free Adaptively Biased Low-Dropout Regulator With Subthreshold Undershoot-Reduction for SoC,"This paper presents an output-capacitor-free adaptively biased low-dropout regulator with subthreshold undershoot-reduction (ABSTUR LDR) for SoC power management applications. Techniques of adaptive biasing (AB) and Miller compensation with Q-reduction are employed to achieve low-voltage high-precision regulation with extended loop bandwidth while maintaining low quiescent current and high current efficiency. The pass transistor is designed to work in the linear region at heavy load to save silicon area, and a symmetrically matched current-voltage mirror is used to implement the AB scheme with accurate current sensing for the full load range. The dedicated STUR circuit, which is low-voltage compatible and consumes very low current in the steady state, is inserted to momentarily but exponentially increase the gate discharging current of the pass transistor when the LDR output has a large undershoot due to a large step up of the load current. Undershoot voltage is hence dramatically reduced. Stability of the ABSTUR LDR is thoroughly analyzed and tradeoffs between the undershoot-reduction strength and the light load stability are discussed. Features of the proposed ABSTUR LDR are experimentally verified by a prototype fabricated in a standard 0.35-μm CMOS process.","Logic gates,
Transient analysis,
Transistors,
Stability analysis,
Impedance,
Bandwidth,
Topology"
Comparing Fuzzy Partitions: A Generalization of the Rand Index and Related Measures,"In this paper, we introduce a fuzzy extension of a class of measures to compare clustering structures, namely, measures that are based on the number of concordant and the number of discordant pairs of data points. This class includes the well-known Rand index but also commonly used alternatives, such as the Jaccard measure. In contrast with previous proposals, our extension exhibits desirable metrical properties. Apart from elaborating on formal properties of this kind, we present an experimental study in which we compare different fuzzy extensions of the Rand index and the Jaccard measure.","Indexes,
Proposals,
Bonding,
Loss measurement,
Vectors,
Clustering algorithms,
Probabilistic logic"
Face Identification Using Large Feature Sets,"With the goal of matching unknown faces against a gallery of known people, the face identification task has been studied for several decades. There are very accurate techniques to perform face identification in controlled environments, particularly when large numbers of samples are available for each face. However, face identification under uncontrolled environments or with a lack of training data is still an unsolved problem. We employ a large and rich set of feature descriptors (with more than 70 000 descriptors) for face identification using partial least squares to perform multichannel feature weighting. Then, we extend the method to a tree-based discriminative structure to reduce the time required to evaluate probe samples. The method is evaluated on Facial Recognition Technology (FERET) and Face Recognition Grand Challenge (FRGC) data sets. Experiments show that our identification method outperforms current state-of-the-art results, particularly for identifying faces acquired across varying conditions.","Face,
Vectors,
Probes,
Feature extraction,
Face recognition,
Training,
Lighting"
Infrastructure-assisted routing in vehicular networks,"Deploying roadside access points (APs) or an infrastructure can improve data delivery. Our empirical results from real trace driven simulations show that deploying APs produces up to 5× performance gain in delivery ratio and reduces delivery delay by as much as 35% with simple routing. However, we also find that buffer resources at the APs become a critical factor and poor buffer allocation leads to marginal performance gain for inter-vehicle routing. Motivated by this important observation, we investigate the optimal infrastructure-assisted routing for inter-vehicle data delivery. It remains a challenging issue for two major reasons. First, the addition of APs dramatically changes delivery opportunities between vehicles, which has not been well understood by existing work. Second, packet forwarding and buffer allocation are inter-dependent and should be addressed together. To tackle the challenges, we first characterize packet delivery probability as a function of predicted vehicle trajectories and AP locations. Then, we formulate the coexisting problem of packet forwarding and buffer allocation as an optimization problem and show that it is a knapsack problem. We design a global algorithm to solve this optimization problem. For more realistic settings, we propose a distributed algorithm for packet forwarding and buffer allocation in which each vehicle and the APs make decisions locally. Through trace-driven simulations, we demonstrate that the distributed algorithm steadily outperforms other alternative approaches under a wide range of network configurations.",
A Distributed Trust Evaluation Model and Its Application Scenarios for Medical Sensor Networks,"The development of medical sensor networks (MSNs) is imperative for e-healthcare, but security remains a formidable challenge yet to be resolved. Traditional cryptographic mechanisms do not suffice given the unique characteristics of MSNs, and the fact that MSNs are susceptible to a variety of node misbehaviors. In such situations, the security and performance of MSNs depend on the cooperative and trust nature of the distributed nodes, and it is important for each node to evaluate the trustworthiness of other nodes. In this paper, we identify the unique features of MSNs and introduce relevant node behaviors, such as transmission rate and leaving time, into trust evaluation to detect malicious nodes. We then propose an application-independent and distributed trust evaluation model for MSNs. The trust management is carried out through the use of simple cryptographic techniques. Simulation results demonstrate that the proposed model can be used to effectively identify malicious behaviors and thereby exclude malicious nodes. This paper also reports the experimental results of the Collection Tree Protocol with the addition of our proposed model in a network of TelosB motes, which show that the network performance can be significantly improved in practice. Further, some suggestions are given on how to employ such a trust evaluation model in some application scenarios.","Cryptography,
Base stations,
Wireless sensor networks,
Peer to peer computing,
Biomedical monitoring,
Wireless communication"
Detection of Land-Cover Transitions in Multitemporal Remote Sensing Images With Active-Learning-Based Compound Classification,"This paper presents a novel iterative active learning (AL) technique aimed at defining effective multitemporal training sets to be used for the supervised detection of land-cover transitions in a pair of remote sensing images acquired on the same area at different times. The proposed AL technique is developed in the framework of the Bayes' rule for compound classification. At each iteration, it selects the pair of spatially aligned unlabeled pixels in the two images that are classified with the maximum uncertainty. These pixels are then labeled by an external supervisor and included in the training set. The uncertainty of a pair of pixels is assessed by the joint entropy defined by considering two possible different simplifying assumptions: 1) class-conditional independence and 2) temporal independence between multitemporal images. Accordingly, different algorithms are introduced. The proposed joint-entropy-based AL algorithms for compound classification are compared with each other and with a marginal-entropy-based AL technique (in which the entropy is computed separately on single-date images) applied to the postclassification comparison method. The experimental results obtained on two multispectral and multitemporal data sets show the effectiveness of the proposed technique.","Training,
Joints,
Compounds,
Entropy,
Uncertainty,
Labeling,
Context"
Image-Based Estimation of Ventricular Fiber Orientations for Personalized Modeling of Cardiac Electrophysiology,"Technological limitations pose a major challenge to acquisition of myocardial fiber orientations for patient-specific modeling of cardiac (dys)function and assessment of therapy. The objective of this project was to develop a methodology to estimate cardiac fiber orientations from in vivo images of patient heart geometries. An accurate representation of ventricular geometry and fiber orientations was reconstructed, respectively, from high-resolution ex vivo structural magnetic resonance (MR) and diffusion tensor (DT) MR images of a normal human heart, referred to as the atlas. Ventricular geometry of a patient heart was extracted, via semiautomatic segmentation, from an in vivo computed tomography (CT) image. Using image transformation algorithms, the atlas ventricular geometry was deformed to match that of the patient. Finally, the deformation field was applied to the atlas fiber orientations to obtain an estimate of patient fiber orientations. The accuracy of the fiber estimates was assessed using six normal and three failing canine hearts. The mean absolute difference between inclination angles of acquired and estimated fiber orientations was 15.4° . Computational simulations of ventricular activation maps and pseudo-ECGs in sinus rhythm and ventricular tachycardia indicated that there are no significant differences between estimated and acquired fiber orientations at a clinically observable level.","Heart,
Geometry,
Computational modeling,
In vivo,
Optical fiber testing,
Estimation,
Three dimensional displays"
FTV for 3-D Spatial Communication,"Free-viewpoint TV (FTV) is cutting the frontier of audiovisual communications. FTV is an innovative media that enables us to view 3-D space by freely changing our viewpoints. It also allows us to listen at any listening point in the 3-D space. Since FTV transmits all audiovisual information of the 3-D space, it can reconstruct an audiovisual replica of the 3-D space anywhere and anytime over distance and time. For video, FTV captures a part of rays in 3-D space by using many cameras, and the other rays that are not captured are obtained by interpolating the captured rays. We constructed real-time FTV systems including the complete chain of operation from image capture to display. We also carried out FTV on a laptop computer and a mobile player. For audio, two kinds of free listening-point systems are demonstrated. MPEG regarded FTV as the most challenging 3-D media and has been conducting its international standardization activities. The first phase of FTV was multiview video coding (MVC) and the second phase of FTV is 3-D video (3DV). MVC enables the efficient coding of multiple camera views and was completed in 2009. MVC has been adopted by Blu-ray 3-D. 3DV is a standard that targets serving a variety of 3-D displays and its call for proposals was issued in March 2011.","Cameras,
Audio-visual systems,
Interpolation,
Receivers,
TV,
Rendering (computer graphics),
Transform coding,
Three dimensional displays"
Ultra-Wideband Differential Bandpass Filter With Narrow Notched Band and Improved Common-Mode Suppression by DGS,"A novel microstrip ultra-wideband (UWB) differential filter with narrow notched band based on the transversal signal- interference concept is presented. In order to enhance the interference immunity from undesired signals efficiently, the notched band is implemented by coupling with quarter wavelength shorted-line at input and output ports. By taking advantage of the bandgap characteristic of defected ground structure (DGS), a slot-line DGS is used for improving the common-mode rejection. In this work, at the center frequency of the notched band which is 2.45 GHz, about 7.3% bandwidth (2.35-2.53 GHz) is realized by full-wave simulator. Agreement between experiment and simulation is observed.","Impedance,
Wireless communication,
Passband,
Ultra wideband technology,
Band pass filters,
Interference,
Microstrip"
Maximum Performance Computing with Dataflow Engines,Multidisciplinary dataflow computing is a powerful approach to scientific computing that has led to orders-of-magnitude performance improvements for a wide range of applications.,
Mechanisms responsible for dynamic ON-resistance in GaN high-voltage HEMTs,"We have developed a new methodology to study the dynamic ON-resistance (RON) of high-voltage GaN High-Electron-Mobility Transistors (HEMTs). With this technique, we have investigated dynamic RON transients over a time span of 11 decades. In OFF to ON time transients, we observe a fast release of trapped electrons through a temperature-independent tunneling process. We attribute this to border traps at the AlGaN barrier/AlN spacer interface. Over a longer time scale, we observe conventional thermally activated electron detrapping from traps at the surface of the device or inside the AlGaN barrier. These findings provide a path for power switching device engineering with minimum dynamic RON.","Transient analysis,
Electron traps,
Aluminum gallium nitride,
Gallium nitride,
HEMTs,
MODFETs,
Switches"
The Degrees of Freedom of Isotropic MIMO Interference Channels Without State Information at the Transmitters,"This paper fully determines the degree-of-freedom (DoF) region of two-user interference channels with arbitrary number of transmit and receive antennas in the case of isotropic and independent (or block-wise independent) fading, where the channel state information is available to the receivers but not to the transmitters. Thus, the DoF gap between previous upper and lower bounds due to the authors, Vaze and Varanasi, and Huang, Jafar, Shamai, and Vishwanath is closed. The DoF result characterizes the capacity region to the first order of the logarithm of the signal-to-noise ratio (SNR) in the high-SNR regime. The DoF region is achievable by using random Gaussian codebooks independent of the channel states, which implies that it is impossible to increase the DoF using beamforming and interference alignment in the absence of channel state information at the transmitters.","Transmitters,
Interference channels,
Rayleigh channels,
MIMO,
Receiving antennas"
Passivity-Based Pose Synchronization in Three Dimensions,"This paper addresses passivity-based pose synchronization in the Special Euclidean group SE(3) . We first develop a passivity-based distributed velocity input law to achieve pose synchronization. We next show that the pose synchronizes exponentially fast under an assumption on the initial states of the bodies, with an exponential convergence rate given by algebraic connectivity of interconnection graphs. We also prove pose synchronization in the presence of communication delays and topology switches. We moreover give further extensions of the present law, where desirable velocities and collision avoidance are taken into account. Finally, the effectiveness of the present inputs is demonstrated through numerical simulations and experiments on a planar (2D) test bed.","Synchronization,
Convergence,
Delay,
Switches,
Symmetric matrices,
Kinematics,
Topology"
Penalized Likelihood PET Image Reconstruction Using Patch-Based Edge-Preserving Regularization,"Iterative image reconstruction for positron emission tomography (PET) can improve image quality by using spatial regularization that penalizes image intensity difference between neighboring pixels. The most commonly used quadratic penalty often oversmoothes edges and fine features in reconstructed images. Nonquadratic penalties can preserve edges but often introduce piece-wise constant blocky artifacts and the results are also sensitive to the hyper-parameter that controls the shape of the penalty function. This paper presents a patch-based regularization for iterative image reconstruction that uses neighborhood patches instead of individual pixels in computing the nonquadratic penalty. The new regularization is more robust than the conventional pixel-based regularization in differentiating sharp edges from random fluctuations due to noise. An optimization transfer algorithm is developed for the penalized maximum likelihood estimation. Each iteration of the algorithm can be implemented in three simple steps: an EM-like image update, an image smoothing and a pixel-by-pixel image fusion. Computer simulations show that the proposed patch-based regularization can achieve higher contrast recovery for small objects without increasing background variation compared with the quadratic regularization. The reconstruction is also more robust to the hyper-parameter than conventional pixel-based nonquadratic regularizations. The proposed regularization method has been applied to real 3-D PET data.","Image reconstruction,
Image edge detection,
Optimization,
Positron emission tomography,
Noise measurement,
Convergence,
Robustness"
A General CPL-AdS Methodology for Fixing Dynamic Parameters in Dual Environments,"The algorithm of Continuous Point Location with Adaptive d-ary Search (CPL-AdS) strategy exhibits its efficiency in solving stochastic point location (SPL) problems. However, there is one bottleneck for this CPL-AdS strategy which is that, when the dimension of the feature, or the number of divided subintervals for each iteration, d is large, the decision table for elimination process is almost unavailable. On the other hand, the larger dimension of the features d can generally make this CPL-AdS strategy avoid oscillation and converge faster. This paper presents a generalized universal decision formula to solve this bottleneck problem. As a matter of fact, this decision formula has a wider usage beyond handling out this SPL problems, such as dealing with deterministic point location problems and searching data in Single Instruction Stream-Multiple Data Stream based on Concurrent Read and Exclusive Write parallel computer model. Meanwhile, we generalized the CPL-AdS strategy with an extending formula, which is capable of tracking an unknown dynamic parameter λ* in both informative and deceptive environments. Furthermore, we employed different learning automata in the generalized CPL-AdS method to find out if faster learning algorithm will lead to better realization of the generalized CPL-AdS method. All of these aforementioned contributions are vitally important whether in theory or in practical applications. Finally, extensive experiments show that our proposed approaches are efficient and feasible.","Search problems,
Learning automata,
Discrete Fourier transforms,
Vectors,
Automata,
Heuristic algorithms"
Whisper: Tracing the Spatiotemporal Process of Information Diffusion in Real Time,"When and where is an idea dispersed? Social media, like Twitter, has been increasingly used for exchanging information, opinions and emotions about events that are happening across the world. Here we propose a novel visualization design, “Whisper”, for tracing the process of information diffusion in social media in real time. Our design highlights three major characteristics of diffusion processes in social media: the temporal trend, social-spatial extent, and community response of a topic of interest. Such social, spatiotemporal processes are conveyed based on a sunflower metaphor whose seeds are often dispersed far away. In Whisper, we summarize the collective responses of communities on a given topic based on how tweets were retweeted by groups of users, through representing the sentiments extracted from the tweets, and tracing the pathways of retweets on a spatial hierarchical layout. We use an efficient flux line-drawing algorithm to trace multiple pathways so the temporal and spatial patterns can be identified even for a bursty event. A focused diffusion series highlights key roles such as opinion leaders in the diffusion process. We demonstrate how our design facilitates the understanding of when and where a piece of information is dispersed and what are the social responses of the crowd, for large-scale events including political campaigns and natural disasters. Initial feedback from domain experts suggests promising use for today's information consumption and dispersion in the wild.","Media,
Monitoring,
Real-time systems,
Diffusion processes,
Twitter,
Social network services"
Speech Enhancement Using Generative Dictionary Learning,"The enhancement of speech degraded by real-world interferers is a highly relevant and difficult task. Its importance arises from the multitude of practical applications, whereas the difficulty is due to the fact that interferers are often nonstationary and potentially similar to speech. The goal of monaural speech enhancement is to separate a single mixture into its underlying clean speech and interferer components. This under-determined problem is solved by incorporating prior knowledge in the form of learned speech and interferer dictionaries. The clean speech is recovered from the degraded speech by sparse coding of the mixture in a composite dictionary consisting of the concatenation of a speech and an interferer dictionary. Enhancement performance is measured using objective measures and is limited by two effects. A too sparse coding of the mixture causes the speech component to be explained with too few speech dictionary atoms, which induces an approximation error we denote source distortion. However, a too dense coding of the mixture results in source confusion, where parts of the speech component are explained by interferer dictionary atoms and vice-versa. Our method enables the control of the source distortion and source confusion trade-off, and therefore achieves superior performance compared to powerful approaches like geometric spectral subtraction and codebook-based filtering, for a number of challenging interferer classes such as speech babble and wind noise.","Speech,
Dictionaries,
Speech enhancement,
Speech coding,
Time domain analysis,
Prototypes"
Density-Based Multifeature Background Subtraction with Support Vector Machine,"Background modeling and subtraction is a natural technique for object detection in videos captured by a static camera, and also a critical preprocessing step in various high-level computer vision applications. However, there have not been many studies concerning useful features and binary segmentation algorithms for this problem. We propose a pixelwise background modeling and subtraction technique using multiple features, where generative and discriminative techniques are combined for classification. In our algorithm, color, gradient, and Haar-like features are integrated to handle spatio-temporal variations for each pixel. A pixelwise generative background model is obtained for each feature efficiently and effectively by Kernel Density Approximation (KDA). Background subtraction is performed in a discriminative manner using a Support Vector Machine (SVM) over background likelihood vectors for a set of features. The proposed algorithm is robust to shadow, illumination changes, spatial variations of background. We compare the performance of the algorithm with other density-based methods using several different feature combinations and modeling techniques, both quantitatively and qualitatively.","Density functional theory,
Support vector machines,
Computational modeling,
Kernel,
Image color analysis,
Vectors,
Convergence"
A New Green's Function Formulation for Modeling Homogeneous Objects in Layered Medium,"A new Green's function formulation is developed systematically for modeling general homogeneous (dielectric or magnetic) objects in a layered medium. The dyadic form of the Green's function is first derived based on the pilot vector potential approach. The matrix representation in the moment method implementation is then derived by applying integration by parts and vector identities. The line integral issue in the matrix representation is investigated, based on the continuity property of the propagation factor and the consistency of the primary term and the secondary term. The extinction theorem is then revisited in the inhomogeneous background and a surface integral equation for general homogeneous objects is set up. Different from the popular mixed potential integral equation formulation, this method avoids the artificial definition of scalar potential. The singularity of the matrix representation of the Green's function can be made as weak as possible. Several numerical results are demonstrated to validate the formulation developed in this paper. Finally, the duality principle of the layered medium Green's function is discussed in the appendix to make the formulation succinct.","Green's function methods,
Dielectrics,
Integral equations,
Nonhomogeneous media,
Magnetic domains,
Magnetic multilayers,
Vectors"
Normal Forms of Spiking Neural P Systems With Anti-Spikes,"Spiking neural P systems with anti-spikes (ASN P systems, for short) are a variant of spiking neural P systems, which were inspired by inhibitory impulses/spikes or inhibitory synapses. In this work, we consider normal forms of ASN P systems. Specifically, we prove that ASN P systems with pure spiking rules of categories (a, a) and (a, a̅) without forgetting rules are universal as number generating devices. In an ASN P system with spiking rules of categories (a, a̅) and (a̅, a) without forgetting rules, the neurons change spikes to anti-spikes or change anti-spikes to spikes; such systems are proved to be universal. We also prove that ASN P systems with inhibitory synapses using pure spiking rules of category (a, a) and forgetting rules are universal. These results answer an open problem and improve a corresponding result from [IJCCC, IV(3), 2009, 273-282].",
Accelerating Quantum Monte Carlo Simulations of Real Materials on GPU Clusters,"More accurate than mean-field methods and more scalable than quantum chemical methods, continuum quantum Monte Carlo (QMC) is an invaluable tool for predicting the properties of matter from fundamental principles. Because QMC algorithms offer multiple forms of parallelism, they're ideal candidates for acceleration in the many-core paradigm.","Graphics processing unit,
Monte Carlo methods,
Wave functions,
Quantum methods,
Mathematical model,
Computational modeling"
Optimizing Backup Optical-Network-Units Selection and Backup Fibers Deployment in Survivable Hybrid Wireless-Optical Broadband Access Networks,"Survivability is one of the key issues in hybrid wireless-optical broadband access networks (WOBAN) since the single segment failure can cause huge data loss. The single segment failure refers to a scenario where all optical-network-units (ONUs) are disconnected with the optical line terminal (OLT). Previous schemes focus on protecting WOBAN against single segment failure by deploying backup fibers. However, previous schemes suffer from two key problems. First, they ignore optimizing the selection of backup ONUs, which determines the cost of recovering the traffic interrupted by the failure. Second, they underutilize the residual capacity of segments, thus requiring higher backup fibers cost. In this paper, we propose a new and efficient scheme, called Optimizing Backup ONUs selection and backup Fibers deployment (OBOF), to enhance the survivability of WOBAN against the single segment failure. Our OBOF is composed of two consecutive steps, backup ONUs selection and backup fibers deployment. In the first step, aiming to minimize the cost of recovering the traffic interrupted by the failure, the simulated annealing (SA) algorithm is customized to optimize the selection of backup ONUs. In the second step, most importantly, an enhanced greedy cost-efficiency (EGCE) algorithm is proposed to optimize the deployment of backup fibers. Our EGCE consists of a novel remote backup segment (RBS) method, which can efficiently utilize the residual capacity of the segments, and a Bound on Length of Backup-optical-path (BLB) method, which limits the increase in recovery time induced by RBS. Extensive experimental results demonstrate that our OBOF scheme outperforms the previous schemes significantly, especially in the scenario of higher traffic demand.","Optical network units,
Wireless communication,
Passive optical networks,
Optical fibers,
Algorithm design and analysis"
Collaborative mobile charging for sensor networks,"The limited battery capacity of sensor nodes has become the biggest impediment to wireless sensor network (WSN) applications. Two recent breakthroughs in the areas of wireless energy transfer and rechargeable lithium batteries promise the use of mobile vehicles, with high volume batteries, as mobile chargers that transfer energy to sensor nodes wirelessly. In this paper, for the first time, we envision a novel charging paradigm: collaborative mobile charging, where mobile chargers are allowed to charge each other. We investigate the problem of scheduling multiple mobile chargers, which collaboratively recharge sensors, to maximize the ratio of the amount of payload energy to overhead energy, such that every sensor will not run out of energy. We first consider the uniform case where all sensors consume energy at the same rate, and propose a scheduling algorithm, PushWait, which is proven to be optimal in this case and can cover a one-dimensional WSN of infinite length. Then, in the non-uniform case, which is conjectured to be NP-hard, we first present two observations from space and time aspects to remove some impossible scheduling choices, and we propose our heuristic algorithm, ClusterCharging(β), which clusters sensors into groups and divides a scheduling cycle into charging rounds. Its approximation ratio is also presented. Extensive evaluations confirm the efficiency of our algorithms.","wireless sensor networks,
computational complexity,
inductive power transmission,
scheduling"
A Switched System Approach to Exponential Stabilization Through Communication Network,"This paper considers a networked control loop, where the plant is a “slave” part, and the remote controller and observer constitute the “master”. Since the performance of networked control systems (NCS) depends on the quality of service (QoS) available from the network, it is worth to design a controller that takes into account qualitative information on the QoS in realtime. The goal of the design is to provide a controller that guarantees the following two things: 1) high performances (here expressed by exponential decay rates) when the QoS remains globally the same and 2) global stability when the QoS changes. In order to guarantee the global stability, the controller will switch by respecting a dwell time constraint. The dwell time parameters are obtained by using the switched system theories and the obtained conditions are linear matrix inequalities. An experiment illustrates how the controller can be implemented for a control over Internet application (remote control of a small robot).","Delay,
Switches,
Stability analysis,
Switched systems,
Observers,
Quality of service"
Multifeature Landmark-Free Active Appearance Models: Application to Prostate MRI Segmentation,"Active shape models (ASMs) and active appearance models (AAMs) are popular approaches for medical image segmentation that use shape information to drive the segmentation process. Both approaches rely on image derived landmarks (specified either manually or automatically) to define the object's shape, which require accurate triangulation and alignment. An alternative approach to modeling shape is the level-set representation, defined as a set of signed distances to the object's surface. In addition, using multiple image derived attributes (IDAs) such as gradient information has previously shown to offer improved segmentation results when applied to ASMs, yet little work has been done exploring IDAs in the context of AAMs. In this work, we present a novel AAM methodology that utilizes the level set implementation to overcome the issues relating to specifying landmarks, and locates the object of interest in a new image using a registration based scheme. Additionally, the framework allows for incorporation of multiple IDAs. Our multifeature landmark-free AAM (MFLAAM) utilizes an efficient, intuitive, and accurate algorithm for identifying those IDAs that will offer the most accurate segmentations. In this paper, we evaluate our MFLAAM scheme for the problem of prostate segmentation from T2-w MRI volumes. On a cohort of 108 studies, the levelset MFLAAM yielded a mean Dice accuracy of 88% ± 5%, and a mean surface error of 1.5 mm ± .8 mm with a segmentation time of 150/s per volume. In comparison, a state of the art AAM yielded mean Dice and surface error values of 86% ± 9% and 1.6 mm ± 1.0 mm, respectively. The differences with respect to our levelset-based MFLAAM model are statistically significant (p <; .05). In addition, our results were in most cases superior to several recent state of the art prostate MRI segmentation methods.","Shape,
Active appearance model,
Image segmentation,
Principal component analysis,
Image reconstruction,
Magnetic resonance imaging,
Indexes"
Learning Semantic and Visual Similarity for Endomicroscopy Video Retrieval,"Content-based image retrieval (CBIR) is a valuable computer vision technique which is increasingly being applied in the medical community for diagnosis support. However, traditional CBIR systems only deliver visual outputs, i.e., images having a similar appearance to the query, which is not directly interpretable by the physicians. Our objective is to provide a system for endomicroscopy video retrieval which delivers both visual and semantic outputs that are consistent with each other. In a previous study, we developed an adapted bag-of-visual-words method for endomicroscopy retrieval, called “Dense-Sift,” that computes a visual signature for each video. In this paper, we present a novel approach to complement visual similarity learning with semantic knowledge extraction, in the field of in vivo endomicroscopy. We first leverage a semantic ground truth based on eight binary concepts, in order to transform these visual signatures into semantic signatures that reflect how much the presence of each semantic concept is expressed by the visual words describing the videos. Using cross-validation, we demonstrate that, in terms of semantic detection, our intuitive Fisher-based method transforming visual-word histograms into semantic estimations outperforms support vector machine (SVM) methods with statistical significance. In a second step, we propose to improve retrieval relevance by learning an adjusted similarity distance from a perceived similarity ground truth. As a result, our distance learning method allows to statistically improve the correlation with the perceived similarity. We also demonstrate that, in terms of perceived similarity, the recall performance of the semantic signatures is close to that of visual signatures and significantly better than those of several state-of-the-art CBIR methods. The semantic signatures are thus able to communicate high-level medical knowledge while being consistent with the low-level visual signatures and much shorter than them. In our resulting retrieval system, we decide to use visual signatures for perceived similarity learning and retrieval, and semantic signatures for the output of an additional information, expressed in the endoscopist own language, which provides a relevant semantic translation of the visual retrieval outputs.","Semantics,
Visualization,
Colonic polyps,
Medical diagnostic imaging,
Computer aided instruction,
Image retrieval"
Revisiting Recurrent Neural Networks for robust ASR,"In this paper, we show how new training principles and optimization techniques for neural networks can be used for different network structures. In particular, we revisit the Recurrent Neural Network (RNN), which explicitly models the Markovian dynamics of a set of observations through a non-linear function with a much larger hidden state space than traditional sequence models such as an HMM. We apply pretraining principles used for Deep Neural Networks (DNNs) and second-order optimization techniques to train an RNN. Moreover, we explore its application in the Aurora2 speech recognition task under mismatched noise conditions using a Tandem approach. We observe top performance on clean speech, and under high noise conditions, compared to multi-layer perceptrons (MLPs) and DNNs, with the added benefit of being a “deeper” model than an MLP but more compact than a DNN.",
Single-Machine Scheduling With Job-Position-Dependent Learning and Time-Dependent Deterioration,"Job deterioration and learning co-exist in many realistic scheduling situations. This paper introduces a general scheduling model that considers the effects of position-dependent learning and time-dependent deterioration simultaneously. In the proposed model, the actual processing time of a job depends not only on the total processing time of the jobs already processed but also on its scheduled position. This paper focuses on the single-machine scheduling problems with the objectives of minimizing the makespan, total completion time, total weighted completion time, discounted total weighted completion time, and maximum lateness based on the proposed model, respectively. It shows that they are polynomially solvable and optimal under certain conditions. Additionally, it presents some approximation algorithms based on the optimal schedules for the corresponding single-machine scheduling problems and analyzes their worst case error bound.","Optimal scheduling,
Single machine scheduling,
Job shop scheduling,
Minimization,
Approximation algorithms,
Approximation methods"
WR-3 Band Waveguides and Filters Fabricated Using SU8 Photoresist Micromachining Technology,"This paper demonstrates a two-layer SU8 photoresist micromachining technology that has similar performance to conventionally machined metal. The technology is demonstrated in the WR-3 band (220-325 GHz). Three different WR-3 band circuits, namely a WR-3 band straight through waveguide, a bandpass filter and a dual-band filter are demonstrated. For the measurements, a conventionally precision machined metal block was used for the WR-3 band waveguide and the bandpass filter to achieve good calibration and accurate interconnection with standard waveguide flanges; whereas, for the dual-band filter, two back-to-back right-angle bends are added in order to achieve accurate, reliable waveguide interconnection without using the metal block. A measured average insertion loss of 0.03 dB/mm has been achieved for the 14.97 mm long straight through waveguide. This is comparable to the loss of around 0.02 dB/mm for a standard metal waveguide at this frequency. The fifth-order waveguide filter exhibits an 8% 3 dB bandwidth at a central frequency of around 300 GHz. The minimum passband insertion loss was measured to be around 1 dB and the return loss was better than 10 dB throughout the passband. The filter results showed a notable improvement over those obtained from the separate SU8 layer technique that was also used to make the same devices for comparison. To further demonstrate the advantages of the new two-layer SU8 micromachining technique, the dual-band filter included isolated regions in the waveguide channels that would have not been possible for micromachining using the previous separate single layer technique. The performance of the micromachined dual band filter was excellent in terms of very low insertion losses on both passbands.","Millimeter wave devices,
Loss measurement,
Insertion loss,
Micromachining,
Dual band,
Resists"
Real-Time Path Planning for Coordinated Transport of Multiple Particles Using Optical Tweezers,"Automated transport of multiple particles using optical tweezers requires real-time path planning to move them in coordination by avoiding collisions among themselves and with randomly moving obstacles. This paper develops a decoupled and prioritized path planning approach by sequentially applying a partially observable Markov decision process algorithm on every particle that needs to be transported. We use an iterative version of a maximum bipartite graph matching algorithm to assign given goal locations to such particles. We then employ a three-step method consisting of clustering, classification, and branch and bound optimization to determine the final collision-free paths. We demonstrate the effectiveness of the developed approach via experiments using silica beads in a holographic tweezers setup. We also discuss the applicability of our approach and challenges in manipulating biological cells indirectly by using the transported particles as grippers.","Real-time systems,
Grippers,
Path planning,
Collision avoidance,
Markov processes"
Target Selection With Hybrid Feature for BCI-Based 2-D Cursor Control,"To control a cursor on a monitor screen, a user generally needs to perform two tasks sequentially. The first task is to move the cursor to a target on the monitor screen (termed a 2-D cursor movement), and the second task is either to select a target of interest by clicking on it or to reject a target that is not of interest by not clicking on it. In a previous study, we implemented the former function in an EEG-based brain-computer interface system using motor imagery and the P300 potential to control the horizontal and vertical cursor movements, respectively. In this study, the target selection or rejection functionality is implemented using a hybrid feature from motor imagery and the P300 potential. Specifically, to select the target of interest, the user must focus his or her attention on a flashing button to evoke the P300 potential, while simultaneously maintaining an idle state of motor imagery. Otherwise, the user performs left-/right-hand motor imagery without paying attention to any buttons to reject the target. Our data analysis and online experimental results validate the effectiveness of our approach. The proposed hybrid feature is shown to be more effective than the use of either the motor imagery feature or the P300 feature alone. Eleven subjects attended our online experiment, in which a trial involved sequential 2-D cursor movement and target selection. The average duration of each trial and average accuracy of target selection were 18.19 s and 93.99% , respectively, and each target selection or rejection event was performed within 2 s.","Feature extraction,
Ash,
Accuracy,
Electroencephalography,
Image color analysis,
Support vector machines,
Data analysis"
Interference Aware-Coordinated Beamforming in a Multi-Cell System,"In this paper, we propose jointly optimized linear transceiver algorithms called interference aware-coordinated beamforming (IA-CBF) for a two-cell system where each base station is equipped with multiple transmit antennas. To generalize IA-CBF to more than two-cell scenarios, a new beam-switching mechanism combined with IA-CBF is proposed. For a two-cell system, we derive a minimum-mean-square-error-type IA-CBF algorithm based on a lower bound on the achievable sum rate. We propose optimal (under an assumption of zero other-cell interference) and suboptimal transmit/receive beamforming vectors through zero-forcing IA-CBF algorithms. We also investigate the optimality of the proposed IA-CBF algorithms with respect to the number of receive antennas. Numerical results confirm that the proposed system with two transmit/receive antennas achieves the full degrees of freedom (a.k.a. multiplexing gain) of the two-cell multiple-input multiple-output channel while showing a better sum rate performance than competitive solutions such as non-cooperative eigen-beamforming and interference nulling. A three-dimensional ray tracing tool is also used to evaluate the proposed multi-cell IA-CBF algorithm.","Vectors,
Array signal processing,
Base stations,
Mobile communication,
MIMO,
Interference channels"
LQR-RRT*: Optimal sampling-based motion planning with automatically derived extension heuristics,"The RRT* algorithm has recently been proposed as an optimal extension to the standard RRT algorithm [1]. However, like RRT, RRT* is difficult to apply in problems with complicated or underactuated dynamics because it requires the design of a two domain-specific extension heuristics: a distance metric and node extension method. We propose automatically deriving these two heuristics for RRT* by locally linearizing the domain dynamics and applying linear quadratic regulation (LQR). The resulting algorithm, LQR-RRT*, finds optimal plans in domains with complex or underactuated dynamics without requiring domain-specific design choices. We demonstrate its application in domains that are successively torque-limited, underactuated, and in belief space.","Trajectory,
Heuristic algorithms,
Planning,
Measurement,
Standards,
Cost function,
Convergence"
Multisensor Data Fusion in an Integrated Tracking System for Endoscopic Surgery,"Surgical planning and navigation systems are vital for minimally invasive endoscopic surgeries but it is challenging to track the position and orientation of intrabody surgical instruments in these procedures. In order to address this problem, we propose a tracking system including multiple-sensor integration and data fusion. The proposed tracking approach is free of the constraints of line-of-sight, less subject to environmental distortion, and with higher update rate. By incorporating electromagnetic and inertial sensors, the system yields continuous 6-DOF information. Based on a system dynamic model and estimation theories, a new multisensor fusion algorithm, cascade orientation and position-estimation algorithm, is proposed for the integrated tracking device. The experimental results show that the proposed algorithms achieve accurate orientation and position tracking with robustness.","Surgery,
Electromagnetics,
Optical sensors,
Biomedical optical imaging,
Optical imaging,
Adaptive optics"
Scale- and Rotation-Invariant Local Binary Pattern Using Scale-Adaptive Texton and Subuniform-Based Circular Shift,"This paper proposes an effective scale- and rotation-invariant local binary pattern (LBP) feature for texture classification. A circular neighboring set of an image pixel is defined as a scale-adaptive texton by taking into account the fundamental local structure property of the pixel. The scale space of a texture image is derived by the Laplacian of the Gaussian and then employed to determine the optimal scale of each pixel reflecting the characteristic length of the corresponding structure and determining the radius of the scale-adaptive texton. Different pixels have different optimal scales, resulting in the scale invariance. Contrary to the traditional LBP features that usually ignore global spatial information, the proposed method also defines subuniform patterns of each uniform pattern to improve the discrimination. For each uniform pattern, the subuniform pattern with the maximum statistical value is defined as the dominant orientation subuniform pattern. It is moved to the first column, and the others are circularly shifted. Experimental results demonstrate a good discrimination capability of the proposed scale- and rotation-invariant LBP in texture classification. Particularly, the LBP based on the scale-adaptive texton is promising to be powerful for texture description and scale-invariant texture classification, and the circular shift subuniform LBP can further improve the performance in the rotation-invariant texture classification.","Histograms,
Feature extraction,
Indexes,
Joints,
Kernel,
Data mining,
Educational institutions"
BSIM-IMG: A Compact Model for Ultrathin-Body SOI MOSFETs With Back-Gate Control,"In this paper, we present an accurate and computationally efficient model for circuit simulation of ultrathin-body silicon-on-insulator MOSFETs with strong back-gate control. This work advances previous works in terms of numerical accuracy, computational efficiency, and behavior of the higher order derivatives of the drain current. We propose a consistent analytical solution for the calculation of front- and back-gate surface potentials and inversion charge. The accuracy of our surface potential calculation is on the order of nanovolts. The drain current model includes velocity saturation, channel-length modulation, mobility degradation, quantum confinement effect, drain-induced barrier lowering, and self-heating effect. The model has correct behavior for derivatives of the drain current and shows an excellent agreement with experimental data for long- and short-channel devices with 8-nm-thin silicon body and 10-nm-thin BOX.",
Performance Analysis of Probabilistic Multipath Transmission of Video Streaming Traffic over Multi-Radio Wireless Devices,"Popular smart wireless devices become equipped with multiple radio interfaces. Multihoming support can be enabled to allow for multiple simultaneous associations with heterogeneous networks. In this study, we focus on video streaming traffic and propose analytical approaches to evaluate the packet-level and call-level performance of a multipath transmission scheme, which sends video traffic bursts over multiple available channels in a probabilistic manner. A probability generation function (PGF) and z-transform method is applied to derive the PGF of packet delay and any arbitrary moment in general. Particularly, we can obtain the average delay, delay jitter, and delay outage probability. The essential characteristics of video traffic are taken into account, such as deterministic burst intervals, highly dynamic burst length, and batch arrivals of transmission packets. The video substream traffic resulting from the probabilistic flow splitting is characterized by means of zero-inflated models. Further, the call-level performance, in terms of flow blocking probability and system throughput, is evaluated with a three-dimensional Markov process and compared with that of an always-best access selection. The numerical and simulations results demonstrate the effectiveness of our analysis framework and the performance gain of multipath transmission.","Streaming media,
Delay,
Wireless communication,
Probabilistic logic,
Throughput,
Mobile communication,
Bandwidth"
An Opportunistic Resource Sharing and Topology-Aware mapping framework for virtual networks,"Network virtualization provides a promising way to overcome Internet ossification. A major challenge is virtual network mapping, i.e., how to embed multiple virtual network requests with resource constraints into a substrate network, such that physical resources are utilized in an efficient and effective manner. Since this problem is known to be NP-complete, a variety of heuristic algorithms have been proposed. In this paper, we re-examine this problem and propose a virtual network mapping framework, ORS TA, which is based on Opportunistic Resource Sharing and Topology-Aware node ranking. Opportunistic resource sharing is taken into consideration at the entire network level for the first time and we develop an online approximation algorithm, FFA, for solving the corresponding time slot assignment problem. To measure the topology importance of a substrate node, a node ranking method, MCRank, based on Markov chain is presented. We also devise a simple and practical method to estimate the residual resource of a substrate node/link. Extensive simulation experiments demonstrate that the proposed framework enables the substrate network to achieve efficient physical resource utilization and to accept many more virtual network requests over time.",
An adaptive technique to improve wireless power transfer for consumer electronics,"This paper presents an adaptive technique to enhance the efficiency of magnetic resonance based wireless power transfer system for future portable consumer electronics. In order to transfer energy to mobile devices, asymmetric coupling resonators with larger sizes of coils in a transmitter than those in a receiver are exploited. By changing a coupling coefficient between coils only in the transmitting side, the system performance increases significantly. An experiment setup has been developed, and the S21 parameter has been measured showing 3.3 dB improvement of system using the adaptive technique at a distance of 65 cm. An important finding is that the technique is also effective in case of multiple receiving coils. The measured performance was improved by roughly 1 dB with the use of the adaptive technique.","Coils,
Receivers,
Couplings,
Consumer electronics,
Wireless communication,
Resonant frequency,
Adaptive systems"
Detecting texts of arbitrary orientations in natural images,"With the increasing popularity of practical vision systems and smart phones, text detection in natural scenes becomes a critical yet challenging task. Most existing methods have focused on detecting horizontal or near-horizontal texts. In this paper, we propose a system which detects texts of arbitrary orientations in natural images. Our algorithm is equipped with a two-level classification scheme and two sets of features specially designed for capturing both the intrinsic characteristics of texts. To better evaluate our algorithm and compare it with other competing algorithms, we generate a new dataset, which includes various texts in diverse real-world scenarios; we also propose a protocol for performance evaluation. Experiments on benchmark datasets and the proposed dataset demonstrate that our algorithm compares favorably with the state-of-the-art algorithms when handling horizontal texts and achieves significantly enhanced performance on texts of arbitrary orientations in complex natural scenes.","Shape,
Image edge detection,
Algorithm design and analysis,
Clutter,
Joining processes,
Histograms,
Robustness"
Model-Based Estimation of Knee Stiffness,"During natural locomotion, the stiffness of the human knee is modulated continuously and subconsciously according to the demands of activity and terrain. Given modern actuator technology, powered transfemoral prostheses could theoretically provide a similar degree of sophistication and function. However, experimentally quantifying knee stiffness modulation during natural gait is challenging. Alternatively, joint stiffness could be estimated in a less disruptive manner using electromyography (EMG) combined with kinetic and kinematic measurements to estimate muscle force, together with models that relate muscle force to stiffness. Here we present the first step in that process, where we develop such an approach and evaluate it in isometric conditions, where experimental measurements are more feasible. Our EMG-guided modeling approach allows us to consider conditions with antagonistic muscle activation, a phenomenon commonly observed in physiological gait. Our validation shows that model-based estimates of knee joint stiffness coincide well with experimental data obtained using conventional perturbation techniques. We conclude that knee stiffness can be accurately estimated in isometric conditions without applying perturbations, which presents an important step toward our ultimate goal of quantifying knee stiffness during gait.","Muscles,
Torque,
Knee,
Electromyography,
Joints,
Force"
Local Color Vector Binary Patterns From Multichannel Face Images for Face Recognition,"This paper proposes a novel face descriptor based on color information, i.e., so-called local color vector binary patterns (LCVBPs), for face recognition (FR). The proposed LCVBP consists of two discriminative patterns: color norm patterns and color angular patterns. In particular, we have designed a method for extracting color angular patterns, which enables to encode the discriminating texture patterns derived from spatial interactions among different spectral-band images. In order to perform FR tasks, the proposed LCVBP feature is generated by combining multiple features extracted from both color norm patterns and color angular patterns. Extensive and comparative experiments have been conducted to evaluate the proposed LCVBP feature on five public databases. Experimental results show that the proposed LCVBP feature is able to yield excellent FR performance for challenging face images. In addition, the effectiveness of the proposed LCVBP feature has successfully been tested by comparing other state-of-the-art face descriptors.","Image color analysis,
Face,
Feature extraction,
Histograms,
Vectors,
Gray-scale,
Lighting"
Optimal power allocation for GSVD-based beamforming in the MIMO Gaussian wiretap channel,"This paper considers a multiple-input multiple-output (MIMO) Gaussian wiretap channel model, where there exists a transmitter, a legitimate receiver and an eavesdropper, each equipped with multiple antennas. Perfect secrecy is achieved when the transmitter and the legitimate receiver can communicate at some positive rate, while ensuring that the eavesdropper gets zero bits of information. In this paper, the perfect secrecy rate of the multiple antenna MIMO wiretap channel is maximized for arbitrary numbers of antennas under the assumption that the transmitter performs beamforming based on the generalized singular value decomposition (GSVD). More precisely, the optimal allocation of power for the GSVD-based precoder that maximizes the achievable secrecy rate is derived. Numerical results are presented to illustrate that the achievable secrecy rate of the GSVD-based precoding approach is nearly identical to that of the optimal scheme.","Resource management,
MIMO,
Array signal processing,
Covariance matrix,
Transmitters,
Signal to noise ratio,
Receivers"
A Filter Approach to Multiple Feature Construction for Symbolic Learning Classifiers Using Genetic Programming,"Feature construction is an effort to transform the input space of classification problems in order to improve the classification performance. Feature construction is particularly important for classifier inducers that cannot transform their input space intrinsically. This paper proposes GPMFC, a multiple-feature construction system for classification problems using genetic programming (GP). This paper takes a nonwrapper approach by introducing a filter-based measure of goodness for constructed features. The constructed, high-level features are functions of original input features. These functions are evolved by GP using an entropy-based fitness function that maximizes the purity of class intervals. A decomposable objective function is proposed so that the system is able to construct multiple high-level features for each problem. The constructed features are used to transform the original input space to a new space with better separability. Extensive experiments are conducted on a number of benchmark problems and symbolic learning classifiers. The results show that, in most cases, the new approach is highly effective in increasing the classification performance in rule-based and decision tree classifiers. The constructed features help improve the learning performance of symbolic learners. The constructed features, however, may lack intelligibility.","Decision trees,
Transforms,
Numerical models,
Genetic programming,
Machine learning algorithms,
Feature extraction,
Biological cells"
Autonomous Gas-Sensitive Microdrone: Wind Vector Estimation and Gas Distribution Mapping,"This article presents the development and validation of an autonomous, gas sensitive microdrone that is capable of estimating the wind vector in real time using only the onboard control unit of the microdrone and performing gas distribution mapping (DM). Two different sampling approaches are suggested to address this problem. On the one hand, a predefined trajectory is used to explore the target area with the microdrone in a real-world gas DM experiment. As an alternative sampling approach, we introduce an adaptive strategy that suggests next sampling points based on an artificial potential field (APF). Initial results in real-world experiments demonstrate the capability of the proposed adaptive sampling strategy for gas DM and its use for gas source localization.","Robot sensing systems,
Real time systems,
Gas detectors,
Delta modulation,
Mobile communication,
Delta modulation"
Intra-cloud lightning: Building CDNs in the cloud,"Content distribution networks (CDNs) using storage clouds have recently started to emerge. Compared to traditional CDNs, storage cloud-based CDNs have the advantage of cost effectively offering hosting services to Web content providers without owning infrastructure. However, existing work on replica placement in CDNs does not readily apply in the cloud. In this paper, we investigated the joint problem of building distribution paths and placing Web server replicas in cloud CDNs to minimize the cost incurred on the CDN providers while satisfying QoS requirements for user requests. We formulate the cost optimization problem with accurate cost models and QoS requirements and show that the monthly cost can be as low as 2.62 US Dollars for a small Web site. We develop a suite of offline, online-static and online-dynamic heuristic algorithms that take as input network topology and work load information such as user location and request rates. We then evaluate the heuristics via Web trace-based simulation, and show that our heuristics behave very close to optimal under various network conditions.","Quality of service,
Servers,
Heuristic algorithms,
Web sites,
Network topology,
Bandwidth,
Topology"
Adaptive Approximate Data Collection for Wireless Sensor Networks,"Data collection is a fundamental task in wireless sensor networks. In many applications of wireless sensor networks, approximate data collection is a wise choice due to the constraints in communication bandwidth and energy budget. In this paper, we focus on efficient approximate data collection with prespecified error bounds in wireless sensor networks. The key idea of our data collection approach ADC (Approximate Data Collection) is to divide a sensor network into clusters, discover local data correlations on each cluster head, and perform global approximate data collection on the sink node according to model parameters uploaded by cluster heads. Specifically, we propose a local estimation model to approximate the readings of sensor nodes in subsets, and prove rated error-bounds of data collection using this model. In the process of model-based data collection, we formulate the problem of selecting the minimum subset of sensor nodes into a minimum dominating set problem which is known to be NP-hard, and propose a greedy heuristic algorithm to find an approximate solution. We further propose a monitoring algorithm to adaptively adjust the composition of node subsets according to changes of sensor readings. Our trace-driven simulations demonstrate that ADC remarkably reduces communication cost of data collection with guaranteed error bounds.",
Regularized Kernel Discriminant Analysis With a Robust Kernel for Face Recognition and Verification,"We propose a robust approach to discriminant kernel-based feature extraction for face recognition and verification. We show, for the first time, how to perform the eigen analysis of the within-class scatter matrix directly in the feature space. This eigen analysis provides the eigenspectrum of its range space and the corresponding eigenvectors as well as the eigenvectors spanning its null space. Based on our analysis, we propose a kernel discriminant analysis (KDA) which combines eigenspectrum regularization with a feature-level scheme (ER-KDA). Finally, we combine the proposed ER-KDA with a nonlinear robust kernel particularly suitable for face recognition/verification applications which require robustness against outliers caused by occlusions and illumination changes. We applied the proposed framework to several popular databases (Yale, AR, XM2VTS) and achieved state-of-the-art performance for most of our experiments.","Training,
Feature extraction,
Face,
Null space,
Eigenvalues and eigenfunctions,
Robustness"
Linear and Nonlinear Elastic Modulus Imaging: An Application to Breast Cancer Diagnosis,"We reconstruct the in vivo spatial distribution of linear and nonlinear elastic parameters in ten patients with benign (five) and malignant (five) tumors. The mechanical behavior of breast tissue is represented by a modified Veronda-Westmann model with one linear and one nonlinear elastic parameter. The spatial distribution of these elastic parameters is determined by solving an inverse problem within the region of interest (ROI). This inverse problem solution requires the knowledge of the displacement fields at small and large strains. The displacement fields are measured using a free-hand ultrasound strain imaging technique wherein, a linear array ultrasound transducer is positioned on the breast and radio frequency echo signals are recorded within the ROI while the tissue is slowly deformed with the transducer. Incremental displacement fields are determined from successive radio-frequency frames by employing cross-correlation techniques. The rectangular regions of interest were subjectively selected to obtain low noise displacement estimates and therefore were variables that ranged from 346 to 849.6 mm . It is observed that malignant tumors stiffen at a faster rate than benign tumors and based on this criterion nine out of ten tumors were correctly classified as being either benign or malignant.",
SimPL: An Effective Placement Algorithm,"We propose a self-contained, flat, quadratic global placer that is simpler than existing placers and easier to integrate into timing-closure flows. It maintains lower-bound and upper-bound placements that converge to a final solution. The upper-bound placement is produced by a novel look-ahead legalization algorithm. Our placer SimPL outperforms mPL6, FastPlace3, NTUPlace3, APlace2, and Capo simultaneously in runtime and solution quality, running 7.10 times faster than mPL6 (when using a single thread) and reducing wirelength by 3% on the ISPD 2005 benchmark suite. More significant improvements are achieved on larger benchmarks. The new algorithm is amenable to parallelism, and we report empirical studies with SSE2 instructions and up to eight parallel threads.",
A Microstrip Patch Electronically Steerable Parasitic Array Radiator (ESPAR) Antenna With Reactance-Tuned Coupling and Maintained Resonance,"A new approach to parasitic phased-array antennas is presented. A symmetric two-layer, single-input inexpensive three-element array at 1-GHz employing varactors as tuning mechanisms are designed, fabricated, and measured. The driven element is mutually coupled to two parasitic elements in the H-plane. The varactors are used to control the mutual coupling and beam scanning and to maintain resonance at 1 GHz. A continuous scanning range of -15 + 15° is measured with maintained impedance matching and radiation pattern integrity. The low cost of diode varactors, used in place of expensive phase shifters, allows for more economic fabrication. This is advantageous to applications in point-to-point communication systems, weather, and target tracking radar systems.","Couplings,
Arrays,
Varactors,
Capacitance,
Microstrip,
Resonant frequency,
Loading"
Geometry of power flows in tree networks,"We investigate the problem of power flow and its relationship to optimization in tree networks. We show that due to the tree topology of the network, the general optimal power flow problem simplifies greatly. Our approach is to look at the injection region of the power network. The injection region is simply the set of all vectors of bus power injections that satisfy the network and operation constraints. The geometrical object of interest is the set of Pareto-optimal points of the injection region, since they are the solutions to the minimization of increasing functions. We view the injection region as a linear transformation of the higher dimensional power flow region, which is the set of all feasible power flows, one for each direction of each line. We show that if the voltage magnitudes are fixed, then the injection region becomes a product of two-bus power flow regions, one for each line in the network. Using this decomposition, we show that under the practical condition that the angle difference across each line is not too large, the set of Pareto-optimal points of the injection region remains unchanged by taking the convex hull. Therefore, the optimal power flow problem can be convexified and efficiently solved. This result improves upon earlier works since it does not make any assumptions about the active bus power constraints. We also obtain some partial results for the variable voltage magnitude case.","Vectors,
Optimization,
Network topology,
Topology,
Thermal stability,
Admittance,
Geometry"
Atomic Congestion Games on Graphs and Their Applications in Networking,"In this paper, we introduce and analyze the properties of a class of games, the atomic congestion games on graphs (ACGGs), which is a generalization of the classical congestion games. In particular, an ACGG captures the spatial information that is often ignored in a classical congestion game. This is useful in many networking problems, e.g., wireless networks where interference among the users heavily depends on the spatial information. In an ACGG, a player's payoff for using a resource is a function of the number of players who interact with it and use the same resource. Such spatial information can be captured by a graph. We study fundamental properties of the ACGGs: under what conditions these games possess a pure strategy Nash equilibrium (PNE), or the finite improvement property (FIP), which is sufficient for the existence of a PNE. We show that a PNE may not exist in general, but that it does exist in many important special cases including tree, loop, or regular bipartite networks. The FIP holds for important special cases including systems with two resources or identical payoff functions for each resource. Finally, we present two wireless network applications of ACGGs: power control and channel contention under IEEE 802.11.",
Copyright Protection for E-Government Document Images,"The proposed copyright protection scheme combines the discrete cosine transform (DCT) and singular value decomposition (SVD) using a control parameter to avoid the false-positive problem. In this article, we propose an efficient copyright protection scheme for e-government document images. First, we apply the discrete cosine transform (DCT) to the host image and use the zigzag space-filling curve (SFC) for the DCT coefficients. The DCT coefficients in the zigzag manner are then mapped into four areas with different frequencies in a rectangular shape. Then, we apply the singular value decomposition (SVD) operation to each area, and the host image is modified by the left singular vectors and the singular values of the DCT-transformed watermark to embed the watermark image. The left singular vectors and singular values are used as a control parameter to avoid the false-positive problem. Each area decides the scaling factor's optimal value using a genetic algorithm (GA) with the mean of the watermark's SVs. A scaling factor is simulated by chromosomes, and several optimization GA operators are used. After remapping each modified coefficient DCT back to the original position, the proposed inverse DCT produces the watermarked image. Our experimental results show that we can improve the image quality GA-based evolution and that this approach is robust under several kinds of attacks.","Discrete cosine transforms,
Watermarking,
Genetic algorithms,
Electronic government,
Electronic mail,
Copyright protection"
Tumor Burden Analysis on Computed Tomography by Automated Liver and Tumor Segmentation,"The paper presents the automated computation of hepatic tumor burden from abdominal computed tomography (CT) images of diseased populations with images with inconsistent enhancement. The automated segmentation of livers is addressed first. A novel 3-D affine invariant shape parameterization is employed to compare local shape across organs. By generating a regular sampling of the organ's surface, this parameterization can be effectively used to compare features of a set of closed 3-D surfaces point-to-point, while avoiding common problems with the parameterization of concave surfaces. From an initial segmentation of the livers, the areas of atypical local shape are determined using training sets. A geodesic active contour corrects locally the segmentations of the livers in abnormal images. Graph cuts segment the hepatic tumors using shape and enhancement constraints. Liver segmentation errors are reduced significantly and all tumors are detected. Finally, support vector machines and feature selection are employed to reduce the number of false tumor detections. The tumor detection true position fraction of 100% is achieved at 2.3 false positives/case and the tumor burden is estimated with 0.9% error. Results from the test data demonstrate the method's robustness to analyze livers from difficult clinical cases to allow the temporal monitoring of patients with hepatic cancer.","Liver,
Tumors,
Shape,
Image segmentation,
Computed tomography,
Cancer"
Novel Tensor Product Models for Automatic Transmission System Control,"This paper discusses novel tensor product (TP) models for the control of two complex components of the vehicle automatic transmission systems, namely the drive line without clutch and, the valve-clutch. The TP models are obtained by a transformation of the linear parameter-varying models derived from the first principle nonlinear mathematical models of the controlled processes. Experimental results validate the performance of the proposed TP models.","Mathematical model,
Engines,
Wheels,
Control systems,
State-space methods,
Tensile stress,
Vectors"
IEEE 802.11 Saturation Throughput Analysis in the Presence of Hidden Terminals,"Due to its usefulness and wide deployment, IEEE 802.11 has been the subject of numerous studies, but still lacks a complete analytical model. Hidden terminals are common in IEEE 802.11 and cause the degradation of throughput. Despite the importance of the hidden terminal problem, there have been a relatively small number of studies that consider the effect of hidden terminals on IEEE 802.11 throughput, and many are not accurate for a wide range of conditions. In this paper, we present an accurate new analytical saturation throughput model for the infrastructure case of IEEE 802.11 in the presence of hidden terminals. Simulation results show that our model is accurate in a wide variety of cases.","Throughput,
Markov processes,
IEEE 802.11 Standards,
Analytical models,
Multiaccess communication,
Load modeling,
Computational modeling"
Distributed Coordination of Internet Data Centers Under Multiregional Electricity Markets,"This paper addresses the problem of electricity cost management for Internet service providers with a collection of spatially distributed data centers. As the demand on Internet services and cloud computing has kept increasing in recent years, the power usage associated with IDC operations has been uprising significantly. The cyber and physical aspects of IDCs interact with each other, and bring unprecedented challenges in power management. While most existing research focuses on reducing power consumptions of IDCs at one specific location, the problem of reducing the total electricity cost has been overlooked. This is an important problem faced by service providers, especially in the present multielectricity-market environment, where the price of electricity may exhibit temporal and spatial diversities. Further, for these service providers, guaranteeing the quality of service (QoS; i.e., service level objectives) such as service delay guarantees to the end users is of critical importance. This paper studies the problem of minimizing the total electricity cost geared to QoS constraint as well as the location diversity and time diversity of electricity price under multiregional electricity markets. We jointly consider both the cyber and physical management capabilities of IDCs, and exploit both the center-level load balancing and the server-level power control in a unified scheme. We model the problem as a constrained mixed integer programming based on generalized benders decomposition (GBD) technique. Extensive evaluations based on real-life electricity price data for multiple IDC locations demonstrate the effectiveness of our scheme.","Power system economics,
Electricity supply industry,
Load management,
Internet,
Power control,
Energy efficiency,
Cyberspace,
Network topology,
Power system management,
Network servers,
Database systems"
Fusion of Difference Images for Change Detection Over Urban Areas,"As a result of urbanization, land use/land cover classes in urban areas are changing rapidly, and this trend increased in the recent years. Change information detected from multi-temporal remote sensing images can thus help to understand urban development and to effectively support urban planning. Differences in reflectance spectra, easily obtained by multi-temporal remote sensing images, are important indicators to characterize these changes. Although many algorithms were proposed to generate difference images, the results are usually greatly inconsistent. In order to integrate the merits of different algorithms to recognize spectral changes, fusion techniques merging multiple difference images are proposed and implemented in this paper. Feature and decision level fusion are used to combine simple change detectors, and to build an automatic change detection procedure. The proposed approach is tested with multi-temporal CBERS and HJ-1 images, and experimental results demonstrate its effectiveness and reliability. By integrating different change information, the appropriate fusion method can be selected according to the specific application in order to minimize the omission or the commission errors.","Remote sensing,
Feature extraction,
Urban areas,
Change detection algorithms,
Principal component analysis,
Accuracy,
Earth"
Formulating Spatially Varying Performance in the Statistical Fusion Framework,"To date, label fusion methods have primarily relied either on global [e.g., simultaneous truth and performance level estimation (STAPLE), globally weighted vote] or voxelwise (e.g., locally weighted vote) performance models. Optimality of the statistical fusion framework hinges upon the validity of the stochastic model of how a rater errs (i.e., the labeling process model). Hitherto, approaches have tended to focus on the extremes of potential models. Herein, we propose an extension to the STAPLE approach to seamlessly account for spatially varying performance by extending the performance level parameters to account for a smooth, voxelwise performance level field that is unique to each rater. This approach, Spatial STAPLE, provides significant improvements over state-of-the-art label fusion algorithms in both simulated and empirical data sets.","Estimation,
Humans,
Image segmentation,
Context,
Labeling,
Accuracy,
Robustness"
Generation of Propagating Bessel Beams Using Leaky-Wave Modes: Experimental Validation,"We present the experimental generation of Bessel beams using a leaky radial waveguide. The radial waveguide consists of a capacitive sheet over a ground plane. The capacitive sheet is composed of patch elements printed on both sides of a dielectric substrate. The radial waveguide is coaxially fed and supports an azimuthally invariant leaky-wave mode whose normal electric-field component is a truncated, zeroth-order Bessel function. Two prototypes are presented with the same propagation constant and lateral extent, but different attenuation constants. 2D electric field measurements and their respective Fourier transforms validate the operation of the prototypes as Bessel-beam launchers at two frequency bands. Cleaner patterns are achieved by the prototype with lower attenuation constant. The dual-band capability and associated frequency dependent resolution can be useful in near-field planar focusing systems. The proposed structure can be used for generating arbitrary zeroth-order propagating Bessel beams at microwave and millimeter-wave frequencies.","Prototypes,
Impedance,
Propagation constant,
Dispersion,
Electric variables measurement,
Frequency measurement,
Surface impedance"
Using technical debt data in decision making: Potential decision approaches,"The management of technical debt ultimately requires decision making - about incurring, paying off, or deferring technical debt instances. This position paper discusses several existing approaches to complex decision making, and suggests that exploring their applicability to technical debt decision making would be a worthwhile subject for further research.",
Integrated impact analysis for managing software changes,"The paper presents an adaptive approach to perform impact analysis from a given change request to source code. Given a textual change request (e.g., a bug report), a single snapshot (release) of source code, indexed using Latent Semantic Indexing, is used to estimate the impact set. Should additional contextual information be available, the approach configures the best-fit combination to produce an improved impact set. Contextual information includes the execution trace and an initial source code entity verified for change. Combinations of information retrieval, dynamic analysis, and data mining of past source code commits are considered. The research hypothesis is that these combinations help counter the precision or recall deficit of individual techniques and improve the overall accuracy. The tandem operation of the three techniques sets it apart from other related solutions. Automation along with the effective utilization of two key sources of developer knowledge, which are often overlooked in impact analysis at the change request level, is achieved. To validate our approach, we conducted an empirical evaluation on four open source software systems. A benchmark consisting of a number of maintenance issues, such as feature requests and bug fixes, and their associated source code changes was established by manual examination of these systems and their change history. Our results indicate that there are combinations formed from the augmented developer contextual information that show statistically significant improvement over standalone approaches.","Software,
Couplings,
Data mining,
Maintenance engineering,
History,
Information retrieval,
Automation"
Precise Segmentation of 3-D Magnetic Resonance Angiography,"Accurate automatic extraction of a 3-D cerebrovascular system from images obtained by time-of-flight (TOF) or phase contrast (PC) magnetic resonance angiography (MRA) is a challenging segmentation problem due to the small size objects of interest (blood vessels) in each 2-D MRA slice and complex surrounding anatomical structures (e.g., fat, bones, or gray and white brain matter). We show that due to the multimodal nature of MRA data, blood vessels can be accurately separated from the background in each slice using a voxel-wise classification based on precisely identified probability models of voxel intensities. To identify the models, an empirical marginal probability distribution of intensities is closely approximated with a linear combination of discrete Gaussians (LCDG) with alternate signs, using our previous EM-based techniques for precise linear combination of Gaussian-approximation adapted to deal with the LCDGs. The high accuracy of the proposed approach is experimentally validated on 85 real MRA datasets (50 TOF and 35 PC) as well as on synthetic MRA data for special 3-D geometrical phantoms of known shapes.","Image segmentation,
Biomedical imaging,
Blood vessels,
Three dimensional displays,
Deformable models,
Probability distribution,
Brain modeling"
Decoding Intra-Limb and Inter-Limb Kinematics During Treadmill Walking From Scalp Electroencephalographic (EEG) Signals,"Brain-machine interface (BMI) research has largely been focused on the upper limb. Although restoration of gait function has been a long-standing focus of rehabilitation research, surprisingly very little has been done to decode the cortical neural networks involved in the guidance and control of bipedal locomotion. A notable exception is the work by Nicolelis' group at Duke University that decoded gait kinematics from chronic recordings from ensembles of neurons in primary sensorimotor areas in rhesus monkeys. Recently, we showed that gait kinematics from the ankle, knee, and hip joints during human treadmill walking can be inferred from the electroencephalogram (EEG) with decoding accuracies comparable to those using intracortical recordings. Here we show that both intra- and inter-limb kinematics from human treadmill walking can be achieved with high accuracy from as few as 12 electrodes using scalp EEG. Interestingly, forward and backward predictors from EEG signals lagging or leading the kinematics, respectively, showed different spatial distributions suggesting distinct neural networks for feedforward and feedback control of gait. Of interest is that average decoding accuracy across subjects and decoding modes was ~ 0.68±0.08, supporting the feasibility of EEG-based BMI systems for restoration of walking in patients with paralysis.","Decoding,
Joints,
Legged locomotion,
Kinematics,
Electrodes,
Electroencephalography,
Hip"
Conceptual Design of A Multi-Agent System for Interconnected Power Systems Restoration,"Outages and faults in interconnected power systems may cause cascading sequences of events, and catastrophic failures of power systems. How to efficiently manage power systems and restore the systems from faults is a challenging research issue in power engineering. Multi-agent systems are employed to address such a challenge in recent years. A centralized coordination strategy was firstly introduced to manage agents in a power system. Such a strategy usually adopts a single central coordinator to control the whole system for system management, maintenance, and restoration purposes. However, disadvantages such as deficiencies in robustness, openness, and flexibility prevent this strategy from extensive online applications. Consequently, a decentralized coordination strategy was proposed to overcome such limitations. But the decentralized coordination strategy cannot efficiently provide a global solution when serious faults spread out in a power system. In this paper, a conceptual multi-agent system design is introduced to express our proposal in power system modeling. A novel dynamic team forming mechanism is proposed to dynamically manage agents in power system with a flexible coordination structure, so as to balance the effectiveness and efficiency of the introduced multi-agent system. The results from simulations of case studies indicate the performance of the proposed multi-agent model.","Power systems,
Barium,
Multiagent systems,
Complexity theory,
Robustness,
Process control,
Decision making"
Feature Selection Based on Class-Dependent Densities for High-Dimensional Binary Data,"Data and knowledge management systems employ feature selection algorithms for removing irrelevant, redundant, and noisy information from the data. There are two well-known approaches to feature selection, feature ranking (FR) and feature subset selection (FSS). In this paper, we propose a new FR algorithm, termed as class-dependent density-based feature elimination (CDFE), for binary data sets. Our theoretical analysis shows that CDFE computes the weights, used for feature ranking, more efficiently as compared to the mutual information measure. Effectively, rankings obtained from both the two criteria approximate each other. CDFE uses a filtrapper approach to select a final subset. For data sets having hundreds of thousands of features, feature selection with FR algorithms is simple and computationally efficient but redundant information may not be removed. On the other hand, FSS algorithms analyze the data for redundancies but may become computationally impractical on high-dimensional data sets. We address these problems by combining FR and FSS methods in the form of a two-stage feature selection algorithm. When introduced as a preprocessing step to the FSS algorithms, CDFE not only presents them with a feature subset, good in terms of classification, but also relieves them from heavy computations. Two FSS algorithms are employed in the second stage to test the two-stage feature selection idea. We carry out experiments with two different classifiers (naive Bayes' and kernel ridge regression) on three different real-life data sets (NOVA, HIVA, and GINA) of the”Agnostic Learning versus Prior Knowledge” challenge. As a stand-alone method, CDFE shows up to about 92 percent reduction in the feature set size. When combined with the FSS algorithms in two-stages, CDFE significantly improves their classification accuracy and exhibits up to 97 percent reduction in the feature set size. We also compared CDFE against the winning entries of the challenge and found that it outperforms the best results on NOVA and HIVA while obtaining a third position in case of GINA.","Mutual information,
Markov processes,
Redundancy,
Algorithm design and analysis,
Frequency selective surfaces,
Accuracy,
Approximation algorithms"
Chip Error Pattern Analysis in IEEE 802.15.4,"IEEE 802.15.4 standard specifies physical layer (PHY) and medium access control (MAC) sublayer protocols for low-rate and low-power communication applications. In this protocol, every 4-bit symbol is encoded into a sequence of 32 chips that are actually transmitted over the air. The 32 chips as a whole is also called a pseudonoise code (PN-Code). Due to complex channel conditions such as attenuation and interference, the transmitted PN-Code will often be received with some PN-Code chips corrupted. In this paper, we conduct a systematic analysis on these errors occurring at chip level. We find that there are notable error patterns corresponding to different cases. We then show that recognizing these patterns enables us to identify the channel condition in great details. We believe that understanding what happened to the transmission in our way can potentially bring benefit to channel coding, routing, and error correction protocol design. Finally, we propose Simple Rule, a simple yet effective method based on the chip error patterns to infer the link condition with an accuracy of over 96 percent in our evaluations.","Interference,
Time series analysis,
Measurement,
Attenuation,
Bars,
Mobile computing,
Spread spectrum communication"
Optical Flow Switching Networks,"Present-day networks are being challenged by dramatic increases in data rate demands of emerging applications. A new network architecture, incorporating “optical flow switching,” will enable significant rate growth, power efficiency, and cost-effective scalability of next-generation networks. We will explore architecture concepts germinated 22 years ago, technology and testbed demonstrations performed in the last 17 years, and the architecture construct from the physical layer to the transport layer of an implementable optical flow switching network that is scalable and manageable.","Optical fiber networks,
Optical switches,
Optical packet switching,
Optical amplifiers,
Image motion analysis,
Optical fibers"
Automatic Motion and Noise Artifact Detection in Holter ECG Data Using Empirical Mode Decomposition and Statistical Approaches,"We present a real-time method for the detection of motion and noise (MN) artifacts, which frequently interferes with accurate rhythm assessment when ECG signals are collected from Holter monitors. Our MN artifact detection approach involves two stages. The first stage involves the use of the first-order intrinsic mode function (F-IMF) from the empirical mode decomposition to isolate the artifacts' dynamics as they are largely concentrated in the higher frequencies. The second stage of our approach uses three statistical measures on the F-IMF time series to look for characteristics of randomness and variability, which are hallmark signatures of MN artifacts: the Shannon entropy, mean, and variance. We then use the receiver-operator characteristics curve on Holter data from 15 healthy subjects to derive threshold values associated with these statistical measures to separate between the clean and MN artifacts' data segments. With threshold values derived from 15 training data sets, we tested our algorithms on 30 additional healthy subjects. Our results show that our algorithms are able to detect the presence of MN artifacts with sensitivity and specificity of 96.63% and 94.73%, respectively. In addition, when we applied our previously developed algorithm for atrial fibrillation (AF) detection on those segments that have been labeled to be free from MN artifacts, the specificity increased from 73.66% to 85.04% without loss of sensitivity (74.48%-74.62%) on six subjects diagnosed with AF. Finally, the computation time was less than 0.2 s using a MATLAB code, indicating that real-time application of the algorithms is possible for Holter monitoring.","Manganese,
Electrocardiography,
Accuracy,
Noise measurement,
Noise,
Monitoring,
Sensitivity"
The Computational Materials Repository,"The possibilities for designing new materials based on quantum physics calculations are rapidly growing, but these design efforts lead to a significant increase in the amount of computational data created. The Computational Materials Repository (CMR) addresses this data challenge and provides a software infrastructure that supports the collection, storage, retrieval, analysis, and sharing of data produced by many electronic-structure simulators.","Quantum physics,
Materials processing,
Graphical user interfaces,
Database systems,
Taxonomy"
Bipolar Resistive RAM Characteristics Induced by Nickel Incorporated Into Silicon Oxide Dielectrics for IC Applications,"In this letter, we successfully produced resistive switching behaviors by nickel doped into silicon oxide at room temperature. The nickel element was doped into silicon oxide, which is a useful dielectric material in integrated circuit (IC) industries by cosputtering technology. Based on the proposed method, satisfactory reliability of the resistance switching device can be demonstrated by endurance and retention evaluation. We believe that the silicon oxide doped with nickel at room temperature is a promising method for resistive random access memory nonvolatile memory applications due to its compatibility with the IC processes.","Nickel,
Dielectrics,
Tin,
Resistance,
Silicon,
Nonvolatile memory,
Doping"
Secure and Energy-Efficient Disjoint Multipath Routing for WSNs,"Recent advances in microelectromechanical system (MEMS) technology have boosted the deployment of wireless sensor networks (WSNs). Limited by the energy storage capability of sensor nodes, it is crucial to jointly consider security and energy efficiency in data collection of WSNs. The disjoint multipath routing scheme with secret sharing is widely recognized as one of the effective routing strategies to ensure the safety of information. This kind of scheme transforms each packet into several shares to enhance the security of transmission. However, in many-to-one WSNs, shares have high probability to traverse through the same link and to be intercepted by adversaries. In this paper, we formulate the secret-sharing-based multipath routing problem as an optimization problem. Our objective aims at maximizing both network security and lifetime, subject to the energy constraints. To this end, a three-phase disjoint routing scheme called the Security and Energy-efficient Disjoint Route (SEDR) is proposed. Based on the secret-sharing algorithm, the SEDR scheme dispersively and randomly delivers shares all over the network in the first two phases and then transmits these shares to the sink node. Both theoretical and simulation results demonstrate that our proposed scheme has significant improvement in network security under both scenarios of single and multiple black holes without reducing the network lifetime.","Routing,
Wireless sensor networks,
Energy consumption,
Cryptography,
Dispersion,
Routing protocols"
Energy-Efficient Capture of Stochastic Events under Periodic Network Coverage and Coordinated Sleep,"We consider a high density of sensors randomly placed in a geographical area for event monitoring. The monitoring regions of the sensors may have significant overlap, and a subset of the sensors can be turned off to conserve energy, thereby increasing the lifetime of the monitoring network. Prior work in this area does not consider the event dynamics. In this paper, we show that knowledge about the event dynamics can be exploited for significant energy savings, by putting the sensors on a periodic on/off schedule. We discuss energy-aware optimization of the periodic schedule for the cases of an synchronous and a asynchronous network. To reduce the overhead of global synchronization, we further consider a spectrum of regionally synchronous networks where the size of the synchronization region is specifiable. Under the periodic scheduling, coordinated sleep by the sensors can be applied orthogonally to minimize the redundancy of coverage and further improve the energy efficiency. We consider the interactions between the periodic scheduling and coordinated sleep. We show that the asynchronous network exceeds any regionally synchronous network in the coverage intensity, thereby increasing the effectiveness of the event capture, though the opportunities for coordinated sleep decreases as the synchronization region gets smaller. When the sensor density is high, the asynchronous network with coordinated sleep can achieve extremely good event capture performance while being highly energy efficient.","Sensors,
Schedules,
Delay,
Optimization,
Synchronization,
Redundancy,
Monitoring"
Designing Chip-Level Nanophotonic Interconnection Networks,"Technology scaling will soon enable high-performance processors with hundreds of cores integrated onto a single die, but the success of such systems could be limited by the corresponding chip-level interconnection networks. There have been many recent proposals for nanophotonic interconnection networks that attempt to provide improved performance and energy-efficiency compared to electrical networks. This paper discusses the approach we have used when designing such networks, and provides a foundation for designing new networks. We begin by briefly reviewing the basic silicon-photonic device technology before outlining design issues and surveying previous nanophotonic network proposals at the architectural level, the microarchitectural level, and the physical level. In designing our own networks, we use an iterative process that moves between these three levels of design to meet application requirements given our technology constraints. We use our ongoing work on leveraging nanophotonics in an on-chip title-to-tile network, processor-to-main-memory network, and dynamic random-access memory (DRAM) channel to illustrate this design process.","Topology,
Network topology,
Nanoscale devices,
Microarchitecture,
Optical transmitters,
Receivers,
Multiprocessor interconnection"
Human and Machine Performance on Periocular Biometrics Under Near-Infrared Light and Visible Light,"Periocular biometrics is the recognition of individuals based on the appearance of the region around the eye. Periocular recognition may be useful in applications where it is difficult to obtain a clear picture of an iris for iris biometrics, or a complete picture of a face for face biometrics. Previous periocular research has used either visible-light (VL) or near-infrared (NIR) light images, but no prior research has directly compared the two illuminations using images with similar resolution. We conducted an experiment in which volunteers were asked to compare pairs of periocular images. Some pairs showed images taken in VL, and some showed images taken in NIR light. Participants labeled each pair as belonging to the same person or to different people. Untrained participants with limited viewing times correctly classified VL image pairs with 88% accuracy, and NIR image pairs with 79% accuracy. For comparison, we presented pairs of iris images from the same subjects. In addition, we investigated differences between performance on light and dark eyes and relative helpfulness of various features in the periocular region under different illuminations. We calculated performance of three computer algorithms on the periocular images. Performance for humans and computers was similar.","Iris recognition,
Face,
Humans,
Face recognition,
Lighting,
Accuracy"
Reducing interference between multiple structured light depth sensors using motion,"We present a method for reducing interference between multiple structured light-based depth sensors operating in the same spectrum with rigidly attached projectors and cameras. A small amount of motion is applied to a subset of the sensors so that each unit sees its own projected pattern sharply, but sees a blurred version of the patterns of other units. If high spacial frequency patterns are used, each sensor sees its own pattern with higher contrast than the patterns of other units, resulting in simplified pattern disambiguation. An analysis of this method is presented for a group of commodity Microsoft Kinect color-plus-depth sensors with overlapping views. We demonstrate that applying a small vibration with a simple motor to a subset of the Kinect sensors results in reduced interference, as manifested as holes and noise in the depth maps. Using an array of six Kinects, our system reduced interference-related missing data from from 16.6% to 1.4% of the total pixels. Another experiment with three Kinects showed an 82.2% percent reduction in the measurement error introduced by interference. A side-effect is blurring in the color images of the moving units, which is mitigated with post-processing. We believe our technique will allow inexpensive commodity depth sensors to form the basis of dense large-scale capture systems.","Cameras,
Interference,
Sensors,
Measurement uncertainty,
Prototypes,
Arrays,
Color"
Complex Interaction Between Tori and Onset of Three-Frequency Quasi-Periodicity in a Current Mode Controlled Boost Converter,"It is known that power electronic circuits like dc-dc converters are highly nonlinear systems, and that period doubling and Neimark-Sacker bifurcations are common sources of instability in such systems. It has also been shown that these two types of bifurcation may interact, giving rise to interesting dynamical phenomena. In this paper we show that in a current mode controlled dc-dc converter, periodic, quasi-periodic, and saturation behavior can coexist for the same parameter value, and there can be complex interactions between them. Furthermore, abrupt exit to saturation mode can be triggered by a torus-torus collision. Finally, we report the first observation of three-frequency quasi-periodicity in a power electronic system.","Orbits,
Bifurcation,
Eigenvalues and eigenfunctions,
Switches,
Manifolds,
Clocks,
Stability analysis"
Polynomial Fuzzy Observer Designs: A Sum-of-Squares Approach,"This paper presents a sum-of-squares (SOS) approach to polynomial fuzzy observer designs for three classes of polynomial fuzzy systems. The proposed SOS-based framework provides a number of innovations and improvements over the existing linear matrix inequality (LMI)-based approaches to Takagi-Sugeno (T-S) fuzzy controller and observer designs. First, we briefly summarize previous results with respect to a polynomial fuzzy system that is a more general representation of the well-known T-S fuzzy system. Next, we propose polynomial fuzzy observers to estimate states in three classes of polynomial fuzzy systems and derive SOS conditions to design polynomial fuzzy controllers and observers. A remarkable feature of the SOS design conditions for the first two classes (Classes I and II) is that they realize the so-called separation principle, i.e., the polynomial fuzzy controller and observer for each class can be separately designed without lack of guaranteeing the stability of the overall control system in addition to converging state-estimation error (via the observer) to zero. Although, for the last class (Class III), the separation principle does not hold, we propose an algorithm to design polynomial fuzzy controller and observer satisfying the stability of the overall control system in addition to converging state-estimation error (via the observer) to zero. All the design conditions in the proposed approach can be represented in terms of SOS and are symbolically and numerically solved via the recently developed SOSTOOLS and a semidefinite-program solver, respectively. To illustrate the validity and applicability of the proposed approach, three design examples are provided. The examples demonstrate the advantages of the SOS-based approaches for the existing LMI approaches to T-S fuzzy observer designs.","Polynomials,
Observers,
Fuzzy systems,
Nonlinear systems,
Bismuth,
Vectors,
Numerical stability"
On Signal Selection for Visibility Enhancement in Trace-Based Post-Silicon Validation,"Today's complex integrated circuit designs increasingly rely on post-silicon validation to eliminate bugs that escape from pre-silicon verification. One effective silicon debug technique is to monitor and trace the behaviors of the circuit during its normal operation. However, due to the associated overhead, designers can only afford to trace a small number of signals in the design. Selecting which signals to trace is therefore a crucial issue for the effectiveness of this technique. This paper proposes an automated trace signal selection strategy with a new probability-based evaluation metric, which is able to dramatically enhance the visibility in post-silicon validation. Experimental results on benchmark circuits show that the proposed technique is more effective than existing solutions.","Logic gates,
Silicon,
Computer bugs,
Integrated circuit modeling,
Measurement,
Real time systems,
Industries"
A modified brain storm optimization,"Brain storm optimization (BSO) is a new kind of swarm intelligence algorithm inspired by human creative problem solving process. Human being is the most intelligent organism in the world and the brainstorming process popularly used by them has been demonstrated to be a significant and promising way to create great ideas for problem solving. BSO transplants the brainstorming process in human being into optimization algorithm design and gains successes. BSO generally uses the grouping, replacing, and creating operators to produce ideas as many as possible to approach the problem global optimum generation by generation. In this paper, we propose two novel designs to enhance the conventional BSO performance. The first design of the modified BSO (MBSO) is that it uses a simple grouping method (SGM) in the grouping operator instead of the clustering method to reduce the algorithm computational burden. The second design is that MBSO uses a novel idea difference strategy (IDS) in the creating operator instead of the Gaussian random strategy. The IDS not only contains open minded element to avoid the ideas being trapped by local optima, but also can match the search environment to create better new ideas for problem solving. Experiments have been conducted to illustrate the effectiveness and efficiency of the MBSO algorithm. Moreover, the contributions of SGM and IDS are investigated to show how and why MBSO can perform better than BSO.",
Error Analysis of Nonconstant Admittivity for MR-Based Electric Property Imaging,"Magnetic resonance electrical property tomography (MREPT) is a new imaging modality to visualize a distribution of admittivity γ = σ+iωε inside the human body where σ and ε denote electrical conductivity and permittivity, respectively. Using B1 maps acquired by an magnetic resonance imaging scanner, it produces cross-sectional images of σ and ε at the Larmor frequency. Since current MREPT methods rely on an assumption of a locally homogeneous admittivity, there occurs a reconstruction error where this assumption fails. Rigorously analyzing the reconstruction error in MREPT, we showed that the error is fundamental and may cause technical difficulties in interpreting MREPT images of a general inhomogeneous object. We performed numerical simulations and phantom experiments to quantitatively support the error analysis. We compared the MREPT image reconstruction problem with that of magnetic resonance electrical impedance tomography (MREIT) to highlight distinct features of both methods to probe the same object in terms of its high- and low-frequency conductivity distributions, respectively. MREPT images showed large errors along boundaries where admittivity values changed whereas MREIT images showed no such boundary effects. Noting that MREIT makes use of the term neglected in MREPT, a novel MREPT admittivity image reconstruction method is proposed to deal with the boundary effects, which requires further investigation on the complex directional derivative in the real Euclidian space \BBR3.","Conductivity,
Image reconstruction,
Magnetic resonance imaging,
Phantoms,
Permittivity,
Tomography"
"SeDAX: A Scalable, Resilient, and Secure Platform for Smart Grid Communications","Smart Grid applications are imposing challenging requirements of security and reliability on the N-way communication infrastructure being designed to support multiple grid applications. These challenges stem from the increasing incorporation of distributed renewable energy sources on to the grid, the rising deployment of electric vehicles, and active consumer participation into power grid operations, all of which communicate with the utility control center with varying degrees of priority and security. To address these challenging requirements, we propose SeDAX, a SEcure Data-centric Application eXtensible platform for Smart Grid applications. SeDAX implements scalable, resilient and secure data delivery and data sharing in a wide area network. The platform can scalably handle high volumes of data generated by both applications and sensors. The SeDAX architecture has as its basis a Delaunay Triangulation (DT) network. The properties of the DT graph are leveraged to scalably support secure data-centric (or information-centric) group communication. The primary goals of this platform are to support communication resilience and data availability. The key functional blocks of the SeDAX platform are: (1) a geographic hash forwarding algorithm that operates over the DT graph (DT-GHF), and (2) a DT-based data replication scheme. The forwarding and replication schemes are scalable and cost effective in terms of communication overhead and memory. We describe the design details of the SeDAX platform and present empirical results on the performance of SeDAX as compared with other geometric-based alternatives such as Geographic Hash Table (GHT) forwarding and Content Addressable Networking (CAN). The operation of SeDAX is illustrated in the context of implementing demand response, a known Smart Grid application.","Security,
Smart grids,
Load management,
Servers,
Availability,
Quality of service"
jFuzzyLogic: a robust and flexible Fuzzy-Logic inference system language implementation,"This work introduces jFuzzyLogic, an open source library for fuzzy systems which allow us to design Fuzzy Logic Controllers supporting the standard for Fuzzy Control Programming published by the International Electrotechnical Commission. This library is written in Java and is available as open source from jfuzzylogic.sourceforge.net. The use of jFuzzyLogic is illustrated through the analysis of one case study.","Java,
Fuzzy logic,
Libraries,
Fuzzy control,
Software,
IEC standards"
Time-Resolved Interventional Cardiac C-arm Cone-Beam CT: An Application of the PICCS Algorithm,"Time-resolved cardiac imaging is particularly interesting in the interventional setting since it would provide both image guidance for accurate procedural planning and cardiac functional evaluations directly in the operating room. Imaging the heart in vivo using a slowly rotating C-arm system is extremely challenging due to the limitations of the data acquisition system and the high temporal resolution required to avoid motion artifacts. In this paper, a data acquisition scheme and an image reconstruction method are proposed to achieve time-resolved cardiac cone-beam computed tomography imaging with isotropic spatial resolution and high temporal resolution using a slowly rotating C-arm system. The data are acquired within 14 s using a single gantry rotation with a short scan angular range. The enabling image reconstruction method is the prior image constrained compressed sensing (PICCS) algorithm. The prior image is reconstructed from data acquired over all cardiac phases. Each cardiac phase is then reconstructed from the retrospectively gated cardiac data using the PICCS algorithm. To validate the method, several studies were performed. Both numerical simulations using a hybrid motion phantom with static background anatomy as well as physical phantom studies have been used to demonstrate that the proposed method enables accurate reconstruction of image objects with a high isotropic spatial resolution. A canine animal model scanned in vivo was used to further validate the method.","Image reconstruction,
Computed tomography,
Data acquisition,
Phantoms,
Three dimensional displays,
Animals"
Very Low Resolution Face Recognition Problem,"This paper addresses the very low resolution (VLR) problem in face recognition in which the resolution of the face image to be recognized is lower than 16 × 16. With the increasing demand of surveillance camera-based applications, the VLR problem happens in many face application systems. Existing face recognition algorithms are not able to give satisfactory performance on the VLR face image. While face super-resolution (SR) methods can be employed to enhance the resolution of the images, the existing learning-based face SR methods do not perform well on such a VLR face image. To overcome this problem, this paper proposes a novel approach to learn the relationship between the high-resolution image space and the VLR image space for face SR. Based on this new approach, two constraints, namely, new data and discriminative constraints, are designed for good visuality and face recognition applications under the VLR problem, respectively. Experimental results show that the proposed SR algorithm based on relationship learning outperforms the existing algorithms in public face databases.","Face,
Image resolution,
Image reconstruction,
Training,
Linearity,
Clustering algorithms,
Face recognition"
Probabilistic learning of task-specific visual attention,"Despite a considerable amount of previous work on bottom-up saliency modeling for predicting human fixations over static and dynamic stimuli, few studies have thus far attempted to model top-down and task-driven influences of visual attention. Here, taking advantage of the sequential nature of real-world tasks, we propose a unified Bayesian approach for modeling task-driven visual attention. Several sources of information, including global context of a scene, previous attended locations, and previous motor actions, are integrated over time to predict the next attended location. Recording eye movements while subjects engage in 5 contemporary 2D and 3D video games, as modest counterparts of everyday tasks, we show that our approach is able to predict human attention and gaze better than the state-of-the-art, with a large margin (about 15% increase in prediction accuracy). The advantage of our approach is that it is automatic and applicable to arbitrary visual tasks.","Games,
Visualization,
Computational modeling,
Predictive models,
Bayesian methods,
Vectors,
Context"
Selecting Key Poses on Manifold for Pairwise Action Recognition,"In action recognition, bag of visual words based approaches have been shown to be successful, for which the quality of codebook is critical. In a large vocabulary of poses (visual words), some key poses play a more decisive role than others in the codebook. This paper proposes a novel approach for key poses selection, which models the descriptor space utilizing a manifold learning technique to recover the geometric structure of the descriptors on a lower dimensional manifold. A PageRank-based centrality measure is developed to select key poses according to the recovered geometric structure. In each step, a key pose is selected from the manifold and the remaining model is modified to maximize the discriminative power of selected codebook. With the obtained codebook, each action can be represented with a histogram of the key poses. To solve the ambiguity between some action classes, a pairwise subdivision is executed to select discriminative codebooks for further recognition. Experiments on benchmark datasets showed that our method is able to obtain better performance compared with other state-of-the-art methods.",
Toward Covert Iris Biometric Recognition: Experimental Results From the NICE Contests,"This paper announces and discusses the experimental results from the Noisy Iris Challenge Evaluation (NICE), an iris biometric evaluation initiative that received worldwide participation and whose main innovation is the use of heavily degraded data acquired in the visible wavelength and uncontrolled setups, with subjects moving and at widely varying distances. The NICE contest included two separate phases: 1) the NICE.I evaluated iris segmentation and noise detection techniques and 2) the NICE:II evaluated encoding and matching strategies for biometric signatures. Further, we give the performance values observed when fusing recognition methods at the score level, which was observed to outperform any isolated recognition strategy. These results provide an objective estimate of the potential of such recognition systems and should be regarded as reference values for further improvements of this technology, which-if successful-may significantly broaden the applicability of iris biometric systems to domains where the subjects cannot be expected to cooperate.","Iris,
Iris recognition,
Image segmentation,
Protocols,
Imaging,
Lighting,
Materials"
Performance Analysis of Multihop-Diversity-Aided Multihop Links,"A multihop transmission scheme is proposed and studied, where all the relay nodes (RNs) of a multihop link are assumed to have buffers for temporarily storing their received packets. Hence, the RNs are operated under the so-called store-and-forward relaying scheme. As a benefit of storing packets at the RNs, during each time slot, the best hop typically has the highest signal-to-noise ratio (SNR), which can be selected from the set of hops that have packets awaiting transmission in the buffer. A packet is then transmitted over the best hop. This hop selection procedure is reminiscent of selection diversity, which is referred to here as multihop diversity (MHD). In this paper, we investigate both the bit error and outage probability and the delay performance of the MHD scheme when assuming that each hop experiences both propagation path loss and independent and identically distributed (i.i.d.) flat Rayleigh fading. The medium access control (MAC) layer implementation and several closed-form formulas are derived. Both numerical and simulation results are provided to characterize the achievable performance of the MHD scheme. Our performance results show that relying on multiple hops has the potential to provide a significant diversity gain, which may be exploited for enhancing the reliability of wireless multihop communications.","Magnetohydrodynamics,
Delay,
Bit error rate,
Tin,
Fading,
Protocols,
Silicon"
TDMA cluster-based MAC for VANETs (TC-MAC),"One of the challenges for Vehicular Ad-hoc Networks (VANETs) is the design of the Medium Access Control (MAC) protocol. When exchanging messages between vehicles, there are network issues that must be addressed, including the hidden terminal problem, high density, high node mobility, and data rate limitations. A cluster-based MAC scheme is needed in VANETs to overcome the lack of specialized hardware for infrastructure and the mobility to support network stability and channel utilization. This paper presents a MAC algorithm for vehicular ad-hoc networks using a new method for TDMA slot reservation based on clustering of vehicles. Our algorithm aims to decrease collisions and packet drops in the channel, as well as provide fairness in sharing the wireless medium and minimizing the effect of hidden terminals.",
A Model-Based Shot Boundary Detection Technique Using Frame Transition Parameters,"We have presented a unified model for detecting different types of video shot transitions. Based on the proposed model, we formulate frame estimation scheme using the previous and the next frames. Unlike other shot boundary detection algorithms, instead of properties of frames, frame transition parameters and frame estimation errors based on global and local features are used for boundary detection and classification. Local features include scatter matrix of edge strength and motion matrix. Finally, the frames are classified as no change (within shot frame), abrupt change, or gradual change frames using a multilayer perceptron network. The proposed method is relatively less dependent on user defined thresholds and is free from sliding window size as widely used by various schemes found in the literature. Moreover, handling both abrupt and gradual transitions along with non-transition frames under a single framework using model guided visual feature is another unique aspect of the work.","Histograms,
Mathematical model,
Visualization,
Image edge detection,
Feature extraction,
Computational modeling,
Bismuth"
Super Resolution for Multiview Images Using Depth Information,"In stereoscopic and multiview video, binocular suppression theory states that the visual subjective quality of 3-D experience is not much affected by asymmetrical blurring of the individual views. Based on these studies, mixed-resolution frameworks applied for multiview systems offer great data-size reduction without incurring in significant quality degradation in 3-D video applications. However, it is interesting to recover high-frequency content of the blurred views, to reduce visual strain due to long-term exposure and to make the system suitable for free-viewpoint television. In this paper, we present a novel super-resolution technique, in which low-resolution views are enhanced with the aid of high-frequency content from neighboring full-resolution views, and the corresponding depth information for all views. Occlusions are handled by checking the consistency between views. Tests for synthetic and real image data in stereo and multiview cases are presented, and results show that significant objective quality gains can be achieved without any extra side information.","Image resolution,
Strontium,
Encoding,
Gain,
Three dimensional displays,
Interpolation,
Quantization"
Sentence-level Arabic sentiment analysis,"Arabic sentiment analysis research existing currently is very limited. While sentiment analysis has many applications in English, the Arabic language is still recognizing its early steps in this field. In this paper, we show an application on Arabic sentiment analysis by implementing a sentiment classification for Arabic tweets. The retrieved tweets are analyzed to provide their sentiments polarity (positive, or negative). Since, this data is collected from the social network Twitter; it has its importance for the Middle East region, which mostly speaks Arabic.",
Modeling and Estimation of One-Shot Random Access for Finite-User Multichannel Slotted ALOHA Systems,This paper presents a combinatorial model and approximation formulas to estimate the average number of successful and collided users for a one-shot random access in finite-user multichannel slotted ALOHA systems. The proposed model and approximation can be used to evaluate the performance of group paging for machine-type communication (MTC) in 3GPP LTE. Numerical results demonstrate the applicable range of the approximation formulas and the accuracy of the derived performance metrics.,
Automated Recognition of Obstructive Sleep Apnea Syndrome Using Support Vector Machine Classifier,"Obstructive sleep apnea (OSA) is a common sleep disorder that causes pauses of breathing due to repetitive obstruction of the upper airways of the respiratory system. The effect of this phenomenon can be observed in other physiological signals like the heart rate variability, oxygen saturation, and the respiratory effort signals. In this study, features from these signals were extracted from 50 control and 50 OSA patients from the Sleep Heart Health Study database and implemented for minute and subject classifications. A support vector machine (SVM) classifier was used with linear and second-order polynomial kernels. For the minute classification, the respiratory features had the highest sensitivity while the oxygen saturation gave the highest specificity. The polynomial kernel always had better performance and the highest accuracy of 82.4% (Sen: 69.9%, Spec: 91.4%) was achieved using the combined-feature classifier. For subject classification, the polynomial kernel had a clear improvement in the oxygen saturation accuracy as the highest accuracy of 95% was achieved by both the oxygen saturation (Sen: 100%, Spec: 90.2%) and the combined-feature (Sen: 91.8%, Spec: 98.0%). Further analysis of the SVM with other kernel types might be useful for optimizing the classifier with the appropriate features for an OSA automated detection algorithm.","Accuracy,
Kernel,
Heart rate variability,
Sleep apnea,
Polynomials,
Sensitivity,
Support vector machines"
On Identifying Primary User Emulation Attacks in Cognitive Radio Systems Using Nonparametric Bayesian Classification,"Primary user emulation (PUE) attacks, where attackers mimic the signals of primary users (PUs), can cause significant performance degradation in cognitive radio (CR) systems. Detection of the presence of PUE attackers is thus an important problem. In this paper, using device-specific features, we propose a passive, nonparametric classification method to determine the number of transmitting devices in the PU spectrum. Our method, called DECLOAK, is passive since the sensing device listens and captures signals without injecting any signal to the wireless environment. It is nonparametric because the number of active devices needs not to be known as a priori. Channel independent features are selected forming fingerprints for devices, which cannot be altered postproduction. The infinite Gaussian mixture model (IGMM) is adopted and a modified collapsed Gibbs sampling method is proposed to classify the extracted fingerprints. Due to its unsupervised nature, there is no need to collect legitimate PU fingerprints. In combination with received power and device MAC address, we show through simulation studies that the proposed method can efficiently detect the PUE attack. The performance of DECLOAK is also shown to be superior than that of the classical non-parametric mean shift (MS) based clustering method.","OFDM,
Feature extraction,
Wireless communication,
Wireless sensor networks,
Emulation,
Performance evaluation,
Educational institutions"
Adaptive Multiscale Entropy Analysis of Multivariate Neural Data,"Multiscale entropy (MSE) has been widely used to quantify a system's complexity by taking into account the multiple time scales inherent in physiologic time series. The method, however, is biased toward the coarse scale, i.e., low-frequency components due to the progressive smoothing operations. In addition, the algorithm for extracting the different scales is not well adapted to nonlinear/nonstationary signals. In this letter, we introduce adaptive multiscale entropy (AME) measures in which the scales are adaptively derived directly from the data by virtue of recently developed multivariate empirical mode decomposition. Depending on the consecutive removal of low-frequency or high-frequency components, our AME can be estimated at either coarse-to-fine or fine-to-coarse scales over which the sample entropy is performed. Computer simulations are performed to verify the effectiveness of AME for analysis of the highly nonstationary data. Local field potentials collected from the visual cortex of macaque monkey while performing a generalized flash suppression task are used as an example to demonstrate the usefulness of our AME approach to reveal the underlying dynamics in complex neural data.","Entropy,
Time series analysis,
Visualization,
Biomedical measurements,
USA Councils,
Diamond-like carbon,
Smoothing methods"
Tracking of Triangular References Using Signal Transformation for Control of a Novel AFM Scanner Stage,"In this paper, we design feedback controllers for lateral and transversal axes of an atomic force microscope (AFM) piezoelectric tube scanner. The controllers are constrained to keep the standard deviation of the measurement noise fed back to the displacement output around 0.13 nm. It is shown that the incorporation of appropriate inner loops provides disturbance rejection capabilities and robustness against dc gain uncertainties, two requirements for satisfactory operation of signal transformation method. Simulations and experiments show significant improvement of steady-state tracking error with signal transformation, while limiting the projected measurement noise.","Noise,
Electron tubes,
Noise measurement,
Bandwidth,
Gain,
Robustness,
Electrodes"
Large-Vocabulary Continuous Speech Recognition Systems: A Look at Some Recent Advances,"Over the past decade or so, several advances have been made to the design of modern large vocabulary continuous speech recognition (LVCSR) systems to the point where their application has broadened from early speaker dependent dictation systems to speaker-independent automatic broadcast news transcription and indexing, lectures and meetings transcription, conversational telephone speech transcription, open-domain voice search, medical and legal speech recognition, and call center applications, to name a few. The commercial success of these systems is an impressive testimony to how far research in LVCSR has come, and the aim of this article is to describe some of the technological underpinnings of modern systems. It must be said, however, that, despite the commercial success and widespread adoption, the problem of large-vocabulary speech recognition is far from being solved: background noise, channel distortions, foreign accents, casual and disfluent speech, or unexpected topic change can cause automated systems to make egregious recognition errors. This is because current LVCSR systems are not robust to mismatched training and test conditions and cannot handle context as well as human listeners despite being trained on thousands of hours of speech and billions of words of text.","Automatic speech recognition,
Speech recognition,
Hidden Markov models,
Vocabularies,
Acoustics,
Adaptation models"
Online map-matching based on Hidden Markov model for real-time traffic sensing applications,"In many Intelligent Transportation System (ITS) applications that crowd-source data from probe vehicles, a crucial step is to accurately map the GPS trajectories to the road network in real time. This process, known as map-matching, often needs to account for noise and sparseness of the data because (1) highly precise GPS traces are rarely available, and (2) dense trajectories are costly for live transmission and storage. We propose an online map-matching algorithm based on the Hidden Markov Model (HMM) that is robust to noise and sparseness. We focused on two improvements over existing HMM-based algorithms: (1) the use of an optimal localizing strategy, the variable sliding window (VSW) method, that guarantees the online solution quality under uncertain future inputs, and (2) the novel combination of spatial, temporal and topological information using machine learning. We evaluated the accuracy of our algorithm using field test data collected on bus routes covering urban and rural areas. Furthermore, we also investigated the relationships between accuracy and output delays in processing live input streams. In our tests on field test data, VSW outperformed the traditional localizing method in terms of both accuracy and output delay. Our results suggest that it is viable for low latency applications such as traffic sensing.","Trajectory,
Accuracy,
Roads,
Delay,
Hidden Markov models,
Vehicles,
Markov processes"
Quality of Experience of VoIP Service: A Survey of Assessment Approaches and Open Issues,"This survey gives a comprehensive review of recent advances related to the topic of VoIP QoE (Quality of user' Experience). It starts by providing some insight into the QoE arena and outlines the principal building blocks of a VoIP application. The sources of impairments over data IP networks are identified and distinguished from signal-oriented sources of quality degradation observed over telecom networks. An overview of existing subjective and objective methodologies for the assessment of the QoE of voice conversations is then presented outlining how subjective and objective speech quality methodologies have evolved to consider time-varying QoS transport networks. A description of practical procedures for measuring VoIP QoE and illustrative results is then given. Utilization methodology of several speech quality assessment frameworks is summarized. A survey of emerging single-ended parametric-model speech quality assessment algorithms dedicated to VoIP service is then given. In particular, after presenting a primitive single-ended parametric-model algorithm especially conceived for the evaluation of VoIP conversations, new artificial assessors of VoIP service are detailed. In particular, we describe speech quality assessment algorithms that consider, among others, packet loss burstiness, unequal importance of speech wave, and transient loss of connectivity. The following section concentrates on the integration of VoIP service over mobile data networks. The impact of quality-affecting phenomena, such as handovers and CODEC changeover are enumerated and some primary subjective results are summarized. The survey concludes with a review of open issues relating to automatic assessment of VoIP.","Speech,
Quality assessment,
Quality of service,
Delay,
Laboratories,
Jitter,
Degradation"
Synthesizing API usage examples,"Key program interfaces are sometimes documented with usage examples: concrete code snippets that characterize common use cases for a particular data type. While such documentation is known to be of great utility, it is burdensome to create and can be incomplete, out of date, or not representative of actual practice. We present an automatic technique for mining and synthesizing succinct and representative human-readable documentation of program interfaces. Our algorithm is based on a combination of path sensitive dataflow analysis, clustering, and pattern abstraction. It produces output in the form of well-typed program snippets which document initialization, method calls, assignments, looping constructs, and exception handling. In a human study involving over 150 participants, 82% of our generated examples were found to be at least as good at human-written instances and 94% were strictly preferred to state of the art code search.","Documentation,
Concrete,
Humans,
Abstracts,
Java,
Algorithm design and analysis,
Clustering algorithms"
Eye-Tracking Database for a Set of Standard Video Sequences,"This correspondence describes a publicly available database of eye-tracking data, collected on a set of standard video sequences that are frequently used in video compression, processing, and transmission simulations. A unique feature of this database is that it contains eye-tracking data for both the first and second viewings of the sequence. We have made available the uncompressed video sequences and the raw eye-tracking data for each sequence, along with different visualizations of the data and a preliminary analysis based on two well-known visual attention models.","Visualization,
Databases,
Video sequences,
Tracking,
Cameras,
Accuracy,
Calibration"
Laser-Based Kinematic Calibration of Robot Manipulator Using Differential Kinematics,"This paper proposes a novel systematic technique to estimate entire kinematic parameter errors of robot manipulator. Small errors always exist in link length and link twist for physical manipulators, which affect the precision in kinematic equations leading to calculate wrong joint angle values in inverse kinematic equations. In order to solve these problems, the proposed technique employs a structured laser module (SLM), a stationary camera, the Jacobian matrices, and an extended Kalman filter (EKF). The SLM is attached to the end-effector of the manipulator arm and the stationary camera is used to determine an accurate position where the laser comes out. Variances between actual and measured positions of laser beams are represented by the Jacobian matrices formulated from differential kinematics. Then, the EKF is used to estimate kinematic parameters. Effectiveness of the proposed technique is verified with 7 DOF humanoid manipulator arm by computer simulation and 4 DOF manipulator by actual experiment.","Measurement by laser beam,
Kinematics,
Calibration,
Kalman filters,
Manipulators,
Jacobian matrices"
Understanding THz Pulse Propagation in the Atmosphere,"In this paper, we have extracted the THz refractivity of water vapor (n(ω)-1) from the complex spectra of the precise coherent THz-TDS absorption measurement with a 6.18 m long sample path . We fit the new refractivity and the previous absorption measurements to the sum of the contributions from all of the water vapor lines (with the same van-Vleck Weisskopf lineshape) in the JPL, Pasadena, CA, database from 0 to 10 THz. The precision of the resulting theoretical absorption and refractivity is demonstrated by the good agreement between the calculated THz output pulse and the measured output pulse, both having the same THz input pulse. Using this capability, we have calculated the transmitted THz pulses through the atmosphere at specified humidity and temperature for a variety of input pulses for the distances of 500, 1000, and 2000 m. We have also tested the predicted stable propagation of the proposed “ideal THz bit pulse” [2], and showed that this pulse evolves into two overlapping pulses after 2000 m of propagation. We showed these two new pulses I and II to be transform-limited THz bit pulses with stable propagation to 2000 m. THz bit pulses I and II span the spectral ranges of 0.13-0.18 THz and 0.18-0.33 THz, respectively, and can support the bit rate distance products of 20 and 40 (Gb/s) km, respectively.",
Socially-aware robot navigation: A learning approach,"The ability to act in a socially-aware way is a key skill for robots that share a space with humans. In this paper we address the problem of socially-aware navigation among people that meets objective criteria such as travel time or path length as well as subjective criteria such as social comfort. Opposed to model-based approaches typically taken in related work, we pose the problem as an unsupervised learning problem. We learn a set of dynamic motion prototypes from observations of relative motion behavior of humans found in publicly available surveillance data sets. The learned motion prototypes are then used to compute dynamic cost maps for path planning using an any-angle A* algorithm. In the evaluation we demonstrate that the learned behaviors are better in reproducing human relative motion in both criteria than a Proxemics-based baseline method.","Prototypes,
Humans,
Robots,
Context,
Computational modeling,
Dynamics,
Heuristic algorithms"
Cooperative Secret Key Generation from Phase Estimation in Narrowband Fading Channels,"By exploiting multipath fading channels as a source of common randomness, physical layer (PHY) based key generation protocols allow two terminals with correlated observations to generate secret keys with information-theoretical security. The state of the art, however, still suffers from major limitations,e.g., low key generation rate, lower entropy of key bits and a high reliance on node mobility. In this paper, a novel cooperative key generation protocol is developed to facilitate high-rate key generation in narrowband fading channels, where two keying nodes extract the phase randomness of the fading channel with the aid of relay node(s). For the first time, we explicitly consider the effect of estimation methods on the extraction of secret key bits from the underlying fading channels and focus on a popular statistical method - maximum likelihood estimation (MLE). The performance of the cooperative key generation scheme is extensively evaluated theoretically. We successfully establish both a theoretical upper bound on the maximum secret key rate from mutual information of correlated random sources and a more practical upper bound from Cramer-Rao bound (CRB) in estimation theory. Numerical examples and simulation studies are also presented to demonstrate the performance of the cooperative key generation system. The results show that the key rate can be improved by a couple of orders of magnitude compared to the existing approaches.",
Application of Evolutionary Fuzzy Cognitive Maps for Prediction of Pulmonary Infections,"In this paper, a new evolutionary-based fuzzy cognitive map (FCM) methodology is proposed to cope with the forecasting of the patient states in the case of pulmonary infections. The goal of the research was to improve the efficiency of the prediction. This was succeeded with a new data fuzzification procedure for observables and optimization of gain of transformation function using the evolutionary learning for the construction of FCM model. The approach proposed in this paper was validated using real patient data from internal care unit. The results emerged had less prediction errors for the examined data records than those produced by the conventional genetic-based algorithmic approaches.","Optimization,
Diseases,
Lungs,
Logistics,
Predictive models,
Prediction algorithms,
Vectors"
Strategies for human-in-the-loop robotic grasping,"Human-in-the loop robotic systems have the potential to handle complex tasks in unstructured environments, by combining the cognitive skills of a human operator with autonomous tools and behaviors. Along these lines, we present a system for remote human-in-the-loop grasp execution. An operator uses a computer interface to visualize a physical robot and its surroundings, and a point-and-click mouse interface to command the robot. We implemented and analyzed four different strategies for performing grasping tasks, ranging from direct, real-time operator control of the end-effector pose, to autonomous motion and grasp planning that is simply adjusted or confirmed by the operator. Our controlled experiment (N=48) results indicate that people were able to successfully grasp more objects and caused fewer unwanted collisions when using the strategies with more autonomous assistance. We used an untethered robot over wireless communications, making our strategies applicable for remote, human-in-the-loop robotic applications.","Grippers,
Grasping,
Collision avoidance,
Robot sensing systems,
Planning,
USA Councils"
A Novel Algorithm for View and Illumination Invariant Image Matching,"The challenges in local-feature-based image matching are variations of view and illumination. Many methods have been recently proposed to address these problems by using invariant feature detectors and distinctive descriptors. However, the matching performance is still unstable and inaccurate, particularly when large variation in view or illumination occurs. In this paper, we propose a view and illumination invariant image-matching method. We iteratively estimate the relationship of the relative view and illumination of the images, transform the view of one image to the other, and normalize their illumination for accurate matching. Our method does not aim to increase the invariance of the detector but to improve the accuracy, stability, and reliability of the matching results. The performance of matching is significantly improved and is not affected by the changes of view and illumination in a valid range. The proposed method would fail when the initial view and illumination method fails, which gives us a new sight to evaluate the traditional detectors. We propose two novel indicators for detector evaluation, namely, valid angle and valid illumination, which reflect the maximum allowable change in view and illumination, respectively. Extensive experimental results show that our method improves the traditional detector significantly, even in large variations, and the two indicators are much more distinctive.","Lighting,
Feature extraction,
Detectors,
Image matching,
Histograms,
Transforms,
Estimation"
Sparse kernel approximations for efficient classification and detection,"Efficient learning with non-linear kernels is often based on extracting features from the data that “linearise” the kernel. While most constructions aim at obtaining low-dimensional and dense features, in this work we explore high-dimensional and sparse ones. We give a method to compute sparse features for arbitrary kernels, re-deriving as a special case a popular map for the intersection kernel and extending it to arbitrary additive kernels. We show that bundle optimisation methods can handle efficiently these sparse features in learning. As an application, we show that product quantisation can be interpreted as a sparse feature encoding, and use this to significantly accelerate learning with this technique. We demonstrate these ideas on image classification with Fisher kernels and object detection with deformable part models on the challenging PASCAL VOC data, obtaining five to ten-fold speed-ups as well as reducing memory use by an order of magnitude.","Kernel,
Approximation methods,
Vectors,
Encoding,
Support vector machines,
Additives,
Quantization"
Estimating A Reference Standard Segmentation With Spatially Varying Performance Parameters: Local MAP STAPLE,"We present a new algorithm, called local MAP STAPLE, to estimate from a set of multi-label segmentations both a reference standard segmentation and spatially varying performance parameters. It is based on a sliding window technique to estimate the segmentation and the segmentation performance parameters for each input segmentation. In order to allow for optimal fusion from the small amount of data in each local region, and to account for the possibility of labels not being observed in a local region of some (or all) input segmentations, we introduce prior probabilities for the local performance parameters through a new maximum a posteriori formulation of STAPLE. Further, we propose an expression to compute confidence intervals in the estimated local performance parameters. We carried out several experiments with local MAP STAPLE to characterize its performance and value for local segmentation evaluation. First, with simulated segmentations with known reference standard segmentation and spatially varying performance, we show that local MAP STAPLE performs better than both STAPLE and majority voting. Then we present evaluations with data sets from clinical applications. These experiments demonstrate that spatial adaptivity in segmentation performance is an important property to capture. We compared the local MAP STAPLE segmentations to STAPLE, and to previously published fusion techniques and demonstrate the superiority of local MAP STAPLE over other state-of-the-art algorithms.","Image segmentation,
Manuals,
Estimation,
Accuracy,
Equations,
Uncertainty,
Closed-form solutions"
"RIP-Based Near-Oracle Performance Guarantees for SP, CoSaMP, and IHT","This correspondence presents an average case denoising performance analysis for SP, CoSaMP, and IHT algorithms. This analysis considers the recovery of a noisy signal, with the assumptions that it is corrupted by an additive random zero-mean white Gaussian noise and has a K-sparse representation with respect to a known dictionary D . The proposed analysis is based on the RIP, establishing a near-oracle performance guarantee for each of these algorithms. Beyond bounds for the reconstruction error that hold with high probability, in this work we also provide a bound for the average error.","Vectors,
Matching pursuit algorithms,
Algorithm design and analysis,
Gaussian noise,
Dictionaries,
Approximation methods"
Smooth Trade-Offs between Throughput and Delay in Mobile Ad Hoc Networks,"Throughput capacity in mobile ad hoc networks has been studied extensively under many different mobility models. However, most previous research assumes global mobility, and the results show that a constant per-node throughput can be achieved at the cost of very high delay. Thus, we are having a very big gap here, i.e., either low throughput and low delay in static networks or high throughput and high delay in mobile networks. In this paper, employing a practical restricted random mobility model, we try to fill this gap. Specifically, we assume that a network of unit area with n nodes is evenly divided into cells with an area of n -2α, each of which is further evenly divided into squares with an area of n-2β(0≤ α ≤ β ≤1/2). All nodes can only move inside the cell which they are initially distributed in, and at the beginning of each time slot, every node moves from its current square to a uniformly chosen point in a uniformly chosen adjacent square. By proposing a new multihop relay scheme, we present smooth trade-offs between throughput and delay by controlling nodes' mobility. We also consider a network of area nγ (0 ≤ γ ≤ 1) and find that network size does not affect the results obtained before.","Throughput,
Delay,
Relays,
Mobile computing,
Mobile ad hoc networks,
Wireless networks"
Sparse Unsupervised Dimensionality Reduction for Multiple View Data,"Different kinds of high-dimensional visual features can be extracted from a single image. Images can thus be treated as multiple view data when taking each type of extracted high-dimensional visual feature as a particular understanding of images. In this paper, we propose a framework of sparse unsupervised dimensionality reduction for multiple view data. The goal of our framework is to find a low-dimensional optimal consensus representation from multiple heterogeneous features by multiview learning. In this framework, we first learn low-dimensional patterns individually from each view, considering the specific statistical property of each view. We construct a low-dimensional optimal consensus representation from those learned patterns, the goal of which is to leverage the complementary nature of the multiple views. We formulate the construction of the low-dimensional consensus representation to approximate the matrix of patterns by means of a low-dimensional consensus base matrix and a loading matrix. To select the most discriminative features for the spectral embedding of multiple views, we propose to add an l1-norm into the loading matrix's columns and impose orthogonal constraints on the base matrix. We develop a new alternating algorithm, i.e., spectral sparse multiview embedding, to efficiently obtain the solution. Each row of the loading matrix encodes structured information corresponding to multiple patterns. In order to gain flexibility in sharing information across subsets of the views, we impose a novel structured sparsity-inducing norm penalty on the loading matrix's rows. This penalty makes the loading coefficients adaptively load shared information across subsets of the learned patterns. We call this method structured sparse multiview dimensionality reduction. Experiments on a toy benchmark image data set and two real-world Web image data sets demonstrate the effectiveness of the proposed algorithms.","Sparse matrices,
Loading,
Vectors,
Feature extraction,
Principal component analysis,
Visualization,
Educational institutions"
Denser and More Stable SRAM Using FinFETs With Multiple Fin Heights,We present the optimization of multiple-fin-height FinFET static random access memory (SRAM) to reduce cell leakage and improve the stability and density of SRAM. Using a taller fin FinFET for the pull-down device increases the read static noise margin of the SRAM and can potentially reduce the SRAM cell area. A reasonable amount of channel doping in all the transistors can be used to reduce the cell leakage current without appreciably degrading the stability of the SRAM cell. Increasing the channel doping of the access transistor simultaneously improves the read stability and decreases the cell leakage current of the SRAM cell.,"Random access memory,
FinFETs,
Doping,
Logic gates,
Stability analysis,
Leakage current"
Multiuser MIMO Relay Networks in Nakagami-m Fading Channels,"This paper proposes a low complexity protocol that preserves full diversity in multiuser amplify-and-forward relay networks with NS antennas at the source, NR antennas at the relay, and ND antennas at each of the K destinations. In the proposed protocol, a two-fold diversity is guaranteed: 1) multi-antenna diversity via transmit antenna selection with maximal-ratio combining (TAS/MRC), and 2) multiuser diversity via opportunistic scheduling. Under perfect feedback with precise channel state information (CSI), we derive new exact and asymptotic symbol error rate (SER) expressions in closed-form for the general case of Nakagami-m fading. We prove that the full diversity order of NSNDKmX + min{NSNRmY, NRNDKmZ} is guaranteed, where mX, mY, and mZ denote the fading parameters of the source-destination, source-relay, and relay-destination links, respectively. To examine the impact of delayed feedback, we next derive new exact and asymptotic SER expressions in closed-form. We prove that in the presence of delayed feedback, outdated CSI degrades the diversity order to NDmX + min{NRmY, NDmZ}. In addition, based on our asymptotic expressions, we determine the optimal power allocation between the source and the relay such that the SER is minimized. We show that optimal power allocation offers superior performance over uniform power allocation; highlighting a pivotal design choice for maximizing network performance without investing additional resources.","Relays,
MIMO,
Signal to noise ratio,
Fading,
Diversity reception,
Receiving antennas"
MIMO-Aided Near-Capacity Turbo Transceivers: Taxonomy and Performance versus Complexity,"In this treatise, we firstly review the associated Multiple-Input Multiple-Output (MIMO) system theory and review the family of hard-decision and soft-decision based detection algorithms in the context of Spatial Division Multiplexing (SDM) systems. Our discussions culminate in the introduction of a range of powerful novel MIMO detectors, such as for example Markov Chain assisted Minimum Bit-Error Rate (MC-MBER) detectors, which are capable of reliably operating in the challenging high-importance rank-deficient scenarios, where there are more transmitters than receivers and hence the resultant channel-matrix becomes non-invertible. As a result, conventional detectors would exhibit a high residual error floor. We then invoke the Soft-Input Soft-Output (SISO) MIMO detectors for creating turbo-detected two- or three-stage concatenated SDM schemes and investigate their attainable performance in the light of their computational complexity. Finally, we introduce the powerful design tools of EXtrinsic Information Transfer (EXIT)-charts and characterize the achievable performance of the diverse near-capacity SISO detectors with the aid of EXIT charts.","Detectors,
Markov processes,
Computational complexity,
Niobium,
MIMO,
Multiplexing"
Aggregated-Proofs Based Privacy-Preserving Authentication for V2G Networks in the Smart Grid,"Vehicle-to-grid (V2G) as an essential network component of smart grid, provides services by periodically collecting the charging status of a battery vehicle (BV). A BV is normally associated with a default interest group (e.g., power grid operator). When the BV accesses its default charging or communication point, it works in the home mode. The BV may move around and temporarily access other aggregators, and then it works in the visiting mode. In this paper, we first identify that, for an aggregator, BVs have different security challenges when they work in different modes. Then, we propose an aggregated-proofs based privacy-preserving authentication scheme (AP3A) to achieve simultaneous identification and secure identification for different working mode BVs. In AP3A, BVs are differentiated into either home or visiting mode, and multiple BVs can be simultaneously authenticated by an aggregator to conserve communication resources. In addition, the aggregated pseudo-status variation is presented to realize that multiple BVs' power status can be collected as a whole without revealing any individual privacy. We perform comprehensive analysis on the proposed scheme, including attack analysis, security analysis, and performance analysis. It is shown that AP3A can resist major attacks for security protection and privacy preservation, and can be an efficient authentication approach for V2G networks.","Authentication,
Electric vehicles,
Vehicles,
Batteries,
Protocols,
Privacy"
Stochastic Analysis of a Stable Normalized Least Mean Fourth Algorithm for Adaptive Noise Canceling With a White Gaussian Reference,"The least mean fourth (LMF) algorithm has several stability problems. Its stability depends on the variance and distribution type of the adaptive filter input, the noise variance, and the initialization of the filter weights. A global solution to these stability problems was presented recently for a normalized LMF (NLMF) algorithm. Here, a stochastic analysis of the mean-square deviation (MSD) of the globally stable NLMF algorithm is provided. The analysis is done in the context of adaptive noise canceling with a white Gaussian reference input and Gaussian, binary, and uniform desired signals. The analytical model is shown to accurately predict the results of Monte Carlo simulations. Comparisons of the NLMF and NLMS algorithms are then made for various parameter selections. It is then shown under what conditions the NLMF algorithm is superior to NLMS algorithm for adaptive noise canceling.","Algorithm design and analysis,
Vectors,
Noise measurement,
Adaptive filters,
Mathematical model,
Stability criteria"
Passive Markers for Tracking Surgical Instruments in Real-Time 3-D Ultrasound Imaging,"A family of passive echogenic markers is presented by which the position and orientation of a surgical instrument can be determined in a 3-D ultrasound volume, using simple image processing. Markers are attached near the distal end of the instrument so that they appear in the ultrasound volume along with the instrument tip. They are detected and measured within the ultrasound image, thus requiring no external tracking device. This approach facilitates imaging instruments and tissue simultaneously in ultrasound-guided interventions. Marker-based estimates of instrument pose can be used in augmented reality displays or for image-based servoing. Design principles for marker shapes are presented that ensure imaging system and measurement uniqueness constraints are met. An error analysis is included that can be used to guide marker design and which also establishes a lower bound on measurement uncertainty. Finally, examples of marker measurement and tracking algorithms are presented along with experimental validation of the concepts.",
An Efficient Resource Allocation Scheme Using Particle Swarm Optimization,"Developing techniques for optimal allocation of limited resources to a set of activities has received increasing attention in recent years. In this paper, an efficient resource allocation scheme based on particle swarm optimization (PSO) is developed. Different from many existing evolutionary algorithms for solving resource allocation problems (RAPs), this PSO algorithm incorporates a novel representation of each particle in the population and a comprehensive learning strategy for the PSO search process. The novelty of this representation lies in that the position of each particle is represented by a pair of points, one on each side of the constraint hyper-plane in the problem space. The line joining these two points intersects the constraint hyper-plane and their intersection point indicates a feasible solution. With the evaluation value of the feasible solution used as the fitness value of the particle, such a representation provides an effective way to ensure the equality resource constraints in RAPs are met. Without the distraction of infeasible solutions, the particle thus searches the space smoothly. In addition, particles search for optimal solutions by learning from themselves and their neighborhood using the comprehensive learning strategy, helping prevent premature convergence and improve the solution quality for multimodal problems. This new algorithm is shown to be applicable to both single-objective and multiobjective RAPs, with performance validated by a number of benchmarks and by a real-world bed capacity planning problem. Experimental results verify the effectiveness and efficiency of the proposed algorithm.","Resource management,
Algorithm design and analysis,
Educational institutions,
Particle swarm optimization,
Heuristic algorithms,
Capacity planning,
Genetic algorithms"
An Optimization Transfer Algorithm for Nonlinear Parametric Image Reconstruction From Dynamic PET Data,"Direct reconstruction of kinetic parameters from raw projection data is a challenging task in molecular imaging using dynamic positron emission tomography (PET). This paper presents a new optimization transfer algorithm for penalized likelihood direct reconstruction of nonlinear parametric images that is easy to use and has a fast convergence rate. Each iteration of the proposed algorithm can be implemented in three simple steps: a frame-by-frame maximum likelihood expectation-maximization (EM)-like image update, a frame-by-frame image smoothing, and a pixel-by-pixel time activity curve fitting. Computer simulation shows that the direct algorithm can achieve a better bias-variance performance than the indirect reconstruction algorithm. The convergence rate of the new algorithm is substantially faster than our previous algorithm that is based on a separable paraboloidal surrogate function. The proposed algorithm has been applied to real 4-D PET data.","Heuristic algorithms,
Image reconstruction,
Kinetic theory,
Positron emission tomography,
Optimization,
Convergence,
Maximum likelihood estimation"
Pulse Propagation in a Short Nonlinear Graded-Index Multimode Optical Fiber,"We present a detailed analysis of the modal properties, dispersive behavior, and nonlinear mode coupling in graded-index multimode fibers (GIMFs), and lay out a simplified form of a generalized nonlinear Schrödinger equation, which can be used to explore the rich nonlinear dynamics related to the propagation and interaction of light pulses in GIMFs in a tractable manner. We also briefly discuss an application of the presented formalism in the study of four-wave mixing in these fibers. While the reported formalism is fairly general, our presentation is mainly targeted at device applications in which short segments of GIMFs are used.","Optical fibers,
Nonlinear optics,
Four-wave mixing"
Non Adaptive Second-Order Generalized Integrator for Identification of a Biased Sinusoidal Signal,"This note presents a new algorithm that is designed to identify the frequency, magnitude, phase and offset of a biased sinusoidal signal. The structure of the algorithm includes an orthogonal system generator based on a second-order generalized integrator. The proposed strategy has the advantages of a fast and accurate signal reconstruction capability and a good rejection to noise.","Frequency estimation,
Phase locked loops,
Resonant frequency,
Noise,
Noise measurement,
Estimation error"
Formal Approach to the Deployment of Distributed Robotic Teams,"We present a computational framework for automatic synthesis of control and communication strategies for a robotic team from task specifications that are given as regular expressions about servicing requests in an environment. We assume that the location of the requests in the environment and the robot capacities and cooperation requirements to service the requests are known. Our approach is based on two main ideas. First, we extend recent results from formal synthesis of distributed systems to check for the distributability of the task specification and to generate local specifications, while accounting for the service and communication capabilities of the robots. Second, by using a technique that is inspired by linear temporal logic model checking, we generate individual control and communication strategies. We illustrate the method with experimental results in our robotic urban-like environment.","Robots,
Doped fiber amplifiers,
Educational institutions,
System recovery,
Fuses,
Cities and towns,
Protocols"
Three-Dimensional Face Reconstruction From a Single Image by a Coupled RBF Network,"Reconstruction of a 3-D face model from a single 2-D face image is fundamentally important for face recognition and animation because the 3-D face model is invariant to changes of viewpoint, illumination, background clutter, and occlusions. Given a coupled training set that contains pairs of 2-D faces and the corresponding 3-D faces, we train a novel coupled radial basis function network (C-RBF) to recover the 3-D face model from a single 2-D face image. The C-RBF network explores: 1) the intrinsic representations of 3-D face models and those of 2-D face images; 2) mappings between a 3-D face model and its intrinsic representation; and 3) mappings between a 2-D face image and its intrinsic representation. Since a particular face can be reconstructed by its nearest neighbors, we can assume that the linear combination coefficients for a particular 2-D face image reconstruction are identical to those for the corresponding 3-D face model reconstruction. Therefore, we can reconstruct a 3-D face model by using a single 2-D face image based on the C-RBF network. Extensive experimental results on the BU3D database indicate the effectiveness of the proposed C-RBF network for recovering the 3-D face model from a single 2-D face image.","Face,
Image reconstruction,
Solid modeling,
Radial basis function networks,
Training,
Shape,
Neurons"
Degrees of Freedom of Interference Channels With CoMP Transmission and Reception,"We study the degrees of freedom (DoF) of the K
-user interference channel with coordinated multipoint (CoMP) transmission and reception. Each message is jointly transmitted by M_{t}
successive transmitters, and is jointly received by M_{r}
successive receivers. We refer to this channel as the CoMP channel with a transmit cooperation order of M_{t}
and receive cooperation order of M_{r}
. Since the channel has a total of K
transmit antennas and K
receive antennas, the maximum possible DoF is equal to K
. We show that the CoMP channel has K
DoF if and only if M_{t} + M_{r} \geq K+1
. The key idea is that the zero forcing of the interference corresponding to the i{{\rm th}}
message at the decoder of the j{{\rm th}}
message, where j \ne i
, can be viewed as a shared responsibility between the M_{t}
transmitters carrying the i{{\rm th}}
message, and the M_{r}
receivers decoding the j{{\rm th}}
message. For the general case, we derive an outer bound that states that the DoF is bounded above by \left \lceil (K+M_{t}+M_{r}-2)/2\right \rceil
. For the special case with only CoMP transmission, i.e, M_{r} = 1
, we propose a scheme that can achieve (K+M_{t}-1)/2
DoF for all K < 10
, and conjecture that the result holds true for all K
. In the proposed coding scheme, the M_{t}
transmitters carrying each message are used to cancel the interference introduced by this message at the first M_{t}-1
receivers, thereby allowing each of these receivers to enjoy 1 DoF, and asymptotic interference alignment is used to align the interfering signals at each other receiver to occupy half the signal space. The achievability proofs are based on the notion of algebraic independence from algebraic geometry.","Transmitters,
Interference channels,
Decoding,
Vectors,
Receiving antennas"
Different-Level Redundancy-Resolution and Its Equivalent Relationship Analysis for Robot Manipulators Using Gradient-Descent and Zhang 's Neural-Dynamic Methods,"To solve the inverse kinematic problem of redundant robot manipulators, two redundancy-resolution schemes are investigated: one is resolved at joint-velocity level, and the other is resolved at joint-acceleration level. Both schemes are reformulated as a quadratic programming (QP) problem. Two recurrent neural networks (RNNs) are then developed for the online solution of the resultant QP problem. The first RNN solver is based on the gradient-descent method and is termed as gradient neural network (GNN). The other solver is based on Zhang 's neural-dynamic method and is termed as Zhang neural network (ZNN). The computer simulations performed on a three-link planar robot arm and the PUMA560 manipulator demonstrate the efficacy of the two redundancy-resolution schemes and two RNN QP-solvers presented, as well as the superiority of the ZNN QP-solver compared to the GNN one. More importantly, the simulation results show that the solutions of the two presented schemes fit well with each other, i.e., the two different-level redundancy-resolution schemes could be equivalent in some sense. The theoretical analysis based on the gradient-descent method and Zhang 's neural-dynamic method further substantiates the new finding about the different-level redundancy-resolution equivalence.","Manipulators,
Acceleration,
Artificial neural networks,
Redundancy,
Jacobian matrices,
Recurrent neural networks"
Android4TV: A proposition for integration of DTV in Android devices,"This paper presents a proposition for integration of DTV in Android devices. The proposed system offers complete DTV functionality, while enabling users to use the TV device as a regular Android device. The proposition also includes a specification of a Java API that should be used to access DTV content from Android applications.","Digital TV,
Androids,
Humanoid robots,
Smart phones,
Java,
Middleware"
Microphone Array Processing for Distant Speech Recognition: From Close-Talking Microphones to Far-Field Sensors,"Distant speech recognition (DSR) holds the promise of the most natural human computer interface because it enables man-machine interactions through speech, without the necessity of donning intrusive body- or head-mounted microphones. Recognizing distant speech robustly, however, remains a challenge. This contribution provides a tutorial overview of DSR systems based on microphone arrays. In particular, we present recent work on acoustic beam forming for DSR, along with experimental results verifying the effectiveness of the various algorithms described here; beginning from a word error rate (WER) of 14.3% with a single microphone of a linear array, our state-of-the-art DSR system achieved a WER of 5.3%, which was comparable to that of 4.2% obtained with a lapel microphone. Moreover, we present an emerging technology in the area of far-field audio and speech processing based on spherical microphone arrays. Performance comparisons of spherical and linear arrays reveal that a spherical array with a diameter of 8.4 cm can provide recognition accuracy comparable or better than that obtained with a large linear array with an aperture length of 126 cm.","Tutorials,
Automatic speech recognition,
Speech recognition,
Array signal processing,
Microphones"
Spatiotemporal Local Monogenic Binary Patterns for Facial Expression Recognition,"Feature representation is an important research topic in facial expression recognition from video sequences. In this letter, we propose to use spatiotemporal monogenic binary patterns to describe both appearance and motion information of the dynamic sequences. Firstly, we use monogenic signals analysis to extract the magnitude, the real picture and the imaginary picture of the orientation of each frame, since the magnitude can provide much appearance information and the orientation can provide complementary information. Secondly, the phase-quadrant encoding method and the local bit exclusive operator are utilized to encode the real and imaginary pictures from orientation in three orthogonal planes, and the local binary pattern operator is used to capture the texture and motion information from the magnitude through three orthogonal planes. Finally, both concatenation method and multiple kernel learning method are respectively exploited to handle the feature fusion. The experimental results on the Extended Cohn-Kanade and Oulu-CASIA facial expression databases demonstrate that the proposed methods perform better than the state-of-the-art methods, and are robust to illumination variations.",
"Fabrication of
Fe
16
N
2
Films by Sputtering Process and Experimental Investigation of Origin of Giant Saturation Magnetization in
Fe
16
N
2","We present a systematic study to address a longstanding mystery in magnetic materials and magnetism, whether there is giant saturation magnetization in Fe16N2 and why. Experimental results based on sputtered thin film samples are presented. The magnetism of Fe16N2 is discussed systematically from the aspects of material processing, magnetic characterization and theoretical investigation. It is observed that thin films with Fe16N2+Fe8N mixture phases and high degree of N ordering, exhibit a saturation magnetization up to 2.68T at room temperature, which substantially exceeds the ferromagnetism limit based on the traditional band magnetism understanding. From X-ray magnetic circular Dichorism (XMCD) experiment, transport measurement and first-principle calculation based on LDA+U method, it is both experimentally and theoretically justified that the origin of giant saturation magnetization is correlated with the formation of highly localized 3d electron states in this Fe-N system. A large magnetocrystalline anisotropy for such a material is also discussed. Our proposed “cluster+atom” theory provides promising directions on designing novel magnetic materials with unique performances.","Iron,
Saturation magnetization,
Gallium arsenide,
Magnetometers,
Sputtering,
Perpendicular magnetic anisotropy"
Single and Multiple Object Tracking Using Log-Euclidean Riemannian Subspace and Block-Division Appearance Model,"Object appearance modeling is crucial for tracking objects, especially in videos captured by nonstationary cameras and for reasoning about occlusions between multiple moving objects. Based on the log-euclidean Riemannian metric on symmetric positive definite matrices, we propose an incremental log-euclidean Riemannian subspace learning algorithm in which covariance matrices of image features are mapped into a vector space with the log-euclidean Riemannian metric. Based on the subspace learning algorithm, we develop a log-euclidean block-division appearance model which captures both the global and local spatial layout information about object appearances. Single object tracking and multi-object tracking with occlusion reasoning are then achieved by particle filtering-based Bayesian state inference. During tracking, incremental updating of the log-euclidean block-division appearance model captures changes in object appearance. For multi-object tracking, the appearance models of the objects can be updated even in the presence of occlusions. Experimental results demonstrate that the proposed tracking algorithm obtains more accurate results than six state-of-the-art tracking algorithms.","Tracking,
Cameras,
Solid modeling,
Covariance matrix,
Algorithm design and analysis,
Inference algorithms,
Visual analytics"
Compact Millimeter-Wave Sensor for Remote Monitoring of Vital Signs,"A compact millimeter-wave (MMW) sensor has been developed for remote monitoring of human vital signs (heart and respiration rate). The low-power homodyne transceiver operating at 94 GHz was assembled by using solid-state active and passive block-type components and can be battery operated. A description of the MMW system front end and the back-end acquisition hardware and software is presented. Representative test case results on the application of various signal processing and data analysis algorithms developed to extract faint physiological signals of interest in presence of strong background interference are provided. Although the laboratory experiments so far have been limited to standoff distances of up to 15 m, the upper limit of the detection range is expected to be higher. In comparison with its microwave counterparts, the MMW system described here provides higher directivity, increased sensitivity, and longer detection range for measuring subtle mechanical displacements associated with heart and respiration functions. The system may be adapted for use in a wide range of standoff sensing applications including for patient health care, structural health monitoring, nondestructive testing, biometric sensing, and remote vibrometry in general.","Biomedical monitoring,
Remote monitoring,
Heart rate,
Mixers,
Time frequency analysis,
Vibrometers"
Debye Length and Active Layer Thickness-Dependent Performance Variations of Amorphous Oxide-Based TFTs,"We analyzed the active layer thickness-dependent performance variations of amorphous oxide-based semiconductor thin-film transistors (AOS TFTs), which are typically operated in depletion mode by using an ATLAS 2-D device simulator. The negative shift of threshold voltage was originated from increasing the amount of intrinsic carrier as active layer thickness is increased. On the contrary, off-current level was a function of Debye length, which is in inverse proportion to the square root of carrier density and the amount of valence band deep states, as well as active layer thickness. Therefore, the relation between Debye length and active layer thickness determines the off-current level, which also enables to explain the off-current behavior of AOS TFTs under light illumination.","Neodymium,
Thin film transistors,
Charge carrier density,
Threshold voltage,
Performance evaluation,
Educational institutions"
BodyCloud: Integration of Cloud Computing and body sensor networks,"Spatially distributed sensor nodes can be used to monitor systems and humans conditions in a wide range of application domains. A network of body sensors in a community of people generates large amounts of contextual data that requires a scalable approach for storage and processing. Cloud computing can provide a powerful, scalable storage and processing infrastructure to perform both online and offline analysis and mining of body sensor data streams. This paper presents BodyCloud, a system architecture based on Cloud Computing for the management and monitoring of body sensor data streams. It incorporates key concepts such as scalability and flexibility of resources, sensor heterogeneity, and the dynamic deployment and management of user and community applications.","Monitoring,
Cloud computing,
Biomedical monitoring,
Computer architecture,
Real-time systems,
Wireless sensor networks,
Medical services"
Image Quality Assessment by Visual Gradient Similarity,"A full-reference image quality assessment (IQA) model by multiscale visual gradient similarity (VGS) is presented. The VGS model adopts a three-stage approach: First, global contrast registration for each scale is applied. Then, pointwise comparison is given by multiplying the similarity of gradient direction with the similarity of gradient magnitude. Third, intrascale pooling is applied, followed by interscale pooling. Several properties of human visual systems on image gradient have been explored and incorporated into the VGS model. It has been found that Stevens' power law is also suitable for gradient magnitude. Other factors such as quality uniformity, visual detection threshold of gradient, and visual frequency sensitivity also affect subjective image quality. The optimal values of two parameters of VGS are trained with existing IQA databases, and good performance of VGS has been verified by cross validation. Experimental results show that VGS is competitive with state-of-the-art metrics in terms of prediction precision, reliability, simplicity, and low computational cost.","Visualization,
Image quality,
Measurement,
Humans,
Adaptation models,
Signal to noise ratio,
Computational modeling"
FireCol: A Collaborative Protection Network for the Detection of Flooding DDoS Attacks,"Distributed denial-of-service (DDoS) attacks remain a major security problem, the mitigation of which is very hard especially when it comes to highly distributed botnet-based attacks. The early discovery of these attacks, although challenging, is necessary to protect end-users as well as the expensive network infrastructure resources. In this paper, we address the problem of DDoS attacks and present the theoretical foundation, architecture, and algorithms of FireCol. The core of FireCol is composed of intrusion prevention systems (IPSs) located at the Internet service providers (ISPs) level. The IPSs form virtual protection rings around the hosts to defend and collaborate by exchanging selected traffic information. The evaluation of FireCol using extensive simulations and a real dataset is presented, showing FireCol effectiveness and low overhead, as well as its support for incremental deployment in real networks.","Fires,
Entropy,
Computer crime,
Collaboration,
Time frequency analysis,
IP networks"
Automated repair of HTML generation errors in PHP applications using string constraint solving,"PHP web applications routinely generate invalid HTML. Modern browsers silently correct HTML errors, but sometimes malformed pages render inconsistently, cause browser crashes, or expose security vulnerabilities. Fixing errors in generated pages is usually straightforward, but repairing the generating PHP program can be much harder. We observe that malformed HTML is often produced by incorrect constant prints, i.e., statements that print string literals, and present two tools for automatically repairing such HTML generation errors. PHPQuickFix repairs simple bugs by statically analyzing individual prints. PHPRepair handles more general repairs using a dynamic approach. Based on a test suite, the property that all tests should produce their expected output is encoded as a string constraint over variables representing constant prints. Solving this constraint describes how constant prints must be modified to make all tests pass. Both tools were implemented as an Eclipse plugin and evaluated on PHP programs containing hundreds of HTML generation errors, most of which our tools were able to repair automatically.","HTML,
Maintenance engineering,
Databases,
Computer bugs,
Browsers,
Cascading style sheets,
USA Councils"
Global State Synchronization in Networks of Cyclic Feedback Systems,This technical note studies global asymptotic state synchronization in networks of identical systems. Conditions on the coupling strength required for the synchronization of nodes having a cyclic feedback structure are deduced using incremental dissipativity theory. The method takes advantage of the incremental passivity properties of the constituent subsystems of the network nodes to reformulate the synchronization problem as one of achieving incremental passivity by coupling. The method can be used in the framework of contraction theory to constructively build a contracting metric for the incremental system. The result is illustrated for a network of biochemical oscillators.,
Particle swarm optimization: Velocity initialization,"Since its birth in 1995, particle swarm optimization (PSO) has been well studied and successfully applied. While a better understanding of PSO and particle behaviors have been obtained through theoretical and empirical analysis, some issues about the beavior of particles remain unanswered. One such issue is how velocities should be initialized. Though zero initial velocities have been advocated, a popular initialization strategy is to set initial weights to random values within the domain of the optimization problem. This article first illustrates that particles tend to leave the boundaries of the search space irrespective of the initialization approach, resulting in wasted search effort. It is also shown that random initialization increases the number of roaming particles, and that this has a negative impact on convergence time. It is also shown that enforcing a boundary constraint on personal best positions does not help much to address this problem. The main objective of the article is to show that the best approach is to initialize particles to zero, or random values close to zero, without imposing a personal best bound.","Search problems,
Optimization,
Particle swarm optimization,
Convergence,
Topology,
Aerospace electronics,
Clamps"
Characterization of the indoor magnetic field for applications in Localization and Mapping,"To improve our understanding of the indoor properties of the perturbed Earth's magnetic field, we have developed a methodology to obtain dense and spatially referenced samples of the magnetic vector field on the ground's surface and in the free space above. This methodology draws on the use of various tracking techniques (photometric, odometric, and motion capture) to accurately determine the pose of the magnetic sensor, which can be positioned manually by humans or autonomously by robots to acquire densely gridded sample datasets. We show that the indoor magnetic field exhibits a fine-grained and persistent micro-structure of perturbations in terms of its direction and intensity. Instead of being a hindrance to indoor navigation, we believe that the variations of the three vector components are sufficiently expressive to form re-recognizable features based on which accurate localization is possible. We provide experimental results using our methodology to map the magnetic field on the ground's surface in our indoor research facilities. With the use of a magnetometer and very little computation, these resulting maps can serve to compensate the perturbations and subsequently determine pose of a human or robot in dead reckoning applications.","SLAM (robots),
compensation,
indoor environment,
magnetic fields,
magnetic sensors,
magnetometers,
mobile robots,
perturbation techniques"
A Preclinical System Prototype for Focused Microwave Thermal Therapy of the Breast,"A preclinical prototype of a transcutaneous thermal therapy system has been developed for the targeted treatment of breast cancer cells using focused microwaves as an adjuvant to radiation, chemotherapy, and high-intensity-focused ultrasound. The prototype system employs a 2-D array of tapered microstrip patch antennas operating at 915 MHz to focus continuous-wave microwave energy transcutaneously into the pendent breast suspended in a coupling medium. Prior imaging studies are used to ascertain the material properties of the breast tissue, and these data are incorporated into a multiphysics model. Time-reversal techniques are employed to find a solution (relative amplitudes and phase) for focusing at a given location. Modeling tests of this time-reversal focusing method have been performed, which demonstrate good targeting accuracy within heterogeneous breast tissue. Experimental results using the laboratory prototype to perform focused heating in tissue-mimicking gelatin phantoms have demonstrated 1.5-cm-diameter focal spot sizes and differential heating at the desired focus sufficient to achieve an antitumor effect confined to the target region.","Electromagnetic heating,
Microwave theory and techniques,
Arrays,
Microwave imaging,
Hyperthermia,
Microwave antenna arrays"
Wide-Loading-Range Fully Integrated LDR With a Power-Supply Ripple Injection Filter,"A low-dropout regulator for on-chip application with a power-supply rejection (PSR) boosting filter circuit for enhancing supply noise rejection at middle-to-high frequency over a wide loading range is presented in this brief. The idea has been analytically modeled and experimentally verified with a standard 0.13- μm CMOS process. The on-chip compensation capacitance is 1 pF. For the PSR filter design, the total on-chip capacitance is 20 pF. From the experimental results, the implemented regulator can operate with supply voltage of 1.2 V with nominal dropout voltage of 0.2 V at maximum load of 50 mA and IQ of 37.32 μA.",
Fast Motion Estimation System Using Dynamic Models for H.264/AVC Video Coding,"H.264/AVC offers many coding tools for achieving high compression gains of up to 50% more than other standards. These tools dramatically increase the computational complexity of the block based motion estimation (BB-ME) which consumes up to 80% of the entire encoder's computations. In this paper, computationally efficient accurate skipping models are proposed to speed up any BB-ME algorithm. First, an accurate initial search center (ISC) is decided using a smart prediction technique. Thereafter, a dynamic early stop search termination (DESST) is used to decide if the block at the ISC position can be considered as a best match candidate block or not. If the DESST algorithm fails, a less complex style of the motion estimation algorithm which incorporates dynamic padding window size technique will be used. Further reductions in computations are achieved by combining the following two techniques. First, a dynamic partial internal stop search technique which utilizes an accurate adaptive threshold model is exploited to skip the internal sum of absolute difference operations between the current and the candidate blocks. Second, a dynamic external stop search technique greatly reduces the unnecessary operations by skipping all the irrelevant blocks in the search area. The proposed techniques can be incorporated in any block matching motion estimation algorithm. Computational complexity reduction is reflected in the amount of savings in the motion estimation encoding time. The novelty of the proposed techniques comes from their superior saving in computations with an acceptable degradation in both peak signal-to-noise ratio (PSNR) and bit-rate compared to the state of the art and the recent motion estimation techniques. Simulation results using H.264/AVC reference software (JM 12.4) show up to 98% saving in motion estimation time using the proposed techniques compared to the conventional full search algorithm with a negligible degradation in the PSNR by approximately 0.05 dB and a small increase in the required bits per frame by only 2%. Experimental results also prove the effectiveness of the proposed techniques if they are incorporated with any fast BB-ME technique such as fast extended diamond enhanced predictive zonal search and predictive motion vector field adaptive search technique.","Motion estimation,
Heuristic algorithms,
Computational complexity,
Mathematical model,
Pixel,
Video sequences,
PSNR"
Energy-Aware Network Planning for Wireless Cellular System with Inter-Cell Cooperation,"In traditional cellular networks, the network planning scheme is imperative for satisfying the coverage and traffic requirement. The rapidly growing number of users in today's cellular networks demands more base stations (BSs) to accommodate the increasing traffic load. The dense deployment results in severe energy consumption, which is often overlooked by existing network planning schemes. In this paper, an energy-aware network planning scheme is proposed to reduce the energy consumption of BSs by leveraging the coverage extension functionality of the inter-cell cooperation. The network planning problem is formulated as a mixed integer programming problem, which is solved with the Lagrangian relaxation method. Numerical results show that the energy efficiency can be enhanced by as much as 20% compared with the non-cooperative scheme without violating the QoS requirement. It is also shown that the proposed scheme is robust to the energy consumption structure of the BSs, and thus can be used with various types of BSs.",
Multiple Hypotheses Bayesian Frame Rate Up-Conversion by Adaptive Fusion of Motion-Compensated Interpolations,"Frame rate up-conversion (FRUC) improves the viewing experience of a video because the motion in a FRUC-constructed high frame-rate video looks more smooth and continuous. This paper proposes a multiple hypotheses Bayesian FRUC scheme for estimating the intermediate frame with maximum a posteriori probability, in which both temporal motion model and spatial image model are incorporated into the optimization criterion. The image model describes the spatial structure of neighboring pixels while the motion model describes the temporal correlation of pixels along motion trajectories. Instead of employing a single uniquely optimal motion, multiple “optimal” motion trajectories are utilized to form a group of motion hypotheses. To obtain accurate estimation for the pixels in missing intermediate frames, the motion-compensated interpolations generated by all these motion hypotheses are adaptively fused according to the reliability of each hypothesis. We revealed by numerical analysis that this reliability (i.e., the variance of interpolation errors along the hypothesized motion trajectory) can be measured by the variation of reference pixels along the motion trajectory. To obtain the multiple motion fields, a set of block-matching sizes is used and the motion fields are estimated by progressively reducing the size of matching block. Experimental results show that the proposed method can significantly improve both the objective and the subjective quality of the constructed high frame rate video.","Trajectory,
Vectors,
Motion estimation,
Estimation,
Reliability,
Interpolation,
Bayesian methods"
Efficient Algorithm for Level Set Method Preserving Distance Function,"The level set method is a popular technique for tracking moving interfaces in several disciplines, including computer vision and fluid dynamics. However, despite its high flexibility, the original level set method is limited by two important numerical issues. First, the level set method does not implicitly preserve the level set function as a distance function, which is necessary to estimate accurately geometric features, s.a. the curvature or the contour normal. Second, the level set algorithm is slow because the time step is limited by the standard Courant-Friedrichs-Lewy (CFL) condition, which is also essential to the numerical stability of the iterative scheme. Recent advances with graph cut methods and continuous convex relaxation methods provide powerful alternatives to the level set method for image processing problems because they are fast, accurate, and guaranteed to find the global minimizer independently to the initialization. These recent techniques use binary functions to represent the contour rather than distance functions, which are usually considered for the level set method. However, the binary function cannot provide the distance information, which can be essential for some applications, s.a. the surface reconstruction problem from scattered points and the cortex segmentation problem in medical imaging. In this paper, we propose a fast algorithm to preserve distance functions in level set methods. Our algorithm is inspired by recent efficient l1 optimization techniques, which will provide an efficient and easy to implement algorithm. It is interesting to note that our algorithm is not limited by the CFL condition and it naturally preserves the level set function as a distance function during the evolution, which avoids the classical re-distancing problem in level set methods. We apply the proposed algorithm to carry out image segmentation, where our methods prove to be 5-6 times faster than standard distance preserving level set techniques. We also present two applications where preserving a distance function is essential. Nonetheless, our method stays generic and can be applied to any level set methods that require the distance information.",
"PMU-Based Wide-Area Security Assessment: Concept, Method, and Implementation","This paper presents a concept, method, and implementation of utilizing phasor measurement unit (PMU) information to monitor the wide-area security of a power system. The close dependency of major transmission paths requires an approach that takes that interaction into account while establishing operational transfer capability, and evaluates grid reliability and security on a system-wide basis. Thus, the concept of wide-area security region, which considers all essential constraints, including thermal, voltage stability, transient stability, and small signal stability, is proposed. This approach expands the idea of traditional transmission system nomograms to a multidimensional case, involving multiple system limits and parameters such as transmission path constraints, zonal generation or load, etc., considered concurrently. In this paper, the security region boundary is represented using piecewise approximation with the help of linear inequalities (so called hyperplanes) in a multidimensional space, consisting of system parameters that are critical for security analysis. The goal of this approximation is to find a minimum set of hyperplanes that describe the boundary with a given accuracy. Offline computer simulations are conducted to build the security region and the hyperplanes can be applied in real time with phasor information for on-line security assessment. Numerical simulations have been performed for the full size Western Electricity Coordinating Council (WECC) system model, which comprises 15 126 buses and 3034 generators. Simulation results demonstrated the feasibility and effectiveness of this approach, and proved that the proposed approach can significantly enhance the wide-area situation awareness for a bulk power system like WECC.",
Mesh Segmentation with Concavity-Aware Fields,"This paper presents a simple and efficient automatic mesh segmentation algorithm that solely exploits the shape concavity information. The method locates concave creases and seams using a set of concavity-sensitive scalar fields. These fields are computed by solving a Laplacian system with a novel concavity-sensitive weighting scheme. Isolines sampled from the concavity-aware fields naturally gather at concave seams, serving as good cutting boundary candidates. In addition, the fields provide sufficient information allowing efficient evaluation of the candidate cuts. We perform a summarization of all field gradient magnitudes to define a score for each isoline and employ a score-based greedy algorithm to select the best cuts. Extensive experiments and quantitative analysis have shown that the quality of our segmentations are better than or comparable with existing state-of-the-art more complex approaches.","Shape,
Solid modeling,
Computational modeling,
Face,
Laplace equations,
Extremities,
Boundary conditions"
Transient Thermal Performance of IGBT Power Modules Attached by Low-Temperature Sintered Nanosilver,"Recently, to accurately study the transient thermal behavior of power modules, a transient thermal measurement system was developed to investigate the transient thermal behavior of insulated-gate bipolar transistor (IGBT) modules attached by nanosilver paste and two kinds of lead-free solders. We found that the transient thermal impedance of IGBT modules attached by nanosilver paste was 9% lower than that of the modules using SAC305 and SN100C with 40-ms heating pulse. In addition, finite-element analysis is employed to simulate thermal performance of the IGBT devices. The simulation shows that the transient thermal impedance of IGBT modules attached by nanosilver paste was also lower than that of the modules using lead-free solders. A convenient way was introduced to well predict the transient thermal behavior of IGBT power module. The calculated results agreed well with the measured one. The interface thermal impedance of sintered nanosilver and SNC100C are calculated to be 0.011 ~ 0.031 K/W and 0.022 ~ 0.042 K/W, respectively.","Insulated gate bipolar transistors,
Impedance,
Transient analysis,
Thermal conductivity,
Heating,
Conductivity,
Temperature measurement"
Distributed Bayesian learning in multiagent systems: Improving our understanding of its capabilities and limitations,"In this article, we study social networks of agents, where agents learn not only from private signals (i.e., signals only available to the agents receiving them), but from other agents too. Based on all the available information, agents modify their beliefs in events of interest and make decisions on which actions to take based on the beliefs. In doing so, they optimize functions that reflect some (cumulative) reward. This problem has been studied in various disciplines including control theory, operations research, artificial intelligence, game theory, information theory, economics, statistics, computer science, and signal processing.","Social network services,
Software agents,
Decision making,
Computer applications"
Joint Source-Channel Coding and Optimization for Layered Video Broadcasting to Heterogeneous Devices,"Heterogeneous quality-of-service (QoS) video broadcast over wireless network is a challenging problem, where the demand for better video quality needs to be reconciled with different display size, variable channel condition requirements. In this paper, we present a framework for broadcasting scalable video to heterogeneous QoS mobile users with diverse display devices and different channel conditions. The framework includes joint video source-channel coding and optimization. First, we model the problem of broadcasting a layered video to heterogeneous devices as an aggregate utility achieving problem. Second, based on scalable video coding, we introduce the temporal-spatial content distortion metric to build adaptive layer structure, so as to serve mobile users with heterogeneous QoS requirements. Third, joint Fountain coding protection is introduced so as to provide flexible and reliable video stream. Finally, we use dynamic programming approach to obtain optimal layer broadcasting policy, so as to achieve maximum broadcasting utility. The objective is to achieve maximum overall receiving quality of the heterogeneous QoS receivers. Experimental results demonstrate the effectiveness of the solution.","Multimedia communication,
Broadcasting,
Streaming media,
Joints,
Encoding,
Quality of service,
Receivers"
A Comparison Study of Validity Indices on Swarm-Intelligence-Based Clustering,"Swarm intelligence has emerged as a worthwhile class of clustering methods due to its convenient implementation, parallel capability, ability to avoid local minima, and other advantages. In such applications, clustering validity indices usually operate as fitness functions to evaluate the qualities of the obtained clusters. However, as the validity indices are usually data dependent and are designed to address certain types of data, the selection of different indices as the fitness functions may critically affect cluster quality. Here, we compare the performances of eight well-known and widely used clustering validity indices, namely, the Caliński-Harabasz index, the CS index, the Davies-Bouldin index, the Dunn index with two of its generalized versions, the I index, and the silhouette statistic index, on both synthetic and real data sets in the framework of differential-evolution-particle-swarm-optimization (DEPSO)-based clustering. DEPSO is a hybrid evolutionary algorithm of the stochastic optimization approach (differential evolution) and the swarm intelligence method (particle swarm optimization) that further increases the search capability and achieves higher flexibility in exploring the problem space. According to the experimental results, we find that the silhouette statistic index stands out in most of the data sets that we examined. Meanwhile, we suggest that users reach their conclusions not just based on only one index, but after considering the results of several indices to achieve reliable clustering structures.","Indexes,
Clustering algorithms,
Vectors,
Partitioning algorithms,
Particle swarm optimization,
Encoding,
Context"
Reference-Free PRFS MR-Thermometry Using Near-Harmonic 2-D Reconstruction of the Background Phase,"Proton resonance frequency shift (PRFS) MR thermometry (MRT) is the generally preferred method for monitoring thermal ablation, typically implemented with gradient-echo (GRE) sequences. Standard PRFS MRT is based on the subtraction of a temporal reference phase map and is, therefore, intrinsically sensitive to tissue motion (including deformation) and to external perturbation of the magnetic field. Reference-free (or reference-less) PRFS MRT has been previously described by Rieke and was based on a 2-D polynomial fit performed on phase data from outside the heated region, to estimate the background phase inside the region of interest. While their approach was undeniably a fundamental progress in terms of robustness against tissue motion and magnetic perturbations, the underlying mathematical formalism requires a thick unheated border and may be subject to numerical instabilities with high order polynomials. A novel method of reference-free PRFS MRT is described here, using a physically consistent formalism, which exploits mathematical properties of the magnetic field in a homogeneous or near-homogeneous medium.","Image reconstruction,
Approximation methods,
Magnetic resonance imaging,
Coils,
Polynomials,
Mathematical model"
An Effective Approach to the Synthesis of Phase-Only Reconfigurable Linear Arrays,"We present an effective approach to the optimal mask-constrained power pattern synthesis of uniformly spaced array antennas able to dynamically reconfigure their radiation pattern by modifying only the excitation phases. The proposed approach results in a design procedure having a very low computational burden and, by exploiting at best the knowledge available in the separate synthesis of each pattern, is able to solve the underlying combinatorial optimization problem and to achieve solutions close (or equivalent) to the global optimum. A set of representative examples are reported in order to validate the proposed approach. Some extensions of the developed theory to cases other than linear arrays are also outlined.","Optimization,
Phased arrays,
Vectors,
Linear antenna arrays,
Antenna radiation patterns,
Indexes"
Sleep Scheduling for Critical Event Monitoring in Wireless Sensor Networks,"In this paper, we focus on critical event monitoring in wireless sensor networks (WSNs), where only a small number of packets need to be transmitted most of the time. When a critical event occurs, an alarm message should be broadcast to the entire network as soon as possible. To prolong the network lifetime, some sleep scheduling methods are always employed in WSNs, resulting in significant broadcasting delay, especially in large scale WSNs. In this paper, we propose a novel sleep scheduling method to reduce the delay of alarm broadcasting from any sensor node in WSNs. Specifically, we design two determined traffic paths for the transmission of alarm message, and level-by-level offset based wake-up pattern according to the paths, respectively. When a critical event occurs, an alarm is quickly transmitted along one of the traffic paths to a center node, and then it is immediately broadcast by the center node along another path without collision. Therefore, two of the big contributions are that the broadcasting delay is independent of the density of nodes and its energy consumption is ultra low. Exactly, the upper bound of the broadcasting delay is only 3D+2L, where D is the maximum hop of nodes to the center node, L is the length of sleeping duty cycle, and the unit is the size of time slot. Extensive simulations are conducted to evaluate these notable performances of the proposed method compared with existing works.","Delay,
Broadcasting,
Wireless sensor networks,
Charge coupled devices,
Monitoring,
Downlink,
Sleep"
Information-Theoretic Lower Bounds on the Oracle Complexity of Stochastic Convex Optimization,"Relative to the large literature on upper bounds on complexity of convex optimization, lesser attention has been paid to the fundamental hardn4516420ess of these problems. Given the extensive use of convex optimization in machine learning and statistics, gaining an understanding of these complexity-theoretic issues is important. In this paper, we study the complexity of stochastic convex optimization in an oracle model of computation. We introduce a new notion of discrepancy between functions, and use it to reduce problems of stochastic convex optimization to statistical parameter estimation, which can be lower bounded using information-theoretic methods. Using this approach, we improve upon known results and obtain tight minimax complexity estimates for various function classes.","Complexity theory,
Convex functions,
Stochastic processes,
Optimization methods,
Upper bound,
Power capacitors"
Autocratic Decision Making Using Group Recommendations Based on the ILLOWA Operator and Likelihood-Based Comparison Relations,"In this paper, we present a new method for interval linguistic labels aggregation and consensus measure for autocratic decision making using group recommendations based on the proposed interval linguistic labels ordered weighted average (ILLOWA) operator and the likelihood-based comparison relations of interval linguistic labels. We propose the ILLOWA operator to aggregate interval linguistic labels. We propose the concepts of likelihood-based comparison relations of interval linguistic labels. Based on the proposed ILLOWA operator and likelihood-based comparison relations of interval linguistic labels, we propose a new method for interval linguistic labels aggregation and consensus measure for autocratic decision making using group recommendations. The proposed method can overcome the drawbacks of Ben-Arieh and Chen's method. It provides us with a useful way for interval linguistic labels aggregation and consensus measure for autocratic decision making using group recommendations.","Pragmatics,
Decision making,
Open wireless architecture,
Aggregates,
Humans,
Investments,
Companies"
Performance Analysis of Wireless Sensor Networks With Mobile Sinks,"In wireless sensor networks (WSNs), one major challenge is how to prolong the network lifetime while maintaining a certain data collection rate for resource-limited static sensors. To achieve this goal, many mobility-assisted data collection (MADC) schemes have been proposed in the literature. However, there is a lack of systematic analysis on the behaviors of the MADC models in terms of both throughput capacity, which is defined as the maximal data collection rate, and lifetime, which will be associated with a specific data collection rate. In this paper, we address this issue in a large-scale WSN with mobile sinks from a theoretical perspective, which has not yet been studied. In particular, we first propose a general MADC model that includes many important parameters such as the number of mobile sinks, the velocity of a mobile sink, and the traveling path of a mobile node. We then develop a comprehensive theoretical approach to obtain the achievable throughput capacity and lifetime. By applying the proposed approach, we investigate the behaviors of WSNs with one or more mobile sinks. Our analysis not only shows how a WSN with mobile sinks can outperform a static WSN but also provides insights on how we can adjust the MADC parameters to improve the data collection rate and to maximize the lifetime. Finally, our analysis is validated through extensive simulations.","Mobile communication,
Wireless sensor networks,
Throughput,
Sensors,
Data models,
Mobile computing,
Analytical models"
Energy harvesting cooperative communications,"In this paper, we propose a new cooperative wireless transmission in a scenario where the source salvages the energy during the relay's transmission considering the fact that the source does not need to retrieve the transmitted message. We also evaluate a direct wireless transmission with wireless energy transfer as a reference. We analyze the performance of these transmission techniques in terms of outage probability. Our analytical results reveal the advantage of energy salvage in combination with spatial diversity over the direct transmission even if the energy transfer efficiency is considerably low.","Energy harvesting,
Wireless sensor networks,
Wireless communication,
Energy exchange,
Relays,
Batteries,
Computational modeling"
Accurate Automatic Analysis of Cardiac Cine Images,"Acquisition of noncontrast agent cine cardiac magnetic resonance (CMR) gated images through the cardiac cycle is, at present, a well-established part of examining cardiac global function. However, regional quantification is less well established. We propose a new automated framework for analyzing the wall thickness and thickening function on these images that consists of three main steps. First, inner and outer wall borders are segmented from their surrounding tissues with a geometric deformable model guided by a special stochastic speed relationship. The latter accounts for Markov-Gibbs shape and appearance models of the object-of-interest and its background. In the second step, point-to-point correspondences between the inner and outer borders are found by solving the Laplace equation and provide initial estimates of the local wall thickness and the thickening function index. Finally, the effects of the segmentation error is reduced and a continuity analysis of the LV wall thickening is performed through iterative energy minimization using a generalized Gauss-Markov random field (GGMRF) image model. The framework was evaluated on 26 datasets from clinical cine CMR images that have been collected from patients with eleven independent studies, with chronic ischemic heart disease and heart damage. The performance evaluation of the proposed segmentation approach, based on the receiver operating characteristic (ROC) and Dice similarity coefficients (DSC) between manually drawn and automatically segmented contours, confirmed a high robustness and accuracy of the proposed segmentation approach. Furthermore, the Bland-Altman plot is used to assess the limit of agreement of our measurements of the global function parameters compared to the ground truth. Importantly, comparative results on the publicly available database (MICCAI 2009 Cardiac MR Left Ventricle Segmentation) demonstrated a superior performance of the proposed segmentation approach over published methods.",
Nonnegative Blind Source Separation by Sparse Component Analysis Based on Determinant Measure,"The problem of nonnegative blind source separation (NBSS) is addressed in this paper, where both the sources and the mixing matrix are nonnegative. Because many real-world signals are sparse, we deal with NBSS by sparse component analysis. First, a determinant-based sparseness measure, named D-measure, is introduced to gauge the temporal and spatial sparseness of signals. Based on this measure, a new NBSS model is derived, and an iterative sparseness maximization (ISM) approach is proposed to solve this model. In the ISM approach, the NBSS problem can be cast into row-to-row optimizations with respect to the unmixing matrix, and then the quadratic programming (QP) technique is used to optimize each row. Furthermore, we analyze the source identifiability and the computational complexity of the proposed ISM-QP method. The new method requires relatively weak conditions on the sources and the mixing matrix, has high computational efficiency, and is easy to implement. Simulation results demonstrate the effectiveness of our method.","Sparse matrices,
Source separation,
Educational institutions,
Indexes,
Matrix decomposition,
Cost function"
"Low Profile, Miniaturized, Inductively Coupled Capacitively Loaded Monopole Antenna","A novel high-gain low-profile miniaturized antenna with omnidirectional vertically polarized radiation, similar to a short dipole is presented. The proposed design focus is on increasing the gain and improving the polarization purity of the radiated field in the horizontal plane. The gain and polarization improvement are achieved by isolating the feed structure from a miniaturized resonant radiating structure composed of an in-plane capacitor and a structurally embedded transformer. The antenna topology is developed, based on circuit model and through full-wave simulations the equivalence is established. The equivalent circuit model assists in the initial design, and then minor modifications are required to achieve the desired frequency of operation. The initial topology of the proposed antenna, the so-called Inductively Coupled Capacitively Loaded Monopole Antenna (ICCLMA), consists of two metal layers, a feeding pin and a shorting pin. The performance of the proposed antenna is compared to that of an ordinary inverted F antenna and a more recent low profile vertically polarized antenna (LMMMA) . It is shown that the gain of ICCLMA is 9 dB and 4 dB higher than that of the conventional inverted-F antenna and the LMMMA, respectively. To simplify the fabrication process a modified single-layer ICCLMA topology is presented and optimized. Finally, a design procedure to further reduce the lateral dimension of ICCLMA is presented. A procedure for accurate measurement of antennas with small ground planes is also presented.","Antenna radiation patterns,
Antenna measurements,
Integrated circuit modeling,
Loaded antennas,
Equivalent circuits,
Pins"
Advanced System Level Simulation Platform for Three-Dimensional UWB Through-Wall Imaging SAR Using Time-Domain Approach,"A previously developed simulation platform for localization purposes has been extended and customized to accurately analyze and simulate ultra wideband (UWB) through-wall imaging (TWI) synthetic aperture radar (SAR) systems as well. The newly added features/modules include electromagnetic simulator to account for wall presence and target scattering, a wideband backprojection imaging algorithm, and different transceiver architectures and antenna array configurations. The developed platform is capable of time gating to suppress early wall reflections and simulates various discrete components and functions of the UWB SAR system using both linear and nonlinear analysis. The simulator has been experimentally validated for both dielectric and metallic targets. The developed simulator can also be used to study various effects related to operation frequency, pulse width, pulse shape, wall dispersion, and carrier leakage. It predicts UWB system performance such as detection range, image resolution, and receiver dynamic range. The system's components can be re-optimized for high performance 3-D imaging based on our developed models. The simulation platform is also suitable for designing the optimal signal waveform that could improve the recovered image quality for TWI applications.","Radar imaging,
Ultra wideband radar,
Imaging,
Integrated circuit modeling,
Prototypes,
Solid modeling"
Virtual Caregiver: An Ambient-Aware Elderly Monitoring System,"The growing number of elderly population at home and abroad necessitates improved approaches to elderly care provision. Elders, often with cognitive and physical impairment, need assistance in their activities of daily living (ADLs), which is usually provided by human caregivers (HCGs). As the demand for caregiver's assistance increases, the shortage of traditional care resources becomes obvious. In this paper, we present the Virtual Caregiver (ViCare) framework that supports a HCG to monitor continuously the elderly by being aware of their surroundings. The ViCare system attempts to understand the elderly persons' activities and contexts based on the data captured by the sensors placed in their environment and dynamically decides what services to provide them or whether there is a need to interrupt HCG depending on the type of activities. It not only minimizes the cognitive load of the HCG but also provides a seamless assistance to the elderly toward their improved health and well-being in their living environment. We conducted the experiments in an instrumented home environment and obtained positive results in terms of the satisfaction of the elderly, interaction event handling, caregiver's acceptance, and their engagement.","Senior citizens,
Humans,
Sensors,
Context-aware services,
Remote monitoring,
Service robots"
Spectrum mobility games,"Cognitive radio gives users the ability to switch channels and make use of dynamic spectrum opportunities. However, switching channels takes time, and may affect the quality of a user's transmission. When a cognitive radio user's channel becomes unavailable, sometimes it may be better waiting until its current channel becomes available again. Motivated by the recent FCC ruling on TV white space, we consider the scenario where cognitive radio users are given the foreknowledge of channel availabilities. Using this information, each user must decide when and how to switch channels. The users wish to exploit spectrum opportunities, but they must take account of the cost of switching channels and the congestion that comes from sharing channels with one another. We model the scenario as a game which, as we show, is equivalent to a network congestion game in the literature after proper and non-trivial transformations. This allows us to design a protocol which the users can apply to find Nash equilibria in a distributed manner. We further evaluate how the performance of the proposed schemes depends on switching cost using real channel availability measurements.",
Hand gesture recognition using Kinect,"Hand gesture recognition (HGR) is an important research topic because some situations require silent communication with sign languages. Computational HGR systems assist silent communication, and help people learn a sign language. In this article, a novel method for contact-less HGR using Microsoft Kinect for Xbox is described, and a real-time HGR system is implemented. The system is able to detect the presence of gestures, to identify fingers, and to recognize the meanings of nine gestures in a pre-defined Popular Gesture scenario. The accuracy of the HGR system is from 84% to 99% with single-hand gestures, and from 90% to 100% if both hands perform the same gesture at the same time. Because the depth sensor of Kinect is an infrared camera, the lighting conditions, signers' skin colors and clothing, and background have little impact on the performance of this system. The accuracy and the robustness make this system a versatile component that can be integrated in a variety of applications in daily life.","Gesture recognition,
Clocks,
Thumb"
On the position accuracy of mobile robot localization based on particle filters combined with scan matching,"Many applications in mobile robotics and especially industrial applications require that the robot has a precise estimate about its pose. In this paper, we analyze the accuracy of an integrated laser-based robot pose estimation and positioning system for mobile platforms. For our analysis, we used a highly accurate motion capture system to precisely determine the error in the robot's pose. We are able to show that by combining standard components such as Monte-Carlo localization, KLD sampling, and scan matching, an accuracy of a few millimeters at taught-in reference locations can be achieved. We believe that this is an important analysis for developers of robotic applications in which pose accuracy matters.","Accuracy,
Service robots,
Robot kinematics,
Lasers,
Robot sensing systems,
Mobile robots"
Boosting 3-D-Geometric Features for Efficient Face Recognition and Gender Classification,"We utilize ideas from two growing but disparate ideas in computer vision-shape analysis using tools from differential geometry and feature selection using machine learning-to select and highlight salient geometrical facial features that contribute most in 3-D face recognition and gender classification. First, a large set of geometries curve features are extracted using level sets (circular curves) and streamlines (radial curves) of the Euclidean distance functions of the facial surface; together they approximate facial surfaces with arbitrarily high accuracy. Then, we use the well-known Adaboost algorithm for feature selection from this large set and derive a composite classifier that achieves high performance with a minimal set of features. This greatly reduced set, consisting of some level curves on the nose and some radial curves in the forehead and cheeks regions, provides a very compact signature of a 3-D face and a fast classification algorithm for face recognition and gender selection. It is also efficient in terms of data storage and transmission costs. Experimental results, carried out using the FRGCv2 dataset, yield a rank-1 face recognition rate of 98% and a gender classification rate of 86% rate.","Face recognition,
Shape analysis,
Feature extraction,
Machine learning,
Feature extraction"
"A Generalization of Distance Functions for Fuzzy c
-Means Clustering With Centroids of Arithmetic Means","Fuzzy c-means (FCM) is a widely used fuzzy clustering method, which allows an object to belong to two or more clusters with a membership grade between zero and one. Despite the considerable efforts made by the clustering community, the common characteristics of distance functions suitable for FCM remain unclear. To fill this crucial void, in this paper, we first provide a generalized definition of distance functions that fit FCM directly. The goal is to provide more flexibility to FCM in the choice of distance functions while preserving the simplicity of FCM by using the centroids of arithmetic means. Indeed, we show that any distance function that fits FCM directly can be derived by a continuously differentiable convex function and, thus, is an instance of the generalized point-to-centroid distance (P2C-D) by definition. In addition, we prove that if the membership grade matrix is nondegenerate, any instance of the P2C-D fits FCM directly. Finally, extensive experiments have been conducted to demonstrate that the P2C-D leads to the global convergence of FCM and that the clustering performances are significantly affected by the choices of distance functions.",
Channel Condition Based Contention Window Adaptation in IEEE 802.11 WLANs,"In IEEE 802.11 standard, the backoff parameters of its collision avoidance mechanism can be very inefficient and hence, the network becomes far from its optimal behavior. There have been several mechanisms to tune the Contention Window (CW) with the aim to achieve the optimal throughput in the IEEE 802.11 WLAN, however, the mechanisms do not specifically address a proper setting of the backoff parameters under non-saturated conditions. Noting that typical 802.11 networks are usually non-saturated, in this paper, we analytically derive the CW sizes that maximize the WLAN system throughput under both saturated and non-saturated conditions. Then, using the CW sizes derived, we propose a distributed algorithm that enables each station to dynamically adapt its CW according to the channel congestion status. The performance of the proposed algorithm is investigated through simulation. Simulation results indicate that our proposed backoff algorithm provides a remarkable performance improvement in terms of the delay experienced by a packet in the MAC layer, while maintaining an optimal throughput close to the theoretical throughput limit of the IEEE 802.11 Distributed Coordination Function (DCF) access scheme.",
Tracking Control of a Closed-Chain Five-Bar Robot With Two Degrees of Freedom by Integration of an Approximation-Based Approach and Mechanical Design,"The trajectory tracking problem of a closed-chain five-bar robot is studied in this paper. Based on an error transformation function and the backstepping technique, an approximation-based tracking algorithm is proposed, which can guarantee the control performance of the robotic system in both the stable and transient phases. In particular, the overshoot, settling time, and final tracking error of the robotic system can be all adjusted by properly setting the parameters in the error transformation function. The radial basis function neural network (RBFNN) is used to compensate the complicated nonlinear terms in the closed-loop dynamics of the robotic system. The approximation error of the RBFNN is only required to be bounded, which simplifies the initial “trail-and-error” configuration of the neural network. Illustrative examples are given to verify the theoretical analysis and illustrate the effectiveness of the proposed algorithm. Finally, it is also shown that the proposed approximation-based controller can be simplified by a smart mechanical design of the closed-chain robot, which demonstrates the promise of the integrated design and control philosophy.",
First-Person Vision,"For understanding the behavior, intent, and environment of a person, the surveillance metaphor is traditional; that is, install cameras and observe the subject, and his/her interaction with other people and the environment. Instead, we argue that the first-person vision (FPV), which senses the environment and the subject's activities from a wearable sensor, is more advantageous with images about the subject's environment as taken from his/her view points, and with readily available information about head motion and gaze through eye tracking. In this paper, we review key research challenges that need to be addressed to develop such FPV systems, and describe our ongoing work to address them using examples from our prototype systems.","Surveillance,
Image matching,
Object recognition,
Wearable sensors,
Tracking,
Videos,
Computer vision,
Service robots,
Intelligent systems,
Quality assessment,
Behavioral science"
Reliability Modeling and Management of Nanophotonic On-Chip Networks,"While transistor performance and energy efficiency have dramatically improved in recent years, electrical interconnect improvements has failed to keep pace. Recent advances in nanophotonic fabrication have made on-chip optics an attractive alternative. However, system integration challenges remain. In particular, the parameters of on-chip nanophotonic structures are sensitive to fabrication-induced process variation and run-time spatial thermal variation across the die. This work addresses the performance and reliability challenges that arise from this sensitivity to variation. The paper first presents a model predicting the system-level effects of thermal and process variation in nanophotonic networks. It then shows how to optimize many-core system performance and reliability by using run-time techniques to compensate for the thermal and process variation effects.","Reliability,
Noise,
System-on-a-chip,
Optical resonators,
Tuning,
Nanoscale devices,
Temperature measurement"
Persistent Brain Network Homology From the Perspective of Dendrogram,"The brain network is usually constructed by estimating the connectivity matrix and thresholding it at an arbitrary level. The problem with this standard method is that we do not have any generally accepted criteria for determining a proper threshold. Thus, we propose a novel multiscale framework that models all brain networks generated over every possible threshold. Our approach is based on persistent homology and its various representations such as the Rips filtration, barcodes, and dendrograms. This new persistent homological framework enables us to quantify various persistent topological features at different scales in a coherent manner. The barcode is used to quantify and visualize the evolutionary changes of topological features such as the Betti numbers over different scales. By incorporating additional geometric information to the barcode, we obtain a single linkage dendrogram that shows the overall evolution of the network. The difference between the two networks is then measured by the Gromov-Hausdorff distance over the dendrograms. As an illustration, we modeled and differentiated the FDG-PET based functional brain networks of 24 attention-deficit hyperactivity disorder children, 26 autism spectrum disorder children, and 11 pediatric control subjects.",
Brain Surface Conformal Parameterization With the Ricci Flow,"In brain mapping research, parameterized 3-D surface models are of great interest for statistical comparisons of anatomy, surface-based registration, and signal processing. Here, we introduce the theories of continuous and discrete surface Ricci flow, which can create Riemannian metrics on surfaces with arbitrary topologies with user-defined Gaussian curvatures. The resulting conformal parameterizations have no singularities and they are intrinsic and stable. First, we convert a cortical surface model into a multiple boundary surface by cutting along selected anatomical landmark curves. Secondly, we conformally parameterize each cortical surface to a parameter domain with a user-designed Gaussian curvature arrangement. In the parameter domain, a shape index based on conformal invariants is computed, and inter-subject cortical surface matching is performed by solving a constrained harmonic map. We illustrate various target curvature arrangements and demonstrate the stability of the method using longitudinal data. To map statistical differences in cortical morphometry, we studied brain asymmetry in 14 healthy control subjects. We used a manifold version of Hotelling's T2 test, applied to the Jacobian matrices of the surface parameterizations. A permutation test, along with the cumulative distribution of p-values, were used to estimate the overall statistical significance of differences. The results show our algorithm's power to detect subtle group differences in cortical surfaces.","Measurement,
Surface treatment,
Brain,
Face,
Geometry,
Conformal mapping,
Three dimensional displays"
"A New Multiplicative Denoising Variational Model Based on
m
th Root Transformation","In coherent imaging systems, such as the synthetic aperture radar (SAR), the observed images are contaminated by multiplicative noise. Due to the edge-preserving feature of the total variation (TV), variational models with TV regularization have attracted much interest in removing multiplicative noise. However, the fidelity term of the variational model, based on maximum a posteriori estimation, is not convex, and so, it is usually difficult to find a global solution. Hence, the logarithmic function is used to transform the nonconvex variational model to the convex one. In this paper, instead of using the log, we exploit the th root function to relax the nonconvexity of the variational model. An algorithm based on the augmented Lagrangian function, which has been applied to solve the log transformed convex variational model, can be applied to solve our proposed model. However, this algorithm requires solving a subproblem, which does not have a closed-form solution, at each iteration. Hence, we propose to adapt the linearized proximal alternating minimization algorithm, which does not require inner iterations for solving the subproblems. In addition, the proposed method is very simple and highly parallelizable; thus, it is efficient to remove multiplicative noise in huge SAR images. The proposed model for multiplicative noise removal shows overall better performance than the convex model based on the log transformation.","Numerical models,
Noise,
Computational modeling,
Lagrangian functions,
Noise reduction,
Adaptation models,
Minimization"
Auction-based resource allocation in cognitive radio systems,"Auction theory, as a subfield of economics, provides useful tools to model, analyze, and optimize radio resource management in cognitive radio environments. By using an auction, radio resources such as subchannel, time slot, and transmit power can be allocated among licensed and unlicensed users in the system, following market laws. Due to the flexibility of mechanism design, there are various auction mechanisms that have been applied to cognitive radio systems with different characteristics. In this article, we first provide an overview of the basics of general auctions. Then the motivations and specific design issues in applying auctions to wireless network architectures and protocols are discussed. Then we review the state of the art in the use of auction theory and mechanism design in cognitive radio networks. This will enable the readers to have a general view of auction fundamentals, as well as the recent development and applications of auction theory in the emerging cognitive wireless networks.","Cognitive radio,
Base stations,
Resource management,
Cost accounting,
Radio communication,
Multiaccess communication"
Face spoofing detection from single images using texture and local shape analysis,"Current face biometric systems are vulnerable to spoofing attacks. A spoofing attack occurs when a person tries to masquerade as someone else by falsifying data and thereby gaining illegitimate access. Inspired by image quality assessment, characterisation of printing artefacts and differences in light reflection, the authors propose to approach the problem of spoofing detection from texture analysis point of view. Indeed, face prints usually contain printing quality defects that can be well detected using texture and local shape features. Hence, the authors present a novel approach based on analysing facial image for detecting whether there is a live person in front of the camera or a face print. The proposed approach analyses the texture and gradient structures of the facial images using a set of low-level feature descriptors, fast linear classification scheme and score level fusion. Compared to many previous works, the authors proposed approach is robust and does not require user-cooperation. In addition, the texture features that are used for spoofing detection can also be used for face recognition. This provides a unique feature space for coupling spoofing detection and face recognition. Extensive experimental analysis on three publicly available databases showed excellent results compared to existing works.","image texture,
biometrics (access control),
face recognition,
image classification"
A whitebox approach for automated security testing of Android applications on the cloud,"By changing the way software is delivered to end-users, markets for mobile apps create a false sense of security: apps are downloaded from a market that can potentially be regulated. In practice, this is far from truth and instead, there has been evidence that security is not one of the primary design tenets for the mobile app stores. Recent studies have indicated mobile markets are harboring apps that are either malicious or vulnerable leading to compromises of millions of devices. The key technical obstacle for the organizations overseeing these markets is the lack of practical and automated mechanisms to assess the security of mobile apps, given that thousands of apps are added and updated on a daily basis. In this paper, we provide an overview of a multi-faceted project targeted at automatically testing the security and robustness of Android apps in a scalable manner. We describe an Android-specific program analysis technique capable of generating a large number of test cases for fuzzing an app, as well as a test bed that given the generated test cases, executes them in parallel on numerous emulated Androids running on the cloud.","Security,
Androids,
Humanoid robots,
Layout,
Smart phones,
Testing,
Software"
Impact of Model Shape Mismatch on Reconstruction Quality in Electrical Impedance Tomography,"Electrical impedance tomography (EIT) is a low-cost, noninvasive and radiation free medical imaging modality for monitoring ventilation distribution in the lung. Although such information could be invaluable in preventing ventilator-induced lung injury in mechanically ventilated patients, clinical application of EIT is hindered by difficulties in interpreting the resulting images. One source of this difficulty is the frequent use of simple shapes which do not correspond to the anatomy to reconstruct EIT images. The mismatch between the true body shape and the one used for reconstruction is known to introduce errors, which to date have not been properly characterized. In the present study we, therefore, seek to 1) characterize and quantify the errors resulting from a reconstruction shape mismatch for a number of popular EIT reconstruction algorithms and 2) develop recommendations on the tolerated amount of mismatch for each algorithm. Using real and simulated data, we analyze the performance of four EIT reconstruction algorithms under different degrees of shape mismatch. Results suggest that while slight shape mismatch is well tolerated by all algorithms, using a circular shape severely degrades their performance.",
Separate Magnitude and Phase Regularization via Compressed Sensing,"Compressed sensing (CS) has been used for accelerating magnetic resonance imaging acquisitions, but its use in applications with rapid spatial phase variations is challenging, e.g., proton resonance frequency shift (PRF-shift) thermometry and velocity mapping. Previously, an iterative MRI reconstruction with separate magnitude and phase regularization was proposed for applications where magnitude and phase maps are both of interest, but it requires fully sampled data and unwrapped phase maps. In this paper, CS is combined into this framework to reconstruct magnitude and phase images accurately from undersampled data. Moreover, new phase regularization terms are proposed to accommodate phase wrapping and to reconstruct images with encoded phase variations, e.g., PRF-shift thermometry and velocity mapping. The proposed method is demonstrated with simulated thermometry data and in vivo velocity mapping data and compared to conventional phase corrected CS.","Image reconstruction,
Cost function,
Magnetic resonance imaging,
Wavelet transforms,
Finite difference methods"
Detection of Sudden Pedestrian Crossings for Driving Assistance Systems,"In this paper, we study the problem of detecting sudden pedestrian crossings to assist drivers in avoiding accidents. This application has two major requirements: to detect crossing pedestrians as early as possible just as they enter the view of the car-mounted camera and to maintain a false alarm rate as low as possible for practical purposes. Although many current sliding-window-based approaches using various features and classification algorithms have been proposed for image-/video-based pedestrian detection, their performance in terms of accuracy and processing speed falls far short of practical application requirements. To address this problem, we propose a three-level coarse-to-fine video-based framework that detects partially visible pedestrians just as they enter the camera view, with low false alarm rate and high speed. The framework is tested on a new collection of high-resolution videos captured from a moving vehicle and yields a performance better than that of state-of-the-art pedestrian detection while running at a frame rate of 55 fps.",
Random Access: An Information-Theoretic Perspective,"This paper considers a random access system where each sender is in one of two possible states, active or not active, and the states are only known to the common receiver. Active senders encode data into independent information streams, a subset of which is decoded depending on the collective interference. An information-theoretic formulation of the problem is presented and the set of achievable rates is characterized with a guaranteed gap to optimality. Inner and outer bounds on the capacity region of a two-sender system are tight in the case of a binary-expansion deterministic channel and differ by less than one bit in the case of a Gaussian channel. In systems with an arbitrary number of senders, the symmetric scenario of equal access probabilities and received power constraints is studied and the system throughput, i.e., the maximum achievable expected sum rate, is characterized. It is shown that a simple coding scheme where active senders transmit a single message is optimum for a binary-expansion deterministic channel and achieves within one bit of the optimum in the case of a Gaussian channel. Finally, a comparison with the slotted ALOHA protocol is provided, showing that encoding rate adaptation at the transmitters achieves constant (rather than zero) throughput as the number of users tends to infinity.",
D-Pro: Dynamic Data Center Operations With Demand-Responsive Electricity Prices in Smart Grid,"The study of today's cyber-physical system (CPS) has been an important research area. Internet data centers (IDCs) are energy consuming CPSs that support the reliable operations of many important online services. Along with the increasing Internet services and cloud computing in recent years, the power usage associated with IDC operations had been surging significantly. Such mass power consumption has brought extremely heavy burden on IDC operators. While most previous work only consider about dynamical optimization of IDC under electricity markets, the reaction of IDC toward electricity market has been overlooked. Due to the fact that IDCs are usually large-volume users in the electricity market, they might have market power to affect the electricity price. In this paper, we study how to address the challenge of interactions between IDC operation and electricity market price. To this end, we propose a supply function to model the market power of IDC and formulate a total electricity cost minimization problem as a non-linear programming. Then we present CMC algorithm inspired by the economics concept. CMC algorithm not only solves the optimization problem efficiently, but also uncovers the impetus of the work load distribution. Extensive performance evaluations demonstrate that the proposed method can effectively minimize the total electricity cost of IDCs by adaptively handling the interaction between IDCs and smart grid.",
Flash Crowd in P2P Live Streaming Systems: Fundamental Characteristics and Design Implications,"Peer-to-peer (P2P) live video streaming systems have recently received substantial attention, with commercial deployment gaining increased popularity in the internet. It is evident from our practical experiences with real-world systems that, it is not uncommon for hundreds of thousands of users to choose to join a program in the first few minutes of a live broadcast. Such a severe flash crowd phenomenon in live streaming poses significant challenges in the system design. In this paper, for the first time, we develop a mathematical model to: 1) capture the fundamental relationship between time and scale in P2P live streaming systems under a flash crowd, and 2) explore the design principle of population control to alleviate the impact of the flash crowd. We carry out rigorous analysis that brings forth an in-depth understanding on effects of the gossip protocol and peer dynamics. In particular, we demonstrate that there exists an upper bound on the system scale with respect to a time constraint. By trading peer startup delays in the initial stage of a flash crowd for system scale, we design a simple and flexible population control framework that can alleviate the flash crowd without the requirement of otherwise costly server deployment.","Ash,
Bandwidth,
Servers,
Peer to peer computing,
Delay,
Streaming media,
Upper bound"
Ultrafast All-Optical Half Adder Using Quantum-Dot Semiconductor Optical Amplifier-Based Mach-Zehnder Interferometer,"Interferometric devices have drawn a great interest in all-optical signal processing for their high-speed photonic activity. Quantum-dot semiconductor optical amplifier (QD-SOA)-based gate has added a new momentum in this field to perform all-optical logic and algebraic operations. In this paper, a new and alternative scheme for all-optical half adder using two QD-SOA-based Mach-Zehnder interferometers is theoretically investigated and demonstrated. The proposed scheme is driven by the pair of input data streams for one switch between which the Boolean xor function is to be executed to produce sum-bit. Then the output of the first switch and one of the input data are utilized to drive the second switch to produce carry-bit. The impact of the peak data power as well as of the QD-SOAs current density, small signal gain, and QD-SOAs length on the ER and Q-factor of the switching outcome are explored and assessed by means of numerical simulation. The operation of the system is demonstrated with 160 Gbit/s.","Optical switches,
Adders,
Semiconductor optical amplifiers,
Current density,
Optical interferometry"
Efficient Parallel Framework for H.264/AVC Deblocking Filter on Many-Core Platform,"The H.264/AVC deblocking filter is becoming the performance bottleneck of H.264/AVC parallelization on many-core platform. Efficient parallelization of the deblocking filter on a many-core platform is challenging, because the deblocking filter has complicated data dependencies, which provide insufficient parallelism for so many cores. Furthermore, parallelization may have significant synchronization and load imbalance overhead. At present, research on the parallelizing deblocking filter on a many-core platform is rare and focuses on data-level parallelization. In this paper, we propose a three-step framework considering task-level segmentation and data-level parallelization to efficiently parallelize the deblocking filter. First, we review the entire deblocking filter process in 4 × 4 block edge-level and divide it into two parts: 1) boundary strength computation (BSC) and 2) edge discrimination and filtering (EDF), which increases the parallelism. Then, we apply the Markov empirical transition probability matrix and Huffman tree (METPMHT) to the BSC, which alleviate the load imbalance problem. Finally, we use an independent pixel connected area parallelization (IPCAP) for the EDF, which increases the parallelism and reduces the synchronization. In experiments, we apply our parallel method to the deblocking filter of the H.264/AVC reference software JM15.1 on the Tile64 platform without any Tile64 platform-based optimizations. Compared to the well-known 2D-wavefront method, the proposed method achieves on average 14.85, 17.83, and 10.60 times speed-up for QCIF, CIF, and HD videos using 62 cores, respectively.",
Coordinated primary frequency control among non-synchronous systems connected by a multi-terminal high-voltage direct current grid,"The authors consider a power system composed of several non-synchronous AC areas connected by a multi-terminal high-voltage direct current (HVDC) grid. In this context, the authors propose a distributed control scheme that modifies the power injections from the different AC areas into the DC grid so as to make the system collectively react to load imbalances. This collective reaction allows each individual AC area to downscale its primary reserves. The scheme is inspired by algorithms for the consensus problem extensively studied by the control theory community. It modifies the power injections based on frequency deviations of the AC areas so as to make them stay close to each other. A stability analysis of the closed-loop system is reported as well as simulation results on a benchmark power system with five AC areas. These results show that with proper tuning, the control scheme makes the frequency deviations converge rapidly to a common value following a load imbalance in an area.","power transmission control,
frequency control,
high-voltage engineering,
HVDC power transmission,
load regulation,
power grids"
A Reagent-Saving Mixing Algorithm for Preparing Multiple-Target Biochemical Samples Using Digital Microfluidics,"Recent advances in digital microfluidics have led to the promise of miniaturized laboratories, with the associated advantages of high sensitivity and less human-induced errors. Front-end operations such as sample preparation play a pivotal role in biochemical laboratories, and in applications in biomedical engineering and life science. For fast and high-throughput biochemical applications, preparing samples of multiple target concentrations sequentially is inefficient and time-consuming. Therefore, it is critical to concurrently prepare samples of multiple target concentrations. In addition, since reagents used in biochemical reactions are expensive, reagent-saving has become an important consideration in sample preparation. Prior work in this area does not address the problem of reagent-saving and concurrent sample preparation for multiple target concentrations. In this paper, we propose the first reagent-saving mixing algorithm for biochemical samples of multiple target concentrations. The proposed algorithm not only minimizes the consumption of reagents, but it also reduces the number of waste droplets and the sample preparation time by preparing the target concentrations concurrently. The proposed algorithm is evaluated on both real biochemical experiments and synthetic test cases to demonstrate its effectiveness and efficiency. Compared to prior work, the proposed algorithm can achieve up to 41% reduction in the number of reagent droplets and waste droplets, and up to 50% reduction in sample preparation time.",
Near-Affine-Invariant Texture Learning for Lung Tissue Analysis Using Isotropic Wavelet Frames,"We propose near-affine-invariant texture descriptors derived from isotropic wavelet frames for the characterization of lung tissue patterns in high-resolution computed tomography (HRCT) imaging. Affine invariance is desirable to enable learning of nondeterministic textures without a priori localizations, orientations, or sizes. When combined with complementary gray-level histograms, the proposed method allows a global classification accuracy of 76.9% with balanced precision among five classes of lung tissue using a leave-one-patient-out cross validation, in accordance with clinical practice.","Lungs,
Wavelet transforms,
Wavelet analysis,
Imaging,
Diseases,
Histograms"
A Tight Linear Time (1/2)-Approximation for Unconstrained Submodular Maximization,"We consider the Unconstrained Submodular Maximization problem in which we are given a non-negative submodular function f : 2N → ℝ+, and the objective is to find a subset S ⊆ N maximizing f(S). This is one of the most basic submodular optimization problems, having a wide range of applications. Some well known problems captured by Unconstrained Submodular Maximization include MaxCut, Max-DiCut, and variants of Max-SAT and maximum facility location. We present a simple randomized linear time algorithm achieving a tight approximation guarantee of 1/2, thus matching the known hardness result of Feige et al. [11]. Our algorithm is based on an adaptation of the greedy approach which exploits certain symmetry properties of the problem. Our method might seem counterintuitive, since it is known that the greedy algorithm fails to achieve any bounded approximation factor for the problem.","Approximation algorithms,
Approximation methods,
Optimized production technology,
Algorithm design and analysis,
Greedy algorithms,
Linear programming,
Computer science"
TAIEX Forecasting Using Fuzzy Time Series and Automatically Generated Weights of Multiple Factors,"In this paper, we present a new method to forecast the Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX) using fuzzy time series and automatically generated weights of multiple factors. The proposed method uses the variation magnitudes of adjacent historical data to generate fuzzy variation groups of the main factor (i.e., the TAIEX) and the elementary secondary factors (i.e., the Dow Jones, the NASDAQ and the M1B), respectively. Based on the variation magnitudes of the main factor TAIEX and the elementary secondary factors of a particular trading day, it constructs the occurrence vector of the main factor and the occurrence vectors of the elementary secondary factors on the trading day, respectively. By calculating the correlation coefficients between the numerical data series of the main factor and the numerical data series of each elementary secondary factor, respectively, it calculates the relevance degree between the forecasted variation of the main factor and the forecasted variation of each elementary secondary factor. Based on the correlation coefficients between the numerical data series of the main factor and the numerical data series of each elementary secondary factor on a trading day, it automatically generates the weights of the occurrence vector of the main factor and the occurrence vector of each elementary secondary factor on the trading day, respectively. Then, it calculates the forecasted variation of the main factor and the forecasted variation of each elementary secondary factor on the trading day, respectively, to obtain the final forecasted variation on the trading day. Finally, based on the closing index of the TAIEX on the trading day and the final forecasted variation on the trading day, it generates the forecasted value of the next trading day. The experimental results show that the proposed method outperforms the existing methods.","Time series analysis,
Forecasting,
Fuzzy logic,
Predictive models,
Training data,
Indexes"
Can facial cosmetics affect the matching accuracy of face recognition systems?,"The matching performance of automated face recognition has significantly improved over the past decade. At the same time several challenges remain that significantly affect the deployment of such systems in security applications. In this work, we study the impact of a commonly used face altering technique that has received limited attention in the biometric literature, viz., non-permanent facial makeup. Towards understanding its impact, we first assemble two databases containing face images of subjects, before and after applying makeup. We present experimental results on both databases that reveal the effect of makeup on automated face recognition and suggest that this simple alteration can indeed compromise the accuracy of a biometric system. While these are early results, our findings clearly indicate the need for a better understanding of this face altering scheme and the importance of designing algorithms that can successfully overcome the obstacle imposed by the application of facial makeup.","Databases,
Face,
Face recognition,
Feature extraction,
Accuracy,
Lighting,
Kernel"
Evaluation of SiC MOSFETs for a high efficiency three-phase buck rectifier,"This paper presents the characteristics of a 1200 V, 33 A SiC MOSFET and a 1200 V, 60 A SiC schottky barrier diode (SBD). The switching characteristics of the devices are tested by a double pulse test (DPT) based on a current-source structure at voltage levels up to 680 V and current up to 20 A. In addition, based on these devices, a 7.5 kW, three-phase buck rectifier for a 400 Vdc architecture data center power supply is designed. The total loss of this rectifier is calculated full load. The results show that the SiC based buck rectifier can obtain low power loss and smaller weight and volume than a Si based rectifier.","Rectifiers,
Silicon carbide,
MOSFETs,
MOSFET circuits,
Inductors,
Switches,
Switching loss"
Towards a Better Understanding of Large-Scale Network Models,"Connectivity and capacity are two fundamental properties of wireless multihop networks. The scalability of these properties has been a primary concern for which asymptotic analysis is a useful tool. Three related but logically distinct network models are often considered in asymptotic analyses, viz. the dense network model, the extended network model, and the infinite network model, which consider respectively a network deployed in a fixed finite area with a sufficiently large node density, a network deployed in a sufficiently large area with a fixed node density, and a network deployed in with a sufficiently large node density. The infinite network model originated from continuum percolation theory and asymptotic results obtained from the infinite network model have often been applied to the dense and extended networks. In this paper, through two case studies related to network connectivity on the expected number of isolated nodes and on the vanishing of components of finite order respectively, we demonstrate some subtle but important differences between the infinite network model and the dense and extended network models. Therefore, extra scrutiny has to be used in order for the results obtained from the infinite network model to be applicable to the dense and extended network models. Asymptotic results are also obtained on the expected number of isolated nodes, the vanishingly small impact of the boundary effect on the number of isolated nodes, and the vanishing of components of finite order in the dense and extended network models using a generic random connection model.","Analytical models,
Euclidean distance,
Australia,
Signal to noise ratio,
Interference,
Integral equations,
Spread spectrum communication"
Evaluating mobility models for temporal prediction with high-granularity mobility data,"A mobility model is an essential requirement in accurately predicting an individual's future location. While extensive studies have been conducted to predict human mobility, previous work used coarse-grained mobility data with limited ability to capture human movements at a fine-grained level. In this paper, we empirically analyze several mobility models for predicting temporal behavior of an individual user. Unlike previous approaches, which employed coarse-grained mobility data with partial temporal-coverage, we use fine-grained and continuous mobility data for the evaluation of mobility models.We explore the regularity and predictability of human mobility, and evaluate location-dependent and location-independent models with several feature-aided schemes. Our experimental results show that a location-dependent predictor is better than a location-independent predictor for predicting temporal behavior of individual user. The duration of stay at a location is strongly correlated to the arrival time at the current location and the return-tendency to the next location, rather than recent k location sequences.We also find that false-positive predictions can be reduced by adaptive use of mobility models.",
A 2-DOF Electrostatically Actuated MEMS Nanopositioner for On-Chip AFM,"A new 2-DOF microelectromechanical systems (MEMS)-based parallel kinematic nanopositioner with electrostatic actuation is presented. The device has been designed, fabricated, and implemented using the silicon-on-insulator-based MEMSCAP SOIMUMPs process. Experimental characterization shows that in-plane displacements in excess of 15 μm are achievable and that the first resonant mode along each axis is located at approximately 820 Hz. The nanopositioner's use in a practical application is demonstrated, with the device being used as the scanning stage during an atomic force microscope scan.","Nanopositioning,
Atomic force microscopy,
Force,
Springs,
Scanning electron microscopy,
Actuators"
Trajectories and keyframes for kinesthetic teaching: A human-robot interaction perspective,"Kinesthetic teaching is an approach to providing demonstrations to a robot in Learning from Demonstration whereby a human physically guides a robot to perform a skill. In the common usage of kinesthetic teaching, the robot's trajectory during a demonstration is recorded from start to end. In this paper we consider an alternative, keyframe demonstrations, in which the human provides a sparse set of consecutive keyframes that can be connected to perform the skill. We present a user-study (n = 34) comparing the two approaches and highlighting their complementary nature. The study also tests and shows the potential benefits of iterative and adaptive versions of keyframe demonstrations. Finally, we introduce a hybrid method that combines trajectories and keyframes in a single demonstration.","Robots,
Trajectory,
Education,
Joints,
Speech,
USA Councils,
Humans"
Spatial Composition Grading of Binary Metal Alloy Gate Electrode for Short-Channel SOI/SON MOSFET Application,"An overall performance comparison analysis based on 2-D Poisson's equation solution has been presented here both for silicon-on-insulator (SOI) and silicon-on-nothing (SON) MOSFET structures. In this paper, for the first time, an idea of work function engineering with continuous horizontal mole fraction variation in a binary alloy gate has been proposed and implemented analytically to reduce rolloff in threshold voltage for SON MOSFET, thereby improving its performance over single-gate SON structures. Analytical model-based simulation verified that SON is superior over SOI MOSFET due to its higher immunity to different short-channel effects and increased current driving capability. Our results are found to be in good agreement with simulation results, thereby verifying the accuracy of the proposed analytical model.","Silicon,
Poisson equations,
Logic gates,
Electric potential,
MOSFET circuits,
Threshold voltage,
Electrodes"
An empirical study on influence of approximation approaches on enhancing fireworks algorithm,"This paper presents an empirical study on the influence of approximation approaches on accelerating the fireworks algorithm search by elite strategy. In this study, we use three sampling data methods to approximate fitness landscape, i.e. the best fitness sampling method, the sampling distance near the best fitness individual sampling method and the random sampling method. For each approximation methods, we conduct a series of combinative evaluations with the different sampling method and sampling number for accelerating fireworks algorithm. The experimental evaluations on benchmark functions show that this elite strategy can enhance the fireworks algorithm search capability effectively. We also analyze and discuss the related issues on the influence of approximation model, sampling method, and sampling number on the fireworks algorithm acceleration performance.","Approximation algorithms,
Sampling methods,
Acceleration,
Sparks,
Least squares approximation,
Benchmark testing"
Continuous Recognition of Player's Affective Body Expression as Dynamic Quality of Aesthetic Experience,"The emergence of full-body computer games raises an interesting question: Can body movement be used to measure the aesthetic experience of players? In this paper, we aim to take a first step toward answering this question. Such a question emerges from the fact that various studies have shown the dual role of body movement, i.e., a window on people's emotional and mental states as well as a means to affect people's cognitive and affective processes. In this paper, first, we investigate the possibility of automatically recognizing the emotional expressions conveyed by the player's body movement in a Nintendo sport game. Our results showed that our automatic recognition system achieved recognition rates comparable to human observers' benchmarks. Second, by taking a pragmatist definition of aesthetic experience into account, we argue that the tracked body expressions do not only express what the player may be feeling. Given their modulating role on cognition and affect, these body expressions also let the player actively construct and assign affective meanings to the unfolding of the game. We argue that the player's variety of emotional bodily expressions constitutes the emotional rhythmic dynamic of aesthetic experience and, as such, they provide a measure of its distinctive quality.","Games,
Human computer interaction,
Emotion recognition,
Humans,
Observers,
Cognition,
Context"
Design and Implementation of a Pipelined Datapath for High-Speed Face Detection Using FPGA,"This paper presents design and implementation of a pipelined datapath for real-time face detection using cascades of boosted classifiers. We propose following methods: symmetric image downscaling, classifier sharing, and cascade merging, to achieve the desired processing speed and area efficiency. First, an image pyramid with 16 levels is generated from the input image to simultaneously detect faces with different scales. The downscaled images are then transferred to the first stage of the cascade that is shared between the corresponding image pairs based on the pixel validity of the symmetric image pyramid. The last method exploits the different hit ratios of the cascade stages. We use a tree-structured cascade of classifiers since most of the nonface elements are eliminated during the early stages of the classifier. The use of a synthesis tool confirms that the proposed design reduces resource utilization by one-eighth without accuracy loss, compared to the fully parallelized implementation of the same algorithm. We implemented the proposed hardware architecture on a Xilinx Virtex-5 LX330 FPGA. The indicative throughput is 307 frames/s irrespective of the number of faces in the scene for standard VGA (640 × 480) images with an operating frequency of 125.59 MHz. We may ensure that face detection results are generated at each clock cycle after the initial pipeline delay, using this fully pipelined datapath for tree-structured cascade classifiers.",
Simulating and Evaluating the Local Behavior of Small Pedestrian Groups,"Recent advancements in local methods have significantly improved the collision avoidance behavior of virtual characters. However, existing methods fail to take into account that in real life pedestrians tend to walk in small groups, consisting mainly of pairs or triples of individuals. We present a novel approach to simulate the walking behavior of such small groups. Our model describes how group members interact with each other, with other groups and individuals. We highlight the potential of our method through a wide range of test-case scenarios. We evaluate the results from our simulations using a number of quantitative quality metrics, and also provide visual and numerical comparisons with video footages of real crowds.",
Acoustic Source Localization and Tracking of a Time-Varying Number of Speakers,"Particle filter-based acoustic source tracking algorithms track (online and in real-time) the position of a sound source-a person speaking in a room-based on the current data from a distributed microphone array as well as the previously recorded data. This paper develops a multi-target tracking (MTT) methodology to allow for an unknown and time-varying number of speakers in a fully probabilistic manner and in doing so does not resort to independent modules for new target proposal or target number estimation as in previous works. The approach uses the concept of an existence grid to propose possible regions of activity before tracking is carried out with a variable dimension particle filter-which also explicitly supports the concept of a null particle, containing no target states, when no speakers are active. Examples demonstrate typical tracking performance in a number of different scenarios with simultaneously active speech sources.","Target tracking,
Speech,
Proposals,
Microphones,
Acoustics,
Monte Carlo methods,
Vectors"
oPass: A User Authentication Protocol Resistant to Password Stealing and Password Reuse Attacks,"Text password is the most popular form of user authentication on websites due to its convenience and simplicity. However, users' passwords are prone to be stolen and compromised under different threats and vulnerabilities. Firstly, users often select weak passwords and reuse the same passwords across different websites. Routinely reusing passwords causes a domino effect; when an adversary compromises one password, she will exploit it to gain access to more websites. Second, typing passwords into untrusted computers suffers password thief threat. An adversary can launch several password stealing attacks to snatch passwords, such as phishing, keyloggers and malware. In this paper, we design a user authentication protocol named oPass which leverages a user's cellphone and short message service to thwart password stealing and password reuse attacks. oPass only requires each participating website possesses a unique phone number, and involves a telecommunication service provider in registration and recovery phases. Through oPass, users only need to remember a long-term password for login on all websites. After evaluating the oPass prototype, we believe oPass is efficient and affordable compared with the conventional web authentication mechanisms.","Authentication,
Protocols,
Computers,
Human factors,
Telecommunications,
Servers"
Relaxation in X-Space Magnetic Particle Imaging,"Magnetic particle imaging (MPI) is a new imaging modality that noninvasively images the spatial distribution of superparamagnetic iron oxide nanoparticles (SPIOs). MPI has demonstrated high contrast and zero attenuation with depth, and MPI promises superior safety compared to current angiography methods, X-ray, computed tomography, and magnetic resonance imaging angiography. Nanoparticle relaxation can delay the SPIO magnetization, and in this work we investigate the open problem of the role relaxation plays in MPI scanning and its effect on the image. We begin by amending the X-space theory of MPI to include nanoparticle relaxation effects. We then validate the amended theory with experiments from a Berkeley x-space relaxometer and a Berkeley x-space projection MPI scanner. Our theory and experimental data indicate that relaxation reduces SNR and asymmetrically blurs the image in the scanning direction. While relaxation effects can have deleterious effects on the MPI scan, we show theoretically and experimentally that x-space reconstruction remains robust in the presence of relaxation. Furthermore, the role of relaxation in x-space theory provides guidance as we develop methods to minimize relaxation-induced blurring. This will be an important future area of research for the MPI community.","Magnetization,
Coils,
Mathematical model,
Image reconstruction,
Equations,
Convolution,
Magnetic resonance imaging"
Oscillations of Heart Rate and Respiration Synchronize During Affective Visual Stimulation,"The objective of this study is to investigate the synchronization between breathing patterns and heart rate during emotional visual elicitation, that is, using sets of images gathered from the international affective picture system having five levels of arousal and five levels of valence, including a neutral reference level. Thirty-five healthy volunteers were emotionally elicited in agreement with a bidimensional spatial localization of affective states, i.e., arousal/valence plane, while two peripheral physiological signals, ECG and Respiration activity, were acquired simultaneously. The synchronization was then quantified by applying the concept of phase synchronization of chaotic oscillators, i.e., the cardio-respiratory synchrogram. This technique allowed us to estimate the synchronization ratio m:n as the attendance of n heartbeats in each m respiratory cycle, even for noisy and nonstationary data. We found a stronger evidence of cardiorespiratory synchronization during arousal than during neutral states.","Synchronization,
Heart rate variability,
Electrocardiography,
Resonant frequency,
Heart beat,
Feature extraction"
On Minimizing the Impact of Mobility on Topology Control in Mobile Ad Hoc Networks,"Although topology control has received much attention in stationary sensor networks by effectively minimizing energy consumption, reducing interference, and shortening end-to-end delay, the transience of mobile nodes in Mobile Ad hoc Networks (MANETs) renders topology control a great challenge. To circumvent the transitory nature of mobile nodes, k-edge connected topology control algorithms have been proposed to construct robust topologies for mobile networks. However, uniformly using the value of k for localized topology control algorithms in any local graph is not effective because nodes move at different speeds. Moreover, the existing k-edge connected topology control algorithms need to determine the value of k a priori, but moving speeds of nodes are unpredictable, and therefore, these algorithms are not practical in MANETs. A dynamic method is proposed in this paper to effectively employ k-edge connected topology control algorithms in MANETs. The proposed method automatically determines the appropriate value of k for each local graph based on local information while ensuring the required connectivity ratio of the whole network. The results show that the dynamic method can enhance the practicality and scalability of existing k-edge connected topology control algorithms while guaranteeing the network connectivity.","Topology,
Network topology,
Mobile computing,
Heuristic algorithms,
Probability,
Mobile ad hoc networks"
Nanoscale Communication With Molecular Arrays in Nanonetworks,"Molecular communication is a promising nanoscale communication paradigm that enables nanomachines to exchange information by using molecules as communication carrier. Up to now, the molecular communication channel between a transmitter nanomachine (TN) and a receiver nanomachine (RN) has been modeled as either concentration channel or timing channel. However, these channel models necessitate exact time synchronization of the nanomachines and provide a relatively low communication bandwidth. In this paper, the Molecular ARray-based COmmunication (MARCO) scheme is proposed, in which the transmission order of different molecules is used to convey molecular information without any need for time synchronization. The MARCO channel model is first theoretically derived, and the intersymbol interference and error probabilities are obtained. Based on the error probability, achievable communication rates are analytically obtained. Numerical results and performance comparisons reveal that MARCO provides significantly higher communication rate, i.e., on the scale of 100 Kbps, than the previously proposed molecular communication models without any need for synchronization. More specifically, MARCO can provide more than 250 Kbps of molecular communication rate if intersymbol time and internode distance are set to 2 μs and 2 nm, respectively.","Molecular communication,
Nanobioscience,
Synchronization,
Channel models,
Error probability,
Microorganisms"
Paper-Based Inkjet-Printed Tri-Band U-Slot Monopole Antenna for Wireless Applications,"Realization of a U-slot tri-band monopole antenna on a low-cost paper substrate using inkjet-printed technology is presented for the first time. The U-shaped slot is optimized to enhance the bandwidth and to achieve tri-band operation of 1.57, 3.2, and 5 GHz with measured impedance bandwidths of 3.21%, 28.1%, and 36%, respectively. The antenna is fabricated through a metallic nanoparticle ink on a standard commercial paper. Thus, the antenna can be used to cover the GPS, WiMAX, HiperLAN/2, and WLAN. The antenna has a compact size of 12 × 37.3 × 0.44 mm3, leaving enough space for the driving electronics on the paper substrate. The impedance bandwidth, current distributions, radiation patterns, gain, and efficiency of the antenna have been studied through computer simulations and measurements.","Antennas,
Antenna measurements,
Substrates,
Printing,
Bandwidth,
Frequency measurement"
Inferring method specifications from natural language API descriptions,"Application Programming Interface (API) documents are a typical way of describing legal usage of reusable software libraries, thus facilitating software reuse. However, even with such documents, developers often overlook some documents and build software systems that are inconsistent with the legal usage of those libraries. Existing software verification tools require formal specifications (such as code contracts), and therefore cannot directly verify the legal usage described in natural language text in API documents against code using that library. However, in practice, most libraries do not come with formal specifications, thus hindering tool-based verification. To address this issue, we propose a novel approach to infer formal specifications from natural language text of API documents. Our evaluation results show that our approach achieves an average of 92% precision and 93% recall in identifying sentences that describe code contracts from more than 2500 sentences of API documents. Furthermore, our results show that our approach has an average 83% accuracy in inferring specifications from over 1600 sentences describing code contracts.","Contracts,
Semantics,
Natural languages,
Libraries,
Law,
Accuracy"
Booster: Reactive core acceleration for mitigating the effects of process variation and application imbalance in low-voltage chips,"Lowering supply voltage is one of the most effective techniques for reducing microprocessor power consumption. Unfortunately, at low voltages, chips are very sensitive to process variation, which can lead to large differences in the maximum frequency achieved by individual cores. This paper presents Booster, a simple, low-overhead framework for dynamically rebalancing performance heterogeneity caused by process variation and application imbalance. The Booster CMP includes two power supply rails set at two very low but different voltages. Each core can be dynamically assigned to either of the two rails using a gating circuit. This allows cores to quickly switch between two different frequencies. An on-chip governor controls the timing of the switching and the time spent on each rail. The governor manages a “boost budget” that dictates how many cores can be sped up (depending on the power constraints) at any given time. We present two implementations of Booster: Booster VAR, which virtually eliminates the effects of core-to-core frequency variation in near-threshold CMPs, and Booster SYNC, which additionally reduces the effects of imbalance in multithreaded applications. Evaluation using PARSEC and SPLASH2 benchmarks running on a simulated 32-core system shows an average performance improvement of 11% for Booster VAR and 23% for Booster SYNC.","Rails,
Synchronization,
Instruction sets,
Switches,
Reactive power,
Voltage control,
Regulators"
Fighting the Curse of Dimensionality: Compressive Sensing in Exploration Seismology,"Many seismic exploration techniques rely on the collection of massive data volumes that are mined for information during processing. This approach has been extremely successful, but current efforts toward higher resolution images in increasingly complicated regions of Earth continue to reveal fundamental shortcomings in our typical workflows. The “curse” of dimensionality is the main roadblock and is exemplified by Nyquist's sampling criterion, which disproportionately strains current acquisition and processing systems as the size and desired resolution of our survey areas continues to increase.","Sparse matrices,
Pollution measurement,
Seismology,
Linear approximation,
Transforms,
Noise measurement,
Seismic measurements,
Geophysical measurements,
Geophysical signal processing"
Broadband Modulation Performance of 100-GHz EO Polymer MZMs,"We experimentally characterize the performance of 100-GHz electro-optical polymer Mach-Zehnder modulators in both dual-drive and single-drive versions using broadband modulation. For the dual-drive version, we measure bit-error rate (BER) at 80 Gbit/s for differential phase-shift keying (DPSK) and >; 90 Gbit/s for on-off keying (OOK). The eye diagrams of 100 Gbit/s OOK and S21 measurement of up to 110-GHz further indicate a response bandwidth of >;100 GHz. Tunable-chirp operation is also demonstrated by changing the phase and amplitude of each driving signal. For the single-drive version, a BER of 10-9 is achieved for both 100-Gbit/s OOK and DPSK signals without optical or electrical equalization. The single-drive version shows a 7-dB bandwidth of >; 110-GHz and a chirp factor of as low as -0.02.","Radiofrequency amplifiers,
Phase shift keying,
Chirp modulation,
Electrooptic modulators,
Polymers"
Robust Patchwork-Based Embedding and Decoding Scheme for Digital Audio Watermarking,"This paper presents a novel patchwork-based embedding and decoding scheme for digital audio watermarking. At the embedding stage, an audio segment is divided into two subsegments and the discrete cosine transform (DCT) coefficients of the subsegments are computed. The DCT coefficients related to a specified frequency region are then partitioned into a number of frame pairs. The DCT frame pairs suitable for watermark embedding are chosen by a selection criterion and watermarks are embedded into the selected DCT frame pairs by modifying their coefficients, controlled by a secret key. The modifications are conducted in such a way that the selection criterion used at the embedding stage can be applied at the decoding stage to identify the watermarked DCT frame pairs. At the decoding stage, the secret key is utilized to extract watermarks from the watermarked DCT frame pairs. Compared with existing patchwork watermarking methods, the proposed scheme does not require information of which frame pairs of the watermarked audio signal enclose watermarks and is more robust to conventional attacks.",
Correlation-Coefficient-Based Fast Template Matching Through Partial Elimination,"Partial computation elimination techniques are often used for fast template matching. At a particular search location, computations are prematurely terminated as soon as it is found that this location cannot compete with an already known best match location. Due to the nonmonotonic growth pattern of the correlation-based similarity measures, partial computation elimination techniques have been traditionally considered inapplicable to speed up these measures. In this paper, we show that partial elimination techniques may be applied to a correlation coefficient by using a monotonic formulation, and we propose basic-mode and extended-mode partial correlation elimination algorithms for fast template matching. The basic-mode algorithm is more efficient on small template sizes, whereas the extended mode is faster on medium and larger templates. We also propose a strategy to decide which algorithm to use for a given data set. To achieve a high speedup, elimination algorithms require an initial guess of the peak correlation value. We propose two initialization schemes including a coarse-to-fine scheme for larger templates and a two-stage technique for small- and medium-sized templates. Our proposed algorithms are exact, i.e., having exhaustive equivalent accuracy, and are compared with the existing fast techniques using real image data sets on a wide variety of template sizes. While the actual speedups are data dependent, in most cases, our proposed algorithms have been found to be significantly faster than the other algorithms.",
SDRP: A Secure and Distributed Reprogramming Protocol for Wireless Sensor Networks,"Wireless reprogramming for a wireless sensor network is the process of uploading new code or changing the functionality of existing code. For security reasons, every code update must be authenticated to prevent an adversary from installing malicious code in the network. All existing reprogramming protocols are based on the centralized approach in which only the base station has the authority to initiate reprogramming. However, it is desirable and sometimes necessary for multiple authorized network users to simultaneously and directly reprogram sensor nodes without involving the base station, which is referred to as distributed reprogramming. In this case, the network owner can also assign different reprogramming privileges to different users. Motivated by this consideration, we develop a secure and distributed reprogramming protocol named SDRP , which is the first work of its kind. The protocol uses identity-based cryptography to secure the reprogramming and to reduce the communication and storage requirements of each node. Moreover, our theoretical analysis demonstrates the security properties of our protocol. We also implement SDRP in a network of resource-limited sensor nodes to show its high efficiency in practice.","Wireless sensor networks,
Protocols,
Public key cryptography,
Base stations,
Authentication,
Mobile handsets,
Network security"
Adaptive Kriging controller design for hypersonic flight vehicle via back-stepping,"In this study, the adaptive Kriging controller is investigated for the longitudinal dynamics of a generic hypersonic flight vehicle. For the altitude subsystem, the dynamics are transformed into the strict-feedback form where the back-stepping scheme is used. The velocity subsystem is transformed into the output-feedback form. Considering the non-linearity of the dynamics, the nominal feedback is included in the controller while Kriging system is used to estimate the uncertainty, which is described as the realisations of Gaussian random functions. To eliminate the infinite increase of the data size, the recursive Kriging algorithm is adopted in this study. Under the proposed controller, the almost surely bounded stability analysis is presented. The simulation study compared with neural back-stepping control is presented to show the effectiveness of the proposed control approach.","uncertain systems,
adaptive control,
aircraft control,
attitude control,
feedback,
Gaussian processes,
neurocontrollers,
stability"
Depth map compression using multi-resolution graph-based transform for depth-image-based rendering,"Depth map compression is important for efficient network transmission of 3D visual data in texture-plus-depth format, where the observer can synthesize an image of a freely chosen viewpoint via depth-image-based rendering (DIBR) using received neighboring texture and depth maps as anchors. Unlike texture maps, depth maps exhibit unique characteristics like smooth interior surfaces and sharp edges that can be exploited for coding gain. In this paper, we propose a multi-resolution approach to depth map compression using previously proposed graph-based transform (GBT). The key idea is to treat smooth surfaces and sharp edges of large code blocks separately and encode them in different resolutions: encode edges in original high resolution (HR) to preserve sharpness, and encode smooth surfaces in low-pass-filtered and down-sampled low resolution (LR) to save coding bits. Because GBT does not filter across edges, it produces small or zero high-frequency components when coding smooth-surface depth maps and leads to a compact representation in the transform domain. By encoding down-sampled surface regions in LR GBT, we achieve representation compactness for a large block without the high computation complexity associated with an adaptive large-block GBT. At the decoder, encoded LR surfaces are up-sampled and interpolated while preserving encoded HR edges. Experimental results show that our proposed multi-resolution approach using GBT reduced bitrate by 68% compared to native H.264 intra with DCT encoding original HR depth maps, and by 55% compared to single-resolution GBT encoding small blocks.",
From GPGPU to Many-Core: Nvidia Fermi and Intel Many Integrated Core Architecture,"Comparing the architectures and performance levels of an Nvidia Fermi accelerator with an Intel MIC Architecture coprocessor demonstrates the benefit of the coprocessor for bringing highly parallel applications into, or even beyond, GPGPU performance regions.","Computer architecture,
Microwave integrated circuits,
Coprocessors,
Graphics processing unit,
Programming,
Performance evaluation,
Random access memory"
Neuromuscular Interfacing: Establishing an EMG-Driven Model for the Human Elbow Joint,"Assistive devices aim to mitigate the effects of physical disability by aiding users to move their limbs or by rehabilitating through therapy. These devices are commonly embodied by robotic or exoskeletal systems that are still in development and use the electromyographic (EMG) signal to determine user intent. Not much focus has been placed on developing a neuromuscular interface (NI) that solely relies on the EMG signal, and does not require modifications to the end user's state to enhance the signal (such as adding weights). This paper presents the development of a flexible, physiological model for the elbow joint that is leading toward the implementation of an NI, which predicts joint motion from EMG signals for both able-bodied and less-abled users. The approach uses musculotendon models to determine muscle contraction forces, a proposed musculoskeletal model to determine total joint torque, and a kinematic model to determine joint rotational kinematics. After a sensitivity analysis and tuning using genetic algorithms, subject trials yielded an average root-mean-square error of 6.53° and 22.4° for a single cycle and random cycles of movement of the elbow joint, respectively. This helps us to validate the elbow model and paves the way toward the development of an NI.",
Three-Dimensional nand Flash Architecture Design Based on Single-Crystalline STacked ARray,"Various critical issues related with 3-D stacked nand Flash memory are examined in this paper. Our single-crystalline STacked ARray (STAR) has many advantages such as better scalability, possibility of single-crystal channel, less sensitivity to 3-D interference, stable virtual source/drain characteristic, and more extendability over other stacked structures. With STAR, we proposed a unit 3-D structure, i.e., “building.” Then, using this new component, 3-D block and full chip architecture are successfully designed. For the first time, the structure and operation methods of the “full” array are considered. The fully designed 3-D nand Flash architecture will be the novel solution of reliable 3-D stacked nand Flash memory for terabit density.",
CitySee: Urban CO2 monitoring with sensors,"Motivated by the needs of precise carbon emission measurement and real-time surveillance for CO2 management in cities, we present CitySee, a real-time CO2-monitoring system using sensor networks for an urban area (around 100 square kilometers). In order to conduct environment monitoring in a real-time and long-term manner, CitySee has to address the following challenges, including sensor deployment, data collection, data processing, and network management. In this discussion, we mainly focus on the sensor deployment problem so that necessary requirements like connectivity, coverage, data representability are satisfied. We also briefly go through the solutions for the remaining challenges. In CitySee, the sensor deployment problem can be abstracted as a relay node placement problem under hole-constraint. By carefully taking all constraints and real deployment situations into account, we propose efficient and effective approaches and prove that our scheme uses additional relay nodes at most twice of the minimum. We evaluate the performance of our approach through extensive simulations resembling realistic deployment. The results show that our approach outperforms previous strategies. We successfully apply this design into CitySee, a large-scale wireless sensor network consisting of 1096 relay nodes and 100 sensor nodes in Wuxi City, China.",
Energy-Efficient Translucent Optical Transport Networks With Mixed Regenerator Placement,"Translucent networks utilize sparse placements of optical-electronic-optical (O/E/O) 3R (reamplification, reshaping, and retiming) regenerators to improve the cost effectiveness and energy efficiency of wavelength-routed optical transport networks. In this paper, we show that the energy cost of a translucent network can be further reduced by leveraging the energy efficiency of all-optical 2R (reamplification and reshaping) regenerators. We propose a translucent network infrastructure that uses all-optical 2R regenerators to partially replace O/E/O 3R regenerators and implements mixed regenerator placements (MRP). We first consider the problem of MRP along a single given path, and propose three path-based impairment-aware MRP algorithms, based on periodic placement, genetic algorithm (GA), and ant colony optimization (ACO). We then address the offline network planning problem and develop a heuristic algorithm. By incorporating with one of the proposed MRP algorithms, the heuristic can achieve joint optimization of MRP and routing and wavelength assignment for high energy efficiency. We design simulations to compare the performance of different offline network planning scenarios and to see which one can provide the best balance between quality of transmission and energy cost. Simulation results show that the algorithm achieves 58.91-73.62% saving on regeneration energy, compared to the traditional scheme without all-optical 2R regenerators. The results also indicate that the joint optimization using the MRP-GA obtains the best network planning in terms of energy efficiency. Finally, we address the problem of online provisioning, and propose several algorithms to serve dynamic lightpath requests in translucent networks with MRP, and implement them in simulations to compare their performance in terms of blocking probability. Simulation results indicate that the online provisioning algorithm that utilizes the combination of the MRP-GA and a multiple MRP scheme achieves the lowest blocking probability.",
Fast Bundle Algorithm for Multiple-Instance Learning,"We present a bundle algorithm for multiple-instance classification and ranking. These frameworks yield improved models on many problems possessing special structure. Multiple-instance loss functions are typically nonsmooth and nonconvex, and current algorithms convert these to smooth nonconvex optimization problems that are solved iteratively. Inspired by the latest linear-time subgradient-based methods for support vector machines, we optimize the objective directly using a nonconvex bundle method. Computational results show this method is linearly scalable, while not sacrificing generalization accuracy, permitting modeling on new and larger data sets in computational chemistry and other applications. This new implementation facilitates modeling with kernels.","Kernel,
Compounds,
Microwave integrated circuits,
Drugs,
Computational modeling,
Support vector machines,
Optimization"
Cooperative Defense Against Pollution Attacks in Network Coding Using SpaceMac,"Intra-session network coding is inherently vulnerable to pollution attacks. In this paper, first, we introduce a novel homomorphic MAC scheme called SpaceMac, which allows an intermediate node to verify whether received packets belong to a specific subspace, even if the subspace is expanding over time. Then, we use SpaceMac as a building block to design a cooperative scheme that provides complete defense against pollution attacks: (i) it can detect polluted packets early at intermediate nodes, and (ii) it can identify the exact location of all, even colluding, attackers, thus making it possible to eliminate them. Our scheme is cooperative: parents and children of any node cooperate to detect any corrupted packets sent by the node, and nodes in the network cooperate with a central controller to identify the exact location of all attackers. We implement SpaceMac in both C/C++ and Java as a library, which we make publicly available. Our evaluation on both a PC and an Android device shows that the SpaceMac algorithms can be computed quickly and efficiently and that our cooperative defense scheme has low computation overhead and significantly lower communication overhead than those of state-of-the-art schemes.",
Using Coding-Based Ensemble Learning to Improve Software Defect Prediction,"Using classification methods to predict software defect proneness with static code attributes has attracted a great deal of attention. The class-imbalance characteristic of software defect data makes the prediction much difficult; thus, a number of methods have been employed to address this problem. However, these conventional methods, such as sampling, cost-sensitive learning, Bagging, and Boosting, could suffer from the loss of important information, unexpected mistakes, and overfitting because they alter the original data distribution. This paper presents a novel method that first converts the imbalanced binary-class data into balanced multiclass data and then builds a defect predictor on the multiclass data with a specific coding scheme. A thorough experiment with four different types of classification algorithms, three data coding schemes, and six conventional imbalance data-handling methods was conducted over the 14 NASA datasets. The experimental results show that the proposed method with a one-against-one coding scheme is averagely superior to the conventional methods.","Software defects,
Prediction algorithms,
Boosting,
Encoding,
Software algorithms,
Classification,
Predictive models"
L2P2: Location-aware location privacy protection for location-based services,"Location privacy has been a serious concern for mobile users who use location-based services provided by the third-party provider via mobile networks. Recently, there have been tremendous efforts on developing new anonymity or obfuscation techniques to protect location privacy of mobile users. Though effective in certain scenarios, these existing techniques usually assume that a user has a constant privacy requirement along spatial and/or temporal dimensions, which may not be true in real-life scenarios. In this paper, we introduce a new location privacy problem: Location-aware Location Privacy Protection (L2P2) problem, where users can define dynamic and diverse privacy requirements for different locations. The goal of the L2P2 problem is to find the smallest cloaking area for each location request so that diverse privacy requirements over spatial and/or temporal dimensions are satisfied for each user. In this paper, we formalize two versions of the L2P2 problem, and propose several efficient heuristics to provide such location-aware location privacy protection for mobile users. Through multiple simulations on a large data set of trajectories for one thousand mobile users, we confirm the effectiveness and efficiency of the proposed L2P2 algorithms.","Privacy,
Mobile communication,
Servers,
Data privacy,
Measurement,
Entropy,
Educational institutions"
Towards Optimal Adaptive UFH-Based Anti-Jamming Wireless Communication,"Anti-jamming communication without pre-shared secrets has gained increasing research interest recently and is commonly tackled by utilizing the technique of uncoordinated frequency hopping (UFH). Existing researches, however, are almost all based on ad hoc designs of frequency hopping strategies, mainly due to lack of theoretical foundations for scheme performance evaluation. To fill this gap, in this paper we introduce the online optimization theory into our solution and, for the first time, make the thorough quantitative performance characterization possible for UFH-based anti-jamming communications. Specifically, we formulate the UFH-based anti-jamming communication as a non-stochastic multi-armed bandit (MAB) problem and propose an online learning-based UFH algorithm achieving asymptotic optimum. To reduce the time and space complexity, we further develop an enhanced algorithm exploiting the internal structure of strategy selection process. We analytically prove the optimality of the proposed algorithms under various message coding scenarios. An extensive simulation study is conducted to validate our theoretical analysis and show that the learning-based UFH algorithms are resilient against both oblivious and adaptive jamming attacks.","Jamming,
Receivers,
Encoding,
Algorithm design and analysis,
Spread spectrum communication,
Protocols,
Sensors"
A Physically Segmented Hidden Markov Model Approach for Continuous Tool Condition Monitoring: Diagnostics and Prognostics,"In this paper, a temporal probabilistic approach based on the hidden Markov model (HMM), named physically segmented HMM with continuous output, is introduced for continuous tool condition monitoring in machinery systems. The proposed approach has the advantage of providing an explicit relationship between the actual health states and the hidden state values. The provided relationship is further exploited for formulation and parameter estimation in the proposed approach. The introduced approach is tested for continuous tool wear prediction in a computer numerical control milling machine and compared with two well-established neural network (NN) approaches, namely, multilayer perceptron and Elman network. In the experimental study, the prediction results are provided and compared after adopting appropriate hyper-parameter values for all the approaches by cross-validation. Based on the experimental results, physically segmented HMM approach outperforms the NN approaches. Moreover, the prognosis ability of the proposed approach is studied.","Hidden Markov models,
Feature extraction,
Sensors,
Probability distribution,
Maximum likelihood estimation"
Intelligent Lighting Control for Vision-Based Robotic Manipulation,"The ability of a robot vision system to capture informative images is greatly affected by the condition of lighting in the scene. This paper reveals the importance of active lighting control for robotic manipulation and proposes novel strategies for good visual interpretation of objects in the workspace. Good illumination means that it helps to get images with large signal-to-noise ratio, wide range of linearity, high image contrast, and true color rendering of the object's natural properties. It should also avoid occurrences of highlight and extreme intensity unbalance. If only passive illumination is used, the robot often gets poor images where no appropriate algorithms can be used to extract useful information. A fuzzy controller is further developed to maintain the lighting level suitable for robotic manipulation and guidance in dynamic environments. As carried out in this paper, with both examples of numerical simulations and practical experiments, it promises satisfactory results with the proposed idea of active lighting control.","Lighting,
Robot sensing systems,
Light sources,
Cameras,
Lighting control,
Image color analysis"
Snakes With an Ellipse-Reproducing Property,"We present a new class of continuously defined parametric snakes using a special kind of exponential splines as basis functions. We have enforced our bases to have the shortest possible support subject to some design constraints to maximize efficiency. While the resulting snakes are versatile enough to provide a good approximation of any closed curve in the plane, their most important feature is the fact that they admit ellipses within their span. Thus, they can perfectly generate circular and elliptical shapes. These features are appropriate to delineate cross sections of cylindrical-like conduits and to outline bloblike objects. We address the implementation details and illustrate the capabilities of our snake with synthetic and real data.",
K-SVD dictionary-learning for the analysis sparse model,"The synthesis-based sparse representation model for signals has drawn a considerable interest in the past decade. Such a model assumes that the signal of interest can be decomposed as a linear combination of a few atoms from a given dictionary. In this paper we concentrate on an alternative, analysis-based model, where an Analysis Dictionary multiplies the signal, leading to a sparse out-come. Our goal is to learn the analysis dictionary from a set of signal examples, and the approach taken is parallel and similar to the one adopted by the K-SVD algorithm that serves the corresponding problem in the synthesis model. We present the development of the algorithm steps, which include two greedy tailored pursuit algorithms and a penalty function for the dictionary update stage. We demonstrate its effectiveness in several experiments, showing a successful and meaningful recovery of the analysis dictionary.","Dictionaries,
Algorithm design and analysis,
Analytical models,
Training,
Vectors,
Computational modeling,
Noise measurement"
Energy-efficient planning and management of cellular networks,"We study base stations energy-efficient management algorithms in a cellular access network taking into account different planning strategies. To provide energy savings, sleep modes are adopted at the Base Stations (BSs). We propose two switch-off strategies that are based either on the cell load or the BS coverage overlap. Our results show that energy savings between 10% and 30% can be achieved also for the deployment already planned to be energy-efficient, while even higher savings are achievable with the other deployments. Moreover, we find that both the proposed switch-off strategies obtain similar results, suggesting that the order at which the BSs are switched-off, and the set of BSs selected to be switched off, do not change significantly the average estimation of potential energy savings. Furthermore, on a realistic case study, comparisons are made between the results obtained by using deterministic channel estimation models and empirical formulations.",
Bridging the Semantic Gap via Functional Brain Imaging,"The multimedia content analysis community has made significant efforts to bridge the gaps between low-level features and high-level semantics perceived by humans. Recent advances in brain imaging and neuroscience in exploring the human brain's responses during multimedia comprehension demonstrated the possibility of leveraging cognitive neuroscience knowledge to bridge the semantic gaps. This paper presents our initial effort in this direction by using functional magnetic resonance imaging (fMRI). Specifically, task-based fMRI (T-fMRI) was performed to accurately localize the brain regions involved in video comprehension. Then, natural stimulus fMRI (N-fMRI) data were acquired when subjects watched the multimedia clips selected from the TRECVID datasets. The responses in the localized brain regions were measured and used to extract high-level features as the representation of the brain's comprehension of semantics in the videos. A novel computational framework was developed to learn the most relevant low-level feature sets that best correlate the fMRI-derived semantic features based on the training videos with fMRI scans, and then the learned model was applied to larger scale TRECVID video datasets without fMRI scans for category classification. Our experimental results demonstrate: 1) there are meaningful couplings between brain's fMRI-derived responses and video stimuli, suggesting the validity of linking semantics and low-level features via fMRI and 2) the computationally learned low-level features can significantly (p <; 0.01) improve video classification in comparison with original low-level features and extracted low-level features resulted from well-known feature projection algorithms.","Semantics,
Feature extraction,
Humans,
Streaming media,
Multimedia communication,
Brain modeling"
Quantitative analysis ageing status of natural ester-paper insulation and mineral oil-paper insulation by polarization/depolarization current,"Polarization and Depolarization Current (PDC) technique is an effective tool to assess the condition of oil-paper insulation system in power transformers. So far the PDC behaviors of mineral oil-paper insulation have been widely investigated. However, with the increasing number of transformer choosing natural ester as its insulation oil, it is important to investigate the PDC characteristics of natural ester-paper insulation to see whether the PDC technique can also be used to assess the condition of new insulation system using natural ester in transformers accurately. In this research, natural esterpaper insulation sample and mineral oil-paper insulation sample were subjected to thermally accelerated ageing experiment at 110°C for 120 days. The PDC characteristics of natural ester-paper insulation sample and mineral oil-paper insulation sample were compared over the ageing process. A new method for assessing the ageing condition of the oil-paper insulation in terms of the depolarization charge quantity was proposed. Results show that the polarization/depolarization current of natural ester-paper insulation sample is higher than that of mineral oil-paper insulation sample with the same ageing intervals. The depolarization charge quantity of both kinds of oil-paper insulation sample is very sensitive to their ageing conditions. There is an exponential relation between the stable depolarization charge quantity of both kinds of oil-paper insulation sample and the degree of polymerization (DP) of paper. The depolarization charge quantity can be used to predict the ageing condition of oil-paper insulation providing the measurement temperature is kept the same.",
Static Routing and Wavelength Assignment for Multicast Advance Reservation in All-Optical Wavelength-Routed WDM Networks,"In this paper, we investigate the static multicast advance reservation (MCAR) problem for all-optical wavelength-routed WDM networks. Under the advanced reservation traffic model, connection requests specify their start time to be some time in the future and also specify their holding times. We investigate the static MCAR problem where the set of advance reservation requests is known ahead of time. We prove the MCAR problem is NP-complete, formulate the problem mathematically as an integer linear program (ILP), and develop three efficient heuristics, seqRWA, ISH, and SA, to solve the problem for practical size networks. We also introduce a theoretical lower bound on the number of wavelengths required. To evaluate our heuristics, we first compare their performances to the ILP for small networks, and then simulate them over real-world, large-scale networks. We find the SA heuristic provides close to optimal results compared to the ILP for our smaller networks, and up to a 33% improvement over seqRWA and up to a 22% improvement over ISH on realistic networks. SA provides, on average, solutions 1.5-1.8 times the cost given by our conservative lower bound on large networks.","Color,
WDM networks,
Routing,
Optical fiber networks,
Image color analysis,
Correlation,
Optical switches"
Optimal Beamformer Design for Dual-Hop MIMO AF Relay Networks over Rayleigh Fading Channels,"In this paper, a dual-hop multiple-input multiple-output (MIMO) amplify-and-forward (AF) relay network, where the source, relay and destination are each equipped with multiple antennas, is studied. By deriving and maximizing the receive signal-to-noise ratio (SNR) at the destination, we first obtain the optimal beamforming (BF) weights for the relay network. In order to evaluate the performance of the relay network, we then investigate the outage probability (OP), probability density function (PDF) and moments of the receive SNR as well as the ergodic capacity of the system in a closed-form. Furthermore, the average symbol error rate (ASER) expression of the relay network with the optimal transmit-receive BF is derived for three commonly used modulation formats, namely, M-ary pulse amplitude modulation (M-PAM), M-ary phase shift keying (M-PSK), and M-ary quadrature amplitude modulation (M-QAM). Finally, computer simulations are conducted to demonstrate the validity and efficacy of the designed MIMO relay network and its performance analysis.",
Performance Modeling and Analysis of Network Firewalls,"Network firewalls act as the first line of defense against unwanted and malicious traffic targeting Internet servers. Predicting the overall firewall performance is crucial to network security engineers and designers in assessing the effectiveness and resiliency of network firewalls against DDoS (Distributed Denial of Service) attacks as those commonly launched by today's Botnets. In this paper, we present an analytical queueing model based on the embedded Markov chain to study and analyze the performance of rule-based firewalls when subjected to normal traffic flows as well as DoS attack flows targeting different rule positions. We derive equations for key features and performance measures of engineering and design significance. These features and measures include throughput, packet loss, packet delay, and firewall's CPU utilization. In addition, we verify and validate our analytical model using simulation and real experimental measurements.",
On the Uplink MAC Performance of a Drive-Thru Internet,"As IEEE 802.11 access points (APs) open up services to mobile clients, opportunistic access to the roadside communication infrastructures from traveling vehicles has become more prominent and has drawn considerable attention. In particular, data uploading from traveling vehicles has a great potential for many vehicular ad hoc network applications, where both the intermittent connectivity and the time-varying vehicle arrivals have presented significant challenges to the current analytical models. Our focus is on the carrier sense multiple access with collision avoidance-based medium access control (MAC) layer performance in a last-hop drive-thru Internet, considering both the contention nature of the uplink and the realistic vehicle traffic model. Analytical and simulation results show the intrinsic relationships among the vehicle density and speed, the coverage of the AP, the achievable throughput, and the total amount of data uploaded by vehicles. We further investigate the efficacy of an admission control scheme by the AP for achieving an optimal operating region that has both a high throughput and a large amount of data uploaded from each drive-thru vehicle.","Vehicles,
IEEE 802.11 Standards,
Analytical models,
Throughput,
Internet,
Downlink,
Road transportation"
Buffer-Aware Network Coding for Wireless Networks,"Network coding, which can combine various traffic flows or packets via algebraic operations, has the potential of achieving substantial throughput and power efficiency gains in wireless networks. As such, it is considered as a powerful solution to meet the stringent demands and requirements of next-generation wireless systems. However, because of the random and asynchronous packet arrivals, network coding may result in severe delay and packet loss because packets need to wait to be network-coded with each others. To overcome this and guarantee quality of service (QoS), we present a novel cross-layer approach, which we shall refer to as Buffer-Aware Network Coding, or BANC, which allows transmission of some packets without network coding to reduce the packet delay. We shall derive the average delay and power consumption of BANC by presenting a random mapping description of BANC and Markov models of buffer states. A cross-layer optimization problem that minimizes the average delay under a given power constraint is then proposed and analyzed. Its solution will not only demonstrate the fundamental performance limits of BANC in terms of the achievable delay region and delay-power tradeoff, but also obtains the delay-optimal BANC schemes. Simulation results will show that the proposed approach can strike the optimal tradeoff between power efficiency and QoS.","Network coding,
Relays,
Delay,
Encoding,
Wireless networks,
Markov processes,
Quality of service"
A Methodology for Validating Artifact Removal Techniques for Physiological Signals,"Artifact removal from physiological signals is an essential component of the biosignal processing pipeline. The need for powerful and robust methods for this process has become particularly acute as healthcare technology deployment undergoes transition from the current hospital-centric setting toward a wearable and ubiquitous monitoring environment. Currently, determining the relative efficacy and performance of the multiple artifact removal techniques available on real world data can be problematic, due to incomplete information on the uncorrupted desired signal. The majority of techniques are presently evaluated using simulated data, and therefore, the quality of the conclusions is contingent on the fidelity of the model used. Consequently, in the biomedical signal processing community, there is considerable focus on the generation and validation of appropriate signal models for use in artifact suppression. Most approaches rely on mathematical models which capture suitable approximations to the signal dynamics or underlying physiology and, therefore, introduce some uncertainty to subsequent predictions of algorithm performance. This paper describes a more empirical approach to the modeling of the desired signal that we demonstrate for functional brain monitoring tasks which allows for the procurement of a “ground truth” signal which is highly correlated to a true desired signal that has been contaminated with artifacts. The availability of this “ground truth,” together with the corrupted signal, can then aid in determining the efficacy of selected artifact removal techniques. A number of commonly implemented artifact removal techniques were evaluated using the described methodology to validate the proposed novel test platform.","Electroencephalography,
Correlation,
Accelerometers,
Electrodes,
Detectors,
Signal to noise ratio,
Biomedical monitoring"
A Flexible Depth Probe Using Liquid Crystal Polymer,"We proposed a method of making a flexible depth-type neural probe using liquid crystal polymer. Conventional depth neural probes made of metal or silicon have the limitations of a single recording site per shank or the brittleness of the silicon substrate. To avoid these drawbacks, polymer-based depth neural probes have been developed with biocompatible polymers such as polyimides or parylenes. However, those have suffered from the difficulty of inserting the probes into brain tissues due to their high flexibility, requiring mechanical reinforcements. Herein, we report the first attempt to use a flexible material, liquid crystal polymer (LCP), as a substrate for a depth-type neural probe. The LCP-based probe offers a controllable stiffness vs. flexibility and compatibility with thin-film processes in addition to its inherent characteristics such as high reliability and biocompatibility. In the present study, an LCP neural probe was fabricated to have enough stiffness to penetrate the dura mater of rodent brains without a guide tool or additional reinforcement structures. A simultaneous multichannel neural recording was successfully achieved from the somatosensory motor cortex of the rodents. Immunohistochemistry showed that the electrodes could be inserted into the desired regions in the brain.",
A Capstone Course on Agile Software Development Using Scrum,"In this paper, an undergraduate capstone course in software engineering is described that not only exposes students to agile software development, but also makes it possible to observe the behavior of developers using Scrum for the first time. The course requires students to work as Scrum Teams, responsible for the implementation of a set of user stories defined by a project domain expert playing the role of the Product Owner. During the course, data on project management activities are collected in order to analyze the amount of work completed, compliance with the release and iteration plans, productivity, ability in effort estimation, and the like. The paper discusses the achievement of teaching goals and provides empirical evaluation of students' progress in estimation and planning skills. A summary of lessons learned and recommendations is given, reflecting the issues to be considered when teaching courses in agile software development. Surveys of students have shown that they were overwhelmingly positive about the course, indicating that the course fully met or even exceeded their expectations.",
A New Control Strategy of an Electric-Power-Assisted Steering System,"The control of electric-power-assisted steering (EPAS) systems is a challenging problem due to multiple objectives and the need for several pieces of information to implement the control. The control objectives are to generate assist torque with fast responses to driver's torque commands, ensure system stability, attenuate vibrations, transmit the road information to the driver, and improve the steering wheel returnability and free-control performance. The control must also be robust to modeling errors and parameter uncertainties. To achieve these objectives, a new control strategy is introduced in this paper. A reference model is used to generate an ideal motor angle that can guarantee the desired performance, and then, a sliding-mode control is used to track the desired motor angle. This reference model is built using a dynamic mechanical EPAS model, which is driven by the driver torque, the road reaction torque, and the desired assist torque. To implement the reference model with a minimum of sensors, a sliding-mode observer with unknown inputs and robust differentiators are employed to estimate the driver torque, the road reaction torque, and the system's states. With the proposed control strategy, there is no need for different algorithms, rules for switching between these algorithms, or fine-tuning of several parameters. In addition, our strategy improves system performance and robustness and reduces costs. The simulation results show that the proposed control structure can satisfy the desired performance.",
A scalable double in-memory checkpoint and restart scheme towards exascale,"As the size of supercomputers increases, the probability of system failure grows substantially, posing an increasingly significant challenge for scalability. It is important to provide resilience for long running applications. Checkpoint-based fault tolerance methods are effective approaches at dealing with faults. With these methods, the state of the entire parallel application is checkpointed to reliable storage. When a failure occurs, the application is restarted from a recent checkpoint. In previous work, we have demonstrated an efficient double in-memory checkpoint and restart fault tolerance scheme, which leverages Charm++'s parallel objects for checkpointing. In this paper, we further optimize the scheme by eliminating several bottlenecks caused by serialized communication. We extend the in-memory checkpointing scheme to work on MPI communication layer, and demonstrate the performance on very large scale supercomputers. For example, when running a one million atom molecular dynamics simulation on up to 64K cores of a BlueGene/P machine, the checkpoint time was in milliseconds. The restart time was measured to be less than 0.15 seconds on 64K cores.","Program processors,
Checkpointing,
Fault tolerance,
Fault tolerant systems,
Computer crashes,
Optimization,
Protocols"
Secure Incentives for Commercial Ad Dissemination in Vehicular Networks,"This paper introduces a promising application over vehicular ad hoc networks (VANETs), where advertisers use VANETs to disseminate their commercial ads via car-to-car communication, targeting a large number of potential customers inside cars. However, due to the noncooperative behavior of selfish or even malicious nodes in real-world scenarios, such a vehicular advertisement system cannot be realized unless proper incentives and security mechanisms are in place. This paper presents signature-seeking drive (SSD), which is a secure incentive framework that stimulates cooperative dissemination of advertising messages among vehicular users in a secure way. Unlike existing incentive systems, SSD does not rely on tamper-proof hardware or game-theoretic approaches but leverages a public key infrastructure to provide secure incentives for cooperative nodes. With a set of ad dissemination designs proposed, we demonstrate that our SSD is robust in both incentive and security perspectives.","Vehicles,
Advertising,
Companies,
Copper,
Public key,
Ad hoc networks"
Hierarchical Scale-Based Multiobject Recognition of 3-D Anatomical Structures,"Segmentation of anatomical structures from medical images is a challenging problem, which depends on the accurate recognition (localization) of anatomical structures prior to delineation. This study generalizes anatomy segmentation problem via attacking two major challenges: 1) automatically locating anatomical structures without doing search or optimization, and 2) automatically delineating the anatomical structures based on the located model assembly. For 1), we propose intensity weighted ball-scale object extraction concept to build a hierarchical transfer function from image space to object (shape) space such that anatomical structures in 3-D medical images can be recognized without the need to perform search or optimization. For 2), we integrate the graph-cut (GC) segmentation algorithm with prior shape model. This integrated segmentation framework is evaluated on clinical 3-D images consisting of a set of 20 abdominal CT scans. In addition, we use a set of 11 foot MR images to test the generalizability of our method to the different imaging modalities as well as robustness and accuracy of the proposed methodology. Since MR image intensities do not possess a tissue specific numeric meaning, we also explore the effects of intensity nonstandardness on anatomical object recognition. Experimental results indicate that: 1) effective recognition can make the delineation more accurate; 2) incorporating a large number of anatomical structures via a model assembly in the shape model improves the recognition and delineation accuracy dramatically; 3) ball-scale yields useful information about the relationship between the objects and the image; 4) intensity variation among scenes in an ensemble degrades object recognition performance.","Shape,
Training,
Image segmentation,
Anatomical structure,
Three dimensional displays,
Image recognition,
Estimation"
Spectrum clouds: A session based spectrum trading system for multi-hop cognitive radio networks,"Spectrum trading creates more accessing opportunities for secondary users (SUs) and economically benefits the primary users (PUs). However, it is challenging to implement spectrum trading in multi-hop cognitive radio networks (CRNs) due to harsh cognitive radio (CR) requirements on SUs' devices and complex conflict and competition relationship among different CR sessions. Unlike the per-user based spectrum trading designs in previous studies, in this paper, we propose a novel session based spectrum trading system, spectrum clouds, in multi-hop CRNs. In spectrum clouds, we introduce a new service provider, called secondary service provider (SSP), to harvest the available spectrum bands and facilitate the accessing of SUs without CR capability. The SSP also conducts spectrum trading among CR sessions w.r.t. their conflicts and competitions. Leveraging a 3-dimensional (3-D) conflict graph, we mathematically describe the conflicts and competitions among the candidate sessions for spectrum trading. Given the rate requirements and bidding values of candidate trading sessions, we formulate the optimal spectrum trading into the SSP's revenue maximization problem under multiple cross-layer constraints in multi-hop CRNs. In view of the NP-hardness of the problem, we have also developed heuristic algorithms to pursue feasible solutions. Through extensive simulations, we show that the solutions found by the proposed algorithms are close to the optimal one.",
FPGA Implementation of Abundance Estimation for Spectral Unmixing of Hyperspectral Data Using the Image Space Reconstruction Algorithm,"One of the most popular and widely used techniques for analyzing remotely sensed hyperspectral data is spectral unmixing, which relies on two stages: (i) identification of pure spectral signatures (endmembers) in the data, and (ii) estimation of the abundance of each endmember in each (possibly mixed) pixel. Due to the high dimensionality of the hyperspectral data, spectral unmixing is a very time-consuming task. With recent advances in reconfigurable computing, especially using field programmable gate arrays (FPGAs), hyperspectral image processing algorithms can now be accelerated for on-board exploitation using compact hardware components with small size and cost. Although in previous work several efforts have been directed towards FPGA implementation of endmember extraction algorithms, the abundance estimation step has received comparatively much less attention. In this work, we develop a parallel FPGA-based design of the image space reconstruction algorithm (ISRA), a technique for solving linear inverse problems with positive constraints that has been used to estimate the abundance of each endmember in each pixel of a hyperspectral image. It is an iterative algorithm that guarantees convergence (after a certain number of iterations) and positive values in the results of the abundances (an important consideration in unmixing applications). Our system includes a direct memory access (DMA) module and implements a pre-fetching technique to hide the latency of the input/output communications. The method has been implemented on a Virtex-4 XC4VFX60 FPGA (a model that is similar to radiation-hardened FPGAs certified for space operation) and tested using real hyperspectral data sets collected by the Airborne Visible Infra-Red Imaging Spectrometer (AVIRIS) over the Cuprite mining district in Nevada and the Jasper Ridge Biological Preserve in California. Experimental results demonstrate that our hardware version can significantly outperform an equivalent software version, thus being able to provide abundance estimation results in near real-time, which makes our reconfigurable system appealing for on-board hyperspectral data processing.","Hyperspectral imaging,
Field programmable gate arrays,
Estimation,
Hardware,
Vectors,
Computer architecture"
"Virtual Appliances, Cloud Computing, and Reproducible Research","As science becomes increasingly computational, reproducibility has become increasingly difficult, perhaps surprisingly. In many contexts, virtualization and cloud computing can mitigate the issues involved without significant overhead to the researcher, enabling the next generation of rigorous and reproducible computational science.","Virtual machining,
Cloud computing,
Research and development,
Reproducibility of results,
Context awareness,
Documentation,
Information retrieval,
Scientific computing"
The Tile Assembly Model is Intrinsically Universal,"We prove that the abstract Tile Assembly Model (aTAM) of nanoscale self-assembly is intrinsically universal. This means that there is a single tile assembly system U that, with proper initialization, simulates any tile assembly system T. The simulation is ""intrinsic"" in the sense that the self-assembly process carried out by U is exactly that carried out by T, with each tile of T represented by an m × m ""super tile"" of U. Our construction works for the full aTAM at any temperature, and it faithfully simulates the deterministic or nondeterministic behavior of each T. Our construction succeeds by solving an analog of the cell differentiation problem in developmental biology: Each super tile of U, starting with those in the seed assembly, carries the ""genome"" of the simulated system T. At each location of a potential super tile in the self-assembly of U, a decision is made whether and how to express this genome, i.e., whether to generate a super tile and, if so, which tile of T it will represent. This decision must be achieved using asynchronous communication under incomplete information, but it achieves the correct global outcome(s).","Tiles,
Assembly,
Self-assembly,
Assembly systems,
Genomics,
Bioinformatics,
Computational modeling"
RTMBA: A Real-Time Model-Based Reinforcement Learning Architecture for robot control,"Reinforcement Learning (RL) is a paradigm for learning decision-making tasks that could enable robots to learn and adapt to their situation on-line. For an RL algorithm to be practical for robotic control tasks, it must learn in very few samples, while continually taking actions in real-time. Existing model-based RL methods learn in relatively few samples, but typically take too much time between each action for practical on-line learning. In this paper, we present a novel parallel architecture for model-based RL that runs in real-time by 1) taking advantage of sample-based approximate planning methods and 2) parallelizing the acting, model learning, and planning processes in a novel way such that the acting process is sufficiently fast for typical robot control cycles. We demonstrate that algorithms using this architecture perform nearly as well as methods using the typical sequential architecture when both are given unlimited time, and greatly out-perform these methods on tasks that require real-time actions such as controlling an autonomous vehicle.","Planning,
Real time systems,
Computational modeling,
Robots,
Approximation algorithms,
Multicore processing"
iPad in Education: A Case Study of iPad Adoption and Use in a Primary School,"Apple's iPad has attracted a lot of attention since its release in 2010 and one area in which it has been adopted is the education sector. The iPad's large multi-touch screen, sleek profile and the ability to easily download and purchase a huge variety of educational applications make it attractive to educators. This paper presents a case study of the iPad's adoption in a primary school, one of the first in the world to adopt it. From interviews with teachers and IT staff, we conclude that the iPad's main strengths are the way in which it provides quick and easy access to information for students and the support it provides for collaboration. However, staff need to carefully manage both the teaching and the administrative environment in which the iPad is used, and we provide some lessons learned that can help other schools considering adopting the iPad in the classroom.","Educational institutions,
Mobile communication,
Mobile handsets,
Portable computers,
Keyboards,
Collaboration"
Redundancy Resolution of the Human Arm and an Upper Limb Exoskeleton,"The human arm has 7 degrees of freedom (DOF) while only 6 DOF are required to position the wrist and orient the palm. Thus, the inverse kinematics of an human arm has a nonunique solution. Resolving this redundancy becomes critical as the human interacts with a wearable robot and the inverse kinematics solution of these two coupled systems must be identical to guarantee an seamless integration. The redundancy of the arm can be formulated by defining the swivel angle, the rotation angle of the plane defined by the upper and lower arm around a virtual axis that connects the shoulder and wrist joints. Analyzing reaching tasks recorded with a motion capture system indicates that the swivel angle is selected such that when the elbow joint is flexed, the palm points to the head. Based on these experimental results, a new criterion is formed to resolve the human arm redundancy. This criterion was implemented into the control algorithm of an upper limb 7-DOF wearable robot. Experimental results indicate that by using the proposed redundancy resolution criterion, the error between the predicted and the actual swivel angle adopted by the motor control system is less then 5°.",
Fast-Decodable Asymmetric Space-Time Codes From Division Algebras,"Multiple-input double-output (MIDO) codes are important in the near-future wireless communications, where the portable end-user device is physically small and will typically contain at most two receive antennas. Especially tempting is the 4×2 channel due to its immediate applicability in the digital video broadcasting (DVB). Such channels optimally employ rate-two space-time (ST) codes consisting of (4×4) matrices. Unfortunately, such codes are in general very complex to decode, hence setting forth a call for constructions with reduced complexity. Recently, some reduced complexity constructions have been proposed, but they have mainly been based on different ad hoc methods and have resulted in isolated examples rather than in a more general class of codes. In this paper, it will be shown that a family of division algebra based MIDO codes will always result in at least 37.5% worst-case complexity reduction, while maintaining full diversity and, for the first time, the nonvanishing determinant (NVD) property. The reduction follows from the fact that, similarly to the Alamouti code, the codes will be subsets of matrix rings of the Hamiltonian quaternions, hence allowing simplified decoding. At the moment, such reductions are among the best known for rate-two MIDO codes [5], [6]. Several explicit constructions are presented and shown to have excellent performance through computer simulations.simulations.","Lattices,
Algebra,
Digital video broadcasting,
Space-time codes,
Maximum likelihood decoding,
Receiving antennas"
Efficient scene simulation for robust monte carlo localization using an RGB-D camera,"This paper presents Kinect Monte Carlo Localization (KMCL), a new method for localization in three dimensional indoor environments using RGB-D cameras, such as the Microsoft Kinect. The approach makes use of a low fidelity a priori 3-D model of the area of operation composed of large planar segments, such as walls and ceilings, which are assumed to remain static. Using this map as input, the KMCL algorithm employs feature-based visual odometry as the particle propagation mechanism and utilizes the 3-D map and the underlying sensor image formation model to efficiently simulate RGB-D camera views at the location of particle poses, using a graphical processing unit (GPU). The generated 3D views of the scene are then used to evaluate the likelihood of the particle poses. This GPU implementation provides a factor of ten speedup over a pure distance-based method, yet provides comparable accuracy. Experimental results are presented for five different configurations, including: (1) a robotic wheelchair, (2) a sensor mounted on a person, (3) an Ascending Technologies quadrotor, (4) a Willow Garage PR2, and (5) an RWI B21 wheeled mobile robot platform. The results demonstrate that the system can perform robust localization with 3D information for motions as fast as 1.5 meters per second. The approach is designed to be applicable not just for robotics but other applications such as wearable computing.",
Automated Brain Structure Segmentation Based on Atlas Registration and Appearance Models,"Accurate automated brain structure segmentation methods facilitate the analysis of large-scale neuroimaging studies. This work describes a novel method for brain structure segmentation in magnetic resonance images that combines information about a structure's location and appearance. The spatial model is implemented by registering multiple atlas images to the target image and creating a spatial probability map. The structure's appearance is modeled by a classifier based on Gaussian scale-space features. These components are combined with a regularization term in a Bayesian framework that is globally optimized using graph cuts. The incorporation of the appearance model enables the method to segment structures with complex intensity distributions and increases its robustness against errors in the spatial model. The method is tested in cross-validation experiments on two datasets acquired with different magnetic resonance sequences, in which the hippocampus and cerebellum were segmented by an expert. Furthermore, the method is compared to two other segmentation techniques that were applied to the same data. Results show that the atlas- and appearance-based method produces accurate results with mean Dice similarity indices of 0.95 for the cerebellum, and 0.87 for the hippocampus. This was comparable to or better than the other methods, whereas the proposed technique is more widely applicable and robust.",
Low-Temperature Organic (CYTOP) Passivation for Improvement of Electric Characteristics and Reliability in IGZO TFTs,"We proposed and fabricated amorphous indium- gallium-zinc-oxide thin-film transistors (TFTs) employing a novel organic-passivation layer (CYTOP) that results in low damage and good dielectric quality. The TFT with the CYTOP- passivation layer successfully exhibited a relatively good electrical characteristic (μsat = 12.3 cm2/V · s) compared with that (μsat = 5.8 cm2/V · s) of the TFT with a SiOx-passivation layer. The CYTOP-passivated device exhibited relatively good stability (ΔVTH : 2.8 V) under positive bias-temperature stress while the TFTs with the SiOx-passivation layer showed a 3.3-V ΔVTH shift, respectively. The CYTOP passivation was performed at low annealing temperature (180οC), and therefore, it is a good candidate for advanced flexible displays.",
Non-Cooperative Feedback-Rate Control Game for Channel State Information in Wireless Networks,"It has been well recognized that channel state information (CSI) feedback is of great importance for downlink transmissions of closed-loop wireless networks. However, the existing work typically researched the CSI feedback problem for each individual mobile station (MS), and thus, cannot efficiently model the interactions among self-interested mobile users in the network level. To this end, in this paper, we propose an alternative approach to investigate the CSI feedback-rate control problem in the analytical setting of a game theoretic framework, in which a multiple-antenna base station (BS) communicates with a number of co-channel MSs through linear precoder. Specifically, we first present a non-cooperative feedback-rate control game (NFC), in which each MS selects the feedback-rate to maximize its performance in a distributed way. To improve efficiency from a social optimum point of view, we then introduce pricing, called the non-cooperative feedback-rate control game with price (NFCP). The game utility is defined as the performance gain by CSI feedback minus the price as a linear function of the CSI feedback-rate. The existence of the Nash equilibrium of such games is investigated, and two types of feedback protocols (FDMA and CSMA) are studied. Simulation results show that by adjusting the pricing factor, the distributed NFCP game results in close optimal performance compared with that of the centralized scheme.",
Weighted adaptive Hough and ellipsopolar transforms for real-time iris segmentation,"Efficient and robust segmentation of less intrusively or non-cooperatively captured iris images is still a challenging task in iris biometrics. This paper proposes a novel two-stage algorithm for the localization and mapping of iris texture in images of the human eye into Daugman's doubly dimensionless polar coordinates. Motivated by the growing demand for real-time capable solutions, coarse center detection and fine boundary localization usually combined in traditional approaches are decoupled. Therefore, search space at each stage is reduced without having to stick to simpler models. Another motivation of this work is independence of sensors. A comparison of reference software on different datasets highlights the problem of database-specific optimizations in existing solutions. This paper instead proposes the application of Gaussian weighting functions to incorporate model-specific prior knowledge. An adaptive Hough transform is applied at multiple resolutions to estimate the approximate position of the iris center. Subsequent polar transform detects the first elliptic limbic or pupillary boundary, and an ellipsopolar transform finds the second boundary based on the outcome of the first. This way, both iris images with clear limbic (typical for visible-wavelength) and with clear pupillary boundaries (typical for near infrared) can be processed in a uniform manner.","Transforms,
Iris,
Iris recognition,
Image edge detection,
Image segmentation,
Shape,
Active shape model"
Quaternion-Based Kalman Filter With Vector Selection for Accurate Orientation Tracking,"Human body orientation estimation from microinertial/magnetic sensor units is highly important for synthetic environments, robotics, and other human-computer interaction applications. In practice, the main challenge is how to deal with linear acceleration interference and magnetic disturbance which always cause significant attitude-estimation errors. In this paper, we present a novel quaternion-based Kalman filter with vector selection scheme for accurate human body orientation estimation using an inertial/magnetic sensor unit. In the proposed algorithm, the gyroscope measurement is used as an input to construct the linear process equation, and the accelerometer and magnetometer measurements are manipulated to establish the linear pseudomeasurement equation. A linear Kalman filter is then deployed to estimate the body orientation. In the Kalman filter framework, a vector selection scheme is designed to protect the algorithm against undesirable conditions such as temporary intensive movement and magnetic disturbance and enable it to acquire more accurate orientation estimation. The experimental results have shown that the proposed algorithm can provide accurate attitude estimations with regard to the ground truth.",
Efficient Compression of QRS Complexes Using Hermite Expansion,"We propose a novel algorithm for the compression of ECG signals, in particular QRS complexes. The algorithm is based on the expansion of signals with compact support into a basis of discrete Hermite functions. These functions can be constructed by sampling continuous Hermite functions at specific sampling points. They form an orthogonal basis in the underlying signal space. The proposed algorithm relies on the theory of signal models based on orthogonal polynomials. We demonstrate that the constructed discrete Hermite functions have important ad- vantages compared to continuous Hermite functions, which have previously been suggested for the compression of QRS complexes. Our algorithm achieves higher compression ratios compared with previously reported algorithms based on continuous Hermite functions, discrete Fourier, cosine, or wavelet transforms.",
The Success Factors Powering Industry-Academia Collaboration,Collaboration between industry and academia supports improvement and innovation in industry and helps to ensure industrial relevance in academic research. This article presents an exploratory study of the factors for successful collaboration between industry and academia in software research.,"Computer science education,
Collaboration,
Business,
Technological innovation,
Research and development"
Virtual Multifunction Power Quality Analyzer Based on Adaptive Linear Neural Network,"Monitoring of electrical quantities is an important task for the evaluation of power quality (PQ). However, analysis methods for PQ disturbances are quite different. This circumstance would make the design of a multifunction PQ-measuring instrument difficult. In this paper, the design and implementation of a virtual multifunction PQ analyzer based on the adaptive linear neural network are discussed. The main advantages of the realized analyzer are the simplification and integration for the harmonic/interharmonic analyzer, flickermeter, and voltage event identifier by adopting the same computational mechanism. Finally, some tests are made to verify the performance of the proposed virtual multifunction analyzer.","Harmonic analysis,
Power system harmonics,
Voltage fluctuations,
Instruments,
Frequency estimation,
Voltage measurement"
Task-oriented design of concentric tube robots using mechanics-based models,"We introduce a method for task-oriented design of concentric tube robots, which are tentacle-like robots with the potential to enable new minimally invasive surgical procedures. Our objective is to create a robot design on a patient-specific and surgery-specific basis to enable the robot to reach multiple clinically relevant sites while avoiding anatomical obstacles. Our method uses a mechanically accurate model of concentric tube robot kinematics that considers a robot's time-varying shape throughout the performance of a task. Our method combines a search over a robot's design space with sampling-based motion planning over its configuration space to compute a design under which the robot can feasibly perform a specified task without damaging surrounding tissues. To accelerate the algorithm, we leverage design coherence, the observation that collision-free configuration spaces of robots of similar designs are similar. If a solution exists, our method is guaranteed, as time is allowed to increase, to find a design and corresponding feasible motion plan. We provide examples illustrating the importance of using mechanically accurate models during design and motion planning and demonstrating our method's effectiveness in a medically motivated simulated scenario involving navigation through the lung.",
A Comprehensive Cardiac Motion Estimation Framework Using Both Untagged and 3-D Tagged MR Images Based on Nonrigid Registration,"In this paper, we present a novel technique based on nonrigid image registration for myocardial motion estimation using both untagged and 3-D tagged MR images. The novel aspect of our technique is its simultaneous usage of complementary information from both untagged and 3-D tagged MR images. To estimate the motion within the myocardium, we register a sequence of tagged and untagged MR images during the cardiac cycle to a set of reference tagged and untagged MR images at end-diastole. The similarity measure is spatially weighted to maximize the utility of information from both images. In addition, the proposed approach integrates a valve plane tracker and adaptive incompressibility into the framework. We have evaluated the proposed approach on 12 subjects. Our results show a clear improvement in terms of accuracy compared to approaches that use either 3-D tagged or untagged MR image information alone. The relative error compared to manually tracked landmarks is less than 15% throughout the cardiac cycle. Finally, we demonstrate the automatic analysis of cardiac function from the myocardial deformation fields.","Three dimensional displays,
Tracking,
Myocardium,
Image resolution,
Image segmentation,
Image sequences,
Motion segmentation"
Robust Statistical Fusion of Image Labels,"Image labeling and parcellation (i.e., assigning structure to a collection of voxels) are critical tasks for the assessment of volumetric and morphometric features in medical imaging data. The process of image labeling is inherently error prone as images are corrupted by noise and artifacts. Even expert interpretations are subject to subjectivity and the precision of the individual raters. Hence, all labels must be considered imperfect with some degree of inherent variability. One may seek multiple independent assessments to both reduce this variability and quantify the degree of uncertainty. Existing techniques have exploited maximum a posteriori statistics to combine data from multiple raters and simultaneously estimate rater reliabilities. Although quite successful, wide-scale application has been hampered by unstable estimation with practical datasets, for example, with label sets with small or thin objects to be labeled or with partial or limited datasets. As well, these approaches have required each rater to generate a complete dataset, which is often impossible given both human foibles and the typical turnover rate of raters in a research or clinical environment. Herein, we propose a robust approach to improve estimation performance with small anatomical structures, allow for missing data, account for repeated label sets, and utilize training/catch trial data. With this approach, numerous raters can label small, overlapping portions of a large dataset, and rater heterogeneity can be robustly controlled while simultaneously estimating a single, reliable label set and characterizing uncertainty. The proposed approach enables many individuals to collaborate in the construction of large datasets for labeling tasks (e.g., human parallel processing) and reduces the otherwise detrimental impact of rater unavailability","Training data,
Reliability,
Estimation,
Labeling,
Testing,
Brain modeling,
Mathematical model"
An Enhanced Bag-of-Visual Word Vector Space Model to Represent Visual Content in Athletics Images,"Images that have a different visual appearance may be semantically related using a higher level conceptualization. However, image classification and retrieval systems tend to rely only on the low-level visual structure within images. This paper presents a framework to deal with this semantic gap limitation by exploiting the well-known bag-of-visual words (BVW) to represent visual content. The novelty of this paper is threefold. First, the quality of visual words is improved by constructing visual words from representative keypoints. Second, domain specific “non-informative visual words” are detected which are useless to represent the content of visual data but which can degrade the categorization capability. Distinct from existing frameworks, two main characteristics for non-informative visual words are defined: a high document frequency (DF) and a small statistical association with all the concepts in the collection. The third contribution in this paper is that a novel method is used to restructure the vector space model of visual words with respect to a structural ontology model in order to resolve visual synonym and polysemy problems. The experimental results show that our method can disambiguate visual word senses effectively and can significantly improve classification, interpretation, and retrieval performance for the athletics images.",
SAMI: Service-based arbitrated multi-tier infrastructure for Mobile Cloud Computing,"Mobile Cloud Computing (MCC) is the state-of-the-art mobile computing technology aims to alleviate resource poverty of mobile devices. Recently, several approaches and techniques have been proposed to augment mobile devices by leveraging cloud computing. However, long-WAN latency and trust are still two major issues in MCC that hinder its vision. In this paper, we analyze MCC and discuss its issues. We leverage Service Oriented Architecture (SOA) to propose an arbitrated multi-tier infrastructure model named SAMI for MCC. Our architecture consists of three major layers, namely SOA, arbitrator, and infrastructure. The main strength of this architecture is in its multi-tier infrastructure layer which leverages infrastructures from three main sources of Clouds, Mobile Network Operators (MNOs), and MNOs' authorized dealers. On top of the infrastructure layer, an arbitrator layer is designed to classify Services and allocate them the suitable resources based on several metrics such as resource requirement, latency and security. Utilizing SAMI facilitate development and deployment of service-based platform-neutral mobile applications.",
Measuring Distance From Single Spike Feedback Signals in Molecular Communication,"Systems of bionanomachines may benefit future applications which require interaction with biological systems at the nano- to microscale. Molecular communication is a suitable communication mechanism for autonomous bionanomachines which are limited in size and capability and for interfacing with biological systems. In molecular communication, a bionanomachine transmits information to a receiver bionanomachine by modulating the concentration of molecules in the environment. One promising direction for molecular communication is for a bionanomachine to measure the distance to another bionanomachine in order to perform location-based functionality or to adapt communications using the measured distance. In this paper, a bionanomachine measures the distance to another bionanomachine by requesting the other bionanomachine to transmit a feedback signal of many molecules transmitted over a short time interval (i.e., a single spike of molecules). Upon receiving the feedback signal, the bionanomachine which requested the feedback signal then estimates distance by measuring the Round Trip Time (RTT) or Signal Attenuation (SA) of the received feedback signal. The propagation of molecules and the receiving of molecules are modeled to investigate how distance impacts measured RTT and SA. Simulations are performed to measure the accuracy of the distance measurement, the time required to measure distance, and how the number of molecules transmitted affects accuracy.","Molecular communication,
Time measurement,
Protocols,
Receivers,
Distance measurement,
Nanobioscience,
Transceivers"
Graph-Constrained Group Testing,"Nonadaptive group testing involves grouping arbitrary subsets of n items into different pools. Each pool is then tested and defective items are identified. A fundamental question involves minimizing the number of pools required to identify at most d defective items. Motivated by applications in network tomography, sensor networks and infection propagation, a variation of group testing problems on graphs is formulated. Unlike conventional group testing problems, each group here must conform to the constraints imposed by a graph. For instance, items can be associated with vertices and each pool is any set of nodes that must be path connected. In this paper, a test is associated with a random walk. In this context, conventional group testing corresponds to the special case of a complete graph on n vertices. For interesting classes of graphs a rather surprising result is obtained, namely, that the number of tests required to identify d defective items is substantially similar to what is required in conventional group testing problems, where no such constraints on pooling is imposed. Specifically, if T(n) corresponds to the mixing time of the graph G, it is shown that with m = O(d2T2(n) log(n/d)) nonadaptive tests, one can identify the defective items. Consequently, for the Erdos-Rényi random graph G(n, p), as well as expander graphs with constant spectral gap, it follows that m = O(d2 log3 n) non-adaptive tests are sufficient to identify d defective items. Next, a specific scenario is considered that arises in network tomography, for which it is shown that m = O(d3 log3 n) nonadaptive tests are sufficient to identify d defective items. Noisy counterparts of the graph constrained group testing problem are considered, for which parallel results are developed. We also briefly discuss extensions to compressive sensing on graphs.","Testing,
Vectors,
Sparse matrices,
Wireless sensor networks,
Tomography,
Graph theory,
Routing"
Using random shape theory to model blockage in random cellular networks,"Shadow fading is severe in downtown areas where buildings are densely located. This paper proposes a stochastic model to quantify blockages due to shadowing, using methods from random shape theory. Buildings inside a cell are modeled as line segments with random sizes and orientations, with locations from a spatial Poisson point process. Dense urban areas can be modeled by the parameters of the line process. Based on this construction, the distribution of the power loss caused by shadowing in a particular path is expressed in closed form. The distribution can be used to compute several performance metrics of interest in random systems. Simulations illustrate coverage and connectivity as a function of the metrics of blockages, such as the density and the average size of buildings.",
Recovering traceability links between an API and its learning resources,"Large frameworks and libraries require extensive developer learning resources, such as documentation and mailing lists, to be useful. Maintaining these learning resources is challenging partly because they are not explicitly linked to the frameworks' API, and changes in the API are not reflected in the learning resources. Automatically recovering traceability links between an API and learning resources is notoriously difficult due to the inherent ambiguity of unstructured natural language. Code elements mentioned in documents are rarely fully qualified, so readers need to understand the context in which a code element is mentioned. We propose a technique that identifies code-like terms in documents and links these terms to specific code elements in an API, such as methods. In an evaluation study with four open source systems, we found that our technique had an average recall and precision of 96%.","Context,
Documentation,
Libraries,
Joining processes,
Java,
XML,
HTML"
High Range Resolution Ultrasonographic Vascular Imaging Using Frequency Domain Interferometry With the Capon Method,"For high range resolution ultrasonographic vascular imaging, we apply frequency domain interferometry with the Capon method to a single frame of in-phase and quadrature (IQ) data acquired using a commercial ultrasonographic device with a 7.5 MHz linear array probe. In order to tailor the adaptive beamforming algorithm for ultrasonography we employ four techniques: frequency averaging, whitening, radio-frequency data oversampling, and the moving average. The proposed method had a range resolution of 0.05 mm in an ideal condition, and experimentally detected the boundary couple 0.17 mm apart, where the boundary couple was indistinguishable from a single boundary utilizing a B-mode image. Further, this algorithm could depict a swine femoral artery with a range beam width of 0.054 mm and an estimation error for the vessel wall thickness of 0.009 mm, whereas using a conventional method the range beam width and estimation error were 0.182 and 0.021 mm, respectively. The proposed method requires 7.7 s on a mobile PC with a single CPU for a 1 × 3 cm region of interest. These findings indicate the potential of the proposed method for the improvement of range resolution in ultrasonography without deterioration in temporal resolution, resulting in enhanced detection of vessel stenosis.","Radio frequency,
Frequency domain analysis,
Imaging,
Arteries,
Ultrasonic imaging,
Signal resolution,
Image resolution"
Estimating probability of collision for safe motion planning under Gaussian motion and sensing uncertainty,"We present a fast, analytical method for estimating the probability of collision of a motion plan for a mobile robot operating under the assumptions of Gaussian motion and sensing uncertainty. Estimating the probability of collision is an integral step in many algorithms for motion planning under uncertainty and is crucial for characterizing the safety of motion plans. Our method is computationally fast, enabling its use in online motion planning, and provides conservative estimates to promote safety. To improve accuracy, we use a novel method to truncate estimated a priori state distributions to account for the fact that the probability of collision at each stage along a plan is conditioned on the previous stages being collision free. Our method can be directly applied within a variety of existing motion planners to improve their performance and the quality of computed plans. We apply our method to a car-like mobile robot with second order dynamics and to a steerable medical needle in 3D and demonstrate that our method for estimating the probability of collision is orders of magnitude faster than naïve Monte Carlo sampling methods and reduces estimation error by more than 25% compared to prior methods.",
Efficient Online Subspace Learning With an Indefinite Kernel for Visual Tracking and Recognition,"We propose an exact framework for online learning with a family of indefinite (not positive) kernels. As we study the case of nonpositive kernels, we first show how to extend kernel principal component analysis (KPCA) from a reproducing kernel Hilbert space to Krein space. We then formulate an incremental KPCA in Krein space that does not require the calculation of preimages and therefore is both efficient and exact. Our approach has been motivated by the application of visual tracking for which we wish to employ a robust gradient-based kernel. We use the proposed nonlinear appearance model learned online via KPCA in Krein space for visual tracking in many popular and difficult tracking scenarios. We also show applications of our kernel framework for the problem of face recognition.","Kernel,
Hilbert space,
Visualization,
Robustness,
Eigenvalues and eigenfunctions,
Principal component analysis,
Vectors"
"AMI threats, intrusion detection requirements and deployment recommendations","Advanced Metering Infrastructures (AMI) facilitate bidirectional communication between smart meters and utilities, allowing information about consumption, outages, and electricity rates to be shared reliably and efficiently. However, the numerous smart meters being connected through mesh networks open new opportunities for attackers to interfere with communications and compromise utilities' assets or steal customers' private information. The goal of this paper is to survey the various threats facing AMIs and the common attack techniques used to realize them in order to identify and understand the requirements for a comprehensive intrusion detection solution. The threat analysis leads to an extensive “attack tree” that captures the attackers' key objectives (e.g., energy theft) and the individual attack steps (e.g., eavesdropping on the network) that would be involved in achieving them. With reference to the attack tree, we show the type of information that would be required to effectively detect attacks. We also suggest that the widest coverage in monitoring the attacks can be provided by a hybrid sensing infrastructure that uses both a centralized intrusion detection system and embedded meter sensors.","Sensors,
Monitoring,
Routing,
Mesh networks,
Cryptography,
Intrusion detection"
Energy Efficiency of Cooperative Jamming Strategies in Secure Wireless Networks,"Energy efficient secure communication in wireless networks in the presence of eavesdroppers is considered. For a secure transmission to the destination, a set of intermediate ""jammer"" nodes are chosen to generate artificial noise that confuses the eavesdropper. We consider two jamming strategies: beamforming and cooperative diversity. Previous research has focused largely on cooperative beamforming strategies, but we demonstrate a number of scenarios where a cooperative diversity strategy is desirable. This motivates approaches which selectively switch between the two strategies, from which significant energy savings can often be realized. In our simulations, energy savings of up to 60% are observed in the simulated networks.","Jamming,
Array signal processing,
Noise,
Receivers,
Wireless networks,
Relays"
REWIRE: An optimization-based framework for unstructured data center network design,"Despite the many proposals for data center network (DCN) architectures, designing a DCN remains challenging. DCN design is especially difficult when expanding an existing network, because traditional DCN design places strict constraints on the topology (e.g., a fat-tree). Recent advances in routing protocols allow data center servers to fully utilize arbitrary networks, so there is no need to require restricted, regular topologies in the data center. Therefore, we propose a data center network design framework, that we call REWIRE, to design networks using an optimization algorithm. Our algorithm finds a network with maximal bisection bandwidth and minimal end-to-end latency while meeting user-defined constraints and accurately modeling the predicted cost of the network. We evaluate REWIRE on a wide range of inputs and find that it significantly outperforms previous solutions-its network designs have up to 100-500% more bisection bandwidth and less end-to-end network latency than equivalent-cost DCNs built with best practices.","Optical switches,
Bandwidth,
Topology,
Servers,
Network topology,
Delay,
Routing"
Texture-Based Analysis of COPD: A Data-Driven Approach,"This study presents a fully automatic, data-driven approach for texture-based quantitative analysis of chronic obstructive pulmonary disease (COPD) in pulmonary computed tomography (CT) images. The approach uses supervised learning where the class labels are, in contrast to previous work, based on measured lung function instead of on manually annotated regions of interest (ROIs). A quantitative measure of COPD is obtained by fusing COPD probabilities computed in ROIs within the lung fields where the individual ROI probabilities are computed using a k nearest neighbor (kNN ) classifier. The distance between two ROIs in the kNN classifier is computed as the textural dissimilarity between the ROIs, where the ROI texture is described by histograms of filter responses from a multi-scale, rotation invariant Gaussian filter bank. The method was trained on 400 images from a lung cancer screening trial and subsequently applied to classify 200 independent images from the same screening trial. The texture-based measure was significantly better at discriminating between subjects with and without COPD than were the two most common quantitative measures of COPD in the literature, which are based on density. The proposed measure achieved an area under the receiver operating characteristic curve (AUC) of 0.713 whereas the best performing density measure achieved an AUC of 0.598. Further, the proposed measure is as reproducible as the density measures, and there were indications that it correlates better with lung function and is less influenced by inspiration level.",
Control of cascaded H-bridge multilevel inverter with individual MPPT for grid-connected photovoltaic generators,"A single-phase cascaded H-bridge multilevel inverter for a grid-connected photovoltaic (PV) system with nonactive power compensation is presented in this paper. To maximize the solar energy extraction of each PV string, an individual maximum power point tracking (MPPT) control scheme is applied, which allows the independent control of each dc-link voltage. A generalized nonactive power theory is applied to generate the nonactive current reference. Within the inverter's capability, the local consumption of nonactive power is provided to realize power factor correction. A single-phase modular cascaded multilevel inverter prototype has been built. Each H-bridge is connected to a 195 W solar panel. Simulation and experimental results are presented to validate the proposed ideas.","Inverters,
Voltage control,
Topology,
Power control,
Photovoltaic systems"
Situation Awareness and Cognitive Modeling,This paper discusses the basic concepts of computer support for situation awareness. The main idea is to share “situations” by computer and human agents. Two cases of situation awareness are discussed. Some of the future research topics are listed.,"Cognitive science,
Human computer interaction,
Cyberspace,
Research and development,
Social network services,
Social factors"
Model-Based Predictive Control Applied to the Doubly-Fed Induction Generator Direct Power Control,"This paper proposes a model-based predictive controller for doubly-fed induction generator direct power control. The control law is derived by optimization of an objective function that considers the control effort and the difference between the predicted outputs (active and reactive power) and the specific references, with predicted outputs calculated using a linearized state-space model. In this case, the controller uses active and reactive power loop directly for the generator power control. Because the generator leakage inductance and resistance information were required for this control method, the influence of the estimation errors for these parameters was also investigated. Simulation results are carried out to validate the proposed controller.",
A Survey of Applications of Identity-Based Cryptography in Mobile Ad-Hoc Networks,"Security in mobile ad-hoc networks (MANETs) continues to attract attention after years of research. Recent advances in identity-based cryptography (IBC) sheds light on this problem and has become popular as a solution base. We present a comprehensive picture and capture the state of the art of IBC security applications in MANETs based on a survey of publications on this topic since the emergence of IBC in 2001. In this paper, we also share insights into open research problems and point out interesting future directions in this area.",
NCTU-GR: Efficient Simulated Evolution-Based Rerouting and Congestion-Relaxed Layer Assignment on 3-D Global Routing,"The increasing complexity of interconnection designs has enhanced the importance of research into global routing when seeking high-routability (low overflow) results or rapid search paths that report wirelength estimations to a placer. This work presents two routing techniques, namely circular fixed-ordering monotonic routing and evolution-based rip-up and rerouting using a two-stage cost function in a high-performance congestion-driven 2-D global router. We also propose two efficient via-minimization methods, namely congestion relaxation by layer shifting and rip-up and reassignment, for a dynamic programming-based layer assignment. Experimental results demonstrate that our router achieves performance similar to the first two winning routers in ISPD 2008 Routing Contest in terms of both routability and wirelength at a 1.05 × and 18.47 × faster routing speed. Moreover, the proposed layer assignment achieves fewer vias and shorter wirelength than congestion-constrained layer assignment (COLA).","Routing,
Cost function,
History,
Wires,
Adaptation model,
Runtime,
Estimation"
A 0.38 THz Fully Integrated Transceiver Utilizing a Quadrature Push-Push Harmonic Circuitry in SiGe BiCMOS,"A fully integrated transceiver operating at 0.38 terahertz (THz) has been demonstrated in 0.13 μm SiGe BiCMOS with fT = 230 GHz. We present a quadrature push-push harmonic circuitry consisting of the clamping pairs driven by balanced quadrature LO signals coupled through the transformers and the Coplanar Stripline (CPS). Harmonic generation of the clamping circuit is analyzed with a clamped sinusoidal model. Several terahertz circuits such as a quadrupler, a THz subharmonic mixer, and an IQ quadrature generator are implemented with the quadrature push-push circuitry to realize a homodyne FMCW radar. Radar functionality is demonstrated with ranging and detection of a target at 10 cm. The measured Equivalent Isotropically Radiated Power (EIRP) of the transmitter is -11 dBm at 0.38 THz and the receiver noise figure (NF) is between 35-38 dB while dissipating a power of 380 mW.","Harmonic analysis,
Clamps,
Transceivers,
Transmitters,
Integrated circuit modeling,
Radar,
Generators"
What make long term contributors: Willingness and opportunity in OSS community,"To survive and succeed, software projects need to attract and retain contributors. We model the individual's chances to become a valuable contributor through her capacity, willingness, and the opportunity to contribute at the time of joining. Using issue tracking data of Mozilla and Gnome, we find that the probability for a new joiner to become a Long Term Contributor (LTC) is associated with her willingness and environment. Specifically, during their first month, future LTCs tend to be more active and show more community-oriented attitude than other joiners. Joiners who start by commenting on instead of reporting an issue or ones who succeed to get at least one reported issue to be fixed, more than double their odds of becoming an LTC. The micro-climate with a productive and clustered peer group increases the odds. On the contrary, the macro-climate with high project popularity and the micro-climate with low attention from peers reduce the odds. This implies that the interaction between individual's attitude and project's climate are associated with the odds that an individual would become a valuable contributor or disengage from the project. Our findings may provide a basis for empirical approaches to design a better community architecture and to improve the experience of contributors.",
ENF Extraction From Digital Recordings Using Adaptive Techniques and Frequency Tracking,"A novel forensic tool used for assessing the authenticity of digital audio recordings is known as the electric network frequency (ENF) criterion. It involves extracting the embedded power line (utility) frequency from said recordings and matching it to a known database to verify the time the recording was made, and its authenticity. In this paper, a nonparametric, adaptive, and high resolution technique, known as the time-recursive iterative adaptive approach, is presented as a tool for the extraction of the ENF from digital audio recordings. A comparison is made between this data dependent (adaptive) filter and the conventional short-time Fourier transform (STFT). Results show that the adaptive algorithm improves the ENF estimation accuracy in the presence of interference from other signals. To further enhance the ENF estimation accuracy, a frequency tracking method based on dynamic programming will be proposed. The algorithm uses the knowledge that the ENF is varying slowly with time to estimate with high accuracy the frequency present in the recording.","Time frequency analysis,
Frequency estimation,
Digital recording,
Iterative methods,
Databases,
Government"
Hybrid power quality conditioner for co-phase power supply system in electrified railway,"Power quality conditioners based on modern power electronics technology were proposed to solve the power quality problems of the electrified railway power supply system. Large-capacity power converters are used as the main circuits of the compensator, which is one of the main reasons for the high initial cost of the railway power conditioner. A hybrid power quality conditioner (HPQC) for co-phase power supply system in electrified railway is proposed in this study. The HPQC adopts a single-phase back-to-back converter. It connects to the feeding phase of the balance feeding transformer via an L-C branch and to the other phase via a coupling transformer. To inject the same compensating currents to the traction power supply system, the DC bus voltage of the HPQC could be much lower than that of an active power conditioner (APC). As a result, the cost of the power quality conditioner is reduced. Simulation models are built with a HPQC connected to the secondary side of a 110 kV/27.5 kV V/V transformer. Simulation results show the HPQC could compensate reactive current, unbalance current and current harmonics simultaneously. Comparisons with an APC are also given. A small-capacity experimental prototype is built in the laboratory to validate the HPQC and testing results are also provided.","railway electrification,
power convertors,
power electronics,
power supply quality,
power transformers"
A Monolithically-Integrated Optical Receiver in Standard 45-nm SOI,"Integrated photonics has emerged as an I/O technology that can meet the throughput demands of future many-core processors. Taking advantage of the low capacitance environment provided by monolithic integration, we developed an integrating receiver front-end built directly into a clocked comparator, achieving high sensitivity and energy-efficiency. A simple model of the receiver provides intuition on the effects of wiring and photodiode capacitance, and leads to a photodiode-splitting technique enabling improved sensitivity at higher data rates. The receiver is characterized in situ and shown to operate with μA-sensitivity at 3.5 Gb/s with a power consumption of 180 μ W (52 fJ/bit) and area of 108 μm2 . This work demonstrates that photonics and electronics can be jointly integrated in a standard 45-nm SOI process.","Capacitance,
Optical receivers,
Sensitivity,
Clocks,
Optical sensors,
Bandwidth"
On the Equal-Rate Capacity of the AWGN Multiway Relay Channel,"The
L
-user additive white Gaussian noise multiway relay channel is investigated, where
L
users exchange information at the same rate through a single relay. A new achievable rate region, based on the functional-decode-forward coding strategy, is derived. For the case where there are three or more users, and all nodes transmit at the same power, the capacity is obtained. For the case where the relay power scales with the number of users, it is shown that both compress-forward and functional-decode-forward achieve rates within a constant number of bits of the capacity at all SNR levels; in addition, functional-decode-forward outperforms compress-forward and complete-decode-forward at high SNR levels.","Relays,
AWGN,
Encoding,
Lattices,
Upper bound,
Signal to noise ratio,
Downlink"
Flame Image-Based Burning State Recognition for Sintering Process of Rotary Kiln Using Heterogeneous Features and Fuzzy Integral,"Accurate and robust recognition of burning state for sintering process of rotary kiln plays an important role in the design of image-based intelligent control systems. Existing approaches such as consensus-based methods, temperature-based methods and image segmentation-based methods could not achieve satisfactory performance. This paper presents a flame image-based burning state recognition system using a set of heterogeneous features and fusion techniques. These features, i.e., the color feature, the global and local configuration features, are able to characterize different aspects of flame images, and they can be extracted from pixel values directly without segmentation efforts. In this study, ensemble learner models with four types of base classifiers and five fusion operators are examined with comprehensive comparisons. A total of 482 typical flame images, including 86 over-burning state images, 193 under-burning state images, and 203 normal-burning state images, were used in our experiments. These images were collected from the No. 3 rotary kiln at the Shanxi Aluminum Corporation in China, and labeled by the rotary kiln operational experts. Results demonstrate that our proposed image-based burning state recognition systems outperform other methods in terms of both recognition accuracy and robustness against the disturbance from smoke and dust inside the kiln.","Feature extraction,
Neural networks,
Visualization,
Fuzzy systems,
Image color analysis,
Image recognition,
Image segmentation"
Physical layer security from inter-session interference in large wireless networks,"Physical layer secrecy in wireless networks in the presence of eavesdroppers of unknown location is considered. In contrast to prior schemes, which have expended energy in the form of cooperative jamming to enable secrecy, we develop schemes where multiple transmitters send their signals in a cooperative fashion to confuse the eavesdroppers. Hence, power is not expended on “artificial noise”; rather, the signal of a given transmitter is protected by the aggregate interference produced by the other transmitters. We introduce a two-hop strategy for the case of equal path-loss between all pairs of nodes, and then consider its embedding within a multi-hop approach for the general case of an extended network. In each case, we derive an achievable number of eavesdroppers that can be present in the region while secure communication between all sources and intended destinations is ensured.","Relays,
Transmitters,
Interference,
Wireless networks,
Protocols,
Receivers,
Signal to noise ratio"
Fast Linear Model Predictive Control Via Custom Integrated Circuit Architecture,"This paper addresses the implementation of linear model predictive control (MPC) at millisecond range, or faster, sampling rates. This is achieved by designing a custom integrated circuit architecture that is specifically targeted to the MPC problem. As opposed to the more usual approach using a generic serial architecture processor, the design here is implemented using a field-programmable gate array and employs parallelism, pipelining, and specialized numerical formats. The performance of this approach is profiled via the control of a 14th-order resonant structure with 12 sample prediction horizon at 200-μs sampling rate. The results indicate that no more than 30 μs are required to compute the control action. A feasibility study indicates that the design can also be implemented in 130 nm CMOS technology, with a core area of 2.5 mm2. These results illustrate the feasibility of MPC for reasonably complex systems, using relatively cheap, small, and low-power computing hardware.","Computer architecture,
Observers,
Field programmable gate arrays,
Integrated circuit modeling,
Predictive models,
Optimization,
Predictive control"
Robust Relative Location Estimation in Wireless Sensor Networks with Inexact Position Problems,"In this paper, the relative location estimation problem, a prominent issue faced by several applications in wireless sensor networks (WSNs), is considered. Sensors are classified into two categories: location-aware and location-unaware sensors. To estimate the positions of location-unaware sensors, exact positions are often assumed for location-aware sensors. However, in practice, such precise data may not be available. Therefore, determining the positions of location-unaware sensors in the presence of inexact positions of location-aware sensors is the primary focus of this study. A robust min-max optimization method is proposed for the relative location estimation problem by minimizing the worst-case estimation error. The corresponding optimization problem is originally nonconvex, but after it is transformed into a convex semidefinite program (SDP), it can be solved by existing numerical techniques. In the presence of inexact positions of location-aware sensors, the robustness of the proposed approach is validated by simulations under different WSN topologies. Modified maximum-likelihood (ML) estimation and second-order cone programming (SOCP) relaxation methods have been used for localization in comparison with the proposed approach.","Sensors,
Wireless sensor networks,
Robustness,
Optimization,
Maximum likelihood estimation,
Convex functions"
Grammatical Evolution of Local Search Heuristics,"Genetic programming approaches have been employed in the literature to automatically design constructive heuristics for cutting and packing problems. These heuristics obtain results superior to human-created constructive heuristics, but they do not generally obtain results of the same quality as local search heuristics, which start from an initial solution and iteratively improve it. If local search heuristics can be successfully designed through evolution, in addition to a constructive heuristic which initializes the solution, then the quality of results which can be obtained by automatically generated algorithms can be significantly improved. This paper presents a grammatical evolution methodology which automatically designs good quality local search heuristics that maintain their performance on new problem instances.",
Optimal index codes for a class of multicast networks with receiver side information,"This paper studies a special class of multicast index coding problems where a sender transmits messages to multiple receivers, each with some side information. Here, each receiver knows a unique message a priori, and there is no restriction on how many messages each receiver requests from the sender. For this class of multicast index coding problems, we obtain the optimal index code, which has the shortest codelength for which the sender needs to send in order for all receivers to obtain their (respective) requested messages. This is the first class of index coding problems where the optimal index codes are found. In addition, linear index codes are shown to be optimal for this class of index coding problems.","Indexes,
Receivers,
Unicast,
Relays,
Linear code,
Educational institutions"
Linear Precoding for MIMO Broadcast Channels With Finite-Alphabet Constraints,"We investigate the design of linear transmit precoder for multiple-input multiple-output (MIMO) broadcast channels (BC) with finite alphabet input signals. We first derive an explicit expression for the achievable rate region of the MIMO BC with discrete constellation inputs, which is generally applicable to cases involving arbitrary user number and arbitrary antenna number. We further present a weighted sum rate upper bound of the MIMO BC with identical transmit precoding matrices. The resulting bound exhibits a serious performance loss because of the non-uniquely decodable transmit signals for MIMO BC with finite alphabet inputs in high signal-to-noise ratio (SNR) region. This performance loss motivates the use of a simple precoding to combat the non-unique decodability. Based on a constrained optimization problem formulation, we apply the Karush-Kuhn-Tucker analysis to derive necessary conditions for MIMO BC precoders to maximize the weighted sum-rate. We then propose an iterative gradient descent algorithm with backtracking line search to optimize the linear precoders for each user. Our { simulation} results under the practical transmit symbols of discrete constellations demonstrate significant gains by the proposed algorithm over other precoding schemes including the traditional iterative water-filling (WF) design for the Gaussian input signals. For the low-density parity-check coded systems, our precoder provides considerably coded BER improvement through iterative decoding and detection.","MIMO,
Signal to noise ratio,
Modulation,
Vectors,
Optimization,
Educational institutions,
Interference"
A Utility-Interfaced Phase-Modulated High-Frequency Isolated Dual LCL DC/AC Converter,"This paper presents a phase-modulated high-frequency isolated dc/ac converter as the grid interface in a distributed generation system. The converter includes two full-bridge HF LCL-type resonant inverters working at fixed duty cycle. The power control is realized by means of the phase-shift between the two bridges. Using the LCL-type resonant tank, zero-voltage-switching is achieved for all switches for the whole power range. With the phase-shift modulated sinusoidally, a full-wave rectified output current synchronized with the utility line is obtained, which is unfolded and fed to the single-phase utility line. The analysis is verified with computer simulation results. Experimental data based on a 500-W prototype circuit is included for validation purpose.",
Design challenges for secure implantable medical devices,"Implantable medical devices, or IMDs, are increasingly being used to improve patients' medical outcomes. Designers of IMDs already balance safety, reliability, complexity, power consumption, and cost. However, recent research has demonstrated that designers should also consider security and data privacy to protect patients from acts of theft or malice, especially as medical technology becomes increasingly connected to other systems via wireless communications or the Internet. This survey paper summarizes recent work on IMD security. It discusses sound security principles to follow and common security pitfalls to avoid. As trends in power efficiency, sensing, wireless systems and bio-interfaces make possible new and improved IMDs, they also underscore the importance of understanding and addressing security and privacy concerns in an increasingly connected world.","Biosensors,
Privacy,
Insulin,
Wireless communication,
Encryption"
Noisy Depth Maps Fusion for Multiview Stereo Via Matrix Completion,"This paper introduces a general framework to fuse noisy point clouds from multiview images of the same object. We solve this classical vision problem using a newly emerging signal processing technique known as matrix completion. With this framework, we construct the initial incomplete matrix from the observed point clouds by all the cameras, with the invisible points by any camera denoted as unknown entries. The observed points corresponding to the same object point are put into the same row. When properly completed, the recovered matrix should have rank one, since all the columns describe the same object. Therefore, an intuitive approach to complete the matrix is by minimizing its rank subject to consistency with observed entries. In order to improve the fusion accuracy, we propose a general noisy matrix completion method called log-sum penalty completion (LPC), which is particularly effective in removing outliers. Based on the majorization–minimization algorithm (MM), the non-convex LPC problem is effectively solved by a sequence of convex optimizations. Experimental results on both point cloud fusion and MVS reconstructions verify the effectiveness of the proposed framework and the LPC algorithm.","Cameras,
Three dimensional displays,
Noise,
Estimation,
Vectors,
Robustness,
Noise measurement"
Data centres in the ancillary services market,"Ancillary services are the mechanisms power grids use to address short-term variability in supply and demand as well as the impact of power plant or transmission line failures. Organizations providing such services can earn revenue, or at least reduce their energy costs. This paper explores options for large data centres to reduce costs in this way. Simulation results are presented for a system that models the processing of a workload and the resulting energy use, focusing on the impact of providing specific types of ancillary services. Trace data recording the workload from three supercomputing facilities along with pricing information from a US-based electrical grid are used. Results presented show energy costs reduced by up to 12% with only a small impact on the quality of service provided to users of the data centre. Further reductions in energy costs are shown for data centres willing to cede more control over short-term energy consumption.","Power demand,
Power grids,
Load management,
Servers,
Real-time systems,
Availability,
Pricing"
A differential game approach to distributed demand side management in smart grid,"Smart grid is a visionary user-centric system that will elevate the conventional power grid system to one which functions more cooperatively, responsively, and economically. Dynamic demand side management is one of the key issues that enable the implementation of smart grid. In this paper, we use the framework of dynamic games to model the distribution demand side management. The market price is characterized as the dynamic state using a sticky price model. A two-layer optimization framework is established. At the lower level, for each player (such as one household), different appliances are scheduled for energy consumption. At the upper level, the dynamic game is used to capture the interaction among different players in their demand responses through the market price. We analyze the N-person nonzero-sum stochastic differential game and characterize its feedback Nash equilibrium. A special case of homogeneous users is investigated in detail and we provide a closed-form solution for the optimal demand response. From the simulation results, we demonstrate the use of demand response strategy from the game-theoretic framework and study the behavior of market price and demand responses to different parameters.","Games,
Load management,
Nash equilibrium,
Dynamic scheduling,
Analytical models,
Power system dynamics,
Home appliances"
A case for fully decentralized dynamic VM consolidation in clouds,"One way to conserve energy in cloud data centers is to transition idle servers into a power saving state during periods of low utilization. Dynamic virtual machine (VM) consolidation (VMC) algorithms are proposed to create idle times by periodically repacking VMs on the least number of physical machines (PMs). Existing works mostly apply VMC on top of centralized, hierarchical, or ring-based system topologies which result in poor scalability and/or packing efficiency with increasing number of PMs and VMs. In this paper, we propose a novel fully decentralized dynamic VMC schema based on an unstructured peer-to-peer (P2P) network of PMs. The proposed schema is validated using three well known VMC algorithms: First-Fit Decreasing (FFD), Sercon, V-MAN, and a novel migration-cost aware ACO-based algorithm. Extensive experiments performed on the Grid'5000 testbed show that once integrated in our fully decentralized VMC schema, traditional VMC algorithms achieve a global packing efficiency very close to a centralized system. Moreover, the system remains scalable with increasing number of PMs and VMs. Finally, the migration-cost aware ACO-based algorithm outperforms FFD and Sercon in the number of released PMs and requires less migrations than FFD and V-MAN.",
Variational Blue Noise Sampling,"Blue noise point sampling is one of the core algorithms in computer graphics. In this paper, we present a new and versatile variational framework for generating point distributions with high-quality blue noise characteristics while precisely adapting to given density functions. Different from previous approaches based on discrete settings of capacity-constrained Voronoi tessellation, we cast the blue noise sampling generation as a variational problem with continuous settings. Based on an accurate evaluation of the gradient of an energy function, an efficient optimization is developed which delivers significantly faster performance than the previous optimization-based methods. Our framework can easily be extended to generating blue noise point samples on manifold surfaces and for multi-class sampling. The optimization formulation also allows us to naturally deal with dynamic domains, such as deformable surfaces, and to yield blue noise samplings with temporal coherence. We present experimental results to validate the efficacy of our variational framework. Finally, we show a variety of applications of the proposed methods, including nonphotorealistic image stippling, color stippling, and blue noise sampling on deformable surfaces.",
Spatial Computing and Social Media in the Context of Disaster Management,"The growing trend of using smartphones and other GPS-enabled devices has provided new opportunities for developing spatial computing applications and technologies in unanticipated and unprecedented ways. Some capabilities of today's smartphones highlight the potential of citizen sensors to enable the next generation of geoinformatics. One promising application area for this is social media and its application to disaster management. Dynamic, real-time incident information collected from onsite human responders about the extent of damage, the evolution of the event, the community's needs, and responders' ability to deal with the situation, combined with information from the larger emergency management community, could lead to more accurate and real-time situational awareness. This would enable informed decisions, better resource allocation and thus a better response and outcome to the total crisis. In this context, the US Department of Homeland Security's Science & Technology Directorate (DHS-S&T) has initiated the Social Media Alert and Response to Threats to Citizens"" (SMART-C) program, which aims to develop citizen participatory sensing capabilities for decision support throughout the disaster life cycle via a multitude of devices and modalities. Here, the authors provide an overview of the envisioned SMART-C system's capabilities and discuss some of the interesting and unique challenges that arise due to the combination of spatial computing and social media within the context of disaster management.","Social network services,
Smart phones,
Emergencies,
Disaster management,
Global Positioning System"
Combating Hidden and Exposed Terminal Problems in Wireless Networks,"The hidden terminal problem is known to degrade the throughput of wireless networks due to collisions, while the exposed terminal problem results in poor performance by wasting valuable transmission opportunities. As a result, extensive research has been conducted to solve these two problems, such as Carrier Sense Multiple Access with Collision Avoidance (CSMA/CA). However, CSMA-like protocols cannot solve both of these two problems at once. The fundamental reason lies in the fact that they cannot obtain accurate Channel Usage Information (CUI, who is transmitting or receiving nearby) with a low cost. To obtain additional CUI in a cost-efficient way, we propose a cross layer design, FAST (Full-duplex Attachment System). FAST contains a PHY layer Attachment Coding, which transmits control information independently on the air, without degrading the effective throughput of the original data traffic, and a MAC layer Attachment Sense, which utilizes the PHY layer control information to identify the hidden and exposed nodes in real time. We theoretically analyze the feasibility of the Attachment Coding, and then implement it on a GNU Radio testbed consisting of eight USRP2 nodes. We also conduct extensive simulations to evaluate the performance of FAST, and the experimental results show that FAST can effectively solve both the hidden and the exposed terminal problems, and improve the average throughput by up to 200% over CSMA in practical ad-hoc networks.",
Iterative Deepening A* Algorithms for the Container Relocation Problem,"The container relocation problem, where containers that are stored in bays are retrieved in a fixed sequence, is a crucial port operation. Existing approaches using branch and bound algorithms are only able to optimally solve small cases in a practical time frame. In this paper, we investigate iterative deepening A* algorithms (rather than branch and bound) using new lower bound measures and heuristics, and show that this approach is able to solve much larger instances of the problem in a time frame that is suitable for practical application. We also examine a more difficult variant of the problem that has been largely ignored in existing literature.",
Wolf search algorithm with ephemeral memory,"In computer science, a computational challenge exists in finding a globally optimized solution from a tremendously large search space. Heuristic optimization methods have therefore been created that can search the very large spaces of candidate solutions. These methods have been extensively studied in the past, and progressively extended in order to suit a wide range of optimization problems. Researchers recently have invented a collection of heuristic optimization methods inspired by the movements of animals and insects (e.g., Firefly, Cuckoos, Bats and Accelerated PSO) with the advantages of efficient computation and easy implementation. This paper proposes a new bio-inspired heuristic optimization algorithm called the Wolf Search Algorithm (WSA) that imitates the way wolves search for food and survive by avoiding their enemies. The contribution of the paper is twofold: 1. for verifying the efficacy of the WSA the algorithm is tested quantitatively and compared to other heuristic algorithms under a range of popular non-convex functions used as performance test problems for optimization algorithms; 2. The WSA is investigated with respective to its memory requirement. Superior results are observed in most tests.","Visualization,
Search problems,
Heuristic algorithms,
Educational institutions,
Marine animals,
Optimization methods"
Anchor-Guiding Mechanism for Beacon-Assisted Localization in Wireless Sensor Networks,"Localization is one of the most important issues in wireless sensor networks (WSNs). In the most widely proposed range-free algorithms, nodes estimate location by employing the geometric constraints imposed by the location of the mobile anchor. However, none of them addresses how the mobile anchor moves to optimize the improvement of location inaccuracies and minimize the anchor's movement. This paper assumes that previous range-free algorithms have been executed for a period of time and the deployed sensors are of different location inaccuracies. According to the size of the estimative region of each static sensor, an anchor-guiding mechanism is proposed to determine the beacon locations and construct an efficient path for the mobile anchor. Experimental study reveals that the proposed anchor-guiding mechanism effectively guides the mobile anchor to move along an efficient path, thereby saving the time required for improving or balancing the location inaccuracies of all sensor nodes.",
Secret Key Generation for Correlated Gaussian Sources,"Secret key generation by multiple terminals is considered based on their observations of jointly distributed Gaussian signals, followed by public communication among themselves. Exploiting an inherent connection between secrecy generation and lossy data compression, two main contributions are made. The first is a characterization of strong secret key capacity, and entails a converse proof technique that is valid for real-valued (and not necessarily Gaussian) as well as finite-valued signals. The capacity formula acquires a simple form when the terminals observe “symmetrically correlated” jointly Gaussian signals. For the latter setup with two terminals, considering schemes that involve quantization at one terminal, the best rate of an achievable secret key is characterized as a function of quantization rate; secret key capacity is attained as the quantization rate tends to infinity. Structured codes are shown to attain the optimum tradeoff between secret key rate and quantization rate, constituting our second main contribution.",
A Novel Approach to Optical Switching for Intradatacenter Networking,"In this paper, we propose to apply a novel paradigm called labeled optical burst switching with home circuit (LOBS-HC) for intradatacenter networking to provide a high bisection bandwidth and significantly reduce the cost and energy consumption associated with electronic packet switching. The unique features of LOBS-HC that make it more suitable than either optical circuit switching (OCS) or optical packet/burst switching are exploited to enable all-to-all communications with a guaranteed lossless transmission bandwidth between any given pair of pods, while also supporting bursty transmissions through wavelength-sharing among home circuits (HCs) and statistical multiplexing. As a case study, hypercube-like topologies are considered for the interconnection among the pods within a datacenter. In particular, we first propose a simple but efficient HC assignment scheme called complementary HC for 2-D cube or ring, and then extend our works to n-cube and generalized hypercube by applying the concept of spanning balanced tree (SBT) for their HC assignment. Our analysis results show that with such datacenters, the minimum number of wavelengths needed in each case is significantly reduced from that needed with OCS and also, the network cost in terms of wires and transceivers needed is considerably reduced from that incurs with datacenters using electronic packet switching. We then evaluate the traffic performance of such hypercube-based datacenters using LOBS-HC through simulation experiments via the OPNET simulator. The performance results obtained for a variety of communication patterns and traffic models within a datacenter demonstrate the feasibility of the proposed approach.",
Dynamic Sub-GOP Forward Error Correction Code for Real-Time Video Applications,"Reed-Solomon erasure codes are commonly studied as a method to protect the video streams when transmitted over unreliable networks. As a block-based error correcting code, on one hand, enlarging the block size can enhance the performance of the Reed-Solomon codes; on the other hand, large block size leads to long delay which is not tolerable for real-time video applications. In this paper a novel Dynamic Sub-GOP FEC (DSGF) approach is proposed to improve the performance of Reed-Solomon codes for video applications. With the proposed approach, the Sub-GOP, which contains more than one video frame, is dynamically tuned and used as the RS coding block, yet no delay is introduced. For a fixed number of extra introduced packets, for protection, the length of the Sub-GOP and the redundancy devoted to each Sub-GOP becomes a constrained optimization problem. To solve this problem, a fast greedy algorithm is proposed. Experimental results show that the proposed ap proach outperforms other real-time error resilient video coding technologies.","Encoding,
Delay,
Streaming media,
Real time systems,
Forward error correction,
Systematics,
Reed-Solomon codes"
ITS-cloud: Cloud computing for Intelligent transportation system,"Cloud computing is known as services delivery such as shared resources, platforms, software and data, in the interest of end-users. They are located in distributed datacenters over a network such as the Internet. In this paper a new cloud computing model called ITS-Cloud applied to the Intelligent Transportation Systems (ITS) is proposed to improve transport outcomes such as road safety, transport productivity, travel reliability, informed travel choices, environment protection, and traffic resilience. It consists of two sub-models: the statistic and the dynamic cloud sub-models. In the former, vehicles benefit of the conventional cloud advantages however; the dynamic one which is a temporary cloud is formed by the vehicles themselves which represent the cloud datacenters. To validate our proposal, a simulation study is performed to deal with the load balancing as a NP-Complete problem. The reached results are obtained using Bees Life Algorithm (BLA) applied to ITS-Cloud and compared with those reached by (BLA) applied only to the conventional Cloud.","resource allocation,
automated highways,
cloud computing,
computational complexity"
UNISM: Unified Scheduling and Mapping for General Networks on Chip,"Task scheduling and core mapping have a significant impact on the overall performance of network on chip (NOC). In this paper, a unified task scheduling and core mapping algorithm called UNISM is proposed for different NOC architectures including regular mesh, irregular mesh and custom networks. First, a unified model combining scheduling and mapping is introduced using mixed integer linear programming (MILP). Then, a novel graph model is proposed to consider the network irregularity and estimate communication energy and latency, since the number of network hops is not accurate enough for irregular mesh and custom networks. To make the MILP-based UNISM scalable, a heuristic is employed to speed up our method. Compared with two previous state-of-the-art works, experimental results show that more than 15% and 11.5% improvement on the execution time is achieved with similar energy consumption on average for regular mesh NOC. For irregular and custom NOC, the improvement is 27.3% and 14.5% on the execution time with 24.3% and 18.5% lower energy. Moreover, our method is scalable for large benchmarks in terms of runtime.","Energy consumption,
Computer architecture,
Processor scheduling,
Job shop scheduling,
Very large scale integration,
Network-on-chip"
Sparse Spatial Coding: A novel approach for efficient and accurate object recognition,"Successful state-of-the-art object recognition techniques from images have been based on powerful methods, such as sparse representation, in order to replace the also popular vector quantization (VQ) approach. Recently, sparse coding, which is characterized by representing a signal in a sparse space, has raised the bar on several object recognition benchmarks. However, one serious drawback of sparse space based methods is that similar local features can be quantized into different visual words. We present in this paper a new method, called Sparse Spatial Coding (SSC), which combines a sparse coding dictionary learning, a spatial constraint coding stage and an online classification method to improve object recognition. An efficient new off-line classification algorithm is also presented. We overcome the problem of techniques which make use of sparse representation alone by generating the final representation with SSC and max pooling, presented for an online learning classifier. Experimental results obtained on the Caltech 101, Caltech 256, Corel 5000 and Corel 10000 databases, show that, to the best of our knowledge, our approach supersedes in accuracy the best published results to date on the same databases. As an extension, we also show high performance results on the MIT-67 indoor scene recognition dataset.",
Diagnosis of Technical Condition of Power Transformers Based on the Analysis of Vibroacoustic Signals Measured in Transient Operating Conditions,"The issue of an effective assessment of the technical condition of the mechanical structure of the power transformer core and windings originated the research work discussed in this paper. This publication presents the results which indicate the possibility of developing a new and noninvasive diagnostic method of the transformer active part. The method developed is based on the time-frequency analysis results of the mechanical vibrations measured of the monitored appliance. The registration of vibrations is performed during switching the transformer monitored into idle operation. This paper characterizes the power object under study, the measuring system applied, and discusses a new methodology of assessment of the technical condition of the core and windings using a modified vibroacoustic method. The original measurement results presented in this paper were obtained during switching on a 200-kVA transformer in laboratory conditions. The analysis of the signals measured was carried out for four operating conditions of the transformer under study: 1) with the core pressed by the manufacturer; 2) with the core with loose screws fixing the upper yoke; 3) with the core with loose screws fixing the upper and lower yokes; and 4) with the core with loose screws fixing the upper and lower yokes with a simultaneous unpressing of the windings of the upper voltage side.","Vibrations,
Transformer cores,
Windings,
Vibration measurement,
Switches,
Power transformer insulation"
A 12-bit 20 MS/s 56.3 mW Pipelined ADC With Interpolation-Based Nonlinear Calibration,"The linearity of a high-resolution pipelined analog- to-digital converter (ADC) is mainly limited by the capacitor mismatch and the finite operational amplifier (OPAMP) gain in the multiplying-digital-to-analog converter (MDAC). Therefore, high resolution pipelined ADCs usually require high-gain OPAMP and large capacitors, which causes large ADC power. In recent years, various nonlinear calibration techniques have been developed to compensate both linear and nonlinear error from MDCAs so that low-power MDACs with small capacitors and low-gain OPAMP can be used. Hence, the ADC power can be greatly reduced. This paper introduces a novel interpolation- based digital self-calibration architecture for pipelined ADC. Compared to previous techniques, the new architecture is free of adaptation. Hence, long convergence is not needed. The complexity of the digital processor is also considerably lower. The new architecture does not use backend ADC to measure MDACs. Hence, it is free of the accumulation of measurement error, which leads to more accurate calibration. A prototype ADC with the calibration architecture is fabricated in a 0.35 3.3 V CMOS process. The ADC samples at 20 MS/s. The calibration improves the ADC DNL and INL from 1.47 LSB and 7.85 LSB to 0.2 LSB and 0.27 LSB. For a 590 kHz sinusoidal signal, the calibration improves the ADC signal-to-noise-distortion ratio(SNDR) and spurious-free dynamic range (SFDR) from 41.3 dB and 52.1 dB to 72.5 dB and 84.4 dB respectively. The 11.8-ENOB 20 MS/s ADC consumes 56.3 mW power with 3.3 V supply. The 0.78 pJ/step figure-of-merit (FOM) is low for designs in 0.35 CMOS processes. At the Nyquist frequency, SNDR of the calibrated ADC drops 8 dB due to the slow settling of the first pipeline stage.","Calibration,
Capacitors,
Pipelines,
Gain,
Transfer functions,
Interpolation,
Switches"
On truth discovery in social sensing: A maximum likelihood estimation approach,"This paper addresses the challenge of truth discovery from noisy social sensing data. The work is motivated by the emergence of social sensing as a data collection paradigm of growing interest, where humans perform sensory data collection tasks. A challenge in social sensing applications lies in the noisy nature of data. Unlike the case with well-calibrated and well-tested infrastructure sensors, humans are less reliable, and the likelihood that participants' measurements are correct is often unknown a priori. Given a set of human participants of unknown reliability together with their sensory measurements, this paper poses the question of whether one can use this information alone to determine, in an analytically founded manner, the probability that a given measurement is true. The paper focuses on binary measurements. While some previous work approached the answer in a heuristic manner, we offer the first optimal solution to the above truth discovery problem. Optimality, in the sense of maximum likelihood estimation, is attained by solving an expectation maximization problem that returns the best guess regarding the correctness of each measurement. The approach is shown to outperform the state of the art fact-finding heuristics, as well as simple baselines such as majority voting.","Sensors,
Atmospheric measurements,
Particle measurements,
Reliability,
Maximum likelihood estimation,
Silicon,
Equations"
Automatic design of low-power encoders using reversible circuit synthesis,"The application of coding strategies is an established methodology to improve the characteristics of on-chip interconnect architectures. Therefore, design methods are required which realize the corresponding encoders and decoders with as small as possible overhead in terms of power and delay. In the past, conventional design methods have been applied for this purpose.","Encoding,
Logic gates,
Hamming weight,
Design methodology,
Power demand,
Decoding,
Integrated circuit interconnections"
Compressed Sensing Based Real-Time Dynamic MRI Reconstruction,"This work addresses the problem of real-time online reconstruction of dynamic magnetic resonance imaging sequences. The proposed method reconstructs the difference between the previous and the current image frames. This difference image is sparse. We recover the sparse difference image from its partial k-space scans by using a nonconvex compressed sensing algorithm. As there was no previous fast enough algorithm for real-time reconstruction, we derive a novel algorithm for this purpose. Our proposed method has been compared against state-of-the-art offline and online reconstruction methods. The accuracy of the proposed method is less than offline methods but noticeably higher than the online techniques. For real-time reconstruction we are also concerned about the reconstruction speed. Our method is capable of reconstructing 128 × 128 images at the rate of 6 frames/s, 180 × 180 images at the rate of 5 frames/s and 256 × 256 images at the rate of 2.5 frames/s.",
Dynamic Bit Allocation for Object Tracking in Wireless Sensor Networks,"In this paper, we study the target tracking problem in wireless sensor networks (WSNs) using quantized sensor measurements where the total number of bits that can be transmitted from sensors to the fusion center is limited. At each time step of tracking, a total of R available bits need to be distributed among the N sensors in the WSN for the next time step. The optimal solution for the bit allocation problem can be obtained by using a combinatorial search which may become computationally prohibitive for large N and R. Therefore, we develop two new suboptimal bit allocation algorithms which are based on convex optimization and approximate dynamic programming (A-DP). We compare the mean squared error (MSE) and computational complexity performances of convex optimization and A-DP with other existing suboptimal bit allocation schemes based on generalized Breiman, Friedman, Olshen, and Stone (GBFOS) algorithm and greedy search. Simulation results show that, A-DP, convex optimization and GBFOS yield similar MSE performance, which is very close to that based on the optimal exhaustive search approach and they outperform greedy search and nearest neighbor based bit allocation approaches significantly. Computationally, A-DP is more efficient than the bit allocation schemes based on convex optimization and GBFOS, especially for a large sensor network.","Bit rate,
Target tracking,
Wireless sensor networks,
Convex functions,
Dynamic scheduling,
Heuristic algorithms,
Mutual information"
PEV-based combined frequency and voltage regulation for smart grid,"With the increasing popularity of plug-in electric vehicles (PEVs), they will be able to help the power grid by providing various ancillary services. In fact, recent studies have suggested that PEVs can participate in frequency regulation. In this paper, we consider offering both, i.e., combined, frequency and voltage regulation by PEVs. In this regard, we first investigate a set of constraints that need to be taken into account on PEVs' active and reactive power flow to offer ancillary services. Next, we formulate two joint optimization problems, based on different pricing and contract scenarios, that can be solved for optimal combined offering of frequency and voltage regulation by PEVs. They address both day-ahead command-based and day-ahead price-based models. Simulation results show that the proposed designs can benefit both users and utilities.",
Humidity Sensing by Polymer-Loaded UHF RFID Antennas,"Passive ultra high-frequency radio frequency identification tags, besides item labeling, are also able to exploit capability to sense the physical state of the tagged object as well as of the surrounding environment. Here, a new family of polymer-doped tags are proposed and fully characterized for the detection of ambient humidity. A sensitive chemical species based on PEDOT:PSS is used to load a shaped slot, carved into a folded-like patch tag. The communication and sensing capabilities of the resulting radio-sensor are investigated by means of simulation and measurements that show how to control and balance above opposite requirements by a proper deposition of the sensitive material. The device could have interesting applications in the assessment of the air quality within living and controlled rooms, in the monitoring of the conservation state of foods, in the preservation of walls, and even in the medical field, e.g., to monitor the healing of wounds.","Humidity,
Polymers,
Antenna measurements,
Radiofrequency identification,
Antennas"
"Quantifying spectrum, cost, and energy efficiency in fixed-grid and flex-grid networks [Invited]","Single and multi-carrier networks offering channel rates up to 400 Gb/s are evaluated under realistic reach parameters. It is found that efficient spectrum utilization and fine bit-rate granularity are essential to achieve cost and energy efficiency. Additionally, the break-even cost of flexible orthogonal frequency division multiplexing transponders is examined under different settings. The break-even cost of a flexible transponder corresponds to the cost value for which the total cost of the network is equal to that of the related single-line-rate network. The impact of the traffic load, the additional cost required for flex-grid optical cross connects, the cost of spectrum, as well as the cost of fixed-grid transponders is examined.","Transponders,
Optical switches,
Optimization,
OFDM,
Optical fiber networks,
Resource management,
Minimization"
{\cal U}Boost: Boosting with the Universum,"It has been shown that the Universum data, which do not belong to either class of the classification problem of interest, may contain useful prior domain knowledge for training a classifier [1], [2]. In this work, we design a novel boosting algorithm that takes advantage of the available Universum data, hence the name UBoost. UBoost is a boosting implementation of Vapnik's alternative capacity concept to the large margin approach. In addition to the standard regularization term, UBoost also controls the learned model's capacity by maximizing the number of observed contradictions. Our experiments demonstrate that UBoost can deliver improved classification accuracy over standard boosting algorithms that use labeled data alone.",
Video Coding With Rate-Distortion Optimized Transform,"Block-based discrete cosine transform (DCT) has been successfully adopted into several international image/video coding standards, e.g., MPEG-2, H.264/AVC, as it can achieve a good tradeoff between performance and complexity. Although DCT theoretically approximates the optimum Karhunen-Loève transform under first-order Markov conditions, one fixed set of transform basis functions (TBF) cannot handle all the cases efficiently due to the non-stationary nature of video contents. To further improve the performance of block-based transform coding, in this paper, we present the design of rate-distortion optimized transform (RDOT) which contributes to both intraframe and interframe coding. The most important property which makes a difference between RDOT and the conventional DCT is that, in the proposed method, transform is implemented with multiple TBF candidates which are obtained from off-line training. With this feature, for coding each residual block, the encoder is capable to select the optimal set of TBF in terms of rate-distortion performance, and better energy compaction is achieved in the transform domain. To obtain an optimum group of candidate TBF, we have developed a two-step iterative optimization technique for the off-line training, with which the TBF candidates are refined at each iteration until the training process becomes converged. Moreover, analysis on the optimal group of candidate TBF is also presented in this paper, with a detailed description of a practical implementation for the proposed algorithm on the latest VCEG key technical area software platform. Extensive experimental results show that, compared with the conventional DCT-based transform scheme adopted into the state-of-the-art H.264/AVC video coding standard, significant improvement of coding performance has been achieved for both intraframe and interframe coding with our proposed method.","Encoding,
Discrete cosine transforms,
Indexes,
Rate-distortion,
Video coding,
IP networks"
MIMO-UWB Channel Characterization Within an Underground Mine Gallery,"Multiple input multiple output-ultrawide band (MIMO-UWB) systems are experimentally evaluated for underground mine high-speed radio communications. Measurement campaigns using two different antenna configurations have been made in an underground gold mine. Furthermore, two scenarios, which are the line of sight (LoS) and the non-LoS (NLoS), i.e., taking into account the mining machinery effect, are distinguished and studied separately. In fact, the channel is characterized in terms of coherence bandwidth, path loss, shadowing, channel correlation, and capacity. Results reveal how antenna array configuration affects main channel parameters and suggest that mining machinery presence substantially affects both received power and time dispersion parameters within the underground mine and should, therefore, be considered when assessing the performance of in-gallery wireless systems. Moreover, it is shown that the MIMO-UWB takes benefit of the large spreading bandwidth and the multipath propagation environment to increase the channel capacity.","Antenna measurements,
MIMO,
Frequency measurement,
Bandwidth,
Correlation,
Coherence,
Receiving antennas"
Period Extension and Randomness Enhancement Using High-Throughput Reseeding-Mixing PRNG,"We present a new reseeding-mixing method to extend the system period length and to enhance the statistical properties of a chaos-based logistic map pseudo random number generator (PRNG). The reseeding method removes the short periods of the digitized logistic map and the mixing method extends the system period length to 2253 by “xoring” with a DX generator. When implemented in the TSMC 0.18- μm 1P6M CMOS process, the new reseeding-mixing PRNG (RM-PRNG) attains the best throughput rate of 6.4 Gb/s compared with other nonlinear PRNGs. In addition, the generated random sequences pass the NIST SP 800-22 statistical tests including ratio test and U-value test.","Generators,
Hardware,
Chaos,
Throughput,
Cryptography,
NIST,
Logic gates"
Motion Tracking for Medical Imaging: A Nonvisible Structured Light Tracking Approach,"We present a system for head motion tracking in 3D brain imaging. The system is based on facial surface reconstruction and tracking using a structured light (SL) scanning principle. The system is designed to fit into narrow 3D medical scanner geometries limiting the field of view. It is tested in a clinical setting on the high resolution research tomograph (HRRT), Siemens PET scanner with a head phantom and volunteers. The SL system is compared to a commercial optical tracking system, the Polaris Vicra system, from NDI based on translatory and rotary ground truth motions of the head phantom. The accuracy of the systems was similar, with root mean square (rms) errors of 0.09° for ±20° axial rotations, and rms errors of 0.24 mm for ± 25 mm translations. Tests were made using 1) a light emitting diode (LED) based miniaturized video projector, the Pico projector from Texas Instruments, and 2) a customized version of this projector replacing a visible light LED with a 850 nm near infrared LED. The latter system does not provide additional discomfort by visible light projection into the patient's eyes. The main advantage over existing head motion tracking devices, including the Polaris Vicra system, is that it is not necessary to place markers on the patient. This provides a simpler workflow and eliminates uncertainties related to marker attachment and stability. We show proof of concept of a marker less tracking system especially designed for clinical use with promising results.",
Distributed ADMM for model predictive control and congestion control,"Many problems in control can be modeled as an optimization problem over a network of nodes. Solving them with distributed algorithms provides advantages over centralized solutions, such as privacy and the ability to process data locally. In this paper, we solve optimization problems in networks where each node requires only partial knowledge of the problem's solution. We explore this feature to design a decentralized algorithm that allows a significant reduction in the total number of communications. Our algorithm is based on the Alternating Direction of Multipliers (ADMM), and we apply it to distributed Model Predictive Control (MPC) and TCP/IP congestion control. Simulation results show that the proposed algorithm requires less communications than previous work for the same solution accuracy.","Vectors,
Actuators,
Bipartite graph,
Convergence,
Gradient methods,
Algorithm design and analysis,
Clustering algorithms"
A generalized framework for opening doors and drawers in kitchen environments,"In this paper, we present a generalized framework for robustly operating previously unknown cabinets in kitchen environments. Our framework consists of the following four components: (1) a module for detecting both Lambertian and non-Lambertian (i.e. specular) handles, (2) a module for opening and closing novel cabinets using impedance control and for learning their kinematic models, (3) a module for storing and retrieving information about these objects in the map, and (4) a module for reliably operating cabinets of which the kinematic model is known. The presented work is the result of a collaboration of three PR2 beta sites. We rigorously evaluated our approach on 29 cabinets in five real kitchens located at our institutions. These kitchens contained 13 drawers, 12 doors, 2 refrigerators and 2 dishwashers. We evaluated the overall performance of detecting the handle of a novel cabinet, operating it and storing its model in a semantic map. We found that our approach was successful in 51.9% of all 104 trials. With this work, we contribute a well-tested building block of open-source software for future robotic service applications.","Robot sensing systems,
Kinematics,
Robot kinematics,
Grippers,
Solid modeling,
Trajectory"
Simultaneous MR-Compatible Emission and Transmission Imaging for PET Using Time-of-Flight Information,"Quantitative positron emission tomography (PET) imaging relies on accurate attenuation correction. Predicting attenuation values from magnetic resonance (MR) images is difficult because MR signals are related to proton density and relaxation properties of tissues. Here, we propose a method to derive the attenuation map from a transmission scan. An annulus transmission source is positioned inside the field-of-view of the PET scanner. First a blank scan is acquired. The patient is injected with FDG and placed inside the scanner. 511-keV photons coming from the patient and the transmission source are acquired simultaneously. Time-of-flight information is used to extract the coincident photons originating from the annulus. The blank and transmission data are compared in an iterative reconstruction method to derive the attenuation map. Simulations with a digital phantom were performed to validate the method. The reconstructed attenuation coefficients differ less than 5% in volumes of interest inside the lungs, bone, and soft tissue. When applying attenuation correction in the reconstruction of the emission data a standardized uptake value error smaller than 9% was obtained for all tissues. In conclusion, our method can reconstruct the attenuation map and the emission data from a simultaneous scan without prior knowledge about the anatomy or the attenuation coefficients of the tissues.","Attenuation,
Positron emission tomography,
Image reconstruction,
Photonics,
Data mining,
Timing,
Phantoms"
Feedback Stabilized Interrogation Technique for EFPI/FBG Hybrid Fiber-Optic Pressure and Temperature Sensors,"This paper discusses a Single Wavelength Interrogation (SWI) technique used to measure fast changing pressure related signals and over a large operational temperature range. The novel technique is based on a fiber-optic pressure and temperature hybrid sensor, and a feedback stabilization technique for a tunable laser source. The fiber-optic hybrid sensor consists of a miniature diaphragm based all-silica Extrinsic Fabry-Perot Interferometric (EFPI) Fiber-Optic Pressure Sensor (FOPS) which additionally incorporates a Fiber Bragg Grating (FBG) temperature sensor. The FBG temperature sensor is used as a feedback element to stabilize the output wavelength of the tunable laser source to operate always in the linear range of the EFPI FOPS.",
TAHES: Truthful double Auction for Heterogeneous Spectrums,"Auction is widely applied in wireless communication for spectrum allocation. Most of prior works have assumed that spectrums are identical. In reality, however, spectrums provided by different owners have distinctive characteristics in both spacial and frequency domains. Spectrum availability also varies in different geo-locations. Furthermore, frequency diversity may cause non-identical conflicts among spectrum buyers since different frequencies have distinct communication ranges. Under such realistic scenario, existing spectrum auction schemes cannot provide truthfulness or efficiency. In this paper, we propose a Truthful double Auction for HEterogeneous Spectrum, called TAHES. TAHES allows buyers to explicitly express their personalized preferences for heterogeneous spectrums and also addresses the problem of interference graph variation. We prove that TAHES has nice economic properties including truthfulness, individual rationality and budget balance.","Interference,
Cost accounting,
Availability,
White spaces,
Resource management,
Economics,
Wireless communication"
An Efficient Outpatient Scheduling Approach,Outpatient scheduling is considered as a complex problem. Efficient solutions to this problem are required by many health care facilities. This paper proposes an efficient approach to outpatient scheduling by specifying a bidding method and converting it to a group role assignment problem. The proposed approach is validated by conducting simulations and experiments with randomly generated patient requests for available time slots. The major contribution of this paper is an efficient outpatient scheduling approach making automatic outpatient scheduling practical. The exciting result is due to the consideration of outpatient scheduling as a collaborative activity and the creation of a qualification matrix in order to apply the group role assignment algorithm.,"Simulation,
Schedules,
Dynamic scheduling,
Optimization,
Medical services,
Availability"
A Sign-Component-Based Framework for Chinese Sign Language Recognition Using Accelerometer and sEMG Data,"Identification of constituent components of each sign gesture can be beneficial to the improved performance of sign language recognition (SLR), especially for large-vocabulary SLR systems. Aiming at developing such a system using portable accelerometer (ACC) and surface electromyographic (sEMG) sensors, we propose a framework for automatic Chinese SLR at the component level. In the proposed framework, data segmentation, as an important preprocessing operation, is performed to divide a continuous sign language sentence into subword segments. Based on the features extracted from ACC and sEMG data, three basic components of sign subwords, namely the hand shape, orientation, and movement, are further modeled and the corresponding component classifiers are learned. At the decision level, a sequence of subwords can be recognized by fusing the likelihoods at the component level. The overall classification accuracy of 96.5% for a vocabulary of 120 signs and 86.7% for 200 sentences demonstrate the feasibility of interpreting sign components from ACC and sEMG data and clearly show the superior recognition performance of the proposed method when compared with the previous SLR method at the subword level. The proposed method seems promising for implementing large-vocabulary portable SLR systems.","Shape,
Handicapped aids,
Sensors,
Hidden Markov models,
Electromyography,
Muscles,
Feature extraction"
RGB-(D) scene labeling: Features and algorithms,"Scene labeling research has mostly focused on outdoor scenes, leaving the harder case of indoor scenes poorly understood. Microsoft Kinect dramatically changed the landscape, showing great potentials for RGB-D perception (color+depth). Our main objective is to empirically understand the promises and challenges of scene labeling with RGB-D. We use the NYU Depth Dataset as collected and analyzed by Silberman and Fergus [30]. For RGB-D features, we adapt the framework of kernel descriptors that converts local similarities (kernels) to patch descriptors. For contextual modeling, we combine two lines of approaches, one using a superpixel MRF, and the other using a segmentation tree. We find that (1) kernel descriptors are very effective in capturing appearance (RGB) and shape (D) similarities; (2) both superpixel MRF and segmentation tree are useful in modeling context; and (3) the key to labeling accuracy is the ability to efficiently train and test with large-scale data. We improve labeling accuracy on the NYU Dataset from 56.6% to 76.1%. We also apply our approach to image-only scene labeling and improve the accuracy on the Stanford Background Dataset from 79.4% to 82.9%.",
Gait Recognition Across Various Walking Speeds Using Higher Order Shape Configuration Based on a Differential Composition Model,"Gait has been known as an effective biometric feature to identify a person at a distance. However, variation of walking speeds may lead to significant changes to human walking patterns. It causes many difficulties for gait recognition. A comprehensive analysis has been carried out in this paper to identify such effects. Based on the analysis, Procrustes shape analysis is adopted for gait signature description and relevant similarity measurement. To tackle the challenges raised by speed change, this paper proposes a higher order shape configuration for gait shape description, which deliberately conserves discriminative information in the gait signatures and is still able to tolerate the varying walking speed. Instead of simply measuring the similarity between two gaits by treating them as two unified objects, a differential composition model (DCM) is constructed. The DCM differentiates the different effects caused by walking speed changes on various human body parts. In the meantime, it also balances well the different discriminabilities of each body part on the overall gait similarity measurements. In this model, the Fisher discriminant ratio is adopted to calculate weights for each body part. Comprehensive experiments based on widely adopted gait databases demonstrate that our proposed method is efficient for cross-speed gait recognition and outperforms other state-of-the-art methods.",
Global Convergence of Online BP Training With Dynamic Learning Rate,The online backpropagation (BP) training procedure has been extensively explored in scientific research and engineering applications. One of the main factors affecting the performance of the online BP training is the learning rate. This paper proposes a new dynamic learning rate which is based on the estimate of the minimum error. The global convergence theory of the online BP training procedure with the proposed learning rate is further studied. It is proved that: 1) the error sequence converges to the global minimum error; and 2) the weight sequence converges to a fixed point at which the error function attains its global minimum. The obtained global convergence theory underlies the successful applications of the online BP training procedure. Illustrative examples are provided to support the theoretical analysis.,"Training,
Convergence,
Neural networks,
Educational institutions,
Learning systems,
Neurons,
Algorithm design and analysis"
Zero-Forcing Based MIMO Two-Way Relay with Relay Antenna Selection: Transmission Scheme and Diversity Analysis,"Combining of physical-layer network coding (PNC) and multiple-input multiple-output (MIMO) can significantly improve the performance of the wireless two-way relay network (TWRN). This paper proposes novel Max-Min optimization based relay antenna selection (RAS) schemes for zero-forcing (ZF) based MIMO-PNC transmission. RAS relaxes ZF's constraints on the number of antennas and extends the applications of ZF based MIMO-PNC to more practical scenarios, where the dedicated relay has more antennas than the end node. Moreover, RAS also brings diversity advantages to TWRN and the achievable diversity gains of the proposed schemes are theoretically analyzed. In particular, an equivalence relation is carefully built for the diversity gains obtained by 1) RAS for ZF based MIMO-PNC and 2) transmit antenna selection (TAS) for MIMO broadcasting (BC) with ZF receivers. This equivalence transforms the original problem to a more tractable form which eventually allows explicit analytical results. It is interesting to see that Max-Min RAS keeps the network diversity gain of ZF based MIMO-PNC to be the same as the diversity gain of the point-to-point link within the TWRN. This insight extends the understanding on the behaviors of ZF transceivers with antenna selection (AS) to relatively complicated MIMO-TWRN/BC scenarios.",
Synchronization of Dynamical Networks by Network Control,"In this note, we study locally controlled synchronization of a dynamical network by introducing a distributed controller which has a different network structure from the original network. We refer to this configuration as a feedback network. To reflect practical reality, a cost function is considered to constrain the controller, and then the constrained controller design problem is transformed into a mixed-integer nonlinear optimization problem. In addition, when a single controller cannot be found under the constraint, a switching controller is designed by a Lyapunov function method. The convex combination technique is used to design the synchronizing switching signal between the candidate controllers, and its coefficients are given by the solution of a convex optimization problem. We also provide a feasible way to construct the candidate controllers, and give a numerical example which demonstrates the effectiveness of the proposed results.","Synchronization,
Switches,
Couplings,
Convex functions,
Human computer interaction,
Eigenvalues and eigenfunctions"
A modular approach to soft robots,"This paper describes a modular approach to creating soft robotic systems. The basis of these systems is an elastomeric actuation element powered by direct mechanical energy in the form of pressurized fluids. Fluidic elastomer actuators are fast and inexpensive to fabricate and offer safety and adaptability to robotic systems. Arrangements of these units can yield arbitrarily complex motions and achieve various functionalities. Actuation power can be generated on-board by a pneumatic battery, which harnesses the catalyzed chemical decomposition of hydrogen peroxide into oxygen gas, for mobile implementations. The modular nature of these robots enable distributed sensing and computation elements. Composition techniques of such soft robots are defined. Example systems are demonstrated and analyzed.","Actuators,
Robot sensing systems,
Batteries,
Robot kinematics,
Pneumatic systems"
Real-Time Driver's Stress Event Detection,"In this paper, a real-time methodology for the detection of stress events while driving is presented. The detection is based on the use of physiological signals, i.e., electrocardiogram, electrodermal activity, and respiration, as well as past observations of driving behavior. Features are calculated over windows of specific length and are introduced in a Bayesian network to detect driver's stress events. The accuracy of the stress event detection based only on physiological features, evaluated on a data set obtained in real driving conditions, resulted in an accuracy of 82%. Enhancement of the stress event detection model with the incorporation of driving event information has reduced false positives, yielding an increased accuracy of 96%. Furthermore, our methodology demonstrates good adaptability due to the application of online learning of the model parameters.",
An Extended Visual Cryptography Algorithm for General Access Structures,"Conventional visual secret sharing schemes generate noise-like random pixels on shares to hide secret images. It suffers a management problem, because of which dealers cannot visually identify each share. This problem is solved by the extended visual cryptography scheme (EVCS), which adds a meaningful cover image in each share. However, the previous approaches involving the EVCS for general access structures suffer from a pixel expansion problem. In addition, the visual cryptography (VC)-based approach needs a sophisticated codebook design for various schemes. In this paper, we propose a general approach to solve the above- mentioned problems; the approach can be used for binary secret images in noncomputer-aided decryption environments. The pro- posed approach consists of two phases. In the first phase, based on a given access structure, we construct meaningless shares using an optimization technique and the construction for conventional VC schemes. In the second phase, cover images are added in each share directly by a stamping algorithm. The experimental results indicate that a solution to the pixel expansion problem of the EVCS for GASs is achieved. Moreover, the display quality of the recovered image is very close to that obtained using conventional VC schemes.","Visualization,
Optimization,
Encryption,
Materials,
Facsimile,
Indexes"
Delay-Cognizant Interactive Streaming of Multiview Video With Free Viewpoint Synthesis,"In interactive multiview video streaming (IMVS), a client receives and observes one of many available viewpoints of the same scene and periodically requests from the server view switches to neighboring views, as the video is played back in time uninterruptedly. One key technical challenge is to design a frame coding structure that facilitates periodic view switching and achieves an optimal tradeoff between storage cost and expected transmission rate. In this paper, we first propose three significant improvements over existing IMVS systems and then study the corresponding frame structure optimization. First, using depth-image-based rendering, the new IMVS system enables free viewpoint switching, i.e., by encoding and transmitting both texture and depth maps of captured views, a client can select and synthesize any virtual view from an almost continuum of viewpoints between the left-most and right-most captured views. Second, the IMVS system adopts a more realistic Markovian view-switching model with memory that more accurately captures user behaviors than previous memoryless models . A view-switching model is used in predicting client's future view-switching patterns. Third, assuming that the round-trip-time (RTT) delay during server-client communication is nonnegligible, during an IMVS session, the IMVS system additionally transmits redundant frames RTT into future playback, so that zero-delay view switching can be achieved. Given these improvements, we formalize a new joint optimization of the frame coding structure, transmission schedule, and quantization parameters of the texture and depth maps of multiple camera views. We propose an iterative algorithm to achieve fast and near-optimal solutions. The convergence of the algorithm is also demonstrated. Experimental results show that the proposed optimized rate-allocation method requires 38% lower transmission rate than the fixed rate-allocation scheme. In addition, with the same storage, the transmission rate of the optimized frame structure can be up to 55% lower than that of an I-frame-only structure and 27% lower than that of the structure without distributed source coding frames.",
Real-time human motion tracking using multiple depth cameras,"In this paper, we consider the problem of tracking human motion with a 22-DOF kinematic model from depth images. In contrast to existing approaches, our system naturally scales to multiple sensors. The motivation behind our approach, termed Multiple Depth Camera Approach (MDCA), is that by using several cameras, we can significantly improve the tracking quality and reduce ambiguities as for example caused by occlusions. By fusing the depth images of all available cameras into one joint point cloud, we can seamlessly incorporate the available information from multiple sensors into the pose estimation. To track the high-dimensional human pose, we employ state-of-the-art annealed particle filtering and partition sampling. We compute the particle likelihood based on the truncated signed distance of each observed point to a parameterized human shape model. We apply a coarse-to-fine scheme to recognize a wide range of poses to initialize the tracker. In our experiments, we demonstrate that our approach can accurately track human motion in real-time (15Hz) on a GPGPU. In direct comparison to two existing trackers (OpenNI, Microsoft Kinect SDK), we found that our approach is significantly more robust for unconstrained motions and under (partial) occlusions.","Humans,
Tracking,
Shape,
Sensors,
Joints,
Cameras,
Computational modeling"
"Distributed Barrier Coverage in Wireless Visual Sensor Networks With \beta
-QoM","Wireless visual sensor networks (WVSNs) can not only provide monitoring functions like wireless sensor networks but also capture images of the monitored area. This is why the barrier coverage problem in WVSNs has received attention from many researchers. However, previous research of barrier coverage did not consider breadth of coverage, i.e., the width of collected images. In this paper, we consider breadth to increase the quality of monitor (QoM) of WVSNs. For WVSNs consisting of camera sensors without rotation capability, we propose an algorithm called basic distributed β-breadth belt-barrier construction algorithm without rotation (D-TriB). D-TriB constructs a belt-barrier with β breadth to offer β level of QoM, we call β-QoM. For WVSNs consisting of camera sensors with rotation capability, we propose the enhanced distributed β -breadth belt-barrier construction algorithm with rotation (D-TriBR). The proposed algorithms can not only reduce the number of camera sensors required to construct a barrier but also ensure that any barrier with β-QoM in the network can be identified. Finally, the successful rate of the proposed algorithms under different conditions, including β requirement, sensor distribution, and rotation capability, is also evaluated through simulations.",
A Hierarchical Flight Planning Framework for Air Traffic Management,"The continuous growth of air traffic demand, skyrocketing fuel price, and increasing concerns on safety and environmental impact of air transportation necessitate the modernization of the air traffic management (ATM) system in the United States. The design of such a large-scale networked system that involves complex interactions among automation and human operators poses new challenges for many engineering fields. This paper investigates several important facets of the future ATM system from a systems-level point of view. In particular, we develop a hierarchical decentralized decision architecture that can design 4-D (space +time) path plans for a large number of flights while satisfying weather and capacity constraints of the overall system. The proposed planning framework respects preferences of individual flights and encourages information sharing among different decision makers in the system, and thus has a great potential to reduce traffic delays and weather risks while maintaining safety standards. The framework is validated through a large-scale simulation based on real traffic data over the entire airspace of the contiguous United States. We envision that the hierarchical decentralization approach developed in this paper would also provide useful insights into the design of decision and information hierarchies for other large-scale infrastructure systems.","Cyberspace,
Meteorology,
Aircraft navigation,
Asynchronous transfer mode,
Air traffic control,
Aerospace engineering,
Air safety,
Network topology,
Environmental factors"
On the Joint V2I and V2V Scheduling for Cooperative VANETs With Network Coding,"In the paper, we investigate the information spread problem in a joint vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V) communication system. A scene is considered where more information centers (or base stations) are allocated along the road so that the information centers are able to broadcast timely messages to vehicles within the range of the broadcast signal of each base station, which we shall refer to as broadcast zone . The seamless information spread is used to guarantee that messages are correctly received by each vehicle, regardless of whether it pulls into broadcast zones or not. We first derive the maximum throughput of the V2I downlink system for both additive white Gaussian noise (AWGN) channels and Rayleigh fading channels with Doppler effects. A measurement-based algorithm to estimate the throughput is also proposed. We then discuss the maximum achievable amount of information that can be relayed forward along a vehicular stream. A network coding technique will then be proposed to cancel the interference caused by relay signals to vehicles that are receiving messages from the corresponding information center. These theoretical results will give more insight into the vehicular communication system design.",
Digital Signature-Based Secure Node Disjoint Multipath Routing Protocol for Wireless Sensor Networks,"The objective of energy efficient routing protocol is to increase the operational lifetime of the wireless sensor networks. Multipath routing protocols enhance the lifetime of the wireless sensor networks by distributing traffic among multiple paths instead of a single optimal path. Transmission of secured data is also an important research concern in the wireless sensor networks. In this paper, a secure node disjoint multipath routing protocol for wireless sensor networks is proposed. Here, the data packets are transmitted in a secure manner by using the digital signature crypto system. It is compared with an ad hoc on-demand multipath distance vector routing protocol. It shows better results in terms of packet delivery fraction, energy consumption, and end-to-end delay compared to the ad hoc on-demand multipath distance vector routing.","Routing protocols,
Wireless sensor networks,
Public key cryptography,
Digital signatures"
On the Compound Capacity of a Class of MIMO Channels Subject to Normed Uncertainty,"The compound capacity of uncertain multiple-input multiple-output channels is considered, when the channel is modeled by a class described by a (known) nominal channel and a constrained-norm (unknown) uncertainty. Within this framework, two types of classes are investigated with additive and multiplicative uncertainties subject to a spectral norm constraint, using the singular value decomposition and related singular value inequalities as the main tools. The compound capacity is a maxmin mutual information, representing the capacity of the class, in which the minimization is done over the class of channels while the maximization is done over the transmit covariance. Closed-form solutions for the compound capacity of the classes are obtained and several properties related to transmit and receive eigenvectors are presented. It is shown that, under certain conditions, the compound capacity of the class is equal to the worst-case channel capacity, thus establishing a saddle-point property. Explicit closed-form solutions are given for the worst-case channel uncertainty and the capacity-achieving transmit covariance matrix: the best transmission strategy achieving the compound capacity is a multiple beamforming on the nominal (known) channel eigenmodes with the beam power distribution via the water filling at a degraded SNR. As the uncertainty increases, fewer eigenmodes are used until only the strongest one remains active so that transmit beamforming is an optimal robust transmission strategy in this large-uncertainty regime, for which explicit conditions are given. Using these results, upper and lower bounds of the compound capacity are constructed for other bounded uncertainties and some generic properties are pointed out. The results are extended to compound multiple-access and broadcast channels. In all considered cases, the price to pay for channel uncertainty is an SNR loss (or, equivalently, the nominal channel degradation) commensurate with the uncertainty set radius measured by the spectral norm and the optimal signaling strategy is the transmission on the degraded nominal channel.",
Nonrigid Motion Modeling of the Liver From 3-D Undersampled Self-Gated Golden-Radial Phase Encoded MRI,"Magnetic resonance imaging (MRI) has been commonly used for guiding and planning image guided interventions since it provides excellent soft tissue visualization of anatomy and allows motion modeling to predict the position of target tissues during the procedure. However, MRI-based motion modeling remains challenging due to the difficulty of acquiring multiple motion-free 3-D respiratory phases with adequate contrast and spatial resolution. Here, we propose a novel retrospective respiratory gating scheme from a 3-D undersampled high-resolution MRI acquisition combined with fast and robust image registrations to model the nonrigid deformation of the liver. The acquisition takes advantage of the recently introduced golden-radial phase encoding (G-RPE) trajectory. G-RPE is self-gated, i.e., the respiratory signal can be derived from the acquired data itself, and allows retrospective reconstructions of multiple respiratory phases at any arbitrary respiratory position. Nonrigid motion modeling is applied to predict the liver deformation of an average breathing cycle. The proposed approach was validated on 10 healthy volunteers. Motion model accuracy was assessed using similarity-, surface-, and landmark-based validation methods, demonstrating precise model predictions with an overall target registration error of TRE = 1.70 ± 0.94 mm which is within the range of the acquired resolution.","Image reconstruction,
Three dimensional displays,
Image resolution,
Deformable models,
Splines (mathematics),
Magnetic resonance imaging,
Coils"
Effectiveness of Stressors in Aggressively Scaled FinFETs,"The stress transfer efficiency (STE) and impact of process-induced stress on carrier mobility enhancement in aggressively scaled FinFETs are studied for different stressor technologies, substrate types, and gate-stack formation processes. TCAD simulations show that strained-source/drain STE is 1.5× larger for bulk FinFETs than for SOI FinFETs. Although a gate-last process substantially enhances longitudinal stress within the channel region, it provides very little improvement in electron mobility over that achieved with a gate-first process. Guidelines for FinFET stressor technology optimization are provided, and performance enhancement trends for future technology nodes are projected.",
Characterizing geospatial dynamics of application usage in a 3G cellular data network,"Recent studies on cellular network measurement have provided the evidence that significant geospatial correlations, in terms of traffic volume and application access, exist in cellular network usage. Such geospatial correlation patterns provide local optimization opportunities to cellular network operators for handling the explosive growth in the traffic volume observed in recent years. To the best of our knowledge, in this paper, we provide the first fine-grained characterization of the geospatial dynamics of application usage in a 3G cellular data network. Our analysis is based on two simultaneously collected traces from the radio access network (containing location records) and the core network (containing traffic records) of a tier-1 cellular network in the United States. To better understand the application usage in our data, we first cluster cell locations based on their application distributions and then study the geospatial dynamics of application usage across different geographical regions. The results of our measurement study present cellular network operators with fine-grained insights that can be leveraged to tune network parameter settings.","Indexes,
Geospatial analysis,
Land mobile radio cellular systems,
IP networks,
Computer architecture,
Electronic mail,
Optimization"
Equation Environment Coupling and Interference on the Electric-Field Intrabody Communication Channel,"Wearableand implantable medical sensors have been investigated continuously in recent years to provide better diagnostics and monitoring for personal health care. Much attention has been drawn to the establishment of the ubiquitous body area network (BAN) to reliably connect the body sensors and collect the sensor data in real time. Electric-held intrabody communication (EF-IBC) is a promising physical link technology for the body area network. Compared to existing wireless technologies, EF-IBC hts the body characteristics better and is able to achieve higher data rate with less transmission power. EF-IBC relies on the parasitic capacitive coupling between the transmitter and the receiver to close the signal circuit loop. With this parasitic coupling, EF-IBC links can be influenced by the environment. However until now, there is lack of systematic research on various environment coupling effects to the EF-IBC channel. In this paper, environment effects on the EF-IBC channel are comprehensively studied. The interference from the nearby EF-IBC channel is investigated for the first time to gain useful insights into the establishment of the BAN with EF-IBC. The FEM model is also established to explain the mechanism of the capacitive return path.","Finite element methods,
Couplings,
Electrodes,
Capacitors,
Copper,
Capacitance,
Interference"
Automated Capture of Experiment Context for Easier Reproducibility in Computational Research,"Published scientific research that relies on numerical computations is too often not reproducible. For computational research to become consistently and reliably reproducible, the process must become easier to achieve, as part of day-to-day research. A combination of best practices and automated tools can make it easier to create reproducible research.",
Qi-ferry: Energy-constrained wireless charging in wireless sensor networks,"Using the technology of wireless energy transfer, the paper proposes Qi-ferry which physically carries energy, roves a wireless sensor network, and wirelessly charges sensor nodes to extend their lifetime. To optimize the usage of the entire energy reserve on a Qi-ferry, both the movement of the Qi-ferry itself and its wireless charging of sensor nodes share the same pool of battery energy reserve, resulting in a tradeoff between how many sensors the Qi-ferry could charge and how far it could travel. The paper formulates an energy-constrained Qi-ferry wireless charging problem in wireless sensor networks, which maximizes the number of sensors wirelessly charged by a Qi-ferry subject to an energy constraint limiting the total energy consumed by the Qi-ferry for both moving and charging. Due to the NP-hardness of the problem, the paper proposes heuristic solutions based on the meta-heuristics of Particle Swarm Optimization. Evaluation results validate the effectiveness of the solutions.","Wireless sensor networks,
Wireless communication,
Batteries,
Ad hoc networks,
Energy exchange,
Heuristic algorithms,
Energy consumption"
Input Power Factor Compensation for High-Power CSC Fed PMSM Drive Using d -Axis Stator Current Control,"In this paper, an input power factor compensation method is proposed for a high-power pulse-width-modulated current-source-converter (CSC)-fed permanent magnet synchronous motor (PMSM) drive system. The proposed method is based on controlling the d-axis stator current component in the field-oriented control (FOC) scheme of the drive system. The CSC-fed PMSM drive system and its FOC scheme are first introduced. Then, the relationships between the machine side, dc-link, and the line side are investigated. Based on the analysis, a new d-axis stator current control scheme that can ensure unity input power factor for the operating speed range is proposed. The main feature of the proposed scheme is to compensate the line-side power factor without the need for modulation index control in either the rectifier or the inverter. Therefore, offline Selective Harmonic Elimination (SHE) modulation schemes can be implemented on both line- and machine-side converters to minimize the total harmonic distortion. This results in reduced switching frequency and reduced switching losses. Simulation results for a 2.44 MW medium-voltage system and experimental results from a low-voltage 6.5 kW IPM motor drive are provided to verify the effectiveness of the proposed compensation method.","Stators,
Reactive power,
Modulation,
Rectifiers,
Capacitors,
Power harmonic filters,
Rotors"
Low-Energy Standby-Sparing for Hard Real-Time Systems,"Time-redundancy techniques are commonly used in real-time systems to achieve fault tolerance without incurring high energy overhead. However, reliability requirements of hard real-time systems that are used in safety-critical applications are so stringent that time-redundancy techniques are sometimes unable to achieve them. Standby sparing as a hardware-redundancy technique can be used to meet high reliability requirements of safety-critical applications. However, conventional standby-sparing techniques are not suitable for low-energy hard real-time systems as they either impose considerable energy overheads or are not proper for hard timing constraints. In this paper we provide a technique to use standby sparing for hard real-time systems with limited energy budgets. The principal contribution of this paper is an online energy-management technique which is specifically developed for standby-sparing systems that are used in hard real-time applications. This technique operates at runtime and exploits dynamic slacks to reduce the energy consumption while guaranteeing hard deadlines. We compared the low-energy standby-sparing (LESS) system with a low-energy time-redundancy system (from a previous work). The results show that for relaxed time constraints, the LESS system is more reliable and provides about 26% energy saving as compared to the time-redundancy system. For tight deadlines when the time-redundancy system is not sufficiently reliable (for safety-critical application), the LESS system preserves its reliability but with about 49% more energy consumption.",
Understanding collective crowd behaviors: Learning a Mixture model of Dynamic pedestrian-Agents,"In this paper, a new Mixture model of Dynamic pedestrian-Agents (MDA) is proposed to learn the collective behavior patterns of pedestrians in crowded scenes. Collective behaviors characterize the intrinsic dynamics of the crowd. From the agent-based modeling, each pedestrian in the crowd is driven by a dynamic pedestrian-agent, which is a linear dynamic system with its initial and termination states reflecting a pedestrian's belief of the starting point and the destination. Then the whole crowd is modeled as a mixture of dynamic pedestrian-agents. Once the model is unsupervisedly learned from real data, MDA can simulate the crowd behaviors. Furthermore, MDA can well infer the past behaviors and predict the future behaviors of pedestrians given their trajectories only partially observed, and classify different pedestrian behaviors in the scene. The effectiveness of MDA and its applications are demonstrated by qualitative and quantitative experiments on the video surveillance dataset collected from the New York Grand Central Station.",
Detection and Localization of Tissue Malignancy Using Contrast-Enhanced Microwave Imaging: Exploring Information Theoretic Criteria,"We present a new approach to the problem of detecting cancerous tissues at low-to-medium signal-to-noise ratios (SNRs) in an interference-prone biological medium, where the dielectric properties of the surrounding heterogeneous healthy tissues are comparable to those of the tumors. Suppose that microwave contrast agents, such as microbubbles or nanocomposites, are selectively delivered to the cancer site via systemic administration, and the difference between the backscatter responses (differential signal) before and after the administration of contrast medium to the tissue anomalies can be extracted. We can then formulate the problem from the perspective of signal model selection. Subsequently, two information theoretic criteria (ITC), namely the Akaike information criterion (AIC) and the minimum description length (MDL), are applied as a blind method to reliably detect the malignant tumor and estimate its location using ITC-oriented strategies. Finally, numerical examples based on a 2-D canonical biological phantom, which synthesizes an interference-prone microwave imaging scenario, are carried out to evaluate the performance of the proposed ITC-based algorithms. The dielectric properties of the phantom are varied to investigate diagnostics of three types of dysplastic tissues: liver, lung, and breast cancers. We also use a 3-D anatomically realistic breast model as a testbed to verify the effectiveness of the proposed method.",
Frequency Dependence of Alpha-Particle Induced Soft Error Rates of Flip-Flops in 40-nm CMOS Technology,"In this paper, the alpha-particle induced soft error rate of two flip-flops are investigated as a function of operating frequency between 80 MHz and 1.2 GHz. The two flip-flops-an unhardened D flip-flop and a hardened pseudo-DICE flip-flop were designed in a TSMC 40 nm bulk CMOS technology. The error rates of both flip-flops increase with frequency. Analyses show that an internal single-event transient based upset mechanism is responsible for the frequency dependence of the error rates.",
A hybrid system for reducing the false alarm rate of anomaly intrusion detection system,"In this paper, we propose a hybrid intrusion detection system that combines k-Means, and two classifiers: K-nearest neighbor and Naïve Bayes for anomaly detection. It consists of selecting features using an entropy based feature selection algorithm which selects the important attributes and removes the irredundant attributes. This algorithm operates on the KDD-99 Data set; this data set is used worldwide for evaluating the performance of different intrusion detection systems. The next step is clustering phase using k-Means. We have used the KDD99 (knowledge Discovery and Data Mining) intrusion detection contest. This system can detect the intrusions and further classify them into four categories: Denial of Service (DoS), U2R (User to Root), R2L (Remote to Local), and probe. The main goal is to reduce the false alarm rate of IDS1.","Intrusion detection,
Classification algorithms,
Clustering algorithms,
Training,
Probes,
Accuracy,
Data mining"
A compact model for double-gate tunneling field-effect-transistors and its implications on circuit behaviors,"A compact model for tunneling field-effect-transistors (TFETs) is presented. The model includes a band-to-band tunneling (BTBT) current module and a terminal charge module. TCAD simulations show that the model describes TFETs currents and capacitances accurately. The model is implemented into a circuit simulator and used to simulate TFETs logic circuits and SRAMs. Unique features in TEFTs including large overshoot during switching, long delay and uni-directional conduction are demonstrated.","Integrated circuit modeling,
Tunneling,
Logic gates,
Semiconductor device modeling,
Capacitance,
Electric potential,
Transistors"
New Classes of Frequency-Hopping Sequences With Optimal Partial Correlation,"In this paper, the partial Hamming correlation properties of frequency-hopping sequences (FHSs) are discussed. The Peng-Fan bounds on sets of FHSs are generalized to the case of partial correlation. Both individual FHSs with optimal partial autocorrelation and sets of FHSs with optimal partial correlation are presented. The former has more new parameters compared with the known individual FHSs with optimal partial autocorrelation, while the later is obtained in the literature for the first time.","Correlation,
Arrays,
Educational institutions,
Equations,
Periodic structures,
Electronic mail,
Mobile communication"
A Mathematical Framework for Analyzing Adaptive Incentive Protocols in P2P Networks,"In peer-to-peer (P2P) networks, incentive protocol is used to encourage cooperation among end-nodes so as to deliver a scalable and robust service. However, the design and analysis of incentive protocols have been ad hoc and heuristic at best. The objective of this paper is to provide a simple yet general framework to analyze and design incentive protocols. We consider a class of incentive protocols that can learn and adapt to other end-nodes' strategies. Based on our analytical framework, one can evaluate the expected performance gain and, more importantly, the system robustness of a given incentive protocol. To illustrate the framework, we present two adaptive learning models and three incentive policies and show the conditions in which the P2P networks may collapse and the conditions in which the P2P networks can guarantee a high degree of cooperation. We also show the connection between evaluating incentive protocol and evolutionary game theory so one can easily identify robustness characteristics of a given policy. Using our framework, one can gain the understanding on the price of altruism and system stability, as well as the correctness of the adaptive incentive policy.",
A Local 3-D Motion Descriptor for Multi-View Human Action Recognition from 4-D Spatio-Temporal Interest Points,"In this paper, we address the problem of human action recognition in reconstructed 3-D data acquired by multi-camera systems. We contribute to this field by introducing a novel 3-D action recognition approach based on detection of 4-D (3-D space
+
time) spatio-temporal interest points (STIPs) and local description of 3-D motion features. STIPs are detected in multi-view images and extended to 4-D using 3-D reconstructions of the actors and pixel-to-vertex correspondences of the multi-camera setup. Local 3-D motion descriptors, histogram of optical 3-D flow (HOF3D), are extracted from estimated 3-D optical flow in the neighborhood of each 4-D STIP and made view-invariant. The local HOF3D descriptors are divided using 3-D spatial pyramids to capture and improve the discrimination between arm- and leg-based actions. Based on these pyramids of HOF3D descriptors we build a bag-of-words (BoW) vocabulary of human actions, which is compressed and classified using agglomerative information bottleneck (AIB) and support vector machines (SVMs), respectively. Experiments on the publicly available i3DPost and IXMAS datasets show promising state-of-the-art results and validate the performance and view-invariance of the approach.","Three dimensional displays,
Humans,
Feature extraction,
Optical imaging,
Shape,
Solid modeling,
Cameras"
Optimal Beaconing Control for Epidemic Routing in Delay-Tolerant Networks,"Owing to the uncertainty of transmission opportunities between mobile nodes, the routing in delay-tolerant networks (DTNs) exploits the mechanism of opportunistic forwarding. Energy-efficient algorithms and policies for DTN are crucial to maximizing the message delivery probability while reducing the delivery cost. In this contribution, we investigate the problem of energy-efficient optimal beaconing control in a DTN. We model the message dissemination under variable beaconing rate with a continuous-time Markov model. Based on this model, we then formulate the optimization problem of the optimal beaconing control for epidemic routing and obtain the optimal threshold policy from the solution of this optimization problem. Furthermore, through extensive numerical results, we demonstrate that the proposed optimal threshold policy significantly outperforms the static policy with constant beaconing rate in terms of system energy consumption savings.",
A Generic Framework for Video Annotation via Semi-Supervised Learning,"Learning-based video annotation is essential for video analysis and understanding, and many various approaches have been proposed to avoid the intensive labor costs of purely manual annotation. However, there lacks a generic framework due to several difficulties, such as dependence of domain knowledge, insufficiency of training data, no precise localization and in efficacy for large-scale video dataset. In this paper, we propose a novel approach based on semi-supervised learning by means of information from the Internet for interesting event annotation in videos. Concretely, a Fast Graph-based Semi-Supervised Multiple Instance Learning (FGSSMIL) algorithm, which aims to simultaneously tackle these difficulties in a generic framework for various video domains (e.g., sports, news, and movies), is proposed to jointly explore small-scale expert labeled videos and large-scale unlabeled videos to train the models. The expert labeled videos are obtained from the analysis and alignment of well-structured video related text (e.g., movie scripts, web-casting text, close caption). The unlabeled data are obtained by querying related events from the video search engine (e.g., YouTube, Google) in order to give more distributive information for event modeling. Two critical issues of FGSSMIL are: (1) how to calculate the weight assignment for a graph construction, where the weight of an edge specifies the similarity between two data points. To tackle this problem, we propose a novel Multiple Instance Learning Induced Similarity (MILIS) measure by learning instance sensitive classifiers; (2) how to solve the algorithm efficiently for large-scale dataset through an optimization approach. To address this issue, Concave-Convex Procedure (CCCP) and nonnegative multiplicative updating rule are adopted. We perform the extensive experiments in three popular video domains: movies, sports, and news. The results compared with the state-of-the-arts are promising and demonstrate the effectiveness and efficiency of our proposed approach.",
Reproducible Research for Scientific Computing: Tools and Strategies for Changing the Culture,This article considers the obstacles involved in creating reproducible computational research as well as some efforts and approaches to overcome them.,"Hidden Markov models,
Research and development,
Scientific computing,
Computational complexity,
Reproducibility of results"
Scientific Storytelling Using Visualization,"Scientists frequently tell stories using visualizations of scientific data, in the process of disseminating findings to peers and the general public. However, techniques and methods for effective scientific storytelling have received little attention so far. This article explores how literary and theatrical narrative conventions can inform the design and presentation of visualizations, and discusses the challenges of adapting scientific visualizations for broader audiences. It also summarizes recent workshops' findings on the role of storytelling in visualizations, and presents several examples of successful scientific-storytelling production teams. The conclusion is that scientific storytelling deserves greater support and recognition by the visualization community.","Information resources,
Knowledge transfer,
Science (general),
Data visualization"
RSVP keyboard: An EEG based typing interface,"Humans need communication. The desire to communicate remains one of the primary issues for people with locked-in syndrome (LIS). While many assistive and augmentative communication systems that use various physiological signals are available commercially, the need is not satisfactorily met. Brain interfaces, in particular, those that utilize event related potentials (ERP) in electroencephalography (EEG) to detect the intent of a person noninvasively, are emerging as a promising communication interface to meet this need where existing options are insufficient. Existing brain interfaces for typing use many repetitions of the visual stimuli in order to increase accuracy at the cost of speed. However, speed is also crucial and is an integral portion of peer-to-peer communication; a message that is not delivered timely often looses its importance. Consequently, we utilize rapid serial visual presentation (RSVP) in conjunction with language models in order to assist letter selection during the brain-typing process with the final goal of developing a system that achieves high accuracy and speed simultaneously. This paper presents initial results from the RSVP Keyboard system that is under development. These initial results on healthy and locked-in subjects show that single-trial or few-trial accurate letter selection may be possible with the RSVP Keyboard paradigm.","Electroencephalography,
Brain models,
Keyboards,
Accuracy,
Visualization,
Brain computer interfaces"
Effective Software Fault Localization Using an RBF Neural Network,"We propose the application of a modified radial basis function neural network in the context of software fault localization, to assist programmers in locating bugs effectively. This neural network is trained to learn the relationship between the statement coverage information of a test case and its corresponding execution result, success or failure. The trained network is then given as input a set of virtual test cases, each covering a single statement. The output of the network, for each virtual test case, is considered to be the suspiciousness of the corresponding covered statement. A statement with a higher suspiciousness has a higher likelihood of containing a bug, and thus statements can be ranked in descending order of their suspiciousness. The ranking can then be examined one by one, starting from the top, until a bug is located. Case studies on 15 different programs were conducted, and the results clearly show that our proposed technique is more effective than several other popular, state of the art fault localization techniques. Further studies investigate the robustness of the proposed technique, and illustrate how it can easily be applied to programs with multiple bugs as well.","Neurons,
Biological neural networks,
Computer bugs,
Radial basis function networks,
Training,
Software,
Context"
Weakly Supervised Graph Propagation Towards Collective Image Parsing,"In this work, we propose a weakly supervised graph propagation method to automatically assign the annotated labels at image level to those contextually derived semantic regions. The graph is constructed with the over-segmented patches of the image collection as nodes. Image-level labels are imposed on the graph as weak supervision information over subgraphs, each of which corresponds to all patches of one image, and the contextual information across different images at patch level are then mined to assist the process of label propagation from images to their descendent regions. The ultimate optimization problem is efficiently solved by Convex Concave Programming (CCCP). Extensive experiments on four benchmark datasets clearly demonstrate the effectiveness of our proposed method for the task of collective image parsing. Two extensions including image annotation and concept map based image retrieval demonstrate the proposed image parsing algorithm can effectively aid other vision tasks.",
Mining User Movement Behavior Patterns in a Mobile Service Environment,"Mobile service systems offer users useful information ubiquitously via mobile devices. Based on changeable user movement behavior patterns (UMBPs), mobile service systems have the capability of effectively mining a special request from abundant data. In this paper, UMBPs are studied in terms of the problem of mining matching mobile access patterns based on joining the following four kinds of characteristics, U, L, T, and S, where U is the mobile user, L is the movement location, T is the dwell time in the timestamp, and S is the service request. By introducing standard graph-matching algorithms along with the primitives of a database management system, which comprises grouping, sorting, and joining, these joint operations are defined. Moreover, by mining the associated structure via maximum weight bipartite graph matching, a prediction mechanism, based on the model of UMBPs, is utilized to find strong relationships among U , L, T , and S. In addition, a PC-based experimental evaluation under various simulation conditions, using synthetically generated data, is introduced. Finally, performance studies are conducted to show that, in terms of execution efficiency and scalability, the proposed procedures produced excellent performance results.","Mobile communication,
Data mining,
Databases,
Pattern matching,
Tin,
Web services,
Prediction algorithms"
Image Retrieval in Forensics: Tattoo Image Database Application,"In this article, we took an unsupervised approach in designing appropriate similarity measures to explicitly address the challenge arising from low-quality tattoo image matching. In the future, we plan to improve the matching algorithm by exploring both super- vised and semisupervised learning algorithms. Besides tattoos, other types of soft forensic evidence can be collected and managed in the form of images, such as shoe prints and gang graffiti images. Although Tattoo-ID focuses on tattoo image matching and retrieval, the underlying techniques developed in the Tattoo-ID system can be adopted to other forensic image databases.15 Other types of soft forensic image evidence might include shoeprints and gang graffiti images. In the future, we plan to extend the Tattoo-ID system to different application domains.","Iris recognition,
Forensics,
Digital forensics,
Image retrieval,
Fingerprint recognition,
Content management"
Toward cloud-based grasping with uncertainty in shape: Estimating lower bounds on achieving force closure with zero-slip push grasps,"This paper explores how Cloud Computing can facilitate grasping with shape uncertainty. We consider the most common robot gripper: a pair of thin parallel jaws, and a class of objects that can be modeled as extruded polygons. We model a conservative class of push-grasps that can enhance object alignment. The grasp planning algorithm takes as input an approximate object outline and Gaussian uncertainty around each vertex and center of mass. We define a grasp quality metric based on a lower bound on the probability of achieving force closure. We present a highly-parallelizable algorithm to compute this metric using Monte Carlo sampling. The algorithm uses Coulomb frictional grasp mechanics and a fast geometric test for conservative conditions for force closure. We run the algorithm on a set of sample shapes and compare the grasps with those from a planner that does not model shape uncertainty. We report computation times with single and multi-core computers and sensitivity analysis on algorithm parameters. We also describe physical grasp experiments using the Willow Garage PR2 robot.",
Integrating Graph Partitioning and Matching for Trajectory Analysis in Video Surveillance,"In order to track moving objects in long range against occlusion, interruption, and background clutter, this paper proposes a unified approach for global trajectory analysis. Instead of the traditional frame-by-frame tracking, our method recovers target trajectories based on a short sequence of video frames, e.g., 15 frames. We initially calculate a foreground map at each frame obtained from a state-of-the-art background model. An attribute graph is then extracted from the foreground map, where the graph vertices are image primitives represented by the composite features. With this graph representation, we pose trajectory analysis as a joint task of spatial graph partitioning and temporal graph matching. The task can be formulated by maximizing a posteriori under the Bayesian framework, in which we integrate the spatio-temporal contexts and the appearance models. The probabilistic inference is achieved by a data-driven Markov chain Monte Carlo algorithm. Given a period of observed frames, the algorithm simulates an ergodic and aperiodic Markov chain, and it visits a sequence of solution states in the joint space of spatial graph partitioning and temporal graph matching. In the experiments, our method is tested on several challenging videos from the public datasets of visual surveillance, and it outperforms the state-of-the-art methods.",
Tree Formation with Physical Layer Security Considerations in Wireless Multi-Hop Networks,"Physical layer security has emerged as a promising technique that complements existing cryptographic approaches and enables the securing of wireless transmissions against eavesdropping. In this paper, the impact of optimizing physical layer security metrics on the architecture and interactions of the nodes in multi-hop wireless networks is studied. In particular, a game-theoretic framework is proposed using which a number of nodes interact and choose their optimal and secure communication paths in the uplink of a wireless multi-hop network, in the presence of eavesdroppers. To this end, a tree formation game is formulated in which the players are the wireless nodes that seek to form a network graph among themselves while optimizing their multi-hop secrecy rates or the path qualification probabilities, depending on their knowledge of the eavesdroppers' channels. To solve this game, a distributed tree formation algorithm is proposed and is shown to converge to a stable Nash network. Simulation results show that the proposed approach yields significant performance gains in terms of both the average bottleneck secrecy rate per node and the average path qualification probability per node, relative to classical best-channel algorithms and the single-hop star network. The results also assess the properties and characteristics of the resulting Nash networks.","Network security,
Game theory,
Spread spectrum communication,
Communication system security,
Physical layer,
Fading channels"
A blind deconvolution approach to ultrasound imaging,"In this paper, a single-input multiple-output (SIMO) channel model is introduced for the deconvolution process of ultrasound imaging; the ultrasound pulse is the single system input and tissue reflectivity functions are the channel impulse responses. A sparse regularized blind deconvolution model is developed by projecting the tissue reflectivity functions onto the null space of a cross-relation matrix and projecting the ultrasound pulse onto a low-resolution space. In this way, the computational load is greatly reduced and the estimation accuracy can be improved because the proposed deconvolution model contains fewer variables. Subsequently, an alternating direction method of multipliers (ADMM) algorithm is introduced to efficiently solve the proposed blind de convolution problem. Finally, the performance of the proposed blind deconvolution method is examined using both computer simulated data and practical in vitro and in vivo data. The results show a great improvement in the quality of ultrasound images in terms of signal-to-noise ratio and spatial resolution gain.","Ultrasonic imaging,
Deconvolution,
Reflectivity,
Imaging,
Vectors,
Null space,
Frequency domain analysis"
CLive: Cloud-assisted P2P live streaming,"Peer-to-peer (P2P) video streaming is an emerging technology that reduces the barrier to stream live events over the Internet. Unfortunately, satisfying soft real-time constraints on the delay between the generation of the stream and its actual delivery to users is still a challenging problem. Bottlenecks in the available upload bandwidth, both at the media source and inside the overlay network, may limit the quality of service (QoS) experienced by users. A potential solution for this problem is assisting the P2P streaming network by a cloud computing infrastructure to guarantee a minimum level of QoS. In such approach, rented cloud resources (helpers) are added on demand to the overlay, to increase the amount of total available bandwidth and the probability of receiving the video on time. Hence, the problem to be solved becomes minimizing the economical cost, provided that a set of constraints on QoS is satisfied. The main contribution of this paper is CLIVE, a cloud-assisted P2P live streaming system that demonstrates the feasibility of these ideas. CLIVE estimates the available capacity in the system through a gossip-based aggregation protocol and provisions the required resources from the cloud to guarantee a given level of QoS at low cost. We perform extensive simulations and evaluate CLIVE using large-scale experiments under dynamic realistic settings.","Peer to peer computing,
Streaming media,
Bandwidth,
Protocols,
Quality of service,
Delay,
Probability density function"
FlashTrie: Beyond 100-Gb/s IP Route Lookup Using Hash-Based Prefix-Compressed Trie,"It is becoming apparent that the next-generation IP route lookup architecture needs to achieve speeds of 100 Gb/s and beyond while supporting IPv4 and IPv6 with fast real-time updates to accommodate ever-growing routing tables. Some of the proposed multibit-trie-based schemes, such as TreeBitmap, have been used in today's high-end routers. However, their large data structures often require multiple external memory accesses for each route lookup. A pipelining technique is widely used to achieve high-speed lookup with the cost of using many external memory chips. Pipelining also often leads to poor memory load-balancing. In this paper, we propose a new IP route lookup architecture called FlashTrie that overcomes the shortcomings of the multibit-trie-based approaches. We use a hash-based membership query to limit off-chip memory accesses per lookup and to balance memory utilization among the memory modules. By compacting the data structure size, the lookup depth of each level can be increased. We also develop a new data structure called Prefix-Compressed Trie that reduces the size of a bitmap by more than 80%. Our simulation and implementation results show that FlashTrie can achieve 80-Gb/s worst-case throughput while simultaneously supporting 2 M prefixes for IPv4 and 318 k prefixes for IPv6 with one lookup engine and two Double-Data-Rate (DDR3) SDRAM chips. When implementing five lookup engines on a state-of-the-art field programmable gate array (FPGA) chip and using 10 DDR3 memory chips, we expect FlashTrie to achieve 1-Gpps (packet per second) throughput, equivalent to 400 Gb/s for IPv4 and 600 Gb/s for IPv6. FlashTrie also supports incremental real-time updates.","IP networks,
Data structures,
Memory management,
System-on-a-chip,
Random access memory,
Routing,
Pipelines"
AgileRegulator: A hybrid voltage regulator scheme redeeming dark silicon for power efficiency in a multicore architecture,"The widening gap between the fast-increasing transistor budget but slow-growing power delivery and system cooling capability calls for novel architectural solutions to boost energy efficiency. Leveraging the fact of surging “dark silicon” area, we propose a hybrid scheme to use both on-chip and off-chip voltage regulators, called “AgileRegulator”, for a multicore system to explore both coarse-grain and fine-grain power phases. We present two complementary algorithms: Sensitivity-Aware Application Scheduling (SAAS) and Responsiveness-Aware Application Scheduling (RAAS) to maximally achieve the energy saving potential of the hybrid regulator scheme. Experimental results show that the hybrid scheme achieves performance-energy efficiency close to per-core DVFS, without imposing much design cost. Meanwhile, the silicon overhead of this scheme is well contained into the “dark silicon”. Unlike other application specific schemes based on accelerators, the proposed scheme itself is a simple and universal solution for chip area and energy trade-offs.","System-on-a-chip,
Regulators,
Silicon,
Bandwidth,
Memory management,
Tuning,
Multicore processing"
"Integrating Instance Selection, Instance Weighting, and Feature Weighting for Nearest Neighbor Classifiers by Coevolutionary Algorithms","Cooperative coevolution is a successful trend of evolutionary computation which allows us to define partitions of the domain of a given problem, or to integrate several related techniques into one, by the use of evolutionary algorithms. It is possible to apply it to the development of advanced classification methods, which integrate several machine learning techniques into a single proposal. A novel approach integrating instance selection, instance weighting, and feature weighting into the framework of a coevolutionary model is presented in this paper. We compare it with a wide range of evolutionary and nonevolutionary related methods, in order to show the benefits of the employment of coevolution to apply the techniques considered simultaneously. The results obtained, contrasted through nonparametric statistical tests, show that our proposal outperforms other methods in the comparison, thus becoming a suitable tool in the task of enhancing the nearest neighbor classifier.","Training,
Proposals,
Accuracy,
Data mining,
Genetic algorithms,
Learning systems,
Concrete"
Unsupervised Locating of WiFi Access Points Using Smartphones,"WiFi positioning systems require radio maps in the form of either RF fingerprints or positions of WiFi access points (APs). In particular, knowledge of the AP positions is essential to enable a locating mechanism as well as to understand the nature of underlying WiFi networks, such as density, connectivity, interference characteristics, and so on. In this paper, we propose an approach called Serendipity, which locates WiFi APs in an unsupervised manner using radio scans collected by ordinary smartphone users. From the radio scans, we extract dissimilarities between all pairs of WiFi APs and estimate relative positions of APs by analyzing the dissimilarities based on a multidimensional scaling technique. We then find the absolute positions with additional radio scans whose positions are known. The discovered positions of WiFi APs are used for the positioning of smartphones or the management of the WiFi networks. To validate the proposed approach, we conducted experiments on several indoor locations.",
Single-Image Refocusing and Defocusing,"In this paper, we present a postprocessing method to tackle the single-image refocusing-and-defocusing problem. The proposed method can accomplish the tasks of focus-map estimation and image refocusing and defocusing. Given an image with a mixture of focused and defocused objects, we first detect the edges and then estimate the focus map based on the edge blurriness, which is depicted explicitly by a parametric model. The image refocusing problem is addressed in a blind deconvolution framework, where the image prior is modeled by using both global and local constraints. In particular, we correct the defocused blurry edges to sharp ones with the aid of the parametric edge model and then render this cue as a local prior to ensure the sharpness of the refocused image. Experimental results demonstrate that the proposed method performs well in producing visually plausible images with different focus effects from a single input.","Image edge detection,
Pixel,
Estimation,
Lenses,
Apertures,
Cameras,
Deconvolution"
A Dual-Channel Compass/GPS/GLONASS/Galileo Reconfigurable GNSS Receiver in 65 nm CMOS With On-Chip I/Q Calibration,"A fully integrated dual-channel reconfigurable GNSS receiver supporting Compass/GPS/GLONASS/Galileo systems is implemented in 65 nm CMOS. The receiver incorporates two independent channels to receive dual-frequency signals simultaneously. GNSS signals located at the 1.2 GHz or 1.6 GHz bands are supported, with their bandwidths programmable among 2.2 MHz, 4.2 MHz, 8 MHz, 10 MHz, and 18 MHz. By implementing a flexible frequency plan with a low/zero-IF architecture and reconfigurable analog baseband circuits, only one frequency synthesizer is required to provide the local oscillator (LO) frequency for two channels, thereby avoiding any LO crosstalk. Analog baseband circuits employ operational amplifiers that are capable of power scaling, in order to minimize power consumption across different operating modes. An I/Q mismatch calibration module placed prior to the complex-IF bandpass filter is implemented to improve the image rejection ratio. The receiver achieves a minimum 1.88 dB noise figure, an average 50 dB image rejection ratio, and a 64 dB dynamic range with 1 dB steps of gain-adjustment, with a total power consumption of 31-44 mW. Finally, experimental verification combining both the receiver and a digital baseband shows a positioning result comparable to commercial chips.","Noise,
Global Navigation Satellite Systems,
Receivers,
Gain,
Global Positioning System,
Bandwidth,
Compass"
SORT-SGM: Subpixel Optimized Real-Time Semiglobal Matching for Intelligent Vehicles,"The suitability of stereo algorithms for intelligent vehicle applications is conditioned by their ability to compute dense accurate disparity maps in real time. In this paper, an original stereo reconstruction system that is designed for automotive applications is presented. The system is based on the semiglobal matching algorithm (SGM), which is widely known for its high quality and potential for real-time implementation. Several improvements that target the matching, disparity optimization, and disparity refinement steps are proposed. Pixel-level matching uses the census transform because of its invariance to intensity differences due to camera bias or gain that affects the images. The huge memory bandwidth requirements for the SGM disparity optimization step are reduced through a new integration strategy. At the subpixel level, accuracy is increased by devising a new methodology for generating dedicated subpixel interpolation functions. Using this methodology, two novel subpixel interpolation functions for the SGM algorithm are implemented and evaluated. The proposed algorithm has been implemented on a graphics processing unit in the Compute Unified Device Architecture (CUDA). The result is an increased speed and accuracy algorithm profiled for complex real-traffic scenarios. The proposed algorithm has been evaluated at a large scale, and evidence that was collected from both standard benchmarks and real-world images confirm the findings and show a significant improvement over existing solutions.",
A Semi-Markov Model for Mitosis Segmentation in Time-Lapse Phase Contrast Microscopy Image Sequences of Stem Cell Populations,"We propose a semi-Markov model trained in a max-margin learning framework for mitosis event segmentation in large-scale time-lapse phase contrast microscopy image sequences of stem cell populations. Our method consists of three steps. First, we apply a constrained optimization based microscopy image segmentation method that exploits phase contrast optics to extract candidate subsequences in the input image sequence that contains mitosis events. Then, we apply a max-margin hidden conditional random field (MM-HCRF) classifier learned from human-annotated mitotic and nonmitotic sequences to classify each candidate subsequence as a mitosis or not. Finally, a max-margin semi-Markov model (MM-SMM) trained on manually-segmented mitotic sequences is utilized to reinforce the mitosis classification results, and to further segment each mitosis into four predefined temporal stages. The proposed method outperforms the event-detection CRF model recently reported by Huh as well as several other competing methods in very challenging image sequences of multipolar-shaped C3H10T1/2 mesenchymal stem cells. For mitosis detection, an overall precision of 95.8% and a recall of 88.1% were achieved. For mitosis segmentation, the mean and standard deviation for the localization errors of the start and end points of all mitosis stages were well below 1 and 2 frames, respectively. In particular, an overall temporal location error of 0.73 ±1.29 frames was achieved for locating daughter cell birth events.","Hidden Markov models,
Image segmentation,
Feature extraction,
Microscopy,
Image sequences,
Markov processes,
Mathematical model"
"Semantic Object Maps for robotic housework - representation, acquisition and use","In this article we investigate the representation and acquisition of Semantic Objects Maps (SOMs) that can serve as information resources for autonomous service robots performing everyday manipulation tasks in kitchen environments. These maps provide the robot with information about its operation environment that enable it to perform fetch and place tasks more efficiently and reliably. To this end, the semantic object maps can answer queries such as the following ones: “What do parts of the kitchen look like?”, “How can a container be opened and closed?”, “Where do objects of daily use belong?”, “What is inside of cupboards/drawers?”, etc. The semantic object maps presented in this article, which we call SOM+, extend the first generation of SOMs presented by Rusu et al. [1] in that the representation of SOM+ is designed more thoroughly and that SOM+ also include knowledge about the appearance and articulation of furniture objects. Also, the acquisition methods for SOM+ substantially advance those developed in [1] in that SOM+ are acquired autonomously and with low-cost (Kinect) instead of very accurate (laser-based) 3D sensors. In addition, perception methods are more general and are demonstrated to work in different kitchen environments.","Robot sensing systems,
Refrigerators"
Tracking and Pairing Vehicle Headlight in Night Scenes,"Traffic surveillance is an important topic in computer vision and intelligent transportation systems and has intensively been studied in the past decades. However, most of the state-of-the-art methods concentrate on daytime traffic monitoring. In this paper, we propose a nighttime traffic surveillance system, which consists of headlight detection, headlight tracking and pairing, and camera calibration and vehicle speed estimation. First, a vehicle headlight is detected using a reflection intensity map and a reflection suppressed map based on the analysis of the light attenuation model. Second, the headlight is tracked and paired by utilizing a simple yet effective bidirectional reasoning algorithm. Finally, the trajectories of the vehicle's headlight are employed to calibrate the surveillance camera and estimate the vehicle's speed. Experimental results on typical sequences show that the proposed method can robustly detect, track, and pair the vehicle headlight in night scenes. Extensive quantitative evaluations and related comparisons demonstrate that the proposed method outperforms state-of-the-art methods.",
Compressive Light Field Sensing,"We propose a novel design for light field image acquisition based on compressive sensing principles. By placing a randomly coded mask at the aperture of a camera, incoherent measurements of the light passing through different parts of the lens are encoded in the captured images. Each captured image is a random linear combination of different angular views of a scene. The encoded images are then used to recover the original light field image via a novel Bayesian reconstruction algorithm. Using the principles of compressive sensing, we show that light field images with a large number of angular views can be recovered from only a few acquisitions. Moreover, the proposed acquisition and recovery method provides light field images with high spatial resolution and signal-to-noise-ratio, and therefore is not affected by limitations common to existing light field camera designs. We present a prototype camera design based on the proposed framework by modifying a regular digital camera. Finally, we demonstrate the effectiveness of the proposed system using experimental results with both synthetic and real images.","Apertures,
Cameras,
Compressed sensing,
Lenses,
Spatial resolution"
Scandate Dispenser Cathode Fabrication for A High-Aspect-Ratio High-Current-Density Sheet Beam Electron Gun,A high-current-density scandate tungsten dispenser cathode was used for the demonstration of a 25 : 1-aspect-ratio 750-A/cm2 -current-density sheet beam for the Defence Advanced Research Project Agency High-Frequency Integrated Vacuum Electronics (HiFIVE) program intended for the realization of a wideband ( ~ 30%) 220-GHz traveling wave tube. The elliptical cathode with homogeneous microstructure was made from 1-2-μm-size tungsten powder added with nanosized Scandia using the sol-gel method; it has a current density of up to 160 A/cm2 at 1050 °C. A sheet beam gun analyzer was built to test the terahertz sheet beam gun and determine the size and current density of a sheet electron beam produced by the impregnated scandate tungsten dispenser cathode. A sheet electron beam with an aspect ratio of 12.5 : 1 with a current density exceeding 375 A/cm2 has been obtained using a BVERI impregnated scandate dispenser cathode without magnetic compression; further magnetic field compression would give the final current density of 750 A/cm2.,
Integrating depth and color cues for dense multi-resolution scene mapping using RGB-D cameras,"The mapping of environments is a prerequisite for many navigation and manipulation tasks. We propose a novel method for acquiring 3D maps of indoor scenes from a freely moving RGB-D camera. Our approach integrates color and depth cues seamlessly in a multi-resolution map representation. We consider measurement noise characteristics and exploit dense image neighborhood to rapidly extract maps from RGB-D images. An efficient ICP variant allows maps to be registered in real-time at VGA resolution on a CPU. For simultaneous localization and mapping, we extract key views and optimize the trajectory in a probabilistic framework. Finally, we propose an efficient randomized loop-closure technique that is designed for on-line operation. We benchmark our method on a publicly available RGB-D dataset and compare it with a state-of-the-art approach that uses sparse image features.","Cameras,
Image resolution,
Trajectory,
Image color analysis,
Simultaneous localization and mapping,
Real-time systems"
A model predictive control approach to the load shifting problem in a household equipped with an energy storage unit,"This paper deals with the load shifting problem in a household equipped with smart appliances and an energy storage unit with conversion losses. The problem is faced by establishing an event driven Model Predictive Control framework aiming to meet the real life dynamics of a household and to keep low the impact of the control system on the total electric energy consumption. The proposed approach allows the consumer to minimize the daily energy cost in scenarios characterized by Time of Use tariffs and Demand Side Management, by dynamically evaluating the best time to run of the appliances and the optimal evolution of the battery level of charge. A proper set of realistic simulations validates the proposed approach, showing the relevance of the energy storage unit in the domestic load shifting architecture.","Home appliances,
Optimal control,
Energy storage,
Strontium,
Load modeling,
Optimization,
Erbium"
Control lyapunov functions and hybrid zero dynamics,"Hybrid zero dynamics extends the Byrnes-Isidori notion of zero dynamics to a class of hybrid models called systems with impulse effects. Specifically, given a smooth submanifold that is contained in the zero set of an output function and is invariant under both the continuous flow of the system with impulse effects as well as its reset map, the restriction dynamics is called the hybrid zero dynamics. Prior results on the stabilization of periodic orbits of the hybrid zero dynamics have relied on input-output linearization of the transverse variables. The principal result of this paper shows how control Lyapunov functions can be used to exponentially stabilize periodic orbits of the hybrid zero dynamics, thereby significantly extending the class of stabilizing controllers. An illustration of this result on a model of a bipedal walking robot is provided.",
Multi-Modal Image Registration Based on Gradient Orientations of Minimal Uncertainty,"In this paper, we propose a new multi-scale technique for multi-modal image registration based on the alignment of selected gradient orientations of reduced uncertainty. We show how the registration robustness and accuracy can be improved by restricting the evaluation of gradient orientation alignment to locations where the uncertainty of fixed image gradient orientations is minimal, which we formally demonstrate correspond to locations of high gradient magnitude. We also embed a computationally efficient technique for estimating the gradient orientations of the transformed moving image (rather than resampling pixel intensities and recomputing image gradients). We have applied our method to different rigid multi-modal registration contexts. Our approach outperforms mutual information and other competing metrics in the context of rigid multi-modal brain registration, where we show sub-millimeter accuracy with cases obtained from the retrospective image registration evaluation project. Furthermore, our approach shows significant improvements over standard methods in the highly challenging clinical context of image guided neurosurgery, where we demonstrate misregistration of less than 2 mm with relation to expert selected landmarks for the registration of pre-operative brain magnetic resonance images to intra-operative ultrasound images.",
Energy-Based Swing-Up Control for a Remotely Driven Acrobot: Theoretical and Experimental Results,"This brief concerns the energy-based swing-up control for a remotely driven acrobot (RDA) which is a 2-link planar robot with the first link being underactuated and the second link being remotely driven by an actuator mounted at a fixed base through a belt. An energy-based swing-up controller is designed via the Lyapunov stability theory. A global motion analysis of the RDA under the designed controller is provided focusing on the behavior of the closed-loop solution and the stability of the closed-loop equilibrium points. The conditions on control parameters for achieving a successful swing-up control are given. Furthermore, an experimental setup is described and experimental results are given to validate the presented theoretical results. The energy-based swing-up controller for the RDA is shown to be effective both theoretically and practically.","Robots,
Switches,
Actuators,
Belts,
Joints,
Torque"
Optimal Control of Wireless Networks With Finite Buffers,"This paper considers network control for wireless networks with finite buffers. We investigate the performance of joint flow control, routing, and scheduling algorithms that achieve high network utility and deterministically bounded backlogs inside the network. Our algorithms guarantee that buffers inside the network never overflow. We study the tradeoff between buffer size and network utility and show that under the one-hop interference model, if internal buffers have size (N-1)/(2 \epsilon)
, then \epsilon
-optimal network utility can be achieved, where \epsilon
is a control parameter and N
is the number of network nodes. The underlying scheduling/routing component of the considered control algorithms requires ingress queue length information (IQI) at all network nodes. However, we show that these algorithms can achieve the same utility performance with delayed ingress queue length information at the cost of a larger average backlog bound. We also show how to extend the results to other interference models and to wireless networks with time-varying link quality. Numerical results reveal that the considered algorithms achieve nearly optimal network utility with a significant reduction in queue backlog compared to existing algorithms in the literature.","Throughput,
Routing,
Optimization,
Wireless networks,
Interference,
Delay,
Scheduling algorithm"
"Performance Assessment and Design for Univariate Alarm Systems Based on FAR, MAR, and AAD","The performance of a univariate alarm system can be assessed in many cases by three indices, namely, the false alarm rate (FAR), missed alarm rate (MAR), and averaged alarm delay (AAD). First, this paper studies the definition and computation of the FAR, MAR, and AAD for the basic mechanism of alarm generation solely based on a trip point, and for the advanced mechanism of alarm generation by exploiting alarm on/off delays. Second, a systematic design of alarm systems is investigated based on the three performance indices and the tradeoffs among them. The computation of FAR, MAR, and AAD and the design of alarm systems require the probability density functions (PDFs) of the univariate process variable in the normal and abnormal conditions. Thus, a new method based on mean change detection is proposed to estimate the two PDFs. Numerical examples and an industrial case study are provided to validate the obtained theoretical results on the FAR, MAR and AAD, and to illustrate the proposed performance assessment and alarm system design procedures.","Alarm systems,
Delay,
Markov processes,
Probability density function,
Monitoring,
Mathematical model"
"Outage Analysis of Multihop Relay Systems in Interference-Limited Nakagami-
m
Fading Channels","In this paper, we study the outage probability of multihop transmission systems with amplify-and-forward (AF) and decode-and-forward (DF) relaying protocols operating over a Nakagami-m fading environment in the presence of cochannel interference. We consider the case of interference-limited relays with ideal AF relay gains based on the inverse of the fading amplitude of the desired signal in the previous link. For an arbitrary but fixed number of Nakagami-distributed interferers per hop, we derive a closed-form expression for the outage probability of an N-hop AF relaying system in terms of the multivariate Lauricella function FB(N) that can be evaluated with commonly available computer software. Moreover, the outage performance of an N-hop DF relaying system is also derived in closed form, and the two performances are compared. Simulation results are also provided to demonstrate the accuracy of the analytical expressions.","Relays,
Rayleigh channels,
Analytical models,
Simulation,
Interchannel interference"
Multimodal Video Indexing and Retrieval Using Directed Information,"We propose a novel framework for multimodal video indexing and retrieval using shrinkage optimized directed information assessment (SODA) as similarity measure. The directed information (DI) is a variant of the classical mutual information which attempts to capture the direction of information flow that videos naturally possess. It is applied directly to the empirical probability distributions of both audio-visual features over successive frames. We utilize RASTA-PLP features for audio feature representation and SIFT features for visual feature representation. We compute the joint probability density functions of audio and visual features in order to fuse features from different modalities. With SODA, we further estimate the DI in a manner that is suitable for high dimensional features p and small sample size n (large p small n ) between pairs of video-audio modalities. We demonstrate the superiority of the SODA approach in video indexing, retrieval, and activity recognition as compared to the state-of-the-art methods such as hidden Markov models (HMM), support vector machine (SVM), cross-media indexing space (CMIS), and other noncausal divergence measures such as mutual information (MI). We also demonstrate the success of SODA in audio and video localization and indexing/retrieval of data with missaligned modalities.","Indexing,
Visualization,
Hidden Markov models,
Humans,
Joints,
Mutual information,
Support vector machines"
Short-Circuit Fault Protection Strategy for High-Power Three-Phase Three-Wire Inverter,"This paper proposes a four-stage fault protection scheme against the short-circuit fault for the high-power three-phase three-wire combined inverter to achieve high reliability. The short-circuit fault on the load side is the focus of this paper, and the short-circuit fault of switching devices is not involved. Based on the synchronous rotating frame, the inverter is controlled as a voltage source in the normal state. When a short-circuit fault (line-to-line fault or balanced three-phase fault) occurs, the hardware-circuit-based hysteresis current control strategy can effectively limit the output currents and protect the switching devices from damage. In the meantime, the software controller detects the fault and switches to the current controlled mode. Under the current controlled state, the inverter behaves as a current source until the short-circuit fault is cleared by the circuit breaker. After clearing the fault, the output voltage recovers quickly from the current controlled state. Therefore, the selective protection is realized and the critical loads can be continuously supplied by the inverter. The operational principle, design consideration, and implementation are discussed in this paper. The simulation and experimental results are provided to verify the validity of theoretical analysis.","Circuit faults,
Inverters,
Switches,
Circuit breakers,
Impedance,
Hysteresis,
Voltage control"
Generative Bayesian Image Super Resolution With Natural Image Prior,"We propose a new single image super resolution (SR) algorithm via Bayesian modeling with a natural image prior modeled by a high-order Markov random field (MRF). SR is one of the long-standing and active topics in image processing community. It is of great use in many practical applications, such as astronomical observation, medical imaging, and the adaptation of low-resolution contents onto high-resolution displays. One category of the conventional approaches for image SR is formulating the problem with Bayesian modeling techniques and then obtaining its maximum-a-posteriori solution, which actually boils down to a regularized regression task. Although straightforward, this approach cannot exploit the full potential offered by the probabilistic modeling, as only the posterior mode is sought. On the other hand, current Bayesian SR approaches using the posterior mean estimation typically use very simple prior models for natural images to ensure the computational tractability. In this paper, we present a Bayesian image SR approach with a flexible high-order MRF model as the prior for natural images. The minimum mean square error (MMSE) criteria are used for estimating the HR image. A Markov chain Monte Carlo-based sampling algorithm is presented for obtaining the MMSE solution. The proposed method cannot only enjoy the benefits offered by the flexible prior, but also has the advantage of making use of the probabilistic modeling to perform a posterior mean estimation, thus is less sensitive to the local minima problem as the MAP solution. Experimental results indicate that the proposed method can generate competitive or better results than state-of-the-art SR algorithms.","Strontium,
Bayesian methods,
Image resolution,
Estimation,
Computational modeling,
Image edge detection,
Probabilistic logic"
Compact Printed Multiband Antenna With Independent Setting Suitable for Fixed and Reconfigurable Wireless Communication Systems,"This paper presents the design of a low-profile compact printed antenna for fixed frequency and reconfigurable frequency bands. The antenna consists of a main patch, four sub-patches, and a ground plane to generate five frequency bands, at 0.92, 1.73, 1.98, 2.4, and 2.9 GHz, for different wireless systems. For the fixed-frequency design, the five individual frequency bands can be adjusted and set independently over the wide ranges of 18.78%, 22.75%, 4.51%, 11%, and 8.21%, respectively, using just one parameter of the antenna. By putting a varactor (diode) at each of the sub-patch inputs, four of the frequency bands can be controlled independently over wide ranges and the antenna has a reconfigurable design. The tunability ranges for the four bands of 0.92, 1.73, 1.98, and 2.9 GHz are 23.5%, 10.30%, 13.5%, and 3%, respectively. The fixed and reconfigurable designs are studied using computer simulation. For verification of simulation results, the two designs are fabricated and the prototypes are measured. The results show a good agreement between simulated and measured results.","Antennas,
Varactors,
Resonant frequency,
Tuning,
Voltage measurement,
Antenna measurements"
A semantics aware approach to automated reverse engineering unknown protocols,"Extracting the protocol message format specifications of unknown applications from network traces is important for a variety of applications such as application protocol parsing, vulnerability discovery, and system integration. In this paper, we propose ProDecoder, a network trace based protocol message format inference system that exploits the semantics of protocol messages without the executable code of application protocols. ProDecoder is based on the key insight that the n-grams of protocol traces exhibit highly skewed frequency distribution that can be leveraged for accurate protocol message format inference. In ProDecoder, we first discover the latent relationship among n-grams by first grouping protocol messages with the same semantics and then inferring message formats by keyword based clustering and cluster sequence alignment. We implemented and evaluated ProDecoder to infer message format specifications of SMB (a binary protocol) and SMTP (a textual protocol). Our experimental results show that ProDecoder accurately parses and infers SMB protocol with 100% precision and recall. For SMTP, ProDecoder achieves approximately 95% precision and recall.",
Automated annotation of coral reef survey images,"With the proliferation of digital cameras and automatic acquisition systems, scientists can acquire vast numbers of images for quantitative analysis. However, much image analysis is conducted manually, which is both time consuming and prone to error. As a result, valuable scientific data from many domains sit dormant in image libraries awaiting annotation. This work addresses one such domain: coral reef coverage estimation. In this setting, the goal, as defined by coral reef ecologists, is to determine the percentage of the reef surface covered by rock, sand, algae, and corals; it is often desirable to resolve these taxa at the genus level or below. This is challenging since the data exhibit significant within class variation, the borders between classes are complex, and the viewpoints and image quality vary. We introduce Moorea Labeled Corals, a large multi-year dataset with 400,000 expert annotations, to the computer vision community, and argue that this type of ecological data provides an excellent opportunity for performance benchmarking. We also propose a novel algorithm using texture and color descriptors over multiple scales that outperforms commonly used techniques from the texture classification literature. We show that the proposed algorithm accurately estimates coral coverage across locations and years, thereby taking a significant step towards reliable automated coral reef image annotation.","Image color analysis,
Algae,
Benchmark testing,
Histograms,
Computer vision,
Vectors,
Shape"
Peak-Error-Constrained Sparse FIR Filter Design Using Iterative SOCP,"In this paper, a novel algorithm is proposed to design sparse FIR filters. It is known that this design problem is highly nonconvex due to the existence of -norm of a filter coefficient vector in its objective function. To tackle this difficulty, an iterative procedure is developed to search a potential sparsity pattern, which is then used to compute the final solution by solving a convex optimization problem. In each iterative step, the original sparse filter design problem is successively transformed to a simpler subproblem. It can be proved that under a weak condition, globally optimal solutions of these subproblems can be attained by solving their dual problems. In this case, the overall iterative procedure converges to a locally optimal solution of the original design problem. The design procedure described above can be repeated for several times to further improve the sparsity of design results. The output of the previous stage can be used as the initial point of the subsequent design. The performance of the proposed algorithm is evaluated by two sets of design examples, and compared to other sparse FIR filter design algorithms.",
TruCentive: A game-theoretic incentive platform for trustworthy mobile crowdsourcing parking services,"The shortage of parking in crowded urban areas causes severe societal problems such as traffic congestion, environmental pollution, and many others. Recently, crowdsourced parking, where smartphone users are exploited to collect realtime parking availability information, has attracted significant attention. However, existing crowdsourced parking information systems suffer from low user participation rate and data quality due to the lack of carefully designed incentive schemes. In this paper, we address the incentive problem of trustworthy crowdsourced parking information systems by presenting an incentive platform named TruCentive, where high utility parking data can be obtained from unreliable crowds of mobile users. Our contribution is three-fold. First, we provide hierarchical incentives to stimulate the participation of mobile users for contributing parking information. Second, by introducing utility-related incentives, our platform encourages participants to contribute high utility data and thereby enhances the quality of collected data. Third, our active confirmation scheme validates the parking information utility by game-theoretically formulated incentive protocols. The active confirming not only validates the utility of contributed data but re-sells the high utility data as well. Our evaluation through user study on Amazon Mechanical Turk and simulation study demonstrate the feasibility and stability of TruCentive incentive platform.","Availability,
Protocols,
Mobile communication,
Incentive schemes,
Vehicles,
Sensors,
Equations"
A multilevel inverter with reduced number of switches,"A multilevel inverter is a power electronic device that is used for high voltage and high power applications, with the added advantages of low switching stress and lower total harmonic distortion (THD), hence reducing the size and bulk of the passive filters. This paper proposes a new topology of a cascaded multilevel inverter that utilizes less number of switches than the conventional topology. Therefore with less number of switches in the circuit, there will be a reduction in the gate driver circuits and also in effect fewer switches will be conducting for specific intervals of time. The circuitry consists of smaller multilevel inverter blocks connected in series to achieve its characteristic output waveform. A seven level inverter will be simulated with the implementation of PWM techniques and its effect on the harmonic spectrum will be analyzed. The system will be modelled with the help of MATLAB/SIMULINK.","Inverters,
Pulse width modulation,
Topology,
Power harmonic filters,
Harmonic analysis,
Switches,
Time frequency analysis"
Energy-efficient intrusion detection with a barrier of probabilistic sensors,"Intrusion detection is a significant application in wireless sensor networks (WSNs). S. Kumar et al have introduced the concept of barrier coverage, which deploys sensors in a narrow belt region to guarantee that any intrusion across the region is to be detected. However, the practical issues have not been investigated such as scheduling sensors energy-efficiently while guaranteeing the detection probability of any intrusion across the region based on probabilistic sensing model, which is a more realistic sensing model. Besides, the intruders may be humans, animals, fighter planes or other things, which obviously have diverse moving speeds. In this paper, we analyze the detection probability of arbitrary path across the barrier of sensors theoretically and take the maximum speed of possible intruders into consideration since the sensor networks are designed for different intruders in different scenarios. Based on the theoretical analysis of detection probability, we formulate a Minimum Weight ∈-Barrier Problem about how to schedule sensors energy-efficiently. We show the problem NP-hard and propose a bounded approximation algorithm, called Minimum Weight Barrier Algorithm (MWBA) to schedule the activation of sensors. To evaluate our design, we analyze the performance of MWBA theoretically and also perform extensive simulations to demonstrate the effectiveness of our proposed algorithm.","Wireless sensor networks,
Probabilistic logic,
Belts,
Sensor phenomena and characterization,
Image edge detection,
Algorithm design and analysis"
Voronoi Tessellation Based Interpolation Method for Wi-Fi Radio Map Construction,"The fingerprint-based approach for positioning in WLAN has been drawing great attention these days. However, the approach usually requires tremendous time and efforts to collect location fingerprints for the target area. In this paper, we propose an interpolation method based on Voronoi tessellation to significantly reduce such calibration efforts and to improve accuracy. Unlike other interpolation methods, our method refines the propagation model for each cell of the target area tessellated by a higher-order Voronoi diagram. Consequently, our method can take into account the signal fading caused by walls and obstacles more accurately. The proposed method significantly outperformed other interpolation methods in accuracy.","Interpolation,
Buildings,
Fading,
IEEE 802.11 Standards,
Accuracy,
Calibration,
Wireless LAN"
Design and Exploration of Low-Power Analog to Information Conversion Based on Compressed Sensing,"The long-standing analog-to-digital conversion paradigm based on Shannon/Nyquist sampling has been challenged lately, mostly in situations such as radar and communication signal processing where signal bandwidth is so large that sampling architectures constraints are simply not manageable. Compressed sensing (CS) is a new emerging signal acquisition/compression paradigm that offers a striking alternative to traditional signal acquisition. Interestingly, by merging the sampling and compression steps, CS also removes a large part of the digital architecture and might thus considerably simplify analog-to-information (A2I) conversion devices. This so-called “analog CS,” where compression occurs directly in the analog sensor readout electronics prior to analog-to-digital conversion, could thus be of great importance for applications where bandwidth is moderate, but computationally complex, and power resources are severely constrained. In our previous work (Mamaghanian, 2011), we quantified and validated the potential of digital CS systems for real-time and energy-efficient electrocardiogram compression on resource-constrained sensing platforms. In this paper, we review the state-of-the-art implementations of CS-based signal acquisition systems and perform a complete system-level analysis for each implementation to highlight their strengths and weaknesses regarding implementation complexity, performance and power consumption. Then, we introduce the spread spectrum random modulator pre-integrator (SRMPI), which is a new design and implementation of a CS-based A2I read-out system that uses spread spectrum techniques prior to random modulation in order to produce the low rate set of digital samples. Finally, we experimentally built an SRMPI prototype to compare it with state-of-the-art CS-based signal acquisition systems, focusing on critical system design parameters and constraints, and show that this new proposed architecture offers a compelling alternative, in particular for low power and computationally-constrained embedded systems.","Sensors,
Demodulation,
Electrocardiography,
Bandwidth,
Computer architecture,
Compressed sensing,
Spread spectrum communication"
Multi-Agent System-Based Real-Time Load Management for All-Electric Ship Power Systems in DC Zone Level,"All-electric ship power systems have finite generation and include a large portion of dynamic loads and nonlinear loads relative to the total power capacity. Therefore, the load demand and power generation of the system should be matched in real-time. In this paper, a novel multi-agent system-based real-time load management technique is proposed to optimally determine the switch status of loads in DC zones while satisfying the operating constraints of the system in real-time. The multi-agent system cooperative control protocol is developed based on a proposed reduced-order agent model and artificial potential function of the multi-agent system, which aims to maximize the energized loads in the all-electric ship power system. The cooperative controller aims to cooperatively achieve the group objectives that are difficult to reach by centralized controller. Further, simulation results verify the viability and performance of the proposed technique in PSCAD/EMTDC software.",
Neuromorphic Adaptive Plastic Scalable Electronics: Analog Learning Systems,This article provides an overview of the HRL Systems of Neuromorphic Adaptive Plastic Scalable Electronics (SyNAPSE) project and progress made thus far. The multifaceted SyNAPSE program seeks to advance the state of the art in biological algorithms and in developing a new generation of neuromorphic electronic machines necessary for the efficient implementation of these algorithms by drawing inspiration from biology.The fundamental premise of the HRL team to develop brain architecture and related tools has been to recognize that there was a sequence of evolutionary events by which the brain architecture evolved from a primitive brain into a modern brain.,"Research and development,
Intelligent systems,
Neuromorphics,
Artificial intelligence,
Biological system modeling,
Adaptive systems,
Complexity theory,
Programmable control"
Incentive-based coordinated charging control of plug-in electric vehicles at the distribution-transformer level,"Distribution utilities are becoming increasingly aware that their networks may struggle to accommodate large numbers of plug-in electric vehicles (PEVs). In particular, uncoordinated overnight charging is expected to be problematic, as the corresponding aggregated power demand exceeds the capacity of most distribution substation transformers. In this paper, a dynamical model of PEVs served by a single temperature-constrained substation transformer is presented and a centralized scheduling scheme is formulated to coordinate charging of a heterogeneous PEV fleet. We employ the dual-ascent method to derive an iterative, incentive-based and non-centralized implementation of the PEV charging algorithm, which is optimal upon convergence. Then, the distributed open-loop problem is embedded in a predictive control scheme to introduce robustness against disturbances. Simulations of an overnight charging scenario illustrate the effectiveness of the so-obtained incentive-based coordinated PEV control scheme in terms of performance and enforcing the transformer's thermal constraint.","System-on-a-chip,
Vehicles,
Tin,
Batteries,
Power transformer insulation,
Vectors,
Power demand"
Assessment of Stereoscopic Crosstalk Perception,"Stereoscopic three-dimensional (3-D) services do not always prevail when compared with their two-dimensional (2-D) counterparts, though the former can provide more immersive experience with the help of binocular depth. Various specific 3-D artefacts might cause discomfort and severely degrade the Quality of Experience (QoE). In this paper, we analyze one of the most annoying artefacts in the visualization stage of stereoscopic imaging, namely, crosstalk, by conducting extensive subjective quality tests. A statistical analysis of the subjective scores reveals that both scene content and camera baseline have significant impacts on crosstalk perception, in addition to the crosstalk level itself. Based on the observed visual variations during changes in significant factors, three perceptual attributes of crosstalk are summarized as the sensorial results of the human visual system (HVS). These are shadow degree, separation distance, and spatial position of crosstalk. They are classified into two categories: 2-D and 3-D perceptual attributes, which can be described by a Structural SIMilarity (SSIM) map and a filtered depth map, respectively. An objective quality metric for predicting crosstalk perception is then proposed by combining the two maps. The experimental results demonstrate that the proposed metric has a high correlation (over 88%) when compared with subjective quality scores in a wide variety of situations.","Crosstalk,
Three dimensional displays,
Stereo image processing,
Measurement,
Silver,
Visualization,
Cameras"
Estimating Android applications' CPU energy usage via bytecode profiling,"Optimizing the energy efficiency of mobile applications can greatly increase user satisfaction. However, developers lack easily applied tools for estimating the energy consumption of their applications. This paper proposes a new approach, eCalc, that is lightweight in terms of its developer requirements and provides code-level estimates of energy consumption. The approach achieves this using estimation techniques based on program analysis of the mobile application. In evaluation, eCalc is able to estimate energy consumption within 9.5% of the ground truth for a set of mobile applications. Additionally, eCalc provides useful and meaningful feedback to the developer that helps to characterize energy consumption of the application.","Energy consumption,
Software,
Accuracy,
Benchmark testing,
Hardware,
Monitoring,
Energy measurement"
A Complete Processing Chain for Shadow Detection and Reconstruction in VHR Images,"The presence of shadows in very high resolution (VHR) images can represent a serious obstacle for their full exploitation. This paper proposes to face this problem as a whole through the proposal of a complete processing chain, which relies on various advanced image processing and pattern recognition tools. The first key point of the chain is that shadow areas are not only detected but also classified to allow their customized compensation. The detection and classification tasks are implemented by means of the state-of-the-art support vector machine approach. A quality check mechanism is integrated in order to reduce subsequent misreconstruction problems. The reconstruction is based on a linear regression method to compensate shadow regions by adjusting the intensities of the shaded pixels according to the statistical characteristics of the corresponding nonshadow regions. Moreover, borders are explicitly handled by making use of adaptive morphological filters and linear interpolation for the prevention of possible border artifacts in the reconstructed image. Experimental results obtained on three VHR images representing different shadow conditions are reported, discussed, and compared with two other reconstruction techniques.","Image reconstruction,
Interpolation,
Image color analysis,
Telecommunications,
Indexes,
Image resolution,
Image restoration"
Abnormal crowd behavior detection based on social attribute-aware force model,"In this paper, a novel social attribute-aware force model is presented for abnormal crowd pattern detection in video sequences. We take social characteristics of crowd behaviors into account in order to improve the effectiveness of the simulation on the interaction behaviors of the crowd. A quick unsupervised method is proposed to estimate the scene scale. Both the social disorder attribute and congestion attribute are introduced to describe the realistic social behaviors by using statistical context feature. Through the semantic attribute-aware enhancement, we obtain an improved model on the basis of social force. We validate our method in public available datasets for abnormal detection, and the experimental results show promising performance compared with other state of the art methods.",
Alternating Minimization Algorithm for Speckle Reduction With a Shifting Technique,"Speckles (multiplicative noise) in synthetic aperture radar (SAR) make it difficult to interpret the observed image. Due to the edge-preserving feature of total variation (TV), variational models with TV regularization have attracted much interest in reducing speckles. Algorithms based on the augmented Lagrangian function have been proposed to efficiently solve speckle-reduction variational models with TV regularization. However, these algorithms require inner iterations or inverses involving the Laplacian operator at each iteration. In this paper, we adapt Tseng's alternating minimization algorithm with a shifting technique to efficiently remove the speckle without any inner iterations or inverses involving the Laplacian operator. The proposed method is very simple and highly parallelizable; therefore, it is very efficient to despeckle huge-size SAR images. Numerical results show that our proposed method outperforms the state-of-the-art algorithms for speckle-reduction variational models with a TV regularizer in terms of central-processing-unit time.",
Low-Power Pulse-Triggered Flip-Flop Design With Conditional Pulse-Enhancement Scheme,"In this paper, a novel low-power pulse-triggered flip-flop (FF) design is presented. First, the pulse generation control logic, an and function, is removed from the critical path to facilitate a faster discharge operation. A simple two-transistor and gate design is used to reduce the circuit complexity. Second, a conditional pulse-enhancement technique is devised to speed up the discharge along the critical path only when needed. As a result, transistor sizes in delay inverter and pulse-generation circuit can be reduced for power saving. Various postlayout simulation results based on UMC CMOS 90-nm technology reveal that the proposed design features the best power-delay-product performance in seven FF designs under comparison. Its maximum power saving against rival designs is up to 38.4%. Compared with the conventional transmission gate-based FF design, the average leakage power consumption is also reduced by a factor of 3.52.","Transistors,
Clocks,
Delay,
Pulse generation,
Power demand,
Latches,
Inverters"
Monotone Centroid Flow Algorithm for Type Reduction of General Type-2 Fuzzy Sets,"Recently, type-2 fuzzy logic systems (T2 FLSs) have received increased research attention due to their potential to model and cope with the dynamic uncertainties ubiquitous in many engineering applications. However, because of the complex nature and the computational intensity of the inference process, only the constrained version of T2 FLSs, i.e., the interval T2 FLSs, was typically used. Fortunately, the very recently introduced concepts of α-planes and zSlices allow for efficient representation, as well as a computationally fast inference process, with general T2 (GT2) FLSs. This paper addresses the type-reduction phase in GT2 FLSs, using GT2 fuzzy sets (FSs) represented in the α-plane framework. The monotone property of centroids of a set of α-planes is derived and leveraged toward developing a simple to implement but fast algorithm for type reduction of GT2 FSs - i.e., the monotone centroid flow (MCF) algorithm. When compared with the centroid flow (CF) algorithm, which was previously developed by Zhai and Mendel, the MCF algorithm features the following advantages. 1) The MCF algorithm computes numerically identical centroid as the Karnik-Mendel (KM) iterative algorithms, unlike the approximated centroid which is obtained with the CF algorithm; 2) the MCF algorithm is faster than the CF algorithm, as well as the independent application of the KM algorithms; 3) the MCF algorithm is easy to implement, unlike the CF algorithm, which requires computation of the derivatives of the centroid; and 4) the MCF algorithm completely eliminates the need to apply the KM iterative procedure to any α-planes of the GT2 FS. The performance of the algorithm is presented on benchmark problems and compared with other type-reduction techniques that are available in the literature.",
High-Voltage Modular Power Supply Using Parallel and Series Configurations of Flyback Converter for Pulsed Power Applications,"To cover wide range of pulsed power applications, this paper proposes a modularity concept to improve the performance and flexibility of the pulsed power supply. The proposed scheme utilizes the advantage of parallel and series configurations of flyback modules in obtaining high-voltage levels with fast rise time (dv/dt). Prototypes were implemented using 600-V insulated-gate bipolar transistor (IGBT) switches to generate up to 4-kV output pulses with 1-kHz repetition rate for experimentation. To assess the proposed modular approach for higher number of the modules, prototypes were implemented using 1700-V IGBTs switches, based on ten-series modules, and tested up to 20 kV. Conducted experimental results verified the effectiveness of the proposed method.",
A DTLS based end-to-end security architecture for the Internet of Things with two-way authentication,"In this paper, we introduce the first fully implemented two way authentication security scheme for the Internet of Things (IoT) based on existing Internet standards, especially the Datagram Transport Layer Security (DTLS) protocol. The proposed security scheme is based on the most widely used public key cryptography (RSA), and works on top of standard low power communication stacks.We believe that by relying on an established standard, existing implementations, engineering techniques and security infrastructure can be reused, which enables easy security uptake. We present an implemented system architecture for the proposed scheme based on a low-power hardware platform suitable for the IoT. We further demonstrate its feasibility (low overheads and high interoperability) through extensive evaluation.","Servers,
Protocols,
Ciphers,
Peer to peer computing,
Internet,
Authentication"
Case studies in just-in-time requirements analysis,"Many successful software projects do not follow the commonly assumed best practice of engineering well-formed requirements at project inception. Instead, the requirements are captured less formally, and only fully elaborated once the implementation begins, known as `just-in-time' requirements. Given the apparent disparity between best practices and actual practices, several questions arise. One concerns the nature of requirements engineering in non-traditional forms. What types of tools and practices are used? Another is formative: what types of problems are encountered in just-intime requirements, and how might we support organizations in solving those problems? In this paper we conduct separate case studies on the requirements practices of three open-source software projects. Using an individual task as the unit of analysis, we study how the project proceeds from requirement to implementation, in order to understand how each project manages requirements. We then comment on the benefits and problems of just-in-time requirements analysis. This allows us to propose research directions about requirements engineering in just-in-time settings. In particular, we see the need to better understand the context of practice, and the need to properly evaluate the cost of decisions. We propose a taxonomy to describe the requirements practices spectrum from fully formal to just-in-time.",
An Efficient Camera Calibration Technique Offering Robustness and Accuracy Over a Wide Range of Lens Distortion,"In the field of machine vision, camera calibration refers to the experimental determination of a set of parameters that describe the image formation process for a given analytical model of the machine vision system. Researchers working with low-cost digital cameras and off-the-shelf lenses generally favor camera calibration techniques that do not rely on specialized optical equipment, modifications to the hardware, or an a priori knowledge of the vision system. Most of the commonly used calibration techniques are based on the observation of a single 3-D target or multiple planar (2-D) targets with a large number of control points. This paper presents a novel calibration technique that offers improved accuracy, robustness, and efficiency over a wide range of lens distortion. This technique operates by minimizing the error between the reconstructed image points and their experimentally determined counterparts in “distortion free” space. This facilitates the incorporation of the exact lens distortion model. In addition, expressing spatial orientation in terms of unit quaternions greatly enhances the proposed calibration solution by formulating a minimally redundant system of equations that is free of singularities. Extensive performance benchmarking consisting of both computer simulation and experiments confirmed higher accuracy in calibration regardless of the amount of lens distortion present in the optics of the camera. This paper also experimentally confirmed that a comprehensive lens distortion model including higher order radial and tangential distortion terms improves calibration accuracy.","Cameras,
Calibration,
Lenses,
Mathematical model,
Nonlinear distortion,
Quaternions,
Numerical models"
Efficient and Fair Bandwidth Allocation in Multichannel Cognitive Radio Networks,"Cognitive radio (CR) improves spectrum efficiency by allowing secondary users (SUs) to dynamically exploit the idle spectrum owned by primary users (PUs). This paper studies optimal bandwidth allocation of SUs for throughput efficiency. Consider the following tradeoff: an SU increases its instantaneous throughput by accessing more spectrum, but channel access/switching overhead, contention among multiple SUs, and dynamic PU activity create higher liability for larger bandwidths. So how much is too much? In this paper, we study the optimal bandwidth allocation for multiple SUs. Our approach is twofold. We first study the optimal bandwidth an SU should use to maximize the per-SU throughput in the long term. The optimal bandwidth is derived in the context of dynamic PU activity, where we consider both independent and correlated PU channel scenarios while accounting for the effects of channel switching overhead. We further consider the case of suboptimal spectrum use by SUs in the short term due to PU activity dynamics. We propose an efficient channel reconfiguration (CREC) scheme to improve SUs' performance. We use real PU channel activity traces in the simulations to validate our results. The work sheds light on the design of spectrum sharing protocols in cognitive radio networks.",
A Colon Video Analysis Framework for Polyp Detection,"This paper presents an automated video analysis framework for the detection of colonic polyps in optical colonoscopy. Our proposed framework departs from previous methods in that we include spatial frame-based analysis and temporal video analysis using time-course image sequences. We also provide a video quality assessment scheme including two measures of frame quality. We extract colon-specific anatomical features from different image regions using a windowing approach for intraframe spatial analysis. Anatomical features are described using an eigentissue model. We apply a conditional random field to model interframe dependences in tissue types and handle variations in imaging conditions and modalities. We validate our method by comparing our polyp detection results to colonoscopy reports from physicians. Our method displays promising preliminary results and shows strong invariance when applied to both white light and narrow-band video. Our proposed video analysis system can provide objective diagnostic support to physicians by locating polyps during colon cancer screening exams. Furthermore, our system can be used as a cost-effective video annotation solution for the large backlog of existing colonoscopy videos.","Colonoscopy,
Feature extraction,
Image edge detection,
Vectors,
Training,
Image color analysis,
Filtering algorithms"
Network-Wide Local Unambiguous Failure Localization (NWL-UFL) via Monitoring Trails,"Monitoring trail (m-trail) has been proposed as an effective approach for link failure localization in all-optical wavelength division multiplexing (WDM) mesh networks. Previous studies in failure localization rely on alarm dissemination via control plane signaling such that the network controller can collect the flooded alarms to form an alarm code for failure identification. Such cross-layer signaling effort obviously leads to additional control complexity. This paper investigates a novel m-trail failure localization scenario, called network-wide local unambiguous failure localization (NWL-UFL), where each node can perform UFL based on locally available on–off state of traversing m-trails, such that alarm dissemination in the control plane can be completely avoided. The paper first defines and formulates the m-trail allocation problem under NWL-UFL and conducts a series of bound analysis on the cover length required for localizing any single-link failure. This is the first study on monitoring trail allocation problem that aims to gain understanding on the consumed cover length via analytical approaches due to the special feature of the NWL-UFL scenario. A novel heuristic algorithm based on random spanning tree assignment (RSTA) and greedy link swapping (GLS) is developed for solving the formulated problem. Extensive simulation on thousands of randomly generated network topologies is conducted to verify the proposed scheme by comparing it to a naive counterpart and with the derived lower bounds. We also demonstrate the impact of topology diversity on the performance of the proposed scheme as well as its scalability regarding network sizes.","Monitoring,
Optical transmitters,
Resource management,
Optical receivers,
Topology,
Repeaters,
Optical fiber networks"
The Shuttle Nanoelectromechanical Nonvolatile Memory,"Nonvolatile memory (NVM) devices based on storage layers, p-n junctions and transistors, such as FLASH, suffer from poor retention at high temperature, high voltage writing, and wear out while cycling. This paper presents the structure, operation, and modeling of a nanoelectromechanical NVM based on the switching of a free electrode between two stable states. This electrode, called the shuttle, has no mechanical anchors and commutes between two positions. It is guided inside an insulator pod. Adhesion forces between the shuttle and fixed electrodes serve to hold the shuttle in stable positions. Smooth metal layers give strong Van der Waals stiction between two surfaces in contact. Memory detection is obtained by probing the conductance between two fixed contacts; the shuttle serves as a switchable open/short electrode. Electromechanical contacts have an ideally large resistance ratio between on and off levels. At microscale, gravity is found to be negligible compared with adhesion forces, which motivates the anchorless design for high-temperature data storage. The model proposed is based on charge induction over the surface of metal electrodes and is validated by finite-element method. Kinematic equations and energy transfers of the shuttle device are explored. Due to its unique anchorless design, the scalability of the anchorless shuttle memory is found to be excellent.","Electrodes,
Switches,
Nonvolatile memory,
Adhesives,
Logic gates,
Electrostatics,
Mathematical model"
Segmentation of Skin Lesions in 2-D and 3-D Ultrasound Images Using a Spatially Coherent Generalized Rayleigh Mixture Model,"This paper addresses the problem of jointly estimating the statistical distribution and segmenting lesions in multiple-tissue high-frequency skin ultrasound images. The distribution of multiple-tissue images is modeled as a spatially coherent finite mixture of heavy-tailed Rayleigh distributions. Spatial coherence inherent to biological tissues is modeled by enforcing local dependence between the mixture components. An original Bayesian algorithm combined with a Markov chain Monte Carlo method is then proposed to jointly estimate the mixture parameters and a label-vector associating each voxel to a tissue. More precisely, a hybrid Metropolis-within-Gibbs sampler is used to draw samples that are asymptotically distributed according to the posterior distribution of the Bayesian model. The Bayesian estimators of the model parameters are then computed from the generated samples. Simulation results are conducted on synthetic data to illustrate the performance of the proposed estimation strategy. The method is then successfully applied to the segmentation of in vivo skin tumors in high-frequency 2-D and 3-D ultrasound images.",
Towards Better Fault Localization: A Crosstab-Based Statistical Approach,"It is becoming prohibitively expensive and time consuming, as well as tedious and error-prone, to perform debugging manually. Among the debugging activities, fault localization has been one of the most expensive, and therefore, a large number of fault-localization techniques have been proposed over the recent years. This paper presents a crosstab-based statistical technique that makes use of the coverage information of each executable statement and the execution result (success or failure) with respect to each test case to localize faults in an effective and efficient manner. A crosstab is constructed for each executable statement, and a statistic is computed to determine the suspiciousness of the corresponding statement. Statements with a higher suspiciousness are more likely to contain bugs and should be examined before those with a lower suspiciousness. Case studies are performed on both small- (the Siemens and Unix suites) and large-sized programs (space, grep, gzip, and make), and results suggest that the crosstab-based technique (CBT) is more effective (in terms of a smaller percentage of executable statements that have to be examined until the first statement containing the fault is reached) than other techniques, such as Tarantula. Further studies using the Siemens suite reveal that the proposed technique is also more effective at locating faults than other statistically oriented techniques, such as SOBER and Liblit05. Additional experiments evaluate the CBT from other perspectives, such as its efficiency in terms of time taken, its applicability to object-oriented languages (on a very large Java program: Ant), and its sensitivity to test suite size, and demonstrate its superior performance.",
Performance Optimisation of Soft and Hard Spectrum Sensing Schemes in Cognitive Radio,"Cognitive radios represent a promising technique to address the problem of efficient spectrum utilisation. However, their performance is limited by their capability to sense the spectrum. This letter proposes a fair comparison between soft and hard spectrum sensing schemes, based on the practical assumption of limited time resources, which was never explored in previous studies. By considering the achieved detection probability as the performance metric and the false alarm probability as constraint, this work analytically proves that the hard scheme can represent a favourable solution, especially in short sensing times and/or large numbers of users. The sufficient condition by which the soft scheme outperforms the hard scheme is also introduced. This condition is represented by the number of collected samples from the channel in a closed-form expression, which depends on the sensing time, the Signal-to-Noise-Ratio (SNR), the number of available users and the predefined false alarm probability threshold. All these factors are independently evaluated throughout this work. The analysis is carried out through mathematical equations and confirmed by simulation results.",
Movie Rating and Review Summarization in Mobile Environment,"In this paper, we design and develop a movie-rating and review-summarization system in a mobile environment. The movie-rating information is based on the sentiment-classification result. The condensed descriptions of movie reviews are generated from the feature-based summarization. We propose a novel approach based on latent semantic analysis (LSA) to identify product features. Furthermore, we find a way to reduce the size of summary based on the product features obtained from LSA. We consider both sentiment-classification accuracy and system response time to design the system. The rating and review-summarization system can be extended to other product-review domains easily.","Motion pictures,
Support vector machines,
Mobile communication,
Semantics,
Feature extraction,
Search engines,
Internet"
A large scale exploratory analysis of software vulnerability life cycles,"Software systems inherently contain vulnerabilities that have been exploited in the past resulting in significant revenue losses. The study of vulnerability life cycles can help in the development, deployment, and maintenance of software systems. It can also help in designing future security policies and conducting audits of past incidents. Furthermore, such an analysis can help customers to assess the security risks associated with software products of different vendors. In this paper, we conduct an exploratory measurement study of a large software vulnerability data set containing 46310 vulnerabilities disclosed since 1988 till 2011. We investigate vulnerabilities along following seven dimensions: (1) phases in the life cycle of vulnerabilities, (2) evolution of vulnerabilities over the years, (3) functionality of vulnerabilities, (4) access requirement for exploitation of vulnerabilities, (5) risk level of vulnerabilities, (6) software vendors, and (7) software products. Our exploratory analysis uncovers several statistically significant findings that have important implications for software development and deployment.","Computer hacking,
Complexity theory,
Aggregates,
Measurement,
Open source software"
Network-Based High Level Data Classification,"Traditional supervised data classification considers only physical features (e.g., distance or similarity) of the input data. Here, this type of learning is called low level classification. On the other hand, the human (animal) brain performs both low and high orders of learning and it has facility in identifying patterns according to the semantic meaning of the input data. Data classification that considers not only physical attributes but also the pattern formation is, here, referred to as high level classification. In this paper, we propose a hybrid classification technique that combines both types of learning. The low level term can be implemented by any classification technique, while the high level term is realized by the extraction of features of the underlying network constructed from the input data. Thus, the former classifies the test instances by their physical features or class topologies, while the latter measures the compliance of the test instances to the pattern formation of the data. Our study shows that the proposed technique not only can realize classification according to the pattern formation, but also is able to improve the performance of traditional classification techniques. Furthermore, as the class configuration's complexity increases, such as the mixture among different classes, a larger portion of the high level term is required to get correct classification. This feature confirms that the high level classification has a special importance in complex situations of classification. Finally, we show how the proposed technique can be employed in a real-world application, where it is capable of identifying variations and distortions of handwritten digit images. As a result, it supplies an improvement in the overall pattern recognition rate.","Pattern formation,
Training,
Semantics,
Feature extraction,
Support vector machines,
Topology,
Complex networks"
Automatic Coronary Calcium Scoring in Low-Dose Chest Computed Tomography,"The calcium burden as estimated from non-ECG-synchronized computed tomography (CT) exams acquired in screening of heavy smokers has been shown to be a strong predictor of cardiovascular events. We present a method for automatic coronary calcium scoring with low-dose, non-contrast-enhanced, non-ECG-synchronized chest CT. First, a probabilistic coronary calcium map was created using multi-atlas segmentation. This map assigned an a priori probability for the presence of coronary calcifications at every location in a scan. Subsequently, a statistical pattern recognition system was designed to identify coronary calcifications by texture, size, and spatial features; the spatial features were computed using the coronary calcium map. The detected calcifications were quantified in terms of volume and Agatston score. The best results were obtained by merging the results of three different supervised classification systems, namely direct classification with a nearest neighbor classifier, and two-stage classification with nearest neighbor and support vector machine classifiers. We used a total of 231 test scans containing 45 674mm of coronary calcifications. The presented method detected on average 157/198mm (sensitivity 79.2%) of coronary calcium volume with on average 4 mm false positive volume. Calcium scoring can be performed automatically in low-dose, noncontrast enhanced, non-ECG-synchronized chest CT in screening of heavy smokers to identify subjects who might benefit from preventive treatment.","Calcium,
Computed tomography,
Arteries,
Feature extraction,
Probability,
Support vector machines,
Training"
A Switched-Inductor Integrated Voltage Regulator With Nonlinear Feedback and Network-on-Chip Load in 45 nm SOI,"A four-phase integrated buck converter in 45 nm silicon-on-insulator (SOI) technology is presented. The controller uses unlatched pulse-width modulation (PWM) with nonlinear gain to provide both stable small-signal dynamics and fast response (~700 ps) to large input and output transients. This fast control approach reduces the required output capacitance by 5× in comparison to a conventional, latched PWM controller at a similar operating point. The converter switches package-integrated air-core inductors at 80 MHz and delivers 1 A/mm2 at 83% efficiency and 0.66 conversion ratio. A network-on-chip (NoC) serves as a realistic digital load along with a programmable current source capable of generating load current steps with slew rate of ~1 A/100 ps for characterization of the control scheme.","Capacitance,
Capacitors,
System-on-a-chip,
Voltage control,
Inductors,
Switches,
Pulse width modulation"
Modeling and Optimization of Building Emergency Evacuation Considering Blocking Effects on Crowd Movement,"In building emergency evacuation, the perception of hazards can stress crowds, evoke their competitive behaviors, and trigger disorder and blocking as they pass through narrow passages (e.g., a small exit). This is a serious concern threatening evacuees' survivability and egress efficiency. How to optimize crowd guidance while considering such effects is an important problem. Based on advanced microscopic pedestrian models and simulations, this paper establishes a new macroscopic network-flow model where fire, smoke, and psychological factors can evoke a crowd's desire to escape—the desired flow rate. Disorder and blocking occur when the desired flow rate exceeds the passage capacity, resulting in a drastic decrease of crowd movement in a nonlinear and random fashion. To effectively guide crowds, a divide-and-conquer approach is developed based on groups to reduce computational complexity and to reflect psychological findings. Egress routes for individual groups are optimized by using a novel combination of stochastic dynamic programming and the rollout scheme. These routes are then coordinated so that limited passage capacities are shared to meet the total need for joint movement. Numerical testing and simulation demonstrate that, compared with a strategy of merely using nearest exits, our solution can evacuate more people more rapidly by preventing or mitigating potential disorder and blocking at bottleneck passages.","Psychology,
Simulation,
Computational modeling,
Stress,
Optimization,
Behavioral science,
Modeling,
Dynamic programming"
Fusing Dependent Decisions for Hypothesis Testing With Heterogeneous Sensors,"In this paper, we consider a binary decentralized detection problem where the local sensor observations are quantized before their transmission to the fusion center. Sensor observations, and hence their quantized versions, may be heterogeneous as well as statistically dependent. A composite binary hypothesis testing problem is formulated, and a copula-based generalized likelihood ratio test (GLRT) based fusion rule is derived given that the local sensors are uniform multilevel quantizers. An alternative computationally efficient fusion rule is also designed which involves injecting a deliberate random disturbance to the local sensor decisions before fusion. Although the introduction of external noise causes a reduction in the received signal-to-noise ratio (SNR), it is shown that the proposed approach can result in a detection performance comparable to the GLRT detector without external noise, especially when the number of quantization levels is large.","Quantization,
Sensor fusion,
Noise,
Zinc,
Joints,
Random variables"
Bayesian Hemodynamic Parameter Estimation by Bolus Tracking Perfusion Weighted Imaging,"A delay-insensitive probabilistic method for estimating hemodynamic parameters, delays, theoretical residue functions, and concentration time curves by computed tomography (CT) and magnetic resonance (MR) perfusion weighted imaging is presented. Only a mild stationarity hypothesis is made beyond the standard perfusion model. New microvascular parameters with simple hemodynamic interpretation are naturally introduced. Simulations on standard digital phantoms show that the method outperforms the oscillating singular value decomposition (oSVD) method in terms of goodness-of-fit, linearity, statistical and systematic errors on all parameters, especially at low signal-to-noise ratios (SNRs). Delay is always estimated sharply with user-supplied resolution and is purely arterial, by contrast to oSVD time-to-maximum TMAX that is very noisy and biased by mean transit time (MTT), blood volume, and SNR. Residue functions and signals estimates do not suffer overfitting anymore. One CT acute stroke case confirms simulation results and highlights the ability of the method to reliably estimate MTT when SNR is low. Delays look promising for delineating the arterial occlusion territory and collateral circulation.",
Analog Filter Design Using Ring Oscillator Integrators,"Integrators are key building blocks in many analog signal processing circuits and systems. The DC gain of conventional opamp-RC or Gm- C integrators is severely limited by the gain of operational transconductance amplifier (OTA) used to implement them. Process scaling reduces transistor output resistance, which further exacerbates this issue. We propose applying ring oscillator integrators (ROIs) in the design of high order analog filters. ROIs implemented with simple CMOS inverters achieve infinite DC gain at low supply voltages independent of transistor non-idealities and imperfections such as finite output impedance. Consequently, ROIs scale more effectively into newer processes. A prototype fourth order filter designed using the ROIs was fabricated in 90 nm CMOS and occupies an area of 0.29 mm2. Operating with a 0.55 V supply, the filter consumes 2.9 mW power and achieves bandwidth of 7 MHz, SNR of 61.4 dB, SFDR of 67.6 dB and THD of 60.1 dB. The measured IM3 obtained by feeding two tones at 1 MHz and 2 MHz is 63.4 dB.","Ring oscillators,
Pulse width modulation,
Noise measurement,
Gain,
Detectors,
Charge pumps"
Sequence of the Most Informative Joints (SMIJ): A new representation for human skeletal action recognition,"Much of the existing work on action recognition combines simple features (e.g., joint angle trajectories, optical flow, spatio-temporal video features) with somewhat complex classifiers or dynamical models (e.g., kernel SVMs, HMMs, LDSs, deep belief networks). Although successful, these approaches represent an action with a set of parameters that usually do not have any physical meaning. As a consequence, such approaches do not provide any qualitative insight that relates an action to the actual motion of the body or its parts. For example, it is not necessarily the case that clapping can be correlated to hand motion or that walking can be correlated to a specific combination of motions from the feet, arms and body. In this paper, we propose a new representation of human actions called Sequence of the Most Informative Joints (SMIJ), which is extremely easy to interpret. At each time instant, we automatically select a few skeletal joints that are deemed to be the most informative for performing the current action. The selection of joints is based on highly interpretable measures such as the mean or variance of joint angles, maximum angular velocity of joints, etc. We then represent an action as a sequence of these most informative joints. Our experiments on multiple databases show that the proposed representation is very discriminative for the task of human action recognition and performs better than several state-of-the-art algorithms.","Joints,
Humans,
Hidden Markov models,
Time series analysis,
Data mining,
Feature extraction"
IncogniSense: An anonymity-preserving reputation framework for participatory sensing applications,"Reputation systems rate the contributions to participatory sensing campaigns from each user by associating a reputation score. The reputation scores are used to weed out incorrect sensor readings. However, an adversary can deanonmyize the users even when they use pseudonyms by linking the reputation scores associated with multiple contributions. Since the contributed readings are usually annotated with spatiotemporal information, this poses a serious breach of privacy for the users. In this paper, we address this privacy threat by proposing a framework called IncogniSense. Our system utilizes periodic pseudonyms generated using blind signature and relies on reputation transfer between these pseudonyms. The reputation transfer process has an inherent trade-off between anonymity protection and loss in reputation. We investigate by means of extensive simulations several reputation cloaking schemes that address this tradeoff in different ways. Our system is robust against reputation corruption and a prototype implementation demonstrates that the associated overheads are minimal.","Servers,
Sensors,
Cryptography,
Joining processes,
Robustness,
Privacy,
Generators"
Analysis of instruction-level vulnerability to dynamic voltage and temperature variations,"Variation in performance and power across manufactured parts and their operating conditions is an accepted reality in aggressive CMOS processes. This paper considers challenges and opportunities in identifying this variation and methods to combat it for improved computing systems. We introduce the notion of instruction-level vulnerability (ILV) to expose variation and its effects to the software stack for use in architectural/compiler optimizations. To compute ILV, we quantify the effect of voltage and temperature variations on the performance and power of a 32-bit, RISC, in-order processor in 65 nm TSMC technology at the level of individual instructions. Results show 3.4 ns (68FO4) delay variation and 26.7x power variation among instructions, and across extreme corners. Our analysis shows that ILV is not uniform across the instruction set. In fact, ILV data partitions instructions into three equivalence classes. Based on this classification, we show how a low-overhead robustness enhancement techniques can be used to enhance performance by a factor of 1.1x-5.5x.","Clocks,
Pipelines,
Power system dynamics,
Temperature sensors,
Delay,
Temperature distribution"
"Discrete-Time Neural Network for Fast Solving Large Linear L_{1}
Estimation Problems and its Application to Image Restoration","There is growing interest in solving linear L1 estimation problems for sparsity of the solution and robustness against non-Gaussian noise. This paper proposes a discrete-time neural network which can calculate large linear L1 estimation problems fast. The proposed neural network has a fixed computational step length and is proved to be globally convergent to an optimal solution. Then, the proposed neural network is efficiently applied to image restoration. Numerical results show that the proposed neural network is not only efficient in solving degenerate problems resulting from the nonunique solutions of the linear L1 estimation problems but also needs much less computational time than the related algorithms in solving both linear L1 estimation and image restoration problems.","Estimation,
Image restoration,
Convergence,
Iterative methods,
Recurrent neural networks,
Vectors,
Noise"
Experimental Study of Design Parameters in Silicon Micropillar Array Solar Cells Produced by Soft Lithography and Metal-Assisted Chemical Etching,"Solar cells, consisting of core-shell p-n junction silicon micropillars on a thin membrane fabricated using soft lithography and metal-assisted chemical etching, are studied as a function of geometrical designs. Significant enhancement in absorption rate is found without much dependence on the pillar diameters in the range of 0.5-2 μm. However, the short-circuit current increases continuously with diameter, which is inversely proportional to the total surface area for a fixed diameter/pitch pillar array. This study provides unambiguous evidence that surface recombination is the dominant loss mechanism in nanowire- or micropillar-based solar cells.","Silicon,
Photovoltaic cells,
Arrays,
Absorption,
Metals,
Etching"
Context-Based Electronic Health Record: Toward Patient Specific Healthcare,"Due to the increasingly data-intensive clinical environment, physicians now have unprecedented access to detailed clinical information from a multitude of sources. However, applying this information to guide medical decisions for a specific patient case remains challenging. One issue is related to presenting information to the practitioner: displaying a large (irrelevant) amount of information often leads to information overload. Next-generation interfaces for the electronic health record (EHR) should not only make patient data easily searchable and accessible, but also synthesize fragments of evidence documented in the entire record to understand the etiology of a disease and its clinical manifestation in individual patients. In this paper, we describe our efforts toward creating a context-based EHR, which employs biomedical ontologies and (graphical) disease models as sources of domain knowledge to identify relevant parts of the record to display. We hypothesize that knowledge (e.g., variables, relationships) from these sources can be used to standardize, annotate, and contextualize information from the patient record, improving access to relevant parts of the record and informing medical decision making. To achieve this goal, we describe a framework that aggregates and extracts findings and attributes from free-text clinical reports, maps findings to concepts in available knowledge sources, and generates a tailored presentation of the record based on the information needs of the user. We have implemented this framework in a system called Adaptive EHR, demonstrating its capabilities to present and synthesize information from neurooncology patients. This paper highlights the challenges and potential applications of leveraging disease models to improve the access, integration, and interpretation of clinical patient data.","Ontologies,
Diseases,
Biological system modeling,
Medical diagnostic imaging,
Natural language processing"
Redundant Wavelets on Graphs and High Dimensional Data Clouds,"In this paper, we propose a new redundant wavelet transform applicable to scalar functions defined on high dimensional coordinates, weighted graphs and networks. The proposed transform utilizes the distances between the given data points to construct tree-like structures. We modify the filter-bank decomposition scheme of the redundant wavelet transform by adding in each decomposition level operators that reorder the approximation coefficients. These reordering operators are derived by organizing the tree-node features so as to shorten the path that passes through these points. We explore the use of the proposed transform for the recovery of labels defined on point clouds and to image denoising, and show that in both cases the results are promising.","Wavelet transforms,
Vectors,
Image denoising,
Signal processing algorithms,
Approximation methods,
Noise reduction"
Autonomous Learning of High-Level States and Actions in Continuous Environments,"How can an agent bootstrap up from a low-level representation to autonomously learn high-level states and actions using only domain-general knowledge? In this paper, we assume that the learning agent has a set of continuous variables describing the environment. There exist methods for learning models of the environment, and there also exist methods for planning. However, for autonomous learning, these methods have been used almost exclusively in discrete environments. We propose attacking the problem of learning high-level states and actions in continuous environments by using a qualitative representation to bridge the gap between continuous and discrete variable representations. In this approach, the agent begins with a broad discretization and initially can only tell if the value of each variable is increasing, decreasing, or remaining steady. The agent then simultaneously learns a qualitative representation (discretization) and a set of predictive models of the environment. These models are converted into plans to perform actions. The agent then uses those learned actions to explore the environment. The method is evaluated using a simulated robot with realistic physics. The robot is sitting at a table that contains a block and other distractor objects that are out of reach. The agent autonomously explores the environment without being given a task. After learning, the agent is given various tasks to determine if it learned the necessary states and actions to complete them. The results show that the agent was able to use this method to autonomously learn to perform the tasks.","Context,
Reliability,
Predictive models,
Bayesian methods,
Learning,
Heuristic algorithms,
Complexity theory"
Initial explorations on design pattern energy usage,"As the use of computers has grown, so too has concern about the amount of power they consume. Data centers, for example, are limited in scalability as they struggle with soaring energy costs from many large companies relying on fast, reliable, and round-the-clock computing services. On large-scale computing clusters, like data centers, even a small drop in power consumption can have large effects. Across computing contexts, reducing power consumed by computers has become a major focus. In this paper, we present a new approach for mapping software design to power consumption and present empirical results of the approach on different software implementations. In particular, we compare the power profiles of software using design patterns against software not using design patterns as a way to explore how high-level design decisions affect an application's energy usage. We show how mappings between software design and power consumption profiles can provide software designers and developers with useful information about the power behavior of the software they are developing. The goal is for software engineers to use this information in designing and developing more energy efficient solutions.","Power demand,
Software,
Computers,
Monitoring,
Production facilities,
Energy measurement,
Power measurement"
Geographic trough filling for internet datacenters,"To reduce datacenter energy consumption and cost, current practice has considered demand-proportional resource provisioning schemes, where servers are turned on/off according to the load of requests. Most existing work considers instantaneous (Internet) requests only, which are explicitly or implicitly assumed to be delay-sensitive. On the other hand, in datacenters, there exist a vast amount of delay-tolerant jobs, such as background/maintainance jobs. In this paper, we explicitly differentiate delay-sensitive jobs and delay tolerant jobs. We focus on the problem of using delay-tolerant jobs to fill the extra capacity of datacenters, referred to as trough/valley filling. Giving a higher priority to delay-sensitive jobs, our scheme complements most existing demand-proportional resource provisioning schemes. Our goal is to design an intelligent trough filling mechanism that is energy efficient and also achieves good delay performance. Specifically, we propose a joint dynamic speed scaling and traffic shifting scheme. The scheme does not need statistical information of the system, which is usually difficult to obtain. In the proposed scheme, energy cost saving comes from dynamic speed scaling, statistical multiplexing, electricity price diversity, and service efficiency diversity. In addition, good delay performance is achieved via load shifting and capacity allocation based on queue conditions. We show the efficiency of the proposed scheme by both analysis and simulation.","Servers,
Delay,
Bandwidth,
Load modeling,
Electricity,
Resource management,
Internet"
Energy-aware scheduling for infrastructure clouds,"More and more data centers are built, consuming ever more kilo watts of energy. Over the years, energy has become a dominant cost factor for data center operators. Utilizing low-power idle modes is an immediate remedy to reduce data center power consumption. We use simulation to quantify the difference in energy consumption caused exclusively by virtual machine schedulers. Besides demonstrating the inefficiency of wide-spread default schedulers, we present our own optimized scheduler. Using a range of realistic simulation scenarios, our customized scheduler OptSched reduces cumulative machine uptime by up to 60.1%. We evaluate the effect of data center composition, run time distribution, virtual machine sizes, and batch requests on cumulative machine uptime. IaaS administrators can use our results to quickly assess possible reductions in machine uptime and, hence, untapped energy saving potential.","Servers,
Virtual machining,
Random access memory,
Cloud computing,
Indexes,
Scheduling,
Round robin"
On multiple foreground cosegmentation,"In this paper, we address a challenging image segmentation problem called multiple foreground cosegmentation (MFC), which concerns a realistic scenario in general Webuser photo sets where a finite number of K foregrounds of interest repeatedly occur cross the entire photo set, but only an unknown subset of them is presented in each image. This contrasts the classical cosegmentation problem dealt with by most existing algorithms, which assume a much simpler but less realistic setting where the same set of foregrounds recurs in every image. We propose a novel optimization method for MFC, which makes no assumption on foreground configurations and does not suffer from the aforementioned limitation, while still leverages all the benefits of having co-occurring or (partially) recurring contents across images. Our method builds on an iterative scheme that alternates between a foreground modeling module and a region assignment module, both highly efficient and scalable. In particular, our approach is flexible enough to integrate any advanced region classifiers for foreground modeling, and our region assignment employs a combinatorial auction framework that enjoys several intuitively good properties such as optimality guarantee and linear complexity. We show the superior performance of our method in both segmentation quality and scalability in comparison with other state-of-the-art techniques on a newly introduced FlickrMFC dataset and the standard ImageNet dataset.","Bismuth,
Image segmentation,
Silicon,
Vegetation,
Computational modeling,
Heuristic algorithms,
Optimization"
Efficient and Progressive Algorithms for Distributed Skyline Queries over Uncertain Data,"The skyline operator has received considerable attention from the database community, due to its importance in many applications including multicriteria decision making, preference answering, and so forth. In many applications where uncertain data are inherently exist, i.e., data collected from different sources in distributed locations are usually with imprecise measurements, and thus exhibit kind of uncertainty. Taking into account the network delay and economic cost associated with sharing and communicating large amounts of distributed data over an internet, an important problem in this scenario is to retrieve the global skyline tuples from all the distributed local sites with minimum communication cost. Based on the well-known notation of the probabilistic skyline query over centralized uncertain data, in this paper, we propose the notation of distributed skyline queries over uncertain data. Furthermore, two communication- and computation-efficient algorithms are proposed to retrieve the qualified skylines from distributed local sites. Extensive experiments have been conducted to verify the efficiency, the effectiveness and the progressiveness of our algorithms with both the synthetic and real data sets.","Distributed databases,
Algorithm design and analysis,
Servers,
Bandwidth,
Uncertainty,
Probabilistic logic"
An Improved Method for the Estimation and Visualization of Velocity Fields from Gastric High-Resolution Electrical Mapping,"High-resolution (HR) electrical mapping is an important clinical research tool for understanding normal and abnormal gastric electrophysiology. Analyzing velocities of gastric electrical activity in a reliable and accurate manner can provide additional valuable information for quantitatively and qualitatively comparing features across and within subjects, particularly during gastric dysrhythmias. In this study, we compared three methods of estimating velocities from HR recordings to determine which method was the most reliable for use with gastric HR electrical mapping. The three methods were 1) simple finite difference (FD) 2) smoothed finite difference (FDSM), and 3) a polynomial-based method. With synthetic data, the accuracy of the simple FD method resulted in velocity errors almost twice that of the FDSM and the polynomial-based method, in the presence of activation time error up to 0.5 s. With three synthetic cases under various noise types and levels, the FDSM resulted in average speed error of 3.2% and an average angle error of 2.0° and the polynomial-based method had an average speed error of 3.3% and an average angle error of 1.7 °. With experimental gastric slow wave recordings performed in pigs, the three methods estimated similar velocities (6.3-7.3 mm/s), but the FDSM method had a lower standard deviation in its velocity estimate than the simple FD and the polynomial-based method, leading it to be the method of choice for velocity estimation in gastric slow wave propagation. An improved method for visualizing velocity fields is also presented.",
Red blood cell segmentation using masking and watershed algorithm: A preliminary study,"Image segmentation is the most important step and a key technology in image processing which directly affect the next processing. In human blood cell segmentation cases, many methods were applied for obtaining better results. It is basically an improved visualization to observe blood cell under blood smear process. This paper will present an approach for red blood cell (RBC) segmentation which is a part of study to perform automated counting for RBC. The methods involve are Ycbcr color conversion, masking, morphological operators and watershed algorithm. The combination of Ycbcr color conversion and morphological operator produce segmented white blood cell (WBC) nucleus. Then it is being used as a mask to remove WBC from the blood cell image. Morphological operators involve binary erosion diminish small object like platelet. The resulted RBC segmentation is passing through marker controlled watershed algorithm which handles overlapping cells. The improvement need to be done for both segmentation and overlapped cell handling to obtain better result in the future.",
Robust Clipping for OFDM Transmissions over Memoryless Impulsive Noise Channels,"The detriment arising from strong and frequently occurring impulses over an Orthogonal Frequency Division Multiplexing system is paramount because signals on sub-carriers appear to be corrupted simultaneously. To overcome this obstacle, clipping has been reported as an effective approach. Unlike previous works, this work derived the clipping threshold without assuming the a priori knowledge of the probability density function (PDF) of impulsive noise, which is usually unobtainable in precise measure in most practical scenarios, and may change rapidly over time. Then, a decoding metric accommodated to the clipping effect was derived to realize coding gain. To attest the proposed scheme, this study conducted computer simulations in compliance with the IEEE 1901 standard. For various impulse noise models under consideration, the proposed scheme was promisingly on par with its conventional counterpart, the clipping threshold of which, however, relies on an assumed PDF.",
An 80 mV Startup Dual-Mode Boost Converter by Charge-Pumped Pulse Generator and Threshold Voltage Tuned Oscillator With Hot Carrier Injection,"This paper presents an 80 mV startup-voltage dual-mode boost converter for energy harvesting applications. The charge-pumped pulse generator enables a startup operation of the boost converter from the input voltage of 80 mV. The threshold voltage tuned oscillator for the clock generator of the boost converter compensates for the die-to-die process variation by a hot carrier injection (HCI), thereby reducing the minimum operation voltage (VDDMIN) of the clock generator by 45% with a trimming time of 10 minutes. The proposed step-up converter achieves the lowest startup voltage without using a mechanical switch or a large transformer.","Charge pumps,
Oscillators,
Pulse generation,
Clocks,
Power transistors,
Transistors,
Human computer interaction"
Stochastic Competitive Learning in Complex Networks,"Competitive learning is an important machine learning approach which is widely employed in artificial neural networks. In this paper, we present a rigorous definition of a new type of competitive learning scheme realized on large-scale networks. The model consists of several particles walking within the network and competing with each other to occupy as many nodes as possible, while attempting to reject intruder particles. The particle's walking rule is composed of a stochastic combination of random and preferential movements. The model has been applied to solve community detection and data clustering problems. Computer simulations reveal that the proposed technique presents high precision of community and cluster detections, as well as low computational complexity. Moreover, we have developed an efficient method for estimating the most likely number of clusters by using an evaluator index that monitors the information generated by the competition process itself. We hope this paper will provide an alternative way to the study of competitive learning..","Communities,
Stochastic processes,
Complex networks,
Legged locomotion,
Machine learning,
Vectors,
Mathematical model"
Generalized Cross-Correlation Properties of Chu Sequences,"In this paper, detailed cross-correlation properties for Chu sequences are investigated. All possible values of the cross-correlation function of Chu sequences are derived for any given sequence length and lag, and the maximum magnitude distribution function ρN(x), which is defined as the number of all Chu sequence pairs with length-N whose maximum magnitude of the cross-correlation function is √Nx, is obtained. Also, good lower and upper bounds on the maximum number of available Chu sequences and a construction algorithm for the corresponding partial Chu sequence set are proposed when the maximum magnitude of the cross-correlation among the sequences is constrained. Numerical examples show that the proposed bounds are quite tight and the proposed construction algorithm is near-optimal up to fairly large value of N.","Correlation,
Distribution functions,
Argon,
Gold,
Upper bound,
Electrical engineering,
Industries"
Electrical Characterization for Intertier Connections and Timing Analysis for 3-D ICs,Reducing interconnect delay and power consumption has become a major concern in deep submicron designs. 3-D technologies have been proposed as a promising solution to mitigate interconnect problems. This paper examines the electrical characterization of vertical intertier connections such as through silicon via (TSV) and microbumps considering process variations and studies their timing impact on the circuit level. We first provide parasitic RC characteristics of intertier connections including TSV and microbumps and examine their delay. Then circuit simulation is performed to evaluate the timing impact of intertier connections.,"Through-silicon vias,
Capacitance,
Delay,
Substrates,
Integrated circuit interconnections,
Metals,
Integrated circuit modeling"
Transmission Strategies in Multiple-Access Fading Channels With Statistical QoS Constraints,"Effective capacity, which provides the maximum constant arrival rate that a given service process can support while satisfying statistical queueing constraints, is analyzed in a multiuser scenario. In particular, the effective capacity region of fading multiple-access channels in the presence of quality of service (QoS) constraints is studied. Perfect channel side information is assumed to be available at both the transmitters and the receiver. It is initially assumed that the transmitters send the information at a fixed power level and, hence, do not employ power control policies. Under this assumption, the performance achieved by superposition coding with successive decoding techniques is investigated. It is shown that varying the decoding order with respect to the channel states can significantly increase the achievable throughput region. In the two-user case, the optimal decoding strategy is determined for the scenario in which the users have the same QoS constraints. The performance of orthogonal transmission strategies is also analyzed. It is shown that for certain QoS constraints, time-division multiple access can achieve better performance than superposition coding if fixed successive decoding order is used at the receiver side. In the subsequent analysis, power control policies are incorporated into the transmission strategies. The optimal power allocation policies for any fixed decoding order over all channel states are identified. For a given variable decoding-order strategy, the conditions that the optimal power control policies must satisfy are determined, and an algorithm that can be used to compute these optimal policies is provided.","Decoding,
Quality of service,
Throughput,
Fading,
Power control,
Delay,
Signal to noise ratio"
Zinc-Oxide Thin-Film Transistor With Self-Aligned Source/Drain Regions Doped With Implanted Boron for Enhanced Thermal Stability,"Because of the rapid diffusion of hydrogen in zinc oxide even at a relatively low temperature, zinc-oxide-based thin-film transistors (TFTs) with hydrogen-doped source/drain regions suffer from degraded thermal stability. The use of boron, which is a heavier and a more slowly diffusing dopant, is systematically investigated as a replacement of hydrogen. Its effectiveness as a dopant has been studied in terms of a range of process conditions, including its implantation dosage and the subsequent heat treatment temperature, time, and ambience. The lowest resistivity of 2 mΩ-cm has been obtained at a boron dose of 1016/cm2. Self-aligned top-gated zinc-oxide TFTs with source/drain regions doped with implanted boron are shown to be more stable than those doped with hydrogen, even when subjected to the relatively high temperature needed for the formation of a good-quality passivation layer.","Zinc oxide,
Heat treatment,
Conductivity,
Thin film transistors,
Thermal stability,
Boron,
Plasma temperature"
Statistical analysis of false positives and false negatives from real traffic with intrusion detection/prevention systems,"False positives and false negatives happen to every intrusion detection and intrusion prevention system. This work proposes a mechanism for false positive/negative assessment with multiple IDSs/IPSs to collect FP and FN cases from real-world traffic and statistically analyze these cases. Over a period of 16 months, more than 2000 FPs and FNs have been collected and analyzed. From the statistical analysis results, we obtain three interesting findings. First, more than 92.85 percent of false cases are FPs even if the numbers of attack types for FP and FN are similar. That is mainly because the behavior of applications or the format of the application content is self-defined; that is, there is not complete conformance to the specifications of RFCs. Accordingly, when this application meets an IDS/IPS with strict detection rules, its traffic will be regarded as malicious traffic, resulting in a lot of FPs. Second, about 91 percent of FP alerts, equal to about 85 percent of false cases, are not related to security issues, but to management policy. For example, some companies and campuses limit or forbid their employees and students from using peer-to-peer applications; therefore, in order to easily detect P2P traffic, an IDS/IPS is configured to be sensitive to it. Hence, this causes alerts to be triggered easily regardless of whether the P2P application has malicious traffic or not. The last finding shows that buffer overflow, SQL server attacks, and worm slammer attacks account for 93 percent of FNs, even though they are aged attacks. This indicates that these attacks always have new variations to evade IDS/IPS detection.","Statistical analysis,
Intrusion detection,
Peer to peer computing,
Protocols,
Servers,
Telecommunication traffic"
Head pose estimation on depth data based on Particle Swarm Optimization,"We propose a method for human head pose estimation based on images acquired by a depth camera. During an initialization phase, a reference depth image of a human subject is obtained. At run time, the method searches the 6-dimensional pose space to find a pose from which the head appears identical to the reference view. This search is formulated as an optimization problem whose objective function quantifies the discrepancy of the depth measurements between the hypothesized views to the reference view. The method is demonstrated in several data sets including ones with known ground truth and comparatively evaluated with respect to state of the art methods. The obtained experimental results show that the proposed method outperforms existing methods in accuracy and tolerance to occlusions. Additionally, compared to the state of the art, it handles head pose estimation in a wider range of head poses.","Estimation,
Accuracy,
Face,
Cameras,
Optimization,
Humans"
Optimizing memory hierarchy allocation with loop transformations for high-level synthesis,"For the majority of computation-intensive application systems, off-chip memory bandwidth is a critical bottleneck for both performance and power consumption. The efficient utilization of limited on-chip memory resources plays a vital role in reducing the off-chip memory accesses. This paper presents an efficient approach for optimizing the on-chip memory allocation by loop transformations in the imperfectly nested loops. We analytically model the on-chip buffer size and off-chip bandwidth after affine loop transformation, loop fusion/distribution and code motion. Branch-and-bound and knapsack reuse techniques are proposed to reduce the computation complexity in finding optimal solutions. Experimental results show that our scheme can save 40% of on-chip memory size with the same bandwidth consumption compared to the previous approaches.",
Unsupervised Change Detection of Satellite Images Using Local Gradual Descent,"In this paper, we propose a novel technique for unsupervised change detection of multitemporal satellite images using Gaussian mixture model (GMM), local gradual descent, and k -means clustering. Data distribution of the difference image is first modeled by bimodal GMM with “changed” and “unchanged” components. The neighborhood data around each pixel form a sample and are modified by the so-called local gradual descent matrix (LGDM), values of which are descending from center toward outside. LGDM visits each sample and causes small variations in pixel values of the sample in an attempt to shift the sample toward the correct Gaussian component center in the feature space. Thus, LGDM decides how much modification to the current sample is necessary for true categorization of the current pixel by later k-means. The motivation behind the proposed approach is twofold. First, a general method that could efficiently explore both local and global changes for unsupervised change detections is needed. Second, unsupervised change detection methods generally use nonsystematic selections of system parameters. Hence, a parameter selection method without using the ground truth image is required for unsupervised methods. The proposed change detection method is tested for both optical and advanced synthetic aperture radar satellite images and compared with the recent works based on the same input set. The proposed method outperforms the others qualitatively and quantitatively.","Satellites,
Feature extraction,
Noise,
Data models,
Indexes,
Principal component analysis,
Contamination"
VLSI Design of an SVM Learning Core on Sequential Minimal Optimization Algorithm,"The sequential minimal optimization (SMO) algorithm has been extensively employed to train the support vector machine (SVM). This work presents an efficient application specific integrated circuit chip design for sequential minimal optimization. This chip is implemented as an intellectual property core, suitable for use in an SVM-based recognition system on a chip. The proposed SMO chip was tested and found to be fully functional, using a prototype system based on the Altera DE2 board with a Cyclone II 2C70 field-programmable gate array.",
Tangent Bundles on Special Manifolds for Action Recognition,"Increasingly, machines are interacting with people through human action recognition from video streams. Video data can naturally be represented as a third-order data tensor. Although many tensor-based approaches have been proposed for action recognition, the geometry of the tensor space is seldom regarded as an important aspect. In this paper, we stress that a data tensor is related to a tangent bundle on a special manifold. Using a manifold charting, we can extract discriminating information between actions. Data tensors are first factorized using high-order singular value decomposition, where each factor is projected onto a tangent space and the intrinsic distance is computed from a tangent bundle for action classification. We examine a standard manifold charting and some alternative chartings on special manifolds, particularly, the special orthogonal group, Stiefel manifolds, and Grassmann manifolds. Because the proposed paradigm frames the classification scheme as a nearest neighbor based on the intrinsic distance, prior training is unnecessary. We evaluate our method on three public action databases including the Cambridge gesture, the UMD Keck body gesture, and the UCF sport datasets. The empirical results reveal that our method is highly competitive with the current state-of-the-art methods, robust to small alignment errors, and yet simpler.","Manifolds,
Tensile stress,
Vectors,
Humans,
Measurement,
Geometry,
Shape"
Tunable Control Strategy for Wave Energy Converters With Limited Power Takeoff Rating,"In wave energy converters (WECs), the maximum power extraction would be achievable at the expense of a very high rating of the electric and power electronics equipment. The goal of this paper is to show how a convenient tradeoff between high-power extraction and viable electrical device rating can be achieved by a proper choice of the WEC control strategy. Referring to a direct coupled point absorber in heave operating in regular waves, it will be analytically shown how most common control techniques impact on both the power performance and the power takeoff (PTO) rating. Thus, a tool that can assist in the preliminary PTO sizing by taking into account the main constraints imposed by the application is obtained. Following, an adaptive control strategy including a reactive component is proposed, whose goal is to improve the overall system performance when the WEC is already operative in the sea. Its effectiveness in increasing the average power extraction while respecting the PTO peak power constraint is proved by computer simulations in both regular and irregular waves, and specific analyses also including the PTO force/torque limitation are finally developed.",
Cross-Layer Framework for QoS Support in Wireless Multimedia Sensor Networks,"The emergence of wireless multimedia sensor networks (WMSNs) has made it possible to realize multimedia delivery on tiny sensing devices. The volume and characteristics of multimedia data is quite different from the data generated in WSNs that has raised the need to explore communication protocols for multimedia delivery in WMSNs. The existing studies focus on providing quality-of-service (QoS) to each individual source but they are not adaptive to create room for maximizing the number of sources. In this paper, we propose a novel cross-layer framework for QoS support in WMSNs. The objective of the proposed framework is to maximize the capacity of the deployed network to enhance the number of video sources given that the QoS constraint of each individual source is also preserved. This is achieved by implementing Wyner-Ziv lossy distributed source coding at the sensor node with variable group of pictures (GOP) size, exploiting multipath routing for real-time delivery and link adaptation to enhance the bandwidth under the given bit error rate. Hence, application requirements are mapped on joint operations of application, network, link and MAC layers to achieve the desired QoS. Simulation results reveal that the framework admits larger number of video sources under the satisfied distortion constraint.",
A spectral transform approach to stochastic circuits,"Stochastic computing (SC) processes data in the form of long pseudo-random bit-streams denoting probabilities. Its key advantages are simple computational elements and high soft-error tolerance. Recent technology developments have revealed important new SC applications such as image processing and LDPC decoding. Despite its long history, SC still lacks a comprehensive design methodology; existing methods tend to be ad hoc and limited to a few arithmetic functions. We demonstrate a fundamental relation between stochastic circuits and spectral transforms. Based on this, we propose a transform approach to the analysis and synthesis of SC circuits. We illustrate the approach for a variety of basic combinational SC design problems, and show that the area cost associated with stochastic number generation can be significantly reduced.","Fourier transforms,
Vectors,
Polynomials,
Tin,
Parity check codes,
Accuracy"
Cooperative Profit Sharing in Coalition-Based Resource Allocation in Wireless Networks,"We consider a network in which several service providers offer wireless access to their respective subscribed customers through potentially multihop routes. If providers cooperate by jointly deploying and pooling their resources, such as spectrum and infrastructure (e.g., base stations) and agree to serve each others' customers, their aggregate payoffs, and individual shares, may substantially increase through opportunistic utilization of resources. The potential of such cooperation can, however, be realized only if each provider intelligently determines with whom it would cooperate, when it would cooperate, and how it would deploy and share its resources during such cooperation. Also, developing a rational basis for sharing the aggregate payoffs is imperative for the stability of the coalitions. We model such cooperation using the theory of transferable payoff coalitional games. We show that the optimum cooperation strategy, which involves the acquisition, deployment, and allocation of the channels and base stations (to customers), can be computed as the solution of a concave or an integer optimization. We next show that the grand coalition is stable in many different settings, i.e., if all providers cooperate, there is always an operating point that maximizes the providers' aggregate payoff, while offering each a share that removes any incentive to split from the coalition. The optimal cooperation strategy and the stabilizing payoff shares can be obtained in polynomial time by respectively solving the primals and the duals of the above optimizations, using distributed computations and limited exchange of confidential information among the providers. Numerical evaluations reveal that cooperation substantially enhances individual providers' payoffs under the optimal cooperation strategy and several different payoff sharing rules.",
Experimental Characterization of an UWB Propagation Channel in Underground Mines,"An experimental characterization of the ultrawideband (UWB) propagation channel in an underground mine environment over the frequency range from 3 GHz to 10 GHz is reported in this paper. Two kinds of antennas, directional and omnidirectional, were used to investigate the effect of the antenna directivity on the path loss propagation and on the time dispersion parameters in both line-of-sight (LOS) and no-line-of-sight (NLOS) underground galleries. The measurement and simulation results show that the path loss exponents in an underground environment are larger than their counterparts in an indoor environment. In NLOS, the directional-directional (Direct-Direct) antenna combination showed better radiation efficiency for reducing the time dispersion parameters while the omnidirectional-omni directional (Omni-Omni) case resulted better performance in term of path loss. After extracting the channel parameters, a statistical modeling of the UWB underground channel based on data measurements was conducted.","Antenna measurements,
Delay,
Frequency measurement,
Directive antennas,
Propagation losses,
Loss measurement,
Receivers"
Generator coherency and area detection in large power systems,"This study provides a new general approach for defining coherent generators in power systems based on the coherency in low-frequency inter-area modes. The disturbance is considered to be distributed in the network by applying random load changes which is the random walk representation of real loads instead of a single fault and coherent generators are obtained by spectrum analysis of the generators velocity variations. In order to find the coherent areas and their borders in the inter-connected networks, non-generating buses are assigned to each group of coherent generator using similar coherency detection techniques. The method is evaluated on two test systems and coherent generators and areas are obtained for different operating points to provide a more accurate grouping approach which is valid across a range of realistic operating points of the system.",
Distributed event-triggered control with network delays and packet losses,This paper presents a distributed event-based control approach to cope with communication delays and packet losses affecting a networked dynamical system consisting of N linear time-invariant coupled systems. Two communication protocols are proposed to deal with these communication effects. It is shown that both protocols preserve the system stability in the sense that the state of every subsystem converges to a small region around the origin if the delay and the number of packet losses are bounded. Analytical expressions for the delay bound and the maximum number of consecutive packet losses are derived. Simulations illustrate the results.,
Opinion mining and sentiment analysis on a Twitter data stream,"Opinion mining and sentiment analysis is a fast growing topic with various world applications, from polls to advertisement placement. Traditionally individuals gather feedback from their friends or relatives before purchasing an item, but today the trend is to identify the opinions of a variety of individuals around the globe using microblogging data. This paper discusses an approach where a publicised stream of tweets from the Twitter microblogging site are preprocessed and classified based on their emotional content as positive, negative and irrelevant; and analyses the performance of various classifying algorithms based on their precision and recall in such cases. Further, the paper exemplifies the applications of this research and its limitations.","Accuracy,
Support vector machines,
Niobium"
Scheduled-Step-Size Affine Projection Algorithm,"An approach for scheduling the step sizes of an adaptive filter using the affine projection algorithm (APA) is proposed so that its mean-square deviation (MSD) learning curve can be guided along a pre-designed trajectory. This approach eliminates the parameter-tuning process and does not require estimating unmeasurable stochastic quantities. Furthermore, a step-size lower bound is derived in random-walk-modeled environments that leads the adaptive filter to achieve the smallest steady-state MSD, while in stationary environments, the closer to zero the step size is, the smaller the steady-state MSD. For efficient memory usage in practice, the schedule is modified from full-table step sizes to a few down-sampled step sizes without performance degradation. In a simulation, the scheduled-step-size APA exhibits fast convergence and produces small steady-state error not only for a white signal but also for various colored input signals for a properly chosen projection order. The proposed algorithm also demonstrates greater robustness over different signal-to-noise ratios than the existing variable-step-size APAs.","Steady-state,
Schedules,
Scheduling,
Vectors,
Convergence,
Projection algorithms,
Robustness"
On Load Distribution over Multipath Networks,"Efficient utilization of network resources, provided by multiple interfaces available on today devices, is critical in facilitating parallel connections through multiple paths. Load distribution strategies in using multiple interfaces for simultaneous data transmission have been studied. This paper presents a thorough literature review of various existing load distribution models, and classifies them in terms of their key functionalities such as traffic splitting and path selection. Based on a number of significant criteria such as the ability to balance load and to maintain packet ordering, along with several other issues, which affect network performance perceived by users, we analyze various examples of existing models, and then compare and identify their exhibited advantages as well as shortcomings.","Load modeling,
Routing,
Load management,
Radiation detectors,
Round robin,
Ad hoc networks,
Bandwidth"
Quantum-Behaved Particle Swarm Optimization: Analysis of Individual Particle Behavior and Parameter Selection,"Quantum-behaved particle swarm optimization (QPSO), motivated by concepts from quantum mechanics and particle swarm optimization (PSO), is a probabilistic optimization algorithm belonging to the bare-bones PSO family. Although it has been shown to perform well in finding the optimal solutions for many optimization problems, there has so far been little analysis on how it works in detail. This paper presents a comprehensive analysis of the QPSO algorithm. In the theoretical analysis, we analyze the behavior of a single particle in QPSO in terms of probability measure. Since the particle's behavior is influenced by the contraction-expansion (CE) coefficient, which is the most important parameter of the algorithm, the goal of the theoretical analysis is to find out the upper bound of the CE coefficient, within which the value of the CE coefficient selected can guarantee the convergence or boundedness of the particle's position. In the experimental analysis, the theoretical results are first validated by stochastic simulations for the particle's behavior. Then, based on the derived upper bound of the CE coefficient, we perform empirical studies on a suite of well-known benchmark functions to show how to control and select the value of the CE coefficient, in order to obtain generally good algorithmic performance in real world applications. Finally, a further performance comparison between QPSO and other variants of PSO on the benchmarks is made to show the efficiency of the QPSO algorithm with the proposed parameter control and selection methods.","parameter selection,
Particle swarm optimization,
quantum behavior,
probabilistic boundedness,
convergence"
Unobtrusive online monitoring of sleep at home,"We describe an online sleep monitoring service, based on unobtrusive ballistocardiography (BCG) measurement in an ordinary bed. The novelty of the system is that the sleep tracking web application is based on measurements from a fully unobtrusive sensor. The BCG signal is measured with a piezoelectric film sensor under the mattress topper, and sent to the web server for analysis. Heart rate and respiratory variation, activity, sleep stages, and stress reactions are inferred based on the signal. The sleep information is presented to the user along with measurements of the sleeping environment (temperature, noise, luminosity) and user-logged tags (e.g. stress, alcohol, exercise). The approach is designed for long-term use at home, allowing users to follow the development of their sleep over months and years. The service has also a medical use, as sleep disorder patients can be measured for long periods before and after interventions.","Sleep apnea,
Heart rate variability,
Monitoring,
Stress,
Temperature measurement"
"Compression of Graphical Structures: Fundamental Limits, Algorithms, and Experiments","Information theory traditionally deals with “conventional data,” be it textual data, image, or video data. However, databases of various sorts have come into existence in recent years for storing “unconventional data” including biological data, social data, web data, topographical maps, and medical data. In compressing such data, one must consider two types of information: the information conveyed by the structure itself, and the information conveyed by the data labels implanted in the structure. In this paper, we attempt to address the former problem by studying information of graphical structures (i.e., unlabeled graphs). As the first step, we consider the Erdös-Rényi graphs G(n,p) over n vertices in which edges are added independently and randomly with probability p. We prove that the structural entropy of G(n,p) is (n;2)h(p)-logn!+o(1)=(n;2)h(p)-nlog+O(n), where h(p)=-plogp-(1-p)log(1-p) is the entropy rate of a conventional memoryless binary source. Then, we propose a two-stage compression algorithm that asymptotically achieves the structural entropy up to the nlog term (i.e., the first two leading terms) of the structural entropy. Our algorithm runs either in time O(n2) in the worst case for any graph or in time O(n+e) on average for graphs generated by G(n,p), where e is the average number of edges. To the best of our knowledge, this is the first provable (asymptotically) optimal graph compressor for Erdös-Rényi graph models. We use combinatorial and analytic techniques such as generating functions, Mellin transform, and poissonization to establish these findings. Our experiments confirm the theoretical results and also show the usefulness of our algorithm for some real-world graphs such as the Internet, biological networks, and social networks.","Entropy,
Partitioning algorithms,
Encoding,
Orbits,
Compression algorithms,
Data structures,
Biological information theory"
NINEPIN: Non-invasive and energy efficient performance isolation in virtualized servers,"A virtualized data center faces important but challenging issue of performance isolation among heterogeneous customer applications. Performance interference resulting from the contention of shared resources among co-located virtual servers has significant impact on the dependability of application QoS. We propose and develop NINEPIN, a non-invasive and energy efficient performance isolation mechanism that mitigates performance interference among heterogeneous applications hosted in virtualized servers. It is capable of increasing data center utility. Its novel hierarchical control framework aligns performance isolation goals with the incentive to regulate the system towards optimal operating conditions. The framework combines machine learning based self-adaptive modeling of performance interference and energy consumption, utility optimization based performance targeting and a robust model predictive control based target tracking. We implement NINEPIN on a virtualized HP ProLiant blade server hosting SPEC CPU2006 and RUBiS benchmark applications. Experimental results demonstrate that NINEPIN outperforms a representative performance isolation approach, Q-Clouds, improving the overall system utility and reducing energy consumption.","Servers,
Interference,
MIMO,
Adaptation models,
Energy consumption,
Predictive models,
Optimization"
Robust Image Alignment for Tampering Detection,"The widespread use of classic and newest technologies available on Internet (e.g., emails, social networks, digital repositories) has induced a growing interest on systems able to protect the visual content against malicious manipulations that could be performed during their transmission. One of the main problems addressed in this context is the authentication of the image received in a communication. This task is usually performed by localizing the regions of the image which have been tampered. To this aim the aligned image should be first registered with the one at the sender by exploiting the information provided by a specific component of the forensic hash associated to the image. In this paper we propose a robust alignment method which makes use of an image hash component based on the Bag of Features paradigm. The proposed signature is attached to the image before transmission and then analyzed at destination to recover the geometric transformations which have been applied to the received image. The estimator is based on a voting procedure in the parameter space of the model used to recover the geometric transformation occurred into the manipulated image. The proposed image hash encodes the spatial distribution of the image features to deal with highly textured and contrasted tampering patterns. A block-wise tampering detection which exploits an histograms of oriented gradients representation is also proposed. A non-uniform quantization of the histogram of oriented gradient space is used to build the signature of each image block for tampering purposes. Experiments show that the proposed approach obtains good margin of performances with respect to state-of-the art methods.","Robustness,
Forensics,
Estimation,
Visualization,
Context,
Watermarking,
Feature extraction"
Spike Detection and Clustering With Unsupervised Wavelet Optimization in Extracellular Neural Recordings,"Automatic and accurate detection of action potentials of unknown waveforms in noisy extracellular neural recordings is an important requirement for developing brain–computer interfaces. This study introduces a new, wavelet-based manifestation variable that combines the wavelet shrinkage denoising with multiscale edge detection for robustly detecting and finding the occurrence time of action potentials in noisy signals. To further improve the detection performance by eliminating the dependence of the method to the choice of the mother wavelet, we propose an unsupervised optimization for best basis selection. Moreover, another unsupervised criterion based on a correlation similarity measure was defined to update the wavelet selection during the clustering to improve the spike sorting performance. The proposed method was compared to several previously proposed methods by using a wide range of realistic simulated data as well as selected experimental recordings of intracortical signals from freely moving rats. The detection performance of the proposed method substantially surpassed previous methods for all signals tested. Moreover, updating the wavelet selection for the clustering task was shown to improve the classification performance with respect to maintaining the same wavelet as for the detection stage.","Multiresolution analysis,
Noise,
Detectors,
Low pass filters,
Noise measurement,
Discrete wavelet transforms"
A System for Seismocardiography-Based Identification of Quiescent Heart Phases: Implications for Cardiac Imaging,"Seismocardiography (SCG), a representation of mechanical heart motion, may more accurately determine periods of cardiac quiescence within a cardiac cycle than the electrically derived electrocardiogram (EKG) and, thus, may have implications for gating in cardiac computed tomography. We designed and implemented a system to synchronously acquire echocardiography, EKG, and SCG data. The device was used to study the variability between EKG and SCG and characterize the relationship between the mechanical and electrical activity of the heart. For each cardiac cycle, the feature of the SCG indicating Aortic Valve Closure was identified and its time position with respect to the EKG was observed. This position was found to vary for different heart rates and between two human subjects. A color map showing the magnitude of the SCG acceleration and computed velocity was derived, allowing for direct visualization of quiescent phases of the cardiac cycle with respect to heart rate.",
Towards elastic and fine-granular bandwidth allocation in spectrum-sliced optical networks,"To overcome the inefficiency of the rigid frequency allocation in traditional wavelength division multiplexing (WDM) networks, the idea of slicing the optical spectrum for elastic and flexible bandwidth allocation has attracted significant interest recently. The resulting network, namely, the spectrum-sliced elastic optical path (SLICE) network, can facilitate both the super-wavelength and sub-wavelength traffic accommodation by allocating an appropriate number of sub-carriers. Compared to traditional wavelength routed WDM networks (WRNs), SLICE networks have the advantages of higher spectrum efficiency (through the elimination of spectrum gaps or guard-bands when possible) and better signal quality (by overcoming various impairments), thanks to the orthogonal frequency division multiplexing technology. To accommodate traffic demands in SLICE networks, the process of routing and spectrum allocation (RSA) has to be employed, which is different from and more challenging than the traditional routing and wavelength assignment problem in WRNs. In this work, we comprehensively study the RSA problem assuming the presence of known static or off-line traffic. We formally define the static RSA problem and show the NP-hardness of the optimal RSA problem. Integer linear programing models are then formulated to achieve different optimization goals in SLICE networks. We further analyze the lower/upper bound of the spectrum resources (i.e., sub-carriers) in SLICE networks with uniform traffic demands. To efficiently resolve the RSA problem in a large-scale network, we also propose two efficient algorithms, namely, the shortest path with maximum spectrum reuse algorithm, and the balanced load spectrum allocation algorithm, to minimize the required number of sub-carriers in a SLICE network. Our results show that the proposed algorithms can match the analysis and approximate the optimal solutions from the integer linear programing model.","OFDM,
Routing,
Optical fiber networks,
Resource management,
Indexes,
WDM networks,
Frequency domain analysis"
Generative-Discriminative Basis Learning for Medical Imaging,"This paper presents a novel dimensionality reduction method for classification in medical imaging. The goal is to transform very high-dimensional input (typically, millions of voxels) to a low-dimensional representation (small number of constructed features) that preserves discriminative signal and is clinically interpretable. We formulate the task as a constrained optimization problem that combines generative and discriminative objectives and show how to extend it to the semi-supervised learning (SSL) setting. We propose a novel large-scale algorithm to solve the resulting optimization problem. In the fully supervised case, we demonstrate accuracy rates that are better than or comparable to state-of-the-art algorithms on several datasets while producing a representation of the group difference that is consistent with prior clinical reports. Effectiveness of the proposed algorithm for SSL is evaluated with both benchmark and medical imaging datasets. In the benchmark datasets, the results are better than or comparable to the state-of-the-art methods for SSL. For evaluation of the SSL setting in medical datasets, we use images of subjects with mild cognitive impairment (MCI), which is believed to be a precursor to Alzheimer's disease (AD), as unlabeled data. AD subjects and normal control (NC) subjects are used as labeled data, and we try to predict conversion from MCI to AD on follow-up. The semi-supervised extension of this method not only improves the generalization accuracy for the labeled data (AD/NC) slightly but is also able to predict subjects which are likely to converge to AD.","Matrix decomposition,
Jacobian matrices,
Biomedical imaging,
Optimization,
Machine learning,
Image reconstruction,
Loading"
An Inductively Powered Implantable Blood Flow Sensor Microsystem for Vascular Grafts,"Monitoring blood flow rate inside prosthetic vascular grafts enables an early detection of the graft degradation, followed by the timely intervention and prevention of the graft failure. This paper presents an inductively powered implantable blood flow sensor microsystem with bidirectional telemetry. The microsystem integrates silicon nanowire (SiNW) sensors with tunable piezoresistivity, an ultralow-power application-specific integrated circuit (ASIC), and two miniature coils that are coupled with a larger coil in an external monitoring unit to form a passive wireless link. Operating at 13.56-MHz carrier frequency, the implantable microsystem receives power and command from the external unit and backscatters digitized sensor readout through the coupling coils. The ASIC fabricated in 0.18-μm CMOS process occupies an active area of 1.5 × 1.78 mm
2
and consumes 21.6 μW only. The sensors based on the SiNW and diaphragm structure provide a gauge factor higher than 300 when a small negative tuning voltage (−0.5–0 V) is applied. The measured performance of the pressure sensor and ASIC has demonstrated 0.176 mmHg/√Hz sensing resolution.","Coils,
Application specific integrated circuits,
Wireless communication,
Implants,
Blood flow,
Wireless sensor networks,
Piezoresistance"
Bounding the Coding Advantage of Combination Network Coding in Undirected Networks,"We refer to network coding schemes in which information flows propagate along a combination network topology as combination network coding (CNC). CNC and its variations are the first network coding schemes studied in the literature, and so far still represent arguably the most important class of known structures where network coding is nontrivial. Our main goal in this paper is to seek a thorough understanding on the advantage of CNC in undirected networks, by proving a tight bound on its potential both in improving multicast throughput (the coding advantage) and in reducing multicast cost under a linear link flow cost model (the cost advantage). We prepare three results towards this goal. First, we show that the cost advantage of CNC is upper-bounded by 9/8 under the uniform link cost setting. Second, we show that achieving a larger cost advantage is impossible by considering an arbitrary instead of uniform link cost configuration. Third, we show that in a given network topology, for any form of network coding, the coding advantage under arbitrary link capacity configurations is always upper-bounded by the cost advantage under arbitrary link cost configurations. Combining the three results together, we conclude that the potential for CNC to improve throughput and to reduce routing cost are both upper-bounded by a factor of 9/8. The bound is tight since it is achieved in specific networks. This result can be viewed as a natural step towards improving the bound of 2 proved for the coding advantage of general multicast network coding.","Network coding,
Encoding,
Computer numerical control,
Throughput,
Receivers,
Network topology,
Topology"
Separating Function Estimation Tests: A New Perspective on Binary Composite Hypothesis Testing,"In this paper, we study some relationships between the detection and estimation theories for a binary composite hypothesis test H0 against H1 and a related estimation problem. We start with a one-dimensional (1D) space for the unknown parameter space and one-sided hypothesis problems and then extend out results into more general cases. For one-sided tests, we show that the uniformly most powerful (UMP) test is achieved by comparing the minimum variance and unbiased estimator (MVUE) of the unknown parameter with a threshold. Thus for the case where the UMP test does not exist, the MVUE of the unknown parameter does not exist either. Therefore for such cases, a good estimator of the unknown parameter is deemed as a good decision statistic for the test. For a more general class of composite testing with multiple unknown parameters, we prove that the MVUE of a separating function (SF) can serve as the optimal decision statistic for the UMP unbiased test where the SF is continuous, differentiable, positive for all parameters under H1 and is negative for the parameters under H0. We then prove that the UMP unbiased statistic is equal to the MVUE of an SF. In many problems with multiple unknown parameters, the UMP test does not exist. For such cases, we show that if one detector between two detectors has a better receiver operating characteristic (ROC) curve, then using its decision statistic we can estimate the SF more ε-accurately, in probability. For example, the SF is the signal-to-noise ratio (SNR) in some problems. These results motivate us to introduce new suboptimal SF-estimator tests (SFETs) which are easy to derive for many problems. Finally, we provide some practical examples to study the relationship between the decision statistic of a test and the estimator of its corresponding SF.",
Fisheye Video Correction,"Various types of video can be captured with fisheye lenses; their wide field of view is particularly suited to surveillance video. However, fisheye lenses introduce distortion, and this changes as objects in the scene move, making fisheye video difficult to interpret. Current still fisheye image correction methods are either limited to small angles of view, or are strongly content dependent, and therefore unsuitable for processing video streams. We present an efficient and robust scheme for fisheye video correction, which minimizes time-varying distortion and preserves salient content in a coherent manner. Our optimization process is controlled by user annotation, and takes into account a wide set of measures addressing different aspects of natural scene appearance. Each is represented as a quadratic term in an energy minimization problem, leading to a closed-form solution via a sparse linear system. We illustrate our method with a range of examples, demonstrating coherent natural-looking video output. The visual quality of individual frames is comparable to those produced by state-of-the-art methods for fisheye still photograph correction.","Lenses,
Streaming media,
Cameras,
Shape analysis,
Optimization,
Optical distortion"
Sparse Ensemble Learning for Concept Detection,"This work presents a novel sparse ensemble learning scheme for concept detection in videos. The proposed ensemble first exploits a sparse non-negative matrix factorization (NMF) process to represent data instances in parts and partition the data space into localities, and then coordinates the individual classifiers in each locality for final classification. In the sparse NMF, data exemplars are projected to a set of locality bases, in which the non-negative superposition of basis images reconstructs the original exemplars. This additive combination ensures that each locality captures the characteristics of data exemplars in part, thus enabling the local classifiers to hold reasonable diversity in their own regions of expertise. More importantly, the sparse NMF ensures that an exemplar is projected to only a few bases (localities) with non-zero coefficients. The resultant ensemble model is, therefore, sparse, in the way that only a small number of efficient classifiers in the ensemble will fire on a testing sample. Extensive tests on the TRECVid 08 and 09 datasets show that the proposed ensemble learning achieves promising results and outperforms existing approaches. The proposed scheme is feature-independent, and can be applied in many other large scale pattern recognition problems besides visual concept detection.",
Simulation Study of the Layout Technique for P-hit Single-Event Transient Mitigation via the Source Isolation,"In this paper, a layout technique for P-hit single-event transient (SET) mitigation via source isolation is studied by way of technology-computer-aided-design numerical simulations. The source-isolation layout design methodology is thoroughly discussed for the combinational standard cell. Based on a 90-nm twin-well CMOS technology, the simulation results indicate that the proposed “radiation hardened by design” (RHBD) technique can significantly reduce SET pulsewidth. The effects of the ion strike angles and strike locations on this hardened technique are also studied, and the area penalty is also discussed. When we combine the layout technique that utilizes the quenching effect with the proposed source-isolation layout technique, the RHBD standard-cell library can be further exploited for additional P-hit SET mitigation in the spaceborne integrated-circuit design.","Layout,
Electric potential,
Numerical models,
Transistors,
Integrated circuit modeling,
Substrates,
Simulation"
Fast Semantic Diffusion for Large-Scale Context-Based Image and Video Annotation,"Exploring context information for visual recognition has recently received significant research attention. This paper proposes a novel and highly efficient approach, which is named semantic diffusion, to utilize semantic context for large-scale image and video annotation. Starting from the initial annotation of a large number of semantic concepts (categories), obtained by either machine learning or manual tagging, the proposed approach refines the results using a graph diffusion technique, which recovers the consistency and smoothness of the annotations over a semantic graph. Different from the existing graph-based learning methods that model relations among data samples, the semantic graph captures context by treating the concepts as nodes and the concept affinities as the weights of edges. In particular, our approach is capable of simultaneously improving annotation accuracy and adapting the concept affinities to new test data. The adaptation provides a means to handle domain change between training and test data, which often occurs in practice. Extensive experiments are conducted to improve concept annotation results using Flickr images and TV program videos. Results show consistent and significant performance gain (10 on both image and video data sets). Source codes of the proposed algorithms are available online.",
Simple and Accurate Circuit Simulation Model for Gallium Nitride Power Transistors,"Simple and accurate circuit simulation model for gallium nitride (GaN) power field-effect transistors (FETs) is presented and validated in high-frequency low-voltage synchronous buck (SB) dc-dc power converters. For comparison, simulation results are also presented for the power converter based on silicon power metal-oxide semiconductor (MOS)FETs with similar voltage and current ratings. An improvement in power conversion efficiency of more than 4% is reported with GaN power FETs compared to the best commercially available silicon power MOSFETs in a 19 V/1.2 V, 7 W SB dc-dc power converter with excellent load regulation. A temperature- and frequency-dependent power inductor model is also reported and is shown to be necessary in order to accurately model the converter performance.","Gallium nitride,
Integrated circuit modeling,
Power transistors,
Semiconductor device modeling,
Silicon,
Capacitance,
MOSFETs"
Learning-based model predictive control on a quadrotor: Onboard implementation and experimental results,"In this paper, we present details of the real time implementation onboard a quadrotor helicopter of learning-based model predictive control (LBMPC). LBMPC rigorously combines statistical learning with control engineering, while providing levels of guarantees about safety, robustness, and convergence. Experimental results show that LBMPC can learn physically based updates to an initial model, and how as a result LBMPC improves transient response performance. We demonstrate robustness to mis-learning. Finally, we show the use of LBMPC in an integrated robotic task demonstration-The quadrotor is used to catch a ball thrown with an a priori unknown trajectory.","Vehicle dynamics,
Vectors,
Trajectory,
Vehicles,
Predictive models,
Force,
Robots"
Autonomous Management of Everyday Places for a Personalized Location Provider,"Currently available location technologies such as the global positioning system (GPS) or Wi-Fi fingerprinting are limited, respectively, to outdoor applications or require offline signal learning. In this paper, we present a smart phone-based autonomous construction and management of a personalized location provider in indoor and outdoor environments. Our system makes use of electronic compass and accelerometer, specifically for indoor user tracking. We mainly focus on providing point of interest (POI) locations with room-level accuracy in everyday life. We present a practical tracking model to handle noisy sensors and complicated human movements with unconstrained placement. We also employ a room-level fingerprint-based place-learning technique to generate logical location from the properties of pervasive Wi-Fi radio signals. The key concept is to track the physical location of a user by employing inertial sensors in the smartphone and to aggregate identical POIs by matching logical location. The proposed system does not require a priori signal training since each user incrementally constructs his/her own radio map into their daily lives. We implemented the system on Android phones and validated its practical usage in everyday life through real deployment. The extensive experimental results show that our system is indeed acceptable as a fundamental system for various mobile services on a smartphone.","Context,
Global Positioning System,
Sensors,
IEEE 802.11 Standards,
Accelerometers,
Tracking,
Monitoring"
Modified Iterative-Learning-Control-Based Ramp Metering Strategies for Freeway Traffic Control With Iteration-Dependent Factors,"For a freeway traffic system with strict repeatable pattern, iterative learning control (ILC) has been successfully applied to local ramp metering for a macroscopic freeway environment by formulating the original ramp metering problem as an output tracking, disturbance rejection, and error compensation problem. In this paper, we address the freeway traffic ramp-metering system under a nonstrict repeatable pattern. ILC-based ramp metering and ILC add-on to ALINEA strategies are modified to deal with the presence of iteration-dependent parameters, iteration-dependent desired trajectory, and input constraints. Theoretical analysis and extensive simulations are used to verify the effectiveness of the proposed approaches.",
LTE uplink scheduling algorithms: Performance and challenges,"LTE uses the SC-FDMA radio access technology for its uplink transmission. As a result, resources assigned to the same user must be contiguous in the frequency domain. Several uplink scheduling algorithms were proposed in the literature to fit that constraint. These algorithms take as input a matrix which is used by the Packet Scheduler for an efficient resource allocation. The performance of these algorithms is affected by the paradigm that is used to construct that matrix. Two main paradigms exist in the literature, channel dependent and proportional fairness. In this paper, we evaluate the performance of some LTE uplink scheduling algorithms for both channel dependent and proportional fairness paradigms. As a result, we identify the weaknesses of the existing paradigms and define some challenges for future enhancement.",
A Cloud-Based Architecture for Citizen Services in Smart Cities,"With continuous increase in urban population, the need to plan and implement smart cities based solutions for better urban governance is becoming more evident. These solutions are driven, on the one hand, by innovations in ICT and, on the other hand, to increase the capability and capacity of cities to mitigate environmental, social inclusion, economic growth and sustainable development challenges. In this respect, citizens' science or public participation provides a key input for informed and intelligent planning decision and policy making. However, the challenge here is to facilitate public in acquiring the right contextual information in order to be more productive, innovative and be able to make appropriate decisions which impact on their well being, in particular, and economic and environmental sustainability in general. Such a challenge requires contemporary ICT solutions, such as using Cloud computing, capable of storing and processing significant amount of data and produce intelligent contextual information. However, processing and visualising contextual information in a Cloud environment is not straightforward due to user profiling and contextual segregation of data that could be used in different applications of a smart city. In this regard, we present a Cloud-based architecture for context-aware citizen services for smart cities and walkthrough it using a hypothetical case study.","Cities and towns,
Computer architecture,
Decision making,
Cloud computing,
Sensors,
Context,
Planning"
A Sparse and Spatially Constrained Generative Regression Model for fMRI Data Analysis,"In this study, we present an advanced Bayesian framework for the analysis of functional magnetic resonance imaging (fMRI) data that simultaneously employs both spatial and sparse properties. The basic building block of our method is the general linear regression model that constitutes a well-known probabilistic approach. By treating regression coefficients as random variables, we can apply an enhanced Gibbs distribution function that captures spatial constrains and at the same time allows sparse representation of fMRI time series. The proposed scheme is described as a maximum a posteriori approach, where the known expectation maximization algorithm is applied offering closed-form update equations for the model parameters. We have demonstrated that our method produces improved performance and functional activation detection capabilities in both simulated data and real applications.","Data models,
Mathematical model,
Correlation,
Noise,
Analytical models,
Estimation,
Markov processes"
A low-cost game framework for a home-based stroke rehabilitation system,"Stroke is a major cause of severe physical disability, leading into a variety of impairments. In general, stroke rehabilitation is a process which requires intensive direct physical therapy and is usually guided by physiotherapists. The long and intensive therapy sessions often results in patients losing the motivation to continue with the therapy, and as a result patients do not recover to their prospective. With increasing occurrence of stroke incidence, therapists are under pressure for time. At present most of the rehabilitation programmes are highly human intensive. Thus an innovative game technology that supports stroke rehabilitation may provide new opportunities. The main objective of this paper is to present a new low cost game framework for stroke rehabilitation programme that would increase patients' motivation for therapy, and also to study the feasibility and effect of a new game based technology to support hand and leg rehabilitation. In this paper, some important new game design principles for hand and leg rehabilitation with a standard angle based representation of the full body motion during exercise, for improving the accuracy of stroke exercise are presented. The design of serious games, with important game design principle frequently linked with worthy user engagement, may offer perceptions into how more effective systems can be developed for stroke rehabilitation. The additional bio-signal and online database will enable evaluation of patient s movement performance.","Games,
Medical treatment,
Lead,
Standards,
Legged locomotion"
Analysis of Volume Integral Equation Formulations for Scattering by High-Contrast Penetrable Objects,"The volume integral equation method is applied in electromagnetic scattering from arbitrarily shaped three-dimensional inhomogeneous objects. The properties of the volume electric and magnetic field integral equations (VEFIE and VMFIE) are investigated. Numerical experiments show that if the Galerkin's method with the lowest mixed-order basis functions is used to discretize the equations the accuracy of the VMFIE can be significantly poorer than the accuracy of the VEFIE, in particular, for high-contrast objects at high frequencies. The accuracy of the VMFIE can be essentially improved with full first order (linear) basis functions. The linear basis functions are found to be useful also when a single volume integral equation is used to model a general scatterer where both permittivity and permeability differ from the background.","Integral equations,
Equations,
Permittivity,
Testing,
Accuracy,
Dielectrics,
Scattering"
SEU Recovery Mechanism for SRAM-Based FPGAs,"The application of SRAM-based field-programmable gate arrays (FPGAs) in mission-critical systems requires error-mitigation and recovery techniques to protect them from the errors caused by high-energy radiation, also known as single event upsets (SEUs). For this, modular redundancy and runtime partial reconfiguration are commonly employed techniques. However, the reported solutions feature different tradeoffs in the area overhead and the fault latency. In this paper, we propose a low area-overhead SEU recovery mechanism and describe its application in different self-recoverable architectures, which are experimentally evaluated using a specially designed fault-emulation environment. The environment enables the user to inject faults at selected locations of the configuration memory and experimentally evaluate the reliability of the developed solutions.","Field programmable gate arrays,
Tunneling magnetoresistance,
Error correction codes,
Single event upset,
Random access memory,
Circuit faults,
Hardware"
Incremental gradient on the Grassmannian for online foreground and background separation in subsampled video,"It has recently been shown that only a small number of samples from a low-rank matrix are necessary to reconstruct the entire matrix. We bring this to bear on computer vision problems that utilize low-dimensional subspaces, demonstrating that subsampling can improve computation speed while still allowing for accurate subspace learning. We present GRASTA, Grassmannian Robust Adaptive Subspace Tracking Algorithm, an online algorithm for robust subspace estimation from randomly subsampled data. We consider the specific application of background and foreground separation in video, and we assess GRASTA on separation accuracy and computation time. In one benchmark video example [16], GRASTA achieves a separation rate of 46.3 frames per second, even when run in MATLAB on a personal laptop.","Vectors,
Robustness,
Streaming media,
Equations,
Heuristic algorithms,
Lighting,
Real time systems"
A Scalable Distributed Architecture for Intelligent Vision System,"The complexity of intelligent computer vision systems demands novel system architectures that are capable of integrating various computer vision algorithms into a working system with high scalability. The real-time applications of human-centered computing are based on multiple cameras in current systems, which require a transparent distributed architecture. This paper presents an application-oriented service share model for the generalization of vision processing. Based on the model, a vision system architecture is presented that can readily integrate computer vision processing and make application modules share services and exchange messages transparently. The architecture provides a standard interface for loading various modules and a mechanism for modules to acquire inputs and publish processing results that can be used as inputs by others. Using this architecture, a system can load specific applications without considering the common low-layer data processing. We have implemented a prototype vision system based on the proposed architecture. The latency performance and 3-D track function were tested with the prototype system. The architecture is scalable and open, so it will be useful for supporting the development of an intelligent vision system, as well as a distributed sensor system.","Machine vision,
Computer architecture,
Servers,
Computer vision,
Computational modeling,
Artificial intelligence,
Cameras"
Regional cardiac motion and strain estimation in three-dimensional echocardiography: a validation study in thick-walled univentricular phantoms,"Automatic quantification of regional left ventricular deformation in volumetric ultrasound data remains challenging. Many methods have been proposed to extract myocardial motion, including techniques using block matching, phase-based correlation, differential optical flow methods, and image registration. Our lab previously presented an approach based on elastic registration of subsequent volumes using a B-spline representation of the underlying transformation field. Encouraging results were obtained for the assessment of global left ventricular function, but a thorough validation on a regional level was still lacking. For this purpose, univentricular thick-walled cardiac phantoms were deformed in an experimental setup to locally assess strain accuracy against sonomicrometry as a reference method and to assess whether regions containing stiff inclusions could be detected. Our method showed good correlations against sonomicrometry: r2 was 0.96, 0.92, and 0.84 for the radial (εRR), longitudinal (εLL), and circumferential (εCC) strain, respectively. Absolute strain errors and strain drift were low for εLL (absolute mean error: 2.42%, drift: -1.05%) and εCC (error: 1.79%, drift: -1.33%) and slightly higher for εRR (error: 3.37%, drift: 3.05%). The discriminative power of our methodology was adequate to resolve full transmural inclusions down to 17 mm in diameter, although the inclusion-to-surrounding tissue stiffness ratio was required to be at least 5:2 (absolute difference of 39.42 kPa). When the inclusion-to-surrounding tissue stiffness ratio was lowered to approximately 2:1 (absolute difference of 22.63 kPa), only larger inclusions down to 27 mm in diameter could still be identified. Radial strain was found not to be reliable in identifying dysfunctional regions.",
A Block-Based Pass-Parallel SPIHT Algorithm,"Set-partitioning in hierarchical trees (SPIHT) is a widely used compression algorithm for wavelet-transformed images. One of its main drawbacks is a slow processing speed due to its dynamic processing order that depends on the image contents. To overcome this drawback, this paper presents a modified SPIHT algorithm called block-based pass-parallel SPIHT (BPS). BPS decomposes a wavelet-transformed image into 4 × 4 blocks and simultaneously encodes all the bits in a bit-plane of a 4 × 4 block. To exploit parallelism, BPS reorganizes the three passes of the original SPIHT algorithm and then BPS encodes/decodes the reorganized three passes in a parallel and pipelined manner. The precalculation of the stream length of each pass enables the parallel and pipelined execution of these three passes by not only an encoder but also a decoder. The modification of the processing order slightly degrades the compression efficiency. Experimental results show that the peak signal-to-noise ratio loss by BPS is between approximately 0.23 and 0.59 dB when compared to the original SPIHT algorithm. Both an encoder and a decoder are implemented in the hardware that can process 120 million samples per second at an operating clock frequency of 100 MHz. This processing speed allows a video of size of 1920 × 1080 in the 4:2:2 format to be processed at the rate of 30 frames/s. The gate count of the hardware is about 43.9 K.",
On Performance of Vector OFDM With Linear Receivers,"Vector Orthogonal Frequency Division Multiplexing (OFDM) for single transmit antenna systems is a general transmission scheme, where OFDM and Single-Carrier Frequency Domain Equalization (SC-FDE) can be treated as two special/extreme cases. Due to its flexibility, it has drawn more and more attention recently. So far, all the studies about Vector OFDM assume the Maximum Likelihood (ML) receiver. In this paper, we investigate the performance of Vector OFDM with linear receivers, i.e., the Zero-Forcing (ZF) and Minimum Mean Square Error (MMSE) receivers. We first show that the detection SNR gap between the MMSE and ZF receivers increases with both channel SNR and the vector blocks (VB) size defined in Vector OFDM. Then, it is proved that for both ZF and MMSE receivers, all the transmitted symbols have equal performance. This is different from the Vector OFDM with ML receiver, where different VBs may have different coding gain, and thus may have different performances. We analyze the diversity order for Vector OFDM with MMSE receiver, and show that, regardless of the Vector OFDM symbol length N, the diversity order can be represented as min{[M2-R],D}+1, where M is the VB size, R is the spectrum efficiency in bits/symbol, and D is the maximum delay of the multipath channel. For Vector OFDM with ZF receiver, we show that the diversity order equals 1 and the performance is the same as the conventional OFDM at high SNR.",
A Web Aggregation Approach for Distributed Randomized PageRank Algorithms,"The PageRank algorithm employed at Google assigns a measure of importance to each web page for rankings in search results. In our recent papers, we have proposed a distributed randomized approach for this algorithm, where web pages are treated as agents computing their own PageRank by communicating with linked pages. This paper builds upon this approach to reduce the computation and communication loads for the algorithms. In particular, we develop a method to systematically aggregate the web pages into groups by exploiting the sparsity inherent in the web. For each group, an aggregated PageRank value is computed, which can then be distributed among the group members. We provide a distributed update scheme for the aggregated PageRank along with an analysis on its convergence properties. The method is especially motivated by results on singular perturbation techniques for large-scale Markov chains and multi-agent consensus. A numerical example is provided to illustrate the level of reduction in computation while keeping the error in rankings small.","Vectors,
Eigenvalues and eigenfunctions,
Web pages,
Protocols,
Algorithm design and analysis,
Markov processes,
Educational institutions"
Fault Tolerant Control Allowing Sensor Healthy-to-Faulty and Faulty-to-Healthy Transitions,"In this paper, we present a new sensor fault tolerant control scheme for linear, discrete-time systems. The scheme consists of a bank of estimators, each associated with a sensor or group of sensors, a mechanism for the detection and identification of sensor transitions from healthy-to-faulty and faulty-to-healthy operation, an estimate reconfiguration module, and an estimate-based feedback controller with reference tracking. The detection and identification approach is based on the separation of “healthy” and “faulty” sets, where appropriately selected residual variables remain under healthy or faulty operation, from “after-fault” and “after-recovery” sets, towards which the residual variables “jump” when abrupt sensor faults or recoveries occur in one or more groups of sensors. This “set-separation” approach provides pre-checkable fault tolerance guarantees whenever certain conditions, given in terms of system's known data such as plant and estimator dynamics and bounds on reference and disturbance signals, are satisfied.",
A 10-Bit 80-MS/s Decision-Select Successive Approximation TDC in 65-nm CMOS,"This paper presents a 10-bit 80-MS/s successive approximation time-to-digital converter (TDC) with a decision-select structure for on-chip timing measurement applications. Time-domain successive approximation is realized utilizing a relative timing difference between input and reference timings. While the successive approximation scheme allows high bit resolutions and low power consumptions, the decision-select structure enables fast bit conversions that lead to high sampling rates. The decision-select structure unrolls the successive approximation iteration loop and removes time-consuming timing estimation and adjustment procedures to minimize bit conversion times. As the successive approximation scheme relies on a binary search, exponential delay lines are adopted to achieve good power and noise performances by reducing the total number of delay stages. The proposed TDC uses only 0.048 delay stages per bit conversion. A test-chip prototype fabricated in a 65-nm CMOS technology consumes 9.6 mW at 80-MS/s and demonstrates 0.23-pJ/conversion-step figure-of merit (FOM) and 0.5-LSB single-shot precision.",
Robust Fuzzy Extractors and Authenticated Key Agreement From Close Secrets,"Consider two parties holding samples from correlated distributions
W
and
W
′
, respectively, where these samples are within distance
t
of each other in some metric space. The parties wish to agree on a close-to-uniformly distributed secret key
R
by sending a single message over an insecure channel controlled by an all-powerful adversary who may read and modify anything sent over the channel. We consider both the keyless case, where the parties share no additional secret information, and the keyed case, where the parties share a long-term secret
𝖲𝖪
𝖤𝗑𝗍
that they can use to generate a sequence of session keys
{
R
j
}
using multiple pairs
{(
W
j
,
W
′
j
)}
. The former has applications to, e.g., biometric authentication, while the latter arises in, e.g., the bounded-storage model with errors. We show solutions that improve upon previous work in several respects. The best prior solution for the keyless case with no errors (i.e.,
t=0
) requires the min-entropy of
W
to exceed
2n/3
, where
n
is the bit length of
W
. Our solution applies whenever the min-entropy of
W
exceeds the minimal threshold
n/2
, and yields a longer key.","Robustness,
Measurement,
Cryptography,
Random variables,
Authentication,
Entropy"
Predictive Contour Control With Adaptive Feed Rate,"Contour control is an important issue in motion system development. In this paper, a contour-control methodology combining predictive control and adaptive feed rate is proposed. To reduce the computational time required for online optimization, a simple unconstrained model predictive controller is first designed to perform biaxial contour-position control. The performance index introduced in this paper allows the designer to manipulate the importance between contour error, axial tracking error, and control usage. The controller is then implemented to track diamond and free-form contours. The results demonstrate that the controller is capable of not only tracking both contours with high precision (contour and axial) for steady motions, but also improving contour precision during transient periods. To further reduce the contour error during transient periods, an adaptive feed-rate scheme is proposed, which utilizes the predicted contour error to adjust the feed rate online. This adaptive feed-rate scheme is experimentally validated using diamond and limacon contours. The results demonstrate that in comparison with constant feed-rate schemes, the proposed adaptive feed-rate scheme is capable of significantly reducing the transient contour error at high feed rates, while maintaining comparable tracking performance at low feed rates.","Barium,
Diamond-like carbon,
Mathematical model,
Feeds,
Transient analysis,
Tracking,
Computer numerical control"
Tag-Based Image Retrieval Improved by Augmented Features and Group-Based Refinement,"In this paper, we propose a new tag-based image retrieval framework to improve the retrieval performance of a group of related personal images captured by the same user within a short period of an event by leveraging millions of training web images and their associated rich textual descriptions. For any given query tag (e.g., “car”), the inverted file method is employed to automatically determine the relevant training web images that are associated with the query tag and the irrelevant training web images that are not associated with the query tag. Using these relevant and irrelevant web images as positive and negative training data respectively, we propose a new classification method called support vector machine (SVM) with augmented features (AFSVM) to learn an adapted classifier by leveraging the prelearned SVM classifiers of popular tags that are associated with a large number of relevant training web images. Treating the decision values of one group of test photos from AFSVM classifiers as the initial relevance scores, in the subsequent group-based refinement process, we propose to use the Laplacian regularized least squares method to further refine the relevance scores of test photos by utilizing the visual similarity of the images within the group. Based on the refined relevance scores, our proposed framework can be readily applied to tag-based image retrieval for a group of raw consumer photos without any textual descriptions or a group of Flickr photos with noisy tags. Moreover, we propose a new method to better calculate the relevance scores for Flickr photos. Extensive experiments on two datasets demonstrate the effectiveness of our framework.","Training,
Image retrieval,
Semantics,
Support vector machines,
Noise measurement,
Snow,
Training data"
Feedback Effects in Plasmonic Slot Waveguides Examined Using a Closed Form Model,"Analysis of the feedback effects in plasmonic waveguides is carried out using an analytical model. The closed-form model is extracted from the waveguide physical parameters is simple, accurate, and provides insight into understanding the feedback effects in plasmonic waveguide structures. These feedback effects are utilized to obtain various filter functions using the same base structures, with exceptional tolerance to fabrication imperfections in comparison to its plasmonic and dielectric counterparts.",
Simultaneous and Proportional Force Estimation in Multiple Degrees of Freedom From Intramuscular EMG,"This letter investigates simultaneous and proportional estimation of force in 2 degree-of-freedoms (DoFs) from intramuscular electromyography (EMG). Intramuscular EMG signals from three able-bodied subjects were recorded along with isometric forces in multiple DoF from the right arm. The association between five EMG features and force profiles was modeled using an artificial neural network. Correlation coefficients between the measured and the estimated forces were 0.85 ± 0.056 and 0.88 ± 0.05 without and with post processing, respectively. The results showed that force can be estimated in 2 DoFs with high accuracy and that the degree of performance depended on the force function (task) to be estimated.","Force,
Electromyography,
Estimation,
Muscles,
Educational institutions,
Fingers,
Electrodes"
A codebook-free and annotation-free approach for fine-grained image categorization,"Fine-grained categorization refers to the task of classifying objects that belong to the same basic-level class (e.g. different bird species) and share similar shape or visual appearances. Most of the state-of-the-art basic-level object classification algorithms have difficulties in this challenging problem. One reason for this can be attributed to the popular codebook-based image representation, often resulting in loss of subtle image information that are critical for fine-grained classification. Another way to address this problem is to introduce human annotations of object attributes or key points, a tedious process that is also difficult to generalize to new tasks. In this work, we propose a codebook-free and annotation-free approach for fine-grained image categorization. Instead of using vector-quantized codewords, we obtain an image representation by running a high throughput template matching process using a large number of randomly generated image templates. We then propose a novel bagging-based algorithm to build a final classifier by aggregating a set of discriminative yet largely uncorrelated classifiers. Experimental results show that our method outperforms state-of-the-art classification approaches on the Caltech-UCSD Birds dataset.","Birds,
Humans,
Training,
Visualization,
Image representation,
Image color analysis,
Vectors"
Introducing the QEST broker: Scaling the IoT by bridging MQTT and REST,"In the “Internet of Things” (IoT) vision the physical world blends with virtual one, while machine-to-machine interaction improve our daily life. Clearly, how these virtual objects are exposed to us is critical, so that their user interface must be designed to support the easiness of usage that is driven by the users' needs, which is different from what machines requires. These two requirements must be solved, and an integrated solution should emerge, if we want to bring the IoT to the 50 billions network that is predicted to became in the next years. We believe that these requirements cannot be met by the same communication protocol, and so we propose a new kind of broker, named QEST that can bridge the two worlds, represented by their state-of-the-art protocols: MQTT and REST. In this paper, we demonstrate that our approach allows rapid development of user-facing IoT systems, while grating machines all the performance they need.",
Enhancement-Mode AlN/GaN MOSHFETs on Si Substrate With Regrown Source/Drain by MOCVD,"High-performance enhancement-mode (E-mode) AlN/GaN metal-oxide-semiconductor heterojunction field-effect transistors (MOSHFETs) on Si substrates have been demonstrated. Record high peak transconductance Gm of 509 mS/mm and maximum drain current Id of 860 mA/mm were achieved for E-mode MOSHFETs with a source/drain spacing value Lsd of 0.7 m. Low gate leakage current (<;10-3 mA/mm) and improved ohmic contact resistance (0.153 Ω·mm) were enabled by a combination of Al2O3 gate dielectric and regrown source/drain contacts. Al2O3 also significantly increases the 2DEG density under the channel, which is beneficial for device performance by reducing the access resistance. The on-resistance is as low as 1.63 mm. The average regrowth interface resistance across the sample was estimated to be 0.056 Ω·mm. The E-mode MOSHFETs exhibit a high Ion/Ioff ratio up to 106.","Gallium nitride,
Logic gates,
HEMTs,
Silicon,
Aluminum oxide,
Substrates,
MODFETs"
SRAM Assist Techniques for Operation in a Wide Voltage Range in 28-nm CMOS,"Reducing static random-access memory (SRAM) operational voltage (Vmin) can greatly improve energy efficiency, yet SRAM Vmin does not scale with technology due to increased process variability. Assist techniques have been shown to improve the operation of SRAM, but previous investigations of assist techniques at design time have either relied on static metrics that do not account for important transient effects or make specific assumptions about failure distributions. This paper uses importance sampling of dynamic failure metrics to quantify and analyze the effect of different assist techniques, array organization, and timing on Vmin at design time. This approach demonstrates that the most effective technique for reducing SRAM Vmin is the negative bitline write assist, resulting in a Vmin of 600 mV for a 28-nm LP process in the typical corner.","Random access memory,
Sampling methods,
Voltage control,
SRAM chips,
Low voltage,
Low power electronics"
Collaborative Vehicular Content Dissemination with Directional Antennas,"We study the performance of collaborative vehicular content dissemination, where the content is distributed within the network by vehicle-to-vehicle opportunistic communications and the vehicle nodes are equipped with directional antennas. Through analysing a large real-world vehicle trace, we adopt an accurate mobility model of Levy-walk to set up the realistic vehicular network simulation environment. Using a fluid approximation, we derive a theoretical model to depict the system performance of content dissemination time. The accuracy of the proposed analysis is confirmed by simulation results, which also show that the directional antenna performs better than the omni-directional antenna in our considered scenario, especially when the antenna beam is well scheduled with small beamwidth and high beam steering rate.",
Mobility Enhanced RPL for Wireless Sensor Networks,"In this paper, we investigate the problem of supporting mobility over RPL (IPv6 Routing Protocol for Low power and Lossy Networks) when applied to route traffic in Wireless Sensor Networks (WSNs). RPL is a routing protocol adapted for information routing with low power, low storage and processing sensor devices, in static topologies commonly found in WSNs, but which is not directly designed for mobile scenarios. Specifically, RPL actively decreases control traffic, at the price of lower reactivity to topology changes. In this paper, we propose to introduce some new mechanisms to the native RPL that reconcile decrease in control traffic and reactivity. They are based on an identification of mobile nodes, and furthermore they enhance RPL behavior in case of node mobility. Our approach will be, henceforth, called ME-RPL (Mobility Enhanced RPL).","Mobile nodes,
Wireless sensor networks,
Routing,
Routing protocols,
Topology"
A Novel Domain Adaptation Bayesian Classifier for Updating Land-Cover Maps With Class Differences in Source and Target Domains,"This paper addresses the problem of land-cover map updating by classification of multitemporal remote-sensing images in the context of domain adaptation (DA). The basic assumptions behind the proposed approach are twofold. The first one is that training data (ground reference information) are available for one of the considered multitemporal acquisitions (source domain) whereas they are not for the other (target domain). The second one is that multitemporal acquisitions (i.e., target and source domains) may be characterized by different sets of classes. Unlike other approaches available in the literature, the proposed DA Bayesian classifier based on maximum a posteriori decision rule (DA-MAP) automatically identifies whether there exist differences between the set of classes in the target and source domains and properly handles these differences in the updating process. The proposed method was tested in different scenarios of increasing complexity related to multitemporal image classification. Experimental results on medium-resolution and very high resolution multitemporal remote-sensing data sets confirm the effectiveness and the reliability of the proposed DA-MAP classifier.","Training,
Computer aided software engineering,
Remote sensing,
Vectors,
Bayesian methods,
Reliability,
Estimation"
An Energy-Efficient and High-Speed Mobile Memory I/O Interface Using Simultaneous Bi-Directional Dual (Base+RF)-Band Signaling,"A fully-integrated 8.4 Gb/s 2.5 pJ/b mobile memory I/O transceiver using simultaneous bidirectionaldual band signaling is presented. Incorporating both RF-band and baseband transceiver designs, this prototype demonstrates an energy-efficient and high-bandwidth solution for future mobile memory I/O interface. The proposed amplitude shift keying (ASK) modulator/demodulator with on-chip band-selective transformer obviates a power hungry pre-emphasis and equalization circuitry, revealing a low-power, compact and standard mobile memory-compatible solution. Designed and fabricated in 65-nm CMOS technology, each RF-band and baseband transceiver consumes 10.5 mW and 11 mW and occupies 0.08 mm2 and 0.06 mm2 die area, respectively. The dual-band transceiver achieves error-free operation (BER <; 10-15 ) with 223- 1 PRBS at 8.4 Gb/s over a distance of 10 cm.",
Application of Contact Graph Routing to LEO satellite DTN communications,"Delay-/Disruption-Tolerant Networking, which originated from research on deep space communications, has enlarged its scope to encompass all challenged networks, including LEO satellite communications. Focusing on single satellite or incomplete constellation cases, the advantages of DTN mainly relate to its ability to cope with disruption and intermittent connectivity, typical of LEOs. This, however, requires the adoption of routing solutions specifically designed for DTNs. Among the many proposals, Contact Graph Routing, designed by NASA for deep space, seems particularly appealing, as it takes advantage of the a priori knowledge of “contacts” between DTN nodes, a characteristic peculiar to both deep space and LEO environments. This paper aims to investigate the suitability of CGR in LEO satellite DTN communications, by focusing on two practical application scenarios: Earth observation and data mule. Results, obtained through a Linux testbed running ION, the DTN Bundle protocol and CGR implementation developed by NASA, highlight the advantages of CGR when applied to LEO satellite communications.",
Wafer-Level Heterogeneous Integration of GaN HEMTs and Si (100) MOSFETs,"This letter demonstrates a new technology for the heterogeneous integration of GaN and Si devices, which is scalable at least up to 4-in wafers and compatible with conventional Si fabrication. The key step in the proposed technology is the fabrication of a Si (100)-GaN-Si hybrid wafer by bonding a silicon (100) on insulator (SOI) wafer to the nitride surface of an AlGaN/GaN on Si (111) wafer. A thin layer of silicon oxide is used to enhance the bonding between the SOI and the AlGaN/GaN wafers. Using this technology, Si pMOSFETs and GaN high-electron-mobility transistors have been fabricated on a 4-in hybrid wafer. Due to the high-temperature stability of GaN as well as the high-quality semiconductor material resulting from the transfer method, these devices exhibit excellent performance. A hybrid power amplifier has been fabricated as a circuit demonstrator, which shows the potential to integrate GaN and Si devices on the same chip to enable new performance in high-efficiency power amplifiers, mixed signal circuits, and digital electronics.","Silicon,
Gallium nitride,
HEMTs,
MODFETs,
Aluminum gallium nitride,
MOSFETs,
Logic gates"
"Graphene-Based
Q
-Switched Erbium-Doped Fiber Laser With Wide Pulse-Repetition-Rate Range","We demonstrated a novel graphene Q-switched erbium-doped fiber laser with wide pulse-repetition-rate range. The Q-switched fiber laser is constructed with a 37-cm linear cavity formed by two fiber Bragg gratings, a section of highly doped erbium fiber, and a graphene saturable absorber. The laser has a low pump threshold of 16.9 mW, a wide range of repetition rate from 31.7 to 236.3 kHz, and minimum pulse duration of 206 ns. The short-cavity laser structure enables laser action free of self-mode-locking effects.",
Hierarchical Filtered Motion for Action Recognition in Crowded Videos,"Action recognition with cluttered and moving background is a challenging problem. One main difficulty lies in the fact that the motion field in an action region is contaminated by the background motions. We propose a hierarchical filtered motion (HFM) method to recognize actions in crowded videos by the use of motion history image (MHI) as basic representations of motion because of its robustness and efficiency. First, we detect interest points as the two-dimensional Harris corners with recent motion, e.g., locations with high intensities in the MHI. Then, a global spatial motion smoothing filter is applied to the gradients of the MHI to eliminate isolated unreliable or noisy motions. At each interest point, a local motion field filter is applied to the smoothed gradients of the MHI by computing structure proximity between any pixel in the local region and the interest point. Thus, the motion at a pixel is enhanced or weakened based on its structure proximity with the interest point. To validate its effectiveness, we characterize the spatial and temporal features by histograms of oriented gradient in the intensity image and the MHI, respectively, and use a Gaussian-mixture-model-based classifier for action recognition. The performance of the proposed approach achieves the state-of-the-art results on the KTH dataset that has clean background. More importantly, we perform cross-dataset action classification and detection experiments, where the KTH dataset is used for training, while the microsoft research (MSR) action dataset II that consists of crowded videos with people moving in the background is used for testing. Our experiments show that the proposed HFM method significantly outperforms existing techniques.","Videos,
Pixel,
Histograms,
History,
Robustness,
Lighting,
Feature extraction"
Turbo Multi-User Detection for OFDM/SDMA Systems Relying on Differential Evolution Aided Iterative Channel Estimation,"A differential evolution (DE) algorithm aided iterative channel estimation and turbo multi-user detection (MUD) scheme is proposed for multi-user multi-input multiple-output aided orthogonal frequency-division multiplexing / space-division multiple-access (OFDM/SDMA) systems. The proposed scheme iteratively exchanges the estimated channel information and the detected data between the channel estimator and MUD employing a turbo technique, which gradually improves the accuracy of the channel estimation and the MUD, especially for the first iteration. Quadrature amplitude modulation (QAM) is employed in most wireless standards by virtue of providing a high throughput. However, the optimal maximum likelihood (ML)-MUD becomes extremely complex for employment in QAM-aided multi-user systems. Hence, two different DE aided MUD schemes, the DE aided minimum symbol error rate (MSER)-MUD as well as the discrete DE aided ML-MUD, were developed, and their achievable performance versus complexity was characterized. The simulation results demonstrate that the proposed DE aided channel estimator is capable of approaching the Cramer-Rao lower bound with just two or three iterations. The ultimate bit error rate lower-bound of the single-user additive white Gaussian noise scenario has been approached in the range of Eb / N0 ≥ 10 dB and Eb / N0 ≥ 6 dB for the DE aided MSER-MUD and the discrete DE aided ML-MUD, respectively.","Multiuser detection,
OFDM,
Multiaccess communication,
Vectors,
Channel estimation,
Optimization,
Modulation"
Characterization of Contact Resistance Stability in MEM Relays With Tungsten Electrodes,"The impact of device operating parameters on the ON-state resistance (RON) of microelectromechanical relays with tungsten (W) electrodes is reported. Due to the susceptibility of W to oxidation, RON increases undesirably over the device operating cycles. This issue is aggravated by Joule heating when the relay is in the on state. The experimental results confirm that shorter ON time, as well as shorter off time, provides for more stable RON with respect to the number of ON/OFF switching cycles.","Relays,
Electrodes,
Switches,
Oxidation,
Resistance,
Circuit stability,
Tungsten"
Opportunistic Spectrum Access in Multiple-Primary-User Environments Under the Packet Collision Constraint,"Cognitive radio (CR) technology has great potential to alleviate spectrum scarcity in wireless communications. It allows secondary users (SUs) to opportunistically access spectrum licensed by primary users (PUs) while protecting PU activity. The protection of the PUs is central to the adoption of this technology since no PU would accommodate SU access to its own detriment. In this paper, we consider an SU that must protect multiple PUs simultaneously. We focus on the PU packet collision probability as the protection metric. The PUs are unslotted and may have different idle/busy time distributions and protection requirements. Under general idle time distributions, we determine the form of the SU optimal access policy and identify two special cases for which the computation of the optimal policy is significantly reduced. We also present a simple algorithm to determine these policies using principles of convex optimization theory. We then derive the optimal policy for the same system when an SU has extra “side information” on PU activity. We evaluate the performance of these policies through simulation.","Sensors,
Measurement,
Interference,
Switches,
Cognitive radio,
Convex functions,
Markov processes"
Merging SenticNet and WordNet-Affect emotion lists for sentiment analysis,"SenticNet is currently one of the most comprehensive freely available semantic resources for opinion mining. However, it only provides numerical polarity scores, while more detailed sentiment-related information for its concepts is often desirable. Another important resource for opinion mining and sentiment analysis is WordNet-Affect, which in turn lacks quantitative information. We report a work on automatically merging these two resources by assigning emotion labels to more than 2700 concepts.",
Investigation of Defects and Errors in Nanomagnetic Logic Circuits,"Nanomagnetic logic circuits have recently gained interest as a possible post CMOS ultralow-power computing platform. In these circuits, single-domain nanomagnets communicate and perform logical computations through nearest neighbor dipole interactions. The state variable is magnetization direction and computations can take place without passing an electric current. Both experiment and theory have shown, however, that errors in circuit operation can sometimes occur. In this paper, we investigate the reasons for this, develop a simple model to explain imperfections in 1-D chains of nanomagnets, and show that it agrees with experiment. Finally, we discuss possible improvements in nanomagnet design suggested by the model to improve error rates.","Magnetic resonance imaging,
Clocks,
Predictive models,
Histograms,
Computational modeling,
Magnetization,
Saturation magnetization"
Residential task scheduling under dynamic pricing using the multiple knapsack method,"A key component of the smart grid is the ability to enable dynamic residential pricing to incentivize the customer and the overall community to utilize energy more uniformly. However, the complications involved require that automated strategies be provided to the customer to achieve this goal. This paper presents a solution to the problem of optimally scheduling a set of residential appliances under day-ahead variable peak pricing in order to minimize the customer's energy bill (and also, simultaneously spread out energy usage). We map the problem to a well known problem in computer science - the multiple knapsack problem - which enables cheap and efficient solutions to the scheduling problem. Results show that this method is effective in meeting its goals.","Home appliances,
Pricing,
Smart grids,
Schedules,
Electricity,
Power demand,
Optimization"
A Polynomial Dynamic Programming Algorithm for Crude Oil Transportation Planning,"Crude oil transportation is a central logistics operation in petrochemical industry because its cost represents a significant part in the cost of petrochemical products. In this paper, we consider the transportation by tankers or trucks. We show that under some realistic assumptions, this problem can be transformed into a single item lot sizing problem with limited production and inventory capacities. We develop a strongly polynomial dynamic programming algorithm to solve it. The problem of crude oil transportation is very difficult. There are few efficient methods in this domain. In the model considered in this paper, crude oil is directly shipped from a supplier port to n client ports to satisfy customer demands over T future periods. The supplier port disposes a fleet of identical tankers with limited capacity. The inventory capacities of customers are limited and time-varying. The backlogging is admitted. The objective is to find an optimal shipment plan minimizing the total cost over the T-period horizon. When the number of tankers is unlimited and customer demands are independent, shipment plans of different customers become independent. This problem can be considered as n independent problems. Each of them can be transformed into a single item lot sizing problem with limited production and inventory capacities, where tanker capacity corresponds to production capacity in classical lot sizing models. The main contributions of this paper are: 1) transformation of a transportation planning problem into a lot-sizing problem; 2) an O(T3) algorithm is proposed to solve it; and 3) the results can also be applied to terrestrial transportation with direct deliveries.",
Timely Data Delivery in a Realistic Bus Network,"WiFi-enabled buses and stops may form the backbone of a metropolitan delay-tolerant network, which exploits nearby communications, temporary storage at stops, and predictable bus mobility to deliver non-real-time information. This paper studies the routing problem in such a network. Assuming that the bus schedule is known, we maximize the delivery probability by a given deadline for each packet. Our approach takes the randomness into account, which stems from road traffic conditions, passengers boarding and alighting, and other factors that affect bus mobility. In this sense, this paper is one of the first to tackle quasi-deterministic mobility scenarios. We propose a simple stochastic model for bus arrivals at stops, supported by a study of real-life traces collected in a large urban network. A succinct graph representation of this model allows us to devise an optimal (under our model) single-copy routing algorithm and then extend it to cases where several copies of the same data are permitted. Through an extensive simulation study, we compare the optimal routing algorithm with three other approaches: 1) minimizing the expected traversal time over our graph; 2) maximizing the delivery probability over an infinite time-horizon; and 3) a recently proposed heuristic based on bus frequencies. We show that our optimal algorithm shows the best performance, but it essentially reduces to minimizing the expected traversal time. When transmissions frequently fail (more than half of the times), the algorithm behaves similarly to a heuristic that maximizes the delivery probability over an infinite time horizon. For reliable transmissions and values of deadlines close to the expected delivery time, the multicopy extension requires only ten copies to almost reach the performance of the costly flooding approach.",
Reliability Analysis of Phasor Measurement Unit Considering Data Uncertainty,This paper proposes a combined statistical and fuzzy Markov method for reliability evaluation of phasor measurement unit (PMU). The major purpose is to deal with uncertainties of reliability data in PMU. The membership functions of reliability parameters can be built based on statistics and fuzzy set theory. The fuzzy hierarchical Markov models are presented to quantify membership functions of multiple reliability indices of the entire PMU. A fuzzy sensitivity analysis index is developed to estimate the effects of parameter uncertainties on the uncertainty of PMU reliability and identify the most sensitive component(s). Numerical results are provided to demonstrate the effectiveness of the proposed techniques.,"Reliability,
Phasor measurement units,
Maintenance engineering,
Power system reliability,
Markov processes,
Uncertainty,
Global Positioning System"
UAVNet: A mobile wireless mesh network using Unmanned Aerial Vehicles,"We developed UAVNet, a framework for the autonomous deployment of a flying Wireless Mesh Network using small quadrocopter-based Unmanned Aerial Vehicles (UAVs). The flying wireless mesh nodes are automatically interconnected to each other and building an IEEE 802.11s wireless mesh network. The implemented UAVNet prototype is able to autonomously interconnect two end systems by setting up an airborne relay, consisting of one or several flying wireless mesh nodes. The developed software includes basic functionality to control the UAVs and to setup, deploy, manage, and monitor a wireless mesh network. Our evaluations have shown that UAVNet can significantly improve network performance.","Wireless communication,
Relays,
Wireless sensor networks,
Throughput,
Software,
Wireless mesh networks,
Communication system security"
Safety Control of Hidden Mode Hybrid Systems,"In this paper, we consider the safety control problem for hidden mode hybrid systems (HMHSs), which are a special class of hybrid automata in which the mode is not available for control. For these systems, safety control is a problem with imperfect state information. We tackle this problem by introducing the notion of nondeterministic discrete information state and by translating the problem to one with perfect state information. The perfect state information control problem is obtained by constructing a new hybrid automaton, whose discrete state is an estimate of the HMHS mode and is, as such, available for control. This problem is solved by computing the capture set and the least restrictive control map for the new hybrid automaton. Sufficient conditions for the termination of the algorithm that computes the capture set are provided. Finally, we show that the solved perfect state information control problem is equivalent to the original problem with imperfect state information under suitable assumptions. We illustrate the application of the proposed technique to a collision avoidance problem between an autonomous vehicle and a human driven vehicle at a traffic intersection.",
Real-Time Compressed- Domain Video Watermarking Resistance to Geometric Distortions,"A proposed real-time video watermarking scheme is transparent and robust to geometric distortions, including rotation with cropping, scaling, aspect ratio change, frame dropping, and swapping.","Discrete wavelet transforms,
Watermarking,
Streaming media,
Histograms,
Video recording,
Discrete cosine transforms,
Real time systems"
Bandwidth-Power Aware Cooperative Multipath Routing for Wireless Multimedia Sensor Networks,"Cooperative communication is becoming an attractive technology as it can greatly improve the spatial diversity without additional antennas. This novel communication paradigm can effectively reduce power consumption via multi-node cooperation and resource allocation. This paper studies the energy-efficient node-disjoint multi-path routing for a given source-destination pair by joint route construction, relay assignment and power allocation methods. We first define a new bandwidth-power aware cooperative multi-path routing (BP-CMPR) problem, and formally prove its NP-hardness. The paper then presents a polynomial-time heuristic algorithm CMPR to solve the above problem. The algorithm adopts the Suurballe's method to find k minimal-weight node-disjoint paths from source to destination on a weighted graph. Then, dynamic programming is used to implement relay assignment and power allocation. The theoretical analysis shows that CMPR can reach approximation factors of 2 and \frac{4}{3} for BP-CMPR under the amplify-and-forward and decode-and-forward schemes respectively. The distributed version of the algorithm DCMPR is also presented for this problem. We also prove that both CMPR and DCMPR construct the same cooperative multi-path routing, and show via simulations that the performance of the proposed scheme is more than 15% better than that of a traditional multi-path routing scheme, and close to the optimal result for BP-CMPR in variety of situations.",
A Hybrid Patch/Slot Implantable Antenna for Biotelemetry Devices,"A single-fed miniaturized hybrid patch/slot implantable antenna is designed and experimentally demonstrated for medical communications service (MICS) (402-405 MHz). By embedding the meander slot and six open slots in the ground, the proposed antenna can obtain effective size reduction at a fixed frequency operation. Compared to traditional planar inverted-F antennas (PIFAs), the proposed method has advantages of good size reduction and also being easy to be optimized to the necessary resonance frequency. The proposed antenna has dimensions of 10×16×1.27 mm3. The simulated and measured bandwidths are 23.9% and 22.8%, respectively.","Slot antennas,
Antenna measurements,
Patch antennas,
Bandwidth,
Biomedical telemetry,
Biomedical monitoring"
"Novel Design Solutions for Remote Access, Acquire and Control of Laboratory Experiments on DC Machines","Laboratory experiments are integral part of science and engineering education. Automation is changing the nature of these laboratories, and the focus of the system designer is on the availability of various interfacing tools to access the laboratory hardware remotely with the integration of computer-supported learning environment. This paper presents the novel design techniques to access experiments on electrical machines remotely through the Web using virtual instrumentation (VI) tools. The general Web-interface architecture is presented to facilitate control and measurement of experimentation parameters online with complete isolation from the electrical line voltage. LabVIEW-supported VI tools are used to create the Web-based automation and control of the experiment hardware. The custom-built electrical hardware is designed to interface the Web server with the experimental resources and to support user-friendly interface to access the data online. The safety issues while operating the electrical machines online are addressed through the control logic designed by the graphical code. The designed system exploits the data acquisition and the LabVIEW features to extend the dc motor and generator experimentation online along with the acquired data that are presented in virtual meters as well as in graphical plots.",
Security Education against Phishing: A Modest Proposal for a Major Rethink,"When tempted by a good deal online, users don't focus on security warnings; rather, they look for signs to confirm a site's trustworthiness. User education needs to focus on challenging and correcting the misconceptions that guide current behavior.","Computer security,
Training,
User centered design,
Social network services"
ML-Based Channel Estimations for Non-Regenerative Relay Networks with Multiple Transmit and Receive Antennas,"This paper investigates the channel estimations in a relay network with multiple transmit and receive antennas, including the estimation of the end-to-end channel matrix and the individual estimation of the transmitter-relay channels and the relay-receiver channels. For the end-to-end channel estimation, instead of directly estimating entries of the channel matrix, we use singular value decomposition (SVD) and estimate its largest singular value and singular vectors, which are then combined to form an estimation of the channel matrix. An approximate maximum-likelihood (ML) estimation is proposed, which is shown to become the exact ML estimation when the time duration of each training step equals the number of antennas at the transmitter. Simulation on the mean square error (MSE) shows that the SVD-based approximate ML estimation performs about the same as the exact ML estimation and is superior to entry-based estimations. For the individual channel estimation, we decompose each channel vector into the product of its length and direction, and find the ML estimation of each. By using an approximation on the probability density function (PDF) of the observations during training, an analytical ML estimation is derived. The ML estimation with the exact PDF is also investigated and a solution is obtained numerically. Simulation on the MSE shows that the two have similar performance. Compared with cascade channel estimations, its performance is superior for the relay-receiver channel estimation and comparable for the transmitter-relay channel estimation. Extension to the general multiple-antenna multiple-relay network is also provided.","Channel estimation,
Relays,
Maximum likelihood estimation,
Training,
Vectors,
Receivers"
The sharing at roadside: Vehicular content distribution using parked vehicles,"In Vehicular Ad Hoc Networks (VANETs), content distribution directly relies on the fleeting and dynamic contacts between moving vehicles, which often leads to prolonged downloading delay and terrible user experience. Deploying Wifi-based Access Points (APs) could relieve this problem, but it often requires a large amount of investment, especially at the city scale. In this paper, we propose the idea of ParkCast, which doesn't need investment, but leverages roadside parking to distribute contents in urban VANETs. With wireless device and rechargable battery, parked vehicles can communicate with any vehicles driving through them. Owing to the extensive parking in cities, available resources and contact opportunities for sharing are largely increased. To each road, parked vehicles at roadside are grouped into a line cluster as far as possible, which is locally coordinated for node selection and data transmission. Such a collaborative design paradigm exploits the sequential contacts between moving vehicles and parked ones, implements sequential file transfer, reduces unnecessary messages and collisions, and then expedites content distribution greatly. We investigate ParkCast through theoretic analysis and realistic survey and simulation. The results prove that our scheme achieve high performance in distribution of contents with different sizes, especially in sparse traffic conditions.","Vehicles,
Magnetic heads,
Roads,
Delay,
Network coding,
Collaboration,
Cities and towns"
Video Super-Resolution Using Codebooks Derived From Key-Frames,"Example-based super-resolution (SR) is an attractive option to Bayesian approaches to enhance image resolution. We use a multiresolution approach to example-based SR and discuss codebook construction for video sequences. We match a block to be super-resolved to a low-resolution version of the reference high-resolution image blocks. Once the match is found, we carefully apply the high-frequency contents of the chosen reference block to the one to be super-resolved. In essence, the method relies on “betting” that if the low-frequency contents of two blocks are very similar, their high-frequency contents also might match. In particular, we are interested in scenarios where examples can be picked up from readily available high-resolution images that are strongly related to the frame to be super-resolved. Hence, they constitute an excellent source of material to construct a dynamic codebook. Here, we propose a method to super-resolve a video using multiple overlapped variable-block-size codebooks. We implemented a mixed-resolution video coding scenario, where some frames are encoded at a higher resolution and can be used to enhance the other lower-resolution ones. In another scenario, we consider the framework where the camera captures a video at a lower resolution and also takes periodic snapshots at a higher resolution. Results indicate substantial gains over interpolation and fixed-codebook SR, and significant gains over previous works as well.","Image resolution,
Strontium,
Motion estimation,
Interpolation,
Databases,
Data mining,
PSNR"
Throughput Improvement by Joint Relay Selection and Link Scheduling in Relay-Assisted Cellular Networks,"We consider joint relay selection and link scheduling to maximize the network throughput in relay-assisted cellular networks. The spatial reuse is leveraged by scheduling multiple links to simultaneously transmit. The coupling among relay selection, link scheduling, and the interference that is introduced by simultaneous transmissions makes this problem hard to solve. We summarize spatial reuse into two forms. The first form of spatial reuse exists among second-hop links, where relay stations transmit to mobile users. The second form of spatial reuse exists between second- and first-hop links, where the base station transmits to relay stations or mobile users. A framework is proposed to decouple the joint problem into the following two subproblems: 1) a frame segmentation problem and 2) a relay selection problem. Under this framework, we propose two algorithms for either only the first form of spatial reuse exists or both forms of spatial reuse exist. Numerical results show that, with the first form of spatial reuse, the performance of the proposed heuristic relay selection algorithm is very close to the optimum. In the given scenario, when both forms of spatial reuse exist and the proposed heuristic frame segmentation algorithm is applied, the throughput is improved by up to more than 50% compared with the case without spatial reuse.",
Outage Probability and Achievable Diversity Order of Opportunistic Relaying in Cognitive Secondary Radio Networks,"In cognitive radio networks, cognitive secondary users (CSUs) can interfere with the primary users (PUs) when they falsely occupy the PU's licensed spectrum. If CSUs in transmission temporarily form a cooperative relaying network, the interference from CSUs to PU can be reduced due to the cooperative diversity. In this paper, the outage performance as well as the achievable diversity order of opportunistic relaying used for cooperative CSUs is investigated. The cooperative relaying network of CSUs is referred to opportunistically relayed cognitive secondary network (ORCSN). Exact outage probabilities and then the diversity order by high SNR approximation are provided under Rayleigh and Nakagami-m fading channels, respectively. It is shown that a spectrum-sensing method used by the CSUs plays an important role in determining the diversity order in ORCSN. Under Rayleigh fading channels, a cooperative sensing enables ORCSN to achieve the full diversity order but a distributed sensing provides the diversity order smaller than one. Under Nakagami-m fading channels, the achievable diversity order is restricted by the Nakagami channel parameters between the PU and the CSUs and also depends on the sensing method. Moreover, the full diversity order can be achieved by a proper selection of the threshold used for spectrum sensing. Numerical investigation is also provided and used to verify the analysis.","Relays,
Fading,
Sensors,
Signal to noise ratio,
Decision support systems,
Nakagami distribution,
Cascading style sheets"
Depth Video Coding Using Adaptive Geometry Based Intra Prediction for 3-D Video Systems,"Depth video coding is an essential part of 3-D video processing systems. Specifically, object boundary regions are important in depth video coding since these regions significantly affect the visual quality of a synthesized view. In this paper, we propose an efficient depth video coding method to determine precise intra prediction modes and thereby reduce the loss of boundary information. To achieve this objective, we analyze and exploit statistical and geometric characteristics of the depth video. Experimental results subsequently show that the proposed method performs better than the original intra prediction of H.264/AVC in terms of bit savings and rendering quality.",
Unsupervised Semantic Feature Discovery for Image Object Retrieval and Tag Refinement,"We have witnessed the exponential growth of images and videos with the prevalence of capture devices and the ease of social services such as Flickr and Facebook. Meanwhile, enormous media collections are along with rich contextual cues such as tags, geo-locations, descriptions, and time. To obtain desired images, users usually issue a query to a search engine using either an image or keywords. Therefore, the existing solutions for image retrieval rely on either the image contents (e.g., low-level features) or the surrounding texts (e.g., descriptions, tags) only. Those solutions usually suffer from low recall rates because small changes in lighting conditions, viewpoints, occlusions, or (missing) noisy tags can degrade the performance significantly. In this work, we tackle the problem by leveraging both the image contents and associated textual information in the social media to approximate the semantic representations for the two modalities. We propose a general framework to augment each image with relevant semantic (visual and textual) features by using graphs among images. The framework automatically discovers relevant semantic features by propagation and selection in textual and visual image graphs in an unsupervised manner. We investigate the effectiveness of the framework when using different optimization methods for maximizing efficiency. The proposed framework can be directly applied to various applications, such as keyword-based image search, image object retrieval, and tag refinement. Experimental results confirm that the proposed framework effectively improves the performance of these emerging image retrieval applications.","Visualization,
Semantics,
Media,
Image retrieval,
Vocabulary,
Accuracy,
Electronic mail"
Improved GPU/CUDA Based Parallel Weather and Research Forecast (WRF) Single Moment 5-Class (WSM5) Cloud Microphysics,"The Weather Research and Forecasting (WRF) model is an atmospheric simulation system which is designed for both operational and research use. WRF is currently in operational use at the National Oceanic and Atmospheric Administration (NOAA)'s national weather service as well as at the air force weather agency and meteorological services worldwide. Getting weather predictions in time using latest advances in atmospheric sciences is a challenge even on the fastest super computers. Timely weather predictions are particularly useful for severe weather events when lives and property are at risk. Microphysics is a crucial but computationally intensive part of WRF. WRF Single Moment 5-class (WSM5) microphysics scheme represents fallout of various types of precipitation, condensation and thermodynamics effects of latent heat release. Therefore, to expedite the computation process, Graphics Processing Units (GPUs) appear an attractive alternative to traditional CPU architectures. In this paper, we accelerate the WSM5 microphysics scheme on GPUs and obtain a considerable speedup thereby significantly reducing the processing time. Such high performance and computationally efήcient GPUs allow us to use higher resolution WRF forecasts. The use of high resolution WRF enables us to compute microphysical processes for increasingly small clouds and water droplets. To implement WSM5 scheme on GPUs, the WRF code was rewritten into CUDA C, a high level data-parallel programming language used on NVIDIA GPU. We observed a reduction in processing time from 16928 ms on CPU to 43.5 ms on a Graphics Processing Unit (GPU). We obtained a speedup of 389× without I/O using a single GPU. Taking I/O transfer times into account, the speedup obtained is 206×. The speedup was further increased by using four GPUs, speedup being 1556× and 357× for without I/O and with I/O, respectively.","Graphics processing unit,
Clouds,
Instruction sets,
Ice,
Snow,
Atmospheric modeling"
Autonomous Depth Adjustment for Underwater Sensor Networks: Design and Applications,To fully understand the ocean environment requires sensing the full water column. Utilizing a depth adjustment system on an underwater sensor network provides this while also improving global sensing and communications. This paper presents a depth adjustment system for waters up to 50 m deep that connects to the aquanode sensor network nodes. We performed experiments characterizing and demonstrating the functionality of the depth adjustment system. We discuss the application of this device in improving acoustic communication and also verify the functionality of a decentralized depth adjustment algorithm that optimizes the placement of the nodes for collecting sensing data.,"Rivers,
Temperature sensors,
Couplers,
Magnetic levitation,
Winches,
Wireless sensor networks"
"Double-Input Converters Based on H-Bridge Cells: Derivation, Small-Signal Modeling, and Power Sharing Analysis","This paper analyzes a new family of dc-dc converters; labeled H-bridge based double-input dc-dc converters. First, it derives four converter topologies by cascading two H-bridge cells and interfacing the cascaded cells to different configurations of inductor, capacitor, and load. Next, it develops a small-signal model of the four converters and combines them into a canonical small-signal model. Finally, it analyzes the power sharing capability of the converters. It also presents simulation and experimental results to verify the theoretical outcomes.","Inductors,
Switches,
Topology,
Mathematical model,
Equations,
Load modeling,
Capacitors"
RankExplorer: Visualization of Ranking Changes in Large Time Series Data,"For many applications involving time series data, people are often interested in the changes of item values over time as well as their ranking changes. For example, people search many words via search engines like Google and Bing every day. Analysts are interested in both the absolute searching number for each word as well as their relative rankings. Both sets of statistics may change over time. For very large time series data with thousands of items, how to visually present ranking changes is an interesting challenge. In this paper, we propose RankExplorer, a novel visualization method based on ThemeRiver to reveal the ranking changes. Our method consists of four major components: 1) a segmentation method which partitions a large set of time series curves into a manageable number of ranking categories; 2) an extended ThemeRiver view with embedded color bars and changing glyphs to show the evolution of aggregation values related to each ranking category over time as well as the content changes in each ranking category; 3) a trend curve to show the degree of ranking changes over time; 4) rich user interactions to support interactive exploration of ranking changes. We have applied our method to some real time series data and the case studies demonstrate that our method can reveal the underlying patterns related to ranking changes which might otherwise be obscured in traditional visualizations.","Image color analysis,
Time series analysis,
Data visualization,
Market research,
Encoding"
Safe semi-autonomous control with enhanced driver modeling,"During semi-autonomous driving, threat assessment is used to determine when controller intervention that overwrites or corrects the driver's input is required. Since today's semi-autonomous systems perform threat assessment by predicting the vehicle's future state while treating the driver's input as a disturbance, controller intervention is limited to just emergency maneuvers. In order to improve vehicle safety and reduce the aggressiveness of maneuvers, threat assessment must occur over longer prediction horizons where driver's behavior cannot be neglected. We propose a framework that divides the problem of semi-autonomous control into two components. The first component reliably predicts the vehicle's potential behavior by using empirical observations of the driver's pose. The second component determines when the semi-autonomous controller should intervene. To quantitatively measure the performance of the proposed approach, we define metrics to evaluate the infor-mativeness of the prediction and the utility of the intervention procedure. A multi-subject driving experiment illustrates the usefulness, with respect to these metrics, of incorporating the driver's pose while designing a semi-autonomous system.","Vehicles,
Trajectory,
Accidents,
Optimization,
Measurement,
Cameras,
Mobile robots"
Scheduling for Network-Coded Multicast,"We consider multicasting using random linear network coding over a multihop wireless network in the bandwidth limited regime. We address the associated medium access problem and propose a scheduling technique that activates hyperarcs rather than links, as in classical scheduling approaches. We encapsulate the constraints on valid network configurations in a conflict graph model and formulate a joint optimization problem taking into account both the network coding subgraph and the schedule. Next, using Lagrangian relaxation, we decompose the overall problem into two subproblems, a multiple-shortest-paths problem and a maximum weighted stable set (MWSS) problem. We show that if we use a greedy heuristic for the MWSS part of the problem, the overall algorithm is completely distributed. We provide extensive simulation results for both the centralized optimal and the decentralized algorithms. The optimal algorithm improves performance by up to a factor of two over widely used techniques such as orthogonal or two-hop-constrained scheduling. The decentralized algorithm is shown to buy its distributed operation with some throughput losses. Experimental results on randomly generated networks suggest that these losses are not large. Finally, we study the power consumption of our scheme and quantify the tradeoff between power and bandwidth efficiency.","Network coding,
Interference,
Wireless networks,
Scheduling,
Vectors,
Optimization"
A Novel Group-Based Handover Authentication Scheme with Privacy Preservation for Mobile WiMAX Networks,"This letter proposes an efficient group-based handover authentication scheme for mobile WiMAX networks. When the first Mobile Station (MS) of the handover group moves from the service Base Station (BS) to a target BS, the service BS transmits all the handover group members security context to the target BS. Thus the rest of the MSs in the same handover group can bypass the Extensible Authentication Protocol (EAP) and the security context transfer phases to directly perform the handover authentication, which obviously reduces handover latency. Moreover, the proposed scheme not only meets the essential security requirements in handover authentication semantics (such as mutual authentication and resisting the domino effect) but also achieves privacy preservation.","Authentication,
Mobile communication,
WiMAX,
Privacy"
A Secure Single Sign-On Mechanism for Distributed Computer Networks,"User identification is an important access control mechanism for client-server networking architectures. The concept of single sign-on can allow legal users to use the unitary token to access different service providers in distributed computer networks. Recently, some user identification schemes have been proposed for distributed computer networks. Unfortunately, most existing schemes cannot preserve user anonymity when possible attacks occur. Also, the additional time-synchronized mechanisms they use may cause extensive overhead costs. To overcome these drawbacks, we propose a secure single sign-on mechanism that is efficient, secure, and suitable for mobile devices in distributed computer networks.",
Authentication and key management for Advanced Metering Infrastructures utilizing physically unclonable functions,"Conventional utility meters are increasingly being replaced with smart meters as smart meter based AMIs (Advanced Metering Infrastructures) provide many benefits over conventional power infrastrucutures. However, security issues pertaining to the data transmission between smart meters and utility servers have been a major concern. With large scale AMI deployments, addressing these issues is challenging. In particular, as data travels through several networks, secure end-to-end communication based on strong authentication mechanisms and a robust and scalable key management schemes are crucial for assuring the confidentiality and the integrity of this data. In this paper, we propose an approach based on PUF (physically unclonable function) technology for providing strong hardware based authentication of smart meters and efficient key management to assure the confidentiality and integrity of messages exchanged between smart meters and the utility. Our approach does not require modifications to the existing smart meter communication. We have developed a proof-of-concept implementation of the proposed approach which is also briefly discussed in the paper.","Cryptography,
System-on-chip,
Authentication,
Protocols,
Standards,
Servers"
Analytical Estimation of Path Duration in Mobile Ad Hoc Networks,"Path duration is an important design parameter that determines the performance of a mobile ad hoc network (MANET). For example, it can be used to estimate the route expiry time parameter for routes in “on demand” routing protocols. This paper proposes an analytical model to estimate path duration in a MANET using the random way point mobility model as a reference. The salient feature of the proposed model is that it establishes a relationship between path duration and MANET design parameters including node density, transmission range, number of hops, and velocity of nodes. Although this relationship has been previously demonstrated through simulations, a detailed analytical model is not available in the literature to present. In particular, the relationship between path duration and node density has not been derived in previous models. The accuracy of the proposed model is validated by comparing the results obtained from the analytical model with the experimental results available in literature and with the results of simulations carried out in ns-2.","Routing protocols,
Mobile ad hoc networks,
Relays,
Analytical models,
Routing,
Stability analysis,
Measurement"
Normalized Energy Density-Based Forensic Detection of Resampled Images,"We propose a new method to detect resampled imagery. The method is based on examining the normalized energy density present within windows of varying size in the second derivative of the image in the frequency domain, and exploiting this characteristic to derive a 19-D feature vector that is used to train a SVM classifier. Experimental results are reported on 7500 raw images from the BOSS database. Comparison with prior work reveals that the proposed algorithm performs similarly for resampling rates greater than 1, and is superior to prior work for resampling rates less than 1. Experiments are performed for both bilinear and bicubic interpolations, and qualitatively similar results are observed for each. Results are also provided for the detection of resampled imagery with noise corruption and JPEG compression. As expected, some degradation in performance is observed as the noise increases or the JPEG quality factor declines.","Forensics,
Interpolation,
Cutoff frequency,
Correlation,
Vectors,
Frequency domain analysis,
Discrete Fourier transforms"
"Neural Modeling of Episodic Memory: Encoding, Retrieval, and Forgetting","This paper presents a neural model that learns episodic traces in response to a continuous stream of sensory input and feedback received from the environment. The proposed model, based on fusion adaptive resonance theory (ART) network, extracts key events and encodes spatio-temporal relations between events by creating cognitive nodes dynamically. The model further incorporates a novel memory search procedure, which performs a continuous parallel search of stored episodic traces. Combined with a mechanism of gradual forgetting, the model is able to achieve a high level of memory performance and robustness, while controlling memory consumption over time. We present experimental studies, where the proposed episodic memory model is evaluated based on the memory consumption for encoding events and episodes as well as recall accuracy using partial and erroneous cues. Our experimental results show that: 1) the model produces highly robust performance in encoding and recalling events and episodes even with incomplete and noisy cues; 2) the model provides enhanced performance in a noisy environment due to the process of forgetting; and 3) compared with prior models of spatio-temporal memory, our model shows a higher tolerance toward noise and errors in the retrieval cues.","Vectors,
Encoding,
Subspace constraints,
Memory management,
Adaptation models,
Robustness,
Computational modeling"
An object-based semantic world model for long-term change detection and semantic querying,"Recent years have seen rising interest in robotic mapping algorithms that operate at the level of objects, rather than two- or three-dimensional occupancy. Such “semantic maps” permit higher-level reasoning than occupancy maps, and are useful for any application that involves dealing with objects, including grasping, change detection, and object search. We describe and experimentally verify such a system aboard a mobile robot equipped with a Microsoft Kinect RGB-D sensor. Our representation is object-based, and makes uniquely weak assumptions about the quality of the perceptual data available; in particular, we perform no explicit object recognition. This allows our system to operate in large, dynamic, and uncon-strained environments, where modeling every object that occurs (or might occur) is impractical. Our dataset, which is publicly available, consists of 67 autonomous runs of our robot over a six-week period in a roughly 1600m2 office environment. We demonstrate two applications built on our system: semantic querying and change detection.","Semantics,
Robot sensing systems,
Pipelines,
Image color analysis,
Robot kinematics,
Object recognition"
Efficient information retrieval for ranked queries in cost-effective cloud environments,"Cloud computing as an emerging technology trend is expected to reshape the advances in information technology. In this paper, we address two fundamental issues in a cloud environment: privacy and efficiency. We first review a private keyword-based file retrieval scheme proposed by Ostrovsky et. al. Then, based on an aggregation and distribution layer (ADL), we present a scheme, termed efficient information retrieval for ranked query (EIRQ), to further reduce querying costs incurred in the cloud. Queries are classified into multiple ranks, where a higher ranked query can retrieve a higher percentage of matched files. Extensive evaluations have been conducted on an analytical model to examine the effectiveness of our scheme.",
From Pictorial Structures to deformable structures,Pictorial Structures (PS) define a probabilistic model of 2D articulated objects in images. Typical PS models assume an object can be represented by a set of rigid parts connected with pairwise constraints that define the prior probability of part configurations. These models are widely used to represent non-rigid articulated objects such as humans and animals despite the fact that such objects have parts that deform non-rigidly. Here we define a new Deformable Structures (DS) model that is a natural extension of previous PS models and that captures the non-rigid shape deformation of the parts. Each part in a DS model is represented by a low-dimensional shape deformation space and pairwise potentials between parts capture how the shape varies with pose and the shape of neighboring parts. A key advantage of such a model is that it more accurately models object boundaries. This enables image likelihood models that are more discriminative than previous PS likelihoods. This likelihood is learned using training imagery annotated using a DS “puppet.” We focus on a human DS model learned from 2D projections of a realistic 3D human body model and use it to infer human poses in images using a form of non-parametric belief propagation.,"Shape,
Joints,
Deformable models,
Training,
Torso,
Solid modeling,
Vectors"
Power-Trading in Wireless Communications: A Cooperative Networking Business Model,"Managing the power resource in battery operated wireless devices is very crucial for extending the lifetime, here we propose the concept of power trading in wireless communications. We present a business model using sealed bid procurement auction based game theory for power-trading in cooperative wireless communication with quality of service (QoS) constraints. We formulate the problem as an auction in a buyer's market sequentially/repeatedly played with a single source and a multiple relay network. The source, in-need of cooperation of a relay due to lack of battery power to communicate with the destination, broadcasts a cooperation-request specifying its QoS requirements. The QoS that we consider here are the bit error rate and the total delay associated with relaying the source data. The relays respond with their bids in terms of Euros/bit, and the source selects the best relay based on the bids. The relays compete with each other to win the game and profit from power trading. Each relay updates its pricing index via reinforcement learning to win the game during successive bidding intervals of the repeated game. Based on this model our results show that the relay node with the best features such as a better wireless channel and a better geographical position with respect to the source and destination nodes has a better chance of winning the game, and hence giving rise to a dominant strategy. More importantly, we show that the gains from the wireless channels can be converted into economic profits which is an attractive feature of the proposed business model for power trading.",
Cascaded Coupled Line Filter With Reconfigurable Bandwidths Using LCP Multilayer Circuit Technology,"This paper presents a new design method for reconfigurable coupled line filters. The main aim is to develop an analytical design procedure for designing this type of reconfigurable filter with any orders and bandwidths. The new design procedure allows not only making the design easy, but also increasing the passband performance by eliminating the impedance transformers needed for matching purposes used in previous filters. A reconfigurable bandpass filter of this type is designed that can switch between three distinct bandwidth states ranging from around 26% to 50% ripple fractional bandwidth (FBW) centered at 2 GHz. In addition, liquid crystal polymer (LCP) multilayer circuit technology, which offers a great flexibility in realizing required even- and odd-mode impedances for a wideband coupled line filter, is deployed to implement the designed filter. The reconfigurable filter exhibits insertion losses ranging from 0.57 dB for the widest passband state to 1.95 dB for the narrowest passband state. The fabricated filter shows good agreement with EM simulated results.","Impedance,
Wideband,
Passband,
Nonhomogeneous media,
Switches,
Equivalent circuits"
Kinect-like depth denoising,"Accuracy and stability of Kinect-like depth data is limited by its generating principle. In order to serve further applications with high quality depth, the preprocessing on depth data is essential. In this paper, we analyze the characteristics of the Kinect-like depth data by examing its generation principle and propose a spatial-temporal denoising algorithm taking into account its special properties. Both the intra-frame spatial correlation and the inter-frame temporal correlation are exploited to fill the depth hole and suppress the depth noise. Moreover, a divisive normalization approach is proposed to assist the noise filtering process. The 3D rendering results of the processed depth demonstrates that the lost depth is recovered in some hole regions and the noise is suppressed with depth features preserved.",
"Social computing: an intersection of recommender systems, trust/reputation systems, and social networks","Computational applications now go beyond personal computing, facilitating collaboration and social interactions. Social computing is an area of information technology concerned with the intersection of human and social studies connected by computer networks. The primary goal of this article is to provide a brief survey of three popular social computing services: recommender systems, trust/reputation systems, and social networks. We approach these services from a data representation perspective and discuss two of their main challenges: network sparsity and coldstart problems. We also present a novel graph model, which provides an abstract taxonomy and a common data representation model for the three services. We are mainly motivated by the power of graph theory in data representation and analysis for social computing services. Through this model, we believe that it becomes clearer that data from different contexts can be related such that new solutions can be explored; thus, it may provide illumination for the aforementioned problems and stimulate new research.","Social network services,
Recommender systems,
Computational modeling,
Data models,
Collaboration,
Communities"
"Guns, swords and data: Clustering of player behavior in computer games in the wild","Behavioral data from computer games can be exceptionally high-dimensional, of massive scale and cover a temporal segment reaching years of real-time and a varying population of users. Clustering of user behavior provides a way to discover behavioral patterns that are actionable for game developers. Interpretability and reliability of clustering results is vital, as decisions based on them affect game design and thus ultimately revenue. Here case studies are presented focusing on clustering analysis applied to high-dimensionality player behavior telemetry, covering a combined total of 260,000 characters from two major commercial game titles: the Massively Multiplayer Online Role-Playing Game Tera and the multi-player strategy war game Battlefield 2: Bad Company 2. K-means and Simplex Volume Maximization clustering were applied to the two datasets, combined with considerations of the design of the games, resulting in actionable behavioral profiles. Depending on the algorithm different insights into the underlying behavior of the population of the two games are provided.","Games,
Telemetry,
Computers,
Clustering algorithms,
Industries,
Feature extraction,
Algorithm design and analysis"
A CMOS Distributed Amplifier With Distributed Active Input Balun Using GBW and Linearity Enhancing Techniques,"A CMOS distributed amplifier (DA) with distributed active input balun is presented that achieves a gain-bandwidth product of 818 GHz, while improving linearity. Each gm cell within the DA employs dual-output two-stage topology that improves gain and linearity without adversely affecting bandwidth (BW) and power. Comprehensive analysis and simulations are carried out to investigate gain, BW, linearity, noise, and stability of the proposed gm cell, and compare them with conventional gm cells. Fabricated in a 65-nm low-power CMOS process, the 0.9-mm2 DA achieves 22 dB of gain and a P1dB of 10 dBm, while consuming dc power of 97 mW from a 1.3-V supply. A distributed balun, designed and fabricated in the same process, using the same gm topology achieves a BW larger than 70 GHz and a gain of 4 dB with 19.5-mW power consumption from 1.3-V supply.",
On-Chip Noise Sensor for Integrated Circuit Susceptibility Investigations,"With the growing concerns about electromagnetic compatibility of integrated circuits, the need for accurate prediction tools and models to reduce risks of noncompliance becomes critical for circuit designers. However, an on-chip characterization of noise is still necessary for model validation and design optimization. Although different on-chip measurement solutions have been proposed for emission issue characterization, no on-chip measurement methods have been proposed to address the susceptibility issues. This paper presents an on-chip noise sensor dedicated to the study of circuit susceptibility to electromagnetic interferences. A demonstration of the sensor measurement performances and benefits is proposed through a study of the susceptibility of a digital core to conducted interferences. Sensor measurements ensure a better characterization of actual coupling of interferences within the circuit and a diagnosis of failure origins.","Noise,
System-on-a-chip,
Computer architecture,
Voltage measurement,
Microprocessors,
Attenuators"
Application of Cognitive Rehabilitation Theory to the Development of Smart Prompting Technologies,"Older adults with cognitive impairments often have difficulty performing instrumental activities of daily living (IADLs). Prompting technologies have gained popularity over the last decade and have the potential to assist these individuals with IADLs in order to live independently. Although prompting techniques are routinely used by caregivers and health care providers to aid individuals with cognitive impairment in maintaining their independence with everyday activities, there is no clear consensus or gold standard regarding prompt content, method of instruction, timing of delivery, or interface of prompt delivery in the gerontology or technology literatures. In this paper, we demonstrate how cognitive rehabilitation principles can inform and advance the development of more effective assistive prompting technologies that could be employed in smart environments. We first describe cognitive rehabilitation theory (CRT) and show how it provides a useful theoretical foundation for guiding the development of assistive technologies for IADL completion. We then use the CRT framework to critically review existing smart prompting technologies to answer questions that will be integral to advancing development of effective smart prompting technologies. Finally, we raise questions for future exploration as well as challenges and suggestions for future directions in this area of research.",
VOCL: An optimized environment for transparent virtualization of graphics processing units,"Graphics processing units (GPUs) have been widely used for general-purpose computation acceleration. However, current programming models such as CUDA and OpenCL can support GPUs only on the local computing node, where the application execution is tightly coupled to the physical GPU hardware. In this work, we propose a virtual OpenCL (VOCL) framework to support the transparent utilization of local or remote GPUs. This framework, based on the OpenCL programming model, exposes physical GPUs as decoupled virtual resources that can be transparently managed independent of the application execution. The proposed framework requires no source code modifications. We also propose various strategies for reducing the overhead caused by data communication and kernel launching and demonstrate about 85% of the data write bandwidth and 90% of the data read bandwidth compared to data write and read, respectively, in a native nonvirtualized environment. We evaluate the performance of VOCL using four real-world applications with various computation and memory access intensities and demonstrate that compute-intensive applications can execute with negligible overhead in the VOCL environment.",
Simulation-Based Joint Estimation of Body Deformation and Elasticity Parameters for Medical Image Analysis,"Estimation of tissue stiffness is an important means of noninvasive cancer detection. Existing elasticity reconstruction methods usually depend on a dense displacement field (inferred from ultrasound or MR images) and known external forces. Many imaging modalities, however, cannot provide details within an organ and therefore cannot provide such a displacement field. Furthermore, force exertion and measurement can be difficult for some internal organs, making boundary forces another missing parameter. We propose a general method for estimating elasticity and boundary forces automatically using an iterative optimization framework, given the desired (target) output surface. During the optimization, the input model is deformed by the simulator, and an objective function based on the distance between the deformed surface and the target surface is minimized numerically. The optimization framework does not depend on a particular simulation method and is therefore suitable for different physical models. We show a positive correlation between clinical prostate cancer stage (a clinical measure of severity) and the recovered elasticity of the organ. Since the surface correspondence is established, our method also provides a nonrigid image registration, where the quality of the deformation fields is guaranteed, as they are computed using a physics-based simulation.",
Multilabel Classification with Principal Label Space Transformation,"We consider a hypercube view to perceive the label space of multilabel classification problems geometrically. The view allows us not only to unify many existing multilabel classification approaches but also design a novel algorithm, principal label space transformation (PLST), that captures key correlations between labels before learning. The simple and efficient PLST relies on only singular value decomposition as the key step. We derive the theoretical guarantee of PLST and evaluate its empirical performance using real-world data sets. Experimental results demonstrate that PLST is faster than the traditional binary relevance approach and is superior to the modern compressive sensing approach in terms of both accuracy and efficiency.",
Improving Convergence Speed and Scalability in OSPF: A Survey,"Open Shortest Path First (OSPF), a link state routing protocol, is a popular interior gateway protocol (IGP) in the Internet. Wide spread deployment and years of experience running the protocol have motivated continuous improvements in its operation as the nature and demands of the routing infrastructures have changed. Modern routing domains need to maintain a very high level of service availability. Hence, OSPF needs to achieve fast convergence to topology changes. Also, the ever-growing size of routing domains, and possible presence of wireless mobile adhoc network (MANET) components, requires highly scalable operation on part of OSPF to avoid routing instability. Recent years have seen significant efforts aimed at improving OSPF's convergence speed as well as scalability and extending OSPF to achieve seamless integration of mobile adhoc networks with conventional wired networks. In this paper, we present a comprehensive survey of these efforts.","Routing protocols,
Routing,
IP networks,
Convergence,
Hardware,
Scalability"
Estimating service response time for elastic cloud applications,"This paper presents a Markovian analytical model to estimate service response time for elastic cloud applications. Given the expected application workload, the number of virtual machine (VM) instances, and the capacity of each VM instance, the model can approximate the mean service time. The mean service time is a critical metric to estimate, and contributes to the SLA end-to-end response time experienced by application users. The end-to-end response time is an aggregated delay of the service time in addition to delays incurred at the network nodes and links. Our analytical model focuses on estimating the mean service time; however, the model is sufficiently general and can be extremely useful in studying cloud performance. Equations for key performance measures are derived. These measures include mean response time, throughput, request loss, queueing probability, and CPU utilization. The correctness of the model has been verified using discrete-event simulation.","Analytical models,
Time factors,
Computational modeling,
Mathematical model,
Load modeling,
Cloud computing,
Conferences"
New Channel Selection Rule for JPEG Steganography,"In this paper, we present a new channel selection rule for joint photographic experts group (JPEG) steganography, which can be utilized to find the discrete cosine transform (DCT) coefficients that may introduce minimal detectable distortion for data hiding. Three factors are considered in our proposed channel selection rule, i.e., the perturbation error (PE), the quantization step (QS), and the magnitude of quantized DCT coefficient to be modified (MQ). Experimental results demonstrate that higher security performance can be obtained in JPEG steganography via our new channel selection rule.","Discrete cosine transforms,
Transform coding,
Quantization,
Image coding,
Security,
Materials,
Educational institutions"
A Unified Matching Framework for Multi-Flow Decode-and-Forward Cooperative Networks,"Recent works have shown that cooperative diversity can be achieved by using relay selection (RS), distributed space-time coding (DSTC), and distributed beam-forming (DBF) in narrow-band decode-and-forward (DF) cooperative networks with one source-and-destination (s-d) pair. However, the joint resource allocation for broadband DF cooperative networks with multiple s-d flows has not received much attention yet. In this paper, a random hypergraph based unified matching framework is proposed, under which five feasible types of multi-flow DF cooperative networks will be considered. In each type, the maximum matching method will be applied to RS, DSTC, and DBF schemes so as to achieve the optimal channel allocation and relay selection with fairness assurance. By analyzing the properties of maximum matching, the outage probability of each s-d pair after resource allocation will be obtained. The results of diversity-multiplexing tradeoff will show that the proposed framework is capable of achieving the full frequency diversity and cooperative diversity for each s-d pair simultaneously, while the frequency multiplexing is equally shared. Based on the unified framework, the random rotation based parallel Hopcroft-Karp (R2PHK) algorithm will then be designed, which can work in each destination node independently, and shall enjoy a poly-logarithmic complexity O(log2loN), where N is the number of channels and lo is a constant.","Relays,
Channel allocation,
Resource management,
Frequency diversity,
Fading,
Radio spectrum management,
Bipartite graph"
Characteristics of Thin-Film Transistors Fabricated on Fluorinated Zinc Oxide,"Thin-film transistors fabricated on fluorinated zinc oxide have been found to exhibit improved electrical characteristics. The dependence of the extent of the improvement on the amount of fluorine, precisely controlled using ion implantation, is investigated. At a fluorine concentration of 1020/cm3, transistors with a relatively high field-effect mobility of ~60 cm2/V·s have been realized. The enhancement is attributed to the passivation of carrier traps by fluorine. Fluorine concentration in excess of 1020/cm3 is found to result in degraded transistor characteristics.","Zinc oxide,
Thin film transistors,
Passivation,
Sputtering,
Logic gates,
Thermal stability"
Multiband and Wideband Monopole Antenna for GSM900 and Other Wireless Applications,"In this letter, the design of a compact monopole antenna for multiband and wideband operations is proposed. The antenna has three distinct frequency bands, centered at 0.94, 2.7, and 4.75 GHz. The antenna has a compact size of only 30 × 40 × 1.57 mm including the ground plane. The multiband and wideband operations are achieved by using an E-shaped slot on the ground plane. The design procedure is also discussed. The frequency bands can be independently controlled by using the parameters of the E-slot. The impedance bandwidth, current distributions, radiation patterns, gain, and efficiency of the antenna are studied by computer simulation and measurements.","Antenna measurements,
Broadband antennas,
Slot antennas,
Wideband,
Resonant frequency,
Gain measurement"
Spectrum sensing based on three-state model to accomplish all-level fairness for co-existing multiple cognitive radio networks,"Spectrum sensing plays a critical role in cognitive radio networks (CRNs). The majority of spectrum sensing algorithms aim to detect the existence of a signal on a channel, i.e., they classify a channel into either busy or idle state, referred to as a two-state sensing model in this paper. While this model works properly when there is only one CRN accessing a channel, it significantly limits the potential and fairness of spectrum access when there are multiple co-existing CRNs. This is because if the secondary users (SUs) from one CRN are accessing a channel, SUs from other CRNs would detect the channel as busy and hence be starved. In this paper, we propose a three-state sensing model that distinguishes the channel into three states: idle, occupied by a primary user, or occupied by a secondary user. This model effectively addresses the fairness concern of the two-state sensing model, and resolves the starvation problem of multiple co-existing CRNs. To accurately detect each state of the three, we develop a two-stage detection procedure. In the first stage, energy detection is employed to identify whether a channel is idle or occupied. If the channel is occupied, the received signal is further analyzed at the second stage to determine whether the signal originates from a primary user or an SU. For the second stage, we design a statistical model and use it for distance estimation. For detection performance, false alarm and miss detection probabilities are theoretically analyzed. Furthermore, we thoroughly analyze the performance of throughput and fairness for the three-state sensing model compared with the two-state sensing model. In terms of fairness, we define a novel performance metric called all-level fairness for all(ALFA) to characterize fairness among CRNs. Extensive simulations are carried out under various scenarios to evaluate the three-state sensing model and verify the aforementioned theoretical analysis.","Sensors,
Estimation,
Measurement,
Analytical models,
Accuracy,
Cognitive radio,
Noise"
Resonant wireless power transfer to ground sensors from a UAV,"Wireless magnetic resonant power transfer is an emerging technology that has many advantages over other wireless power transfer methods due to its safety, lack of interference, and efficiency at medium ranges. In this paper, we develop a wireless magnetic resonant power transfer system that enables unmanned aerial vehicles (UAVs) to provide power to, and recharge batteries of wireless sensors and other electronics far removed from the electric grid. We address the difficulties of implementing and outfitting this system on a UAV with limited payload capabilities and develop a controller that maximizes the received power as the UAV moves into and out of range. We experimentally demonstrate our prototype wireless power transfer system by using a UAV to transfer nearly 5W of power to a ground sensor.","Coils,
Sensors,
Wireless sensor networks,
Wireless communication,
Magnetic resonance,
Voltage control"
Dopant Segregation and Nickel Stanogermanide Contact Formation on \hbox{p}^{+} \hbox{Ge}_{0.947}\hbox{Sn}_{0.053} Source/Drain,"P+Ge1-xSnx is a promising source and drain (S/D) stressor material for Ge p-MOSFETs, and an S/D material in Ge1-xSnx channel p-MOSFETs. In this paper, we investigate the dopant segregation (DS) effects in the stanogermanidation of p+Ge0.947Sn0.053 (boron-doped). A study comparing the contact resistance RC of nickel stanogermanide [Ni(Ge1-xSnx) or Ni(GeSn)] contact on p+Ge1-xSnx and nickel germanide (NiGe) contact on p+ Ge was performed. A more pronounced DS effect is achieved during the stanogermanidation in comparison with the NiGe/p+Ge control. RC is 44% lower in the Ni(Ge1-x Snx)/p+GeSn structure as compared to the NiGe/p+Ge control. The reduced RC is attributed to a more significant DS effect and the lower bandgap of Ge1-xSnx as compared with Ge.","Nickel,
Tin,
MOSFET circuits,
Lattices,
Substrates"
Accurate Localization of Optic Radiation During Neurosurgery in an Interventional MRI Suite,Accurate localization of the optic radiation is key to improving the surgical outcome for patients undergoing anterior temporal lobe resection for the treatment of refractory focal epilepsy. Current commercial interventional magnetic resonance imaging (MRI) scanners are capable of performing anatomical and diffusion weighted imaging and are used for guidance during various neurosurgical procedures. We present an interventional imaging workflow that can accurately localize the optic radiation during surgery. The workflow is driven by a near real-time multichannel nonrigid image registration algorithm that uses both anatomical and fractional anisotropy pre- and intra-operative images. The proposed workflow is implemented on graphical processing units and we perform a warping of the pre-operatively parcellated optic radiation to the intra-operative space in under 3 min making the proposed algorithm suitable for use under the stringent time constraints of neurosurgical procedures. The method was validated using both a numerical phantom and clinical data using pre- and post-operative images from patients who had undergone surgery for treatment of refractory focal epilepsy and shows strong correlation between the observed post-operative visual field deficit and the predicted damage to the optic radiation. We also validate the algorithm using interventional MRI datasets from a small cohort of patients. This work could be of significant utility in image guided interventions and facilitate effective surgical treatments.,"Surgery,
Biomedical optical imaging,
Optical imaging,
Joints,
Magnetic resonance imaging,
Phantoms"
Single-Channel Blind Estimation of Arterial Input Function and Tissue Impulse Response in DCE-MRI,"Multipass dynamic MRI and pharmacokinetic modeling are used to estimate perfusion parameters of leaky capillaries. Curve fitting and nonblind deconvolution are the established methods to derive the perfusion estimates from the observed arterial input function (AIF) and tissue tracer concentration function. These nonblind methods are sensitive to errors in the AIF, measured in some nearby artery or estimated by multichannel blind deconvolution. Here, a single-channel blind deconvolution algorithm is presented, which only uses a single tissue tracer concentration function to estimate the corresponding AIF and tissue impulse response function. That way, many errors affecting these functions are reduced. The validity of the algorithm is supported by simulations and tests on real data from mouse. The corresponding nonblind and multichannel methods are also presented.","Deconvolution,
Convolution,
Signal to noise ratio,
Mice,
Extrapolation,
Delay"
Differential Extrapolation Method for Separating Dielectric and Rough Conductor Losses in Printed Circuit Boards,"Copper foil in printed circuit board (PCB) transmission lines/interconnects is roughened to promote adhesion to dielectric substrates. It is important to characterize PCB substrate dielectrics and correctly separate dielectric and conductor losses, especially as data rates in high-speed digital designs increase. Herein, a differential method is proposed for separating conductor and dielectric losses in PCBs with rough conductors. This approach requires at least three transmission lines with identical, or at least as close as technologically possible, basic geometry parameters of signal trace, distance-to-ground planes, and dielectric properties, while the average peak-to-valley amplitude of surface roughness of the conductor would be different. The peak-to-valley amplitude of conductor roughness is determined from scanning electron microscopy images.","Conductors,
Surface roughness,
Rough surfaces,
Dielectric losses,
Surface impedance,
Transmission line measurements"
Asking and answering questions about unfamiliar APIs: An exploratory study,"The increasing size of APIs and the increase in the number of APIs available imply developers must frequently learn how to use unfamiliar APIs. To identify the types of questions developers want answered when working with unfamiliar APIs and to understand the difficulty they may encounter answering those questions, we conducted a study involving twenty programmers working on different programming tasks, using unfamiliar APIs. Based on the screen captured videos and the verbalization of the participants, we identified twenty different types of questions programmers ask when working with unfamiliar APIs, and provide new insights to the cause of the difficulties programmers encounter when answering questions about the use of APIs. The questions we have identified and the difficulties we observed can be used for evaluating tools aimed at improving API learning, and in identifying areas of the API learning process where tool support is missing, or could be improved.","Programming,
XML,
Videos,
Usability,
Documentation,
Production facilities,
Navigation"
"Moral Decision Making in Autonomous Systems: Enforcement, Moral Emotions, Dignity, Trust, and Deception","As humans are being progressively pushed further downstream in the decision-making process of autonomous systems, the need arises to ensure that moral standards, however defined, are adhered to by these robotic artifacts. While meaningful inroads have been made in this area regarding the use of ethical lethal military robots, including work by our laboratory, these needs transcend the warfighting domain and are pervasive, extending to eldercare, robot nannies, and other forms of service and entertainment robotic platforms. This paper presents an overview of the spectrum and specter of ethical issues raised by the advent of these systems, and various technical results obtained to date by our research group, geared towards managing ethical behavior in autonomous robots in relation to humanity. This includes: 1) the use of an ethical governor capable of restricting robotic behavior to predefined social norms; 2) an ethical adaptor which draws upon the moral emotions to allow a system to constructively and proactively modify its behavior based on the consequences of its actions; 3) the development of models of robotic trust in humans and its dual, deception, drawing on psychological models of interdependence theory; and 4) concluding with an approach towards the maintenance of dignity in human-robot relationships.","Robots,
Ethics,
Human factors,
Adaptation models,
Decision making,
Social implications of technology,
Autonomic systems,
Behavioral science"
"Performance evaluation of object serialization libraries in XML, JSON and binary formats","This paper compares twelve libraries of object serialization from qualitative and quantitative aspects. Those are object serialization in XML, JSON and binary formats. Using each library, a common example is serialized to a file. The size of the serialized file and the processing time are measured during the execution to compare all object serialization libraries. Some libraries show the performance penalty. But it is clear that there is no best solution. Each library makes good in the context it was developed.",
Cyclic Codes From the Two-Prime Sequences,"Cyclic codes are a subclass of linear codes and have wide applications in consumer electronics, data storage systems, and communication systems as they have efficient encoding and decoding algorithms. In this paper, the two-prime sequence is employed to construct several classes of cyclic codes over GF(q). Lower bounds on the minimum weight of these cyclic codes are developed. Some of the codes obtained are optimal or almost optimal. The p-ranks of the twin-prime difference sets and a class of almost difference sets are computed.","Polynomials,
Zinc,
Linear code,
Generators,
Consumer electronics,
Communication systems"
Distributed Battery Micro-Storage Systems Design and Operation in a Deregulated Electricity Market,"This paper covers some design and operation aspects of distributed battery micro-storage systems in a deregulated electricity market system. In this paper, the term “micro” refers to the size of the energy storage (ES) system compared to the grid generation, with a capacity from few kilowatt-hours and up. Generally, ES enhances the performance of renewable distributed generators (DGs) and increases the efficiency of the entire power system. Energy storage allows for leveling the load, shaving peak demands, and furthermore, transacting power with the utility grid. In this paper, different design aspects of distributed micro-storage systems are covered such as system architecture, system sizing, power stage design, battery management system (BMS), economic aspects and operation in a deregulated electricity market with and without renewable DGs.","Batteries,
Inverters,
Circuit faults,
System-on-a-chip,
Electricity,
Adaptation models,
Real time systems"
A Multiband Reconfigurable Power Amplifier for UMTS Handset Applications,"A new practical reconfigurable output network for a multiband reconfigurable power amplifier (PA) is proposed for universal mobile telecommunications system (UMTS) handset applications. The proposed reconfigurable network can reconfigure the output power and the output path, as well as the frequency. It consists of a power-reconfigurable network, a frequency-reconfigurable network, and a path-selection network. In this paper, its reconfiguration principle is described to extract key design parameters for the reconfigurable PA implementation. To demonstrate the performance of the proposed structure, a 5 mm × 6 mm multiband reconfigurable PA module is developed for UMTS high- and low-frequency band application. The fabricated PA module can cover any three bands out of five popular high- and low-frequency UMTS bands. To enhance the efficiency during low output power operation, the authors' stage-bypass technique is also employed. The fabricated PA module showed adjacent channel leakage ratios better than -39 dBc up to the rated linear output power and power-added efficiencies of higher than 39% at Pout=28 dBm over all the UMTS frequency bands. Efficiency degradation was limited to less than 2% compared to the single-band PA. Measured RF performance of the reconfigurable PA validates the usefulness of the proposed reconfigurable structure for multiband UMTS applications.","Switches,
Impedance,
Power generation,
3G mobile communication,
Telephone sets,
Trajectory,
Degradation"
Spatially Adapted Total Variation Model to Remove Multiplicative Noise,"Multiplicative noise removal based on total variation (TV) regularization has been widely researched in image science. In this paper, inspired by the spatially adapted methods for denoising Gaussian noise, we develop a variational model, which combines the TV regularizer with local constraints. It is also related to a TV model with spatially adapted regularization parameters. The automated selection of the regularization parameters is based on the local statistical characteristics of some random variable. The corresponding subproblem can be efficiently solved by the augmented Lagrangian method. Numerical examples demonstrate that the proposed algorithm is able to preserve small image details, whereas the noise in the homogeneous regions is sufficiently removed. As a consequence, our method yields better denoised results than those of the current state-of-the-art methods with respect to the signal-to-noise-ratio values.","Noise,
TV,
Adaptation models,
Minimization,
Numerical models,
Computational modeling,
Noise reduction"
A Decentralized Modular Control Framework for Robust Control of FES-Activated Walker-Assisted Paraplegic Walking Using Terminal Sliding Mode and Fuzzy Logic Control,"A major challenge to developing functional electrical stimulation (FES) systems for paraplegic walking and widespread acceptance of these systems is the design of a robust control strategy that provides satisfactory tracking performance. The systems need to be robust against time-varying properties of neuromusculoskeletal dynamics, day-to-day variations, subject-to-subject variations, external disturbances, and must be easily applied without requiring offline identification during different experimental sessions. Another major problem related to walker-assisted FES-activated walking concerns the high metabolic rate and upper body effort that limit the clinical applications of FES systems. In this paper, we present a novel decentralized modular control framework for robust control of walker-assisted FES-activated walking. For each muscle-joint dynamics, an independent module control is designed, and the dynamics of the plant are identified online. This process requires no prior knowledge about the dynamics of the plant to be controlled and no offline learning phase. The module is based on adaptive fuzzy terminal sliding mode control and fuzzy logic control. The module control adjusts both pulse-amplitude and pulsewidth of the stimulation signal in such a way that upper body effort is minimized and the lower extremity walking pattern lies within a defined boundary of the reference trajectory. The proposed control strategy has been evaluated on three paraplegic subjects. The results showed that accurate tracking performance and smooth walking pattern were achieved. This favorable performance was obtained without requiring offline identification, manual adjustments, and predefined ON/OFF timing of the muscles.",
Differential Microstrip and Slot-Ring Antennas for Millimeter-Wave Silicon Systems,"Differential on-chip microstrip and slot-ring antennas with a quartz superstrate are presented for wafer-scale silicon systems. The antennas are fed at the nonradiating edge, which is compatible with differential coupled-lines, and are built on a 0.13-μ m CMOS process with a layout that meets all the metal density rules. A high radiation efficiency is achieved using a 100- μm quartz superstrate placed on top of the silicon chip. Both antennas have a measured gain varies from about 2 to 3 dBi at 91-94 GHz, with a - 10-dB S11 bandwidth of 7-8 GHz and a simulated radiation efficiency of >;50%. The designs are compatible with single- and multielement transceivers, and with wafer-scale imaging systems and power-combining arrays.",
MIMO Stochastic Model and Capacity Evaluation of On-Body Channels,"The improvement in terms of channel capacity provided by using a MIMO antenna system in personal area networks is investigated. Two on-body channel models derived in the 2.45 GHz frequency band are also presented and applied to two on-body links. The first proposed model uses, for each spatial subchannel, the same average values for the Rician factor, received power, and shadowing deviation. The second model encompasses the polarization loss in the on-body channels by utilizing different values of these parameters per each spatial subchannel. Furthermore, the joint correlation matrix is used instead of the classical Kronecker product. It is shown that the second model results in a better agreement of the achievable capacity with the measured channel. Also, the equal power and waterfilling power allocation schemes are compared in such on-body channels and it is shown that, adopting waterfilling instead of the equal power provides a higher capacity in the low SNR range while yielding the same achievable capacity in high SNR.","Signal to noise ratio,
Rayleigh channels,
Eigenvalues and eigenfunctions,
MIMO,
Correlation,
Antenna measurements"
A Batch-Mode Active Learning Technique Based on Multiple Uncertainty for SVM Classifier,"In this letter, we present a novel batch-mode active learning technique for solving multiclass classification problems by using the support vector machine classifier with the one-against-all architecture. The uncertainty of each unlabeled sample is measured by defining a criterion which not only considers the smallest distance to the decision hyperplanes but also takes into account the distances to other hyperplanes if the sample is within the margin of their decision boundaries. To select batch of most uncertain samples from all over the decision region, the uncertain regions of the classifiers are partitioned into multiple parts depending on the number of geometrical margins of binary classifiers passing on them. Then, a balanced number of most uncertain samples are selected from each part. To minimize the redundancy and keep the diversity among these samples, the kernel k-means clustering algorithm is applied to the set of uncertain samples, and the representative sample (medoid) from each cluster is selected for labeling. The effectiveness of the proposed method is evaluated by comparing it with other batch-mode active learning techniques existing in the literature. Experimental results on two different remote sensing data sets confirmed the effectiveness of the proposed technique.",
Robust Classification Method of Tumor Subtype by Using Correlation Filters,"Tumor classification based on Gene Expression Profiles (GEPs), which is of great benefit to the accurate diagnosis and personalized treatment for different types of tumor, has drawn a great attention in recent years. This paper proposes a novel tumor classification method based on correlation filters to identify the overall pattern of tumor subtype hidden in differentially expressed genes. Concretely, two correlation filters, i.e., Minimum Average Correlation Energy (MACE) and Optimal Tradeoff Synthetic Discriminant Function (OTSDF), are introduced to determine whether a test sample matches the templates synthesized for each subclass. The experiments on six publicly available data sets indicate that the proposed method is robust to noise, and can more effectively avoid the effects of dimensionality curse. Compared with many model-based methods, the correlation filter-based method can achieve better performance when balanced training sets are exploited to synthesize the templates. Particularly, the proposed method can detect the similarity of overall pattern while ignoring small mismatches between test sample and the synthesized template. And it performs well even if only a few training samples are available. More importantly, the experimental results can be visually represented, which is helpful for the further analysis of results.","Correlation,
Tumors,
Training,
Noise,
Feature extraction,
Matched filters,
Robustness"
Variable Stiffness Actuators: A Port-Based Power-Flow Analysis,"Variable stiffness actuators realize a novel class of actuators, which are capable of changing the apparent output stiffness independently of the output position. This is mechanically achieved by the internal introduction of a number of elastic elements and a number of actuated degrees of freedom (DOFs), which determine how the elastic elements are sensed at the output. During the nominal behavior of these actuators, the power flow from the internal actuated DOFs can be such that energy is undesirably stored in the elastic elements because of the specific kinematic structure of the actuator. In this study, we focus on the analysis of the power flow in variable stiffness actuators. More specifically, the analysis is restricted to the kinematic structure of the actuators, in order to show the influence of the topological structure on the power flow, rather than on the realization choices. We define a measure that indicates the ratio between the total amount of power that is injected by the internal actuated DOFs and the power that is captured by the internal elastic elements which, therefore, cannot be used to do work on the load. In order to define the power-flow ratio, we exploit a generic port-based model of variable stiffness actuators, which highlights the kinematic properties of the design and the power flows in the actuator structure.","Actuators,
Kinematics,
Measurement,
Springs,
Robots,
Analytical models,
Network topology"
Hybrid generalized approximate message passing with applications to structured sparsity,"Gaussian and quadratic approximations of message passing algorithms on graphs have attracted considerable attention due to their computational simplicity, analytic tractability, and wide applicability in optimization and statistical inference problems. This paper summarizes a systematic framework for incorporating such approximate message passing (AMP) methods in general graphical models. The key concept is a partition of dependencies of a general graphical model into strong and weak edges, with each weak edge representing a small, linearizable coupling of variables. AMP approximations based on the central limit theorem can be applied to the weak edges and integrated with standard message passing updates on the strong edges. The resulting algorithm, which we call hybrid generalized approximate message passing (Hybrid-GAMP), can yield significantly simpler implementations of sum-product and max-sum loopy belief propagation. By varying the partition between strong and weak edges, a performance-complexity trade-off can be achieved. Structured sparsity problems are studied as an example of this general methodology where there is a natural partition of edges.",
Efficient Sparse Modeling With Automatic Feature Grouping,"For high-dimensional data, it is often desirable to group similar features together during the learning process. This can reduce the estimation variance and improve the stability of feature selection, leading to better generalization. Moreover, it can also help in understanding and interpreting data. Octagonal shrinkage and clustering algorithm for regression (OSCAR) is a recent sparse-modeling approach that uses a l1 -regularizer and a pairwise l∞-regularizer on the feature coefficients to encourage such feature grouping. However, computationally, its optimization procedure is very expensive. In this paper, we propose an efficient solver based on the accelerated gradient method. We show that its key proximal step can be solved by a highly efficient simple iterative group merging algorithm. Given d input features, this reduces the empirical time complexity from O(d2 ~ d5) for the existing solvers to just O(d). Experimental results on a number of toy and real-world datasets demonstrate that OSCAR is a competitive sparse-modeling approach, but with the added ability of automatic feature grouping.",
Symbolic Models and Emergent Models: A Review,"There exists a large conceptual gap between symbolic models and emergent models for the mind. Many emergent models work on low-level sensory data, while many symbolic models deal with high-level abstract (i.e., action) symbols. There has been relatively little study on intermediate representations, mainly because of a lack of knowledge about how representations fully autonomously emerge inside the closed brain skull, using information from the exposed two ends (the sensory end and the motor end). As reviewed here, this situation is changing. A fundamental challenge for emergent models is abstraction, which symbolic models enjoy through human handcrafting. The term abstract refers to properties disassociated with any particular form. Emergent abstraction seems possible, although the brain appears to never receive a computer symbol (e.g., ASCII code) or produce such a symbol. This paper reviews major agent models with an emphasis on representation. It suggests two different ways to relate symbolic representations with emergent representations: One is based on their categorical definitions. The other considers that a symbolic representation corresponds to a brain's outside behaviors observed and handcrafted by other outside human observers; but an emergent representation is inside the brain.","Computational modeling,
Humans,
Brain models,
Computer architecture,
Robots,
Artificial intelligence"
Enhancing candidate link generation for requirements tracing: The cluster hypothesis revisited,"Modern requirements tracing tools employ information retrieval methods to automatically generate candidate links. Due to the inherent trade-off between recall and precision, such methods cannot achieve a high coverage without also retrieving a great number of false positives, causing a significant drop in result accuracy. In this paper, we propose an approach to improving the quality of candidate link generation for the requirements tracing process. We base our research on the cluster hypothesis which suggests that correct and incorrect links can be grouped in high-quality and low-quality clusters respectively. Result accuracy can thus be enhanced by identifying and filtering out low-quality clusters. We describe our approach by investigating three open-source datasets, and further evaluate our work through an industrial study. The results show that our approach outperforms a baseline pruning strategy and that improvements are still possible.","Clustering algorithms,
Humans,
Algorithm design and analysis,
Software,
Gold,
Context,
Software algorithms"
The Development of an Agent-Based Modeling Framework for Simulating Engineering Team Work,"Team working is becoming increasingly important in modern organizations due to its beneficial outcomes. A team's performance levels are determined by complex interactions between the attributes of its individual members, the communication and dynamics between members, the working environment, and the team's work tasks. As organizations evolve, so too does the nature of team working. During the past two decades, product development in engineering organizations has increasingly been undertaken by multidisciplinary integrated product teams. Such increasing complexity means that the nature of research methods for studying teams must also evolve. Accordingly, this paper proposes an agent-based modeling approach for simulating team working within an engineering environment, informed by research conducted in two engineering organizations. The model includes a number of variables at an individual level (competency, motivation, availability, response rate), team level (communication, shared mental models, trust), and task level (difficulty, workflow), which jointly determine team performance (quality, time to complete the task, time spent working on the task). In addition to describing the model's development, the paper also reports the results of various simulation runs that were conducted in response to realistic team working scenarios, together with its validation. Finally, the paper discusses the model's practical applications as a tool for facilitating organizational decision making with respect to optimizing team working.","Industrial psychology,
Mathematical model,
Team working,
Multiagent systems,
Simulation"
Reliability Assessment of Through-Silicon Vias in Multi-Die Stack Packages,"A thermo-mechanical reliability study of through-silicon vias (TSVs) is presented in this paper. TSVs are used to interconnect stacked dies to achieve 3-D packages. As the core of the TSV contains high coefficient of thermal expansion (CTE) copper surrounded by low-CTE SiO2 and Si materials, the thermo-mechanical reliability of TSVs is a concern. When dies with such TSVs are stacked and packaged, the presence of additional structures and associated materials could introduce different thermo-mechanical concerns compared with free-standing wafers. This paper presents 3-D finite-element models for studying the thermo-mechanical stresses in TSVs in free-standing wafers and in stacked dies, which are packaged. Warpage measurements have been used to validate the finite-element modeling approach. The results from the finite-element models show that the TSV stresses in a packaging configuration are typically lower than the TSV stresses in a free-standing wafer configuration. In addition, it is seen that the microbumps connecting adjacent dies experience high magnitude of inelastic strain, indicating that such locations are of reliability concern.","Through-silicon vias,
Strain,
Copper,
Stress,
Three dimensional displays,
Thermomechanical processes,
Substrates"
Model-Based Tomographic Reconstruction of Objects Containing Known Components,"The likelihood of finding manufactured components (surgical tools, implants, etc.) within a tomographic field-of-view has been steadily increasing. One reason is the aging population and proliferation of prosthetic devices, such that more people undergoing diagnostic imaging have existing implants, particularly hip and knee implants. Another reason is that use of intraoperative imaging (e.g., cone-beam CT) for surgical guidance is increasing, wherein surgical tools and devices such as screws and plates are placed within or near to the target anatomy. When these components contain metal, the reconstructed volumes are likely to contain severe artifacts that adversely affect the image quality in tissues both near and far from the component. Because physical models of such components exist, there is a unique opportunity to integrate this knowledge into the reconstruction algorithm to reduce these artifacts. We present a model-based penalized-likelihood estimation approach that explicitly incorporates known information about component geometry and composition. The approach uses an alternating maximization method that jointly estimates the anatomy and the position and pose of each of the known components. We demonstrate that the proposed method can produce nearly artifact-free images even near the boundary of a metal implant in simulated vertebral pedicle screw reconstructions and even under conditions of substantial photon starvation. The simultaneous estimation of device pose also provides quantitative information on device placement that could be valuable to quality assurance and verification of treatment delivery.","Kernel,
Image reconstruction,
Vectors,
Metals,
Implants,
Solid modeling,
Interpolation"
A Unified Approach to Chaos Suppressing and Inducing in a Periodically Forced Family of Nonlinear Oscillators,"This paper finds and investigates the application of single-exponential local decay pulse (SELDP) to suppress and induce chaos in a family of nonlinear oscillators subject to weak damping and external periodic excitations. Fourier series of SELDP defined on a period is derived and the approximate series is extended to that defined on the set of whole positive real numbers. To show the feasibility of the obtained results, we first give an effective design scheme of electrical circuit related to SELDP signal and this may be helpful in future implementations. We concentrate on this case in which the unforced system possesses two homoclinic orbits. In order to apply Melnikov's approach to make the underlying parameter conditions for suppressing and inducing chaos more clear, a generic numerical algorithm is proposed to compute complicated Melnikov functions. Two propositions, serving as designing the correct parameters in the SELDP function are also given. From our study, we find that chaos can be induced (suppressed) according to the corresponding Melnikov functions have (do not have) simple zeros. Our work can help to understand the underlying mechanisms of suppressing and inducing chaos. The simulation results show the effectiveness of our proposed approach.","Chaos,
Orbits,
Oscillators,
Manifolds,
Damping,
Force,
Discharges"
Numerical Sensitivity of Linear Matrix Inequalities Using Shift and Delta Operators,"The numerical sensitivity of linear matrix inequalities (LMIs) arising from discrete-time control with short sampling periods is analyzed using shift and delta operators. The delta operator avoids cancellation problems for short sampling periods, and it includes a system scaling proportional to the inverse of the sampling period. The numerical sensitivity of both these mechanisms is investigated analytically, and verified by numerical examples. The conclusion is that the scaling procedure is (somewhat surprisingly) much more essential for shorter sampling periods than avoiding the cancellation problem.","Sensitivity,
Linear matrix inequalities,
Numerical models,
Educational institutions,
MATLAB,
Convex functions,
Programming"
Automatic segmentation of latent fingerprints,"Latent fingerprints are routinely found at crime scenes due to the inadvertent contact of the criminals' finger tips with various objects. As such, they have been used as crucial evidence for identifying and convicting criminals by law enforcement agencies. However, compared to plain and rolled prints, latent fingerprints usually have poor quality of ridge impressions with small fingerprint area, and contain large overlap between the foreground area (friction ridge pattern) and structured or random noise in the background. Accordingly, latent fingerprint segmentation is a difficult problem. In this paper, we propose a latent fingerprint segmentation algorithm whose goal is to separate the fingerprint region (region of interest) from background. Our algorithm utilizes both ridge orientation and frequency features. The orientation tensor is used to obtain the symmetric patterns of fingerprint ridge orientation, and local Fourier analysis method is used to estimate the local ridge frequency of the latent fingerprint. Candidate fingerprint (foreground) regions are obtained for each feature type; an intersection of regions from orientation and frequency features localizes the true latent fingerprint regions. To verify the viability of the proposed segmentation algorithm, we evaluated the segmentation results in two aspects: a comparison with the ground truth foreground and matching performance based on segmented region.","Image segmentation,
Tensile stress,
Frequency measurement,
NIST,
Feature extraction,
Databases,
Noise measurement"
The Locality of Distributed Symmetry Breaking,"We present new bounds on the locality of several classical symmetry breaking tasks in distributed networks. A sampling of the results include 1) A randomized algorithm for computing a maximal matching (MM) in O(log Δ + (log log n)4) rounds, where Δ is the maximum degree. This improves a 25-year old randomized algorithm of Israeli and Itai that takes O(log n) rounds and is provably optimal for all log Δ in the range [(log log n)4, √log n]. 2) A randomized maximal independent set (MIS) algorithm requiring O(log Δ√log n) rounds, for all Δ, and only 2O(√log log n) rounds when Δ = poly(log n). These improve on the 25-year old O(log n)-round randomized MIS algorithms of Luby and Alon, Babai, and Itai when log Δ ≫ √log n. 3) A randomized (Δ + 1)-coloring algorithm requiring O(log Δ + 2O((√log log n)) rounds, improving on an algorithm of Schneider and Wattenhofer that takes O(log Δ + √log n) rounds. This result implies that an O(Δ)-coloring can be computed in 2O(√log log n) rounds for all Δ, improving on Kothapalli et al.'s O(√log n)-round algorithm. We also introduce a new technique for reducing symmetry breaking problems on low arboricity graphs to low degree graphs. Corollaries of this reduction include MM and MIS algorithms for low arboricity graphs (e.g., planar graphs and graphs that exclude any fixed minor) requiring O(√log n) and O(log2/3 n) rounds w.h.p., respectively.","Algorithm design and analysis,
Computer science,
Color,
Electronic mail,
Computational modeling,
Random variables,
Educational institutions"
A Scalable Memory-Based Reconfigurable Computing Framework for Nanoscale Crossbar,"Nanoscale molecular electronic devices amenable to bottom-up self-assembly into a crossbar structure have emerged as a promising candidate for future electronic systems. To address some of the design challenges in molecular crossbar, we propose “memory-based architecture for reconfigurable computing” (MBARC), where memory, instead of switch-based logic functions, is used as the computing element. MBARC leverages on the fact that regular and periodic structures of molecular crossbar are attractive for a dense memory design. The main idea in MBARC is to partition a logic circuit, store the partitions as multi-input-multi-output lookup tables in a memory array, and then, use a simple CMOS-based scheduler to evaluate the partitions in a topological time-multiplexed manner. Compared to existing reconfigurable nanocomputing models, the proposed memory-based computing has three major advantages: 1) it minimizes the requirement of programmable interconnects (PIs); 2) it minimizes the number of CMOS interfacing elements that are required for level restoration and cascading logic blocks; and 3) it can achieve higher defect tolerance through efficient use of redundancy. Simulation results for a set of ISCAS benchmarks show average improvement of 32% in area, 21% in delay, and 34% in energy per vector compared to the implementation of a nanoscale field-programmable gate array. Effectiveness of the framework is also studied for two large sequential circuits, namely, 2-D discrete cosine transform and eight-tap finite-impulse-response filter.","Switches,
Nanoscale devices,
Molecular electronics,
Self-assembly,
Logic functions,
Periodic structures,
Logic circuits,
Table lookup,
Logic arrays,
Programmable logic arrays"
Assembling 2-D Blocks Into 3-D Chips,"Despite numerous advantages of 3-D integrated circuits (ICs), their commercial success remains limited. In part, this is due to the wide availability of trustworthy intellectual property (IP) blocks developed for 2-D ICs and proven through repeated use. Block-based design reuse is imperative for heterogeneous 3-D ICs where memory, logic, analog, and microelectromechanical systems dies are manufactured at different technology nodes and circuit modules cannot be partitioned among several dies. In this paper, we show how to integrate 2-D IP blocks into 3-D chips without altering their layout. Experiments indicate that the overhead of proposed integration is small, which can help accelerate industry adoption of 3-D integration.","Through-silicon vias,
IP networks,
Logic gates,
Pins,
Integrated circuit interconnections,
Layout"
The vsaUT-II: A novel rotational variable stiffness actuator,"In this paper, the vsaUT-II, a novel rotational variable stiffness actuator, is presented. As the other designs in this class of actuation systems, the vsaUT-II is characterized by the property that the output stiffness can be changed independently of the output position. It consists of two internal elastic elements and two internal actuated degrees of freedom. The mechanical design of the vsaUT-II is such that the apparent output stiffness can be varied by changing the transmission ratio between the elastic elements and the output. This kinematic structure guarantees that the output stiffness can be changed without changing the potential energy stored internally in the elastic elements. This property is validated in simulations with the port-based model of the system and in experiments, through a proper control law design, on the prototype.","Force,
Springs,
Actuators,
Gears,
Robots,
Kinematics,
Prototypes"
Exploiting the Use of DC SCOPF Approximation to Improve Iterative AC SCOPF Algorithms,"This paper focuses on improving the solution techniques for the AC SCOPF problem of active power dispatch by using the DC SCOPF approximation within the SCOPF algorithm. Our approach brings two benefits compared with benchmark SCOPF algorithms: it speeds up the solution of an iterative AC SCOPF algorithm thanks to a more efficient identification of binding contingencies and allows improving the objective by an appropriate choice of a limited number of corrective actions for each contingency. The proposed approach is illustrated on five test systems of 60, 118, 300, 1203, and 2746 buses.","power system security,
approximation theory,
iterative methods,
load dispatching,
load flow"
The physical travelling salesman problem: WCCI 2012 competition,"Numerous competitions have emerged in recent years that allow researchers to evaluate their algorithms on a variety of real-time video games with different degrees of complexity. These competitions, which vary from classical arcade games like Ms Pac-Man to racing simulations (Torcs) and realtime strategy games (StarCraft), are essential to establish a uniform testbed that allows practitioners to refine their algorithms over time. In this paper we propose a new competition to be held for the first time at WCCI 2012: the Physical Travelling Salesman Problem is an open-ended single-player real-time game that removes some of the complexities evident in other video games while preserving some of the most fundamental challenges. This paper motivates and outlines the PTSP and discusses in detail the framework of the competition, including software interfaces, parameter settings, rules and details of submission.","Games,
Navigation,
Marine vehicles,
Real time systems,
Cities and towns,
Acceleration,
Educational institutions"
Towards energy-fairness in asynchronous duty-cycling sensor networks,"In this paper, we investigate the problem of controlling node sleep intervals so as to achieve the min-max energy fairness in asynchronous duty-cycling sensor networks. We propose a mathematical model to describe the energy efficiency of such networks and observe that traditional sleep interval setting strategy, i.e., operating sensor nodes with identical sleep intervals, or intuitive control heuristics, i.e., greedily increasing sleep intervals of sensor nodes with high energy consumption rates, hardly perform well in practice. There is an urgent need to develop an efficient sleep interval control strategy for achieving fair and high energy efficiency. To this end, we theoretically formulate the Sleep Interval Control (SIC) problem and find it a convex optimization problem. By utilizing the convex property, we decompose the original problem and propose a distributed algorithm, called GDSIC. In GDSIC, sensor nodes can tune sleep intervals through a local information exchange such that the maximum energy consumption rate in the network approaches to be minimized. The algorithm is self-adjustable to the traffic load variance and is able to serve as a unified framework for a variety of asynchronous duty-cycling MAC protocols. We implement our approach in a prototype system and test its feasibility and applicability on a 50-node testbed. We further conduct extensive trace-driven simulations to examine the efficiency and scalability of our algorithm with various settings.","Energy consumption,
Silicon carbide,
Protocols,
Receivers,
Wireless sensor networks,
Data communication,
Switching circuits"
Scalable optimal countermeasure selection using implicit enumeration on attack countermeasure trees,"Constraints such as limited security investment cost precludes a security decision maker from implementing all possible countermeasures in a system. Existing analytical model-based security optimization strategies do not prevail for the following reasons: (i) none of these model-based methods offer a way to find optimal security solution in the absence of probability assignments to the model, (ii) methods scale badly as size of the system to model increases and (iii) some methods suffer as they use attack trees (AT) whose structure does not allow for the inclusion of countermeasures while others translate the non-state-space model (e.g., attack response tree) into a state-space model hence causing state-space explosion. In this paper, we use a novel AT paradigm called attack countermeasure tree (ACT) whose structure takes into account attacks as well as countermeasures (in the form of detection and mitigation events). We use greedy and branch and bound techniques to study several objective functions with goals such as minimizing the number of countermeasures, security investment cost in the ACT and maximizing the benefit from implementing a certain countermeasure set in the ACT under different constraints. We cast each optimization problem into an integer programming problem which also allows us to find optimal solution even in the absence of probability assignments to the model. Our method scales well for large ACTs and we compare its efficiency with other approaches.","Investments,
Optimization,
Logic gates,
Analytical models,
Linear programming,
Authentication"
Sparse representation for blind image quality assessment,"Blind image quality assessment (BIQA) is an important yet difficult task in image processing related applications. Existing algorithms for universal BIQA learn a mapping from features of an image to the corresponding subjective quality or divide the image into different distortions before mapping. Although these algorithms are promising, they face the following problems: (1) they require a large number of samples (pairs of distorted image and its subjective quality) to train a robust mapping; (2) they are sensitive to different datasets; and (3) they have to be retrained when new training samples are available. In this paper, we introduce a simple yet effective algorithm based upon the sparse representation of natural scene statistics (NSS) feature. It consists of three key steps: extracting NSS features in the wavelet domain, representing features via sparse coding, and weighting differential mean opinion scores by the sparse coding coefficients to obtain the final visual quality values. Thorough experiments on standard databases show that the proposed algorithm outperforms representative BIQA algorithms and some full-reference metrics.",
Green-aware workload scheduling in geographically distributed data centers,"Renewable (or green) energy, such as solar or wind, has at least partially powered data centers to reduce the environmental impact of traditional energy sources (brown energy with high carbon footprint). In this paper, we propose a holistic workload scheduling algorithm to minimize the brown energy consumption across multiple geographically distributed data centers with renewable energy sources. While green energy supply for a single data center is intermittent due to daily/seasonal effects, our workload scheduling algorithm is aware of different amounts of green energy supply and dynamically schedules the workload across data centers. The scheduling decision adapts to workload and data center cooling dynamics. Our experiments with real workload traces demonstrate that our scheduling algorithm greatly reduces brown energy consumption by up to 40% in comparison with other scheduling policies.","Green products,
Cooling,
Energy consumption,
Optimization,
Scheduling algorithms,
Distributed databases"
Connectivity Maintenance in Mobile Wireless Networks via Constrained Mobility,"We explore distributed mechanisms for maintaining the physical layer connectivity of a mobile wireless network while still permitting significant area coverage. Moreover, we require that these mechanisms maintain connectivity despite the unpredictable wireless propagation behavior found in complex real-world environments. To this end, we propose the Spreadable Connected Autonomic Network (SCAN) algorithm, a fully distributed, on-line, low overhead mechanism for maintaining the connectivity of a mobile wireless network. SCAN leverages knowledge of the local (2-hop) network topology to enable each node to intelligently halt its own movement and thereby avoid network partitioning events. By relying on topology data instead of locality information and deterministic connectivity models, SCAN can be applied in a wide range of realistic operational environments. We believe it is for precisely this reason that, to our best knowledge, SCAN was the first such approach to be implemented in hardware. Here, we present results from our implementation of SCAN, finding that our mobile robotic testbed maintains full connectivity over 99% of the time. Moreover, SCAN achieves this in a complex indoor environment, while still allowing testbed nodes to cover a significant area.","Wireless communication,
Mobile communication,
Maintenance engineering,
Robot sensing systems,
Peer to peer computing,
Robustness"
Dynamic Phasor and Frequency Estimators Considering Decaying DC Components,"When a power system experiences off-nominal conditions such as frequency deviation and power oscillation, the accuracy of phasor estimation may degrade. Moreover, the estimated value deviates farther from the theoretical value because of decaying DC components. New phasor estimators are proposed in this paper. They are able to handle the dynamic characteristics as well as the decaying DC components so as to improve the accuracy of phasor estimation. A new frequency estimator is proposed for this purpose. Two filters are employed to estimate the fundamental component and DC components, respectively. Then, least squares method (LSM) gives accurate estimation by reassigning the estimations obtained by short time Fourier transformation (STFT). The performance of the proposed algorithm is evaluated by computer-simulated signals, EMTDC-generated signals, and signals recorded by a commercial relay from real time digital simulator (RTDS). The evaluation results indicate that the proposed algorithms can achieve accurate phasor estimation, frequency estimation, and even power estimation in presence of frequency deviations and decaying DC components with a minimal increase of computational cost and time delay compared with the conventional STFT.","Estimation,
Frequency estimation,
Power system dynamics,
Heuristic algorithms,
Computational efficiency,
Accuracy,
Signal processing algorithms"
Antialiasing Filter Design for Subpixel Downsampling via Frequency-Domain Analysis,"In this paper, we are concerned with image downsampling using subpixel techniques to achieve superior sharpness for small liquid crystal displays (LCDs). Such a problem exists when a high-resolution image or video is to be displayed on low-resolution display terminals. Limited by the low-resolution display, we have to shrink the image. Signal-processing theory tells us that optimal decimation requires low-pass filtering with a suitable cutoff frequency, followed by downsampling. In doing so, we need to remove many useful image details causing blurring. Subpixel-based downsampling, taking advantage of the fact that each pixel on a color LCD is actually composed of individual red, green, and blue subpixel stripes, can provide apparent higher resolution. In this paper, we use frequency-domain analysis to explain what happens in subpixel-based downsampling and why it is possible to achieve a higher apparent resolution. According to our frequency-domain analysis and observation, the cutoff frequency of the low-pass filter for subpixel-based decimation can be effectively extended beyond the Nyquist frequency using a novel antialiasing filter. Applying the proposed filters to two existing subpixel downsampling schemes called direct subpixel-based downsampling (DSD) and diagonal DSD (DDSD), we obtain two improved schemes, i.e., DSD based on frequency-domain analysis (DSD-FA) and DDSD based on frequency-domain analysis (DDSD-FA). Experimental results verify that the proposed DSD-FA and DDSD-FA can provide superior results, compared with existing subpixel or pixel-based downsampling methods.","Rendering (computer graphics),
Image resolution,
Image color analysis,
Frequency domain analysis,
Image edge detection,
Color,
Humans"
New Absorbing Boundary Conditions and Analytical Model for Multilayered Mushroom-Type Metamaterials: Applications to Wideband Absorbers,"An analytical model is presented for the analysis of multilayer wire media loaded with 2-D arrays of thin material terminations, characterized in general by a complex surface conductivity. This includes the cases of resistive, thin metal, or graphene patches and impedance ground planes. The model is based on the nonlocal homogenization of the wire media with additional boundary conditions (ABCs) at the connection of thin (resistive) material. Based on charge conservation, new ABCs are derived for the interface of two uniaxial wire mediums with thin imperfect conductors at the junction. To illustrate the application of the analytical model and to validate the new ABCs, we characterize the reflection properties of multilayer absorbing structures. It is shown that in such configurations the presence of vias results in the enhancement of the absorption bandwidth and an improvement in the absorptivity performance for increasing angles of an obliquely incident TM-polarized plane wave. The results obtained using the analytical model are validated against full-wave numerical simulations.","Wires,
Boundary conditions,
Junctions,
Nonhomogeneous media,
Periodic structures"
Circuit Modeling of Nonlinear Lumped Element Transmission Lines Including Hybrid Lines,"A nonlinear lumped element transmission line (NLETL) that consists of an LC-ladder network can be used to convert a rectangular input pump pulse into a series of RF oscillations at the output. The discreteness of the LC sections in the network contributes to the line dispersion while the nonlinearity of the LC elements produces the nonlinear characteristics of the line. Both of these properties combine to produce wave trains of high frequency. This paper describes an NLETL circuit model that is used to simulate RF generation for a given input pump pulse and the experiments used to validate the simulated results. The circuit model is used to study a nonlinear capacitive line that comprises nonlinear C but linear L and a nonlinear inductive line that comprises nonlinear L but linear C. Extensive and comprehensive parametric studies were carried out for the various NLETLs to understand the behavior and characteristics of these lines. Interesting observations were made, and explanations were given for their occurrence. A hybrid line that comprises both nonlinear elements L and C was also investigated using the circuit model with the goal of better matching to a resistive load. Simulations of the hybrid line indicate promising results.","Oscillators,
Integrated circuit modeling,
Mathematical model,
Inductors,
Equations,
Numerical models,
Capacitance"
Design and Implementation of a Delay-Guaranteed Motor Drive for Precision Motion Control,"This paper proposes a systematic design approach for a precision-guaranteed motion control system. We develop a delay-guaranteed motor drive with our new software implementation and real-time Ethernet, which can be used as a building block to build up a multi-axis motion control system. Our drive software implementation provides a probabilistic guarantee on drive-local processing delays to motor actuation, while real-time Ethernet provides a deterministic guarantee on message communication delays from a motion control host to each drive. In the paper, we address the precision of a motion control system in two terms: host cycle time and simultaneous actuation deviation. The host cycle time is a period with which the host can periodically release motor control messages while the average drive utilization does not exceed 1, and the simultaneous actuation deviation is the difference between the earliest and the latest actuation at different drives in response to the same message. In our approach, the main objective is to minimize the periods of tasks in each drive, using our stochastic analysis, which gives us a minimum possible host cycle time. Together with an existing delay analysis of real-time Ethernet, we analyze the end-to-end delay from message release to motor actuation and in turn the simultaneous actuation deviation. Through experiments, we show that for various requirements on the deadline miss probabilities of the tasks, we can successfully reduce the host cycle time and evaluate the resulting distribution of the simultaneous actuation deviation depending on the number of drives.","Motor drives,
Delay,
Motion control,
Software,
Real time systems,
Synchronization,
Time factors"
Path scheduling on digital microfluidic biochips,"Since the inception of digital microfluidics, the synthesis problems of scheduling, placement and routing have been performed offline (before runtime) due to their algorithmic complexity. However, with the increasing maturity of digital microfluidic research, online synthesis is becoming a realistic possibility that can bring new benefits in the areas of dynamic scheduling, control-flow, fault-tolerance and live-feedback. This paper contributes to the digital microfluidic synthesis process by introducing a fast, novel path-based scheduling algorithm that produces better schedules than list scheduler for assays with high fan-out; path scheduler computes schedules in milliseconds, making it suitable for both offline and online synthesis.","Schedules,
Proteins,
Electrodes,
Microfluidics,
Processor scheduling,
Optimal scheduling,
Arrays"
Making Computations and Publications Reproducible with VisTrails,"The VisTrails system supports the creation of reproducible experiments. VisTrails integrates data acquisition, derivation, analysis, and visualization as executable components throughout the scientific exploration process, and through systematic provenance capture, it makes it easier to generate and share reproducible results. Using VisTrails, authors can link results to their provenance, reviewers can assess the experiment's validity, and readers can repeat and utilize the computations.","Data visualization,
Reproducibility of results,
Research and development,
Scientific computing,
Programming,
Systematics"
To cloud or not to cloud: A mobile device perspective on energy consumption of applications,"The cloud computing paradigm enables the work anywhere anytime paradigm by allowing application execution and data storage on remote servers. This is especially useful for mobile computing and communication devices that are constrained in terms of computation power and storage. It is however not clear how preferable cloud-based applications would be for mobile device users. For users of such battery life constrained devices, the most important criteria might be the energy consumed by the applications they run. The goal of this work is to characterize under what scenarios cloud-based applications would be relatively more energy-efficient for users of mobile devices. This work first empirically studies the energy consumption for various types of applications and for multiple classes of devices to make this determination. Subsequently, it presents an analytical model that helps characterize energy consumption of mobile devices under both the cloud and non-cloud application scenarios. Finally, an algorithm GreenSpot is presented that considers application features and energy-performance tradeoffs to determine whether cloud or local execution will be more preferable.","Games,
Mobile handsets,
Energy consumption,
Cloud computing,
Portable computers,
IEEE 802.11 Standards,
Servers"
"S
3
MKL
: Scalable Semi-Supervised Multiple Kernel Learning for Real-World Image Applications","We study the visual learning models that could work efficiently with little ground-truth annotation and a mass of noisy unlabeled data for large scale Web image applications, following the subroutine of semi-supervised learning (SSL) that has been deeply investigated in various visual classification tasks. However, most previous SSL approaches are not able to incorporate multiple descriptions for enhancing the model capacity. Furthermore, sample selection on unlabeled data was not advocated in previous studies, which may lead to unpredictable risk brought by real-world noisy data corpse. We propose a learning strategy for solving these two problems. As a core contribution, we propose a scalable semi-supervised multiple kernel learning method (S3MKL) to deal with the first problem. The aim is to minimize an overall objective function composed of log-likelihood empirical loss, conditional expectation consensus (CEC) on the unlabeled data and group LASSO regularization on model coefficients. We further adapt CEC into a group-wise formulation so as to better deal with the intrinsic visual property of real-world images. We propose a fast block coordinate gradient descent method with several acceleration techniques for model solution. Compared with previous approaches, our model better makes use of large scale unlabeled images with multiple feature representation with lower time complexity. Moreover, to address the issue of reducing the risk of using unlabeled data, we design a multiple kernel hashing scheme to identify the “informative” and “compact” unlabeled training data subset. Comprehensive experiments are conducted and the results show that the proposed learning framework provides promising power for real-world image applications, such as image categorization and personalized Web image re-ranking with very little user interaction.","Kernel,
Visualization,
Training,
Data models,
Noise measurement,
Training data,
Learning systems"
Tunable Decoupling and Matching Network for Diversity Enhancement of Closely Spaced Antennas,"A tunable decoupling and matching network (DMN) for a two-element closely spaced antenna array is presented. The DMN achieves perfect matching for the eigenmodes of the array and thus simultaneously isolates and matches the system ports while keeping the circuit small. Arrays of closely spaced wire and microstrip monopole pairs are used to demonstrate the proposed DMN. It is found that monopoles with different lengths can be used for the design frequency by using this DMN, which increases the design flexibility. This property also enables frequency tuning using the DMN only without having to change the length of the antennas. The proposed DMN uses only one varactor to achieve a tuning range of 18.8% with both return loss and isolation better than 10 dB when the spacing between the antennas is 0.05 λ. When the spacing increases to 0.1 λ, and the antennas are properly matched, the simulated tuning range is more than 60%.","Arrays,
Bandwidth,
Antenna arrays,
Tuning,
Microstrip"
Generating Evanescent Bessel Beams Using Near-Field Plates,"We present a near-field plate that can generate an evanescent Bessel beam. The metallic plate consists of nonperiodic concentric corrugations that surround a coaxially fed aperture. The design procedure for such a device is outlined. The designed plate is simulated using a full-wave electromagnetic solver and is shown to produce an evanescent Bessel beam, thereby verifying its design and operation. The performance of the near-field plate is contrasted against a coaxial probe and a near-field plate designed to produce an Airy focal pattern with the same beamwidth. Such a device, capable of producing evanescent Bessel beams, will find applications in near-field probing/imaging systems, data storage, and biomedical devices.",
A Conceptual Modeling of Meme Complexes in Stochastic Search,"In science, gene provides the instruction for making proteins, while meme is the sociocultural equivalent of a gene containing instructions for carrying out behavior. Taking inspiration from nature, we model the memeplex in search as instructions that specify the coadapted meme complexes of individuals in their lifetime. In particular, this paper presents a study on the conceptual modeling of meme complexes or memeplexes for more effective problem solving in the context of modern stochastic optimization. The memeplex representation, credit assignment criteria for meme coadaptation, and the role of emergent memeplexes in the lifetime learning process of a memetic algorithm in search are presented. A coadapted memetic algorithm that takes the proposed conceptual modeling of memeplexes into actions to solve capacitated vehicle routing problems (CVRPs) of diverse characteristics is then designed. Results showed that adaptive memeplexes provide a means of creating highly robust, self-configuring, and scalable algorithms, thus generating improved or competitive results when benchmarking against several existing adaptive or human-designed state-of-the-art memetic algorithms and metaheuristics, on a plethora of CVRP sets considered.",
A Low-Power Magnitude Detector for Analysis of Transient-Rich Signals,"Magnitude detection, such as envelope detection or RMS estimation, is needed for many low-power signal-analysis applications. In such applications, the temporal accuracy of the magnitude detector is as important as its amplitude accuracy. We present a low-power audio-frequency magnitude detector that simultaneously achieves both high temporal accuracy and high amplitude accuracy. This performance is achieved by rectifying the signal with a high-ripple peak detector and then averaging this rectified signal with an adaptive-time-constant filter. The time constant of this filter decreases with increasing amplitude, enabling the filter to quickly respond on a short time scale to transients, while steady-state ripple is averaged on a longer time scale. The circuit has been fabricated in a 0.18 μm CMOS process and consumes only 1.1 nW-1.08 μW when tuned for operation from 20 Hz-20 kHz. It exhibits a dynamic range of 70 dB across typical speech frequencies.",
Estimation of Effective Wind Speed for Fixed-Speed Wind Turbines Based on Frequency Domain Data Fusion,"The rotator of the wind turbine is subject to a spatially and temporally distributed wind field; the wind speed varies significantly at different points over the blades plane. This makes a direct measurement of effective wind speed impossible. We analyze the spectrums of the measurement of the anemometer and generator power of a wind turbine, and point out that the characteristics of these two signals are complementary in the frequency domain. Then an observer for effective wind speed is proposed based on frequency-domain data fusion. The observer design is formulated as a mixed-sensitivity problem with linear matrix inequalities (LMIs). Simulations were carried out to assess the performance under a realistic wind speed profile. The simulation results show that the observer can not only guarantee the static accuracy, but also improve the dynamic accuracy of the measurements of the effective wind.","Wind speed,
Wind turbines,
Generators,
Observers,
Power measurement,
Fluid flow measurement,
Mathematical model"
Leader-Following Formation of Switching Multirobot Systems via Internal Model,"In this paper, the leader-following formation problem of multirobot systems with switching interconnection topologies is considered. The robots are required to move in a formation with formation constrains described in terms of relative distances of the robots and the formation (as whole entity) is required to track the trajectory generated by an exosystem. The exosystem of the considered multirobot systems provides driving forces or environmental disturbance, whose dynamics is different from the dynamics of the robots. A systematic distributed design approach for the leader-following formation problem is proposed via dynamic output feedback with the help of canonical internal model.","Robots,
Multirobot systems,
Switches,
Lead,
Topology,
Steady-state,
Generators"
Outdoor Scene Image Segmentation Based on Background Recognition and Perceptual Organization,"In this paper, we propose a novel outdoor scene image segmentation algorithm based on background recognition and perceptual organization. We recognize the background objects such as the sky, the ground, and vegetation based on the color and texture information. For the structurally challenging objects, which usually consist of multiple constituent parts, we developed a perceptual organization model that can capture the nonaccidental structural relationships among the constituent parts of the structured objects and, hence, group them together accordingly without depending on a priori knowledge of the specific objects. Our experimental results show that our proposed method outperformed two state-of-the-art image segmentation approaches on two challenging outdoor databases (Gould data set and Berkeley segmentation data set) and achieved accurate segmentation quality on various outdoor natural scene environments.","Image segmentation,
Organizations,
Image color analysis,
Shape,
Context,
Training,
Humans"
Thermal Management Challenges in Telecommunication Systems and Data Centers,"The framework for this paper is the growing concern about the worldwide increasing energy consumption of telecommunications systems and data centers, and particularly the contribution of the thermal management system. The present energy usage of these systems is discussed, as well as the relationship between cooling system design and the total cost of ownership. This paper identifies immediate and future thermal bottlenecks facing the industry, ranging from technological issues at the component and system level to more general needs involving reliability, modularity, and multidisciplinary design. Based on this enumeration, the main challenges to implementing cooling solutions are reviewed. Particular attention is paid to implementing liquid cooling, since this technology seems the most promising to addressing the key thermal bottlenecks, and improving the future sustainability of thermal management in the telecom and data center industry. Finally, an outlook is presented toward future potential challenges.","Cooling,
Heat recovery,
Waste heat,
Space heating,
Telecommunications,
Energy consumption"
Automatic parameter recommendation for practical API usage,"Programmers extensively use application programming interfaces (APIs) to leverage existing libraries and frameworks. However, correctly and efficiently choosing and using APIs from unfamiliar libraries and frameworks is still a non-trivial task. Programmers often need to ruminate on API documentations (that are often incomplete) or inspect code examples (that are often absent) to learn API usage patterns. Recently, various techniques have been proposed to alleviate this problem by creating API summarizations, mining code examples, or showing common API call sequences. However, few techniques focus on recommending API parameters. In this paper, we propose an automated technique, called Precise, to address this problem. Differing from common code completion systems, Precise mines existing code bases, uses an abstract usage instance representation for each API usage example, and then builds a parameter usage database. Upon a request, Precise queries the database for abstract usage instances in similar contexts and generates parameter candidates by concretizing the instances adaptively. The experimental results show that our technique is more general and applicable than existing code completion systems, specially, 64% of the parameter recommendations are useful and 53% of the recommendations are exactly the same as the actual parameters needed. We have also performed a user study to show our technique is useful in practice.","Context,
Abstracts,
Arrays,
Indexes,
Complexity theory,
Documentation"
Wireless Positioning Using TDS-OFDM Signals in Single-Frequency Networks,"Wireless positioning using digital television (DTV) signals is a promising complementary to global positioning system due to high transmission power and wide coverage of DTV transmitters. Without changing the current infrastructure of Chinese DTV broadcasting network, this paper proposes a positioning scheme using time-domain synchronous (TDS) orthogonal frequency division multiplexing (OFDM) signals in single-frequency networks. The transmission parameter signaling (TPS) embedded in the TDS-OFDM signals is time-division multiplexed as orthogonal frequency-domain pilots, and then the time-domain pseudorandom noise sequence and the frequency-domain TPS are jointly utilized for accurate time of arrival (TOA) estimation for each transmitter. The theoretical bound of the TOA estimation accuracy is also derived. The proposed wireless positioning scheme has no impact on the normal TV program reception. Simulation results show that the positioning accuracy of less than 1 m can be achieved in SFN scenarios. The idea of time-frequency joint positioning can also be applied to other OFDM-based wireless systems.",
Reducing Electricity Cost of Smart Appliances via Energy Buffering Framework in Smart Grid,"To reduce the long term electricity cost of smart appliances (SAs) with deferrable operation time in smart grid, we propose a novel energy buffering framework to intelligently schedule the distributed energy storage (DES) for the cost reduction of SAs in this paper. The proposed energy buffering framework determines the action policy (e.g., charging or discharging) and the power allocation policy of the DES to provide DES power to proper SAs at proper time with lower price than that of the utility grid, resulting in the reduction of the long term financial cost of SAs. Specifically, we first formulate the optimal decision problem in the energy buffering framework as a discounted cost Markov decision process (MDP) over infinite-horizon. Then, we propose an optimal scheme for the energy buffering framework to solve the discounted cost MDP based on online learning approach. Extensive simulation results show that the proposed optimal scheme for the energy buffering framework can significantly reduce the long term financial cost comparing with the baseline schemes and the myopic scheme.","Electricity,
Real time systems,
Batteries,
Pricing,
Delay,
Smart grids,
Resource management"
A Stochastic Power Network Calculus for Integrating Renewable Energy Sources into the Power Grid,"Renewable energy such as solar and wind generation will constitute an important part of the future grid. As the availability of renewable sources may not match the load, energy storage is essential for grid stability. In this paper we investigate the feasibility of integrating solar photovoltaic (PV) panels and wind turbines into the grid by also accounting for energy storage. To deal with the fluctuation in both the power supply and demand, we extend and apply stochastic network calculus to analyze the power supply reliability with various renewable energy configurations. To illustrate the validity of the model, we conduct a case study for the integration of renewable energy sources into the power system of an island off the coast of Southern California. In particular, we asses the power supply reliability in terms of the average Fraction of Time that energy is Not-Served (FTNS).","Calculus,
Stochastic processes,
Power supplies,
Batteries,
Measurement"
Joint Channel Bandwidth and Power Allocation Game for Selfish Cooperative Relaying Networks,"Resource-exchange-based incentive mechanisms are investigated for both selection cooperation (SC) and selection relaying (SR) networks using the cooperative bargaining game approach. Consider a user node that can act as a source as well as a potential relay for other nodes, and it is selfish to share an own resource with others only if the data rate achieved through cooperative relaying is not lower than that achieved without the cooperation by consuming the same amount of the resource. In the SC scenario, only one relay is allotted to a source. Then, a two-person SC game (SCG) is formulated to address the joint bandwidth and power allocation problem for two cooperative nodes. In the SR scenario, a set of relays is allotted to a source. Hence, we propose a one-to-many SR game (SRG) to address the multinode cooperation case. For both SCG and SRG, specific data frame structures are designed to accommodate both the bandwidth resource (in the form of transmission time) and the energy resource (in the form of transmission power) for a cooperative node. To achieve the system efficiency and per-node fairness objectives simultaneously, the Nash bargaining solution (NBS) method is used to solve both SCG and SRG. The existence and uniqueness of the NBS are proved. Moreover, theoretical analysis and simulations are provided to testify as to the effectiveness of the proposed SCG and SRG for efficient and fair resource allocation in the SC and SR scenarios, respectively.",
Minimizing Access Cost for Multiple Types of Memory Units in Embedded Systems Through Data Allocation and Scheduling,"Software-controlled memories, such as scratch-pad memory (SPM), have been widely adopted in many digital signal processors to achieve high performance with low cost. Multiple types of memory units with varying performance and cost can be found in one system. In this paper, we design a polynomial-time algorithm, the regional optimal data allocation (RODA) algorithm, using dynamic programming approach. It guarantees optimal data allocation with minimal access cost for a program region. A polynomial-time algorithm, the global data allocation (GDA) algorithm, is proposed to reduce access cost efficiently based on regional results generated by the RODA algorithm. A heuristic, the maximal similarity scheduling (MSS) algorithm, is also developed to find an execution sequence of program regions with maximal similarity of accessed data items for consecutive regions in order to reduce memory traffic. The experimental results on a set of benchmarks show that our technique that combines the GDA and the MSS algorithms outperforms greedy algorithm in all the experimental cases.","Resource management,
Signal processing algorithms,
Heuristic algorithms,
Memory management,
Greedy algorithms,
Dynamic programming,
Dynamic scheduling"
Age-based cooperative caching in Information-Centric Networks,"Information-Centric Networking (ICN) provides substantial flexibility for users to obtain information. One of the most important commonalities of ICN designs is the universal caching. It is widely accepted that the in-network caching would improve performance. However, there has been no consensus on how to design an efficient caching scheme in ICN network. In this paper we propose an age-based cooperative cache scheme aiming at reducing network delay and publisher load for ICN network. We focus on light-weight collaboration mechanisms that spread popular contents to the network edge while at the same time fully utilize the storage capacity of intermediate nodes. We evaluate the effectiveness of our scheme under real traces and realistic network topology. The results indicate that our scheme achieves significant performance gains.",
INK-SVD: Learning incoherent dictionaries for sparse representations,This work considers the problem of learning an incoherent dictionary that is both adapted to a set of training data and incoherent so that existing sparse approximation algorithms can recover the sparsest representation. A new decorrelation method is presented that computes a fixed coherence dictionary close to a given dictionary. That step iterates pairwise decorrelations of atoms in the dictionary. Dictionary learning is then performed by adding this decorrelation method as an intermediate step in the K-SVD learning algorithm. The proposed algorithm INK-SVD is tested on musical data and compared to another existing decorrelation method. INK-SVD can compute a dictionary that approximates the training data as well as K-SVD while decreasing the coherence from 0.6 to 0.2.,"Dictionaries,
Decorrelation,
Coherence,
Approximation methods,
Approximation algorithms,
Correlation,
Signal to noise ratio"
Fast image dehazing using improved dark channel prior,"In the frog and haze climatic condition, the captured picture will become blurred and the color is partial gray and white, due to the effect of atmospheric scattering. This situation brings a great deal of inconvenience to the video surveillance system, so the study of defogging algorithm in this weather is of great importance. This paper deeply analyzes the physical process of imaging in foggy weather. After full study on the haze removal algorithm of single image over the last decade, we propose a fast haze removal algorithm which based on a fast bilateral filtering combined with dark colors prior. This algorithm starts with the atmospheric scattering model, derives a estimated transmission map by using dark channel prior, and then combines with grayscale to extract refined transmission map by using the fast bilateral filter. This algorithm has a fast execution speed and greatly improves the original algorithm which is more time-consuming. On this basis, we analyzed the reasons why the image is dim after the haze removal using dark channel prior, and proposed the improved transmission map formula. Experimental-results show that this algorithm is feasible which effectively restores the contrast and color of the scene, significantly improves the visual effects of the image. Those image with large area of sky usually prone to distortion when using the dark channel prior, Therefore we propose a method of weakening the sky region, aims to improve the adaptability of the algorithm.","Image color analysis,
Algorithm design and analysis,
Computer vision,
Filtering algorithms,
Educational institutions,
Conferences,
Meteorology"
Refined methods for creating realistic haptic virtual textures from tool-mediated contact acceleration data,"Dragging a tool across a textured object creates rich high-frequency vibrations that distinctly convey the physical interaction between the tool tip and the object surface. Varying one's scanning speed and normal force alters these vibrations, but it does not change the perceived identity of the tool or the surface. Previous research developed a promising data-driven approach to embedding this natural complexity in a haptic virtual environment: the approach centers on recording and modeling the tool contact accelerations that occur during real texture interactions at a limited set of force-speed combinations. This paper aims to optimize these prior methods of texture modeling and rendering to improve system performance and enable potentially higher levels of haptic realism. The key elements of our approach are drawn from time series analysis, speech processing, and discrete-time control. We represent each recorded texture vibration with a low-order auto-regressive moving-average (ARMA) model, and we optimize this set of models for a specific tool-surface pairing (plastic stylus and textured ABS plastic) using metrics that depend on spectral match, final prediction error, and model order. For rendering, we stably resample the texture models at the desired output rate, and we derive a new texture model at each time step using bilinear interpolation on the line spectral frequencies of the resampled models adjacent to the user's current force and speed. These refined processes enable our TexturePad system to generate a stable and spectrally accurate vibration waveform in real time, moving us closer to the goal of virtual textures that are indistinguishable from their real counterparts.","Mathematical model,
Force,
Haptic interfaces,
Acceleration,
Data models,
Vibrations,
Computational modeling"
Language and Discourse Are Powerful Signals of Student Emotions during Tutoring,"We explored the possibility of predicting student emotions (boredom, flow/engagement, confusion, and frustration) by analyzing the text of student and tutor dialogues during interactions with an Intelligent Tutoring System (ITS) with conversational dialogues. After completing a learning session with the tutor, student emotions were judged by the students themselves (self-judgments), untrained peers, and trained judges. Transcripts from the tutorial dialogues were analyzed with four methods that included 1) identifying direct expressions of affect, 2) aligning the semantic content of student responses to affective terms, 3) identifying psychological and linguistic terms that are predictive of affect, and 4) assessing cohesion relationships that might reveal student affect. Models constructed by regressing the proportional occurrence of each emotion on textual features derived from these methods yielded large effects (R2 = 38%) for the psychological, linguistic, and cohesion-based methods, but not the direct expression and semantic alignment methods. We discuss the theoretical, methodological, and applied implications of our findings toward text-based emotion detection during tutoring.","Semantics,
Education,
Pragmatics,
Natural language processing,
Psychology,
Feature extraction,
Particle measurements,
Emotion recognition,
Behavioral science"
An Adaptive Prediction-Based Approach to Lossless Compression of Floating-Point Volume Data,"In this work, we address the problem of lossless compression of scientific and medical floating-point volume data. We propose two prediction-based compression methods that share a common framework, which consists of a switched prediction scheme wherein the best predictor out of a preset group of linear predictors is selected. Such a scheme is able to adapt to different datasets as well as to varying statistics within the data. The first method, called APE (Adaptive Polynomial Encoder), uses a family of structured interpolating polynomials for prediction, while the second method, which we refer to as ACE (Adaptive Combined Encoder), combines predictors from previous work with the polynomial predictors to yield a more flexible, powerful encoder that is able to effectively decorrelate a wide range of data. In addition, in order to facilitate efficient visualization of compressed data, our scheme provides an option to partition floating-point values in such a way as to provide a progressive representation. We compare our two compressors to existing state-of-the-art lossless floating-point compressors for scientific data, with our data suite including both computer simulations and observational measurements. The results demonstrate that our polynomial predictor, APE, is comparable to previous approaches in terms of speed but achieves better compression rates on average. ACE, our combined predictor, while somewhat slower, is able to achieve the best compression rate on all datasets, with significantly better rates on most of the datasets.","Floating-point arithmetic,
Polynomials,
Entropy coding,
Data visualization,
Image coding,
Data models"
Yield enhancement for 3D-stacked ICs: Recent advances and challenges,"Three-dimensional (3D) integrated circuits (ICs) that stack multiple dies vertically using through-silicon vias (TSVs) have gained wide interests of the semiconductor industry. The shift towards volume production of 3D-stacked ICs, however, requires their manufacturing yield to be commercially viable. Various techniques have been presented in the literature to address this important problem, including pre-bond testing techniques to tackle the “known good die” problem, TSV redundancy designs to provide defect-tolerance, and wafter/die matching solutions to improve the overall stack yield. In this paper, we survey recent advances in this filed and point out challenges to be resolved in the future.","Through-silicon vias,
Three dimensional displays,
Testing,
Bonding,
Redundancy,
Semiconductor device modeling,
Maintenance engineering"
Ultrawideband Antenna for LTE/GSM/UMTS Wireless USB Dongle Applications,"In the letter, a simply printed planar antenna covering GSM850/900/1800/1900/UMTS2100 and LTE700/2300/2500 operating frequency bands for wireless USB dongle applications is proposed, designed, and fabricated. The presented antenna consists of a large patch and a matching network in order to enhance impedance bandwidth. The upper operating bands including GSM1800/1900/UMTS2100/LTE2300/2500 are primarily attributed to the large patch. Meanwhile, the lower resonant modes covering LTE700/GSM850/900 bands are generated physically by ground planes of both the USB dongle circuit board and the laptop board. The impedance matching over all bands is improved by the matching network. The proposed antenna occupies a small size of 20 &times;20&nbsp; mm2 and can be easily printed on a 0.8-mm-thick FR4 substrate of conventional dimensions of 20 &times;70&nbsp;mm2, which makes it promising for wireless USB dongle applications.","Antennas,
Universal Serial Bus,
Antenna measurements,
Portable computers,
Wireless communication,
Gain measurement,
Bandwidth"
Bundle: A Group-Based Programming Abstraction for Cyber-Physical Systems,"This paper describes a novel group-based programming abstraction called a “Bundle” for cyber-physical systems (CPS). Similar to other programming abstractions, a Bundle creates logical collections of sensing devices. However, previous abstractions were focused on wireless sensor networks (WSNs) and did not address key aspects of CPS. Bundles elevate the programming domain from a single WSN to complex systems of systems by allowing the programming of applications involving multiple CPSs that are controlled by different administrative domains and support mobility both within and across CPSs. Bundles can seamlessly group not only sensors, but also actuators which constitute an important part of CPS. They enable programming in a multiuser environment with fine grained access right control and conflict resolution mechanism. Bundles support heterogeneous devices, such as motes, PDAs, laptops, and actuators according to the applications' requirements. They allow different applications to simultaneously use the same sensors and actuators. Bundles facilitate feedback control mechanisms by dynamic membership update and requirements reconfiguration based on feedback from the current members. The Bundle abstraction is implemented in Java which ensures ease and conciseness of programming. We present the design and implementation details of Bundles as well as a performance evaluation using 32 applications written with Bundles. This set includes across-network applications that have sophisticated sensing and actuation logic, mobile nodes that are heterogeneous, and feedback control mechanisms. Each of these applications is programmed in less than 60 lines of code.","Actuators,
Programming,
Wireless sensor networks,
Temperature sensors,
Logic gates,
Java"
Networked Computing in Wireless Sensor Networks for Structural Health Monitoring,"This paper studies the problem of distributed computation over a network of wireless sensors. While this problem applies to many emerging applications, to keep our discussion concrete, we will focus on sensor networks used for structural health monitoring. Within this context, the heaviest computation is to determine the singular value decomposition (SVD) to extract mode shapes (eigenvectors) of a structure. Compared to collecting raw vibration data and performing SVD at a central location, computing SVD within the network can result in significantly lower energy consumption and delay. Using recent results on decomposing SVD, a well-known centralized operation, we seek to determine a near-optimal communication structure that enables the distribution of this computation and the reassembly of the final results, with the objective of minimizing energy consumption subject to a computational delay constraint. We show that this reduces to a generalized clustering problem and establish that it is NP-hard. By relaxing the delay constraint, we derive a lower bound. We then propose an integer linear program (ILP) to solve the constrained problem exactly as well as an approximate algorithm with a proven approximation ratio. We further present a distributed version of the approximate algorithm. We present both simulation and experimentation results to demonstrate the effectiveness of these algorithms .","Sensors,
Delay,
Wireless sensor networks,
Energy consumption,
Monitoring,
Base stations,
Approximation methods"
Tissue Tracking and Registration for Image-Guided Surgery,"Vision-based tracking of tissue is a key component to enable augmented reality during a surgical operation. Conventional tracking techniques in computer vision rely on identifying strong edge features or distinctive textures in a well-lit environment; however endoscopic tissue images do not have strong edge features, are poorly lit and exhibit a high degree of specular reflection. Therefore, prior work in achieving densely populated 3-D features for describing tissue surface profiles require complex image processing techniques and have been limited in providing stable, long-term tracking or real-time processing. In this paper, we present an integrated framework for accurately tracking tissue in surgical stereo-cameras at real-time speeds. We use a combination of the STAR feature detector and binary robust independent elementary features to acquire salient features that can be persistently tracked at high frame rates. The features are then used to acquire a densely-populated map of the deformations of tissue surface in 3-D. We evaluate the method against popular feature algorithms in in vivo animal study video sequences, and we also apply the proposed method to human partial nephrectomy video sequences. We extend the salient feature framework to support region tracking in order to maintain the spatial correspondence of a tracked region of tissue or a medical image registration to the surrounding tissue. In vitro tissue studies show registration accuracies of 1.3–3.3 mm using a rigid-body transformation method.","Feature extraction,
Tracking,
Surface reconstruction,
Image registration,
Stereo image processing,
Surgery,
Real time systems"
DiCode: DoS-Resistant and Distributed Code Dissemination in Wireless Sensor Networks,"Code dissemination in a wireless sensor network (WSN) is the process of propagating a new program image or relevant commands to sensor nodes. As a WSN is usually deployed in hostile environments, secure code dissemination is and will continue to be a major concern. Most code dissemination protocols are based on the centralized approach in which only the base station has the authority to initiate code dissemination. However, it is desirable and sometimes necessary to disseminate code images in a distributed manner which allows multiple authorized network users to simultaneously and directly update code images on different nodes without involving the base station. Motivated by this consideration, we develop a secure and distributed code dissemination protocol named DiCode. A salient feature of DiCode is its ability to resist denial-of-service attacks which have severe consequences on network availability. Further, the security properties of our protocol are demonstrated by theoretical analysis. To verify the efficiency of the proposed approach in practice, we also implement the proposed mechanism in a network of resource-constrained sensor nodes.","Wireless sensor networks,
Protocols,
Public key,
Base stations,
Computer crime,
Authentication"
Square root law for communication with low probability of detection on AWGN channels,"We present a square root limit on low probability of detection (LPD) communication over additive white Gaussian noise (AWGN) channels. Specifically, if a warden has an AWGN channel to the transmitter with non-zero noise power, we prove that o(√n) bits can be sent from the transmitter to the receiver in n AWGN channel uses with probability of detection by the warden less than e for any ϵ >; 0, and, if a lower bound on the noise power on the warden's channel is known, then O(√n) bits can be covertly sent in n channel uses. Conversely, trying to transmit more than O(√n) bits either results in detection by the warden with probability one or a non-zero probability of decoding error as n → ∞. Further, we show that LPD communication on the AWGN channel allows one to send a nonzero symbol on every channel use, in contrast to what might be expected from the square root law found recently in image-based steganography.","Decoding,
AWGN,
Vectors,
AWGN channels,
Error probability,
Entropy"
Performance Limits of Compressive Sensing-Based Signal Classification,"Most of the recent compressive sensing (CS) literature has focused on sparse signal recovery based on compressive measurements. However, exact signal recovery may not be required in certain signal processing applications such as in inference problems. In this paper, we provide performance limits of classification of sparse as well as not necessarily sparse signals based on compressive measurements. When signals are not necessarily sparse, we show that Kullback-Leibler and Chernoff distances between two probability density functions under any two hypotheses are preserved up to a factor of M/N with M(<;N)-length compressive measurements compared to that with N-length original measurements when the pdfs of the original-length observation vectors exhibit certain properties. These results are used to quantify the performance limits in terms of upper and lower bounds on the probability of error in signal classification with M-length compressive measurements. When the signals of interest are sparse in the standard canonical basis, performance limits are derived in terms of lower bounds on the probability of error in classifying sparse signals with any classification rule.","Vectors,
Density measurement,
Probability density function,
Noise measurement,
Loss measurement,
Additive noise"
Energy-Efficient Reverse Skyline Query Processing over Wireless Sensor Networks,"Reverse skyline query plays an important role in many sensing applications, such as environmental monitoring, habitat monitoring, and battlefield monitoring. Due to the limited power supplies of wireless sensor nodes, the existing centralized approaches, which do not consider energy efficiency, cannot be directly applied to the distributed sensor environment. In this paper, we investigate how to process reverse skyline queries energy efficiently in wireless sensor networks. Initially, we theoretically analyzed the properties of reverse skyline query and proposed a skyband-based approach to tackle the problem of reverse skyline query answering over wireless sensor networks. Then, an energy-efficient approach is proposed to minimize the communication cost among sensor nodes of evaluating range reverse skyline query. Moreover, optimization mechanisms to improve the performance of multiple reverse skylines are also discussed. Extensive experiments on both real-world data and synthetic data have demonstrated the efficiency and effectiveness of our proposed approaches with various experimental settings.","Wireless sensor networks,
Query processing,
Humidity,
Monitoring,
Base stations,
Birds,
Technical Activities Guide - TAG"
The ETSF: An e-Infrastructure That Bridges Simulations and Experiments,"The European Theoretical Spectroscopy Facility (ETSF) is a distributed knowledge network that gives researchers access to state-of-the-art computer simulations for electronic excited states in matter. Focusing on the fundamental knowledge of matter at the quantum-mechanical level, ETSF seeks to transfer this understanding to the future design of technologies in multiple areas.",
H.264 Coarse Grain Scalable (CGS) and Medium Grain Scalable (MGS) Encoded Video: A Trace Based Traffic and Quality Evaluation,"The scalable video coding (SVC) extension of the H.264/AVC video coding standard provides two mechanisms, namely coarse grain scalability (CGS) and medium grain scalability (MGS), for quality scalable video encoding, which varies the fidelity (signal-to-noise ratio) of the encoded video stream. As H.264/AVC and its SVC extension are expected to become widely adopted for the network transport of video, it is important to thoroughly study their network traffic characteristics, including the bit rate variability. In this paper, we report on a large-scale study of the rate-distortion (RD) and rate variability-distortion (VD) characteristics of CGS and MGS. We found that CGS achieves low bit rate overheads in the 10–30% range compared to H.264 SVC single-layer encodings only for encodings with a total of up to three quality levels; more quality levels result in substantially higher overheads. The traffic variabilities of CGS are generally lower than for single-layer streams. We found that in the low to mid range of the MGS quality scalability, MGS can achieve the same or even slightly higher RD efficiency than corresponding single-layer encoding; toward the upper end of the MGS quality scalability range the RD efficiency drops off significantly. MGS layer extraction following the hierarchical B frame structure gives nearly as high RD performance as RD-optimized extraction. In the range of high RD efficiency, MGS streams have significantly higher traffic variabilities than single-layer streams at the frame time scale. At the group-of-pictures (GoP) time scale, MGS has similar or lower levels of traffic variability compared to single-layer streams. Generally, MGS layer extraction over the time horizon of individual GoPs gives significantly lower traffic variability than extraction over the time horizon of the full video sequence.",
Multipitch Estimation of Piano Music by Exemplar-Based Sparse Representation,"Pitch, together with other midlevel music features such as rhythm and timbre, holds the promise of bridging the semantic gap between low-level features and high-level semantics for music understanding. This paper investigates the pitch estimation of a piano music signal by exemplar-based sparse representation. A note exemplar is a segment of a piano note, stored in the dictionary. We first describe how to represent a segment of the piano music signal as a linear combination of a small number of note exemplars from a large note exemplar dictionary and then show how the sparse representation problem can be solved by -regularized minimization. The proposed approach incorporates tuning factor estimation, note candidate selection, and hidden-Markov-model-based smoothing into the estimation process to improve accuracy. Unlike previous approaches, the proposed approach does not require retraining for a new piano. Instead, only a dozen notes of the new piano are needed. This feature is computationally attractive and avoids intense manual labeling. The system performance is evaluated using 70 classical music recordings of two real pianos under different recording conditions. The results show that the proposed system outperforms four state-of-the-art systems.",
Wireless Capsule Endoscopy Video Segmentation Using an Unsupervised Learning Approach Based on Probabilistic Latent Semantic Analysis With Scale Invariant Features,"Since wireless capsule endoscopy (WCE) is a novel technology for recording the videos of the digestive tract of a patient, the problem of segmenting the WCE video of the digestive tract into subvideos corresponding to the entrance, stomach, small intestine, and large intestine regions is not well addressed in the literature. A selected few papers addressing this problem follow supervised leaning approaches that presume availability of a large database of correctly labeled training samples. Considering the difficulties in procuring sizable WCE training data sets needed for achieving high classification accuracy, we introduce in this paper an unsupervised learning approach that employs Scale Invariant Feature Transform (SIFT) for extraction of local image features and the probabilistic latent semantic analysis (pLSA) model used in the linguistic content analysis for data clustering. Results of experimentation indicate that this method compares well in classification accuracy with the state-of-the-art supervised classification approaches to WCE video segmentation.","Feature extraction,
Image color analysis,
Semantics,
Endoscopes,
Training,
Intestines,
Image segmentation"
Schottky Source/Drain InAlN/AlN/GaN MISHEMT With Enhanced Breakdown Voltage,"In this letter, we present the deployment of Schottky source/drain (SSD) in InAlN/GaN metal-insulator-semiconductor high-electron-mobility transistors (MISHEMTs) for off-state breakdown voltage improvement. The improved breakdown voltage relies on the suppression of electron injection into the buffer under the Schottky source contact. A VBD of 460 V is obtained in an SSD MISHEMT with an LGD = 10&nbsp;μm, at a 170% improvement compared with that of the control MISHEMT featuring ohmic source/drain. Despite the SSD contacts, an SSD MISHEMT with a gate length of 1 μm exhibits a respectable drain current density of 416 mA/mm and a transconductance of 113 mS/mm.",
Data Hiding in MPEG Video Files Using Multivariate Regression and Flexible Macroblock Ordering,"This paper proposes two data hiding approaches using compressed MPEG video. The first approach hides message bits by modulating the quantization scale of a constant bitrate video. A payload of one message bit per macroblock is achieved. A second order multivariate regression is used to find an association between macroblock-level feature variables and the values of a hidden message bit. The regression model is then used by the decoder to predict the values of the hidden message bits with very high prediction accuracy. The second approach uses the flexible macroblock ordering feature of H.264/AVC to hide message bits. Macroblocks are assigned to arbitrary slice groups according to the content of the message bits to be hidden. A maximum payload of three message bits per macroblock is achieved. The proposed solutions are analyzed in terms of message extraction accuracy, message payload, excessive bitrate and quality distortion. Comparisons with previous work reveal that the proposed solutions are superior in terms of message payload while causing less distortion and compression overhead.","Quantization,
Materials,
Feature extraction,
Streaming media,
Transform coding,
Payloads,
Encoding"
Affinity learning via self-diffusion for image segmentation and clustering,"Computing a faithful affinity map is essential to the clustering and segmentation tasks. In this paper, we propose a graph-based affinity (metric) learning method and show its application to image clustering and segmentation. Our method, self-diffusion (SD), performs a diffusion process by propagating the similarity mass along the intrinsic manifold of data points. Theoretical analysis is given to the SD algorithm and we provide a way of deriving the critical time stamp t. Our method therefore has nearly no parameter tuning and leads to significantly improved affinity maps, which help to greatly enhance the quality of clustering. In addition, we show that much improved image segmentation results can be obtained by combining SD with e.g. the normalized cuts algorithm. The proposed method can be used to deliver robust affinity maps for a range of problems.","Delta modulation,
Kernel,
Image segmentation,
Laplace equations,
Measurement,
Manifolds,
Accuracy"
Content dissemination by pushing and sharing in mobile cellular networks: An analytical study,"The The ever increasing traffic demand is a serious concern of mobile network operators, and the conventional pull-based (or request-based) communication model may not be able to handle this data explosion problem. To reduce the traffic load on cellular links for disseminating content, we propose to push the content to a subset of subscribers via cellular links, and to allow the subscribers to share the content via opportunistic local connectivity (i.e. Wi-Fi ad-hoc mode). We theoretically model and analyze how the content can be disseminated by both pushing via cellular links and sharing via Wi-Fi links, where handovers are modeled based on the multi-compartment model. We also formulate a mathematical framework to optimize the content dissemination, by which the trade-off between the dissemination delay and the energy cost is explored.","wireless LAN,
cellular radio,
information dissemination,
radio links,
telecommunication traffic"
HodgeRank on Random Graphs for Subjective Video Quality Assessment,"This paper introduces a novel framework, HodgeRank on Random Graphs, based on paired comparison, for subjective video quality assessment. Two types of random graph models are studied, i.e., Erdös-Rényi random graphs and random regular graphs. Hodge decomposition of paired comparison data may derive, from incomplete and imbalanced data, quality scores of videos and inconsistency of participants' judgments. We demonstrate the effectiveness of the proposed framework on LIVE video database. Both of the two random designs are promising sampling methods without jeopardizing the accuracy of the results. In particular, due to balanced sampling, random regular graphs may achieve better performances when sampling rates are small. However, when the number of videos is large or when sampling rates are large, their performances are so close that Erdös-Rényi random graphs, as the simplest independent and identically distributed sampling scheme, could provide good approximations to random regular graphs, as a dependent sampling scheme. In contrast to the traditional deterministic incomplete block designs, our random design is not only suitable for traditional laboratory studies, but also for crowdsourcing experiments on Internet where the raters are distributive and it is hard to control with fixed designs.","Educational institutions,
Quality assessment,
Electronic mail,
Data models,
Internet,
Laplace equations,
Materials"
ecMTCP: An Energy-Aware Congestion Control Algorithm for Multipath TCP,"In this paper, we develop an energy-aware congestion control algorithm for multipath TCP, called ecMTCP. ecMTCP moves traffic from the most congested paths to the more lightly loaded paths, as well as from higher energy cost paths to the lower ones, thus achieving load-balancing and energy-savings. Our simulation results show that ecMTCP can achieve greater energy-savings compared to MPTCP, and preserve fairness to regular TCP.","Energy measurement,
Load modeling,
Throughput,
Internet,
Mathematical model,
Algorithm design and analysis,
Simulation"
A survey on bio-inspired algorithms for web service composition,"Web service composition has become a promising technology in a variety of e-science or e-business areas. There are a variety of models and methods to deal with this issue from different aspects. Bio-inspired algorithms are becoming main approaches and solutions. This paper reviews the current researches on web service composition based on bio-inspired algorithms, such as Ant Colony Optimization (ACO), Genetic Algorithm(GA), Evolutionary Algorithm (EA) and Particle Swarm Optimization(PSO). By analyzing and investigating different approaches, this paper gives an overview about the researches on bio-inspired algorithm in web service composition and point out future directions.","Abstracts,
Biological system modeling,
Adaptation models,
Fluid flow measurement,
Switches,
Reliability"
On the Impact of Mutation-Selection Balance on the Runtime of Evolutionary Algorithms,"The interplay between mutation and selection plays a fundamental role in the behavior of evolutionary algorithms (EAs). However, this interplay is still not completely understood. This paper presents a rigorous runtime analysis of a non-elitist population-based EA that uses the linear ranking selection mechanism. The analysis focuses on how the balance between parameter η, controlling the selection pressure in linear ranking, and parameter χ controlling the bit-wise mutation rate, impacts the runtime of the algorithm. The results point out situations where a correct balance between selection pressure and mutation rate is essential for finding the optimal solution in polynomial time. In particular, it is shown that there exist fitness functions which can only be solved in polynomial time if the ratio between parameters η and χ is within a narrow critical interval, and where a small change in this ratio can increase the runtime exponentially. Furthermore, it is shown quantitatively how the appropriate parameter choice depends on the characteristics of the fitness function. In addition to the original results on the runtime of EAs, this paper also introduces a very useful analytical tool, i.e., multi-type branching processes, to the runtime analysis of non-elitist population-based EAs.","Runtime,
Polynomials,
Evolutionary computation,
Genetics,
Pressure measurement,
Algorithm design and analysis,
Random variables"
"BASont - A modular, adaptive building automation system ontology","Several ontologies exist that model aspects of home or building automation systems for specific use cases. However, no comprehensive approach exists, that models building automation systems in a modular way to be usable in various use cases and tools. The paper proposes the BASont that addresses various use cases over the life cycle of a building automation system from design, to commissioning, to operation, and refurbishment. The use of the BASont is demonstrated for a data retrieval and self-commissioning use case.","Subspace constraints,
Abstracts,
Semantics,
Buildings,
Topology"
Coded cooperative data exchange problem for general topologies,"We consider the coded cooperative data exchange problem for general graphs. In this problem, given a graph G = (V, E) representing clients in a broadcast network, each of which initially hold a (not necessarily disjoint) set of information packets; one wishes to design a communication scheme in which eventually all clients will hold all the packets of the network. Communication is performed in rounds, where in each round a single client broadcasts a single (possibly encoded) information packet to its neighbors in G. The objective is to design a broadcast scheme that satisfies all clients with the minimum number of broadcast rounds. The coded cooperative data exchange problem has seen significant research over the last few years; mostly when the graph G is the complete broadcast graph in which each client is adjacent to all other clients in the network, but also on general topologies, both in the fractional and integral setting. In this work we focus on the integral setting in general undirected topologies G. We tie the data exchange problem on G to certain well studied combinatorial properties of G and in such show that solving the problem exactly or even approximately within a multiplicative factor of log |V| is intractable (i.e., NP-Hard). We then turn to study efficient data exchange schemes yielding a number of communication rounds comparable to our intractability result. Our communication schemes do not involve encoding, and in such yield bounds on the coding advantage in the setting at hand.","Approximation methods,
Approximation algorithms,
Encoding,
Topology,
Algorithm design and analysis,
Polynomials,
Standards"
GPU Accelerated Generation of Digitally Reconstructed Radiographs for 2-D/3-D Image Registration,"Recent advances in programming languages for graphics processing units (GPUs) provide developers with a convenient way of implementing applications which can be executed on the CPU and GPU interchangeably. GPUs are becoming relatively cheap, powerful, and widely available hardware components, which can be used to perform intensive calculations. The last decade of hardware performance developments shows that GPU-based computation is progressing significantly faster than CPU-based computation, particularly if one considers the execution of highly parallelisable algorithms. Future predictions illustrate that this trend is likely to continue. In this paper, we introduce a way of accelerating 2-D/3-D image registration by developing a hybrid system which executes on the CPU and utilizes the GPU for parallelizing the generation of digitally reconstructed radiographs (DRRs). Based on the advancements of the GPU over the CPU, it is timely to exploit the benefits of many-core GPU technology by developing algorithms for DRR generation. Although some previous work has investigated the rendering of DRRs using the GPU, this paper investigates approximations which reduce the computational overhead while still maintaining a quality consistent with that needed for 2-D/3-D registration with sufficient accuracy to be clinically acceptable in certain applications of radiation oncology. Furthermore, by comparing implementations of 2-D/3-D registration on the CPU and GPU, we investigate current performance and propose an optimal framework for PC implementations addressing the rigid registration problem. Using this framework, we are able to render DRR images from a
256×256×133
CT volume in
∼24
ms using an NVidia GeForce 8800 GTX and in
∼2
ms using NVidia GeForce GTX 580. In addition to applications requiring fast automatic patient setup, these levels of performance suggest image-guided radiation therapy at video frame rates is technically feasible using relatively low cost PC architecture.","Graphics processing unit,
Rendering (computer graphics),
Computed tomography,
Casting,
Approximation methods,
Message systems,
Acceleration"
MOMCC: Market-oriented architecture for Mobile Cloud Computing based on Service Oriented Architecture,"The vision of augmenting computing capabilities of mobile devices, especially smartphones with least cost is likely transforming to reality leveraging cloud computing. Cloud exploitation by mobile devices breeds a new research domain called Mobile Cloud Computing (MCC). However, issues like portability and interoperability should be addressed for mobile augmentation which is a non-trivial task using component-based approaches. Service Oriented Architecture (SOA) is a promising design philosophy embraced by mobile computing and cloud computing communities to stimulate portable, complex application using prefabricated building blocks called Services. Utilizing distant cloud resources to host and run Services is hampered by long WAN latency. Exploiting mobile devices in vicinity alleviates long WAN latency, while creates new set of issues like Service publishing and discovery as well as clientserver security, reliability, and Service availability. In this paper, we propose a market-oriented architecture based on SOA to stimulate publishing, discovering, and hosting Services on nearby mobiles, which reduces long WAN latency and creates a business opportunity that encourages mobile owners to embrace Service hosting. Group of mobile phones simulate a nearby cloud computing platform. We create new role of Service host by enabling unskilled mobile owners/users to host Services developed by skilled developers. Evidently, Service availability, reliability, and Service-oriented mobile application portability will increase towards green ubiquitous computing in our mobile cloud infrastructure.",
Statistical Analysis of ENOB and Yield in Binary Weighted ADCs and DACS With Random Element Mismatch,"Mismatch motivates many of the design decisions for binary weighted, ratiometric converters, such as successive approximation (SAR) analog-to-digital converters (ADC), but the statistical relationship between mismatch and signal-to-noise-plus-distortion ratio (SNDR) has not been precisely quantified. In this paper, we analyze the effects of capacitor mismatch in a binary weighted, charge redistribution SAR ADC and derive a new analytic expression relating capacitor mismatch and the effective-number-of-bits (ENOB). We then explore the statistics of this new expression and develop a model that accurately predicts yield in terms of ENOB. Finally, the major results of this paper are generalized into a simple and compact design equation that relates resolution, mismatch, and ENOB to yield for all binary weighted, ratiometric converters. The expressions derived in this paper offer practical insight into the relationship between mismatch and performance for all binary, weighted ratiometric converters with these results validated through numerical simulations.","Capacitors,
Noise,
Capacitance,
Arrays,
Approximation methods,
Equations,
Mathematical model"
Capacity of OFDM Two-Hop Relaying Systems for Medium-Voltage Power-Line Access Networks,"Orthogonal frequency-division multiplexing (OFDM) transmission is considered for a medium-voltage (MV) power-line access network (AN). In this paper, we analyze the channel capacity of OFDM-based two-hop relaying systems over MV power lines, where a single relay node is used between the source and destination nodes in an effort to enhance the channel capacity using either cooperative relaying (CR) or noncooperative relaying protocols. For each relaying protocol, the relay node operates in either the amplify-and-forward (AF) or the decode-and-forward (DF) mode. Numerical results show that the channel capacity of the CR protocol in the DF mode is superior to that in the AF mode, as well as to the NCR protocol in the AF and DF modes.","Relays,
OFDM,
Channel capacity,
Protocols,
Noise,
Broadband communication,
Power grids"
Binarization of Low-Quality Barcode Images Captured by Mobile Phones Using Local Window of Adaptive Location and Size,"It is difficult to directly apply existing binarization approaches to the barcode images captured by mobile device due to their low quality. This paper proposes a novel scheme for the binarization of such images. The barcode and background regions are differentiated by the number of edge pixels in a search window. Unlike existing approaches that center the pixel to be binarized with a window of fixed size, we propose to shift the window center to the nearest edge pixel so that the balance of the number of object and background pixels can be achieved. The window size is adaptive either to the minimum distance to edges or minimum element width in the barcode. The threshold is calculated using the statistics in the window. Our proposed method has demonstrated its capability in handling the nonuniform illumination problem and the size variation of objects. Experimental results conducted on 350 images captured by five mobile phones achieve about 100% of recognition rate in good lighting conditions, and about 95% and 83% in bad lighting conditions. Comparisons made with nine existing binarization methods demonstrate the advancement of our proposed scheme.",
Adaptive time slotted channel hopping for wireless sensor networks,"The performance of wireless sensor networks (WSN) is prone to adverse influences from a number of factors such as the interference from co-located wireless systems utilising the same spectral space. Channel hopping technique was proposed to mitigate the problem via periodic change of the operating frequency, and has been adopted in the form of time slotted channel hopping (TSCH) by IEEE 802.15.4e standard. This paper proposes adaptive slotted channel hopping (A-TSCH), an enhanced version of the TSCH aided by blacklisting technique. Complete design and implementation specifics are provided; and the results of experiments are analysed to show its advantages over existing TSCH. The main finding of this work is that A-TSCH can significantly improve the reliability of channel hopping scheme and thus provide better protection from interference for wireless sensor networks.","Wireless sensor networks,
Noise,
IEEE 802.15 Standards,
Equations,
Mathematical model,
Channel estimation,
Interference"
Energy-Efficient Delay-Constrained Transmission and Sensing for Cognitive Radio Systems,"In this paper, we study energy-efficient transmission for Cognitive Radio (CR) that opportunistically operates on the primary user's channel through spectrum sensing. Spectrum sensing and compulsory idling (for incumbent protection) introduce energy overheads for Secondary User (SU) operations, and thus, an appropriate balance between energy consumption in data transmission and energy overheads is required. We formulate this problem as a discrete-time Markov decision process in which the SU aims at minimizing its average cost (including both energy consumption and delay cost) to finish a target traffic payload through an appropriate rate allocation. Based on certainty equivalent control, we propose a low-complexity rate-adaptation policy that achieves comparable performance with the optimal policy. With the low-complexity policy, we quantify the impact of energy overheads (including the power consumption for spectrum sensing and compulsory idling) on the SU transmission strategy. Specifically, the SU rate increases with the increase of energy overheads, whose marginal impact, however, diminishes. Moreover, the marginal impact of energy overheads is more significant for delay-insensitive traffic compared with that for delay-sensitive traffic. To mitigate the loss due to imperfect spectrum sensing, we quantify that the SU decreases (increases) its rate with a larger misdetection probability (false alarm probability).","Sensors,
Delay,
Payloads,
Energy consumption,
Educational institutions,
Markov processes,
Fading"
On the construction of data aggregation tree with minimum energy cost in wireless sensor networks: NP-completeness and approximation algorithms,"In many applications, it is a basic operation for the sink to periodically collect reports from all sensors. Since the data gathering process usually proceeds for many rounds, it is important to collect these data efficiently, that is, to reduce the energy cost of data transmission. Under such applications, a tree is usually adopted as the routing structure to save the computation costs for maintaining the routing tables of sensors. In this paper, we work on the problem of constructing a data aggregation tree that minimizes the total energy cost of data transmission in a wireless sensor network. In addition, we also address such a problem in the wireless sensor network where relay nodes exist. We show these two problems are NP-complete, and propose O(1)-approximation algorithms for each of them. Simulations show that the proposed algorithms each have good performance in terms of the energy cost.","Approximation algorithms,
Approximation methods,
Relays,
Routing,
Wireless sensor networks,
Sensors,
Steiner trees"
Simultaneous Localization of Multiple Unknown and Transient Radio Sources Using a Mobile Robot,"We report system and algorithm developments that utilize a single mobile robot to simultaneously localize multiple unknown transient radio sources. Because of signal source anonymity, short transmission durations, and dynamic transmission patterns, the robot cannot treat the radio sources as continuous radio beacons. To deal with this challenging localization problem, we model the radio source behaviors using a novel spatiotemporal probability occupancy grid that captures transient characteristics of radio transmissions and tracks posterior probability distributions of radio sources. As a Monte Carlo method, a ridge walking motion planning algorithm is proposed to enable the robot to efficiently traverse the high-probability regions to accelerate the convergence of the posterior probability distribution. We also formally show that the time to find a radio source is insensitive to the number of radio sources, and hence, our algorithm has great scalability. We have implemented the algorithms and extensively tested them in comparison with two heuristic methods: a random walk and a fixed-route patrol. The localization time of our algorithms is consistently shorter than that of the two heuristic methods.","Robot sensing systems,
Transient analysis,
Antenna radiation patterns,
Mobile robots"
Characterization of Encapsulants for High-Voltage High-Temperature Power Electronic Packaging,"Seven encapsulants with operating temperature up to 250 °C are surveyed for possible use in high-temperature high-power planar packages. Processability is assessed by studying the flow fronts and the cured properties of the surveyed materials between paralleled plates. Material B failed in the flow test because it dried out in seconds. Materials A, C, and D failed the curability test because A and C showed volume shrinkage during curing, while D cracked after curing owing to its brittle nature. It is found that elastic materials that usually correspond to low glass transition temperatures (Tg) tend to perform better with regard to large-area planar-structure packages. Materials E-G are confirmed to be comparatively stable with respect to temperature, and both dielectric strength and dielectric permittivity decrease by about 40 and 30%, respectively, as the temperature is increased from 25 to 250 °C. The thermal aging test show that the materials harden during the aging process. Meanwhile, cracking starts in the material matrix. The dielectric strength of the sample drops by 60-70% to only around 10 kV/mm once cracking occurs.","Curing,
Glass,
Substrates,
Packaging,
Dielectrics,
Dielectric breakdown"
It was a bit of a race: Gamification of version control,"The adoption of software engineering practices cannot always be achieved by education or processes. However, social software has the potential for supporting deliberate behavior change. We present preliminary results of an experiment in which we encouraged computer science students to make more frequent commits to version control by using a social software application. We provided a web-based newsfeed of commits that also displayed a leaderboard. While we have yet to analyze the data, interviews we conducted with the participants allow for first qualitative insights.","Software,
Software engineering,
Lead,
Games,
Electronic mail,
Education,
Computer science"
Object Segmentation of Database Images by Dual Multiscale Morphological Reconstructions and Retrieval Applications,"Processing images for specific targets on a large scale has to handle various kinds of contents with regular processing steps. To segment objects in one image, we utilized dual multiScalE Graylevel mOrphological open and close recoNstructions (SEGON) to build a background (BG) gray-level variation mesh, which can help to identify BG and object regions. It was developed from a macroscopic perspective on image BG gray levels and implemented using standard procedures, thus robustly dealing with large-scale database images. The image segmentation capability of existing methods can be exploited by the BG mesh to improve object segmentation accuracy. To evaluate the segmentation accuracy, the probability of coherent segmentation labeling, i.e., the normalized probability random index (PRI), between a computer-segmented image and the hand-labeled one is computed for comparisons. Content-based image retrieval (CBIR) was carried out to evaluate the object segmentation capability in dealing with large-scale database images. Retrieval precision-recall (PR) and rank performances, with and without SEGON, were compared. For multi-instance retrieval with shape feature, AdaBoost was used to select salient common feature elements. For color features, the histogram intersection between two scalable HSV descriptors was calculated, and the mean feature vector was used for multi-instance retrieval. The distance measure for color feature can be adapted when both positive and negative queries are provided. The normalized correlation coefficient of features among query samples was computed to integrate the similarity ranks of different features in order to perform multi-instance with multifeature query. Experiments showed that the proposed object segmentation method outperforms others by 21% in the PRI. Performing SEGON-enabled CBIR on large-scale databases also improves on the PR performance reported elsewhere by up to 42% at a recall rate of 0.5. The proposed object segmentation method can be extended to extract other image features, and new feature types can be incorporated into the algorithm to further improve the image retrieval performance.","Image segmentation,
Image reconstruction,
Object segmentation,
Databases,
Shape,
Image color analysis,
Stability criteria"
Initialization Independent Clustering With Actively Self-Training Method,"The results of traditional clustering methods are usually unreliable as there is not any guidance from the data labels, while the class labels can be predicted more reliable by the semisupervised learning if the labels of partial data are given. In this paper, we propose an actively self-training clustering method, in which the samples are actively selected as training set to minimize an estimated Bayes error, and then explore semisupervised learning to perform clustering. Traditional graph-based semisupervised learning methods are not convenient to estimate the Bayes error; we develop a specific regularization framework on graph to perform semisupervised learning, in which the Bayes error can be effectively estimated. In addition, the proposed clustering algorithm can be readily applied in a semisupervised setting with partial class labels. Experimental results on toy data and real-world data sets demonstrate the effectiveness of the proposed clustering method on the unsupervised and the semisupervised setting. It is worthy noting that the proposed clustering method is free of initialization, while traditional clustering methods are usually dependent on initialization.","Clustering algorithms,
Semisupervised learning,
Vectors,
Reliability,
Clustering methods,
Laplace equations,
Manifolds"
Super-Resolution in Respiratory Synchronized Positron Emission Tomography,"Respiratory motion is a major source of reduced quality in positron emission tomography (PET). In order to minimize its effects, the use of respiratory synchronized acquisitions, leading to gated frames, has been suggested. Such frames, however, are of low signal-to-noise ratio (SNR) as they contain reduced statistics. Super-resolution (SR) techniques make use of the motion in a sequence of images in order to improve their quality. They aim at enhancing a low-resolution image belonging to a sequence of images representing different views of the same scene. In this work, a maximum a posteriori (MAP) super-resolution algorithm has been implemented and applied to respiratory gated PET images for motion compensation. An edge preserving Huber regularization term was used to ensure convergence. Motion fields were recovered using a B-spline based elastic registration algorithm. The performance of the SR algorithm was evaluated through the use of both simulated and clinical datasets by assessing image SNR, as well as the contrast, position and extent of the different lesions. Results were compared to summing the registered synchronized frames on both simulated and clinical datasets. The super-resolution image had higher SNR (by a factor of over 4 on average) and lesion contrast (by a factor of 2) than the single respiratory synchronized frame using the same reconstruction matrix size. In comparison to the motion corrected or the motion free images a similar SNR was obtained, while improvements of up to 20% in the recovered lesion size and contrast were measured. Finally, the recovered lesion locations on the SR images were systematically closer to the true simulated lesion positions. These observations concerning the SNR, lesion contrast and size were confirmed on two clinical datasets included in the study. In conclusion, the use of SR techniques applied to respiratory motion synchronized images lead to motion compensation combined with improved image SNR and contrast, without any increase in the overall acquisition times.","Lesions,
Positron emission tomography,
Signal to noise ratio,
Image reconstruction,
Synchronization,
Spatial resolution"
Hybrid Computational Simulation and Study of Continuous Wave Terahertz Photomixers,"A hybrid numerical simulation method is presented to model and analyze integrated terahertz (THz) photomixer antennas. The proposed computational method combines an optoelectronic solver and a full-wave electromagnetic solver to rigorously model continuous wave (CW) THz photomixer sources. In this hybrid computational approach, the photomixer source is modeled in a rigorous manner without any approximation. The optoelectronic solver is used to find absorbed optical intensity and optical carrier generation rate inside the fast photoconductive region through solving an optical scattering problem. Then, the equations governing the charge carrier transport inside the photoconductor are solved to give THz photo-current by considering realistic material parameters. Finally, through a full-wave electromagnetic solver, and using calculated photo-current from the optoelectronic simulator, antenna parameters and radiated THz power are obtained. Using the proposed hybrid simulation method the effects of photomixer parameters on the THz photo-current and radiated power is rigorously investigated for several geometries. Moreover, results of a parametric study on various factors such as carrier lifetime of material, incident optical power density, applied bias voltage, THz beat frequency, and the gap size are presented. The method can be used for accurate design refinement at pre-fabrication stage.","Optical scattering,
Mathematical model,
Computational modeling,
Charge carrier processes,
Broadband antennas"
"Discriminative Training for Automatic Speech Recognition: Modeling, Criteria, Optimization, Implementation, and Performance","Discriminative training techniques have been shown to consistently outperform the maximum likelihood (ML) paradigm for acoustic model training in automatic speech recognition (ASR). Consequently, today's discriminative training methods are fundamental components of state-of-the-art systems and are a major line of research in speech recognition. This article gives a comprehensive overview of discriminative training methods for acoustic model training in the context of ASR. The article covers all related aspects of discriminative training for speech recognition, i.e., specific training criteria and their relation, statistical modeling, different parameter optimization approaches, efficient implementation of discriminative training, and a performance overview.","Automatic speech recognition,
Speech recognition,
Training,
Modeling,
Performance evaluation,
Acoustics,
Maximum likelihood estimation"
Android botnets on the rise: Trends and characteristics,"Smartphones are the latest technology trend of the 21st century. Today's social expectation of always staying connected and the need for an increase in productivity are the reasons for the increase in smartphone usage. One of the leaders of the smartphone evolution is Google's Android Operating System (OS). The openness of the design and the ease of customizing are the aspects that are placing Android ahead of the other smartphone OSs. Such popularity has not only led to an increase in Android usage but also to the rise of Android malware. Although such malware is not having a significant impact on the popularity of Android smartphones, it is however creating new possibilities for threats. One such threat is the impact of botnets on Android smartphones. Recently, malware has surfaced that revealed specific characteristics relating to traditional botnet activities. Malware such as Geinimi, Pjapps, DroidDream, and RootSmart all display traditional botnet functionalities. These malicious applications show that Android botnets is a reality. From a security perspective it is important to understand the underlying structure of an Android botnet. This paper evaluates Android malware with the purpose of identifying specific trends and characteristics relating to botnet behaviour. The botnet trends and characteristics are detected by a comprehensive literature study of well-known Android malware applications. The identified characteristics are then further explored in terms of the Android Botnet Development Model and the Android Botnet Discovery Process. The common identified trends and characteristics aid the understanding of Android botnet activities as well as the possible discovery of an Android bot.","Androids,
Humanoid robots,
Smart phones,
Malware,
Market research,
Servers"
Order Matters: Transmission Reordering in Wireless Networks,"Modern wireless interfaces support a physical-layer capability called Message in Message (MIM). Briefly, MIM allows a receiver to disengage from an ongoing reception and engage onto a stronger incoming signal. Links that otherwise conflict with each other can be made concurrent with MIM. However, the concurrency is not immediate and can be achieved only if conflicting links begin transmission in a specific order. The importance of link order is new in wireless research, motivating MIM-aware revisions to link-scheduling protocols. This paper identifies the opportunity in MIM-aware reordering, characterizes the optimal improvement in throughput, and designs a link-layer protocol for enterprise wireless LANs to achieve it. Testbed and simulation results confirm the performance gains of the proposed system.",
3-line RANSAC for orthogonal vanishing point detection,"A wide range of robotic systems needs to estimate their rotation for diverse tasks like automatic control and stabilization, among many others. In regards of the limitations of traditional navigation equipments (like GPS and inertial sensors), this paper follows a vision approach based on the observation of vanishing points (VPs). Urban environments (outdoor as well as indoor) generally contain orthogonal VPs which constitutes an important constraint to fulfill in order to correctly acquire the structure of the scenes. In contrast to existing VP-based techniques, our method inherently enforces the orthogonality of the VPs by directly incorporating the orthogonality constraint into the model estimation step of the RANSAC procedure, which allows real-time applications. The model is estimated from only 3 lines, which corresponds to the theoretical minimal sampling for rotation estimation and constitutes our 3-line RANSAC. We also propose a 1-line RANSAC when the horizon plane is known. Our algorithm has been validated successfully on challenging real datasets.","Estimation,
Real-time systems,
Cameras,
Clustering algorithms,
Robots,
Complexity theory,
Google"
Discovering Thematic Objects in Image Collections and Videos,"Given a collection of images or a short video sequence, we define a thematic object as the key object that frequently appears and is the representative of the visual contents. Successful discovery of the thematic object is helpful for object search and tagging, video summarization and understanding, etc. However, this task is challenging because 1) there lacks a priori knowledge of the thematic objects, such as their shapes, scales, locations, and times of re-occurrences, and 2) the thematic object of interest can be under severe variations in appearances due to viewpoint and lighting condition changes, scale variations, etc. Instead of using a top-down generative model to discover thematic visual patterns, we propose a novel bottom-up approach to gradually prune uncommon local visual primitives and recover the thematic objects. A multilayer candidate pruning procedure is designed to accelerate the image data mining process. Our solution can efficiently locate thematic objects of various sizes and can tolerate large appearance variations of the same thematic object. Experiments on challenging image and video data sets and comparisons with existing methods validate the effectiveness of our method.","Visualization,
Data mining,
Videos,
Vocabulary,
Complexity theory,
Search problems,
Image segmentation"
Fair and Consistent Hardware Evaluation of Fourteen Round Two SHA-3 Candidates,"The first contribution of our paper is that we propose a platform, a design strategy, and evaluation criteria for a fair and consistent hardware evaluation of the second-round SHA-3 candidates. Using a SASEBO-GII field-programmable gate array (FPGA) board as a common platform, combined with well defined hardware and software interfaces, we compare all 256-bit version candidates with respect to area, throughput, latency, power, and energy consumption. Our approach defines a standard testing harness for SHA-3 candidates, including the interface specification for the SHA-3 module on our testing platform. The second contribution is that we provide both FPGA and 90-nm CMOS application-specific integrated circuit (ASIC) synthesis results and thereby are able to compare the results. Our third contribution is that we release the source code of all the candidates and by using a common, fixed, publicly available platform, our claimed results become reproducible and open for a public verification.","Hardware,
Field programmable gate arrays,
Clocks,
Cryptography,
Software,
Throughput"
Image Deblurring Using Derivative Compressed Sensing for Optical Imaging Application,"The problem of reconstruction of digital images from their blurred and noisy measurements is unarguably one of the central problems in imaging sciences. Despite its ill-posed nature, this problem can often be solved in a unique and stable manner, provided appropriate assumptions on the nature of the images to be recovered. In this paper, however, a more challenging setting is considered, in which accurate knowledge of the blurring operator is lacking, thereby transforming the reconstruction problem at hand into a problem of blind deconvolution. As a specific application, the current presentation focuses on reconstruction of short-exposure optical images measured through atmospheric turbulence. The latter is known to give rise to random aberrations in the optical wavefront, which are in turn translated into random variations of the point spread function of the optical system in use. A standard way to track such variations involves using adaptive optics. Thus, for example, the Shack-Hartmann interferometer provides measurements of the optical wavefront through sensing its partial derivatives. In such a case, the accuracy of wavefront reconstruction is proportional to the number of lenslets used by the interferometer and, hence, to its complexity. Accordingly, in this paper, we show how to minimize the above complexity through reducing the number of the lenslets while compensating for undersampling artifacts by means of derivative compressed sensing. Additionally, we provide empirical proof that the above simplification and its associated solution scheme result in image reconstructions, whose quality is comparable to the reconstructions obtained using conventional (dense) measurements of the optical wavefront.","Image reconstruction,
Optical imaging,
Optical interferometry,
Optical sensors,
Apertures,
Adaptive optics,
Optical variables measurement"
Identifying models of HVAC systems using semiparametric regression,"Heating, ventilation, and air-conditioning (HVAC) systems use a large amount of energy, and so they are an interesting area for efficiency improvements. The focus here is on the use of semiparametric regression to identify models, which are amenable to analysis and control system design, of HVAC systems. This paper briefly describes two testbeds that we have built on the Berkeley campus for modeling and efficient control of HVAC systems, and we use these testbeds as case studies for system identification. The main contribution of this work is that the use of semiparametric regression allows for the estimation of the heating load from occupancy, equipment, and solar heating using only temperature measurements. These estimates are important for building accurate models as well as designing efficient control schemes, and in our other work we have been able to achieve a reduction in energy consumption on a single room testbed using heating load estimation in conjunction with the learning-based model predictive control (LBMPC) technique. Furthermore, this framework is not restrictive to modeling nonlinear HVAC behavior, because we have been able to use this methodology to create hybrid system models that incorporate such nonlinearities.",
Closed-Form Expressions for the Maximum Transient Noise Voltage Caused by an IC Switching Current on a Power Distribution Network,"Closed-form expressions for transient power distribution network (PDN) noise caused by an IC switching current are derived for a PDN structure comprised of traces with decoupling capacitors. Criteria for identifying a dominant decoupling capacitor for an impulse switching current are also proposed. The derived PDN noise expressions are validated with measurements of currents at both local and bulk capacitors, the PDN impedance, and the total voltage noise in an operating consumer device.",
Miniature Hook-Shaped Multiband Antenna for Mobile Applications,"In this letter, a novel and compact printed monopole antenna is presented, which has a simple but effective radiating patch for multiband wireless communication systems and mobile devices. Operational bands covered simultaneously by the antenna include the following: UMTS (1920-2170 MHz), 2.4-GHz WLAN (2400-2484 MHz), mobile WiMAX (IEEE 802.16e 2500-2690 MHz), 5-GHz WLAN (5150-5350/5725-5825 MHz), and ITS (5795-6400 MHz). A parametric study is applied in the antenna design process to achieve the required operational frequency bands. Desired resonances can be tuned by adjusting the gaps between the radiating semicircular arms and central feed-line, as well as embedding a dielectric slot in the ground surface. The antenna has dimensions ~ 20×20×1 mm3, which is smaller than previously proposed monopole structures. The design concept was validated by fabricating the antenna prototype and measuring its characteristics. The measured results show the antenna exhibits omnidirectional radiation and appropriate gain.","Antenna measurements,
Wireless LAN,
Microstrip antennas,
WiMAX,
Antenna radiation patterns,
Slot antennas"
Hybrid Nanomaterial for Stabilizing the Antibiofilm Activity of Eugenia carryophyllata Essential Oil,"The aim of the present study was to demonstrate that Fe3O4/oleic acid core/shell nanostructures could be used as systems for stabilizing the Eugenia carryophyllata essential oil (EO) on catheter surface pellicles, in order to improve their resistance to fungal colonization. EO microwave assisted extraction was performed in a Neo-Clevenger (related) device and its chemical composition was settled by GC-MS analysis. Fe3O4/oleic acid-core/shell nanoparticles (NP) were obtained by a precipitation method under microwave condition. High resolution transmission electron microscopy (HR-TEM) was used as a primary characterization method. The NPs were processed to achieve a core/shell/EO coated-shell nanosystem further used for coating the inner surface of central venous catheter samples. The tested fungal strains have been recently isolated from different clinical specimens. The biofilm architecture was assessed by confocal laser scanning microscopy (CLSM). Our results claim the usage of hybrid nanomaterial (core/shell/coated-shell) for the stabilization of E. carryophyllata EO, which prevented or inhibited the fungal biofilm development on the functionalized catheter, highlighting the opportunity of using these nanosystems to obtain improved, anti-biofilm coatings for biomedical applications.","Catheters,
Surface treatment,
Fungi,
Biomedical materials,
Nanostructures"
Methods for Reliable Simulation-Based PLC Code Verification,"Simulation-based programmable logic controller (PLC) code verification is a part of virtual commissioning, where the control code is verified against a virtual prototype of an application. With today's general OPC interface, it is easy to connect a PLC to a simulation tool for, e.g., verification purposes. However, there are some problems with this approach that can lead to an unreliable verification result. In this paper, four major problems with the OPC interface are described, and two possible solutions to the problems are presented: a general IEC 61131-3-based software solution, and a new OPC standard solution.","Real time systems,
Robots,
Jitter,
Servers,
Computational modeling,
Metals,
Synchronization"
Image Prediction Based on Neighbor-Embedding Methods,"This paper describes two new intraimage prediction methods based on two data dimensionality reduction methods: nonnegative matrix factorization (NMF) and locally linear embedding. These two methods aim at approximating a block to be predicted in the image as a linear combination of k-nearest neighbors determined on the known pixels in a causal neighborhood of the input block. Variable k can be seen as a parameter controlling some sort of sparsity constraints of the approximation vector. The impact of this parameter as well as of the nonnegativity and sum-to-one constraints for the addressed prediction problem has been analyzed. The prediction and RD performances of these two new image prediction methods have then been evaluated in a complete image coding-and-decoding algorithm. Simulation results show gains up to 2 dB in terms of the PSNR of the reconstructed signal after coding and decoding of the prediction residue when compared with H.264/AVC intraprediction modes, up to 3 dB when compared with template matching, and up to 1 dB when compared with a sparse prediction method.","Approximation methods,
Dictionaries,
Prediction algorithms,
Matching pursuit algorithms,
Approximation algorithms,
Decoding,
Prediction methods"
Adaptive Local Fusion With Fuzzy Integrals,"We propose a novel method for fusing different classifiers outputs. Our approach, called context extraction for local fusion with fuzzy integrals (CELF-FI), is a local approach that adapts a fuzzy integrals fusion method to different regions of the feature space. It is based on a novel objective function that combines context identification and multialgorithm fusion criteria into a joint objective function. This objective function consists of two terms: The first is designed to produce compact clusters, called contexts, and the second is designed to produce Sugeno measures for fuzzy integral fusion for each context. The terms are optimized simultaneously via alternating optimization. To test a new sample, first, its features (extracted by each algorithm) are used to assign it to each context with a fuzzy membership degree. Second, the sample confidence values (assigned by each algorithm) are fused within each context using the learned context fusion parameters. Then, the context-dependent partial confidence values are weighted by the membership degrees and averaged over all contexts to produce a final confidence value. We illustrate the performance of CELF using synthetic data, and we apply it to the problem of landmine detection using ground penetrating radar and wideband electromagnetic induction. Our extensive experiments have indicated that the proposed fusion approach outperforms all individual classifiers, the global fuzzy integral fusion method, and the basic local fusion with linear aggregation.",
Associating Internet Usage with Depressive Behavior Among College Students,"Depression is a serious mental health problem affecting a significant segment of American society today, and in particular college students. In a survey by the U.S. Centers for Disease Control (CDC) in 2009, 26.1% of U.S. students nationwide reported feeling so sad or hopeless almost every day for 2 or more weeks in a row that they stopped doing some usual activities. Similar statistics are also reported in mental health studies by the American College Health Association, and by independent surveys. In this article, the author report their findings from a month-long experiment conducted at Missouri University of Science and Technology on studying depressive symptoms among college students who use the Internet. This research was carried out using real campus Internet data collected continuously, unobtrusively, and while preserving privacy.",
Invertible Extractors and Wiretap Protocols,"A wiretap protocol is a pair of randomized encoding and decoding functions such that knowledge of a bounded fraction of the encoding of a message reveals essentially no information about the message, while knowledge of the entire encoding reveals the message using the decoder. In this paper, the notion of efficiently invertible extractors is studied and it is shown that a wiretap protocol can be constructed from such an extractor. Then, invertible extractors for symbol-fixing, affine, and general sources are constructed and used to create wiretap protocols with asymptotically optimal trade-offs between their rate (ratio of the length of the message versus its encoding) and resilience (ratio of the observed positions of the encoding and the length of the encoding). The results are further applied to create wiretap protocols for challenging communication problems, such as active intruders who change portions of the encoding, network coding, and intruders observing arbitrary Boolean functions of the encoding.","Protocols,
Encoding,
Entropy,
Decoding,
Resilience,
Privacy,
Network coding"
Imagining the Future: Thoughts on Computing,"New and compelling ideas are transforming the future of computing, bringing about a plethora of changes that have significant implications for our profession and our society and raising some profound technical questions. This Web extra video interview features Dan Reed of Microsoft giving us a sense of how new cloud architectures and cloud capabilities will begin to move computer science education, research, and thinking in whole new directions.","Cloud computing,
Technological innovation,
Privacy,
Network security"
The Relevance Voxel Machine (RVoxM): A Self-Tuning Bayesian Model for Informative Image-Based Prediction,"This paper presents the relevance voxel machine (RVoxM), a dedicated Bayesian model for making predictions based on medical imaging data. In contrast to the generic machine learning algorithms that have often been used for this purpose, the method is designed to utilize a small number of spatially clustered sets of voxels that are particularly suited for clinical interpretation. RVoxM automatically tunes all its free parameters during the training phase, and offers the additional advantage of producing probabilistic prediction outcomes. We demonstrate RVoxM as a regression model by predicting age from volumetric gray matter segmentations, and as a classification model by distinguishing patients with Alzheimer's disease from healthy controls using surface-based cortical thickness data. Our results indicate that RVoxM yields biologically meaningful models, while providing state-of-the-art predictive accuracy.",
MobiShare: Flexible privacy-preserving location sharing in mobile online social networks,"Location sharing is a fundamental component of mobile online social networks (mOSNs), which also raises significant privacy concerns. The mOSNs collect a large amount of location information over time, and the users' location privacy is compromised if their location information is abused by adversaries controlling the mOSNs. In this paper, we present MobiShare, a system that provides flexible privacy-preserving location sharing in mOSNs. MobiShare is flexible to support a variety of location-based applications, in that it enables location sharing between both trusted social relations and untrusted strangers, and it supports range query and user-defined access control. In MobiShare, neither the social network server nor the location server has a complete knowledge of the users' identities and locations. The users' location privacy is protected even if either of the entities colludes with malicious users.",
"GENESIS: An agent-based model of interdomain network formation, traffic flow and economics","We propose an agent-based network formation model for the Internet at the Autonomous System (AS) level. The proposed model, called GENESIS, is based on realistic provider and peering strategies, with ASes acting in a myopic and decentralized manner to optimize a cost-related fitness function. GENESIS captures key factors that affect the network formation dynamics: highly skewed traffic matrix, policy-based routing, geographic co-location constraints, and the costs of transit/peering agreements. As opposed to analytical game-theoretic models, which focus on proving the existence of equilibria, GENESIS is a computational model that simulates the network formation process and allows us to actually compute distinct equilibria (i.e., networks) and to also examine the behavior of sample paths that do not converge. We find that such oscillatory sample paths occur in about 10% of the runs, and they always involve tier- 1 ASes, resembling the tier-1 peering disputes often seen in practice. GENESIS results in many distinct equilibria that are highly sensitive to initial conditions and the order in which ASes (agents) act. This implies that we cannot predict the properties of an individual AS in the Internet. However, certain properties of the global network or of certain classes of ASes are predictable. We also examine whether the underlying game is zero-sum, and identify three sufficient conditions for that property. Finally, we apply GENESIS in a specific “what-if” question, asking how the openness towards peering affects the resulting network in terms of topology, traffic flow and economics. Interestingly, we find that the peering openness that maximizes the fitness of different network classes (tier-1, tier-2 and tier-3 providers) closely matches that seen in real-world peering policies.","Peer to peer computing,
Oscillators,
Internet,
Computational modeling,
Economics,
Network topology,
Topology"
Online incremental attribute-based zero-shot learning,"The paper presents a new online incremental zero-shot learning method for applications in robotics and mobile communications where attribute labeling is obtained via online interaction with users, and where the potential for inconsistency exists. Unique to most previous offline batch learning methods, the proposed method is based on the indirect-attribute-prediction (IAP) model instead of the direct-attribute-prediction (DAP). Using self-organizing and incremental neural networks (SOINN) as the learning mechanism, our method can learn new attributes and update existing attributes in an online incremental manner while retaining as high accuracy as that of the state-of-the-art offline method. Compared to the offline methods, the computation time has also been reduced by more than 99%. Two experiments evaluated two aspects of the proposed method. First, our method clearly outperforms the previous IAP-based offline method in terms of both time and accuracy, and yield approximately the same accuracy as the DAP-based offline method. Second, the proposed method can deal with situations where object attributes are gradually labeled via interaction with many users and where some of them may be incorrect. This scenario is very important for applications in mobile communications and robotics where some objects and attributes may be initially unknown and must be learnt online.",
KNN matting,"We are interested in a general alpha matting approach for the simultaneous extraction of multiple image layers; each layer may have disjoint segments for material matting not limited to foreground mattes typical of natural image matting. The estimated alphas also satisfy the summation constraint. Our approach does not assume the local color-line model, does not need sophisticated sampling strategies, and generalizes well to any color or feature space in any dimensions. Our matting technique, aptly called KNN matting, capitalizes on the nonlocal principle by using K nearest neighbors (KNN) in matching nonlocal neighborhoods, and contributes a simple and fast algorithm giving competitive results with sparse user markups. KNN matting has a closed-form solution that can leverage on the preconditioned conjugate gradient method to produce an efficient implementation. Experimental evaluation on benchmark datasets indicates that our matting results are comparable to or of higher quality than state of the art methods.",
Signal Detection in Antenna-Hopping Space-Division Multiple-Access Systems With Space-Shift Keying Modulation,"To take the advantages of the M-ary space-shift keying (MSSK) modulation invented recently, a MSSK fast antenna-hopping space-division multiple-access (MSSK FAH-SDMA) scheme is proposed and studied in this paper. In addition to supporting multiple-access, the FAH is introduced also to achieve transmit diversity by sending every MSSK symbol over several time-slots under the control of a FAH pattern (address). Associated with the MSSK FAH-SDMA, a range of linear and nonlinear detection schemes are studied. Specifically, the linear detection schemes considered include the matched-filtering single-user detector (MF-SUD), zero-forcing multiuser detector (ZF-MUD) and minimum mean-square error (MMSE)-MUD, while the nonlinear detection schemes addressed include the maximum likelihood (ML)-MUD and the receiver multiuser diversity aided multi-stage MMSE (RMD/MS-MMSE) MUD. The single-user pairwise error probability (SU-PEP) and bit error rate (BER) union-bound of the single-user MSSK FAH-SDMA systems employing ML detection are analyzed in detail. Based on the SU-PEP, the minimum transmit diversity order of the MSSK FAH-SDMA systems is specified. For the MSSK FAH-SDMA systems with linear detection, we study two types of MSSK demodulation schemes, which are referred to as the intrauser detections (IUDs), named as the maximum likelihood (ML)-IUD and direct (D)-IUD. For the MSSK FAH-SDMA systems employing the RMD/MS-MMSE MUD, two types of reliability measurement (RM) schemes are proposed, which are the maximum a-posteriori (MAP)-RM and ratio test (RT)-RM. Finally, the BER performance of the MSSK FAH-SDMA systems with various combinations of the proposed techniques is studied, when assuming that the channels from any transmit antennas to any receive antennas experience independent and identically distributed (i.i.d.) Rayleigh fading.","Transmitting antennas,
Multiuser detection,
Modulation,
Receiving antennas,
Bit error rate,
Multiaccess communication"
Scaling of High-Aspect-Ratio Current Limiters for the Individual Ballasting of Large Arrays of Field Emitters,"We report the fabrication and characterization of high-aspect-ratio silicon pillar current limiters [vertical ungated field-effect transistors (FETs)] for ballasting individual field emitters within field-emitter arrays (FEAs). Dense (1-
μm
pitch) FEAs that are individually ballasted by 100-nm-diameter and 10-
μm
-tall current limiters were fabricated, resulting in an emitter tip radius under 10 nm. When characterized without field emitters, the vertical current limiters (ungated FETs) show current-source-like behavior, with saturation currents up to 15 pA/FET. When the current limiters are incorporated into large arrays of field emitters, the current–voltage characteristics of the FEA show evidence of current limitation at high extraction gate voltages. Emission current densities of over 200
μ
A/cm
2
were obtained from 1.36 million emitter arrays with 5-
μm
pitch.","Current limiters,
Silicon,
Logic gates,
FETs,
Doping,
Electronic ballasts,
Fabrication"
A Tripolar Current-Steering Stimulator ASIC for Field Shaping in Deep Brain Stimulation,"A significant problem with clinical deep brain stimulation (DBS) is the high variability of its efficacy and the frequency of side effects, related to the spreading of current beyond the anatomical target area. This is the result of the lack of control that current DBS systems offer on the shaping of the electric potential distribution around the electrode. This paper presents a stimulator ASIC with a tripolar current-steering output stage, aiming at achieving more selectivity and field shaping than current DBS systems. The ASIC was fabricated in a 0.35-μ m CMOS technology occupying a core area of 0.71 mm2. It consists of three current sourcing/sinking channels. It is capable of generating square and exponential-decay biphasic current pulses with five different time constants up to 28 ms and delivering up to 1.85 mA of cathodic current, in steps of 4 μA, from a 12 V power supply. Field shaping was validated by mapping the potential distribution when injecting current pulses through a multicontact DBS electrode in saline.","Satellite broadcasting,
Electric potential,
Application specific integrated circuits,
Finite element methods,
Anodes,
Nerve fibers"
Cascaded TAS/MRC in MIMO Multiuser Relay Networks,"We propose cascaded transmit antenna selection with maximal-ratio combining (TAS/MRC) for use in multiuser relay networks (MRN) with NS, NR, and ND antennas at the source, the relay, and each of the K destinations, respectively. We consider opportunistic scheduling where the destination with the highest instantaneous end-to-end signal-to-noise ratio (SNR) is scheduled for transmission. In cascaded TAS/MRC, a single transmit antenna that maximizes the instantaneous received SNR in each hop is selected, and all the receive antennas are MRC combined. We derive new exact closed-form statistics of the end-to-end SNR, from which we derive the exact and the approximate symbol error rate (SER) for M-ary quadrature amplitude modulation (M-QAM) and M-ary phase-shift keying (M-PSK). New concise expressions are derived to characterize the diversity order and the array gain. We highlight that our proposed scheme attains the maximum diversity order of NR × min{NS, NDK}. Furthermore, we determine the optimal power assignment at the source and the relay that minimizes the SER.","Relays,
Signal to noise ratio,
MIMO,
Receiving antennas,
Transmitting antennas,
Vectors"
Broadband Balun Using Fully Artificial Fractal-Shaped Composite Right/Left Handed Transmission Line,"In this letter, a compact balun with bandwidth enhancement is firstly proposed based on fully artificial fractal-shaped composite right/left handed transmission line (CRLH TL). It consists of three -90° CRLH branches and one +90° CRLH branch. The left handed contribution is realized by chip components while the right handed part is exploited by fractal microstriplines in terms of miniaturization. For verification, a balun operating at 1.5 GHz is designed, fabricated, and measured. Numerical and measured results agree well, which has confirmed the design concept and the derived formulae. The fabricated balun exhibits a bandwidth of 83.3% from 1 to 2.25 GHz, characterized by return loss better than 10 dB, amplitude and phase imbalance varied within ±1 dB and ±3.4°. Moreover, the circuit footprint is only 24.5% of the area that its conventional counterpart occupies.","Impedance matching,
Fractals,
Broadband communication,
Broadband antennas,
Wireless communication,
Transmission line measurements,
Impedance"
Efficient Image Copy Detection Using Multiscale Fingerprints,A multiscale scale-invariant feature transform (SIFT) descriptor can help improve our ability to discriminate between images when using copy detection to identify illegal image copies.,"Histograms,
Image recognition,
Visualization,
Binary codes,
Feature extraction,
Table lookup,
Hamming distance,
Digital forensics,
Forensics"
Connectivity of large-scale Cognitive Radio Ad Hoc Networks,"Connectivity of large-scale wireless networks has received considerable attention in the past several years. Different from traditional wireless networks, in Cognitive Radio Ad-hoc Networks (CRAHNs), primary users have spectrum access priority of the licensed bands over secondary users. Therefore, the connectivity of the secondary network is affected by not only the density and transmission power of secondary users, but also the activities of primary users. In addition, the number of licensed bands also has impact on the connectivity of CRAHNs. To capture the dynamic characteristics of opportunistic spectrum access, we introduce the Cognitive Radio Graph Model (CRGM) which takes into account the impact of the number of channels and the activities of primary users. Furthermore, we combine the CRGM with continuum percolation model to study the connectivity in the secondary network. We prove that secondary users can form the percolated network when the density of primary users is below the critical density. Then, the upper bound of the critical density of the primary users in the percolated CRAHNs is derived. Simulation results show that both the number of channels and the activities of primary users greatly impact the connectivity of CRAHNs.","Cognitive radio,
Availability,
Radio link,
Wireless networks,
Ad hoc networks,
Lattices,
Educational Activities Board"
Loss-Scaled Large-Margin Gaussian Mixture Models for Speech Emotion Classification,"This paper considers a learning framework for speech emotion classification using a discriminant function based on Gaussian mixture models (GMMs). The GMM parameter set is estimated by margin scaling with a loss function to reduce the risk of predicting emotions with high loss. Here, the loss function is defined as a function of a distance metric using the Watson and Tellegen's emotion model. Margin scaling is known to have good generalization ability and can be considered appropriate for emotion modeling where the parameter set is likely to be over-fitted to the training data set whose characteristics may differ from those of the testing data set. Our learning framework is formulated as a constrained optimization problem which is solved using semi-definite programming. Three tasks were evaluated: acted emotion classification, natural emotion classification, and cross database emotion classification. In each task, four loss functions were evaluated. In all experiments, results consistently show that margin scaling improves the classification accuracy over other learning frameworks based on the maximum-likelihood, maximum mutual information and max-margin framework without margin scaling. Experiment results also show that margin scaling substantially reduces the overall loss compared to the max-margin framework without margin scaling.","Speech,
Hidden Markov models,
Databases,
Training data,
Computers,
Testing,
Accuracy"
Edge-prioritized channel- and traffic-aware uplink Carrier Aggregation in LTE-advanced systems,"LTE-Advanced (LTE-A) systems support wider transmission bandwidths and hence, higher data rates for bulk traffic, as a result of Carrier Aggregation (CA). However, existing literature lacks efforts on channel-aware CA, especially in the uplink. The cell-edge users particularly suffer from exhaustion of resources, higher fading losses, lower SINR values (hence, requiring a higher power consumption) due to lossy channels that their traffic requirements are least-satisfied by channel-blind CA. This paper addresses the above concern by proposing an edge-prioritized channel- and traffic-aware uplink CA comprising Component Carrier (CC) assignment and resource scheduling. The LTE-A UEs are spatially-grouped and the under-represented edge UE groups, having the least assignable resources (good CCs), are prioritized for CA. This results in assigning the best channels to the edge groups. The frequency resources are scheduled to the groups based on inter-group and intra-group Proportional Fair Packet Scheduling (PFPS) in the time and frequency domains respectively, to resolve resource contention. The proposed approach outperforms the existing channel-blind Round-Robin and channel-aware Opportunistic CA, in terms of overall uplink throughput, by 33% in CC assignment and 21% in PFPS, in addition to significant throughput improvements for the edge UEs.",
Learning Content Similarity for Music Recommendation,"Many tasks in music information retrieval, such as recommendation, and playlist generation for online radio, fall naturally into the query-by-example setting, wherein a user queries the system by providing a song, and the system responds with a list of relevant or similar song recommendations. Such applications ultimately depend on the notion of similarity between items to produce high-quality results. Current state-of-the-art systems employ collaborative filter methods to represent musical items, effectively comparing items in terms of their constituent users. While collaborative filter techniques perform well when historical data is available for each item, their reliance on historical data impedes performance on novel or unpopular items. To combat this problem, practitioners rely on content-based similarity, which naturally extends to novel items, but is typically outperformed by collaborative filter methods. In this paper, we propose a method for optimizing content-based similarity by learning from a sample of collaborative filter data. The optimized content-based similarity metric can then be applied to answer queries on novel and unpopular items, while still maintaining high recommendation accuracy. The proposed system yields accurate and efficient representations of audio content, and experimental results show significant improvements in accuracy over competing content-based recommendation techniques.","Collaboration,
Measurement,
Equations,
Training,
Vectors,
Histograms,
Mel frequency cepstral coefficient"
Hierarchical Statistical Shape Models of Multiobject Anatomical Structures: Application to Brain MRI,"The accurate segmentation of subcortical brain structures in magnetic resonance (MR) images is of crucial importance in the interdisciplinary field of medical imaging. Although statistical approaches such as active shape models (ASMs) have proven to be particularly useful in the modeling of multiobject shapes, they are inefficient when facing challenging problems. Based on the wavelet transform, the fully generic multiresolution framework presented in this paper allows us to decompose the interobject relationships into different levels of detail. The aim of this hierarchical decomposition is twofold: to efficiently characterize the relationships between objects and their particular localities. Experiments performed on an eight-object structure defined in axial cross sectional MR brain images show that the new hierarchical segmentation significantly improves the accuracy of the segmentation, and while it exhibits a remarkable robustness with respect to the size of the training set.","Shape,
Training,
Brain models,
Mathematical model,
Image segmentation"
Compact covariance descriptors in 3D point clouds for object recognition,One of the most important tasks for mobile robots is to sense their environment. Further tasks might include the recognition of objects in the surrounding environment. Three dimensional range finders have become the sensors of choice for mapping the environment of a robot. Recognizing objects in point clouds provided by such sensors is a difficult task. The main contribution of this paper is the introduction of a new covariance based point cloud descriptor for such object recognition. Covariance based descriptors have been very successful in image processing. One of the main advantages of these descriptors is their relatively small size. The comparisons between different covariance matrices can also be made very efficient. Experiments with real world and synthetic data will show the superior performance of the covariance descriptors on point clouds compared to state-of-the-art methods.,
HBS: A Novel Biometric Feature Based on Heartbeat Morphology,"In this paper, a new feature named heartbeat shape (HBS) is proposed for ECG-based biometrics. HBS is computed from the morphology of segmented heartbeats. Computation of the feature involves three basic steps: 1) resampling and normalization of a heartbeat; 2) reduction of matching error; and 3) shift invariant transformation. In order to construct both gallery and probe templates, a few consecutive heartbeats which could be captured in a reasonably short period of time are required. Thus, the identification and verification methods become efficient. We have tested the proposed feature independently on two publicly available databases with 76 and 26 subjects, respectively, for identification and verification. The second database contains several subjects having clinically proven cardiac irregularities (atrial premature contraction arrhythmia). Experiments on these two databases yielded high identification accuracy (98% and 99.85%, respectively) and low verification equal error rate (1.88% and 0.38%, respectively). These results were obtained by using templates constructed from five consecutive heartbeats only. This feature compresses the original ECG signal significantly to be useful for efficient communication and access of information in telecardiology scenarios.","Electrocardiography,
Shape,
Polynomials,
Morphology,
Interpolation,
Feature extraction,
Kernel"
Tapered Slot Antenna With Band-Notched Function for Ultrawideband Radios,"A novel tapered slot antenna (TSA) with a band-notched function for ultrawideband (UWB) radios is proposed in this letter. By inserting an Archimedean spiral-shaped slot into a microstrip open-circuit circular stub of microstrip-slotline transition, a UWB operation with a notched frequency band can be obtained. Measured data for the optimized case show the bandwidth for the VSWR <; 2 to be 8.8 GHz (from 2.4 to 11.2 GHz) with a notched band frequency from 4.6 to 6.2 GHz. By inserting the resonance slot on the nonradiating part of the antenna, the proposed antenna is capable of avoiding the spatial-dependent bandstop characteristics. Also, the designed antenna has a small size of 50 × 50 mm2, which is a size reduction of 40% with respect to previous similar antennas.","Ultra wideband antennas,
Slot antennas,
Antenna measurements,
Frequency measurement,
Antenna radiation patterns"
Airlift: Video conferencing as a cloud service using inter-datacenter networks,"It is typical for enterprises to rely on services from cloud providers in order to build a scalable platform with abundant available resources to satisfy user demand, and for cloud providers to deploy a number of datacenters inter-connected with high-capacity links, across different geographical regions. In this paper, we propose that video conferencing, even with its stringent delay constraints, should also be provided as a cloud service, taking full advantage of the inter-datacenter network in the cloud. We design Airlift, a new protocol designed for the inter-datacenter network, tailored to the needs of a cloud-based video conferencing service. Airlift delivers packets in live video conferences to their respective destination datacenters, with the objective of maximizing the total throughput across all conferences, yet without violating end-to-end delay constraints. In order to simplify our protocol design in Airlift, we use intra-session network coding and the concept of conceptual flows, such that the optimization problem that can be conveniently formulated as a linear program. Our real-world implementation of Airlift has been deployed over the Amazon EC2 cloud. We show that Airlift delivers a substantial performance advantage over state-of-the-art peer-to-peer solutions.",
Temperature Measurement of Molten Pig Iron With Slag Characterization and Detection Using Infrared Computer Vision,"Accurate temperature measurement in industrial environments is as important as it is challenging. Precise control over temperature measurement is crucial when processing metals, such as iron or steel, where temperature monitoring is critical to productivity and product quality. In the steel manufacturing process, temperature measurement of molten pig iron is particularly important, as it is a required parameter of the physical models used to control operations in steel furnaces. However, measuring the temperature of molten pig iron is not an easy task. Conventional methods using thermocouples or pyrometers present serious drawbacks which limit their applicability and do not provide accurate measurements. In this paper, an infrared computer vision system is proposed to measure the temperature of molten pig iron while it is being poured. The proposed system confronts two challenges: The stream must be detected in the infrared images, and the slag, which can partially cover the stream of molten pig iron, must be detected and removed from the stream. Fast, robust, and accurate methods are proposed. A calibration procedure for the emissivity of the molten pig iron and for the temperature level is also proposed and applied. This procedure makes it possible to differentiate molten pig iron from slag in the stream. Tests indicate that the results meet production needs.","Temperature measurement,
Iron,
Streaming media,
Slag,
Image edge detection,
Mouth,
Cameras"
An Extended Path Following Algorithm for Graph-Matching Problem,"The path following algorithm was proposed recently to approximately solve the matching problems on undirected graph models and exhibited a state-of-the-art performance on matching accuracy. In this paper, we extend the path following algorithm to the matching problems on directed graph models by proposing a concave relaxation for the problem. Based on the concave and convex relaxations, a series of objective functions are constructed, and the Frank-Wolfe algorithm is then utilized to minimize them. Several experiments on synthetic and real data witness the validity of the extended path following algorithm.",
Optimal cost function and magnitude power for NMF-based speech separation and music interpolation,"There has been a significant amount of research in new algorithms and applications for nonnegative matrix factorization, but relatively little has been published on practical considerations for real-world applications, such as choosing optimal parameters for a particular application. In this paper, we will look at two applications, single-channel source separation of speech and interpolating missing music data. We will present the optimal parameters found for the experiments as well as discuss how parameters affect performance.","Vectors,
Tunneling magnetoresistance,
Speech,
Cost function,
Interpolation,
Training data,
Source separation"
Combining Numerous Uncorrelated MEMS Gyroscopes for Accuracy Improvement Based on an Optimal Kalman Filter,"In this paper, an approach to improve the accuracy of microelectromechanical systems (MEMS) gyroscopes by combining numerous uncorrelated gyroscopes is presented. A Kalman filter (KF) is used to fuse the output signals of several uncorrelated sensors. The relationship between the KF bandwidth and the angular rate input is quantitatively analyzed. A linear model is developed to choose suitable system parameters for a dynamic application of the concept. Simulation and experimental tests of a six-gyroscope array proved that the presented approach was effective to improve the MEMS gyroscope accuracy. The experimental results indicate that six identical gyroscopes with a noise density of 0.11°/s/√Hz and a bias instability of 62°/h can be combined to form a virtual gyroscope with a noise density of 0.03°/s/√Hz and a bias instability of 16.8°/h . The accuracy improvement is better than that of a simple averaging process of the individual sensors.",
Imaging feedback of histotripsy treatments using ultrasound shear wave elastography,"Histotripsy is a cavitation-based ultrasound therapy that mechanically fractionates soft solid tissues into fluid-like homogenates. This paper investigates the feasibility of imaging the tissue elasticity change during the histotripsy process as a tool to provide feedback for the treatments. The treatments were performed on agar tissue phantoms and ex vivo kidneys using 3-cycle ultrasound pulses delivered by a 750-kHz therapeutic array at peak negative/positive pressure of 17/108 MPa and a repetition rate of 50 Hz. Lesions with different degrees of damage were created with increasing numbers of therapy pulses from 0 to 2000 pulses per treatment location. The elasticity of the lesions was measured with ultrasound shear wave elastography, in which a quasi-planar shear wave was induced by acoustic radiation force generated by the therapeutic array, and tracked with ultrasound imaging at 3000 frames per second. Based on the shear wave velocity calculated from the sequentially captured frames, the Young's modulus was reconstructed. Results showed that the lesions were more easily identified on the shear wave velocity images than on B-mode images. As the number of therapy pulses increased from 0 to 2000 pulses/location, the Young's modulus decreased exponentially from 22.1 ± 2.7 to 2.1 ± 1.1 kPa in the tissue phantoms (R2 = 0.99, N = 9 each), and from 33.0 ± 7.1 to 4.0 ± 2.5 kPa in the ex vivo kidneys (R2 = 0.99, N = 8 each). Correspondingly, the tissues transformed from completely intact to completely fractionated as examined via histology. A good correlation existed between the lesions' Young's modulus and the degree of tissue fractionation as examined with the percentage of remaining structurally intact cell nuclei (R2 = 0.91, N = 8 each). These results indicate that lesions produced by histotripsy can be detected with high sensitivity using shear wave elastography. Because the decrease in the tissue elasticity corresponded well with the morphological and histological change, this study provides a basis for predicting the local treatment outcomes from tissue elasticity change.",
Efficient Clustering Aggregation Based on Data Fragments,"Clustering aggregation, known as clustering ensembles, has emerged as a powerful technique for combining different clustering results to obtain a single better clustering. Existing clustering aggregation algorithms are applied directly to data points, in what is referred to as the point-based approach. The algorithms are inefficient if the number of data points is large. We define an efficient approach for clustering aggregation based on data fragments. In this fragment-based approach, a data fragment is any subset of the data that is not split by any of the clustering results. To establish the theoretical bases of the proposed approach, we prove that clustering aggregation can be performed directly on data fragments under two widely used goodness measures for clustering aggregation taken from the literature. Three new clustering aggregation algorithms are described. The experimental results obtained using several public data sets show that the new algorithms have lower computational complexity than three well-known existing point-based clustering aggregation algorithms (Agglomerative, Furthest, and LocalSearch); nevertheless, the new algorithms do not sacrifice the accuracy.","Clustering algorithms,
Partitioning algorithms,
Computational complexity,
Mutual information,
Correlation,
Dispersion"
FTrack: Infrastructure-free floor localization via mobile phone sensing,"Mobile phone localization plays a key role in the fast-growing Location Based Applications domain. Most of the existing localization schemes rely on infrastructure support such as GSM, WiFi or GPS. In this paper, we present FTrack, a novel floor localization system to identify the floor level in a multi-floor building on which a mobile user is located. FTrack uses the mobile phone's accelerometer only without any infrastructure support. It does not require any prior knowledge of the building such as floor height. By capturing user encounters and analyzing user trails, FTrack finds the mapping from the traveling time (when taking the elevator) or the step counts (when walking on the stairs) between any two floors to the number of floor levels. The mapping can then be used for mobile users to pinpoint their current floor levels. We conduct both simulation and field studies to demonstrate the effectiveness of FTrack. Our field trial in a 10-floor building shows that FTrack achieves an accuracy of over 90% after two hours in our experiment.","Elevators,
Mobile communication,
Legged locomotion,
Acceleration,
Merging,
Servers"
Shadow Removal Using Bilateral Filtering,"In this paper, we propose a simple but effective shadow removal method using a single input image. We first derive a 2-D intrinsic image from a single RGB camera image based solely on colors, particularly chromaticity. We next present a method to recover a 3-D intrinsic image based on bilateral filtering and the 2-D intrinsic image. The luminance contrast in regions with similar surface reflectance due to geometry and illumination variances is effectively reduced in the derived 3-D intrinsic image, while the contrast in regions with different surface reflectance is preserved. However, the intrinsic image contains incorrect luminance values. To obtain the correct luminance, we decompose the input RGB image and the intrinsic image. Each image is decomposed into a base layer and a detail layer. We obtain a shadow-free image by combining the base layer from the input RGB image and the detail layer from the intrinsic image such that the details of the intrinsic image are transferred to the input RGB image from which the correct luminance values can be obtained. Unlike previous methods, the presented technique is fully automatic and does not require shadow detection.",
Sure-fast bilateral filters,"Edge-preserving smoothing is widely used in image processing and bilateral filtering is one way to achieve it. Bilateral filter is a nonlinear combination of domain and range filters. Implementing the classical bilateral filter is computationally intensive, owing to the nonlinearity of the range filter. In the standard form, the domain and range filters are Gaussian functions and the performance depends on the choice of the filter parameters. Recently, a constant time implementation of the bilateral filter has been proposed based on raised-cosine approximation to the Gaussian to facilitate fast implementation of the bilateral filter. We address the problem of determining the optimal parameters for raised-cosine-based constant time implementation of the bilateral filter. To determine the optimal parameters, we propose the use of Stein's unbiased risk estimator (SURE). The fast bilateral filter accelerates the search for optimal parameters by faster optimization of the SURE cost. Experimental results show that the SURE-optimal raised-cosine-based bilateral filter has nearly the same performance as the SURE-optimal standard Gaussian bilateral filter and the Oracle mean squared error (MSE)-based optimal bilateral filter.","Kernel,
PSNR,
Noise measurement,
Standards,
Approximation methods,
Computer vision,
Maximum likelihood detection"
Fast visual road recognition and horizon detection using multiple artificial neural networks,"The development of autonomous vehicles is a highly relevant research topic in mobile robotics. Road recognition using visual information is an important capability for autonomous navigation in urban environments. Over the last three decades, a large number of visual road recognition approaches have been appeared in the literature. This paper proposes a novel visual road detection system based on multiple artificial neural networks that can identify the road based on color and texture. Several features are used as inputs of the artificial neural network such as: average, entropy, energy and variance from different color channels (RGB, HSV, YUV). As a result, our system is able to estimate the classification and the confidence factor of each part of the environment detected by the camera. Experimental tests have been performed in several situations in order to validate the proposed approach.","Roads,
Artificial neural networks,
Databases,
Training,
Entropy,
Visualization,
Image color analysis"
Online Parameter Optimization-Based Prediction for Converter Gas System by Parallel Strategies,"Linz Donawitz converter gas (LDG) is one of the most important sources of fuel energy in steel industry, whose reasonable use plays a crucial role in energy saving and environment protection. In practice, online prediction of variation of gas holder level and gas demand by users is fundamental to gas utilization and scheduling activities. In this study, a least square support vector machine-based prediction model combined with the parallel strategies is proposed, in which parameter optimization is realized online by a parallel particle swarm optimization and a parallelized validation method, both being implemented with the use of a graphic processing unit. The experiments demonstrate that the online parameter optimization based model greatly improves the prediction quality compared to the version with the fixed modeling parameters. Furthermore, the parallelized strategies largely reduce the computational cost thus guaranteeing the real-time effectiveness of the practical application.","Production,
Converters,
Computational modeling,
Optimization,
Graphics processing unit,
Predictive models,
Support vector machines"
Extensions of learning-based model predictive control for real-time application to a quadrotor helicopter,"A new technique called learning-based model predictive control (LBMPC) rigorously combines statistics and learning with control engineering, while providing levels of guarantees about safety, robustness, and convergence. This paper describes modifications of LBMPC that enable its realtime implementation on an ultra-low-voltage processor that is onboard a quadrotor helicopter testbed, and it also discusses the numerical algorithms used to implement the control scheme on the quadrotor. Experimental results are provided that demonstrate the improvement to dynamic response that the learning in LBMPC provides, as well as the robustness of LBMPC to mis-learning.","Robustness,
Optimization,
Approximation methods,
Predictive control,
Noise,
Helicopters,
Safety"
"Reversing the Trend of Engineering Enrollment Declines With Innovative Outreach, Recruiting, and Retention Programs","This paper discusses an all-encompassing approach to increase the number of students in engineering through innovative outreach, recruiting, and retention programs. Prior to adopting these programs, the School of Electrical and Computer Engineering (ECE) at the University of Oklahoma (OU), Norman, experienced a reduction in engineering enrollment similar to the trend that has occurred across the U.S. over the last few years. As a result, the school investigated the key factors that influence selection of engineering as a career path and initiated a corrective program to reverse this trend. The program involves focusing on the present through retention, on the immediate future through recruiting, and on the distant future through outreach. The focus of all of these programs is to mobilize the OU-ECE faculty and student body to present advanced engineering technologies, innovative demonstrations, and hands-on activities at a level that the individual student can understand and appreciate. Student surveys and interviews are used to assess the program qualitatively, and OU-ECE enrollment numbers are used as a quantitative assessment.","Educational institutions,
Robots,
Organizations,
Engineering profession,
Computer bugs,
Electrical engineering"
Constructions of Quadratic and Cubic Rotation Symmetric Bent Functions,"In this paper, we consider constructions of rotation symmetric bent functions, which are of the forms: fc(x) = Σi=1m-1 ci(Σj=0n-1 xjxi+j) + cm(Σj=0m-1 xjxm+j) and ft(x) = Σi=0n-1 (xixt+ixm+i + xixt+i) + Σi=0m-1 xixm+i, where n = 2m, ci ϵ {0,1} (the subscript u of xu in the previous expressions is taken as u modulo n). For each case, a necessary and sufficient condition is obtained. To the best of our knowledge, this class of cubic rotation symmetric bent functions is the first example of an infinite class of nonquadratic rotation symmetric bent functions.","Boolean functions,
Cryptography,
Vectors,
Computer science,
Hamming weight,
Polynomials"
Ultrathin-Body High-Mobility InAsSb-on-Insulator Field-Effect Transistors,"Ultrathin-body InAsSb-on-insulator n-type field-effect transistors (FETs) with ultrahigh electron mobilities are reported. The devices are obtained by the layer transfer of ultrathin InAs0.7Sb0.3 layers (thickness of 7-17 nm) onto Si/SiO2 substrates. InAsSb-on-insulator FETs exhibit an effective mobility of ~ 3400 cm2/V·s for a body thickness of 7 nm, which represents ~ 2× enhancement over InAs devices of similar thickness. The top-gated FETs deliver an intrinsic transconductance of ~ 0.56 mS/μm (gate length of ~ 500 nm) at VDS = 0.5 V with ION/IOFF of 102-103. These results demonstrate the utility of the transfer process for obtaining high-mobility n-FETs on Si substrates by using mixed anion arsenide-antimonide as the active channel material.","FETs,
Silicon,
Logic gates,
Substrates,
Educational institutions"
"Summarizing Rushes Videos by Motion, Object, and Event Understanding","Rushes footages are considered as cheap gold mine with the potential for reuse in broadcasting and filmmaking industries. However, mining “gold” from unedited videos such as rushes is challenging as the reusable segments are buried in a large set of redundant information. In this paper, we propose a unified framework for stock footage classification and summarization to support video editors in navigating and organizing rushes videos. Our approach is composed of two steps. First, we employ motion features to filter the undesired camera motion and locate the stock footage. A hierarchical hidden Markov model (HHMM) is proposed to model the motion feature distribution and classify video segments into different categories to decide their potential for reuse. Second, we generate a short video summary to facilitate quick browsing of the stock footages by including the objects and events that are important for storytelling. For objects, we detect the presence of persons and moving objects. For events, we extract a set of features to detect and describe visual (motion activities and scene changes) and audio events (speech clips). A representability measure is then proposed to select the most representative video clips for video summarization. Our experiments show that the proposed HHMM significantly outperforms other methods based on SVM, FSM, and HMM. The automatically generated rushes summaries are also demonstrated to be easy-to-understand, containing little redundancy, and capable of including ground-truth objects and events with shorter durations and relatively pleasant rhythm based on the TRECVID 2007, 2008, and our subjective evaluations.","Videos,
Cameras,
Materials,
Hidden Markov models,
Feature extraction,
Motion pictures,
Redundancy"
Resource prediction based on double exponential smoothing in cloud computing,"With the development of cloud computing, customers are more and more concerned with cost on the resources which are not free in the cloud. Cloud resource providers can offer users two payment plans, i.e., reservation and on-demand plans for resource provision. In general, cost on resources gained by reservation plan is cheaper than on-demand plan. So the accuracy of resource prediction is of importance. In this paper, we present a resource prediction model based on double exponential smoothing, which considers not only the current state of resources but also the history records. Experiments performed on CloudSim cloud simulator show that the proposed method has a better performance on prediction accuracy.","Smoothing methods,
Cloud computing,
Predictive models,
History,
Time series analysis,
Accuracy,
Computational modeling"
On managing quality of experience of multiple video streams in wireless networks,"Managing the Quality-of-Experience (QoE) of video streaming for wireless clients is becoming increasingly important due to the rapid growth of video traffic on wireless networks. The inherent variability of the wireless channel as well as the Variable Bit Rate (VBR) of the compressed video streams make QoE management a challenging problem. Prior work has studied this problem in the context of transmitting a single video stream. In this paper, we investigate multiplexing schemes to transmit multiple video streams from a base station to mobile clients that use number of playout stalls as a performance metric. In this context, we present an epoch-by-epoch framework to fairly allocate wireless transmission slots to streaming videos. In each epoch our scheme essentially reduces the vulnerability to stalling by allocating slots to videos in a way that maximizes the minimum `playout lead' across all videos. Next, we show that the problem of allocating slots fairly is NP-complete even for a constant number of videos. We then present a fast lead-aware greedy algorithm for the problem. Our choice of greedy algorithm is motivated by the fact that this algorithm is optimal when the channel quality of a user remains unchanged within an epoch (but different users may experience different channel quality). Moreover, our experimental results based on public MPEG-4 video traces and wireless channel traces that we collected from a WiMAX test-bed show that the lead-aware greedy approach performs a fair distribution of stalls across the clients when compared to other algorithms, while still maintaining similar or lower average number of stalls per client.","Streaming media,
Lead,
Greedy algorithms,
Wireless communication,
Multiplexing,
Servers,
Resource management"
Switched and Symmetric Pursuit/Evasion Games Using Online Model Predictive Control With Application to Autonomous Aircraft,"This paper describes a supervisory controller for pursuit and evasion of two fixed-wing autonomous aircraft. Novel contributions of the work include the real-time use of model-predictive control, specifically nonlinear model predictive tracking control, for predictions of the vehicle under control, as well as predictions for the adversarial aircraft. In addition to this inclusion, the evasive controller is a hybrid system, providing switching criteria to change modes to become a pursuer based on the current and future state of the vehicle under control, and that of the adversarial aircraft. Results of the controller for equally matched platforms in actual flight tests against a US Air Force trained F-15 test pilot are given. Extensive simulation analysis of the symmetric games is provided, including regressive analysis based on initial conditions of height advantage, and relative velocity vectors, and in particular the effect of allowing the evading aircraft to switch modes between “evader” and “pursuer” during the game.","Games,
Aircraft,
Vehicles,
Atmospheric modeling,
Predictive models,
Mathematical model,
Optimization"
Securing cloud computing environment against DDoS attacks,"Cloud computing is becoming one of the next IT industry buzz word. However, as cloud computing is still in its infancy, current adoption is associated with numerous challenges like security, performance, availability, etc. In cloud computing where infrastructure is shared by potentially millions of users, Distributed Denial of Service (DDoS) attacks have the potential to have much greater impact than against single tenanted architectures. This paper tested the efficiency of a cloud trace back model in dealing with DDoS attacks using back propagation neural network and finds that the model is useful in tackling Distributed Denial of Service attacks.","Computer crime,
Cloud computing,
Training,
IP networks,
Testing,
Simple object access protocol"
A 2.8GS/s 44.6mW time-interleaved ADC achieving 50.9dB SNDR and 3dB effective resolution bandwidth of 1.5GHz in 65nm CMOS,This paper presents a power- and area-efficient 24-way time-interleaved SAR ADC designed in 65nm CMOS. At 2.8GS/s sampling rate the ADC consumes 44.6mW of power from a 1.2V supply while achieving peak SNDR of 50.9dB and retaining SNDR higher than 48.2dB across the entire first Nyquist zone.,"Calibration,
Capacitors,
Clocks,
Timing,
Switches,
Very large scale integration,
Switching circuits"
Medusa: A Scalable MR Console Using USB,"Magnetic resonance imaging (MRI) pulse sequence consoles typically employ closed proprietary hardware, software, and interfaces, making difficult any adaptation for innovative experimental technology. Yet MRI systems research is trending to higher channel count receivers, transmitters, gradient/shims, and unique interfaces for interventional applications. Customized console designs are now feasible for researchers with modern electronic components, but high data rates, synchronization, scalability, and cost present important challenges. Implementing large multichannel MR systems with efficiency and flexibility requires a scalable modular architecture. With Medusa, we propose an open system architecture using the universal serial bus (USB) for scalability, combined with distributed processing and buffering to address the high data rates and strict synchronization required by multichannel MRI. Medusa uses a modular design concept based on digital synthesizer, receiver, and gradient blocks, in conjunction with fast programmable logic for sampling and synchronization. Medusa is a form of synthetic instrument, being reconfigurable for a variety of medical/scientific instrumentation needs. The Medusa distributed architecture, scalability, and data bandwidth limits are presented, and its flexibility is demonstrated in a variety of novel MRI applications.","Universal Serial Bus,
Radio frequency,
Hardware,
Magnetic resonance imaging,
Real time systems,
Synchronization,
Control systems"
Adaptive Gating for Multitarget Tracking With Gaussian Mixture Filters,"In this correspondence, we use a generalization of the Bayesian approach to the multitarget problem that goes under the name of cardinalized probability hypothesis density (CPHD) filter to jointly estimate a time varying number of targets and their locations from sets of noisy range measurements. While in the case of Gaussian linear models a closed-form solution for the CPHD recursion exists in the form of a Gaussian mixture (GM), the more general case of nonlinear systems suboptimal solutions becomes necessary. Due to the Gaussianity assumption in the the GM-CPHD filter, we propose to integrate the square-root cubature Kalman filter (S-CKF) into the GM-CPHD recursion. A novel weighted gating strategy, which exploits the GM implementation of the proposed S-CKF-GM-CPHD filter, is offered to lower the computational time by adaptively increasing the gate sizes in proportion to the likelihood of the single GM components. The results reveal that the proposed gating yields considerable savings in processing requirements compared to no gating, without any significant degradation in performance. In addition, although the run time improvement achieved with elliptical or adaptive gating is equivalent, the latter does not degrade the results.","Bayesian methods,
Vectors,
Mathematical model,
Kalman filters,
Target tracking,
Noise measurement,
Approximation methods"
Does Game Theory Work?,"Given the current level of international interest in game theory and its applications in AI and computer science, it seems worth pausing to consider whether game theory actually works. This article considers the evidence available in support of the two most common interpretations of game theory: the descriptive interpretation, which considers game theory as trying to predict actual behavior, and the normative interpretation, which considers game theory as providing advice on how to act optimally.","Game theory,
Artificial intelligence,
Behavioral science"
Night-Time EKG and HRV Monitoring With Bed Sheet Integrated Textile Electrodes,"A system for unobtrusive night-time electrocardiogram (EKG) and heart rate variability (HRV) monitoring as well as data analysis methods are presented, comparing bed sheet HR and HRV values with corresponding parameters obtained by a reference measurement. Our system uses eight embroidered textile electrodes attached laterally to a bed sheet for measuring bipolar contact EKG from multiple channels. The electrodes are arranged in a line so that at least two adjacent electrodes make sufficient skin contact. The focus of the signal processing development has been on selecting the best measurement channel for further analysis and minimizing the amount of incorrectly detected R-peaks. The test measurements were performed with four healthy men without previously known cardiac disorders and one who frequently had premature ventricular contractions (ectopic beats). For healthy test subjects, an average of 94.9% heartbeat detection coverage was achieved with the system during 29 measurement nights (in total 213.8 h of data). In most cases, the quality of the signal obtained from bed sheet electrodes is good enough for the computer-assisted cardiac arrhythmia detection. Applications for EKG derived RR-interval data include the calculation of HRV parameters that can be utilized in sleep quality analysis and other wellness-related topics as well as sleep apnoea detection.","Electrocardiography,
Electrodes,
Heart rate variability,
Noise,
Sleep apnea"
Intercloud Architecture for interoperability and integration,"This paper presents on-going research to develop the Intercloud Architecture Framework (ICAF) that addresses problems in multi-provider multi-domain heterogeneous cloud based infrastructure services and applications integration and interoperability. The paper refers to existing standards in Cloud Computing, in particular, recently published NIST Cloud Computing Reference Architecture (CCRA). The proposed ICAF defines four complementary components addressing Intercloud integration and interoperability: multilayer Cloud Services Model that combines commonly adopted cloud service models, such as IaaS, PaaS, SaaS, in one multilayer model with corresponding inter-layer interfaces; Intercloud Control and Management Plane that supports cloud based applications interaction; Intercloud Federation Framework, and Intercloud Operation Framework. The paper briefly describes the architectural framework for cloud based infrastructure services provisioned on-demand being developed in the framework of the GEYSERS project that is used as a basis for building multilayer cloud services integration framework that allows optimized provisioning of both computing, storage and networking resources. The proposed architecture is intended to provide an architectural model for developing Intercloud middleware and in this way will facilitate clouds interoperability and integration.","Cloud computing,
Computer architecture,
Interoperability,
NIST,
Computational modeling,
Conferences"
Extraction of Isothermal Condition and Thermal Network in UTBB SOI MOSFETs,"In this letter, we present a thermal network extraction methodology to characterize self-heating effect using two-port RF measurements. We show the technique of determining isothermal condition using only the self-heating (thermal) dominated range of the spectrum. We use a self-consistent self-heating extraction scheme using both the real and imaginary parts of drain port admittance parameters. Appropriate thermal network is investigated, and a large amount of temperature rise due to self-heating is confirmed for short channel silicon-on-insulator MOSFETs with ultrathin body and buried oxide.","Isothermal processes,
MOSFETs,
Temperature measurement,
Radio frequency,
Frequency measurement,
Logic gates"
Estimation of Mouse Organ Locations Through Registration of a Statistical Mouse Atlas With Micro-CT Images,"Micro-CT is widely used in preclinical studies of small animals. Due to the low soft-tissue contrast in typical studies, segmentation of soft tissue organs from noncontrast enhanced micro-CT images is a challenging problem. Here, we propose an atlas-based approach for estimating the major organs in mouse micro-CT images. A statistical atlas of major trunk organs was constructed based on 45 training subjects. The statistical shape model technique was used to include inter-subject anatomical variations. The shape correlations between different organs were described using a conditional Gaussian model. For registration, first the high-contrast organs in micro-CT images were registered by fitting the statistical shape model, while the low-contrast organs were subsequently estimated from the high-contrast organs using the conditional Gaussian model. The registration accuracy was validated based on 23 noncontrast-enhanced and 45 contrast-enhanced micro-CT images. Three different accuracy metrics (Dice coefficient, organ volume recovery coefficient, and surface distance) were used for evaluation. The Dice coefficients vary from 0.45 ±0.18 for the spleen to 0.90 ±0.02 for the lungs, the volume recovery coefficients vary from 0.96 ±0.10 for the liver to 1.30 ±0.75 for the spleen, the surface distances vary from 0.18 ±0.01 mm for the lungs to 0.72 ±0.42 mm for the spleen. The registration accuracy of the statistical atlas was compared with two publicly available single-subject mouse atlases, i.e., the MOBY phantom and the DIGIMOUSE atlas, and the results proved that the statistical atlas is more accurate than the single atlases. To evaluate the influence of the training subject size, different numbers of training subjects were used for atlas construction and registration. The results showed an improvement of the registration accuracy when more training subjects were used for the atlas construction. The statistical atlas-based registration was also compared with the thin-plate spline based deformable registration, commonly used in mouse atlas registration. The results revealed that the statistical atlas has the advantage of improving the estimation of low-contrast organs.","Shape,
Skin,
Mice,
Skeleton,
Image segmentation,
Lungs"
No-Reference Bitstream-Based Visual Quality Impairment Detection for High Definition H.264/AVC Encoded Video Sequences,"Ensuring and maintaining adequate Quality of Experience towards end-users are key objectives for video service providers, not only for increasing customer satisfaction but also as service differentiator. However, in the case of High Definition video streaming over IP-based networks, network impairments such as packet loss can severely degrade the perceived visual quality. Several standard organizations have established a minimum set of performance objectives which should be achieved for obtaining satisfactory quality. Therefore, video service providers should continuously monitor the network and the quality of the received video streams in order to detect visual degradations. Objective video quality metrics enable automatic measurement of perceived quality. Unfortunately, the most reliable metrics require access to both the original and the received video streams which makes them inappropriate for real-time monitoring. In this article, we present a novel no-reference bitstream-based visual quality impairment detector which enables real-time detection of visual degradations caused by network impairments. By only incorporating information extracted from the encoded bitstream, network impairments are classified as visible or invisible to the end-user. Our results show that impairment visibility can be classified with a high accuracy which enables real-time validation of the existing performance objectives.","Streaming media,
Video sequences,
Measurement,
Visualization,
Encoding,
Degradation,
Real time systems"
Cooperative multi sensor network for traffic safety applications at intersections,"To significantly reduce injury and fatal accidents smart intersections equipped with sensors and communication infrastructure have been proposed. In this publication a novel multi sensor network to perceive the intersection environment is presented. Based on an intensive analysis of accident scenarios in Germany the system was designed to address 75 % of all severe and lethal accidents. 14 laserscanners, 10 cameras, signal phase tapping and an I2V communication unit have been installed at a public intersection in Aschaffenburg, Germany. By using computer based field of view modelling the sensor positions are carefully selected to avoid occlusions. Thus, the infrastructure perception system provides a bird's eye view. Our experiments show that spatial and temporal alignment of sensor data is achieved. We also demonstrate that a part of the sensor network, a calibrated stereo system, allows 3D coordinates in the field of view region of the cameras to be determined with an accuracy of 30 mm.","Cameras,
Accidents,
Vehicles,
Lasers,
High definition video,
Roads,
Spatial resolution"
Long-Period Grating Inscribed on Concatenated Double-Clad and Single-Clad Fiber for Simultaneous Measurement of Temperature and Refractive Index,"In this letter, a kind of long-period fiber grating (LPFG) that is capable of simultaneous measurement of temperature and surrounding refractive index (RI) is fabricated and demonstrated. The compact LPFG is written on a piece of spliced standard single-mode fiber (SMF) and double-clad fiber (DCF) with the CO2 laser point-by-point irradiation technique. The LPFG section in the DCF is solely sensitive to temperature, while the section of the LPFG in the SMF is sensitive to both temperature and surrounding RI. After temperature and RI calibration, the LPFG has been used to measure the RI change of ethylene glycol with the change of temperature to demonstrate its capability for dual parameter simultaneous measurement.",
Sparse Color Interest Points for Image Retrieval and Object Categorization,"Interest point detection is an important research area in the field of image processing and computer vision. In particular, image retrieval and object categorization heavily rely on interest point detection from which local image descriptors are computed for image matching. In general, interest points are based on luminance, and color has been largely ignored. However, the use of color increases the distinctiveness of interest points. The use of color may therefore provide selective search reducing the total number of interest points used for image matching. This paper proposes color interest points for sparse image representation. To reduce the sensitivity to varying imaging conditions, light-invariant interest points are introduced. Color statistics based on occurrence probability lead to color boosted points, which are obtained through saliency-based feature selection. Furthermore, a principal component analysis-based scale selection method is proposed, which gives a robust scale estimation per interest point. From large-scale experiments, it is shown that the proposed color interest point detector has higher repeatability than a luminance-based one. Furthermore, in the context of image retrieval, a reduced and predictable number of color features show an increase in performance compared to state-of-the-art interest points. Finally, in the context of object recognition, for the Pascal VOC 2007 challenge, our method gives comparable performance to state-of-the-art methods using only a small fraction of the features, reducing the computing time considerably.",
Robustly Extracting Captions in Videos Based on Stroke-Like Edges and Spatio-Temporal Analysis,"This paper presents an effective and efficient approach to extracting captions from videos. The robustness of our system comes from two aspects of contributions. First, we propose a novel stroke-like edge detection method based on contours, which can effectively remove the interference of non-stroke edges in complex background so as to make the detection and localization of captions much more accurate. Second, our approach highlights the importance of temporal feature, i.e., inter-frame feature, in the task of caption extraction (detection, localization, segmentation). Instead of regarding each video frame as an independent image, through fully utilizing the temporal feature of video together with spatial analysis in the computation of caption localization, segmentation and post-processing, we demonstrate that the use of inter-frame information can effectively improve the accuracy of caption localization and caption segmentation. In the comprehensive our evaluation experiments, the experimental results on two representative datasets have shown the robustness and efficiency of our approach.","Image edge detection,
Videos,
Image segmentation,
Feature extraction,
Image color analysis,
Detectors,
Indexing"
Tensor Learning for Regression,"In this paper, we exploit the advantages of tensorial representations and propose several tensor learning models for regression. The model is based on the canonical/parallel-factor decomposition of tensors of multiple modes and allows the simultaneous projections of an input tensor to more than one direction along each mode. Two empirical risk functions are studied, namely, the square loss and ε-insensitive loss functions. The former leads to higher rank tensor ridge regression (TRR), and the latter leads to higher rank support tensor regression (STR), both formulated using the Frobenius norm for regularization. We also use the group-sparsity norm for regularization, favoring in that way the low rank decomposition of the tensorial weight. In that way, we achieve the automatic selection of the rank during the learning process and obtain the optimal-rank TRR and STR. Experiments conducted for the problems of head-pose, human-age, and 3-D body-pose estimations using real data from publicly available databases, verified not only the superiority of tensors over their vector counterparts but also the efficiency of the proposed algorithms.","Tensile stress,
Computer science,
Roads,
Electronic mail,
Matrix decomposition,
Visualization,
Materials"
Quasi-three-level converter for switched reluctance motor drives reducing current rising and falling times,"This study presents a new configuration of power converter for switched reluctance motor drives. The system allows reduction of the detrimental impact of the commutation processes in motor winding on overall motor performance through enabling reconfiguration of windings connection during operation of motor. Shorter time of commutation, which is the main characteristic of the system, increases the motor average torque particularly in range of operation with high rotational speed. Application of the system in a standard switched reluctance motor-based drive results in extension of range of operation with constant torque and mechanical power as much as two times. The electromechanical characteristics of motor driven from the system are compared with those of the same motor driven from a standard half-bridge converter.","reluctance motor drives,
commutation,
machine windings,
power convertors"
Adaptive Extended Pipelined Second-Order Volterra Filter for Nonlinear Active Noise Controller,"This correspondence presents an extended pipelined second-order Volterra (EPSOV) filter for active control of nonlinear noise processes. The corresponding nonlinear filtered-x algorithms using the filter bank implementation are also suggested. Compared to the standard SOV filter using the filtered-x least mean square (SOVFXLMS), those modules of the EPSOV filter can be performed simultaneously in a pipelined parallelism fashion, and this would lead to a significant improvement in its total computational efficiency. Results obtained from computer simulations for nonlinear noise processes demonstrate that the proposed method outperforms the SOV.","Filter banks,
Adaptive filters,
Filtering algorithms,
Nonlinear filters,
Maximum likelihood detection,
Filtering theory,
Finite impulse response filter"
Fiducial Optimization for Minimal Target Registration Error in Image-Guided Neurosurgery,"This paper presents new methods for the optimal selection of anatomical landmarks and optimal placement of fiducial markers in image-guided neurosurgery. These methods allow the surgeon to optimally plan fiducial marker locations on routine diagnostic images before preoperative imaging and to intraoperatively select the set of fiducial markers and anatomical landmarks that minimize the expected target registration error (TRE). The optimization relies on a novel empirical simulation-based TRE estimation method built on actual fiducial localization error (FLE) data. Our methods take the guesswork out of the registration process and can reduce localization error without additional imaging and hardware. Our clinical experiments on five patients who underwent brain surgery with a navigation system show that optimizing one marker location and the anatomical landmarks configuration reduced the TRE. The average TRE values using the usual fiducials setup and using the suggested method were 4.7 mm and 3.2 mm, respectively. We observed a maximum improvement of 4 mm. Reducing the target registration error has the potential to support safer and more accurate minimally invasive neurosurgical procedures.",
Product of Experts for Statistical Parametric Speech Synthesis,"Multiple acoustic models are often combined in statistical parametric speech synthesis. Both linear and non-linear functions of an observation sequence are used as features to be modeled. This paper shows that this combination of multiple acoustic models can be expressed as a product of experts (PoE); the likelihoods from the models are scaled, multiplied together, and then normalized. Normally these models are individually trained and only combined at the synthesis stage. This paper discusses a more consistent PoE framework where the models are jointly trained. A training algorithm for PoEs based on linear feature functions and Gaussian experts is derived by generalizing the training algorithm for trajectory HMMs. However for non-linear feature functions or non-Gaussian experts this is not possible, so a scheme based on contrastive divergence learning is described. Experimental results show that the PoE framework provides both a mathematically elegant way to train multiple acoustic models jointly and significant improvements in the quality of the synthesized speech.","Hidden Markov models,
Speech,
Speech synthesis,
Trajectory,
Adaptation models,
Acoustics"
Trajectory optimization for domains with contacts using inverse dynamics,"This paper presents an algorithm for direct trajectory optimization in domains with contact. Since contacts and other unilateral constraints may introduce non-smooth dynamics, many standard algorithms of optimal control and reinforcement learning cannot be directly applied to such domains. We use a smooth contact model that can compute inverse dynamics through the contact, thereby avoiding hybrid representation of the non-smooth contact state. This allows us to formulate an unconstrained, continuous trajectory optimization problem, which can be solved using standard optimization tools. We demonstrate our approach by optimizing a running gait for a 31-dimensional simulated humanoid. The resulting gait is demonstrated in a movie attached as supplementary material. The optimization result exhibits a synchronous motion of the arm and the opposite leg, eliminating undesired angular momentum; this is a key feature of bipedal running, and its emergence attests to the power of the optimization process.","Trajectory,
Optimization,
Dynamics,
Computational modeling,
Heuristic algorithms,
Optimal control,
Legged locomotion"
A Coordinate System for Gaussian Networks,"This paper investigates network information theory problems where the external noise is Gaussian distributed. In particular, the Gaussian broadcast channel with coherent fading and the Gaussian interference channel are considered. It is shown that in these problems, non-Gaussian code ensembles can achieve higher rates than the Gaussian ones. It is also shown that the strong Shamai-Laroia conjecture on the Gaussian ISI channel does not hold. In order to analyze non-Gaussian code ensembles over Gaussian networks, a geometrical tool using the Hermite polynomials is proposed. This tool provides a coordinate system to analyze a class of non-Gaussian input distributions that are invariant over Gaussian networks.",
Risk limiting dispatch of wind power,"Integrating wind and solar power into the grid requires dispatching various types of reserve generation to compensate for the randomness of renewable power. The dispatch is usually determined by a system operator (SO) or an aggregator who `firms' variable energy by bundling it with conventional power. The optimal dispatch is formulated as the solution to a stochastic control problem and shown to have a closed form that can be quickly computed. Different objectives and risk constraints can be included in the formulation and trade-offs can be evaluated. In particular one can quantify the influence of sequential forecasts on the total integration cost and the choice of dispatched generation. When the forecast error is Gaussian, the optimal dispatch policy can be precomputed.","Wind forecasting,
Real-time systems,
Wind power generation,
Standards,
Marketing and sales,
Contracts,
Limiting"
Radiometric Calibration of the Landsat MSS Sensor Series,"Multispectral remote sensing of the Earth using Landsat sensors was ushered on July 23, 1972, with the launch of Landsat-1. Following that success, four more Landsat satellites were launched, and each of these carried the Multispectral Scanner System (MSS). These five sensors provided the only consistent multispectral space-based imagery of the Earth's surface from 1972 to 1982. This work focuses on developing both a consistent and absolute radiometric calibration of this sensor system. Cross-calibration of the MSS was performed through the use of pseudoinvariant calibration sites (PICSs). Since these sites have been shown to be stable for long periods of time, changes in MSS observations of these sites were attributed to changes in the sensors themselves. In addition, simultaneous data collections were available for some MSS sensor pairs, and these were also used for cross-calibration. Results indicated substantial differences existed between instruments, up to 16%, and these were reduced to 5% or less across all MSS sensors and bands. Lastly, this paper takes the calibration through the final step and places the MSS sensors on an absolute radiometric scale. The methodology used to achieve this was based on simultaneous data collections by the Landsat-5 MSS and Thematic Mapper (TM) instruments. Through analysis of image data from a PICS location and through compensating for the spectral differences between the two instruments, the Landsat-5 MSS sensor was placed on an absolute radiometric scale based on the Landsat-5 TM sensor. Uncertainties associated with this calibration are considered to be less than 5%.","Earth,
Satellites,
Remote sensing,
Calibration,
Radiometry,
Instruments,
Detectors"
On Statistical Tests for Randomness Included in the NIST SP800-22 Test Suite and Based on the Binomial Distribution,"In this paper we review some statistical tests included in the NIST SP 800-22 suite, which is a collection of tests for the evaluation of both true-random (physical) and pseudorandom (algorithmic) number generators for cryptographic applications. The output of these tests is the so-called p-value which is a random variable whose distribution converges to the uniform distribution in the interval [0,1] when testing an increasing number of samples from an ideal generator. Here, we compute the exact non-asymptotic distribution of p-values produced by few of the tests in the suite, and propose some computation-friendly approximations. This allows us to explain why intensive testing produces false-positives with a probability much higher than the expected one when considering asymptotic distribution instead of the true one. We also propose a new approximation for the Spectral Test reference distribution, which is more coherent with experimental results.","Generators,
Testing,
NIST,
Reliability,
Approximation methods,
Security,
Forensics"
An Empirical Study on Using Visual Embellishments in Visualization,"In written and spoken communications, figures of speech (e.g., metaphors and synecdoche) are often used as an aid to help convey abstract or less tangible concepts. However, the benefits of using rhetorical illustrations or embellishments in visualization have so far been inconclusive. In this work, we report an empirical study to evaluate hypotheses that visual embellishments may aid memorization, visual search and concept comprehension. One major departure from related experiments in the literature is that we make use of a dual-task methodology in our experiment. This design offers an abstraction of typical situations where viewers do not have their full attention focused on visualization (e.g., in meetings and lectures). The secondary task introduces “divided attention”, and makes the effects of visual embellishments more observable. In addition, it also serves as additional masking in memory-based trials. The results of this study show that visual embellishments can help participants better remember the information depicted in visualization. On the other hand, visual embellishments can have a negative impact on the speed of visual search. The results show a complex pattern as to the benefits of visual embellishments in helping participants grasp key concepts from visualization.",
Price of Anarchy for Congestion Games in Cognitive Radio Networks,"In this paper, we consider a cognitive radio network where multiple heterogenous secondary users (SUs) compete for transmissions on idle primary channels. We model this as a singleton congestion game, where the probability for an SU to successfully access a channel decreases with the number of SUs selecting the same channel. In particular, we consider player-specific payoffs that depend not only on the shares of the channel but also on different preference constants. Such system can be modeled as a congestion game, and we study the price of anarchy (PoA) for four families of such a game: identical, player-specific symmetric, resource-specific symmetric, and asymmetric games. We characterize the worst-case PoA in terms of the number of SUs and channels, and illustrate the network scenarios under which the worse case performance is reached. We further illustrate the PoA results with two Medium Access Control (MAC) schemes: uniform MAC and slotted Aloha. For both cases, we observe that the average performance of the game equilibrium is better than the worst-case PoA. Our study sheds light on how to design stable systems with smaller efficiency loss of the equilibrium.",
Axis: Automatically fixing atomicity violations through solving control constraints,"Atomicity, a general correctness criterion in concurrency programs, is often violated in real-world applications. The violations are difficult for developers to fix, making automatic bug fixing techniques attractive. The state of the art approach aims at automating the manual fixing process but cannot provide any theoretical reasoning and guarantees. We provide an automatic approach that applies well-studied discrete control theory to guarantee deadlocks are not introduced and maximal preservation of the concurrency of the original code. Under the hood, we reduce the problem of violation fixing to a constraint solving problem using the Petri net model. Our evaluation on 13 subjects shows that the slowdown incurred by our patches is only 40% of that of the state of the art. With the deadlock-free guarantee, our patches incur moderate overhead (around 10%), which is a worthwhile cost for safety.","Equations,
System recovery,
Mathematical model,
Vectors,
Computer bugs,
Concurrent computing,
Cognition"
N-Grams and the Last-Good-Reply Policy Applied in General Game Playing,"The aim of general game playing (GGP) is to create programs capable of playing a wide range of different games at an expert level, given only the rules of the game. The most successful GGP programs currently employ simulation-based Monte Carlo tree search (MCTS). The performance of MCTS depends heavily on the simulation strategy used. In this paper, we introduce improved simulation strategies for GGP that we implement and test in the GGP agent CADIAPLAYER, which won the International GGP competition in both 2007 and 2008. There are two aspects to the improvements: first, we show that a simple ϵ-greedy exploration strategy works better in the simulation play-outs than the softmax-based Gibbs measure currently used in CADIAPLAYER and, second, we introduce a general framework based on N-grams for learning promising move sequences. Collectively, these enhancements result in a much improved performance of CADIAPLAYER. For example, in our test suite consisting of five different two-player turn-based games, they led to an impressive average win rate of approximately 70%. The enhancements are also shown to be effective in multiplayer and simultaneous-move games. We additionally perform experiments with the last-good-reply policy (LGRP). The LGRP combined with N-grams is also tested. The LGRP has already been shown to be successful in Go programs and we demonstrate that it also has promise in GGP.","Games,
Law,
Monte Carlo methods,
Servers,
Learning systems,
Computational modeling"
Wide Band Gap Gallium Phosphide Solar Cells,"Gallium phosphide (GaP), with its wide band gap of 2.26 eV, is a good candidate for the top junction solar cell in a multijunction solar cell system. Here, we design, fabricate, characterize, and analyze GaP solar cells. Liquid phase epitaxy is used to grow the semiconductor layers. Four generations of GaP solar cells are developed and fabricated with each solar cell structure being designed and improved based on the first principles analyses of the predecessor solar cells. Quantum efficiency and current-voltage measurements are used to analyze the solar cell performance and to develop predictive models. We create a GaP solar cell with an efficiency of 2.42% under AM 1.5G one sun illumination.","Photovoltaic cells,
Space charge,
Junctions,
Epitaxial layers,
Photonic band gap,
Sun"
Technology assessment of Si and III-V FinFETs and III-V tunnel FETs from soft error rate perspective,"Sea-level soft error performance has been investigated for Si FinFET, III-V FinFET and III-V Heterojunction Tunnel FET in this paper. Transient error generation and transient current profiles in these devices have been evaluated using device simulation. Based on the critical charge extraction for each emerging device-based circuit, the electrical and latching window masking effects have been studied. Below 0.5V, III-V FinFET logic shows reduced soft error rate (SER) compared to Si FinFET. HTFET shows reduced SER for both SRAM and logic compared to Si and III-V FinFET over the evaluated voltage range of 0.3V-0.6V.","FinFETs,
Silicon,
SRAM cells,
Transient analysis,
Neutrons,
Latches"
Local binary pattern and its derivatives for face recognition,"Texture is the surface property that is used to identify and recognise objects. This property is widely used in many applications including texture-based face recognition systems, surveillance, identity verification and so on. The Local binary pattern (LBP) texture method is most successful for face recognition. Owing to the great success of LBP, recently many models, which are variants of LBP have been proposed for texture analysis. Some of the derivatives of LBPs are multivariate local binary pattern, centre symmetric local binary pattern, local binary pattern variance, dominant local binary pattern, advanced local binary pattern, local texture pattern (LTP) and local derivative pattern (LDP). In this scenario, it is essential to review, whether LBP or their derivatives perform better for face recognition. The real-time challenges such as illumination changes, rotations, angle variations and facial expression variations are evaluated by different LBP-based models. Experiments were conducted on the Japanese female facial expression, YALE and FRGC version2 databases. The results show that LDP and LTP perform much better than the other LBP-based models.","visual databases,
face recognition,
image texture"
Quaternion-Based Hybrid Feedback for Robust Global Attitude Synchronization,"We apply recent results on robust global asymptotic stabilization of the attitude of a single rigid body to the problem of globally synchronizing the attitude of a network of rigid bodies using a decentralized strategy. The proposed hybrid feedback scheme relies on the communication of a binary logic variable between each pair of neighboring rigid bodies that determines the orientation of a torque component acting to reduce their relative error. Through a hysteretic switch of this logic variable, the hybrid feedback achieves global synchronization under the assumption that the network is connected and acyclic. The hysteresis eliminates chattering while preventing the “unwinding phenomenon” apparent in some quaternion-based attitude control schemes. The results are exercised in a numerical example.",
Radial Basis Function Networks With Linear Interval Regression Weights for Symbolic Interval Data,"This paper introduces a new structure of radial basis function networks (RBFNs) that can successfully model symbolic interval-valued data. In the proposed structure, to handle symbolic interval data, the Gaussian functions required in the RBFNs are modified to consider interval distance measure, and the synaptic weights of the RBFNs are replaced by linear interval regression weights. In the linear interval regression weights, the lower and upper bounds of the interval-valued data as well as the center and range of the interval-valued data are considered. In addition, in the proposed approach, two stages of learning mechanisms are proposed. In stage 1, an initial structure (i.e., the number of hidden nodes and the adjustable parameters of radial basis functions) of the proposed structure is obtained by the interval competitive agglomeration clustering algorithm. In stage 2, a gradient-descent kind of learning algorithm is applied to fine-tune the parameters of the radial basis function and the coefficients of the linear interval regression weights. Various experiments are conducted, and the average behavior of the root mean square error and the square of the correlation coefficient in the framework of a Monte Carlo experiment are considered as the performance index. The results clearly show the effectiveness of the proposed structure.","Clustering algorithms,
Data models,
Upper bound,
Linear regression,
Radial basis function networks,
Partitioning algorithms,
Argon"
Image super-resolution via dual-dictionary learning and sparse representation,"Learning-based image super-resolution aims to reconstruct high-frequency (HF) details from the prior model trained by a set of high- and low-resolution image patches. In this paper, HF to be estimated is considered as a combination of two components: main high-frequency (MHF) and residual high-frequency (RHF), and we propose a novel image super-resolution method via dual-dictionary learning and sparse representation, which consists of the main dictionary learning and the residual dictionary learning, to recover MHF and RHF respectively. Extensive experimental results on test images validate that by employing the proposed two-layer progressive scheme, more image details can be recovered and much better results can be achieved than the state-of-the-art algorithms in terms of both PSNR and visual perception.","Dictionaries,
Image resolution,
Image reconstruction,
Interpolation,
Signal resolution,
Training,
PSNR"
Noninvasive Bed Sensing of Human Biosignals Via Piezoceramic Devices Sandwiched Between the Floor and Bed,"This paper describes a novel bed sensing method for noninvasive, constraint-free, subliminal detection of biosignals. The sensor system detects the heartbeat, respiration, body movement, position change, and scratching motion of a person lying or sleeping on the bed. These biosignals provide not only basic medical information but also sophisticated details about sleep conditions. Thus, the bed sensing method can be used to monitor the health condition of people sleeping at home, as well as that of patients in the hospital. Furthermore, the bed sensor system can detect emerging changes in the physical condition of a person, whether at home or in the hospital. The basic device used for sensing is piezoceramic bonded to stainless steel plate sandwiched between the floor and the four corners of the bed. Thus, no special bed is required. The device, which detects the biosignals generated as mechanical vibrations, has a wide dynamic range and high signal-to-noise (SN) ratio enabling the detection of microvibrations from the heartbeat by the change in acting force, without saturation from body movements. It accurately detects the person's heartbeat and respiration as well as body movement and even the number of scratching motions. The device is suitable for various health monitoring applications including sleep and medical monitoring for circulatory system disorders, as well as diseases characterized by itching.","Heart beat,
Foot,
Vibrations,
Steel,
Sensor systems,
Force"
The DeepTree Exhibit: Visualizing the Tree of Life to Facilitate Informal Learning,"In this paper, we present the DeepTree exhibit, a multi-user, multi-touch interactive visualization of the Tree of Life. We developed DeepTree to facilitate collaborative learning of evolutionary concepts. We will describe an iterative process in which a team of computer scientists, learning scientists, biologists, and museum curators worked together throughout design, development, and evaluation. We present the importance of designing the interactions and the visualization hand-in-hand in order to facilitate active learning. The outcome of this process is a fractal-based tree layout that reduces visual complexity while being able to capture all life on earth; a custom rendering and navigation engine that prioritizes visual appeal and smooth fly-through; and a multi-user interface that encourages collaborative exploration while offering guided discovery. We present an evaluation showing that the large dataset encouraged free exploration, triggers emotional responses, and facilitates visitor engagement and informal learning.","Collaboration,
Layout,
Navigation,
Phylogeny,
Rendering (computer graphics),
Data visualization,
Information science"
A constraint sufficient statistics based distributed particle filter for bearing only tracking,"A constrained sufficient statistic based distributed implementation of the particle filter (CSS/DPF) is proposed for angle/bearing-only tracking (BOT) applications. The CSS/DPF runs localized particle filters at each sensor node and computes the global sufficient statistics (GSS) of the overall system as a function (summation) of the local sufficient statistics (LSS). The CSS/DPF is, therefore, a two stage procedure: (i) First, the means of LSS at local nodes are computed by running average consensus algorithms to derive the GSS, and; (ii) Each node then updates its localized particle filter using the modified GSS. Simulation results show that the CSS/DPF is near-optimal with its performance almost identical to that of the centralized particle filter. The number of average consensus runs in the CSS/DPF are reduced by an order of magnitude of the dimension of the state vector, thereby, reducing the communication complexity and bandwidth requirement of the distributed implementation.","Cascading style sheets,
Vectors,
Noise,
Radar tracking,
Complexity theory,
Estimation,
Monte Carlo methods"
"An 80 GHz Wide Tuning Range Push-Push VCO With {\rm g} _{\rm m}
-Boosted Full-Wave Rectification Technique in 90 nm CMOS","In this letter, an 80 GHz push-push VCO with a gm-boosted full-wave rectification pair for W-band (75 to 110 GHz) applications is presented. Incorporating a gm-boosted push-push pair as a full-wave rectifier not only increases second-harmonic swing but also operates at low power consumption. Besides, the distributed LC-tank structure helps to further split the parasitic capacitances of buffers and then the push-push pair can extend the frequency tuning range effectively. The push-push VCO is implemented in 90 nm CMOS technology , and it achieves a tuning range of 3.4% and phase noise of -104.2 dBc/Hz at 10 MHz offset. The core area is 0.3 × 0.21 mm2, and the power consumption is 2.66 mW from a 1.4 V supply voltage excluding buffers.","Voltage-controlled oscillators,
Tuning,
Capacitance,
Frequency conversion,
CMOS integrated circuits,
CMOS technology"
Ballerina: Automatic generation and clustering of efficient random unit tests for multithreaded code,"Testing multithreaded code is hard and expensive. A multithreaded unit test creates two or more threads, each executing one or more methods on shared objects of the class under test. Such unit tests can be generated at random, but basic random generation produces tests that are either slow or do not trigger concurrency bugs. Worse, such tests have many false alarms, which require human effort to filter out. We present Ballerina, a novel technique for automated random generation of efficient multithreaded tests that effectively trigger concurrency bugs. Ballerina makes tests efficient by having only two threads, each executing a single, randomly selected method. Ballerina increases chances that such simple parallel code finds bugs by appending it to more complex, randomly generated sequential code. We also propose a clustering technique to reduce the manual effort in inspecting failures of automatically generated multithreaded tests. We evaluate Ballerina on 14 real-world bugs from six popular codebases: Groovy, JDK, JFreeChart, Apache Log4j, Apache Lucene, and Apache Pool. The experiments show that tests generated by Ballerina find bugs on average 2×-10× faster than basic random generation, and our clustering technique reduces the number of inspected failures on average 4×-8×. Using Ballerina, we found three previously unknown bugs, two of which were already confirmed and fixed.",
Optimal Step-Size Affine Projection Algorithm,"This letter describes how to set up the step size of the affine projection algorithm (APA) based on mean-square deviation analysis. The analysis considers the cross-correlation between the current weight error vector and the prior measurement noises associated with the reused inputs vectors for better prediction of the learning behavior of the APA. With the predetermined step size based on the analysis, the proposed approach eliminates the parameter-tuning process and the derived algorithm achieves both the fast convergence rate and the low steady-state error. Simulation results show that the proposed algorithm performs better than previous algorithms.",
Bits From Photons: Oversampled Image Acquisition Using Binary Poisson Statistics,"We study a new image sensor that is reminiscent of a traditional photographic film. Each pixel in the sensor has a binary response, giving only a 1-bit quantized measurement of the local light intensity. To analyze its performance, we formulate the oversampled binary sensing scheme as a parameter estimation problem based on quantized Poisson statistics. We show that, with a single-photon quantization threshold and large oversampling factors, the Cramér-Rao lower bound (CRLB) of the estimation variance approaches that of an ideal unquantized sensor, i.e., as if there were no quantization in the sensor measurements. Furthermore, the CRLB is shown to be asymptotically achievable by the maximum-likelihood estimator (MLE). By showing that the log-likelihood function of our problem is concave, we guarantee the global optimality of iterative algorithms in finding the MLE. Numerical results on both synthetic data and images taken by a prototype sensor verify our theoretical analysis and demonstrate the effectiveness of our image reconstruction algorithm. They also suggest the potential application of the oversampled binary sensing scheme in high dynamic range photography.","Photonics,
Quantization,
Image sensors,
Sensors,
Image reconstruction,
Maximum likelihood estimation"
Reduced-Complexity Iterative-Detection-Aided Generalized Space-Time Shift Keying,"A novel reduced-complexity soft decision (SoD)-aided detector is proposed for the recent concept of space-time shift keying (STSK), where the detector's achievable performance is capable of closely approaching that of the optimal maximum a posteriori (MAP) detector. More specifically, we exploit a hybrid combination of the modified matched filtering concept and of reduced-complexity exhaustive search for the sake of reducing the MAP detector's decoding complexity. Furthermore, we extended this detector to support the class of generalized STSK (GSTSK) scheme that subsumes diverse multiple-input-multiple-output (MIMO) arrangements. The proposed reduced-complexity SoD-aided GSTSK detector also attains significantly lower complexity than the MAP detector while imposing only marginal performance degradation, which is in the range of 1-2 dB. As an optional means of further reducing complexity, the Markov Chain Monte Carlo (MCMC) algorithm is invoked for the proposed GSTSK detector. Our EXtrinsic Information Transfer (EXIT) chart analysis reveals that the proposed STSK detector is capable of closely approaching the optimal performance, whereas the GSTSK detector advocated exhibits a modest performance gap with respect to the max-log MAP detector.","Detectors,
Complexity theory,
Decoding,
MIMO,
Dispersion,
Iterative decoding,
Receivers"
Applying reinforcement learning to small scale combat in the real-time strategy game StarCraft:Broodwar,"This paper presents an evaluation of the suitability of reinforcement learning (RL) algorithms to perform the task of micro-managing combat units in the commercial real-time strategy (RTS) game StarCraft:Broodwar (SC:BW). The applied techniques are variations of the common Q-learning and Sarsa algorithms, both simple one-step versions as well as more sophisticated versions that use eligibility traces to offset the problem of delayed reward. The aim is the design of an agent that is able to learn in an unsupervised manner in a complex environment, eventually taking over tasks that had previously been performed by non-adaptive, deterministic game AI. The preliminary results presented in this paper show the viability of the RL algorithms at learning the selected task. Depending on whether the focus lies on maximizing the reward or on the speed of learning, among the evaluated algorithms one-step Q-learning and Sarsa(λ) prove best at learning to manage combat units.","Games,
Learning systems,
Learning,
Planning,
Machine learning,
Machine learning algorithms"
A Function for Quality Evaluation of Retinal Vessel Segmentations,"Retinal blood vessel assessment plays an important role in the diagnosis of ophthalmic pathologies. The use of digital images for this purpose enables the application of a computerized approach and has fostered the development of multiple methods for automated vascular tree segmentation. Metrics based on contingency tables for binary classification have been widely used for evaluating the performance of these algorithms. Metrics from this family are based on the measurement of a success or failure rate in the detected pixels, obtained by means of pixel-to-pixel comparison between the automated segmentation and a manually-labeled reference image. Therefore, vessel pixels are not considered as a part of a vascular structure with specific features. This paper contributes a function for the evaluation of global quality in retinal vessel segmentations. This function is based on the characterization of vascular structures as connected segments with measurable area and length. Thus, its design is meant to be sensitive to anatomical vascularity features. Comparison of results between the proposed function and other general quality evaluation functions shows that this proposal renders a high matching degree with human quality perception. Therefore, it can be used to enhance quality evaluation in retinal vessel segmentations, supplementing the existing functions. On the other hand, from a general point of view, the applied concept of measuring descriptive properties may be used to design specialized functions aimed at segmentation quality evaluation in other complex structures.","Image segmentation,
Measurement,
Humans,
Manuals,
Retinal vessels,
Biomedical imaging,
Educational institutions"
Robot navigation with model predictive equilibrium point control,"An autonomous vehicle intended to carry passengers must be able to generate trajectories on-line that are safe, smooth and comfortable. Here, we propose a strategy for robot navigation in a structured, dynamic indoor environment, where the robot reasons about the near future and makes a locally optimal decision at each time step.","Robots,
Collision avoidance,
Trajectory,
Navigation,
Optimization,
Aerospace electronics,
Dynamics"
Aerial service robotics: The AIRobots perspective,"This paper presents the main vision and research activities of the ongoing European project AIRobots (Innovative Aerial Service Robot for Remote Inspection by Contact, www.airobots.eu). The goal of AIRobots is to develop a new generation of aerial service robots capable of supporting human beings in all those activities that require the ability to interact actively and safely with environments not constrained on ground but, indeed, airborne. Besides presenting the main ideas and the research activities within the three-year project, the paper shows the first technological outcomes obtained during the first year and a half of activity.","Vehicles,
Inspection,
Humans,
Service robots,
Robot sensing systems"
A Cloud-based Intrusion Detection Service framework,"Intrusion Detection System (IDS) have become increasingly popular over the past years as an important network security technology to detect cyber attacks in a wide variety of network communication. IDS monitors' network or host system activities by collecting network information, and analyze this information for malicious activities. Cloud computing, with the concept of Software as a Service (SaaS) presents an exciting benefit when it enables providers to rent their services to users in perform complex tasks over the Internet. In addition, Cloud based services reduce a cost in investing new infrastructure, training new personnel, or licensing new software. In this paper, we introduce a novel framework based on Cloud computing called Cloud-based Intrusion Detection Service (CBIDS). This model enables the identification of malicious activities from different points of network and overcome the deficiency of classical intrusion detection. CBIDS can be implemented to detect variety of attacks in private and public Clouds.",
Resonant MEMS Mass Sensors for Measurement of Microdroplet Evaporation,"Microelectromechanical systems (MEMS)-based resonant mass sensors have been extensively studied due to their high sensitivity and small size, making them very suitable for detecting micro- or nanosized particles, as well as monitoring microscaled physical processes. In a range of physical and biological applications, accurate estimation and precise control of the evaporation process of microdroplets are very important. However, due to the lack of appropriate measurement tools, the evaporation process of microdroplets has not been well characterized. Here, we introduce a self-oscillating MEMS mass sensor with a uniform mass sensitivity to directly measure the mass changes of evaporating microdroplets. The mass sensor has a unique spring structure to provide spatially uniform mass sensitivity. The sensor's velocity is fed back to the actuation signal to induce self-oscillation, enabling rapid determination of the resonant frequency. The evaporation rates of single microdroplets of dimethyl sulfoxide and water at various temperatures are obtained. With the measured evaporation rates and the simulated surface area of the microdroplet, the enthalpies of vaporization of both liquids are extracted and found to be in agreement with those in the literature. The method developed in this work can be a valuable tool to enhance our understanding of microscaled physical processes involving rapid mass change, such as evaporation, deposition, self-assembly, cryopreservation, and other biological applications.","Springs,
Sensitivity,
Resonant frequency,
Frequency measurement,
Sensor systems,
Micromechanical devices"
Automatic Segmentation of Episodes Containing Epileptic Clonic Seizures in Video Sequences,"Epilepsy is a neurological disorder characterized by sudden, often unexpected transitions from normal to pathological behavioral states called epileptic seizures. Some of these seizures are accompanied by uncontrolled, often rhythmic movements of body parts when seizure activity propagates to brain areas responsible for the initiation and control of movement. The dynamics of these transitions is, in general, unknown. As a consequence, individuals have to be monitored for long periods in order to obtain sufficient data for adequate diagnosis and to plan therapeutic strategy. Some people may require long-term care in special units to allow for timely intervention in case seizures get out of control. Our goal is to present a method by which a subset of motor seizures can be detected using only remote sensing devices (i.e., not in contact with the subject) such as video cameras. These major motor seizures (MMS) consist of clonic movements and are often precursors of generalized tonic-clonic (convulsive) seizures, sometimes leading to a condition known as status epilepticus, which is an acute life-threatening event. We propose an algorithm based on optical flow, extraction of global group transformation velocities, and band-pass temporal filtering to identify occurrence of clonic movements in video sequences. We show that for a validation set of 72 prerecorded epileptic seizures in 50 people, our method is highly sensitive and specific in detecting video segments containing MMS with clonic movements.",
Blind Detection with Unique Identification in Two-Way Relay Channel,"This paper considers the blind detection for a two-way relay system in which two source nodes exchange information via a relay node by amplify-and-forward relaying. An efficient transmission scheme is first proposed to achieve unique identifications of both the transmitted symbols and channel coefficients at a noise-free receiver using the M-ary phase shift keying modulation. Blind receivers based on the generalized likelihood ratio test are then derived for both the reciprocal and nonreciprocal channels with additive Gaussian noise. The least square error-based receiver is also studied for the case without prior knowledge of the noise power for detection. Moreover, constellation selection algorithms are proposed to achieve a uniform transmission bit rate for the ease of implementation. Finally, numerical results are provided to validate the proposed schemes.","Receivers,
Relays,
Noise,
Vectors,
Phase shift keying,
Silicon carbide,
Channel estimation"
On-Chip Octave-Spanning Supercontinuum in Nanostructured Silicon Waveguides Using Ultralow Pulse Energy,"We present an approach for generating an octave-spanning supercontinuum on a silicon chip using input pulse energy as low as 6.8 pJ. This is enabled by advanced dispersion engineering with a nanoscale slot structure. We analyze the performance of the supercontinuum generation in terms of bandwidth, spectral coherence, and flatness, under different operating conditions. We show that, accompanying with the spectral broadening, the input pulse is compressed to 12 fs, which opens an opportunity for on-chip few-cycle pulse generation.",
Adaptive rate compressive sensing for background subtraction,"We study the problem of adaptive compressive sensing (CS) of a time-varying signal with slowly changing sparsity and rapidly varying support. We are specifically interested in visual surveillance applications such as background subtraction and tracking. Classical CS theory assumes prior knowledge of signal sparsity in order to determine the number of sensor measurements needed to ensure adequate signal reconstruction. However, when dealing with time-varying signals such as video, prior information regarding the exact sparsity may be difficult to obtain. Assuming a sensor that is able to take an adaptive number of compressive measurements, we present an algorithm based on cross validation that quantitatively evaluates the current measurement rate and adjusts it as needed.","Compressed sensing,
Sensors,
Image reconstruction,
Image coding,
Cameras,
Standards,
Time measurement"
Adaptive Online Performance Evaluation of Video Trackers,"We propose an adaptive framework to estimate the quality of video tracking algorithms without ground-truth data. The framework is divided into two main stages, namely, the estimation of the tracker condition to identify temporal segments during which a target is lost and the measurement of the quality of the estimated track when the tracker is successful. A key novelty of the proposed framework is the capability of evaluating video trackers with multiple failures and recoveries over long sequences. Successful tracking is identified by analyzing the uncertainty of the tracker, whereas track recovery from errors is determined based on the time-reversibility constraint. The proposed approach is demonstrated on a particle filter tracker over a heterogeneous data set. Experimental results show the effectiveness and robustness of the proposed framework that improves state-of-the-art approaches in the presence of tracking challenges such as occlusions, illumination changes, and clutter and on sequences containing multiple tracking errors and recoveries.",
Audio-based human activity recognition using Non-Markovian Ensemble Voting,"Human activity recognition is a key component for socially enabled robots to effectively and naturally interact with humans. In this paper we exploit the fact that many human activities produce characteristic sounds from which a robot can infer the corresponding actions. We propose a novel recognition approach called Non-Markovian Ensemble Voting (NEV) able to classify multiple human activities in an online fashion without the need for silence detection or audio stream segmentation. Moreover, the method can deal with activities that are extended over undefined periods in time. In a series of experiments in real reverberant environments, we are able to robustly recognize 22 different sounds that correspond to a number of human activities in a bathroom and kitchen context. Our method outperforms several established classification techniques.",
Connecting Meeting Behavior with Extraversion&#x2014;A Systematic Study,"This work investigates the suitability of medium-grained meeting behaviors, namely, speaking time and social attention, for automatic classification of the Extraversion personality trait. Experimental results confirm that these behaviors are indeed effective for the automatic detection of Extraversion. The main findings of our study are that: 1) Speaking time and (some forms of) social gaze are effective indicators of Extraversion, 2) classification accuracy is affected by the amount of time for which meeting behavior is observed, 3) independently considering only the attention received by the target from peers is insufficient, and 4) distribution of social attention of peers plays a crucial role.","Feature extraction,
Speech recognition,
Ethics,
Context awareness,
Computer vision,
Psychology,
Man machine systems,
Human factors,
Information processing"
Digitally Implemented Average Current-Mode Control in Discontinuous Conduction Mode PFC Rectifier,"This paper proposes a digital average current-mode control method in discontinuous conduction mode (DCM) power factor correction rectifier. The proposed control technique does not estimate, but directly senses the average value of the inductor current in each switching cycle. It is implemented by means of a conventional current sensing circuit and a microcontroller. The calculation burden of the microcontroller is the same with that of conventional two-loop-controlled converter because the additional calculation process is not required. The control method achieves lower total harmonic distortion and higher power factor than the conventional technique. Experimental results with a 200-W prototype verify the feasibility and performance of the proposed control method.",
Super-Resolution Without Dense Flow,"Super-resolution is a widely applied technique that improves the resolution of input images by software methods. Most conventional reconstruction-based super-resolution algorithms assume accurate dense optical flow fields between the input frames, and their performance degrades rapidly when the motion estimation result is not accurate enough. However, optical flow estimation is usually difficult, particularly when complicated motion is presented in real-world videos. In this paper, we explore a new way to solve this problem by using sparse feature point correspondences between the input images. The feature point correspondences, which are obtained by matching a set of feature points, are usually precise and much more robust than dense optical flow fields. This is because the feature points represent well-selected significant locations in the image, and performing matching on the feature point set is usually very accurate. In order to utilize the sparse correspondences in conventional super-resolution, we extract an adaptive support region with a reliable local flow field from each corresponding feature point pair. The normalized prior is also proposed to increase the visual consistency of the reconstructed result. Extensive experiments on real data were carried out, and results show that the proposed algorithm produces high-resolution images with better quality, particularly in the presence of large-scale or complicated motion fields.",
Optimal surface deployment problem in wireless sensor networks,"Sensor deployment is a fundamental issue in a wireless sensor network, which often dictates the overall network performance. Previous studies on sensor deployment mainly focused on sensor networks on 2D plane or in 3D volume. In this paper, we tackle the problem of optimal sensor deployment on 3D surfaces, aiming to achieve the highest overall sensing quality. In general, the reading of a sensor node exhibits unreliability, which often depends on the distance between the sensor and the target to be sensed, as observed in a wide range of applications. Therefore, with a given set of sensors, a sensor network offers different accuracy in data acquisition when the sensors are deployed in different ways in the Field of Interest (FoI). We formulate this optimal surface deployment problem in terms of sensing quality by introducing a general function to measure the unreliability of monitored data in the entire sensor network. We present its optimal solution and propose a series of algorithms for practical implementation. Extensive simulations are conducted on various 3D mountain surface models to demonstrate the effectiveness of the proposed algorithms.","Three dimensional displays,
Sensors,
Measurement,
Surface topography,
Partitioning algorithms,
Shape,
Wireless sensor networks"
Investigating multi-touch gestures as a novel biometric modality,"We propose a new behavioral biometric modality based on multi-touch gestures. We define a canonical set of multi-touch gestures based on the movement characteristics of the palm and fingertips being used to perform the gesture. We developed an algorithm to generate and verify multi-touch gesture templates. We tested our techniques on a set of 22 different gestures. Employing a matching algorithm for a multi-touch verification system with a k-NN classifier we achieved 1.28% Equal Error Rate (EER). With score-based classifiers where only the first five samples of a genuine subject were considered as templates, we achieved 4.46 % EER. Further, with the combination of three commonly used gestures: pinch, zoom, and rotate, using all five fingers, 1.58% EER was achieved using a score-based classifier. These results are encouraging and point to the possibility of touch based biometric systems in real world applications like user verification and active authentication.","Thumb,
Training,
Cost function,
Biometrics (access control),
Mice,
Physiology,
Euclidean distance"
The Complete Proof Theory of Hybrid Systems,"Hybrid systems are a fusion of continuous dynamical systems and discrete dynamical systems. They freely combine dynamical features from both worlds. For that reason, it has often been claimed that hybrid systems are more challenging than continuous dynamical systems and than discrete systems. We now show that, proof-theoretically, this is not the case. We present a complete proof-theoretical alignment that interreduces the discrete dynamics and the continuous dynamics of hybrid systems. We give a sound and complete axiomatization of hybrid systems relative to continuous dynamical systems and a sound and complete axiomatization of hybrid systems relative to discrete dynamical systems. Thanks to our axiomatization, proving properties of hybrid systems is exactly the same as proving properties of continuous dynamical systems and again, exactly the same as proving properties of discrete dynamical systems. This fundamental cornerstone sheds light on the nature of hybridness and enables flexible and provably perfect combinations of discrete reasoning with continuous reasoning that lift to all aspects of hybrid systems and their fragments.","Approximation methods,
Differential equations,
Cognition,
Polynomials,
Computer science,
Vectors"
A survey on routing protocols in Wireless Sensor Networks,"This paper presents a survey of state-of-the-art routing techniques in Wireless Sensor Networks (WSNs). Compared with traditional wireless networks, WSNs are characterized with denser levels of node deployment, higher unreliability of sensor nodes and severe power, computation and memory constraints. Various design challenges such as energy efficiency, data delivery models, quality of service, overheads etc., for routing protocols in WSNs are highlighted. We addressed most of the proposed routing methods along with scheme designs, benefits and result analysis wherever possible. The routing protocols discussed are classified into seven categories such as Data centric routing, Hierarchical routing, Location based routing, Negotiation based routing, Multipath based routing, Quality of Service (QoS) routing and Mobility based routing. This paper also compares the routing protocols against parameters such as power consumption, scalability, mobility, optimal routing and data aggregation. The paper concludes with possible open research issues in WSNs.","Routing,
Wireless sensor networks,
Routing protocols,
Quality of service,
Energy consumption,
Mobile communication"
Nanoparticle-Based Metamaterials as Multiband Plasmonic Resonator Antennas,"Plasmonic metamaterials based on metal-dielectric nanostructures exhibit unique optical properties such as high near-field enhancement, negative refractive indexing, and optical cloaking. In this paper, we present a plasmonic multiband metamaterial based on UT shaped nanoparticles. In order to understand the multispectral response, we analyze the near-field distributions at the corresponding resonance frequencies. In addition, we both numerically and experimentally, show the dependence of the spectral response on the geometrical parameters of the structure. By embedding the system in a dielectric cladding medium, we show strong sensitivities of the resonant behavior to the refractive index and thickness of the dielectric load. Due to its tunable multiband spectral characteristics, the proposed metamaterial antenna can be used for wide range of applications, such as wavelength-tunable active filters, optical modulators, ultrafast switching devices, and biosensing.",
Analysis and Improvement of a Secure and Efficient Handover Authentication for Wireless Networks,"A handover authentication protocol in mobile networks enables mobile nodes to securely and seamlessly roam over multiple access points. Many such protocols have been proposed but shown to be either insecure or inefficient. Very recently, a novel handover authentication protocol named PairHand was proposed, which has been shown to outperform all other protocols in terms of security and efficiency. However, we identify an inherent design weakness in the handover authentication phase of PairHand, and demonstrate that under certain circumstances it is vulnerable to a session key compromised problem. Further, we propose a simple modification to fix the identified security problem without losing any features (such as high efficiency and robust security) of PairHand. Experiments using our implementation on Laptop PCs show that the suggested modification is applicable in real world applications.",
Verification of automotive control applications using S-TaLiRo,"S-TALIRO is a software toolbox that performs stochastic search for system trajectories that falsify realtime temporal logic specifications. S-TaLiRo is founded on the notion of robustness of temporal logic specifications. In this paper, we present a dynamic programming algorithm for computing the robustness of temporal logic specifications with respect to system trajectories. We also demonstrate that typical automotive functional requirements can be captured and falsified using temporal logics and S-TALIRO.","Robustness,
Heuristic algorithms,
Trajectory,
Gears,
Measurement,
Optimization,
Dynamic programming"
Tolerating process variations in nanophotonic on-chip networks,"Nanophontonic networks, a potential candidate for future networks on-chip, have been challenged for their reliability due to several device-level limitations. One of the main issues is that fabrication errors (a.k.a. process variations) can cause devices to malfunction, rendering communication unreliable. For example, microring resonator, a preferred optical modulator device, may not resonate at the designated wavelength under process variations (PV), leading to communication errors and bandwidth loss. This paper proposes a series of solutions to the wavelength drifting problem of microrings and subsequent bandwidth loss problem of an optical network, due to PV. The objective is to maximize network bandwidth through proper arrangement among microrings and wavelengths with minimum power requirement. Our arrangement, called “MinTrim”, solves this problem using simple integer linear programming, adding supplementary microrings and allowing flexible assignment of wavelengths to network nodes as long as the resulting network presents maximal bandwidth. Each step is shown to improve bandwidth provisioning with lower power requirement. Evaluations on a sample network show that a baseline network could lose more than 40% bandwidth due to PV. Such loss can be recovered by MinTrim to produce a network with 98.4% working bandwidth. In addition, the power required in arranging microrings is 39% lower than the baseline. Therefore, MinTrim provides an efficient PV-tolerant solution to improving the reliability of on-chip phontonics.","Bandwidth,
Heating,
System-on-a-chip,
Optical waveguides,
Modulation,
Optical device fabrication"
Binary particle swarm optimisation for feature selection: A filter based approach,"Based on binary particle swarm optimisation (BPSO) and information theory, this paper proposes two new filter feature selection methods for classification problems. The first algorithm is based on BPSO and the mutual information of each pair of features, which determines the relevance and redundancy of the selected feature subset. The second algorithm is based on BPSO and the entropy of each group of features, which evaluates the relevance and redundancy of the selected feature subset. Different weights for the relevance and redundancy in the fitness functions of the two proposed algorithms are used to further improve their performance in terms of the number of features and the classification accuracy. In the experiments, a decision tree (DT) is employed to evaluate the classification accuracy of the selected feature subset on the test sets of four datasets. The results show that with proper weights, two proposed algorithms can significantly reduce the number of features and achieve similar or even higher classification accuracy in almost all cases. The first algorithm usually selects a smaller feature subset while the second algorithm can achieve higher classification accuracy.","Redundancy,
Equations,
Entropy,
Mutual information,
Mathematical model,
Accuracy,
Rough sets"
Stability Analysis of an Efficient Anti-Collision Protocol for RFID Tag Identification,"A stable and efficient anti-collision protocol is very important for tags identification in many radio frequency identification (RFID) system such as flow productions and automatic controls. In this paper, we introduce an efficient anti-collision protocol named collision tree protocol (CT) and analyze the stability of it in detail. Both theoretical results and experimental results indicate that the performance of CT is only dependent on the number of tags to be identified and not influenced by the distribution of tag IDs and other factors, and the average performance of CT for one-tag identification converges to a constant. According to the definition of the stability of an anti-collision protocol, CT is a stable anti-collision protocol for RFID tag identification. The stability proposed in this paper provides a new performance metric for evaluating the performance of different anti-collision protocols for RFID tag identification. As a stable protocol, the time delay and the power consumption for one-tag identification of CT tend to be constant. Therefore, CT can be applied to various tags identification systems and especially suited to the RFID systems in which both the time delay and the power consumption for tags (or objects) identification are required to be limited and stable.","Protocols,
Complexity theory,
Radiofrequency identification,
Stability analysis,
Radiation detectors,
Heuristic algorithms,
Binary trees"
Performance Enhancement of Near-UV Light-Emitting Diodes With an InAlN/GaN Superlattice Electron-Blocking Layer,"In this study, the characteristics of the nitride-based near-UV light-emitting diode (LED) with an InAlN/GaN superlattice (SL) electron-blocking layer (EBL) are analyzed numerically and experimentally. The emission spectra, carrier concentrations in the quantum wells, energy-band diagrams, electrostatic fields, and internal quantum efficiency are investigated. The results indicate that the LED with an InAlN/GaN SL EBL has a better hole-injection efficiency and lower electron leakage over the LED with a conventional rectangular AlGaN EBL or with an AlGaN/GaN SL EBL. The results also show that the efficiency droop is markedly improved when the InAlN/GaN SL EBL is used.","Gallium nitride,
Light emitting diodes,
Aluminum gallium nitride,
Charge carrier processes,
Superlattices,
Electric potential,
Electrostatics"
On Routing and Channel Selection in Cognitive Radio Mesh Networks,"Secondary users in a cognitive radio mesh network may select from a set of available channels, provided that they do not disrupt communications among primary users. This ability can improve the overall network performance but introduces the question of how to best use the channels. This paper first considers the problem of selecting the channels to use given a routing path such that the end-to-end throughput along the path is maximized. We show that a dynamic programming-based approach can optimally solve the problem and, if the path satisfies a natural condition, in time, be linear in the length (hop count) of the path. In addition, the algorithm can easily be implemented in a distributed fashion. We also examine the harder joint problem of finding the best routing path and channel selection that maximizes the end-to-end throughput. We prove that obtaining a (2/3 + ε) approximation to the joint problem is NP-hard. We then present a heuristic algorithm for the joint problem and a second heuristic channel-aware routing-only algorithm. Numerical results are provided to demonstrate the effectiveness of the methods on several experimental scenarios.",
A hash-based RFID security protocol for strong privacy protection,"RFID (Radio Frequency Identification) tags are small, wireless electronic devices that help identify objects and people. Privacy protection and integrity assurance become rather crucial in the RFID systems, because these RFID tags may have a wide transmission range, making them subject to unauthorized scanning by malicious readers and various other attacks. Hence, Ha et al. proposed an RFID protocol and proved that their protocol can provide the forward privacy service. However, in this paper, it is shown that an attacker can track a target tag by observing unsuccessful previous session of the tag. That is, Ha et al.'s RFID protocol fails to provide the forward privacy protection as claimed. Therefore, to overcome the privacy weaknesses of Ha et al.'s RFID protocol, an RFID protocol based on the cryptographic hash functions is proposed. Moreover, the proposed RFID protocol is evaluated according to both the privacy attribute and the implementation performance.","Radiofrequency identification,
Protocols,
Privacy,
Synchronization,
Authentication,
Cryptography"
Opportunities and Challenges of Using Plasmonic Components in Nanophotonic Architectures,"Nanophotonic architectures have recently been proposed as a path to providing low latency, high bandwidth network-on-chips. These proposals have primarily been based on micro-ring resonator modulators which, while capable of operating at tremendous speed, are known to have both a high manufacturing induced variability and a high degree of temperature dependence. The most common solution to these two problems is to introduce small heaters to control the temperature of the ring directly, which can significantly reduce overall power efficiency. In this paper, we introduce plasmonics as a complementary technology. While plasmonic devices have several important advantages, they come with their own new set of restrictions, including propagation loss and lack of wave division multiplexing (WDM) support. To overcome these challenges we propose a new hybrid photonic/plasmonic channel that can support WDM through the use of photonic micro-ring resonators as variation tolerant passive filters. Our aim is to exploit the best of both technologies: wave-guiding of photonics, and modulating using plasmonics. This channel provides moderate bandwidth with distance independent power consumption and a higher degree of temperature and process variation tolerance. We describe the state of plasmonics research, present architecturally-useful models of many of the most important devices, explore new ways in which the limitations of the technology can most readily be minimized, and quantify the applicability of these novel hybrid schemes across a variety of interconnect strategies. Our link-level analysis shows that the hybrid channel can save from 28% to 45% of total channel energy-cost per bit depending on process variation conditions.","Plasmons,
Photonics,
Modulation,
Optical waveguides,
Metals,
Optical losses,
Optical ring resonators"
A human detection method for residential smart energy systems based on Zigbee RSSI changes,"In this article, the device-free human presence detection method based on radio signal strength variations is proposed. The method exploits the known fact that human body interferes with radio signals by causing fading and shadowing effects. Introduced irregularities in the radio propagation pattern indicate possible presence of a human. The proposed method is incorporated into the existing platform for intelligent residential energy management. As opposed to conventional solutions which utilize a complex set of sensors for human detection, the proposed approach achieves the same only by analyzing and quantifying radio signal strength variations incorporated in messages exchanged between 2.4 GHz radio transceivers. One of the key benefits of the proposed solution is the integration of the detection algorithm into the smart power outlets and smart light switches. Such an approach improves interactions in smart home systems, enables intelligent power consumption management and low installation cost.",
A novel ID-based authentication framework with adaptive privacy preservation for VANETs,"In Vehicular Ad hoc Networks (VANETs), authentication is a crucial security requirement to avoid attacks to both inter-vehicle and vehicle-roadside communication. Vehicles have to be prevented from the misuse of their private data and the attacks on their privacy. In this paper, we investigate the authentication and privacy issues in VANETs. We propose a novel ID-based authentication framework with adaptive privacy preservation for VANETs. In this framework, adaptive self-generated pseudonyms are used as identifiers instead of real-world IDs. The update of the pseudonyms depends on vehicular demands. The ID-Based Signature (IBS) scheme and the ID-Based Online/Offline Signature (IBOOS) scheme are used, for authentication between the Road Side Units (RSUs) and vehicles, as well as authentication among vehicles, respectively. System evaluation has been executed using efficient IBS and IBOOS schemes. It shows that, the proposed authentication framework with privacy preservation is suitable to the VANET environment.","Vehicles,
Authentication,
Privacy,
Roads,
Cryptography,
Digital signatures"
Energy consumption model for mobile devices in 3G and WLAN networks,"In this paper, we propose an advanced model, called e-Aware, for estimating how application layer protocol properties affect the energy consumption of mobile devices, operating in 3G (WCDMA) and WLAN (802.11) networks. The main motivation for the model is to facilitate designing energy-efficient networking solutions, by reducing the need for time-consuming measurements with real-life networks and devices. The model makes a distinction between signaling and media transfers due to their different energy consumption characteristics, and takes into account the fundamentals of radio interface properties, such as different energy states and timers controlling them. The model is fine-tuned using device-specific coefficients that are defined according to real-world measurements with actual devices. We have implemented the model and simulated it in Matlab environment. The correct functionality is verified by comparing the results with real-life measurements in identical networking scenarios.","Power demand,
Energy consumption,
Multiaccess communication,
Spread spectrum communication,
Mathematical model,
Media,
IEEE 802.11 Standards"
A Novel Semiautomated Atherosclerotic Plaque Characterization Method Using Grayscale Intravascular Ultrasound Images: Comparison With Virtual Histology,"Intravascular ultrasound (IVUS) virtual histology (VH-IVUS) is a new technique, which provides automated plaque characterization in IVUS frames, using the ultrasound backscattered RF-signals. However, its computation can only be performed once per cardiac cycle (ECG-gated technique), which significantly decreases the number of characterized IVUS frames. Also atherosclerotic plaques in images that have been acquired by machines, which are not equipped with the VH software, cannot be characterized. To address these limitations, we have developed a plaque characterization technique that can be applied in grayscale IVUS images. Our semiautomated method is based on a three-step approach. In the first step, the plaque area [region of interest (ROI)] is detected semiautomatically. In the second step, a set of features is extracted for each pixel of the ROI and in the third step, a random forest classifier is used to classify these pixels into four classes: dense calcium, necrotic core, fibrotic tissue, and fibro-fatty tissue. In order to train and validate our method, we used 300 IVUS frames acquired from virtual histology examinations from ten patients. The overall accuracy of the proposed method was 85.65% suggesting that our approach is reliable and may be further investigated in the clinical and research arena.",
Analysis of Degradation Mechanisms in Low-Temperature Polycrystalline Silicon Thin-Film Transistors under Dynamic Drain Stress,"Degradation induced by dynamic drain stress in both n-type and p-type low-temperature polycrystalline silicon thin-film transistors (TFTs) is systematically investigated. A transition-time-dependent hot-carrier (HC) mechanism is attributed to be the dominant degradation mechanism even for stress amplitudes close to the operation condition. Previously proposed nonequilibrium-drain-junction degradation model is further elaborated by including time-dependent carrier emission/recombination process. Different from that of n-type TFTs, a two-stage degradation behavior is first observed in p-type TFTs. By considering the effect of electron trapping in the initial stage on the dynamic HC mechanism in the second stage, degradation of both n-type and p-type TFTs can be consistently understood within a unified model, which also explains the absence of the two-stage degradation in n-type TFTs. Finally, this paper is further extended to show that the unified model should also be applicable to HC degradation induced by dynamic gate stress.","Degradation,
Stress,
Thin film transistors,
Logic gates,
Transient analysis,
Charge carrier processes,
Silicon"
Performance evaluation of SiC power MOSFETs for high-temperature applications,"In this paper, the high-temperature performance of the commercial SiC power MOSFETs has been extensively evaluated beyond 125 °C - the maximum junction temperature according to the datasheet. Both the static and switching characteristics have been measured under various temperatures up to 200 °C. The results show the superior electrical performance of the SiC MOSFETs for high-temperature operation. Meanwhile, the gate biasing and gate switching tests have also been conducted to test the gate oxide reliability of these devices under elevated temperatures. The test results reveal the degradation in the device characteristics under high temperature and different gate voltage conditions, which exhibit the trade-off between the performance and the reliability of SiC MOSFETs for high-temperature applications.","MOSFETs,
Logic gates,
Temperature measurement,
Silicon carbide,
Temperature,
Switches,
Silicon"
A textured object recognition pipeline for color and depth image data,"We present an object recognition system which leverages the additional sensing and calibration information available in a robotics setting together with large amounts of training data to build high fidelity object models for a dataset of textured household objects. We then demonstrate how these models can be used for highly accurate detection and pose estimation in an end-to-end robotic perception system incorporating simultaneous segmentation, object classification, and pose fitting. The system can handle occlusions, illumination changes, multiple objects, and multiple instances of the same object. The system placed first in the ICRA 2011 Solutions in Perception instance recognition challenge. We believe the presented paradigm of building rich 3D models at training time and including depth information at test time is a promising direction for practical robotic perception systems.",
Volumetric real-time imaging using a CMUT ring array,"A ring array provides a very suitable geometry for forward-looking volumetric intracardiac and intravascular ultrasound imaging. We fabricated an annular 64-element capacitive micromachined ultrasonic transducer (CMUT) array featuring a 10-MHz operating frequency and a 1.27-mm outer radius. A custom software suite was developed to run on a PCbased imaging system for real-time imaging using this device. This paper presents simulated and experimental imaging results for the described CMUT ring array. Three different imaging methods-flash, classic phased array (CPA), and synthetic phased array (SPA)-were used in the study. For SPA imaging, two techniques to improve the image quality-Hadamard coding and aperture weighting-were also applied. The results show that SPA with Hadamard coding and aperture weighting is a good option for ring-array imaging. Compared with CPA, it achieves better image resolution and comparable signal-tonoise ratio at a much faster image acquisition rate. Using this method, a fast frame rate of up to 463 volumes per second is achievable if limited only by the ultrasound time of flight; with the described system we reconstructed three cross-sectional images in real-time at 10 frames per second, which was limited by the computation time in synthetic beamforming.",
Iterative Narrowband-Based Graph Cuts Optimization for Geodesic Active Contours With Region Forces (GACWRF),"In this paper, an iterative narrow-band-based graph cuts (INBBGC) method is proposed to optimize the geodesic active contours with region forces (GACWRF) model for interactive object segmentation. Based on cut metric on graphs proposed by Boykov and Kolmogorov, an NBBGC method is devised to compute the local minimization of GAC. An extension to an iterative manner, namely, INBBGC, is developed for less sensitivity to the initial curve. The INBBGC method is similar to graph-cuts-based active contour (GCBAC) presented by Xu , and their differences have been analyzed and discussed. We then integrate the region force into GAC. An improved INBBGC (IINBBGC) method is proposed to optimize the GACWRF model, thus can effectively deal with the concave region and complicated real-world images segmentation. Two region force models such as mean and probability models are studied. Therefore, the GCBAC method can be regarded as the special case of our proposed IINBBGC method without region force. Our proposed algorithm has been also analyzed to be similar to the Grabcut method when the Gaussian mixture model region force is adopted, and the band region is extended to the whole image. Thus, our proposed IINBBGC method can be regarded as narrow-band-based Grabcut method or GCBAC with region force method. We apply our proposed IINBBGC algorithm on synthetic and real-world images to emphasize its performance, compared with other segmentation methods, such as GCBAC and Grabcut methods.","Image segmentation,
Active contours,
Minimization,
Image edge detection,
Pixel,
Force,
Equations"
"k
-Angle Object Coverage Problem in a Wireless Sensor Network","One of the fundamental issues in sensor networks is the coverage problem, which reflects how well a field is monitored or tracked by sensors. Various versions of this problem have been studied, such as object, area, barrier, and hole coverage problems. In this paper, we define a new k-angle object coverage problem in a wireless sensor network. Each sensor can only cover a limited angle and range, but can freely rotate to any direction to cover a particular angle. Given a set of sensors and a set of objects at known locations, the goal is to use the least number of sensors to k-angle-cover the largest number of objects such that each object is monitored by at least k sensors satisfying some angle constraint. We propose centralized and distributed polynomial-time algorithms to solve this problem. Simulation results show that our algorithms can be effective in maximizing coverage of objects. A prototype system is developed to demonstrate the usefulness of angle coverage.",
The Issue of (Software) Plagiarism: A Student View,"The issue of plagiarism is discussed in the context of university education in disciplines related to computing. The focus is therefore mainly on software plagiarism. First, however, a case is made for the claim that the most important reason that plagiarism cannot be tolerated lies in the essence of the concept of a university as it is rooted in the Western cultural tradition. The main contribution of this paper is in providing firsthand insight into students' views on some of the delicate questions related to student plagiarism. However, this paper presents views from both sides of the question, including the views of staff members. This paper is quite unique in that it is coauthored by students who provide independent comments and recommendations.","Plagiarism,
Software,
Computers,
Education,
Materials,
Computer science,
Informatics"
Power-Driven Flip-Flop Merging and Relocation,"We propose a power-driven flip-flop (FF) merging and relocation approach that can be applied after conventional timing-driven placement and before clock network synthesis. It targets to reduce the clock network size and thus the clock power consumption while controlling the switching power of the nets connected to the FFs by selectively merging FFs into multibit FFs and relocating them under timing and placement density constraints. The experimental results are very encouraging. For a set of benchmarks, our approach reduced the switching capacitance of clock network by 36%-43% after gated clock tree synthesis. Finally, the total switching capacitance of clock network and nets connected to the FFs is reduced by 24%-29%.",
An FPGA-Based Embedded Robust Speech Recognition System Designed by Combining Empirical Mode Decomposition and a Genetic Algorithm,"A field-programmable gate array (FPGA)-based robust speech measurement and recognition system is the focus of this paper, and the environmental noise problem is its main concern. To accelerate the recognition speed of the FPGA-based speech recognition system, the discrete hidden Markov model is used here to lessen the computation burden inherent in speech recognition. Furthermore, the empirical mode decomposition is used to decompose the measured speech signal contaminated by noise into several intrinsic mode functions (IMFs). The IMFs are then weighted and summed to reconstruct the original clean speech signal. Unlike previous research, in which IMFs were selected by trial and error for specific applications, the weights for each IMF are designed by the genetic algorithm to obtain an optimal solution. The experimental results in this paper reveal that this method achieves a better speech recognition rate for speech subject to various environmental noises. Moreover, this paper also explores the hardware realization of the designed speech measurement and recognition systems on an FPGA-based embedded system with the System-On-a-Chip (SOC) architecture. Since the central-processing-unit core adopted in the SOC has limited computation ability, this paper uses the integer fast Fourier transform (FFT) to replace the floating-point FFT to speed up the computation for capturing speech features through a mel-frequency cepstrum coefficient. The result is a significant reduction in the calculation time without influencing the speech recognition rate. It can be seen from the experiments in this paper that the performance of the implemented hardware is significantly better than that of existing research.","Speech recognition,
Speech,
Training,
Noise,
Vectors,
Speech coding,
System-on-a-chip"
The Intrusion Detection in Mobile Sensor Network,"Intrusion detection is an important problem in sensor networks. Prior works in static sensor environments show that constructing sensor barriers with random sensor deployment can be effective for intrusion detection. In response to the recent surge of interest in mobile sensor applications, this paper studies the intrusion detection problem in a mobile sensor network, where it is believed that mobile sensors can improve barrier coverage. Specifically, we focus on providing
k
-barrier coverage against moving intruders. This problem becomes particularly challenging given that the trajectories of sensors and intruders need to be captured. We first demonstrate that this problem is similar to the classical kinetic theory of gas molecules in physics. We then derive the inherent relationship between barrier coverage performance and a set of crucial system parameters including sensor density, sensing range, and sensor and intruder mobility. We examine the correlations and sensitivity from the system parameters, and we derive the minimum number of mobile sensors that needs to be deployed in order to maintain the
k
-barrier coverage for a mobile sensor network. Finally, we show that the coverage performance can be improved by an order of magnitude with the same number of sensors when compared to that of the static sensor environment.",
An ESPRIT-SAA-Based Detection Method for Broken Rotor Bar Fault in Induction Motors,"This paper presents a novel detection method for broken rotor bar fault (BRB) in induction motors based on the estimation of signal parameters via rotational invariance technique (ESPRIT) and simulated annealing algorithm (SAA). The performance of ESPRIT is tested with the simulated stator current signal of an induction motor with BRB. It shows that even with short-time measurement data, the technique is capable of correctly identifying the frequencies of the BRB characteristic components but with a low accuracy on the amplitudes and initial phases of those components. The SAA is then used to determine their amplitudes and initial phases and shows satisfactory results. Finally, experiments on a 3-kW, 380-V, 50-Hz induction motor are conducted to demonstrate the effectiveness of the ESPRIT-SAA-based method in detecting BRB with short-time measurement data. It proves that the proposed method is a promising choice for BRB detection in induction motors operating with small slip and fluctuant load.",
Evaluation of Marton's Inner Bound for the General Broadcast Channel,"The best known inner bound on the two-receiver general broadcast channel is due to Marton. However this region is not computable (except in certain special cases) as no bounds on the cardinality of its auxiliary random variables exist. Nor is it even clear that the inner bound is a closed set. The main obstacle in proving cardinality bounds is the fact that the traditional use of the Carathéodory theorem, the main known tool for proving cardinality bounds, does not yield a finite cardinality result. One of the main contributions of this paper is the introduction of a new tool based on an identity that relates the second derivative of the Shannon entropy of a discrete random variable (under a certain perturbation) to the corresponding Fisher information. In order to go beyond the traditional Carathéodory type arguments, we identify certain properties that the auxiliary random variables corresponding to the extreme points of the inner bound need to satisfy. These properties are then used to establish cardinality bounds on the auxiliary random variables of the inner bound, thereby proving the computability of the region, and its closedness. Lastly, we establish a conjecture of Nair and Zizhou that Marton's inner bound and the recent outer bound of Nair and El Gamal do not match in general.","Random variables,
Joints,
Equations,
Entropy,
Vectors,
Receivers,
Encoding"
Autocalibration of Triaxial MEMS Accelerometers With Automatic Sensor Model Selection,"Up to now, little attention has been posed on a principled derivation of the cost function used for autocalibration of MEMS tri-axial accelerometers. By formulating the calibration problem in the context of maximum likelihood estimate, we derive here a general formulation that can be reduced to the classical quadratic cost function under certain hypotheses. Moreover, we adopt the Akaike information criterion to automatically choose the most adequate linear sensor model for the given calibration data set. Experiments on simulated and real data show the effectiveness of the proposed approach.","Calibration,
Micromechanical devices,
Vectors,
Noise,
Accuracy,
Accelerometers,
Data models"
Evasion Techniques: Sneaking through Your Intrusion Detection/Prevention Systems,"Detecting attacks disguised by evasion techniques is a challenge for signature-based Intrusion Detection Systems (IDSs) and Intrusion Prevention Systems (IPSs). This study examines five common evasion techniques to determine their ability to evade recent systems. The denial-of-service (DoS) attack attempts to disable a system by exhausting its resources. Packet splitting tries to chop data into small packets, so that a system may not completely reassemble the packets for signature matching. Duplicate insertion can mislead a system if the system and the target host discard different TCP/IP packets with a duplicate offset or sequence. Payload mutation fools a system with a mutative payload. Shellcode mutation transforms an attacker's shellcode to escape signature detection. This study assesses the effectiveness of these techniques on three recent signature-based systems, and among them, explains why Snort can be evaded. The results indicate that duplicate insertion becomes less effective on recent systems, but packet splitting, payload mutation and shellcode mutation can be still effective against them.","Payloads,
IP networks,
Computer crime,
Handwriting recognition,
Cryptography,
Intrusion detection"
A Flexible Underwater Pressure Sensor Array Using a Conductive Elastomer Strain Gauge,"This paper presents a flexible pressure sensor array which is demonstrated to transduce underwater pressure variations produced by moving objects and surface waves. The sensors exhibit a 0.0014 fractional resistance change per 100 Pa, achieving a high 1.5-Pa pressure resolution. The measurement has a repeatability of 22% of the peak amplitude of the pressure waveform, due to creep. Additionally, sensor operation while bent to a 0.5-m radius of curvature is demonstrated. Each sensor consists of a strain-concentrating polydimethylsiloxane (PDMS) diaphragm and a resistive strain gauge made of a conductive carbon-black-PDMS composite. A 1-D array of four sensors with a 15-mm center-to-center spacing is fabricated, and the dynamic response of the sensors is characterized and modeled.",
"A Path-Connected-Cluster Wireless Sensor Network and Its Formation, Addressing, and Routing Protocols","Although wireless sensor networks (WSNs) have been extensively researched, their deployment is still a main concern. We observe that many monitoring applications for WSNs have adopted a path-connected-cluster (PCC) topology, where regions to be monitored are deployed with clusters of sensor nodes. Since these clusters might be physically separated, paths of sensor nodes are used to connect them together. We call such networks PCC-WSNs. PCC-WSNs may be widely applied in real situations, such as bridge-connected islands, street-connected buildings, and pipe-connected ponds. In this paper, we show that the address assignment scheme defined by ZigBee will perform poorly in terms of address utilization. We then propose a systematical solution, which includes network formation, automatic address assignment, and light-weight routing. Simulation results verify the effectiveness of the proposed solution.","Routing,
Zigbee,
Wireless sensor networks,
Topology,
Monitoring,
Network topology,
Vegetation"
AIS-Based Coordinated and Adaptive Control of Generator Excitation Systems for an Electric Ship,"An artificial immune system (AIS)-based control of generator excitation systems for the U.S. Navy's electric ship is presented in this paper to solve power quality problems caused by high-energy loads such as direct energy weapons. The coordinated development of the AIS controllers mainly consists of two parts-innate immunity (optimal) and adaptive immunity. The parameters of the controllers for the former, to provide optimal performance, are determined simultaneously using particle swarm optimization. For dramatic changes in the ship's power system, adaptive control based on the immune system feedback law is developed. The feedback law adapts the controllers' parameters only during transient disturbances. After the disturbance, the controllers' parameters are restored to their innate values. A ship's real-time power system and the proposed AIS control of all excitation systems have been implemented on a real-time digital simulator and a digital signal processor, respectively. Results from the hardware-in-the-loop studies show that the AIS controllers can provide effective control of all generators' terminal voltages during pulsed loads, restoring and stabilizing them quickly.","Immune system,
Generators,
Marine vehicles,
Voltage control,
Power system stability,
Reactive power,
Digital signal processing"
Magnetic Relaxation Detector for Microbead Labels,"A compact and robust magnetic label detector for biomedical assays is implemented in 0.18-μ m CMOS. Detection relies on the magnetic relaxation signature of a microbead label for improved tolerance to environmental variations and relaxed dynamic range requirement, eliminating the need for baseline calibration and reference sensors. The device includes embedded electromagnets to eliminate external magnets and reduce power dissipation. Correlated double sampling combined with offset servo loops and magnetic field modulation, suppresses the detector offset to sub-μ T. Single 4.5-μ m magnetic beads are detected in 16 ms with a probability of error <; 0.1%.","Magnetometers,
Magnetic sensors,
Magnetic separation,
Magnetic moments,
Magnetic circuits,
Magnetic resonance imaging"
"Performance Analysis of Multihop Wireless Links Over Generalized-
K
Fading Channels","The performance of multihop links is studied in this contribution by both analysis and simulations when communicating over generalized-K (KG) fading channels. The performance metrics considered include symbol error rate (SER), outage probability, level crossing rate (LCR), and average outage duration (AOD). First, the expressions for both the SER and outage probability are derived by approximating the probability density function (pdf) of the end-to-end signal-to-noise ratio (SNR) using an equivalent end-to-end pdf. We show that this equivalent end-to-end pdf is accurate for analyzing the outage probability. Then, the second-order statistics of LCR and AOD of multihop links are analyzed. Finally, the performance of multihop links is investigated by either simulations or evaluation of the expressions derived. Our performance results show that the analytical expressions obtained can be well justified by the simulation results. The studies show that the KG channel model and the expressions derived in this paper are highly efficient for the prediction of the performance metrics and statistics for the design of multihop communication links.","Fading,
Signal to noise ratio,
Probability density function,
Random processes,
Relays,
Joints,
Shadow mapping"
Multiview Face Recognition: From TensorFace to V-TensorFace and K-TensorFace,"Face images under uncontrolled environments suffer from the changes of multiple factors such as camera view, illumination, expression, etc. Tensor analysis provides a way of analyzing the influence of different factors on facial variation. However, the TensorFace model creates a difficulty in representing the nonlinearity of view subspace. In this paper, to break this limitation, we present a view-manifold-based TensorFace (V-TensorFace), in which the latent view manifold preserves the local distances in the multiview face space. Moreover, a kernelized TensorFace (K-TensorFace) for multiview face recognition is proposed to preserve the structure of the latent manifold in the image space. Both methods provide a generative model that involves a continuous view manifold for unseen view representation. Most importantly, we propose a unified framework to generalize TensorFace, V-TensorFace, and K-TensorFace. Finally, an expectation-maximization like algorithm is developed to estimate the identity and view parameters iteratively for a face image of an unknown/unseen view. The experiment on the PIE database shows the effectiveness of the manifold construction method. Extensive comparison experiments on Weizmann and Oriental Face databases for multiview face recognition demonstrate the superiority of the proposed V- and K-TensorFace methods over the view-based principal component analysis and other state-of-the-art approaches for such purpose.","Face,
Manifolds,
Tensile stress,
Face recognition,
Vectors,
Kernel,
Databases"
Direct Evaluation of IEC 61850-9-2 Process Bus Network Performance,"This letter presents a technique to assess the overall network performance of sampled value process buses based on IEC 61850-9-2 using measurements from a single location in the network. The method is based upon the use of Ethernet cards with externally synchronized time stamping, and characteristics of the process bus protocol. The application and utility of the method is demonstrated by measuring latency introduced by Ethernet switches. Network latency can be measured from a single set of captures, rather than comparing source and destination captures. Absolute latency measures will greatly assist the design testing, commissioning and maintenance of these critical data networks.",
Pedestrian-inspired sampling-based multi-robot collision avoidance,"We present a distributed collision avoidance algorithm for multiple mobile robots that is model-predictive, sampling-based, and intuitive for operation around humans. Unlike purely reactive approaches, the proposed algorithm incorporates arbitrary trajectories as generated by a motion planner running on each navigating robot as well as predicted human trajectories. Our approach, inspired by human navigation in crowded pedestrian environments, draws from the sociology literature on pedestrian interaction. We propose a simple two-phase algorithm in which agents initially cooperate to avoid each other and then initiate civil inattention, thus lessening reactivity and committing to a trajectory. This process entails a pedestrian bargain in which all agents act competently to avoid each other and, once resolution is achieved, to avoid interfering with others' planned trajectories. This approach, being human-inspired, fluidly permits navigational interaction between humans and robots. We report experimental results for the algorithm running on real robots with and without human presence and in simulation.","Robots,
Collision avoidance,
Trajectory,
Humans,
Planning,
Prediction algorithms,
Navigation"
A decentralized control policy for adaptive information gathering in hazardous environments,"This paper proposes an algorithm for driving a group of resource-constrained robots with noisy sensors to localize an unknown number of targets in an environment, while avoiding hazards at unknown positions that cause the robots to fail. The algorithm is based upon the analytic gradient of mutual information of the target locations and measurements and offers two primary improvements over previous algorithms [6], [13]. Firstly, it is decentralized. This follows from an approximation to mutual information based upon the fact that the robots' sensors and environmental hazards have a finite area of influence. Secondly, it allows targets to be localized arbitrarily precisely with limited computational resources. This is done using an adaptive cellular decomposition of the environment, so that only areas that likely contain a target are given finer resolution. The estimation is built upon finite set statistics, which provides a rigorous, probabilistic framework for multi-target tracking. The algorithm is shown to perform favorably compared to existing approximation methods in simulation.","Robot sensing systems,
Hazards,
Mutual information,
Approximation methods,
Bayesian methods"
Modeling and control of a new quadrotor manipulation system,"This paper introduces a new quadrotor manipulation system that consists of a 2-link manipulator attached to the bottom of a quadrotor. This new system presents a solution for the drawbacks found in the current quadrotor manipulation system which uses a gripper fixed to a quadrotor. Unlike the current system, the proposed system enables the end-effector to achieve any arbitrary orientation and thus increases its degrees of freedom from 4 to 6. Also, it provides enough distance between the quadrotor and the object to be manipulated. This is useful in some applications such as demining applications. System kinematics and dynamics are derived which are highly nonlinear. Controller is designed based on feedback linearization to track desired trajectories. Controlling the movements in the horizontal directions is simplified by utilizing the derived nonholonmic constraints. Finally, the proposed system is simulated using MATLAB/SIMULINK program. The simulation results show the effectiveness of the proposed controller.","trajectory control,
control system synthesis,
end effectors,
feedback,
grippers,
helicopters,
linearisation techniques,
manipulator dynamics,
manipulator kinematics,
rotors"
"Design, Implementation, and Performance of a Load Balancer for SIP Server Clusters","This paper introduces several novel load-balancing algorithms for distributing Session Initiation Protocol (SIP) requests to a cluster of SIP servers. Our load balancer improves both throughput and response time versus a single node while exposing a single interface to external clients. We present the design, implementation, and evaluation of our system using a cluster of Intel x86 machines running Linux. We compare our algorithms to several well-known approaches and present scalability results for up to 10 nodes. Our best algorithm, Transaction Least-Work-Left (TLWL), achieves its performance by integrating several features: knowledge of the SIP protocol, dynamic estimates of back-end server load, distinguishing transactions from calls, recognizing variability in call length, and exploiting differences in processing costs for different SIP transactions. By combining these features, our algorithm provides finer-grained load balancing than standard approaches, resulting in throughput improvements of up to 24% and response-time improvements of up to two orders of magnitude. We present a detailed analysis of occupancy to show how our algorithms significantly reduce response time.",
Automatic Detection of Gadolinium-Enhancing Multiple Sclerosis Lesions in Brain MRI Using Conditional Random Fields,"Gadolinium-enhancing lesions in brain magnetic resonance imaging of multiple sclerosis (MS) patients are of great interest since they are markers of disease activity. Identification of gadolinium-enhancing lesions is particularly challenging because the vast majority of enhancing voxels are associated with normal structures, particularly blood vessels. Furthermore, these lesions are typically small and in close proximity to vessels. In this paper, we present an automatic, probabilistic framework for segmentation of gadolinium-enhancing lesions in MS using conditional random fields. Our approach, through the integration of different components, encodes different information such as correspondence between the intensities and tissue labels, patterns in the labels, or patterns in the intensities. The proposed algorithm is evaluated on 80 multimodal clinical datasets acquired from relapsing-remitting MS patients in the context of multicenter clinical trials. The experimental results exhibit a sensitivity of 98% with a low false positive lesion count. The performance of the proposed algorithm is also compared to a logistic regression classifier, a support vector machine and a Markov random field approach. The results demonstrate superior performance of the proposed algorithm at successfully detecting all of the gadolinium-enhancing lesions while maintaining a low false positive lesion count.",
A New Low-Complexity PTS Scheme Based on Successive Local Search Using Sequences,"A new partial transmit sequence (PTS) scheme with low computational complexity is proposed, where two search steps are taken to find a subset of phase rotating vectors showing good peak-to-average power ratio (PAPR) reduction performance. In the first step, sequences with low correlation are used as phase rotating vectors for PTS scheme, which are called the initial phase vectors. In the second step, local search is performed based on the initial phase vectors to find additional phase rotating vectors which show good PAPR reduction performance. Numerical analysis shows that the proposed PTS scheme achieves better PAPR reduction performance with significantly reduced computational complexity than the existing low-complexity PTS schemes.",
Passivation Properties of Atomic-Layer-Deposited Hafnium and Aluminum Oxides on Si Surfaces,"This paper studies the chemical and field effect passivation properties of silicon surfaces by thin hafnium oxide (HfO2) and aluminum oxide (Al2O3) layers grown by chemical-vapor-based atomic layer deposition method. Using a rigorous metal-oxide-semiconductor model and results from capacitance-voltage measurements, the density of fixed charges (Nf) and the density of interface traps (Dit) at the HfO2/Si and Al2O3/Si interfaces were obtained. Microwave photoconductivity decay measurements were used to characterize interface recombination velocities at these interfaces.","Silicon,
Aluminum oxide,
Passivation,
Hafnium compounds,
Substrates,
Capacitance"
On linear index coding for random graphs,"In the index coding problem, the goal is to transmit an n character word over a field F to n receivers (one character per receiver), where the receivers have side information represented by a graph G. The objective is to minimize the length of a codeword broadcasted to all receivers which allows each receiver to learn its character. For linear index coding, the minimum possible length is known to be equal to the minrank parameter. In this paper we initiate the study of the typical minimum length of a linear index code for the random graph G(n, p) over a field F. First, we prove that for every constant size field F and a constant p, the minimum length of a linear index code for G(n, p) over F is almost surely Ω(√n). Second, we introduce and study two special models of index coding and study their typical minimum length: Locally decodable index codes in which the receivers are required to query at most q characters from the encoded message (such codes naturally correspond to efficient decoding); and low density index codes in which every character of the broadcasted word affects at most q characters in the encoded message (such codes naturally correspond to efficient encoding procedures). We present enhanced results for these special models.","Indexes,
Vectors,
Receivers,
Generators,
Channel coding,
Hamming weight"
Group-Wise Registration of Point Sets for Statistical Shape Models,"This paper presents a novel, fast, group-wise registration technique based on establishing soft correspondences between groups of point sets. The registration approach is used to create a statistical shape model, capable of learning the shape variations within a training set. The shape model consists of a mean shape and its transformations to all training shapes. We decouple the procedure into two steps: updating the mean shape and registering it to the training shapes. The algorithm alternates between these two steps until convergence. Following the generation of the statistical shape model, we use the soft correspondence approach to register the model to a new observation. We perform extensive experiments on two data sets: lumbar spine and hippocampi. We compare our algorithm to available state-of-the-art group-wise registration algorithms including feature-based and volume-based approaches. We demonstrate improved generalization, specificity and compactness compared to these algorithms.","Shape,
Training,
Mathematical model,
Computational modeling,
Algorithm design and analysis,
Deformable models,
Image registration"
On-demand test suite reduction,"Most test suite reduction techniques aim to select, from a given test suite, a minimal representative subset of test cases that retains the same code coverage as the suite. Empirical studies have shown, however, that test suites reduced in this manner may lose fault detection capability. Techniques have been proposed to retain certain redundant test cases in the reduced test suite so as to reduce the loss in fault-detection capability, but these still do concede some degree of loss. Thus, these techniques may be applicable only in cases where loose demands are placed on the upper limit of loss in fault-detection capability. In this work we present an on-demand test suite reduction approach, which attempts to select a representative subset satisfying the same test requirements as an initial test suite conceding at most l% loss in fault-detection capability for at least c% of the instances in which it is applied. Our technique collects statistics about loss in fault-detection capability at the level of individual statements and models the problem of test suite reduction as an integer linear programming problem. We have evaluated our approach in the contexts of three scenarios in which it might be used. Our results show that most test suites reduced by our approach satisfy given fault detection capability demands, and that the approach compares favorably with an existing test suite reduction approach.","Fault detection,
Testing,
Computational modeling,
Integer linear programming,
Educational institutions,
Software"
Selective Sampling for Beat Tracking Evaluation,"In this paper, we propose a method that can identify challenging music samples for beat tracking without ground truth. Our method, motivated by the machine learning method “selective sampling,” is based on the measurement of mutual agreement between beat sequences. In calculating this mutual agreement we show the critical influence of different evaluation measures. Using our approach we demonstrate how to compile a new evaluation dataset comprised of difficult excerpts for beat tracking and examine this difficulty in the context of perceptual and musical properties. Based on tag analysis we indicate the musical properties where future advances in beat tracking research would be most profitable and where beat tracking is too difficult to be attempted. Finally, we demonstrate how our mutual agreement method can be used to improve beat tracking accuracy on large music collections.","Histograms,
Accuracy,
Humans,
Electronic mail,
Europe,
Estimation,
Correlation"
Crossbar NoCs Are Scalable Beyond 100 Nodes,"We describe the design and layout of a radix-128 crossbar in 90 nm CMOS. The data path is 32 bits wide and runs at 750 MHz using a three-stage pipeline, while fitting in a silicon area as small as 6.6 mm2 by filling it at the 90% level. The control path occupies 7 mm2 next to the data path by filling it at 35% level, and reconfigures the data path once every three clock cycles. Next, we arrange 128 1 mm2 “user tiles” around the crossbar, forming a 150 mm2 die, and we connect all tiles to the crossbar via global links running on top of the tiles. Including the overhead of repeaters and flip flops on global links, the area cost of the crossbar is 11% of the die. Thus, we prove that crossbar networks-on-chips (NoCs) are small enough for radices exceeding by far the few tens of ports, that were believed to be the practical limit up to now, and reaching above 100 ports. We also attempt a first-order comparison between our crossbar and a model of a popular mesh NoC, and we find that our crossbar NoC increases performance when traffic is global and stressed, at the cost of worse performance when traffic is local and benign. Finally, we present an experimental cost analysis showing that crossbar area practically grows as O(N2W), as all wiring of the crossbar fits over its standard cells, while crossbar delay grows as O(N√W) , as wire length increases with the perimeter of the crossbar.","Tiles,
Multiplexing,
Wires,
Logic gates,
Wiring,
Random access memory,
Delay"
Frequency Modulation Technique for MEMS Resistive Sensing,"Frequency modulation technique can be applied to microelectromechanical systems (MEMS) transducers that require some form of resistive sensing. For example, electrothermal sensing is being investigated as a viable means of measuring displacement in micromachined transducers. This paper proposes a highly sensitive readout circuit, which can convert 10 Ω change of resistance in a 400 Ω electrothermal sensor to more than 200 kHz frequency variation (350-550 KHz). The frequency variations are then converted to voltage values by means of a frequency demodulation. In addition, the proposed technique achieves high linearity from the voltage applied to the actuator to the voltage measured at the sensor's output, which can potentially eliminate the need for an additional linearization if the sensor is used in a feedback loop. The proposed approach leads to high sensitivity in the MEMS electrothermal sensing since the method is not affected by amplitude variations that could arise from the readout circuit.",
A mobile platform for real-time human activity recognition,"Context-aware applications have been the focus of extensive research yet their implementation in mobile devices usually becomes challenging due to restrictions in regards to processing power and energy. In this paper, we propose a mobile platform to provide real-time human activity recognition. Our system features (1) an efficient library, MECLA, for the mobile evaluation of classification algorithms; and (2) a mobile application for real-time human activity recognition running within a Body Area Network. The evaluation indicates that the system can be implemented in real scenarios meeting accuracy, response time, and energy consumption requirements.","Sensors,
Feature extraction,
Mobile communication,
Time factors,
Accuracy,
Acceleration,
Mobile handsets"
A security aspects in cloud computing,"The concept of cloud computing is a very vast concept which is very efficient and effective security services. The cloud computing methodology is a conceptual based technology which is used widely now a day. But in data privacy protection and data retrieval control is one of the most challenging research work in cloud computing, because of users secrete data which is to be stored by user. An enterprise usually store data in internal storage and then tries to protect the data from other outside source. They also provide authentication at certain specific level. Cloud computing offers an innovative business model for organizations to adopt IT services without upfront investment. Despite the potential gains achieved from the cloud computing, the organizations are slow in accepting it due to security issues and challenges associated with it. Security is one of the major issues which hamper the growth of cloud. The idea of handing over important data to another company is worrisome; such that the consumers need to be vigilant in understanding the risks of data breaches in this new environment. This paper introduces a detailed analysis of the cloud computing security issues and challenges focusing on the cloud computing types and the service delivery types. This paper mainly proposes the core concept of secured cloud computing. It suggests the cloud computing based on separate encryption and decryption services from the storage service. Due to this increasing demand for more clouds there is an ever growing threat of security becoming a major issue. This paper shall look at ways in which security threats can be a danger to cloud computing and how they can be avoided.","Cryptography,
Computational modeling,
Monitoring,
Privacy,
Companies,
Authentication"
Moving Object Detection and Tracking Using a Spatio-Temporal Graph in H.264/AVC Bitstreams for Video Surveillance,"This paper presents a spatio-temporal graph-based method of detecting and tracking moving objects by treating the encoded blocks with non-zero motion vectors and/or non-zero residues as potential parts of objects in H.264/AVC bitstreams. A spatio-temporal graph is constructed by first clustering the encoded blocks of potential object parts into block groups, each of which is defined as an attributed subgraph where the attributes of the vertices represent the positions, motion vectors and residues of the blocks. In order to remove false-positive blocks and to track the real objects, temporal connections between subgraphs in two consecutive frames are constructed and the similarities between subgraphs are computed, which constitutes a spatio-temporal graph. We show the experimental results that the proposed spatio-temporal graph-based representation of potential object blocks enables effective detection for the small-sized objects and the objects with small motion vectors and residues, and allows for reliable tracking of the detected objects even under occlusion. The identification of the detected moving objects is determined as rectangular regions of interest (ROIs) for which the ROI sizes and positions are adaptively adjusted to give the best approximation of the real shapes and positions of the objects.",
Efficient Interactive Coding against Adversarial Noise,"In this work, we study the problem of constructing interactive protocols that are robust to noise, a problem that was originally considered in the seminal works of Schulman (FOCS '92, STOC '93), and has recently regained popularity. Robust interactive communication is the interactive analogue of error correcting codes: Given an interactive protocol which is designed to run on an error-free channel, construct a protocol that evaluates the same function (or, more generally, simulates the execution of the original protocol) over a noisy channel. As in (non-interactive) error correcting codes, the noise can be either stochastic, i.e. drawn from some distribution, or adversarial, i.e. arbitrary subject only to a global bound on the number of errors. We show how to efficiently simulate any interactive protocol in the presence of constant-rate adversarial noise, while incurring only a constant blow-up in the communication complexity (CC). Our simulator is randomized, and succeeds in simulating the original protocol with probability at least 1 - 2-Ω(CC).",
Diffeomorphic Sulcal Shape Analysis on the Cortex,"We present a diffeomorphic approach for constructing intrinsic shape atlases of sulci on the human cortex. Sulci are represented as square-root velocity functions of continuous open curves in R 3, and their shapes are studied as functional representations of an infinite-dimensional sphere. This spherical manifold has some advantageous properties-it is equipped with a Riemannian L 2 metric on the tangent space and facilitates computational analyses and correspondences between sulcal shapes. Sulcal shape mapping is achieved by computing geodesics in the quotient space of shapes modulo scales, translations, rigid rotations, and reparameterizations. The resulting sulcal shape atlas preserves important local geometry inherently present in the sample population. The sulcal shape atlas is integrated in a cortical registration framework and exhibits better geometric matching compared to the conventional euclidean method. We demonstrate experimental results for sulcal shape mapping, cortical surface registration, and sulcal classification for two different surface extraction protocols for separate subject populations.","Shape,
Vectors,
Measurement,
Electronic mail,
Surface morphology,
Protocols,
Manifolds"
Can faces verify blood-relations?,"Humans can verify unknown parent-offspring and sibling pairs over unrelated subject pairs. A computational scheme to accomplish the task robustly, in the presence of challenges due to gender and age gap between related-pairs, finds many applications such as matching orphaned/lost children, identifying relatives from a photo collection. We propose one of the first computational schemes to verify sibling pairs along with parent-child relation. Towards the same, we present a novel ensemble metric learning scheme that combines the advantages of task-specific learning, adaptive prototype and feature selection and `late fusion'. We demonstrate the robustness of the scheme on a very large scale, real-world dataset. Specifically, we show that the gender difference among related-pairs leads to lower performance of traditional verification and metric learning algorithms. Through various experiments, we quantitatively study the robustness of the proposed scheme in the general and specific case of different gender related-pairs, achieving up to 80%, 75% accuracy for the parent-child and siblings relations respectively.",
Dense-Timed Pushdown Automata,"We propose a model that captures the behavior of real-time recursive systems. To that end, we introduce dense-timed pushdown automata that extend the classical models of pushdown automata and timed automata, in the sense that the automaton operates on a finite set of real-valued clocks, and each symbol in the stack is equipped with a real-valued clock representing its ""age"". The model induces a transition system that is infinite in two dimensions, namely it gives rise to a stack with an unbounded number of symbols each of which with a real-valued clock. The main contribution of the paper is an EXPTIME-complete algorithm for solving the reachability problem for dense-timed pushdown automata.","Clocks,
Automata,
Cost accounting,
Computational modeling,
Petri nets,
Standards,
Analytical models"
Optical traffic grooming in OFDM-based elastic optical networks [Invited],"Orthogonal frequency-division multiplexing (OFDM) is a multi-carrier modulation technology that transmits a high-speed data stream using multiple spectrally overlapped lower-speed subcarriers. Optical OFDM (O-OFDM) technology is a promising candidate for future high-speed optical transmission. Based on O-OFDM, a novel elastic optical network architecture with immense flexibility and scalability in spectrum allocation and data rate accommodation can be built to support diverse services and the rapid growth of Internet traffic. This architecture can provide various services directly at the optical layer in a spectrum-efficient way through bandwidth-elastic optical paths. However, carrying various data rate services using a single type of bandwidth-variable transponder might not be cost-efficient. Electrical traffic grooming is a traditional approach for sub-wavelength service accommodation in wavelength division multiplexing networks. However, it places additional electrical switching and optical-electrical-optical conversion requirements on the network, which may lead to higher cost and energy consumption. In contrast, grooming traffic optically is an attractive option for elastic optical networks. In this paper, we propose a novel optical grooming approach to aggregate and distribute traffic directly at the optical layer in OFDM-based elastic optical networks. We study routing and spectrum allocation algorithms of optical grooming to show the benefits of this approach. Our results demonstrate that significant transmitter and spectrum savings can be achieved by the optical grooming versus the non-grooming scenario, and a trade-off between optimizing the number of transmitters and optimizing spectrum usage should be considered during network planning.","Optical transmitters,
Optical fiber networks,
Optical switches,
Optical receivers,
High speed optical techniques,
OFDM,
Optical fibers"
Approximation Limits of Linear Programs (Beyond Hierarchies),"We develop a framework for proving approximation limits of polynomial-size linear programs from lower bounds on the nonnegative ranks of suitably defined matrices. This framework yields unconditional impossibility results that are applicable to any linear program as opposed to only programs generated by hierarchies. Using our framework, we prove that quadratic approximations for CLIQUE require linear programs of exponential size. (This lower bound applies to linear programs using a certain encoding of CLIQUE as a linear optimization problem) Moreover, we establish a similar result for approximations of semi definite programs by linear programs. Our main technical ingredient is a quantitative improvement of Razborov's rectangle corruption lemma (1992) for the high error regime, which gives strong lower bounds on the nonnegative rank of certain perturbations of the unique disjoint ness matrix.","Encoding,
Approximation methods,
Complexity theory,
Linear programming,
Approximation algorithms,
Vectors,
Polynomials"
Implementing Realistic Heavy Ion Tracks in a SEE Prediction Tool: Comparison Between Different Approaches,"Different radial ionization profiles modeling approaches are compared for the energy deposition representation in a single event effects (SEE) prediction tool. The total SEU cross-section calculated with the different approaches is compared for different SOI and bulk technologies, along with the multiple bit upset (MBU) prediction. A “refined average” approach is identified as a good trade-off for implementation in an engineer SEE prediction tool, taking into account sufficiently detailed physics, without asking for too much computer resources.","Random access memory,
Ionization,
Semiconductor process modeling,
Databases,
Predictive models,
Monte Carlo methods"
3-D nonlocal means filter with noise estimation for hyperspectral imagery denoising,"Noise reduction is one of important processing tasks for hyperspectral imagery (HSI). In this paper, a three-dimensional (3-D) nonlocal means filter is proposed for noise reduction of HSI. Recently, non-local means method attracts many attentions due to its global and local integrated property. Nonlocal algorithm searches the similar image patches in the whole scene to build the mean filter, so that it overcomes the disadvantage of local filter that only local pixels within a small neighbor is used, and the disadvantage of global filter that local structure is ignored. In order to explore the spectral-spatial correlation of HSI, nonlocal means method is extended from 2-D to 3-D. Furthermore, as HSI contains both of signal-independent and signal-dependent noises, variance-stabilizing transformation based on noise estimation is used to make noise reduction under the additive Gaussian noise model. Experiments with the real hyperspectral data set indicate that the proposed strategy can work well in both of detail preservation and noise removal.","Noise,
Noise reduction,
Silicon,
Estimation,
Hyperspectral imaging,
Correlation"
Secure Communication in the Low-SNR Regime,"Secrecy capacity of a multiple-antenna wiretap channel is studied in the low signal-to-noise ratio (SNR) regime. Expressions for the first and second derivatives of the secrecy capacity with respect to SNR at SNR = 0 are derived. Transmission strategies required to achieve these derivatives are identified. In particular, it is shown that it is optimal in the low-SNR regime to transmit in the maximal-eigenvalue eigenspace of φ = Hm† Hm - Nm/Ne He†He where Hm and He denote the channel matrices associated with the legitimate receiver and eavesdropper, respectively, and Nm and Ne are the noise variances at the receiver and eavesdropper, respectively. Energy efficiency is analyzed by finding the minimum bit energy required for secure and reliable communications, and the wideband slope. Increased bit energy requirements under secrecy constraints are quantified. Finally, the impact of fading is investigated, and the benefits of fading in terms of energy efficiency are shown.","Signal to noise ratio,
Covariance matrix,
Fading,
Receivers,
Transmitters,
Optimization,
Channel models"
Side Information and Noise Learning for Distributed Video Coding Using Optical Flow and Clustering,"Distributed video coding (DVC) is a coding paradigm that exploits the source statistics at the decoder side to reduce the complexity at the encoder. The coding efficiency of DVC critically depends on the quality of side information generation and accuracy of noise modeling. This paper considers transform domain Wyner-Ziv (TDWZ) coding and proposes using optical flow to improve side information generation and clustering to improve the noise modeling. The optical flow technique is exploited at the decoder side to compensate for weaknesses of block-based methods, when using motion-compensation to generate side information frames. Clustering is introduced to capture cross band correlation and increase local adaptivity in the noise modeling. This paper also proposes techniques to learn from previously decoded WZ frames. Different techniques are combined by calculating a number of candidate soft side information for low density parity check accumulate decoding. The proposed decoder side techniques for side information and noise learning (SING) are integrated in a TDWZ scheme. On test sequences, the proposed SING codec robustly improves the coding efficiency of TDWZ DVC. For WZ frames using a GOP size of 2, up to 4-dB improvement or an average (Bjøntegaard) bit-rate savings of 37% is achieved compared with DISCOVER.","Noise,
Decoding,
Optical imaging,
Correlation,
Video coding,
Adaptation models,
Optical noise"
Echo Model Analyses and Imaging Algorithm for High-Resolution SAR on High-Speed Platform,"The “stop-go” approximation is widely used for the processing of synthetic aperture radar (SAR) data, and the error brought by this assumption can be negligible for most SAR systems. However, for the SAR on a high-speed platform, with the increasing requirements on high-resolution imaging, the error may be intolerable for SAR imaging. In this case, the radar motion within a pulse repetition interval should be taken into account for the echo model and imaging algorithm. In this paper, according to the geometric configuration of the SAR working process, an accurate echo model is presented. By comparing the “stop-go” echo (which denotes the echo based on the “stop-go” approximation in this paper) with the accurate echo, the error brought by the “stop-go” approximation is introduced, and the intolerable error is shown in a reference system. A spotlight imaging algorithm based on the accurate echo is given and is well supported by the simulation results.","Approximation methods,
Delay effects,
Azimuth,
Imaging,
Approximation algorithms,
Spaceborne radar"
Real-Time Visualization System of Magnetic Field Utilizing Augmented Reality Technology for Education,"In electromagnetics education, it is important for beginners, who start to learn electromagnetics, to give an illustration of magnetic field. In this paper we propose a new real-time visualization system. It can visualize a composite image of source materials and their generated magnetic field utilizing the Augmented Reality technique to the users. With this real-time visualization system, electromagnetics learners can observe the visualized magnetic field as a realistic magnetic distribution on real-time and the visualized field changes immediately they move the objects.",
MIMO Zero-Forcing Detection Analysis for Correlated and Estimated Rician Fading,"Experimental modeling of wireless fading channels performed by the WINNER II project has been shown to fit a Rician rather than Rayleigh distribution, the latter being assumed in many analytical studies of multiple-input-multiple-output (MIMO) communication systems. Unfortunately, a Rician MIMO channel matrix has a nonzero mean (i.e., specular component) that yields, for the matrix product that determines the MIMO performance, a noncentral Wishart distribution that is difficult to analyze. Previously, the noncentral Wishart distribution has been approximated, based on a first-order-moment fit, by a central Wishart distribution and used to derive average error probability (AEP) expressions for zero-forcing (ZF) detection. We first reveal that this approximation and the MIMO performance evaluation tools derived from it may be reliable only for rank-one specular matrices. We then exploit this approximation to derive an AEP expression for a lesser known, yet optimal, MIMO ZF approach that, unlike the conventional approach, accounts for channel estimation accuracy through the channel statistics. After validating this AEP expression for the rank-one case, it is shown that the ZF performance averaged over realistic (i.e., WINNER II) distributions of the Rician K-factor and azimuth spread (AS) can be much worse than that for the average K and AS. Finally, through simulations, it is shown that the optimal detection approach can substantially outperform the conventional approach for ZF for full-rank specular matrices, as well as for minimum mean square error detection for both rank-one and full-rank specular matrices.","Rician channels,
Approximation methods,
Fading,
Channel estimation,
Accuracy,
Correlation"
A New Universal Isolated Converter for Grid Connection,"This paper proposes an isolated universal-link ac-ac power converter suitable for grid connection. The proposed power converter can have multiple ports to connect various loads or electric energy sources, and the configuration can be arranged according to the situation. The proposed power converter does not need to employ the large interface inductor at input side and the huge electrolytic capacitor at dc link. Moreover, it utilizes high-frequency transformers for the galvanic isolation instead of bulky line-frequency transformers. These characteristics of the proposed power converter result in the reduction of the system volume and weight remarkably. The proposed power converter is the modular structure, and an H-bridge works as a basic module of the converter. By stacking the modules, the power converter can be adapted to the high-voltage grid and the various types of loads and/or sources. This paper addresses the structure of the proposed power converter and the fundamental principle of power flow. The operation of the proposed converter is verified by both computer simulations and experimental results with a laboratory-level prototype system.","Inverters,
Bridge circuits,
Rectifiers,
Topology,
Capacitors,
Switches,
Renewable energy resources"
Informing the Design of Proxemic Interactions,"Proxemic interactions can help address six key challenges of ubicomp interaction design and how devices can sense or capture proxemic information via five dimensions-distance, orientation, movement, identity, and location.",
Identification of Coulomb Friction-Impeded Systems With a Triple-Relay Feedback Apparatus,"This paper aims to identify friction-impeded servo-mechanical systems using a time-domain based approach with a multiple-relay feedback apparatus. By converting the closed-loop system into a triple-relay feedback system, switching conditions of a stable limit cycle are obtained. Following by this, stable oscillations are excited by choosing suitable relay gains. Hence, the level of Coulomb friction and other linear parameters are identified by numerically solving a set of equations with data from just a single limit cycle experiment. This method is also robust to measurement noise. Simulation and real-time experiments on a DC motor show the practical appeal of the proposed method.","Relays,
Limit-cycles,
Switches,
Oscillators,
Friction,
Noise,
Stability analysis"
Technology scaling and soft error reliability,This paper discusses several attributes of integrated circuit scaling in relation to radiation soft error failure modes and vulnerability.,"Switches,
Inverters,
Logic gates,
CMOS integrated circuits,
MOS devices,
CMOS technology,
Sensitivity"
Improving crowd-sourced Wi-Fi localization systems using Bluetooth beacons,"Crowd-sourced Wi-Fi-based localization systems utilize user input for RF scene analysis and map construction. Such systems reduce the deployment cost and privacy concerns that expert-based site survey systems can create. However, the main bottleneck of such crowd-sourcing localization systems is a bootstrapping stage, where lack of contributions by users results in no accuracy guarantee and frequent unnecessary prompting for users' input, even for explored areas. In this paper, we propose a crowd-sourcing localization system that uses both Wi-Fi scene analysis and Bluetooth beacons to address the insufficient contribution challenge. After prompting for user input, the mobile device not only submits Wi-Fi fingerprint to a map server, but also enables Bluetooth beacons to disseminate/share its location and fingerprint information to quickly populate the signal map. Then, subsequent user devices entering the area can discover the Bluetooth beacons and are able to instantly obtain room-level location information without causing unnecessary prompting to users. We implement our proposed system in the Linux OS and evaluate the prototype extensively through both experiments and simulation. Our evaluation results show that using Bluetooth beacons help to improve signal map growth, while maintaining reasonable localization accuracy.","Bluetooth,
IEEE 802.11 Standards,
Accuracy,
Measurement,
Mobile handsets,
Image analysis,
Interference"
Reinforcement learning control based on multi-goal representation using hierarchical heuristic dynamic programming,We are interested in developing a multi-goal generator to provide detailed goal representations that help to improve the performance of the adaptive critic design (ACD). In this paper we propose a hierarchical structure of goal generator networks to cascade external reinforcement into more informative internal goal representations in the ACD. This is in contrast with previous designs in which the external reward signal is assigned to the critic network directly. The ACD control system performance is evaluated on the ball-and-beam balancing benchmark under noise-free and various noisy conditions. Simulation results in the form of a comparative study demonstrate effectiveness of our approach.,
Early detection of the Pedestrian's intention to cross the street,"This paper focuses on monocular-video-based stationary detection of the pedestrian's intention to enter the traffic lane. We propose a motion contour image based HOG-like descriptor, MCHOG, and a machine learning algorithm that reaches the decision at an accuracy of 99% within the initial step at the curb of smart infrastructure. MCHOG implicitly comprises the body language of gait initiation, especially the body bending and the spread of legs. In a case study at laboratory conditions we present ROC performance data and an evaluation of the span of time necessary for recognition. While MCHOG in special cases indicates detection of the intention before the whole body moves, on average it allows for detection of the movement within 6 frames at a frame rate of 50 Hz and an accuracy of 80%. Feasibility of the method in a real world intersection scenario is demonstrated.","Legged locomotion,
Roads,
Support vector machines,
Accuracy,
Humans,
Image edge detection,
Vehicles"
Adaptation in Dynamic Environments: A Case Study in Mission Planning,"Many random events usually are associated with executions of operational plans at various companies and organizations. For example, some tasks might be delayed and/or executed earlier. Some operational constraints can be introduced due to new regulations or business rules. In some cases, there might be a shift in the relative importance of objectives associated with these plans. All these potential modifications create a huge pressure on planning staff for generating plans that can adapt quickly to changes in environment during execution. In this paper, we address adaptation in dynamic environments. Many researchers in evolutionary community addressed the problem of optimization in dynamic environments. Through an overview on applying evolutionary algorithms for solving dynamic optimization problems, we classify the paper into two main categories: 1) finding/tracking optima, and 2) adaptation and we discuss their relevance for solving planning problems. Based on this discussion, we propose a computational approach to adaptation within the context of planning. This approach models the dynamic planning problem as a multiobjective optimization problem and an evolutionary mechanism is incorporated; this adapts the current solution to new situations when a change occurs. As the multiobjective model is used, the proposed approach produces a set of non-dominated solutions after each planning cycle. This set of solutions can be perceived as an information-rich data set which can be used to support the adaptation process against the effect of changes. The main question is how to exploit this set efficiently. In this paper, we propose a method based on the concept of centroids over a number of changing-time steps; at each step we obtain a set of non-dominated solutions. We carried out a case study on this proposed approach. Mission planning was used for our experiments and experimental analysis. We selected mission planning as our test environment because battlefields are always highly dynamic and uncertain and can be conveniently used to demonstrate different types of changes, especially time-varying constraints. The obtained results support the significance of our centroid-based approach.",
Design methodology for sample preparation on digital microfluidic biochips,"Recent advances in digital microfluidic biochips have led to a promising future for miniaturized laboratories, with the associated advantages of high sensitivity and reconfigurability. As one of the front-end operations on digital microfluidic biochips, sample preparation plays an important role in biochemical assays and applications. For fast and high-throughput biochemical applications, it is critical to develop an automated design methodology for sample preparation. Prior work in this area does not provide solutions to the problem of design automation for sample preparation. Moreover, it is critical to ensure the correctness of droplets and recover from errors efficiently during sample preparation. Published work on error recovery is inefficient and impractical for sample preparation. Therefore, in this paper, we present an automated design methodology for sample preparation, including architectural synthesis, layout synthesis, and dynamic error recovery. The proposed algorithm is evaluated on real-life biochemical applications to demonstrate its effectiveness and efficiency. Compared to prior work, the proposed algorithm can achieve up to 48.39% reduction in sample preparation time.","Layout,
Heuristic algorithms,
Mixers,
Sensors,
System-on-a-chip,
Proteins"
Contrast-Enhanced Fusion of Multisensor Images Using Subband-Decomposed Multiscale Retinex,"In this paper, we propose a novel pixel-level multisensor image fusion algorithm with simultaneous contrast enhancement. In order to accomplish both image fusion and contrast enhancement simultaneously, we suggest a modified framework of the subband-decomposed multiscale retinex (SDMSR), our previous contrast enhancement algorithm. This framework is based on a fusion strategy that reflects the multiscale characteristics of the SDMSR well. We first apply two complementary intensity transfer functions to source images in order to effectively utilize hidden information in both shadows and highlights in the fusion process. We then decompose retinex outputs into nearly nonoverlapping spectral subbands. The decomposed retinex outputs are then fused subband-by-subband, by using global weighting as well as local weighting to overcome the limitations of the pixel-based fusion approach. After the fusion process, we apply a space-varying subband gain to each fused SD retinex output according to the subband characteristic so that the contrast of the fused image can be effectively enhanced. In addition, in order to effectively manage artifacts and noise, we make the degree of enhancement of fused details adjustable by improving a detail adjustment function. From experiments with various multisensor image pairs, the results clearly demonstrate that even if source images have poor contrast, the proposed algorithm makes it possible to generate a fused image with highly enhanced contrast while preserving visually salient information contained in the source images.","Image fusion,
Lighting,
Transforms,
Image enhancement,
Radio access networks,
RNA,
Charge coupled devices"
Multicast Service-Oriented Virtual Network Embedding in Wireless Mesh Networks,"Multicast is used in numerous real-time applications which have high demand on quality of service (QoS). When a number of multicast applications are deployed in a wireless mesh network (WMN), network virtualization technology can be used to guarantee the QoS for each application. Since wireless links are unreliable, packet loss is inevitable when the multicast service-oriented virtual networks (VNs) are embedded into a WMN. Although multicast allows the occurrence of packet loss, it is still important to ensure the packet loss rate is below a certain level for QoS guarantee. In this letter, we propose a novel approach, referred to as WELL, to settle the problem of embedding multicast VNs with reliability constraints into a WMN with lossy links. Through opportunistic rebroadcast, WELL minimizes the activation time of the VNs while satisfying their reliability constraints. Simulation results reveal that WELL dramatically outperforms both pure broadcast and unicast based solutions.",
A High-Q Terahertz Resonator for the Measurement of Electronic Properties of Conductors and Low-Loss Dielectrics,The successful engineering of sources and components in the terahertz (THz) regime benefits from good characterization of materials properties. Previous research reports have shown that calculations of material parameters that are valid at radio frequencies are no longer accurate at THz frequencies. A high-quality-factor quasi-optical hemispherical resonator operating between 300 GHz-1 THz has been designed and implemented for the measurement of electronic properties of conductors as well as low-loss dielectrics. This apparatus is the first quasi-optical resonator to achieve Q≈ 4×105 at frequencies greater than 400 GHz in the THz regime. It is also the first open resonator designed to measure effective conductivity at these frequencies. This paper discusses the techniques that enabled high-Q operation in the THz regime. It also includes measurements of silicon with different doping densities and conductors of various surface roughness values with comparison to theoretical predictions.,"Optical resonators,
Mirrors,
Resonant frequency,
Couplings,
Loss measurement,
Dielectric measurements,
Frequency measurement"
Investigating Internal Gettering of Iron at Grain Boundaries in Multicrystalline Silicon via Photoluminescence Imaging,"In this paper, we present measurements and modeling of the reduction in dissolved iron Fe; concentrations near grain boundaries in multicrystalline silicon (mc-Si) wafers. The measurements of the interstitial Fe concentrations are obtained via photoluminescence images taken before and after iron-boron pair dissociation. A simple diffusion-capture model was developed to characterize the removal of interstitial Fe by the gettering sites. The model is based on a numerical solution to the 1-D diffusion equation with two fitting parameters: the diffusion length of dissolved Fe atoms and the effective gettering velocity at the gettering site. By comparing the simulation with a controlled phosphorous gettering process, the model is shown to give good estimation of the diffusion length of Fe atoms. For as-cut multicrystalline silicon wafers from different parts of the ingot, that is, wafers with different average dissolved Fe concentrations [Fei], the diffusion lengths of Fe atoms are found to decrease with decreasing average [Fei] This suggests the presence of relaxation precipitation during the internal gettering of dissolved Fe by the grain boundaries in mc-Si during ingot cooling.",
Distributed Covariance Estimation in Gaussian Graphical Models,"We consider distributed estimation of the inverse covariance matrix in Gaussian graphical models. These models factorize the multivariate distribution and allow for efficient distributed signal processing methods such as belief propagation (BP). The classical maximum likelihood approach to this covariance estimation problem, or potential function estimation in BP terminology, requires centralized computing and is computationally intensive. This motivates suboptimal distributed alternatives that tradeoff accuracy for communication cost. A natural solution is for each node to perform estimation of its local covariance with respect to its neighbors. The local maximum likelihood estimator is asymptotically consistent but suboptimal, i.e., it does not minimize mean squared estimation (MSE) error. We propose to improve the MSE performance by introducing additional symmetry constraints using averaging and pseudolikelihood estimation approaches. We compute the proposed estimates using message passing protocols, which can be efficiently implemented in large scale graphical models with many nodes. We illustrate the advantages of our proposed methods using numerical experiments with synthetic data as well as real world data from a wireless sensor network.",
Sensitivity Analysis of Server Virtualized System Availability,"Server virtualization is a technology used in many enterprise systems to reduce operation and acquisition costs, and increase the availability of their critical services. Virtualized systems may be even more complex than traditional nonvirtualized systems; thus, the quantitative assessment of system availability is even more difficult. In this paper, we propose a sensitivity analysis approach to find the parameters that deserve more attention for improving the availability of systems. Our analysis is based on Markov reward models, and suggests that host failure rate is the most important parameter when the measure of interest is the system mean time to failure. For capacity oriented availability, the failure rate of applications was found to be another major concern. The results of both analyses were cross-validated by varying each parameter in isolation, and checking the corresponding change in the measure of interest. A cost-based optimization method helps to highlight the parameter that should have higher priority in system enhancement.",
A Fully Decentralized Multi-Agent System for Intelligent Restoration of Power Distribution Network Incorporating Distributed Generations [Application Notes],"In the distribution network fault management, service restoration is a very important component. When a fault occurs, it is necessary to restore power to these deenergized loads as soon as possible. The restoration problem could be formulated as a multilevel, multi-objective optimization problem with constraints [1].","Multiagent systems,
Fault diagnosis,
Power system restoration,
Power distribution"
Novel 2-D MMSE Subpixel-Based Image Down-Sampling,"Subpixel-based down-sampling is a method that can potentially improve apparent resolution of a down-scaled image on LCD by controlling individual subpixels rather than pixels. However, the increased luminance resolution comes at price of chrominance distortion. A major challenge is to suppress color fringing artifacts while maintaining sharpness. We propose a new subpixel-based down-sampling pattern called diagonal direct subpixel-based down-sampling (DDSD) for which we design a 2-D image reconstruction model. Then, we formulate subpixel-based down-sampling as a MMSE problem and derive the optimal solution called minimum mean square error for subpixel-based down-sampling (MMSE-SD). Unfortunately, straightforward implementation of MMSE-SD is computational intensive. We thus prove that the solution is equivalent to a 2-D linear filter followed by DDSD, which is much simpler. We further reduce computational complexity using a small k × k filter to approximate the much larger MMSE-SD filter. To compare the performances of pixel and subpixel-based down-sampling methods, we propose two novel objective measures: normalized l1 high frequency energy for apparent luminance sharpness and PSNRU(V) for chrominance distortion. Simulation results show that both MMSE-SD and MMSE-SD(k) can give sharper images compared with conventional down-sampling methods, with little color fringing artifacts.",
Thermal Phase Noise Measurements in Optical Fiber Interferometers,"We present measurement data of fundamental thermal noise in a 40-m fiber optic Mach-Zehnder interferometer (MZI) using 80-μm-diameter optical fiber. To extend the measurements to low frequencies (below 500 Hz), the experimental setup is carefully designed to minimize ambient noise, thermal drift, and the phase and amplitude noise of the lasers. These experimental results are compared with theoretical predictions for the magnitude of the fundamental thermal noise in fiber, due to both thermodynamic temperature fluctuations and spontaneous length fluctuations. The experimental data, using two different solid-state lasers with two different emission wavelengths (1319 and 1550 nm), is in reasonable agreement with both theories over frequencies ranging from 20 Hz to 100 kHz. In terms of strain resolution, this paper demonstrates a fundamental thermal noise limit of approximately one femtostrain/rt(Hz) for a 40-m fiber optic MZI.","Phase noise,
Thermal noise,
Optical fiber theory,
Optical fiber sensors,
Noise measurement"
Single-Event Response of the SiGe HBT Operating in Inverse-Mode,"The single-event effect sensitivity of inverse-mode biased SiGe HBTs in both bulk and SOI technology platforms are investigated, for the first time, using digital circuits and stand-alone device test structures. Comparisons of heavy-ion broad beam data of shift register circuits constructed with forward-mode and inverse-mode biased SiGe HBTs from a first-generation, complementary SOI SiGe BiCMOS process, reveal an improvement in SEU mitigation for the inverse-mode shift register architecture. Full 3D TCAD simulations highlight the differences in transient current origination between forward and inverse-mode biased devices, illustrating the impact of doping profiles on ion-induced shunt duration. To extend the analysis to a bulk platform, new fourth-generation npn , SiGe HBTs were biased in both the forward and inverse-mode and irradiated at NRL using the two photon absorption measurement system. These measurements support the analysis of transient origination using 3D TCAD simulations. Furthermore, the isolation of the output terminal from the sensitive subcollector-substrate junction is experimentally demonstrated for the inverse-mode bias. Fully coupled mixed-mode simulations predict a significant reduction in sensitive area for inverse-mode shift registers built in a bulk SiGe platform.","Silicon germanium,
Shift registers,
Transient analysis,
Heterojunction bipolar transistors,
Single event upset,
Radiation hardening"
Active User-Side Evil Twin Access Point Detection Using Statistical Techniques,"In this paper, we consider the problem of “evil twin” attacks in wireless local area networks (WLANs). An evil twin is essentially a rogue (phishing) Wi-Fi access point (AP) that looks like a legitimate one (with the same SSID). It is set up by an adversary, who can eavesdrop on wireless communications of users' Internet access. Existing evil twin detection solutions are mostly for wireless network administrators to verify whether a given AP is in an authorized list or not, instead of for a wireless client to detect whether a given AP is authentic or evil. Such administrator-side solutions are limited, expensive, and not available for many scenarios. Thus, a lightweight, effective, and user-side solution is highly desired. In this work, we propose a novel user-side evil twin detection technique that outperforms traditional administrator-side detection methods in several aspects. Unlike previous approaches, our technique does not need a known authorized AP/host list, thus it is suitable for users to identify and avoid evil twins. Our technique does not strictly rely on training data of target wireless networks, nor depend on the types of wireless networks. We propose to exploit fundamental communication structures and properties of such evil twin attacks in wireless networks and to design new active, statistical and anomaly detection algorithms. Our preliminary evaluation in real-world widely deployed 802.11b and 802.11 g wireless networks shows very promising results. We can identify evil twins with a very high detection rate while maintaining a very low false positive rate.","Servers,
Wireless networks,
Communication system security,
IEEE 802.11 Standards,
Internet,
Protocols"
A Geometric Approach to Low-Rank Matrix Completion,"The low-rank matrix completion problem can be succinctly stated as follows: given a subset of the entries of a matrix, find a low-rank matrix consistent with the observations. While several low-complexity algorithms for matrix completion have been proposed so far, it remains an open problem to devise -type search procedures with provable performance guarantees. The standard approach to the problem, which involves the minimization of an objective function defined using the Frobenius metric, has inherent difficulties: the objective function is not continuous and the solution set is not closed. To address this problem, we consider an optimization procedure that searches for a column (or row) space that is geometrically consistent with the partial observations. The geometric objective function is continuous everywhere and the solution set is the closure of the solution set of the Frobenius metric. We also preclude the existence of local minimizers, and hence establish strong performance guarantees, for special completion scenarios, which do not require matrix incoherence and hold with probability one for arbitrary matrix size.","Vectors,
Measurement,
Sparse matrices,
Manifolds,
Optimization,
Matrix decomposition,
Search problems"
Multiple Model Adaptive Mixing Control: The Discrete-Time Case,"Most of the work in multiple model adaptive control with various forms of switching focused on continuous-time systems. The purpose of this technical note is to extend the results of one approach, the adaptive mixing control (AMC), to discrete-time systems. Further, the technical note solves the tracking problem which has not been addressed in most schemes of this class. Stability and robustness properties of the AMC scheme for discrete-time systems are analyzed. It is shown that in the ideal case, when no disturbances or unmodeled dynamics are present, the tracking error converges to zero. In the non ideal case, the mean-square tracking error is of the order of magnitude of the modeling error provided the unmodeled dynamics satisfy a norm-bound condition. While these robustness results are conceptually similar to those of traditional robust adaptive control, the proposed scheme does not suffer from the drawback of stabilizability of the estimated plant and in addition performs much better in simulation studies. Furthermore, it allows well developed results from robust control to be incorporated in the design.",
Exact In-Network Aggregation with Integrity and Confidentiality,"In-network aggregation reduces the energy cost of processing aggregate queries (such as SUM, MAX, etc.) in wireless sensor networks. Recently, research has focused on secure in-network aggregation, motivated by the following two scenarios: 1) the sensors are deployed in open and unsafe environments, and 2) the aggregation process is outsourced to an untrustworthy service. Despite the bulk of work on the topic, there is currently no solution providing both integrity and confidentiality in the above scenarios. Moreover, existing solutions either return approximate results, or have limited applicability to certain types of aggregate queries. Our paper is the first work that provides both integrity and confidentiality in the aforementioned scenarios, while covering a wide range of aggregates and returning exact results. We initially present SIES, a scheme that solves exact SUM queries through a combination of homomorphic encryption and secret sharing. Subsequently, we show how to adapt SIES in order to support many other exact aggregate queries (such as MAX, MEDIAN, etc.). Finally, we augment our schemes with a functionality that identifies malicious sensors, preventing denial-of-service (DoS) attacks and attributing robustness to the system. Our techniques are lightweight and induce very small bandwidth consumption. Therefore, they constitute ideal solutions for resource-constrained sensors.",
Proactive Insider Threat Detection through Graph Learning and Psychological Context,"The annual incidence of insider attacks continues to grow, and there are indications this trend will continue. While there are a number of existing tools that can accurately identify known attacks, these are reactive (as opposed to proactive) in their enforcement, and may be eluded by previously unseen, adversarial behaviors. This paper proposes an approach that combines Structural Anomaly Detection (SA) from social and information networks and Psychological Profiling (PP) of individuals. SA uses technologies including graph analysis, dynamic tracking, and machine learning to detect structural anomalies in large-scale information network data, while PP constructs dynamic psychological profiles from behavioral patterns. Threats are finally identified through a fusion and ranking of outcomes from SA and PP. The proposed approach is illustrated by applying it to a large data set from a massively multi-player online game, World of War craft (WoW). The data set contains behavior traces from over 350,000 characters observed over a period of 6 months. SA is used to predict if and when characters quit their guild (a player association with similarities to a club or workgroup in non-gaming contexts), possibly causing damage to these social groups. PP serves to estimate the five-factor personality model for all characters. Both threads show good results on the gaming data set and thus validate the proposed approach.","Psychology,
Hidden Markov models,
Data models,
Social network services,
Games,
Semantics,
Context"
Brushless doubly-fed reluctance machine rotor design,"This paper investigates the rotor design factors that impact the performance of brushless doubly-fed reluctance machines (BDFRMs). The performance of the BDFRM relies on the ability of the rotor structure to modulate stator magnetic fields so that magnetic coupling occurs between stator windings that do not otherwise interact. This paper investigates those factors that create the desired magnetic coupling and those that can cause undesirable magnetic performance. Theoretical analysis is compared to test results from an early prototype BDFRM and then applied to the design of a new BDFRM. New designs are explored using Finite Element Analysis. A prototype, based on these investigations is under construction.","Rotors,
Windings,
Stator windings,
Couplings,
Air gaps,
Reluctance machines"
A Multialgorithm Analysis of Three Iris Biometric Sensors,"The issue of interoperability between iris sensors is an important topic in large-scale and long-term applications of iris biometric systems. This work compares three commercially available iris sensors and three iris matching systems and investigates the impact of cross-sensor matching on system performance in comparison to single-sensor performance. Several factors which may impact single-sensor and cross-sensor performance are analyzed, including changes in the acquisition environment and differences in dilation ratio between iris images. The sensors are evaluated using three different iris matching algorithms, and conclusions are drawn regarding the interaction between the sensors and the matching algorithm in both the cross-sensor and single-sensor scenarios. Finally, the relative performances of the three sensors are compared.","Iris recognition,
Lighting,
Biosensors,
Cameras,
Context,
Software"
A chunk caching location and searching scheme in Content Centric Networking,"Content Centric Networking (CCN) is a new network infrastructure around content dissemination and retrieval, shift from host addresses to named data. Each CCN router has a cache to store the chunks passed by it. Therefore the caching strategy about chunk placement can greatly affect the whole CCN performance. This paper proposes an implicit coordinate chunk caching location and searching scheme (CLS) in CCN hierarchical infrastructure. In CLS, there is at most one copy of a chunk cached on the path between a server and a leaf router. This copy is pulled down one level towards the leaf router by a request or pushed up one level towards the server by the cache eviction. Thus, it is possible to store more diverse contents in the whole CCN and improve the network performance. Plus, in order to reduce the server workload and file download time, a caching trail of chunk is created to direct the following request where to find the chunk. Extensive test-bed experiments have been performed to evaluate the proposed scheme in terms of a wide range of performance metrics. The results show that the proposed scheme outperforms existing algorithms.","Servers,
Routing,
Algorithm design and analysis,
Face,
Internet,
Bandwidth"
Thin Cloud Detection of All-Sky Images Using Markov Random Fields,"Thin cloud detection for all-sky images is a challenge in ground-based sky-imaging systems because of low contrast and vague boundaries between cloud and sky regions. We treat cloud detection as a labeling problem based on the Markov random field model. In this model, each pixel is represented by a combined-feature vector that aims at improving the disparity between thin cloud and sky. The distribution of each label in the feature space is defined as a Gaussian model. Spatial information is coded by a generalized Potts model. During the estimation, thin cloud is detected by minimizing the posterior energy with an iterative procedure. Both subjective and objective evaluation results demonstrate higher accuracy of the algorithm compared with some other algorithms.","Clouds,
Estimation,
Feature extraction,
Image segmentation,
Detection algorithms,
Markov processes,
Image color analysis"
Heavy-Ion-Induced Current Transients in Bulk and SOI FinFETs,"Measured heavy-ion induced current transients are compared for two different junction contact schemes (dumbbell and saddle) in bulk FinFETs. Devices with saddle contacts collect 17% less charge than their counterparts with dumbbell contacts. Transient shunt effects are observed in both bulk and SOI FinFETs with saddle contacts. SOI FinFETs with saddle contacts collect twice as much charge as that generated in the fin. The substrate bias has a large effect on the SOI devices, with the maximum amounts of charge collected when the substrate is negatively biased.","FinFETs,
Single event transient,
Silicon on insulator technology"
Maximum Power Point Tracking for Ocean Wave Energy Conversion,"Many forms of renewable energy exist in the world's oceans, with ocean wave energy showing great potential. However, the ocean environment presents many challenges for cost-effective renewable energy conversion, including optimal control of a wave energy converter (WEC). This paper presents a maximum power point tracking (MPPT) algorithm for control of a point absorber WEC. The algorithm and testing hardware are presented in detail, as well as simulated and laboratory test results. The results show that MPPT applied to ocean wave energy is an effective and promising control strategy.","Generators,
Ocean waves,
Testing,
Hardware,
Data acquisition,
Surface waves,
Energy conversion"
Logics of Dynamical Systems,"We study the logic of dynamical systems, that is, logics and proof principles for properties of dynamical systems. Dynamical systems are mathematical models describing how the state of a system evolves over time. They are important in modeling and understanding many applications, including embedded systems and cyber-physical systems. In discrete dynamical systems, the state evolves in discrete steps, one step at a time, as described by a difference equation or discrete state transition relation. In continuous dynamical systems, the state evolves continuously along a function, typically described by a differential equation. Hybrid dynamical systems or hybrid systems combine both discrete and continuous dynamics. This is a brief survey of differential dynamic logic for specifying and verifying properties of hybrid systems. We explain hybrid system models, differential dynamic logic, its semantics, and its axiomatization for proving logical formulas about hybrid systems. We study differential invariants, i.e., induction principles for differential equations. We briefly survey theoretical results, including soundness and completeness and deductive power. Differential dynamic logic has been implemented in automatic and interactive theorem provers and has been used successfully to verify safety-critical applications in automotive, aviation, railway, robotics, and analogue electrical circuits.","Differential equations,
Acceleration,
Semantics,
Mathematical model,
Automata,
Vehicle dynamics,
Complexity theory"
Approximating line losses and apparent power in AC power flow linearizations,"The linearized DC model is widely used in optimization of power systems but few studies evaluate the accuracy and feasibility of its solutions. This paper studies the source of errors in the linearized DC model and proposes three new models to improve its accuracy. In particular, it proposes a cold-start model capturing line losses and hot-starts models for approximating apparent power and more accurate phase angles. All of the models are linear programs and can easily be used as a building block for more complex applications. Experimental results on well-known benchmarks show the significant benefits in accuracy of the new models and the high correlation of their solutions with AC solutions.","Mathematical model,
Accuracy,
Load flow,
Load modeling,
Approximation methods,
Equations"
Self-learning demand side management for a heterogeneous cluster of devices with binary control actions,"Finding an optimal planning for a large cluster of devices with binary control actions is a challenging task for both centralized and distributed approaches. This is certainly the case when a significant fraction of devices in the cluster has binary control actions, since the resulting optimization problem belongs to NP-hard integer programming. A distributed approach can be a good solution to address this problem. Good performance however, often relies on the presence of local intelligence, such as planning and prediction at device or household level. In this work we apply a self-learning agent-based demand side management approach to a heterogeneous cluster of devices with binary control actions. The required local intelligence is limited to a state estimation and local comfort and constraint checking. Each device is represented by an individual agent communicating a bid function to a virtual energy market. In the approach the aggregated energy and power constraints of a cluster of devices are learned, independent of the type and number of devices. The aggregated constraints are estimated based upon the aggregated bid functions. These constraints are used to determine an optimal control signal managing the cluster. The approach has been evaluated in two distinct scenario's including devices with binary control actions, showing that the self-learning approach converges within 12 days to obtain 80 % of the maximum optimization potential, with a generic approach that requires limited intelligence at device level.","Boilers,
Optimization,
Performance evaluation,
Clustering algorithms,
System-on-a-chip,
State estimation,
Optimal control"
Online Set Point Modulation to Enhance Microgrid Dynamic Response: Theoretical Foundation,The need for higher degree of infrastructure utilization of the electric power system inevitably results in its operation closer to the limits. This in turn places the burden on control and protection strategies to ensure the constraints are not violated. This is especially imperative in microgrids in which resources are more limited and constraints are tighter. This paper presents an adaptive control strategy to augment the existing controllers and enhance their performance. This strategy monitors the response of a controlled device and temporarily modulates its control set point to achieve close tracking of the set point in the presence of disturbances. A detailed analytical derivation for the case that the overall behavior of the system (the devices and its controller) is approximated with a second-order transfer function is presented to confirm the viability of this strategy and its ability in designing a response with limited over- or undershoot.,"Transient response,
Modulation,
Transfer functions,
Microgrids,
Damping,
Smart grids"
Degrees of Freedom Region for an Interference Network With General Message Demands,"We consider a single-hop interference network with K transmitters and J receivers, all having M antennas. Each transmitter emits an independent message and each receiver requests an arbitrary subset of the messages. This generalizes the well-known K -user M-antenna interference channel, where each message is requested by a unique receiver. For our setup, we derive the degrees of freedom (DoF) region. The achievability scheme generalizes the interference alignment schemes proposed by Cadambe and Jafar. In particular, we achieve general points in the DoF region by using multiple base vectors and aligning all interferers at a given receiver to the interferer with the largest DoF. As a byproduct, we obtain the DoF region for the original interference channel. We also discuss extensions of our approach where the same region can be achieved by considering a reduced set of interference alignment constraints, thus reducing the time-expansion duration needed. The DoF region for the considered system depends only on a subset of receivers whose demands meet certain characteristics. The geometric shape of the DoF region is also discussed.","Receivers,
Vectors,
Array signal processing,
Transmitting antennas,
Interference channels"
Exploiting New Interconnect Technologies in On-Chip Communication,"The continuing scaling of transistors has increased the number of cores available in current processors, and the number of cores is expected to continue to increase. In such many core processors, the communication between cores with the on-chip interconnect is becoming a challenge as it not only must provide low latency and high bandwidth but also needs to be cost-effective in terms of power consumption. The communication challenge is not only within a single chip but providing high bandwidth to the increasing number of cores from off-chip memory is also a challenge. The conventional metal interconnect is limited, especially for global communication, and can not scale efficiently. In this paper, we investigate alternative interconnect technologies that can be exploited to address the communication challenges in future many core processor. We provide an overview of the different technologies that are available and then, investigate how these interconnect technologies impact the architecture of the on-chip communication and the system design.","System-on-a-chip,
Integrated circuit interconnections,
Three dimensional displays,
Bandwidth,
Wires,
Topology,
Optical waveguides"
A Concatenational Graph Evolution Aging Model,"Modeling the long-term face aging process is of great importance for face recognition and animation, but there is a lack of sufficient long-term face aging sequences for model learning. To address this problem, we propose a CONcatenational GRaph Evolution (CONGRE) aging model, which adopts decomposition strategy in both spatial and temporal aspects to learn long-term aging patterns from partially dense aging databases. In spatial aspect, we build a graphical face representation, in which a human face is decomposed into mutually interrelated subregions under anatomical guidance. In temporal aspect, the long-term evolution of the above graphical representation is then modeled by connecting sequential short-term patterns following the Markov property of aging process under smoothness constraints between neighboring short-term patterns and consistency constraints among subregions. The proposed model also considers the diversity of face aging by proposing probabilistic concatenation strategy between short-term patterns and applying scholastic sampling in aging prediction. In experiments, the aging prediction results generated by the learned aging models are evaluated both subjectively and objectively to validate the proposed model.","Aging,
Face,
Active appearance model,
Correlation,
Computational modeling,
Data models,
Muscles"
Junction-Level Thermal Analysis of 3-D Integrated Circuits Using High Definition Power Blurring,"The degraded thermal path of 3-D integrated circuits (3DICs) makes thermal analysis at the chip-scale an essential part of the design process. Performing an appropriate thermal analysis on such circuits requires a model with junction-level fidelity; however, the computational burden imposed by such a model is tremendous. In this paper, we present enhancements to two thermal modeling techniques for integrated circuits to make them applicable to 3DICs. First, we present a resistive mesh-based approach that improves on the fidelity of prior approaches by constructing a thermal model of the full structure of 3DICs, including the interconnect. Second, we introduce a method for dividing the thermal response caused by a heat load into a high fidelity “near response” and a lower fidelity “far response” in order to implement Power Blurring high definition (HD), a hierarchical thermal simulation approach based on Power Blurring that incorporates the resistive mesh-based models and allows for junction-level accuracy at the full-chip scale. The Power Blurring HD technique yields approximately three orders of magnitude of improvement in memory usage and up to six orders of magnitude of improvement in runtime for a three-tier synthetic aperture radar circuit, as compared to using a full-chip junction-scale resistive mesh-based model. Finally, measurement results are presented showing that Power Blurring high definition (HD) accurately determines the shape of the thermal profile of the 3DIC surface after a correction factor is added to adjust for a discrepancy in the absolute temperature values.","Integrated circuit modeling,
Transistors,
Heating,
Thermal conductivity,
Conductivity,
High definition video,
Mathematical model"
On Maximizing Delay-Constrained Coverage of Urban Vehicular Networks,"The success of a real-time sensing application with a vehicular network highly depends on the spatiotemporal coverage of sensing data that can be collected from the vehicular network. Deploying broadband wireless base stations is an effective way to collect vehicular sensing data and the deployment of base stations has a great impact on delay-constrained coverage. This paper considers the critical problem of base stations for maximizing delay-constrained coverage of an urban area achieved by the vehicular network. This is particularly challenging. We theoretically prove that the optimal deployment of base stations is NP-hard even when the future vehicular traces are assumed as a priori. In a realistic setting, however, the future vehicular traces cannot be known in advance. Therefore, the challenge is to incorporate high vehicle mobility and compute the base station deployment for maximizing the expected delay-constrained coverage. By mining a large dataset of real vehicular GPS traces, we show that there is strong regularity with vehicle mobility. With this important observation, we formulate a new objective of maximizing the expected sensing coverage. This takes random vehicle mobility into account and exploits the regularity in vehicle mobility. We develop greedy algorithms for base station deployment. The achieved sensing coverage of the proposed algorithm is guaranteed to be larger than (1-1/e) of the theoretical optimum. We have performed extensive simulations based on the real vehicular GPS trace dataset and conclusive results show that our algorithms achieve near optimal coverage of the urban area and significantly outperform alternative algorithms.","Sensors,
Vehicles,
Base stations,
Urban areas,
Roads,
Wireless sensor networks,
Spatiotemporal phenomena"
What Do We Know about Scientific Software Development's Agile Practices?,"The development of scientific software has similarities with processes that follow the software engineering ""agile manifesto"": responsiveness to change and collaboration are of utmost importance. But how well do current scientific software-development processes match the practices found in agile development methods, and what are the effects of using agile practices in such processes?",
Android: Static Analysis Using Similarity Distance,"As Android applications become increasingly ubiquitous, we need algorithms and tools to protect applications from product tampering and piracy, while facilitating valid product updates. Since it is easy to derive Java source code from Android byte code, Android applications are particularly vulnerable to tampering. This paper presents an algorithm, based on a customized similarity distance, which returns a value between 0 and 1, which can serve as a change indicator. Potential applications of the algorithm include 1) to determine if obfuscators, applied by developers, are protecting their code from piracy, 2) to determine if an Android application is infected with malware, facilitating the automatic extraction of the injected malware, and 3) to identify valid code updates and releases as part of the code release cycle.","Compressors,
Smart phones,
Humanoid robots,
Androids,
Java,
Algorithm design and analysis,
Clustering algorithms"
"Identification of Directed Influence: Granger Causality, Kullback-Leibler Divergence, and Complexity","Detecting and characterizing causal interdependencies and couplings between different activated brain areas from functional neuroimage time series measurements of their activity constitutes a significant step toward understanding the process of brain functions. In this letter, we make the simple point that all current statistics used to make inferences about directed influences in functional neuroimage time series are variants of the same underlying quantity. This includes directed transfer entropy, transinformation, Kullback-Leibler formulations, conditional mutual information, and Granger causality. Crucially, in the case of autoregressive modeling, the underlying quantity is the likelihood ratio that compares models with and without directed influences from the past when modeling the influence of one time series on another. This framework is also used to derive the relation between these measures of directed influence and the complexity or the order of directed influence. These results provide a framework for unifying the Kullback-Leibler divergence, Granger causality, and the complexity of directed influence.",
"k
Out of
n
Region Incrementing Scheme in Visual Cryptography","Recently, Wang introduced a novel (2, n ) region incrementing visual cryptographic scheme (RIVCS), which can gradually reconstruct secrets in a single image with multiple security levels. In RIVCS, the secret image is subdivided into multiple regions in such a way that any t shadow images, where 2 ≤ t ≤ n, can be used to reveal the (t-1) th region. However, Wang's scheme suffers from the incorrect-color problem, which the colors of reconstructed images may be reversed (i.e., the black and white are reversed). If the color of text is also the secret information, the incorrect-color problem will compromise the secret. Additionally, Wang's scheme is only suitable for the 2-out-of-n case, i.e., (k,n)-RIVCS where k=2. In this paper, we propose a general (k,n)-RIVCS, where k and n are any integers, that is able to reveal correct colors of all regions. This paper has made three main contributions: 1) our scheme is a general (k,n)-RIVCS, where k and n can be any integers; 2) the incorrect-color problem is solved; and 3) our (k,n)-RIVCS is theoretically proven to satisfy the security and contrast conditions.",
Carrier-Mobility Enhancement via Strain Engineering in Future Thin-Body MOSFETs,"The impact of body-thickness scaling on strain-induced carrier-mobility enhancement in thin-body CMOSFETs with high-k/metal gate stacks, based on quantum-mechanical simulations calibrated with measured data, is presented to provide insight into device performance enhancement trends for future technology nodes.","FinFETs,
Stress,
Logic gates,
High K dielectric materials,
Silicon"
Probabilistic modeling of EV charging and its impact on distribution transformer loss of life,"The effect of uncontrolled electric vehicle (EV) charging on the distribution side is considerable and has the potential to affect the life of distribution components. This especially has significant impact on secondary-distribution transformers in residential zones. With smart grid implementation, assessment for reliability of feeder-level components becomes more crucial. This work analyzes the distribution-level secondary transformer loss of life as the result of EV charging. Different charging patterns are developed using a probabilistic model for vehicle arrival time and charge left at arrival. A number of different scenarios, such as residential loading, weather patterns, and geographical locations, are considered in analyzing the effects.","Oil insulation,
Loading,
Probabilistic logic,
Electric vehicles,
Batteries,
Load modeling"
Reusing and Retargeting On-Chip Instrument Access Procedures in IEEE P1687,"This paper discusses the reuse and retargeting of test instruments and test patterns using the IEEE P1687 standard in an era where reuse of existing functional elements and integration of IP blocks is accelerating rapidly. It briefly discusses the deficiencies of existing 1149.1 (JTAG) and 1500 standards and demonstrates how the new standard, P1687, plugs these exposures by specifying JTAG as an off-chip to on-chip interface to the instrument access infrastructure. It provides a simple example to underscore the need for the standard and then builds on this example to show how the standard can be used for more complex situations.",
A diffusion-based binary digital communication system,"Diffusion-based communications refers to the transfer of information using particles as message carriers whose propagation is based on the law of particle diffusion. Though still at an early stage, there have been growing interests and research efforts dedicated to this communication technology. It has been identified that diffusion-based communications is one of the most promising approaches for end-to-end communication between nanoscale devices in the near future. In this paper, the design of a binary digital communication system is proposed based on particle diffusion. Stochastic signaling through On-Off Keying (OOK) for random particle emission and a diffusion channel with memory is considered. The diffusion is considered in the cases of one, two, and three dimensions. The receiver detection problem is formulated by using an information-theoretic approach. The optimal decision threshold for the receiver detection is derived through mutual information maximization for two cases, namely, when the a priori probability of bit transmission is fixed and known to the receiver and when this probability is unknown to the receiver. Numerical results indicate that in the case of diffusion in one or two dimensions, the information of a priori probability plays a key role in optimizing the system performance, while it does not when considering the diffusion in three dimensions.","Mutual information,
Receivers,
Molecular communication,
Channel capacity,
Random variables,
Transmitters"
Macroblock Classification Method for Video Applications Involving Motions,"In this paper, a macroblock classification method is proposed for various video processing applications involving motions. Based on the analysis of the Motion Vector field in the compressed video, we propose to classify Macroblocks of each video frame into different classes and use this class information to describe the frame content. We demonstrate that this low-computation-complexity method can efficiently catch the characteristics of the frame. Based on the proposed macroblock classification, we further propose algorithms for different video processing applications, including shot change detection, motion discontinuity detection, and outlier rejection for global motion estimation. Experimental results demonstrate that the methods based on the proposed approach can work effectively on these applications.",
Recursive outlier-robust filtering and smoothing for nonlinear systems using the multivariate student-t distribution,"Nonlinear Kalman filter and Rauch-Tung-Striebel smoother type recursive estimators for nonlinear discrete-time state space models with multivariate Student's t-distributed measurement noise are presented. The methods approximate the posterior state at each time step using the variational Bayes method. The nonlinearities in the dynamic and measurement models are handled using the nonlinear Gaussian filtering and smoothing approach, which encompasses many known nonlinear Kalman-type filters. The method is compared to alternative methods in a computer simulation.","Smoothing methods,
Approximation methods,
Noise,
Noise measurement,
Kalman filters,
Computational modeling,
Time measurement"
Bidirectional Electrothermal Actuator With Z-Shaped Beams,"A bidirectional micro-actuator powered by electrothermal force is successfully demonstrated under both dc and ac operations, without the assistance of magnetic field, using MetalMUMPs process. To achieve small stiffness without buckling, which tends to occur in V-shaped actuators, a new Z-shaped electrothermal actuator is designed. With the actuation current from -13 mA to +13 mA, the electrothermal actuator can achieve a bidirectional motion in a dynamic range from -11.6 μm to +12.8 μm. Experimentally obtained frequency response of the actuator indicates that it has a bandwidth of 49 Hz.","Actuators,
Bidirectional control,
Heating,
Educational institutions,
Bandwidth,
Finite element methods,
Dynamic range"
IMA: An Integrated Monitoring Architecture With Sensor Networks,"The integrated monitoring has become an important approach for investigation, detection, and policy decision in many fields. Unfortunately, current monitoring systems are commonly developed by different organizations using specific technologies and platforms, bringing a lot of difficulties for the seamless integration and unified access. To address the aforementioned problem, a novel integrated monitoring architecture based on Web services is proposed, which offers a universal client for accessing different monitoring systems and then facilitates system integration under the heterogeneous environment. By analyzing the characters of sensor-network-based monitoring applications, this paper presents the whole architecture design which consists of the standardized Web services, management subsystem, configuration subsystem, local monitoring subsystem, and integration monitoring subsystem. Through the integration architecture, the distributed isomerous monitoring systems can be accessed in a unified user interface if owning the corresponding ranking. In order to validate the proposed architecture, three different monitoring systems are constructed and integrated. The results show that the seamless system integration is achieved and the supervisory efficiency is improved remarkably.","Monitoring,
Computer architecture,
Temperature measurement,
Temperature sensors,
Instruments,
Service oriented architecture"
Cloud computing security requirements: A systematic review,"Many publications have dealt with various types of security requirements in cloud computing but not all types have been explored in sufficient depth. It is also hard to understand which types of requirements have been under-researched and which are most investigated. This paper's goal is to provide a comprehensive and structured overview of cloud computing security requirements and solutions. We carried out a systematic review and identified security requirements from previous publications that we classified in nine sub-areas: Access Control, Attack/Harm Detection, Non-repudiation, Integrity, Security Auditing, Physical Protection, Privacy, Recovery, and Prosecution. We found that (i) the least researched sub-areas are non-repudiation, physical protection, recovery and prosecution, and that (ii) access control, integrity and auditability are the most researched sub-areas.",
Fast and Accurate Human Detection Using a Cascade of Boosted MS-LBP Features,"In this letter, a new scheme for generating local binary patterns (LBP) is presented. This Modified Symmetric LBP (MS-LBP) feature takes advantage of LBP and gradient features. It is then applied into a boosted cascade framework for human detection. By combining MS-LBP with Haar-like feature into the boosted framework, the performances of heterogeneous features based detectors are evaluated for the best trade-off between accuracy and speed. Two feature training schemes, namely Single AdaBoost Training Scheme (SATS) and Dual AdaBoost Training Scheme (DATS) are proposed and compared. On the top of AdaBoost, two multidimensional feature projection methods are described. A comprehensive experiment is presented. Apart from obtaining higher detection accuracy, the detection speed based on DATS is 17 times faster than HOG method.",
Cooperative Sparse Representation in Two Opposite Directions for Semi-Supervised Image Annotation,"Recent studies have shown that sparse representation (SR) can deal well with many computer vision problems, and its kernel version has powerful classification capability. In this paper, we address the application of a cooperative SR in semi-supervised image annotation which can increase the amount of labeled images for further use in training image classifiers. Given a set of labeled (training) images and a set of unlabeled (test) images, the usual SR method, which we call forward SR, is used to represent each unlabeled image with several labeled ones, and then to annotate the unlabeled image according to the annotations of these labeled ones. However, to the best of our knowledge, the SR method in an opposite direction, that we call backward SR to represent each labeled image with several unlabeled images and then to annotate any unlabeled image according to the annotations of the labeled images which the unlabeled image is selected by the backward SR to represent, has not been addressed so far. In this paper, we explore how much the backward SR can contribute to image annotation, and be complementary to the forward SR. The co-training, which has been proved to be a semi-supervised method improving each other only if two classifiers are relatively independent, is then adopted to testify this complementary nature between two SRs in opposite directions. Finally, the co-training of two SRs in kernel space builds a cooperative kernel sparse representation (Co-KSR) method for image annotation. Experimental results and analyses show that two KSRs in opposite directions are complementary, and Co-KSR improves considerably over either of them with an image annotation performance better than other state-of-the-art semi-supervised classifiers such as transductive support vector machine, local and global consistency, and Gaussian fields and harmonic functions. Comparative experiments with a nonsparse solution are also performed to show that the sparsity plays an important role in the cooperation of image representations in two opposite directions. This paper extends the application of SR in image annotation and retrieval.","Strontium,
Kernel,
Vectors,
Training,
Noise,
Sparse matrices,
Visualization"
Thermal Properties of AlGaN/GaN HFETs on Bulk GaN Substrates,"Micro-Raman thermography, microphotoluminescence spectroscopy, and thermal simulation were used to study the thermal properties of AlGaN/GaN heterostructure field-effect transistors grown on semi-insulating bulk GaN substrates. A bulk GaN thermal conductivity of 260 was determined from temperature measurements on operating devices in combination with finite-difference thermal simulations. This is significantly higher than typical thin GaN epilayer thermal conductivities, due to a lower dislocation density in bulk GaN. Despite the thermal conductivity of bulk GaN being lower than that of SiC, transistors on bulk GaN exhibited a similar thermal resistance as GaN-on-SiC devices, attributed to the absence of a thermal boundary resistance between the device epilayers and substrate for GaN-on-GaN devices.","Gallium nitride,
Substrates,
Temperature measurement,
Thermal conductivity,
Conductivity,
Aluminum gallium nitride,
HEMTs"
Human action recognition using depth maps,"In this paper we propose an approach to recognize human actions using depth images. Here, we capture the motion dynamics of the object from the depth difference image and average depth image. The features from the space-time depth difference images are obtained from hierarchical division of the silhouette bounding box. We also make use of motion history images to represent the temporal information about the action. We make use of the translation, scale and orientation invariant Hu moments to represent the features of the motion history image and the average depth image. We then classify human actions using support vector machines. We analyze the representation efficiency of Hu moments and the hierarchical division of bounding boxes separately in order to evaluate the contribution of each of the features. The results show superior performance of over 90% when both features are combined.","History,
Humans,
Feature extraction,
Vectors,
Cameras,
Image recognition,
Computer vision"
Dynamic Cluster Reconfiguration for Energy Conservation in Computation Intensive Service,"This paper considers the problem of dynamic cluster reconfiguration for computation intensive services. In order to provide a quality-of-service in terms of overload probability, we formulate the problem of energy consumption as a constrained optimization problem, i.e., minimizing the number of active servers to reduce the energy consumption while keeping the overload probability below a desired threshold. An overload probability estimation model is derived by applying large deviation principle, and an online measurement based algorithm is developed to decide the number of servers to power on/off, which makes decision based on current workload without any prior knowledge of the workload statistics. Moreover, the proposed dynamic cluster reconfiguration algorithm iteratively adjusts the number of the active servers, instead of directly determining the number of active servers that is hard to guarantee optimality for the nonstationary workloads. Since the distribution of the workloads among the servers has an impact on potential active servers to turn off, a server scheduling strategy is proposed to collaborate with the proposed decision algorithm to achieve better energy conservation. In order to provide an integrated solution, we present an event model-based implementation to demonstrate the practical application of the proposed approach. Finally, we evaluate the performance of the scheme by using real workloads. The experimental results show the adaptability of the proposed approach to the variations in the workload and robustness of quality-of-service for nonstationary workloads.",
Maintaining invariant traceability through bidirectional transformations,"Following the “convention over configuration” paradigm, model-driven development (MDD) generates code to implement the “default” behaviour that has been specified by a template separate from the input model, reducing the decision effort of developers. For flexibility, users of MDD are allowed to customise the model and the generated code in parallel. A synchronisation of changed model or code is maintained by reflecting them on the other end of the code generation, as long as the traceability is unchanged. However, such invariant traceability between corresponding model and code elements can be violated either when (a) users of MDD protect custom changes from the generated code, or when (b) developers of MDD change the template for generating the default behaviour. A mismatch between user and template code is inevitable as they evolve for their own purposes. In this paper, we propose a two-layered invariant traceability framework that reduces the number of mismatches through bidirectional transformations. On top of existing vertical (model↔code) synchronisations between a model and the template code, a horizontal (code↔code) synchronisation between user and template code is supported, aligning the changes in both directions. Our blinkit tool is evaluated using the data set available from the CVS repositories of a MDD project: Eclipse MDT/GMF.",
CastFlow: Clean-slate multicast approach using in-advance path processing in programmable networks,"Multipoint communication is an important requirement for many types of applications such as videoconferencing, IPTV and online radio. However, the division of Internet in autonomous systems hinders the widespread adoption of traditional multicast protocols, which, for using distributed algorithms, delay the group control events processing. This paper proposes a multicast clean-slate approach logically centralized based on programmable networks and anticipated processing for all routes from each possible source, aiming to reduce event delays. A prototype was implemented based on OpenFlow technology. In addition, extensive evaluation was performed and results show promising delays comparable to the requirements of multipoint applications.","Topology,
Routing,
Routing protocols,
Network topology,
Prototypes,
Control systems"
Fast Covariance Matching With Fuzzy Genetic Algorithm,"The exiting covariance matching method is not suited for real-time applications due to its demand for exhaustive search. Aiming at this problem, we developed a novel approach based on fuzzy genetic algorithm (GA) to boost the computing efficiency of covariance matching. The approach employs GA in searching for optimal solution in a large image region. To avoid premature convergence or local optimum which often occur in traditional GAs, we use a fuzzy inference system to adaptively estimate the crossover and mutation probabilities to gain convergence in a much higher speed than using a conventional GA. Experimental results show that the proposed approach can significantly improve the processing speed of covariance matching, while keeping the matching results almost unchanged. The runtime performance of the proposed approach is faster than its counterparts using exhaustive search with eight times and more.","Genetic algorithms,
Covariance matrix,
Frequency modulation,
Convergence,
Optimization,
Feature extraction,
Genetics"
High-Efficiency InGaN/GaN Dot-in-a-Wire Red Light-Emitting Diodes,"We report on the achievement of high-performance InGaN/GaN dot-in-a-wire red light-emitting diodes on Si(111) substrates. Owing to the superior 3-D carrier confinement offered by the self-organized dot-in-a-wire heterostructures, the devices exhibit relatively high (~18%-32%) internal quantum efficiency at room temperature. Moreover, no efficiency droop was observed for injection current up to ~480A/cm2 under pulsed biasing conditions. We have also demonstrated that, by controlling the inhomogeneous broadening of the dot-in-a-wire heterostructures, the devices can exhibit relatively stable emission characteristics with increasing current.","Gallium nitride,
Light emitting diodes,
Temperature measurement,
Current measurement,
Quantum dots,
Substrates,
Molecular beam epitaxial growth"
Compact Directive Ultra-Wideband Rectangular Waveguide Based Antenna for Radar and Communication Applications,"A new directive ultra-wideband antenna based on rectangular waveguide aperture antennas is presented. Conventional rectangular aperture antennas are limited by the single mode operation of the waveguide as well as relatively long and narrowband resonant feeds. To overcome these limitations, we developed a new rectangular waveguide antenna feeding structure that can establish an aperture field distribution very similar to that of the fundamental waveguide mode with a relatively short waveguide section and over two octaves of bandwidth. The overall antenna size is 0.55 λm × 0.27λm × 0.18 λm where λm is wavelength at the minimum operating frequency. Due to the planar aperture of the antenna, a polarizer could be added to the antenna to ensure good cross-polarization performance with fabrication tolerances. The proposed feed requires a balun structure, and thus an integrated balun design is presented. It is found that a standard balun would interact with the antenna structure and thus a modified design was implemented. The antenna was fabricated and measured. The antenna had VSWR <; 2.5 from 1.08 to 4.9 GHz and the measured gain showed almost constant aperture gain which increases from 5.3 dBi at the low frequency end to 11 dBi at the high frequency edge.","Feeds,
Apertures,
Directive antennas,
Impedance matching,
Ultra wideband antennas,
Radar antennas"
The Johnson-Lindenstrauss Transform Itself Preserves Differential Privacy,"This paper proves that an ""old dog"", namely - the classical Johnson-Lindenstrauss transform, ""performs new tricks"" - it gives a novel way of preserving differential privacy. We show that if we take two databases, D and D', such that (i) D'-D is a rank-1 matrix of bounded norm and (ii) all singular values of D and D' are sufficiently large, then multiplying either D or D' with a vector of iid normal Gaussians yields two statistically close distributions in the sense of differential privacy. Furthermore, a small, deterministic and public alteration of the input is enough to assert that all singular values of D are large. We apply the Johnson-Lindenstrauss transform to the task of approximating cut-queries: the number of edges crossing a (S, S)-cut in a graph. We show that the JL transform allows us to publish a sanitized graph that preserves edge differential privacy (where two graphs are neighbors if they differ on a single edge) while adding only O(|S|ϵ) random noise to any given query (w.h.p). Comparing the additive noise of our algorithm to existing algorithms for answering cut-queries in a differentially private manner, we outperform all others on small cuts (|S| = o(n)). We also apply our technique to the task of estimating the variance of a given matrix in any given direction. The JL transform allows us to publish a sanitized covariance matrix that preserves differential privacy w.r.t bounded changes (each row in the matrix can change by at most a norm-1 vector) while adding random noise of magnitude independent of the size of the matrix (w.h.p). In contrast, existing algorithms introduce an error which depends on the matrix dimensions.",
A Self-Normalization Reconstruction Technique for PET Scans Using the Positron Emission Data,"Positron emission tomography (PET) image quality in both clinical and preclinical environments highly depends on an accurate knowledge of the detector hardware to correct for image quality degrading effects like gain, temperature, and photon detection efficiency variations of the individual crystals. In conventional PET systems some of these variations are typically corrected using a dedicated calibration scan in which the scanner performance for a well-known activity source is measured. We propose an alternative method for estimating the relative sensitivity of each detector pixel using the coincidences as well as the singles emission data of each PET scan. The overall idea is to compare the total sum of all measured single photons before coincidence processing in each crystal with a steadily low-frequent distribution that can normally be expected. Both the estimated activity and the estimated detector sensitivity are simultaneously improved by using an extended iterative reconstruction scheme. This way we ensure the use of an optimal calibration correction (with the exception of a global factor) for each data set, even if the scanner performance has changed between two scans. Data measured with a preclinical PET scanner (HYPERIon-I) which uses analog silicon photomultipliers in combination with a custom-made ASIC shows a significant increase of image quality and homogeneity using the proposed method.","Crystals,
Detectors,
Positron emission tomography,
Integrated circuits,
Image reconstruction,
Sensitivity,
Phantoms"
Efficient Construction for Region Incrementing Visual Cryptography,"A region incrementing visual cryptography scheme (RIVCS) deals with the sharing of an image consisting of multiple regions with different secrecy levels, which can be incrementally revealed as the number of shares increases. The encoding basis matrices of RIVCS for an image containing three to five regions have been reported in the literature, but no construction method has ever been studied. We develop a novel and efficient construction for RIVCS using linear programming in this paper. The proposed integer linear program aims at the minimization of the pixel expansion under the constraints for being a RIVCS. Experimental results demonstrate the feasibility, applicability, and flexibility of our construction. The pixel expansions and contrasts derived from our scheme are also better than the previous results.","Cryptography,
Visualization,
Hamming weight,
Encoding,
Linear programming,
Image reconstruction,
Tin"
Factor graph based incremental smoothing in inertial navigation systems,"This paper describes a new approach for information fusion in inertial navigation systems. In contrast to the commonly used filtering techniques, the proposed approach is based on a non-linear optimization for processing incoming measurements from the inertial measurement unit (IMU) and any other available sensors into a navigation solution. A factor graph formulation is introduced that allows multi-rate, asynchronous, and possibly delayed measurements to be incorporated in a natural way. This method, based on a recently developed incremental smoother, automatically determines the number of states to recompute at each step, effectively acting as an adaptive fixed-lag smoother. This yields an efficient and general framework for information fusion, providing nearly-optimal state estimates. In particular, incoming IMU measurements can be processed in real time regardless to the size of the graph. The proposed method is demonstrated in a simulated environment using IMU, GPS and stereo vision measurements and compared to the optimal solution obtained by a full non-linear batch optimization and to a conventional extended Kalman filter (EKF).","Sensors,
Optimization,
Global Positioning System,
Mathematical model,
Smoothing methods,
Atmospheric measurements"
Rigorous Characterization of Carbon Nanotube Complex Permittivity Over a Broadband of RF Frequencies,This study presents a comprehensive characterization of the frequency dependence of the effective complex permittivity of bundled carbon nanotubes (CNTs) considering different densities over a broadband of frequencies from 10 MHz to 50 GHz using only one measurement setup. The extraction technique is based on rigorous modeling of coaxial and circular discontinuities using a mode matching technique in conjunction with an inverse optimization method to map the simulated scattering parameters to those measured by a vector network analyzer. The dramatic values of complex permittivity obtained at low frequencies are physically explained by the percolation theory. The effective permittivity of a mixture of nanoparticles of alumina and CNTs versus frequency and packing density is studied to verify the previously obtained phenomenon.,"Permittivity,
Materials,
Permittivity measurement,
Dielectric constant,
Broadband communication,
Frequency measurement,
Nanoparticles"
The Effect of Random Dopant Fluctuations on Logic Timing at Low Voltage,"In order to achieve ultra-low power (ULP), ICs are being designed for VDD ≤ 0.5 V. At these low voltages, random dopant fluctuations (RDFs) result in a stochastic component of logic delay that can be comparable to the global corner delay. Moreover, the probability density function (PDF) of this stochastic delay can be highly non-Gaussian. In order to predict the statistical impact of RDF-induced local variations on logic timing, it is necessary to incorporate these effects into a timing closure methodology. This paper presents a computationally efficient methodology for stochastic characterization of standard cell li- braries at low voltage, where the cell delay is a nonlinear function of the transistor random variables (RVs), and the resulting cell delay has a non-Gaussian PDF. It also presents a computation- ally efficient methodology for computing any point on the PDF of a timing path (TP) delay, in the case where cell delays are non-Gaussian. The method is called nonlinear operating point analysis of local variation (NLOPALV). The general NLOPALV theory is developed. It is applied to cell library characterization, and the accuracy of the NLOPALV approach is validated by comparison to Monte Carlo simulation. NLOPALV is also applied to timing path analysis on a 28 nm DSP IC. The approach has been implemented using commercial CAD tools, and integrated into a commercial IC design flow. The NLOPALV approach gives timing results that are within 5% accuracy compared to Monte Carlo analysis at VDD = 0.5 V. This compares to errors on the order of 50% when the Gaussian approximation is used.","Delay,
Nonlinear optics,
Transistors,
Stochastic processes,
Random variables,
Low voltage"
Object Detection From Videos Captured by Moving Camera by Fuzzy Edge Incorporated Markov Random Field and Local Histogram Matching,"In this paper, we put forward a novel region matching-based motion estimation scheme to detect objects with accurate boundaries from videos captured by moving camera. Here, a fuzzy edge incorporated Markov random field (MRF) model is considered for spatial segmentation. The algorithm is able to identify even the blurred boundaries of objects in a scene. Expectation Maximization algorithm is used to estimate the MRF model parameters. To reduce the complexity of searching, a new scheme is proposed to get a rough idea of maximum possible shift of objects from one frame to another by finding the amount of shift in positions of the centroid. We propose a χ2-test-based local histogram matching scheme for detecting moving objects from complex scenes from low illumination environment and objects that change size from one frame to another. The proposed scheme is successfully applied for detecting moving objects from video sequences captured in both real-life and controlled environments. It is also noticed that the proposed scheme provides better results with less object background misclassification as compared to existing techniques.",
Robust Fast Time-Varying Multipath Fading Channel Estimation and Equalization for MIMO-OFDM Systems via a Fuzzy Method,"Channel estimation is an important issue for wireless communication systems. A channel estimation scheme using a Takagi-Sugeno (T-S) fuzzy-based Kalman filter under the time-varying velocity of the mobile station in a multiple-input multiple-output orthogonal frequency-division multiplexing (MIMO-OFDM) system is proposed in this paper. The fuzzy technique is used to interpolate several linear models to approximate the nonlinear estimation system. A MIMO system with the orthogonal space-time block coding (OSTBC) scheme is considered, where the radio channel is modeled as an autoregressive (AR) random process. The parameters of the AR process and the channel gain are simultaneously estimated by the proposed method. One-step-ahead prediction can be obtained during this estimation procedure. This is useful for the decision-directed channel-tracking design, particularly in the fast-fading channel. Furthermore, the robust minimum mean-square error (MMSE) equalization design can be achieved by considering the channel prediction error to improve the performance of symbol detection. To validate the performance of our proposed method, several simulation results are given and compared with those of other methods. When considering the time-varying velocity of the mobile station communication in the MIMO-OFDM system, the enhanced equalizer based on the T-S fuzzy-based Kalman filter performs better than those based on the conventional channel estimators in terms of symbol error rate.","Channel estimation,
Kalman filters,
OFDM,
Estimation,
Mobile communication,
Equalizers,
Receivers"
Lean Software Management: BBC Worldwide Case Study,"This case study examines how the lean ideas behind the Toyota production system can be applied to software project management. It is a detailed investigation of the performance of a nine-person software development team employed by BBC Worldwide based in London. The data collected in 2009 involved direct observations of the development team, the kanban boards, the daily stand-up meetings, semistructured interviews with a wide variety of staff, and statistical analysis. The evidence shows that over the 12-month period, lead time to deliver software improved by 37%, consistency of delivery rose by 47%, and defects reported by customers fell 24%. The significance of this work is showing that the use of lean methods including visual management, team-based problem solving, smaller batch sizes, and statistical process control can improve software development. It also summarizes key differences between agile and lean approaches to software development. The conclusion is that the performance of the software development team was improved by adopting a lean approach. The faster delivery with a focus on creating the highest value to the customer also reduced both technical and market risks. The drawbacks are that it may not fit well with existing corporate standards.",
The use of unmanned aerial vehicles and wireless sensor network in agricultural applications,"The application of pesticides and fertilizers in agricultural areas is of prime importance for crop yields. The use of aircrafts is becoming increasingly common in carrying out this task mainly because of its speed and effectiveness in the spraying operation. However, some factors may reduce the yield, or even cause damage (e.g. crop areas not covered in the spraying process, overlapping spraying of crop areas, applying pesticides on the outer edge of the crop). Climatic conditions, such as the intensity and direction of the wind while spraying add further complexity to the control problem. In this paper, we describe an architecture based on unmanned aerial vehicles (UAVs) which can be employed to implement a control loop for agricultural applications where UAVs are responsible for spraying chemicals on crops. The process of applying the chemicals is controlled by means of the feedback obtained from the wireless sensor network (WSN) deployed on the crop field. The aim of this solution is to support short delays in the control loop so that the spraying UAV can process the information from the sensors. We evaluate an algorithm to adjust the UAV route under changes in wind intensity and direction. Moreover, we evaluate the impact of the number of communication messages between the UAV and the WSN. Results show that the adjustment of the route based on the feedback information from the sensors could minimize the waste of pesticides.","Chemicals,
Routing protocols,
Wireless sensor networks,
Agriculture,
Sensors,
Spraying,
Routing"
An electrochemical model-based particle filter approach for Lithium-ion battery estimation,"Lithium-ion batteries are currently amongst the leading technologies for electrical energy storage. In automotive industry they are recognized as the most promising alternative to gasoline powered engines. State estimation of the state of the battery can provide useful information regarding the state of charge (SOC) and state of health (SOH) of the battery which play a crucial role in optimal and safe utilization of the battery. Although the electrochemical dynamics of the battery are described by nonlinear system of PDAEs, most works in the area of condition monitoring of the battery resort to empirical or equivalent electrical circuit models. These models don't provide any physical insight into the battery and lack insight into physical limitations of the battery. This work presents a particle filter algorithm for state estimation and condition monitoring of the Li-ion battery. This filter can effectively deal with the nonlinear and complex nature of the PDAEs describing the dynamics of the battery. It provides accurate estimation of the average as well as spatial distribution of concentration in the battery. The simulation results demonstrate the effectiveness of the proposed estimation algorithm.","Batteries,
Mathematical model,
Equations,
Estimation,
Heuristic algorithms,
Particle filters,
Electrodes"
Construction of Optimum Composite Field Architecture for Compact High-Throughput AES S-Boxes,"In this work, we derive three novel composite field arithmetic (CFA) Advanced Encryption Standard (AES) S-boxes of the field GF(((22)2)2). The best construction is selected after a sequence of algorithmic and architectural optimization processes. Furthermore, for each composite field constructions, there exists eight possible isomorphic mappings. Therefore, after the exploitation of a new common subexpression elimination algorithm, the isomorphic mapping that results in the minimal implementation area cost is chosen. High throughput hardware implementations of our proposed CFA AES S-boxes are reported towards the end of this paper. Through the exploitation of both algebraic normal form and seven stages fine-grained pipelining, our best case achieves a throughput 3.49 Gbps on a Cyclone II EP2C5T144C6 field-programmable gate array.","Polynomials,
Logic gates,
Optimization,
Hardware,
Pipeline processing,
Complexity theory,
Very large scale integration"
Text-Line Extraction in Handwritten Chinese Documents Based on an Energy Minimization Framework,"Text-line extraction in unconstrained handwritten documents remains a challenging problem due to nonuniform character scale, spatially varying text orientation, and the interference between text lines. In order to address these problems, we propose a new cost function that considers the interactions between text lines and the curvilinearity of each text line. Precisely, we achieve this goal by introducing normalized measures for them, which are based on an estimated line spacing. We also present an optimization method that exploits the properties of our cost function. Experimental results on a database consisting of 853 handwritten Chinese document images have shown that our method achieves a detection rate of 99.52% and an error rate of 0.32%, which outperforms conventional methods.","Cost function,
Minimization,
Data mining,
Robustness,
Materials,
State estimation,
Image color analysis"
DC fault analysis of VSC based multi-terminal HVDC systems,"The use of Voltage Source Converter (VSC) based HVDC transmission has been strongly suggested for the interconnection of various power networks. However, VSCs susceptibility to DC faults, particularly the potential damage caused to the converter IGBTs due to overcurrent, is an issue that must be addressed. This paper analyses the behaviour of a VSC-based HVDC system under varying DC fault conditions. A two terminal multi-terminal DC system, consisting of a single sending and receiving end is used as a case study. Recharging of the DC link Capacitor after a DC line-to-line fault was found to act as additional damping for the AC fault current, helping to reduce the AC current offset. Also, it was discovered that the development of potential earth loops with the system as a result of DC lineto-earth faults can lead to substantial overcurrent if an effective earthing scheme is not in place.","power convertors,
capacitors,
earthing,
fault currents,
HVDC power transmission,
insulated gate bipolar transistors,
overcurrent protection"
Interactive exploration of large-scale time-varying data using dynamic tracking graphs,"Exploring and analyzing the temporal evolution of features in large-scale time-varying datasets is a common problem in many areas of science and engineering. One natural representation of such data is tracking graphs, i.e., constrained graph layouts that use one spatial dimension to indicate time and show the “tracks” of each feature as it evolves, merges or disappears. However, for practical data sets creating the corresponding optimal graph layouts that minimize the number of intersections can take hours to compute with existing techniques. Furthermore, the resulting graphs are often unmanageably large and complex even with an ideal layout. Finally, due to the cost of the layout, changing the feature definition, e.g. by changing an iso-value, or analyzing properly adjusted sub-graphs is infeasible. To address these challenges, this paper presents a new framework that couples hierarchical feature definitions with progressive graph layout algorithms to provide an interactive exploration of dynamically constructed tracking graphs. Our system enables users to change feature definitions on-the-fly and filter features using arbitrary attributes while providing an interactive view of the resulting tracking graphs. Furthermore, the graph display is integrated into a linked view system that provides a traditional 3D view of the current set of features and allows a cross-linked selection to enable a fully flexible spatio-temporal exploration of data. We demonstrate the utility of our approach with several large-scale scientific simulations from combustion science.","Layout,
Feature extraction,
Data visualization,
Vegetation,
Correlation,
Measurement,
Visualization"
Inter-Domain Analysis of Smart Grid Domain Dependencies Using Domain-Link Matrices,"Developers of the smart grid have proposed a number of independent smart grid architectures. This has resulted in a lack of common vision and understanding of the common smart grid reference architecture. In particular, there is a lack of understanding of various inter-domain relationships and dependencies among technical and business domains within the smart grid. This paper presents an inter-domain analysis of these complex dependencies among the business and technical domains of the smart grid using Domain-Link Matrices. This inter-domain analysis clarifies and bridges the technical architecture to the business architecture. The aim is to maintain the rationale for the solutions developed in the technical domains in order to solve the problems of the business domains; and, as such, this analysis contributes toward further development and refinement of the smart grid reference architecture.","Smart grids,
Computer architecture,
NIST,
Context,
Electricity,
Companies"
Sensor fusion for flexible human-portable building-scale mapping,"This paper describes a system enabling rapid multi-floor indoor map building using a body-worn sensor system fusing information from RGB-D cameras, LIDAR, inertial, and barometric sensors. Our work is motivated by rapid response missions by emergency personnel, in which the capability for one or more people to rapidly map a complex indoor environment is essential for public safety. Human-portable mapping raises a number of challenges not encountered in typical robotic mapping applications including complex 6-DOF motion and the traversal of challenging trajectories including stairs or elevators. Our system achieves robust performance in these situations by exploiting state-of-the-art techniques for robust pose graph optimization and loop closure detection. It achieves real-time performance in indoor environments of moderate scale. Experimental results are demonstrated for human-portable mapping of several floors of a university building, demonstrating the system's ability to handle motion up and down stairs and to organize initially disconnected sets of submaps in a complex environment.",
Identifying At-Risk Employees: Modeling Psychosocial Precursors of Potential Insider Threats,"In many insider crimes, managers and other coworkers observed that the offenders had exhibited signs of stress, disgruntlement, or other issues, but no alarms were raised. Barriers to using such psychosocial indicators include the inability to recognize the signs and the failure to record the behaviors so that they can be assessed. A psychosocial model was developed to assess an employee's behavior associated with an increased risk of insider abuse. The model is based on case studies and research literature on factors/correlates associated with precursor behavioral manifestations of individuals committing insider crimes. To test the model's agreement with human resources and management professionals, we conducted an experiment with positive results. If implemented in an operational setting, the model would be part of a set of management tools for employee assessment to identify employees who pose a greater insider threat.","Personnel,
Stress,
Predictive models,
Laboratories,
Sorting,
Analytical models,
Random variables"
Acceleration Strategies in Generalized Belief Propagation,"Generalized belief propagation is a popular algorithm to perform inference on large-scale Markov random fields (MRFs) networks. This paper proposes the method of accelerated generalized belief propagation with three strategies to reduce the computational effort. First, a min-sum messaging scheme and a caching technique are used to improve the accessibility. Second, a direction set method is used to reduce the complexity of computing clique messages from quartic to cubic. Finally, a coarse-to-fine hierarchical state-space reduction method is presented to decrease redundant states. The results show that a combination of these strategies can greatly accelerate the inference process in large-scale MRFs. For common stereo matching, it results in a speed-up of about 200 times.",
Fusing iris and conjunctival vasculature: Ocular biometrics in the visible spectrum,"Ocular biometrics refers to the imaging and use of characteristic features of the eyes for personal identification. Traditionally, the iris has been viewed as a powerful ocular biometric cue. However, the iris is typically imaged in the near infrared (NIR) spectrum. RGB images of the iris, acquired in the visible spectrum, offer limited biometric information for dark-colored irides. In this work, we explore the possibility of performing ocular biometric recognition in the visible spectrum by utilizing the iris in conjunction with the vasculature observed in the white of the eye. We design a weighted fusion scheme to combine the information originating from these two modalities. Experiments on a dataset of 50 subjects indicate that such a fusion scheme improves the equal error rate by a margin of 4.5% over an iris-only approach.","Iris recognition,
Tiles,
Iris,
Image segmentation,
Face,
Vectors"
Space information flow: Multiple unicast,"The multiple unicast network coding conjecture states that for multiple unicast in an undirected network, network coding is equivalent to routing. Simple and intuitive as it appears, the conjecture has remained open since its proposal in 2004 [1], [2], and is now a well-known unsolved problem in the field of network coding. In this work, we provide a proof to the conjecture in its space/geometric version. Space information flow is a new paradigm being proposed [3], [4]. It studies the transmission of information in a geometric space, where information flows are free to propagate along any trajectories, and may be encoded wherever they meet. The goal is to minimize a natural bandwidth-distance sum-product (network volume), while sustaining end-to-end unicast and multicast communication demands among terminals at known coordinates. The conjecture is true in networks only if it is true in space. Our main result is that network coding is indeed equivalent to routing in the space model. Besides its own merit, this partially verifies the original conjecture, and further leads to a geometric framework [5] for a hopeful proof to the conjecture.","Network coding,
Unicast,
Routing,
Throughput,
Vectors,
Encoding"
Contrast-Independent Curvilinear Structure Detection in Biomedical Images,"Many biomedical applications require detection of curvilinear structures in images and would benefit from automatic or semiautomatic segmentation to allow high-throughput measurements. Here, we propose a contrast-independent approach to identify curvilinear structures based on oriented phase congruency, i.e., the phase congruency tensor (PCT). We show that the proposed method is largely insensitive to intensity variations along the curve and provides successful detection within noisy regions. The performance of the PCT is evaluated by comparing it with state-of-the-art intensity-based approaches on both synthetic and real biological images.",
Architecture on Demand: Synthesis and scalability,"The optical cross-connect (OXC) is a key element in current WDM networks. In this context, the design of OXCs is becoming very challenging since it has to fulfil requirements from legacy optical networks and be future-proof to support both legacy lower bitrates and future high-speed super-channels by means of flexible allocation of spectral resources. In this paper we review the novel concept of Architecture on Demand (AoD) to dynamically synthesise architectures suited to the switching and processing requirements of traffic. We propose a technique suited to perform architecture computation and composition and discuss the scalability of the proposed technique. Results show that it is possible to reduce the number of hardware modules used at least by half compared to other conventional architectures.","Optical switches,
Backplanes,
Buildings,
Computer architecture,
Scalability,
Optical packet switching"
On-Chip Measurement of Single-Event Transients in a 45 nm Silicon-on-Insulator Technology,Direct observation of fast-transient single event signatures often involves considerable uncertainty due to the limitations of monitoring circuitry. A built-in-self-test circuit for the measurement of single-event transients (SET) has been implemented in a 45 nm partially depleted silicon-on-insulator technology that allows for the extraction of measurement-induced uncertainty. SET pulse width data from heavy-ion experiments are provided and compared to technology computer aided design simulations. A method for compensating for the measurement bias and skew is provided.,"Transient analysis,
System-on-a-chip,
Radiation effects,
Single event transient,
Silicon on insulator technology"
Highly accurate 3D surface models by sparse surface adjustment,"In this paper, we propose an approach to obtain highly accurate 3D models from range data. The key idea of our method is to jointly optimize the poses of the sensor and the positions of the surface points measured with a range scanning device. Our approach applies a physical model of the underlying range sensor. To solve the optimization task it employs a state-of-the-art graph-based optimizer and iteratively refines the structure of the error function by recomputing the data associations after each optimization. We present our approach and evaluate it on data recorded in different real world environments with a RGBD camera and a laser range scanner. The experimental results demonstrate that our method is able to substantially improve the accuracy of SLAM results and that it compares favorable over the moving least squares method.","Optimization,
Computational modeling,
Simultaneous localization and mapping,
Entropy,
Measurement uncertainty"
Uplink Performance Characterization and Analysis of Two-Tier Femtocell Networks,"This paper provides a cross-layer analysis of uplink (UL) performance in femtocell (FC) networks. It characterizes the UL physical interference in FC networks and studies its impact on the delay and the data loss rate of constant-bit-rate (CBR) traffic and on the maximum achievable femto user (FU) throughput. This paper derives data-link layer quality-of-service (QoS) performances as a function of physical layer parameters, thereby establishing key cross-layer relationships that can be useful for designing efficient resource-allocation techniques for FC networks.","Interference,
Wireless communication,
Power control,
Shadow mapping,
Delay,
Quality of service,
Fading"
Sideband radiation reduction exploiting pattern multiplication in directive time-modulated linear arrays,The reduction of the power losses in the sideband radiation of directive time-modulated linear arrays is addressed. The approach is based on the optimisation of the pulse sequence modulating the static excitations of the array elements to exploit pattern multiplication effects such that the sideband level of the harmonic pattern term related to the array factor is balanced by the element pattern distribution. A set of representative numerical results is reported and discussed to illustrate the potentialities and the limitations of the proposed approach.,"pulse modulation,
antenna radiation patterns,
linear antenna arrays"
"Diamagnetic Levitation Causes Changes in the Morphology, Cytoskeleton, and Focal Adhesion Proteins Expression in Osteocytes","Diamagnetic levitation technology is a novel simulated weightless technique and has recently been applied in life-science research. We have developed a superconducting magnet platform with large gradient high magnetic field (LG-HMF), which can provide three apparent gravity levels, namely, μg (diamagnetic levitation), 1g, and 2g for diamagnetic materials. In this study, the effects of LG-HMF on the activity, morphology, and cytoskeleton (actin filament, microtubules, and vimentin intermediate filaments) in osteocyte - like cell line MLO-Y4 were detected by 3-(4,5-dimethylthiazol-2-yl)-2,5-diphenyltetrazolium bromide (MTT) methods, hematoxylin-eosin (HE) staining, and laser scanning confocal microscopy (LSCM), respectively. The changes induced by LG-HMF in distribution and expression of focal adhesion (FA) proteins, including vinculin, paxillin, and talin in MLO-Y4 were determined by LSCM and Western blotting. The results showed that LG-HMF produced by superconducting magnet had no lethal effects on MLO-Y4. Compared to control, diamagnetic levitation (μg) affected MLO-Y4 morphology, nucleus size, cytoskeleton architecture, and FA proteins distribution and expression. The study indicates that osteocytes are sensitive to altered gravity and FA proteins (vinculin, paxillin, and talin) may be involved in osteocyte mechanosensation. The diamagnetic levitation may be a novel ground-based space-gravity simulator and can be used for biological experiment at cellular level.","Computer architecture,
Microprocessors,
Levitation,
Superconducting magnets,
Gravity,
USA Councils"
Weather effects on FSO network connectivity,"The use of relays is one of the most promising methods for mitigating impairments of the performance of free-space optical (FSO) systems and extending their limited transmission range. However, several factors contribute to significant link performance degradation. Most severe is the influence of the adverse atmospheric conditions that frequently appear, thus making the design of strongly connected networks a demanding issue. In this paper, we consider a multiple-hop FSO network, where the nodes are distributed at fixed positions on a given path-link. We take account of the most critical weather phenomena, i.e., fog, rain, and snow, and derive analytical expressions for the node isolation probability, assuming a suitable path loss model. Next, we find the number of transceivers for a given path-link in order to achieve reliable performance. We also examine the reverse case; i.e., we find the total service length for a known number of FSO transceivers. The effect of the prime FSO modulation formats is also considered. The addressed analytical framework offers significant insights into the main factors that degrade the performance of FSO networks. It constitutes a valuable tool for telecom researchers to design such networks in practice.","Rain,
Snow,
Transceivers,
Attenuation,
Optical receivers,
Optical scattering"
Implementation of an a-Si:H TFT Gate Driver Using a Five-Transistor Integrated Approach,An integrated five-transistor/one-capacitor approach for realizing a a-Si:H thin-film transistor (TFT) gate driver operating in multiphase-clock mode is proposed and investigated. The driver needs only one large-size TFT and one small-size storage capacitor. The performance and function of the proposed driver are verified experimentally. The dependence of the performance on the device size is studied in detail. Stability of the fabricated drivers is tested using a flexible measurement scheme. Measured results show that the fabricated gate driver can work stably even though the low-level-holding TFTs have a threshold-voltage shift of 19 V.,"Logic gates,
Temperature measurement,
Delay,
Thin film transistors,
Driver circuits,
Capacitors,
Electrodes"
Multimodal ocular biometrics approach: A feasibility study,"Growing efforts have been concentrated on the development of alternative biometric recognition strategies, the intended goal to increase the accuracy and counterfeit-resistance of existing systems without increased cost. In this paper, we propose and evaluate a novel biometric approach using three fundamentally different traits captured by the same camera sensor. Considered traits include: 1) the internal, non-visible, anatomical properties of the human eye, represented by Oculomotor Plant Characteristics (OPC); 2) the visual attention strategies employed by the brain, represented by Complex Eye Movement patterns (CEM); and, 3) the unique physical structure of the iris. Our experiments, performed using a low-cost web camera, indicate that the combined ocular traits improve the accuracy of the resulting system. As a result, the combined ocular traits have the potential to enhance the accuracy and counterfeit-resistance of existing and future biometric systems.","Iris recognition,
Visualization,
Measurement,
Iris,
Accuracy,
Cameras"
Evaluating sinkhole defense techniques in RPL networks,"In this work, we present the results of a study on the detrimental effects of sinkhole attacks on Wireless Sensor Networks (WSNs) which employ the Routing Protocol for LLNs (Low-power and Lossy Networks). A sinkhole is a compromised node which attempts to capture traffic with the intent to drop messages, thus degrading the end-to-end delivery performance, that is, reducing the number of messages successfully delivered to their destination. The mechanism by which the sinkhole captures traffic is by advertising an attractive route to its neighbors. We evaluate two countermeasures addressing the sinkhole problem: a parent fail-over and a rank authentication technique. We show via simulation that while each technique, applied alone, does not work all that well, the combination of the two techniques significantly improves the performance of a network under attack. We also demonstrate that, with the defenses described, increasing the density of the network can combat a penetration of sinkholes nodes, without needing to identify the sinkholes.","Wireless sensor networks,
Routing,
Noise,
Uncertainty,
Authentication,
Routing protocols"
Novel Layout Technique for N-Hit Single-Event Transient Mitigation via Source-Extension,"In this paper, a novel layout technique for N-hit single-event transient (SET) mitigation that is based on source-extension is proposed. Based on 65 nm bulk CMOS technology, both mixed-mode numerical simulations with technology computer-aided design (TCAD), as well as heavy-ion experiments show SET pulse widths are efficiently reduced with source extension. As opposed to what is found in the P-hit SET production process, where the source plays a detrimental role in SET mitigation due to the well-known bipolar effect, in the N-hit SET production process the source plays a beneficial role in reducing SET pulse widths, attributable to a parasitic reversed bipolar effect. This effect will be discussed in depth in this paper, and the proposed 'radiation hardened by design' (RHBD) layout technique will be extended to common combinational standard cells. The area penalty will also be discussed for the proposed layout technique. Meanwhile, both the P-hit and N-hit SET mitigation layout techniques will be introduced into the standard inverter layout, and the final improvement in SET pulse width will be discussed.",
Parallel Computation of 2D Morse-Smale Complexes,The Morse-Smale complex is a useful topological data structure for the analysis and visualization of scalar data. This paper describes an algorithm that processes all mesh elements of the domain in parallel to compute the Morse-Smale complex of large 2D datasets at interactive speeds. We employ a reformulation of the Morse-Smale complex using Forman's Discrete Morse Theory and achieve scalability by computing the discrete gradient using local accesses only. We also introduce a novel approach to merge gradient paths that ensures accurate geometry of the computed complex. We demonstrate that our algorithm performs well on both multicore environments and on massively parallel architectures such as the GPU.,"Manifolds,
Geometry,
Vectors,
Data visualization,
Algorithm design and analysis,
Parallel algorithms"
CloudGPS: A scalable and ISP-friendly server selection scheme in cloud computing environments,"In order to minimize user perceived latency while ensuring high data availability, cloud applications desire to select servers from one of the multiple data centers (i.e., server clusters) in different geographical locations, which are able to provide desired services with low latency and low cost. This paper presents CloudGPS, a new server selection scheme of the cloud computing environment that achieves high scalability and ISP-friendliness. CloudGPS proposes a configurable global performance function that allows Internet service providers (ISPs) and cloud service providers (CSPs) to leverage the cost in terms of inter-domain transit traffic and the quality of service in terms of network latency. CloudGPS bounds the overall burden to be linear with the number of end users. Moreover, compared with traditional approaches, CloudGPS significantly reduces network distance measurement cost (i.e., from O(N) to O(1) for each end user in an application using N data centers). Furthermore, CloudGPS achieves ISP-friendliness by significantly decreasing inter-domain transit traffic.","Servers,
Cloud computing,
Estimation,
Peer to peer computing,
Databases,
Accuracy"
A stochastic calculus for network systems with renewable energy sources,"We consider the performance modeling and evaluation of network systems powered with renewable energy sources such as solar and wind energy. Such energy sources largely depend on environmental conditions, which are hard to predict accurately. As such, it may only make sense to require the network systems to support a soft quality of service (QoS) guarantee, i.e., to guarantee a service requirement with a certain high probability. In this paper, we build a solid mathematical foundation to help better understand the stochastic energy constraint and the inherent correlation between QoS and the uncertain energy supply. We utilize a calculus approach to model the cumulative amount of charged energy and the cumulative amount of consumed energy. We derive upper and lower bounds on the remaining energy level based on a stochastic energy charging rate and a stochastic energy discharging rate. By building the bridge between energy consumption and task execution (i.e., service), we study the QoS guarantee under the constraint of uncertain energy sources.","Stochastic processes,
Renewable energy resources,
Quality of service,
Calculus,
Analytical models,
Energy consumption,
Safety"
Analysis of Nonlinear Phenomena in a Thermal Micro-Actuator With a Built-In Thermal Position Sensor,"An analysis of nonlinear effects associated with a chevron thermal micro-actuator with a built in thermal position sensor under static conditions is presented in this paper. The nonlinearities present in both actuator and sensor are studied. The phenomena considered for the sensor include: thermal coupling from actuator to sensor and temperature dependence of electrical resistivity. Those considered for the actuator include: non-uniform spatial distribution of temperature in arms, temperature dependency of thermal expansion coefficient, deviation of arm shape from straight line due to physical constraints, and temperature dependence of electrical resistivity.","Temperature sensors,
Actuators,
Resistors,
Resistance,
Conductivity"
"Investigation of safety in human-robot-interaction for a series elastic, tendon-driven robot arm","This paper presents the design of the lightweight BioRob manipulator with spring-loaded tendon-driven actuation developed for safe physical human-robot interaction. The safety of the manipulator is analyzed by an analytical worst-case estimation of impact and clamping forces in the absence of collision detection. As intrinsic joint compliance can pose a threat by storing energy, a safety evaluation method is proposed taking the potential energy stored in the elastic actuation into account. The evaluation shows that the robot arm design constrains the worst case clamping forces to only 25 N, while being able to handle loads up to 2 kg, and inherits extremely low impact properties, such as an effective mass of less than 0.4 kg in non near-singular configurations, enabling safe operation even in case of high velocities. The results are validated in simulation and experiments.","Joints,
Collision avoidance,
Clamps,
Safety,
Force,
Manipulators"
Vertical handoff decision algorithm for improved quality of service in heterogeneous wireless networks,"Fourth-generation networks are expected to integrate heterogeneous wireless technologies. To ensure seamless mobility across disparate wireless technologies, efficient handoff schemes are required to enhance quality of service (QoS) and offer reliable ubiquitous computing environment. This study reviews classical and existing fuzzy approaches adopted for vertical handoff to ensure seamless mobility across overlaid heterogeneous networks. A neuro-fuzzy multi-parameter-based vertical handoff decision algorithm (VHDA) is proposed. The proposed VHDA considers six parameters and applies rule-based system for vertical handoff decision. The number of vertical handoffs measured in a simulated environment shows that average number of vertical handoffs for the proposed VHDA reduces by 13.3 and 29.8% for the existing fuzzy technique and the classical technique, respectively. Further, reduction in number of unnecessary vertical handoffs in the proposed algorithm shows reduction in ping-pong effect by 15.9%, improvement in end-point service availability (ESA) and throughput by 16.57 and 5.97%, with respect to existing fuzzy technique leading towards improved QoS. Finally, the results of performance assessment, carried out using handoff quality indicator (used to quantify QoS) which is dependent upon ping-pong effect, ESA and throughput, show that the proposed VHDA offers better QoS than existing vertical handoff techniques.","quality of service,
4G mobile communication,
fuzzy set theory,
mobile computing"
Application of General Orthogonal Polynomials to Fast Simulation of Nonlinear Descriptor Systems Through Piecewise-Linear Approximation,"In this letter, we report an approach combining piecewise-linear (PWL) approximation with general orthogonal polynomials to efficiently simulate large nonlinear descriptor systems in time-domain. The main idea of this approach is first to approximate a nonlinear function by a piecewise-linear representation. Then, using the recursive formulae of general orthogonal polynomials, orthonormal bases can be produced for fast simulation of the PWL model. The effectiveness of our approach is demonstrated on two nonlinear circuit models.","Polynomials,
Integrated circuit modeling,
Computational modeling,
Mathematical model,
Chebyshev approximation,
Numerical models"
Memetic artificial bee colony algorithm for large-scale global optimization,"Memetic computation (MC) has emerged recently as a new paradigm of efficient algorithms for solving the hardest optimization problems. On the other hand, artificial bees colony (ABC) algorithms demonstrate good performances when solving continuous and combinatorial optimization problems. This study tries to use these technologies under the same roof. As a result, a memetic ABC (MABC) algorithm has been developed that is hybridized with two local search heuristics: the Nelder-Mead algorithm (NMA) and the random walk with direction exploitation (RWDE). The former is attended more towards exploration, while the latter more towards exploitation of the search space. The stochastic adaptation rule was employed in order to control the balancing between exploration and exploitation. This MABC algorithm was applied to a Special suite on Large Scale Continuous Global Optimization at the 2012 IEEE Congress on Evolutionary Computation. The obtained results the MABC are comparable with the results of DECC-G, DECC-G*, and MLCC.","Optimization,
Convergence,
Algorithm design and analysis,
Memetics,
Measurement,
Evolutionary computation,
Heuristic algorithms"
Automatic Detection and Segmentation of Lymph Nodes From CT Data,"Lymph nodes are assessed routinely in clinical practice and their size is followed throughout radiation or chemotherapy to monitor the effectiveness of cancer treatment. This paper presents a robust learning-based method for automatic detection and segmentation of solid lymph nodes from CT data, with the following contributions. First, it presents a learning based approach to solid lymph node detection that relies on marginal space learning to achieve great speedup with virtually no loss in accuracy. Second, it presents a computationally efficient segmentation method for solid lymph nodes (LN). Third, it introduces two new sets of features that are effective for LN detection, one that self-aligns to high gradients and another set obtained from the segmentation result. The method is evaluated for axillary LN detection on 131 volumes containing 371 LN, yielding a 83.0% detection rate with 1.0 false positive per volume. It is further evaluated for pelvic and abdominal LN detection on 54 volumes containing 569 LN, yielding a 80.0% detection rate with 3.2 false positives per volume. The running time is 5-20 s per volume for axillary areas and 15-40 s for pelvic. An added benefit of the method is the capability to detect and segment conglomerated lymph nodes.","Lymph nodes,
Detectors,
Feature extraction,
Shape,
Solids,
Computed tomography,
Cancer"
Analytical Modeling and Design Optimization of Linear Synchronous Motor With Stair-Step-Shaped Magnetic Poles for Electromagnetic Launch Applications,"In this paper, a stair-step-shaped magnetic pole structure is proposed to use in a permanent-magnet linear synchronous motor (PMLSM) for its application in an electromagnetic launch system. The aim of this configuration is to shape the air-gap flux density distribution produced by poles to be as close to a sine waveform as possible for the reduction of thrust ripple and the increase of motor controllability. An analytical model is derived for the PMLSMs by solving Maxwell equations and applying the superposition theorem for calculating the magnetic field, electromotive force, and thrust/torque of the motor. Magnet dimensions are then optimized using the analytical method and genetic algorithm, where the reduction of air-gap flux density harmonics is considered as the optimization target. Finally, the effectiveness of the proposed technique to enhance the motor performance is investigated by a time-stepping transient finite-element method. The results show an improvement in the optimal motor performance.","Force,
Analytical models,
Magnetic flux,
Synchronous motors,
Finite element methods,
Air gaps,
Windings"
Retrieval of the Height of Buildings From WorldView-2 Multi-Angular Imagery Using Attribute Filters and Geometric Invariant Moments,"This paper proposes a novel approach to the retrieval of buildings' height from multi-angular high spatial resolution images. To achieve this task, we combined two main concepts: multilevel morphological attribute filters, used for the definition of the objects in the image, and geometric invariant moments exploited for the characterization of the spatial properties of the previously detected shapes. The main concept of this study relies on the spatial properties of very high resolution images acquired from different angles of view. In particular, if we model the urban environment as an ensemble of vertical and horizontal surfaces, we can assume that the shapes related to the horizontal surfaces (i.e. the top of the buildings) do not suffer any relevant spatial distortion if detected from two angles of view, while vertical surfaces present strong changes in shape. Starting from this assumption, once each shape in each angular images has been spatially characterized, it is possible to identify univocally the same horizontal surface (i.e. the roof of a building) in each angular image. Finally, the knowledge of the acquisition angles permits the retrieval of the buildings height using simple trigonometric calculations. In this paper the proposed approach has been successfully applied to a WorldView-2 (WV2) very high resolution dataset composed by five angular images.",
Routing for Power Minimization in the Speed Scaling Model,"We study network optimization that considers power minimization as an objective. Studies have shown that mechanisms such as speed scaling can significantly reduce the power consumption of telecommunication networks by matching the consumption of each network element to the amount of processing required for its carried traffic. Most existing research on speed scaling focuses on a single network element in isolation. We aim for a network-wide optimization. Specifically, we study a routing problem with the objective of provisioning guaranteed speed/bandwidth for a given demand matrix while minimizing power consumption. Optimizing the routes critically relies on the characteristic of the speed-power curve f(s), which is how power is consumed as a function of the processing speed s. If f is superadditive, we show that there is no bounded approximation in general for integral routing, i.e., each traffic demand follows a single path. This contrasts with the well-known logarithmic approximation for subadditive functions. However, for common speed-power curves such as polynomials f(s) = μsα, we are able to show a constant approximation via a simple scheme of randomized rounding. We also generalize this rounding approach to handle the case in which a nonzero startup cost σ appears in the speed-power curve, i.e., f(s) = {σ + μsα, if s >; 0; 0, if s = 0. We present an O((σ/μ)1/α)-approximation, and we discuss why coming up with an approximation ratio independent of the startup cost may be hard. Finally, we provide simulation results to validate our algorithmic approaches.","Approximation methods,
Routing,
Power demand,
Polynomials,
Cost function,
Bandwidth"
A survey of fast mode decision algorithms for inter-prediction and their applications to high efficiency video coding,"The emerging High Efficiency Video Coding (HEVC) standard attempts to improve the coding efficiency by a factor of two over H.264/AVC using new compression tools with high computational complexity. The increased computational complexity makes the real-time execution with reasonable computing power become one of the critical concerns for the commercialization of HEVC. A large number of prediction modes are the main causes of the increased complexity of HEVC. Thus, a fast decision of a prediction mode needs to be effectively used to reduce the computational complexity. To take advantage of large amounts of previous works and to find a guide for application to HEVC, this paper presents a survey of these efforts for the previous standards, especially for H.264/AVC, and examines the possibility of the previous algorithms to be applicable for HEVC. To this end, previous algorithms are categorized and then the effectiveness of each category for HEVC is evaluated. For this evaluation, a previous algorithm is modified for HEVC when it is not applicable to HEVC directly. Simulation results show that most previous algorithms with slight modification, in general, improve the encoding speed with a relatively small degradation of the compression efficiency. Among them, hierarchical mode decision is especially effective whereas mode pre-decision using motion or spatial homogeneity often results in inaccurate results.","Video coding,
Prediction algorithms,
Correlation,
Software algorithms,
Encoding,
Classification algorithms,
Algorithm design and analysis"
Hidden-Concept Driven Multilabel Image Annotation and Label Ranking,"Conventional semisupervised image annotation algorithms usually propagate labels predominantly via holistic similarities over image representations and do not fully consider the label locality, inter-label similarity, and intra-label diversity among multilabel images. Taking these problems into consideration, we present the hidden-concept driven image annotation and label ranking algorithm (HDIALR), which conducts label propagation based on the similarity over a visually semantically consistent hidden-concepts space. The proposed method has the following characteristics: 1) each holistic image representation is implicitly decomposed into label representations to reveal label locality: the decomposition is guided by the so-called hidden concepts, characterizing image regions and reconstructing both visual and nonvisual labels of the entire image; 2) each label is represented by a linear combination of hidden concepts, while the similar linear coefficients reveal the inter-label similarity; 3) each hidden concept is expressed as a respective subspace, and different expressions of the same label over the subspace then induce the intra-label diversity; and 4) the sparse coding-based graph is proposed to enforce the collective consistency between image labels and image representations, such that it naturally avoids the dilemma of possible inconsistency between the pairwise label similarity and image representation similarity in multilabel scenario. These properties are finally embedded in a regularized nonnegative data factorization formulation, which decomposes images representations into label representations over both labeled and unlabeled data for label propagation and ranking. The objective function is iteratively optimized by a convergence provable updating procedure. Extensive experiments on three benchmark image datasets well validate the effectiveness of our proposed solution to semisupervised multilabel image annotation and label ranking problem.","Matrix decomposition,
Image representation,
Image segmentation,
Birds,
Semantics,
Sun,
Rocks"
Comparison between JSON and XML in Applications Based on AJAX,"As the core technology of Web 2.0, Ajax has caught more and more attention. Xml, as the traditional data load format, needs to be resolved by DOM (Document Object Model ) both in client-side and server-side, which wastes system resource and makes a great reduction of user-friendliness. In this paper, a light-weightdata-interchanging format-JSON (Java Script Object Notation) will be introduced, which provides a higher level of flexibility and efficiency. We make a comparison between JSON and XML through expriment, then use JSON as data-transfering format in an actual project. Results show that JSON is more suitable as a data-loading tool for Ajax applications.","XML,
Reactive power,
Educational institutions,
Servers,
Standards"
Performance evaluation of Smart Grid data aggregation via homomorphic encryption,"Homomorphic encryption allows arithmetic operations to be performed on ciphertext and gives the same result as if the same arithmetic operation is done on the plaintext. Homomorphic encryption has been touted as one of the promising methods to be employed in Smart Grid (SG) to provide data privacy which is one of the main security concerns in SG. In addition to data privacy, real-time data flow is crucial in SG to provide on-time detection and recovery of possible failures. In this paper, we investigate the overhead of using homomorphic encryption in SG in terms of bandwidth and end-to-end data delay when providing data privacy. Specifically, we compare the latency and data size of end-to-end (ETE) and hop-by-hop (HBH) homomorphic encryption within a network of Smart Meters (SMs). In HBH encryption, at each intermediate node, the received encrypted data from downstream nodes are decrypted first before the aggregation, and then the result is encrypted again for transmission to upstream nodes. On the other hand, the intermediate node in ETE encryption only performs aggregation on ciphertexts for transmission to upstream nodes. We implemented secure data aggregation using Paillier cryptosystem and tested it under various conditions. The experiment results have shown that even though HBH homomorphic encryption has additional computational overhead at intermediate nodes, surprisingly it provides comparable latency and fixed data size passing through the network compared to ETE homomorphic encryption.","Encryption,
Power demand,
Wireless sensor networks,
Delay,
Electricity"
A rainfall prediction model using artificial neural network,"The multilayered artificial neural network with learning by back-propagation algorithm configuration is the most common in use, due to of its ease in training. It is estimated that over 80% of all the neural network projects in development use back-propagation. In back-propagation algorithm, there are two phases in its learning cycle, one to propagate the input patterns through the network and other to adapt the output by changing the weights in the network. The back-propagation-feed forward neural network can be used in many applications such as character recognition, weather and financial prediction, face detection etc. The paper implements one of these applications by building training and testing data sets and finding the number of hidden neurons in these layers for the best performance. In the present research, possibility of predicting average rainfall over Udupi district of Karnataka has been analyzed through artificial neural network models. In formulating artificial neural network based predictive models three layered network has been constructed. The models under study are different in the number of hidden neurons.",
Semantic-Aware Metadata Organization Paradigm in Next-Generation File Systems,"Existing data storage systems based on the hierarchical directory-tree organization do not meet the scalability and functionality requirements for exponentially growing data sets and increasingly complex metadata queries in large-scale, Exabyte-level file systems with billions of files. This paper proposes a novel decentralized semantic-aware metadata organization, called SmartStore, which exploits semantics of files' metadata to judiciously aggregate correlated files into semantic-aware groups by using information retrieval tools. The key idea of SmartStore is to limit the search scope of a complex metadata query to a single or a minimal number of semantically correlated groups and avoid or alleviate brute-force search in the entire system. The decentralized design of SmartStore can improve system scalability and reduce query latency for complex queries (including range and top-k queries). Moreover, it is also conducive to constructing semantic-aware caching, and conventional filename-based point query. We have implemented a prototype of SmartStore and extensive experiments based on real-world traces show that SmartStore significantly improves system scalability and reduces query latency over database approaches. To the best of our knowledge, this is the first study on the implementation of complex queries in large-scale file systems.","Semantics,
Indexes,
Correlation,
Large scale integration,
Organizations,
Computational complexity"
Network-Based Distributed Mobility Control in Localized Mobile LISP Networks,"In Locator-Identifier Separation Protocol (LISP), the existing mobility control scheme is based on a centralized approach, in which the Map Server is used as a mobility anchor. However, such a centralized scheme has some limitations, including traffic overhead at central server, service degradation by a single point of failure, and larger handover delay. In this Letter, we propose a network-based distributed mobility control in localized mobile LISP networks. From numerical analysis, it is shown that the proposed distributed scheme can provide better performance than the existing centralized scheme in terms of the signaling loads for binding update/query and the handover delay.","Manganese,
Delay,
Mobile communication,
Least squares approximation,
Mobile computing,
Registers,
Switches"
On the Maximum Achievable Sum-Rate With Successive Decoding in Interference Channels,"In this paper, we investigate the maximum achievable sum-rate of the two-user Gaussian interference channel with Gaussian superposition coding and successive decoding. We first examine an approximate deterministic formulation of the problem, and introduce the complementarity conditions that capture the use of Gaussian coding and successive decoding. In the deterministic channel problem, we find the constrained sum-capacity and its achievable schemes with the minimum number of messages, first in symmetric channels, and then in general asymmetric channels. We show that the constrained sum-capacity oscillates as a function of the cross link gain parameters between the information theoretic sum-capacity and the sum-capacity with interference treated as noise. Furthermore, we show that if the number of messages of either of the two users is fewer than the minimum number required to achieve the constrained sum-capacity, the maximum achievable sum-rate drops to that with interference treated as noise. We provide two algorithms to translate the optimal schemes in the deterministic channel model to the Gaussian channel model. We also derive two upper bounds on the maximum achievable sum-rate of the Gaussian Han-Kobayashi schemes, which automatically upper bound the maximum achievable sum-rate using successive decoding of Gaussian codewords. Numerical evaluations show that, similar to the deterministic channel results, the maximum achievable sum-rate with successive decoding in the Gaussian channels oscillates between that with Han-Kobayashi schemes and that with single message schemes.","Decoding,
Receivers,
Interference channels,
Noise,
Upper bound,
Channel models"
The Universe at extreme scale: Multi-petaflop sky simulation on the BG/Q,"Remarkable observational advances have established a compelling cross-validated model of the Universe. Yet, two key pillars of this model -- dark matter and dark energy -- remain mysterious. Next-generation sky surveys will map billions of galaxies to explore the physics of the 'Dark Universe'. Science requirements for these surveys demand simulations at extreme scales; these will be delivered by the HACC (Hybrid/Hardware Accelerated Cosmology Code) framework. HACC's novel algorithmic structure allows tuning across diverse architectures, including accelerated and multi-core systems. On the IBM BG/Q, HACC attains unprecedented scalable performance - currently 6.23 PFlops at 62% of peak and 92% parallel efficiency on 786,432 cores (48 racks) - at extreme problem sizes with up to almost two trillion particles, larger than any cosmological simulation yet performed. HACC simulations at these scales will for the first time enable tracking individual galaxies over the entire volume of a cosmological survey.",
A genetic algorithm for discovering process trees,"Existing process discovery approaches have problems dealing with competing quality dimensions (fitness, simplicity, generalization, and precision) and may produce anomalous process models (e.g., deadlocking models). In this paper we propose a new genetic process mining algorithm that discovers process models from event logs. The tree representation ensures the soundness of the model. Moreover, as experiments show, it is possible to balance the different quality dimensions. Our genetic process mining algorithm is the first algorithm where the search process can be guided by preferences of the user while ensuring correctness.","Unified modeling language,
Genetic algorithms,
System recovery,
Data mining,
Analytical models,
Predictive models,
Genetics"
Motion saliency detection using low-rank and sparse decomposition,"Motion saliency detection has an important impact on further video processing tasks, such as video segmentation, object recognition and adaptive compression. Different to image saliency, in videos, moving regions (objects) catch human beings' attention much easier than static ones. Based on this observation, we propose a novel method of motion saliency detection, which makes use of the low-rank and sparse decomposition on video slices along X-T and Y-T planes to achieve the goal, i.e. separating foreground moving objects from backgrounds. In addition, we adopt the spatial information to preserve the completeness of the detected motion objects. In virtue of adaptive threshold selection and efficient noise elimination, the proposed approach is suitable for different video scenes, and robust to low resolution and noisy cases. The experiments demonstrate the performance of our method compared with the state-of-the-art.",
Active Subspace: Toward Scalable Low-Rank Learning,"We address the scalability issues in low-rank matrix learning problems. Usually these problems resort to solving nuclear norm regularized optimization problems (NNROPs), which often suffer from high computational complexities if based on existing solvers, especially in large-scale settings. Based on the fact that the optimal solution matrix to an NNROP is often low rank, we revisit the classic mechanism of low-rank matrix factorization, based on which we present an active subspace algorithm for efficiently solving NNROPs by transforming large-scale NNROPs into small-scale problems. The transformation is achieved by factorizing the large solution matrix into the product of a small orthonormal matrix (active subspace) and another small matrix. Although such a transformation generally leads to nonconvex problems, we show that a suboptimal solution can be found by the augmented Lagrange alternating direction method. For the robust PCA (RPCA) (Candès, Li, Ma, & Wright, 2009) problem, a typical example of NNROPs, theoretical results verify the suboptimality of the solution produced by our algorithm. For the general NNROPs, we empirically show that our algorithm significantly reduces the computational complexity without loss of optimality.",
Exposing Digital Forgeries in Ballistic Motion,"We describe a geometric technique to detect physically implausible trajectories of objects in video sequences. This technique explicitly models the three-dimensional ballistic motion of objects in free-flight and the two-dimensional projection of the trajectory into the image plane of a static or moving camera. Deviations from this model provide evidence of manipulation. The technique assumes that the object's trajectory is substantially influenced only by gravity, that the image of the object's center of mass can be determined from the images, and requires that any camera motion can be estimated from background elements. The computational requirements of the algorithm are modest, and any detected inconsistencies can be illustrated in an intuitive, geometric fashion. We demonstrate the efficacy of this analysis on videos of our own creation and on videos obtained from video-sharing websites.","Cameras,
Projectiles,
Trajectory,
Forensics,
Equations,
Security,
Estimation"
ENteric Immunity SImulator: A Tool for In Silico Study of Gastroenteric Infections,"Clinical symptoms of microbial infection of the gastrointestinal (GI) tract are often exacerbated by inflammation induced pathology. Identifying novel avenues for treating and preventing such pathologies is necessary and complicated by the complexity of interacting immune pathways in the gut, where effector and inflammatory immune cells are regulated by anti-inflammatory or regulatory cells. Here we present new advances in the development of the ENteric Immunity SImulator (ENISI), a simulator of GI immune mechanisms in response to resident commensal bacteria as well as invading pathogens and the effect on the development of intestinal lesions. ENISI is a tool for identifying potential treatment strategies that reduce inflammation-induced damage and, at the same time, ensure pathogen removal by allowing one to test plausibility of in vitro observed behavior as explanations for observations in vivo, propose behaviors not yet tested in vitro that could explain these tissue-level observations, and conduct low-cost, preliminary experiments of proposed interventions/treatments. An example of such application is shown in which we simulate dysentery resulting from Brachyispira hyodysenteriae infection and identify aspects of the host immune pathways that lead to continued inflammation-induced tissue damage even after pathogen elimination.","Immune system,
Pathogens,
Mathematical model,
Microorganisms,
Computational modeling,
Biological system modeling,
Adaptation models"
Oriented Modulation for Watermarking in Direct Binary Search Halftone Images,"In this paper, a halftoning-based watermarking method is presented. This method enables high pixel-depth watermark embedding, while maintaining high image quality. This technique is capable of embedding watermarks with pixel depths up to 3 bits without causing prominent degradation to the image quality. To achieve high image quality, the parallel oriented high-efficient direct binary search (DBS) halftoning is selected to be integrated with the proposed orientation modulation (OM) method. The OM method utilizes different halftone texture orientations to carry different watermark data. In the decoder, the least-mean-square-trained filters are applied for feature extraction from watermarked images in the frequency domain, and the naïve Bayes classifier is used to analyze the extracted features and ultimately to decode the watermark data. Experimental results show that the DBS-based OM encoding method maintains a high degree of image quality and realizes the processing efficiency and robustness to be adapted in printing applications.","Watermarking,
Satellite broadcasting,
Feature extraction,
Image quality,
Frequency domain analysis,
Decoding,
Modulation"
Biometric Authentication: System Security and User Privacy,"While biometric systems aren't foolproof, the research community has made significant strides to identify vulnerabilities and develop measures to counter them.","Biometrics,
Network security,
Authentication,
Privacy"
ICFHR 2012 Competition on Writer Identification Challenge 1: Latin/Greek Documents,"Writer identification is important for forensic analysis, helping experts to deliberate on the authenticity of documents. The general objective of the ICFHR 2012 Writer Identification Contest is to record recent advances in the field of writer identification using established evaluation performance measures. Challenge 1 of the contest deals specifically with Latin scripts. The benchmarking dataset of challenge 1 of the contest was created with the help of 100 writers that were asked to copy four parts of text in two languages (English and Greek). This paper describes the contest details for this challenge including the evaluation measures used as well as the performance of the seven submitted methods along with a short description of each method.","Benchmark testing,
Educational institutions,
Accuracy,
Laboratories,
Image edge detection,
Writing,
Computer science"
Simulation of a wireless power transfer system for electric vehicles with power factor correction,"Wireless power transfer has been a popular topic of recent research. Most research has been done to address the limitations of coil-to-coil efficiency. However, little has been done to address the problem associated with the low input power factor with which the systems operate. This paper details the steps taken to analyze a wireless power transfer system from the view of the power grid under a variety of loading conditions with and without power factor correction.","Coils,
Couplings,
Reactive power,
Integrated circuit modeling,
Load modeling,
Wireless communication,
Batteries"
Controller Area Network (CAN): Response time analysis with offsets,"Desynchronizing streams of frames through the means of offsets has today become common practice in automotive CAN networks. This is because this traffic shaping strategy is very beneficial in terms of reducing response times especially at high load levels. However, to the best of our knowledge, there is no result available in the literature that allows the response times of frames with offsets to be calculated for CAN. In this paper, we address this shortcoming of existing CAN schedulability analysis, and propose an extendible framework built upon the transaction model to derive worst-case response times (WCRT) on CAN. As will be shown in the experiments performed on realistic automotive networks, explicitly integrating offsets in the analysis permits a much tighter WCRT evaluation than with the classical synchronous analysis, which ultimately enables the designer to reduce resource over-provisioning.","Time factors,
Jitter,
Analytical models,
Communication systems,
Automotive engineering,
Synchronization,
Delay"
Corrective Line Switching With Security Constraints for the Base and Contingency Cases,"Following a line outage, the fast corrective operations of transmission line switching might be used to regain N-1 security of the system without generation re-dispatch or load shedding. The problem to find feasible switching operations can be formulated as a constraint satisfaction problem (CSP). Feasibility checking, however, is difficult since changes in load flows caused by line switching operations are discontinuous, and many contingency cases need to be examined. In this paper, DC flow is considered for simplicity, and variables include binary line statuses and continuous phase angles. Security constraints for the base case, N-1, and selected N-2 cases are formulated in a unified way by using a separate set of phase angles for each case. The problem is solved by using constraint programming (CP), and a tree search procedure is developed. Since it is time consuming to handle continuous variables in the tree search, only binary variables are branched on. Once reaching a leaf node where the topology is fixed, the constraints become linear DC flow feasibility conditions and are examined by solving a linear programming problem. Effectiveness of the method is demonstrated on IEEE 30-bus and 118-bus systems.","Switches,
Generators,
Security,
Search problems,
Topology,
Transient analysis"
Heartbeat and Respiration Detection From Optical Interferometric Signals by Using a Multimethod Approach,"In this paper, a multimethod approach for heartbeat and respiration detection from an optical interferometric signal is proposed. Optical interferometer is a sensitive device that detects physical changes of optical-fiber length due to external perturbations. When in direct or indirect contact with human body (e.g., hidden in a bed mattress), mechanical and acoustic activity of cardiac muscle and respiration reflect in the interferometric signal, enabling entirely unobtrusive monitoring of heartbeat and respiration. A novel, two-phased multimethod approach was developed for this purpose. The first phase selects best performing combinations of detection methods on a training set of signals. The second phase applies the selected methods to test set of signals and fuses all the detections of vital signs. The test set consisted of 14 subjects cycling an ergometer until reaching their submaximal heart rate. The following resting periods were analyzed showing high efficiency (98.18 ± 1.40% sensitivity and 97.04 ± 4.95% precision) and accuracy (mean absolute error of beat-to-beat intervals 22±9 ms) for heartbeat detection, and acceptable efficiency (90.06 ± 7.49% sensitivity and 94.21 ± 3.70% precision) and accuracy (mean absolute error of intervals between respiration events 0.33 ± 0.14 s) for respiration detection.","Heart beat,
Optical interferometry,
Heart rate variability,
Optical fibers,
Band pass filters,
Optical fiber sensors,
Optical filters"
Targeted Steganalysis of Edge Adaptive Image Steganography Based on LSB Matching Revisited Using B-Spline Fitting,"In this letter, the authors point out that the readjusting phase of edge adaptive image steganography based on LSB matching revisited introduces a pulse distortion to the long exponential tail of the histogram of the absolute difference of the pixel pairs. Making use of this observation, a targeted steganalytic method based on B-Spline fitting is proposed. Experimental results show that the proposed method obtains excellent results for detecting stego images with low embedding rate. The dominant performance of our method compared with state-of-the-art blind steganalyzers, such as SPAM and SRM is apparent. Furthermore, our method can accurately estimate the threshold used in the secret data embedding procedure and can separate the stego images with unit block size from those with block sizes greater than one.","Histograms,
Image edge detection,
Splines (mathematics),
Educational institutions,
Machine learning algorithms,
Algorithm design and analysis,
Feature extraction"
DDC: A Novel Scheme to Directly Decode the Collisions in UHF RFID Systems,"RFID has been gaining popularity due to its variety of applications, such as inventory control and localization. One important issue in RFID system is tag identification. In RFID systems, the tag randomly selects a slot to send a Random Number (RN) packet to contend for identification. Collision happens when multiple tags select the same slot, which makes the RN packet undecodable and thus reduces the channel utilization. In this paper, we redesign the RN pattern to make the collided RNs decodable. By leveraging the collision slots, the system performance can be dramatically enhanced. This novel scheme is called DDC, which is able to directly decode the collisions without exact knowledge of collided RNs. In the DDC scheme, we modify the RN generator in RFID tag and add a collision decoding scheme for RFID reader. We implement DDC in GNU Radio and USRP2 based testbed to verify its feasibility. Both theoretical analysis and testbed experiment show that DDC achieves 40 percent tag read rate gain compared with traditional RFID protocol.","Radiofrequency identification,
Protocols,
Estimation,
Decoding,
Algorithm design and analysis,
Throughput,
Frequency estimation"
"Planar F-Deletion: Approximation, Kernelization and Optimal FPT Algorithms","Let F be a finite set of graphs. In the F-DELETION problem, we are given an n-vertex graph G and an integer k as input, and asked whether at most k vertices can be deleted from G such that the resulting graph does not contain a graph from F as a minor. F-DELETION is a generic problem and by selecting different sets of forbidden minors F, one can obtain various fundamental problems such as VERTEX COVER, FEEDBACK VERTEX SET or TREEWIDTH η-DELETION. In this paper we obtain a number of generic algorithmic results about F-DELETION, when F contains at least one planar graph. The highlights of our work are · A constant factor approximation algorithm for the optimization version of F-DELETION; · A linear time and single exponential parameterized algorithm, that is, an algorithm running in time O(2O(k)n), for the parameterized version of F-DELETION where all graphs in F are connected; · A polynomial kernel for parameterized F-DELETION. These algorithms unify, generalize, and improve a multitude of results in the literature. Our main results have several direct applications, but also the methods we develop on the way have applicability beyond the scope of this paper. Our results - constant factor approximation, polynomial kernelization and FPT algorithms - are stringed together by a common theme of polynomial time preprocessing.","Approximation algorithms,
Approximation methods,
Polynomials,
Kernel,
Indexes,
Complexity theory,
Optimization"
Bug introducing changes: A case study with Android,"Changes, a rather inevitable part of software development can cause maintenance implications if they introduce bugs into the system. By isolating and characterizing these bug introducing changes it is possible to uncover potential risky source code entities or issues that produce bugs. In this paper, we mine the bug introducing changes in the Android platform by mapping bug reports to the changes that introduced the bugs. We then use the change information to look for both potential problematic parts and dynamics in development that can cause maintenance implications. We believe that the results of our study can help better manage Android software development.","Androids,
Humanoid robots,
Computer bugs,
Software,
Prediction algorithms,
Programming,
Joining processes"
A sparse representation approach to face matching across plastic surgery,"Plastic surgery procedures can significantly alter facial appearance, thereby posing a serious challenge even to the state-of-the-art face matching algorithms. In this paper, we propose a novel approach to address the challenges involved in automatic matching of faces across plastic surgery variations. In the proposed formulation, part-wise facial characterization is combined with the recently popular sparse representation approach to address these challenges. The sparse representation approach requires several images per subject in the gallery to function effectively which is often not available in several use-cases, as in the problem we address in this work. The proposed formulation utilizes images from sequestered non-gallery subjects with similar local facial characteristics to fulfill this requirement. Extensive experiments conducted on a recently introduced plastic surgery database [17] consisting of 900 subjects highlight the effectiveness of the proposed approach.","Face,
Surgery,
Plastics,
Training,
Databases,
Face recognition,
Facial features"
On the Interpolation of Data with Normally Distributed Uncertainty for Visualization,"In many fields of science or engineering, we are confronted with uncertain data. For that reason, the visualization of uncertainty received a lot of attention, especially in recent years. In the majority of cases, Gaussian distributions are used to describe uncertain behavior, because they are able to model many phenomena encountered in science. Therefore, in most applications uncertain data is (or is assumed to be) Gaussian distributed. If such uncertain data is given on fixed positions, the question of interpolation arises for many visualization approaches. In this paper, we analyze the effects of the usual linear interpolation schemes for visualization of Gaussian distributed data. In addition, we demonstrate that methods known in geostatistics and machine learning have favorable properties for visualization purposes in this case.","Interpolation,
Gaussian processes,
Data visualization,
Uncertainty,
Distributed databases,
Random variables,
Data models"
Dynamical Behaviors of Discretized Second-Order Terminal Sliding-Mode Control Systems,"Discretization behaviors of second-order terminal sliding-mode control systems are studied. The existence, the stability, and basins of attraction of periodic solutions are investigated. The influence of the system's parameters on the size of the steady-state solution is discussed. Theoretical results are illustrated with simulation examples.","Orbits,
Trajectory,
Sliding mode control,
Steady-state,
Convergence,
Equations"
Graph Weight Allocation to Meet Laplacian Spectral Constraints,"We adjust the node and edge weightings of graphs using convex optimization to impose bounds on their Laplacian spectra. First, we derive necessary and sufficient conditions that characterize the feasibility of spectral bounds given positive node and edge weightings. Synthesizing these conditions leads naturally to algorithms that exploit convexity to achieve several eigenvalue bounds simultaneously. The algorithms we propose apply to many graph design problems as well as multi-agent systems control. Finally, we suggest efficient ways to accommodate larger graphs, and show that dual formulations lead to substantial improvement in the size of graphs that can be addressed.","Eigenvalues and eigenfunctions,
Laplace equations,
Linear matrix inequalities,
Symmetric matrices,
Aircraft,
Heuristic algorithms,
Optimization"
Analysis of template aging in iris biometrics,"It has been widely believed that biometric template aging does not occur for iris biometrics. We compare the match score distribution for short time-lapse iris image pairs, with a mean of approximately one month between the enrollment image and the verification image, to the match score distributions for image pairs with one, two and three years of time lapse. We find clear and consistent evidence of a template aging effect that is noticeable at one year and that increases with increasing time lapse. For a state-of-the-art iris matcher, and three years of time lapse, at a decision threshold corresponding to a one in two million false match rate, we observe an 153% increase in the false non-match rate, with a bootstrap estimated 95% confidence interval of 85% to 307%.","Iris recognition,
Aging,
Magnetic resonance,
Springs,
Humans,
Lighting"
Quantifying Cognitive State From EEG Using Dependence Measures,"The exquisite human ability to perceive facial features has been explained by the activity of neurons particularly responsive to faces, found in the fusiform gyrus and the anterior part of the superior temporal sulcus. This study hypothesizes and demonstrates that it is possible to automatically discriminate face processing from processing of a simple control stimulus based on processed EEGs in an online fashion with high temporal resolution using measures of statistical dependence applied on steady-state visual evoked potentials. Correlation, mutual information, and a novel measure of association, referred to as generalized measure of association (GMA), were applied on filtered current source density data. Dependences between channel locations were assessed for two separate conditions elicited by distinct pictures (a face and a Gabor grating) flickering at a rate of 17.5 Hz. Filter settings were chosen to minimize the distortion produced by bandpassing parameters on dependence estimation. Statistical analysis was performed for automated stimulus classification using the Kolmogorov-Smirnov test. Results show active regions in the occipito-parietal part of the brain for both conditions with a greater dependence between occipital and inferotemporal sites for the face stimulus. GMA achieved a higher performance in discriminating the two conditions. Because no additional face-like stimuli were examined, this study established a basic difference between one particular face and one nonface stimulus. Future work may use additional stimuli and experimental manipulations to determine the specificity of the current connectivity results.","Correlation,
Mutual information,
Visualization,
Electroencephalography,
Q factor,
Time series analysis"
Novel Diversity/MIMO PIFA Antenna With Broadband Circular Polarization for Multimode Satellite Navigation,"A broadband circular polarized two-element planar inverted-F antenna (PIFA) with pattern diversity and high isolation for multimode satellite navigation is reported. Circular polarization characteristic of the proposed antenna is achieved by introducing a cross branch at its corner of the ground. The modified PIFA structure gives the antenna a broadband impedance bandwidth characteristic. A prototype is fabricated and measured. The results show that this circular polarized antenna with compact dimension has broadband from 1.1 to 1.7 GHz and good isolation of 14 dB between the two elements over the whole band, which makes the antenna suitable for handheld terminal application of multimode satellite navigation.","Broadband antennas,
Antenna measurements,
Antenna radiation patterns,
Bandwidth,
Broadband communication,
Frequency measurement"
Discriminative Feature Selection by Nonparametric Bayes Error Minimization,"Feature selection is fundamental to knowledge discovery from massive amount of high-dimensional data. In an effort to establish theoretical justification for feature selection algorithms, this paper presents a theoretically optimal criterion, namely, the discriminative optimal criterion (DoC) for feature selection. Compared with the existing representative optimal criterion (RoC, [CHECK END OF SENTENCE]) which retains maximum information for modeling the relationship between input and output variables, DoC is pragmatically advantageous because it attempts to directly maximize the classification accuracy and naturally reflects the Bayes error in the objective. To make DoC computationally tractable for practical tasks, we propose an algorithmic framework, which selects a subset of features by minimizing the Bayes error rate estimated by a nonparametric estimator. A set of existing algorithms as well as new ones can be derived naturally from this framework. As an example, we show that the Relief algorithm [CHECK END OF SENTENCE] greedily attempts to minimize the Bayes error estimated by the k-Nearest-Neighbor (kNN) method. This new interpretation insightfully reveals the secret behind the family of margin-based feature selection algorithms [CHECK END OF SENTENCE], [CHECK END OF SENTENCE] and also offers a principled way to establish new alternatives for performance improvement. In particular, by exploiting the proposed framework, we establish the Parzen-Relief (P-Relief) algorithm based on Parzen window estimator, and the MAP-Relief (M-Relief) which integrates label distribution into the max-margin objective to effectively handle imbalanced and multiclass data. Experiments on various benchmark data sets demonstrate the effectiveness of the proposed algorithms.","Search problems,
Classification algorithms,
Minimization,
Optimization,
Training,
Algorithm design and analysis,
Kernel"
Change and Control Paradoxes in Mobile Infrastructure Innovation: The Android and iOS Mobile Operating Systems Cases,"The advent of the smart phone as a highly complex technology has been accompanied by mobile operating systems (OS), large communities of developers, diverse content providers, and increasingly complex networks, jointly forming digital infrastructures. The multi-faceted and relational character of such digital infrastructures raises issues around how change and control can be conceptualized and understood. We discuss how change and control are paradoxically related in digital infrastructures and how they affect the evolution of such infrastructures. We examine these paradoxes by examining the change in, and competition between, two mobile operating systems: Apple's iOS and Google's Android along with their related platform features and ecologies. We seek to validate a proposed theoretical framework of the dynamics of change and control through second-order analysis of the two cases. We observe that multiple factors had a significant effect on the evolution of these platforms including user interface, development platforms, business models, and value extraction principles. We observe how these factors significantly affect the evolution of mobile platform ecologies as well as speculate about the future of mobile system platforms.","Mobile communication,
Mobile computing,
Operating systems,
Smart phones,
Linux,
Business,
Ecosystems"
Temporal Denoising of Kinect Depth Data,"The release of the Microsoft Kinect has attracted the attention of researchers in a variety of computer science domains. Even though this device is still relatively new, its recent applications have shown some promising results in terms of replacing current conventional methods like the stereo-camera for robotics navigation, multi-camera system for motion detection and laser scanner for 3D reconstruction. While most work around the Kinect is on how to take full advantage of its capabilities, so far only a few studies have been carried out on the limitations of this device and fewer that provide solutions to enhance the precision of its measurements. In this paper, we review and analyse current work in this area, and present and evaluate a temporal denoising algorithm to reduce the instability of the depth measurements provided by the Kinect over different distances.","Sensors,
Vibrations,
Noise reduction,
Filtering algorithms,
Filtering,
Current measurement,
Cameras"
High-Speed Low-Power Viterbi Decoder Design for TCM Decoders,"High-speed, low-power design of Viterbi decoders for trellis coded modulation (TCM) systems is presented in this paper. It is well known that the Viterbi decoder (VD) is the dominant module determining the overall power consumption of TCM decoders. We propose a pre-computation architecture incorporated with T-algorithm for VD, which can effectively reduce the power consumption without degrading the decoding speed much. A general solution to derive the optimal pre-computation steps is also given in the paper. Implementation result of a VD for a rate-3/4 convolutional code used in a TCM system shows that compared with the full trellis VD, the precomputation architecture reduces the power consumption by as much as 70% without performance loss, while the degradation in clock speed is negligible.","Decoding,
Computer architecture,
Viterbi algorithm,
Clocks,
Convolutional codes,
Power demand"
Designing an Adaptive Acoustic Modem for Underwater Sensor Networks,"There is a growing interest in using underwater networked systems for oceanographic applications. These networks often rely on acoustic communication, which poses a number of challenges for reliable data transmission. The underwater acoustic channel is highly variable; each link can experience vastly different conditions, which change according to environmental factors as well as the locations of the communicating nodes. This makes it difficult to ensure reliable communication. Furthermore, due to the high transmit power, the energy consumed in transmitting data is substantial, which is exacerbated at lower data rates. The main challenge that we address in this article is how to build a system that provides reliable and energy efficient communication in underwater sensor networks. To this end, we propose an adaptive underwater acoustic modem which changes its parameters according to the situation. We present the design of such a modem and provide supporting results from simulations and experiments.","Modems,
Frequency shift keying,
Chirp,
Spread spectrum communication,
Delay,
Acoustics"
Degrees of freedom of 2-user and 3-user rank-deficient MIMO interference channels,"We study the degrees of freedom (DoF) of 2-user and 3-user multiple input multiple output (MIMO) interference channels with rank deficient channel matrices. Only achievable DoF results and trivial outer bounds were previously available for these problems, restricted to symmetric settings. For the 2-user rank deficient MIMO interference channel we prove the optimality of previously known achievable DoF in the symmetric case and generalize the result to fully asymmetric settings. For the 3-user rank deficient MIMO interference channel, we improve the achievable DoF and provide a tight outer bound to establish optimality. Linear precoding based achievable schemes are found to be DoF optimal in both cases.","radiofrequency interference,
linear codes,
MIMO communication,
precoding"
Incompressible Deformation Estimation Algorithm (IDEA) From Tagged MR Images,"Measuring the 3D motion of muscular tissues, e.g., the heart or the tongue, using magnetic resonance (MR) tagging is typically carried out by interpolating the 2D motion information measured on orthogonal stacks of images. The incompressibility of muscle tissue is an important constraint on the reconstructed motion field and can significantly help to counter the sparsity and incompleteness of the available motion information. Previous methods utilizing this fact produced incompressible motions with limited accuracy. In this paper, we present an incompressible deformation estimation algorithm (IDEA) that reconstructs a dense representation of the 3D displacement field from tagged MR images and the estimated motion field is incompressible to high precision. At each imaged time frame, the tagged images are first processed to determine components of the displacement vector at each pixel relative to the reference time. IDEA then applies a smoothing, divergence-free, vector spline to interpolate velocity fields at intermediate discrete times such that the collection of velocity fields integrate over time to match the observed displacement components. Through this process, IDEA yields a dense estimate of a 3D displacement field that matches our observations and also corresponds to an incompressible motion. The method was validated with both numerical simulation and in vivo human experiments on the heart and the tongue.","Three dimensional displays,
Splines (mathematics),
Tagging,
Image reconstruction,
Estimation,
Smoothing methods,
Tracking"
An HTTP web traffic model based on the top one million visited web pages,"The ever-changing behavior of HTTP web pages requires an adjustment of the web models used for simulation and benchmarking. In this paper, we present the statistical data of the one million most visited web sites. Using this data, we examine the changes in size and number of objects by comparing our findings with well-known web traffic models. The results show a trend towards large pages including multimedia content. In addition, today's web pages are created dynamically, i.e., that the content is downloaded from web servers spread all around the world. Finally, we discuss new web traffic models and present the parameters gathered from our measurements.","Web pages,
Videos,
Browsers,
Internet,
Fires,
Size measurement,
Loading"
Sparse WiFi Deployment for Vehicular Internet Access With Bounded Interconnection Gap,"Vehicular Internet access via open WiFi access points (APs) has been demonstrated to be a feasible solution to provide opportunistic data service to moving vehicles. Using an in situ deployment, however, such a solution does not provide performance guarantees due to unpredictable intermittent connectivity. On the other hand, a solution that tries to cover every point in an entire road network with APs (a full coverage) is not very practical due to prohibitive deployment and operational costs. In this paper, we introduce a new notion of intermittent coverage for mobile users, called Alpha Coverage, which provides worst-case guarantees on the interconnection gap, i.e., the distance or expected delay between two consecutive mobile-AP contacts for a vehicle, while using significantly fewer APs than needed for full coverage. We propose efficient algorithms to verify whether a given deployment provides Alpha Coverage. The problem of finding an economic deployment that provides α -coverage turns out to be NP-hard. We hence provide both approximation algorithms that have provable guarantees on the performance as well as efficient heuristics that perform well in practice. The efficiency of our algorithms is demonstrated via simulations using data from real-world road networks.","Roads,
Approximation methods,
Approximation algorithms,
Mobile communication,
Internet,
IEEE 802.11 Standards,
Vehicles"
Improved Control Design Methods for Proximate Time-Optimal Servomechanisms,"It is well known that minimum time-optimal control for servomechanisms can generate chattering in the presence of measurement noises, feedback delays, or model uncertainties; thus, it is not practical in applications. Maybe, the most popular alternative approach is the so-called proximate time-optimal servomechanism (PTOS). This approach starts with a near-time-optimal controller and, then, switches to a linear controller when the system output is close to a given target. However, the chattering problem is avoided at the expense of a slower time response. In this paper, two methods for eliminating the conservatism present in the PTOS are proposed. The first method applies a dynamically damped controller that allows the so-called acceleration discount factor to be pushed arbitrarily close to 1. The second method applies a continuous nonlinear control law that makes use of no switching. Experimental results show that the proposed designs practically eliminate the conservatism in the traditional PTOS.","Damping,
Servomechanisms,
Motion control,
Automatic control"
Flickr Distance: A Relationship Measure for Visual Concepts,"This paper proposes the Flickr Distance (FD) to measure the visual correlation between concepts. For each concept, a collection of related images are obtained from the Flickr website. We assume that each concept consists of several states, e.g., different views, different semantics, etc., which are considered as latent topics. Then a latent topic visual language model (LTVLM) is built to capture these states. The Flickr distance between two concepts is defined as the Jensen-Shannon (J-S) divergence between their LTVLM. Differently from traditional conceptual distance measurements, which are based on Web textual documents, FD is based on the visual information. Comparing with the WordNet distance, FD can easily scale up with the increasing size of the conceptual corpus. Comparing with the Google Distance (NGD) and Tag Concurrence Distance (TCD), FD uses the visual information and can properly measure the conceptual relations. We apply FD to multimedia-related tasks and find methods based on FD significantly outperform those based on NGD and TCD. With the FD measurement, we also construct a large-scale visual conceptual network (VCNet) to store the knowledge of conceptual relationship. Experiments show that FD is more coherent to human cognition and it also outperforms text-based distances in real-world applications.",
Multiple-Target Tracking for Intelligent Headlights Control,"Intelligent vehicle lighting systems aim at automatically regulating the headlights' beam to illuminate as much of the road ahead as possible while avoiding dazzling other drivers. A key component of such a system is computer vision software that is able to distinguish blobs due to vehicles' headlights and rear lights from those due to road lamps and reflective elements such as poles and traffic signs. In a previous work, we have devised a set of specialized supervised classifiers to make such decisions based on blob features related to its intensity and shape. Despite the overall good performance, there remain challenging that have yet to be solved: notably, faint and tiny blobs corresponding to quite distant vehicles. In fact, for such distant blobs, classification decisions can be taken after observing them during a few frames. Hence, incorporating tracking could improve the overall lighting system performance by enforcing the temporal consistency of the classifier decision. Accordingly, this paper focuses on the problem of constructing blob tracks, which is actually one of multiple-target tracking (MTT), but under two special conditions: We have to deal with frequent occlusions, as well as blob splits and merges. We approach it in a novel way by formulating the problem as a maximum a posteriori inference on a Markov random field. The qualitative (in video form) and quantitative evaluation of our new MTT method shows good tracking results. In addition, we will also see that the classification performance of the problematic blobs improves due to the proposed MTT algorithm.",
Fast Morphological Image Processing Open-Source Extensions for GPU Processing With CUDA,"GPU architectures offer a significant opportunity for faster morphological image processing, and the NVIDIA CUDA architecture offers a relatively inexpensive and powerful framework for performing these operations. However, the generic morphological erosion and dilation operation in the CUDA NPP library is relatively naive, and performance scales expensively with increasing structuring element size. The objective of this work is to produce a freely available GPU capability for morphological operations so that fast GPU processing can be readily available to those in the morphological image processing community. Open-source extensions to CUDA (hereafter referred to as LTU-CUDA) have been produced for erosion and dilation using a number of structuring elements for both 8 bit and 32 bit images. Support for 32 bit image data is a specific objective of the work in order to facilitate fast processing of image data from 3D range sensors with high depth precision. Furthermore, the implementation specifically allows scalability of image size and structuring element size for processing of large image sets. Images up to 4096 by 4096 pixels with 32 bit precision were tested. This scalability has been achieved by forgoing the use of shared memory in CUDA multiprocessors. The vHGW algorithm for erosion and dilation independent of structuring element size has been implemented for horizontal, vertical, and 45 degree line structuring elements with significant performance improvements over NPP. However, memory handling limitations hinder performance in the vertical line case providing results not independent of structuring element size and posing an interesting challenge for further optimisation. This performance limitation is mitigated for larger structuring elements using an optimised transpose function, which is not default in NPP, and applying the horizontal structuring element. LTU-CUDA is an ongoing project and the code is freely available at https://github.com/VictorD/LTU-CUDA.","Graphics processing unit,
Application software,
Image processing,
Message systems,
Libraries,
Signal processing algorithms,
Timing"
Discovering Time-Constrained Sequential Patterns for Music Genre Classification,"A music piece can be considered as a sequence of sound events which represent both short-term and long-term temporal information. However, in the task of automatic music genre classification, most of text-categorization-based approaches could only capture temporal local dependencies (e.g., unigram and bigram-based occurrence statistics) to represent music contents. In this paper, we propose the use of time-constrained sequential patterns (TSPs) as effective features for music genre classification. First of all, an automatic language identification technique is performed to tokenize each music piece into a sequence of hidden Markov model indices. Then TSP mining is applied to discover genre-specific TSPs, followed by the computation of occurrence frequencies of TSPs in each music piece. Finally, support vector machine classifiers are employed based on these occurrence frequencies to perform the classification task. Experiments conducted on two widely used datasets for music genre classification, GTZAN and ISMIR2004Genre, show that the proposed method can discover more discriminative temporal structures and achieve a better recognition accuracy than the unigram and bigram-based statistical approach.","Music,
Hidden Markov models,
Feature extraction,
Computer science,
Data mining,
Educational institutions"
Recursive Algorithm for Reliability Evaluation of Non-Repairable Phased Mission Systems With Binary Elements,"Many practical systems are phased-mission systems (PMS), where the mission consists of multiple, consecutive, and non-overlapping phases of operation. An accurate reliability analysis of a PMS must consider the statistical dependencies of component states across phases, as well as dynamics in system configurations, success criteria, and component behavior. In this paper, we propose a method for exact reliability evaluation of arbitrary binary or multi-state PMS consisting of non-identical binary non-repairable elements. The method is invariant to changes in system structure and demand among missions, and takes into account the time-varying and phase-dependent failure rates and associated cumulative damage effects. The proposed method is based on conditional probabilities, and an efficient recursive formula to compute these probabilities based on branch and bound. The main advantage of this method is that it does not require composition of decision diagrams, and can be fully automated. The method is illustrated using both an analytical example, and a numerical example.","Vectors,
Reliability,
System performance,
Acceleration,
Probability,
Stress,
Analytical models"
The inverted pendulum: A fundamental benchmark in control theory and robotics,"For at least fifty years, the inverted pendulum has been the most popular benchmark, among others, for teaching and researches in control theory and robotics. This paper presents the key motivations for the use of that system and explains, in details, the main reflections on how the inverted pendulum benchmark gives an effective and efficient application. Several real experiences, virtual models and web-based remote control laboratories will be presented with emphasis on the practical design implementation of this system. A bibliographical survey of different design control approaches and trendy robotic problems will be presented through applications to the inverted pendulum system. In total, 150 references in the open literature, dating back to 1960, are compiled to provide an overall picture of historical, current and challenging developments based on the stabilization principle of the inverted pendulum.","Control systems,
Robots,
Benchmark testing,
Control theory,
Education,
Laboratories,
Robustness"
Design of a Novel Test Fixture to Measure Rotational Core Losses in Machine Laminations,"The need for testing magnetic materials used in electric machine laminations and measurements under a rotating field is of importance in machine design. In order to obtain satisfactory experimental data, the design of the measurement apparatus deserves particular attention. The purpose of this paper is to propose a novel design of a magnetic circuit based on the Halbach array, which generates a uniform flux density inside the test specimen for the measurement of rotational core loss. The proposed design is simulated and prototyped, and experimental tests are performed on two different samples of M19 gauge-24 and M36 gauge-29 silicon steel at three different frequencies (60 Hz, 400 Hz, and 1 kHz). The field-metric method is used in this work to evaluate the rotational core losses.","Arrays,
Magnetic flux,
Core loss,
Magnetic circuits,
Loss measurement,
Magnetic field measurement,
Coils"
Robust Single-Hidden Layer Feedforward Network-Based Pattern Classifier,"In this paper, a new robust single-hidden layer feedforward network (SLFN)-based pattern classifier is developed. It is shown that the frequency spectrums of the desired feature vectors can be specified in terms of the discrete Fourier transform (DFT) technique. The input weights of the SLFN are then optimized with the regularization theory such that the error between the frequency components of the desired feature vectors and the ones of the feature vectors extracted from the outputs of the hidden layer is minimized. For the linearly separable input patterns, the hidden layer of the SLFN plays the role of removing the effects of the disturbance from the noisy input data and providing the linearly separable feature vectors for the accurate classification. However, for the nonlinearly separable input patterns, the hidden layer is capable of assigning the DFTs of all feature vectors to the desired positions in the frequency-domain such that the separability of all nonlinearly separable patterns are maximized. In addition, the output weights of the SLFN are also optimally designed so that both the empirical and the structural risks are well balanced and minimized in a noisy environment. Two simulation examples are presented to show the excellent performance and effectiveness of the proposed classification scheme.",
Application of Power System Frequency for Digital Audio Authentication,"Frequency is an important parameter for the operation and control of power systems. One novel application of frequency measurements involves using this information to authenticate a digital audio/video recording presented as forensic evidence in legal proceedings. To apply this technique, called the electrical network frequency (ENF) criterion, both a reference frequency database and an accurate frequency estimation method are required. This paper briefly introduces a wide-area frequency monitoring network (FNET) as the reference frequency database and analyzes statistical features of frequency of the four North American interconnections in terms of different time scales. Combined with digital filtering and a three-sample interpolation, the short-time Fourier transform (STFT) is adjusted to estimate the ENF embedded in digital audio recordings. A procedure of using the ENF criterion, ranging from signal preprocessing to ENF estimation and reference frequency database matching, is then proposed. Further, oscillator error of the digital recording device is considered and an iterative error correction method is given to assist with the frequency database matching. Factors which influence the accuracy of frequency estimation, such as parameter selections of the STFT and signal-to-noise ratio, are also discussed. Test results show that the procedure is capable of performing digital audio authentication.","Frequency estimation,
Authentication,
Time frequency analysis,
Oscillators,
Authentication,
Power systems,
Fourier transforms,
Digital audio broadcasting"
Providing Performance Guarantees in Multipass Network Processors,"Current network processors (NPs) increasingly deal with packets with heterogeneous processing times. In such an environment, packets that require many processing cycles delay low-latency traffic because the common approach in today's NPs is to employ run-to-completion processing. These difficulties have led to the emergence of the Multipass NP architecture, where after a processing cycle ends, all processed packets are recycled into the buffer and recompete for processing resources. In this paper, we provide a model that captures many of the characteristics of this architecture, and we consider several scheduling and buffer management algorithms that are specially designed to optimize the performance of multipass network processors. In particular, we provide analytical guarantees for the throughput performance of our algorithms. We further conduct a comprehensive simulation study, which validates our results.","Throughput,
Algorithm design and analysis,
Processor scheduling,
Recycling,
Instruction sets,
Memory management"
"A Comparison of Two MIMO Relaying Protocols in Nakagami- m
Fading","Transmit antenna selection with receive maximal-ratio combining (TAS/MRC) and transmit antenna selection with receive selection combining (TAS/SC) are two attractive multiple-input-multiple-output (MIMO) protocols. In this paper, we present a framework for the comparative analysis of TAS/MRC and TAS/SC in a two-hop amplify-and-forward relay network. In doing so, we derive exact and asymptotic expressions for the symbol error rate (SER) in Nakagami-m fading. Using the asymptotic expressions, the SNR gap between the two protocols is quantified. Given that the two protocols maintain the same diversity order, we show that the SNR gap is entirely dependent on the array gain. Motivated by this, we derive the SNR gap as a simple ratio of the respective array gains of the two protocols. This ratio explicitly takes into account the impact of the number of antennas and the fading severity parameter . In addition, we address the fundamental question of “How to allocate the total transmit power between the source and the relay in such a way that the SER is minimized?” Our answer is given in the form of new compact expressions for the power allocation factor, which is a practical design tool that optimally distributes the total transmit power in the network.","Relays,
Receiving antennas,
MIMO,
Signal to noise ratio,
Fading,
Protocols,
Transmitting antennas"
"Requirements, Challenges and Analysis of Alternatives for Wireless Datalinks for Unmanned Aircraft Systems","Two key challenges in the design of datalinks for unmanned aircraft (UAS) systems compared to other wireless links are the long range of distances and speeds that need to be covered. The 960 - 1164 MHz part of the IEEE L band has been identified as a candidate spectrum for future manned and unmanned aircraft datalinks. The amount of spectrum available in the L-Band is not sufficient to support video applications common in UASs and so dual-band designs using both L-Band and C-Band are being considered. For L-Band, two projects funded by EUROCONTROL L-Band Digital Aeronautical Communications Systems 1 and 2 (L-DACS1 and L-DACS2) are often mentioned for use in UAS also. We briefly discuss issues with their use for UAS. We compare the two proposals in terms of their scalability, spectral efficiency, and interference resistance. Then we discuss several issues in UAS datalink design including availability, networking, preemption, and chaining. We also propose ways to mitigate interference with other systems in the L-Band.","Aircraft,
OFDM,
WiMAX,
L-band,
Downlink,
Military aircraft"
High-Speed and Bias-Free Optical Random Number Generator,"True randomness is critical to secure communication in both quantum and classical regimes. We propose an approach of true random number generation based on the intrinsic randomness of spontaneous emission. In this approach, a method of random bit extraction was employed to extract true random bits simultaneously as the measurement of the physical entropy source. The random bits generated by the true random number generators have been statistically verified to be bias-free and mutually independent. With the current experimental setup, 7 random bits can be generated in parallel at a rate up to 40 GHz.",
Robust White Matter Lesion Segmentation in FLAIR MRI,"This paper discusses a white matter lesion (WML) segmentation scheme for fluid attenuation inversion recovery (FLAIR) MRI. The method computes the volume of lesions with subvoxel precision by accounting for the partial volume averaging (PVA) artifact. As WMLs are related to stroke and carotid disease, accurate volume measurements are most important. Manual volume computation is laborious, subjective, time consuming, and error prone. Automated methods are a nice alternative since they quantify WML volumes in an objective, efficient, and reliable manner. PVA is initially modeled with a localized edge strength measure since PVA resides in the boundaries between tissues. This map is computed in 3-D and is transformed to a global representation to increase robustness to noise. Significant edges correspond to PVA voxels, which are used to find the PVA fraction α (amount of each tissue present in mixture voxels). Results on simulated and real FLAIR images show high WML segmentation performance compared to ground truth (98.9% and 83% overlap, respectively), which outperforms other methods. Lesion load studies are included that automatically analyze WML volumes for each brain hemisphere separately. This technique does not require any distributional assumptions/parameters or training samples and is applied on a single MR modality, which is a major advantage compared to the traditional methods.","Lesions,
Image edge detection,
Magnetic resonance imaging,
Image segmentation,
Diseases,
Three dimensional displays,
Sensitivity"
Error Analysis for Matrix Elastic-Net Regularization Algorithms,"Elastic-net regularization is a successful approach in statistical modeling. It can avoid large variations which occur in estimating complex models. In this paper, elastic-net regularization is extended to a more general setting, the matrix recovery (matrix completion) setting. Based on a combination of the nuclear-norm minimization and the Frobenius-norm minimization, we consider the matrix elastic-net (MEN) regularization algorithm, which is an analog to the elastic-net regularization scheme from compressive sensing. Some properties of the estimator are characterized by the singular value shrinkage operator. We estimate the error bounds of the MEN regularization algorithm in the framework of statistical learning theory. We compute the learning rate by estimates of the Hilbert-Schmidt operators. In addition, an adaptive scheme for selecting the regularization parameter is presented. Numerical experiments demonstrate the superiority of the MEN regularization algorithm.",
Design and performance of an all-SiC three-phase buck rectifier for high efficiency data center power supplies,"This paper presents a 7.5 kW liquid cooled three-phase buck rectifier which will be used as the front-end rectifier in 400 Vdc architecture data center power supply systems. SiC MOSFETs and SiC Schottky barrier diodes (SBDs) are used in parallel to obtain low power semiconductor losses. Input and output filters are designed and inductor core material is compared to reduce passive component losses. A low-loss modulation scheme and 28 kHz switching frequency are selected to optimize the converter design for efficiency. A prototype of the proposed rectifier is constructed and tested, and greater than 98.5% efficiency is obtained at full load.","Rectifiers,
Silicon carbide,
Inductors,
MOSFETs,
Silicon,
Switching frequency,
Semiconductor diodes"
Learning rotation-aware features: From invariant priors to equivariant descriptors,"Identifying suitable image features is a central challenge in computer vision, ranging from representations for low-level to high-level vision. Due to the difficulty of this task, techniques for learning features directly from example data have recently gained attention. Despite significant benefits, these learned features often have many fewer of the desired invariances or equivariances than their hand-crafted counterparts. While translation in-/equivariance has been addressed, the issue of learning rotation-invariant or equivariant representations is hardly explored. In this paper we describe a general framework for incorporating invariance to linear image transformations into product models for feature learning. A particular benefit is that our approach induces transformation-aware feature learning, i.e. it yields features that have a notion with which specific image transformation they are used. We focus our study on rotation in-/equivariance and show the advantages of our approach in learning rotation-invariant image priors and in building rotation-equivariant and invariant descriptors of learned features, which result in state-of-the-art performance for rotation-invariant object detection.","Feature extraction,
Histograms,
Data models,
Image restoration,
Object detection,
Transforms,
Training data"
Nanofork for Single Cells Adhesion Measurement via ESEM-Nanomanipulator System,"In this paper, single cells adhesion force was measured using a nanofork. The nanofork was used to pick up a single cell on a line array substrate inside an environmental scanning electron microscope (ESEM). The line array substrate was used to provide small gaps between the single cells and the substrate. Therefore, the nanofork could be inserted through these gaps in order to successfully pick up a single cell. Adhesion force was measured during the cell pick-up process from the deflection of the cantilever beam. The nanofork was fabricated using focused ion beam (FIB) etching process while the line array substrate was fabricated using nanoimprinting technology. As to investigate the effect of contact area on the strength of the adhesion force, two sizes of gap distance of line array substrate were used, i.e., and . Results showed that cells attached on the gap line array substrate required more force to be released as compared to the cells attached on the gap line array substrate.","Nanobioscience,
Substrates,
Force,
Adhesives,
Arrays,
Force measurement,
Structural beams"
Sketch-Based Annotation and Visualization in Video Authoring,"Authoring context-aware, interactive video representation is usually a complex process. A user-friendly multimedia authoring environment is thus solicited to explore and express users' design ideas efficiently and naturally. In this paper we present a sketch-based two-layer representation, called scene structure graph (SSG), to facilitate the video authoring process. One layer in SSG uses sketches as a concise form with which the visualization of scene information is easily understood and the other layer uses a graph to represent and edit the narrative structure in the authoring process. With SSG, the authoring process works in two stages. In the first stage, various sketch forms such as symbols and hand-drawing illustrations are used as basic primitives to annotate the video clips and the hyperlinks encoding spatio-temporal relations are established in SSG. In the second stage, sketches in SSGs are modified and new SSG is composed for any particular authoring purpose. Three user studies are elaborated, showing that the SSG is user-friendly and can achieve a good balance between expressiveness of users' intent and ease of use for authoring of interactive video.",
Sherlock is around: Detecting network failures with local evidence fusion,"Traditional approaches for wireless sensor network diagnosis are mainly sink-based. They actively collect global evidences from sensor nodes to the sink so as to conduct centralized analysis at the powerful back-end. On the one hand, long distance proactive information retrieval incurs huge transmission overhead; On the other hand, due to the coupling effect between diagnosis component and the application itself, sink often fails to obtain complete and precise evidences from the network, especially for the problematic or critical parts. To avoid large overhead in evidence collection process, self-diagnosis injects fault inference modules into sensor nodes and let them make local decisions. Diagnosis results from single nodes, however, are generally inaccurate due to the narrow scope of system performances. Besides, existing self-diagnosis methods usually lead to inconsistent results from different inference processes. How to balance the workload among the sensor nodes in a diagnosis task is a critical issue. In this work, we present a new in-network diagnosis approach named Local-Diagnosis (LD2), which conducts the diagnosis process in a local area. LD2 achieves diagnosis decision through distributed evidence fusion operations. Each sensor node provides its own judgements and the evidences are fused within a local area based on the Dempster-Shafer theory, resulting in the consensus diagnosis report. We implement LD2 on TinyOS 2.1 and examine the performance on a 50 nodes indoor testbed.","Wireless sensor networks,
Bayesian methods,
Measurement,
Accuracy,
Reliability,
Computer crashes,
Protocols"
Iterative Solver for Linear System Obtained by Edge Element: Variable Preconditioned Method With Mixed Precision on GPU,"The variable preconditioned (VP) Krylov subspace method with mixed precision is implemented on graphics processing unit (GPU) using compute unified device architecture (CUDA), and the linear system obtained from the edge element is solved by means of the method. The VPGCR method has the sufficient condition for the convergence. This sufficient condition leads us that the residual equation for the preconditioned procedure of VPGCR can be solved in the range of single precision. To stretch the sufficient condition, we propose the hybrid scheme of VP Krylov subspace method that uses single and double precision operations. The results of computations show that VPCG with mixed precision on GPU demonstrated significant achievement than that of CPU. Especially, VPCG-JOR on GPU with mixed precision is 41.853 times faster than that of VPCG-CG on CPU.","Graphics processing unit,
Linear systems,
Peer to peer computing,
Educational institutions,
Mathematical model,
Symmetric matrices,
Vectors"
Evaluating Hadoop for Data-Intensive Scientific Operations,"Emerging sensor networks, more capable instruments, and ever increasing simulation scales are generating data at a rate that exceeds our ability to effectively manage, curate, analyze, and share it. Data-intensive computing is expected to revolutionize the next-generation software stack. Hadoop, an open source implementation of the MapReduce model provides a way for large data volumes to be seamlessly processed through use of large commodity computers. The inherent parallelization, synchronization and fault-tolerance the model offers, makes it ideal for highly-parallel data-intensive applications. MapReduce and Hadoop have traditionally been used for web data processing and only recently been used for scientific applications. There is a limited understanding on the performance characteristics that scientific data intensive applications can obtain from MapReduce and Hadoop. Thus, it is important to evaluate Hadoop specifically for data-intensive scientific operations -- filter, merge and reorder-- to understand its various design considerations and performance trade-offs. In this paper, we evaluate Hadoop for these data operations in the context of High Performance Computing (HPC) environments to understand the impact of the file system, network and programming modes on performance.","Conferences,
Cloud computing"
Hollow Out-of-Plane Polymer Microneedles Made by Solvent Casting for Transdermal Drug Delivery,"Although hollow microneedles have been proposed as an effective and convenient method for transdermal drug delivery, their expensive fabrication techniques to date have prevented their mass fabrication as a viable option. A novel method, based on solvent casting, is presented for inexpensive fabrication of hollow out-of-plane polymer microneedles. Microneedles are formed during a solvent evaporation process, which leaves a polymer layer around pillars in a prefabricated mold. The mold is fabricated using photolithography and can be used for consecutive solvent casting of microneedles. Arrays of microneedles with lengths up to 250 μm have been fabricated from clay-reinforced polyimide. Several mechanical tests were performed on solvent cast solid structures to find the optimum clay percentage in the polyimide that would lead to the highest compressive strength. The fabricated needles were tested for robustness, and it was observed that the needles were capable of withstanding on average compressive loads of up to 0.32 N. The suitability of the microneedles for skin penetration and drug delivery was demonstrated by injection of fluorescent beads into a skin sample.","Skin,
Solvents,
Polyimides,
Needles,
Casting,
Fabrication"
Computing Morse-Smale Complexes with Accurate Geometry,"Topological techniques have proven highly successful in analyzing and visualizing scientific data. As a result, significant efforts have been made to compute structures like the Morse-Smale complex as robustly and efficiently as possible. However, the resulting algorithms, while topologically consistent, often produce incorrect connectivity as well as poor geometry. These problems may compromise or even invalidate any subsequent analysis. Moreover, such techniques may fail to improve even when the resolution of the domain mesh is increased, thus producing potentially incorrect results even for highly resolved functions. To address these problems we introduce two new algorithms: (i) a randomized algorithm to compute the discrete gradient of a scalar field that converges under refinement; and (ii) a deterministic variant which directly computes accurate geometry and thus correct connectivity of the MS complex. The first algorithm converges in the sense that on average it produces the correct result and its standard deviation approaches zero with increasing mesh resolution. The second algorithm uses two ordered traversals of the function to integrate the probabilities of the first to extract correct (near optimal) geometry and connectivity. We present an extensive empirical study using both synthetic and real-world data and demonstrates the advantages of our algorithms in comparison with several popular approaches.","Geometry,
Manifolds,
Vectors,
Algorithm design and analysis,
Standards,
Robustness,
Topology"
"Analyst's Workspace: An embodied sensemaking environment for large, high-resolution displays","Distributed cognition and embodiment provide compelling models for how humans think and interact with the environment. Our examination of the use of large, high-resolution displays from an embodied perspective has lead directly to the development of a new sensemaking environment called Analyst's Workspace (AW). AW leverages the embodied resources made more accessible through the physical nature of the display to create a spatial workspace. By combining spatial layout of documents and other artifacts with an entity-centric, explorative investigative approach, AW aims to allow the analyst to externalize elements of the sensemaking process as a part of the investigation, integrated into the visual representations of the data itself. In this paper, we describe the various capabilities of AW and discuss the key principles and concepts underlying its design, emphasizing unique design principles for designing visual analytic tools for large, high-resolution displays.",
Living Liquid: Design and Evaluation of an Exploratory Visualization Tool for Museum Visitors,"Interactive visualizations can allow science museum visitors to explore new worlds by seeing and interacting with scientific data. However, designing interactive visualizations for informal learning environments, such as museums, presents several challenges. First, visualizations must engage visitors on a personal level. Second, visitors often lack the background to interpret visualizations of scientific data. Third, visitors have very limited time at individual exhibits in museums. This paper examines these design considerations through the iterative development and evaluation of an interactive exhibit as a visualization tool that gives museumgoers access to scientific data generated and used by researchers. The exhibit prototype, Living Liquid, encourages visitors to ask and answer their own questions while exploring the time-varying global distribution of simulated marine microbes using a touchscreen interface. Iterative development proceeded through three rounds of formative evaluations using think-aloud protocols and interviews, each round informing a key visualization design decision: (1) what to visualize to initiate inquiry, (2) how to link data at the microscopic scale to global patterns, and (3) how to include additional data that allows visitors to pursue their own questions. Data from visitor evaluations suggests that, when designing visualizations for public audiences, one should (1) avoid distracting visitors from data that they should explore, (2) incorporate background information into the visualization, (3) favor understandability over scientific accuracy, and (4) layer data accessibility to structure inquiry. Lessons learned from this case study add to our growing understanding of how to use visualizations to actively engage learners with scientific data.","Data visualization,
Learning systems,
Performance evaluation,
Motion pictures,
Prototypes,
Information analysis,
Image color analysis"
Parallelized Evolutionary Learning for Detection of Biclusters in Gene Expression Data,"The analysis of gene expression data obtained from microarray experiments is important for discovering the biological process of genes. Biclustering algorithms have been proven to be able to group the genes with similar expression patterns under a number of experimental conditions. In this paper, we propose a new biclustering algorithm based on evolutionary learning. By converting the biclustering problem into a common clustering problem, the algorithm can be applied in a search space constructed by the conditions. To further reduce the size of the search space, we randomly separate the full conditions into a number of condition subsets (subspaces), each of which has a smaller number of conditions. The algorithm is applied to each subspace and is able to discover bicluster seeds within a limited computing time. Finally, an expanding and merging procedure is employed to combine the bicluster seeds into larger biclusters according to a homogeneity criterion. We test the performance of the proposed algorithm using synthetic and real microarray data sets. Compared with several previously developed biclustering algorithms, our algorithm demonstrates a significant improvement in discovering additive biclusters.","Gene expression,
Clustering algorithms,
Bioinformatics,
Search problems,
Computational biology,
Algorithm design and analysis,
Optics"
Monolithically Integrated Gain-Flattened Ring Mode-Locked Laser for Comb-Line Generation,"We demonstrate broadband comb-line generation from an integrated multiple quantum well InGaAsP/InP passively mode-locked laser (MLL) with a gain flattening filter (GFF) based on an asymmetric Mach-Zehnder interferometer. The intracavity filter flattens the nonuniform gain profile of the semiconductor material providing a more uniform net cavity gain. The GFF MLL has a -10 dB comb span of 15 nm (1.88 THz), the widest spectral width yet demonstrated for an integrated QW MLL at 1.55 μm . The measured optical linewidth at the center of the comb is 29 MHz, the -20 dB RF linewidth 500 KHz, while the output spectrum is phase-locked to produce 900 fs pulses at a repetition rate of 30 GHz with 4.6 ps integrated jitter from 100 Hz to 30 MHz.","Optical filters,
Optical variables measurement,
Optical mixing,
Integrated optics,
Gain,
Optical pulses,
Laser mode locking"
A Class of Optimal Frequency Hopping Sequences with New Parameters,"In this paper, we propose an interleaving construction of new sets of frequency hopping sequences from the known ones. By choosing suitable known optimal frequency hopping sequences and sets of frequency hopping sequences and then recursively applying the proposed construction, optimal frequency hopping sequences and sets of frequency hopping sequences with new parameters can be obtained.","Correlation,
Spread spectrum communication,
Optimized production technology,
Educational institutions,
Electronic mail,
Materials"
Comprehensive online defect diagnosis in on-chip networks,"We propose a comprehensive yet low-cost solution for online detection and diagnosis of permanent faults in on-chip networks. Using error syndrome collection and packet/flit-counting techniques, high-resolution defect diagnosis is feasible in both datapath and control logic of the on-chip network without injecting any test traffic or incurring significant performance overhead.","Radiation detectors,
Probability,
Accuracy,
Error correction codes,
Routing,
Transient analysis,
Circuit faults"
Characterization of a Mechanical Motion Amplifier Applied to a MEMS Accelerometer,"In this paper, a mechanical amplification concept for microelectromechanical systems (MEMS) physical sensors is proposed with the aim to improve their sensitivity. The scheme is implemented using a system of micromachined levers (microlevers) as a deflection amplifying mechanism. The effectiveness of the mechanism is demonstrated for a capacitive accelerometer. A proof-of-concept single-axis mechanically amplified accelerometer with an amplification factor of 40 has been designed, simulated, and fabricated, and results from its evaluation are presented in this paper. The sensor's amplified output has a sensitivity of 2.39 V/g using an open-loop capacitive pick-off circuit based on charge amplifiers. Experimental results show that the addition of the mechanical amplifier does not alter the noise floor of the sensor. The measured natural frequency of the first mode of the sensor is at 734 Hz, and the full-scale measurement range is up to 7 g with a maximum nonlinearity of 2%. It is shown, through comparison with a conventional design, that the mechanically amplified accelerometer provides higher deflection without sacrificing bandwidth.","Accelerometers,
Force,
Mechanical sensors,
Noise,
Sensitivity,
Mathematical model"
Multivariable feedback particle filter,"In recent work it is shown that importance sampling can be avoided in the particle filter through an innovation structure inspired by traditional nonlinear filtering combined with Mean-Field Game formalisms [9], [19]. The resulting feedback particle filter (FPF) offers significant variance improvements; in particular, the algorithm can be applied to systems that are not stable. The filter comes with an up-front computational cost to obtain the filter gain. This paper describes new representations and algorithms to compute the gain in the general multivariable setting. The main contributions are, (i) Theory surrounding the FPF is improved: Consistency is established in the multivariate setting, as well as well-posedness of the associated PDE to obtain the filter gain. (ii) The gain can be expressed as the gradient of a function, which is precisely the solution to Poisson's equation for a related MCMC diffusion (the Smoluchowski equation). This provides a bridge to MCMC as well as to approximate optimal filtering approaches such as TD-learning, which can in turn be used to approximate the gain. (iii) Motivated by a weak formulation of Poisson's equation, a Galerkin finite-element algorithm is proposed for approximation of the gain. Its performance is illustrated in numerical experiments.","Mathematical model,
Equations,
Approximation methods,
Kalman filters,
Approximation algorithms,
Covariance matrix,
Poisson equations"
On Measure Transformed Canonical Correlation Analysis,"In this paper, linear canonical correlation analysis (LCCA) is generalized by applying a structured transform to the joint probability distribution of the considered pair of random vectors, i.e., a transformation of the joint probability measure defined on their joint observation space. This framework, called measure transformed canonical correlation analysis (MTCCA), applies LCCA to the data after transformation of the joint probability measure. We show that judicious choice of the transform leads to a modified canonical correlation analysis, which, in contrast to LCCA, is capable of detecting non-linear relationships between the considered pair of random vectors. Unlike kernel canonical correlation analysis, where the transformation is applied to the random vectors, in MTCCA the transformation is applied to their joint probability distribution. This results in performance advantages and reduced implementation complexity. The proposed approach is illustrated for graphical model selection in simulated data having non-linear dependencies, and for measuring long-term associations between companies traded in the NASDAQ and NYSE stock markets.","Correlation,
Vectors,
Joints,
Transforms,
Covariance matrix,
Probability distribution"
A New Analytical Model for Multi-Hop Cognitive Radio Networks,"The cognitive radio (CR) is an emerging technique for increasing the utilisation of communication resources by allowing the unlicensed users to employ the under-utilised spectrum. In this paper, a new analytical performance model is developed to evaluate the QoS of multi-hop CR networks. After validating its accuracy through extensive simulation experiments, the analytical model is adopted as a cost-effective tool to investigate the effects of the primary users' activities on the network performance. Moreover, the model can be used to study the strategy of employing under-utilised spectra so as to maximise the overall resource utilisation and network performance.",
Optimizing video encoding for adaptive streaming over HTTP,"Adaptive streaming over Hyper-Text Transport protocol (HTTP) is the new trend in video delivery on the Internet and is expected to be supported by consumer electronic devices such as Blu-ray players and DVRs. Proprietary solutions have been around for a couple of years and standardization efforts are entering the final stage. In order to make this platform successful, optimized content preparation algorithms are needed. We propose a contentbased segmentation process for adaptive streaming over HTTP. This solution offers a good balance between network delivery requirements and rate-distortion (RD) performance. Resulting video stream is tailored for better quality of experience (QoE) for the end user. Experiments confirm that our algorithm outperforms popular segmentation techniques and saves10% of bandwidth on average for the same objective quality levels. This saving is significant given the volume of traffic that video delivery generates every day on the Internet.","Streaming media,
Encoding,
Bandwidth,
Bit rate,
Motion pictures,
Internet,
Algorithm design and analysis"
Computation of the Natural Poles of an Object in the Frequency Domain Using the Cauchy Method,A methodology for the computation of the natural poles of an object in the frequency domain is presented. This methodology is then applied to compute the natural poles for perfectly conducting objects (PEC) in the frequency domain and compare the results to those obtained using the usual late time response. The main advantage of the proposed method is that there is no need to differentiate between the early time and the late time response of the object because the Cauchy method is applied to extract the Singularity Expansion Method (SEM) poles directly in the frequency domain. Simulation examples are analyzed to illustrate the potential of this method.,"Frequency domain analysis,
Damping,
Matrix decomposition,
Libraries,
Polynomials,
Time factors,
Resonant frequency"
Pulse Shape Measurements by On-Chip Sense Amplifiers of Single Event Transients Propagating Through a 90 nm Bulk CMOS Inverter Chain,"Single event transient (SET) pulse shapes caused by Au ions with an energy of 946 MeV were measured at the microprobe facility at GSI in Darmstadt. Using on-chip sense amplifiers, our novel approach allows observing SET pulse shapes at any interesting circuit node with negligible distortion. We were hence able to accurately trace the propagation of SET pulses through a 90 nm CMOS inverter chain.","Particle beams,
Radiation effects,
Single event transient,
CMOS technology"
Controlled sensing for hypothesis testing,"In this paper, the problem of multiple hypothesis testing with observation control is considered. The structure of the optimal controller under various asymptotic regimes is studied. First, a setup with a fixed sample size is considered. In this setup, the asymptotic quantity of interest is the optimal exponent for the maximal error probability. For the case of binary hypothesis testing, it is shown that the optimal error exponent corresponds to the maximum Chernoff information over the choice of controls. It is also shown that a pure stationary control policy, i.e., a fixed policy which does not depend on specific realizations of past measurements and past controls (open-loop), is asymptotically optimal even among the class of all causal control policies. We also derive lower and upper bounds for the optimal error exponent for the case of multiple hypothesis testing. Second, a sequential setup is considered wherein the controller can also decide when to stop taking observations. In this case, the objective is to minimize the expected stopping time subject to the constraints of vanishing error probabilities under each hypothesis. A sequential test is proposed for testing multiple hypotheses and is shown to be asymptotically optimal.","Testing,
Error probability,
Sensors,
Current measurement,
Educational institutions,
Delay"
New Methodology for the Design of Efficient Binary Addition Circuits in QCA,"The quantum-dot cellular automata (QCA) approach is an attractive emerging technology suitable for the development of ultradense low-power high-performance digital circuits. Even though several solutions have been proposed recently for binary addition circuits, the design of efficient adders in QCA still poses several challenges since, most often, designers tend to implement strategies and methodologies close to those consolidated for the CMOS logic design. In this paper, we propose a new design method that exploits in original ways the properties of auxiliary propagate and generates signals to reduce the number of majority gates required to implement adders in QCA and/or the addition time. Three new formulations of basic logic equations frequently used in the designs of fast binary adders are proposed. To evaluate the potential advantage of the new strategy, two examples of application of the aforementioned method are discussed in this paper.","Adders,
Clocks,
Equations,
Quantum dots,
Wires,
Mathematical model,
Logic gates"
Holographic Capture and Display Systems in Circular Configurations,"This paper presents a novel method of multi-spatial light modulator (SLM) holographic image display that enables wide angle reconstruction of images of real world objects. The image data are delivered by means of digital holography. The capture and display systems are arranged in a circular configuration. In order to support the proper information flow between the multi-sensor capture and multi-SLM display systems we perform analysis using the Wigner distribution function. We also consider a mismatch of the capture and display configurations as well as the visual perception of the displayed image. Experimental results based on the reconstruction of real world scenes are presented that demonstrate the validity of the theoretical solutions. A single camera is used to record the digital holograms, where the object is rotated between captures, and these holograms are then displayed on a circular configuration of SLMs. The results show the limitation of multi-SLM holographic displays in terms of visual perception. These problems arise from the limited angular distribution of the SLMs on a display circle and the presence of gaps between the SLMs.","Cameras,
Image reconstruction,
Holography,
Bandwidth,
Three dimensional displays,
Holographic optical components,
Optical imaging"
Group-Based Active Query Selection for Rapid Diagnosis in Time-Critical Situations,"In applications such as active learning and disease/fault diagnosis, one often encounters the problem of identifying an unknown object through a minimal number of queries. This problem has been referred to as query learning or object/entity identification. We consider three extensions of this fundamental problem that are motivated by practical considerations in real-world,time-critical identification tasks such as emergency response. First, we consider the problem where the objects are partitioned into groups, and the goal is to identify only the group to which the object belongs. Second, we address the situation where the queries are partitioned into groups, and an algorithm may suggest a group of queries to a human user, who then selects the actual query. Third, we consider the problem of object identification in the presence of persistent query noise, and relate it to group identification. To address these problems we show that a standard algorithm for object identification, known as generalized binary search, may be viewed as a generalization of Shannon-Fano coding. We then extend this result to the group-based settings, leading to new algorithms, whose performance is demonstrated through a logarithmic approximation bound, and through experiments on simulated data and a database used for toxic chemical identification.",
A Broadband Three-Dimensionally Isotropic Negative-Refractive-Index Medium,"When designing negative-refractive-index (NRI) metamaterials, scientists have struggled to overcome three primary obstacles: polarization dependence, narrow bandwidth, and fabrication challenges. Here, we address these issues with the design of a three-dimensional, fully isotropic, broadband NRI medium that can be produced on a large scale. The simulated structure exhibits a NRI bandwidth of 24.1%, more than twice that achievable using a typical split-ring resonator/wire medium. A four-hundred-unit-cell slab measuring 15 cm×15 cm×6 cm is fabricated and used as a flat NRI lens. The lens produces a super- resolved focus independent of the type of source or its polarization.","Lenses,
Permeability,
Permittivity,
Slabs,
Thyristors,
Materials,
Bandwidth"
Pseudo-orthogonal frequency coded wireless SAW RFID temperature sensor tags,"SAW sensors are ideal for various wireless, passive multi-sensor applications because they are small, rugged, radiation hard, and offer a wide range of material choices for operation over broad temperature ranges. The readable distance of a tag in a multi-sensor environment is dependent on the insertion loss of the device and the processing gain of the system. Single-frequency code division multiple access (CDMA) tags that are used in high-volume commercial applications must have universal coding schemes and large numbers of codes. The use of a large number of bits at the common center frequency to achieve sufficient code diversity in CDMA tags necessitates reflector banks with >30 dB loss. Orthogonal frequency coding is a spread-spectrum approach that employs frequency and time diversity to achieve enhanced tag properties. The use of orthogonal frequency coded (OFC) SAW tags reduces adjacent reflector interactions for low insertion loss, increased range, complex coding, and system processing gain. This work describes a SAW tag-sensor platform that reduces device loss by implementing long reflector banks with optimized spectral coding. This new pseudo-OFC (POFC) coding is defined and contrasted with the previously defined OFC coding scheme. Auto- and cross-correlation properties of the chips and their relation to reflectivity per strip and reflector length are discussed. Results at 250 MHz of 8-chip OFC and POFC SAW tags will be compared. The key parameters of insertion loss, cross-correlation, and autocorrelation of the two types of frequency-coded tags will be analyzed, contrasted, and discussed. It is shown that coded reflector banks can be achieved with near-zero loss and still maintain good coding properties. Experimental results and results predicted by the coupling of modes model are presented for varying reflector designs and codes. A prototype 915-MHz POFC sensor tag is used as a wireless temperature sensor and the results are shown.","Correlation,
Time frequency analysis,
Bandwidth,
Electrodes,
Encoding,
Couplings"
Using dynamic analysis to discover polynomial and array invariants,"Dynamic invariant analysis identifies likely properties over variables from observed program traces. These properties can aid programmers in refactoring, documenting, and debugging tasks by making dynamic patterns visible statically. Two useful forms of invariants involve relations among polynomials over program variables and relations among array variables. Current dynamic analysis methods support such invariants in only very limited forms. We combine mathematical techniques that have not previously been applied to this problem, namely equation solving, polyhedra construction, and SMT solving, to bring new capabilities to dynamic invariant detection. Using these methods, we show how to find equalities and inequalities among nonlinear polynomials over program variables, and linear relations among array variables of multiple dimensions. Preliminary experiments on 24 mathematical algorithms and an implementation of AES encryption provide evidence that the approach is effective at finding these invariants.",
Reducing Data Transfer in Service-Oriented Architectures: The Circulate Approach,"As the number of services and the size of data involved in workflows increases, centralized orchestration techniques are reaching the limits of scalability. When relying on web services without third-party data transfer, a standard orchestration model needs to pass all data through a centralized engine, which results in unnecessary data transfer and the engine to become a bottleneck to the execution of a workflow. As a solution, this paper presents and evaluates Circulate, an alternative service-oriented architecture which facilitates an orchestration model of central control in combination with a choreography model of optimized distributed data transport. Extensive performance analysis through the PlanetLab framework is conducted on a web service-based implementation over a range of Internet-scale configurations which mirror scientific workflow environments. Performance analysis concludes that our architecture's optimized model of data transport speeds up the execution time of workflows, consistently outperforms standard orchestration and scales with data and node size. Furthermore, Circulate is a less-intrusive solution as individual services do not have to be reconfigured in order to take part in a workflow.","Engines,
Computer architecture,
Service oriented architecture,
Local area networks,
Data models,
Distributed databases"
Removing Label Ambiguity in Learning-Based Visual Saliency Estimation,"Visual saliency is a useful clue to depict visually important image/video contents in many multimedia applications. In visual saliency estimation, a feasible solution is to learn a “feature-saliency” mapping model from the user data obtained by manually labeling activities or eye-tracking devices. However, label ambiguities may also arise due to the inaccurate and inadequate user data. To process the noisy training data, we propose a multi-instance learning to rank approach for visual saliency estimation. In our approach, the correlations between various image patches are incorporated into an ordinal regression framework. By iteratively refining a ranking model and relabeling the image patches with respect to their mutual correlations, the label ambiguities can be effectively removed from the training data. Consequently, visual saliency can be effectively estimated by the ranking model, which can pop out real targets and suppress real distractors. Extensive experiments on two public image data sets show that our approach outperforms 11 state-of-the-art methods remarkably in visual saliency estimation.","Visualization,
Correlation,
Training data,
Estimation,
Feature extraction,
Data models,
Training"
Efficient algorithms for K-anonymous location privacy in participatory sensing,"Location privacy is an important concern in participatory sensing applications, where users can both contribute valuable information (data reporting) as well as retrieve (location-dependent) information (query) regarding their surroundings. K-anonymity is an important measure for privacy to prevent the disclosure of personal data. In this paper, we propose a mechanism based on locality-sensitive hashing (LSH) to partition user locations into groups each containing at least K users (called spatial cloaks). The mechanism is shown to preserve both locality and K-anonymity. We then devise an efficient algorithm to answer kNN queries for any point in the spatial cloaks of arbitrary polygonal shape. Extensive simulation study shows that both algorithms have superior performance with moderate computation complexity.","Data privacy,
Algorithm design and analysis,
Sensors"
Sophisticated Denial of Service attacks aimed at application layer,"Popularity of application services offered by Internet has grown a lot in recent years. Basically, Internet was built with the focus on its functionality and not with the focus on the security tasks. This has led to discovering embedded weaknesses in Internet architecture, which can be misused by attackers with malicious purposes. This paper focuses on application layer Denial of Service (DoS) and Distributed Denial of Service (DDoS) attacks detection, because these attacks present a continuous critical threat to the Internet services. DDoS attacks are typically carried out at the network layer. However, there is evidence to suggest that application layer DDoS attacks can be more effective than the traditional ones. Over some period of time, researchers proposed many solutions to prevent the DoS/DDoS attacks from different OSI layers, but there has been done only a very small research on application layer. In this paper, we consider sophisticated attacks that utilize legitimate application layer requests from legitimately connected network machines to overwhelm Web server. Since the attack signature of each application layer DDoS is represented in abnormal user behavior, we propose several mechanisms, which can be used for application DoS/DDoS attack detection.","Computer crime,
Computers,
Web servers,
Bandwidth,
IP networks,
Monitoring"
Joint scheduling of processing and Shuffle phases in MapReduce systems,"MapReduce has emerged as an important paradigm for processing data in large data centers. MapReduce is a three phase algorithm comprising of Map, Shuffle and Reduce phases. Due to its widespread deployment, there have been several recent papers outlining practical schemes to improve the performance of MapReduce systems. All these efforts focus on one of the three phases to obtain performance improvement. In this paper, we consider the problem of jointly scheduling all three phases of the MapReduce process with a view of understanding the theoretical complexity of the joint scheduling and working towards practical heuristics for scheduling the tasks. We give guaranteed approximation algorithms and outline several heuristics to solve the joint scheduling problem.",
Lossless Migrations of Link-State IGPs,"Network-wide migrations of a running network, such as the replacement of a routing protocol or the modification of its configuration, can improve the performance, scalability, manageability, and security of the entire network. However, such migrations are an important source of concerns for network operators as the reconfiguration campaign can lead to long, service-disrupting outages. In this paper, we propose a methodology that addresses the problem of seamlessly modifying the configuration of link-state Interior Gateway Protocols (IGPs). We illustrate the benefits of our methodology by considering several migration scenarios, including the addition and the removal of routing hierarchy in a running IGP, and the replacement of one IGP with another. We prove that a strict operational ordering can guarantee that the migration will not create any service outage. Although finding a safe ordering is NP-complete, we describe techniques that efficiently find such an ordering and evaluate them using several real-world and inferred ISP topologies. Finally, we describe the implementation of a provisioning system that automatically performs the migration by pushing the configurations on the routers in the appropriate order while monitoring the entire migration process.","Routing protocols,
Topology,
Routing,
Logic gates,
IP networks,
Convergence"
A fast direct matrix solver for surface integral equation methods for electromagnetic wave scattering from non-penetrable targets,"The implementation details of a fast direct solver is described herein for solving dense matrix equations from the application of surface integral equation methods for electromagnetic field scatterings from non-penetrable targets. The proposed algorithm exploits the smoothness of the far field and computes a low rank decomposition of the off-diagonal coupling blocks of the matrices through a set of skeletonization processes. Moreover, an artificial surface (the Huygens’ surface) is introduced for each clustering group to efficiently account for the couplings between well-separated groups. Furthermore, a recursive multilevel version of the algorithm is presented. Although asymptotically the algorithm would not alter the bleak outlook of the complexity of the worst case scenario, O(N3) for required CPU time where N denotes the number of unknowns, for electrically large electromagnetic (EM) problems; through numerical examples, we found that the proposed multilevel direct solver can scale as good as O(N1.3) in memory consumption and O(N1.8) in CPU time for moderate-sized EM problems. Note that our conclusions are drawn based on a few sample examples that we have conducted and should not be taken as a true complexity analysis for general electrodynamic applications. However, for the fixed frequency (h-refinement) scenario, where the discretization size decreases, the computational complexities observed agree well with the theoretical predictions. Namely, the algorithm exhibits O(N) and O(N1.5) complexities for memory consumption and CPU time, respectively.","Matrix decomposition,
Complexity theory,
Integral equations,
Couplings,
Surface waves,
Algorithm design and analysis,
Memory management"
Enterprise Service Bus Monitoring Framework for SOA Systems,"The paper presents a Monitoring Framework for the integration layer of SOA systems realized by an Enterprise Service Bus (ESB). It introduces a generic ESB Metamodel (EMM) and defines mechanisms which gather monitoring data related to the model entities. Applicability of the model is verified on the Java Business Integration (JBI) specification-available standardization of an ESB. An analysis of the JBI specification from the Metamodel perspective is presented, resulting in identification of JBI monitoring deficiencies. Then, the paper illustrates a realization of mechanisms ameliorating JBI deficiencies. The paper also defines the notion of a Monitoring Goal Metamodel which lays a foundation for a fully featured and technology-agnostic monitoring framework established on the EMM. The Monitoring Goal Metamodel allows a declarative definition of how the framework should react to anomalies by performing drill-down monitoring to diagnose the root cause of the problems. Evaluation of the prototype implementation of the ESB Monitoring Framework that verifies its correctness and fulfillment of the nonfunctional requirements is presented. Related work and some important relevant projects and technologies are also briefly described. Finally, the paper is summarized with conclusions and a vision of the proposed framework usage and extensions.","Monitoring,
Business,
Topology,
Containers,
Measurement,
Service oriented architecture,
Engines"
4-D Reconstruction for Dynamic Fluorescence Diffuse Optical Tomography,"Dynamic fluorescence diffuse optical tomography (FDOT) is important for the research of drug delivery, medical diagnosis, and treatment. Conventionally, dynamic tomographic images are reconstructed frame-by-frame, independently. This approach fails to account for the temporal correlations in measurement data. Ideally, the entire image sequence should be considered as a whole and a 4-D reconstruction should be performed. However, the fully 4-D reconstruction is computationally intensive. In this paper, we propose a new 4-D reconstruction approach for dynamic FDOT, which is achieved by applying a temporal Karhunen–Loève (KL) transformation to the imaging equation. By taking advantage of the decorrelation and compression properties of the KL transformation, the complex 4-D optical reconstruction problem is greatly simplified. To evaluate the performance of the method, simulation, phantom, and in vivo experiments ({ N}=7)
are performed on a hybrid FDOT/X-ray computed tomography imaging system. The experimental results indicate that the reconstruction images obtained by the KL method provide good reconstruction quality. Additionally, by discarding high-order KL components, the computation time involved with fully 4-D reconstruction can be greatly reduced in contrast to the conventional frame-by-frame reconstruction.","Image reconstruction,
Fluorescence,
Liver,
Karhunen-Loeve transforms,
Optical imaging,
Tomography"
A Distributed Differential Space-Time Coding Scheme With Analog Network Coding in Two-Way Relay Networks,"In this correspondence, we consider general two-way relay networks (TWRNs) with two source and N relay nodes. A distributed differential space time coding with analog network coding (DDSTC-ANC) scheme is proposed. A simple blind estimation and a differential signal detector are developed to recover the desired signal at each source. The pairwise error probability (PEP) and block error rate (BLER) of the DDSTC-ANC scheme are analyzed. Exact and simplified PEP expressions are derived. To improve the system performance, the optimum power allocation (OPA) between the source and relay nodes is determined based on the simplified PEP expression. The analytical results are verified through simulations.","Relays,
Encoding,
Network coding,
Vectors,
Protocols,
Decoding,
Bismuth"
Using Service-Based GIS to Support Earthquake Research and Disaster Response,"Service-based geographic information system (GIS) technologies can enable an open-architecture cyberinfrastructure to provide standards-compliant data products and computing services for both earthquake research and disaster planning and response. Here, a service-based GIS framework is evaluated using examples from two earthquake science projects: QuakeSim and E-Decider.",
Shape Deformation in Two-Dimensional Electrical Impedance Tomography,"Electrical impedance tomography (EIT) uses measurements from surface electrodes to reconstruct an image of the conductivity of the contained medium. However, changes in measurements result from both changes in internal conductivity and changes in the shape of the medium relative to the electrode positions. Failure to account for shape changes results in a conductivity image with significant artifacts. Previous work to address shape changes in EIT has shown that in some cases boundary shape and electrode location can be uniquely determined for isotropic conductivities; however, for geometrically conformal changes, this is not possible. This prior work has shown that the shape change problem can be partially addressed. In this paper, we explore the limits of compensation for boundary movement in EIT using three approaches. First, a theoretical model was developed to separate a deformation vector field into conformal and non-conformal components, from which the reconstruction limits may be determined. Next, finite element models were used to simulate EIT measurements from a domain whose boundary has been deformed. Finally, an experimental phantom was constructed from which boundary deformation measurements were acquired. Results, both in simulation and with experimental data, suggest that some electrode movement and boundary distortions can be reconstructed based on conductivity changes alone while reducing image artifacts in the process.","Conductivity,
Electrodes,
Shape,
Tomography,
Vectors,
Finite element methods,
Image reconstruction"
A Shift-Invariant Latent Variable Model for Automatic Music Transcription,"In this work, a probabilistic model for multiple-instrument automatic music transcription is proposed. The model extends the shift-invariant probabilistic latent component analysis method, which is used for spectrogram factorization. Proposed extensions support the use of multiple spectral templates per pitch and per instrument source, as well as a time-varying pitch contribution for each source. Thus, this method can effectively be used for multiple-instrument automatic transcription. In addition, the shift-invariant aspect of the method can be exploited for detecting tuning changes and frequency modulations, as well as for visualizing pitch content. For note tracking and smoothing, pitch-wise hidden Markov models are used. For training, pitch templates from eight orchestral instruments were extracted, covering their complete note range. The transcription system was tested on multiple-instrument polyphonic recordings from the RWC database, a Disklavier data set, and the MIREX 2007 multi-F0 data set. Results demonstrate that the proposed method outperforms leading approaches from the transcription literature, using several error metrics.",
Reconciling manual and automatic refactoring,"Although useful and widely available, refactoring tools are underused. One cause of this underuse is that a developer sometimes fails to recognize that she is going to refactor before she begins manually refactoring. To address this issue, we conducted a formative study of developers' manual refactoring process, suggesting that developers' reliance on “chasing error messages” when manually refactoring is an error-prone manual refactoring strategy. Additionally, our study distilled a set of manual refactoring workflow patterns. Using these patterns, we designed a novel refactoring tool called BeneFactor. BeneFactor detects a developer's manual refactoring, reminds her that automatic refactoring is available, and can complete her refactoring automatically. By alleviating the burden of recognizing manual refactoring, BeneFactor is designed to help solve the refactoring tool underuse problem.","Manuals,
Software,
Java,
Videos,
Software reliability"
Computing All Nash Equilibria of Multiplayer Games in Electricity Markets by Solving Polynomial Equations,"The analysis of the Nash equilibrium (NE) in electricity markets with imperfect competition is subject to two major challenges: the treatment of multiplayer games and the determination of the existence of multiple market equilibria. To resolve these obstacles, a solution method, based on the payoff matrix approach and polynomial equations, is proposed in this paper to calculate all the Nash equilibria of multiplayer games in the electricity markets. First, the proposed method decomposes the game by means of a set of all pure strategies assigned with positive probabilities (support). For each possible support, the NE condition can be characterized by a set of polynomial equations with inequality constraints. Next, the homotopy continuation algorithm is employed to obtain all solutions of the polynomial system. Finally, all Nash equilibria can be found by verifying each solution of all polynomial systems. Two example systems, one involving the Cournot model and the other based on the supply function equilibrium (SFE) model, are applied to test the proposed method, respectively. The results show that the proposed method has the ability to identify all NE under certain conditions, indicating that the proposed algorithm is useful for providing insights into the theoretical analysis of electricity markets.","Games,
Polynomials,
Electricity supply industry,
Mathematical model,
Nash equilibrium,
Monitoring"
Error-Correcting Unordered Codes and Hardware Support for Robust Asynchronous Global Communication,"This paper introduces a new family of error-correction unordered (ECU) codes for global communication, called Zero-Sum. They combine the timing-robustness of delay-insensitive (i.e., unordered) codes with the fault-tolerance of error-correcting codes (providing 1-bit error correction or 2-bit detection). Two key features of the codes are that they are systematic, allowing direct extraction of data, and weighted, where the check field is computed as the sum of data index weights. A wide variety of weight assignments is shown to be feasible. Two practical enhancements are also proposed. The Zero-Sum+ code extends error detection to 3-bit errors, or alternatively handles 2-bit detection and 1-bit correction. The Zero-Sum* code supports heuristic 2-bit correction, while still guaranteeing 2-bit detection, under different strategies of weight assignment. Detailed hardware implementations of the supporting components (encoder, completion detection, error corrector) are given, as well as an outline of the system microarchitecture. In comparison to the best alternative systematic ECU code, the basic Zero-Sum code provided better or comparable coding efficiency, with a 5.74%-18.18% reduction in average number of wire transitions for most field sizes. Several Zero-Sum* codes were also evaluated for their 2-bit error correction coverage; initial results are promising, where the best strategy corrected 52.92%-71.16% of all 2-bit errors for most field sizes, with only a moderate decrease in coding efficiency and increase in wire transitions. Technology-mapped pre-layout implementations of the supporting Zero-Sum code hardware were synthesized with the UC Berkeley ABC tool using a 90 nm industrial standard cell library. Results indicate that they have moderate area and delay overheads. In comparison, supporting hardware for the best nonsystematic ECU codes have 3.82-10.44× greater area for larger field sizes.","Indexes,
Hardware,
Receivers,
Error correction codes,
Protocols,
Systematics,
Encoding"
Optimal charging of electric vehicles in smart grid: Characterization and valley-filling algorithms,"Electric vehicles (EVs) offer an attractive long-term solution to reduce the dependence on fossil fuel and greenhouse gas emission. However, a fleet of EVs with different EV battery charging rate constraints, that is distributed across a smart power grid network requires a coordinated charging schedule to minimize the power generation and EV charging costs. In this paper, we study a joint optimal power flow (OPF) and EV charging problem that augments the OPF problem with charging EVs over time. While the OPF problem is generally nonconvex and nonsmooth, it is shown recently that the OPF problem can be solved optimally for most practical power grid networks using its convex dual problem. Building on this strong duality result, we study a nested optimization approach to decompose the joint OPF and EV charging problem. We characterize the optimal offline EV charging schedule to be a valley-filling profile, which allows us to develop an optimal offline algorithm with computational complexity that is significantly lower than centralized interior point solvers. Furthermore, we propose a decentralized online algorithm that dynamically tracks the valley-filling profile. Our algorithms are evaluated on the IEEE 14 bus system, and the simulations show that the online algorithm performs almost near optimality (<; 1% relative difference from the offline optimal solution) under different settings.","Heuristic algorithms,
Batteries,
Estimation,
Joints,
Power grids,
Vectors,
Scheduling"
A Spin-Diode Logic Family,"While most modern computing technologies utilize Si complementary metal-oxide-semiconductor (CMOS) transistors and the accompanying CMOS logic family, alternative devices and logic families exhibit significant performance advantages. Though heretofore impractical, diode logic allows for the execution of logic circuits that are faster, smaller, and dissipate less power than conventional architectures. In this paper, magnetoresistive semiconductor heterojunctions are used to produce the first complete logic family based solely on diodes. We utilize the diode magnetoresistance states to create a binary logic family based on high and low currents in which a full range of logic functions is executed. The diode is used as a switch by manipulating its magnetoresistance with current-carrying wires that generate magnetic fields. Using this device structure, we present basis logic elements and complex circuits consisting of as few as 10% of the devices required in their conventional CMOS counterparts. This diode logic family is therefore an intriguing potential replacement for CMOS technology as Si scaling reaches its inherent limits.","Logic gates,
Magnetic fields,
Semiconductor diodes,
Wires,
CMOS integrated circuits,
Magnetoresistance,
Magnetoresistive devices"
Cooperative Unmanned Autonomous Vehicle Control for Spatially Secure Group Communications,"Beyond the individual independent unmanned autonomous vehicle (UAV), cooperative control of multiple UAVs has started to receive significant attention from industry, academia and the military. For the sake of UAV cooperation, proper wireless communication is imperative, but incurs several problems. Among them, spatially secure group communication (SSGC), which must maximize spatial UAV group size while minimizing the communication boundary of the group, is a unique problem for multiple UAV control from a security perspective. In particular, the SSGC problem must be considered for military applications such as multiple unmanned aerial or ground vehicle control. In this paper, we investigate the SSGC problem. To provide a solution, an analytical framework is first presented to model the dynamics of multiple UAVs and SSGC. The theoretical analysis and simulation results regarding how communication affects group dynamics and spatial communication security are also discussed. Our contribution is to suggest a new way to view multiple UAV control with spatially secure communication, and to provide a distributed method to address the problem cooperatively.","Wireless communication,
Vehicle dynamics,
Interference,
Vehicles,
Security,
Communication system security,
Wireless sensor networks"
Multi-Granular Optical Switching: A Classified Overview for the Past and Future,"The wavelength routed network (WRN) accommodates traffic demands by establishing lightpaths along the corresponding routing paths. The wavelength of each lightpath is switched individually by traditional wavelength optical cross-connects (T-OXCs) to transit the traffic. Due to the traffic explosion and the resulted growth in wavelength number, WRNs face a challenge of the increase in node-size (i.e., the port number of a T-OXC) as well as the associated cost and control complexity. As an alternative solution, waveband switching (WBS) is introduced to group multiple wavelengths together as a band or fiber. Whenever possible, the group of wavelengths requires just a single port at a multi-granular optical cross-connect (MG-OXC). One fundamental problem in WBS networks is the routing and wavelength assignment (RWA). With the major goal of minimizing the port numbers in WBS networks, the optimal RWA problem was shown to be NP-Hard. In the literature, various Integer Linear Programming models are proposed to optimally solve a small-size RWA problem, and many heuristic algorithms are proposed to provide a practical solution for the large-scale RWA problem in WBS networks. In this work, we comprehensively review literature studies on waveband switching networks. The topics covered include architecture, RWA problem solving strategies, and future challenges of wavelength conversion, protection, and lightpath rerouting in WBS networks. We aim at presenting a classified view of WBS networks, based on various aspects including the traffic pattern, node and network architecture, grouping policy, and the band configurations. We investigate factors that affect the goal of port reduction and blocking minimization in WBS networks. In addition, we explore several unique features of waveband switching in protection, wavelength conversion and rerouting, along which we point out multiple open challenges in WBS networks that deserve further studies.",
Identification of Hierarchical and Overlapping Functional Modules in PPI Networks,"Various evidences have demonstrated that functional modules are overlapping and hierarchically organized in protein-protein interaction (PPI) networks. Up to now, few methods are able to identify both overlapping and hierarchical functional modules in PPI networks. In this paper, a new hierarchical clustering algorithm, called OH-PIN, is proposed based on the overlapping M_clusters, λ-module, and a new concept of clustering coefficient between two clusters. By recursively merging two clusters with the maximum clustering coefficient, OH-PIN finally assembles all M_clusters into λ -modules. Since M_clusters are overlapping, λ -modules based on them are also overlapping. Thus, OH-PIN can detect a hierarchical organization of overlapping modules by tuning the value of λ. The hierarchical organization is similar to the hierarchical organization of GO annotations and that of the known complexes in MIPS. To compare the performance of OH-PIN and other existing competing algorithms, we apply them to the yeast PPI network. The experimental results show that OH-PIN outperforms the existing algorithms in terms of the functional enrichment and matching with known protein complexes.","Clustering algorithms,
Proteins,
Databases,
Protein engineering"
Principal Component Based Diffeomorphic Surface Mapping,"We present a new diffeomorphic surface mapping algorithm under the framework of large deformation diffeomorphic metric mapping (LDDMM). Unlike existing LDDMM approaches, this new algorithm reduces the complexity of the estimation of diffeomorphic transformations by incorporating a shape prior in which a nonlinear diffeomorphic shape space is represented by a linear space of initial momenta of diffeomorphic geodesic flows from a fixed template. In addition, for the first time, the diffeomorphic mapping is formulated within a decision-theoretic scheme based on Bayesian modeling in which an empirical shape prior is characterized by a low dimensional Gaussian distribution on initial momentum. This is achieved using principal component analysis (PCA) to construct the eigenspace of the initial momentum. A likelihood function is formulated as the conditional probability of observing surfaces given any particular value of the initial momentum, which is modeled as a random field of vector-valued measures characterizing the geometry of surfaces. We define the diffeomorphic mapping as a problem that maximizes a posterior distribution of the initial momentum given observable surfaces over the eigenspace of the initial momentum. We demonstrate the stability of the initial momentum eigenspace when altering training samples using a bootstrapping method. We then validate the mapping accuracy and show robustness to outliers whose shape variation is not incorporated into the shape prior.",
Steady state analysis of high penetration PV on utility distribution feeder,"The current deregulation trend in the electric power industry has led to the utilities trying to adapt Distributed Generation (DG) into their existing infrastructure. In this paper, 12.47 kV distribution feeders of American Electric Power (AEP) are modeled in OpenDSS to investigate the impacts of PV integration. With increasing PV penetration reverse power may flow on the grid which is associated with voltage rise that may lead to violation of integration standards. The impact on voltage profiles and losses depends upon the size and location of the PV system. Voltages of the feeder, voltage regulation and feeder losses under various locations and levels of PV penetration are analyzed for the utility feeder utilizing unbalanced power flow solution.",
WiMAX on FSO: Outage Probability Analysis,"The transmission of multiple wireless signals over optical links has attained a great research interest nowadays. In case where optical fibers are difficult to be deployed, or installation cost is prohibited, optical wireless systems provide an efficient alternative means. In this paper, we consider the WiMAX (IEEE802.16) standard and construct a simple but adequate scenario to investigate radio signal transmission over terrestrial optical wireless channels. An appropriate system architecture is adopted and a channel model, which entails some of the most critical impairments of the optical channel, i.e., attenuation, turbulence, pointing error effects, as well as of the RF channel, i.e., path loss, shadowing, and Rayleigh fading, is taken into account. The overall link budget and a closed-form of the outage probability of the system are deduced. Several analytical results are depicted using a realistic set of parameter values, to lend a helpful insight to the performance of the proposed architecture.","Radio frequency,
Optical transmitters,
WiMAX,
Adaptive optics,
Optical receivers,
Optical attenuators"
Capacity maximization in cooperative CRNs: Joint relay assignment and channel allocation,"Cooperative communication (CC) can offer high channel capacity and reliability in an efficient and low-cost way by forming a virtual antenna array among single-antenna nodes that cooperatively share their antennas. It has been well recognized that the selection of relay nodes plays a critical role in the performance of multiple source-destination pairs. Unfortunately, all prior work has made an unrealistic assumption that each source-destination pair communicates over a dedicated channel with no mutual interference. In this paper, we study the problem of capacity maximization using cooperative communication in a cognitive radio network by jointly considering the relay assignment and channel allocation under a finite set of available channels, where the interference must be considered. It is proved to be NP-hard and a heuristic algorithm is proposed. Moreover, we exploit the network coding opportunities existing in CC that can further increase the capacity. Extensive simulations are conducted to show that the proposed algorithms can achieve high total capacity under various network settings.",
Photonic Generation of Millimeter-Wave Signals With Tunable Phase Shift,"A novel photonic approach to generating a frequency-quadrupled millimeter-wave (mm-wave) signal with a tunable phase shift is proposed and demonstrated. Two second-order optical sidebands are generated by using a Mach-Zehnder modulator (MZM) that is biased at the maximum transmission point and an optical notch filter. A polarization-maintaining fiber Bragg grating (PM-FBG) is then utilized to make the two sidebands orthogonally polarized, which are then sent to a polarization modulator (PolM). By aligning the two orthogonally polarized sidebands with the two principal axes of the PolM, complementary phase modulation is thus achieved. By beating the two phase-modulated sidebands at a photodetector, an mm-wave signal is generated and its phase is continuously tunable by tuning the bias voltage to the PolM. An experiment is performed. An mm-wave signal with a frequency tunable from 36 to 52 GHz is generated and its phase is tunable over 360 ° by tuning the bias voltage.","Amplitude modulation,
Optical polarization,
Optical filters,
Microwave photonics,
Microwave filters,
Optical fibers"
Kernel-Based Linear Spectral Mixture Analysis,"Linear spectral mixture analysis (LSMA) has been widely used in remote sensing community for spectral unmixing. This letter develops a promising technique, called kernel-based LSMA (KLSMA), which uses nonlinear kernels to resolve the issue of nonlinear separability arising in unmixing and further extends several commonly used LSMA techniques to their kernel-based counterparts. Interestingly, according to experiments conducted for real hyperspectral and multispectral images, KLSMA is more effective than LSMA when data samples are heavily mixed.",
A Class of Binomial Bent Functions Over the Finite Fields of Odd Characteristic,This paper studies a class of binomial functions over the finite fields of odd characteristic and characterizes their bentness in terms of the Kloosterman sums. Numerical results show that the proposed class contains bent functions that are affinely inequivalent to all known monomial and binomial ones.,"Polynomials,
Transforms,
Upper bound,
Computers,
Electronic mail,
Educational institutions,
Materials"
Learning inter-related visual dictionary for object recognition,"Object recognition is challenging especially when the objects from different categories are visually similar to each other. In this paper, we present a novel joint dictionary learning (JDL) algorithm to exploit the visual correlation within a group of visually similar object categories for dictionary learning where a commonly shared dictionary and multiple category-specific dictionaries are accordingly modeled. To enhance the discrimination of the dictionaries, the dictionary learning problem is formulated as a joint optimization by adding a discriminative term on the principle of the Fisher discrimination criterion. As well as presenting the JDL model, a classification scheme is developed to better take advantage of the multiple dictionaries that have been trained. The effectiveness of the proposed algorithm has been evaluated on popular visual benchmarks.","Dictionaries,
Visualization,
Optimization,
Training,
Learning systems,
Sparse matrices,
Joints"
Patient-Specific Prediction of Coronary Plaque Growth From CTA Angiography: A Multiscale Model for Plaque Formation and Progression,"Computational fluid dynamics methods based on in vivo 3-D vessel reconstructions have recently been identified the influence of wall shear stress on endothelial cells as well as on vascular smooth muscle cells, resulting in different events such as flow mediated vasodilatation, atherosclerosis, and vascular remodeling. Development of image-based modeling technologies for simulating patient-specific local blood flows is introducing a novel approach to risk prediction for coronary plaque growth and progression. In this study, we developed 3-D model of plaque formation and progression that was tested in a set of patients who underwent coronary computed tomography angiography (CTA) for anginal symptoms. The 3-D blood flow is described by the Navier-Stokes equations, together with the continuity equation. Mass transfer within the blood lumen and through the arterial wall is coupled with the blood flow and is modeled by a convection-diffusion equation. The low density lipoprotein (LDL) transports in lumen of the vessel and through the vessel tissue (which has a mass consumption term) are coupled by Kedem-Katchalsky equations. The inflammatory process is modeled using three additional reaction-diffusion partial differential equations. A full 3-D model was created. It includes blood flow and LDL concentration, as well as plaque formation and progression. Furthermore, features potentially affecting plaque growth, such as patient risk score, circulating biomarkers, localization and composition of the initial plaque, and coronary vasodilating capability were also investigated. The proof of concept of the model effectiveness was assessed by repetition of CTA, six months after the baseline evaluation. Besides the low values of local shear stress, plaque characteristics, risk profile, pattern of circulating adhesion molecules, and reduced coronary flow reserve at baseline appeared to affect plaque progression toward flow-limiting lesions at follow-up evaluation. Although preliminary, our multidisciplinary approach to a “personalized” prediction of coronary plaque progression suggests that incorporation in atherosclerotic models of systemic and local hemodynamic features may better predict evolution of plaques in coronary artery disease stable patients.",
Novel Blind Encoder Parameter Estimation for Turbo Codes,"A novel blind parameter-estimation method, which identifies a turbo encoder, is proposed in this paper. The blind estimator is designed using an iterative expectation-maximization (EM) algorithm. To facilitate this innovative blind estimation scheme, we transform the recursive systematic convolutional (RSC) encoder into a non-systematic convolutional encoder preceded by a feedback encoder. The effect of the separate feedback encoder on the state sequence of the forward convolutional encoder will be studied. Besides, the effectiveness of our proposed new scheme will be evaluated by Monte Carlo simulations.","Convolution,
Convolutional codes,
Estimation,
Turbo codes,
Signal to noise ratio,
Parameter estimation,
Monte Carlo methods"
Speech-based emotion classification using multiclass SVM with hybrid kernel and thresholding fusion,"Emotion classification is essential for understanding human interactions and hence is a vital component of behavioral studies. Although numerous algorithms have been developed, the emotion classification accuracy is still short of what is desired for the algorithms to be used in real systems. In this paper, we evaluate an approach where basic acoustic features are extracted from speech samples, and the One-Against-All (OAA) Support Vector Machine (SVM) learning algorithm is used. We use a novel hybrid kernel, where we choose the optimal kernel functions for the individual OAA classifiers. Outputs from the OAA classifiers are normalized and combined using a thresholding fusion mechanism to finally classify the emotion. Samples with low `relative confidence' are left as `unclassified' to further improve the classification accuracy. Results show that the decision-level recall of our approach for six-class emotion classification is 80.5%, outperforming a state-of-the-art approach that uses the same dataset.",
Cheap Cancellation of Strong Echoes for Digital Passive and Noise Radars,"The problem of cancellation of strong, potentially nonstationary, echoes in noise radars and passive radars utilizing digital transmissions is considered. The proposed solution is a multi-stage procedure. Initial clutter estimates, obtained using the least mean squares (LMS) algorithm, are refined using specially designed filters, “matched” to spectral densities of targets and clutter. When the postprocessing filters are noncausal, the performance of the proposed canceler is improved compared to the solution based on causal filters.",
Statistical Early Termination Model for Fast Mode Decision and Reference Frame Selection in Multiview Video Coding,"Multiview Video Coding (MVC) adopts exhaustive variable size mode decision and multiple reference frame selection to significantly improve high compression efficiency at each macroblock. However, these two technologies increase the computational complexity of MVC encoders tremendously. In this paper, we propose an efficient Statistical DIRECT Mode Early Termination (SDMET) model which estimates the rate distortion degradation, false acceptance rate and false reject rate of early DIRECT mode decision. It can adaptively adjust the rate distortion cost threshold not only according to the quantization parameter, but also the video content and motion properties. Experimental results show that SDMET can reduce 42.40% to 65.60% computation complexity for fast mode decision. When it is jointly optimized with fast multi-reference frame selection, the proposed overall algorithm can achieve 79.57% to 89.21% computational complexity reduction with unnoticeable rate distortion degradation. Additionally, the proposed SDMET and the overall fast mode decision algorithm can be applied to both temporal views and inter-view views in MVC.",
Robust Adaptive Extended Kalman Filtering for Real Time MR-Thermometry Guided HIFU Interventions,"Real time magnetic resonance (MR) thermometry is gaining clinical importance for monitoring and guiding high intensity focused ultrasound (HIFU) ablations of tumorous tissue. The temperature information can be employed to adjust the position and the power of the HIFU system in real time and to determine the therapy endpoint. The requirement to resolve both physiological motion of mobile organs and the rapid temperature variations induced by state-of-the-art high-power HIFU systems require fast MRI-acquisition schemes, which are generally hampered by low signal-to-noise ratios (SNRs). This directly limits the precision of real time MR-thermometry and thus in many cases the feasibility of sophisticated control algorithms. To overcome these limitations, temporal filtering of the temperature has been suggested in the past, which has generally an adverse impact on the accuracy and latency of the filtered data. Here, we propose a novel filter that aims to improve the precision of MR-thermometry while monitoring and adapting its impact on the accuracy. For this, an adaptive extended Kalman filter using a model describing the heat transfer for acoustic heating in biological tissues was employed together with an additional outlier rejection to address the problem of sparse artifacted temperature points. The filter was compared to an efficient matched FIR filter and outperformed the latter in all tested cases. The filter was first evaluated on simulated data and provided in the worst case (with an approximate configuration of the model) a substantial improvement of the accuracy by a factor 3 and 15 during heat up and cool down periods, respectively. The robustness of the filter was then evaluated during HIFU experiments on a phantom and in vivo in porcine kidney. The presence of strong temperature artifacts did not affect the thermal dose measurement using our filter whereas a high measurement variation of 70% was observed with the FIR filter.","Temperature measurement,
Heating,
Accuracy,
Absorption,
Predictive models,
Kalman filters,
Noise"
Novel Robust Direction-of-Arrival-Based Source Localization Algorithm for Wideband Signals,"Source localization for wideband signals using acoustic sensor networks has drawn much research interest recently. The maximum-likelihood is the predominant objective for a wide variety of source localization approaches, and we have previously proposed an expectation-maximization (EM) algorithm to solve the source localization problem. In this paper, we tackle the source localization problem based on the realistic assumption that the sources are corrupted by spatially-non-white noise. We explore the respective limitations of our recently proposed algorithm, namely EM source localization algorithm, and design a new direction-of-arrival (DOA) estimation based (DEB) source localization algorithm. We also derive the Cramer-Rao lower bound (CRLB) analysis and the computational complexity study for the aforementioned source localization schemes. Through Monte Carlo simulations and our derived CRLB analysis, it is demonstrated that our proposed DEB algorithm significantly outperforms the previous EM method in terms of both source localization accuracy and computational complexity.","Direction of arrival estimation,
Vectors,
Maximum likelihood estimation,
Noise measurement,
Robustness"
Medial-Based Deformable Models in Nonconvex Shape-Spaces for Medical Image Segmentation,"We explore the application of genetic algorithms (GA) to deformable models through the proposition of a novel method for medical image segmentation that combines GA with nonconvex, localized, medial-based shape statistics. We replace the more typical gradient descent optimizer used in deformable models with GA, and the convex, implicit, global shape statistics with nonconvex, explicit, localized ones. Specifically, we propose GA to reduce typical deformable model weaknesses pertaining to model initialization, pose estimation and local minima, through the simultaneous evolution of a large number of models. Furthermore, we constrain the evolution, and thus reduce the size of the search-space, by using statistically-based deformable models whose deformations are intuitive (stretch, bulge, bend) and are driven in terms of localized principal modes of variation, instead of modes of variation across the entire shape that often fail to capture localized shape changes. Although GA are not guaranteed to achieve the global optima, our method compares favorably to the prevalent optimization techniques, convex/nonconvex gradient-based optimizers and to globally optimal graph-theoretic combinatorial optimization techniques, when applied to the task of corpus callosum segmentation in 50 mid-sagittal brain magnetic resonance images.","Shape,
Deformable models,
Image segmentation,
Genetic algorithms,
Biomedical imaging,
Optimization,
Data models"
Multiple Error-Correcting WOM-Codes,"A Write Once Memory (WOM) is a storage medium with binary memory elements, called cells, that can change from the zero state to the one state only once. Examples of WOMs include punch cards and optical disks. WOM-codes, introduced by Rivest and Shamir, permit the reuse of a WOM by taking into account the location of cells that have already been changed to the one state. The objective in designing WOM-codes is to use the fewest number of cells to store a specified number of information bits in each of several reuses of the memory. An [n,k,t] WOM-code C is a coding scheme for storing k information bits in n cells t times. At each write, the state of each cell can be changed, provided that the cell is changed from the zero state to the one state. The rate of C, defined by R(C) = kt/n, indicates the total amount of information that is possible to store in a cell in t writes. Two WOM-code constructions correcting a single cell-error were presented by Zemor and Cohen. In this paper, we present another construction of a single-error-correcting WOM-code with a better rate. Our construction can be adapted also for single-error-detection, double-error-correction, and triple-error-correction. For the last case, we use triple-error-correcting BCH-like codes, which were presented by Kasami and more recently described again by Bracken and Helleseth. Finally, we show two constructions that can be combined for the correction of an arbitrary number of errors.","Vectors,
Decoding,
Redundancy,
Encoding,
Educational institutions,
Ash,
Computers"
Visualizing the radial and circumferential strain distribution within vessel phantoms using synthetic-aperture ultrasound elastography,"Noninvasive elastography (NIVE) produces elastograms that are difficult to interpret because NIVE visualizes strain in the transducer coordinate system. In this paper, we hypothesized that transforming normal and shear strain elastograms to the vessel coordinate system will produce better strain elastograms. To corroborate this hypothesis, we acquired synthetic-aperture (SA) ultrasound data from simulated and physical vessel phantoms. In both studies, SA echo frames were reconstructed from data acquired with a sparse transducer array. The simulation study was performed with homogeneous and heterogenous phantoms, but in the experimental study we used a modified ultrasound scanner to acquire SA data from homogeneous (n = 1) and heterogeneous (n = 3) vessel phantoms. Axial and lateral displacements were estimated by performing two-dimensional cross-correlation analysis on the beamformed RF echo frames. We generated radial and circumferential strain elastograms by transforming normal and shear strain elastograms to the vessel coordinate system. The results revealed: 1) radial and circumferential strain elastograms acquired from simulated data had a relative root mean squared error on the order of 0.1%; 2) experimentally acquired radial and circumferential strain elastograms had elastographic contrast-to-noise ratio (CNRe) between 10 and 40 dB, and elastographic signal-to-noise ratio (SNRe) between 10 and 35 dB, depending on the number of active transmission elements employed during imaging; 3) radial and circumferential strain elastograms produced with fewer than 8 active transmission elements were inferior to those computed with a greater number of active elements; and 4) plaques were evident in the strain elastograms, except in those obtained with the sparsest transducer array. This study demonstrated that a syntheticaperture ultrasound system could visualize radial and circumferential strain noninvasively.","Strain,
Phantoms,
Arrays,
Finite element methods,
Ultrasonic imaging,
Transducers,
Radio frequency"
Phase-Coded Millimeter-Wave Waveform Generation Using a Spatially Discrete Chirped Fiber Bragg Grating,"An all-optical approach to generating phase-coded millimeter-wave (mm-wave) waveforms based on optical pulse shaping, using a spatially discrete chirped fiber Bragg grating (SD-CFBG) is proposed and experimentally demonstrated. Since no electro-optical modulator is used, the system is simpler and less costly. In the proposed system, the spectrum of an optical pulse is spectrally sliced by a sinusoidal comb filter. The SD-CFBG is then used as a special dispersive element to map the shaped spectrum to a temporal waveform based on dispersive Fourier transform, and at the same time, to introduce the desired time delay jumps, which are translated to phase shifts. A simplified system without using the comb filter is also studied, in which a single SD-CFBG is employed to simultaneously perform spectral slicing, frequency-to-time mapping, and temporal coding. The proposed technique is validated by two experiments in which two phase-coded mm-wave waveforms at 28.5 GHz and 47.2 GHz with, respectively, a 7-bit and 11-bit Barker code are generated.","Microwave filters,
Microwave photonics,
Delay effects,
Delay,
Encoding"
Modeling indoor TOA ranging error for body mounted sensors,"In Time of arrival (TOA) based indoor human tracking system, the human body mounted with the target sensor can cause non-line of sight (NLOS) scenario and result in significant ranging error. However, the previous studies on the behavior of indoor TOA ranging did not take the effects of human body into account. In this paper, we introduce a statistical TOA ranging error model for body mounted sensors based on the measurements in a typical office building. This model separates the ranging error into multipath error cased multipath combination and undetectable direct path (UDP) error derives from the body-caused NLOS. Both multipath error and UDP error are modeled as a Gaussian variable. The distribution of multipath error is relative to the bandwidth of the system and the distribution of UDP error is relative to the angle between the face direction and the direction of TX-RX, SNR and bandwidth of the system, clearly shows the effects of human body on TOA ranging.","Land mobile radio,
Helium"
Optimal Energy-Efficient Channel Exploration for Opportunistic Spectrum Usage,"This letter studies the channel exploration problem for opportunistic spectrum usage systems, where exploring state information of each channel consumes time and energy. We formulate this problem as an optimal stopping problem and propose a myopic rule with low complexity, called one stage look ahead (1-SLA), to solve it. Moreover, the optimality of the 1-SLA rule for the energy-efficient channel exploration problem is proved, and simulation results are provided to show the effectiveness of the 1-SLA rule.","Throughput,
Complexity theory,
Sensors,
Fading,
Cognitive radio,
Energy consumption"
Evolving Distributed Algorithms With Genetic Programming,"In this paper, we evaluate the applicability of genetic programming (GP) for the evolution of distributed algorithms. We carry out a large-scale experimental study in which we tackle three well-known problems from distributed computing with six different program representations. For this purpose, we first define a simulation environment in which phenomena such as asynchronous computation at changing speed and messages taking over each other, i.e., out-of-order message delivery, occur with high probability. Second, we define extensions and adaptations of established GP approaches (such as tree-based and linear GP) in order to make them suitable for representing distributed algorithms. Third, we introduce novel rule-based GP methods designed especially with the characteristic difficulties of evolving algorithms (such as epistasis) in mind. Based on our extensive experimental study of these approaches, we conclude that GP is indeed a viable method for evolving non-trivial, deterministic, non-approximative distributed algorithms. Furthermore, one of the two rule-based approaches is shown to exhibit superior performance in most of the tasks and thus can be considered as an interesting idea also for other problem domains.","Distributed algorithms,
Protocols,
Genetic programming,
Algorithm design and analysis,
Optimization,
Approximation algorithms,
Computational modeling"
The growth of Diaspora - A decentralized online social network in the wild,"The Diaspora network [1] is a recently launched decentralized online social network with over 216; 000 users as of November 16; 2011. It is a network of independent, federated Diaspora servers that are administrated by individual users who allow Diaspora users' profiles to be hosted on their servers. In this paper we take a first look at the Diaspora network's overall growth in terms of number of users, the topology of its interconnected servers, and the reliability of those servers. We also present a simple analysis to explain the growth of the Diaspora network. Our timely measurement study of a real-world decentralized online social network sheds light on the evolution of such a network in practice, and provides valuable observations and insights that can help the future design and implementation of decentralized online social networking.",
"2
n
Pattern Run-Length for Test Data Compression","This paper presents a new pattern run-length compression method whose decompressor is simple and easy to implement. It encodes 2|n| runs of compatible or inversely compatible patterns, either inside a single test data segment or across multiple test data segments. Experimental results show that it can achieve an average compression ratio of 67.64% and considerable test application time savings.","Encoding,
Test data compression,
Multiplexing,
System-on-a-chip,
Clocks,
Decoding,
Synchronization"
Universal bounds on the scaling behavior of polar codes,"We consider the problem of determining the tradeoff between the rate and the block-length of polar codes for a given block error probability when we use the successive cancellation decoder. We take the sum of the Bhattacharyya parameters as a proxy for the block error probability, and show that there exists a universal parameter μ such that for any binary memoryless symmetric channel W with capacity I(W), reliable communication requires rates that satisfy R < I(W) − αN−1/μ, where α is a positive constant and N is the block-length. We provide lower bounds on μ, namely μ ≥ 3.553, and we conjecture that indeed μ = 3.627, the parameter for the binary erasure channel.",
A High-Precision On-Chip Path Delay Measurement Architecture,"In this paper, we present a novel on-chip path delay measurement architecture for efficiently detecting and debugging of delay faults in the fabricated integrated circuits. Several delay stages are employed in the proposed on-chip path delay measurement (OCDM) circuit, whose delay ranges are increased by a factor of two gradually from the last to the first delay stage. Thus, the proposed OCDM circuit can achieve a large delay measurement range with a small quantity of delay stages. A calibration circuit is incorporated into the proposed on-chip path delay measurement technique to calibrate the delay range of the delay stage under process variations. In addition, delay calibration for import lines is conducted to improve the precision of path delay measurement. Experimental results are presented to validate the proposed path delay measurement architecture.","Delay,
Code division multiplexing,
Calibration,
Clocks,
System-on-a-chip"
Scalable RFID Systems: A Privacy-Preserving Protocol with Constant-Time Identification,"In RFID literature, most “privacy-preserving” protocols require the reader to search all tags in the system in order to identify a single tag. In another class of protocols, the search complexity is reduced to be logarithmic in the number of tags, but it comes with two major drawbacks: it requires a large communication overhead over the fragile wireless channel, and the compromise of a tag in the system reveals secret information about other, uncompromised, tags in the same system. In this work, we take a different approach to address time complexity of private identification in large-scale RFID systems. We utilize the special architecture of RFID systems to propose a symmetric-key privacy-preserving authentication protocol for RFID systems with constant-time identification. Instead of increasing communication overhead, the existence of a large storage device in RFID systems, the database, is utilized for improving the time efficiency of tag identification.","Protocols,
Radiofrequency identification,
Privacy,
Authentication,
Databases,
Games"
Capacity Analysis of Log-Normal Channels Under Various Adaptive Transmission Schemes,"In this letter, analytical models to estimate the capacity of log-normal channels are presented for three adaptive transmission schemes: (i) optimal simultaneous power and rate adaptation, (ii) optimal rate adaptation with constant transmit power, and (iii) truncated channel inversion with fixed rate. Closed-form approximations for capacity under these adaptive transmission schemes are derived. Simulation results confirm the accuracy of the proposed analytical models.",
Teaching Cybersecurity with DeterLab,"The DETER project aims to advance cybersecurity research and education. Over the past seven years, the project has focused on improving and redefining the methods, technology, and infrastructure for developing cyberdefense technology. The project's research results are put into practice by DeterLab, a public, free-for-use experimental facility available to researchers and educators worldwide. Educators can use DeterLab's exercises to teach cybersecurity technology and practices. This use of DeterLab provides valuable feedback on DETER innovations and helps grow the pool of cybersecurity innovators and cyberdefenders.",
Using manipulation primitives for brick sorting in clutter,"This paper explores the idea of manipulation-aided perception and grasping in the context of sorting small objects on a tabletop. We present a robust pipeline that combines perception and manipulation to accurately sort Duplo bricks by color and size. The pipeline uses two simple motion primitives to manipulate the scene in ways that help the robot to improve its perception. This results in the ability to sort cluttered piles of Duplo bricks accurately. We present experimental results on the PR2 robot comparing brick sorting without the aid of manipulation to sorting with manipulation primitives that show the benefits of the latter, particularly as the degree of clutter in the environment increases.",
Combined DWT-DCT based digital image watermarking technique for copyright protection,"A combined DWT and DCT based watermarking technique with low frequency watermarking with weighted correction is proposed. DWT has excellent spatial localization, frequency spread and multi-resolution characteristics, which are similar to the theoretical models of the human visual system (HVS). DCT based watermarking techniques offer compression while DWT based watermarking techniques offer scalability. These desirable properties are used in this combined watermarking technique. In the proposed method watermark bits are embedded in the low frequency band of each DCT block of selected DWT sub-band. The weighted correction is also used to improve the imperceptibility. The extracting procedure reverses the embedding operations without the reference of the original image. Compared with the similar approach by DCT based approach and DWT based approach, the experimental results show that the proposed algorithm apparently preserves superior image quality and robustness under various attacks such as JPEG compression, cropping, sharping, contrast adjustments and so on.",
Object Detection With DoG Scale-Space: A Multiple Kernel Learning Approach,"Difference of Gaussians (DoG) scale-space for an image is a significant way to generate features for object detection and classification. While applying DoG scale-space features for object detection/classification, we face two inevitable issues: dealing with high-dimensional data and selecting/weighting of proper scales. The scale selection process is mostly ad-hoc to present. In this paper, we propose a multiple kernel learning (MKL) method for both DoG scale selection/weighting and dealing with high-dimensional scale-space data. We design a novel shift invariant kernel function for DoG scale-space. To select only the useful scales in the DoG scale-space, a novel framework of MKL is also proposed. We utilize a 1-norm support vector machine (SVM) in the MKL optimization problem for sparse weighting of scales from DoG scale-space. The optimized data-dependent kernel accommodates only a few scales that are most discriminatory according to the large margin principle. With a 2-norm SVM, this learned kernel is applied to a challenging detection problem in oil sand mining: to detect large lumps in oil sand videos. We tested our method on several challenging oil sand data sets. Our method yields encouraging results on these difficult-to-process images and compares favorably against other popular multiple kernel methods.",
Aesthetics-Based Stereoscopic Photo Cropping for Heterogeneous Displays,"Stereoscopic displays are becoming ubiquitous, ranging from large 3-D TVs to small mobile phones. Stereoscopic photos need to be carefully adapted to be effectively viewed on the displays other than originally intended. In this paper, we present a method that can automatically crop and scale an existing stereoscopic photo to a variety of displays while preserving its aesthetic value. We formulate stereoscopic photo adaptation as an optimization problem that aims to preserve the aesthetic value of the input photo. We define a wide range of energy terms to preserve the stereoscopic photo aesthetics by borrowing rules from stereoscopic photography. Our experiments on a wide variety of stereoscopic photos demonstrate that our method can robustly produce display-dependent stereoscopic photos that deliver pleasant viewing experiences.",
Characterizing and Extracting Multiplex Patterns in Complex Networks,"Complex network theory provides a means for modeling and analyzing complex systems that consist of multiple and interdependent components. Among the studies on complex networks, structural analysis is of fundamental importance as it presents a natural route to understanding the dynamics, as well as to synthesizing or optimizing the functions, of networks. A wide spectrum of structural patterns of networks has been reported in the past decade, such as communities, multipartites, bipartite, hubs, authorities, outliers, and bow ties, among others. In this paper, we are interested in tackling the challenging task of characterizing and extracting multiplex patterns (multiple patterns as mentioned previously coexisting in the same networks in a complicated manner), which so far has not been explicitly and adequately addressed in the literature. Our work shows that such multiplex patterns can be well characterized as well as effectively extracted by means of a granular stochastic blockmodel, together with a set of related algorithms proposed here based on some machine learning and statistical inference ideas. These models and algorithms enable us to further explore complex networks from a novel perspective.",
Generating informative paths for persistent sensing in unknown environments,"We present an online algorithm for a robot to shape its path to a locally optimal configuration for collecting information in an unknown dynamic environment. As the robot travels along its path, it identifies both where the environment is changing, and how fast it is changing. The algorithm then morphs the robot's path online to concentrate on the dynamic areas in the environment in proportion to their rate of change. A Lyapunov-like stability proof is used to show that, under our proposed path shaping algorithm, the path converges to a locally optimal configuration according to a Voronoi-based coverage criterion. The path shaping algorithm is then combined with a previously introduced speed controller to produce guaranteed persistent monitoring trajectories for a robot in an unknown dynamic environment. Simulation and experimental results with a quadrotor robot support the proposed approach.",
Elimination of one dc voltage source in stacked multicell converters,"This study presents a novel configuration for stacked multicell (SM) converters. The main advantage of the proposed converter, in comparison with the conventional one, is that the number of required dc voltage sources is reduced from two to one in the proposed topology which results in decreasing the cost and size of the converter. This progress is achieved by adding four low-frequency switches to the conventional configuration of SM converter whereas the number and voltage rating of high-frequency switches and clamping capacitors as well as the number of high-frequency switchings during a full cycle are kept constant. This converter is controlled by phase shifted carrier-sinusoidal pulse width modulation technique; therefore the self-balancing phenomenon of clamping capacitors' voltages is maintained. This study also presents a state-space representation model to analyse the dynamic of clamping capacitor's self-balancing phenomenon in the proposed SM converter by obtaining the switching instants of the pulse width modulation in terms of the Kapteyn series. Numerical solution of obtained state-space representation model of the proposed converter and simulation results as well as measurements taken from an experimental set-up are presented in order to validate the effectiveness and advantages of the proposed configuration as well as its control strategy and state-space model.","state-space methods,
capacitors,
clamps,
power semiconductor switches,
PWM power convertors"
MIMO communications based on molecular diffusion,"Diffusion-based communication refers to the transfer of information using molecules as message carriers whose propagation is based on the law of molecular diffusion. Path loss can have a major impact on the link quality in molecular communication as the signal strength is shown inversely proportional to the cube of the communication distance. In this paper, various diversity techniques for Multi-Input Multi-Output (MIMO) transmissions based on molecular diffusion are proposed to improve the communication performance in nanonetworks in the presence of Multi-User Interference (MUI). Analogous to radio communication, the concept of diversity and Spatial Multiplexing (SM) can be successfully applied in molecular communication. To the best of our knowledge, our paper is the first which investigates the aspects of MIMO transmissions for molecular communication. Numerical results show that the proposed diversity techniques can successfully lower the error rate. Further performance improvement can be obtained by properly allocating molecules among the transmission nodes if the Channel State Information (CSI) is available at the transmitter end. To optimize the system throughput, a dynamic switching mechanism between the diversity mode and the Spatial Multiplexing (SM) mode can be employed.",
Modeling of an electric vehicle charging station for fast DC charging,"The proposed model of an electric vehicle charging station is suitable for the fast DC charging of multiple electric vehicles. The station consists of a single grid-connected inverter with a DC bus where the electric vehicles are connected. The control of the individual electric vehicle charging processes is decentralized, while a separate central control deals with the power transfer from the AC grid to the DC bus. The electric power exchange does not rely on communication links between the station and vehicles, and a smooth transition to vehicle-to-grid mode is also possible. Design guidelines and modeling are explained in an educational way to support implementation in Matlab/Simulink. Simulations are performed in Matlab/Simulink to illustrate the behavior of the station. The results show the feasibility of the model proposed and the capability of the control system for fast DC charging and also vehicle-to-grid.",
Privacy- and Integrity-Preserving Range Queries in Sensor Networks,"The architecture of two-tiered sensor networks, where storage nodes serve as an intermediate tier between sensors and a sink for storing data and processing queries, has been widely adopted because of the benefits of power and storage saving for sensors as well as the efficiency of query processing. However, the importance of storage nodes also makes them attractive to attackers. In this paper, we propose SafeQ, a protocol that prevents attackers from gaining information from both sensor collected data and sink issued queries. SafeQ also allows a sink to detect compromised storage nodes when they misbehave. To preserve privacy, SafeQ uses a novel technique to encode both data and queries such that a storage node can correctly process encoded queries over encoded data without knowing their values. To preserve integrity, we propose two schemes—one using Merkle hash trees and another using a new data structure called neighborhood chains—to generate integrity verification information so that a sink can use this information to verify whether the result of a query contains exactly the data items that satisfy the query. To improve performance, we propose an optimization technique using Bloom filters to reduce the communication cost between sensors and storage nodes.",
Detecting splicing in digital audios using local noise level estimation,"One common form of tampering in digital audio signals is known as splicing, where sections from one audio is inserted to another audio. In this paper, we propose an effective splicing detection method for audios. Our method achieves this by detecting abnormal differences in the local noise levels in an audio signal. This estimation of local noise levels is based on an observed property of audio signals that they tend to have kurtosis close to a constant in the band-pass filtered domain. We demonstrate the efficacy and robustness of the proposed method using both synthetic and realistic audio splicing forgeries.","Noise level,
Noise,
Estimation,
Splicing,
Forgery,
Discrete cosine transforms,
Forensics"
Dynamic climbing of near-vertical smooth surfaces,"A 10 cm hexapedal robot is adapted to dynamically climb near-vertical smooth surfaces. A gecko-inspired adhesive is mounted with an elastomer tendon and polymer loop to a remote-center-of-motion ankle that allows rapid engagement with the surface and minimizes peeling moments on the adhesive. The maximum velocity possible while climbing decreases as the incline gets closer to vertical, with the robot able to achieve speeds of 10 cm second-1 at a 70-degree incline. A model is implemented to describe the effect of incline angle on climbing speed and, together with high-speed video evidence, reveals that climbing velocity is limited by robot dynamics and adhesive properties and not by power.","Foot,
Force,
Legged locomotion,
Tendons,
Polymers,
Robot sensing systems"
Polar coding to achieve the Holevo capacity of a pure-loss optical channel,"In the low-energy high-energy-efficiency regime of classical optical communications - relevant to deep-space optical channels - there is a big gap between reliable communication rates achievable via conventional optical receivers and the ultimate (Holevo) capacity. Achieving the Holevo capacity requires not only optimal codes but also receivers that make collective measurements on long (modulated) codeword waveforms, and it is impossible to implement these collective measurements via symbol-by-symbol detection along with classical postprocessing [1], [2]. Here, we apply our recent results on the classical-quantum polar code [3] - the first near-explicit, linear, symmetric-Holevo-rate achieving code - to the lossy optical channel, and we show that it almost closes the entire gap to the Holevo capacity in the low photon number regime. In contrast, Arikan's original polar codes, applied to the DMC induced by the physical optical channel paired with any conceivable structured optical receiver (including optical homodyne, heterodyne, or direct-detection) fails to achieve the ultimate Holevo limit to channel capacity. However, our polar code construction (which uses the quantum fidelity as a channel parameter rather than the classical Bhattacharyya quantity to choose the “good channels” in the polar-code construction), paired with a quantum successive-cancellation receiver - which involves a sequence of collective non-destructive binary projective measurements on the joint quantum state of the received codeword waveform - can attain the Holevo limit, and can hence in principle achieve higher rates than Arikan's polar code and decoder directly applied to the optical channel. However, even a theoretical recipe for construction of an optical realization of the quantum successive-cancellation receiver remains an open question.",
Close-Packed Arrays of Plasma Jets Emanating From Microchannels in a Transparent Polymer,"Close-packed arrays of microplasma jets, propagating into atmospheric air with uniform plume length and luminosity, have been generated in cylindrical microchannels and characterized. Arrays as large as 8 × 8 with a packing density of ~160 cm-2 have been demonstrated to date. Fabricated in a molded flexible polymer that is transparent deep into the ultraviolet (λ ≳ 250 nm), microchannel devices 350 μm in diameter generate plasma in He feedstock gas with a backing pressure of 760-900 Torr and flow rates up to 4.6 standard liters per minute. Chemical kinetics of the He (21,3S) and He2 (a3Σu+) excited species interacting with laboratory air has been examined by optical emission spectroscopy. The maximum jet length for a 5 × 5 array is 3.8 ± 0.2 mm when the He backing pressure is 840 ± 20 Torr. Relative to previous jet array designs, this technology increases the jet packing density by more than an order of magnitude and yet jet-jet interactions are not observed.","Plasmas,
Helium,
Electrodes,
Microchannel,
Polymers,
Arrays,
Laboratories"
Constrained Registration for Motion Compensation in Atrial Fibrillation Ablation Procedures,"Fluoroscopic overlay images rendered from preoperative volumetric data can provide additional anatomical details to guide physicians during catheter ablation procedures for treatment of atrial fibrillation (AFib). As these overlay images are often compromised by cardiac and respiratory motion, motion compensation methods are needed to keep the overlay images in sync with the fluoroscopic images. So far, these approaches have either required simultaneous biplane imaging for 3-D motion compensation, or in case of monoplane X-ray imaging, provided only a limited 2-D functionality. To overcome the downsides of the previously suggested methods, we propose an approach that facilitates a full 3-D motion compensation even if only monoplane X-ray images are available. To this end, we use a training phase that employs a biplane sequence to establish a patient specific motion model. Afterwards, a constrained model-based 2-D/3-D registration method is used to track a circumferential mapping catheter. This device is commonly used for AFib catheter ablation procedures. Based on the experiments on real patient data, we found that our constrained monoplane 2-D/3-D registration outperformed the unconstrained counterpart and yielded an average 2-D tracking error of 0.6 mm and an average 3-D tracking error of 1.6 mm. The unconstrained 2-D/3-D registration technique yielded a similar 2-D performance, but the 3-D tracking error increased to 3.2 mm mostly due to wrongly estimated 3-D motion components in X-ray view direction. Compared to the conventional 2-D monoplane method, the proposed method provides a more seamless workflow by removing the need for catheter model re-initialization otherwise required when the C-arm view orientation changes. In addition, the proposed method can be straightforwardly combined with the previously introduced biplane motion compensation technique to obtain a good trade-off between accuracy and radiation dose reduction.","Catheters,
Solid modeling,
Training,
Motion compensation,
Tracking,
X-ray imaging,
Image segmentation"
"New construction method for quaternary aperiodic, periodic, and Z-complementary sequence sets","Based on the known binary sequence sets and Gray mapping, a new method for constructing quaternary sequence sets is presented and the resulting sequence sets' properties are investigated. As three direct applications of the proposed method, when we choose the binary aperiodic, periodic, and Z-complementary sequence sets as the known binary sequence sets, the resultant quaternary sequence sets are the quaternary aperiodic, periodic, and Z-complementary sequence sets, respectively. In comparison with the method proposed by Jang et al., the new method can cope with either both the aperiodic and periodic cases or both even and odd lengths of sub-sequences, whereas the former is only fit for the periodic case with even length of sub-sequences. As a consequence, by both our and Jang et al.'s methods, an arbitrary binary aperiodic, periodic, or Z-complementary sequence set can be transformed into a quaternary one no matter its length of sub-sequences is odd or even. Finally, a table on the existing quaternary periodic complementary sequence sets is given as well.",
Semantics-Robust Design Patterns for IEC 61499,"The international standard IEC 61499 for the design of distributed industrial control systems defines an abstract model of function blocks (FB) which allows many different semantic interpretations. As a consequence, in addition, so-called execution models were proposed to specify the execution order of FBs. The variety of models leads to the incompatibility of tools and hinders the portability of automation software. To achieve a degree of execution model independence, in this paper, design patterns are suggested that make FB systems-robust to changes of execution semantics. A semantic-robust pattern is defined for a particular source execution model. The patterns themselves are implemented by means of the FB apparatus and therefore are fairly universal. The patterns can be defined and implemented using the FB transformations expressed in terms of Attributed Graph Grammars.","Semantics,
IEC standards,
Unified modeling language,
Clocks,
Software,
Signal resolution,
Automation"
Branch and bound for informative path planning,"We present an optimal algorithm for informative path planning (IPP), using a branch and bound method inspired by feature selection algorithms. The algorithm uses the monotonicity of the objective function to give an objective function-dependent speedup versus brute force search. We present results which suggest that when maximizing variance reduction in a Gaussian process model, the speedup is significant.","Path planning,
Robots,
Sensors,
Planning,
Upper bound,
Search problems,
Force"
Amplifying tests to validate exception handling code,"Validating code handling exceptional behavior is difficult, particularly when dealing with external resources that may be noisy and unreliable, as it requires: 1) the systematic exploration of the space of exceptions that may be thrown by the external resources, and 2) the setup of the context to trigger specific patterns of exceptions. In this work we present an approach that addresses those difficulties by performing an exhaustive amplification of the space of exceptional behavior associated with an external resource that is exercised by a test suite. Each amplification attempts to expose a program exception handling construct to new behavior by mocking an external resource so that it returns normally or throws an exception following a predefined pattern. Our assessment of the approach indicates that it can be fully automated, is powerful enough to detect 65% of the faults reported in the bug reports of this kind, and is precise enough that 77% of the detected anomalies correspond to faults fixed by the developers.","Space exploration,
Aerospace electronics,
Instruments,
Androids,
Humanoid robots,
Noise measurement,
Media"
Entropy-Based Measures for Quantifying Sleep-Stage Transition Dynamics: Relationship to Sleep Fragmentation and Daytime Sleepiness,"We present two novel entropy-based measures that quantify sleep-stage transition dynamics (sleep structure) from polysomnogram derived hypnograms: Walsh spectral entropy (WSE) and Haar spectral entropy (HSE). These measures quantify patterns of temporal regularity of a categorical time series without requiring numerical encoding (scaling) of the (categorical) sleep stages. Additionally, we show that conditional entropy (CE) is well suited for quantifying predictability of the hypnogram. The relationship of those measures with traditional sleep fragmentation indices (arousal index, total sleep time, and sleep efficiency) is explored for a 394 participant sample of the Cleveland Family Study, an epidemiologic study in which standardized single-night polysomnogram data were collected. The new entropy-based sleep structure measures (WSE, HSE, and CE) are positively correlated (moderate to weak) with the traditional sleep fragmentation indices. Because the sleep structure measures developed in this paper provide direct information related to temporal patterns of sleep that is not contained in traditional sleep fragmentation measures, the correlation between these new alternative sleep structure measures and the traditional sleep fragmentation measures is less important. Our goal is not to develop alternative measures that correlate highly with traditional measures of sleep fragmentation, but rather to provide methods to quantify sleep structure by examining other (e.g., dynamic sleep-stage transition) properties of the hypnogram. Additionally, the relationship of the new entropy-based and traditional measures with daytime sleepiness as quantified by the Epworth sleepiness scale (ESS) is investigated. Multiple linear regression analysis shows that WSE has a stronger relationship with ESS than the traditional measures, even after both are adjusted for common confounders (age, race, gender, and body mass index). This further suggests that the entropy-based measures, especially WSE, are capturing additional temporal patterns of sleep not captured in the traditional sleep fragmentation measures, and have a relationship with daytime sleepiness.","Time series analysis,
Sleep,
Entropy,
Transforms,
Channel coding,
Time measurement"
Parameter-Aware I/O Management for Solid State Disks (SSDs),"Solid state disks (SSDs) have many advantages over hard disk drives, including better reliability, performance, durability, and power efficiency. However, the characteristics of SSDs are completely different from those of hard disk drives with rotating disks. To achieve the full potential performance improvement with SSDs, operating systems or applications must understand the critical performance parameters of SSDs to fine-tune their accesses. However, the internal hardware and software organizations vary significantly among SSDs and, thus, each SSD exhibits different parameters which influence the overall performance. In this paper, we propose a methodology which can extract several essential parameters affecting the performance of SSDs, and apply the extracted parameters to SSD systems for performance improvement. The target parameters of SSDs considered in this paper are 1) the size of read/write unit, 2) the size of erase unit, 3) the size of read buffer, and 4) the size of write buffer. We modify two operating system components to optimize their operations with the SSD parameters. The experimental results show that such parameter-aware management leads to significant performance improvements for large file accesses by performing SSD-specific optimizations.",
Question analysis: How Watson reads a clue,"The first stage of processing in the IBM Watson™ system is to perform a detailed analysis of the question in order to determine what it is asking for and how best to approach answering it. Question analysis uses Watson's parsing and semantic analysis capabilities: a deep Slot Grammar parser, a named entity recognizer, a co-reference resolution component, and a relation extraction component. We apply numerous detection rules and classifiers using features from this analysis to detect critical elements of the question, including: 1) the part of the question that is a reference to the answer (the focus); 2) terms in the question that indicate what type of entity is being asked for (lexical answer types); 3) a classification of the question into one or more of several broad types; and 4) elements of the question that play particular roles that may require special handling, for example, nested subquestions that must be separately answered. We describe how these elements are detected and evaluate the impact of accurate detection on our end-to-end question-answering system accuracy.","Semantics,
Grammar,
Information analysis,
Feature extraction,
Syntactics,
Computer architecture"
Scheduling Heterogeneous Flows with Delay-Aware Deduplication for Avionics Applications,"An avionics network demands determinism and predictability. This is especially challenging because of the relatively low bandwidth of the on-board network, and the emerging needs of heterogeneous flows due to the proliferation of avionics applications. Redundant transmission and hard real-time scheduling potentially generate many duplicate data, which makes deduplication become more difficult. Many avionic flows further exhibit dynamic workloads which may change abruptly online. Hence, besides the guarantee of transmission delay, modern avionic network design needs to flexibly handle burst flows and efficiently implement data deduplication for bandwidth saving. In order to address these challenges, we propose a DeDuplication-aware Deficit Round Robin (D2DRR)-based scheduling scheme for Avionics Full DupleX (AFDX) networks with the benefits of low complexity and easy implementation. The core idea is to judiciously offer proper “division of labor” between switches and end systems and transform the services for heterogeneous flows to a single representation of utilization, i.e., DRR quantum, which can be flexibly reconfigured. We further leverage Bloom filters to support fast deduplication in order to reduce the load on the AFDX network. D2DRR, hence, offers salient features, elastic scheduling and adept deduplication, to deliver substantial performance improvements. Through both simulations and real implementations, extensive experimental results in an AFDX testbed demonstrate the efficacy and efficiency of our proposed schemes.",
On the Dual of Certain Ternary Weakly Regular Bent Functions,"In 2006, Helleseth and Kholosha conjectured and partially proved the existence of a class of ternary weakly regular monomial bent functions and also the expression for the dual bent function up to the sign value. The bentness was finally proved later in 2009 using a complicated technique that employs Stickelberger's theorem. Extensively using the previously found results and approaches, in this paper, a surprisingly short proof for the conjectured expression of the dual is given but without resolving the sign ambiguity. Furthermore, we resolve the sign by finding the trace representation of the dual function.","Educational institutions,
Transforms,
Lead,
Equations,
Mathematical model,
Computers,
Information theory"
Exploiting Channel Periodicity in Body Sensor Networks,"This paper models the periodic characteristics of body sensor network (BSN) wireless channels measured using custom hardware in the 900-MHz and 2.4-GHz bands. The hardware logs received signal strength indication (RSSI) values of both bands simultaneously at a sample rate of 1.3 kS/s. Results from a measurement campaign of BSNs are shown and distilled to reveal characteristics of BSN channels that can be exploited for reducing the power of wireless communication. A new channel model is introduced to add periodicity to existing 802.15.6 WBAN path loss equations. New parameters, activity factor and location factor, are introduced to estimate the model parameters. Finally, a strategy for exploiting the periodic characteristics of the BSN channel is presented as an example, along with the power savings from using this strategy.",
Secrecy via Sources and Channels,"Alice and Bob want to share a secret key and to communicate an independent message, both of which they desire to be kept secret from an eavesdropper Eve. This problem of secret communication and secret-key generation when two resources are available-correlated sources at Alice, Bob, and Eve, and a noisy broadcast channel from Alice to Bob and Eve which is independent of the sources is studied. The goal is to characterize the fundamental tradeoff between the rates of the secret message and secret key. An achievable solution and proof of its optimality for the parallel channels and sources case when each subchannel and source component satisfies a degradation order (either in favor of the legitimate receiver or the eavesdropper) is presented. This includes the case of jointly Gaussian sources and an additive Gaussian channel, for which the secrecy region is evaluated.",
Cautious Operation Planning Under Uncertainties,"This paper deals with day-ahead power systems security planning under uncertainties by posing an optimization problem over a set of power injection scenarios that could show up the next day and modeling the next day's real-time control strategies aiming at ensuring security with respect to contingencies by a combination of preventive and corrective controls. We seek to determine whether and which day-ahead decisions must be taken so that, for scenarios over the next day, there still exists an acceptable combination of preventive and corrective controls ensuring system security for any postulated contingency. We formulate this task as a three-stage feasibility checking problem, where the first stage corresponds to day-ahead decisions, the second stage to preventive control actions, and the third stage to corrective post-contingency controls. We propose a solution approach based on the problem decomposition into successive optimal power flow (OPF) and security-constrained optimal power flow (SCOPF) problems of a special type. Our approach is illustrated on the Nordic32 system and on a 1203-bus model of a real-life system.",
Effects of Cobalt-60 Gamma-Rays on Ge-Se Chalcogenide Glasses and Ag/Ge-Se Test Structures,"Solid state electrolytes fabricated with chalcogenide glass (ChG) are considered viable candidates for the next generation of non-volatile memory technologies. These glasses, which are composed of group IV and/or group V elements with those of group VI chalcogens (S, Se, and Te), are excellent metal ion conductors. Because of this property, the resistance across structures composed of ChG films sandwiched between active metal (e.g., Ag) and inert metal (e.g., Ni) electrodes can be switched upon the application of sufficient bias, thereby enabling memristive action. In this paper, the effects of 60Co gamma-ray irradiations on Ag/Ge30Se70 test structures are investigated. The results show that exposure to high-energy photons can trigger the transport of Ag+ & ions from an active Ag top layer into an underlying Ge30Se70 ChG film. Post-irradiation annealing experiments also indicate that this “photo-doping” process is reversible once the radiation stress is removed. Numerical simulations which model the mechanisms of radiation-induced photo-doping and recovery are shown to agree well with the data. The results and analysis presented in this paper suggest the ChG-based memristors may be more susceptible to transient radiation effects than cumulative radiation damage.","Glass,
Nonvolatile memory,
Numerical simulation,
Memristors,
Radiation effects"
Heartbeat detection from a hydraulic bed sensor using a clustering approach,"Encouraged by previous performance of a hydraulic bed sensor, this work presents a new hydraulic transducer configuration which improves the system's ability to capture a heartbeat signal from four subjects with different body weight and height, gender, age and cardiac history. It also proposes a new approach for detecting the occurrence of heartbeats from ballistocardiogram (BCG) signals through the use of the k-means clustering algorithm, based on finding the location of the J-peaks. Preliminary testing showed that the new transducer arrangement was able to capture the occurrence of heartbeats for all the participants, and the clustering approach achieved correct heartbeat detection ranging from 98.6 to 100% for three of them. Some considerations are discussed regarding adjustments that can be done in order to increase the correct detection of heartbeats for the participant whose percentage of correct detection ranged from 71.0 to 92.5%.","Transducers,
Heart beat,
Heart rate variability,
Feature extraction,
Monitoring,
Conferences,
Clustering algorithms"
A Practical Joint Network-Channel Coding Scheme for Reliable Communication in Wireless Networks,"In this paper, we propose a practical scheme, Non-Binary Joint Network-Channel Coding (NB-JNCC), for reliable multi-path multi-hop communication in arbitrary large-scale wireless networks. NB-JNCC seamlessly couples channel coding and network coding to effectively combat the detrimental effect of fading of wireless channels. Specifically, NB-JNCC combines non-binary irregular low-density parity-check (LDPC) channel coding and random linear network coding through iterative joint decoding, which helps to fully exploit the spatial diversity and redundancy residing in both channel codes and network codes. In addition, since it operates over a high order Galois field, NB-JNCC can be directly combined with high order modulation without the need of any bit-to-symbol conversion nor its inverse. Through both analysis and simulation, we demonstrate the significant performance improvement of NB-JNCC over other schemes.","Relays,
Decoding,
Network coding,
Iterative decoding,
Joints,
Channel coding"
Reduction of electromagnetic field (EMF) of wireless power transfer system using quadruple coil for laptop applications,"In this paper, we proposed an effective coil design for electromagnetic field (EMF) noise reduction from the wireless power transfer system by using quadruple coils in transmitter and receiver for laptop computer application. By using quadruple coils for transmitter and receiver, EMF noise was significantly reduced with negligible change in induced voltage. 3D simulations and the field distributions are shown and the pros and cons are of the quadruple coil designs are discussed.",
Robot-specific social cues in emotional body language,"Humans use very sophisticated ways of bodily emotion expression combining facial expressions, sound, gestures and full body posture. Like others, we want to apply these aspects of human communication to ease the interaction between robots and users. In doing so we believe there is a need to consider what abstraction of human social communicative behaviors is appropriate for robots. The study reported in this paper is a pilot study to not offer simulated emotion but to offer an abstracted robot version of emotion expressions and an evaluation to what extent users interpret these robot expressions as the intended emotional states. To this end, we present the mobile, mildly humanized robot Daryl, for which we created six motion sequences that combine human-like, animal-like, and robot-specific social cues. The results of a user study (N=29) show that despite the absence of facial expressions and articulated extremities, subjects' interpretation of Daryl's emotional states were congruent with the abstracted emotion display. These results demonstrate that abstract displays of emotion that combine human-like, animal-like, and robot-specific modalities could in fact be an alternative to complex facial expressions and will feed into ongoing work identifying robot-specific social cues.","Robots,
Humans,
Ear,
Animals,
Color,
Emotion recognition,
Light emitting diodes"
Whole-body imitation of human motions with a Nao humanoid,"Summary form only given. We present a system that enables a humanoid robot to imitate complex whole-body motions of humans in real time. For recording the human motions, any sensor system capable of inferring the joint angle trajectories can be used. In our work, we capture the human data with an Xsens MVN motion capture system consisting of inertial sensors attached to the body. Our framework converts the human joint angles to the robot's joint angles in real time. Here, we use a mapping between the human's and the robot's joints to ensure feasibility of the motion. The focus of our system lies in ensuring static stability when the motions are executed which is a challenging task, depending on the complexity of the movements. To avoid falls of the robot that might occur when using direct imitation of the joint angle trajectories due to the different weight distribution, we developed an approach that actively balances the center of mass over the support polygon of the robot's feet. At every point in time, our approach ensures that the robot is in a statically stable configuration, i.e., that the ground projection of the center of mass lies within the convex hull of the foot contact points. To achieve this, we apply inverse kinematics given valid foot positions that satisfy the stability criterion and generate the corresponding leg joint angles. In more detail, our system first finds valid positions for the robot's feet by determining a target plane and its orientation, so that the feet can be placed planar and the robot's center of mass is over the support polygon. The new positions of the feet are chosen as the projection on the target plane. Afterwards, the corresponding leg joint angles are calculated via inverse kinematics. To determine whether the configuration is in the double support modus, and if not, which foot is the stance foot, we evaluate the position of the center of mass relative to the feet. As can be seen in the experiments with a Nao humanoid, our approach leads to a highly stable imitation of challenging human movements (see also Fig. 1). In contrast to recent approaches that capture human data using a Kinect-like sensor and only imitate arm movements while keeping the body static, our system can deal with complex, whole-body motions. Note that our approach does not require a prior learning phase but computes stable configurations online and almost in real time as can be seen in the accompanying video. We are currently working on imitating motions to learn complex navigation actions such as climbing up staircases or walking down ramps. Our system can also be used for tele-operated tasks that include whole-body movements where stability needs to be guaranteed in order to successfully fulfill the mission.","Humans,
Joints,
Humanoid robots,
Robot sensing systems,
Foot,
Real time systems"
Neural Network Structure for Spatio-Temporal Long-Term Memory,"This paper proposes a neural network structure for spatio-temporal learning and recognition inspired by the long-term memory (LTM) model of the human cortex. Our structure is able to process real-valued and multidimensional sequences. This capability is attained by addressing three critical problems in sequential learning, namely the error tolerance, the significance of sequence elements and memory forgetting. We demonstrate the potential of the framework with a series of synthetic simulations and the Australian sign language (ASL) dataset. Results show that our LTM model is robust to different types of distortions. Second, our LTM model outperforms other sequential processing models in a classification task for the ASL dataset.","Tin,
Training,
Neurons,
Vectors,
Testing,
Robustness,
Biological neural networks"
From Hardware-in-the-Loop to Hybrid Process Simulation: An Ontology for the Implementation Phase of a Manufacturing System,"Hardware-in-the-loop (HIL) is a widely used testing approach for embedded systems, where real components and/or controllers are tested in closed-loop with a simulation model. In this paper, we generalize HIL by combining multiple simulations and real components into a Hybrid Process Simulation (HPS). An HPS is a test setup that contains at least one simulated and one actual component, but may contain many of both. It is implemented such that each simulated component can be swapped out with its real counterpart without making changes to the existing system, and vice versa. In this paper, an ontology which provides a conceptual architecture is developed for an HPS, such that a general interpretation of a manufacturing system's implementation is made possible. A formalized application method is then devised for replacing simulations with real processes and vice versa. A conceptual architecture is put forth that separates the effect of a component from its spatial essence (volume or mass). This separation allows workpieces in a manufacturing process, for example, to go from the physical world into the virtual world (computer simulation) and back again repeatedly. The conceptual architecture is applied to a small manufacturing line in the following scenarios: replacing a real robot with a simulated robot, replacing a manufacturing cell with a simulated manufacturing cell, and adding a new simulated manufacturing cell to the existing system. These applications successfully demonstrate how an HPS can be used to test a manufacturing system setup with multiple regions of real and simulated components.","Solid modeling,
Ontologies,
Testing,
Manufacturing systems,
Hardware,
Computer architecture"
SVMeFC: SVM Ensemble Fuzzy Clustering for Satellite Image Segmentation,"The problem of unsupervised image segmentation of a satellite image in a number of homogeneous regions can be viewed as the task of clustering the pixels in the intensity space. This letter presents an approach that exploits the capability of some recently proposed fuzzy clustering techniques, as well as support vector machine (SVM) classifiers, to yield improved solutions. All the fuzzy clustering techniques are first used to produce a set of different clustering solutions. Each such solution has been improved by a novel technique based on an SVM classifier. Thereafter, the cluster-based similarity partition algorithm is used to create the final clustering solution from all improved ensemble solutions. Results demonstrating the effectiveness of the proposed technique are provided for numeric remote sensing data described in terms of feature vectors. Moreover, a remotely sensed image of Calcutta City has been segmented using the proposed technique to establish its utility. In addition, the additional information of this letter is given as supplementary at http://sysbio.icm.edu.pl/indra/SVMeFC.html.",
A Discriminative Model of Motion and Cross Ratio for View-Invariant Action Recognition,"Action recognition is very important for many applications such as video surveillance, human-computer interaction, and so on; view-invariant action recognition is hot and difficult as well in this field. In this paper, a new discriminative model is proposed for video-based view-invariant action recognition. In the discriminative model, motion pattern and view invariants are perfectly fused together to make a better combination of invariance and distinctiveness. We address a series of issues, including interest point detection in image sequence, motion feature extraction and description, and view-invariant calculation. First, motion detection is used to extract motion information from videos, which is much more efficient than traditional background modeling and tracking-based methods. Second, as for feature representation, we exact variety of statistical information from motion and view-invariant feature based on cross ratio. Last, in the action modeling, we apply a discriminative probabilistic model-hidden conditional random field to model motion patterns and view invariants, by which we could fuse the statistics of motion and projective invariability of cross ratio in one framework. Experimental results demonstrate that our method can improve the ability to distinguish different categories of actions with high robustness to view change in real circumstances.","Feature extraction,
Hidden Markov models,
Computer vision,
Humans,
Optical imaging,
Image sequences,
Image motion analysis"
Exploring the design space of social network-based Sybil defenses,"Recently, there has been significant research interest in leveraging social networks to defend against Sybil attacks. While much of this work may appear similar at first glance, existing social network-based Sybil defense schemes can be divided into two categories: Sybil detection and Sybil tolerance. These two categories of systems both leverage global properties of the underlying social graph, but they rely on different assumptions and provide different guarantees: Sybil detection schemes are application-independent and rely only on the graph structure to identify Sybil identities, while Sybil tolerance schemes rely on application-specific information and leverage the graph structure and transaction history to bound the leverage an attacker can gain from using multiple identities. In this paper, we take a closer look at the design goals, models, assumptions, guarantees, and limitations of both categories of social network-based Sybil defense systems.","Social network services,
Communities,
Image edge detection,
Buildings,
Joining processes,
Electronic mail,
Protocols"
Lost in translation (and rotation): Rapid extrinsic calibration for 2D and 3D LIDARs,"This paper describes a novel method for determining the extrinsic calibration parameters between 2D and 3D LIDAR sensors with respect to a vehicle base frame. To recover the calibration parameters we attempt to optimize the quality of a 3D point cloud produced by the vehicle as it traverses an unknown, unmodified environment. The point cloud quality metric is derived from Rényi Quadratic Entropy and quantifies the compactness of the point distribution using only a single tuning parameter. We also present a fast approximate method to reduce the computational requirements of the entropy evaluation, allowing unsupervised calibration in vast environments with millions of points. The algorithm is analyzed using real world data gathered in many locations, showing robust calibration performance and substantial speed improvements from the approximations.","Laser radar,
Calibration,
Vehicles,
Sensors,
Entropy,
Cost function"
Sampling and Ontologically Pooling Web Images for Visual Concept Learning,"Sufficient training examples are essential for effective learning of semantic visual concepts. In practice, however, acquiring noise-free training examples has always been expensive. Recently the rapid popularization of social media websites, such as Flickr, has made it possible to collect training exemplars without human assistance. This paper proposes a novel and efficient approach to collect training samples from the noisily tagged Web images for visual concept learning, where we try to maximize two important criteria, relevancy and coverage, of the automatically generated training sets. For the former, a simple method named semantic field is introduced to handle the imprecise and incomplete image tags. Specifically, the relevancy of an image to a target concept is predicted by collectively analyzing the associated tag list of the image using two knowledge sources: WordNet corpus and statistics from Flickr.com. To boost the coverage or diversity of the training sets, we further propose an ontology-based hierarchical pooling method to collect samples not only based on the target concept alone, but also from ontologically neighboring concepts. Extensive experiments on three different datasets (NUS-WIDE, PASCAL VOC, and ImageNet) demonstrate the effectiveness of our proposed approach, producing competitive performance even when comparing with concept classifiers learned using expert- labeled training examples.","Training,
Visualization,
Semantics,
Media,
Animals,
Training data,
Manuals"
Minimizing the disaster risk in optical telecom networks,"Regional failures caused by disasters precipitate huge amount of loss and jeopardize many connections. A risk model for disasters, considering differentiated services, is introduced and a disaster-aware provisioning scheme is proposed to reduce the risk.","Hazards,
Earthquakes,
Optical fiber networks,
Risk management,
Telecommunications,
Optical fibers"
Compressed magnetic resonance imaging based on wavelet sparsity and nonlocal total variation,"This paper introduces an efficient algorithm for the compressed MR image reconstruction problem, which is formulated as the minimization of a linear combination of three terms corresponding to a least square data fitting, nonlocal total variation (NLTV) and wavelet sparsity regularization. In our method, the original minimization problem is decomposed into wavelet sparsity and NLTV norm regularization subproblems respectively. Then, these two subproblems are efficiently solved by existing techniques. Finally, the reconstructed image is obtained from the weighted average of solutions from two subproblems in an iterative framework. Experiments with improved performance over previous methods demonstrate the superior performance of the proposed algorithm for compressed MR image reconstruction.","Image reconstruction,
Signal to noise ratio,
Image coding,
TV,
Imaging,
Compressed sensing,
Computational complexity"
Time to play with a microcontroller managed mobile bot,"Although science, engineering, and technology have an influence on humanity's present and future challenges, many students lack even a fundamental knowledge in these disciplines. Science teachers are looking for new teaching models and tools that provide skills for entering careers these fields. During the last two decades academia has recognized education games as a beneficial instrument for this purpose. This paper presents first steps in the design and development of the online education game, based on the remote experiments - a microcontroller managed mobile bot (ROBOT). A scenario, architecture, and design of the game will be described. The technological restrictions of the remote experiments will be discussed.",
Human influence of robotic swarms with bandwidth and localization issues,"Swarm robots use simple local rules to create complex emergent behaviors. The simplicity of the local rules allows for large numbers of low-cost robots in deployment, but the same simplicity creates difficulties when deploying in many applicable environments. These complex missions sometimes require human operators to influence the swarms towards achieving the mission goals. Human swarm interaction (HSI) is a young field with few user studies exploring operator behavior. These studies all assume perfect information between the operator and the swarm, which is unrealistic in many applicable scenarios. Indoor search and rescue or underwater exploration may present environments where radio limitations restrict the bandwidth of the robots. This study explores this bandwidth restriction in a user study. Three levels of bandwidth are explored to determine what amount of information is necessary to accomplish a swarm foraging task. The lowest bandwidth condition performs poorly, but the medium and high bandwidth condition both perform well. The medium bandwidth condition does so by aggregating useful swarm information to compress the state information. Further, the study shows operators preferences that should have hindered task performance, but operator adaptation allowed for error correction.","Bandwidth,
Humans,
Robot sensing systems,
Spatial resolution,
Standards,
Color"
Comparing the power and performance of Intel's SCC to state-of-the-art CPUs and GPUs,"Power dissipation and energy consumption are becoming increasingly important architectural design constraints in different types of computers, from embedded systems to large-scale supercomputers. To continue the scaling of performance, it is essential that we build parallel processor chips that make the best use of exponentially increasing numbers of transistors within the power and energy budgets. Intel SCC is an appealing option for future many-core architectures. In this paper, we use various scalable applications to quantitatively compare and analyze the performance, power consumption and energy efficiency of different cutting-edge platforms that differ in architectural build. These platforms include the Intel Single-Chip Cloud Computer (SCC) many-core, the Intel Core i7 general-purpose multi-core, the Intel Atom low-power processor, and the Nvidia ION2 GPGPU. Our results show that the GPGPU has outstanding results in performance, power consumption and energy efficiency for many applications, but it requires significant programming effort and is not general enough to show the same level of efficiency for all the applications. The “light-weight” many-core presents an opportunity for better performance per watt over the “heavy-weight” multi-core, although the multi-core is still very effective for some sophisticated applications. In addition, the low-power processor is not necessarily energy-efficient, since the runtime delay effect can be greater than the power savings.","Graphics processing unit,
Jacobian matrices,
Computer architecture,
Energy consumption,
Tiles,
Transistors,
Power demand"
MapReduce across Distributed Clusters for Data-intensive Applications,"Recently, the computational requirements for large scale data-intensive analysis of scientific data have grown significantly. In High Energy Physics (HEP) for example, the Large Hadron Collider (LHC) produced 13 petabytes of data in 2010. This huge amount of data are processed on more than 140 computing centers distributed across 34 countries. The MapReduce paradigm has emerged as a highly successful programming model for large-scale data-intensive computing applications. However, current MapReduce implementations are developed to operate on single cluster environments and cannot be leveraged for large-scale distributed data processing across multiple clusters. On the other hand, workflow systems are used for distributed data processing across data centers. It has been reported that the workflow paradigm has some limitations for distributed data processing, such as reliability and efficiency. In this paper, we present the design and implementation of GHadoop, a MapReduce framework that aims to enable large-scale distributed computing across multiple clusters. G-Hadoop uses the Gfarm file system as an underlying file system and executes MapReduce tasks across distributed clusters. Experiments of the G-Hadoop framework on distributed clusters show encouraging results.","Servers,
Distributed databases,
Data processing,
Torque,
Software,
Computer architecture,
Computational modeling"
Improving early detection of software merge conflicts,"Merge conflicts cause software defects which if detected late may require expensive resolution. This is especially true when developers work too long without integrating concurrent changes, which in practice is common as integration generally occurs at check-in. Awareness of others' activities was proposed to help developers detect conflicts earlier. However, it requires developers to detect conflicts by themselves and may overload them with notifications, thus making detection harder. This paper presents a novel solution that continuously merges uncommitted and committed changes to create a background system that is analyzed, compiled, and tested to precisely and accurately detect conflicts on behalf of developers, before check-in. An empirical study confirms that our solution avoids overloading developers and improves early detection of conflicts over existing approaches. Similarly to what happened with continuous compilation, this introduces the case for continuous merging inside the IDE.","Merging,
Programming,
Software,
Animals,
Semantics,
Servers,
Computer languages"
Point clouds can be represented as implicit surfaces for constraint-based haptic rendering,"We present a constraint-based strategy for haptic rendering of arbitrary point cloud data. With the recent proliferation of low-cost range sensors, dense 3D point cloud data is readily available at high update rates. Taking a cue from the graphics literature, we propose that point data should be represented as an implicit surface, which can be formulated to be mathematically smooth and efficient for computing interaction forces, and for which haptic constraint algorithms are already well-known. This method is resistant to sensor noise, makes no assumptions about surface connectivity or orientation, and data pre-processing is fast enough for use with streaming data. We compare the performance of two different implicit representations and discuss our strategy for handling time-varying point clouds from a depth camera. Applications of haptic point cloud rendering to remote sensing, as in robot telemanipulation, are also discussed.",
Discriminant Learning Through Multiple Principal Angles for Visual Recognition,"Canonical correlation has been prevalent for multiset-based pairwise subspace analysis. As an extension, discriminant canonical correlations (DCCs) have been developed for classification purpose by learning a global subspace based on Fisher discriminant modeling of pairwise subspaces. However, the discriminative power of DCCs is not optimal as it only measures the “local” canonical correlations within subspace pairs, which lacks the “global” measurement among all the subspaces. In this paper, we propose a multiset discriminant canonical correlation method, i.e., multiple principal angle (MPA). It jointly considers both “local” and “global” canonical correlations by iteratively learning multiple subspaces (one for each set) as well as a global discriminative subspace, on which the angle among multiple subspaces of the same class is minimized while that of different classes is maximized. The proposed computational solution is guaranteed to be convergent with much faster converging speed than DCC. Extensive experiments on pattern recognition applications demonstrate the superior performance of MPA compared to existing subspace learning methods.","Correlation,
Training,
Vectors,
Optimization,
Feature extraction,
Electronic mail,
Accuracy"
Fast feature-based video stabilization without accumulative global motion estimation,"This paper presents a novel digital video stabilization approach that provides both efficiency and robustness. In this approach, features of each frame are first detected by the oriented features from accelerated segment test (FAST) method, and then the corresponding features between consecutive frames are matched by a very fast binary descriptor which is based on the rotated binary robust independent elementary features (BRIEF). The oriented FAST combined with the rotated BRIEF, which is called ORB, is very efficient in feature detection and matching, and can be used to speed up the motion estimation without any hardware acceleration. In addition, an improved motion smoothing method is proposed to smooth affine model based motion parameters without accumulative global motion estimation. Unlike the conventional method, the proposed method uses unstable input frames and stabilized output frames instead of original input frames to estimate motion parameters directly, allowing for more desirable motion parameters. Experiments with a variety of videos demonstrate that the proposed approach is both efficient and robust.",
Signal Quality Estimation With Multichannel Adaptive Filtering in Intensive Care Settings,"A signal quality estimate of a physiological waveform can be an important initial step for automated processing of real-world data. This paper presents a new generic point-by-point signal quality index (SQI) based on adaptive multichannel prediction that does not rely on ad hoc morphological feature extraction from the target waveform. An application of this new SQI to photoplethysmograms (PPG), arterial blood pressure (ABP) measurements, and ECG showed that the SQI is monotonically related to signal-to-noise ratio (simulated by adding white Gaussian noise) and to subjective human quality assessment of 1361 multichannel waveform epochs. A receiver-operating-characteristic (ROC) curve analysis, with the human “bad” quality label as positive and the “good” quality label as negative, yielded areas under the ROC curve of 0.86 (PPG), 0.82 (ABP), and 0.68 (ECG).","Electrocardiography,
Humans,
Kalman filters,
Signal to noise ratio,
Indexes,
Gaussian noise,
Channel estimation"
System-Wide Leakage-Aware Energy Minimization Using Dynamic Voltage Scaling and Cache Reconfiguration in Multitasking Systems,"System optimization techniques are widely used to improve energy efficiency as well as overall performance. Dynamic voltage scaling (DVS) is well studied and known to be successful in reducing processor energy consumption. Due to the increasing significance of the memory subsystem's energy consumption, dynamic cache reconfiguration (DCR) techniques are recently proposed at the aim of improving cache subsystem's energy efficiency. As the manufacturing technology scales into the order of nanometers, leakage current, which leads to static power consumption, becomes a significant contributor in the overall power dissipation. In this paper, we consider various system components and study their impact on system-wide energy consumption under different processor voltage levels as well as cache configurations. Based on the observation, we efficiently integrate DVS and DCR techniques together to make decisions judiciously so that the total energy consumption is minimized. Our studies show that considering only DVS or DCR and ignoring the impact from other system components may lead to incorrect conclusions in overall energy savings. Experimental results demonstrate that our approach outperforms existing leakage-aware DVS techniques by 47.6% and leakage-oblivious DVS + DCR technique by up to 23.5%.","Energy consumption,
Voltage control,
Memory management,
Real time systems,
Power demand,
System buses,
Estimation"
Efficient Scheduling Algorithms for Multiantenna CDMA Systems,"In multiple-input-multiple-output (MIMO) multiuser systems, simultaneously serving multiple users achieves high data rates. However, high-performance transmit beamforming requires an adequately designed user-selection scheme. Optimal scheduling can be only obtained through a high computationally complex exhaustive search, and hence, low-complexity heuristic algorithms are required. In addition, employing a multiple-access scheme such as code division (CDMA) largely increases the complexity of optimal scheduling, and it becomes unemployable even for a moderate number of users and antennas. In this context, this paper proposes three heuristic scheduling algorithms for MIMO CDMA systems using zero-forcing beamforming (ZFBF). We use a graph-theoretical approach to model the system as a weighted undirected graph. The problem of user selection is then formulated as a graph coloring problem, namely, the maximum weight N-colorable subgraph problem. Then, we design two heuristics to solve this graph problem. The first algorithm is a low-complexity greedy algorithm. The second algorithm is based on a tabu search approach to resolve efficiently the complexity/performance tradeoff. Numerical and simulation results show the sub-optimal performances and robustness of the proposed low-complexity algorithms.",
On Capacity and Optimal Scheduling for the Half-Duplex Multiple-Relay Channel,"We study the half-duplex multiple-relay channel (HD-MRC) where every node can either transmit or listen but cannot do both at the same time. We obtain a capacity upper bound based on a max-flow min-cut argument and achievable transmission rates based on the decode-forward (DF) coding strategy, for both the discrete memoryless HD-MRC and the phase-fading HD-MRC. We discover that both the upper bound and the achievable rates are functions of the transmit/listen state (a description of which nodes transmit and which receive). More precisely, they are functions of the time fraction of the different states, which we term a schedule. We formulate the optimal scheduling problem to find an optimal schedule that maximizes the DF rate. The optimal scheduling problem turns out to be a maximin optimization, for which we propose an algorithmic solution. We demonstrate our approach on a four-node multiple-relay channel, obtaining closed-form solutions in certain scenarios. Furthermore, we show that for the received signal-to-noise ratio degraded phase-fading HD-MRC, the optimal scheduling problem can be simplified to a max optimization.","Relays,
Optimal scheduling,
Upper bound,
Schedules,
Encoding,
Signal to noise ratio"
Trustworthy Service Provider Selection in Cloud Computing Environment,"Cloud computing is an emerging computing paradigm which allows sharing of massive, heterogeneous, elastic resources among users. Despite of all the hype surrounding the cloud, users are still reluctant to adopt cloud computing because public cloud services process users' data on machines that users do not own hence there is a fear of leakage of users' commercially sensitive data. Due to these reasons, it is very necessary that cloud users' be vigilant while selecting the service providers present in the cloud. To address this problem, selection of trustworthy cloud providers is proposed where users or enterprises employ the services of trustworthy service providers in the cloud. The paper proposes a system based on cooperative model of society where users select trustworthy service providers based on the recommendations given by their trustworthy acquaintances. The uncertainty present in the recommendations is handled through Fuzzy Inference System (FIS). Fuzzy inference system is capable of inferring crisp output even when the inputs are imprecise or uncertain, mimicking the reasoning of human mind. Experiments confirm that selection of trustworthy cloud providers is an effective and feasible way of estimating the trustworthiness of the service providers and thus helping users in protecting their data.","Cloud computing,
Vectors,
Uncertainty,
Educational institutions,
Computer science,
Humans,
Cognition"
Energy-Aware Video Encoding for Image Quality Improvement in Battery-Operated Surveillance Camera,"Growing needs for surveillance in locations without power lines necessitates the development of a surveillance camera with extremely low-power consumption and an assured stable operation until the time of expected run-out of available energy. This paper proposes an algorithm for scheduling of video encoding configurations in a battery-operated surveillance system to reduce the image distortion while assuring the sustained operation until the battery recharge/exchange. The optimal video encoding configuration is determined based on the amount of estimated remaining event duration (considering the uncertainty of events) and remaining battery charge (considering the rate-capacity and recovery effect). The proposed algorithm consists of two steps: design-time step and run-time step. In the design-time step, prediction of remaining event duration, called duration prediction, is performed considering the uncertainty of events and tradeoff between encoding power and image quality. During run-time, video encoding configuration is switched between intra-frame encoding and inter-frame encoding based on the duration prediction obtained in design-time step and the remaining battery charge measured in run-time step. Compared to the conventional method based on the most conservative duration prediction , experimental results show that the proposed method provides 2.24~3.78 dB improvement in the image quality (in terms of peak signal-to-noise ratio in the H.264 encoding of four video sequences while satisfying the battery constraint.","Batteries,
Image quality,
Encoding,
Image coding,
Complexity theory,
Surveillance,
Cameras"
An event-triggered Model Predictive Control scheme for freeway systems,"Objective of this paper is to define an efficient control framework for freeway systems based on ramp metering. First of all, a Model Predictive Control (MPC) scheme is proposed in which the well known nonlinear cell transmission model (CTM) is used for the prediction. The model is then reformulated as a mixed logical dynamical (MLD) system, i.e. it is described by linear dynamic equations and linear inequalities in which both continuous and binary variables are present. In this way, the finite-horizon optimal control problem in the MPC scheme is transformed into a mixed integer quadratic programming problem whose objective function quadratically penalizes the deviation of the state variables from a specific equilibrium point. It is shown that the resulting control law stabilizes the system. Moreover, in order to make it more suitable for a real-time use, the foregoing control strategy is redesigned into an event-triggered control scheme. The idea is to update the control law only when the considered error exceeds a pre-specified threshold. Simulation results demonstrate how the use of the triggering rule allows to preserve the good performance of the proposed control scheme, while reducing the overall computational load.","Traffic control,
Mathematical model,
Vehicles,
Computational modeling,
Optimal control,
Stability analysis,
Predictive control"
An Improved Multiband-Structured Subband Adaptive Filter Algorithm,"Recently, a multiband-structured subband adaptive filter (MSAF) algorithm was proposed to speed up the convergence of the normalized least-mean-square (NLMS) algorithm. In this letter, we extend this work and propose an improved multiband-structured subband adaptive filter (IMSAF) algorithm to increase the convergence speed of the MSAF, which can also be regarded as a unifying framework for the NLMS, MSAF, and affine projection (AP) algorithms. The proposed optimization criterion is based on the principle of minimal disturbance, canceling the most recent P a posteriori errors in each of the N subbands. The stability condition and the computational complexity are also analyzed. Computer simulations in the context of system identification demonstrate the effectiveness of the new algorithm.","Signal processing algorithms,
Vectors,
Convergence,
Acoustics,
Optimization,
Heuristic algorithms,
Stability analysis"
Bandwidth Distribution Solutions for Performance Enhancement in Long-Reach Passive Optical Networks,"Long-reach Passive Optical Networks (LR-PONs) aim to combine the capacity of metro and access networks by extending the reach and split ratio of the conventional PONs. LR-PONs appear as efficient solutions having feeder distances around 100km and high split ratios up to 1000-way. On the other hand, transmission of the signals in long distances up to 100km leads to increased propagation delay whereas high split ratio may lead to long cycle times resulting in large queue occupancies and long packet delays. Before LR-PON becomes widely adopted, the trade-off between the advantages and performance degradation problem which is resulting from long reach and high split ratio properties of LR-PONs needs to be solved. Recent studies have focused on enhancing the performance of dynamic bandwidth allocation in LR-PONs. This article presents a comprehensive survey on the dynamic bandwidth allocation schemes for LR-PONs. In the article, a comparative classification of the proposed schemes based on their quality-of-service awareness, base-types, feeder distances and tested performance metrics is provided. At the end of the article, a brief discussion on the open issues and research challenges for the solution of performance degradation in LR-PONs is presented.","Delay,
Passive optical networks,
EPON,
Optical network units,
IEEE 802.3 Standards,
Bandwidth,
Wavelength division multiplexing"
Estimation of partial discharge inception voltage of magnet wires under inverter surge voltage by volume-time theory,"This paper discusses a novel estimation method for partial discharge inception voltage (PDIV) of magnet wire under inverter surge voltage application. We focused on the generation probability of initial electrons, which induce PD under high electric field and short rise time of surge voltage, by means of Volume-Time theory. We applied the Volume-Time theory to PD inception phenomena in a wedge-shaped air gap of twisted pair samples composed of enameled wires, and estimated PDIV in consideration of initial electron generation probability with temporal and spatial change in electric field distribution. We could estimate PDIV under different waveforms of applied surge voltage for different specifications of enameled wires. PDIV estimated by the extended Volume-Time theory agreed well with the measured PDIV. The estimated PDIV decreased with the increase in the rise time of applied voltage waveform, which corresponded to the V-t characteristics in the time range of inverter surge voltage.","Partial discharges,
Surges,
Electric fields,
Video recording,
Inverters,
Equations,
Coatings"
Categorization and Segmentation of Intestinal Content Frames for Wireless Capsule Endoscopy,"Wireless capsule endoscopy (WCE) is a device that allows the direct visualization of gastrointestinal tract with minimal discomfort for the patient, but at the price of a large amount of time for screening. In order to reduce this time, several works have proposed to automatically remove all the frames showing intestinal content. These methods label frames as {intestinal content - clear} without discriminating between types of content (with different physiological meaning) or the portion of image covered. In addition, since the presence of intestinal content has been identified as an indicator of intestinal motility, its accurate quantification can show a potential clinical relevance. In this paper, we present a method for the robust detection and segmentation of intestinal content in WCE images, together with its further discrimination between turbid liquid and bubbles. Our proposal is based on a twofold system. First, frames presenting intestinal content are detected by a support vector machine classifier using color and textural information. Second, intestinal content frames are segmented into {turbid, bubbles, and clear} regions. We show a detailed validation using a large dataset. Our system outperforms previous methods and, for the first time, discriminates between turbid from bubbles media.","Image segmentation,
Visualization,
Support vector machines,
Endoscopes,
Machine learning,
Wireless communication,
Intestines"
Optimizing robust limit cycles for legged locomotion on unknown terrain,"While legged animals are adept at traversing rough landscapes, it remains a very challenging task for a legged robot to negotiate unknown terrain. Control systems for legged robots are plagued by dynamic constraints from underactuation, actuator power limits, and frictional ground contact; rather than relying purely on disturbance rejection, considerable advantage can be obtained by planning nominal trajectories which are more easily stabilized. In this paper, we present an approach for designing nominal periodic trajectories for legged robots that maximize a measure of robustness against uncertainty in the geometry of the terrain. We propose a direct collocation method which solves simultaneously for a nominal periodic control input, for many possible one-step solution trajectories (using ground profiles drawn from a distribution over terrain), and for the periodic solution to a jump Riccati equation which provides an expected infinite-horizon cost-to-go for each of these samples. We demonstrate that this trajectory optimization scheme can recover the known deadbeat open-loop control solution for the Spring Loaded Inverted Pendulum (SLIP) on unknown terrain. Moreover, we demonstrate that it generalizes to other models like the bipedal compass gait walker, resulting in a dramatic increase in the number of steps taken over moderate terrain when compared against a limit cycle optimized for efficiency only.","Trajectory,
Legged locomotion,
Optimization,
Limit-cycles,
Robustness,
Jacobian matrices"
A transformerless galvanically isolated switched capacitor LED driver,"The design and test of a capacitor-isolated LED driver, suitable for screw-in, residential lighting applications, is reported. The design relies on a pair of high voltage isolation capacitors, comprising part of a series resonant tank. The series resonant tank is integrated with a balanced ladder step-down switched capacitor front-end, enabling the series resonant conversion stage to function conveniently with any line voltage, while still preserving the efficient voltage regulation capability of the resonant stage. Dimming and power control are effected with a low frequency PWM control loop. The tested prototype delivers 15.5 W at 425 mA at rated power into a string of 12 LEDs at 92% efficiency. Efficiency exceeding 85% is maintained over more than a 10:1 dimming range, and also over a wide range of line voltages.","Capacitors,
Light emitting diodes,
Resistance,
Voltage control,
Switching circuits,
Switches,
RLC circuits"
A Multiobjective Optimization Based Fuzzy Control for Nonlinear Spatially Distributed Processes With Application to a Catalytic Rod,"This paper considers the problem of multiobjective fuzzy control design for a class of nonlinear spatially distributed processes (SDPs) described by parabolic partial differential equations (PDEs), which arise naturally in the modeling of diffusion-convection-reaction processes in finite spatial domains. Initially, the modal decomposition technique is applied to the SDP to formulate it as an infinite-dimensional singular perturbation model of ordinary differential equations (ODEs). An approximate nonlinear ODE system that captures the slow dynamics of the SDP is thus derived by singular perturbations. Subsequently, the Takagi-Sugeno fuzzy model is employed to represent the finite-dimensional slow system, which is used as the basis for the control design. A linear matrix inequality (LMI) approach is then developed for the design of multiobjective fuzzy controllers such that the closed-loop SDP is exponentially stable, and an L2 performance bound is provided under a prescribed H∞ constraint of disturbance attenuation for the slow system. Furthermore, using the existing LMI optimization technique, a suboptimal fuzzy controller can be obtained in the sense of minimizing the L2 performance bound. Finally, the proposed method is applied to the control of the temperature profile of a catalytic rod.","Eigenvalues and eigenfunctions,
Fuzzy control,
Process control,
Control design,
Mathematical model"
A least squares regression framework on manifolds and its application to gesture recognition,"Least squares regression is a basic approach for statistical analysis. However, its simplicity has often led to researchers overlooking it for complex recognition problems. In this paper, we present a nonlinear regression framework on manifolds for gesture recognition. Our method is developed based upon two key attributes: underlying geometry and least squares fitting. The former attribute is vital since geometry characterizes the space for classification while the latter exhibits a simple estimation model. Considering geometric properties, we formulate least squares regression as a composite function. This gives a natural extension from Euclidean space to manifolds. Our experiments show that the proposed framework achieves state-of-the-art results on the standard hand gesture and body gesture datasets. Our method also generalizes well on the one-shot-learning CHALEARN gesture challenge.",
Quarter-Sphere SVM: Attribute and Spatio-Temporal correlations based Outlier & Event Detection in wireless sensor networks,"Support-Vector Machines (SVM) have received a great interest in the machine learning community since their introduction, especially in Outlier Detection in Wireless Sensor Networks (WSN). The Quarter-Sphere formulation of One-Class SVM (QS-SVM), extends the main SVM ideas from supervised to unsupervised learning algorithms. The QS-SVM formulation is based only on Spatio-Temporal correlations between the sensor nodes (hence the name Spatio-Temporal Quarter-Sphere SVM, ST-QS-SVM). Thus, it has a non-ideal performance. This work presents a new One-Class Quarter-Sphere SVM formulation based on the novel concept of Attribute Correlations between the sensor nodes, hence the name, Spatio-Temporal-Attribute Quarter-sphere SVM (STA-QS-SVM) formulation. Online and partially online approaches to Outlier Detection in WSNs have been presented using this formulation. The results indicate a significant increase in the Outlier Detection rates and a remarkable reduction in the False Positive rates over the previous formulation (ST-QS-SVM). The results of this novel technique also suggest that the partially online approach is as efficient as the online approach, thereby conserving significant computational and communication complexity. Moreover very high Event Detection rates have been reported for STA-QS-SVM, which have not been reported by ST-QS-SVM.","Support vector machines,
Silicon,
Vectors,
Correlation,
Event detection,
Optimization"
Exposing image splicing with inconsistent local noise variances,"Image splicing is a simple and common image tampering operation, where a selected region from an image is pasted into another image with the aim to change its content. In this paper, based on the fact that images from different origins tend to have different amount of noise introduced by the sensors or post-processing steps, we describe an effective method to expose image splicing by detecting inconsistencies in local noise variances. Our method estimates local noise variances based on an observation that kurtosis values of natural images in band-pass filtered domains tend to concentrate around a constant value, and is accelerated by the use of integral image. We demonstrate the efficacy and robustness of our method based on several sets of forged images generated with image splicing.",
Wireless network-level partial relay cooperation,"In this paper, we evaluate the benefits of using one user of a two-user random access system to relay traffic of the other user.","Relays,
Numerical stability,
Throughput,
Stability criteria,
Educational institutions"
A semantic relatedness approach for traceability link recovery,"Human analysts working with automated tracing tools need to directly vet candidate traceability links in order to determine the true traceability information. Currently, human intervention happens at the end of the traceability process, after candidate traceability links have already been generated. This often leads to a decline in the results' accuracy. In this paper, we propose an approach, based on semantic relatedness (SR), which brings human judgment to an earlier stage of the tracing process by integrating it into the underlying retrieval mechanism. SR tries to mimic human mental model of relevance by considering a broad range of semantic relations, hence producing more semantically meaningful results. We evaluated our approach using three datasets from different application domains, and assessed the tracing results via six different performance measures concerning both result quality and browsability. The empirical evaluation results show that our SR approach achieves a significantly better performance in recovering true links than a standard Vector Space Model (VSM) in all datasets. Our approach also achieves a significantly better precision than Latent Semantic Indexing (LSI) in two of our datasets.","Strontium,
Humans,
Semantics,
Encyclopedias,
Electronic publishing,
Internet"
A Multi-Agent Framework for Thermal Aware Task Migration in Many-Core Systems,"In deep submicrometer era, thermal hot spots, and large temperature gradients significantly impact system reliability, performance, cost, and leakage power. As the system complexity increases, it is more and more difficult to perform thermal management in a centralized manner because of state explosion and the overhead of monitoring the entire chip. In this paper, we propose a framework for distributed thermal management in many-core systems where balanced thermal profile can be achieved by proactive task migration among neighboring cores. The framework has a low cost agent residing in each core that observes the local workload and temperature and communicates with its nearest neighbor for task migration and exchange. By choosing only those migration requests that will result in balanced workload without generating thermal emergency, the proposed framework maintains workload balance across the system and avoids unnecessary migration. Experimental results show that, our distributed management policy achieves almost the same performance as a global management policy when the tasks are initially randomly distributed. Compared with existing proactive task migration technique, our approach generates less hotspot, less migration overhead with negligible performance overhead.","Predictive models,
Thermal management,
Distributed control,
Multiagent systems"
Analysis of Facial Marks to Distinguish Between Identical Twins,"Identical twin face recognition is a challenging task due to the existence of a high degree of correlation in overall facial appearance. Commercial face recognition systems exhibit poor performance in differentiating between identical twins under practical conditions. In this paper, we study the usability of facial marks as biometric signatures to distinguish between identical twins. We propose a multiscale automatic facial mark detector based on a gradient-based operator known as the fast radial symmetry transform. The transform detects bright or dark regions with high radial symmetry at different scales. Next, the detections are tracked across scales to determine the prominence of facial marks. Extensive experiments are performed both on manually annotated and on automatically detected facial marks to evaluate the usefulness of facial marks as biometric signatures. Experiment results are based on identical twin images acquired at the 2009 Twins Days Festival in Twinsburg, Ohio. The results of our analysis signify the usefulness of the distribution of facial marks as a biometric signature. In addition, our results indicate the existence of some degree of correlation between geometric distribution of facial marks across identical twins.","Observers,
Face,
Skin,
Face recognition,
Image color analysis,
Manuals,
Detectors"
Extracting meta-measures from data for fuzzy aggregation of crowd sourced information,"Fuzzy measures (FMs) have been used to model the (typically subjective) “worth” of subsets of information sources relative to a decision making problem. The fuzzy integral (FI) is a way to fuse the information encoded in a FM with the (typically objective) confidences in the strength of a hypothesis arising from the information sources. In prior work, Yager discussed a set of aggregation functions for general FMs. However, that work is primarily focused on theoretical exploration versus application. Herein, we investigate the direct extraction of different FMs from data, one for specificity and another for agreement, in the context of crowd sourcing. In crowd sourcing, one often has a lack of a ground truth or information regarding the reliability of sources. That is, all sources must be assumed equal (in terms of knowledge, experience level, etc.). Our goal is the intelligent fusion of this data taking into account as much information as possible from the data itself. Once a set of FMs are extracted from the data, we aggregate the FMs (resulting in what we herein refer to as a meta-measure) and use it in fuzzy integration. The novel aspect of this work is the extraction of multiple FMs directly from the original pool of data and the use of the resultant meta-measure and a FI to fuse the data from which the FMs were extracted. Herein, our data is interval-valued, thus we focus on fusion with respect to the generalized interval FI.","Frequency modulation,
Data mining,
Lattices,
Fuses,
Reliability,
Fuzzy sets,
Educational institutions"
Low-Profile and Electrically Small Meander-Line Antenna Using a Capacitive Feed Structure,"An electrically small and low-profile meander-line antenna using a capacitive feed structure is presented. The meander line has a length of one quarter-wavelength with a shorted end, and the capacitive feed structure is installed at the other end. A back conductor, which works as a ground plane, is located at a distance of 0.01λ0 to the meander-line element forming in the area of 0.121λ0 × 0.075λ0, which satisfies the condition of electrically small antennas (ka = 0.435 <; 0.5, wavenumber k, radius a of a sphere surrounding the antenna, and wavelength λ0 at the resonance frequency). The fabricated antenna has successfully achieved a peak gain of 0.62 dBi and exhibits a higher radiation efficiency of more than 30% compared to an inverted-F antenna of the same dimension.","Resonant frequency,
Antenna measurements,
Antenna feeds,
Impedance"
A State-Space Modeling Approach for Localization of Focal Current Sources From MEG,"State-space modeling is a promising approach for current source reconstruction from magnetoencephalography (MEG) because it constrains the spatiotemporal behavior of inverse solutions in a flexible manner. However, state-space model-based source localization research remains underdeveloped; extraction of spatially focal current sources and handling of the high dimensionality of the distributed source model remain problematic. In this study, we propose a novel state-space model-based method that resolves these problems, extending our previous source localization method to include a temporal constraint by state-space modeling. To enable focal current reconstruction, we account for spatially inhomogeneous temporal dynamics by introducing dynamics model parameters that differ for each cortical position. The model parameters and the intensity of the current sources are jointly estimated according to a Bayesian framework. We circumvent the high dimensionality of the problem by assuming prior distributions of the model parameters to reduce the sensitivity to unmodeled components, and by adopting variational Bayesian inference to reduce the computational cost. Through simulation experiments and application to real MEG data, we have confirmed that our proposed method successfully reconstructs focal current activities, which evolve with their temporal dynamics.",
Role of video application as an instructional strategy for students learning development,"This paper explored on the video's potential in assisting lecturers to sustain students' concentration and enhance students' enthusiasm in and outside the classroom. The driving educational belief, as idea and practice, is that by bringing ideas to life in design, hence with good-quality technology infrastructure, effective information and communication technologies (ICT) integration in and outside the lecture room is accessible. This study goes some way in bridging this gap by exploring the students' engagement and motivation toward video application. Findings demonstrated positive content learning outcomes as measured by objective tests and anecdotal evidence. The video approach facilitated connections to content, student motivation and commitment in learning development identity.",
BioVLAB-MMIA: A Cloud Environment for microRNA and mRNA Integrated Analysis (MMIA) on Amazon EC2,"MicroRNAs, by regulating the expression of hundreds of target genes, play critical roles in developmental biology and the etiology of numerous diseases, including cancer. As a vast amount of microRNA expression profile data are now publicly available, the integration of microRNA expression data sets with gene expression profiles is a key research problem in life science research. However, the ability to conduct genome-wide microRNA-mRNA (gene) integration currently requires sophisticated, high-end informatics tools, significant expertise in bioinformatics and computer science to carry out the complex integration analysis. In addition, increased computing infrastructure capabilities are essential in order to accommodate large data sets. In this study, we have extended the BioVLAB cloud workbench to develop an environment for the integrated analysis of microRNA and mRNA expression data, named BioVLAB-MMIA. The workbench facilitates computations on the Amazon EC2 and S3 resources orchestrated by the XBaya Workflow Suite. The advantages of BioVLAB-MMIA over the web-based MMIA system include: 1) readily expanded as new computational tools become available; 2) easily modifiable by re-configuring graphic icons in the workflow; 3) on-demand cloud computing resources can be used on an “as needed” basis; 4) distributed orchestration supports complex and long running workflows asynchronously. We believe that BioVLAB-MMIA will be an easy-to-use computing environment for researchers who plan to perform genome-wide microRNA-mRNA (gene) integrated analysis tasks.",
A set-based discrete PSO for cloud workflow scheduling with user-defined QoS constraints,"Cloud computing has emerged as a powerful computing paradigm that enables users to access computing services anywhere on demand. It provides a flexible way to implement computation-intensive workflow applications on a pay-per-use basis. Since users are more concerned on the satisfaction of Quality of Service (QoS) in cloud systems, the cloud workflow scheduling problem that addresses different QoS requirements of users has become an important and challenging problem for workflow management in cloud computing. In this paper, we tackle a cloud workflow scheduling problem which enables users to define various QoS constraints like the deadline constraint, the budget constraint, and the reliability constraint. It also enables users to specify one preferred QoS parameter as the optimization objective. A set-based PSO (S-PSO) approach is proposed for this scheduling problem. As the allocation of service instances can be regarded as the selection problem from a set of service instances, it is found the set-based representation scheme in S-PSO is natural for the considered problem. In addition, the S-PSO provides an effective way to take advantage of problem-based heuristics to further accelerate search. We define penalty-based fitness functions to address the multiple QoS constraints and integrate the S-PSO with seven heuristics. A discrete version of the comprehensive learning PSO (CLPSO) algorithm based on the S-PSO method is implemented. Experimental results show that the proposed approach is very competitive especially on the instances with tight QoS constraints.","Quality of service,
Reliability,
Optimization,
Cloud computing,
Processor scheduling,
Scheduling,
Minimization"
Weight distribution of some cyclic codes,"In this paper, for an odd prime p such that p ≡ 3 mod 4, odd n, and d = (pn + 1)/(pk + 1) + (pn − l)/2 with k|n, the value distribution of the exponential sum S(a, b) when a and b run through Fp n is calculated. The weight distribution of the relevant cyclic code C over Fp with the length L = pn − 1 and the dimension dim FpC = 2n In is also derived. Our result generalizes the case in [5].","Polynomials,
Symmetric matrices,
Hamming weight,
Educational institutions,
Galois fields,
Electrical engineering"
Delay and loss-based transport protocols: Buffer-sizing and stability,"It is generally accepted that buffers, in Internet routers, should be much smaller than the currently deployed bandwidth-delay product rule. However, as yet, there is no consensus on the optimal buffer-sizing strategy. Our focus will be on the performance, with respect to sizing buffers, of transport protocols that use queuing delay and packet loss as their feedback signals for flow and congestion control. The protocols we choose for our study are Compound, Illinois, and AFRICA.","Stability analysis,
Compounds,
Delay,
Bifurcation,
Transport protocols,
Topology"
Light-weight trust-based routing protocol for mobile ad hoc networks,"Mobile ad hoc networks (MANETs) were originally designed for a cooperative environment. To use them in hostile environments, trust-based routing can be used, where instead of establishing the shortest routes as done in traditional routing protocols, most trusted routes are established. In this study, the authors present a light-weight trust-based routing protocol. It is light-weight in the sense that the intrusion detection system (IDS) used for estimating the trust that one node has for another, consumes limited computational resource. Moreover, it uses only local information thereby ensuring scalability. Our light-weight IDS takes care of two kinds of attacks, namely, the blackhole attack and the grey hole attack. Whereas our proposed approach can be incorporated in any routing protocol, the authors have used AODV as the base routing protocol to evaluate our proposed approach and give a performance analysis.","trusted computing,
cooperative communication,
cryptographic protocols,
mobile ad hoc networks,
routing protocols,
telecommunication security"
Enhancing Project-Based Learning in Software Engineering Lab Teaching Through an E-Portfolio Approach,"Project-based learning is one of the main successful student-centered pedagogies broadly used in computing science courses. However, this approach can be insufficient when dealing with practical subjects that implicitly require many deliverables and a great deal of feedback and organizational resources. In this paper, a worked e-portfolio is presented as an approach to improve the teaching/learning and evaluation processes in project-based learning environments needing considerable resources. To validate this approach, a practical project-based software engineering course supported by a Moodle-based e-portfolio was designed and taught. The results obtained corroborated the effectiveness of the e-portfolio in practical software engineering teaching; this approach can be extended to similar subjects in other studies and/or curricula.",
Interventional 4-D C-Arm CT Perfusion Imaging Using Interleaved Scanning and Partial Reconstruction Interpolation,"Tissue perfusion measurement during catheter-guided stroke treatment in the interventional suite is currently not possible. In this work, we present a novel approach that uses a C-arm angiography system capable of computed tomography (CT)-like imaging (C-arm CT) for this purpose. With C-arm CT one reconstructed volume can be obtained every 4-6 s which makes it challenging to measure the flow of an injected contrast bolus. We have developed an interleaved scanning (IS) protocol that uses several scan sequences to increase temporal sampling. Using a dedicated 4-D reconstruction approach based on partial reconstruction interpolation (PRI) we can optimally process our data. We evaluated our combined approach (IS-PRI) with simulations and a study in five healthy pigs. In our simulations, the cerebral blood flow values (unit: ml/100 g/min) were 60 (healthy tissue) and 20 (pathological tissue). For one scan sequence the values were estimated with standard deviations of 14.3 and 2.9, respectively. For two interleaved sequences the standard deviations decreased to 3.6 and 1.5, respectively. We used perfusion CT to validate the in vivo results. With two interleaved sequences we achieved promising correlations ranging from r=0.63 to r=0.94. The results suggest that C-arm CT tissue perfusion imaging is feasible with two interleaved scan sequences.",
Analysis of Radar Sounder Signals for the Automatic Detection and Characterization of Subsurface Features,"Radar sounders operating on satellite platforms (e.g., radar sounding missions at Mars) provide a huge amount of data that currently are mostly analyzed by means of manual investigations. This calls for the development of novel techniques for the automatic extraction of information from sounder signals that could greatly support the scientific community. Such a topic has not been addressed sufficiently in the literature. This paper provides a contribution to fill this gap by presenting both 1) a study of the theoretical statistical properties of radar sounder signals, and 2) two novel techniques for the automatic analysis of sounder radargrams. The main goal of the study is the identification of statistical distributions that can accurately model the amplitude fluctuations of different subsurface targets. This is fundamental for the understanding of signal properties and for the definition of automatic data analysis techniques. The results of such a study drive the development of two novel techniques for 1) the generation of subsurface feature maps, and 2) the automatic detection of the deepest scattering areas visible in the radargrams. The former produces for each radargram a map showing which areas have high probability to contain relevant subsurface features. The latter exploits a region-growing approach properly defined for the analysis of radargrams to identify and compose the basal scattering areas. Experimental results obtained on Shallow Radar data acquired on Mars confirm the effectiveness of the proposed techniques.",
Image Processing Assisted Algorithms for Optical Projection Tomography,"Since it was first presented in 2002, optical projection tomography (OPT) has emerged as a powerful tool for the study of biomedical specimen on the mm to cm scale. In this paper, we present computational tools to further improve OPT image acquisition and tomographic reconstruction. More specifically, these methods provide: semi-automatic and precise positioning of a sample at the axis of rotation and a fast and robust algorithm for determination of postalignment values throughout the specimen as compared to existing methods. These tools are easily integrated for use with current commercial OPT scanners and should also be possible to implement in “home made” or experimental setups for OPT imaging. They generally contribute to increase acquisition speed and quality of OPT data and thereby significantly simplify and improve a number of three-dimensional and quantitative OPT based assessments.","Optimized production technology,
Tomography,
Pancreas,
Mice,
Image reconstruction,
Three dimensional displays"
Endoscopic Video Manifolds for Targeted Optical Biopsy,"Gastro-intestinal (GI) endoscopy is a widely used clinical procedure for screening and surveillance of digestive tract diseases ranging from Barrett's Oesophagus to oesophageal cancer. Current surveillance protocol consists of periodic endoscopic examinations performed in 3-4 month intervals including expert's visual assessment and biopsies taken from suspicious tissue regions. Recent development of a new imaging technology, called probe-based confocal laser endomicroscopy (pCLE), enabled the acquisition of in vivo optical biopsies without removing any tissue sample. Besides its several advantages, i.e., noninvasiveness, real-time and in vivo feedback, optical biopsies involve a new challenge for the endoscopic expert. Due to their noninvasive nature, optical biopsies do not leave any scar on the tissue and therefore recognition of the previous optical biopsy sites in surveillance endoscopy becomes very challenging. In this work, we introduce a clustering and classification framework to facilitate retargeting previous optical biopsy sites in surveillance upper GI-endoscopies. A new representation of endoscopic videos based on manifold learning, “endoscopic video manifolds” (EVMs), is proposed. The low dimensional EVM representation is adapted to facilitate two different clustering tasks; i.e., clustering of informative frames and patient specific endoscopic segments, only by changing the similarity measure. Each step of the proposed framework is validated on three in vivo patient datasets containing 1834, 3445, and 1546 frames, corresponding to endoscopic videos of 73.36, 137.80, and 61.84 s, respectively. Improvements achieved by the introduced EVM representation are demonstrated by quantitative analysis in comparison to the original image representation and principal component analysis. Final experiments evaluating the complete framework demonstrate the feasibility of the proposed method as a promising step for assisting the endoscopic expert in retargeting the optical biopsy sites.","Manifolds,
Biopsy,
Endoscopes,
Biomedical optical imaging,
Optical imaging,
Surveillance,
Optical feedback"
Outage Performance of Opportunistic Cooperation in Amplify-and-Forward Relaying Systems with Relay Selection,"Opportunistic cooperation (OC) dynamically switches between a cooperative mode (CM, using direct and relayed links) and a non-cooperative mode (NM, using only the direct link). In this letter, we consider OC in amplify-and-forward (AF) relaying systems where a best relay is selected as an active relay if CM is selected. The OC is shown to have the same full diversity order as the CM. In terms of asymptotic outage probability, we show that the power gain (sometimes also referred to coding gain) achieved from using the OC compared to the CM is -10/(K+1) log10 (1-((2R)/(2R +1))K+1) dB where R is the data rate used for outage threshold. The result says that the power gain is always positive (in dB) and it increases when the data rate increases or the number of relays decreases. Numerical results are provided to verify the analysis and to give insights on the outage performance of the OC.",
Abnormally Malicious Autonomous Systems and Their Internet Connectivity,"While many attacks are distributed across botnets, investigators and network operators have recently identified malicious networks through high profile autonomous system (AS) depeerings and network shutdowns. In this paper, we explore whether some ASs indeed are safe havens for malicious activity. We look for ISPs and ASs that exhibit disproportionately high malicious behavior using 10 popular blacklists, plus local spam data, and extensive DNS resolutions based on the contents of the blacklists. We find that some ASs have over 80% of their routable IP address space blacklisted. Yet others account for large fractions of blacklisted IP addresses. Several ASs regularly peer with ASs associated with significant malicious activity. We also find that malicious ASs as a whole differ from benign ones in other properties not obviously related to their malicious activities, such as more frequent connectivity changes with their BGP peers. Overall, we conclude that examining malicious activity at AS granularity can unearth networks with lax security or those that harbor cybercrime.","IP networks,
Malware,
Feeds,
Measurement,
Internet,
Electronic mail"
Mission-aware placement of RF-based power transmitters in wireless sensor networks,"Wireless Sensor Networks (WSNs) provide wide reach and coverage at low-cost which enable them to be utilized in various fields such as health, smart grid, industrial facilities and defense. One of the fundamental limitations of WSNs in long-lasting applications is the network lifetime. To overcome the battery constraint of sensor nodes, duty cycling, energy-efficient protocols and energy harvesting have been considered widely in the literature. A recently emerging energy harvesting technique, namely Radio Frequency (RF)-based wireless energy transfer promises to extend the lifetime of Wireless Rechargeable Sensor Networks (WRSN) with no dependency on intermittent ambient energy resources. In RF-based wireless energy transfer, deploying power transmitters to fixed locations is costly due to range limitations of wireless power. For this reason, mobile power transmitters that visit a few selected locations; i.e. landmarks are employed. Furthermore, in WSNs sensors are expected to perform certain tasks or missions during their lifetime. The achievement of each mission provides certain profits. In this paper, we aim to optimally select the landmarks for sensor nodes that participate in profit maximizing missions. We propose an Integer Linear Programming (ILP) model, namely Mission-Aware Placement of Wireless Power Transmitters (MAPIT) that optimizes the placement of RF-based chargers in the WRSN by maximizing the number of nodes receiving power from a landmark and those that contribute the maximum profit by achieving a mission. We show that the profit increases for low landmark limit since the number of nodes receiving power from a landmark increases under less landmarks. On the other hand, profit reduces by increased number of missions since the nodes participating to missions become spatially diverse.",
Coastline Detection in Synthetic Aperture Radar (SAR) Images by Integrating Watershed Transformation and Controllable Gradient Vector Flow (GVF) Snake Model,"Detection of coastline in synthetic aperture radars (SARs) is difficult due to the presence of speckle effect and strong signal return from wind-roughened, wave-modulated sea. This paper presents a new approach to detect coastlines from SAR images by integrating watershed transformation and gradient vector flow (GVF) snake model. Several improvements have been made to improve the accuracy and efficiency of coastline detection. First, ratio of averages edge detector is used to produce gradient maps suitable for watershed transformation. Second, an improved GVF snake model is presented, which exploits two external constraint forces to make the curve evolution more controllable. We name it controllable GVF (CGVF) snake model. Third, a coarse-fine processing scheme is employed, in which watershed transformation is performed on a coarse-resolution image to obtain the initial contours for CGVF snake model, and then CGVF snake model is used to refine the roughly detected coastline at fine resolution. Experimental results on Envisat-ASAR and TerraSAR-X images show that with only a modest computational burden, the new approach produces a good match between the detected coastline and the true one.","Image segmentation,
Image edge detection,
Detectors,
Synthetic aperture radar,
Speckle,
Vectors,
Noise"
Reliability-Informed Beat Tracking of Musical Signals,"A new probabilistic framework for beat tracking of musical audio is presented. The method estimates the time between consecutive beat events and exploits both beat and non-beat information by explicitly modeling non-beat states. In addition to the beat times, a measure of the expected accuracy of the estimated beats is provided. The quality of the observations used for beat tracking is measured and the reliability of the beats is automatically calculated. A k -nearest neighbor regression algorithm is proposed to predict the accuracy of the beat estimates. The performance of the beat tracking system is statistically evaluated using a database of 222 musical signals of various genres. We show that modeling non-beat states leads to a significant increase in performance. In addition, a large experiment where the parameters of the model are automatically learned has been completed. Results show that simple approximations for the parameters of the model can be used. Furthermore, the performance of the system is compared with existing algorithms. Finally, a new perspective for beat tracking evaluation is presented. We show how reliability information can be successfully used to increase the mean performance of the proposed algorithm and discuss how far automatic beat tracking is from human tapping.","Probabilistic logic,
Reliability,
Hidden Markov models,
Estimation,
Accuracy,
Prediction algorithms,
Materials"
A Generalized Multiple Scattering Method for Dense Vias With Axially Anisotropic Modes in an Arbitrarily Shaped Plate Pair,"Numerical addition theorems of both axially anisotropic and axially isotropic parallel-plate modes are derived using a method based on boundary integral equations. This leads to a generalized multiple scattering (GMS) method for signal/power integrity analysis of dense vias in an arbitrarily shaped plate pair, which overcomes the limitation of the conventional multiple scattering method depending on the analytical addition theorems in an infinitely large or a finite circular plate pair. Both the numerical addition theorems and the GMS method have been validated by comparing results with either analytical expressions for special cases or full-wave simulations for more general cases. Several examples are provided to demonstrate the advantages of the generalized method over previous via models by taking into account the axially anisotropic modes due to the asymmetry caused by dense vias and/or arbitrarily shaped power/ground plate edges on via performance.",
Location-constrained survivable network virtualization,"Network virtualization is regarded as a promising solution to the revolution of the current Internet. With virtualization, disruptive technologies can be easily deployed over the logic (service) network and transparently mapped to the physical network via the network embedding process. In this work, we address the survivability issue in the virtualization context via resolving the survivable network embedding problem. Particularly, we investigate the impact of the location-awareness and study the resulted problem, namely, location-constrained survivable network embedding (LSNE) problem. For the first time, we present an Integer Linear Programming (ILP) model to achieve joint optimal resource allocation for both the working and backup demand. For large-scale problems, we propose an efficient heuristic algorithm, which is shown to be close to the optimal results from the ILP.","Substrates,
Heuristic algorithms,
Resource management,
Joints,
Indium phosphide,
Computational modeling,
Bandwidth"
An analysis of peak demand reductions due to elasticity of domestic appliances,"Unlike prior work on demand management, which typically requires industrial loads to be turned off during peak times, this paper studies the potential to carry out demand response by modifying the elastic load components of common household appliances. Such a component can decrease its instantaneous power draw at the expense of increasing its duration of operation with no impact on the appliance's lifetime. We identify the elastic components of ten common household appliances. Assuming separate control of an appliance's elastic component, we quantify the relationship between the potential reduction in aggregate peak and the duration required to complete the operation of appliances in four geographic regions: Ontario, Quebec, France and India. We find that even with a small extension to the operation duration of appliances, peak demand can be significantly reduced in all four regions both during winter and summer. For example, during winter in Quebec, a nearly 125 MW reduction in peak demand can be obtained with just a 10% increase in appliance operation duration. We conclude that exploiting appliance elasticity to reduce peak power demand should be an important consideration for appliance manufacturers. From a policy perspective, our study gives regulators the ability to quantitatively assess the impact of requiring manufacturers to conform to “smart appliance” standards.","Home appliances,
Water heating,
Space heating,
Induction motors,
Resistance heating,
Power demand"
Semantic mapping using object-class segmentation of RGB-D images,"For task planning and execution in unstructured environments, a robot needs the ability to recognize and localize relevant objects. When this information is made persistent in a semantic map, it can be used, e. g., to communicate with humans. In this paper, we propose a novel approach to learning such maps. Our approach registers measurements of RGB-D cameras by means of simultaneous localization and mapping. We employ random decision forests to segment object classes in images and exploit dense depth measurements to obtain scale-invariance. Our object recognition method integrates shape and texture seamlessly. The probabilistic segmentation from multiple views is filtered in a voxel-based 3D map using a Bayesian framework. We report on the quality of our object-class segmentation method and demonstrate the benefits in accuracy when fusing multiple views in a semantic map.","Image segmentation,
Image color analysis,
Simultaneous localization and mapping,
Semantics,
Training,
Decision trees,
Accuracy"
PR2 Remote Lab: An environment for remote development and experimentation,"In this paper, we describe a remote lab system that allows remote groups to access a shared PR2. This lab will enable a larger and more diverse group of researchers to participate directly in state-of-the-art robotics research and will improve the reproducibility and comparability of robotics experiments. We identify a set of requirements that apply to all web-based remote laboratories and focus on solutions to these requirements. Specifically, we present solutions to interface, control and design difficulties in the client and server-side software when implementing a remote laboratory architecture. The combination of shared physical hardware and shared middleware software allows for experiments that build upon and compare against results on the same platform and in the same environment for common tasks. We describe how researchers can interact with the PR2 and its environment remotely through a web interface, as well as develop similar interfaces to visualize and run experiments remotely.","Robot sensing systems,
Streaming media,
Remote laboratories,
Browsers,
Middleware,
Internet"
Wireless photoplethysmographic device for heart rate variability signal acquisition and analysis,"The photoplethysmographic (PPG) signal has the potential to aid in the acquisition and analysis of heart rate variability (HRV) signal: a non-invasive quantitative marker of the autonomic nervous system that could be used to assess cardiac health and other physiologic conditions. A low-power wireless PPG device was custom-developed to monitor, acquire and analyze the arterial pulse in the finger. The system consisted of an optical sensor to detect arterial pulse as variations in reflected light intensity, signal conditioning circuitry to process the reflected light signal, a microcontroller to control PPG signal acquisition, digitization and wireless transmission, a receiver to collect the transmitted digital data and convert them back to their analog representations. A personal computer was used to further process the captured PPG signals and display them. A MATLAB program was then developed to capture the PPG data, detect the RR peaks, perform spectral analysis of the PPG data, and extract the HRV signal. A user-friendly graphical user interface (GUI) was developed in LabView to display the PPG data and their spectra. The performance of each module (sensing unit, signal conditioning, wireless transmission/reception units, and graphical user interface) was assessed individually and the device was then tested as a whole. Consequently, PPG data were obtained from five healthy individuals to test the utility of the wireless system. The device was able to reliably acquire the PPG signals from the volunteers. To validate the accuracy of the MATLAB codes, RR peak information from each subject was fed into Kubios software as a text file. Kubios was able to generate a report sheet with the time domain and frequency domain parameters of the acquired data. These features were then compared against those calculated by MATLAB. The preliminary results demonstrate that the prototype wireless device could be used to perform HRV signal acquisition and analysis.","Heart rate variability,
Wireless communication,
Wireless sensor networks,
Graphical user interfaces,
Medical services,
Biomedical monitoring"
Almost optimal accessing of nonstochastic channels in cognitive radio networks,"We propose joint channel sensing, probing, and accessing schemes for secondary users in cognitive radio networks. Our method has time and space complexity O(N·k) for a network with N channels and k secondary users, while applying classic methods requires exponential time complexity. We prove that, even when channel states are selected by adversary (thus non-stochastic), it results in a total regret uniformly upper bounded by Θ(√TN log N), w.h.p, for communication lasts for T timeslots. Our protocol can be implemented in a distributed manner due to the nonstochastic channel assumption. Our experiments show that our schemes achieve almost optimal throughput compared with an optimal static strategy, and perform significantly better than previous methods in many settings.","Throughput,
Sensors,
Probes,
Protocols,
Cognitive radio,
Complexity theory,
Channel estimation"
Improving Generalization Performance in Co-Evolutionary Learning,"Recently, the generalization framework in co-evolutionary learning has been theoretically formulated and demonstrated in the context of game-playing. Generalization performance of a strategy (solution) is estimated using a collection of random test strategies (test cases) by taking the average game outcomes, with confidence bounds provided by Chebyshev's theorem. Chebyshev's bounds have the advantage that they hold for any distribution of game outcomes. However, such a distribution-free framework leads to unnecessarily loose confidence bounds. In this paper, we have taken advantage of the near-Gaussian nature of average game outcomes and provided tighter bounds based on parametric testing. This enables us to use small samples of test strategies to guide and improve the co-evolutionary search. We demonstrate our approach in a series of empirical studies involving the iterated prisoner's dilemma (IPD) and the more complex Othello game in a competitive co-evolutionary learning setting. The new approach is shown to improve on the classical co-evolutionary learning in that we obtain increasingly higher generalization performance using relatively small samples of test strategies. This is achieved without large performance fluctuations typical of the classical approach. The new approach also leads to faster co-evolutionary search where we can strictly control the condition (sample sizes) under which the speedup is achieved (not at the cost of weakening precision in the estimates).","Games,
Estimation,
Tin,
Chebyshev approximation,
Robustness,
Testing,
Educational institutions"
"A Best-First Soft/Hard Decision Tree Searching MIMO Decoder for a 4 \times
4 64-QAM System","This paper presents the algorithm and VLSI architecture of a configurable tree-searching approach that combines the features of classical depth-first and breadth-first methods. Based on this approach, techniques to reduce complexity while providing both hard and soft outputs decoding are presented. Furthermore, a single programmable parameter allows the user to tradeoff throughput versus BER performance. The proposed multiple-input-multiple-output decoder supports a 4 × 4 64-QAM system and was synthesized with 65-nm CMOS technology at 333 MHz clock frequency. For the hard output scheme the design can achieve an average throughput of 257.8 Mbps at 24 dB signal-to-noise ratio (SNR) with area equivalent to 54.2 Kgates and a power consumption of 7.26 mW. For the soft output scheme it achieves an average throughput of 83.3 Mbps across the SNR range of interest with an area equivalent to 64 Kgates and a power consumption of 11.5 mW.","Decoding,
Measurement,
Throughput,
Bit error rate,
MIMO,
Signal to noise ratio,
Complexity theory"
Modeling of Writing Process for Two-Dimensional Magnetic Recording and Performance Evaluation of Two-Dimensional Neural Network Equalizer,"Modeling of a simple writing process considering intergranular exchange fields and magnetostatic interaction fields between grains is studied for two-dimensional magnetic recording (TDMR). A new designing method of a two-dimensional neural network equalizer with a mis-equalization suppression function (2D-NNEMS) for TDMR is also proposed. The bit-error rate (BER) performance of a low-density parity-check coding and iterative decoding system with the designed 2D-NNEMS is obtained via computer simulation using a read/write channel model employing the proposed writing process under TDMR specifications of 4 Tb/in2, and it is compared with those for one- and two-dimensional finite impulse response equalizers (FIREs). It is clarified that the BER performance for the designed 2D-NNEMS is far superior to those for the FIREs.","Magnetic recording,
Writing,
Media,
Equalizers,
Iterative decoding,
Magnetization,
Neural networks"
Generating Super Stimulated-Echoes in MRI and Their Application to Hyperpolarized C-13 Diffusion Metabolic Imaging,"Stimulated-echoes in MR can be used to provide high sensitivity to motion and flow, creating diffusion and perfusion weighting as well as T1 contrast, but conventional approaches inherently suffer from a 50% signal loss. The super stimulated-echo, which uses a specialized radio-frequency (RF) pulse train, has been proposed in order to improve the signal while preserving motion and T1 sensitivity. This paper presents a novel and straightforward method for designing the super stimulated-echo pulse train using inversion pulse design techniques. This method can also create adiabatic designs with an improved response to RF transmit field variations. The scheme was validated in phantom experiments and shown in vivo to improve signal-to-noise ratio (SNR). We have applied a super stimulated-echo to metabolic MRI with hyperpolarized 13C-labeled molecules. For spectroscopic imaging of hyperpolarized agents, several repetition times are required but only a single stimulated-echo encoding is feasible, which can lead to unwanted motion blurring. To address this, a super stimulated-echo preparation scheme was used in which the diffusion weighting is terminated prior to the acquisition, and we observed a SNR increases of 60% in phantoms and 49% in vivo over a conventional stimulated-echo. Experiments following injection of hyperpolarized [1-13C] -pyruvate in murine transgenic cancer models have shown improved delineation for tumors since signals from metabolites within tumor tissues are retained while those from the vasculature are suppressed by the diffusion preparation scheme.","Encoding,
Imaging,
Radio frequency,
Magnetization,
Modulation,
Sensitivity,
Shape"
Analytical Delay Model Considering Variability Effects in Subthreshold Domain,"The demand of ultralow-power circuits has significantly increased in the last few years. Owing to its great potential in energy savings, the use of supply voltage near or below the transistors' threshold voltages has gained particular attention. Designing these kinds of circuits is still a challenge, particularly when latest advanced process technologies are employed. This brief proposes novel analytical delay models for CMOS circuits running in the subthreshold regime. The delay models proposed here take the effects of the process variability and of the transient variation of the transistors' on-current during the switching into account. Owing to this, delays are predicted with accuracy significantly higher than existing accurate delay models. Furthermore, the novel models are also suitable for gates with transistors' stacks.","Delay,
Logic gates,
Semiconductor device modeling,
Integrated circuit modeling,
Inverters,
Transistors,
Predictive models"
Soft Object Deformation Monitoring and Learning for Model-Based Robotic Hand Manipulation,"This paper discusses the design and implementation of a framework that automatically extracts and monitors the shape deformations of soft objects from a video sequence and maps them with force measurements with the goal of providing the necessary information to the controller of a robotic hand to ensure safe model-based deformable object manipulation. Measurements corresponding to the interaction force at the level of the fingertips and to the position of the fingertips of a three-finger robotic hand are associated with the contours of a deformed object tracked in a series of images using neural-network approaches. The resulting model captures the behavior of the object and is able to predict its behavior for previously unseen interactions without any assumption on the object's material. The availability of such models can contribute to the improvement of a robotic hand controller, therefore allowing more accurate and stable grasp while providing more elaborate manipulation capabilities for deformable objects. Experiments performed for different objects, made of various materials, reveal that the method accurately captures and predicts the object's shape deformation while the object is submitted to external forces applied by the robot fingers. The proposed method is also fast and insensitive to severe contour deformations, as well as to smooth changes in lighting, contrast, and background.","Image color analysis,
Robots,
Shape,
Monitoring,
Image segmentation,
Neural networks,
Deformable models"
LPDA: A lightweight privacy-preserving data aggregation scheme for smart grid,"Security and privacy are challenging issues in smart grid. Failure to address them will hinder the flourish of smart grid. In this paper, aiming at resolving the electricity consumption data security and residential user privacy, we proposed an efficient lightweight privacy-preserving aggregation scheme, called LPDA, for smart grid. The proposed LPDA is characterized by employing one-time masking technique to protect user's privacy while achieving lightweight data aggregation. Detailed security analysis has shown that the proposed LPDA scheme is robust against many security and privacy threats in smart grid. Furthermore, performance evaluation via extensive simulations demonstrates its efficiency in terms of low average aggregation delay.","smart power grids,
power consumption,
power system security,
security of data"
CMOS Image Sensors With Multi-Bucket Pixels for Computational Photography,"This paper presents new image sensors with multi- bucket pixels that enable time-multiplexed exposure, an alter- native imaging approach. This approach deals nicely with scene motion, and greatly improves high dynamic range imaging, structured light illumination, motion corrected photography, etc. To implement an in-pixel memory or a bucket, the new image sensors incorporate the virtual phase CCD concept into a standard 4-transistor CMOS imager pixel. This design allows us to create a multi-bucket pixel which is compact, scalable, and supports true correlated double sampling to cancel kTC noise. Two image sensors with dual and quad-bucket pixels have been designed and fabricated. The dual-bucket sensor consists of a 640H × 576V array of 5.0 μm pixel in 0.11 μm CMOS technology while the quad-bucket sensor comprises 640H × 512V array of 5.6 μm pixel in 0.13 μm CMOS technology. Some computational photography applications were implemented using the two sensors to demonstrate their values in eliminating artifacts that currently plague computational photography.","Noise,
Photography,
Image sensors,
Electric potential,
CMOS integrated circuits,
Transistors"
PEV-based reactive power compensation for wind DG units: A stackelberg game approach,"There has been a growing interest recently towards integrating more renewable energy resources, in particular wind power, in form of distributed generation (DG) units. However, one important challenge with wind DG units is to provide low-cost and fast-responding reactive power compensation of the wind turbine's inductive load to ensure a stable voltage profile in the system. Since reactive power can only be compensated locally, we consider a scenario where a wind DG unit is co-located with a plug-in electric vehicle (PEV) charging station or a parking lot, and we investigate how to align incentives to encourage PEV owners to participate in reactive power compensation for wind DG units. For this purpose, in this paper, we introduce a two-stage Stackelberg game between the wind DG unit and the PEV owners. We use backward induction to analyze the formulated game and derive the optimal pricing scheme. We assess the performance of our proposed scheme using field data and make suggestions for the size of the charging stations.","Reactive power,
Games,
Pricing,
Capacitors,
Switches,
Wind power generation,
Nash equilibrium"
"f
-Divergence Estimation and Two-Sample Homogeneity Test Under Semiparametric Density-Ratio Models","A density ratio is defined by the ratio of two probability densities. We study the inference problem of density ratios and apply a semiparametric density-ratio estimator to the two-sample homogeneity test. In the proposed test procedure, the f-divergence between two probability densities is estimated using a density-ratio estimator. The f -divergence estimator is then exploited for the two-sample homogeneity test. We derive an optimal estimator of f-divergence in the sense of the asymptotic variance in a semiparametric setting, and provide a statistic for two-sample homogeneity test based on the optimal estimator. We prove that the proposed test dominates the existing empirical likelihood score test. Through numerical studies, we illustrate the adequacy of the asymptotic theory for finite-sample inference.",
Low-Complexity Image Processing for Real-Time Detection of Neonatal Clonic Seizures,"In this paper, we consider a novel low-complexity real-time image-processing-based approach to the detection of neonatal clonic seizures. Our approach is based on the extraction, from a video of a newborn, of an average luminance signal representative of the body movements. Since clonic seizures are characterized by periodic movements of parts of the body (e.g., the limbs), by evaluating the periodicity of the extracted average luminance signal it is possible to detect the presence of a clonic seizure. The periodicity is investigated, through a hybrid autocorrelation-Yin estimation technique, on a per-window basis, where a time window is defined as a sequence of consecutive video frames. While processing is first carried out on a single window basis, we extend our approach to interlaced windows. The performance of the proposed detection algorithm is investigated, in terms of sensitivity and specificity, through receiver operating characteristic curves, considering video recordings of newborns affected by neonatal seizures.","Pediatrics,
Electroencephalography,
Quantization,
Real time systems,
Sensitivity,
Image processing,
Reliability"
Context Directory: A context-aware service for mobile context-aware computing applications by the example of Google Android,"To enable context-awareness for many distributed mobile applications, an architecture is needed that supports the collecting of disseminated context attributes. After the structuring and storing of context, the interpretation and adaptation with reference to the current context and changes of context must be applied. These tasks are common to a large set of context-aware applications and can be centralized in a context-aware middleware. This article shows the approach called Context Directory, which helps mobile applications to achieve context-awareness. The software architecture and as a proof of concept four categories of context-aware features are described.","Context,
Context-aware services,
Mobile communication,
Context modeling,
Middleware,
Computer architecture"
A Low-Power and High-Precision Programmable Analog Filter Bank,"Analog filter banks befit remote audio- and vibration-sensing applications, which require frequency analysis to be performed with low-power consumption and with moderate-to-high precision. The precision of a filter bank depends on both the signal-path precision (i.e., dynamic range) and also the parameter precision (e.g., accuracy of the center frequencies). This brief presents a new bandpass filter for audio-frequency filter banks and provides a procedure for designing this filter. The filter is used in a 16-channel filter bank which has been fabricated in a 0.35- CMOS process. This filter bank has a dynamic range exceeding 62 dB and consumes only 63.6 when biased for speech frequencies. The filter bank's parameters are set via floating-gate current sources. This brief shows how to use these floating gates to obtain a versatile filter bank that can be precisely reprogrammed to arbitrary filter spacings and frequency weightings, with a parameter accuracy exceeding 99%.","Gain,
Dynamic range,
Transconductance,
Accuracy,
Time frequency analysis,
Noise"
MOHEFT: A multi-objective list-based method for workflow scheduling,"Nowadays, scientists and companies are confronted with multiple competing goals such as makespan in high-performance computing and economic cost in Clouds that have to be simultaneously optimized. Multi-objective scheduling of scientific workflows in distributed systems is therefore receiving increasing research attention. Most existing approaches typically aggregate all objectives in a single function, defined a-priori without any knowledge about the problem being solved, which negatively impacts the quality of the solutions. In contrast, Pareto-based approaches having as outcome a set of several (nearly-) optimal solutions that represent a tradeoff among the different objectives, have been scarcely studied. In this paper, we propose a new Pareto-based list scheduling heuristic that provides the user with a set of tradeoff optimal solutions from where the one that better suits the user requirements can be manually selected. We demonstrate the potential of MOHEFT for a bi-objective scheduling problem that optimizes makespan and economic cost in a Cloud-based computing scenario. We compare MOHEFT with two state-of-the-art approaches using different synthetic and real-world workflows: the classical HEFT algorithm used in single-objective scheduling and the SPEA2* genetic algorithm used for multi-objective optimisation problems.","Schedules,
Cloud computing,
Processor scheduling,
Optimization,
Computational modeling,
Conferences,
Data models"
Using depth in visual simultaneous localisation and mapping,We present a method of utilizing depth information as provided by RGBD sensors for robust real-time visual simultaneous localisation and mapping (SLAM) by augmenting monocular visual SLAM to take into account depth data. This is implemented based on the feely available software “Parallel Tracking and Mapping” by Georg Klein. Our modifications allow PTAM to be used as a 6D visual SLAM system even without any additional information about odometry or from an inertial measurement unit.,
Anonymization of Longitudinal Electronic Medical Records,"Electronic medical record (EMR) systems have enabled healthcare providers to collect detailed patient information from the primary care domain. At the same time, longitudinal data from EMRs are increasingly combined with biorepositories to generate personalized clinical decision support protocols. Emerging policies encourage investigators to disseminate such data in a deidentified form for reuse and collaboration, but organizations are hesitant to do so because they fear such actions will jeopardize patient privacy. In particular, there are concerns that residual demographic and clinical features could be exploited for reidentification purposes. Various approaches have been developed to anonymize clinical data, but they neglect temporal information and are, thus, insufficient for emerging biomedical research paradigms. This paper proposes a novel approach to share patient-specific longitudinal data that offers robust privacy guarantees, while preserving data utility for many biomedical investigations. Our approach aggregates temporal and diagnostic information using heuristics inspired from sequence alignment and clustering methods. We demonstrate that the proposed approach can generate anonymized data that permit effective biomedical analysis using several patient cohorts derived from the EMR system of the Vanderbilt University Medical Center.",
Conductive Polymer Foam Surface Improves the Performance of a Capacitive EEG Electrode,"In this paper, a new conductive polymer foam-surfaced electrode was proposed for use as a capacitive EEG electrode for nonintrusive EEG measurements in out-of-hospital environments. The current capacitive electrode has a rigid surface that produces an undefined contact area due to its stiffness, which renders it unable to conform to head curvature and locally isolates hairs between the electrode surface and scalp skin, making EEG measurement through hair difficult. In order to overcome this issue, a conductive polymer foam was applied to the capacitive electrode surface to provide a cushioning effect. This enabled EEG measurement through hair without any conductive contact with bare scalp skin. Experimental results showed that the new electrode provided lower electrode-skin impedance and higher voltage gains, signal-to-noise ratios, signal-to-error ratios, and correlation coefficients between EEGs measured by capacitive and conventional resistive methods compared to a conventional capacitive electrode. In addition, the new electrode could measure EEG signals, while the conventional capacitive electrode could not. We expect that the new electrode presented here can be easily installed in a hat or helmet to create a nonintrusive wearable EEG apparatus that does not make users look strange for real-world EEG applications.","Electrodes,
Electroencephalography,
Surface impedance,
Impedance,
Polymers,
Surface topography,
Scalp"
Laplacian Eigenmaps for Automatic Story Segmentation of Broadcast News,"We propose Laplacian Eigenmaps (LE)-based approaches to automatic story segmentation on speech recognition transcripts of broadcast news. We reinforce story boundaries by applying LE analysis to sentence connective strength matrix and reveal the intrinsic geometric structure of stories. Specifically, we construct a Euclidean space in which each sentence is mapped to a vector. As a result, the original inter-sentence connective strength is reflected by the Euclidean distances between the corresponding vectors and cohesive relations between sentences become geometrically evident. Taking advantage of LE, we present three story segmentation approaches: LE-TextTiling, spectral clustering and LE-DP. In LE-DP, we formalize story segmentation as a straightforward criterion minimization problem and give a fast dynamic programming solution to it. Extensive story segmentation experiments on three corpora demonstrate that the proposed LE-based approaches achieve superior performances and significantly outperform several state-of-the-art methods. For instance, LE-TextTiling obtains a relative F1-measure increase of 17.8% on CCTV Mandarin BN corpus as compared to conventional TextTiling; LE-DP achieves a high F1-measure of 0.7460, which significantly outperforms a recent CRF-prosody approach with an F1-measure of 0.6783 on TDT2 Mandarin BN corpus.","Laplace equations,
Semantics,
Media,
Streaming media,
Speech recognition,
Robustness,
Multimedia communication"
MEMS Capacitive Accelerometer-Based Middle Ear Microphone,"The design, implementation, and characterization of a microelectromechanical systems (MEMS) capacitive accelerometer-based middle ear microphone are presented in this paper. The microphone is intended for middle ear hearing aids as well as future fully implantable cochlear prosthesis. Human temporal bones acoustic response characterization results are used to derive the accelerometer design requirements. The prototype accelerometer is fabricated in a commercial silicon-on-insulator (SOI) MEMS process. The sensor occupies a sensing area of 1 mm × 1 mm with a chip area of 2 mm × 2.4 mm and is interfaced with a custom-designed low-noise electronic IC chip over a flexible substrate. The packaged sensor unit occupies an area of 2.5 mm × 6.2 mm with a weight of 25 mg. The sensor unit attached to umbo can detect a sound pressure level (SPL) of 60 dB at 500 Hz, 35 dB at 2 kHz, and 57 dB at 8 kHz. An improved sound detection limit of 34-dB SPL at 150 Hz and 24-dB SPL at 500 Hz can be expected by employing start-of-the-art MEMS fabrication technology, which results in an articulation index of approximately 0.76. Further micro/nanofabrication technology advancement is needed to enhance the microphone sensitivity for improved understanding of normal conversational speech.","Micromechanical devices,
Ear,
Bones,
Accelerometers,
Vibrations,
Sensors,
Microphones"
Constructing a New-Style Conceptual Model of Brain Data for Systematic Brain Informatics,"The development of brain science has led to a vast increase of brain data. To meet requirements of a systematic methodology of Brain Informatics (BI), this paper proposes a new conceptual model of brain data, namely Data-Brain, which explicitly represents various relationships among multiple human brain data sources, with respect to all major aspects and capabilities of human information processing systems (HIPS). A multidimension framework and a BI methodology-based ontological modeling approach have been developed to implement a Data-Brain. The Data-Brain, Data-Brain-based BI provenances, and heterogeneous brain data can be used to construct a Data-Brain-based brain data center which provides a global framework to integrate data, information, and knowledge coming from the whole research process for systematic BI study. Such a Data-Brain modeling approach represents a radically new way for domain-driven conceptual modeling of brain data, which models a whole process of systematically investigating human information processing mechanisms.","Data models,
Systematics,
Brain models,
Ontologies,
Human factors"
Improved Designs for an Electrothermal In-Plane Microactuator,"Reported presently are two design approaches to improve the performance of an electrothermal in-plane microactuator with “chevron” beams. One incorporates beams with uniform cross sections but nonuniform lengths or tilt angles to accommodate the thermally induced expansion of the “shuttle”; the other incorporates beams with nonuniform cross sections to widen the high-temperature “expansion” zones. It is derived analytically, verified using finite-element simulations, and tested by microfabricating actuators occupying a constrained device area that the incorporation of one or the other proposed features leads to an improved performance figure-of-merit, defined to be the product of the actuation displacement and force. An increase in the figure-of-merit by up to 65% per beam has been measured.","Heating,
Force,
Thermal expansion,
Microactuators,
Temperature distribution"
Multiuser Switched Diversity Scheduling Schemes,"Multiuser switched-diversity scheduling schemes were recently proposed in order to overcome the heavy feedback requirements of conventional opportunistic scheduling schemes by applying a threshold-based, distributed, and ordered scheduling mechanism. The main idea behind these schemes is that slight reduction in the prospected multiuser diversity gains is an acceptable trade-off for great savings in terms of required channel-state-information feedback messages. In this work, we characterize the achievable rate region of multiuser switched diversity systems and compare it with the rate region of full feedback multiuser diversity systems. We propose also a novel proportional fair multiuser switched-based scheduling scheme and we demonstrate that it can be optimized using a practical and distributed method to obtain the feedback thresholds. We finally demonstrate by numerical examples that switched-diversity scheduling schemes operate within 0.3 bits/sec/Hz from the ultimate network capacity of full feedback systems in Rayleigh fading conditions.",
Rank-Based Network Coding for Content Distribution in Vehicular Networks,"We propose a rank-based network coding scheme for distributing content in vehicular ad-hoc networks, in which vehicles adaptively broadcast packets based on the content reception status of their neighbors. In contrast to the previous work, CodeOn, vehicles in the proposed method only exchange content reception information in the service channel. The packet injection probability in the proposed method is proportional to the estimated innovation that a vehicle can provide to its neighbors. We also give an analytical model to analyze the system throughput when vehicles apply rank-based network coding to broadcast data. Simulation results demonstrate that the proposed method improves the throughput by more than 32% while maintaining lower end-to-end delay and protocol overhead than the previous work.","Encoding,
Vehicles,
Network coding,
Throughput,
Technological innovation,
Road transportation,
Ad hoc networks"
The Technology of the Gaps: An Evolvable Hardware Synthesized Oscillator for the Control of a Flapping-Wing Micro Air Vehicle,"To date, work in evolvable and adaptive hardware (EAH) has been largely isolated from primary inclusion into larger design processes. Almost without exception, EAH efforts are aimed at creating systems whole cloth, creating drop-in replacements for existing components of a larger design, or creating after-the-fact fixes for designs found to be deficient. This paper will discuss early efforts in integrating EAH methods into the design of a controller for a flapping-wing micro air vehicle (FWMAV). The FWMAV project is extensive, multidisciplinary, and on going. Because EAH methods were in consideration during its earliest design stages, this project provides a rich environment in which to explore means of effectively combining EAH and traditional design methodologies. In addition to providing a concrete EAH design that addresses potential problems with FWMAV flight in a unique way, this paper will also provide a provisional list of EAH design integration principles, drawn from our experiences to date.","Vehicles,
Oscillators,
Hardware,
Frequency control,
Force,
Evolutionary computation,
Presses"
Secure Management of Biomedical Data With Cryptographic Hardware,"The biomedical community is increasingly migrating toward research endeavors that are dependent on large quantities of genomic and clinical data. At the same time, various regulations require that such data be shared beyond the initial collecting organization (e.g., an academic medical center). It is of critical importance to ensure that when such data are shared, as well as managed, it is done so in a manner that upholds the privacy of the corresponding individuals and the overall security of the system. In general, organizations have attempted to achieve these goals through deidentification methods that remove explicitly, and potentially, identifying features (e.g., names, dates, and geocodes). However, a growing number of studies demonstrate that deidentified data can be reidentified to named individuals using simple automated methods. As an alternative, it was shown that biomedical data could be shared, managed, and analyzed through practical cryptographic protocols without revealing the contents of any particular record. Yet, such protocols required the inclusion of multiple third parties, which may not always be feasible in the context of trust or bandwidth constraints. Thus, in this paper, we introduce a framework that removes the need for multiple third parties by collocating services to store and to process sensitive biomedical data through the integration of cryptographic hardware. Within this framework, we define a secure protocol to process genomic data and perform a series of experiments to demonstrate that such an approach can be run in an efficient manner for typical biomedical investigations.",
"Performance of rate 0.96 (68254, 65536) EG-LDPC code for NAND Flash memory error correction","As the process technology scales down and the number of bits per cell increases, NAND Flash memory is more prone to bit errors. In this paper, we employ a rate-0.96 (68254, 65536) Euclidean geometry (EG) low-density parity-check (LDPC) code for NAND Flash memory error correction, and evaluate the performance under binary input (BI) additive white Gaussian noise (AWGN) and NAND Flash memory channels. The performance effect of output signal quantization is also studied. We show the strategies for determining the optimum quantization boundaries and computing the quantized log-likelihood ratio (LLR) for the NAND Flash channel model that is approximated as a mixture of Gaussian distributions. Simulation results show that the error performance with the NAND Flash memory channel is much different from that with the BI-AWGN channel. Since the distribution of NAND Flash memory output signal is not stationary, it is important to accurately assess the stochastic distribution of the signal for optimum sensing.","Flash memory,
Quantization,
Parity check codes,
Sensors,
Error correction codes,
Threshold voltage,
Bit error rate"
A CURE for Noisy Magnetic Resonance Images: Chi-Square Unbiased Risk Estimation,"In this paper, we derive an unbiased expression for the expected mean-squared error associated with continuously differentiable estimators of the noncentrality parameter of a chi-square random variable. We then consider the task of denoising squared-magnitude magnetic resonance (MR) image data, which are well modeled as independent noncentral chi-square random variables on two degrees of freedom. We consider two broad classes of linearly parameterized shrinkage estimators that can be optimized using our risk estimate, one in the general context of undecimated filterbank transforms, and the other in the specific case of the unnormalized Haar wavelet transform. The resultant algorithms are computationally tractable and improve upon most state-of-the-art methods for both simulated and actual MR image data.","Noise reduction,
Wavelet transforms,
Vectors,
Rician channels,
Random variables,
Estimation"
The Enactive Torch: A New Tool for the Science of Perception,"The cognitive sciences are increasingly coming to terms with the embodied, embedded, extended, and experiential aspects of the mind. Exemplifying this shift, the enactive approach points to an essential role of goal-directed bodily activity in the generation of meaningful perceptual experience, i.e., sense-making. Here, building on recent insights into the transformative effects of practical tool-use, we make use of the enactive approach in order to provide a definition of an enactive interface in terms of augmented sense-making. We introduce such a custom-built interface, the Enactive Torch, and present a study of its experiential effects. The results demonstrate that the user experience is not adequately captured by any standardly assumed perceptual modality; rather, it is a new feeling that is mediated by the design of the device and shaped by the overall situation of the task. Taken together these findings show that there is much to be gained by synergies between engineering and the cognitive sciences in the creation of new experience-centered technology. We suggest that the guiding principle should be the design of interfaces that serve as a transparent medium for augmenting our natural skills of interaction with the world, instead of requiring conscious attention to the interface as an opaque object in the world.","Haptic interfaces,
Human computer interaction,
Vibration measurement,
User centered design,
Information processing"
GUIDEX: A Game-Theoretic Incentive-Based Mechanism for Intrusion Detection Networks,"Traditional intrusion detection systems (IDSs) work in isolation and can be easily compromised by unknown threats. An intrusion detection network (IDN) is a collaborative IDS network intended to overcome this weakness by allowing IDS peers to share detection knowledge and experience, and hence improve the overall accuracy of intrusion assessment. In this work, we design an IDN system, called GUIDEX, using game-theoretic modeling and trust management for peers to collaborate truthfully and actively. We first describe the system architecture and its individual components, and then establish a game-theoretic framework for the resource management component of GUIDEX. We establish the existence and uniqueness of a Nash equilibrium under which peers can communicate in a reciprocal incentive compatible manner. Based on the duality of the problem, we develop an iterative algorithm that converges geometrically to the equilibrium. Our numerical experiments and discrete event simulation demonstrate the convergence to the Nash equilibrium and the security features of GUIDEX against free riders, dishonest insiders and DoS attacks.","Economics,
Telecommunication services,
Communication networks,
Computer crime,
Computer security,
Security,
Intrusion detection"
Fractional Order Periodic Adaptive Learning Compensation for State-Dependent Periodic Disturbance,"In this brief, a fractional order periodic adaptive learning compensation (FO-PALC) method is devised for the general state-dependent periodic disturbance minimization on the position and velocity servo platform. In the first trajectory period of the proposed FO-PALC scheme, a fractional order adaptive compensator is designed which can guarantee the boundedness of the system state, input and output signals. From the second repetitive trajectory period and onward, one period previously stored information along the state axis is used in the current adaptation law. Asymptotical stability proof of the system with the proposed FO-PALC is presented. Experimental validation is demonstrated to show the benefits from using fractional calculus in periodic adaptive learning compensation for the state-dependent periodic disturbance.",
"High-Performance Inverted
In
0.53
Ga
0.47
As
MOSHEMTs on a GaAs Substrate With Regrown Source/Drain by MOCVD","We report inverted-type In0.51Al0.49As/In0.53Ga0.47As MOSHEMTs heteroepitaxially grown on GaAs substrates by metal-organic chemical vapor deposition. High 2-D electron gas Hall mobility values of 8200 cm2/V · s at 300 K and 33 900 cm2/V · s at 77 K have been achieved. The buried quantum-well channel design is combined with selectively regrown source/drain (S/D) using a gate-last process. A 120-nm-channel-length MOSHEMT exhibited a maximum drain current of 1884 mA/mm, peak transconductance of 1126 mS/mm at Vds = 0.5 V, and a subthreshold slope of 135 mV/dec at Vds = 0.05 V. With the regrown S/D, an ultralow on-state resistance of 156 Ω·μm was obtained.","Indium gallium arsenide,
MOSFETs,
Logic gates,
Gallium arsenide,
Indium phosphide,
Substrates,
HEMTs"
Emergency Healthcare Workflow Modeling and Timeliness Analysis,"A health emergency is a situation that poses an immediate risk to health and life and requires urgent intervention to prevent its worsening. Emergency healthcare service is a real-time service, where timeliness is critical to mission success. Workflow management technology has received considerable attention in the healthcare field in recent years for the automation of both intra- and interorganizational healthcare processes. However, no work on timeliness analysis has been reported. In our previous work, we proposed Workflows Intuitive and Formal Approach (WIFA) formalism for emergency response workflow modeling. In this paper, we extend our WIFA formalism to take task execution times into account to support emergency response timeliness analysis. An example of emergency healthcare shows how the timed WIFA workflow model works.","Medical treatment,
Medical services,
Real-time systems,
Modeling,
Workflow management software"
Two Couple-Resolution Blocking Protocols on Adaptive Query Splitting for RFID Tag Identification,"How to accelerate tag identification is an important issue in Radio Frequency Identification (RFID) systems. In some cases, the RFID reader repeatedly identifies the same tags since these tags always stay in its communication range. An anticollision protocol, called the adaptive query splitting protocol (AQS), was proposed to handle these cases. This protocol reserves information obtained from the last process of tag identification so that the reader can quickly identify these staying tags again. This paper proposes two blocking protocols, a couple-resolution blocking protocol (CRB) and an enhanced couple-resolution blocking protocol (ECRB), based on AQS. CRB and ECRB not only have the above-mentioned capability as AQS but also use the blocking technique, which prohibits unrecognized tags from colliding with staying tags, to reduce the number of collisions. Moreover, CRB adopts a couple-resolution technique to couple staying tags by simultaneously transmitting two ID prefixes from the reader, while ECRB allows the reader to send only one ID prefix to interrogate a couple of staying tags. Thus, they only need half time to identify staying tags. We formally analyze the identification delay of CRB and ECRB in the worst and average cases. Our analytic and simulation results show that they obviously outperform AQS, and ECRB needs less transmitted bits than CRB.","Protocols,
Radiofrequency identification,
Mobile computing,
Delay,
Estimation,
Algorithm design and analysis,
Simulation"
NOTICE: An Architecture for the Notification of Traffic Incidents,"The past decade has witnessed the confluence of Intelligent Transportation Systems and Vehicular Networks that is expected to change drastically incident detection and to provide timely dissemination of traffic-related information to the traveling public. As a first step in this direction we introduce NOTICE, a secure and privacy-aware architecture for the notification of traffic incidents. Using sensor belts embedded in the roadway, traffic-related messages and advisories are carried between belts by passing cars. NOTICE moves the responsibility for making decisions about traffic-related information dissemination to the infrastructure rather than leaving those decisions with the drivers, which may have incomplete or incorrect knowledge. Extensive simulation have confirmed that NOTICE can provide “up-to-the-minute” notification of traffic-related incidents to the various participants in the traffic.","Road accidents,
Monitoring,
Traffic control,
Road vehicles,
Statistical analysis,
Accidents"
Methods of cloud-path selection for offloading in mobile cloud computing systems,"Recently, there emerge a variety of clouds in sky and thus, several similar cloud services (from different cloud venders) can be provided to a mobile end device. The goal of cloud-path selection is to find an optimal cloud among a certain class of clouds that provide the same service, in order to carry out the offloaded computation tasks. It is easy to choose the optimal cloud to save execution time incurred by offloading to cloud when considering only one factor. However, there are many criteria such as speed, bandwidth, price, security and availability that need to be considered when making final decisions. In this paper, a multiple criteria decision analysis approach based on the analytic hierarchy process (AHP) and the technique for order preference by similarity to ideal solution (TOPSIS) in a fuzzy environment is proposed to decide which cloud is the most suitable one for offloading. The AHP is used to determine the weights of the criteria for cloud-path selection, while fuzzy TOPSIS is to obtain the final ranking of alternative clouds. The numerical analysis is performed to evaluate the model.","Bandwidth,
Cloud computing,
Mobile handsets,
Security,
Servers,
Availability,
Mobile communication"
Fuzzy Integral-Based Gaze Control Architecture Incorporated With Modified-Univector Field-Based Navigation for Humanoid Robots,"When a humanoid robot moves in a dynamic environment, a simple process of planning and following a path may not guarantee competent performance for dynamic obstacle avoidance because the robot acquires limited information from the environment using a local vision sensor. Thus, it is essential to update its local map as frequently as possible to obtain more information through gaze control while walking. This paper proposes a fuzzy integral-based gaze control architecture incorporated with the modified-univector field-based navigation for humanoid robots. To determine the gaze direction, four criteria based on local map confidence, waypoint, self-localization, and obstacles, are defined along with their corresponding partial evaluation functions. Using the partial evaluation values and the degree of consideration for criteria, fuzzy integral is applied to each candidate gaze direction for global evaluation. For the effective dynamic obstacle avoidance, partial evaluation functions about self-localization error and surrounding obstacles are also used for generating virtual dynamic obstacle for the modified-univector field method which generates the path and velocity of robot toward the next waypoint. The proposed architecture is verified through the comparison with the conventional weighted sum-based approach with the simulations using a developed simulator for HanSaRam-IX (HSR-IX).","Robot kinematics,
Navigation,
Humanoid robots,
Heuristic algorithms,
Collision avoidance,
Computer architecture"
Simple Algorithm for Virus Spreading Control on Complex Networks,"A simple topology-manipulative algorithm for control of virus spreading trough complex networks is suggested. The algorithm is studied and applied on an SIS model type of an infection, and the system is described with a set of nonlinear difference probabilistic equations, that represent the dynamics of infection probabilities of nodes and existence probabilities of links in the graph. The validity of the control mechanism is first proven theoretically. Then, simulations are performed and results from both the realistic (status dependent) and probabilistic (analyzed) systems are compared, proving numerically as well, that the suggested algorithm is valid tool for infection eradication from complex networks. Several strategies of control implementation were tested and efficiency of each evaluated on the probabilistic system.","Eigenvalues and eigenfunctions,
Mathematical model,
Network topology,
Equations,
Probabilistic logic,
Heuristic algorithms,
Topology"
Blind Integrity Verification of Medical Images,"This paper presents the first method of digital blind forensics within the medical imaging field with the objective to detect whether an image has been modified by some processing (e.g., filtering, lossy compression, and so on). It compares two image features: the histogram statistics of reorganized block-based discrete cosine transform coefficients, originally proposed for steganalysis purposes, and the histogram statistics of reorganized block-based Tchebichef moments. Both features serve as input of a set of support vector machine classifiers built in order to discriminate tampered images from original ones as well as to identify the nature of the global modification one image may have undergone. Performance evaluation, conducted in application to different medical image modalities, shows that these image features can help, independently or jointly, to blindly distinguish image processing or modifications with a detection rate greater than 70%. They also underline the complementarity of these features.","Feature extraction,
Discrete cosine transforms,
Support vector machines,
Medical diagnostic imaging,
Forensics"
A novel image watermarking scheme using Extreme Learning Machine,"In this paper, a novel digital image watermarking algorithm based on a fast neural network known as Extreme Learning Machine (ELM) for two grayscale images is proposed. The ELM algorithm is very fast and completes its training in milliseconds unlike its other counterparts such as BPN. The proposed watermarking algorithm trains the ELM by using low frequency coefficients of the grayscale host image in transform domain. The trained ELM produces a sequence of 1024 real numbers, normalized as per N(0, 1) as an output. This sequence is used as watermark to be embedded within the host image using Cox's formula to obtain the signed image. The visual quality of the signed images is evaluated by PSNR. High PSNR values indicate that the quality of signed images is quite good. The computed high value of SIM (X, X*) establishes that the extraction process is quite successful and overall the algorithm finds good practical applications, especially in situations that warrant meeting time constraints.","Watermarking,
Training,
Discrete cosine transforms,
Neurons,
Vectors,
Mathematical model,
Machine learning"
Performance of Full CSI Selection Combining for Cooperative Diversity Systems,"Cooperative diversity achieves enhanced data rates and throughput using distributed spatial diversity techniques. We consider a cooperative diversity system comprising of a source, a relay, and a destination, with decode and forward (DF) protocol at the relay. The drawback of conventional instantaneous signal-to-noise ratio (SNR) based selection combining is that it fails to use the instantaneous SNR of the source-relay channel at the destination while selecting the best channel from source-destination and relay-destination channels. Full channel state information (CSI) selection combining, which effectively utilizes the instantaneous SNR of the source-relay channel at the destination, is used to overcome this drawback. The exact end-to-end symbol error probability (SEP) of full CSI selection combining for this DF system, with M-ary phase-shift keying in a flat Rayleigh fading environment, is derived. The analysis is validated through simulations. The diversity gain analysis is also studied for this scheme. Further, we compare the full CSI selection combining scheme with some other existing schemes. Numerical results show that full CSI selection combining has performance similar to that of instantaneous SEP based selection combining, but offers SNR gain over instantaneous SNR based selection combining, max-min selection, and selection cooperation.","Diversity reception,
Signal to noise ratio,
Relays,
Diversity methods,
Phase shift keying,
Rayleigh channels"
Detecting anomalous energy consumptions in distributed manufacturing systems,"This paper presents a novel model-based approach for the prediction of energy consumption in production plants in order to detect anomalies. A special Ethernet-based data acquisition approach is implemented that features real-time sampling of process and energy data. Hybrid timed automaton models of the supervised production plant are generated and executed in parallel to the system by using data samples as model input. According to comparisons of predicted energy consumption with the production plant observations, anomalies can be detected automatically. An evaluation within a small factory shows that anomalies of 10 % differences in energy consumption, wrong control sequences and wrong timings can be detected with a minimum accuracy of 98 %. With this approach, downtimes of production systems can be shortened and atypical energy consumptions can be detected and adjusted to optimal operation.",
{\cal L}_{1} Adaptive Controller for Uncertain Nonlinear Multi-Input Multi-Output Systems With Input Quantization,"We study the merits of the adaptive controller for nonlinear uncertain Multi-Input Multi-Output (MIMO) systems in the presence of significant unmodeled dynamics and input quantization. We show that with both logarithmic quantization and uniform quantization, if the quantization is sufficiently dense, the adaptive controller ensures that the output of the MIMO system follows a desired reference signal with uniform transient and steady-state performance bounds. Compared with the same feedback architecture without quantization, the uniform performance bounds have an additional positive additive term, linear in the quantization constant, which can be reduced by increasing the quantization density. Simulations illustrate the performance of the adaptive controller in the presence of quantization.","Quantization,
MIMO,
Bandwidth,
Adaptive control,
Transient analysis,
Steady-state"
Trajectory clustering for motion prediction,"We investigate a data-driven approach to robotic path planning and analyze its performance in the context of interception tasks. Trajectories of moving objects often contain repeated patterns of motion, and learning those patterns can yield interception paths that succeed more often. We therefore propose an original trajectory clustering algorithm for extracting motion patterns from trajectory data and demonstrate its effectiveness over the more common clustering approach of using k-means. We use the results to build a Hidden Markov Model of a target's motion and predict movement. Our simulations show that these predictions lead to more effective interception. The results of this work have potential applications in coordination of multi-robot systems, tracking and surveillance tasks, and dynamic obstacle avoidance.",
135-GHz Micromachined On-Chip Antenna and Antenna Array,"This paper presents the design, fabrication and “on-wafer” characterization of multi-membrane-supported and polymer-cavity-backed monopole antenna and 2&times; 1 patch antenna array operating in the 135-GHz frequency range. The designs were fabricated on two-layer benzocyclobutene (BCB) material membrane obtained by micromachining of the low resistivity silicon. The silicon material is removed underneath the monopole antenna to produce a cavity surrounded by metal and filled with polymer. This polymer filled cavity provides a better support to the membrane than conventional air cavity which is extremely important for practical applications. In the meantime, the higher synthesized effective dielectric permittivity of the BCB-polymer mixed region than BCB-air mixed one provides the possibility for compact antenna array designs. The proposed monopole antenna shows a measured impedance bandwidth from 124 to 136 GHz for |S11| less than -10 dB and maximum measured gain of 6.74 dBi at 131 GHz; while the 2&times;1 patch antenna array achieved a measured impedance bandwidth from 126.5 to 138 GHz for |S11| less than -10 dB and maximum measured gain of 8.66 dBi at 130 GHz.",
High-Yield Fabrication of Graphene Chemiresistors With Dielectrophoresis,"We demonstrate a simple, low-cost, but effective approach to deposit graphene on silicon wafers with dielectrophoresis. With a comb-shaped electrode design, graphene sheets can be actively captured between electrodes. Dielectrophoresis proves effective in depositing a large-scale array of graphene on desired locations. The deposition of semiconducting single-walled carbon nanotubes (s-SWNTs) with the same approach is also studied to compare the two forms of carbon-based nanomaterials. The graphene deposition has a lower success rate (approximately 62%) than s-SWNTs (100%) to cover the comb fingers due to the 2-D sheet structure and larger dimensions of the material. The assembled graphene sheets can successfully bridge over the electrode gap to create functional, ready-to-use electronic devices. The dielectrophoretically deposited graphene is used as the semiconducting material in a liquid-gated field-effect transistor, and it demonstrates p-type characteristics with holes as the majority charge carriers. When used in two-terminal chemiresistors, the deposited graphene demonstrates high sensitivity toward pH values in liquid. The resistance of graphene is inversely proportional to the pH value of the solution in the range of 5-9 with the pH sensitivity of 17.5 Ω/decade. The high-precision, high-yield deposition provides a practical approach for the fabrication of future graphene electronic devices and sensors.","Electrodes,
Dielectrophoresis,
Fingers,
Electric fields,
Substrates,
Sensors"
Sampling for Shape from Focus in Optical Microscopy,"Shape from focus (SFF), which relies on image focus as a cue within sequenced images, represents a passive technique in recovering object shapes in scenes. Although numerous methods have been recently proposed, less attention has been paid to particular factors affecting them. In regard to SFF, one such critical factor impacting system application is the total number of images. A large data set requires a huge amount of computation power, whereas decreasing the number of images causes shape reconstruction to be crude and erroneous. The total number of images is inversely proportional to interframe distance or sampling step size. In this paper, interframe distance (or sampling step size) criteria for SFF systems have been formulated. In particular, light ray focusing is approximated by the use of a Gaussian beam followed by the formulation of a sampling expression using Nyquist sampling. Consequently, a fitting function for focus curves is also obtained. Experiments are performed on simulated and real objects to validate the proposed schemes.",
New Constructions of 16-QAM Periodic Complementary Sequences,"In this letter, we present a family of 16-QAM periodic complementary sequences (PCSs), including three constructions. Our basic idea is to transform the known quaternary PCSs/GCSs (Golay complementary sequences) into the required ones. In order to guarantee that such transformation of every construction is successful, the own sufficient conditions of three constructions are derived, respectively. Our methods can provide quite rich 16-QAM periodic PCSs, whose main parameters up to period 50 and number 12 of sub-sequences are given in Table 1, from a large number of available quaternary PCSs/GCSs, which can potentially satisfy the requirements of communication systems making use of 16-QAM constellation.","Quadrature amplitude modulation,
Correlation,
Cascading style sheets,
Phase shift keying,
Transforms"
Web-Based Classifiers for Human Action Recognition,"Action recognition in uncontrolled videos is a challenging task, where it is relatively hard to find the large amount of required training videos to model all the variations of the domain. This paper addresses this challenge and proposes a generic method for action recognition. The idea is to use images collected from the Web to learn representations of actions and leverage this knowledge to automatically annotate actions in videos. For this purpose, we first use an incremental image retrieval procedure to collect and clean up the necessary training set for building the human pose classifiers. Our approach is unsupervised in the sense that it requires no human intervention other than the text querying to an internet search engine. Its benefits are two-fold: 1) we can improve retrieval of action images, and 2) we can collect a large generic database of action poses, which can then be used in tagging videos. We present experimental evidence that using action images collected from the Web, annotating actions in the videos is possible. Additionally, we explore how the Web-based pose classifiers can be utilized in conjunction with limited labelled videos. We propose to use “ordered pose pairs” (OPP) for encoding the temporal ordering of poses in our action model, and show that considering the temporal ordering of pose pairs can increase the action recognition accuracy. We also show that by selecting the keyposes with the help of Web-based classifiers, the classification time can be reduced. Our experiments demonstrate that, with or without available video data, the pose models learned from the Web can improve the performance of the action recognition systems.","Videos,
Training,
Humans,
Legged locomotion,
YouTube,
Search engines,
Internet"
Automated Delineation of Calcified Vessels in Mammography by Tracking With Uncertainty and Graphical Linking Techniques,"As a potential biomarker for women's cardiovascular and chronic kidney diseases, breast arterial calcification (BAC) in mammography has become an emerging research topic in recent years. To provide more objective measurement for vascular structures with calcium depositions in mammography, a new computerized method is introduced in this paper to delineate the calcified vessels. Specifically, we leverage two underlying cues, namely calcification and vesselness, into a multiple seeded tracking with uncertainty scheme. This new vessel-tracking scheme generates plenty of sampling paths to describe the complicated topology of the vascular structures with calcium depositions. A compiling and linking process is further carried out to organize the sampling paths together to be the vessel segments that likely belong to the same vessel tract. The proposed method has been evaluated on 63 mammograms, by comparison with manual delineations from two experts using various assessment metrics. The experiment results confirm the efficacy and stability of the proposed method, and also indicate that the proposed method can be potentially used as a convenient BAC measurement tool in replacement of the trivial and tedious manual delineation tasks.","Calcium,
Uncertainty,
Mammography,
Cardiovascular diseases"
Revenue Maximization in Time-Varying Multi-Hop Wireless Networks: A Dynamic Pricing Approach,"In this paper, we study a wireless multi-hop network where multiple flows co-exist and share the network resource collectively. Each flow is associated with a user which has specific requirements on its tradeoff between cost and quality of service. To support heterogeneous transmissions efficiently, we propose a quality-aware dynamic pricing algorithm, namely, QADP, which provably maximizes the overall network revenue while maintaining the stability of the network. Our proposed scheme enjoys the merit of self-adaptability due to its online nature.","Vectors,
Multimedia communication,
Pricing,
Delay,
Spread spectrum communication,
Wireless networks,
Heuristic algorithms"
Pole-Radius-Varying IIR Notch Filter With Transient Suppression,"In this paper, a new IIR notch filter with transient suppression is proposed. The proposed algorithm utilizes a varying pole radius to significantly reduce the transient effect when eliminating a sinusoidal interference in signal enhancement. Based on a time-varying linear difference equation, the analytical solution to a sinusoidal interference is found. With a given tolerance of the transient disturbance, a scheme is derived to predict the duration of the transient response and to determine the damping parameter used for changing the pole radius. Computer simulations demonstrate that the developed pole-radius-varying IIR notch filter significantly outperforms the traditional IIR notch filter.","Transient response,
Interference,
Transient analysis,
Bandwidth,
Electrocardiography,
Q factor,
IIR filters"
A Bioinspired Multilayered Intelligent Cooperative Controller for Stretching Process of Fiber Production,"The stretching process is one of the key sections in fiber production, which is decisive to the quality of the final fiber products. Such a process raises high requirements on the control of the rollers with proper stretching ratios, and the large number of rollers with their special characteristics and the demand for synchronous running usually make the design of a good control scheme difficult. In this paper, a novel bioinspired multilayered intelligent cooperative controller (BMLICC) is proposed to provide a control plan for the interlinked rollers by organizing them into unified stretching units. Based on the multilayer regulation networks of neuroendocrine system in the human body, a networked controller structure is established. It consists of several components like rollers, distributed controllers, communication paths, and conversion units. The rollers in the same unit can exchange the working information rapidly to implement simultaneous response and cooperation. The stretching ratio can be kept stable and has strong resistance against the external disturbances on the stretching system. Both computer-simulation- and device-based experimental results demonstrate that the stretching unit with the proposed BMLICC can maintain its stretching ratio and effectively resist the external disturbances. This is beneficial to improve the performance of the stretched precursors and, furthermore, produce fibers with high quality. The proposed BMLICC can be easily extended to productions with multiple stretching units or industrial processes with similar mechanical structures for better control quality.",
Polyblaze: From one to many bringing the microblaze into the multicore era with Linux SMP support,"Modern computing systems increasingly consist of multiple processor cores. From cell phones to datacenters, multicore computing has become the standard. At the same time, our understanding of the performance impact resource sharing has on these platforms is limited, and therefore, prevents these systems from being fully utilized. As the capacity of FPGAs has grown, they have become a viable method for emulating architecture designs as they offer increased performance and visibility into runtime behaviour compared to simulation. With future systems trending towards asymmetric and heterogeneous systems, and thus further increasing complexity, a framework that enables research in this area is highly desirable. In this work, we present PolyBlaze: a multicore Micro- Blaze based system with Linux Symmetric Multi-Processor (SMP) support on an FPGA. Starting with a single-core, Linux supported, MicroBlaze we detail the changes to the platform, both in hardware and software, required to bring Linux SMP support to the MicroBlaze. We then outline the series of tests performed on our platform to demonstrate both its stability (e.g. more than two weeks of up time) and scalability (up to eight cores on an FPGA, with resource usage increasing linearly with the number of cores).","Multicore processing,
Linux,
Field programmable gate arrays,
Kernel,
Registers,
Hardware"
Achieving High Data Rate in Multiband-OFDM UWB Over Power-Line Communication System,"Theoretical studies indicate that a transmission data rate of up to gigabits per second can be achieved over low-voltage (LV) indoor power-line cables. Achieving a very high data rate (up to 480 Mb/s) is expected by applying WiMedia multiband-orthogonal frequency-divison multiplexing (MB-OFDM) standard for wireless ultra-wideband (UWB) communication over the power-line channel. However, the viability of this concept needs to be tested experimentally. This paper presents a novel design of demonstration system for the UWB over power-line communication technology. The demonstration system consists of an MB-OFDM UWB kit and is capable of transmitting very high data-rate signals over the LV power-line cables. It provides means to evaluate the performance of the UWB over power-line communication systems and analyze its viability in actual home networking scenarios.","OFDM,
Power cables,
Frequency conversion,
Receivers,
Data communication,
Frequency modulation,
Couplers"
"Errors Limiting Split-
CV
Mobility Extraction Accuracy in Buried-Channel InGaAs MOSFETs","The accuracy of the split-CV mobility extraction method is analyzed in buried-channel InGaAs MOSFETs with a Al2O3 gate dielectric and an InP barrier, through a “simulated experiment” procedure using 2-D numerical device simulations that are preliminarily calibrated against experimental I-V and CV curves. The different error sources limiting the method accuracy are pointed out. It is suggested that, as a result of these errors, the split- CV method can appreciably underestimate the actual channel mobility in these devices, with an error of >;20% and >;50% on peak mobility and high-VGS mobility, respectively. The method should therefore not be adopted for accurate mobility measurement in this operating regime but only as a fast response technique providing a conservative estimation of channel mobility. Moreover, the method provides mobility values that rapidly drop below the peak value for decreasing VGS. It is shown that this behavior can be an artifact of the extraction method, which may mask physical mechanisms causing a real mobility drop with decreasing channel carrier density, such as Coulomb scattering mechanisms. This poses limitations to the adoption of split-CV mobility as a reference for mobility model assessment in this operating regime. The proposed methodology can be applied to other III-V FETs, including both heterostructure-based and inversion-mode devices.",
Coupling detection and data association for multiple object tracking,"We present a novel framework for multiple object tracking in which the problems of object detection and data association are expressed by a single objective function. The framework follows the Lagrange dual decomposition strategy, taking advantage of the often complementary nature of the two subproblems. Our coupling formulation avoids the problem of error propagation from which traditional “detection-tracking approaches” to multiple object tracking suffer. We also eschew common heuristics such as “nonmaximum suppression” of hypotheses by modeling the joint image likelihood as opposed to applying independent likelihood assumptions. Our coupling algorithm is guaranteed to converge and can handle partial or even complete occlusions. Furthermore, our method does not have any severe scalability issues but can process hundreds of frames at the same time. Our experiments involve challenging, notably distinct datasets and demonstrate that our method can achieve results comparable to those of state-of-art approaches, even without a heavily trained object detector.","Couplings,
Dictionaries,
Joints,
Detectors,
Minimization,
Object detection,
Markov processes"
Data perturbation with state-dependent noise for participatory sensing,"The emerging participatory sensing applications rely on individuals' inputs which may be highly correlated with individuals' sensitive information or personal data. Hence, privacy protection is crucial to encourage individual participation for participatory sensing applications to generate trustworthy and high quality data. A widely used technique for privacy preservation is data perturbation, which adds noises to original data at the client side to protect individuals' privacy and allows the information server to reconstruct the statistics of the original data. In this paper, we find a serious vulnerability of existing data perturbation algorithms that an adversary may exploit to restore other users' private information (e.g., mean, variance and the distribution of original data) from the perturbed data, because all the participants share the same noise distribution. To overcome such vulnerability, we propose a privacy enhanced state-dependent perturbation (PESP), which assigns different noise distributions to individuals and the noises vary according to the state of real data. PESP is not only able to reconstruct community statistics, but also provides better privacy protection for individuals even when the adversaries acquire the perturbed data. We evaluate PESP through two participatory sensing applications: one analyzes the speed variations of vehicles on the road and the other computes the weight statistics for a particular diet. The results demonstrate the efficiency of the PESP in privacy preservation and reconstruction of the community statistics.","Noise,
Communities,
Servers,
Sensors,
Estimation,
Data models,
Data privacy"
HJam: Attachment transmission in WLANs,"Effective coordination can dramatically reduce radio interference and avoid packet collisions for multi-station wireless local area networks (WLANs). Coordination itself needs consume communication resource and thus competes with data transmission for the limited wireless radio resources. In traditional approaches, control frames and data packets are transmitted in an alternate manner, which brings a great deal of coordination overhead. In this paper we propose a new communication model where the control frames can be “attached” to the data transmission. Thus, control messages and data traffic can be transmitted simultaneously and consequently the channel utilization can be improved significantly. We implement the idea in OFDM-based WLANs called hJam, which fully explores the physical layer features of the OFDM modulation method and allows one data packet and a number of control messages to be transmitted together. hJam is implemented on the GNU Radio testbed consisting of eight USRP2 nodes. We also conduct comprehensive simulations and the experimental results show that hJam can improve the WLANs efficiency by up to 72% compared with the existing 802.11 family protocols.",
Control and understanding: Owning your home network,"Wireless home networks are increasingly deployed in people's homes worldwide. Unfortunately, home networks have evolved using protocols designed for backbone and enterprise networks, which are quite different in scale and character to home networks. We believe this evolution is at the heart of widely observed problems experienced by users managing and using their home networks. In this paper we investigate redesign of the home router to exploit the distinct social and physical characteristics of the home. We extract two key requirements from a range of ethnographic studies: users desire greater understanding of and control over their networks' behaviour. We present our design for a home router that focuses on monitoring and controlling network traffic flows, and so provides a platform for building user interfaces that satisfy these two user requirements. We describe and evaluate our prototype which uses NOX and OpenFlow to provide per-flow control, and a custom DHCP implementation to enable traffic isolation and accurate measurement from the IP layer. It also provides finer-grained per-flow control through interception of wireless association and DNS resolution. We evaluate the impact of these modifications, and thus the applicability of flow-based network management in the home.","Home automation,
Wireless communication,
Routing protocols,
IP networks,
Performance evaluation,
User interfaces"
Performance Modelling and Analysis of Cognitive Mesh Networks,A new analytical model is proposed to investigate the delay and throughput in cognitive mesh networks. The validity of the model is demonstrated via extensive simulation experiments. The model is then used to evaluate the effects of the number of licensed channels and channel utilisation on the network performance.,"Analytical models,
Delay,
Throughput,
Interference,
Logic gates,
Aggregates,
Cognitive radio"
Enhanced SAR ADC energy efficiency from the early reset merged capacitor switching algorithm,"The early reset merged capacitor switching algorithm (EMCS) is proposed as an energy reducing switching technique for a binary weighted, capacitive successive approximation (SAR) analog to digital converter (ADC). The method uses the merged capacitor switching (MCS) architecture and optimizes the use of the VCM level during the SAR conversion. This algorithm can reduce switching power by over 12% with no additional DAC driver activity when compared to the MCS scheme. The MCS and EMCS approaches are analyzed mathematically and the EMCS energy consumption is shown to be lower than or equal to that of the MCS technique for every digital code. Static linearity improvements for this structure are also shown with the integral non-linearity (INL) reducing by a factor of two due to the utilization of the MCS three level DAC. The EMCS implementation methodology is also described.","Capacitors,
Switches,
Electromagnetic compatibility,
Algorithm design and analysis,
Switching circuits,
Capacitance,
Energy efficiency"
Wireless H.264 Video Quality Enhancement Through Optimal Prioritized Packet Fragmentation,"We introduce a cross-layer priority-aware packet fragmentation scheme at the MAC layer to enhance the quality of pre-encoded H.264/AVC compressed bitstreams over bit-rate limited error-prone links in wireless networks. The H.264 slices are classified in four priorities at the encoder based on their cumulative mean square error (CMSE) contribution towards the received video quality. The slices of a priority class in each frame are aggregated into video packets of corresponding priority. We derive the optimal fragment size for each priority class which achieves the maximum expected weighted goodput at different encoded video bit rates, slice sizes and bit error rates. Priority-aware packet fragmentation invokes slice discard in the buffer due to channel bit rate constraints on allocating fragment header bits. We propose a slice discard scheme using frame importance and slice CMSE contribution to control error propagation effects. Packet fragmentation is extended to slice fragmentation by modifying the conventional H.264 decoder to handle partial slice decoding. Priority-aware slice fragmentation combined with the proposed slice discard scheme provides considerable PSNR and VQM gains as compared to priority-agnostic fragmentation.",
Vehicle detection and tracking under various lighting conditions using a particle filter,"The authors propose a vision-based automatic system to detect preceding vehicles on the highway under various lighting and different weather conditions. To adapt to different characteristics of vehicle appearance under various lighting conditions, four cues including underneath shadow, vertical edge, symmetry and taillight are fused for the vehicle detection. The authors achieve this goal by generating probability distribution of vehicle under particle filter framework through the processes of initial sampling, propagation, observation, cue fusion and evaluation. Unlike normal particle filter focusing on single target distribution in a state space, the authors detect multiple vehicles with a single particle filter through a high-level tracking strategy using clustering. In addition, the data-driven initial sampling technique helps the system detect new objects and prevent the multi-modal distribution from collapsing to the local maxima. Experiments demonstrate the effectiveness of the proposed system.","statistical distributions,
driver information systems,
object detection,
object tracking,
particle filtering (numerical methods)"
Participation in Repeated Cooperative Spectrum Sensing: A Game-Theoretic Perspective,"In cognitive radio networks (CRNs), cooperative spectrum sensing (CSS) is usually performed periodically due to the uncertain activity of primary users (PUs). Considering the overhead in performing CSS, a selfish secondary user (SU) may not always participate in CSS. Instead, it elaborately selects a frequency (or number of times) for CSS participation to maximize its interest. A fusion center then schedules it to conduct CSS in appropriate periods. This paper investigates the interactive decision on the CSS participation frequency under sensing performance and quality of service (QoS) requirements. The problem is formulated as a noncooperative game, where Nash Equilibrium (NE) corresponds to the desired frequency selection outcome. Since the strategy sets of SUs are coupled, obtaining directly the NE requires explicit coordination among SUs, which is unrealistic in practice. Alternatively, we decompose the game into a lower-level uncoupled game and a higher-level optimization problem. A distributed hierarchical iterative algorithm (DHIA) is then proposed to obtain the desired frequency selection outcome without requiring explicit coordination. Furthermore, the uncertain sensing performance of SUs and the fairness issue are also considered. Finally, numerical results validate the effectiveness of the proposed scheme.",
CSI Usage over Parallel Fading Channels under Jamming Attacks: A Game Theory Study,"Consider a parallel channel with M independent flat-fading subchannels. There exists a smart jammer which has possession of a copy of perfect channel state information (CSI) measured and sent back by a receiver to its transmitter. Under this model, a class of two-person zero-sum games is investigated where either achievable mutual information rate or Chernoff bound is taken as the underlying pay-off function with the strategy space of each player determined by respective power control and hopping functions. More specifically, we have tackled and answered the following three fundamental questions. The first one is about whether the transmitter and jammer should hop or fully use all degrees of freedom over the entire parallel channels given the full CSI available to both of them, i.e. to hop or not to hop. The second question is about the impact of sending back CSI on system performance considering that the smart jammer can exploit CSI to further enhance its interference effects, i.e. to feedback or not to feedback. The last question is about whether the amount of feedback information can be reduced given the mutual restrictions between transmitter and jammer, i.e. when to feedback and when not to.","Jamming,
Transmitters,
Games,
Game theory,
Fading,
Receivers,
Power control"
Myocardial Blood Flow Quantification From MRI by Deconvolution Using an Exponential Approximation Basis,"We have evaluated the use of deconvolution using an exponential approximation basis for the quantification of myocardial blood flow from perfusion cardiovascular magnetic resonance. Our experiments, based on simulated signal intensity curves, phantom acquisitions, and clinical image data, indicate that exponential deconvolution allows for accurate quantification of myocardial blood flow. Together with automated respiratory motion correction myocardial contour delineation, the exponential deconvolution enables efficient and reproducible quantification of myocardial blood flow in clinical routine.","Myocardium,
Deconvolution,
Silicon,
Dynamics,
Equations,
Phantoms,
Mathematical model"
Binary Discriminant Analysis for Generating Binary Face Template,"Although biometrics is more reliable, robust and convenient than traditional methods, security and privacy concerns are growing. Biometric templates stored in databases are vulnerable to attacks if they are not protected. To solve this problem, a biometric cryptosystem approach that combines cryptography and biometrics has been proposed. Under this approach, helper data is stored in a database rather than the original reference biometric templates. The helper data is generated from the original reference biometric templates and a cryptographic key with error-correcting coding schemes. During decoding, the same cryptographic key can be released from the helper data if and only if the input query data is close enough to the reference. It is assumed that the helper data does not reveal any information about the original reference biometric templates. Thus, the biometric cryptosystem approach can protect the original reference templates. However, error-correcting coding algorithms (e.g., the fuzzy commitment scheme and fuzzy vault) normally require finite input. As most face templates are real-valued templates, a binarization scheme transforming the original real-valued face templates into binary templates is required. Most existing binarization schemes are performed in an ad hoc manner and do not consider the discriminability of the binary template. The recognition accuracy based on the binary templates is thus degraded. In view of this limitation, we propose a new binarization scheme by optimizing binary template discriminability. A novel binary discriminant analysis is developed to transform a real-valued template into a binary template. Differentiation is hard to perform in binary space and direct optimization is difficult. To solve this problem, we construct a continuous function based on the perceptron to optimize binary template discriminability. Our experimental results show that the proposed algorithm improves binary template discriminability.","Biometrics (access control),
Face,
Cryptography,
Transforms,
Training,
Feature extraction"
Noncontact Millimeter-Wave Real-Time Detection and Tracking of Heart Rate on an Ambulatory Subject,"This paper presents a solution to an aiming problem in the remote sensing of vital signs using an integration of two systems. The problem is that to collect meaningful data with a millimeter-wave sensor, the antenna must be pointed very precisely at the subject's chest. Even small movements could make the data unreliable. To solve this problem, we attached a camera to the millimeter-wave antenna, and mounted this combined system on a pan/tilt base. Our algorithm initially finds a subject's face and then tracks him/her through subsequent frames, while calculating the position of the subject's chest. For each frame, the camera sends the location of the chest to the pan/tilt base, which rotates accordingly to make the antenna point at the subject's chest. This paper presents a system for concurrent tracking and data acquisition with results from some sample scenarios.",
Slow-Light-Enhanced Silicon Optical Modulators Under Low-Drive-Voltage Operation,"The integration of nanophotonics components with advanced complementary metal-oxide-semiconductor (CMOS) electronics requires drive voltages as low as 1 V for enabling next-generation CMOS electrophotonics transceivers. Slow-light propagation has been recently demonstrated as an effective mechanism to enhance the modulation efficiency in free-carrier-based electrooptical silicon modulators. Here, we exploit the use of slow light to reduce the driving voltage of carrier-depletion-based Mach-Zehnder modulators. The slow-light phase shifter consists of a p-n junction positioned in the middle of a corrugated waveguide. A modulation efficiency as high as VπLπ ~ 0.6 V·cm is achieved, thus allowing data transmission rates up to 10 Gb/s with a 1.5-Vpp drive voltage and an insertion loss of ~12 dB. The influence of the drive voltage on the modulation speed as well as the variation of the insertion losses with a group index is also analyzed and discussed.","Optical waveguides,
Silicon,
Optical modulation,
Phase shifters,
CMOS integrated circuits,
Insertion loss"
Characteristic Model-Based Adaptive Discrete-Time Sliding Mode Control for the Swing Arm in a Fourier Transform Spectrometer,"This paper aims to guarantee high-precision tracking of the desired optical path difference velocity for a Fourier transform spectrometer (FTS) in a space exploration system with time-varying parameters and nonlinear dynamics. A novel characteristic model-based adaptive discrete-time sliding mode control (ADSMC) scheme is proposed. The design of the ADSMC includes characteristic modeling, characteristic model-based discrete-time sliding mode control, and the estimator of the uncertain coefficients. The stability analysis of the ADSMC is also given in this paper. Simulation and experimental results demonstrate that the proposed characteristic model-based ADSMC can achieve high-precision control over a Michelson interferometer-based FTS. The significant advantages of the proposed ADSMC are its robustness and better control performance over the external disturbance and internal parameter uncertainty of the system.","Mathematical model,
Adaptation models,
Sliding mode control,
Path planning,
Switches,
Optical interferometry"
A privacy-preserving reputation system for participatory sensing,"Participatory sensing is a revolutionary paradigm in which volunteers collect and share information from their local environment using mobile phones. The design of a successful participatory sensing application is met with two challenges - (1) user privacy and (2) data trustworthiness. Addressing these challenges concurrently is a non-trivial task since they result in conflicting system requirements. User privacy is often achieved by removing the links between successive user contributions while such links are essential in establishing trust. In this work, we present a way to transfer reputation values (which is a proxy for assessing trustworthiness) between anonymous contributions. We also propose a reputation anonymization scheme that prevents the inadvertent leakage of privacy due to the inherent relationship between reputation information. We conduct extensive simulations using real-world mobility traces and practical application. The results show that our solution reduces the probabilities of users being tracked via successive contributions by as much as 80%. Moreover, this improvement has no discernible impact on the normal operation of the application.","Servers,
Sensors,
Privacy,
Data privacy,
Aggregates,
Joining processes,
Context"
Adaptive Sensing of Congested Spectrum Bands,"Cognitive radios process their sensed information collectively in order to opportunistically identify and access underutilized spectrum segments (spectrum holes). Due to the transient and rapidly varying nature of the spectrum occupancy, the cognitive radios (secondary users) must be agile in identifying the spectrum holes in order to enhance their spectral efficiency. We propose a novel adaptive procedure to reinforce the agility of the secondary users for identifying multiple spectrum holes simultaneously over a wide spectrum band. This is accomplished by successively exploring the set of potential spectrum holes and progressively allocating the sensing resources to the most promising areas of the spectrum. Such exploration and resource allocation results in conservative spending of the sensing resources and translates into very agile spectrum monitoring. The proposed successive and adaptive sensing procedure is in contrast to the more conventional approaches that distribute the sampling resources equally over the entire spectrum. Besides improved agility, the adaptive procedure requires less-stringent constraints on the power of the primary users to guarantee that they remain distinguishable from the environment noise and renders more reliable spectrum hole detection.","Wideband,
Detectors,
Robustness,
Random variables,
Monitoring"
Multivariable Repetitive-Predictive Controllers Using Frequency Decomposition,"Repetitive control is a methodology for the tracking of a periodic reference signal. This paper develops a new approach to repetitive control systems design using receding horizon control with frequency decomposition of the reference signal. Moreover, design and implementation issues for this form of repetitive predictive control are investigated from the perspectives of controller complexity and the effects of measurement noise. The analysis is supported by a simulation study on a multi-input multi-output robot arm where the model has been constructed from measured frequency response data, and experimental results from application to an industrial AC motor.","Manipulators,
Frequency control,
MIMO,
Robots,
Predictive control"
A Tandem Algorithm for Singing Pitch Extraction and Voice Separation From Music Accompaniment,"Singing pitch estimation and singing voice separation are challenging due to the presence of music accompaniments that are often nonstationary and harmonic. Inspired by computational auditory scene analysis (CASA), this paper investigates a tandem algorithm that estimates the singing pitch and separates the singing voice jointly and iteratively. Rough pitches are first estimated and then used to separate the target singer by considering harmonicity and temporal continuity. The separated singing voice and estimated pitches are used to improve each other iteratively. To enhance the performance of the tandem algorithm for dealing with musical recordings, we propose a trend estimation algorithm to detect the pitch ranges of a singing voice in each time frame. The detected trend substantially reduces the difficulty of singing pitch detection by removing a large number of wrong pitch candidates either produced by musical instruments or the overtones of the singing voice. Systematic evaluation shows that the tandem algorithm outperforms previous systems for pitch extraction and singing voice separation.","Estimation,
Harmonic analysis,
Time frequency analysis,
Hidden Markov models,
Speech,
Instruments,
Spectrogram"
A nonlinear observer for integration of GNSS and IMU measurements with gyro bias estimation,"We present an observer for estimating position, velocity, attitude, and gyro bias, by using inertial measurements of accelerations and angular velocities, magnetometer measurements, and satellite-based measurements of position and (optionally) velocity. The design proceeds in two stages: in Stage I, an attitude and gyro bias estimator is designed based on an unmeasured signal. In Stage II, that design is recovered using measured signals only, by combining it with a position and velocity estimator. We prove global exponential stability of the estimation error and test the design using realistic flight simulation.","Observers,
Velocity measurement,
Global Navigation Satellite Systems,
Position measurement,
Vectors,
Manganese"
Robust topology control in multi-hop cognitive radio networks,"The opening of under-utilized spectrum creates the opportunity of substantial performance improvement through cognitive radio techniques. However, the real network performance may be limited since unlicensed users must vacate and switch to other available spectrum if the current spectrum is reclaimed by the licensed (primary) users. During the spectrum switching time, network partitions may occur since multiple links may be affected if they all operate on the channel reclaimed by the primary users. In this paper, we address this problem through robust topology control, where channels are assigned to minimize channel interference while maintaining network connectivity when primary users appear. To solve this NP-hard problem, we propose both centralized and distributed algorithms. Simulation results show that our solutions outperform existing interference-aware approaches substantially when primary users appear and achieve similar performance at other times.","Robustness,
Interference,
Topology,
Network topology,
Switches,
Cognitive radio,
Algorithm design and analysis"
Non-negative low rank and sparse graph for semi-supervised learning,"Constructing a good graph to represent data structures is critical for many important machine learning tasks such as clustering and classification. This paper proposes a novel non-negative low-rank and sparse (NNLRS) graph for semi-supervised learning. The weights of edges in the graph are obtained by seeking a nonnegative low-rank and sparse matrix that represents each data sample as a linear combination of others. The so-obtained NNLRS-graph can capture both the global mixture of subspaces structure (by the low rankness) and the locally linear structure (by the sparseness) of the data, hence is both generative and discriminative. We demonstrate the effectiveness of NNLRS-graph in semi-supervised classification and discriminative analysis. Extensive experiments testify to the significant advantages of NNLRS-graph over graphs obtained through conventional means.",
Adaptive detection of distributed targets with orthogonal rejection,"This study deals with the problem of detecting distributed targets in the presence of homogeneous and partially homogeneous Gaussian disturbance with unknown covariance matrix. The proposed detectors improve the adaptive beamformer orthogonal rejection test (ABORT) idea to address detection of distributed targets, which makes it possible to decide whether some observations contain a useful target or a signal belonging to the orthogonal complement of the useful subspace. At the design stage, the authors resort to either the plain generalised likelihood ratio test (GLRT) or ad hoc design procedures. Remarkably, the considered criteria lead to receivers ensuring the constant false alarm rate (CFAR) property with respect to the unknown quantities. Moreover, authors' derivations show that the ad hoc detector for a partially homogeneous environment coincides with the generalised adaptive subspace detector. The performance assessment conducted by Monte Carlo simulation has confirmed the effectiveness of the newly proposed detection algorithms.",
"Pursuit, evasion and defense in the plane","Multi-player games are important for analyzing complex real-world applications that involve both cooperative and adversarial agents, but computational complexity complicates solving such games. We study a modified pursuit-evasion game with multiple pursuers and a single evader, played in a convex domain with an exit through which the evader may escape. We present a strategy whereby one pursuer acts as a defender, utilizing a multi-mode switching strategy to prevent the evader from escaping while the other pursuers subsequently capture the evader. The strategy requires each pursuer to have knowledge only of its Voronoi neighbors and the evader, and runs in real time. The existence and uniqueness of the players' trajectories are proved using non-smooth analysis, and it is also shown that the evader can never reach the exit regardless of its control inputs, resulting in eventual capture. Simulation results are presented demonstrating the algorithm.",
Multi-Objective Parameter Optimization in Support Vector Regression: General Formulation and Application to the Retrieval of Soil Moisture From Remote Sensing Data,"This paper deals with the tuning of the free parameters of the Support Vector Regression technique used for the retrieval of geo/bio-physical variables from remotely sensed data. We propose to address this task in the framework of the multi-objective optimization. A multi-objective function is defined based on a set of two (or more) metrics (e.g., mean squared error MSE and determination coefficient R2 ) that quantify from different (and sometimes competing) perspectives the goodness of a given parameter configuration. Then the metrics are jointly optimized according to the concept of Pareto optimality. This allows preserving the meaning of each metric and deriving multiple optimal solutions to the tuning problem. Each solution leads to a different optimal trade-off among the considered metrics. The main advantages of the proposed multi-objective parameter optimization approach with respect to traditional mono-objective strategies are: (1) the intrinsic improved robustness and efficiency, since multiple metrics are jointly exploited in the tuning of the free parameters of the considered regression method; and (2) the possibility to select the parameter configuration that leads to the desired trade-off among different criteria and thus best meets both the application constraints and the requirements of the specific estimation problem. The experimental analysis was focused on the challenging application domain of soil moisture retrieval from microwave remotely sensed data. The results obtained on data sets associated with two different operative conditions are very promising and show the effectiveness of the proposed approach in comparison with more traditional tuning strategies based on a single metric and its usefulness in defining estimation systems for real application domains.","Measurement,
Optimization,
Remote sensing,
Estimation,
Noise,
Tuning,
Biological system modeling"
Volumetric Intraoperative Brain Deformation Compensation: Model Development and Phantom Validation,"During neurosurgery, nonrigid brain deformation may affect the reliability of tissue localization based on preoperative images. To provide accurate surgical guidance in these cases, preoperative images must be updated to reflect the intraoperative brain. This can be accomplished by warping these preoperative images using a biomechanical model. Due to the possible complexity of this deformation, intraoperative information is often required to guide the model solution. In this paper, a linear elastic model of the brain is developed to infer volumetric brain deformation associated with measured intraoperative cortical surface displacement. The developed model relies on known material properties of brain tissue, and does not require further knowledge about intraoperative conditions. To provide an initial estimation of volumetric model accuracy, as well as determine the model's sensitivity to the specified material parameters and surface displacements, a realistic brain phantom was developed. Phantom results indicate that the linear elastic model significantly reduced localization error due to brain shift, from >; 16 mm to under 5 mm, on average. In addition, though in vivo quantitative validation is necessary, preliminary application of this approach to images acquired during neocortical epilepsy cases confirms the feasibility of applying the developed model to in vivo data.","Brain modeling,
Cameras,
Mathematical model,
Biological system modeling,
Surgery,
Calibration"
A Comparison of Information Functions and Search Strategies for Sensor Planning in Target Classification,"This paper investigates the comparative performance of several information-driven search strategies and decision rules using a canonical target classification problem. Five sensor models are considered: one obtained from classical estimation theory and four obtained from Bernoulli, Poisson, binomial, and mixture-of-binomial distributions. A systematic approach is presented for deriving information functions that represent the expected utility of future sensor measurements from mutual information, Rènyi divergence, Kullback-Leibler divergence, information potential, quadratic entropy, and the Cauchy-Schwarz distance. The resulting information-driven strategies are compared to direct-search, alert-confirm, task-driven (TS), and log-likelihood-ratio (LLR) search strategies. Extensive numerical simulations show that quadratic entropy typically leads to the most effective search strategy with respect to correct-classification rates. In the presence of prior information, the quadratic-entropy-driven strategy also displays the lowest rate of false alarms. However, when prior information is absent or very noisy, TS and LLR strategies achieve the lowest false-alarm rates for the Bernoulli, mixture-of-binomial, and classical sensor models.","Entropy,
Time measurement,
Search problems,
Random variables,
Planning,
Mutual information,
Target tracking"
Semantic grasping: Planning robotic grasps functionally suitable for an object manipulation task,"We design an example based planning framework to generate semantic grasps, stable grasps that are functionally suitable for specific object manipulation tasks. We propose to use partial object geometry, tactile contacts, and hand kinematic data as proxies to encode semantic constraints, which are task-related constraints. We introduce a semantic affordance map, which relates local geometry to a set of predefined semantic grasps that are appropriate to different tasks. Using this map, the pose of a robotic hand can be estimated so that the hand is adjusted to achieve the ideal approach direction required by a particular task. A grasp planner is then used to generate a set of final grasps which have appropriate stability, tactile contacts, and hand kinematics along this approach direction. We show experiments planning semantic grasps on everyday objects and executing these grasps with a physical robot.","Semantics,
Planning,
Grasping,
Robots,
Kinematics,
Geometry,
Pipelines"
IVF: Characterizing the Vulnerability of Microprocessor Structures to Intermittent Faults,"As CMOS technology scales into the nanometer era, future shipped microprocessors will be increasingly vulnerable to intermittent faults. Quantitatively characterizing the vulnerability of microprocessor structures to intermittent faults at an early design stage is significantly helpful in balancing system reliability and performance. Prior researches have proposed several metrics to analyze the vulnerability of microprocessor structures to soft errors and hard faults, however, the vulnerability of these structures to intermittent faults is rarely considered yet. In this work, we propose a metric intermittent vulnerability factor (IVF) to characterize the vulnerability of microprocessor structures to intermittent faults. A structure's IVF is the probability an intermittent fault in that structure causes an external visible error (failure). We compute IVFs for reorder buffer and register file considering three intermittent fault models: intermittent stuck-at-1 and stuck-at-0 fault model, intermittent open and short fault model, and intermittent timing fault model. Experimental results show that, among the three types of intermittent faults, intermittent stuck-at-1 faults have the most serious impact on program execution. Besides, IVF varies significantly across individual structures and programs, which implies partial protection to the most vulnerable structures and program phases for minimizing performance and/or energy overheads.",
Combining match scores with liveness values in a fingerprint verification system,"We discuss the problem of combining biometric match scores with liveness measure values in the context of fingerprint verification. Recent literature has focused on the development of methods to assess if an input fingerprint sample is a “live” entity or a “spoof” artefact. This is commonly done by generating a single-valued numerical entity referred to as the liveness measure value. However, the problem of combining this liveness value with match scores has not been rigorously investigated. The goal of this work is to design a framework in which a liveness detector is incorporated with a fingerprint matcher. We first design and analyze three different methods to combine match scores with liveness values. Next, we introduce a Bayesian Belief Network (BBN) scheme that models the relationship between match scores and liveness values. Experiments carried out on a publicly available database of the Fingerprint Liveness Detection Competition 2009 (LivDet09) show the effectiveness of assuming a certain degree of influence of liveness values on match scores.","Probes,
Detectors,
Large scale integration,
Bayesian methods,
Fingerprint recognition,
Databases,
Materials"
Sleep-Stage Decision Algorithm by Using Heartbeat and Body-Movement Signals,"This paper describes a noninvasive algorithm to estimate the sleep stages used in the Rechtschaffen and Kales method (R-K method). The heartbeat and body-movement signals measured by the noninvasive pneumatic method are used to estimate the sleep stages instead of using the Eletroencephalogram and Electromyography in the R-K method. From the noninvasive measurements, we defined two indices that indicate the condition of REM sleep and the sleep depth. Functions to obtain the incidence ratio and the standard deviation of the extracted elements for each sleep stage were also determined, for each age group of the subjects. Using these indices and functions, an algorithm to classify the subjects' sleep stages was proposed. The mean agreement ratios between the sleep stages' data obtained from the proposed method and those from the de facto standard R-K method, for the stages categorized into six, five, and three, were 51.6%, 56.2%, and 77.5%, and their corresponding mean values of kappa statistics were 0.29, 0.39, and 0.48, respectively. The proposed method shows closer agreement with the result of R-K method than the similar noninvasive method presented earlier.",
Coalitional energy purchasing in the smart grid,"Matching demand and supply is recognized as a crucial issue for smart grids, and ICT-based solutions are essential to deliver the infrastructure, algorithms and mechanisms for demand-supply balancing. To date, most work in this area focus on providing users with real time feedback on energy prices and consumption, or on load scheduling of home appliances for individual user consumption. In this paper, we take a complementary approach by exploiting social relationships among consumers to organise them into coalitions of Virtual Electricity Consumers (VECs) that buy electricity as a single customer in order to get a discount on electricity through collective buying. Specifically, we model our problem as a coalitional game and provide an algorithm, based on linear programming, to form VECs. The VECs formed by our algorithm are both efficient (i.e., minimizing the sum of users' payments) and stable (i.e., no user has any incentive to break away). We empirically analyse our approach using real consumption data for a set of households located in UK. Our analysis provides interesting insights into the relationship between structure and stability of VEC's and prices within the electricity market.","Electricity,
Games,
Social network services,
Measurement,
Linear programming,
Stability analysis,
Electricity supply industry"
Issues and Challenges of Wireless Sensor Networks Localization in Emerging Applications,"Wireless sensor networks (WSNs) are widely being used in many environments (e.g., disaster relief and target tracking), and WSNs localization is still a crucial research area because of the new localization requirements for emerging application domains such as cyber-physical systems and cyber-transportation systems (CTS). In this article, we review different node localization approaches, and point out the issues and challenges of WSNs localization in emerging applications. First, the measurement-based techniques are introduced, and the range-free localization that is further classified into proximity-based localization, one-hop localization and multi-hop localization, is deeply analyzed. Then, the method of nonline-of-sight error mitigation is also reviewed. In addition, we give two representative applications (unmanned vehicle with WSNs navigation and CTS) to state the new obstacles for WSNs localization. Finally, the main issues and challenges for improving WSNs localization are outlined in brief.","Wireless sensor networks,
Nonlinear optics,
Vehicles,
Navigation,
Pollution measurement,
Real time systems,
Measurement uncertainty"
Model-Based Method for Projective Clustering,"Clustering high-dimensional data is a major challenge due to the curse of dimensionality. To solve this problem, projective clustering has been defined as an extension to traditional clustering that attempts to find projected clusters in subsets of the dimensions of a data space. In this paper, a probability model is first proposed to describe projected clusters in high-dimensional data space. Then, we present a model-based algorithm for fuzzy projective clustering that discovers clusters with overlapping boundaries in various projected subspaces. The suitability of the proposal is demonstrated in an empirical study done with synthetic data set and some widely used real-world data set.","Clustering algorithms,
Data models,
Electronic mail,
Proposals,
Data mining,
Gene expression,
Analytical models"
Using Non-redundant Mutation Operators and Test Suite Prioritization to Achieve Efficient and Scalable Mutation Analysis,"Mutation analysis is a powerful and unbiased technique to assess the quality of input values and test oracles. However, its application domain is still limited due to the fact that it is a time consuming and computationally expensive method, especially when used with large and complex software systems. Addressing these challenges, this paper makes several contributions to significantly improve the efficiency of mutation analysis. First, it investigates the decrease in generated mutants by applying a reduced, yet sufficient, set of mutants for replacing conditional (COR) and relational (ROR) operators. The analysis of ten real-world applications, with 400,000 lines of code and more than 550,000 generated mutants in total, reveals a reduction in the number of mutants created of up to 37% and more than 25% on average. Yet, since the isolated use of non-redundant mutation operators does not ensure that mutation analysis is efficient and scalable, this paper also presents and experimentally evaluates an optimized workflow that exploits the redundancies and runtime differences of test cases to reorder and split the corresponding test suite. Using the same ten open-source applications, an empirical study convincingly demonstrates that the combination of non-redundant operators and prioritization leveraging information about the runtime and mutation coverage of tests reduces the total cost of mutation analysis further by as much as 65%.",
Strained germanium-tin (GeSn) N-channel MOSFETs featuring low temperature N+/P junction formation and GeSnO2 interfacial layer,"In this paper, we report the world's first germanium-tin (GeSn) channel nMOSFETs. Highlights of process module advances are: low temperature (400 °C) process for forming high quality n+/p junction with high dopant activation and reduced dopant diffusion; interface engineering achieved with GeSnO2 interfacial layer (IL) between high-k gate dielectric and GeSn channel. A gate-last process was employed. The GeSn nMOSFET with GeSnO2 IL demonstrates a substantially improved SS in comparison with Ge control, and an ION/IOFF ratio of 104.","MOSFETs,
Tin,
Junctions,
Logic gates,
Aluminum oxide,
Films,
Capacitors"
Adjustable autonomy for mobile teleoperation of personal service robots,"Controlling personal service robots is an important, complex task which must be accomplished by the users themselves. In this paper, we propose a novel user interface for personal service robots that allows the user to teleoperate the robot using handheld computers. The user can adjust the autonomy of the robot between three levels: body control, skill control, and task control. We design several user interfaces for teleoperation on these levels. On the higher levels, autonomous behavior of the robot relieves the user from significant workload. If the autonomous execution fails, or autonomous functionality is not provided by the robot system, the user can select a lower level of autonomy, e.g., direct body control, to solve a task. In a qualitative user study we evaluate usability aspects of our teleoperation interface with our domestic service robots Cosero and Dynamaid. We demonstrate the benefits of providing adjustable manual and autonomous control.","Navigation,
Mobile communication,
User interfaces,
Service robots,
Humans,
Cameras"
A Simultaneous Balanced Truncation Approach to Model Reduction of Switched Linear Systems,"This paper deals with model reduction by balanced truncation of switched linear systems (SLS). We consider switched linear systems whose dynamics, depending on the switching signal, switches between finitely many linear systems with a common state space. These linear systems are called the modes of the SLS. The idea is to seek for conditions under which there exists a single state space transformation that brings all modes of the SLS in balanced coordinates. As a measure of reachability and observability of the state components of the SLS, we take the average of the diagonal gramians. We then perform balanced truncation by discarding the state components corresponding to the smallest diagonal elements of this average balanced gramian. In order to carry out this program, we derive necessary and sufficient conditions under which a finite collection of linear systems with common state space can be balanced by a single state space transformation. Among other things, we derive sufficient conditions under which global uniform exponential stability of the SLS is preserved under simultaneous balanced truncation. Likewise, we derive conditions for preservation of positive realness or bounded realness of the SLS. Finally, in case that the conditions for simultaneous balancing do not hold, or we simply do not want to check these conditions, we propose to compute a suitable state space transformation on the basis of minimization of an overall cost function associated with the modes of the SLS. We show that in case our conditions do hold, this transformation is in fact simultaneously balancing, bringing us back to the original method described in this paper.",
Kinect cane: An assistive system for the visually impaired based on three-dimensional object recognition,"This paper proposes a novel assistive system for the visually impaired. The system is composed of a Microsoft Kinect sensor, keypad-type controller, tactile device, laptop computer and so on. The system can recognize three-dimensional objects from depth data generated by the Kinect sensor, and inform visually impaired users not only about the existence of objects, but also about their classes such as chairs and upward stairs. Ordinarily, the system works as a conventional white cane. When a user instructs the system to find the object of a particular class, the system executes the recognition scheme that is designed to find the instructed object. If the object is found in the field of view of the Kinect sensor, the tactile device provides vibration feedback. The recognition schemes are applied to actual scenes. The experimental results indicate that the system is promising as means of helping the visually impaired find the desired objects.","Legged locomotion,
Object recognition,
Robot sensing systems,
Educational institutions,
Cameras,
Accuracy"
State estimation for highly dynamic flying systems using key frame odometry with varying time delays,"System state estimation is an essential part for robot navigation and control. A combination of Inertial Navigation Systems (INS) and further exteroceptive sensors such as cameras or laser scanners is widely used. On small robotic systems with limitations in payload, power consumption and computational resources the processing of exteroceptive sensor data often introduces time delays which have to be considered in the sensor data fusion process. These time delays are especially critical in the estimation of system velocity. In this paper we present a state estimation framework fusing an INS with time delayed, relative exteroceptive sensor measurements. We evaluate its performance for a highly dynamic flight system trajectory including a flip. The evolution of velocity and position errors for varying measurement frequencies from 15Hz to 1Hz and time delays up to 1s is shown in Monte Carlo simulations. The filter algorithm with key frame based odometry permits an optimal, local drift free navigation while still being computationally tractable on small onboard computers. Finally, we present the results of the algorithm applied to a real quadrotor by flying from inside a house out through the window.",
Sliding Conjugate Symmetric Sequency-Ordered Complex Hadamard Transform: Fast Algorithm and Applications,"This paper presents a fast algorithm for the computation of sliding conjugate symmetric sequency-ordered complex Hadamard transform (CS-SCHT). The algorithm calculates the values of window i+ N/4 from those of window i, one length-N/4 Walsh Hadamard transform (WHT) and one length-N/4 Modified WHT (MWHT). The proposed algorithm requires O(N) arithmetic operations, which is more efficient than the block-based algorithms of various transforms and the sliding FFT algorithm, but less efficient than the sliding WHT algorithms. Compared to the recently proposed sliding inverse SCHT (ISCHT) algorithm, the proposed algorithm is more efficient for real input but less efficient for complex input. The applications of the sliding CS-SCHT in transform domain adaptive filtering (TDAF) to complex signal channel equalization and real speech signal acoustic echo cancellation are also provided.","Signal processing algorithms,
Memory management,
Algorithm design and analysis,
Matrix decomposition,
Speech,
Discrete Fourier transforms"
Assessment of mental fatigue during car driving by using high resolution EEG activity and neurophysiologic indices,"Driving tasks are vulnerable to the effects of sleep deprivation and mental fatigue, diminishing driver's ability to respond effectively to unusual or emergent situations. Physiological and brain activity analysis could help to understand how to provide useful feedback and alert signals to the drivers for avoiding car accidents. In this study we analyze the insurgence of mental fatigue or drowsiness during car driving in a simulated environment by using high resolution EEG techniques as well as neurophysiologic variables such as heart rate (HR) and eye blinks rate (EBR). Results suggest that it is possible to introduce a EEG-based cerebral workload index that it is sensitive to the mental efforts of the driver during drive tasks of different levels of difficulty. Workload index was based on the estimation of increase of EEG power spectra in the theta band over prefrontal areas and the simultaneous decrease of EEG power spectra over parietal areas in alpha band during difficult drive conditions. Such index could be used in a future to assess on-line the mental state of the driver during the drive task.","Electroencephalography,
Vehicles,
Indexes,
Heart rate,
Fatigue,
Sleep,
Estimation"
Segmenting Human From Photo Images Based on a Coarse-to-Fine Scheme,"Human segmentation in photo images is a challenging and important problem that finds numerous applications ranging from album making and photo classification to image retrieval. Previous works on human segmentation usually demand a time-consuming training phase for complex shape-matching processes. In this paper, we propose a straightforward framework to automatically recover human bodies from color photos. Employing a coarse-to-fine strategy, we first detect a coarse torso (CT) using the multicue CT detection algorithm and then extract the accurate region of the upper body. Then, an iterative multiple oblique histogram algorithm is presented to accurately recover the lower body based on human kinematics. The performance of our algorithm is evaluated on our own data set (contains 197 images with human body region ground truth data), VOC 2006, and the 2010 data set. Experimental results demonstrate the merits of the proposed method in segmenting a person with various poses.","Image segmentation,
Humans,
Torso,
Computed tomography,
Shape,
Image color analysis,
Legged locomotion"
Metric Rectification of Curved Document Images,"In this paper, we propose a metric rectification method to restore an image from a single camera-captured document image. The core idea is to construct an isometric image mesh by exploiting the geometry of page surface and camera. Our method uses a general cylindrical surface (GCS) to model the curved page shape. Under a few proper assumptions, the printed horizontal text lines are shown to be line convergent symmetric. This property is then used to constrain the estimation of various model parameters under perspective projection. We also introduce a paraperspective projection to approximate the nonlinear perspective projection. A set of close-form formulas is thus derived for the estimate of GCS directrix and document aspect ratio. Our method provides a straightforward framework for image metric rectification. It is insensitive to camera positions, viewing angles, and the shapes of document pages. To evaluate the proposed method, we implemented comprehensive experiments on both synthetic and real-captured images. The results demonstrate the efficiency of our method. We also carried out a comparative experiment on the public CBDAR2007 data set. The experimental results show that our method outperforms the state-of-the-art methods in terms of OCR accuracy and rectification errors.",
Fast Higher-Order MR Image Reconstruction Using Singular-Vector Separation,"Medical resonance imaging (MRI) conventionally relies on spatially linear gradient fields for image encoding. However, in practice various sources of nonlinear fields can perturb the encoding process and give rise to artifacts unless they are suitably addressed at the reconstruction level. Accounting for field perturbations that are neither linear in space nor constant over time, i.e., dynamic higher-order fields, is particularly challenging. It was previously shown to be feasible with conjugate-gradient iteration. However, so far this approach has been relatively slow due to the need to carry out explicit matrix-vector multiplications in each cycle. In this work, it is proposed to accelerate higher-order reconstruction by expanding the encoding matrix such that fast Fourier transform can be employed for more efficient matrix-vector computation. The underlying principle is to represent the perturbing terms as sums of separable functions of space and time. Compact representations with this property are found by singular-vector analysis of the perturbing matrix. Guidelines for balancing the accuracy and speed of the resulting algorithm are derived by error propagation analysis. The proposed technique is demonstrated for the case of higher-order field perturbations due to eddy currents caused by diffusion weighting. In this example, image reconstruction was accelerated by two orders of magnitude.",
"Interaction-Free Quantum Optical Fredkin Gates in \chi^{(2)}
Microdisks","We present novel “interaction-free” realizations of quantum optical Fredkin gates that do not rely on direct physical coupling between the target light (signal) and the control light (pump). The interaction-free feature of such gates allow to overcome the fundamental limits of photon loss and quantum-state decoherence imposed by the signal-pump coupling. This advantage, together with the low inherent quantum-noise level in χ(2) microdisks, gives rise to substantially improved performance over the existing Fredkin-gate designs. Explicitly using lithium-niobate mircrodisks, we present two kinds of interaction-free Fredkin gates, a phase gate and an optical-path gate, both of which are designed with telecom-band applications in mind. For both gates, the threshold pump peak power to achieve a gate contrast >;100 and a signal loss <;10% is hundreds of microwatts for practical parameters of the devices.","Cavity resonators,
Logic gates,
Optical pumping,
Nonlinear optics,
Optical surface waves,
Optical device fabrication,
Photonics"
Saddle-Point Strategies in Malware Attack,"Given the flexibility that software-based operation provides, it is unreasonable to expect that new malware will demonstrate a fixed behavior over time. Instead, malware can dynamically change the parameters of their infective hosts in response to the dynamics of the network, in order to maximize their overall damage. However, in return, the network can also dynamically change its counter-measure parameters in order to attain a robust defense against the spread of malware while minimally affecting the normal performance of the network. The infinite dimension of freedom introduced by variation over time and antagonistic and strategic optimization of malware and network against each other demand new attempts for modeling and analysis. We develop a zero-sum dynamic game model and investigate the structural properties of the saddle-point strategies. We specifically show that saddle-point strategies are simple threshold-based policies and hence, a robust dynamic defense is practicable.","Malware,
Games,
Grippers,
Robustness,
Quality of service,
Game theory"
Differential energy based microgrid protection against fault conditions,A differential energy based fault protection in microgrid is presented in this paper. Initially the currents at the respective buses are retrieved and processed through a novel time-frequency transform known as S-transform to generate time-frequency contours. Spectral energy content of the time-frequency contours of fault current signals are calculated and differential energy is computed to register the fault patterns in the microgrid at grid-connected and islanded mode. The proposed scheme is tested for different shunt faults (symmetrical and unsymmetrical) and High Impedance Faults (HIF) in the microgrid with radial and loop structure. The results based on extensive study indicate that the differential energy based protection scheme can reliably protect the microgrid against different fault situations.,"Time frequency analysis,
Fault currents,
Pattern recognition,
Impedance,
Wavelet transforms,
Mathematical model"
"A Boosting, Sparsity- Constrained Bilinear Model for Object Recognition","Using higher-level visual elements to represent images, the authors have developed a sparsity-constrained bilinear model (SBLM) and have combined a set of SBLMs in a boosting-like procedure to enhance performance.","Visualization,
Image processing,
Object recognition,
Image representation,
Robustness,
Adaptation model,
Video communication,
Information retrieval,
Computer vision"
Coordinate Live Streaming and Storage Sharing for Social Media Content Distribution,"The recently emerged user-generated contents (UGC) services, social networking services (SNS), as well as the pervasive wireless mobile network services have formed social media which has drastically changed the content distribution landscape. Today such UGC applications as YouTube allow any user to be a content provider, generating enormous amount of video contents that are quickly and extensively propagated on the Internet through such SNSes as Facebook and Twitter. Unfortunately, the existing UGC sites are facing critical server bottlenecks and the surges created by the social networking users would make the situation even worse. To better understand the challenges and opportunities therein, we investigate users' social behavior and personal preference of online video sharing from both real-trace measurement study on a popular social networking website and a user questionnaire survey. Our data analysis reveals an interesting coexistence of live streaming and storage sharing, and that the users are generally more interested in watching their friend's videos. It further suggests that even though the traffic is significant, most users are willing to share their resources to assist others, implying user collaboration is a rational choice in this context. In this paper, we present Coordinated Live Streaming and Storage Sharing (COOLS), a system for efficient peer-to-peer posting of user-generated videos. Through a novel ID code design that embeds nodes' locations in an overlay, COOLS leverages stable storage users and yet inherently prioritizes living streaming flows. We also present the improvement of the basic overlay design. The evaluation results show that, as compared to other state-of-the-art solutions, COOLS successfully takes advantage of the coexistence of live streaming and storage sharing, providing better scalability, robustness, and streaming quality.","Streaming media,
Social network services,
TV,
Watches,
Peer to peer computing,
Internet,
Servers"
Min-cost multicast networks in Euclidean space,"Space information flow is a new field of research recently proposed by Li and Wu [1], [2]. It studies the transmission of information in a geometric space, where information flows can be routed along any trajectories, and can be encoded wherever they meet. The goal is to satisfy given end-to-end unicast/multicast throughput demands, while minimizing a natural bandwidth-distance sum-product (network volume). Space information flow models the design of a blueprint for a minimum-cost network. We study the multicast version of the space information flow problem, in Euclidean spaces. We present a simple example that demonstrates the design of an information network is indeed different from that of a transportation network. We discuss properties of optimal multicast network embedding, prove that network coding does not make a difference in the basic case of 1-to-2 multicast, and prove upper-bounds on the number of relay nodes required in an optimal acyclic multicast network.","Relays,
Network coding,
Steiner trees,
Encoding,
Receivers,
Vectors,
Vegetation"
Cloud computing: Security challenges,"Although cloud computing can help companies accomplish more by breaking the physical bonds between an IT infrastructure and its users, heightened security threats must be overcome in order to benefit fully from this new computing paradigm that offers an innovative business model for organizations to adopt IT without upfront investment. Despite the potential gains achieved from the cloud computing, the model security is still questionable which impacts the cloud model adoption. The security problem becomes more complicated under the cloud model as new dimensions have entered into the problem scope related to the model architecture, multi-tenancy, elasticity, and layers dependency stack. In this paper we introduce a detailed analysis of the cloud security problem. We investigated the problem from the cloud architecture perspective, the cloud offered characteristics perspective, the cloud stakeholders' perspective, and the cloud service delivery models perspective. Based on this analysis we derive a detailed specification of the cloud security problem and key features that should be covered by any proposed security solution.","Computational modeling,
Security,
Computer architecture,
Runtime"
Access Point Buffer Management for Power Saving in IEEE 802.11 WLANs,"It is crucial to save power and prolong the runtime of mobile stations (STAs) in wireless local area networks (WLANs). In an infrastructure WLAN, a STA cannot be connected until it is associated with an access point (AP), which is responsible for buffering frames for all the associated STAs operating in the power saving mode. Hence, efficient memory utilization is critical for an AP to accommodate as many power-saving STAs as possible. The basic power management (BPM) scheme introduced in the IEEE 802.11 standard achieves power saving by allowing STAs not engaging in data delivery to operate in doze mode, but it does not consider the efficient use of the memory in the AP. To tradeoff power consumption for memory usage, we present an AP-priority timer-based power management (APP-TPM) scheme and develop a novel model for stochastic analysis of the proposed scheme. Based on this model, the probability distributions of the numbers of frames buffered at the AP and the average numbers of frames buffered at the AP are obtained. Moreover, a power-aware buffer management scheme (PBMS), which is based on the derived statistics, is proposed to accommodate as many STAs as possible given a fixed amount of memory in the AP while maintaining low power consumption. Simulation results show that the proposed scheme performs better than BPM in terms of memory usage in the AP.","Memory management,
Wireless LAN,
IEEE 802.11 Standards,
Power system management,
Power demand,
Analytical models,
Random variables"
Fault Localization Based Only on Failed Runs,"Fault localization commonly relies on both passed and failed runs, but passed runs are generally susceptible to coincidental correctness and modern software automatically produces a huge number of bug reports on failed runs. FOnly is an effective new technique that relies only on failed runs to locate faults statistically.",
A Low-Flicker-Noise MEMS Electrothermal Displacement Sensing Technique,"The sensitivity of an electrothermal displacement sensor is heavily dependent on its noise profile, particularly on the flicker noise inherent to the doped silicon heater. We show that the flicker noise in a microelectromechanical systems (MEMS) electrothermal displacement sensor can be reduced by driving the silicon heaters with a high-frequency voltage. The proposed technique has been applied to a MEMS electrothermal sensor fabricated in the standard silicon-on-insulator process. Experimental results demonstrate an 8-dB improvement in noise level compared to the conventional measurement technique. The achieved noise floor is less than -100 dBVrms around the 20-Hz measured signal.","Electrothermal sensors,
Micromechanical devices,
Heating,
Nanopositioning,
Sensors,
Resistors,
Silicon"
60 GHz UWB channel measurement and model,"Measurements of the 60 GHz UWB indoor channel done in a modern office building at the University of L'Aquila, Italy, are presented. The channel sounder is based on a PN-sequence correlation technique with a pulse width of 0.8 ns. Signals are recorded in different locations in line-of-sight and non-line-of-sight scenarios, and for each location the receiver is moved over a grid of 9×9 positions, in order to characterize both the large and the small scale behaviors. Samples of the channel impulse response are recorded at eight different carrier frequencies spanning the bands from 54 to 59 GHz and from 61 to 66 GHz. In this paper we propose an analysis of the experimental data in order to provide models for the large scale behavior of these signals, including a study of the frequency dependence.","Antenna measurements,
Delay,
Receivers,
Wireless communication,
Educational institutions,
Transmitters,
Loss measurement"
A Visual Analytics Approach to Multiscale Exploration of Environmental Time Series,"We present a Visual Analytics approach that addresses the detection of interesting patterns in numerical time series, specifically from environmental sciences. Crucial for the detection of interesting temporal patterns are the time scale and the starting points one is looking at. Our approach makes no assumption about time scale and starting position of temporal patterns and consists of three main steps: an algorithm to compute statistical values for all possible time scales and starting positions of intervals, visual identification of potentially interesting patterns in a matrix visualization, and interactive exploration of detected patterns. We demonstrate the utility of this approach in two scientific scenarios and explain how it allowed scientists to gain new insight into the dynamics of environmental systems.","Time series analysis,
Visual analytics,
Data visualization,
Meteorology,
Entropy,
Earth"
Using E-Portfolios to support experiential learning and open the use of tele-operated laboratories for mobile devices,"The use of laboratories in Engineering Education at universities is an adequate opportunity to implement experiential and research based learning - e.g. in material sciences. Within these laboratories the students have the chance to do own experiments and by that gain own experiences in their learning processes. Recently finished research projects - e.g. like the PeTEX project done by universities in Dortmund (Germany), Palermo (Italy) and Stockholm (Sweden) - implemented an opportunity to do experiential learning by using real laboratory equipment without being physically in the laboratory but having access via the internet. For a couple of reasons this makes sense, for example because limited equipment resources or the high costs of this equipment. Trying to implement experiential learning by the use of these remote laboratories gives the opportunity to the students to do some kind of own research. The question in this context - and for this question we will give a first answer in this paper - is how students could document their own learning process on the one hand and how the teacher can guide the student through this process on the other hand. One possible solution can be seen in the use of e-portfolios. With this e-portfolios the student can document and show to others, what he has been doing. The next step is making the e-portfolio software available for mobile devices so that the student has access from virtually everywhere and every time. With this work in progress paper we show what kind of role e-portfolios can play in the learning process and which kind of scenarios are possible using the software on mobile devices. Furthermore, we show that the combination of experiential learning and the use of e-portfolios offer a great potential to promote the learners' creativity.","Laboratories,
Education,
Software,
Materials"
Measurement and Evaluation of Power Analysis Attacks on Asynchronous S-Box,"This paper demonstrates the hardware implementation of a recently proposed low-power asynchronous Advanced Encryption Standard substitution box (S-Box) design that is capable of being resistant to side channel attack (SCA). A specified SCA standard evaluation field-programmable gate array (FPGA) board (SASEBO-GII) is used to implement both synchronous and asynchronous S-Box designs. This asynchronous S-Box is based on self-time logic referred to as null convention logic (NCL), which supports a few beneficial properties for resisting SCAs: clock free, dual-rail encoding, and monotonic transitions. These beneficial properties make it difficult for an attacker to decipher secret keys embedded within the cryptographic circuit of the FPGA board. Comparisons on the resistance to SCAs of both the original and proposed S-Box design are presented, using differential power analysis (DPA) and correlation power analysis (CPA) attacks. The power measurement results showed that the NCL S-Box had 22%-26% lower total power consumption than the original and was effective against DPA and CPA attacks. An important factor of successfully implementing DPA or CPA attacks, which is the number of power traces, is also analyzed in this paper.","Field programmable gate arrays,
Logic gates,
Power demand,
Power measurement,
Hardware,
Cryptography"
Threshold Voltage Tuning for Faster Activation With Lower Noise in Tri-Mode MTCMOS Circuits,"A new threshold voltage tuning methodology is explored in this paper to minimize the peak power/ground bouncing noise with smaller sleep transistors in multi-threshold CMOS (MTCMOS) circuits. Different circuit techniques with the threshold voltage tuning strategy lower the activation noise, the activation delay, and the size of the additional sleep transistors by up to 27.76%, 32.66%, and 85.71%, respectively, as compared to a previously published noise-aware MTCMOS circuit with standard zero-body-biased high threshold voltage sleep transistors in a UMC 80-nm CMOS technology.","Noise,
Threshold voltage,
Delay,
Transistors,
Tuning,
CMOS integrated circuits,
Power demand"
Model Pulses for Performance Prediction of Digital Microelectronic Systems,"Pulse-shape models are presented that furnish the tools for analyzing a number of aspects of the performance of microelectronic circuits. Model pulse shapes are provided and their properties are analyzed in detail. Applications that are covered include the replication of measured pulses that are of relevance for inter- and intra-chip interconnects and, concurrently, examples of passive circuits that generate them. The pulses are appropriate as input to time-domain electromagnetic simulation. They are also instrumental to microelectronic performance prediction protocols and measurement equipment-aspects that are of crucial importance to integrated circuit packaging.",
Link correlation aware opportunistic routing,"By exploiting reception diversity of wireless network links, researchers have shown that opportunistic routing can improve network performance significantly over traditional routing schemes. However, recently empirical studies indicate that we are too optimistic, i.e. diversity gain can be overestimated if we continue to assume that packet receptions of wireless links are independent events. For the first time, this paper formally analyzes the opportunistic routing gain under the presence of link correlation considering the loss of DATA and ACK packets. Based on the model, we introduce a new link-correlation-aware opportunistic routing scheme, which improves the performance by exploiting the diverse uncorrelated forwarding links. Our design is evaluated using simulation where we show (i) link correlation leads to less diversity gain, (ii) and with our link-correlation-aware design; improvement can be gained. We also provide a unique model to generate strings of randomly correlated receptions.","Correlation,
Routing,
Wireless networks,
Measurement,
Wireless sensor networks,
Protocols"
On the feasibility of precoding-based network alignment for three unicast sessions,"We consider the problem of network coding across three unicast sessions over a directed acyclic graph, when each session has min-cut one. Previous work by Das et al. adapted a precoding-based interference alignment technique, originally developed for the wireless interference channel, specifically to this problem. We refer to this approach as precoding-based network alignment (PBNA). Similar to the wireless setting, PBNA asymptotically achieves half the minimum cut; different from the wireless setting, its feasibility depends on the graph structure. Das et al. provided a set of feasibility conditions for PBNA with respect to a particular precoding matrix. However, the set consisted of an infinite number of conditions, which is impossible to check in practice. Furthermore, the conditions were purely algebraic, without interpretation with regards to the graph structure. In this paper, we first prove that the set of conditions provided by Das. et al are also necessary for the feasibility of PBNA with respect to any precoding matrix. Then, using two graph-related properties and a degree-counting technique, we reduce the set to just four conditions. This reduction enables an efficient algorithm for checking the feasibility of PBNA on a given graph.","Network coding,
Unicast,
Vectors,
Interference,
Wireless communication,
Encoding,
Tin"
Efficient and effective online image retrieval,"With visual information becoming increasingly important, efficient and effective methods for querying and retrieving this kind of information are highly sought after. In this paper, we focus on image information and querying from image collections in an online retrieval fashion. In online retrieval, image features for performing retrieval are not pre-calculated but need to be extracted during the retrieval stage. Consequently, and in particular for large image datasets, the time required for feature extraction becomes crucial so as to not exceed interactive retrieval speeds. Our aim in this work is to match the retrieval accuracy of a high performing yet rather slow image retrieval method, but perform the retrieval in only a fraction of the time. We achieve this by a combination of two carefully crafted filtering stages both of which are based on the way data is stored in JPEG compressed images. The first of these performs extremely fast image retrieval using solely information contained in the JPEG headers. The second stage employs a compressed domain retrieval method that utilises features calculated from JPEG coefficient data. The first filter discards a large part of irrelevant images in a very fast fashion. The remaining images are filtered by the second technique in order to arrive at a relatively small subset of the complete database in a timely fashion. Finally, on this subset the high performing algorithm of choice, the MPEG-7 colour structure descriptor in this paper, is applied to produce a final ranking of the images to be returned to the user. Our experimental results demonstrate that on a large dataset of over 25,000 images our approach achieves retrieval scores nearly identical to those of the high performing technique while reducing the overall retrieval time by a factor of 15.","Transform coding,
Image color analysis,
Image coding,
Feature extraction,
Image retrieval,
Discrete cosine transforms"
The Compact Modeling of Channel Potential in Sub-30-nm NAND Flash Cell String,"This letter presents a compact model of nand Flash strings in which complex characteristics of scaled-down Flash cells can be captured very accurately through simple circuit simulation. Different from previous modeling studies, the proposed model has detailed physical descriptions for channel potential of Flash cell so that various program disturbances due to leakages in nand string can be easily analyzed. The compact model of channel potential is fully compatible with BSIM4 SPICE model. By applying compact model to the 30-nm nand product, many phenomena in the device were realized with more than 95% accuracy at the expense of only a few minutes.","Integrated circuit modeling,
Flash memory,
Electric potential,
Logic gates,
Electron devices,
IEEE Potentials,
Boosting"
A server's perspective of Internet streaming delivery to mobile devices,"Receiving Internet streaming services on various mobile devices is getting more and more popular. To understand and better support Internet streaming delivery to mobile devices, a number of studies have been conducted. However, existing studies have mainly focused on the client side resource consumption and streaming quality. So far, little is known about the server side, which is the key for providing successful mobile streaming services. In this work, we set to investigate the Internet mobile streaming service at the server side. For this purpose, we have collected a one-month server log (with 212 TB delivered video traffic) from a top Internet mobile streaming service provider serving worldwide mobile users. Through trace analysis, we find that (1) a major challenge for providing Internet mobile streaming services is rooted from the mobile device hardware and software heterogeneity. In this workload, we find over 2800 different hardware models with about 100 different screen resolutions running 14 different mobile OS and 3 audio codecs and 4 video codecs. (2) To deal with the device heterogeneity, transcoding is used to customize the video to the appropriate versions at runtime for different devices. A video clip could be transcoded into more than 40 different versions in order to serve requests from different devices. (3) Compared to videos in traditional Internet streaming, mobile streaming videos are typically of much smaller size (a median of 1.68 MBytes) and shorter duration (a median of 2.7 minutes). Furthermore, the daily mobile user accesses are more skewed following a Zipf-like distribution but users' interests also quickly shift. Considering the huge demand of CPU cycles for online transcoding, we further examine server-side caching in order to reduce CPU cycle demand. We show that a policy considering different versions of a video altogether outperforms other intuitive ones when the cache size is limited.","Streaming media,
Mobile handsets,
Mobile communication,
Servers,
Internet,
Video codecs"
A Methodology for Large-Scale Ocean Wave Power Time-Series Generation,"Ocean wave power is characterized by high power density, and wave forecasts can predict incident wave energy days in advance. These qualities make ocean wave power a promising renewable energy source. In the near future, utility-scale wave energy conversion arrays will likely be installed. However, little is currently known on the impact of large wave energy conversion (WEC) facilities on utility operation and planning. In this paper, a methodology is developed for generating WEC array power time series that can be used for wave power utility integration purposes. Sample results show that the methodology produces first-order approximations of WEC array outputs and demonstrate that significant smoothing of the total wave power output from an array can be expected.","Force,
Sea surface,
Surface waves,
Time series analysis,
Ocean waves,
Arrays"
Efficient Resource Allocation for Attentive Automotive Vision Systems,"We describe a novel architecture for automotive vision organized on five levels of abstraction, i.e., sensor, data, semantic, reasoning, and resource allocation levels, respectively. Although we implement and evaluate processes to detect and classify other participants within the immediate environment of a moving vehicle, our main emphasis is on the allocation of computational resource and attentive processing by the sensor suite. To that end, an efficient multiobjective resource allocation method is formalized and implemented. This includes a decision-making process dependent upon the environment, the current goal, the available sensors and computational resource, and the time available to make a decision. We evaluate our approach on road traffic test sequences acquired by a test vehicle provided by Audi. This vehicle includes lidar, video, radar, and sonar sensors, in addition to conventional global positioning system (GPS) navigation, but our evaluation is confined to lidar and video data alone.","Vehicles,
Roads,
Detectors,
Resource management,
Humans,
Probability,
Global Positioning System"
Help Me: Opportunistic smart rescue application and system,"Communicating during disaster times is crucial for both survivors and rescue forces. While fast reaction is critical communication infrastructures, wired and cellular, are often lost, and cannot be restored in a timely fashion. In this paper we present HelpMe, a self learning opportunistic ad-hoc system, which enables smartphone-based ad-hoc communications at disaster times over Wi-Fi. HelpMe smartphone peers communicate using a sophisticated mechanism that performs a transparent on-the-fly classification and matching of requests to peers in the formed opportunistic ad-hoc network. Matching is further leveraged for a smart forwarding, enabling the request to reach the best matching user in the vicinity. Our system enables best peers matching across an opportunistic ad-hoc network on a hop-by-hop basis, in a timely and power conservative manner. Location coordinates are sent with each request. The client is built on top of the Haggle middleware, leveraging its neighbor discovery and interest-based forwarding. The HelpMe client is fully implemented as an iPhone application on top of the Haggle middleware. The HelpMe system consists also of a HelpMe cloud-based server, used only when communication is available before and after the crisis. The server is used for profiling users and creating personalized apps for the users. When communication is restored, it can be leveraged for collecting information for missing persons services. The server is implemented as a web service. We tested the system using several iPhone / iPad clients communicating over Wi-Fi and showed that our settings not only enable a best match, but also enable willing users to become hub nodes in the formed opportunistic network. The system is self-adjusting and supports on the fly settings modifications.",
Multilabel Learning for Protein Subcellular Location Prediction,"Protein subcellular localization aims at predicting the location of a protein within a cell using computational methods. Knowledge of subcellular localization of proteins indicates protein functions and helps in identifying drug targets. Prediction of protein subcellular localization is an important but challenging problem, particularly when proteins may simultaneously exist at, or move between, two or more different subcellular location sites. Most of the existing protein subcellular localization methods are only used to deal with the single-location proteins. To better reflect the characteristics of multiplex proteins, we formulate prediction of subcellular localization of multiplex proteins as a multilabel learning problem. We present and compare two multilabel learning approaches, which exploit correlations between labels and leverage label-specific features, respectively, to induce a high quality prediction model. Experimental results on six protein data sets under various organisms show that our described methods achieve significantly higher performance than any of the existing methods. Among the different multilabel learning methods, we find that methods exploiting label correlations performs better than those leveraging label-specific features.","Proteins,
Correlation,
Training,
Multiplexing,
Learning systems,
Measurement,
Accuracy"
Obtaining High-Quality Relevance Judgments Using Crowdsourcing,"The performance of information retrieval (IR) systems is commonly evaluated using a test set with known relevance. Crowdsourcing is one method for learning the relevant documents to each query in the test set. However, the quality of relevance learned through crowdsourcing can be questionable, because it uses workers of unknown quality with possible spammers among them. To detect spammers, the authors' algorithm compares judgments between workers; they evaluate their approach by comparing the consistency of crowdsourced ground truth to that obtained from expert annotators and conclude that crowdsourcing can match the quality obtained from the latter.",
A new approach to designing electronic systems for operation in extreme environments: Part II - The SiGe remote electronics unit,"We have presented the architecture, simulation, packaging, and over-temperature and radiation testing of a complex, 16-channel, extreme environment capable, SiGe Remote Electronics Unit containing the Remote Sensor Interface ASIC that can serve a wide variety of space-relevant needs as designed. These include future missions to the Moon and Mars, with the additional potential to operate in other hostile environments, including lunar craters and around the Jovian moon, Europa. We have expanded on the previous introduction of the RSI to show the validity of the chip design and performance over an almost 250 K temperature range, down to 100 K, under 100 krad TID radiation exposure, with SEL immunity and operability in a high-flux SET environment.","Space vehicles,
Design methodology,
Environmental factors,
Radar remote sensing,
Circuit layout,
Digital control,
Remote sensing,
Integrated circuits,
NASA,
Space missions,
Microprocessors,
Computer architecture"
To offload or not to offload: An efficient code partition algorithm for mobile cloud computing,"A new class of cognition augmenting applications such as face recognition or natural language processing is emerging for mobile devices. This kind of applications is computation and power intensive and a cloud infrastructure would provide a great potential to facilitate the code execution. Since these applications usually consist of many composable components, finding the optimal execution layout is difficult in real time. In this paper, we propose an efficient code partition algorithm for mobile code offloading. Our algorithm is based on the observation that when a method is offloaded, the subsequent invocations will be offloaded with a high chance. Unlike the current approach which makes an individual decision for each component, our algorithm finds the offloading and integrating points on a sequence of calls by depth-first search and a linear time searching scheme. Experimental results show that, compared with the 0-1 Integer Linear Programming solver, our algorithm runs 2 orders of magnitude faster with more than 90% partition accuracy.",
On the Performance of Covariance Based Spectrum Sensing for Cognitive Radio,"In this paper, the distribution of the test-statistic for the covariance based detection (CBD) is studied in order to obtain the mathematical expressions of false alarm probability (Pf) and detection probability (Pd) . The formulation of decision threshold λ for any Pf is also presented. The expression of Pd allows to evaluate the performance of the CBD technology. Finally, the decision threshold, as well as the derived Pf and Pd , is verified with Monte-Carlo simulations.",
Multispeculative Addition Applied to Datapath Synthesis,"Addition is the key arithmetic operation in most digital circuits and processors. Therefore, their performance and other parameters, such as area and power consumption, are highly dependent on the adders' features. In this paper, we present multispeculation as a way of increasing adders' performance with a low area penalty. In our proposed design, dividing an adder into several fragments and predicting the carry-in of each fragment enables computing every addition in two very short cycles at the most, with 99% or higher probability. Furthermore, based on multispeculation principles, we propose a new strategy for implementing addition chains and hiding most of the penalty cycles due to mispredictions, while keeping at the same time the resource sharing capabilities that are sought in high-level synthesis. Our results show that it is possible to build linear and logarithmic adders more than 4.7× and 1.7× faster than the nonspeculative case, respectively. Moreover, this is achieved with a low area penalty (38% for linear adders) or even an area reduction (-8% for logarithmic adders). Finally, applying multispeculation principles to signal processing benchmarks that use addition chains will result in 25% execution time reduction, with an additional 3% decrease in datapath area with respect to implementations with logarithmic fast adders.","Adders,
Delay,
Power demand"
Exact Synthesis of Toffoli Gate Circuits with Negative Control Lines,"The development of synthesis approaches for reversible circuits is an active research area. Besides heuristic methods, also exact synthesis received significant attention. Here, circuits realizing the desired functions e.g. with a minimal number of gates are determined. However, so far exact synthesis considering Toffoli gate circuits with positive control lines only has been considered. In this paper, we are extending the scope of exact synthesis by additionally considering negative control lines in the circuits to be synthesized. For this purpose, we propose and evaluate a SAT-based synthesis method. Our experiments show that incorporating negative control lines leads to smaller circuits with respect to the number of gates. Furthermore, in some cases even the run-time of the synthesis can be improved.","Logic gates,
Encoding,
Heuristic algorithms,
Boolean functions,
NP-complete problem,
Computer science,
Educational institutions"
Efficient Prediction of Array Element Patterns Using Physics-Based Expansions and a Single Far-Field Measurement,"A method is proposed to predict the antenna array beam through employing a relatively small set of physics-based basis functions-called characteristic basis function patterns (CBFPs)-for modeling the embedded element patterns. The primary CBFP can be measured or extracted from numerical simulations, while additional (secondary) CBFPs are derived from the primary one. Furthermore, each numerically generated CBFP, which is typically simulated/measured for discrete directions only, can in turn be approximated by analytical basis functions with fixed expansion coefficients to evaluate the resulting array pattern at any angle through interpolation. This hierarchical basis reduces the number of unknown expansion coefficients significantly. Accordingly, the CBFP expansion coefficients can be determined through a single far-field measurement of only a few reference sources in the field of view. This is particularly important for multibeam array applications where only a limited number of reference sources are available for predicting the beam shape. Furthermore, this instantaneous beam calibration is fast, i.e., potentially capable to speed up the array calibration by one or two orders of magnitude, which is particularly important if the antenna radiation characteristics are subject to drifts.","Arrays,
Covariance matrix,
Antenna measurements,
Antenna arrays,
Voltage measurement,
Mathematical model"
A Rational-Fraction Dispersion Model for Efficient Simulation of Dispersive Material in FDTD Method,A novel rational-fraction dispersion model is proposed for simulation of optical properties of arbitrary linear dispersive media over a wide wavelength range. A generally applicable method is proposed for estimating the parameters of this model. It is demonstrated that the rational-fraction dispersion model can fit the relative permittivity data of a material accurately and efficiently in a wide wavelength range. The new model is implemented in the finite-difference time-domain method and is applied as a powerful and computationally efficient tool for simulating nano-particles of dispersive materials in a wide wavelength range of light.,"Mathematical model,
Computational modeling,
Finite difference methods,
Equations,
Materials,
Dispersion,
Time domain analysis"
Multi-directional spatial error concealment using adaptive edge thresholding,"In this paper, a new method for spatial concealment of missing areas in image and video signals transmitted over error prone infrastructures, is presented. The concealment process is performed in three steps. First, a novel technique is used to estimate the significant edges of missing areas after performing a directional edge analysis on the correctly received neighboring blocks of the missing areas. This technique uses the moments of the neighboring edge magnitudes to obtain an adaptive threshold for rejecting non-significant directions. Second, based on the predicted significant directions, an approximation is obtained for each missing pixel. Finally, for each pixel, we compute a weighted average by using two edge correspondence measures as weighting factors. Moreover, the adaptive thresholding of the edges let us include as many edges as necessary in the interpolation process. Experiments show that the proposed method outperforms the previous state of the art methods based on both subjective and objective measures.",
Effects of Meandering on Dipole Antenna Resonant Frequency,"In low-frequency applications, antenna designers find that it is beneficial to adjust the resonant frequency while preferably maintaining the physical size as a means of improving the antenna's radiation resistance, which in turn improves the radiation efficiency. The closer the resonant frequency is to the frequency of operation, the more efficient the antenna is. Addition of bends is one such technique for increasing the electrical size of a dipole antenna while maintaining the same overall physical length. This letter presents a study of the effects of bends on the resonant frequency of a dipole antenna in the VHF frequency range. A broadband equivalent circuit model for a straight dipole from previous work is adapted to a three-bend meander dipole antenna, and its performance is compared to that of a straight dipole having the same overall physical length. The predicted frequency response of the broadband model is calculated using circuit simulation software and compared to results from computational electromagnetic modeling and network-analyzer measurement of prototype straight and meandered dipole antennas.","Dipole antennas,
Resonant frequency,
Antenna measurements,
Integrated circuit modeling,
Equivalent circuits,
Broadband antennas"
Gateway discovery algorithm based on multiple QoS path parameters between mobile node and gateway node,"Several gateway selection schemes have been proposed that select gateway nodes based on a single Quality of Service (QoS) path parameter, for instance path availability period, link capacity or end-to-end delay, etc. or on multiple non-QoS parameters, for instance the combination of gateway node speed, residual energy, and number of hops, for Mobile Ad hoc NETworks (MANETs). Each scheme just focuses on the ment of improve only a single network performance, i.e., network throughput, packet delivery ratio, end-to-end delay, or packet drop ratio. However, none of these schemes improves the overall network performance because they focus on a single QoS path parameter or on set of non-QoS parameters. To improve the overall network performance, it is necessary to select a gateway with stable path, a path with the maximum residual load capacity and the minimum latency. In this paper, we propose a gateway selection scheme that considers multiple QoS path parameters such as path availability period, available capacity and latency, to select a potential gateway node. We improve the path availability computation accuracy, we introduce a feedback system to updated path dynamics to the traffic source node and we propose an efficient method to propagate QoS parameters in our scheme. Computer simulations show that our gateway selection scheme improves throughput and packet delivery ratio with less per node energy consumption. It also improves the end-to-end delay compared to single QoS path parameter gateway selection schemes. In addition, we simulate the proposed scheme by considering weighting factors to gateway selection parameters and results show that the weighting factors improve the throughput and end-to-end delay compared to the conventional schemes.","Logic gates,
Ad hoc networks,
Mobile computing,
Quality of service,
Availability,
Delay,
Routing"
Polarimetry With Phased Array Antennas: Theoretical Framework and Definitions,"For phased array receivers, the accuracy with which the polarization state of a received signal can be measured depends on the antenna configuration, array calibration process, and beamforming algorithms. A signal and noise model for a dual-polarized array is developed and related to standard polarimetric antenna figures of merit, and the ideal polarimetrically calibrated, maximum-sensitivity beamforming solution for a dual-polarized phased array feed is derived. A practical polarimetric beamformer solution that does not require exact knowledge of the array polarimetric response is shown to be equivalent to the optimal solution in the sense that when the practical beamformers are calibrated, the optimal solution is obtained. To provide a rough initial polarimetric calibration for the practical beamformer solution, an approximate single-source polarimetric calibration method is developed. The modeled instrumental polarization error for a dipole phased array feed with the practical beamformer solution and single-source polarimetric calibration was -10 dB or lower over the array field of view for elements with alignments perturbed by random rotations with 5 degree standard deviation.",
Agglomerative Mean-Shift Clustering,"Mean-Shift (MS) is a powerful nonparametric clustering method. Although good accuracy can be achieved, its computational cost is particularly expensive even on moderate data sets. In this paper, for the purpose of algorithmic speedup, we develop an agglomerative MS clustering method along with its performance analysis. Our method, namely Agglo-MS, is built upon an iterative query set compression mechanism which is motivated by the quadratic bounding optimization nature of MS algorithm. The whole framework can be efficiently implemented in linear running time complexity. We then extend Agglo-MS into an incremental version which performs comparably to its batch counterpart. The efficiency and accuracy of Agglo-MS are demonstrated by extensive comparing experiments on synthetic and real data sets.","Kernel,
Clustering algorithms,
Acceleration,
Algorithm design and analysis,
Convergence,
Optimization,
Bandwidth"
Augmented Topological Descriptors of Pore Networks for Material Science,"One potential solution to reduce the concentration of carbon dioxide in the atmosphere is the geologic storage of captured CO2 in underground rock formations, also known as carbon sequestration. There is ongoing research to guarantee that this process is both efficient and safe. We describe tools that provide measurements of media porosity, and permeability estimates, including visualization of pore structures. Existing standard algorithms make limited use of geometric information in calculating permeability of complex microstructures. This quantity is important for the analysis of biomineralization, a subsurface process that can affect physical properties of porous media. This paper introduces geometric and topological descriptors that enhance the estimation of material permeability. Our analysis framework includes the processing of experimental data, segmentation, and feature extraction and making novel use of multiscale topological analysis to quantify maximum flow through porous networks. We illustrate our results using synchrotron-based X-ray computed microtomography of glass beads during biomineralization. We also benchmark the proposed algorithms using simulated data sets modeling jammed packed bead beds of a monodispersive material.",
Multimodal Cancelable Biometrics,"Multimodal biometric systems have emerged as highly successful new approach to combat problems of unimodal biometric system such as intraclass variability, interclass similarity, data quality, non-universality, and sensitivity to noise. However, one major issue pertinent to unimodal system remains. It has to do with actual biometric characteristics of users being permanent, and their number being limited. Thus, if user's biometric is compromised, it might be impossible or highly difficult to replace it in a particular system. Cancellable biometric for individual biometric has been a significantly understudied problem. The concept of cancelable biometric or cancelability is to transform a biometric data or feature into a new one so that users can change their single biometric template in a biometric security system. However, cancelability in multimodal biometric has been barely addressed at all. In this paper, we tackle the problem and present a novel solution for cancelable biometrics in multimodal system. We develop a new cancelable biometric template generation algorithm using random projection and transformation-based feature extraction and selection. Performance of the proposed algorithm is validated on multi-modal face and ear database.",
Floating point HOG implementation for real-time multiple object detection,Object detection and localization in a video stream is an important requirement for almost all vision systems. In the article a design embedded into a reconfigurable device which is using the Histogram of Oriented Gradients for feature extraction and SVM classification for detecting multiple objects is presented. Superior accuracy is achieved by making all computations using single precision 32-bit floating point values in all stages of image processing. The resulting implementation is fully pipelined and there is no need for external memory. Finally a working system able to detect and localize three different classes of objects in color images with resolution 640×480 @ 60fps is presented with a computational performance above 9 GFLOPS.,"Support vector machines,
Histograms,
Field programmable gate arrays,
Table lookup,
Real-time systems,
Humans,
Object detection"
How was your day? Online visual workspace summaries using incremental clustering in topic space,"Someday mobile robots will operate continually. Day after day, they will be in receipt of a never ending stream of images. In anticipation of this, this paper is about having a mobile robot generate apt and compact summaries of its life experience. We consider a robot moving around its environment both revisiting and exploring, accruing images as it goes. We describe how we can choose a subset of images to summarise the robot's cumulative visual experience. Moreover we show how to do this such that the time cost of generating an summary is largely independent of the total number of images processed. No one day is harder to summarise than any other.",Robots
The Power of Linear Programming for Valued CSPs,"A class of valued constraint satisfaction problems (VCSPs) is characterised by a valued constraint language, a fixed set of cost functions on a finite domain. An instance of the problem is specified by a sum of cost functions from the language with the goal to minimise the sum. This framework includes and generalises well-studied constraint satisfaction problems (CSPs) and maximum constraint satisfaction problems (Max-CSPs). Our main result is a precise algebraic characterisation of valued constraint languages whose instances can be solved exactly by the basic linear programming relaxation. Using this result, we obtain tractability of several novel and previously widely-open classes of VCSPs, including problems over valued constraint languages that are: (1) sub modular on arbitrary lattices, (2) bisubmodular (also known as k-sub modular) on arbitrary finite domains, (3) weakly (and hence strongly) tree-sub modular on arbitrary trees.","Linear programming,
Cost function,
Lattices,
Robustness,
Complexity theory,
Cloning,
IP networks"
Dynamics of a Contrast Agent Microbubble Attached to an Elastic Wall,"A modified Rayleigh-Plesset equation is derived to model the oscillation of a contrast agent microbubble attached to an elastic wall. The obtained equation shows that contact with the wall affects the bubble oscillation as if the bubble oscillated in a liquid with a changed (effective) density. Depending on the wall properties, the effective density can be either higher or lower than the real liquid density and hence the natural frequency of the attached bubble can be either lower or higher than the natural frequency of the same bubble in an unbounded liquid. Numerical simulations are made for a contrast bubble with shell properties similar to those used in the Marmottant shell model. The cases of a rigid wall and a plastic wall are compared. The properties of the plastic wall are set to correspond to walls of OptiCell chambers commonly used in experiments. It is shown that contact with the rigid wall decreases the natural frequency of the bubble as compared to its natural frequency in an unbounded liquid, whereas contact with the OptiCell wall increases the natural frequency of the bubble. Bubble resonance curves for three cases are compared: the bubble in an unbounded liquid; the bubble at a distance from an OptiCell wall; the bubble in contact with an OptiCell wall. Results obtained for a 2-μm-radius bubble insonified with a 10-cycle, 40 kPa, 2.1 MHz Gaussian pulse show that contact with the OptiCell wall leads to the following effects. The amplitude of the radial oscillation of the attached bubble is decreased by about 70% as compared to that of the same bubble in an unbounded liquid. The fundamental component in the spectrum of the scattered pressure of the attached bubble is decreased by 12 dB. A strong second harmonic appears in the spectrum of the scattered pressure of the attached bubble; its magnitude is about 11.5 dB higher than the level corresponding to the case of an unbounded liquid.",
Large-scale multimedia data mining using MapReduce framework,"In this paper, the framework of MapReduce is explored for large-scale multimedia data mining. Firstly, a brief overview of MapReduce and Hadoop is presented to speed up large-scale multimedia data mining. Then, the high-level theory and low-level implementation for several key computer vision technologies involved in this work are introduced, such as 2D/3D interest point detection, clustering, bag of features, and so on. Experimental results on image classification, video event detection and near-duplicate video retrieval are carried out on a five-node Hadoop cluster to demonstrate the efficiency of the proposed MapReduce framework for large-scale multimedia data mining applications.","Feature extraction,
Multimedia communication,
Streaming media,
Data mining,
Visualization,
Training,
Event detection"
A Real-Time Vehicle Navigation Algorithm in Sensor Network Environments,"In a large-scale wireless sensor traffic network, collecting and processing of the global real-time traffic information are often unreliable. Making real-time navigation decision becomes an arduous task. To address this issue, an efficient wireless-sensor-network-based real-time vehicle navigation algorithm is proposed, in which multiple local traffic information is considered to make a navigation decision in a quick and accurate way. At the same time, a general distance metric is defined for the processing of both exact and fuzzy data. In addition, the algorithm can provide various navigation decisions according to the choice of different attributes to meet the diverse navigation requirements of drivers. Simulation results show the suitability and efficiency of the proposed algorithm.",
On the Throughput Capacity of Wireless Sensor Networks With Mobile Relays,"In wireless sensor networks (WSNs), it is difficult to achieve a large data collection rate because sensors usually have limited energy and communication resources. Such an issue is becoming increasingly more challenging with the emerging of information-intensive applications that require high data collection rate. To address this issue, in this paper, we investigate the throughput capacity of WSNs, where multiple mobile relays are deployed to collect data from static sensors and forward them to a static sink. To facilitate the discussion, we propose a new mobile-relay-assisted data collection (MRADC) model. Based on this model, we analyze the achievable throughput capacity of large-scale WSNs using a constructive approach, which can achieve a certain throughput by choosing appropriate mobility parameters. Our analysis illustrates that, if the number of relays is less than a threshold, then the throughput capacity can be linearly increased with more relays. On the other hand, if the number is greater than the threshold, then the throughput capacity becomes a constant, and the capacity gain over a static WSN depends on two factors: 1) the transmission range and 2) the impact of interference. To verify our analysis, we conduct extensive simulation experiments, which validate the selection of mobility parameters and demonstrate the same throughput behaviors obtained by analysis.",
Distributed Nonconvex Power Control using Gibbs Sampling,"Transmit power control in wireless networks has long been recognized as an effective mechanism to mitigate co-channel interference. Due to the highly non-convex nature, optimal power control is known to be difficult to achieve if a system utility is to be maximized. In our earlier paper , we have proposed a centralized optimal power control algorithm that obtains the global optimal solution for both concave and non-concave system utility functions. A question remained unanswered is whether such global optimal solution can be achieved in a distributed manner. This paper addresses the question by developing a Gibbs Sampling based Asynchronous distributed power control algorithm (referred to as GLAD). The proposed algorithm quickly converges to the global optimal solution regardless of the concavity, differentiability and monotonicity of the utility function. To further enhance the practicality of the algorithm, this paper proposes two variants of the GLAD algorithm, namely I-GLAD and NI-GLAD, to reduce message passing in two dimensions of communication complexity, i.e., time and space. In particular, I-GLAD, where the prefix ""I"" stands for Infrequent message passing, reduces the ""time overhead"" of message passing. The convergence of I-GLAD can be proved regardless of the reduction in the message passing rate. Meanwhile, NI-GLAD, where the prefix ""N"" stands for Neighborhood message passing, restricts the computation overhead related to message passing to a small neighborhood space. Our results show that the optimality of the solution obtained by NI-GLAD depends on the selection of the neighborhood size.",
Detection of obstructive sleep apnea through ECG signal features,"Obstructive sleep apnea (OSA) is a common disorder in which individuals stop breathing during their sleep. Most of sleep apnea cases are currently undiagnosed because of expenses and practicality limitations of overnight polysomnography (PSG) at sleep labs, where an expert human observer is needed to work over night. New techniques for sleep apnea classification are being developed by bioengineers for most comfortable and timely detection. In this paper, an automated classification algorithm is presented which processes short duration epochs of the electrocardiogram (ECG) data. The automated classification algorithm is based on support vector machines (SVM) and has been trained and tested on sleep apnea recordings from subjects with and without OSA. The results show that our automated classification system can recognize epochs of sleep disorders with a high degree of accuracy, approximately 96.5%. Moreover, the system we developed can be used as a basis for future development of a tool for OSA screening.",
Reliable pulse rate evaluation by smartphone,"The paper deals with the robust and reliable evaluation of the Pulse Rate (PR) with a smartphone. The smartphone camera is used to evaluate the volumetric variation of blood by monitoring the change of light absorption in the tissue. Once assessed the correct working operation, the PhotoPlethysmoGram (PPG) signal is detected and the PR is evaluated on the basis of adaptive and statistical analysis. To validate the pointed out method, the PR, evaluated by smartphone, is compared with the Ambulatory Blood Pressure monitor Spacelabs 90207, that is clinically validated medical device. The experimental results confirm the correctness and suitability of the proposed method.","Biomedical monitoring,
Cameras,
Monitoring,
Light emitting diodes,
Reliability,
Fingers,
Blood pressure"
Extensions of Fisher Information and Stam's Inequality,"We explain how the classical notions of Fisher information of a random variable and Fisher information matrix of a random vector can be extended to a much broader setting. We also show that Stam's inequality for Fisher information and Shannon entropy, as well as the more generalized versions proved earlier by the authors, are all special cases of more general sharp inequalities satisfied by random vectors. The extremal random vectors, which we call generalized Gaussians, contain Gaussians as a limiting case but are noteworthy because they are heavy-tailed.",
Highly compact 1T-1R architecture (4F2 footprint) involving fully CMOS compatible vertical GAA nano-pillar transistors and oxide-based RRAM cells exhibiting excellent NVM properties and ultra-low power operation,"For the first time, nano-meter-scaled 1T-1R non-volatile memory (NVM) architecture comprising of RRAM cells built on vertical GAA nano-pillar transistors, either junction-less or junction-based, is systematically investigated. Transistors are fabricated using fully CMOS compatible technology and RRAM cells are stacked onto the tip of the nano-pillars (with a diameter down to ∼37nm) to achieve a compact 4F2 footprint. In addition, through this platform, different RRAM stacks comprising CMOS friendly materials are studied, and it is found that TiN/Ni/HfO2/n+-Si RRAM cells show excellent switching properties in either bipolar or unipolar mode, including (1) ultra-low switching current/power: SET ∼20nA/85nW and RESET ∼200pA/700pW, (2) multi-level switchability, (3) good endurance, >105, (4) satisfactory retention, 10 years at 85oC; and (5) fast switching speed ∼50ns. Moreover, this vertical (gate-all-around) GAA nano-pillar based 1T-1R architecture provides a more direct and flexible test vehicle to verify the scalability and functionality of RRAM candidates with a dimension close to actual application.",
Towards small asymptotically near-optimal roadmaps,"An exciting recent development is the definition of sampling-based motion planners which guarantee asymptotic optimality. Nevertheless, roadmaps with this property may grow too large and lead to longer query resolution times. If optimality requirements are relaxed, existing asymptotically near-optimal solutions produce sparser graphs by removing redundant edges. Even these alternatives, however, include all sampled configurations as nodes in the roadmap. This work proposes a method, which can reject redundant samples but does provide asymptotic coverage and connectivity guarantees, while keeping local path costs low. Not adding every sample can significantly reduce the size of the final roadmap. An additional advantage is that it is possible to define a reasonable stopping criterion for the approach inspired by previous methods. To achieve these objectives, the proposed method maintains a dense graph that is used for evaluating the performance of the roadmap with regards to local path costs. Experimental results show that the method indeed provides small roadmaps, allowing for shorter query resolution times. Furthermore, smoothing the final paths results in an even more advantageous comparison against alternatives with regards to path quality.",
A New PAPR Reduction Scheme Using Efficient Peak Cancellation for OFDM Systems,"A new computationally efficient peak-to-average power ratio (PAPR) reduction scheme for orthogonal frequency division multiplexing (OFDM) signals is proposed, which utilizes the parabolic peak cancellation (PPC) using the truncated kernel signal generated from the inverse fast Fourier transform (IFFT) of the shaped peak reduction tones (PRTs). The proposed scheme only repeats peak canceling in the time domain without iteratively performing IFFT and FFT. Also, the application of the proposed PPC scheme to active constellation extension (ACE) can reduce the number of iterations of IFFT and FFT. Moreover, a transmit power allocation scheme is also suggested to relieve the degradation of bit error rate (BER) of the proposed PAPR reduction scheme. Numerical analysis shows that if the shaping parameters of PRTs are chosen properly, out-of-band (OOB) radiation and BER can be improved while the PAPR reduction performance is maintained.",
A Linked Data platform for mining software repositories,"The mining of software repositories involves the extraction of both basic and value-added information from existing software repositories. The repositories will be mined to extract facts by different stakeholders (e.g. researchers, managers) and for various purposes. To avoid unnecessary pre-processing and analysis steps, sharing and integration of both basic and value-added facts are needed. In this research, we introduce SeCold, an open and collaborative platform for sharing software datasets. SeCold provides the first online software ecosystem Linked Data platform that supports data extraction and on-the-fly inter-dataset integration from major version control, issue tracking, and quality evaluation systems. In its first release, the dataset contains about two billion facts, such as source code statements, software licenses, and code clones from 18 000 software projects. In its second release the SeCold project will contain additional facts mined from issue trackers and versioning systems. Our approach is based on the same fundamental principle as Wikipedia: researchers and tool developers share analysis results obtained from their tools by publishing them as part of the SeCold portal and therefore make them an integrated part of the global knowledge domain. The SeCold project is an official member of the Linked Data dataset cloud and is currently the eighth largest online dataset available on the Web.","Software,
Licenses,
Data mining,
Ontologies,
Communities,
Cloning,
Encyclopedias"
An Efficient Interlaced Multi-Shell Sampling Scheme for Reconstruction of Diffusion Propagators,"In this paper, we propose an interlaced multi-shell sampling scheme for the reconstruction of the diffusion propagator from diffusion weighted magnetic resonance imaging (DW-MRI). In standard multi-shell sampling schemes, sample points are uniformly distributed on several spherical shells in q-space. The distribution of sample points is the same for all shells, and is determined by the vertices of a selected polyhedron. We propose a more efficient interlaced scheme where sample points are different on alternating shells and are determined by the vertices of a pair of dual polyhedra. Since it samples more directions than the standard scheme, this method offers increased angular discrimination. Another contribution of this work is the application of optimal sampling lattices to q-space data acquisition and the proposal of a model-free reconstruction algorithm, which uses the lattice dependent sinc interpolation function. It is shown that under this reconstruction framework, the body centered cubic (BCC) lattice provides increased accuracy. The sampling scheme and the reconstruction algorithms were evaluated on simulated data as well as rat brain data collected on a 600 MHz (14.1T) Bruker imaging spectrometer.","Lattices,
Image reconstruction,
Fourier transforms,
Face,
Scattering,
Magnetic resonance imaging"
"Preliminary studies on the Good, the Bad, and the Ugly face recognition challenge problem","Face recognition has made significant advances over the last twenty years. State-of-the-art algorithms push the performance envelope to near perfect recognition rates on many face databases. Recently, the Good, the Bad, and the Ugly (GBU) face challenge problem has been introduced to focus on hard aspects of face recognition from still frontal images. In this paper, we introduce the CohortLDA baseline algorithm, which is an Linear Discriminant Analysis (LDA) algorithm with color spaces and cohort normalization. CohortLDA greatly outperforms some well known face recognition algorithms on the GBU challenge problem. The GBU protocol includes rules for creating training sets. We investigate the effect on performance of violating the rules for creating training sets. This analysis shows that violating the GBU protocol can substantially over estimate performance on the GBU challenge problem.","Training,
Face,
Face recognition,
Algorithm design and analysis,
Protocols,
Lighting,
Image color analysis"
An Energy Efficient Algrithm Based on LEACH Protocol,"In this paper, we analyse the effectiveness of LEACH protocol in extending the lifetime for energy-constrained wireless sensor networks. An improved protocol LEACH-R is proposed based on LEACH protocol. LEACH-R improves the selection of cluster-head and proposes to choose relaying node compare to LEACH. Residual energy of the nodes is considered during selection of cluster-head, possibility of low-energy nodes being selected as cluster-head is reduced. Based on both residual energy and distance to base station, relaying node is chosen from cluster-heads to become the relay node between base station and other cluster-heads. The simulation result suggests LEACH-R protocol could balance network energy consumption and extend the network life cycle more effectively.","Protocols,
Base stations,
Clustering algorithms,
Wireless sensor networks,
Mathematical model,
Steady-state,
Energy consumption"
Smolign: A Spatial Motifs-Based Protein Multiple Structural Alignment Method,"Availability of an effective tool for protein multiple structural alignment (MSTA) is essential for discovery and analysis of biologically significant structural motifs that can help solve functional annotation and drug design problems. Existing MSTA methods collect residue correspondences mostly through pairwise comparison of consecutive fragments, which can lead to suboptimal alignments, especially when the similarity among the proteins is low. We introduce a novel strategy based on: building a contact-window based motif library from the protein structural data, discovery and extension of common alignment seeds from this library, and optimal superimposition of multiple structures according to these alignment seeds by an enhanced partial order curve comparison method. The ability of our strategy to detect multiple correspondences simultaneously, to catch alignments globally, and to support flexible alignments, endorse a sensitive and robust automated algorithm that can expose similarities among protein structures even under low similarity conditions. Our method yields better alignment results compared to other popular MSTA methods, on several protein structure data sets that span various structural folds and represent different protein similarity levels. A web-based alignment tool, a downloadable executable, and detailed alignment results for the data sets used here are available at http://sacan.biomed. drexel.edu/Smolign and http://bio.cse.ohio-state.edu/Smolign.","Proteins,
Protein engineering,
Libraries,
Measurement uncertainty,
Sun,
Educational institutions,
Computer science"
Carbon Nanotube SRAM Design With Metallic CNT or Removed Metallic CNT Tolerant Approaches,"A study of an eight-transistor static random access memory (SRAM) cell and its implementation in carbon nanotube FET (CNTFET) technology are presented. Simulations of the CNTFET SRAM cell design, using a CNT SPICE model, have shown advantages over the CMOS cell in terms of static power, dynamic power, and noise margin. However, current CNT synthesis processes grow metallic CNTs alongside semiconductor CNTs. This in turn greatly degrades the performance and functionality of SRAM cells. In this paper, we present and compare two approaches to overcome the presence of metallic CNTs. The first approach tolerates metallic CNTs and uses a series of uncorrelated CNTs to form a transistor; this provides tolerance to metallic CNTs. The second approach uses an M × N array of uncorrelated CNTs to form a CNTFET and requires technologies capable of removing metallic CNTs. Both approaches have similar static noise margin. The second approach (removed metallic CNTs) consumes 1.45× more static power; on the other hand, its CNT count and write delay are reduced to 35.6% and 10.9% of the metallic tolerant approach, respectively. The realization of large memory modules in the presence of faulty SRAM cells can be achieved by having memory modules with as few as two spare columns.","CNTFETs,
Random access memory,
Delay,
CMOS integrated circuits,
Inverters,
Noise"
A Project-Based Learning Approach to Programmable Logic Design and Computer Architecture,"This paper describes a course in programmable logic design and computer architecture as it is taught at the University of Newcastle, Australia. The course is designed around a major design project and has two supplemental assessment tasks that are also described. The context of the Computer Engineering degree program within which the course is taught is presented, and some student outcomes are discussed.",
Spatio-Spectral Analysis on the Sphere Using Spatially Localized Spherical Harmonics Transform,"This correspondence studies a spatially localized spectral transform for signals on the unit sphere, which we call spatially localized spherical harmonics transform (SLSHT). For a systematic treatment, we explicitly express the transform in terms of rotated versions of an azimuthally symmetric window function and introduce the spatio-spectral SLSHT distribution with a succinct matrix representation. We present guidelines for the choice of the window function in the SLSHT, based on the inherent tradeoff between the spatial and spectral resolution of different window functions from the perspective of the uncertainty principle. We demonstrate the use of an eigenfunction window, obtained from the Slepian concentration problem on the sphere, as a good choice for window function. As an illustration, we apply the transform to the topographic map of Mars, which can reveal spatially localized spectral contributions that were not obtainable from traditional spherical harmonics analysis.",
IC-DEEP: A serious games based application to assess the ergonomics of in-vehicle information systems,"With the number of in-vehicle information systems and the complexity of their tasks growing at a very high rate in near future, we need a clear understanding of their related distraction or mental workload and its impact on driver performance. Thus, in this paper we introduce these concepts already in the development phase of a product that will be used in an in-vehicle environment. We present the IC-DEEP (In-Car Ergonomics Evaluation Platform), which is an implementation approach in form of a Serious Game (SG) to autonomously assess, under low-time and low-cost conditions, the factors that can jeopardize the driving performance when manipulating or receiving information from in-vehicle information systems (IVISs). We evaluate the feasibility of the proposed approach and draw conclusions on its effects on behavioral changes and IVIS assessment.",
Reconfigurable Linear Optical FM Discriminator,We present a reconfigurable optical discriminator filter for frequency modulated microwave-photonics link applications. The filter is based on a simplified ring-assisted Mach-Zehnder interferometer configuration. It enables conversion of a highly linear frequency to amplitude modulation. Operations in a fixed bandwidth (BW) of 30 GHz and a tunable bandwidth from 10 to 30 GHz are achieved using third- and fifth-order filters. A balanced frequency discrimination architecture with electronically reconfigurable transfer characteristics is demonstrated. We measured a output-third order intercept point (OIP3) linearity improvement over that of a dual-output Mach-Zehnder.,"Frequency modulation,
Microwave filters,
Optical fibers,
Optical fiber filters,
Optical distortion"
Practical application and evaluation of no-SQL databases in Cloud Computing,"Nowadays, more and more data are created every day. To process time-series data in real time, many organizations are looking beyond the traditional data warehouse solutions and into emerging big-data technologies such as open source Map-Reduce frameworks or no-SQL databases. In this project, we develop an application which follows a keyword over multiple social media platforms (e.g. Twitter, Facebook), maintaining the aggregated data in a no-SQL database. Afterwards, in order to choose the most suitable system for our application, we will analyze the no_SQL database systems, define their architecture and data model, and depending on our needs, choose the appropriate one.","Data models,
Facebook,
Servers,
Twitter,
File systems,
Relational databases"
Software Pipelining for Stream Programs on Resource Constrained Multicore Architectures,"Stream programming model has been productively applied to a number of important application domains. Software pipelining is an important code scheduling technique for stream programs. However, the multicore evolution has presented a new dimension of challenges: that is how to orchestrate the best software pipelining schedule in the face of resource constrained architectures (e.g., number of cores, available memory, and bandwidth)? In this paper, we proposed a new solution methodology to address the problem above. Our main contributions include the following. A unified Integer Linear Programming (ILP) formulation has been proposed that combines the requirement of both rate-optimal software pipelining and the minimization of intercore communication overhead. Next, an extended formulation has been proposed to formulate the schedule under memory size constrained systems. It orchestrates the rate-optimal software pipelining execution for stream programs with strict memory, processor cores, and communication constraints. A solution testbed has been implemented for the proposed problem formulations. This has been realized by extending the Brook programming environment with our software pipelining support-named DFBrook. An experimental study has been conducted to verify the effectiveness of the proposed solutions.","Schedules,
Resource management,
Pipeline processing,
Memory management,
Multicore processing"
A systems approach to photovoltaic energy extraction,"Per-panel photovoltaic energy extraction with integrated converters can increase overall array tracking efficiency. Also, switched-capacitor (SC) converters have been evaluated for many applications because of the possibility for on-chip integration; applications to solar arrays are no exception. This paper presents a comprehensive system-level look at solar installations, finding possibilities for optimization at and between all levels of operation in an array. Specifically, this paper examines new arrangements and options for applying switched-capacitor circuits at 3 levels: for the panel and sub-panel level, as part of the overall control strategy, and for ensuring stable and robust interface to the grid with the possibility of eliminating or reducing the use of electrolytic capacitors.",
"A Comparative Study of Graph-Based, Eikonal, and Monodomain Simulations for the Estimation of Cardiac Activation Times","The bidomain and monodomain equations are well established as the standard set of equations for the simulation of cardiac electrophysiological behavior. However, the computational cost of detailed bidomain/monodomain simulations limits their applicability in scenarios where a large number of simulations needs to be performed (e.g., parameter estimation). In this study, we present a graph-based method, which relies on point-to-point path finding to estimate activation times for single points in cardiac tissue with minimal computational costs. To validate our approach, activation times are compared to monodomain simulation results for an anatomically based rabbit ventricular model, incorporating realistic fiber orientation and conduction heterogeneities. Differences in activation times between the graph-based method and monodomain results are less than 10% of the total activation time, and computational performance is orders of magnitude faster with the proposed method when calculating activation times at single points. These results suggest that the graph-based method is well suited for estimating activation times when the need for fast performance justifies a limited loss of accuracy.",
Resource configurable spoken query detection using Deep Boltzmann Machines,"In this paper we present a spoken query detection method based on posteriorgrams generated from Deep Boltzmann Machines (DBMs). The proposed method can be deployed in both semi-supervised and unsupervised training scenarios. The DBM-based posteriorgrams were evaluated on a series of keyword spotting tasks using the TIMIT speech corpus. In unsupervised training conditions, the DBM-approach improved upon our previous best unsupervised keyword detection performance using Gaussian mixture model-based posteriorgrams by over 10%. When limited amounts of labeled data were incorporated into training, the DBM-approach required less than one third of the annotated data in order to achieve a comparable performance of a system that used all of the annotated data for training.",
Autonomous recovery from multi-node failure in Wireless Sensor Network,"Wireless Sensor Networks (WSNs) often serve mission-critical applications in inhospitable environments such as battlefield and territorial borders. Inter-node communication is essential for WSNs to effectively fulfill their tasks. In hostile setups, the WSN may be subject to damage that breaks the network connectivity and disrupts the application. The network must be able to recover from the failure and restore connectivity so that the designated tasks can be carried out. Given the unattended operation of the network, the recovery should be performed autonomously. In this paper we present a distributed algorithm for Autonomous Repair (AuR) of damaged WSN topologies in the event of multiple node failures. AuR models connectivity between neighboring nodes as electrostatic interaction between charges based on Coulomb's law. The recovery process is initiated locally at the neighbors of failed nodes by moving in the direction of loss to reconnect with other nodes. The performance of AuR is validated through simulation.","wireless sensor networks,
telecommunication network reliability,
telecommunication network topology"
Accuracy enhancement of distributed irregularities estimation in optical fiber,The model operation results of the Brillouin Backscattering effect on the distributed irregularities in fiber-optical communication links are given in this paper.,"stimulated Brillouin scattering,
backscatter,
optical fibre networks,
optical fibre theory,
optical links"
Velo: A Knowledge-Management Framework for Modeling and Simulation,"Velo is a reusable, domain-independent knowledge-management infrastructure for modeling and simulation. Velo leverages, integrates, and extends Web-based open source collaborative and data-management technologies to create a scalable and flexible core platform tailored to specific scientific domains. As the examples here describe, Velo has been used in both the carbon sequestration and climate modeling domains.",
Supervised and Unsupervised Parallel Subspace Learning for Large-Scale Image Recognition,"Subspace learning is an effective and widely used image feature extraction and classification technique. However, for the large-scale image recognition issue in real-world applications, many subspace learning methods often suffer from large computational burden. In order to reduce the computational time and improve the recognition performance of subspace learning technique under this situation, we introduce the idea of parallel computing which can reduce the time complexity by splitting the original task into several subtasks. We develop a parallel subspace learning framework. In this framework, we first divide the sample set into several subsets by designing two random data division strategies that are equal data division and unequal data division. These two strategies correspond to equal and unequal computational abilities of nodes under parallel computing environment. Next, we calculate projection vectors from each subset in parallel. The graph embedding technique is employed to provide a general formulation for parallel feature extraction. After combining the extracted features from all nodes, we present a unified criterion to select most distinctive features for classification. Under the developed framework, we separately propose supervised and unsupervised parallel subspace learning approaches, which are called parallel linear discriminant analysis (PLDA) and parallel locality preserving projection (PLPP). PLDA selects features with the largest Fisher scores by estimating the weighted and unweighted sample scatter, while PLPP selects features with the smallest Laplacian scores by constructing a whole affinity matrix. Theoretically, we analyze the time complexities of proposed approaches and provide the fundamental supports for applying random division strategies. In the experiments, we establish two real parallel computing environments and employ four public image and video databases as the test data. Experimental results demonstrate that the proposed approaches outperform several related supervised and unsupervised subspace learning methods, and significantly reduce the computational time.","Feature extraction,
Principal component analysis,
Vectors,
Learning systems,
Training,
Parallel processing,
Linear discriminant analysis"
Data-Driven Cluster Reinforcement and Visualization in Sparsely-Matched Self-Organizing Maps,"A self-organizing map (SOM) is a self-organized projection of high-dimensional data onto a typically 2-dimensional (2-D) feature map, wherein vector similarity is implicitly translated into topological closeness in the 2-D projection. However, when there are more neurons than input patterns, it can be challenging to interpret the results, due to diffuse cluster boundaries and limitations of current methods for displaying interneuron distances. In this brief, we introduce a new cluster reinforcement (CR) phase for sparsely-matched SOMs. The CR phase amplifies within-cluster similarity in an unsupervised, data-driven manner. Discontinuities in the resulting map correspond to between-cluster distances and are stored in a boundary (B) matrix. We describe a new hierarchical visualization of cluster boundaries displayed directly on feature maps, which requires no further clustering beyond what was implicitly accomplished during self-organization in SOM training. We use a synthetic benchmark problem and previously published microbial community profile data to demonstrate the benefits of the proposed methods.","Neurons,
Vectors,
Heating,
Image segmentation,
Data visualization,
Clustering algorithms,
Animals"
VaMV: Variability-aware Memory Virtualization,"Power consumption variability of both on-chip SRAMs and off-chip DRAMs is expected to continue to increase over the next decades. We opportunistically exploit this variability through a novel Variability-aware Memory Virtualization (VaMV) layer that allows programmers to partition their application's address space (through annotations) into virtual address regions and create mapping policies for each region. Each policy has different requirements (e.g., power, fault-tolerance) and is exploited by our dynamic memory management module (VaMVisor), which adapts to the underlying hardware, prioritizes the memory resources according to their characteristics (e.g., power consumption), and selectively maps data to the best-fitting memory resource (e.g., high-utilization data to low-power memory space). Our experimental results on embedded benchmarks show that VaMV is capable of reducing dynamic power consumption by 63% on average while reducing total execution time by an average of 34% by exploiting: 1) SRAM voltage scaling, 2) DRAM power variability, and 3) Efficient dynamic policy-driven variability-aware memory allocation.","Random access memory,
Memory management,
Power demand,
System-on-a-chip,
Resource management,
Hardware,
Dynamic scheduling"
Classification of Upper Limb Motion Trajectories Using Shape Features,"To understand and interpret human motion is a very active research area nowadays because of its importance in sports sciences, health care, and video surveillance. However, classification of human motion patterns is still a challenging topic because of the variations in kinetics and kinematics of human movements. In this paper, we present a novel algorithm for automatic classification of motion trajectories of human upper limbs. The proposed scheme starts from transforming 3-D positions and rotations of the shoulder/elbow/wrist joints into 2-D trajectories. Discriminative features of these 2-D trajectories are, then, extracted using a probabilistic shape-context method. Afterward, these features are classified using a k-means clustering algorithm. Experimental results demonstrate the superiority of the proposed method over the state-of-the-art techniques.","Motion control,
Trajectory,
Feature extraction,
Human factors,
Vectors,
Biomedical measurements"
Sparse representation for face recognition based on discriminative low-rank dictionary learning,"In this paper, we propose a discriminative low-rank dictionary learning algorithm for sparse representation. Sparse representation seeks the sparsest coefficients to represent the test signal as linear combination of the bases in an over-complete dictionary. Motivated by low-rank matrix recovery and completion, assume that the data from the same pattern are linearly correlated, if we stack these data points as column vectors of a dictionary, then the dictionary should be approximately low-rank. An objective function with sparse coefficients, class discrimination and rank minimization is proposed and optimized during dictionary learning. We have applied the algorithm for face recognition. Numerous experiments with improved performances over previous dictionary learning methods validate the effectiveness of the proposed algorithm.",
On the Mechanism of Current Pulse Propagation Along Conical Structures: Application to Tall Towers Struck by Lightning,"We discuss in this paper the propagation of lightning current pulses along conical tall structures. Although the dominant mode of an infinitely long conical transmission line is transverse electric and magnetic (TEM), such a structure can also support higher order TE and TM modes which display a gradual cutoff frequency variation with height. Recently, Baba and Rakov's finite-difference time domain numerical analysis revealed that for a perfectly conducting conical structure, while the current pulses suffer no attenuation as they travel from the cone's apex to its base, the attenuation is significant when pulses propagate from the base to the apex. Adopting an analysis method using 1) the COMSOL Multiphysics simulation environment based on the finite element method and 2) the partial equivalent element circuit method, we study the same reduced-scale structure analyzed by Baba and Rakov. The obtained results confirm the conclusions drawn by Baba and Rakov. We also perform simulations for the case of a 100-m tall tower considering different tower-base radii. It is shown that the upward current pulses are affected by a strong attenuation resulting from the field scattering near the discontinuity at the tower base, followed by a weaker attenuation resulting from the propagation along the cone from its base to the apex. A simple way to modify the engineering lightning return stroke models to account for the attenuation of the upward current pulses is suggested. Finally, we report on experiments to study the current pulse propagation along a 1/582 reduced scale model of the Toronto, CN, tower. The obtained experimental data support the numerical simulations.",
SLC: Split-control Level Converter for dense and stable wide-range voltage conversion,"Ultra-low voltage design makes signal level conversion a critical component in modern low power designs. This paper proposes a static level converter operating in the subthreshold regime, called SLC (Split-control Level Converter). Using a novel circuit structure, SLC effectively eliminates the high leakage and short circuit currents in previous approaches. Designed for 300mV to 2.5V conversion and fabricated in 130nm CMOS, measured results show 2.3×, 9.9×, and 5.9× improvements over conventional DCVS structures in delay, static power, and energy per transition, respectively. Even with the smallest area among wide-range level converters, it also has 5.2× smaller standard deviation in delay and only 5.6% change in FO4 delay with 10% VDDL drop, demonstrating robustness.","Delay,
Temperature measurement,
Robustness,
CMOS integrated circuits,
Temperature distribution,
Synchronization,
Temperature dependence"
Bandwidth Extension of Telephone Speech to Low Frequencies Using Sinusoidal Synthesis and a Gaussian Mixture Model,"The quality of narrowband telephone speech is degraded by the limited audio bandwidth. This paper describes a method that extends the bandwidth of telephone speech to the frequency range 0-300 Hz. The method generates the lowest harmonics of voiced speech using sinusoidal synthesis. The energy in the extension band is estimated from spectral features using a Gaussian mixture model. The amplitudes and phases of the synthesized sinusoidal components are adjusted based on the amplitudes and phases of the narrowband input speech, which provides adaptivity to varying input bandwidth characteristics. The proposed method was evaluated with listening tests in combination with another bandwidth extension method for the frequency range 4-8 kHz. While the low-frequency bandwidth extension was not found to improve perceived quality, the method reduced dissimilarity with wideband speech.","Speech,
Narrowband,
Harmonic analysis,
Speech processing,
Wideband,
Educational institutions"
Pseudorandomness from Shrinkage,"One powerful theme in complexity theory and pseudorandomness in the past few decades has been the use lower bounds to give pseudorandom generators (PRGs). However, the general results using this hardness vs. randomness paradigm suffer a quantitative loss in parameters, and hence do not give nontrivial implications for models where we don't know superpolynomial lower bounds but do know lower bounds of a fixed polynomial. We show that when such lower bounds are proved using random restrictions, we can construct PRGs which are essentially best possible without in turn improving the lower bounds. More specifically, say that a circuit family has shrinkage exponent Γ if a random restriction leaving a p fraction of variables unset shrinks the size of any circuit in the family by a factor of pΓ+o(1). Our PRG uses a seed of length s1/(Γ+1)+o(1) to fool circuits in the family of size s. By using this generic construction, we get PRGs with polynomially small error for the following classes of circuits of size s and with the following seed lengths: 1) For de Morgan formulas, seed length s1/3+o(1); 2) For formulas over an arbitrary basis, seed length s1/2+o(1); 3) For read-once de Morgan formulas, seed length s.234...; 4) For branching programs of size s, seed length s1/2+o(1). The previous best PRGs known for these classes used seeds of length bigger than n/2 to output n bits, and worked only when the size s = O(n) [1].","Generators,
Computational modeling,
Random variables,
Complexity theory,
Polynomials,
Integrated circuit modeling,
Input variables"
Effect of stealthy bad data injection on network congestion in market based power system,"In a smart grid, the strong coupling between cyber and physical operations makes power systems vulnerable to cyber attacks. Changing the traditional structure of power systems and integrating communication devices are beneficial for better monitoring and decisionmaking by System Operators but increases the chance of being maliciously attacked. The communication links can be hacked so that the attacker can alter the power flow and power injection measurements, which are used to estimate the states of power system. In this paper, we formulate an attack strategy that can change the congestion of transmission lines without being detectable. Moreover, the financial benefit in an Ex-Post market is also investigated. Simulation results on an IEEE 30-Bus test system shows both the changes of congestion and the potential financial benefit gained by an attacker.",
A network-based interface for the exploration of high-dimensional data spaces,"The navigation of high-dimensional data spaces remains challenging, making multivariate data exploration difficult. To be effective and appealing for mainstream application, navigation should use paradigms and metaphors that users are already familiar with. One such intuitive navigation paradigm is interactive route planning on a connected network. We have employed such an interface and have paired it with a prominent high-dimensional visualization paradigm showing the N-D data in undistorted raw form: parallel coordinates. In our network interface, the dimensions form nodes that are connected by a network of edges representing the strength of association between dimensions. A user then interactively specifies nodes/edges to visit, and the system computes an optimal route, which can be further edited and manipulated. In our interface, this route is captured by a parallel coordinate data display in which the dimension ordering is configured by the specified route. Our framework serves both as a data exploration environment and as an interactive presentation platform to demonstrate, explain, and justify any identified relationships to others. We demonstrate our interface within a business scenario and other applications.","Correlation,
Measurement,
Layout,
Navigation,
Springs,
Data visualization,
Clutter"
Designing Router Scheduling Policies: A Privacy Perspective,"We study the privacy compromise due to a queuing side channel which arises when a resource is shared between two users in the context of packet networks. The adversary tries to learn about the legitimate user's activities by sending a small but frequent probe stream to the shared resource (e.g., a router). We show that for current frequently used scheduling policies, the waiting time of the adversary is highly correlated with traffic pattern of the legitimate user, thus compromising user privacy. Through precise modeling of the constituent flows and the scheduling policy of the shared resource, we develop a dynamic program to compute the optimal privacy preserving policy that minimizes the correlation between user's traffic and adversary's waiting times. While the explosion of state-space for the problem prohibits us from characterizing the optimal policy, we derive a suboptimal policy using a myopic approximation to the problem. Through simulation results, we show that indeed the suboptimal policy does very well in the high traffic regime. Adapting the intuition from the myopic policy, we propose scheduling policies that demonstrate good tradeoff between privacy and delay in the low and medium traffic regime as well.","Correlation,
Probes,
Delay,
Processor scheduling,
Computers,
DSL"
Assurance of Energy Efficiency and Data Security for ECG Transmission in BASNs,"With the technological advancement in body area sensor networks (BASNs), low cost high quality electrocardiographic (ECG) diagnosis systems have become important equipment for healthcare service providers. However, energy consumption and data security with ECG systems in BASNs are still two major challenges to tackle. In this study, we investigate the properties of compressed ECG data for energy saving as an effort to devise a selective encryption mechanism and a two-rate unequal error protection (UEP) scheme. The proposed selective encryption mechanism provides a simple and yet effective security solution for an ECG sensor-based communication platform, where only one percent of data is encrypted without compromising ECG data security. This part of the encrypted data is essential to ECG data quality due to its unequally important contribution to distortion reduction. The two-rate UEP scheme achieves a significant additional energy saving due to its unequal investment of communication energy to the outcomes of the selective encryption, and thus, it maintains a high ECG data transmission quality. Our results show the improvements in communication energy saving of about 40%, and demonstrate a higher transmission quality and security measured in terms of wavelet-based weighted percent root-mean-squared difference.","Electrocardiography,
Encryption,
Encoding,
Energy consumption,
Electronic mail"
Quantum polar codes for arbitrary channels,"We construct a new entanglement-assisted quantum polar coding scheme which achieves the symmetric coherent information rate by synthesizing “amplitude” and “phase” channels from a given, arbitrary quantum channel. We first demonstrate the coding scheme for arbitrary quantum channels with qubit inputs, and we show that quantum data can be reliably decoded by O(N) rounds of coherent quantum successive cancellation, followed by N controlled-NOT gates (where N is the number of channel uses). We also find that the entanglement consumption rate of the code vanishes for degradable quantum channels. Finally, we extend the coding scheme to channels with multiple qubit inputs. This gives a near-explicit method for realizing one of the most striking phenomena in quantum information theory: the superactivation effect, whereby two quantum channels which individually have zero quantum capacity can have a non-zero quantum capacity when used together.","Encoding,
Decoding,
Quantum entanglement,
Protocols,
Logic gates,
Receivers"
A Model of Data Warehousing Process Maturity,"Even though data warehousing (DW) requires huge investments, the data warehouse market is experiencing incredible growth. However, a large number of DW initiatives end up as failures. In this paper, we argue that the maturity of a data warehousing process (DWP) could significantly mitigate such large-scale failures and ensure the delivery of consistent, high quality, “single-version of truth” data in a timely manner. However, unlike software development, the assessment of DWP maturity has not yet been tackled in a systematic way. In light of the critical importance of data as a corporate resource, we believe that the need for a maturity model for DWP could not be greater. In this paper, we describe the design and development of a five-level DWP maturity model (DWP-M) over a period of three years. A unique aspect of this model is that it covers processes in both data warehouse development and operations. Over 20 key DW executives from 13 different corporations were involved in the model development process. The final model was evaluated by a panel of experts; the results strongly validate the functionality, productivity, and usability of the model. We present the initial and final DWP-M model versions, along with illustrations of several key process areas at different levels of maturity.","Data warehouses,
Business,
Warehousing,
Software,
Programming,
Data mining,
Standards organizations"
Cross-layer design of energy efficient coded ARQ systems,"The energy efficient design of coded automatic-repeat-request (ARQ) systems is studied in this paper. The optimization aims to minimize the energy required for the successfully delivery of one information bit from a transmitter to a receiver. The design is performed by incorporating a wide range of practical system parameters and metrics, such as hardware power consumption, modulation, channel coding, and frame error rate (FER) in the physical layer, and frame length and protocol overhead in the media access control layer. A new log-domain threshold approximation method is proposed to analytically quantify the impacts of the various system parameters on the FER, and the results are used to facilitate the system design. The optimum transmission energy and frame length that minimize the energy per information bit are identified in closed-form expressions as functions of the various practical system parameters. The analytical and simulation results demonstrate that the total energy consumption in a coded ARQ system can be reduced by increasing the transmission energy during one transmission attempt, and significant energy saving as high as 9.5 dB is achieved with the optimum system.","radio transmitters,
access protocols,
automatic repeat request,
channel coding,
error statistics,
modulation,
power consumption,
radio receivers"
Constructing Multiple Kernel Learning Framework for Blast Furnace Automation,"This paper constructs the framework of the reproducing kernel Hilbert space for multiple kernel learning, which provides clear insights into the reason that multiple kernel support vector machines (SVM) outperform single kernel SVM. These results can serve as a fundamental guide to account for the superiority of multiple kernel to single kernel learning. Subsequently, the constructed multiple kernel learning algorithms are applied to model a nonlinear blast furnace system only based on its input-output signals. The experimental results not only confirm the superiority of multiple kernel learning algorithms, but also indicate that multiple kernel SVM is a kind of highly competitive data-driven modeling method for the blast furnace system and can provide reliable indication for blast furnace operators to take control actions.","Kernel,
Support vector machines,
Blast furnaces,
Quadratic programming,
Hilbert space,
Input variables"
The Challenge of Estimating Video Quality in Video Communication Applications [In the Spotlight],"Video communication over the Internet has gone from science fiction to reality. Not only is video streaming and two-way video conferencing becoming common, but, as recently reported by the Associated Press through ABC News [1], today even broadcast television programs such as eyewitness news often use live video from camera phones or Skype on a notebook or desktop computer to interview people and share information. A desired goal in these scenarios is to ensure the best video quality possible. This leads to the challenge of estimating video quality as a key step to achieving the above. This article's goal is to describe the need for video quality estimation and why it is challenging as well as highlight the different types of video quality estimators (VQEs) being developed. Signal processing is viewed as critical throughout this work.","Streaming media,
Estimation,
Loss measurement,
Monitoring,
Propagation losses,
Accuracy,
Image coding"
Task allocation with executable coalitions in multirobot tasks,"In our prior work, we proposed the IQ-ASyMTRe architecture with a measure of information quality to reason about forming coalitions in multirobot tasks. The formed coalitions are guaranteed to be executable, given the current configurations of the robots and environment. A cost and a quality measure are associated with each coalition to further determine its utility for the task. In this paper, we show that IQ-ASyMTRe-like architectures can be utilized to significantly reduce the overall complexity of task allocation by considering only executable coalitions. For implementation, we apply a layering technique such that most existing methods for task allocation can be easily incorporated. Furthermore, we introduce a general process to address situations in which no executable coalitions are available for certain tasks, and integrate it with IQ-ASyMTRe to achieve more autonomy. Such an approach is able to autonomously decompose unsatisfied preconditions of the required task behaviors into satisfiable components, in order to generate partial order plans for them accordingly. We show how this process can be implemented using a market-based approach. Simulation results are provided to demonstrate these techniques.","Resource management,
Robot kinematics,
Robot sensing systems,
Current measurement,
Complexity theory"
MARVEL: A wireless Miniature Anchored Robotic Videoscope for Expedited Laparoscopy,"This paper describes the design and implementation of a Miniature Anchored Robotic Videoscope for Expedited Laparoscopy (MARVEL) and Camera Module (CM) that features wireless communications and control. The CM decreases the surgical-tool bottleneck experienced by surgeons in state-of-the art Laparoscopic Endoscopic Single-Site (LESS) procedures for minimally invasive abdominal surgery. The system includes: (1) a near-zero latency video wireless communications link, (2) a pan/tilt camera platform, actuated by two motors that provides surgeons a full hemisphere field of view inside the abdominal cavity, (3) a small wireless camera, (4) a wireless illumination control system, and (5) a wireless human-machine interface (HMI) to control the CM. An in-vivo experiment on a porcine subject was carried out to test the performance of the system. The robotic design is a Research Platform for a broad range of experiments in a range of domains for faculty and students in the Colleges of Engineering and Medicine and at Tampa General Hospital. This research is the first step in developing semi-autonomous wirelessly controlled and networked laparoscopic devices to enable a paradigm shift in minimally invasive surgery and other domains such as Wireless Body Area Networks.","Wireless communication,
Cameras,
Surgery,
Communication system security,
Light emitting diodes,
Robot vision systems,
Wireless sensor networks"
Generalized opposition-based artificial bee colony algorithm,"The Artificial Bee Colony (ABC) algorithm is a relatively new algorithm for function optimization. The algorithm is inspired by the foraging behavior of honey bees. In this work, the performance of ABC is enhanced by introducing the concept of generalized opposition-based learning. This concept is introduced through the initialization step and through generation jumping. The performance of the proposed generalized opposition-based ABC (GOABC) is compared to the performance of ABC and opposition-based ABC (OABC) using the CEC05 benchmarks library.",
Highly Efficient White Light-Emitting Diodes Based on Quantum Dots and Polymer Interface,"We proposed a novel white-light-emitting diode (LED) using the hybridization of quantum dots (QDs) blended with poly(9, 9-dioctylfluorenyl-2, 7-diyl) (PFO) as the white emissive layer and poly(N-vinylcarbazole) (PVK) blended with poly(N, N' -bis (4-butylphenyl)-N, N'-bis(phenyl) benzidine (poly-TPD) as the hole transport layer (HTL). The red- and green-colored QDs with CdSe and ZnS core and shell structure were mixed with blue emissive PFO to form a hybrid emissive layer, and this layer generated pure white light. We analyzed the performance characteristics of the white-LED and the function of the HTL comprising poly-TPD doped with PVK; the use of this blend led to increased efficiency of the device via the creation of one more assisting energy step in the HTL. Consequently, our white-LED exhibited a luminance of 1,163 cd/m2 and an efficiency of 1.01 cd/A at a CIE 1931 chromaticity of (0.33, 0.36).","Light emitting diodes,
Quantum dots,
Performance evaluation,
Polymers,
Green products,
Color"
The adversarial joint source-channel problem,"This paper introduces the problem of joint source-channel coding in the setup where channel errors are adversarial and the distortion is worst case. Unlike the situation in the case of stochastic source-channel model, the separation principle does not hold in adversarial setup. This surprising observation demonstrates that designing good distortion-correcting codes cannot be done by serially concatenating good covering codes with good error-correcting codes. The problem of the joint code design is addressed and some initial results are offered.","Decoding,
Channel coding,
Error correction codes,
Joints,
Stochastic processes,
Manganese"
Recognizing Emotions From an Ensemble of Features,"This paper details the authors' efforts to push the baseline of emotion recognition performance on the Geneva Multimodal Emotion Portrayals (GEMEP) Facial Expression Recognition and Analysis database. Both subject-dependent and subject-independent emotion recognition scenarios are addressed in this paper. The approach toward solving this problem involves face detection, followed by key-point identification, then feature generation, and then, finally, classification. An ensemble of features consisting of hierarchical Gaussianization, scale-invariant feature transform, and some coarse motion features have been used. In the classification stage, we used support vector machines. The classification task has been divided into person-specific and person-independent emotion recognitions using face recognition with either manual labels or automatic algorithms. We achieve 100% performance for the person-specific one, 66% performance for the person-independent one, and 80% performance for overall results, in terms of classification rate, for emotion recognition with manual identification of subjects.","Feature extraction,
Vectors,
Face,
Emotion recognition,
Training,
Face recognition,
Mercury (metals)"
Algorithmic Bricks: A Tangible Robot Programming Tool for Elementary School Students,"Tangible programming tools enable children to easily learn the programming process, previously considered to be difficult for them. While various tangible programming tools have been developed, there is still a lack of available tools to help students experience the general programming process. This study therefore developed a tool called Algorithmic Bricks (A-Bricks), to improve the programming language experience by considering and utilizing characteristics of procedural language. Specifically, elements such as sequence, repetition, condition, function, and parameter were used to develop A-Bricks. In addition, this study observed the benefits of A-Bricks and confirmed its potential as a tangible educational programming tool by comparing and analyzing elementary school students using A-Bricks to control groups using Scratch.","Programming profession,
Robots,
Usability,
Joining processes,
User interfaces,
Debugging"
Double-Blind Data Discovery Using Double Cross for Large-Scale Wireless Sensor Networks With Mobile Sinks,"Large-scale wireless sensor networks (WSNs) with mobile sinks present new challenges on data discovery because the locations of the mobile sinks cannot be predetermined. In this paper, we study the double-blind data discovery problem in a WSN, where the mobile sink(s) and the sensed data do not know the locations of each other a priori. To address this problem, we first propose a Random Line Walk (RLW) mechanism for message forwarding, and based on this forwarding mechanism, we further propose an efficient data discovery mechanism called Double Cross. Double Cross exploits a simple geometric property of a planar, i.e., for a couple of pairs of orthogonal lines in a planar, the probability that they intersect within the planar is larger than 99%. However, it does not depend on the geographic location or directional information on a node, which is difficult to obtain in such networks. Instead, each sensor node only needs to know the distances between the neighbor nodes within its transmission range. Analytical and simulation results show that Double Cross can achieve a higher successful discovery rate with lower energy consumption, compared existing work.","Mobile communication,
Wireless sensor networks,
Floods,
Trajectory,
Energy consumption,
Protocols,
Mobile computing"
Learning grasp stability,"We deal with the problem of blind grasping where we use tactile feedback to predict the stability of a robotic grasp given no visual or geometric information about the object being grasped. We first simulated tactile feedback using a soft finger contact model in GraspIt! [1] and computed tactile contacts of thousands of grasps with a robotic hand using the Columbia Grasp Database [2]. We used the K-means clustering method to learn a contact dictionary from the tactile contacts, which is a codebook that models the contact space. The feature vector for a grasp is a histogram computed based on the distribution of its contacts over the contact space defined by the dictionary. An SVM is then trained to predict the stability of a robotic grasp given this feature vector. Experiments indicate that this model which requires low-dimension feature input is useful in predicting the stability of a grasp.","Grasping,
Tactile sensors,
Vectors,
Stability analysis,
Friction"
Low Power Programmable Current Mode Computational Imaging Sensor,"A linear current mode computational image sensor is presented in this paper. The sensor monolithically combines current mode imaging elements with current mode digitally programmable analog computational circuitry at the focal plane. The pixel is based on a switchless paradigm and allows for reduced spatial and temporal noise imaging. The imaging array is composed of 128-by-109 pixels. The image sensor provides a noise-corrected image in conjunction with a convolved image in parallel at 50 fps and 50 mW. The maximum measured SNR is 44 dB, maximum FPN of saturated value (after DDS) is 0.22%, and DR is 55 dB.",
Performance analysis and terrain classification for a legged robot over rough terrain,"Minimally actuated millirobotic crawlers navigate unreliably over uneven terrain-even when designed with inherent stability-mostly because of manufacturing variabilities and a lack of good models for ground interaction. In this paper, we investigate the performance of a legged robot as it traverses three distinct rough terrains: tile, carpet, and gravel. Furthermore, we present an accurate, robust, low-lag, and efficient algorithm for terrain classification that uses vibration data from the on-board inertial measurement unit and motor control data from back-EMF sensing and magnetic encoders.","Legged locomotion,
Robot sensing systems,
Tiles,
Accuracy"
Street-to-shop: Cross-scenario clothing retrieval via parts alignment and auxiliary set,"In this paper, we address a practical problem of cross-scenario clothing retrieval - given a daily human photo captured in general environment, e.g., on street, finding similar clothing in online shops, where the photos are captured more professionally and with clean background. There are large discrepancies between daily photo scenario and online shopping scenario. We first propose to alleviate the human pose discrepancy by locating 30 human parts detected by a well trained human detector. Then, founded on part features, we propose a two-step calculation to obtain more reliable one-to-many similarities between the query daily photo and online shopping photos: 1) the within-scenario one-to-many similarities between a query daily photo and the auxiliary set are derived by direct sparse reconstruction; and 2) by a cross-scenario many-to-many similarity transfer matrix inferred offline from an extra auxiliary set and the online shopping set, the reliable cross-scenario one-to-many similarities between the query daily photo and all online shopping photos are obtained. We collect a large online shopping dataset and a daily photo dataset, both of which are thoroughly labeled with 15 clothing attributes via Mechanic Turk. The extensive experimental evaluations on the collected datasets well demonstrate the effectiveness of the proposed framework for cross-scenario clothing retrieval.","Clothing,
Humans,
Image reconstruction,
Feature extraction,
Reliability,
Image color analysis,
Sparse matrices"
A Comparison of Snow Depth on Sea Ice Retrievals Using Airborne Altimeters and an AMSR-E Simulator,"A comparison of snow depths on sea ice was made using airborne altimeters and an Advanced Microwave Scanning Radiometer for the Earth Observing System (AMSR-E) simulator. The data were collected during the March 2006 National Aeronautics and Space Administration (NASA) Arctic field campaign utilizing the NASA P-3B aircraft. The campaign consisted of an initial series of coordinated surface and aircraft measurements over Elson Lagoon, Alaska and adjacent seas followed by a series of large-scale (100 km × 50 km) coordinated aircraft and AMSR-E snow depth measurements over portions of the Chukchi and Beaufort seas. This paper focuses on the latter part of the campaign. The P-3B aircraft carried the University of Colorado Polarimetric Scanning Radiometer (PSR-A), the NASA Wallops Airborne Topographic Mapper (ATM) lidar altimeter, and the University of Kansas Delay-Doppler (D2P) radar altimeter. The PSR-A was used as an AMSR-E simulator, whereas the ATM and D2P altimeters were used in combination to provide an independent estimate of snow depth. Results of a comparison between the altimeter-derived snow depths and the equivalent AMSR-E snow depths using PSR-A brightness temperatures calibrated relative to AMSR-E are presented. Data collected over a frozen coastal polynya were used to intercalibrate the ATM and D2P altimeters before estimating an altimeter snow depth. Results show that the mean difference between the PSR and altimeter snow depths is -2.4 cm (PSR minus altimeter) with a standard deviation of 7.7 cm. The RMS difference is 8.0 cm. The overall correlation between the two snow depth data sets is 0.59.","Snow,
Sea ice,
Sea measurements,
NASA,
Microwave radiometry,
Aircraft"
"Analysis of Power Characteristics for Sap Flow, Soil Moisture, and Soil Water Potential Sensors in Wireless Sensor Networking Systems","While wireless sensor networks (WSNs) become more popular as a tool for scientists and engineers in environmental monitoring, the energy efficiency of WSN's primary unit, the mote, is increasingly critical. Motes perform communication and processing functions and also take measurements using limited onboard battery power. For environmental monitoring deployment, sampling rates need to be assigned to motes such that useful information can be extracted over both spatial and temporal scales. The data sampling rate, which is intimately related to data transmission rate, plays an important role in the mote's battery life. Moreover, while it has been noted that mote operation continues under less than optimal power supply levels, data collected during this time undergoes attenuation from the desired measurement. That is, low battery conditions of motes could significantly affect the accuracy of sensed data. This paper investigates the above two issues to achieve extended battery life for individual wireless motes while maintaining sampling adequacy and reliability in transmitting accurate data. We first study how different sensor characteristics, such as different types of sap flow sensors, can affect motes' sampling and transmission rate. Then, we examine the effect of sensing attenuation due to low battery power on sap flow, soil moisture, and soil water potential measurements. A simple regression model was found to correct data for both the sap flow and soil water potential sensors sampled on under-powered motes. By operating under less than optimal power levels, this effectively increases motes' battery life for reliable data collection from wireless sensor networks.","Sensors,
Batteries,
Wireless sensor networks,
Time division multiplexing,
Heating,
Probes,
Temperature measurement"
Orbital angular momentum generation in a 60GHz wireless radio channel,"We describe transmission of 4-Gbps uncompressed video utilizing a 60-GHz wireless channel with orbital angular momentum (OAM). The laboratory experiments were supported by Matlab simulation; this being utilized to generate holographic masks. Matlab code was further employed to control a printed circuit board (PCB) router drill. Any required shape on, for instance, copper or dielectric plates could be produces. An experimental setup was arranged to validate the transmission performance of 4-Gbps uncompressed video over 60-GHz OAM wireless channel we believe, for the first time. Good agreement was achieved between simulated and measured results. It is concluded that it is practically feasible to send multi-gigabit wireless data over an OAM channel.",
Group-based discovery in low-duty-cycle mobile sensor networks,"Wireless Sensor Networks have been used in many mobile applications such as wildlife tracking and participatory urban sensing. Because of the combination of high mobility and low-duty-cycle operations, it is a challenging issue to reduce discovery delay among mobile nodes, so that mobile nodes can establish connection quickly once they are within each other's vicinity. Existing discovery designs are essentially pair-wise based, in which discovery is passively achieved when two nodes are pre-scheduled to wake-up at the same time. In contrast, for the first time, this work reduces discovery delay significantly by proactively referring wake-up schedules among a group of nodes. Because proactive references incur additional overhead, we introduce a novel selective reference mechanism based on spatiotemporal properties of neighborhood and the mobility of the nodes. Our quantitative analysis indicates that the discovery delay of our group-based mechanism is significantly smaller than that of the pair-wise one. Our testbed experiments using 40 sensor nodes confirm our theoretical analysis, showing one order of magnitude reduction in discovery delay compared with traditional pair-wise methods with only 0.5%~8.8% increase in energy consumption.","Delay,
Schedules,
Protocols,
Mobile computing"
Economic and environmental performances quantification of the university of Genoa Smart Polygeneration Microgrid,"Nowadays, one of the most important research lines on smart power grids and microgrids is related to the evaluation of how such active infrastructures can increase energy efficiency, minimize greenhouse gases emissions and contribute to a deeper penetration of renewable energy sources. To investigate this issue, several test-bed facilities/demonstrators have been designed and are now running or under construction all over the world in order to perform experimental research and testing. Among them, it is important to cite the Smart Polygeneration Microgrid (SPM) developed by the University of Genoa at Savona Campus facilities. The present paper describes the SPM structure and proposes a general method to estimate its economic and environmental benefits connected with the use of renewable energy sources and cogeneration plants; in particular, the attention is focused on the SPM running costs, the CO2 emissions and the primary energy use. The calculation method is explained in details, referring to the “winter configuration” of the SPM trigeneration system.","Cogeneration,
Turbines,
Boilers,
Natural gas,
Economics,
Educational institutions,
Production"
Sugeno fuzzy integral generalizations for Sub-normal Fuzzy set-valued inputs,"In prior work, Grabisch put forth a direct (i.e., result of the Extension Principle) generalization of the Sugeno fuzzy integral (FI) for fuzzy set (FS)-valued normal (height equal to one) integrands and number-based fuzzy measures (FMs). Grabisch's proof is based in large on Dubois and Prade's analysis of functions on intervals, fuzzy numbers (thus normal FSs) and fuzzy arithmetic. However, a case not studied is the extension of the FI for sub-normal FS integrands. In prior work, we described a real-world forensic application in anthropology that requires fusion and has sub-normal FS inputs. We put forth an alternative non-direct approach for calculating FS results from sub-normal FS inputs based on the use of the number-valued integrand and number-valued FM Sugeno FI. In this article, we discuss a direct generalization of the Sugeno FI for sub-normal FS integrands and numeric FMs, called the Sub-normal Fuzzy Integral (SuFI). To no great surprise, it turns out that the SuFI algorithm is a special case of Grabisch's generalization. An algorithm for calculating SuFI and its mathematical properties are compared to our prior method, the Non-Direct Fuzzy Integral (NDFI). It turns out that SuFI and NDFI fuse in very different ways. We assert that in some settings, e.g., skeletal age-at-death estimation, NDFI is preferred to SuFI. Numeric examples are provided to stress important inner workings and differences between the FI generalizations.","Frequency selective surfaces,
Frequency modulation,
Aging,
Estimation,
Radar,
Educational institutions,
Electronic mail"
Electrical Characteristics of Top-Down ZnO Nanowire Transistors Using Remote Plasma ALD,"Top-down fabrication is used to produce ZnO nanowires by remote plasma atomic layer deposition over a SiO2 pillar and anisotropic dry etching. Nanowire field-effect transistors (FETs), with channel lengths in the range of 1.3-18.6 μm, are then fabricated using these 80 nm × 40 nm nanowires. Measured electrical results show n-type enhancement behavior and a breakdown voltage ≥75 V at all channel lengths. This is the first report of high-voltage operation for ZnO nanowire FETs. Reproducible well-behaved electrical characteristics are obtained, and the drain current scales with 1/L, as expected for long-channel FETs. A respectable ION/IOFF ratio of 2×106 is obtained.","Zinc oxide,
FETs,
Nanoscale devices,
Plasmas,
Fabrication,
Electric variables"
Quantifying Video-QoE Degradations of Internet Links,"With the proliferation of multimedia content on the Internet, there is an increasing demand for video streams with high perceptual quality. The capability of present-day Internet links in delivering high-perceptual-quality streaming services, however, is not completely understood. Link-level degradations caused by intradomain routing policies and inter-ISP peering policies are hard to obtain, as Internet service providers often consider such information proprietary. Understanding link-level degradations will enable us in designing future protocols, policies, and architectures to meet the rising multimedia demands. This paper presents a trace-driven study to understand quality-of-experience (QoE) capabilities of present-day Internet links using 51 diverse ISPs with a major presence in the US, Europe, and Asia-Pacific. We study their links from 38 vantage points in the Internet using both passive tracing and active probing for six days. We provide the first measurements of link-level degradations and case studies of intra-ISP and inter-ISP peering links from a multimedia standpoint. Our study offers surprising insights into intradomain traffic engineering, peering link loading, BGP, and the inefficiencies of using autonomous system (AS)-path lengths as a routing metric. Though our results indicate that Internet routing policies are not optimized for delivering high-perceptual-quality streaming services, we argue that alternative strategies such as overlay networks can help meet QoE demands over the Internet. Streaming services apart, our Internet measurement results can be used as an input to a variety of research problems.","Internet,
Jitter,
Streaming media,
Delay,
Routing,
Extraterrestrial measurements,
Probes"
Adaptive Image Registration via Hierarchical Voronoi Subdivision,"Advances in image acquisition systems have made it possible to capture high-resolution images of a scene, recording considerable scene details. With increased resolution comes increased image size and geometric difference between multiview images, complicating image registration. Through Voronoi subdivision, we subdivide large images into small corresponding regions, and by registering small regions, we register the images in a piecewise manner. Image subdivision reduces the geometric difference between regions that are registered and simplifies the correspondence process. The proposed method is a hierarchical one. While previous methods use the same block size and shape at a hierarchy, the proposed method adapts the block size and shape to the local image details and geometric difference between the images. This adaptation makes it possible to keep geometric difference between corresponding regions small and simplifies the correspondence process. Implementational details of the proposed image registration method are provided, and experimental results on various types of images are presented and analyzed.","Image registration,
Cities and towns,
Detectors,
Registers,
Spatial resolution,
Noise"
Nonlinear Approach for Enhancement of Image Focus Volume in Shape From Focus,"Mostly, shape-from-focus algorithms use local averaging using a fixed rectangle window to enhance the initial focus volume. In this linear filtering, the window size affects the accuracy of the depth map. A small window is unable to suppress the noise properly, whereas a large window oversmoothes the object shape. Moreover, the use of any window size smoothes focus values uniformly. Consequently, an erroneous depth map is obtained. In this paper, we suggest the use of iterative 3-D anisotropic nonlinear diffusion filtering (ANDF) to enhance the image focus volume. In contrast to linear filtering, ANDF utilizes the local structure of the focus values to suppress the noise while preserving edges. The proposed scheme is tested using image sequences of synthetic and real objects, and results have demonstrated its effectiveness.",
Detailed Investigation of Mode-Field Adapters Utilizing Multimode-Interference in Graded Index Fibers,"We present a detailed study of mode-field adapters (MFA) based on multimode interference in graded index multimode fibers. We have fabricated and characterized MFAs from a selection of commercially available single-mode and graded index fibers. Compared to existing techniques, the presented MFAs can be fabricated very quickly and are not limited to certain fiber types. Insertion losses of <; 0.5 dB over a spectral range of several hundred nanometers have been obtained, which is comparable or better than the industry standard.","Optical fiber devices,
Couplings,
Indexes,
Optical fiber dispersion,
Wavelength measurement,
Interference,
Equations"
Co-design techniques for distributed real-time embedded systems with communication security constraints,"In this paper we consider distributed real-time embedded systems in which confidentiality of the internal communication is critical. We present an approach to efficiently implement cryptographic algorithms by using hardware/software co-design techniques. The objective is to find the minimal hardware overhead and corresponding process mapping for encryption and decryption tasks of the system, so that the confidentiality requirements for the messages transmitted over the internal communication bus are fulfilled, and time constraints are satisfied. Towards this, we formulate the optimization problems using Constraint Logic Programming (CLP), which returns optimal solutions. However, CLP executions are computationally expensive and, hence, efficient heuristics are proposed as an alternative. Extensive experiments demonstrate the efficiency of the proposed heuristic approaches.","Field programmable gate arrays,
Encryption,
Hardware,
Software,
Schedules"
An integrated low-cost system for at-home rehabilitation,"We show here how integrating novel natural user interfaces, like Microsoft Kinect, with a fully adappatient's current statustive game engine, a system that can be used for rehabilitation at home can be built. A wide variety of game scenarios, a balanced scoring system, quantitative and qualitative exercise evaluation, automatic gameplay level adaptation to patient's current status, and audiovisual feed-back are all implemented inside the Intelligent Game Engine for Rehabilitation here introduced, and are aimed at maximizing patient's motivation and rehabilitation effectiveness. The system is integrated into a multi-level platform that provides continuous monitoring by the hospital and it has been developed inside the framework of the EU funded Rewire project.","Games,
Hospitals,
Engines,
Monitoring,
Robots,
Avatars,
Joints"
Seizure Detection Using the Phase-Slope Index and Multichannel ECoG,"Detection and analysis of epileptic seizures is of clinical and research interest. We propose a novel seizure detection and analysis scheme based on the phase-slope index (PSI) of directed influence applied to multichannel electrocorticogram data. The PSI metric identifies increases in the spatio-temporal interactions between channels that clearly distinguish seizure from interictal activity. We form a global metric of interaction between channels and compare this metric to a threshold to detect the presence of seizures. The threshold is chosen based on a moving average of recent activity to accommodate differences between patients and slow changes within each patient over time. We evaluate detection performance over a challenging population of five patients with different types of epilepsy using a total of 47 seizures in nearly 258 h of recorded data. Using a common threshold procedure, we show that our approach detects all of the seizures in four of the five patients with a false detection rate less than two per hour. A variation on the global metric is proposed to identify which channels are strong drivers of activity in each patient. These metrics are computationally efficient and suitable for real-time application.",
A C-Band AlGaN-GaN MMIC HPA for SAR,"A C-Band MMIC high power amplifier (HPA) has been designed exploiting a 0.25 μm HEMT GaN process on SiC substrate. The HPA is designed for future synthetic aperture radar (SAR) antenna applications. The HPA delivers 16 W output power with PAE over 38% at 6 dB gain compression within a 900 MHz bandwidth around 5.75 GHz. Up to 20 W output power and 40% PAE are obtained at higher gain compression. A comparison with another amplifier, differing only for the layout of the devices in the final stage, points out that the transistor thermal conditions represent the main limitation for this high power density technology.","Gallium nitride,
MMICs,
Power generation,
Gain,
Performance evaluation,
Synthetic aperture radar,
HEMTs"
Equivalent vehicle rotational inertia used for electric vehicle test bench dynamic studies,"This paper provides an easy yet accurate approach for estimating vehicle inertia for the purpose of simulating the effect of vehicle inertia using a large flywheel. The method used to properly map the linear inertia of a vehicle to an equivalent rotational inertia is described in detail and an expression for equivalent rotational inertia of a vehicle is derived analytically using two different approaches considering kinetic energy of a moving mass in the linear and rotational context and vehicle dynamic equations. A MATLAB/Simulink model of a test bench consisting of a torque actuator connected to a large flywheel is used to emulate the effect of vehicle inertia. Using this model, the dynamic inertia effect of an electric vehicle on its traction motor is illustrated for two standard drive cycles. The results obtained from simulation are validated by ADVISOR to confirm the effectiveness of the proposed method in estimating vehicle inertia and it is shown that the use of a flywheel with a calculated rotational inertia using the proposed method can be sufficient in emulating vehicle inertia effect on a test bench.","MATLAB,
Vehicles,
Vehicle dynamics,
Reliability,
Wheels,
Mathematical model"
SAFER PATH: Security architecture using fragmented execution and replication for protection against trojaned hardware,"Ensuring electronic components are free from Hardware Trojans is a very difficult task. Research suggests that even the best pre- and post-deployment detection mechanisms will not discover all malicious inclusions, nor prevent them from being activated. For economic reasons electronic components are used regardless of the possible presence of such Trojans. We developed the SAFER PATH architecture, which uses instruction and data fragmentation, program replication, and voting to create a computational system that is able to operate safely in the presence of active Hardware Trojans. We protect the integrity of the computation, the confidentiality of data being processed and ensure system availability. By combining a small Trusted Computing Base with Commercial-Off-The-Shelf processing elements, we are able to protect computation from the effects of arbitrary Hardware Trojans.","Program processors,
Hardware,
Trojan horses,
Switches,
Random access memory,
Computer architecture"
Egocentric Real-time Workspace Monitoring using an RGB-D camera,"We describe an integrated system for personal workspace monitoring based around an RGB-D sensor. The approach is egocentric, facilitating full flexibility, and operates in real-time, providing object detection and recognition, and 3D trajectory estimation whilst the user undertakes tasks in the workspace. A prototype on-body system developed in the context of work-flow analysis for industrial manipulation and assembly tasks is described. The system is evaluated on two tasks with multiple users, and results indicate that the method is effective, giving good accuracy performance.","Cameras,
Real-time systems,
Trajectory,
Image segmentation,
Image color analysis,
Monitoring,
Robot sensing systems"
"A Formal Approach to Designing Cryptographic Processors Based on
GF(
2
m
)
Arithmetic Circuits","This paper proposes a formal approach to designing Galois-field (GF) arithmetic circuits, which are widely used in modern cryptographic processors. Our method describes GF arithmetic circuits in a hierarchical manner with high-level directed graphs associated with specific GFs and arithmetic functions. The proposed circuit description can be effectively verified by symbolic computations based on polynomial reduction using Grobner bases. The verified description is then translated into the equivalent hardware description language (HDL) codes, which are available for the conventional design flow. We first describe the proposed graph representation and present an example of the description and verification. The significant advantage of the proposed approach is demonstrated through experimental designs of parallel multipliers over GF(2m) for different word lengths and irreducible polynomials. The result shows that the proposed approach has a definite capability of formally verifying practical GF arithmetic circuits for which the conventional techniques fail. We also propose an application of this approach to cryptographic processor design. The target considered here is a 128-bit advanced encryption standard (AES) data path with a loop architecture. To the best of the authors' knowledge, this is the first verification of this type of practical AES data path. We present a detailed description of the AES data path and its verification. The proposed approach successfully verifies the AES data path description within 800 s.","Polynomials,
Program processors,
Cryptography,
IP networks,
Hardware design languages,
Generators"
Smart Association Control in Wireless Mobile Environment Using Max-Flow,"WiFi clients must associate to a specific Access Point (AP) to communicate over the Internet. Current association methods are based on maximum Received Signal Strength Index (RSSI) implying that a client associates to the strongest AP around it. This is a simple scheme that has performed well in purely distributed settings. Modern wireless networks, however, are increasingly being connected by a wired backbone. The backbone allows for out-of-band communication among APs, opening up opportunities for improved protocol design. This paper takes advantage of this opportunity through a coordinated client association scheme where APs consider a global view of the network, and decide on the optimal client-AP association. We show that such an association outperforms RSSI based schemes in several scenarios, while remaining practical and scalable for wide-scale deployment. We also show that optimal association is a NP-Hard problem and our max-flow based heuristic is a promising solution.","Bandwidth,
Resource management,
Protocols,
IEEE 802.11 Standards,
Throughput,
Wireless communication,
Channel allocation"
Quality of service in Plug-in Electric Vehicle charging infrastructure,"Electrification of transportation is offering reduced vehicle emissions and operating costs in addition to increased energy-independence. Electric cars are anticipated to be adopted as passenger vehicles and in commercial fleets in the near future. Plug-in Hybrid Electric Vehicles (PHEVs) can drive on battery up to few hundred miles with the current battery technologies. Depleting PHEV batteries are charged from the power grid either with a Level 1 or Level 2 charger where the latter delivers more power than the former. Despite the advantages of PHEVs, charging several PHEVs simultaneously from the same distribution system may cause local outages due to transformer overloading. Thus, PHEV charging infrastructure calls for admission control schemes that operate on the smart grid. It is also essential to provide service differentiation to increase consumer satisfaction. In this paper, we propose a Quality of Service (QoS)-aware admission control scheme for the PHEV charging infrastructure. Our scheme operates on the Energy Management System (EMS) of the smart grid distribution system. The proposed approach relies on a wireless communication network that delivers the demands of PHEVs to the EMS and delivers the admission decisions of EMS to PHEVs. In our admission control scheme, PHEV owners who are willing to pay more can charge faster than the “best-effort” users similar to the Internet traffic service differentiation mechanisms. We provide mathematical analysis and simulation results for the proposed scheme. We show that high priority PHEVs are supplied with higher power rating, hence they are able to charge faster than low priority PHEVs.",
Traps and pitfalls of using contact traces in performance studies of opportunistic networks,"Contact-based simulations are a very popular tool for the analysis of opportunistic networks. They are used for evaluation of networking metrics, for quantifying the effects of infrastructure and for the design of forwarding strategies. However, little evidence exists that the results of such simulations accurately describe the performance of opportunistic networks, as they commonly ignore some important factors (like limited transmission bandwidth) or they rely on assumptions such as infinite user cache sizes. In order to evaluate this issue, we design a testbed with a real application and real users; we collect application data in addition to the contact traces and compare measured performance to the results of the contact-based simulations. We find that contact-based simulations significantly overestimate delivery ratio, while the captured delay tends to be 2-3 times lower than the experimentally obtained delay. We show that assuming infinite cache sizes leads to misinterpretation of the effects of backbone on an opportunistic network. Finally, we show that contact traces can be used to analytically estimate the delivery ratios and the impact of backbone, through the dependency between a user centrality measure and her delivery ratio.","Twitter,
Internet,
Delay,
Servers,
Performance evaluation,
Logic gates"
"On
2k
-Variable Symmetric Boolean Functions With Maximum Algebraic Immunity
k","Given a positive even integer n, it is found that the weight distribution of any n-variable symmetric Boolean function with maximum algebraic immunity (AI) n/2 is determined by the binary expansion of n . Based on the foregoing, all n-variable symmetric Boolean functions with maximum AI are constructed. The amount is (2 wt(n)+1)2[log2n].",
AALO: Activity recognition in smart homes using Active Learning in the presence of Overlapped activities,"We present AALO: a novel Activity recognition system for single person smart homes using Active Learning in the presence of Overlapped activities. AALO applies data mining techniques to cluster in-home sensor firings so that each cluster represents instances of the same activity. Users only need to label each cluster as an activity as opposed to labeling all instances of all activities. Once the clusters are associated to their corresponding activities, our system can recognize future activities. To improve the activity recognition accuracy, our system preprocesses raw sensor data by identifying overlapping activities. The evaluation of activity recognition performance on a 26-day dataset shows that compared to Naive Bayesian (NB), Hidden Markov Model (HMM), and Hidden Semi Markov Model (HSMM) based activity recognition systems, our average time slice error (24.15%) is much lower than NB (53.04%), and similar to HMM (29.97%) and HSMM (26.29%). Thus, our active learning based approach performs as good as the state of the art supervised techniques (HMM and HSMM).","Microwave filters,
Clustering algorithms"
Vanishing point detection in corridors: using hough transform and K-means clustering,"One of the main challenges in steering a vehicle or a robot is the detection of appropriate heading. Many solutions have been proposed during the past few decades to overcome the difficulties of intelligent navigation platforms. In this study, the authors try to introduce a new procedure for finding the vanishing point based on the visual information and K-Means clustering. Unlike other solutions the authors do not need to find the intersection of lines to extract the vanishing point. This has reduced the complexity and the processing time of our algorithm to a large extent. The authors have imported the minimum possible information to the Hough space by using only two pixels (the points) of each line (start point and end point) instead of hundreds of pixels that form a line. This has reduced the mathematical complexity of our algorithm while maintaining very efficient functioning. The most important and unique characteristic of our algorithm is the usage of processed data for other important tasks in navigation such as mapping and localisation.","robot vision,
Hough transforms,
mobile robots,
path planning,
pattern clustering"
Low-power IPv6 for the Internet of Things,"The Internet of Things allows physical objects, sensors, and actuators to be connected to each other as well as cloud services. Over the past few years, advances in wireless protocols, software systems, and standardization for IPv6 points to a future where every physical object that can benefit from an Internet connection will be connected to the Internet. This paper presents the IPv6 networking support in the Contiki operating system, the system that first introduced the concept of IP networking for low-power wireless systems. We discuss the design and implementation of IPv6 in Contiki as well as the methods used to develop and evaluate low-power mechanisms.","IP networks,
Routing,
Measurement,
Routing protocols,
Power demand,
Wireless sensor networks"
Research on the improvement of MongoDB Auto-Sharding in cloud environment,"With the rapid development of the Internet Web 2.0 technology, the demands of large-scale distributed service and storage in cloud computing have brought great challenges to traditional relational database. NoSQL database which breaks the shackles of RDBMS is becoming the focus of attention. In this paper, the principles and implementation mechanisms of Auto-Sharding in MongoDB database are firstly presented, then an improved algorithm based on the frequency of data operation is proposed in order to solve the problem of uneven distribution of data in auto-sharding. The improved balancing strategy can effectively balance the data among shards, and improve the cluster's concurrent reading and writing performance.","Distributed databases,
Clustering algorithms,
Servers,
Cloud computing,
Writing,
Algorithm design and analysis"
The Effectiveness of Opportunistic Spectrum Access: A Measurement Study,"Dynamic spectrum access networks are designed to allow today's bandwidth-hungry “secondary devices” to share spectrum allocated to legacy devices, or “primary users.” The success of this wireless communication model relies on the availability of unused spectrum and the ability of secondary devices to utilize spectrum without disrupting transmissions of primary users. While recent measurement studies have shown that there is sufficient underutilized spectrum available, little is known about whether secondary devices can efficiently make use of available spectrum while minimizing disruptions to primary users. In this paper, we present the first comprehensive study on the presence of “usable” spectrum in opportunistic spectrum access systems, and whether sufficient spectrum can be extracted by secondary devices to support traditional networking applications. We use for our study fine-grain usage traces of a wide spectrum range (20 MHz–6 GHz) taken at four locations in Germany, the Netherlands, and Santa Barbara, CA. Our study shows that on average, 54% of spectrum is never used and 26% is only partially used. Surprisingly, in this 26% of partially used spectrum, secondary devices can utilize very little spectrum using conservative access policies to minimize interference with primary users. Even assuming an optimal access scheme and extensive statistical knowledge of primary-user access patterns, a user can only extract between 20%–30% of the total available spectrum. To provide better spectrum availability, we propose frequency bundling, where secondary devices build reliable channels by combining multiple unreliable frequencies into virtual frequency bundles. Analyzing our traces, we find that there is little correlation of spectrum availability across channels, and that bundling random channels together can provide sustained periods of reliable transmission with only short interruptions.",
Dynamic adaptive Search Based Software Engineering,"Search Based Software Engineering (SBSE) has proved to be a very effective way of optimising software engineering problems. Nevertheless, its full potential as a means of dynamic adaptivity remains under explored. This paper sets out the agenda for Dynamic Adaptive SBSE, in which the optimisation is embedded into deployed software to create self-optimising adaptive systems. Dynamic Adaptive SBSE will move the research agenda forward to encompass both software development processes and the software products they produce, addressing the long-standing, and as yet largely unsolved, grand challenge of self-adaptive systems.",
Fast error aware model for arithmetic and logic circuits,"As a result of supply voltage reduction and process variations effects, the error free margin for dynamic voltage scaling has been drastically reduced. This paper presents an error aware model for arithmetic and logic circuits that accurately and rapidly estimates the propagation delays of the output bits in a digital block operating under voltage scaling to identify circuit-level failures (timing violations) within the block. Consequently, these failure models are then used to examine how circuit-level failures affect system-level reliability. A case study consisting of a CORDIC DSP unit employing the proposed model provides tradeoffs between power, performance and reliability.","Propagation delay,
Logic gates,
Delay,
Integrated circuit modeling,
Vectors,
Table lookup"
What Makes a Professional Video? A Computational Aesthetics Approach,"Understanding the characteristics of high-quality professional videos is important for video classification, video quality measurement, and video enhancement. A professional video is good not only for its interesting story but also for its high visual quality. In this paper, we study what makes a professional video from the perspective of aesthetics. We discuss how a professional video is created and correspondingly design a variety of features that distinguish professional videos from amateur ones. We study general aesthetics features that are applied to still photos and extend them to videos. We design a variety of features that are particularly relevant to videos. We examined the performance of these features in the problem of professional and amateur video classification. Our experiments show that with these features, 97.3% professional and amateur shot classification accuracy rate is achieved on our own data set and 91.2% professional video detection rate is achieved on a public professional video set. Our experiments also show that the features that are particularly for videos are shown most effective for this task.","Cameras,
Trajectory,
Feature extraction,
Cinematography,
Image color analysis,
Lighting,
Visualization"
Design of a network-based mobile gait rehabilitation system,"In this paper, a network-based mobile gait rehabilitation system is proposed for improved mobility and tele-rehabilitation. In this system, an Internet-based body sensor network is employed for health monitoring and a local highspeed wireless network is developed to achieve precise control of the gait rehabilitation device, which is a compact rotary elastic actuator (cRSEA). A new wireless protocol called MBStarPlus is proposed to achieve a high sampling rate and real-time communication. To deal with packet loss in the wireless network, a modified linear quadratic Gaussian (LQG) controller is combined with a disturbance observer (DOB) to control the cRSEA over the wireless network. Successful system integration and promising experimental results validate both the system design and proposed control algorithm. The plan for clinical testing with the proposed system is discussed.","telemedicine,
actuators,
body sensor networks,
Internet,
linear quadratic Gaussian control,
patient monitoring,
patient rehabilitation"
Optimal Aviation Security Screening Strategies With Dynamic Passenger Risk Updates,"Passenger screening is a critical component of aviation security systems. This paper introduces the multistage sequential passenger screening problem (MSPSP), which models passenger and carry-on baggage screening operations in an aviation security system with the capability of dynamically updating the perceived risk of passengers. The passenger screening operation at an airport terminal is subdivided into multiple screening stages, with decisions made to assign each passenger to one of several available security classes at each such stage. Each passenger's assessed threat value (initially determined by an automated passenger prescreening system) is updated after the passenger proceeds through each screening stage. The objective of MSPSP is to maximize the total security of all passenger screening decisions over a fixed time period, given passenger perceived risk levels and security device performance parameters. An optimal policy for screening passengers in MSPSP is obtained using optimal sequential assignment theory. A Monte Carlo simulation-based heuristic is presented and compared with stochastic sequential assignment and feedback control algorithms. Computational analysis of a two-stage security system provides an assessment of the total security performance.","Security,
Airports,
Random variables,
Atmospheric modeling,
Monte Carlo methods,
Performance evaluation,
Risk management"
Optimal Frequency-Temporal Opportunity Exploitation for Multichannel Ad Hoc Networks,"In multichannel system, user could keep transmitting over an instantaneous “on peak” channel by opportunistically accessing and switching among channels. Previous studies rely on constant transmission duration, which would fail to leverage more opportunities in time and frequency domain. In this paper, we consider opportunistic channel accessing/releasing scheme in multichannel system with Rayleigh fading channels. Our main goal is to derive a throughput-optimal strategy for determining when and which channel to access and when to release it. We formulate this real-time decision-making process as a two-dimensional optimal stopping problem. We prove that the two-dimensional optimal stopping rule can be reduced to a simple threshold-based policy. Leveraging the absorbing Markov chain theory, we obtain the optimal threshold as well as the maximum achievable throughput with computational efficiency. Numerical and simulation results show that our proposed channel utilization scheme achieves up to 140 percent throughput gain over opportunistic transmission with a single channel and up to 60 percent throughput gain over opportunistic channel access with constant transmission duration.","Throughput,
Time frequency analysis,
Fading channels,
Frequency domain analysis,
Markov processes,
Data communication,
Receivers"
A coordinated primary frequency regulation from Permanent Magnet Synchronous Wind Turbine Generation,"As a growing number of Permanent Magnet Synchronous Wind Turbine Generations (PMSG-WT) are integrated into the modern power grid, there has been a great concern for system operators who expects PMSG-WT to play an active role in the primary frequency regulation when frequency event occurs. However, PMSG-WTs are still unable to provide any additional active power in response to the system frequency change. In this work, a control scheme of coordinated frequency regulation for DFIG is redesigned and implemented into a PMSG-WT model by synthesizing the inertial control, over-rotor speed control and pitch angle control. Inertial control emulates the total inertia response of both wind turbine and generator to provide a short-term frequency support. According to the de-loaded optimum power extraction curve, the over-rotor speed and pitch angle controls are coordinated to maintain the reserved power and meanwhile assist the primary frequency regulation in a long-term period. The coordinated control strategy of PMSG-WT comprises the low, medium and high wind speed modes. By this means, the comprehensive control method will promote the PMSG-based wind farms to effectively participate in the system frequency regulation under a full scope of wind speed conditions.","Frequency control,
Rotors,
Wind turbines,
Wind speed,
Wind power generation,
Generators,
Velocity control"
Comparing demand side management approaches,"Due to increasing energy prices and the greenhouse effect, a more efficient energy supply is desirable, preferably based on renewable sources. To cope with the decrease of flexibility due to the introduction of renewables in production side of the supply chain, a more flexible consumer side is required. In literature, a lot of management methodologies are proposed to exploit the flexibility of consuming devices. Due to the large number of devices, these methodologies are often based on cost functions. Comparing the results of different methodologies is hard since differences in results can be caused by the methodologies itself or by less good defined cost functions. In this paper an auction based realtime control is compared with an ILP based realtime control using identical cost functions. Furthermore, the influence of planning on these strategies is studied. The simulation results show that planning leads to better and more predictable results. Furthermore, planning is best combined with an auction. However, the auction should slightly be altered to decrease communication and to be able to cope with (local) grid constraints.",
Marionette mass-spring model for 3D gait biometrics,"Though interest in gait biometrics continues to increase, there have as yet been few approaches which use modelbased algorithms with temporal 3D data. In this paper we describe a new 3D model-based approach using a marionette and mass-spring model to gait biometrics with 3D voxel gait dataset. To model the articulated human body, we use a stick-figure which emulates the marionettes' motion and joint structure. The stick-figure has 11 nodes representing the human joints of head, torso, and lower legs. Each node is linked with at least one other node by a spring. The voxel data points in the next frame have a role as attractor which able to generate forces for each node and then iteratively warp the model into the data. This process is repeated for successive frames for one gait period. The motion kinematics extracted from this tracking process are projected into the sagittal and the frontal plane and used as a gait feature via the discrete Fourier transform. We use 46 subjects where each subject has 4 sample sequences and report encouraging initial gait classification results.","Three dimensional displays,
Biological system modeling,
Data models,
Springs,
Solid modeling,
Kinematics,
Force"
Fixed-Point Analysis and Parameter Selections of MSR-CORDIC With Applications to FFT Designs,"Mixed-scaling-rotation (MSR) coordinate rotation digital computer (CORDIC) is an attractive approach to synthesizing complex rotators. This paper presents the fixed-point error analysis and parameter selections of MSR-CORDIC with applications to the fast Fourier transform (FFT). First, the fixed-point mean squared error of the MSR-CORDIC is analyzed by considering both the angle approximation error and signal round-off error incurred in the finite precision arithmetic. The signal to quantization noise ratio (SQNR) of the output of the FFT synthesized using MSR-CORDIC is thereafter estimated. Based on these analyses, two different parameter selection algorithms of MSR-CORDIC are proposed for general and dedicated MSR-CORDIC structures. The proposed algorithms minimize the number of adders and word-length when the SQNR of the FFT output is constrained. Design examples show that the FFT designed by the proposed method exhibits a lower hardware complexity than existing methods.","Signal processing algorithms,
Approximation algorithms,
Algorithm design and analysis,
Approximation error,
Accuracy,
Optimization"
A Pattern-Recognition-Based Algorithm and Case Study for Clustering and Selecting Business Services,"Positioned as the backbone of service asset management console, a service registry has to enable real-time and offline service selection in an effective manner. This paper presents an analytic algorithm that is used to guide the architectural design of service exploration in a service registry. Service assets are proposed to be framed into a well-established categorical structure based on pattern recognition algorithm. This design aims to provide systematic methodology and enablement architecture for analyzing, clustering, and adapting heterogeneous services for dynamic application integration. The exploitation of pattern recognition algorithm maps a large amount of services into a manageable feature space, which consists of attributes that are related to static description and dynamic features, such as historical QoS and service-level agreement. The proposed architecture and associated service exploration methodology have been integrated into an industry strength service-oriented architecture solution design platform. We also present a case study using the developed platform to illustrate the proposed algorithm for business service clustering and selection.","Business,
Clustering algorithms,
Service oriented architecture,
Time factors,
Algorithm design and analysis,
Biomedical measurements,
Strontium"
Inter-and-intra data center VM-placement for energy-efficient large-Scale cloud systems,"Data centers play the crucial role in the delivery of Cloud services by enabling on-demand access to the shared resources such as software, platform, and infrastructure. Virtual Machine (VM) allocation is one of the challenging tasks in the data center management since user requirements, typically expressed as SLAs, have to be met with the minimum operational expenditure. Despite their huge processing and storage facilities, data centers are among the major contributors of the GreenHouse Gas (GHG) emissions of the IT services. In this paper, we propose a holistic approach for a large-scale Cloud system where the Cloud services are provisioned by several data centers interconnected over the backbone network. We propose a Mixed Integer Linear Programming (MILP) formulation that aims at virtualizing the backbone topology and placing the VMs in data centers with the objective of minimum power consumption. We compare our proposed solution with a benchmark MILP model which selects the closest data centers that can accommodate the user requests taking into account the CPU, memory, and bandwidth capacities of the residing physical hosts. Collected experimental results show the benefit of the proposed management scheme in terms of power consumption, resource utilization, and fairness for medium size data centers.","Power demand,
Benchmark testing,
Equations,
Topology,
Mathematical model,
Network topology,
Cloud computing"
Software models for Smart Grid,"Smart grid technology is progressing worldwide. Various Countries are investing to transform their traditional power grid to Smart grid. They have started realigning their organization to support a Smart grid vision. At this initial stage some software models are required to quantifiably evaluate, monitor the progress and plan for the realization of a smart grid. At present some models like Smart Grid Interoperability Maturity Model, Smart Grid Investment Model, Smart Grid Maturity Model and Smart Grid Conceptual Model are available. Smart Grid Interoperability Maturity Model is used to measure the current status of automation in the areas like transmission, distribution and demand side resources. The Smart Grid Investment Model is used in calculating different smart grid investments, along with their strategies. Smart Grid Maturity model is used in planning of utilities in smart grid transformation; prioritize the tasks and measuring their progress at every stage. Smart Grid Conceptual Model is used to analyze different standards and interoperations of smart grid development. A new proposed Smart Grid Monitoring Model will help in understanding smart grid deployment and capability within electric utility companies.","Smart grids,
Monitoring,
Standards organizations,
Organizations,
Investments,
Biological system modeling"
Optimal control strategy for HVAC system in building energy management,"Heating, ventilating and air conditioning (HVAC) systems have played an important role in building energy and comfort management. It is designed to provide a relatively constant and comfortable temperature in buildings and provide fresh and filtered air with a comfortable humidity level. In this paper, an optimal control strategy is proposed to control the HVAC system for maintaining building's indoor environment with high energy efficiency. The control strategy utilized swarm intelligence to determine the amount of energy dispatched to each equipment in the HVAC system. In order to study the impact of HVAC system operations in the indoor environment, both the building model and HVAC equipment models are developed. A case study is carried out to simulate the real time control process in a specified building environment.","Buildings,
Atmospheric modeling,
Ventilation,
Energy consumption,
Space heating,
Energy management"
Sparse feedback synthesis via the alternating direction method of multipliers,"We study the design of feedback gains that strike a balance between the H2 performance of distributed systems and the sparsity of controller. Our approach consists of two steps. First, we identify sparsity patterns of feedback gains by incorporating sparsity-promoting penalty functions into the H2 problem, where the added terms penalize the number of communication links in the distributed controller. Second, we optimize feedback gains subject to structural constraints determined by the identified sparsity patterns. In the first step, we identify sparsity structure of feedback gains using the alternating direction method of multipliers, which is a powerful algorithm well-suited to large optimization problems. This method alternates between optimizing the sparsity and optimizing the closed-loop H2 norm, which allows us to exploit the structure of the corresponding objective functions. In particular, we take advantage of the separability of sparsity-promoting penalty functions to decompose the minimization problem into sub-problems that can be solved analytically. An example is provided to illustrate the effectiveness of the developed approach.","Optimization,
Equations,
Minimization,
Optimal control,
Linear programming,
Standards,
Matrix decomposition"
The Evolution of Online Social Networks: A tutorial survey,The ideas discussed in this article encapsulate research questions surrounding the dynamics of social networking and social cognitive theory. Economic behavior in an online social network is investigated and the impact of incentives on user activity is examined for different experimental designs such as single unit and multiunit auctions.,"social networking (online),
cognition"
Efficient Resource Utilization for Multi-Flow Wireless Multicasting Transmissions,"Wireless multimedia services are major applications of next generation wireless networks. This paper is one of the first to study the efficient utilization of network resources for increasing the number of concurrent multimedia flows when a channel becomes saturated. We theoretically study the flow scheduling policy and the channel aggregation policy in both single-hop and multi-hop wireless networks with the motivation of ameliorating the trade-off between limited channel resources and multiple flow transmission. To increase the number of performance guaranteed multimedia flows, based on the dynamic states of wireless channels and the profiles of multimedia flows, the two policies fully utilize the performance gap to schedule concurrent flows for transmission in turn and aggregate multiple channels' residual capacities for useful flow transmissions. We then design a novel algorithm - efficient multi-flow multicast transmission (EMMT) - to apply the proposed policies to practical wireless multimedia multicast applications. At last, we use ns2 simulations to evaluate the studied policies and the EMMT algorithm. Our simulation results prove the effectiveness of our schemes in improving network ability to admit more multimedia flows.","Multimedia communication,
Wireless networks,
Delay,
Algorithm design and analysis,
Resource management,
Interference"
On the robustness of large 1-D network of double integrator agents,"We study the robustness to external disturbances of large 1-D network of double-integrator agents with distributed control. We provide precise quantitative comparison of certain H∞ norm between two common control architectures: predecessor-following and symmetric bidirectional. In particular, we show that the scaling laws of the H∞ norm for predecessor-following architecture is O(αN) (α >; 1), but only O(N3) for symmetric bidirectional architecture, where N is the number of agents in the network. The results for symmetric bidirectional architecture are obtained by using a PDE model to approximate the closed-loop dynamics of the network for large N. Numerical calculations show that the PDE approximation provides accurate predictions even when N is small. In addition, we examine the robustness of asymmetric bidirectional architecture. Numerical simulations show that with judicious asymmetry in the velocity feedback, the robustness of the network can be improved considerably over symmetric bidirectional and predecessor-following architectures.","Sensitivity,
Robustness,
Approximation methods,
Vehicle dynamics,
Computer architecture,
Eigenvalues and eigenfunctions,
Trajectory"
Optimized relay node placement for establishing connectivity in sensor networks,"Relay node placement in wireless sensor networks has gained importance due to its potential use in prolonging network life time, reducing data latency, and establishing connected topologies. In this paper we studied the relay node placement problem to establish multi-hop communication paths between every pair terminals (i.e., sensors) where each hop in the path is less than a common communication range. Such a problem is defined as Steiner Tree problem with minimum Steiner points and Bounded Edge-Length problem which is known to be NP-Hard. This paper presents a novel relay node placement heuristics called Incremental Optimization based on Delaunay Triangulation (IO-DT). The algorithm takes advantage of feasibility of finding optimal solution for the case of three terminals. IO-DT calculates the Delaunay triangulation (DT) of terminals and iterates over the formed triangles. In each iteration the algorithm steinerizes a triangle as part of the final topology if selecting such a triangle provides a reduction in total number of relay node required as compared to the minimum spanning tree (mst) based approach. The time complexity of IO-DT is quadratic in the number of terminals, which is superior to competing schemes. The performance of the algorithm is validated through simulation.","wireless sensor networks,
computational complexity,
optimisation"
Demand side management of electric vehicles with uncertainty on arrival and departure times,"Uncertainty on arrival and departure times makes the scheduling of plug-in hybrid electric vehicles an intrinsically stochastic optimization problem. To take the stochastic nature of this problem into consideration, a scalable stochastic optimization strategy has been formulated. Generally, stochastic programming methods are computationally demanding and become impractical for large-scale problems. This work reduced the dimensionality of the scheduling problem with techniques from approximate dynamic programming. To illustrate the advantage of the stochastic algorithm a deterministic method has been formulated. Compared to the deterministic method, the proposed stochastic method can help an aggregator to reduce its expensive peak charging or avoid penalties for not fully charging the batteries of its clients.","Stochastic processes,
Optimization,
Dynamic programming,
Approximation algorithms,
Aerospace electronics,
Approximation methods,
Processor scheduling"
Robustness of Quantitative Compressive Sensing MRI: The Effect of Random Undersampling Patterns on Derived Parameters for DCE- and DSC-MRI,"Compressive sensing (CS) in Cartesian magnetic resonance imaging (MRI) involves random partial Fourier acquisitions. The random nature of these acquisitions can lead to variance in reconstruction errors. In quantitative MRI, variance in the reconstructed images translates to an uncertainty in the derived quantitative maps. We show that for a spatially regularized 2 ×-accelerated human breast CS DCE-MRI acquisition with a 1922 matrix size, the coefficients of variation (CoVs) in voxel-level parameters due to the random acquisition are 1.1%, 0.96%, and 1.5% for the tissue parameters Ktrans, ve, and vp, with an average error in the mean of -2.5%, -2.0%, and -3.7%, respectively. Only 5% of the acquisition schemes had a systematic underestimation larger than than 4.2%, 3.7%, and 6.1%, respectively. For a 2× -accelerated rat brain CS DSC-MRI study with a 642 matrix size, the CoVs due to the random acquisition were 19%, 9.5%, and 15% for the cerebral blood flow and blood volume and mean transit time, respectively, and the average errors in the tumor mean were 9.2%, 0.49%, and -7.0%, respectively. Across 11000 different CS reconstructions, we saw no outliers in the distribution of parameters, suggesting that, despite the random undersampling schemes, CS accelerated quantitative MRI may have a predictable level of performance.","Image reconstruction,
Magnetic resonance imaging,
Tumors,
Histograms,
Acceleration,
Blood,
Compressed sensing"
Mining Distinction and Commonality across Multiple Domains Using Generative Model for Text Classification,"The distribution difference among multiple domains has been exploited for cross-domain text categorization in recent years. Along this line, we show two new observations in this study. First, the data distribution difference is often due to the fact that different domains use different index words to express the same concept. Second, the association between the conceptual feature and the document class can be stable across domains. These two observations actually indicate the distinction and commonality across domains. Inspired by the above observations, we propose a generative statistical model, named Collaborative Dual-PLSA (CD-PLSA), to simultaneously capture both the domain distinction and commonality among multiple domains. Different from Probabilistic Latent Semantic Analysis (PLSA) with only one latent variable, the proposed model has two latent factors y and z, corresponding to word concept and document class, respectively. The shared commonality intertwines with the distinctions over multiple domains, and is also used as the bridge for knowledge transformation. An Expectation Maximization (EM) algorithm is developed to solve the CD-PLSA model, and further its distributed version is exploited to avoid uploading all the raw data to a centralized location and help to mitigate privacy concerns. After the training phase with all the data from multiple domains we propose to refine the immediate outputs using only the corresponding local data. In summary, we propose a two-phase method for cross-domain text classification, the first phase for collaborative training with all the data, and the second step for local refinement. Finally, we conduct extensive experiments over hundreds of classification tasks with multiple source domains and multiple target domains to validate the superiority of the proposed method over existing state-of-the-art methods of supervised and transfer learning. It is noted to mention that as shown by the experimental results CD-PLSA for the collaborative training is more tolerant of distribution differences, and the local refinement also gains significant improvement in terms of classification accuracy.","Data models,
Training,
Mathematical model,
Collaboration,
Joints,
Graphical models,
Companies"
Mobility-aware charger deployment for wireless rechargeable sensor networks,"Wireless charging technology is considered as one of the promising solutions to solve the energy limitation problem for large-scale wireless sensor networks. Obviously, charger deployment is a critical issue since the number of chargers would be limited by the network construction budget, which makes the full-coverage deployment of chargers infeasible. In many of the applications targeted by large-scale wireless sensor networks, end-devices are usually equipped by the human and their movement follows some degree of regularity. Therefore in this paper, we utilize this property to deploy chargers with partial coverage, with an objective to maximize the survival rate of end-devices. We prove this problem is NP-hard, and propose an algorithm to tackle it. The simulation results show that our proposed algorithm can significantly increase the survival rate of end-devices. To our knowledge, this is one of very first works that consider charger deployment with partial coverage in wireless rechargeable sensor networks.","Wireless sensor networks,
Wireless communication,
Batteries,
Postal services,
Humans,
Mobile communication,
Radiation detectors"
Controller design method for a cascaded converter system comprised of two DC-DC converters considering the effects of mutual interactions,"This work analyzes the stability conditions of a cascaded converter system comprised of two dc-dc converters and proposes a new controller design procedure for the two converters considering their dynamic interactions. First, it introduces a single converter small-signal model and its mathematical representation and derives the required transfer functions from it. Next, it uses the single converter model to reach the cascaded converter system model and derives the principal equations for analyzing stability and controller design. Finally, it proposes a new design method based on the analysis of the derived equations. The simulation and experimental results are also provided, which verify the design procedure.",
Bilateral teleoperation of underactuated unmanned aerial vehicles: The virtual slave concept,"In this paper, we present haptic teleoperation of underactuated unmanned aerial vehicles by providing a multidimensional generalization of the virtual slave concept. The proposed control architecture is composed of high-level and low-level controllers. The high-level controller commands the vehicle to accomplish specific tasks and renders both the state and the environment of the vehicle to the operator through haptic feedback. The low-level controller interprets the command signals from the operator, regulates the dynamics of the vehicle and feeds back its state to the high-level loop. Passivity of the teleoperation loop is always ensured independently of the choice of implementation of the low-level controller and the configuration of the flying hardware by a passivity-enforcing supervisor, which associates every action of the slave with an energy expense that can only be made available from a multi-state energy tank. The effectiveness of the proposed algorithm is illustrated with simulations and experimental tests.","Vehicles,
Vehicle dynamics,
Force feedback,
Couplings,
Gravity,
Humans"
Reference point based multi-objective optimization through decomposition,"In this paper we propose a user-preference based evolutionary algorithm that relies on decomposition strategies to convert a multi-objective problem into a set of single-objective problems. The use of a reference point allows the algorithm to focus the search on more preferred regions which can potentially save considerable amount of computational resources. The algorithm that we proposed, dynamically adapts the weight vectors and is able to converge close to the preferred regions. Combining decomposition strategies with reference point approaches paves the way for more effective optimization of many-objective problems. The use of a decomposition method alleviates the selection pressure problem associated with dominance-based approaches while a reference point allows a more focused search. The experimental results show that the proposed algorithm is capable of finding solutions close to the reference points specified by a decision maker. Moreover, our results show that high quality solutions can be obtained using less computational effort as compared to a state-of-the-art decomposition based evolutionary multi-objective algorithm.",Vectors
Junction temperature measurement of IGBTs using short circuit current,"In this paper, a method is proposed to measure the junction temperatures of IGBT discrete devices and modules using short circuit current. Experimental results show that the short circuit current has good sensitivity, linearity and selectivity, which is suitable to be used as temperature sensitive electrical parameters (TSEP). Test circuit and hardware design are proposed for junction temperature measurement in single phase and three phase converters. By connecting a temperature measurement unit to the converter and giving a short circuit pulse, the IGBT junction temperature can be measured.","Temperature measurement,
Insulated gate bipolar transistors,
Junctions,
Short circuit currents,
Temperature sensors,
Logic gates,
Calibration"
Topology connectivity analysis of internet infrastructure using graph spectra,"Understanding and modelling the Internet has been a major research challenge in part due to the complexity of the interaction among its protocols and in part due to multilevel, multidomain topological structure. It is therefore crucial to properly analyse each structural level of the Internet to gain a better understanding, as well as to improve its resilience properties. In this paper, first we present the physical and logical topologies of two ISPs and compare these topologies with the US interstate highway topology by using graph metrics and then using the normalised Laplacian spectrum. Our results indicate that physical network topologies are closely correlated with the motorway transportation topology. Finally, we study the spectral properties of various communication networks and observe that the spectral radius of the normalised Laplacian matrix is a good indicator of graph connectivity when comparing different size and order graphs.","Topology,
Network topology,
Eigenvalues and eigenfunctions,
Road transportation,
Measurement,
Laplace equations,
Symmetric matrices"
H.264/SVC Mode Decision Based on Optimal Stopping Theory,"Fast mode decision algorithms have been widely used in the video encoder implementation to reduce encoding complexity yet without much sacrifice in the coding performance. Optimal stopping theory, which addresses early termination for a generic class of decision problems, is adopted in this paper to achieve fast mode decision for the H.264/Scalable Video Coding standard. A constrained model is developed with optimal stopping, and the solutions to this model are employed to initialize the candidate mode list and predict the early termination. Comprehensive simulation results are conducted to demonstrate that the proposed method strikes a good balance between low encoding complexity and high coding efficiency.","Encoding,
Scalability,
Static VAr compensators,
Prediction algorithms,
Random variables,
Indexes,
Educational institutions"
Cloud monitoring for optimizing the QoS of hosted applications,"Cloud monitoring involves dynamically tracking the Quality of Service (QoS) parameters related to virtualized services (e.g., CPU, storage, network, appliances, etc.), the physical resources they share, and the applications running on them or data hosted on them. Monitoring techniques and services can help a cloud provider or application developer in regards to: (i) keeping the cloud services and hosted applications operating at peak efficiency; (ii) detecting variations in service and application performance; (iii) accounting the SLA violations of certain QoS parameters; and (iv) tracking the leave and join operations of cloud services due to failures and other dynamic configuration changes. In this paper, we describe the PhD research motivation, question, and approach and methodology related to developing novel cloud monitoring techniques and services enabling automated application QoS management under uncertainties.","Quality of service,
Monitoring,
Predictive models,
Hardware,
Cloud computing,
Adaptation models,
Computational modeling"
Robustness in Experiment Design,"This paper focuses on the problem of robust experiment design, i.e., how to design an input signal which gives relatively good estimation performance over a large number of systems and model structures. Specifically, we formulate the robust experiment design problem utilizing fundamental limitations on the variance of estimated parametric models as constraints. Using this formulation we design an input signal for situations where only diffuse a priori information is known about the system. Furthermore, we present a robust version of the unprejudiced optimal input design problem. To achieve this, we first develop a closed form solution for the input spectrum which minimizes the maximum weighted integral of the variance of the frequency response estimate over all model structures.","Noise,
Robustness,
Optimized production technology,
Analytical models,
Maximum likelihood estimation,
Frequency measurement,
Numerical models"
Insights on Media Streaming Progress Using BitTorrent-Like Protocols for On-Demand Streaming,"This paper develops analytical models that characterize the behavior of on-demand stored media content delivery using BitTorrent-like protocols. The models capture the effects of different piece selection policies, including Rarest-First, two variants of In-Order, and two probabilistic policies (Portion and Zipf). Our models provide insight into system behavior and help explain the sluggishness of the system with In-Order streaming. We use the models to compare different retrieval policies across a wide range of system parameters, including peer arrival rate, upload/download bandwidth, and seed residence time. We also provide quantitative results on the startup delays and retrieval times for streaming media delivery. Our results provide insights into the design tradeoffs for on-demand media streaming in peer-to-peer networks. Finally, the models are validated using simulations.","Media,
Delay,
Peer to peer computing,
Protocols,
Load modeling,
Probabilistic logic,
Steady-state"
On eliciting contribution measures in goal models,"Goal models have been found to be useful for supporting the decision making process in the early requirements phase. Through measuring contribution degrees of low-level decisions to the fulfilment of high-level quality goals and combining them with priority statements, it is possible to compare alternative solutions of the requirements problem against each other. But where do contribution measures come from and what is the right way to combine them in order to do such analysis? In this paper we describe how full application of the Analytic Hierarchy Process (AHP) can be used to quantitatively assess contribution relationships in goal models based on stakeholder input and how we can reason about the result in order to make informed decisions. An exploratory experiment shows that the proposed procedure is feasible and offers evidence that the resulting goal model is useful for guiding a decision. It also shows that situation-specific characteristics of the requirements problem at hand may influence stakeholder input in a variety of ways, a phenomenon that may need to be studied further in the context of eliciting such models.",
Topology Control in Cooperative Wireless Ad-Hoc Networks,"Topology control is to determine the transmission power of each node so as to maintain network connectivity and consume the minimum transmission power. Cooperative Communication (CC) is a new technology that allows multiple nodes to simultaneously transmit the same data. It can save transmission power and extend transmission coverage. However, prior research work on topology control considers CC only in the aspect of energy saving, not that of coverage extension. We observe that CC can bridge (link) disconnected networks and therefore identify the challenges in the development of a centralized topology control scheme, named shape Cooperative Bridges, which reduces transmission power of nodes as well as increases network connectivity. We propose three algorithms that select energy efficient neighbor nodes, which assist a source node to communicate with a destination node: an optimal method and two greedy heuristics. In addition, we consider a distributed version of the proposed topology control scheme. Our findings are substantiated by an extensive simulation study, through which we show that the shape Cooperative Bridges scheme substantially increases the connectivity with tolerable increase of transmission power compared to other existing topology control schemes, which means that it outperforms in terms of a connectivity-to-power ratio.","Network topology,
Topology,
Signal to noise ratio,
Wireless communication,
Ad hoc networks,
Bridges,
Heuristic algorithms"
A Trust and Reputation Model Considering Overall Peer Consulting Distribution,"In new widespread peer-to-peer (P2P) systems, peers are exposed to great risk due to frequent trading with unfamiliar peers. Therefore, trust and reputation mechanisms become important issues. For computational efficiency, this paper focuses on localized information trust/reputation mechanisms. Previous studies have not paid much attention to the overall distribution of peer interactions. Based on the scale-free feature of real-world networks, we introduce a power-law distribution of the number of neighbors in P2P trust and reputation systems. To rigorously distinguish the effects of the overall considerations introduced herein, we compare the model proposed in this paper with models in previous studies under the same set of parameters. Simulation results show that the proposed model can discern a small difference between real quality of service (QoS) and other peers' feedback while distinguishing the malicious peers, even when the exaggeration coefficient is high. When one or a group of peers change their QoS, the model exhibits a quick reaction to this change. This response is demonstrated by a rapid decrease in reliability when the QoS change is downward and a slow increase when the change is upward. A slow reaction to the upward QoS change may exclude those peers who frequently change their QoS and encourage consistent reliable service providers.","Quality of service,
Peer to peer computing,
Reliability,
Aggregates,
Measurement,
Humans,
Mathematical model"
